@article{LEE2025106477,
title = {From design to operation: Multi-agent AI for virtual in-situ modeling of digital twins in BIM},
journal = {Automation in Construction},
volume = {179},
pages = {106477},
year = {2025},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2025.106477},
url = {https://www.sciencedirect.com/science/article/pii/S0926580525005175},
author = {Jeyoon Lee and Jiteng Li and Sungmin Yoon},
keywords = {AI agent, Large language model, Digital twin, Building information modeling, Virtual in-situ modeling, Ontology},
abstract = {A virtual building model (VBM) is a mathematical representation that describes the behavior of a physical building. Accurate VBMs provide insightful information about the physical building within the digital twin (DT) framework. However, there is limited research on the autonomous construction of VBMs. To address this gap, this paper proposes a multi-agent artificial intelligence (AI) system that autonomously constructs VBM. The proposed system autonomously develops, calibrates, and manages virtual models that constitute the VBM by leveraging data and information generated throughout the building lifecycle within a BIM environment. The proposed method is validated on a real operating heating, ventilation, and air-conditioning (HVAC) system, autonomously developing a chilled water flow rate model (MAPE 2.27 %) and an evaporator inlet temperature model (RMSE 0.33°C). These results suggest the feasibility of autonomously constructing VBMs and contribute to shifting the DT paradigm from physical construction automation to the autonomous construction of VBM.}
}
@article{LOPES2022117291,
title = {Predicting the top-level ontological concepts of domain entities using word embeddings, informal definitions, and deep learning},
journal = {Expert Systems with Applications},
volume = {203},
pages = {117291},
year = {2022},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2022.117291},
url = {https://www.sciencedirect.com/science/article/pii/S095741742200656X},
author = {Alcides Gonçalves Lopes and Joel Luis Carbonera and Daniela Schimidt and Mara Abel},
keywords = {Ontology learning, Deep learning, Well-founded ontology},
abstract = {Ontology development is a challenging task that encompasses many time-consuming activities. One of these activities is the classification of the domain entities (concepts and instances) according to top-level concepts. This activity is usually performed manually by an ontology engineer. However, when the set of entities increases in size, associating each entity to the proper top-level ontological concept becomes challenging and requires a high level of expertise in both the target domain and ontology engineering. This paper proposes a deep learning approach that automatically classifies domain entities into top-level concepts using their informal definitions and the word embedding of the terms that represent them. From these inputs, we feed a deep neural network consisting of two modules: a feed-forward neural network and a bi-directional recurrent neural network with long short-term units. Our architecture combines both outputs of these modules into a dense layer and provides the probabilities of each candidate class. For validating our proposal, we have developed a dataset based on the OntoWordNet ontology, which provides a classification of WordNet synsets into concepts specified by DOLCE-lite-plus top-level ontology. Our experiments show that our proposal outperforms the baseline approaches by 6% regarding the F-score. In addition, our proposal is less affected by the polysemy in the terms that represent the domain entities than the compared approaches. Consequently, our proposal can consider more instances during its training than the baseline methods.}
}
@article{LIU2022100009,
title = {Representation and association of Chinese financial equity knowledge driven by multilayer ontology},
journal = {Data and Information Management},
volume = {6},
number = {3},
pages = {100009},
year = {2022},
issn = {2543-9251},
doi = {https://doi.org/10.1016/j.dim.2022.100009},
url = {https://www.sciencedirect.com/science/article/pii/S2543925122001073},
author = {Zhenghao Liu and Zhijian Zhang and Xi Zeng and Huakui Lv},
keywords = {Multilayer domain ontology, Concept cube, Financial equity, Knowledge association, Knowledge representation, Triple extraction},
abstract = {Aiming at the current situation of complex financial ownership structure and isolated data organization, this study referring to the methods for multi-layer hierarchical construct domain ontology modeling. At the same time, the three dimensions of industry, company and internal environment were integrated, and the concept cube was designed and constructed based on knowledge extraction and text classification technology, so as to provide a multi-level and fine-grained knowledge representation and association method for financial equity knowledge. The experimental results show that conceptual cube structure represents semantic information as a dense low-dimensional representation vector, which greatly enhances semantic relevance and interpretability. The multi-layer ontology-driven ownership structure reflects a variety of knowledge association patterns, and in the “Intelligent Financial Big Data System” developed by the research team, the association query of three categories of association relationships in the field of industry, enterprise and internal environment is realized, as well as the dynamic analysis and supervision of typical financial management problems.}
}
@article{WANG202312,
title = {SGMFQP: An ontology-based Swine Gut Microbiota Federated Query Platform},
journal = {Methods},
volume = {212},
pages = {12-20},
year = {2023},
issn = {1046-2023},
doi = {https://doi.org/10.1016/j.ymeth.2023.02.010},
url = {https://www.sciencedirect.com/science/article/pii/S1046202323000336},
author = {Ying Wang and Qin Jiang and Yilin Geng and Yuren Hu and Yue Tang and Jixiang Li and Junmei Zhang and Wolfgang Mayer and Shanmei Liu and Hong-Yu Zhang and Xianghua Yan and Zaiwen Feng},
keywords = {Swine gut microbiota, Ontology, Federated query, Workflow orchestration, Datalog},
abstract = {Gut microbiota plays a crucial role in modulating pig development and health, and gut microbiota characteristics are associated with differences in feed efficiency. To answer open questions in feed efficiency analysis, biologists seek to retrieve information across multiple heterogeneous data sources. However, this is error-prone and time-consuming work since the queries can involve a sequence of multiple sub-queries over several databases. We present an implementation of an ontology-based Swine Gut Microbiota Federated Query Platform (SGMFQP) that provides a convenient, automated, and efficient query service about swine feeding and gut microbiota. The system is constructed based on a domain-specific Swine Gut Microbiota Ontology (SGMO), which facilitates the construction of queries independent of the actual organization of the data in the individual sources. This process is supported by a template-based query interface. A Datalog+-based federated query engine transforms the queries into sub-queries tailored for each individual data source, and an automated workflow orchestration mechanism executes the queries in each source database and consolidates the results. The efficiency of the system is demonstrated on several swine feeding scenarios.}
}
@article{NEMATIYAN2023107709,
title = {Model-based systems engineering examination of failures ontology in aircraft turbine blades},
journal = {Engineering Failure Analysis},
volume = {154},
pages = {107709},
year = {2023},
issn = {1350-6307},
doi = {https://doi.org/10.1016/j.engfailanal.2023.107709},
url = {https://www.sciencedirect.com/science/article/pii/S1350630723006635},
author = {S. Nematiyan and Mohammad H. Sabour and M. Moradli and M. Tabatabaie},
keywords = {MBSE, Surface damage analysis, Hot section turbine blades, System engineering, Safety management systems, Failure-causes analysis},
abstract = {The concept of Systems Engineering (SE) is widely used in modern times, with approaches based on analyzing the levels and processes of a system. SE approaches are elaborate based on the interpretation of the system's levels and analyzing the whole process. Although such methods are usually used in the analysis of organizations or enormous systems, this effort attempts to show that the same SE analytical tools can be useable in the deepest level of a system. The study focuses on investigating the failure process of a turbine blade, which is considered a system component. The first essential issue in analyzing a system is its interactions with the environment and its effects on the system's internal cybernetics. The study identifies failure processes that cause structural damage as well-defined and tangible processes of microsystem interactions. The research provides a comprehensive architecture of possible failures in an aircraft's jet engine's hot section turbine blades, utilizing a systemic approach and SE tools such as SysML-based models and Domain Mapping Matrices (DMM) to allocate causes of these failures. This research aims to propose an allocated SE-oriented architecture of Failure-Causes in jet engine turbine blades that is more suitable for use in programming.}
}
@incollection{BLOUIN2021123,
title = {Chapter 5 - An integrated ontology for multi-paradigm modelling for cyber-physical systems},
editor = {Bedir Tekinerdogan and Dominique Blouin and Hans Vangheluwe and Miguel Goulão and Paulo Carreira and Vasco Amaral},
booktitle = {Multi-Paradigm Modelling Approaches for Cyber-Physical Systems},
publisher = {Academic Press},
pages = {123-145},
year = {2021},
isbn = {978-0-12-819105-7},
doi = {https://doi.org/10.1016/B978-0-12-819105-7.00010-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780128191057000106},
author = {Dominique Blouin and Rima Al-Ali and Holger Giese and Stefan Klikovits and Soumyadip Bandyopadhyay and Ankica Barišić and Ferhat Erata},
keywords = {Architectural viewpoints, model-based development process, modelling paradigm, multi-paradigm modelling, cyber-physical systems, model management, ontology, OWL, Protégé},
abstract = {This chapter presents the Multi-Paradigm Modelling for Cyber-Physical Systems (MPM4CPS) ontology. This ontology integrates the Shared, MPM and CPS ontologies respectively introduced in Chapters 2, 3 and 4. It includes cross-cutting notions such as viewpoints, model-based development processes and modelling paradigms that together relate the formalisms and workflows (and their paradigms) to the part of CPSs developed with these formalisms. A brief state of the art on these notions is first presented, on which the MPM4CPS ontology builds. An overview of the ontology is then developed by introducing its main classes and properties. The validation of the ontology is finally presented by showing how it can adequately model the two case studies briefly introduced in Chapter 2. The chapter also discusses perspectives and future work on this integrated ontological framework, which can serve as a basis to develop model management solutions to relate and combine modelling languages and tools, in order to better develop cyber-physical systems with appropriate formalismes and workflows.}
}
@article{WU2025338,
title = {Design of Intelligent Q&A System Based on Knowledge Graph Combined with Large Language Model},
journal = {Procedia Computer Science},
volume = {262},
pages = {338-347},
year = {2025},
note = {The 5th International Conference on Multi-modal Information Analytics (MMIA)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2025.05.061},
url = {https://www.sciencedirect.com/science/article/pii/S1877050925019088},
author = {Quanquan Wu},
keywords = {Large Language Model, LLM, Knowledge Graph, KG, Intelligent Question-Answering, Q&A, System Design},
abstract = {LLM can transform natural language questions into structured queries, and the KG-based Q&A system can provide accurate and reliable answers. The combination of LLM and KG is the key technology to support the modern Q&A model. Through the two-wheel drive of structured knowledge and semantic understanding, the processing ability of complex problems is significantly improved, and the Q&A system is jointly promoted from the primary to the advanced intelligence evolution. In this paper, based on LLM and KG, knowledge distillation based LLM fusion KG technology is studied, so that the target model can absorb the advantages of both, not only have the language processing capability of large models, but also use the structured knowledge of KG to improve performance and interpretability. On this basis, the multi-layer architecture of intelligent Q&A system is designed, which is easy for developers to work together. The ClaudeKG model constructed in this paper is compared with DeepSeek and Doubao baseline models, and the function and performance are analyzed.}
}
@article{LUCZAK20232714,
title = {The use of an ontology to evaluate the suitability of using Design Thinking in teaching based on the syllabus},
journal = {Procedia Computer Science},
volume = {225},
pages = {2714-2722},
year = {2023},
note = {27th International Conference on Knowledge Based and Intelligent Information and Engineering Sytems (KES 2023)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2023.10.263},
url = {https://www.sciencedirect.com/science/article/pii/S1877050923014217},
author = {Kamila Łuczak and Iwona Chomiak-Orsa and Estera Piwoni-Krzeszowska},
keywords = {Design Thinking, creative problem solving, education, ontology},
abstract = {Constant changes in the forms of classes cause various reactions among students, which may oblige those leading to the search for new teaching methods. One of the currently popular methods is Design Thinking. Design Thinking is a method of designing innovative solutions that focuses on understanding users' needs. Article aims to indicate the use of an ontology to assess the legitimacy of using Design Thinking in conducting classes at universities using syllabus analysis. Among the research methods used by the authors of this article were computer simulations and usage scenarios in the Protégé editor. The decision criteria constructed by the authors were based on the fields in the subject syllabus. Among the important criteria of the decision, the authors distinguish the form of conducting classes, teaching methods, or the number of hours allocated to implementing the subject. As a result of the research, the authors constructed an ontology allowing managers of faculties and people conducting subjects to assess the appropriateness of using Design Thinking during didactic classes. In further work, the authors plan to develop the ontology with additional criteria regarding the subject's characteristics and other creative problem-solving methods.}
}
@article{OYELADE2021100034,
title = {A semantic web rule and ontologies based architecture for diagnosing breast cancer using select and test algorithm},
journal = {Computer Methods and Programs in Biomedicine Update},
volume = {1},
pages = {100034},
year = {2021},
issn = {2666-9900},
doi = {https://doi.org/10.1016/j.cmpbup.2021.100034},
url = {https://www.sciencedirect.com/science/article/pii/S2666990021000331},
author = {Olaide Nathaniel Oyelade and Irunokhai Eric Aghiomesi and Owamoyo Najeem and Ahamed Aminu Sambo},
keywords = {Semantic web, Ontology, Rule language, OWL, Breast cancer, Select and test (ST) algorithm, Knowledge representation},
abstract = {Background and Objective
Breast cancer is widely known as the most lethal and chronic disease among women. Computational techniques have been applied to support and aid early detection of the disease. Methods such as image analysis, knowledgebase systems, machine learning, reasoning algorithm and natural language processing techniques. Approaches aimed at leveraging the availability of patient electronic records have been investigated to support formalisation of medical reasoning thereby achieving early detection of breast cancer. However, computational performance of these approaches is often limited largely due to formalism used for representing the records. We consider that a body of information silo in patient record systems, when accurately formalized, could be efficiently used for improving the performance of computational diagnostic systems which detects breast cancer. The objective of this study is the use of an accurate method for representation and formalisation of text-based patient records and domain knowledge to provide support to medical reasoning algorithm aimed at diagnosing breast cancer.
Methods
We propose an architecture which supports formalism of knowledgebase that is applied to reasoning algorithm used for diagnosing breast cancer. The method applied allow for the use of ontologies for the formalisation of both patient records and domain knowledge. Diagnostic procedure and guidelines in the domain were represented using rules based on semantic web rule language (SWRL). Furthermore, we applied the formalized ontologies and rules to Select and Test (ST) medical reasoning algorithm.
Results
Experimentation was done using records of ten (10) patient collected from University Teaching Hospital. Result obtained showed that our proposed system achieved accuracy gain of 23.5% and AUC of (0.49, 1.0).
Conclusion
The impressive performance of the proposed architecture demonstrates the effectiveness of using rules and ontologies for knowledge representation. In addition, we found the interesting performance of the applied ST algorithm as a pointer that it is a potential algorithm in modeling computer aided diagnostic systems (CADs) for detection of breast cancer.}
}
@article{ZHU2022228,
title = {Traditional Chinese Medicine (TCM) Domain Ontology: Current Status and Rethinking for the Future Development},
journal = {Chinese Medical Sciences Journal},
volume = {37},
number = {3},
pages = {228-234},
year = {2022},
issn = {1001-9294},
doi = {https://doi.org/10.24920/004151},
url = {https://www.sciencedirect.com/science/article/pii/S1001929422000475},
author = {Yan Zhu and Keyu Yao and Suyuan Peng and Xiaolin Yang},
keywords = {ontology, traditional Chinese medicine, top-level ontology, domain ontology, semantic standard},
abstract = {ABSTRACT
The past twenty years have seen the increasingly important role of ontology in traditional Chinese medicine (TCM). However, the development of TCM ontology faces many challenges. Since the epistemologies dramatically differ between TCM and contemporary biomedicine, it is hard to apply the existing top-level ontology mechanically. “Data silos” are widely present in the currently available terminology standards, term sets, and ontologies. The formal representation of ontology needs to be further improved in TCM. Therefore, we propose a unified basic semantic framework of TCM based on in-depth theoretical research on the existing top-level ontology and a re-study of important concepts in TCM. Under such a framework, ontologies in TCM subdomains should be built collaboratively and be represented formally in a common format. Besides, extensive cooperation should be encouraged by establishing ontology research communities to promote ontology peer review and reuse.}
}
@article{LIU2020103607,
title = {Concept placement using BERT trained by transforming and summarizing biomedical ontology structure},
journal = {Journal of Biomedical Informatics},
volume = {112},
pages = {103607},
year = {2020},
issn = {1532-0464},
doi = {https://doi.org/10.1016/j.jbi.2020.103607},
url = {https://www.sciencedirect.com/science/article/pii/S1532046420302355},
author = {Hao Liu and Yehoshua Perl and James Geller},
keywords = {Ontology summarization, Machine learning, Ontology placement, Natural language processing, BERT, SNOMED CT},
abstract = {The comprehensive modeling and hierarchical positioning of a new concept in an ontology heavily relies on its set of proper subsumption relationships (IS-As) to other concepts. Identifying a concept’s IS-A relationships is a laborious task requiring curators to have both domain knowledge and terminology skills. In this work, we propose a method to automatically predict the presence of IS-A relationships between a new concept and pre-existing concepts based on the language representation model BERT. This method converts the neighborhood network of a concept into “sentences” and harnesses BERT’s Next Sentence Prediction (NSP) capability of predicting the adjacency of two sentences. To augment our method’s performance, we refined the training data by employing an ontology summarization technique. We trained our model with the two largest hierarchies of the SNOMED CT 2017 July release and applied it to predicting the parents of new concepts added in the SNOMED CT 2018 January release. The results showed that our method achieved an average F1 score of 0.88, and the average Recall score improves slightly from 0.94 to 0.96 by using the ontology summarization technique.}
}
@article{NAQVI20222578,
title = {A Context-Specific Modularization for Ontology Change Management},
journal = {Procedia Computer Science},
volume = {207},
pages = {2578-2587},
year = {2022},
note = {Knowledge-Based and Intelligent Information & Engineering Systems: Proceedings of the 26th International Conference KES2022},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2022.09.316},
url = {https://www.sciencedirect.com/science/article/pii/S1877050922012054},
author = {Muhammad Raza Naqvi and Linda Elmhadhbi and Arkopaul Sakar and Da Xu and Mohammed Hedi Karray},
keywords = {Ontologies, Modularization, Ontology Change, Semantic heterogeneity},
abstract = {Knowledge engineering has a vital role in advancing the semantic web, in which ontologies play a key role in data interoperability and integration. One of the key issues in ontology engineering is how to handle the subsequent updates in the ontologies. A number of concerns need to be considered while working on the ontology change, such as, tracking ontology versions and heterogeneity issues. Ontology change management has been partially addressed by different researchers in overlapping research areas. However, a concrete description of the problem and its related concerns are still not available in the literature. Our work aims to present an overview of ontology change management and its concerns. We point up the need for modularization in ontology change management based on its advantages in the context of ontology reuse from different contextual viewpoints. For this purpose, we propose a protege plugin for reusing OWL modules, and allowing a safe/clean manual integration and reuse of different ontology modules.}
}
@article{SHI2025102837,
title = {Dual data mapping with fine-tuned large language models and asset administration shells toward interoperable knowledge representation},
journal = {Robotics and Computer-Integrated Manufacturing},
volume = {91},
pages = {102837},
year = {2025},
issn = {0736-5845},
doi = {https://doi.org/10.1016/j.rcim.2024.102837},
url = {https://www.sciencedirect.com/science/article/pii/S0736584524001248},
author = {Dachuan Shi and Olga Meyer and Michael Oberle and Thomas Bauernhansl},
keywords = {Interoperability, Large language model, Asset administration shell, Digital twin, Entity matching, Knowledge representation},
abstract = {In the context of Industry 4.0, ensuring the compatibility of digital twins (DTs) with existing software systems in the manufacturing sector presents a significant challenge. The Asset Administration Shell (AAS), conceptualized as the standardized DT for an asset, offers a powerful framework that connects the DT with the established software infrastructure through interoperable knowledge representation. Although the IEC 63278 series specifies the AAS metamodel, it lacks a matching strategy for automating the mapping between proprietary data from existing software and AAS information models. Addressing this gap, we introduce a novel dual data mapping system (DDMS) that utilizes a fine-tuned open-source large language model (LLM) for entity matching. This system facilitates not only the mapping between existing software and AAS models but also between AAS models and standardized vocabulary dictionaries, thereby enhancing the model's semantic interoperability. A case study within the injection molding domain illustrates the practical application of DDMS for the automated creation of AAS instances, seamlessly integrating the manufacturer's existing data. Furthermore, we extensively investigate the potential of fine-tuning decode-only LLMs as generative classifiers and encoding-based classifiers for the entity matching task. To this end, we establish two AAS-specific datasets by collecting and compiling AAS-related resources. In addition, supplementary experiments are performed on general entity-matching benchmark datasets to ensure that our empirical conclusions and insights are generally applicable. The experiment results indicate that the fine-tuned generative LLM classifier achieves slightly better results, while the encoding-based classifier enables much faster inference. Furthermore, the fine-tuned LLM surpasses all state-of-the-art approaches for entity matching, including GPT-4 enhanced with in-context learning and chain of thoughts. This evidence highlights the effectiveness of the proposed DDMS in bridging the interoperability gap within DT applications, offering a scalable solution for the manufacturing industry.}
}
@article{DANESHFAR2022101591,
title = {An ontology to represent geospatial data to support building renovation},
journal = {Advanced Engineering Informatics},
volume = {52},
pages = {101591},
year = {2022},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2022.101591},
url = {https://www.sciencedirect.com/science/article/pii/S1474034622000635},
author = {Maryam Daneshfar and Timo Hartmann and Jochen Rabe},
keywords = {Geospatial data, Building renovation, Knowledge framework, Ontology},
abstract = {Energy-efficient building renovation is an inter-disciplinary task and requires investigation about the building condition in the urban, environmental, and societal context. Existing literature implicitly mentions the effect of surrounding data in different stages of building renovation. Nevertheless, no conceptual framework is available for practitioners to realize the potential of such data in specific phases of the renovation. The main goal of this study is to understand: (1) based on what knowledge framework surrounding geospatial and environmental data can support building renovation projects, (2) if developing an ontology can help representing this knowledge framework, and (3) how experts and engineers involved in the renovation process can contribute to development of this knowledge framework. The results present an ontology that maps surrounding geospatial and environmental concepts for different renovation tasks and use cases within building renovation. The ontology is built upon knowledge captured from previous studies that implicitly mention the effect of these datasets in building renovation, as well as expert knowledge, brainstorming, and monitoring construction sites. Additionally, a semi-structured verification and validation workshop has been performed to incorporate insights from experts directly involved in different stages of building renovation process. This paper contributes to the body of knowledge by generating a common framework for the surrounding data required in building renovation. It has an implication in practice for engineers by providing a shared knowledge framework and for software developers by providing a basis for BIM (Building Information Modeling) and GIS (Geographic Information System) data integration for renovation purposes.}
}
@article{CEUTERICK2023116358,
title = {From prescribing dilemma to knowledge in practice: The ontological politics of benzodiazepines and Z-drugs},
journal = {Social Science & Medicine},
volume = {339},
pages = {116358},
year = {2023},
issn = {0277-9536},
doi = {https://doi.org/10.1016/j.socscimed.2023.116358},
url = {https://www.sciencedirect.com/science/article/pii/S0277953623007153},
author = {Melissa Ceuterick and Pauline {Van Ngoc} and Piet Bracke and Beatrice Scholtes},
keywords = {Benzodiazepines/BZRA, Positioning theory, Prescribing dilemma, Mindlines, Ontological politics},
abstract = {The discrepancy between official guidelines and clinical practice is hardly more pronounced than in the case of benzodiazepines and Z-drugs, also known as benzodiazepine receptor agonists (BZRA). Using social-constructionist positioning theory, we unravel how health care professionals deal with the dilemma of prescribing this medication. Our results reveal a prescribing spectrum that is discursively organised around four different storylines used by professionals. The storylines are organised along three axes that are related to a) prescribers' opinions on prescribing and the negotiation of the related risks, b) the power dynamics between provider and patient in the prescribing process and c) the rhetorical use of arguments. The discerned storylines allow us to explore the emotional and moral side of prescribing and demarcate clinical mindlines -internalised tacit guidelines-that professionals adhere to when they prescribe. By relying on Annemarie Mol's conceptualisation of ontological politics, we explain how these storylines enact multiple versions of this class of medication and justify seemingly contradictory prescribing practices.}
}
@article{CHATTERJEE2021,
title = {An Automatic Ontology-Based Approach to Support Logical Representation of Observable and Measurable Data for Healthy Lifestyle Management: Proof-of-Concept Study},
journal = {Journal of Medical Internet Research},
volume = {23},
number = {4},
year = {2021},
issn = {1438-8871},
doi = {https://doi.org/10.2196/24656},
url = {https://www.sciencedirect.com/science/article/pii/S1438887121004209},
author = {Ayan Chatterjee and Andreas Prinz and Martin Gerdes and Santiago Martinez},
keywords = {activity, nutrition, sensor, questionnaire, SSN, ontology, SNOMED CT, eCoach, personalized, recommendation, automated, CDSS, healthy lifestyle, interoperability, eHealth, goal setting, semantics, simulation, proposition},
abstract = {Background
Lifestyle diseases, because of adverse health behavior, are the foremost cause of death worldwide. An eCoach system may encourage individuals to lead a healthy lifestyle with early health risk prediction, personalized recommendation generation, and goal evaluation. Such an eCoach system needs to collect and transform distributed heterogenous health and wellness data into meaningful information to train an artificially intelligent health risk prediction model. However, it may produce a data compatibility dilemma. Our proposed eHealth ontology can increase interoperability between different heterogeneous networks, provide situation awareness, help in data integration, and discover inferred knowledge. This “proof-of-concept” study will help sensor, questionnaire, and interview data to be more organized for health risk prediction and personalized recommendation generation targeting obesity as a study case.
Objective
The aim of this study is to develop an OWL-based ontology (UiA eHealth Ontology/UiAeHo) model to annotate personal, physiological, behavioral, and contextual data from heterogeneous sources (sensor, questionnaire, and interview), followed by structuring and standardizing of diverse descriptions to generate meaningful, practical, personalized, and contextual lifestyle recommendations based on the defined rules.
Methods
We have developed a simulator to collect dummy personal, physiological, behavioral, and contextual data related to artificial participants involved in health monitoring. We have integrated the concepts of “Semantic Sensor Network Ontology” and “Systematized Nomenclature of Medicine—Clinical Terms” to develop our proposed eHealth ontology. The ontology has been created using Protégé (version 5.x). We have used the Java-based “Jena Framework” (version 3.16) for building a semantic web application that includes resource description framework (RDF) application programming interface (API), OWL API, native tuple store (tuple database), and the SPARQL (Simple Protocol and RDF Query Language) query engine. The logical and structural consistency of the proposed ontology has been evaluated with the “HermiT 1.4.3.x” ontology reasoner available in Protégé 5.x.
Results
The proposed ontology has been implemented for the study case “obesity.” However, it can be extended further to other lifestyle diseases. “UiA eHealth Ontology” has been constructed using logical axioms, declaration axioms, classes, object properties, and data properties. The ontology can be visualized with “Owl Viz,” and the formal representation has been used to infer a participant’s health status using the “HermiT” reasoner. We have also developed a module for ontology verification that behaves like a rule-based decision support system to predict the probability for health risk, based on the evaluation of the results obtained from SPARQL queries. Furthermore, we discussed the potential lifestyle recommendation generation plan against adverse behavioral risks.
Conclusions
This study has led to the creation of a meaningful, context-specific ontology to model massive, unintuitive, raw, unstructured observations for health and wellness data (eg, sensors, interviews, questionnaires) and to annotate them with semantic metadata to create a compact, intelligible abstraction for health risk predictions for individualized recommendation generation.}
}
@article{MOHAMED2023101962,
title = {Context-driven ontology-based risk identification for onshore wind farm projects: A domain-specific approach},
journal = {Advanced Engineering Informatics},
volume = {56},
pages = {101962},
year = {2023},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2023.101962},
url = {https://www.sciencedirect.com/science/article/pii/S1474034623000903},
author = {Emad Mohamed and Nima {Gerami Seresht} and Simaan AbouRizk},
keywords = {Risk management, Risk identification, Factors, Onshore, Wind farm, Ontology, Knowledge, Management, Construction},
abstract = {Risk identification is a knowledge-based process that requires the time-consuming and laborious identification of project-specific risk factors. Current practices for risk identification in construction rely heavily on an expert’s subjective knowledge of the current project and of similar historical projects to determine if a risk may affect the project under study. When quantitative risk-related data are available, they are often stored across multiple sources and in different types of documents complicating data sharing and reuse. The present study introduces an ontology-based approach for construction risk identification that maps and automates the representation of project context and risk information, thereby enhancing the storage, sharing, and reuse of knowledge for the purpose of risk identification. The study also presents a novel wind farm construction project risk ontology that has been validated by a group of industry experts. The resulting ontology-based risk identification approach is able to accommodate project context in the risk identification process and, through implementation of the proposed approach, has identified risk factors that affect the construction of onshore wind farm projects.}
}
@article{ZHANG2022100086,
title = {An ontology-based KBE application for supply chain sustainability assessment},
journal = {Resources, Environment and Sustainability},
volume = {10},
pages = {100086},
year = {2022},
issn = {2666-9161},
doi = {https://doi.org/10.1016/j.resenv.2022.100086},
url = {https://www.sciencedirect.com/science/article/pii/S2666916122000329},
author = {Liang Zhang and Anna Olsen and Andrei Lobov},
keywords = {Ontology, Knowledge based engineering, Product lifecycle management, Sustainability assessment, Supply chain},
abstract = {Product Lifecycle Management (PLM) plays a key role in digital transformation demanded by Industry 4.0 and life cycle assessment, including sustainability assessment. Knowledge Based Engineering (KBE) applications can support PLM by integrating heterogeneous knowledge from different stages throughout the product life. However, the integration of knowledge from different stages and teams can cause misunderstanding if not represented in a unified form. Furthermore, different forms of knowledge used by different software are neither machine-readable nor human-readable, which also sets obstacles to knowledge integration in KBE applications. Supply chain sustainability assessment is such a scenario that entails integrating knowledge from different sources. This paper firstly implements a sustainability assessment method from other scholar to calculate the supply chain sustainability performance and adapts a sustainability assessment ontology for supply chain sustainability assessment. Then, an example KBE application is developed by implementing the sustainability assessment ontology and calculation method to simulate the knowledge sharing and integration between different teams. Finally, through this example application, it is discussed that the implementation of ontology to represent knowledge in PLM application for collaborative tasks like sustainability assessment can increase the efficiency of data sharing and integration. This paper is a proof of concept for the ontology-based framework. This framework can facilitate to represent knowledge but not create new knowledge, which means it can increase the efficiency of the software development, but cannot provide a better calculation method and assessment framework for supply chain sustainability assessment.}
}
@article{ERICKSON2025100853,
title = {LLM experimentation through knowledge graphs: Towards improved management, repeatability, and verification},
journal = {Journal of Web Semantics},
volume = {85},
pages = {100853},
year = {2025},
issn = {1570-8268},
doi = {https://doi.org/10.1016/j.websem.2024.100853},
url = {https://www.sciencedirect.com/science/article/pii/S1570826824000398},
author = {John S. Erickson and Henrique Santos and Vládia Pinheiro and Jamie P. McCusker and Deborah L. McGuinness},
keywords = {Generative large language models, Knowledge graphs, Retrieval-Augmented Generation, Explainability and governance in AI},
abstract = {Generative large language models (LLMs) have transformed AI by enabling rapid, human-like text generation, but they face challenges, including managing inaccurate information generation. Strategies such as prompt engineering, Retrieval-Augmented Generation (RAG), and incorporating domain-specific Knowledge Graphs (KGs) aim to address their issues. However, challenges remain in achieving the desired levels of management, repeatability, and verification of experiments, especially for developers using closed-access LLMs via web APIs, complicating integration with external tools. To tackle this, we are exploring a software architecture to enhance LLM workflows by prioritizing flexibility and traceability while promoting more accurate and explainable outputs. We describe our approach and provide a nutrition case study demonstrating its ability to integrate LLMs with RAG and KGs for more robust AI solutions.}
}
@article{ZHAO2022100300,
title = {An ontology self-learning approach for CNC machine capability information integration and representation in cloud manufacturing},
journal = {Journal of Industrial Information Integration},
volume = {25},
pages = {100300},
year = {2022},
issn = {2452-414X},
doi = {https://doi.org/10.1016/j.jii.2021.100300},
url = {https://www.sciencedirect.com/science/article/pii/S2452414X21000960},
author = {Yuanyuan Zhao and Quan Liu and Wenjun Xu and Huiqun Yuan and Ping Lou},
keywords = {CNC machine capability, Ontology learning, Industrial information integration, Cloud manufacturing},
abstract = {Manufacturing activities in cloud-based environments strongly rely on the online integration and description of the capability of machining resources. In the authors’ previous work, STEP-NC schema was applied to construct an ontology model to support the integration and reasoning of machine tool information and capability. For the maintenance and update of the model, in this paper, a self-learning method is proposed to explore correlations from STEP-NC process planning documents to obtain machining knowledge to improve the comprehensiveness of the model. In this method, a Map/Reduce-based Apriori algorithm is developed incombination with the built ontological model. First, a dataset is extracted from the document according to the importance analysis results of the model. Then, a mining procedure that combinesApriori algorithm and Map/Reduce framework is developed. Finally, two representation modes are adopted to embed the mined results into the model. According to the outcomes of a preliminary experiment with standard STEP-NC documents, this method effectively enables the ontology learning mechanism from the aspects of time consumption and mined associations, which improves the suitability of the enriched ontology model to handle information integration and industrial applications.}
}
@article{CORDEIRO2024105714,
title = {Petro NLP: Resources for natural language processing and information extraction for the oil and gas industry},
journal = {Computers & Geosciences},
volume = {193},
pages = {105714},
year = {2024},
issn = {0098-3004},
doi = {https://doi.org/10.1016/j.cageo.2024.105714},
url = {https://www.sciencedirect.com/science/article/pii/S0098300424001973},
author = {Fábio Corrêa Cordeiro and Patrícia Ferreira {da Silva} and Alexandre Tessarollo and Cláudia Freitas and Elvis {de Souza} and Diogo {da Silva Magalhaes Gomes} and Renato Rocha Souza and Flávio Codeço Coelho},
keywords = {Natural language processing, Information extraction, Ontology, Knowledge graphs, Linguistic corpora},
abstract = {Most companies struggle to find and extract relevant information from their technical documents. In particular, the Oil and Gas (O&G) industry faces the challenge of dealing with large amounts of data hidden within old and new geoscientific reports collected over decades of operation. Making this information available in a structured format can unlock valuable information among these mountains of data, which is crucial to support a wide range of industrial and academic applications. However, most natural language processing resources were built from general domain corpora extracted from the Internet and primarily written in English. This paper presents Petro NLP, a comprehensive set of natural language processing and information extraction resources for the oil and gas industry in Portuguese. We connected an interdisciplinary team of geoscientists, linguists, computer scientists, petroleum engineers, librarians, and ontologists to build a knowledge graph and several annotated corpora. The Petro NLP resources comprise: (i) Petro KGraph– a knowledge graph populated with entities and relations commonly found on technical reports; and (ii) Petrolês, PetroGold, PetroNER, and PetroRE– sets of corpora containing raw text and documents annotated with morphosyntactic labels, named entities, and relations. These resources are fundamental infrastructure for future research in natural language processing and information extraction in the oil industry. Our ongoing research uses these datasets to train and enhance pre-trained machine learning models that automatically extract information from geoscientific technical documents.}
}
@article{ZHANG2023e15192,
title = {Tourism-type ontology framework for tourism-type classification, naming, and knowledge organization},
journal = {Heliyon},
volume = {9},
number = {4},
pages = {e15192},
year = {2023},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2023.e15192},
url = {https://www.sciencedirect.com/science/article/pii/S240584402302399X},
author = {Puwei Zhang and Jia Wang and Rui Li},
keywords = {Tourism-type ontology, Grounded theory, Overall tourism knowledge, Tourism-type classification, Tourism-type naming, Knowledge organization},
abstract = {The names of tourism types formed by scholars and practitioners reflect the connotations of various tourism types from different aspects and carry a wealth of tourism knowledge. The documents containing the names and connotations of 232 tourism types were sorted from the Springer Encyclopedia of Tourism and 16 major international academic journals. These documents were analyzed using the coding method of grounded theory. A total of 155 naming elements, 22 subcategories, and six categories were extracted. These naming elements, subcategories, and categories constitute the tourism-type ontology, which is the first tourism-type classification framework. Furthermore, the construction of tourism-type ontology enriches the existing research on overall tourism knowledge. The tourism-type ontology can also be used as a preliminary framework for organizing overall tourism knowledge and a foundation for constructing a unified tourism-type naming rule.}
}
@article{SABA2021100591,
title = {An ontology based energy management for smart home},
journal = {Sustainable Computing: Informatics and Systems},
volume = {31},
pages = {100591},
year = {2021},
issn = {2210-5379},
doi = {https://doi.org/10.1016/j.suscom.2021.100591},
url = {https://www.sciencedirect.com/science/article/pii/S2210537921000809},
author = {Djamel Saba and Youcef Sahli and Abdelkader Hadidi},
keywords = {Decision making, Domain ontology, Intelligent energy management in building, Intelligent reasoning, Interoperability, Knowledge base},
abstract = {In this work, the main objective is oriented towards the development of a completed system of saving energy at a home in south Algeria. The proposed previously solution (OSEIM) is an intelligent solution based on domain ontology for the electrical energy management in the home; these are designed, built, and operated with increasingly complex technologies. However, the ontology used in this work brings together a body of knowledge that represents all the objects that can positively or negatively influence the consumption of electrical energy, all of this information is linked to each other by meaningful and useful relationships. In addition, the NewOSEIM solution comprising a knowledge base of the OWL (Web Ontology Language) and SWRL rules (Semantic Web Rule Language) providing a reasoning mechanism is developed to offer an optimal solution in energy saving. This work mainly depends on the import of the OSEIM ontology and other ontologies in the field of energy management. Finally, it is noted that the NewOSEIM solution provides an additional energy saving of 2.11 %.}
}
@article{VANDAMME2022100731,
title = {The International Society for the Study of Vascular Anomalies (ISSVA) ontology},
journal = {Journal of Web Semantics},
volume = {74},
pages = {100731},
year = {2022},
issn = {1570-8268},
doi = {https://doi.org/10.1016/j.websem.2022.100731},
url = {https://www.sciencedirect.com/science/article/pii/S1570826822000221},
author = {Philip {van Damme} and Martijn G. Kersloot and Bruna {dos Santos Vieira} and Leo {Schultze Kool} and Ronald Cornet},
keywords = {ISSVA classification, Vascular anomalies, Vascular tumors, Vascular malformations, Ontology engineering},
abstract = {The International Society for the Study of Vascular Anomalies (ISSVA) provides a classification for vascular anomalies that enables specialists to unambiguously classify diagnoses. This classification is only available in PDF format and is not machine-readable, nor does it provide unique identifiers that allow for structured registration. In this paper, we describe the process of transforming the ISSVA classification into an ontology. We also describe the structure of this ontology, as well as two applications of the ontology using examples from the domain of rare disease research. We used the expertise of an ontology expert and clinician during the development process. We semi-automatically added mappings to relevant external ontologies using automated ontology matching systems and manual assessment by experts. The ISSVA ontology should contribute to making data for vascular anomaly research more Findable, Accessible, Interoperable, and Reusable (FAIR). The ontology is available at https://bioportal.bioontology.org/ontologies/ISSVA.}
}
@article{CHARTIER2025102383,
title = {HiBenchLLM: Historical Inquiry Benchmarking for Large Language Models},
journal = {Data & Knowledge Engineering},
volume = {156},
pages = {102383},
year = {2025},
issn = {0169-023X},
doi = {https://doi.org/10.1016/j.datak.2024.102383},
url = {https://www.sciencedirect.com/science/article/pii/S0169023X24001071},
author = {Mathieu Chartier and Nabil Dakkoune and Guillaume Bourgeois and Stéphane Jean},
keywords = {Large Language Models, Historical Inquiry, Benchmarking},
abstract = {Large Language Models (LLMs) such as ChatGPT or Bard have significantly transformed information retrieval and captured the public’s attention with their ability to generate customized responses across various topics. In this paper, we analyze the capabilities of different LLMs to generate responses related to historical facts in French. Our objective is to evaluate their reliability, comprehensiveness, and relevance for direct usability or extraction. To accomplish this, we propose a benchmark consisting of numerous historical questions covering various types, themes, and difficulty levels. Our evaluation of responses provided by 14 selected LLMs reveals several limitations in both content and structure. In addition to an overall insufficient precision rate, we observe uneven treatment of the French language, along with issues related to verbosity and inconsistency in the responses generated by LLMs.}
}
@article{MUSTAPHA2025103066,
title = {A survey of emerging applications of large language models for problems in mechanics, product design, and manufacturing},
journal = {Advanced Engineering Informatics},
volume = {64},
pages = {103066},
year = {2025},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2024.103066},
url = {https://www.sciencedirect.com/science/article/pii/S1474034624007171},
author = {K.B. Mustapha},
keywords = {Pre-trained language models, Large language models, Generative AI, Generative pre-trained transformer, Mechanical engineering, Engineering design, Manufacturing, Mechanics, Intelligent digital twins, Intelligent maintenance, Creativity},
abstract = {In the span of three years, the application of large language models (LLMs) has accelerated across a multitude of professional sectors. Amid this development, a new collection of studies has manifested around leveraging LLMs for segments of the mechanical engineering (ME) field. Concurrently, it has become clear that general-purpose LLMs faced hurdles when deployed in this domain, partly due to their training on discipline-agnostic data. Accordingly, there is a recent uptick of derivative ME-specific LLMs being reported. As the research community shifts towards these new LLM-centric solutions for ME-related problems, the shift compels a deeper look at the diffusion of LLMs in this emerging landscape. Consequently, this review consolidates the diversity of ME-tailored LLMs use cases and identifies the supportive technical stacks associated with these implementations. Broadly, the review demonstrates how various categories of LLMs are re-shaping concrete aspects of engineering design, manufacturing and applied mechanics. At a more specific level, it uncovered emerging LLMs’ role in boosting the intelligence of digital twins, enriching bidirectional communication within the human-cyber-physical infrastructure, advancing the development of intelligent process planning in manufacturing and facilitating inverse mechanics. It further spotlights the coupling of LLMs with other generative models for promoting efficient computer-aided conceptual design, prototyping, knowledge discovery and creativity. Finally, it revealed training modalities/infrastructures necessary for developing ME-specific language models, discussed LLMs' features that are incongruent with typical engineering workflows, and concluded with prescriptive approaches to mitigate impediments to the progressive adoption of LLMs as part of advanced intelligent solutions.}
}
@article{SHIMIZU2020100567,
title = {The enslaved ontology: Peoples of the historic slave trade},
journal = {Journal of Web Semantics},
volume = {63},
pages = {100567},
year = {2020},
issn = {1570-8268},
doi = {https://doi.org/10.1016/j.websem.2020.100567},
url = {https://www.sciencedirect.com/science/article/pii/S1570826820300135},
author = {Cogan Shimizu and Pascal Hitzler and Quinn Hirt and Dean Rehberger and Seila Gonzalez Estrecha and Catherine Foley and Alicia M. Sheill and Walter Hawthorne and Jeff Mixter and Ethan Watrall and Ryan Carty and Duncan Tarr},
keywords = {Digital humanities, Modular ontology, Data integration, Ontology design patterns, History of the slave trade},
abstract = {We present the Enslaved Ontology (V1.0) which was developed for integrating data about the historic slave trade from diverse sources in a use case driven by historians. Ontology development followed modular ontology design principles as derived from ontology design pattern application best practices and the eXtreme Design Methodology. Ontology content focuses on data about historic persons and the event records from which this data can be taken. It also incorporates provenance modeling and some temporal and spatial aspects. The ontology is available as serialized in the Web Ontology Language OWL, and carries modularization annotations using the Ontology Pattern Language (OPLa). It is available under the Creative Commons CC BY 4.0 license.}
}
@article{ABADI2018416,
title = {Improving integrated product design using SWRL rules expression and ontology-based reasoning},
journal = {Procedia Computer Science},
volume = {127},
pages = {416-425},
year = {2018},
note = {PROCEEDINGS OF THE FIRST INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING IN DATA SCIENCES, ICDS2017},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2018.01.139},
url = {https://www.sciencedirect.com/science/article/pii/S1877050918301510},
author = {Asmae Abadi and Hussain Ben-Azza and Souhail Sekkat},
keywords = {Ontology, Design rules, Ontology Web Language (OWL), Semantic Web Rule Language (SWRL), Reasoner, Collaborative Product Development},
abstract = {In this paper, we propose to deal with the complexity of today’s collaborative product design processes using one of the recent and widely used modeling paradigms in industry which is Ontologies. In fact, in addition to their wide expressivity, ontologies provide many reasoning abilities. Therefore, we propose to explore their maturity in dealing with the complexity of nowadays product design processes especially for the expression and execution of product and process design rules. Indeed, integrating, expressing and implementing these specific domains rules are critical issues in nowadays product development processes. The Semantic Web Rule Language (SWRL) is an ontological language based on OWL-DL that allows the expression of these rules. Thus, we propose an overview on the use of the OWL-DL/SWRL approach in industry and we explore the expression and execution of SWRL design rules throughout the development of an industrial case of study in the impression-die forging industry.}
}
@article{PETRUCCI201866,
title = {Expressive ontology learning as neural machine translation},
journal = {Journal of Web Semantics},
volume = {52-53},
pages = {66-82},
year = {2018},
issn = {1570-8268},
doi = {https://doi.org/10.1016/j.websem.2018.10.002},
url = {https://www.sciencedirect.com/science/article/pii/S1570826818300507},
author = {Giulio Petrucci and Marco Rospocher and Chiara Ghidini},
keywords = {Ontology learning, Neural networks, Natural language processing},
abstract = {Automated ontology learning from unstructured textual sources has been proposed in literature as a way to support the difficult and time-consuming task of knowledge modeling for semantic applications. In this paper we propose a system, based on a neural network in the encoder–decoder configuration, to translate natural language definitions into Description Logics formulæ through syntactic transformation. The model has been evaluated to assess its capacity to generalize over different syntactic structures, tolerate unknown words, and improve its performance by enriching the training set with new annotated examples. The results obtained in our evaluation show how approaching the ontology learning problem as a neural machine translation task can be a valid way to tackle long term expressive ontology learning challenges such as language variability, domain independence, and high engineering costs.}
}
@article{LIU2022116741,
title = {Applying ontology learning and multi-objective ant colony optimization method for focused crawling to meteorological disasters domain knowledge},
journal = {Expert Systems with Applications},
volume = {198},
pages = {116741},
year = {2022},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2022.116741},
url = {https://www.sciencedirect.com/science/article/pii/S095741742200210X},
author = {Jingfa Liu and Yi Dong and Zhaoxia Liu and Duanbing Chen},
keywords = {Focused crawler, Multi-objective ant colony optimization, Ontology, Ontology learning},
abstract = {The focused crawler based on semantic analysis is a research hotspot in the field of information retrieval. The domain ontology is generally applied to construct the topic model of the focused crawler. In order to overcome the limitations of builders' knowledge reserve and subjective consciousness in the process of constructing artificially ontology, a semi-automatic construction method of domain ontology based on ontology learning technology combining the latent Dirichlet allocation and the Apriori algorithm is proposed in this article. When evaluating the relevance between a hyperlink and a specific topic, the joint evaluation method considering both the web text and the link structure is usually used. However, the traditional weighted sum method is difficult to reasonably determine the optimal weights of these evaluating indicators. To solve this problem, a multi-objective optimization model for link evaluation and a subsequent multi-objective ant colony optimization algorithm (MOACO) are proposed. In the MOACO, a method of the nearest farthest candidate solution (NFCS) is combined with the fast non-dominated sorting to select a set of Pareto-optimal hyperlinks and guide the crawlers’ search directions. The experimental results of the focused crawling on the domain knowledge of typhoon disasters and rainstorm disasters prove that the ability of the proposed focused crawlers to retrieve topic-relevant webpages.}
}
@article{FRAGA2020100176,
title = {Ontology-based solutions for interoperability among product lifecycle management systems: A systematic literature review},
journal = {Journal of Industrial Information Integration},
volume = {20},
pages = {100176},
year = {2020},
issn = {2452-414X},
doi = {https://doi.org/10.1016/j.jii.2020.100176},
url = {https://www.sciencedirect.com/science/article/pii/S2452414X20300510},
author = {Alvaro Luis Fraga and Marcela Vegetti and Horacio Pascual Leone},
keywords = {Product lifecycle management, Interoperability, Ontology, Roles of ontology, Review},
abstract = {During recent years, globalization has had an impact on the competitive capacity of industries, forcing them to integrate their productive processes with other, geographically distributed, facilities. This requires the information systems that support such processes to interoperate. Significant attention has been paid to the development of ontology-based solutions, which are meant to tackle issues from inconsistency to semantic interoperability and knowledge reusability. This paper looks into how the available technology, models and ontology-based solutions might interact within the manufacturing industry environment to achieve semantic interoperability among industrial information systems. Through a systematic literature review, this paper has aimed to identify the most relevant elements to consider in the development of an ontology-based solution and how these solutions are being deployed in industry. The research analyzed 54 studies in alignment with the specific requirements of our research questions. The most relevant results show that ontology-based solutions can be set up using OWL as the ontology language, Protégé as the ontology modeling tool, Jena as the application programming interface to interact with the built ontology, and different standards from the International Organization for Standardization Technical Committee 184, Subcommittee 4 or 5, to get the foundational concepts, axioms, and relationships to develop the knowledge base. We believe that the findings of this study make an important contribution to practitioners and researchers as they provide useful information about different projects and choices involved in undertaking projects in the field of industrial ontology application.}
}
@article{JI2022108090,
title = {Benchmark construction and experimental evaluations for incoherent ontologies},
journal = {Knowledge-Based Systems},
volume = {239},
pages = {108090},
year = {2022},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2021.108090},
url = {https://www.sciencedirect.com/science/article/pii/S0950705121011588},
author = {Qiu Ji and Weizhuo Li and Shiqi Zhou and Guilin Qi and Yuanfang Li},
keywords = {Incoherent ontologies, Ontology debugging, Ontology repair, Justification computation, Ontology matching},
abstract = {As the core building blocks of the Semantic Web, ontologies provide shared vocabularies and conceptual knowledge for specific application fields. At the same time, ontologies can restrict their individuals and relationships through their semantic schema. However, logical conflicts of an ontology are often inevitably unavoidable in actual application scenarios when the ontology contains any form of disjointness or negation. Generally, logical conflicts can be divided into incoherence and inconsistency. Reasoning with incoherent ontologies may obtain many redundant relationships, and incoherence is a potential cause of inconsistency which seriously affects the correctness of semantic reasoning Therefore, handling incoherence is imperative, which mainly involves the fields of conflicts detection, ontology repair and justification computation. Various incoherent ontologies are indispensable to evaluate the proposed methods for handling incoherence. We provide a survey of relevant research works to study the proposed construction methods of incoherent ontologies. It is observed that incoherent ontologies in existing works still have the following limitations: (1) Lots of web pages used to download ontologies were temporarily constructed are now inaccessible; (2) Most of the existing incoherent ontologies were constructed in a simple way such as randomly adding disjointness axioms or merging ontologies through their alignments without considering all possible incoherence cases. To address the limitations, we propose a general framework to construct incoherent ontologies and design a hybrid algorithm to instantiate this framework. With the implemented construction methods, a comprehensive benchmark containing 116 ontologies is constructed. In our evaluations, incoherent ontologies in the benchmark are measured with 11 classic metrics. We then compare 5 representative ontology debugging systems and 3 repair methods. The evaluation results reveal that these ontologies could reflect different characteristics of each ontology system and repair method. All observations could guide researchers to select incoherent ontologies. The availability of our benchmark makes a contribution to the community of ontology debugging and repair fields.}
}
@article{SEQUEDA2025100858,
title = {Knowledge Graphs as a source of trust for LLM-powered enterprise question answering},
journal = {Journal of Web Semantics},
volume = {85},
pages = {100858},
year = {2025},
issn = {1570-8268},
doi = {https://doi.org/10.1016/j.websem.2024.100858},
url = {https://www.sciencedirect.com/science/article/pii/S1570826824000441},
author = {Juan Sequeda and Dean Allemang and Bryon Jacob},
keywords = {Knowledge Graph, LLM, Large Language Model, Generative AI, Question answering, Knowledge engineering, SPARQL, SQL, OWL, R2RML},
abstract = {Generative AI provides an innovative and exciting way to manage knowledge and data at any scale; for small projects, at the enterprise level, and even at a world wide web scale. It is tempting to think that Generative AI has made other knowledge-based technologies obsolete; that anything we wanted to do with knowledge-based systems, Knowledge Graphs or even expert systems can instead be done with Generative AI. Our position is counter to that conclusion. Our practical experience on implementing enterprise question answering systems using Generative AI has shown that Knowledge Graphs support this infrastructure in multiple ways: they provide a formal framework to evaluate the validity of a query generated by an LLM, serve as a foundation for explaining results, and offer access to governed and trusted data. In this position paper, we share our experience, present industry needs, and outline the opportunities for future research contributions.}
}
@article{FLETCHER2023101155,
title = {Cognitivism ageing: The Alzheimer conundrum as switched ontology & the potential for a new materialist dementia},
journal = {Journal of Aging Studies},
volume = {66},
pages = {101155},
year = {2023},
issn = {0890-4065},
doi = {https://doi.org/10.1016/j.jaging.2023.101155},
url = {https://www.sciencedirect.com/science/article/pii/S0890406523000567},
author = {James Rupert Fletcher},
keywords = {Cognition, 4E, Onto-epistemology, Agential realism, Aducanumab},
abstract = {Following recent regulatory approvals for anti-Alzheimer's monoclonal antibodies, this paper considers the contemporary role of cognitivism in defining the ontological commitments of dementia research, as well as movements away from cognitivism under the umbrella of 4E cognitive science. 4E cognitive theories, extending cognition into bodies, their environs, and active relations between the two, share potentially fruitful affinities with new materialisms which focus on the co-constitution of matter in intra-action. These semi-overlapping conceptual positions furnish some opportunity for an ontological alternative to longstanding cognitivist commitments, particularly to the isolated brain as a material catalyst for commercial interventions. After outlining mainstream cognitivism and its shortcomings, I explore 4E and new materialism as possibly transformative conceptual schemas for dementia research, a field for which cognitivist imaginings of cognitive decline in later life have profound and often regrettable ramifications. To realise this new materialist dementia, I sketch out a cognitive ontology based on Barad's agential realism. This facilitates a reassessment of the biggest conundrum in dementia research – the lack of neat correlation between (apparently material) neuropathology and (apparently immaterial) cognitive impairment – alongside the continued failure of efforts to develop effective interventions. It also gives social researchers working on cognitive decline in later life an opportunity to reappraise the nature of social science as a response to such phenomena. If cognition and cognitive ageing are reimagined as an emergent characteristic of intra-acting matter, then new materialist social science might be at least as conducive to salutogenic interventions as the neuropsychiatric technoscience that dominates the contemporary dementia research economy despite continual failures. I argue that a new materialist cognitive ontology could help us think beyond an ageing cognitivism and, by extension, beyond the Alzheimer conundrum.}
}
@article{JAZIRI20211152,
title = {ORVIPO: An Ontological Prototype for Modeling 3D Scenes in Operating Rooms},
journal = {Procedia Computer Science},
volume = {192},
pages = {1152-1161},
year = {2021},
note = {Knowledge-Based and Intelligent Information & Engineering Systems: Proceedings of the 25th International Conference KES2021},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2021.08.118},
url = {https://www.sciencedirect.com/science/article/pii/S1877050921016070},
author = {Faouzi Jaziri and Rim Messaoudi and Achraf Mtibaa and Jonathan Courbon and Mahdi Kilani and Mohamed Mhiri and Antoine Vacavant},
keywords = {Virtual reality, Ontology, Semantic interoperability, Reasoning rules, Interaction},
abstract = {Virtual Operating room characterizes a large artificial environment of interaction in the medical context. It enables a better simulation for different surgical scenarios through 3D (three‐dimensional) objects. Virtual Reality (VR) uses computer technology to develop these virtual simulated applications. It brings valuable innovations in different fields. It is integrated also to enhance healthcare and therapies. To improve and assist on medical VR applications, ontologies would be useful. They can unify the content of these applications and facilitate their implementation via semantic rules. Also, ontologies can be applied to realize an effective VR knowledge modeling. This paper presents a virtual simulation of an operating room taking advantage of the semantic representation. The goal of this study is to propose a novel ontological VR system that models an operating room and its components. The execution of the proposed method was proved by the developed ontology OROnto (Operating Room Ontology). This ontology was useful for modeling hospital scenarios and the construction of a valuable VR system. To demonstrate the proposed approach feasibility and performance, we have implemented the Operating Room Virtual Integration Process Using Ontology (ORVIPO) prototype. Compared to different other ontological methods and related works, our approach have shown interesting findings such as recall (71%), precision (83%), and F-measure (76%).}
}
@article{SAPEL2023100488,
title = {Towards an ontology-based dictionary for production planning and control in the domain of injection molding as a basis for standardized asset administration shells},
journal = {Journal of Industrial Information Integration},
volume = {35},
pages = {100488},
year = {2023},
issn = {2452-414X},
doi = {https://doi.org/10.1016/j.jii.2023.100488},
url = {https://www.sciencedirect.com/science/article/pii/S2452414X23000614},
author = {Patrick Sapel and Christian Hopmann},
keywords = {Asset administration shell, Dictionary, Injection molding, Ontology, Production planning and control, Standardization},
abstract = {The use of digital technologies in the industrial environment enables great potential for increasing efficiency in manufacturing. One building block are production environments that plan and control their production flow autonomously and decentrally. To this end, all machines and systems (so-called “assets”) need to communicate with each other and derive suitable actions based on the exchanged information. Therefore, all assets need to be represented in the virtual world. This can be realized with digital twins. A concrete implementation of digital twins is the asset administration shell, which comprises all the assets’ properties and the endpoint of the corresponding asset, so intercommunication is possible. Here, the challenges comprise establishing a manufacturer-independent vocabulary that standardizes the assets’ properties and enabling the machines and systems to interpret this vocabulary semantically. Existing standards and information models represent only a fraction of the information requirements (i.e., terms) in this domain, making autonomous production planning and control (PPC) challenging to implement. Furthermore, the information requirements of the machines and peripheral assets as well as the corresponding information flows are insufficiently defined. Therefore, this contribution aims to build a comprehensive vocabulary for the domain of PPC, which serves as a basis for standardized asset administration shells that realize machine-to-machine communication. In particular, PPC processes concerning the injection molding domain’s characteristics are considered since the interaction between the domain’s assets, i.e., injection molding machines, molds, peripheral assets, raw materials, and operators, are especially complex. For this purpose, the relevant input and output information within the injection molding domain was first collected for each process step in PPC. After that, a UML class diagram was modeled under consideration of established standards. The result of this work is an ontology, which can be used as a dictionary for the PPC in the injection molding domain and as a foundation of standardized digital twins in the form of asset administration shells.}
}
@article{KARN2022104234,
title = {ICACIA: An Intelligent Context-Aware framework for COBOT in defense industry using ontological and deep learning models},
journal = {Robotics and Autonomous Systems},
volume = {157},
pages = {104234},
year = {2022},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2022.104234},
url = {https://www.sciencedirect.com/science/article/pii/S0921889022001361},
author = {Arodh Lal Karn and Sudhakar Sengan and Ketan Kotecha and Irina V. Pustokhina and Denis A. Pustokhin and V. Subramaniyaswamy and Dharam Buddhi},
keywords = {Human–Robot Collaboration, Communication system, Contextual Intelligence, Military agents, Deep Learning, Defense industry, Ontology, Mobile Robotic Systems},
abstract = {Most of the world’s most advanced defense technologies are robots, and the defence industry is slowly moving toward including AI in the military robots they build. For these smart robots to make their own decisions about where to go and what to do, they need to be limited by several algorithms that run continuously and at the same time. Autonomy is the range of automated systems that can be adapted to a specific mission, residual risk, and level of team cohesion between humans and robots. Self-driving robotic systems should be collaborative, which means they should be able to interact actively with humans in a shared space or in proximity to humans and robots. Human–Robot Collaboration (HRC) works better when these COBOTs are aware of their surroundings. Mobile Robot (MR) teams whose perceptual and cognitive abilities are very well developed can help a lot with context awareness. To work well with humans, these robots should know what is going on with their human and other robot teammates so they can make decisions on their own. Also, robots should be able to share information about their surroundings so that humans can benefit from a better understanding of the situation. At the same time, humans should be able to see what the robots are doing. In this paper, we propose a knowledge-based framework for humans and robots to work together to understand the context of Defense missions. An ontological model of contexts for missions, agents, and situations; a knowledge base comprising all the tools necessary for a sort of situation; and an efficient and reliable method of collaborative learning are some of its main contributions. The framework works well in terms of how long it takes for people to talk to each other. As the team continues to expand, it can also easily manage communication challenges and a widely differing event frequency range.}
}
@article{DAVARPANAH2025111736,
title = {Semantic knowledge and data modeling of environmental justice},
journal = {Engineering Applications of Artificial Intelligence},
volume = {159},
pages = {111736},
year = {2025},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2025.111736},
url = {https://www.sciencedirect.com/science/article/pii/S0952197625017385},
author = {Armita Davarpanah and Hassan A. Babaie and Fatemeh Shafiei and Na'Taki Osborne Jelks},
keywords = {Environmental justice, Ontology, Knowledge graph, Semantic web rule language, Proctor creek watershed},
abstract = {Most environmental justice information and data are unstructured, posing substantial challenges for effective risk management, disaster response, and comprehensive environmental justice assessments through software tools. To overcome these barriers, we created the Environmental Justice Ontology, a structured framework that organizes essential environmental justice concepts and their complex relationships, enabling machines to interpret environmental justice knowledge. The ontology applies the Semantic Web Rule Language to model EJScreen measures, including % Unemployment and % People of Color. Leveraging the widely adopted Basic Formal Ontology and Common Core Ontologies, Environmental Justice Ontology organizes environmental justice resources—including reports, charts, and datasets—to enable seamless data exchange across various domains. We applied the ontology to structure environmental justice data gathered from the Proctor Creek Watershed in Atlanta, Georgia, using the U.S. Environmental Protection Agency's EJScreen tool. Applying Neo4J AuraDB and natural language processing techniques in Python, we developed two knowledge graphs to support the visualization, querying, and analysis of this environmental justice data. Together, the ontology and knowledge graphs create a structured framework for uncovering complex interactions and correlations between natural and social systems, fostering a comprehensive understanding of the interconnections between environmental, socioeconomic, demographic, and other influencing factors. This framework empowers users and software to assist policymakers in designing sustainable solutions for overburdened communities facing environmental, health, and climate-related challenges. The ontology encompasses a broad range of classes—including disparities, burdens, discrimination, bias, and the challenges faced by disadvantaged communities—that extends beyond the capabilities of EJScreen, enabling seamless integration of future environmental justice data and knowledge.}
}
@article{ALANEN2022108270,
title = {Hybrid ontology for safety, security, and dependability risk assessments and Security Threat Analysis (STA) method for industrial control systems},
journal = {Reliability Engineering & System Safety},
volume = {220},
pages = {108270},
year = {2022},
issn = {0951-8320},
doi = {https://doi.org/10.1016/j.ress.2021.108270},
url = {https://www.sciencedirect.com/science/article/pii/S0951832021007444},
author = {Jarmo Alanen and Joonas Linnosmaa and Timo Malm and Nikolaos Papakonstantinou and Toni Ahonen and Eetu Heikkilä and Risto Tiusanen},
keywords = {Hybrid risk assessment, Cybersecurity analysis method, Model-based system engineering, Ontology, Industrial control systems},
abstract = {This paper introduces a model-based methodology for hybrid reliability, availability, maintainability, safety, and security (RAMSS) risk assessment management, which extends our previous work of model-based, data-driven, support for engineering mission-critical systems. It represents a hybrid risk assessment ontology, which harmonises basic concepts between dependability, safety and security based on well-known industrial standards. Based on the proposed ontology, we create a cybersecurity risk analysis method, called Security Threat Analysis (STA), for industrial control systems and successfully demonstrate the method. For the demonstration, we introduce a data model for creating a tool-supported data repository for STA, then implement this repository with a commercial-off-the-shelf tool. We use the repository to carry out an exemplary STA of a nuclear fuel pool cooling control system, assessing a cybersecurity-related hazard. The demonstration suggests that the hybrid RAMSS risk assessment ontology and the related STA data model are ready to be tested in industrial use, offering a structured data repository to support assessment and traceability between the created artefacts.}
}
@incollection{BRUTZMAN2024107,
title = {Chapter Seven - Autonomy compliance with doctrine and ethics by using ontological frameworks: Shared precision and understanding between humans and machines},
editor = {Peggy Wu and Michael Salpukas and Hsin-Fu Wu and Shannon Ellsworth},
booktitle = {Trolley Crash},
publisher = {Academic Press},
pages = {107-124},
year = {2024},
isbn = {978-0-443-15991-6},
doi = {https://doi.org/10.1016/B978-0-44-315991-6.00013-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780443159916000133},
author = {Don Brutzman and Curtis Blais and Hsin-Fu ‘Sinker’ Wu and Carl Andersen and Richard Markeloff},
keywords = {Unmanned systems, autonomous systems, ethical control, ontology, formal semantics, Autonomous Vehicle Command Language (AVCL), Mission Execution Ontology (MEO)},
abstract = {Ensuring ethical robot behavior requires complex representations and methodologies designed to guarantee it. This chapter synopsizes a large body of work. Our approach extends frameworks already used by the US military to ensure human ethical and doctrinal behavior by human beings. This methodology offers built-in advantages of being able to express complex plans and constraints, yet remaining intelligible to humans, thus supporting a strong requirement for ethical responsibility and liability. To extend the framework to machines, mission constructs are expressed using an Autonomous Vehicle Command Language (AVCL) expressing mission actions and outcomes that can readily be translated and parsed by runnable source code in several programming languages. Missions written in AVCL can be validated via translation to a formalized Mission Execution Ontology (MEO) supporting automated reasoning and queried proofs of ethical correctness. AVCL matches MEO exactly, ensuring that missions are both syntactically valid and semantically compliant with ethical constraints. These technologies are implementable in a simulation, testing, and certification regime that serves as a foundation for human authority over, and trust in, robots that are even capable of lethal/lifesaving force when properly authorized.}
}
@article{PRAYITNO20241070,
title = {Optimizing the Sustainability of Collaborative Logistics in Urban Area through Ontologies and Causal Artificial Intelligence: A Conceptual Framework},
journal = {Procedia CIRP},
volume = {130},
pages = {1070-1076},
year = {2024},
note = {57th CIRP Conference on Manufacturing Systems 2024 (CMS 2024)},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2024.10.208},
url = {https://www.sciencedirect.com/science/article/pii/S2212827124013659},
author = {Kutut Aji Prayitno and Hendro Wicaksono},
keywords = {Collaborative sustainable urban logistics, Causal AI, Ontology, Reinforcement learning},
abstract = {Efficiently managing logistics operations is crucial in elevating sustainability and tackling the challenges urbanization brings in today’s urban environment. Collaborations among the public and private sectors in urban logistics are essential to minimize environmental impacts. This study aims to create a novel conceptual framework for collaborative logistics designed explicitly for sustainable metropolitan areas. The framework aims to enable collaborative data-driven sustainability optimization in urban logistics. It comprises ontologies to facilitate interoperability among stakeholders by providing a shared understanding of the exchanged data. The framework utilizes causal artificial intelligence to enable traceability and transparency of data-driven decisions compared to conventional machine learning working based on correlations. Furthermore, the framework also employs causal reinforcement learning that enables agents to learn what actions lead to targeted outcomes and why those actions are effective. The developed framework optimizes vehicle routes and conveyance selection while considering several operational constraints such as time windows, split-load scenarios, and commodity-specific requirements. Moreover, the system integrates the distinctive features of public transport networks. The suggested strategy minimizes fuel use and overall delivery costs, promoting a more sustainable logistics environment in metropolitan areas measured using Environmental, Social, and Governance (ESG) indicators. This study contributes to the theoretical understanding of collaborative logistics. It underscores the importance of environmental stewardship and societal well-being in logistics planning and implementation by utilizing a data-driven approach.}
}
@article{LIN20191906,
title = {Ontology-based Manufacturing Control Systems (MCS)},
journal = {Procedia Manufacturing},
volume = {39},
pages = {1906-1912},
year = {2019},
note = {25th International Conference on Production Research Manufacturing Innovation: Cyber Physical Manufacturing August 9-14, 2019 | Chicago, Illinois (USA)},
issn = {2351-9789},
doi = {https://doi.org/10.1016/j.promfg.2020.01.242},
url = {https://www.sciencedirect.com/science/article/pii/S2351978920302997},
author = {Yu-Ju Lin and Yao-Yu Hsieh and Chin-Yin Huang},
keywords = {Manufacturing Control System, Ontology Web Language, Protégé, Smart Factory, SPARQL},
abstract = {Programmable Logic Controller (PLC) is a typical control kernel for manufacturing automation, especially in the era of Industry 3.0. Centralized control architecture of PLC with an ease of maintenance has been widely applied in many arenas for automation. However, PLC’s centralized structure is becoming incapable to handle the control requirements of smart factories in Industry 4.0, within which are full of diverse sensors and actuators, not to mention its incapability of expansion and flexibility. OWL (Ontology Web Language) is a language representing knowledge in the format of ontology, whereas ontology is formal way to describe taxonomies and classification networks. Compared to the traditional program control system, system with OWL is ease of modification and expansion. By taking advantages of OWL into manufacturing control system, this research develops a manufacturing ontological knowledge model. Because of the system is built based on Jena package, SPARQL as a knowledge query language will be easily deployed to demonstrate the flexibility, robustness, and re-configurability of an ontology-based manufacturing control system to the environmental disturbances.}
}
@article{ROLDANMOLINA2021101889,
title = {An ontology knowledge inspection methodology for quality assessment and continuous improvement},
journal = {Data & Knowledge Engineering},
volume = {133},
pages = {101889},
year = {2021},
issn = {0169-023X},
doi = {https://doi.org/10.1016/j.datak.2021.101889},
url = {https://www.sciencedirect.com/science/article/pii/S0169023X21000161},
author = {Gabriela R. Roldán-Molina and David Ruano-Ordás and Vitor Basto-Fernandes and José R. Méndez},
keywords = {Ontology, Ontology fixing, Ontology quality measures, Ontology improvement methodology, Deming cycle},
abstract = {Ontology-learning methods were introduced in the knowledge engineering area to automatically build ontologies from natural language texts related to a domain. Despite the initial appeal of these methods, automatically generated ontologies may have errors, inconsistencies, and a poor design quality, all of which must be manually fixed, in order to maintain the validity and usefulness of automated output. In this work, we propose a methodology to assess ontologies quality (quantitatively and graphically) and to fix ontology inconsistencies minimizing design defects. The proposed methodology is based on the Deming cycle and is grounded on quality standards that proved effective in the software engineering domain and present high potential to be extended to knowledge engineering quality management. This paper demonstrates that software engineering quality assessment approaches and techniques can be successfully extended and applied to the ontology-fixing and quality improvement problem. The proposed methodology was validated in a testing ontology, by ontology design quality comparison between a manually created and automatically generated ontology.}
}
@article{WEN2025103235,
title = {Leveraging large language models for Human-Machine collaborative troubleshooting of complex industrial equipment faults},
journal = {Advanced Engineering Informatics},
volume = {65},
pages = {103235},
year = {2025},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2025.103235},
url = {https://www.sciencedirect.com/science/article/pii/S1474034625001284},
author = {Sijie Wen and Fei Li and Weibin Zhuang and Xinyu Pan and Weigang Yu and Jinsong Bao and Xinyu Li},
keywords = {Fault Troubleshooting, Human-Machine Collaboration, Industrial Knowledge Graph, Large Language Models, Knowledge Extraction and Reasoning},
abstract = {The continuous advancement of mechanical manufacturing technology has significantly elevated the importance of large mechanical equipment in industrial enterprises, necessitating effective fault diagnosis methods to ensure operational efficiency and safety. Traditional manual fault diagnosis methods are increasingly proving inefficient, especially when dealing with long fault chains in complex industrial equipment. Moreover, the harsh and corrosive environments in factories often prevent the large-scale deployment of sensors, making automated fault detection methods challenging to implement. This paper introduces an innovative fault diagnosis approach that leverages Large Language Models (LLMs) to enhance human–machine collaborative troubleshooting for complex industrial equipment faults. By employing methods based on LLM, such as triplet extraction, complex semantic mapping, and “5-why” causal analysis, this approach achieves semantically lossless knowledge parsing and extraction of fault knowledge. An Enhanced Causal Fault Knowledge Graph (ECFKG) is constructed, which integrates theory-based and scenario-based knowledge graphs to support fault troubleshooting. Additionally, an Interactive Diagnostic and Troubleshooting Method (IDTM) is introduced, utilizing human–machine collaboration in the fault troubleshooting process to enable dynamic fault diagnosis, thereby enhancing the accuracy and efficiency of diagnosing and resolving faults. A case study on a bridge crane in a steel mill demonstrates the feasibility and improved performance of the proposed methods in real-life scenarios. This study contributes to the field by effectively integrating human intuition with machine computational power, setting a precedent for future advancements in cognitive intelligence-enabled fault diagnosis systems. This research paves the way for more sophisticated, real-time troubleshooting solutions in industrial settings.}
}
@article{COSTA2022101977,
title = {A core ontology on the Human–Computer Interaction phenomenon},
journal = {Data & Knowledge Engineering},
volume = {138},
pages = {101977},
year = {2022},
issn = {0169-023X},
doi = {https://doi.org/10.1016/j.datak.2021.101977},
url = {https://www.sciencedirect.com/science/article/pii/S0169023X21000951},
author = {Simone Dornelas Costa and Monalessa Perini Barcellos and Ricardo de Almeida Falbo and Tayana Conte and Káthia M. {de Oliveira}},
keywords = {Human–Computer Interaction, User interface, Interactive computer system, Ontology, Ontology network},
abstract = {Human–Computer Interaction (HCI) is a complex communication phenomenon involving human beings and computer systems that gained large attention from industry and academia with the advent of new types of interactive systems (mobile applications, smart cities, smart homes, ubiquitous systems and so on). Despite of its importance, there is still a lack of formal and explicit representations of what the HCI phenomenon is. In this paper, we intend to clarify the main notions involved in the HCI phenomenon, by establishing an explicit conceptualization of it. To do so, we need to understand what interactive computer systems are, which types of actions users perform when interacting with an interactive computer system, and finally what human–computer interaction itself is. The conceptualization is presented as a core reference ontology, called HCIO (HCI Ontology), which is grounded in the Unified Foundational Ontology (UFO). HCIO was evaluated using ontology verification and validation techniques and has been used as core ontology of an HCI ontology network.}
}
@article{BLOMBERG202135,
title = {Metalinguistic relativity: Does one's ontology determine one's view on linguistic relativity?},
journal = {Language & Communication},
volume = {76},
pages = {35-46},
year = {2021},
issn = {0271-5309},
doi = {https://doi.org/10.1016/j.langcom.2020.09.007},
url = {https://www.sciencedirect.com/science/article/pii/S0271530920300860},
author = {Johan Blomberg and Jordan Zlatev},
keywords = {Linguistic relativity, Neo-Whorfian, Language and thought, Integral linguistics, Phenomenology, Motivation & Sedimentation model},
abstract = {Linguistic relativity is a notion that has been met with both praise and scorn. We argue that there is correlation between theorists’ general conceptions of the nature of language, and their stance toward linguistic relativity. Starting with the proponents of the thesis, we distinguish between the relativists of the early days (Boas, Whorf) and modern neo-Whofians (Levinson, Slobin), showing that the first but not the latter are committed to a view of language as a monolithic semiotic system contrasting “arbitrarily” with other such systems. Critics of the thesis also come from two diametrically opposed views of language. While universalists see the most significant part of language as pan-human cognitive structure (insulated from thought in general), socio-cultural theorists emphasize the nature of language as contextually situated activity. In both cases the potential for locally sedimented linguistic structures to influence thought is excluded or at best marginalized. In response, we propose that a synthetic ontology of language as an experientially grounded semiotic system for meaning making in actual social contexts allows for the possibility for language to influence thought, though in different ways. These depend on whether we consider language as situated use, as sedimented conventions or as ultimately prelinguistic motivations for “universal” properties like predication. We argue that all three of these perspectives need to be considered. With the help of the Motivation & Sedimentation Model, which is based on such a linguistic ontology, and inspired by the integral linguistics and phenomenology, we show how the deadlock in the debate over linguistic relativity can be resolved, and the possibility for discussion to proceed in less antagonistic manner.}
}
@article{XUE2022102442,
title = {Integrating Energy Smart Grid’s ontologies through multi-objective particle swarm optimization algorithm with competitive mechanism},
journal = {Sustainable Energy Technologies and Assessments},
volume = {53},
pages = {102442},
year = {2022},
issn = {2213-1388},
doi = {https://doi.org/10.1016/j.seta.2022.102442},
url = {https://www.sciencedirect.com/science/article/pii/S2213138822004945},
author = {Xingsi Xue and Pei-Wei Tsai},
keywords = {Energy smart grid, Ontology matching, Multi-objective particle swarm optimization algorithm, Competitive mechanism},
abstract = {Smart city seeks safer, resource-oriented, environment friendly, and cost-effective energy solutions, and due to the distributed and independent nature of energy management systems, Energy Smart Grid (ESG) quickly evolves from a widely accepted concept to an industrial reality. To monitor the energy consumption across various domains and assist efficient energy distribution and storage, it is necessary to integrate various ESG agents’ ontologies. To this end, this work models ESG’s Ontology Matching Problem (ESG-OMP) as a discrete Multi-Objective Optimization Problem (MOOP), which simultaneously optimizes the alignment’s completeness and correctness through determining an optimal entity corresponding set. After that, a Multi-Objective Particle Swarm Optimization Algorithm With Competitive Mechanism (MOPSO-CM) is proposed to address this issue by trading off the alignment’s completeness and correctness, which introduces the CM to update the particles with the pairwise competition that performed in the swarm of current generation. Moreover, an instance-based hybrid similarity measure is used to distinguish the heterogeneous ontology entities. The experiment uses OAEI’s testing datasets, 13 smart grid’s ontology matching tasks and 5 energy smart grid’s ontology matching tasks to test MOPSO-CM’s performance. The experimental results show that MOPSO-CM can effectively address various heterogeneous ontology matching problems and determine high-quality ESG’s ontology alignments.}
}
@article{SPOLADORE2022103690,
title = {An evaluation of agile Ontology Engineering Methodologies for the digital transformation of companies},
journal = {Computers in Industry},
volume = {140},
pages = {103690},
year = {2022},
issn = {0166-3615},
doi = {https://doi.org/10.1016/j.compind.2022.103690},
url = {https://www.sciencedirect.com/science/article/pii/S0166361522000872},
author = {Daniele Spoladore and Elena Pessot},
keywords = {Digital transformation, Industry 4.0, Ontology Engineering, Agile methodologies, Organisational learning},
abstract = {Ontologies are increasingly recognised among the key enablers of the digital transformation of knowledge management processes, but still with a low level of adoption in manufacturing companies. Because ontologies and underlying technologies are complex, Ontology Engineering Methodologies (OEMs) provide a set of guidelines to move from an informal to a formal representation of the company’s knowledge base. This study evaluates three agile OEMs, i.e. UPONLite, SAMOD and RapidOWL, in terms of their process and outcome features, i.e. the OEM steps and the expected quality of the ontological models produced. The assessment is performed from the viewpoint of developers of ontology-based technologies in real industrial use cases. Results show that the three agile OEMs reflect different features to effectively support the digital transformation of companies' knowledge management; thus, they cannot be interchangeable. UPONLite is more effective in contexts where there is a lack of skills in OE, with the need for a structured approach in involving domain experts and generating documentation. SAMOD requires a more extended development period, but with several cycles that allow to map different types of knowledge and enable a “try-and-learn” approach. Conversely, RapidOWL lacks a structured sequence of modelling activities and encourages developers to be creative, but at the same time requires higher expertise in OE. Thus, companies and personnel dedicated to OE should choose the methodology according to the main aims guiding their digitalisation process, the current development status, and the level of expertise.}
}
@article{HATLASSOWINSKA2022111941,
title = {Ontology based approach in solving collision situations at sea},
journal = {Ocean Engineering},
volume = {260},
pages = {111941},
year = {2022},
issn = {0029-8018},
doi = {https://doi.org/10.1016/j.oceaneng.2022.111941},
url = {https://www.sciencedirect.com/science/article/pii/S002980182201277X},
author = {Paulina Hatlas-Sowinska and Mirosław Wielgosz},
keywords = {Ontology, Ontology of communication, Navigational safety, Collision situation, Maritime accident},
abstract = {The article presents an innovative approach to the implementation of semi-automatic communication in solving collision situations at sea based on navigational and communication ontology. Data used in this process are obtained from navigational systems and equipment, including AIS, ARPA and ECDIS. The problem of communication processes management has been analysed. Based on this, navigational and communication ontology has been developed and presented. The construction of ontology takes into account, inter alia, IMO's Standard Marine Communication Phrases. The developed ontology allows the implementation of communication processes as the concatenation of sequences of words corresponding to utterances used by humans. The use of the said ontology in the process of semi-automatic communication may contribute to the reduction of errors in communication and facilitate communication to those with poor English skills. The developed ontology was used to support solving collision situations at sea. Examples of its use in real and simulated cases are presented. The authors made use of official reports of marine accident investigation boards and own scenarios simulating typical situations of ship encounters. The results of research will be used to create an automatic communication system for manned and autonomous ships.}
}
@article{MAKSIMOV2021540,
title = {Knowledge ontology system},
journal = {Procedia Computer Science},
volume = {190},
pages = {540-545},
year = {2021},
note = {2020 Annual International Conference on Brain-Inspired Cognitive Architectures for Artificial Intelligence: Eleventh Annual Meeting of the BICA Society},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2021.06.063},
url = {https://www.sciencedirect.com/science/article/pii/S1877050921013107},
author = {Nikolay Maksimov and Alexander Lebedev},
keywords = {Ontology, knoweledge, ontology development.},
abstract = {The paper considers a purpose and features of ontologies use in describing of subject area, both from a theoretical and an applied point of view. Criteria for identifying ontologies types are indicated. Based on cognition schematism principles, a knowledge representation ontologies system has been developed, that combines language, forms of knowledge representation and process schemes. It is shown that it is exactly such a system of ontologies makes it possible for the practical use of ontologies in computing environments.}
}
@incollection{GIESE202167,
title = {Chapter 4 - An ontology for multi-paradigm modelling},
editor = {Bedir Tekinerdogan and Dominique Blouin and Hans Vangheluwe and Miguel Goulão and Paulo Carreira and Vasco Amaral},
booktitle = {Multi-Paradigm Modelling Approaches for Cyber-Physical Systems},
publisher = {Academic Press},
pages = {67-122},
year = {2021},
isbn = {978-0-12-819105-7},
doi = {https://doi.org/10.1016/B978-0-12-819105-7.00009-X},
url = {https://www.sciencedirect.com/science/article/pii/B978012819105700009X},
author = {Holger Giese and Dominique Blouin and Rima Al-Ali and Hana Mkaouar and Soumyadip Bandyopadhyay and Mauro Iacono and Moussa Amrani and Stefan Klikovits and Ferhat Erata},
keywords = {Multi-paradigm modelling, multi-formalism, model management, megamodelling, ontology, OWL, Protégé},
abstract = {This chapter presents the ontology for Multi-Paradigm Modelling (MPM) specfied using the Web Ontology Language (OWL) as introduced in Chapter 2. A thorough state of the art on MPM's core notions including multi-formalism and model management approaches, languages and tools is presented. In particular, model management approaches have been characterized according to their modularity and incremental execution properties as required to scale for the large complex CPSs we face today. Based on this state of the art, an outline of the MPM ontology is developed by introducing its main classes and properties. The validation of the ontology is presented by showing how it can adequatly model the two case studies briefly introduced in Chapter 2.}
}
@article{POVEDAVILLALON2022104755,
title = {LOT: An industrial oriented ontology engineering framework},
journal = {Engineering Applications of Artificial Intelligence},
volume = {111},
pages = {104755},
year = {2022},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2022.104755},
url = {https://www.sciencedirect.com/science/article/pii/S0952197622000525},
author = {María Poveda-Villalón and Alba Fernández-Izquierdo and Mariano Fernández-López and Raúl García-Castro},
keywords = {Ontology engineering, Ontology development methodology, Ontology development software support, Collaborative ontology development, Ontology industrial development},
abstract = {Ontology Engineering has captured much attention during the last decades leading to the proliferation of numerous works regarding methodologies, guidelines, tools, resources, etc. including topics which are still being investigated. Even though, there are still many open questions when addressing a new ontology development project, regarding how to manage the overall project and articulate transitions between activities or which tasks and tools are recommended for each step. In this work we propose the Linked Open Terms (LOT) methodology, an overall and lightweight methodology for building ontologies based on existing methodologies and oriented to semantic web developments and technologies. The LOT methodology focuses on the alignment with industrial development, in addition to academic and research projects, and software development, that is making ontology development part of the software industry. This methodology includes lessons learnt from more than 20 years in ontological engineering and its application on 18 projects is reported.}
}
@article{KHABAROV20221899,
title = {An impact of ontology-based service-oriented ecosystems on digital transformation of railway transport and engineering education},
journal = {Transportation Research Procedia},
volume = {63},
pages = {1899-1908},
year = {2022},
note = {X International Scientific Siberian Transport Forum — TransSiberia 2022},
issn = {2352-1465},
doi = {https://doi.org/10.1016/j.trpro.2022.06.210},
url = {https://www.sciencedirect.com/science/article/pii/S2352146522004653},
author = {Valeriy Khabarov and Irina Volegzhanina},
keywords = {railway transport, intelligent tutoring agent, education course ontology, industry-related university, service-oriented business ecosystem, digital transformation},
abstract = {The scientific novelty of the article is to ground the digital transformation of railway universities through the development of an ontology-based service-oriented ecosystem. The analysis of scientific publications and results of technical and technological initiatives in the field of railway transport revealed that the industry business ecosystem based on ontologies would determine the nature of digital transformation in railway universities. This idea, however, has not yet been sufficiently developed in education studies. It is obvious that ontologisation will require new conceptual solutions and tools to be implemented. The authors propose a new didactic concept called "knowledge factory". The implementation of this didactic concept requires the development of ontology-based didactic tools. In particular, standardisation of education content through the concepts and relations in ontologies makes it possible to develop a web-application such as an intelligent tutoring agent. The study involved two stages. The first stage - conceptual - grounded the new "knowledge factory" didactic concept and the ontological model of interaction between the railway industry and railway universities. For this purpose, the authors applied the methods of ecosystem and ontological-semantic approaches. At the second stage - practical - an attempt was made to develop a prototype of an intelligent tutoring agent. With this purpose a fragment of ontology for the education course "Artificial Intelligence Systems in Transport: Agent-Based Approach" was developed. The top-down method was applied to develop this ontology. What is also emphasized is that the findings are to a large extent transferable to many industries.}
}
@incollection{ONIKI2023349,
title = {Chapter 11 - Terminologies, ontologies and data models},
editor = {Robert A. Greenes and Guilherme {Del Fiol}},
booktitle = {Clinical Decision Support and Beyond (Third Edition)},
publisher = {Academic Press},
edition = {Third Edition},
address = {Oxford},
pages = {349-382},
year = {2023},
isbn = {978-0-323-91200-6},
doi = {https://doi.org/10.1016/B978-0-323-91200-6.00027-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780323912006000279},
author = {Thomas A. Oniki and Roberto A. Rocha and Lee Min Lau and Davide Sottara and Stanley M. Huff},
keywords = {Terminology, Vocabulary, Ontology, Data model, Information model, FHIR, SNOMED CT, LOINC, Pre-coordination, Context, Terminology services},
abstract = {The understanding, interpretation, sharing, and reuse of CDS cannot be advanced without common data models and terminologies. This chapter addresses the use of vocabularies (whether simple code sets or formal ontologies) and data models in CDS. The chapter discusses the following: why standard coded data are essential for accurate and reliable execution of decision logic; the semantic spectrum, including terminologies, ontologies, and data models; formalisms for representing these knowledge representations and implications of their combination; the use of terminologies, ontologies, and data models in decision support; the role of ontologies, vocabularies, and data models in the sharing of decision support logic.}
}
@article{SHI2025103676,
title = {Fine-tuning a large language model for automated code compliance of building regulations},
journal = {Advanced Engineering Informatics},
volume = {68},
pages = {103676},
year = {2025},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2025.103676},
url = {https://www.sciencedirect.com/science/article/pii/S1474034625005695},
author = {Jack Wei Lun Shi and Wawan Solihin and Justin K.W. Yeoh},
keywords = {Automated code compliance, Large language models, Retrieval-augmented generation},
abstract = {In the Architecture, Engineering, and Construction (AEC) industry, the interpretation and conversion of building rules into a computer-processable format for automated compliance checking systems are crucial for improving the design process. Yet, current systems and research on rule interpretation either demand extensive and time-consuming expert-induced intervention, or rely on hard-coded pattern matching with limited applicability. To address these limitations, this paper introduces BuildThemis, a framework integrating a large language model fine-tuned on a real-world rule interpretation dataset with a Retrieval-Augmented Generation (RAG) mechanism. BuildThemis serves as a code-assistance tool that delivers structured draft scripts that experts can readily refine. The RAG technique grounds the fine-tuned LLM using an external code knowledge base, achieving a higher CodeBERTScore compared to non-RAG code generation approaches. Results demonstrate that the BuildThemis framework enhances the rule interpretation process by capturing latent concepts within rule-script pairs across various codes of practice and generating semantically similar scripts compared to the reference scripts. This approach to automating rule interpretation emphasizes generalization and reusability of rules, enabling the efficient conversion of textual regulatory documents into computable formats.}
}
@article{CHANDRASEKHAR2024100232,
title = {AMGPT: A large language model for contextual querying in additive manufacturing},
journal = {Additive Manufacturing Letters},
volume = {11},
pages = {100232},
year = {2024},
issn = {2772-3690},
doi = {https://doi.org/10.1016/j.addlet.2024.100232},
url = {https://www.sciencedirect.com/science/article/pii/S2772369024000409},
author = {Achuth Chandrasekhar and Jonathan Chan and Francis Ogoke and Olabode Ajenifujah and Amir {Barati Farimani}},
keywords = {Large language models, Retrieval-augmented generation, Machine learning, Contextual querying, Laser powder bed fusion},
abstract = {Generalized large language models (LLMs) such as GPT-4 may not provide specific answers to queries formulated by materials science researchers. These models may produce a high-level outline but lack the capacity to return detailed instructions on manufacturing and material properties of novel alloys. We introduce “AMGPT”, a specialized LLM text generator designed for metal AM queries. The goal of AMGPT is to assist researchers and users in navigating a curated corpus of literature. Instead of training from scratch, we employ a pre-trained Llama2-7B model from Hugging Face in a Retrieval-Augmented Generation (RAG) setup, utilizing it to dynamically incorporate information from ∼50 AM papers and textbooks in PDF format. Mathpix is used to convert these PDF documents into TeX format, facilitating their integration into the RAG pipeline managed by LlamaIndex. A query retrieval function has also been added, enabling the system to fetch relevant literature from Elsevier journals based on the context of the query. Expert evaluations of this project highlight that specific embeddings from the RAG setup accelerate response times and maintain coherence in the generated text.}
}
@article{ZHANG2022157,
title = {Effect of ontological insecurity on vaccination behavior against COVID-19: a hospital-based cross-sectional study},
journal = {Public Health},
volume = {211},
pages = {157-163},
year = {2022},
issn = {0033-3506},
doi = {https://doi.org/10.1016/j.puhe.2022.07.008},
url = {https://www.sciencedirect.com/science/article/pii/S0033350622002037},
author = {M.-X. Zhang and X.-Y. Lv and G.-F. Shi and C. Luo and X.-Y. Wu and W.-Z. Wang and F.-M. Cheng and H.-X. Chen and T.-H. Tung},
keywords = {COVID-19, Ontological insecurity, Vaccination behavior, China},
abstract = {Objective
Coronavirus disease 2019 (COVID-19) has brought great uncertainty to our society and it may have disrupted people's ontological security. Consequently, this hospital-based study concerns the impact of ontological insecurity on vaccination behavior against COVID-19.
Study design
This cross-sectional study was conducted among hospital inpatients.
Methods
A questionnaire survey addressing inpatient ontological insecurity and vaccination behavior against COVID-19 was administered in Taizhou, China. A total of 1223 questionnaires were collected; specifically, 1185 of them were credible, for a validity rate of 96.9%.
Results
The score of ontological insecurity was 13.27 ± 7.84, which was higher in participants who did not recommend vaccination for others than those who did (12.95 ± 8.25 vs 14.00 ± 6.78, P = 0.022). There was no difference between the vaccinated and unvaccinated groups (13.22 ± 7.96 vs 13.35 ± 7.67, P = 0.779). Lower ontological insecurity (odds ratio [OR] = 1.40, 95% confidence interval [CI]: 1.08–1.81) and being inoculated with COVID-19 vaccines (OR = 2.17, 95% CI: 1.67–2.82) were significantly associated with recommendation of COVID-19 vaccines to others after adjusting for sex, age, education, and occupation. Associations between low ontological insecurity and recommendations for COVID-19 vaccines were observed in men, adults aged 18–59 years, non-farmers, and vaccine recipients.
Conclusions
This study suggests that the ontological insecurity of participants affects their behavior of recommending the COVID-19 vaccination to others rather than getting vaccinated themselves. This promotion of vaccination can be considered from the perspective of improving ontological security in China.}
}
@article{ZHU2022101705,
title = {A hierarchical assembly knowledge representation framework and microdevice assembly ontology},
journal = {Advanced Engineering Informatics},
volume = {53},
pages = {101705},
year = {2022},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2022.101705},
url = {https://www.sciencedirect.com/science/article/pii/S147403462200163X},
author = {Dongsheng Zhu and Zhijing Zhang and Lingling Shi and Jiahui Qian and Saren Qimuge and Dan Song},
keywords = {Assembly knowledge integration, Assembly process planning, Spatial relationship, Microdevice assembly ontology},
abstract = {Microdevice assembly knowledge is dispersed in different product development phases, such as assembly design, assembly simulation and assembly process, and a lot of essential knowledge is implicit and heterogeneous. It is difficult for researchers and computer-aided systems to share and reuse different assembly knowledge quickly and accurately, leading to inefficient and inaccurate assembly process planning. To integrate and structurally represent the assembly design knowledge, assembly simulation knowledge and assembly process knowledge of microdevice, this paper proposes a hierarchical assembly knowledge representation framework and develops a microdevice assembly ontology. There are four layers in the framework, including the organizational structure, the structural relationship, the assembly accuracy, and the process characteristics. The assembly design knowledge that is integrated involves the basic properties of the assembly object as well as the spatial, mating, and assembly relationship, etc. Assembly simulation knowledge refers to the permissible range of assembly force and contact force. Knowledge of assembly processes comprises assembly sequence and operating method of the part. The microdevice assembly ontology is developed based on METHONTOLOGY, and implemented with Protégé. The corresponding SWRL rules have been established to inference the implicit knowledge in assembly design. An ignition target assembly knowledge model based on the microdevice assembly ontology is constructed. In the assembly task of the ignition target, engineers can quickly and accurately access the required assembly knowledge from the ignition target assembly knowledge model, thus verifying the integrity and validity of the microdevice assembly ontology.}
}
@article{SIVARAJKUMAR2024,
title = {Mining Clinical Notes for Physical Rehabilitation Exercise Information: Natural Language Processing Algorithm Development and Validation Study},
journal = {JMIR Medical Informatics},
volume = {12},
year = {2024},
issn = {2291-9694},
doi = {https://doi.org/10.2196/52289},
url = {https://www.sciencedirect.com/science/article/pii/S2291969424000322},
author = {Sonish Sivarajkumar and Fengyi Gao and Parker Denny and Bayan Aldhahwani and Shyam Visweswaran and Allyn Bove and Yanshan Wang},
keywords = {natural language processing, electronic health records, rehabilitation, physical exercise, ChatGPT, artificial intelligence, stroke, physical rehabilitation, rehabilitation therapy, exercise, machine learning},
abstract = {Background
The rehabilitation of a patient who had a stroke requires precise, personalized treatment plans. Natural language processing (NLP) offers the potential to extract valuable exercise information from clinical notes, aiding in the development of more effective rehabilitation strategies.
Objective
This study aims to develop and evaluate a variety of NLP algorithms to extract and categorize physical rehabilitation exercise information from the clinical notes of patients who had a stroke treated at the University of Pittsburgh Medical Center.
Methods
A cohort of 13,605 patients diagnosed with stroke was identified, and their clinical notes containing rehabilitation therapy notes were retrieved. A comprehensive clinical ontology was created to represent various aspects of physical rehabilitation exercises. State-of-the-art NLP algorithms were then developed and compared, including rule-based, machine learning–based algorithms (support vector machine, logistic regression, gradient boosting, and AdaBoost) and large language model (LLM)–based algorithms (ChatGPT [OpenAI]). The study focused on key performance metrics, particularly F1-scores, to evaluate algorithm effectiveness.
Results
The analysis was conducted on a data set comprising 23,724 notes with detailed demographic and clinical characteristics. The rule-based NLP algorithm demonstrated superior performance in most areas, particularly in detecting the “Right Side” location with an F1-score of 0.975, outperforming gradient boosting by 0.063. Gradient boosting excelled in “Lower Extremity” location detection (F1-score: 0.978), surpassing rule-based NLP by 0.023. It also showed notable performance in the “Passive Range of Motion” detection with an F1-score of 0.970, a 0.032 improvement over rule-based NLP. The rule-based algorithm efficiently handled “Duration,” “Sets,” and “Reps” with F1-scores up to 0.65. LLM-based NLP, particularly ChatGPT with few-shot prompts, achieved high recall but generally lower precision and F1-scores. However, it notably excelled in “Backward Plane” motion detection, achieving an F1-score of 0.846, surpassing the rule-based algorithm’s 0.720.
Conclusions
The study successfully developed and evaluated multiple NLP algorithms, revealing the strengths and weaknesses of each in extracting physical rehabilitation exercise information from clinical notes. The detailed ontology and the robust performance of the rule-based and gradient boosting algorithms demonstrate significant potential for enhancing precision rehabilitation. These findings contribute to the ongoing efforts to integrate advanced NLP techniques into health care, moving toward predictive models that can recommend personalized rehabilitation treatments for optimal patient outcomes.}
}
@article{ALAYA2024103417,
title = {An ontological approach to the detection of anomalies in vehicular ad hoc networks},
journal = {Ad Hoc Networks},
volume = {156},
pages = {103417},
year = {2024},
issn = {1570-8705},
doi = {https://doi.org/10.1016/j.adhoc.2024.103417},
url = {https://www.sciencedirect.com/science/article/pii/S1570870524000283},
author = {Bechir Alaya and Lamaa Sellami and Pascal Lorenz},
keywords = {Connected vehicles, Intelligent transport systems (ITS), Machine learning, Intrusion detection, Ontology, HTM},
abstract = {In a vehicular environment, by becoming connected, vehicles are subject to more threats in comparison to traditional information systems, with the difference that, as a cyber-physical system, anomalies and intrusions could have repercussions in the physical world. In this work, we have developed an ontological anomaly-detection approach (OADA). The anomalies studied in this work mainly concern: network scans, DNS tunnel attacks, and telemetry data anomalies. Our contribution relates to a study of the attributes of interest for the algorithm used during the detection phase, namely the hierarchical temporal memory algorithm (HTM). The packets exchanged by the vehicle are grouped in instant description windows. These windows are then analyzed to extract a set of attributes. These are linked to the properties of network traffic, such as flow or latency. They are subject to the process of detecting anomalies and intrusions, carried out thanks to the algorithm with HTM. For each entry, the algorithm produces a score that allows us to decide if a window is abnormal and to lift an alert if that is the case. We evaluated our system using a communications and anomalies emulation tool. We use the corpus of data produced thanks to Autobot. We seek to determine from among the best scores of Matthews correlation coefficient (MCC) and Detection efficiency score (DES) which were the parameters for which HTM detects all anomalies with the greatest possible coverage. The obtained results prove that HTM can detect all anomalies for each window duration.}
}
@article{ZUANELLI2022300,
title = {Cybersecurity ontology and defense solutions: the POC platform},
journal = {Procedia Computer Science},
volume = {205},
pages = {300-309},
year = {2022},
note = {2022 International Conference on Military Communication and Information Systems (ICMCIS)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2022.09.031},
url = {https://www.sciencedirect.com/science/article/pii/S1877050922008961},
author = {Elisabetta Zuanelli},
keywords = {Cybersecurity ontology, AI knowledge representation, threat intelligence, graphs networks representation, IoCs correlations},
abstract = {The paper presents the Platform Ontology of Cybersecurity (POC) as developed by the Pragmema team for big data analytics and early detection of cybersecurity incidents as needed in operational defense systems. The modeling of knowledge representation for threat intelligence, info sharing, and incidents reports is based on the theoretical assumptions provided by general linguistics (specifically text linguistics and pragmalinguistics), semantics and cognitive psychology in an AI perspective and turned into neural networks DDBB.}
}
@article{AMOROCHO2021101415,
title = {Reno-Inst: An ontology to support renovation projects planning and renovation products installation},
journal = {Advanced Engineering Informatics},
volume = {50},
pages = {101415},
year = {2021},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2021.101415},
url = {https://www.sciencedirect.com/science/article/pii/S1474034621001671},
author = {Jerson Alexis Pinzon Amorocho and Timo Hartmann},
keywords = {Building renovation, Project planning, Ontology, Knowledge-based engineering},
abstract = {While the use of semantic models has been explored in different areas of the Architecture, Engineering and Construction (AEC) industry to map and formalize knowledge and support different tasks, building renovation seems to be a neglected area in this field. Therefore, this paper presents the Renovation-Installation (Reno-Inst) ontology, which maps knowledge from the renovation domain considering different requirements, constraints, and other elements related to the installation of common renovation products such as windows, thermal insulation panels, and heat radiators. The development of the Reno-Inst ontology relies on an approach combining input from experts and knowledge from related engineering documents. The verification and validation process includes a content evaluation workshop with experts, a verification design stage, and the analysis and implementation of a real case study. The paper provides another example of the power of ontologies as a method for mapping and representing knowledge, gathering, and retrieving relevant information. Particularly, renovation projects encounter diverse challenges that lead to cost and schedule overruns, making their performance typically low. Therefore, the proposed Reno-Inst ontology provides a basis from which new applications can be developed, tested, and deployed to support improvements in the building renovation field, especially in the planning and execution of renovation activities.}
}
@article{AKREMI20221027,
title = {To Medical Ontology Fuzzification Purpose: COVID-19 Study Case},
journal = {Procedia Computer Science},
volume = {207},
pages = {1027-1036},
year = {2022},
note = {Knowledge-Based and Intelligent Information & Engineering Systems: Proceedings of the 26th International Conference KES2022},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2022.09.158},
url = {https://www.sciencedirect.com/science/article/pii/S1877050922010407},
author = {Houda AKREMI and Mouhamed Gaith AYADI and Sami Zghal},
keywords = {Medical Ontology Fuzzification, Fuzzy ontology, Fuzzy logic, COVID-19},
abstract = {Clearly, ontology components are distinguished depending on features of inexactitudes and uncertainties. Such shortcomings are mostly the outcome an indistinct inaccurate semantic lingual representation, supplied by professionals. So as to tackle this lack of exactness issue, the notion of ”fuzziness” has to be considered. In this respect, fuzzy ontologies have been shown to be useful tools to represent specific knowledge (crisp and fuzzy) and reasoning over it. Thus, an advanced fuzzy ontology called the COVID-19 Fuzzy Ontology (CFO) is exhibited in this work. The latter licenses a semantically meaningful representation of fuzzy crusty medical data particulars related to the diagnosis of COVID-19. The CFO also takes into account the imprecise aspects associated to the induced knowledge of this disease. The CFO is grounded from a domain ontology about COVID-19. The evaluation of the CFO ontology shows that it is accurate, consistent, and that it covers COVID-19 terminologies.}
}
@article{FELTUS2023,
title = {Towards a Multidimensional Ontology Model for DIH-Based Organisations},
journal = {International Journal of Knowledge and Systems Science},
volume = {14},
number = {1},
year = {2023},
issn = {1947-8208},
doi = {https://doi.org/10.4018/IJKSS.326764},
url = {https://www.sciencedirect.com/science/article/pii/S1947820823000077},
author = {Christophe Feltus and Damien Nicolas and Djamel Khadraoui},
keywords = {CPS, Cyber-Physical System, Digital Innovation Hub, Network, Ontology, Protégé},
abstract = {ABSTRACT
Digital innovation hubs are of utmost importance when they sustain cooperation in innovative technological domains like the cyber-physical system. In this paper, the authors introduce, in the first part, a DIH ontology that they extend (1) with network and (2) with CPS entities. For this, they remind the questions that the ontology must answer, deploy the methodology proposed by Noy and McGuinness to identify the classes and the associations between classes, and integrate the new CPS ontological extensions. In the second part, they implement the full innovative DIH4CPS ontology within Protégé, and they instantiate it to a real company.}
}
@article{AYADI2019572,
title = {Ontology population with deep learning-based NLP: a case study on the Biomolecular Network Ontology},
journal = {Procedia Computer Science},
volume = {159},
pages = {572-581},
year = {2019},
note = {Knowledge-Based and Intelligent Information & Engineering Systems: Proceedings of the 23rd International Conference KES2019},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2019.09.212},
url = {https://www.sciencedirect.com/science/article/pii/S1877050919313961},
author = {Ali Ayadi and Ahmed Samet and François de Bertrand {de Beuvron} and Cecilia Zanni-Merk},
keywords = {Ontology population, Knowledge acquisition, Natural language processing, Deep learning, Biomolecular Network Ontology},
abstract = {As a scientific discipline, systems biology aims to build models of biological systems and processes through the computer analysis of a large amount of experimental data describing the behaviour of whole cells. It is within this context that we already developed the Biomolecular Network Ontology especially for the semantic understanding of the behaviour of complex biomolecular networks and their transittability. However, the challenge now is how to automatically populate it from a variety of biological documents. To this end, the target of this paper is to propose a new approach to automatically populate the Biomolecular Network Ontology and take advantage of the vast amount of biological knowledge expressed in heterogeneous unstructured data about complex biomolecular networks. Indeed, we have recently observed the emergence of deep learning techniques that provide significant and rapid progress in several domains, particularly in the process of deriving high-quality information from text. Despite its significant progress in recent years, deep learning is still not commonly used to populate ontologies. In this paper, we present a deep learning-based NLP ontology population system to populate the Biomolecular Network Ontology. Its originality is to jointly exploit deep learning and natural language processing techniques to identify, extract and classify new instances referring to the BNO ontology’s concepts from textual data. The preliminary results highlight the efficiency of our proposal for ontology population.}
}
@article{HERMON202448,
title = {A Heritage Digital Twin ontology-based description of Giovanni Baronzio's “Crucifixion of Christ” analytical investigation},
journal = {Journal of Cultural Heritage},
volume = {66},
pages = {48-58},
year = {2024},
issn = {1296-2074},
doi = {https://doi.org/10.1016/j.culher.2023.11.004},
url = {https://www.sciencedirect.com/science/article/pii/S129620742300211X},
author = {Sorin Hermon and Franco Niccolucci and Nikolas Bakirtzis and Svetlana Gasanova},
keywords = {Digital twin, Cultural heritage data integration and interoperability, Transparency of research, Knowledge base, Ontology},
abstract = {The methodologies of Cultural Heritage research and in particular those related to conservation and the analytical study of heritage assets and works of art, recently grouped under the term Heritage Sciences, engage a broad range of disciplines, each with its own characteristic workflows for generating data. Consequently, an emerging challenge is the need to define a digital framework for multi-source data integration, associated with a single heritage asset, but generated by various tools and methods which are often pursued by different research groups and at different times. This digital framework is discussed in this essay as the digital twin of a heritage asset, comprising of the documentation data associated with a heritage asset and its virtual representation. To best describe and define a Heritage Digital Twin ontology and its associated knowledge graph, we use a specific example drawing from art historical and analytical investigation of a 13th century Italian painting masterpiece, the Crucifixion of Christ, by Giovanni Baronzio, one of the leaders of the so-called Rimini School of painting which was greatly influenced by the work of the famous Renaissance master Giotto di Bondone.}
}
@article{ODEGO2024,
title = {An Ontology-Based Approach for Zero-Day Information Security Threat Management},
journal = {International Journal of Information Security and Privacy},
volume = {19},
number = {1},
year = {2024},
issn = {1930-1650},
doi = {https://doi.org/10.4018/IJISP.384606},
url = {https://www.sciencedirect.com/science/article/pii/S1930165025000068},
author = {John Kennedy Otieno Odego and Kennedy Odhiambo Ogada and Dennis Mugambi Kaburu},
keywords = {Information Security, Zero-Day Security Threats, Ontology, Threat Management},
abstract = {ABSTRACT
Zero Day security threats are diverse and manifest in many forms. Despite the growing number of zero day attacks, very little information about the kind of threat and how to defend against the threats is known by information security professionals. Signature based techniques and statistical based techniques have been seen to be less effective in handling Zero-day security threats (ZDST) since they require a new threat signature and threat profile to be learnt each time, meaning new signatures and profiles cannot be detected and behavior-based approaches have always resulted in many false positives in handling of zero-day security threats. The ZDST may result in disruptions of service, loss of data, loss of data integrity, corruption of data, systems malfunction, miscommunication, or other undesired effects on information systems. This research proposes an ontology-based approach for management of ZDST and evaluates its performance for use in detection and prevention of ZDST within the information security domain.}
}
@article{HERRERAMARTIN2022447,
title = {A method for transferring BIM data into domain ontologies: A case study based on airport services},
journal = {Egyptian Informatics Journal},
volume = {23},
number = {3},
pages = {447-467},
year = {2022},
issn = {1110-8665},
doi = {https://doi.org/10.1016/j.eij.2022.04.002},
url = {https://www.sciencedirect.com/science/article/pii/S1110866522000275},
author = {J.J. Herrera-Martín and I. Castilla-Rodríguez and E.J. González and N. Martín-Dorta},
keywords = {Airport facilities, BIM, Ontologies, Semantic Web},
abstract = {Building Information Modeling (BIM) has revolutionized the construction industry as a platform for core integrated design, modeling, asset planning, and collaboration. Although BIM simplifies the retrieval and use of information in construction projects, BIM tools use native formats that pose challenges for data reuse and exchange. This article proposes a method for mapping BIM data into sets of concepts of a specific domains, and the use of Semantic Web tools for the exchange of data and information. Domain ontologies are a widely used tool for the formal definition of a field of knowledge, which facilitates the exchange of information in heterogeneous systems through technologies such as the Semantic Web. The proposed mapping can be used to enrich information and improve data integration in systems based on semantic tools that manage services or maintain facilities and building infrastructures. The article also presents a case study based on the management of airport facilities to illustrate the practical application of the method.}
}
@article{GHERNAOUT20222833,
title = {Towards an ontology-based approach to enhance the mobile blood collection process},
journal = {Procedia Computer Science},
volume = {207},
pages = {2833-2842},
year = {2022},
note = {Knowledge-Based and Intelligent Information & Engineering Systems: Proceedings of the 26th International Conference KES2022},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2022.09.341},
url = {https://www.sciencedirect.com/science/article/pii/S1877050922012303},
author = {Ikram Ghernaout and Linda Elmhadhbi and Arkopaul Sarkar and Sidi Mohamed Meliani and Mohamed Hedi Karray},
keywords = {ontology, upper-level ontology, mobile blood collection},
abstract = {The choice of the best location to install the mobile blood collection center is one of the most significant challenges of the blood supply chain. To date, there is a strong need to mobilize potential donors and maximize the amount of collected blood in order to meet the demand. However, the traditional mobile blood collection process is non-digitalized, and there is a huge amount of information that should be considered to enhance the decision-making process. Understanding data more effectively is a key factor to provide insight in order to support decision makers in choosing the most appropriate site to install the mobile truck in order to target as many donors as possible. Accordingly, an ontology-based cyber-physical social system (CPSS) is essential to improve the mobile blood collection process and digitalize it. In this paper, we present Mobile Blood Collection Ontology (MBCO), a modular suite of ontologies that formalize the mobile blood collection process. To do so, we use Basic Formal Ontology (BFO) as a top-level ontology that facilitates the integration of the different ontological modules and also some existing domain ontologies. The proposed ontology will be exploited later by a data-driven decision support system to find out the best location for the mobile center.}
}
@article{ROBSON2023101204,
title = {An ontology for very large numbers of longitudinal health records to facilitate data mining and machine learning},
journal = {Informatics in Medicine Unlocked},
volume = {38},
pages = {101204},
year = {2023},
issn = {2352-9148},
doi = {https://doi.org/10.1016/j.imu.2023.101204},
url = {https://www.sciencedirect.com/science/article/pii/S2352914823000461},
author = {B. Robson and O.K. Baek},
keywords = {Longitudinal patient record, Ontology, Big data, Artificial intelligence, Machine learning, Deep learning, Neural net},
abstract = {Despite the extensive experience of the authors working in industry with a variety of electronic health records that worked well in their intended context, none currently available in reasonably large numbers seem to have ontologies and formats that will scale well to very large numbers of detailed cradle-to-grave longitudinal health records facilitating knowledge extraction. By that we mean data mining, Deep Learning neural nets and all related analytic and predictive methods for biomedical research and clinical decision support potentially applied to the health records of an entire nation. They are mostly far too complicated to support frequent high-dimensional analysis, which is required because such records will update (or should update) dynamically on a regular basis, will in future include new tests etc. acquired daily by translational medical research, and not least allow public health, research, and diagnostic, vaccine, and drug development teams to respond quickly to emergent epidemics like COVID-19. A Presidential Advisory team call in 2010 for interoperability and ease of data mining for medical records is discussed and the situation seems still not fully resolved. The solution appears to lie between efficient comma separated value files and the ability to embellish these with a moderate degree of more elaborate ontology. One recommendation is made here with discussion and analysis that should guide alternative and future approaches. It combines demographic, comorbidity, genomic, diagnostic, interventional, and outcomes information along with time/date stamping method appropriate to analysis, with facilities for special research studies. By using a “metadata operator”, a suitable balance between a comma separated values file and an ontological structure is possible.}
}
@article{PATEL2023113774,
title = {Ontology-based detection and identification of complex event of illegal parking using SPARQL and description logic queries},
journal = {Chaos, Solitons & Fractals},
volume = {174},
pages = {113774},
year = {2023},
issn = {0960-0779},
doi = {https://doi.org/10.1016/j.chaos.2023.113774},
url = {https://www.sciencedirect.com/science/article/pii/S0960077923006756},
author = {Ashish Singh Patel and Vivek Tiwari and Muneendra Ojha and O.P. Vyas},
keywords = {Data integration, Multimedia representation, Mobile surveillance, Knowledge graph, Information retrieval, Illegal parking},
abstract = {Dynamic monitoring and management of traffic is a significant challenge which requires a mobile surveillance system which is becoming feasible with the evolution of 5G and related technologies. With the advent of 5G, huge amount of data can be transferred over long distance. Furthermore, the evolution of Multi-access Edge Computing (MEC) offers the processing near the edge, resulting in quick response which can cater to mobile surveillance. The mobile surveillance can be performed through a vehicle (Unmanned Aerial Vehicle (UAV)/mobile vehicle) which collects the multi-modal data and sends to nearest edge server over the 5G network. The server sends response quickly to the control center from where the appropriate action can be taken to mitigate its effect on the individuals in real-time. Furthermore, the analysis of multi-modal data captured by surveillance systems must be integrated and efficiently represented. Therefore, in this work, an ontology-based approach is proposed by integrating unstructured video data and structured sensor data for detecting and identifying the complex event of illegal parking. Identifying illegally parked vehicles needs dynamic and strict monitoring; which require the deployment of surveillance systems across the entire city. However, installing a video camera at each place is not feasible. Therefore, the surveillance thorough mobile vehicle is presented to identify illegal parked vehicle for traffic management over the 5G network. In addition, an ontology is developed to represent and reason over the roadside video data while integrating it with sensor data to form a knowledge graph. The knowledge graph retrieves semantic information about the events using SPARQL queries and Description Logics (DL) queries. Thus, a complete video is not required and the extracted information is stored in Resource Description Framework (RDF) format to reduce space requirement significantly. The approach is evaluated by recognizing the complex events of detecting illegally parked vehicles on a real-time dataset recorded using the experimental setup. Furthermore, the framework represents the surveillance video data of parked vehicles captured using the camera installed in a mobile vehicle to cover the road, including the vehicle information location, position, time, etc., as a knowledge graph that can be used later for further analysis.}
}
@article{SCHIMMELPFENNIG2025104900,
title = {CeRTS: certainty retrieval token search in large language model clinical information extraction},
journal = {Journal of Biomedical Informatics},
volume = {170},
pages = {104900},
year = {2025},
issn = {1532-0464},
doi = {https://doi.org/10.1016/j.jbi.2025.104900},
url = {https://www.sciencedirect.com/science/article/pii/S1532046425001297},
author = {Lars E. Schimmelpfennig and Kriti Bhattarai and Inez Y. Oh and Jake Lever and Obi L. Griffith and Malachi Griffith and Albert M. Lai and Zachary B. Abrams},
keywords = {Large language models, Uncertainty estimators, Clinical information extraction},
abstract = {Objective
Large language models (LLMs) must effectively communicate their uncertainty to be viable in clinical settings. As such, the need for reliable uncertainty estimation grows increasingly urgent with the expanding use of LLMs for information extraction from electronic health records. Previous token-level uncertainty estimators have only used token probabilities within a single output sequence. Here, by leveraging the constraints of JSON output structure, we instead consider all likely sequences and their respective probabilities to obtain a more robust measure of model confidence. We develop Certainty Retrieval Token Search (CeRTS), a new uncertainty estimator for structured information extraction.
Methods
We evaluated CeRTS against a previous gold-standard uncertainty estimator when extracting clinical features from lung cancer discharge summaries across eight open-source LLMs. Calibration (Brier score) and discrimination (AUROC) were used to quantify performance.
Results
CeRTS surpassed the previous gold-standard estimator in discriminatory power across every model and achieved better calibration in most cases. CeRTS had the strongest agreement between model confidence and accuracy with Qwen-2.5.
Conclusion
CeRTS enhances LLM-based information extraction from unstructured clinical text by assigning well-calibrated confidence scores to each extracted item, providing medical researchers with a quantitative measure of reliability at minimal additional cost. Although its performance was generally robust, CeRTS struggled with DeepSeek-R1, which we attribute to the model’s Chain-of-Thought reasoning steps. Our evaluation focused on clinical data, but CeRTS can be applied to any domain requiring reliable uncertainty estimation.}
}
@article{LI2025113147,
title = {Knowledge-enhanced large language models for ideation to implementation: A new paradigm in product design},
journal = {Applied Soft Computing},
volume = {176},
pages = {113147},
year = {2025},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2025.113147},
url = {https://www.sciencedirect.com/science/article/pii/S1568494625004582},
author = {Zhinan Li and Zhenyu Liu and Guodong Sa and Jiacheng Sun and Mingjie Hou and Jianrong Tan and Lei Sun and Jun Wei},
keywords = {Decision support systems, Knowledge enhancement, Knowledge graph, Large language models, Multi-design task adapter, Product innovation design, Product intelligent design},
abstract = {Traditional product design processes often struggle to accurately capture complex user needs and generate market-relevant solutions due to a heavy reliance on subjective human input and limited decision support tools. While Large Language Models (LLMs) have shown proficiency in various domains, their application in product design remains limited, often resulting in generic outputs. To address this, we propose an innovative paradigm for intelligent product design generation, termed ProdGen. The core of ProdGen is the ProdGen-Agent system, which integrates LLMs with customized expert design tools, leveraging the proposed Multi-Design Task Adapter (MDT-A) method and a Dual Knowledge Enhancement Mechanism. The MDT-A method injects multimodal design task knowledge into LLMs through a unified knowledge fusion framework, enabling enhanced task decomposition and efficient interaction with custom design tools. The Dual Knowledge Enhancement Mechanism enriches LLM performance by incorporating domain-specific knowledge bases and structured graph-based data retrieval, ensuring more accurate and relevant design outputs. Demonstrated through kitchen design cases, ProdGen-Agent autonomously handles the entire design process, excelling in user need analysis, task breakdown, decision-making support, tool integration, and multidimensional design generation. Expert evaluations validate ProdGen-Agent’s effectiveness in automating complex design tasks, confirming its potential to revolutionize product design processes across various industries by leveraging LLMs in combination with domain expertise.}
}
@article{ZHANG2025103227,
title = {Improving protein–protein interaction modulator predictions via knowledge-fused language models},
journal = {Information Fusion},
volume = {123},
pages = {103227},
year = {2025},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2025.103227},
url = {https://www.sciencedirect.com/science/article/pii/S1566253525003008},
author = {Zitong Zhang and Quan Zou and Chunyu Wang and Junjie Wang and Lingling Zhao},
keywords = {Protein-protein interaction modulator, Knowledge fusion, Language model, Gene ontology, Pretrain},
abstract = {Protein-protein interactions (PPIs) play key roles in numerous biological processes and their dysregulation can lead to various human diseases. Modulating these interactions with small molecule PPI modulators has emerged as a promising strategy for treating such diseases. However, current computational approaches for screening PPI modulators often fail to integrate biomolecular expertise and lack the elucidation of interaction mechanisms. Here, we propose a knowledge-fused modulator-PPI interaction prediction method (KFPPIMI) to alleviate these issues. KFPPIMI constructs separate representation models for modulators and proteins, each of which integrates external knowledge from textual and graph-based data sources via a language modeling framework. The fusion of the nuanced expression of natural language with the structural attributes of biomolecules provides KFPPIMI with a holistic view of modulator-PPI interactions. Extensive experiments are conducted to evaluate the effectiveness of KFPPIMI and its individual components. The results show that KFPPIMI outperforms existing methods in different scenarios. Moreover, the modulator and protein representation model can be successfully applied to their respective downstream tasks with comparable performance.}
}
@article{GONZALEZERAS2022100816,
title = {Ontological engineering for the definition of a COVID-19 pandemic ontology},
journal = {Informatics in Medicine Unlocked},
volume = {28},
pages = {100816},
year = {2022},
issn = {2352-9148},
doi = {https://doi.org/10.1016/j.imu.2021.100816},
url = {https://www.sciencedirect.com/science/article/pii/S2352914821002811},
author = {Alexandra González-Eras and Ricardo Dos Santos and Jose Aguilar and Alberto Lopez},
keywords = {COVID ontology, COVID-19, Ontology integration, Ontological engineering},
abstract = {COVID-19 has generated a lot of information in different formats, and one of them is in the ontology format. Also, there are previous ontologies from other disciplines that can help to analyze the COVID-19 pandemic. Thus, due to the large quantity of COVID-19 information in the form of ontologies, approaches to ontology integration and interoperability could be beneficial. In this context, this research proposes a new ontology, called COVID-19 Pandemic ontology, which is the product of an ontological engineering process proposed in this research that allows the integration of several ontologies to cover all the aspects of this infectious disease. The ontological engineering process defines tasks of fusion, alignment, and linking for integrating the ontologies. The resulting pandemic ontology provides a simple repository for storing information about the COVID-19, reusing existing ontologies, to offer multiple views about the disease, including the social context. This ontology has been tested in different case studies to prove its capabilities to infer useful information about the COVID-19 pandemic.}
}
@article{MEDINANIETO2020129,
title = {An Ontology-based Approach to Describe Collaborative Work by Reusing and Enriching Data From an Institutional Repository},
journal = {Electronic Notes in Theoretical Computer Science},
volume = {354},
pages = {129-139},
year = {2020},
note = {Proceedings of the Eleventh and Twelfth Latin American Workshop on Logic/Languages, Algorithms and New Methods of Reasoning (LANMR)},
issn = {1571-0661},
doi = {https://doi.org/10.1016/j.entcs.2020.10.010},
url = {https://www.sciencedirect.com/science/article/pii/S1571066120300864},
author = {María Auxilio {Medina Nieto} and Delia Arrieta Díaz and Jorge {de la Calleja Mora} and Laura {Zacatzontetl Hernández} and Marilú {Zacatelco Pérez}},
keywords = {Ontologies, semantic web, institutional repositories, document management},
abstract = {Besides tutoring and consultancies, the development of academic and scientific documents in universities evidenced collaborative work. This paper presents an ontology-based approach to describe different modes of collaboration by reusing and enriching data from an institutional repository, from a collection of posters. The approach uses an application ontology that makes explicit the relationships among authors and posters. The paper presents a list of competency questions that are answered in natural language and by the ontology terminology. The proposed approach is of value as this offers machine-readable data to support further analysis and inference mechanisms. This paper represents a reviewed version of the described for the CEUR proceedings for the “Twelfth Latin American Workshop on New Methods of Reasoning 2019 Logic / Languages, Algorithms, New Methods of Reasoning (LANMR 2019)”.}
}
@article{DAWOOD2022,
title = {An Ontology Towards Predicting Terrorism Events},
journal = {International Journal of Cyber Warfare and Terrorism},
volume = {12},
number = {1},
year = {2022},
issn = {1947-3435},
doi = {https://doi.org/10.4018/IJCWT.311421},
url = {https://www.sciencedirect.com/science/article/pii/S1947343522000143},
author = {Zubeida Dawood and Carien {Van 't Wout}},
keywords = {Analysis, Database, Ontology, Ontology Development, Ontology Methodology, Ontology-Based Data Access, Semantic Interoperability, Semantic Web, Terror Attacks, Terror Events, Terrorism, Web-Scraper},
abstract = {ABSTRACT
Although there is an increasing amount of information for counter-terrorism operations freely available online, it is a complex process to extract relevant information and to detect useful patterns in the data in order for intelligence functionaries to identify threats and to predict possible terror attacks. Automation is required for intelligent decision-making. To assist with this, in this paper, the researchers propose an ontology-based data access system for counter-terrorism. The system will enable intelligence analysts to perform specialised semantic searches about terrorist events or groups for analysis using an ontology. In this paper, the researchers present the ontology that was created by following an existing methodology for ontology development, and an ontology-based data access system together with all the components used in development (i.e., databases, web-scraper tools, ontology-based data access software, and data sources). Lastly, the ontology is demonstrated by means of use cases with example queries for generating actionable intelligence for operations.}
}
@article{HAMOUNI20232254,
title = {OntoSoC: An ontology-based approach to battery pack SoC estimation},
journal = {Procedia Computer Science},
volume = {225},
pages = {2254-2263},
year = {2023},
note = {27th International Conference on Knowledge Based and Intelligent Information and Engineering Sytems (KES 2023)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2023.10.216},
url = {https://www.sciencedirect.com/science/article/pii/S1877050923013741},
author = {Ala Eddine Hamouni and Franco Giustozzi and Ahmed Samet and Ali Ayadi and Slimane Arbaoui and Tedjani Mesbahi},
keywords = {Li-ion battery-pack, Ontology, SWRL Rules, State of Charge (SoC)},
abstract = {A critical aspect of managing lithium-ion battery packs in electric vehicle applications is accurately determining the State of Charge (SoC). There are several methods available to estimate it, including coulomb counting with direct evaluation, Open circuit voltage, kalman filter with adaptive approach, particle flter, as well as fuzzy logic and data-based approach. In this paper, we use the state of charge data already computed by a data-driven approach and combine it with an ontology of a battery pack. The built ontology models the battery pack, taking into account the topology, types of cells and their organization inside. To make an exact estimation, different strategies of balance control of the cells are considered. SWRL rules are used to compute the state of charge of the whole battery pack. Matlab Simulink multi-physics model of a lithium-ion battery is used to provide simulated data for the experiments. The given model is evaluated based on regression metrics showing its performance.}
}
@article{CIROKU2024100822,
title = {RevOnt: Reverse engineering of competency questions from knowledge graphs via language models},
journal = {Journal of Web Semantics},
volume = {82},
pages = {100822},
year = {2024},
issn = {1570-8268},
doi = {https://doi.org/10.1016/j.websem.2024.100822},
url = {https://www.sciencedirect.com/science/article/pii/S1570826824000088},
author = {Fiorela Ciroku and Jacopo {de Berardinis} and Jongmo Kim and Albert Meroño-Peñuela and Valentina Presutti and Elena Simperl},
keywords = {Knowledge engineering, Knowledge graph, Ontology development, Competency question extraction},
abstract = {The process of developing ontologies – a formal, explicit specification of a shared conceptualisation – is addressed by well-known methodologies. As for any engineering development, its fundamental basis is the collection of requirements, which includes the elicitation of competency questions. Competency questions are defined through interacting with domain and application experts or by investigating existing datasets that may be used to populate the ontology i.e. its knowledge graph. The rise in popularity and accessibility of knowledge graphs provides an opportunity to support this phase with automatic tools. In this work, we explore the possibility of extracting competency questions from a knowledge graph. This reverses the traditional workflow in which knowledge graphs are built from ontologies, which in turn are engineered from competency questions. We describe in detail RevOnt, an approach that extracts and abstracts triples from a knowledge graph, generates questions based on triple verbalisations, and filters the resulting questions to yield a meaningful set of competency questions; the WDV dataset. This approach is implemented utilising the Wikidata knowledge graph as a use case, and contributes a set of core competency questions from 20 domains present in the WDV dataset. To evaluate RevOnt, we contribute a new dataset of manually-annotated high-quality competency questions, and compare the extracted competency questions by calculating their BLEU score against the human references. The results for the abstraction and question generation components of the approach show good to high quality. Meanwhile, the accuracy of the filtering component is above 86%, which is comparable to the state-of-the-art classifications.}
}
@article{DAHLING2020100571,
title = {OWL2Go: Auto-generation of Go data models for OWL ontologies with integrated serialization and deserialization functionality},
journal = {SoftwareX},
volume = {12},
pages = {100571},
year = {2020},
issn = {2352-7110},
doi = {https://doi.org/10.1016/j.softx.2020.100571},
url = {https://www.sciencedirect.com/science/article/pii/S2352711020302843},
author = {Stefan Dähling and Lukas Razik and Antonello Monti},
keywords = {Ontology, OWL, Go, SAREF},
abstract = {The Web Ontology Language (OWL) is a formal language for the description of terms and their relationship in a certain domain. It enables information exchange among heterogeneous applications and devices in a machine-readable format. However, in software development the usage of data models is common. In order to facilitate the usage of ontologies encoded in OWL also in software development we present OWL2Go. OWL2Go is a code-generator that parses an OWL ontology and generates a Go package implementing a data model compliant with the ontology as well as a serializer and deserializer for conversion between the Go data model and Turtle or JSON-LD documents. We demonstrate the generation process and the usage of the resulting Go package with the Smart Appliances REFerence (SAREF) ontology.}
}
@article{ROMERO2022100409,
title = {A hybrid deep learning and ontology-driven approach to perform business process capability assessment},
journal = {Journal of Industrial Information Integration},
volume = {30},
pages = {100409},
year = {2022},
issn = {2452-414X},
doi = {https://doi.org/10.1016/j.jii.2022.100409},
url = {https://www.sciencedirect.com/science/article/pii/S2452414X22000760},
author = {Marcelo Romero and Wided Guédria and Hervé Panetto and Béatrix Barafort},
keywords = {Deep learning, Long Short-Term Memory Network, Ontology, Process capability assessment},
abstract = {Enterprises are constantly transforming to adapt to an ever-changing and competitive environment. In this context, assessments allow to understand the state of different organisational aspects before performing transformation activities. One of these aspects is the capability of business processes. Evaluating the quality of business processes is relevant to guide improvement initiatives, considering that the way that processes are designed and executed in organisations has direct impact on the quality of products and services. However, assessments are expensive in terms of resources if they are performed by humans. In this sense, recent trends in Artificial Intelligence provide means to improve process capability assessment through the automation of some of its tasks. Following this line, this work presents a method to perform process capability assessment using raw text as input data with the aid of a smart system, able to reduce the need of human intervention to provide reliable assessment results. For this purpose, we introduce a hybrid approach to perform assessments in enterprises using text data as assessment evidence. The method combines the Long Short-Term Memory Network (LSTM) approach and the use of an Ontology named Process Capability Assessment Ontology (PCAO), which also contains a set of rules to calculate process attribute ratings, capability levels, among other aspects. The approach is grounded on the Smart Assessment Framework, a conceptual model devised to guide the development of intelligent assessments in enterprises. We introduce a demonstration of the assessment of a process based on the management of chemical samples from a research institute.}
}
@article{SILVENNOINEN2023151,
title = {A semantic web approach to land use regulations in urban planning: The OntoZoning ontology of zones, land uses and programmes for Singapore},
journal = {Journal of Urban Management},
volume = {12},
number = {2},
pages = {151-167},
year = {2023},
issn = {2226-5856},
doi = {https://doi.org/10.1016/j.jum.2023.02.002},
url = {https://www.sciencedirect.com/science/article/pii/S2226585623000067},
author = {Heidi Silvennoinen and Arkadiusz Chadzynski and Feroz Farazi and Ayda Grišiūtė and Zhongming Shi and Aurel {von Richthofen} and Stephen Cairns and Markus Kraft and Martin Raubal and Pieter Herthogs},
keywords = {City planning, Master plan, Zoning, Knowledge graph, Web 3.0},
abstract = {Semantic web technologies have the potential to significantly improve urban regulatory data access, integration and usability, with potentially large implications for planning practice. Ontologies are a cornerstone of the semantic web. In this paper, we describe OntoZoning, an ontology representing relationships between zoning types, land uses and programmes (more specific land uses) in Singapore. We link the ontology to geospatial data stored in a knowledge graph, which allows executing multi-domain queries on urban data. We demonstrate how such a semantic web based approach can improve access to and usability of land use regulation data, and in particular facilitate site selection and exploration. We also discuss the difficulty of defining some concepts in the land use regulation field, and how OntoZoning could be linked to a broader semantic-web based urban planning regulatory framework.}
}
@article{IQBAL20224767,
title = {Mobile Devices Interface Adaptivity Using Ontologies},
journal = {Computers, Materials and Continua},
volume = {71},
number = {3},
pages = {4767-4784},
year = {2022},
issn = {1546-2218},
doi = {https://doi.org/10.32604/cmc.2022.023239},
url = {https://www.sciencedirect.com/science/article/pii/S1546221822006919},
author = {Muhammad Waseem Iqbal and Muhammad Raza Naqvi and Muhammad Adnan Khan and Faheem Khan and T. Whangbo},
keywords = {User context, adaptive interfaces, human computer interaction},
abstract = {Currently, many mobile devices provide various interaction styles and modes which create complexity in the usage of interfaces. The context offers the information base for the development of Adaptive user interface (AUI) frameworks to overcome the heterogeneity. For this purpose, the ontological modeling has been made for specific context and environment. This type of philosophy states to the relationship among elements (e.g., classes, relations, or capacities etc.) with understandable satisfied representation. The context mechanisms can be examined and understood by any machine or computational framework with these formal definitions expressed in Web ontology language (WOL)/Resource description frame work (RDF). The Protégé is used to create taxonomy in which system is framed based on four contexts such as user, device, task and environment. Some competency questions and use-cases are utilized for knowledge obtaining while the information is refined through the instances of concerned parts of context tree. The consistency of the model has been verified through the reasoning software while SPARQL querying ensured the data availability in the models for defined use-cases. The semantic context model is focused to bring in the usage of adaptive environment. This exploration has finished up with a versatile, scalable and semantically verified context learning system. This model can be mapped to individual User interface (UI) display through smart calculations for versatile UIs.}
}
@article{HU2022175,
title = {Ontology-based system to support industrial system design for aircraft assembly},
journal = {IFAC-PapersOnLine},
volume = {55},
number = {2},
pages = {175-180},
year = {2022},
note = {14th IFAC Workshop on Intelligent Manufacturing Systems IMS 2022},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2022.04.189},
url = {https://www.sciencedirect.com/science/article/pii/S2405896322001902},
author = {Xiaodu Hu and Rebeca Arista and Xiaochen Zheng and Joachim Lentes and Jyri Sorvari and Jinzhi Lu and Fernando Ubis and Dimitris Kiritsis},
keywords = {Ontology, Ontology-based System, aircraft assembly, Model-based System Engineering, requirement management, Models for Manufacturing},
abstract = {The development of an aircraft industrial system is a complex process which faces the challenge of digital discontinuity in multidisciplinary engineering due to various interfaces between different digital tools, leading to extra development time and costs. This paper proposes an ontology-based system, aiming at functionality integration and design process automation, by Models for Manufacturing methodology principles. A tool-agnostic modelling, simulation and validation platform with Discrete Event Simulation and 3D simulation is enabled and demonstrated in a real case study. An ontology layer collecting the domain knowledge enables integration of the proposed system, accelerating the design process and enhancing design quality.}
}
@article{BOUIHI2019313,
title = {An UML to OWL based approach for extracting Moodle’s Ontology for Social Network Analysis},
journal = {Procedia Computer Science},
volume = {148},
pages = {313-322},
year = {2019},
note = {THE SECOND INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING IN DATA SCIENCES, ICDS2018},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2019.01.039},
url = {https://www.sciencedirect.com/science/article/pii/S1877050919300390},
author = {Bouchra Bouihi and Mohamed Bahaj},
keywords = {Semantic web, E-learning, Ontology, Moodle, Social Network Analysis, UML},
abstract = {The main analyses in Social Network Analysis field are focusing on measuring the frequency of social interactions that are modeled only with numbers; 0 or 1 on the graph adjacency matrix. Therefore, ontologies have drawn attention to empower and enhance the Social Network Analysis with semantics. By exploring theses semantics, besides we better view and analyze the interactions between students and teachers inside the Learning Management System, the network graph structure and analyses change. In this paper, we propose a methodology to build Moodle’s OWL (Web Ontology Language) ontology for Social Network Analysis ends. The proposed ontology gives explicit meaning to the relationships inside Moodle instead of modeling them as nodes and edges with implicit semantics like the case in classical Social Network Analysis. The semantics of relationships influences the graph structure and statistics by making some nodes more central and influential and other nodes less central and influential. The built ontology is basically made by exploring the UML (Unified Modeling Language) class diagram that we created from Moodle Mount Orange School and is our main metadata source.}
}
@article{KS2025130573,
title = {Text-attributed community detection in complex networks through LLMs and GNNs: A powerful fusion of language and graphs},
journal = {Neurocomputing},
volume = {647},
pages = {130573},
year = {2025},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2025.130573},
url = {https://www.sciencedirect.com/science/article/pii/S0925231225012457},
author = {Sruthi K.S. and A. Sreekumar and Kannan Balakrishnan},
keywords = {Complex networks, Community detection, Text-Attributed Graphs (TAGs), Node classification, Textual embeddings, Graph neural networks (GNNs), Pre-trained language models (PLMs), Hyperparameter tuning},
abstract = {This paper introduces a novel framework for community detection in complex networks by considering advanced embedding techniques to integrate textual information associated with nodes and edges with graph structures. We propose a Text-Attributed Graph (TAG) approach, where textual data from nodes and edges, such as book descriptions and user reviews in book recommendation systems, is transformed into semantic embeddings using pre-trained language models (PLMs). Specifically, we employ the latest state-of-the-art embedding models, including E5-Base, variants of BERT (SBERT, DistiBERT, BERT-Base, and BERT-Large), and OpenAI’s text-embedding-3-large, and the cost-effective text-embedding-ada-002, to enrich graph representations with meaningful contextual features as edge embeddings. These embeddings are integrated into graph neural networks (GNNs), enabling the model to exploit structural and textual contexts to improve community detection performance. The integration of textual embeddings and several GNNs in this manner offers a promising performance for enhancing community detection tasks in complex networks, opening new possibilities for applications in recommendation systems, information retrieval, predictive tasks, and beyond.}
}
@article{OJINO2022369,
title = {Hotel room personalization via ontology and rule-based reasoning},
journal = {International Journal of Web Information Systems},
volume = {18},
number = {56},
pages = {369-387},
year = {2022},
issn = {1744-0084},
doi = {https://doi.org/10.1108/IJWIS-02-2022-0045},
url = {https://www.sciencedirect.com/science/article/pii/S1744008422000052},
author = {Ronald Ojino and Luisa Mich and Nerey Mvungi},
keywords = {Personalization, Semantic rules, Ontology, Tourism, Guest, Sensors},
abstract = {Purpose
The increasingly competitive hotel industry and emerging customer trends where guests are more discerning and want a personalized experience has led to the need of innovative applications. Personalization is much more important for hotels, especially now in the post-COVID lockdown era, as it challenges their business model. However, personalization is difficult to design and realize due to the variety of factors and requirements to be considered. Differences are both in the offer (hotels and their rooms) and demand (customers’ profiles and needs) in the accommodation domain. As for the implementation, critical issues are in hardware-dependent and vendor-specific Internet of Things devices which are difficult to program. Additionally, there is complexity in realizing applications that consider varying customer needs and context via existing personalization options. This paper aims to propose an ontological framework to enhance the capabilities of hotels in offering their accommodation and personalization options based on a guest’s characteristics, activities and needs.
Design/methodology/approach
A research approach combining both quantitative and qualitative methods was used to develop a hotel room personalization framework. The core of the framework is a hotel room ontology (HoROnt) that supports well-defined machine-readable descriptions of hotel rooms and guest profiles. Hotel guest profiles are modeled via logical rules into an inference engine exploiting reasoning functionalities used to recommend hotel room services and features.
Findings
Both the ontology and the inference engine module have been validated with promising results which demonstrate high accuracy. The framework leverages user characteristics, and dynamic contextual data to satisfy guests’ needs for personalized service provision. The semantic rules provide recommendations to both new and returning guests, thereby also addressing the cold start issue.
Originality/value
This paper extends HoROnt in two ways, to be able to add: instances of the concepts (room characteristics and services; guest profiles), i.e. to create a knowledge base, and logical rules into an inference engine, to model guests’ profiles and to be used to offer personalized hotel rooms. Thanks to the standards adopted to implement personalization, this framework can be integrated into existing reservation systems. It can also be adapted for any type of accommodation since it is broad-based and personalizes varying features and amenities in the rooms.}
}
@article{ZHANG2025113302,
title = {Efficient unified information extraction model based on large language models},
journal = {Applied Soft Computing},
volume = {180},
pages = {113302},
year = {2025},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2025.113302},
url = {https://www.sciencedirect.com/science/article/pii/S1568494625006131},
author = {Xieyun Zhang and Shimin Cai and Xiaorong Shen and Han Yang and Wenhao Hu and Yanru Zhang},
keywords = {Large language model, Unified information extraction, Parameter efficient fine-tuning},
abstract = {Large Language Models (LLMs) have shown underperformance in information extraction (IE) tasks compared to smaller models. This underperformance is largely attributed to the mismatch between IE’s structured output and LLMs’ natural language output and the absence of IE tasks in the pre-training corpus. Furthermore, prior research aimed to adapt LLMs to IE tasks through instructional design without updating model parameters, or by fine-tuning them with substantial computational resources, at the expense of their original performance in other tasks. Inspired by the Parameter Efficient Fine-Tuning (PEFT) technique, we designed an efficient unified information framework for LLMs (LLM-UIE), which performs domain adaptation fine-tuning with low resource requirements. Importantly, LLM-UIE introduced an additional answer selection task to improve LLMs’ ability to generate desired answers, efficiently addressing the inconsistency between LLMs’ fuzzy outputs and standard answers. Experiments on extensive information extraction datasets show that LLM-UIE not only matches but even surpasses the F1 scores of state-of-the-art models while demonstrating significant advantages in training efficiency, substantially reducing training time. Moreover, compared to previous LLM-based studies, LLM-UIE significantly lowers computational resource requirements.}
}
@article{DICKINSON2023103003,
title = {Being-in-family and being-in-community: Ontological (in)securities, diaspora youth agencies, and the Rwandan emigration state},
journal = {Political Geography},
volume = {107},
pages = {103003},
year = {2023},
issn = {0962-6298},
doi = {https://doi.org/10.1016/j.polgeo.2023.103003},
url = {https://www.sciencedirect.com/science/article/pii/S0962629823001816},
author = {Jen Dickinson and Wayne Veck}
}
@article{SHARMA2023102110,
title = {Ontology-based semantic retrieval of documents using Word2vec model},
journal = {Data & Knowledge Engineering},
volume = {144},
pages = {102110},
year = {2023},
issn = {0169-023X},
doi = {https://doi.org/10.1016/j.datak.2022.102110},
url = {https://www.sciencedirect.com/science/article/pii/S0169023X2200101X},
author = {Anil Sharma and Suresh Kumar},
keywords = {Document retrieval, Keyword matching, Similarity value, Relevancy score, Word2vec model and query accuracy},
abstract = {Semantic retrieval of engineering knowledge is crucial in various engineering activities, such as process development and product model planning. To make a solution for this issue, previously, a few word-based semantic enabling existing approaches such as Lexical Retrieval Model with Semantic Residual Embedding’s (LR-SRE), Document Retrieval Model through Semantic Linking (DR-MTS), Semantic Term Matching in Axiomatic Approaches to Information Retrieval (STM-IR) and Hybrid Ontology for Semantic Information Retrieval Model using Keyword Matching Indexing System (HOS-IR) were utilized. But, they all have shown less query-based accuracy results than the required value. In our proposed Information Retrieval (IR) design, the semantic knowledge-based retrieval scheme has been implemented. For query, entered by a user and processed for finding the dominated word. Word is then compared for its similarity equations, and similarity values are then computed to give output. Highly similar values are obtained as the class value. From class, the respective clusters are selected. Then, documents in that cluster are retrieved and ranked according to the relevance of the user. To support the accuracy level performance of this IR system, a word2vec model has been employed with the benefits of Horse Herd Optimization (HHO), which helps to extract vectors as features for classification. These results are stored as a .csv file for further retrieval. By implementing the proposed IR-word2vec model, the results showed that it outperforms other existing techniques by improved similarity index and accuracy for query results in an execution time of 1.7 s.}
}
@article{LEE2023104961,
title = {Ontological inference process using AI-based object recognition for hazard awareness in construction sites},
journal = {Automation in Construction},
volume = {153},
pages = {104961},
year = {2023},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2023.104961},
url = {https://www.sciencedirect.com/science/article/pii/S0926580523002212},
author = {Seul-Ki Lee and Jung-Ho Yu},
keywords = {Hazard awareness, Object relationship, Ontology, AI image recognition technology},
abstract = {Research on automating risk situation recognition using AI is being actively conducted. However, hazard situation recognition using AI has a limitation in securing a large amount of data for training of all hazard situations. This study proposes an approach that combines the conventional AI image recognition technology and relation-based reasoning to overcome the limitations of the method of sufficiently training each image regarding various hazard situations. To validate the proposed process, we constructed ontology by defining the relations between construction site objects and working situations, safety situations required for each working situation, and hazard situations based on the case of the work using mobile scaffolding. This approach will enhance the efficiency of using AI by inferring the current working situation based on the relations between recognized objects and determining whether it is a safe situation based on the inference on the standard safety situation for the corresponding working situation.}
}
@article{TURCHET2022100687,
title = {The Smart Musical Instruments Ontology},
journal = {Journal of Web Semantics},
volume = {72},
pages = {100687},
year = {2022},
issn = {1570-8268},
doi = {https://doi.org/10.1016/j.websem.2021.100687},
url = {https://www.sciencedirect.com/science/article/pii/S1570826821000573},
author = {Luca Turchet and Paolo Bouquet and Andrea Molinari and György Fazekas},
keywords = {Smart Musical Instruments, Internet of Musical Things, Semantic audio},
abstract = {The Smart Musical Instruments (SMIs) are an emerging category of musical instruments that belongs to the wider class of Musical Things within the Internet of Musical Things paradigm. SMIs encompass sensors, actuators, embedded intelligence, and wireless connectivity to local networks and to the Internet. Interoperability represents a key issue within this domain, where heterogeneous SMIs are envisioned to exchange information between each other and a plethora of Musical Things. This paper proposes an ontology for the representation of the knowledge related to SMIs, with the aim of facilitating interoperability between SMIs as well as with other Musical Things interacting with them. There was no previous comprehensive data model for the SMIs domain, however the new ontology relates to existing ontologies, including the SOSA Ontology for the representation of sensors and actuators, the Audio Effects Ontology dealing with the description of digital audio effects, and the IoMusT Ontology for the representation Musical Things and IoMusT ecosystems. This paper documents the design of the ontology and its evaluation with respect to specific requirements gathered from an extensive literature review, which was based on scenarios involving SMIs stakeholders, such as performers and studio producers. The SMI Ontology can be accessed at: https://w3id.org/smi#.}
}
@article{LENTES20223010,
title = {Towards an Ontology for a Lightweight Support System for Production System Rough Planning},
journal = {IFAC-PapersOnLine},
volume = {55},
number = {10},
pages = {3010-3015},
year = {2022},
note = {10th IFAC Conference on Manufacturing Modelling, Management and Control MIM 2022},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2022.10.190},
url = {https://www.sciencedirect.com/science/article/pii/S2405896322022042},
author = {Joachim Lentes},
keywords = {Ontology-Based System, production system planning, support system, rough planning, assembly planning},
abstract = {To shorten times-to-markets, also the planners of production systems have to be supported appropriately. For this, open, adaptable systems are needed which support continuous flows of information, e.g. by leveraging standard data formats – and, which are easy to use for planners without specific knowledge about software development or ontology engineering. This paper introduces a support system for production system rough planning, especially for, but not limited to, assembly systems, which consists of two main components: a standard-based ontology as explicitly formulated external data model and a relatively universal software system working on the ontology. Thereby, focus of this contribution is mainly on the ontology, so on manufacturing modeling.}
}
@article{MEJHEDMKHININI2020100223,
title = {Combining UML and ontology: An exploratory survey},
journal = {Computer Science Review},
volume = {35},
pages = {100223},
year = {2020},
issn = {1574-0137},
doi = {https://doi.org/10.1016/j.cosrev.2019.100223},
url = {https://www.sciencedirect.com/science/article/pii/S1574013719300231},
author = {Meriem {Mejhed Mkhinini} and Ouassila Labbani-Narsis and Christophe Nicolle},
keywords = {Unified modeling language (UML), Ontology, Systematic literature review (SLR), Software engineering, Ontology engineering},
abstract = {UML models and ontologies are two knowledge representations with different strengths and weaknesses. Until recently, they were considered unrelated research domains. However, studies investigating their underlying paradigms and the approaches combining these two are increasingly emerging. Nevertheless, the state of the art research covering the relationship between the two is still under exploration. In this paper, we aim to provide a comprehensive overview of both domains by conducting a literature review of the relevant research work. In this survey, the relationship between UML and ontology is investigated from both the theoretical and practical perspectives. We present a detailed classification of the existing work based on the considered issues and their practical use cases. Finally, we provide an evaluation of the existing work according to the criteria we identified.}
}
@article{MYLOPOULOS2025102483,
title = {Conceptual modeling: Foundations, a historical perspective, and a vision for the future},
journal = {Data & Knowledge Engineering},
volume = {160},
pages = {102483},
year = {2025},
issn = {0169-023X},
doi = {https://doi.org/10.1016/j.datak.2025.102483},
url = {https://www.sciencedirect.com/science/article/pii/S0169023X25000783},
author = {John Mylopoulos and Giancarlo Guizzardi and Nicola Guarino},
keywords = {Conceptual models, Conceptual modeling, Knowledge representation, Ontologies, Philosophical foundations},
abstract = {We recount the foundations of Conceptual Modeling in Computer Science, Philosophy and Cognitive Science and their implications on what are concepts, conceptualizations, and conceptual models. We then review the history of the field, considering earlier work by the three co-authors, and highlight some of the contributions that made it what it is. Finally, we propose three research directions whose solutions could advance the field and will hopefully be addressed in the future. Our study is intended to help to circumscribe and characterize the field. It draws ideas from Philosophy, Cognitive Science, Engineering and the Social Sciences, as well as several areas within Computer Science, including Programming languages, Artificial Intelligence, Databases, Software Engineering, and Information Systems Engineering.}
}
@article{CICCONETO2022105005,
title = {GeoReservoir: An ontology for deep-marine depositional system geometry description},
journal = {Computers & Geosciences},
volume = {159},
pages = {105005},
year = {2022},
issn = {0098-3004},
doi = {https://doi.org/10.1016/j.cageo.2021.105005},
url = {https://www.sciencedirect.com/science/article/pii/S0098300421002880},
author = {Fernando Cicconeto and Lucas Valadares Vieira and Mara Abel and Renata dos Santos Alvarenga and Joel Luis Carbonera and Luan Fonseca Garcia},
keywords = {Ontology, Deep-marine depositional system, Turbidite, Artificial intelligence},
abstract = {An ontology is a logical theory that accounts for a domain vocabulary’s intended meaning, allowing us to develop a computational artifact that explicitly and formally represents the community’s conceptualization related to a vocabulary. This paper presents the GeoReservoir ontology — the result of the ontological analysis of the terminology adopted by geologists in sedimentological studies about deep-marine depositional systems, which is one of the most relevant types of oil and gas reservoirs around the world. Despite the variety of studies describing the patterns of productive reservoirs, this domain demanded new approaches in conceptual modeling methodologies because the available terminology presents issues such as ambiguity and contamination of different interpretations in the terms’ definitions. Previous work has dealt with these issues in geology, resulting in the GeoCore, an ontology that explicitly defines the most generic entities in geology. However, the domain in focus still demanded a specialized ontology containing the particular terms found in reports about deep-marine deposits. GeoReservoir is an extension of GeoCore, which, in its turn, extends the Basic Formal Ontology (BFO), a foundational ontology for scientific domains. GeoReservoir takes advantage of both BFO and GeoCore’s foundations, allowing us to focus our effort on defining the domain-specific entities. A team of professional reservoir geologists supported the knowledge acquisition process. We developed the ontology in iterative steps from an initial prototype to a complete artifact containing the taxonomy of entities and the relations between the entities, being increasingly refined by the experts. We further present a case study demonstrating how one could describe a depositional system in GeoReservoir terms. Moreover, we validated the ontology against defined competency questions (CQs). This work’s final result is offering a sound, consistent and unambiguous terminology to support the integration of data and knowledge about deep-marine depositional system geometry and lithology.}
}
@article{LIU2022104235,
title = {Ontology-based categorization of clinical studies by their conditions},
journal = {Journal of Biomedical Informatics},
volume = {135},
pages = {104235},
year = {2022},
issn = {1532-0464},
doi = {https://doi.org/10.1016/j.jbi.2022.104235},
url = {https://www.sciencedirect.com/science/article/pii/S1532046422002404},
author = {Hao Liu and Simona Carini and Zhehuan Chen and Spencer {Phillips Hey} and Ida Sim and Chunhua Weng},
keywords = {Ontology, Clinical Study, SNOMED CT, Data Visualization, Categorization},
abstract = {Objective
The free-text Condition data field in the ClinicalTrials.gov is not amenable to computational processes for retrieving, aggregating and visualizing clinical studies by condition categories. This paper contributes a method for automated ontology-based categorization of clinical studies by their conditions.
Materials and Methods
Our method first maps text entries in ClinicalTrials.gov’s Condition field to standard condition concepts in the OMOP Common Data Model by using SNOMED CT as a reference ontology and using Usagi for concept normalization, followed by hierarchical traversal of the SNOMED ontology for concept expansion, ontology-driven condition categorization, and visualization. We compared the accuracy of this method to that of the MeSH-based method.
Results
We reviewed the 4,506 studies on Vivli.org categorized by our method. Condition terms of 4,501 (99.89%) studies were successfully mapped to SNOMED CT concepts, and with a minimum concept mapping score threshold, 4,428 (98.27%) studies were categorized into 31 predefined categories. When validating with manual categorization results on a random sample of 300 studies, our method achieved an estimated categorization accuracy of 95.7%, while the MeSH-based method had an accuracy of 85.0%.
Conclusion
We showed that categorizing clinical studies using their Condition terms with referencing to SNOMED CT achieved a better accuracy and coverage than using MeSH terms. The proposed ontology-driven condition categorization was useful to create accurate clinical study categorization that enables clinical researchers to aggregate evidence from a large number of clinical studies.}
}
@article{ALKARMOUTY2025126111,
title = {Harnessing large language models for structured extraction of cytochrome P450–substance interactions from biomedical texts},
journal = {International Journal of Pharmaceutics},
volume = {684},
pages = {126111},
year = {2025},
issn = {0378-5173},
doi = {https://doi.org/10.1016/j.ijpharm.2025.126111},
url = {https://www.sciencedirect.com/science/article/pii/S0378517325009482},
author = {Mariam Alkarmouty and Junya Ooka and Fumiyoshi Yamashita},
keywords = {Text mining, Large language models, ChatGPT, Information extraction, Cytochrome P450},
abstract = {Building on our previous work in biomedical text mining, we revisit the extraction of cytochrome P450 (CYP) and substance interactions using recent advances in large language models (LLMs). We present a scalable, high-accuracy framework that leverages the ChatGPT O3-mini model, employing prompt engineering with structured output formatting, embedded definitions, and selected few-shot examples, combined with batch processing without relying on dictionaries or domain-specific ontologies. Our system achieves strong performance, with recall and precision of 0.963 and 0.987 across all CYP targets, and 0.923 and 0.993 for CYP3A4 specifically. This represents a substantial improvement over our earlier rule-based method. The resulting large-scale analysis not only reflects existing knowledge but also enables a more systematic and comprehensive integration of CYP isoform–substance interaction data, addressing the limitations of previous fragmented efforts. While previous studies have attempted to catalog these interactions, the scale, precision, and automation demonstrated here represent a significant step forward. These findings underscore the potential of LLM-driven pipelines to accelerate biomedical text mining and to support research in drug metabolism and related fields.}
}
@article{VIDANAGAMA2022117869,
title = {Ontology based sentiment analysis for fake review detection},
journal = {Expert Systems with Applications},
volume = {206},
pages = {117869},
year = {2022},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2022.117869},
url = {https://www.sciencedirect.com/science/article/pii/S095741742201123X},
author = {D.U. Vidanagama and A.T.P. Silva and A.S. Karunananda},
keywords = {Domain ontology, Rule-based classifier, Outliers, Feature-level sentiment analysis, Review-related features},
abstract = {Majority of customers and manufacturers who tend to purchase and trade via e-commerce websites primarily rely on reviews before making purchasing decisions and product improvements. Deceptive reviewers consider this opportunity to write fake reviews to mislead customers and manufacturers. This calls for the necessity of identifying fake reviews before making them available for decision making. Accordingly, this research focuses on a fake review detection method that incorporates review-related features including linguistic features, Part-of-Speech (POS) features, and sentiment analysis features. A domain feature ontology is used in the feature-level sentiment analysis and all the review-related features are extracted and integrated into the ontology. The fake review detection is enhanced through a rule-based classifier by inferencing the ontology. Due to the lack of a labeled dataset for model training, the Mahalanobis distance method was used to detect outliers from an unlabeled dataset where the outliers were selected as fake reviews for model training. The performance measures of the rule-based classifier were improved by integrating linguistic features, POS features, and sentiment analysis features, in spite of considering them separately.}
}
@article{ZHAI2022121912,
title = {Patent representation learning with a novel design of patent ontology: Case study on PEM patents},
journal = {Technological Forecasting and Social Change},
volume = {183},
pages = {121912},
year = {2022},
issn = {0040-1625},
doi = {https://doi.org/10.1016/j.techfore.2022.121912},
url = {https://www.sciencedirect.com/science/article/pii/S0040162522004346},
author = {Dongsheng Zhai and Liang Zhai and Mengyang Li and Xijun He and Shuo Xu and Feifei Wang},
keywords = {Patent representation, Technology composition, Technology association, Patent ontology, Heterogeneous graph embedding},
abstract = {Under the background of innovation-driven knowledge economy globalization, comprehensive and insightful patent technology information mining can help enterprises win the first-mover advantage in the increasingly fierce technology competition. However, existing machine learning-based methods do not entirely incorporate the characteristics of patent technology of technology composition and technology association at the micro-level and macro-level, making it difficult to mine detailed and comprehensive patent information. To fill this research gap, firstly, we conduct a comprehensive analysis from the micro-level technology composition perspective of patent documents and the macro-level technology association perspective of patent data involved in the technology field, and then we design a novel patent ontology that includes the entity of patent, function, solution and application field. Secondly, we create a patent heterogeneous network with the help of the proposed patent ontology and the technology association. Finally, to fully use the patent technology characteristics, we develop a heterogeneous graph embedding algorithm to embed this information into the patent representation, and the experiments done on non-perfluorinated proton exchange membrane patent data show that our method produces better patent representation than the comparable models. Furthermore, we utilize the patent representation to perform case study to confirm the method’s reliability and practicability.}
}
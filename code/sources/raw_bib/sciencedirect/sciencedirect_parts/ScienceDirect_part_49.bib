@article{SOVRANO2022101715,
title = {Combining shallow and deep learning approaches against data scarcity in legal domains},
journal = {Government Information Quarterly},
volume = {39},
number = {3},
pages = {101715},
year = {2022},
issn = {0740-624X},
doi = {https://doi.org/10.1016/j.giq.2022.101715},
url = {https://www.sciencedirect.com/science/article/pii/S0740624X2200048X},
author = {Francesco Sovrano and Monica Palmirani and Fabio Vitali},
keywords = {Data scarcity, Deep learning, TF-IDF, Syntagmatic relations, Law},
abstract = {We are recently witnessing a radical shift towards digitisation in many aspects of our daily life, including law, public administration and governance. This has sometimes been done with the aim of reducing costs and human errors by improving data analysis and management, but not without raising major technological challenges. One of these challenges is certainly the need to cope with relatively small amounts of data, without sacrificing performance. Indeed, cutting-edge approaches to (natural) language processing and understanding are often data-hungry, especially those based on deep learning. With this paper we seek to address the problem of data scarcity in automatic Legalese (or legal English) processing and understanding. What we propose is an ensemble of shallow and deep learning techniques called SyntagmTuner, designed to combine the accuracy of deep learning with the ability of shallow learning to work with little data. Our contribution is based on the assumption that Legalese differs from its spoken language in the way the meaning is encoded by the structure of the text and the co-occurrence of words. As result, we show with SyntagmTuner how we can perform important tasks for e-governance, as multi-label classification of the United Nations General Assembly (UNGA) Resolutions or legal question answering, with data-sets of roughly 100 samples or even less.}
}
@article{YOO2020112965,
title = {Automating the expansion of a knowledge graph},
journal = {Expert Systems with Applications},
volume = {141},
pages = {112965},
year = {2020},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2019.112965},
url = {https://www.sciencedirect.com/science/article/pii/S0957417419306839},
author = {SoYeop Yoo and OkRan Jeong},
keywords = {Auto expansion, Knowledge graph, Neologisms, Semantic analysis, Multilingual BERT model},
abstract = {In order to make computers understand human languages and to reason, human knowledge needs to be represented and stored in a form that can be processed by computers. Knowledge graphs have been developed for use as a form of the knowledge base for words and general relationships among words. However, they have two limitations. One is that the knowledge graph is limited in size and scope for most of the human languages. Another is that they are not able to deal with neologisms that form a part of the human common sense. Addressing these problems, we have developed and validated PolarisX which can automatically expand a knowledge graph, by crawling and analyzing the news sites and social media in real-time. We utilize and fine-tune the pre-trained multilingual BERT model for the construction of knowledge graphs without language dependencies. We extract new relationships using the BERT-based relation extraction model and integrate them into the knowledge graph. We verify the novelty and accuracy of PolarisX. It deals with neologisms and does not have language dependencies.}
}
@article{BUENAFE2024101124,
title = {Water words guiding water relations: Agta water epistemology informs water security practices},
journal = {Social Sciences & Humanities Open},
volume = {10},
pages = {101124},
year = {2024},
issn = {2590-2911},
doi = {https://doi.org/10.1016/j.ssaho.2024.101124},
url = {https://www.sciencedirect.com/science/article/pii/S2590291124003218},
author = {Mayo Buenafe and Elena Stuart and Wilma Telan},
keywords = {Water security, Indigenous epistemology, Indigenous languages, Hunter-gatherers and foraging societies, Philippines, Ethnographic studies},
abstract = {Indigenous peoples’ relationship with water challenges paradigms of resource scarcity, and extends beyond extraction and consumption. The Agta foragers of Isabela province in Northeastern Luzon, Philippines engage with water through their knowledge systems and practices, forming a distinct Indigenous epistemology of water which includes both material and non-material dimensions of water relations. This paper reports on an ethnographic investigation involving semi-structured interviews and water mapping activity to examine the material and non-material dimensions of water security among 25 members of Agta forager communities living in the towns of Dinapigue, Divilacan, and Maconacon. The paper focuses on descriptions of Agta water sources, mobility and settlement patterns related to water, intergenerational water knowledge, and “water guardians” to show the components of Agta epistemology of water that can be used to inform water security practices. The authors use a hydrosocial approach based on Indigenous water relations studies to analyze the complex connectivity of material and non-material dimensions of water security. Scholars often do not include Indigenous epistemologies in their analysis, thus this paper advances understanding of how to use such frameworks.}
}
@article{ZHENG202258,
title = {SRF-derived miR210 and miR30c both repress beating cardiomyocyte formation in the differentiation system of embryoid body},
journal = {Biochemical and Biophysical Research Communications},
volume = {626},
pages = {58-65},
year = {2022},
issn = {0006-291X},
doi = {https://doi.org/10.1016/j.bbrc.2022.08.016},
url = {https://www.sciencedirect.com/science/article/pii/S0006291X22011275},
author = {Guoxing Zheng and Zhuzhen He and Yingsi Lu and Qingqing Zhu and Yizhou Jiang and Demeng Chen and Shuibin Lin and Chengming Zhu and Robert Schwartz},
keywords = {Serum response factor, miR210, miR30c, Embryoid bodies, Beating cardiomyocyte},
abstract = {Serum response factor (SRF) cooperates with various co-factors to manage the specification of diverse cell lineages during heart development. Many microRNAs mediate the function of SRF in this process. However, how are miR210 and miR30c involved in the decision of cardiac cell fates remains to be explored. In this study, we found that SRF directly controlled the cardiac expression of miR210. Both miR210 and miR30c blocked the formation of beating cardiomyocyte during embryoid body (EB) differentiation, a cellular model widely used for studying cardiogenesis. Both of anticipated microRNA targets and differentially expressed genes in day8 EBs were systematically determined and enriched with gene ontology (GO), Kyoto encyclopedia of genes and genomes (KEGG) and Reactome. Functional enrichments of prediction microRNA targets and down-regulated genes in day8 EBs of miR210 suggested the importance of PI3K-Akt signal and ETS2 in miR210 inhibition of cardiomyocyte differentiation. Similar analyses revealed that miR30c repressed both developmental progress and the adrenergic signaling in cardiomyocytes during the differentiation of EBs. Taken together, SRF directs the expression of miR210 and miR30c, and they repress cardiac development via inhibiting the differentiation of cardiac muscle cell lineage as well as the cell proliferation. Through the regulation of specific microRNAs, the complication of SRF's function in heart development is emphasized.}
}
@article{ELMIDAOUI20211,
title = {Geographical query reformulation using a geographical adjacency taxonomy builder and word senses},
journal = {Journal of Systems and Information Technology},
volume = {23},
number = {1},
pages = {1-19},
year = {2021},
issn = {1328-7265},
doi = {https://doi.org/10.1108/JSIT-02-2018-0022},
url = {https://www.sciencedirect.com/science/article/pii/S1328726521000100},
author = {Omar {El Midaoui} and Btihal {El Ghali} and Abderrahim {El Qadi} and Moulay Driss Rahmani},
keywords = {Latent semantic analysis, Geographical query reformulation, Information search and retrieval, Spatial entity, The WordNet ontology, Thematic entity},
abstract = {Purpose
Geographical query formulation is one of the key difficulties for users in search engines. The purpose of this study is to improve geographical search by proposing a novel geographical query reformulation (GQR) technique using a geographical taxonomy and word senses.
Design/methodology/approach
This work introduces an approach for GQR, which combines a method of query components separation that uses GeoNames, a technique for reformulating these components using WordNet and a geographic taxonomy constructed using the latent semantic analysis method.
Findings
The proposed approach was compared to two methods from the literature, using the mean average precision (MAP) and the precision at 20 documents (P@20). The experimental results show that it outperforms the other techniques by 15.73% to 31.21% in terms of P@20 and by 17.81% to 35.52% in terms of MAP.
Research limitations/implications
According to the experimental results, the best created taxonomy using the geographical adjacency taxonomy builder contains 7.67% of incorrect links. This paper believes that using a very big amount of data for taxonomy building can give better results. Thus, in future work, this paper intends to apply the approach in a big data context.
Originality/value
Despite this, the reformulation of geographical queries using the new proposed approach considerably improves the precision of queries and retrieves relevant documents that were not retrieved using the original queries. The strengths of the technique lie in the facts of reformulating both thematic and spatial entities and replacing the spatial entity of the query with terms that explain the intent of the query more precisely using a geographical taxonomy.}
}
@article{WANG2025149598,
title = {Genome-wide association study and candidate gene identification for fall armyworm resistance in maize (Zea mays L.)},
journal = {Gene},
volume = {963},
pages = {149598},
year = {2025},
issn = {0378-1119},
doi = {https://doi.org/10.1016/j.gene.2025.149598},
url = {https://www.sciencedirect.com/science/article/pii/S0378111925003877},
author = {Tonghan Wang and Changjin Wang and Minghui Guan and Yaohui Zheng and Lu Sun and Haibing Yu and Lei Chen and Yongfu Wang and Degong Wu and Junli Du},
keywords = {Candidate gene, Fall Armyworm, GWAS, Maize},
abstract = {As a globally vital crop for human consumption, livestock feed, and industrial applications, maize (Zea mays L.) faces severe threats from the invasive pest fall armyworm (FAW), Spodoptera frugiperda. Exploring endogenous resistance genes represents a sustainable approach for FAW management. This study employed the Maize6H-60 K SNP array to characterize genetic diversity and population structure in 212 key inbred lines derived from southeastern Chinese breeding programs. Integrated with field-based resistance phenotyping data from 2023 and 2024, genome-wide association studies (GWAS) identified 21 SNP loci significantly associated with FAW resistance, distributed across chromosomes 1, 2, 3, 5, 6, and 7. Subsequent analyses pinpointed 25 candidate genes within these genomic regions. Gene Ontology (GO) annotation, promoter cis-acting element analysis, and transcriptomic profiling revealed that these genes are functionally enriched in signal transduction, cellular defense responses, and transcriptional regulation. Notably, their promoter regions harbored multiple hormone-responsive (e.g., jasmonic acid and salicylic acid) and stress-inducible cis-elements. Investigation of publicly available transcriptome datasets with qRT-PCR validation demonstrated that six candidate genes exhibited significant expression changes under FAW infestation, suggesting their pivotal roles in maize antiherbivore defense mechanisms. This study not only provides an important molecular basis for the genetic improvement of maize resistance to the fall armyworm but also offers new perspectives for further research on plant − insect interaction mechanisms. In addition, the study’s outcomes offer a solid theoretical foundation for devising maize insect − resistance breeding strategies.}
}
@article{SIVACI2023101221,
title = {The effect of critical thinking dispositions and democratic values of pre-service EFL teachers on their multicultural self-efficacy: A structural equation modeling approach},
journal = {Thinking Skills and Creativity},
volume = {47},
pages = {101221},
year = {2023},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2022.101221},
url = {https://www.sciencedirect.com/science/article/pii/S187118712200222X},
author = {Seda SIVACI and Betül ALTAŞ},
keywords = {Critical thinking dispositions, Democratic values, Multicultural self-efficacy, EFL teachers, Teacher education},
abstract = {The present research aims to investigate the effect of English as a foreign language (EFL) teachers’ critical thinking dispositions and democratic values on their multicultural self-efficacy. Data were collected with 275 pre-service EFL teachers at different universities in several cities of Turkey. Participants’ selection was based on convenience sampling and participants voluntarily took part in the study. Three types of data collection instruments were used: a critical thinking dispositions scale, teacher democratic values scale and a multicultural self-efficacy scale. In this study, the correlational survey method was used, and a model was designed to determine the effect of critical thinking dispositions and democratic values of pre-service EFL teachers on their multicultural self-efficacy. The model was tested by AMOS. The fit indices were at the acceptable level and it was determined that the model explains approximately 57% of multicultural self-efficacy. In order to analyze the data, Structural equation modeling (SEM) was performed. The findings revealed that both critical thinking dispositions and democratic values are the significant predictors of multicultural self-efficacy and they affect pre-service EFL teachers’ multicultural self-efficacy in a positive way.}
}
@article{WANG2018220,
title = {Considering social information in constructing research topic maps},
journal = {The Electronic Library},
volume = {36},
number = {2},
pages = {220-236},
year = {2018},
issn = {0264-0473},
doi = {https://doi.org/10.1108/EL-10-2016-0230},
url = {https://www.sciencedirect.com/science/article/pii/S0264047318000450},
author = {Hei Chia Wang and Yu Hung Chiang and Yen Tzu Huang},
keywords = {Text mining, Social information, Open directory projects, Topic maps},
abstract = {Purpose
In academic work, it is important to identify a specific domain of research. Many researchers may look to conference issues to determine interesting or new topics. Furthermore, conference issues can help researchers identify current research trends in their field and learn about cutting-edge developments in their area of specialization. However, so much conference information is published online that it can be difficult to navigate and analyze in a meaningful or productive way. Hence, the use of knowledge management (KM) could be a way to resolve these issues. In KM, ontology is widely adopted, but most ontology construction methods do not consider social information between target users. Therefore, this study aims to propose a novel method of constructing research topic maps using an open directory project (ODP) and social information.
Design/methodology/approach
The approach is to incorporate conference information (i.e. title, keywords and abstract) as sources and to consider the ways in which social information automatically produces research topic maps. The methodology can be divided into four modules: data collection, element extraction, social information analysis and visualization. The data collection module collects the required conference data from the internet and performs pre-processing. Then, the element extraction module extracts topics, associations and other basic elements of topic maps while considering social information. Finally, the results will be shown in the visualization module for researchers to browse and search.
Findings
The results of this study propose three main findings. First, creating topic maps with the ODP category information can help capture a richer set of classification associations. Second, social information should be considered when constructing topic maps. This study includes the relationship among different authors and topics to support information in social networks. By considering social information, such as co-authorship/collaborator, this method helps researchers find research topics that are unfamiliar but interesting or potential cooperative opportunities in the future. Third, this study presents topic maps that show a clear and simple pathway in interested domain knowledge.
Research limitations implications
First, this study analyzes and collects conference information, including the titles, keywords and abstracts of conference papers, so the data set must include all of the abovementioned information. Second, social information only analyzes co-authorship associations (collabship associations); other social information could be extracted in the future study. Third, this study only analyzes the associations between topics. The intensity of associations is not discussed in the study.
Originality/value
The study will have a great impact on learned societies because it bridges the gap between theory and practice. The study is useful for researchers who want to know which conferences are related to their research. Moreover, social networks can help researchers expand and diversify their research.}
}
@article{COSTA2024102370,
title = {VarClaMM: A reference meta-model to understand DNA variant classification},
journal = {Data & Knowledge Engineering},
volume = {154},
pages = {102370},
year = {2024},
issn = {0169-023X},
doi = {https://doi.org/10.1016/j.datak.2024.102370},
url = {https://www.sciencedirect.com/science/article/pii/S0169023X24000946},
author = {Mireia Costa and Alberto {García S.} and Ana León and Anna Bernasconi and Oscar Pastor},
keywords = {Conceptual modeling, Genomics, Variant classification},
abstract = {Determining the significance of a DNA variant in patients’ health status – a complex process known as variant classification – is highly critical for precision medicine applications. However, there is still debate on how to combine and weigh diverse available evidence to achieve proper and consistent conclusions. Indeed, currently, there are more than 200 different variant classification guidelines available to the scientific community, aiming to establish a framework for standardizing the classification process. Yet, these guidelines are qualitative and vague by nature, hindering their practical application and potential automation. Consequently, more precise definitions are needed. In this work, we discuss our efforts to create VarClaMM, a UML meta-model that aims to provide a clear specification of the key concepts involved in variant classification, serving as a common framework for the process. Through this accurate characterization of the domain, we were able to find contradictions or inconsistencies that might have an effect on the classification results. VarClaMM’s conceptualization efforts will lay the ground for the operationalization of variant classification, enabling any potential automation to be based on precise definitions.}
}
@article{GRAVES2024100051,
title = {Modeling morality and spirituality in artificial chaplains},
journal = {Computers in Human Behavior: Artificial Humans},
volume = {2},
number = {1},
pages = {100051},
year = {2024},
issn = {2949-8821},
doi = {https://doi.org/10.1016/j.chbah.2024.100051},
url = {https://www.sciencedirect.com/science/article/pii/S2949882124000112},
author = {Mark Graves}
}
@article{SANTOSA2024112437,
title = {S3PaR: Section-based Sequential Scientific Paper Recommendation for paper writing assistance},
journal = {Knowledge-Based Systems},
volume = {303},
pages = {112437},
year = {2024},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2024.112437},
url = {https://www.sciencedirect.com/science/article/pii/S0950705124010712},
author = {Natasha Christabelle Santosa and Xin Liu and Hyoil Han and Jun Miyazaki},
keywords = {Recommender systems, Sequential recommendation, Dynamic user interest, Scientific paper recommendation, Graph neural networks, Attention mechanisms},
abstract = {A scientific paper recommender system (RS) is very helpful for literature searching in that it (1) helps novice researchers explore their own field and (2) helps experienced researchers explore new fields outside their area of expertise. However, existing RSs usually recommend relevant papers based on users’ static interests, i.e., papers they cited in their past publication(s) or reading histories. In this paper, we propose a novel recommendation task based on users’ dynamic interests during their paper-writing activity. This dynamism is revealed in (for example) the topic shift while writing the Introduction vs. Related Works section. In solving this task, we developed a new pipeline called “Section-based Sequential Scientific Paper Recommendation (S3PaR)”, which recommends papers based on the context of the given user’s currently written paper section. Our experiments demonstrate that this unique task and our proposed pipeline outperform existing standard RS baselines.}
}
@article{CECH2019206,
title = {Matching UML class models using graph edit distance},
journal = {Expert Systems with Applications},
volume = {130},
pages = {206-224},
year = {2019},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2019.04.008},
url = {https://www.sciencedirect.com/science/article/pii/S0957417419302362},
author = {Pavel Čech},
keywords = {UML class model matching, Graph edit distance, Design pattern detection},
abstract = {The Unified Modelling Language (UML) class model is an essential constituent in the software system development process and a considerable body of knowledge is encompassed in the form of class model designs. A UML class model forms an elaborate specification hierarchy and comparing different class models in order to identify corresponding parts assumes considerable human expertise. To imitate such human capacity an exponentially complex task needs to be addressed. Yet, the research that involves UML class model matching focuses primarily only on a design pattern detection and studies that tackle the problem of matching any class models are rather rare. The aim of this study is to introduce a class model distance computation framework that can be utilised for comparing class models in model repositories. The framework exploits the relational structure between model elements as well as internal element features to devise a distance measure between any pair of class models. The relational structures of two class models in the form of graphs are aligned using the graph edit distance technique. The internal element feature distance computation deploys the Hungarian algorithm for optimal assignment of any two-feature sets. The distance computation framework reduces the comparison task to polynomial time complexity. The study presents experimental performance analysis of the proposed framework conducted using the precision-recall and receiver operating characteristics curves and corresponding areas under the curves. The results of the analysis indicate low false positive rates for both pairwise and pattern detection tasks.}
}
@article{QU2023e12708,
title = {Characterization of diverse populations of sinoatrial node cells and their proliferation potential at single nucleus resolution},
journal = {Heliyon},
volume = {9},
number = {1},
pages = {e12708},
year = {2023},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2022.e12708},
url = {https://www.sciencedirect.com/science/article/pii/S2405844022039962},
author = {Jia-Hua Qu and Richard Telljohann and Rostislav Byshkov and Edward G. Lakatta},
keywords = {Sinoatrial node, Single nucleus RNA-seq, Pacemaker, Proliferation, Metabolism, Immune},
abstract = {Background
Each heartbeat is initiated in the sinoatrial node (SAN), and although a recent study (GSE130710) using single nucleus RNA-seq had discovered different populations of cell types within SAN tissue, the distinct potential functions of these cell types have not been delineated.
Methods
To infer some special potential functions of different SAN cell clusters, we applied principal component analysis (PCA), t-distributed stochastic neighbor embedding (t-SNE) and uniform manifold approximation and projection (UMAP) to the GSE130710 dataset to reduce dimensions, followed by Pseudotime trajectory and AUCell analyses, ANOVA and Hurdle statistical models, and Gene Ontology (GO) and Kyoto Encyclopedia of Genes and Genomes (KEGG) enrichments to determine functional potential of cell types. Nuclear EdU immuno-labeling of SAN tissue confirmed cell type proliferation.
Findings
We identified elements of a coupled clock system known to drive SAN cell pacemaking within the GSE130710 sinus node myocyte cluster, which, surprisingly, manifested signals of suppressed fatty acid and nitrogen metabolism and reduced immune gene expression. Proliferation signaling was enriched in endocardial, epicardial, epithelial cells, and macrophages, in which, fatty acid and nitrogen metabolic signals were also suppressed, but immune signaling was enhanced. EdU labeling was rare in pacemaker cells but was robust in interstitial cells.
Interpretation
Pacemaker cells that initiate each heartbeat manifest suppressed fatty acid and nitrogen metabolism and limited immune signaling and proliferation potential. In contrast, other populations of SAN cells not directly involved in the initiation of heartbeats, manifest robust proliferation and immune potential, likely to ensure an environment required to sustain healthy SAN tissue pacemaker function.}
}
@incollection{GHANDIKOTA2024171,
title = {Chapter Seven - Application of artificial intelligence and machine learning in drug repurposing},
editor = {Vijai Singh},
series = {Progress in Molecular Biology and Translational Science},
publisher = {Academic Press},
volume = {205},
pages = {171-211},
year = {2024},
booktitle = {New Approach for Drug Repurposing Part A},
issn = {1877-1173},
doi = {https://doi.org/10.1016/bs.pmbts.2024.03.030},
url = {https://www.sciencedirect.com/science/article/pii/S1877117324000851},
author = {Sudhir K. Ghandikota and Anil G. Jegga},
keywords = {Drug repurposing, Drug repositioning, Artificial Intelligence, De novo drug discovery, Machine Learning, Deep Learning, Network analysis},
abstract = {The purpose of drug repurposing is to leverage previously approved drugs for a particular disease indication and apply them to another disease. It can be seen as a faster and more cost-effective approach to drug discovery and a powerful tool for achieving precision medicine. In addition, drug repurposing can be used to identify therapeutic candidates for rare diseases and phenotypic conditions with limited information on disease biology. Machine learning and artificial intelligence (AI) methodologies have enabled the construction of effective, data-driven repurposing pipelines by integrating and analyzing large-scale biomedical data. Recent technological advances, especially in heterogeneous network mining and natural language processing, have opened up exciting new opportunities and analytical strategies for drug repurposing. In this review, we first introduce the challenges in repurposing approaches and highlight some success stories, including those during the COVID-19 pandemic. Next, we review some existing computational frameworks in the literature, organized on the basis of the type of biomedical input data analyzed and the computational algorithms involved. In conclusion, we outline some exciting new directions that drug repurposing research may take, as pioneered by the generative AI revolution.}
}
@article{ZHIOUA2024e148,
title = {NEW APPROACH OF ARTIFICIAL INTELLIGENCE FOR FERTILITY TREATMENT KNOWLEDGE ACCESS AND DECISION-MAKING},
journal = {Fertility and Sterility},
volume = {122},
number = {4, Supplement },
pages = {e148-e149},
year = {2024},
note = {80th Scientific Congress of the American Society for Reproductive Medicine},
issn = {0015-0282},
doi = {https://doi.org/10.1016/j.fertnstert.2024.07.537},
url = {https://www.sciencedirect.com/science/article/pii/S0015028224011543},
author = {Kais Zhioua and Marouen Braham}
}
@article{SCHATZKI2025100553,
title = {Agency},
journal = {Information and Organization},
volume = {35},
number = {1},
pages = {100553},
year = {2025},
issn = {1471-7727},
doi = {https://doi.org/10.1016/j.infoandorg.2024.100553},
url = {https://www.sciencedirect.com/science/article/pii/S1471772724000538},
author = {Theodore R. Schatzki},
keywords = {Agency, Acting, Doing, Distributed agency, Agencements, Practices},
abstract = {This essay urges researchers to respect differences among the agencies of different kinds of entities as well as among types of “distributed agency” understood as the agentic character of combinations of entities and events. In opposition, moreover, to the strong approach to sociomateriality in IS, the essay holds that most nexuses to which human people are integral aggregate the different agencies of the entities and events that compose them. The essay develops these theses by carefully sorting out different conceptions of agency and by both disambiguating and exploring four prominent claims contained in the idea that agency is tied to combinations of entities and events. Sorting out different conceptions of agency also shows that agency is causality, that is, particular forms of causality. The overall result is a defense of the integrity of the concept of agency as a reflection of the noun-verb structure of human languages.}
}
@article{AHMADIKARVIGH2018146,
title = {Real-time activity recognition for energy efficiency in buildings},
journal = {Applied Energy},
volume = {211},
pages = {146-160},
year = {2018},
issn = {0306-2619},
doi = {https://doi.org/10.1016/j.apenergy.2017.11.055},
url = {https://www.sciencedirect.com/science/article/pii/S0306261917316409},
author = {Simin Ahmadi-Karvigh and Ali Ghahramani and Burcin Becerik-Gerber and Lucio Soibelman},
keywords = {Building energy efficiency, Building automation, Activity recognition, Appliance control, Waste detection},
abstract = {More than half of the electricity in residential and commercial buildings is consumed by lighting systems and appliances. Consumption by these service systems is directly associated with occupant activities. By recognizing activities and identifying the associated possible energy savings, more effective strategies can be developed to design better buildings and automation systems. In line with this motivation, using inductive and deductive reasoning, we introduce a framework to detect occupant activities and potential wasted energy consumption and peak-hour usage that could be shifted to non-peak hours in real-time. Our framework consists of three sub-algorithms for action detection, activity recognition and waste estimation. As the real-time input, the action detection algorithm receives the data from the sensing system, consisting of plug meters and sensors, to detect the occurred actions (e.g., turning on an appliance) via our unsupervised clustering models. Detected actions are then used by the activity recognition algorithm to recognize the activities (e.g., preparing food) through semantic reasoning on our constructed ontology. Based on the recognized activities, the waste estimation algorithm identifies the potential waste and estimates the potential savings. To evaluate the performance of our framework, an experimental study was carried out in an office with five occupants and in two single-occupancy apartments for two weeks. Following the experiment, the performance of the action detection and activity recognition algorithms was evaluated using the ground truth labels for actions and activities. Average accuracy was 97.6% for action detection using Gaussian Mixture Model with Principal Components Analysis and 96.7% for activity recognition. In addition, 35.5% of the consumption of an appliance or lighting system in average was identified as potential savings.}
}
@article{MANTE20212276,
title = {Synthetic Biology Knowledge System},
journal = {ACS Synthetic Biology},
volume = {10},
number = {9},
pages = {2276-2285},
year = {2021},
issn = {2161-5063},
doi = {https://doi.org/10.1021/acssynbio.1c00188},
url = {https://www.sciencedirect.com/science/article/pii/S2161506321000735},
author = {Jeanet Mante and Yikai Hao and Jacob Jett and Udayan Joshi and Kevin Keating and Xiang Lu and Gaurav Nakum and Nicholas E. Rodriguez and Jiawei Tang and Logan Terry and Xuanyu Wu and Eric Yu and J. Stephen Downie and Bridget T. McInnes and Mai H. Nguyen and Brandon Sepulvado and Eric M. Young and Chris J. Myers},
keywords = {text mining, topic modeling, data mining, sequence annotation, SynBioHub, SBOL},
abstract = {The Synthetic Biology Knowledge System (SBKS) is an instance of the SynBioHub repository that includes text and data information that has been mined from papers published in ACS Synthetic Biology. This paper describes the SBKS curation framework that is being developed to construct the knowledge stored in this repository. The text mining pipeline performs automatic annotation of the articles using natural language processing techniques to identify salient content such as key terms, relationships between terms, and main topics. The data mining pipeline performs automatic annotation of the sequences extracted from the supplemental documents with the genetic parts used in them. Together these two pipelines link genetic parts to papers describing the context in which they are used. Ultimately, SBKS will reduce the time necessary for synthetic biologists to find the information necessary to complete their designs.
}
}
@article{VODYAHO2025107823,
title = {Run time dynamic digital twins and dynamic digital twins networks},
journal = {Future Generation Computer Systems},
volume = {172},
pages = {107823},
year = {2025},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2025.107823},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X25001189},
author = {Alexander Vodyaho and Radhakrishnan Delhibabu and Dmitry I. Ignatov and Nataly Zhukova},
keywords = {Digital twin, Digital twin networks, Dynamic digital threads, Model synthesis},
abstract = {Digital twins are widely used for building various types of cyber–physical systems. There are a huge number of publications devoted to the use of digital twins in production systems. Much less attention is paid to the issues of building runtime digital twins. The article describes an approach to building complex distributed cyber–physical systems with a high level of architectural dynamics built on fog and edge computing platforms based on the use of digital twins. The issues of implementing runtime digital twins and distributed systems of runtime digital twins are considered. The requirements to runtime digital twins are defined. Typical problem statements for constructing and maintaining a runtime digital twin system are formulated. A reference architecture of a dynamic runtime digital twin is proposed, which includes a model of the observed system (or the object) and a model processor. The dynamic model of the observed and managed system is considered as a key element of the digital twin. Possible approaches to the synthesis of built-in models of runtime digital twins are discussed. Examples of using the proposed approach to solve practical problems are given. The described approach may be of interest to specialists involved in research and development of various types of information systems implemented on Internet of Things platforms, such as smart cities, smart transport, medical information systems, etc. It is proposed to conduct further research and development in the areas of creating human digital twins.}
}
@article{MARINO2025,
title = {Enhancing Interoperability for a Sustainable, Patient-Centric Health Care Value Chain: Systematic Review for Taxonomy Development},
journal = {Journal of Medical Internet Research},
volume = {27},
year = {2025},
issn = {1438-8871},
doi = {https://doi.org/10.2196/69465},
url = {https://www.sciencedirect.com/science/article/pii/S1438887125005965},
author = {Carlos Antonio Marino and Claudia {Diaz Paz}},
keywords = {interoperability, health care, electronic health record (EHR), Fast Healthcare Interoperability Resources (FHIR), value chain},
abstract = {Background
Creating a sustainable, patient-centered health care system necessitates integrated supply chains supported by information technologies. However, achieving interoperability among various devices and systems remains a significant hurdle. Our research highlights the need for systematic reviews that address health care interoperability as a holistic knowledge domain. Notably, we observed a lack of studies that outline its structure or develop a comprehensive, high-order facet-based taxonomy from the perspective of supply or value chains. This study aims to address that gap.
Objective
The primary aim of this study is to elucidate the knowledge structure within the extensive domain of health care interoperability, with an emphasis on trending topics, critical hot spots, and the categorization of significant issues. Furthermore, we aim to model the higher-order elements of a taxonomy for health care interoperability within the context of the health care value chain framework.
Methods
We used both quantitative and qualitative methodologies. The PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) framework guided our selection process. We examined 6 databases—Scopus, Web of Science, IEEE Xplore, Embase, Cochrane, and PubMed—focusing on journal articles and gray literature published from 2011 onward. Articles were screened using predefined eligibility criteria. Quantitative bibliometric techniques—including cluster, factor, and network analyses—were applied to explore the structure of the knowledge. A subset of articles was selected for qualitative synthesis using an iterative coding process to develop a higher-order facet-based taxonomy.
Results
We identified 370 articles for quantitative analysis. The bibliometric analysis revealed 2 major clusters. Key terms in the first cluster included interoperability, electronic health record, and eHealth—with betweenness centralities of 70.971, 59.460, and 12.000, respectively, and closeness centralities of 0.047, 0.043, and 0.034, respectively. In the second cluster, the most relevant terms were IoT, blockchain, and health care—with betweenness centralities of 6.765, 2.581, and 1.283, respectively, and closeness centralities of 0.034, 0.030, and 0.030, respectively. Factor analysis explained 59.46% of the variance in a 2-factor model, with the first dimension accounting for 36.78% and the second dimension for 22.68%. The qualitative review of 79 articles yielded a taxonomy with 4 higher-order facets: object (what is shared), source (what mechanism is used), ambit (space covered), and content (technology primarily involved). Each facet extended to a third level of classification.
Conclusions
The comprehensive domain of health care interoperability, viewed through the lens of a sustainable value chain, encompasses studies that highlight various facets or attributes. These studies underscore the relevance of eHealth within this knowledge domain and reflect a strong focus on 2 key health information technologies: electronic health records and the Internet of Things.}
}
@incollection{PETILLI2025,
title = {Image-Based Word Frequency Norms},
booktitle = {Reference Module in Social Sciences},
publisher = {Elsevier},
year = {2025},
isbn = {978-0-443-15785-1},
doi = {https://doi.org/10.1016/B978-0-323-95504-1.00859-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780323955041008590},
author = {Marco A. Petilli and Fritz Günther},
keywords = {Image annotation, Image datasets, Image-based norms, Image-based word frequency, Language experience, Visual experience, Word frequency effect},
abstract = {Traditional word frequency norms are derived from text corpora. This article discusses word frequency derived from domain-specific visual corpora, where words are used to denote or label content in real-world scene images from large-scale datasets. These image-based frequency estimates capture aspects of language usage missing from traditional frequency measures, reflecting their nature at the intersection between language and vision. The article reviews the main approaches for creating these metrics (as well as measures derived from them), discusses studies validating their role as hybrid measures, and highlights their utility in complementing traditional word frequency norms to better address theoretical questions empirically.}
}
@article{LEI2022146233,
title = {Different gene co-expression patterns of aortic intima-media and adventitia in thoracic aortic aneurysm},
journal = {Gene},
volume = {819},
pages = {146233},
year = {2022},
issn = {0378-1119},
doi = {https://doi.org/10.1016/j.gene.2022.146233},
url = {https://www.sciencedirect.com/science/article/pii/S037811192200052X},
author = {Chuxiang Lei and Haoxuan Kan and Wenlin Chen and Dan Yang and Jinrui Ren and Fang Xu and Hui Zhang and Wei Wang and Yuehong Zheng},
keywords = {Thoracic aortic aneurysm, Weighted gene co-expression network analysis, Chemotaxis, Inflammation, Immune infiltration},
abstract = {Background
Due to permanent aortic dilation, thoracic aortic aneurysm (TAA) is a life-threatening disease. Once ruptured, TAA has a high lethality and disability rate. Although studies have focused on transcriptomic alterations in TAA, more detailed analysis is still lacking, especially the different aortic intima-media and adventitia roles. This study aimed to identify the different co-expression patterns between the aortic intima-media and the adventitia underlying the aortic dilation.
Methods
We analyzed the gene expression profiles obtained from Gene Expression Omnibus (GEO, GSE26155) database. With a false discovery rate (FDR) < 0.05 and |log2FC| ≥ 1, 56 and 33 differential genes in the intima-media and adventitia, respectively, between the non-dilated and dilated status. Gene ontology (GO) and gene set enrichment analysis revealed that degranulation and activation of neutrophils play an essential role in the intima-media of dilated aortas. Through weighted gene co-expression network analysis (WGCNA), we identified essential co-expressed modules and hub genes to explore the biological functions of the dysregulated genes.
Results
Functional pathway analysis suggested that lipid metabolism, C-C motif chemokine pathways were significantly enriched in the adventitia, whereas ribosome proteins and related mRNA translation pathways were closely related to intima and media. Furthermore, the ssGSEA analysis indicated that macrophages, helper T cells, and neutrophils were higher in the intima-media of the dilated thoracic aorta. Finally, we validated the critical findings of the study with the murine model of TAA.
Conclusion
This study identified and verified hub genes and pathways in aortic intima-media and adventitia prominently associated with aortic dilation, providing practical understanding in the perspective of searching for new molecular targets.}
}
@article{KLEINALTENKAMP2025166,
title = {The emergence, stabilization, and destabilization of resources: Gated reverb and the sound of the 80s},
journal = {Industrial Marketing Management},
volume = {129},
pages = {166-181},
year = {2025},
issn = {0019-8501},
doi = {https://doi.org/10.1016/j.indmarman.2025.07.009},
url = {https://www.sciencedirect.com/science/article/pii/S0019850125001099},
author = {Michael Kleinaltenkamp and Moritz J. Kleinaltenkamp and Kieran D. Tierney},
keywords = {Music production, Resources, Resource emergence, Process research},
abstract = {B2B marketing scholarship has begun to question the traditional perspective of resources as stable entities that are ‘out there’ for firms to be acquired, transformed, or leveraged to create value. It has instead begun to adopt a more processual perspective emphasizing resources as situational phenomena that come into existence through their use and may also fade away again. While such a process-relational perspective holds great promise to advance B2B resource thinking, it is still nascent, being marked by lingering conceptual inconsistencies and a relative lack of empirical research. Against this backdrop, our study explores the process of resource emergence, stabilization and destabilization, by drawing on the revelatory case study of the “gated reverb drum sound”, popularly known as “the sound of the 80s”. Using archival and primary data, we develop a process model that shows how resources emerge, gain traction and decline over time by moving through four phases: discovering, prototyping, commodifying, and overusing. We illuminate the material-discursive practices making up these phases, and the resource characteristics they enact at different points in time. Our findings provide a new way of thinking about the lifecycle of resources, and the involvement of humans and non-humans in this process, with significant implications for theory and practice.}
}
@article{MA2025103659,
title = {A multi-view contrastive embedding framework for filtering fuzzy requirements of complex products},
journal = {Advanced Engineering Informatics},
volume = {68},
pages = {103659},
year = {2025},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2025.103659},
url = {https://www.sciencedirect.com/science/article/pii/S147403462500552X},
author = {Yufeng Ma and Xiang Zhao and Yajie Dou and Anastasia Dimou and Xuemin Duan and Yuejin Tan},
keywords = {Fuzzy requirements, Knowledge graph embedding, Contrastive learning, Multi-view representation},
abstract = {In complex product development, requirement teams must filter large volumes of user input to identify valid and representative requirements. Compared to professional users, broad user requirements come from diverse sources such as feedback, surveys, and social media, but are often subjective, unstructured, and fuzzy—posing challenges for effective filtering. Existing methods typically overlook this fuzziness. To address this, we propose a multi-view contrastive embedding framework for filtering fuzzy requirements. Requirement triples are modeled as nodes in a knowledge graph and extended into multiple hyper-views for fuzziness-aware representation learning. We integrate knowledge graph embedding with a contrastive learning mechanism. By leveraging multi-view modeling and a fuzziness-aware scoring function, the proposed framework effectively captures and models the degree of fuzziness in user requirements, thereby enabling robust filtering of ambiguous requirements. Experiments on real-world datasets show that our method outperforms existing approaches in filtering and ranking tasks, offering a robust solution for large-scale fuzzy requirement analysis.}
}
@article{MENG2023541,
title = {Solving Arithmetic Word Problems of Entailing Deep Implicit Relations by Qualia Syntax-Semantic Model},
journal = {Computers, Materials and Continua},
volume = {77},
number = {1},
pages = {541-555},
year = {2023},
issn = {1546-2218},
doi = {https://doi.org/10.32604/cmc.2023.041508},
url = {https://www.sciencedirect.com/science/article/pii/S1546221823001169},
author = {Hao Meng and Xinguo Yu and Bin He and Litian Huang and Liang Xue and Zongyou Qiu},
keywords = {Arithmetic word problem, implicit quantity relations, qualia syntax-semantic model},
abstract = {Solving arithmetic word problems that entail deep implicit relations is still a challenging problem. However, significant progress has been made in solving Arithmetic Word Problems (AWP) over the past six decades. This paper proposes to discover deep implicit relations by qualia inference to solve Arithmetic Word Problems entailing Deep Implicit Relations (DIR-AWP), such as entailing commonsense or subject-domain knowledge involved in the problem-solving process. This paper proposes to take three steps to solve DIR-AWPs, in which the first three steps are used to conduct the qualia inference process. The first step uses the prepared set of qualia-quantity models to identify qualia scenes from the explicit relations extracted by the Syntax-Semantic (S2) method from the given problem. The second step adds missing entities and deep implicit relations in order using the identified qualia scenes and the qualia-quantity models, respectively. The third step distills the relations for solving the given problem by pruning the spare branches of the qualia dependency graph of all the acquired relations. The research contributes to the field by presenting a comprehensive approach combining explicit and implicit knowledge to enhance reasoning abilities. The experimental results on Math23K demonstrate hat the proposed algorithm is superior to the baseline algorithms in solving AWPs requiring deep implicit relations.}
}
@article{LIU2022101618,
title = {ABRACL as a potential prognostic biomarker and correlates with immune infiltration in low-grade gliomas},
journal = {Interdisciplinary Neurosurgery},
volume = {30},
pages = {101618},
year = {2022},
issn = {2214-7519},
doi = {https://doi.org/10.1016/j.inat.2022.101618},
url = {https://www.sciencedirect.com/science/article/pii/S2214751922001323},
author = {Bohan Liu and Yanlei Guan and Minghao Wang and Yibo Han and Wenxuan Wang and Yunjie Wang and Pengfei Wu},
keywords = {ABRACL, Low-grade gliomas, Immune infiltration, Prognostic model},
abstract = {Background
Low-gradegliomas (LGGs) as one of the mostcommonbrain tumors and highlyinvadeinto adjacent normal brain tissue, which can result in low rate of radical excision and poor prognosis. Immunotherapy as a potential treatment method has garnered increasing attention in recent years. Wesystematically screenedthe prognosticgenes based on 56,530 genes in CGGA database. Finally, ABRACL was selected as the target gene. ABRACL has not been investigated in gliomas. In our study, we aimed to explore the prognostic value of ABRACL.
Methods
To analyse the prognostic value of ABRACL, gene expression profiles and clinical information of LGGs patients were collated from theTCGAandCGGAdatabases. Functional enrichment analysis was performed by using Gene Ontology (GO) and the Kyoto Encyclopedia of Genes and Genomes (KEGG). CIBERSORTalgorithm was used to calculate the associations between ABRACL and immune cells infiltration. Then, we investigated the associations between ABRACL and immunomodulators. Four immunomodulators (TNFRSF14, TNFSF13, ULBP1, PDCD1LG2) were selected to establish theprognosticmodel which could be used to predict outcomes of LGGs patients.
Conclusion
LGGs patients with high expression of ABRACL showed worse prognosis. ABRACL was an independent prognostic factor of LGGs. ABRACL played an important role in tumor immune microenvironment and promoted tumorigenesis and proliferation of LGGs by regulating the aggregation of macrophages M2. Functional enrichment analysis suggested that ABRACL was associated with various immune functions. Taken together, the results of this study showed that ABRACL was apotentialnovel biomarker of LGGs.}
}
@incollection{BOWDEN201831,
title = {Chapter 2 - Informatics for Interoperability of Molecular-Genetic and Neurobehavioral Databases},
editor = {Robert T. Gerlai},
booktitle = {Molecular-Genetic and Statistical Techniques for Behavioral and Neural Research},
publisher = {Academic Press},
address = {San Diego},
pages = {31-50},
year = {2018},
isbn = {978-0-12-804078-2},
doi = {https://doi.org/10.1016/B978-0-12-804078-2.00002-7},
url = {https://www.sciencedirect.com/science/article/pii/B9780128040782000027},
author = {Douglas M. Bowden and Mark F. Dubach and Evan Dong},
keywords = {Brain atlas, Database, Interoperability, Neuroinformatics, NeuroNames, Ontology, Quantitative neuroanatomy, Standard nomenclature},
abstract = {The merger of data sets from multiple large-scale projects has become a major driver of advance in the biomedical sciences. Progress has been slower than anticipated, however, for the merger of molecular-genetic and neurobehavioral databases. The sophisticated bioinformatics tools for statistical processing of molecular and genetic data find no equivalent in the toolbox of neuroinformatics. A major reason is terminological inconsistency in the coding of neuroanatomic location for such data as gene expression and neuronally relevant macromolecules. Here, we present a straightforward way to establish interoperability among databases that code multidisciplinary data using different terminologies for brain structures. A mediator translates the terminologies of multiple databases through the standard nomenclature of NeuroNames into the terminology of the collating resource. The collating resource then is able to use its own tools and terminology to produce a single database for analysis. Considerable attention is given here to clarification of (1) differences between bioinformatics and neuroinformatics, (2) differences between ontologies for descriptive logic processing versus statistical data processing, and (3) the critical role of mapping multidisciplinary data to standard species-specific brain atlases for quantitative neuroanatomic analysis.}
}
@article{LU2025100024,
title = {Towards information geography in ternary space},
journal = {Information Geography},
volume = {1},
number = {2},
pages = {100024},
year = {2025},
issn = {3050-5208},
doi = {https://doi.org/10.1016/j.infgeo.2025.100024},
url = {https://www.sciencedirect.com/science/article/pii/S3050520825000247},
author = {Guonian Lü and Xudong Li and Min Chen and Liangchen Zhou and Songshan Yue and Xueying Zhang and Mingguang Wu and Jian Wang and Zhaoyuan Yu and Linwang Yuan},
keywords = {Information geography, Information space, Ternary spaces},
abstract = {The rapid development of information technologies provides a new carrier for digitizing, integrating, and synthesizing multiple scales and sources of information. This paradigm shift enables holistic modeling, analysis, and representation of the complex real world. Crucially, information space has emerged as a critical bridge, harmonizing geography's traditional dual dimensions—physical space and human-social space—thereby redefining modern geographic research frameworks. This evolution necessitates a conceptual transition from binary space to ternary space, where information space becomes an integral third dimension. To formalize this paradigm, this paper introduces information geography (InfoGeo), a nascent discipline centered on information space as both its theoretical foundation and research domain. We rigorously define InfoGeo's conceptual architecture, delineate its research objectives, disciplinary system, and methodological framework, and critically compare its epistemological distinctions from geographic information science (GIScience). Through systematic analysis, we identify key challenges and propose a forward-looking research agenda. This study aims to establish InfoGeo as a foundational framework for understanding geospatial phenomena in the digital age and to provide a theoretical roadmap for advancing interdisciplinary geographic research.}
}
@article{JONNAKUTI2024100707,
title = {PolyAMiner-Bulk is a deep learning-based algorithm that decodes alternative polyadenylation dynamics from bulk RNA-seq data},
journal = {Cell Reports Methods},
volume = {4},
number = {2},
pages = {100707},
year = {2024},
issn = {2667-2375},
doi = {https://doi.org/10.1016/j.crmeth.2024.100707},
url = {https://www.sciencedirect.com/science/article/pii/S2667237524000213},
author = {Venkata Soumith Jonnakuti and Eric J. Wagner and Mirjana Maletić-Savatić and Zhandong Liu and Hari Krishna Yalamanchili},
keywords = {alternative polyadenylation (APA), post-transcriptional regulation, deep learning, large language model (LLM), bioinformatics, computational biology, gene regulation},
abstract = {Summary
Alternative polyadenylation (APA) is a key post-transcriptional regulatory mechanism; yet, its regulation and impact on human diseases remain understudied. Existing bulk RNA sequencing (RNA-seq)-based APA methods predominantly rely on predefined annotations, severely impacting their ability to decode novel tissue- and disease-specific APA changes. Furthermore, they only account for the most proximal and distal cleavage and polyadenylation sites (C/PASs). Deconvoluting overlapping C/PASs and the inherent noisy 3′ UTR coverage in bulk RNA-seq data pose additional challenges. To overcome these limitations, we introduce PolyAMiner-Bulk, an attention-based deep learning algorithm that accurately recapitulates C/PAS sequence grammar, resolves overlapping C/PASs, captures non-proximal-to-distal APA changes, and generates visualizations to illustrate APA dynamics. Evaluation on multiple datasets strongly evinces the performance merit of PolyAMiner-Bulk, accurately identifying more APA changes compared with other methods. With the growing importance of APA and the abundance of bulk RNA-seq data, PolyAMiner-Bulk establishes a robust paradigm of APA analysis.}
}
@article{CREMONESI2023104338,
title = {The need for multimodal health data modeling: A practical approach for a federated-learning healthcare platform},
journal = {Journal of Biomedical Informatics},
volume = {141},
pages = {104338},
year = {2023},
issn = {1532-0464},
doi = {https://doi.org/10.1016/j.jbi.2023.104338},
url = {https://www.sciencedirect.com/science/article/pii/S153204642300059X},
author = {Francesco Cremonesi and Vincent Planat and Varvara Kalokyri and Haridimos Kondylakis and Tiziana Sanavia and Victor {Miguel Mateos Resinas} and Babita Singh and Silvia Uribe},
keywords = {Federated learning, Data model, Healthcare, Medical research, Omics, Lessons learned},
abstract = {Federated learning initiatives in healthcare are being developed to collaboratively train predictive models without the need to centralize sensitive personal data. GenoMed4All is one such project, with the goal of connecting European clinical and –omics data repositories on rare diseases through a federated learning platform. Currently, the consortium faces the challenge of a lack of well-established international datasets and interoperability standards for federated learning applications on rare diseases. This paper presents our practical approach to select and implement a Common Data Model (CDM) suitable for the federated training of predictive models applied to the medical domain, during the initial design phase of our federated learning platform. We describe our selection process, composed of identifying the consortium’s needs, reviewing our functional and technical architecture specifications, and extracting a list of business requirements. We review the state of the art and evaluate three widely-used approaches (FHIR, OMOP and Phenopackets) based on a checklist of requirements and specifications. We discuss the pros and cons of each approach considering the use cases specific to our consortium as well as the generic issues of implementing a European federated learning healthcare platform. A list of lessons learned from the experience in our consortium is discussed, from the importance of establishing the proper communication channels for all stakeholders to technical aspects related to –omics data. For federated learning projects focused on secondary use of health data for predictive modeling, encompassing multiple data modalities, a phase of data model convergence is sorely needed to gather different data representations developed in the context of medical research, interoperability of clinical care software, imaging, and –omics analysis into a coherent, unified data model. Our work identifies this need and presents our experience and a list of actionable lessons learned for future work in this direction.}
}
@article{WIHARJA2020100616,
title = {Schema aware iterative Knowledge Graph completion},
journal = {Journal of Web Semantics},
volume = {65},
pages = {100616},
year = {2020},
issn = {1570-8268},
doi = {https://doi.org/10.1016/j.websem.2020.100616},
url = {https://www.sciencedirect.com/science/article/pii/S1570826820300494},
author = {Kemas Wiharja and Jeff Z. Pan and Martin J. Kollingbaum and Yu Deng},
keywords = {Knowledge Graph completion, Schema aware, Knowledge Graph reasoning, Approximate reasoning, SHACL constraint, Correctness and coverage},
abstract = {Recent success of Knowledge Graph has spurred widespread interests in methods for the problem of Knowledge Graph completion. However, efforts to understand the quality of the candidate triples from these methods, in particular from the schema aspect, have been limited. Indeed, most existing Knowledge Graph completion methods do not guarantee that the expanded Knowledge Graphs are consistent with the ontological schema of the initial Knowledge Graph. In this work, we challenge the silver standard method, by proposing the notion of schema-correctness. A fundamental challenge is how to make use of different types of Knowledge Graph completion methods together to improve the production of schema-correct triples. To address this, we analyse the characteristics of different methods and propose a schema aware iterative approach to Knowledge Graph completion. Our main findings are: (i) Some popular Knowledge Graph completion methods have surprisingly low schema-correctness ratio; (ii) Different types of Knowledge Graph completion methods can work with each other to help overcame individual limitations; (iii) Some iterative sequential combinations of Knowledge Graph completion methods have significantly better schema-correctness and coverage ratios than other combinations; (iv) All the MapReduce based iterative methods outperform involved single-pass methods significantly over the tested Knowledge Graphs in terms of productivity of schema-correct triples. Our findings and infrastructure can help further work on evaluating Knowledge Graph completion methods, more fine-grained approaches for schema aware iterative knowledge graph completion, as well as new approximate reasoning approaches based Knowledge Graph completion methods.}
}
@article{VANLEERDAM2024108877,
title = {A predictive model for hypocalcaemia in dairy cows utilizing behavioural sensor data combined with deep learning},
journal = {Computers and Electronics in Agriculture},
volume = {220},
pages = {108877},
year = {2024},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2024.108877},
url = {https://www.sciencedirect.com/science/article/pii/S0168169924002680},
author = {Meike {van Leerdam} and Peter R. Hut and Arno Liseune and Elena Slavco and Jan Hulsen and Miel Hostens},
keywords = {Dairy cattle, Hypocalcaemia, Sensors, Deep learning, Prediction, Transition period},
abstract = {(Sub)clinical hypocalcaemia occurs frequently in the dairy industry, and is one of the earliest symptoms of an impaired transition period. Calcium deficiency is accompanied by changes in cows’ daily behavioural variables, which can be measured by sensors. The goal of this study was to construct a predictive model to identify cows at risk of hypocalcaemia in dairy cows using behavioural sensor data. For this study 133 primiparous and 476 multiparous cows from 8 commercial Dutch dairy farms were equipped with neck and leg sensors measuring daily behavioural parameters, including eating, ruminating, standing, lying, and walking behaviour of the 21 days before calving. From each cow, a blood sample was taken within 48 h after calving to measure their blood calcium concentration. Cows with a blood calcium concentration ≤2.0 mmol/L were defined as hypocalcemic. In order to create a more context based cut-off, a second way of dividing the calcium concentrations into two categories was proposed, using a linear mixed-effects model with a k-Means clustering. Three possible binary predictive models were tested; a logistic regression model, a XgBoost model and a LSTM deep learning model. The models were expanded by adding the following static features as input variables; parity (1, 2 or 3＋), calving season (summer, autumn, winter, spring), day of calcium sampling relative to calving (0, 1 or 2), body condition score and locomotion score. Of the three models, the deep learning model performed best with an area under the receiver operating characteristic curve (AUC) of 0.71 and an average precision of 0.47. This final model was constructed with the addition of the static features, since they improved the model’s tuning AUC with 0.11. The calcium label based on the cut-off categorization method proved to be easier to predict for the models compared to the categorization method with the k-means clustering. This study provides a novel approach for the prediction of hypocalcaemia, and an ameliorated version of the deep learning model proposed in this study could serve as a tool to help monitor herd calcium status and to identify animals at risk for associated transition diseases.}
}
@article{PROENCA201813,
title = {Formalizing ISO/IEC 15504-5 and SEI CMMI v1.3 – Enabling automatic inference of maturity and capability levels},
journal = {Computer Standards & Interfaces},
volume = {60},
pages = {13-25},
year = {2018},
note = {Standards in Software Process Improvement and Capability Determination},
issn = {0920-5489},
doi = {https://doi.org/10.1016/j.csi.2018.04.007},
url = {https://www.sciencedirect.com/science/article/pii/S0920548918300382},
author = {Diogo Proença and José Borbinha},
keywords = {ISO/IEC 15504-5, CMMI v1.3, Process capability, Process maturity, Process assessment, OWL},
abstract = {This paper presents formalizations that capture definitions of a number of concepts of the ISO/IEC 15504-5 process assessment model and the CMMI v1.3 constellations process models and relations among the concepts. The formalizations are expressed in a formal language, OWL. The main objectives for these formalizations are to be consistent with the ISO/IEC 15504-5 process assessment model and the CMMI-DEV/SVC/ACQ v1.3 models and to be effective, i.e., to allow for an automatic determination of an organizations maturity level and of a process capability level based upon data collected during an assessment. The formalizations are presented in a number of levels, from more general concepts to more specific. To assess the validity of the ISO/IEC 15504-5 formalization, a number of test cases for the scenario of automatic determination of the capability levels were developed. To assess the validity of the CMMI v1.3 formalizations, a number of real cases were selected from the CMMI institute published appraisal results with the purpose of validating the automatic determination of both organizational maturity and process areas capability levels. A set of OWL reasoners were then used to derive the capability levels for a specific process group (regarding the ISO/IEC 15504-5) and to derive the organizational maturity and process areas capability levels for the CMMI-DEV v1.3 constellation. While the test results were all positive, the real value of these formalizations comes from the fact that they faithfully captured the main aspects of ISO/IEC 15504-5 and CMMI v1.3, both well established and accepted models for the assessment of organizational processes, and that an inference engine was able to support the assessment of processes capability levels and of organizations maturity levels.}
}
@article{HE2021824,
title = {Construction of carbonate reservoir knowledge base and its application in fracture-cavity reservoir geological modeling},
journal = {Petroleum Exploration and Development},
volume = {48},
number = {4},
pages = {824-834},
year = {2021},
issn = {1876-3804},
doi = {https://doi.org/10.1016/S1876-3804(21)60069-1},
url = {https://www.sciencedirect.com/science/article/pii/S1876380421600691},
author = {Zhiliang HE and Jianfang SUN and Panhong GUO and Hehua WEI and Xinrui LYU and Kelong HAN},
keywords = {knowledge management, reservoir knowledge base, fracture-cavity reservoir, geological modeling, carbonates, paleo-underground river system, Tahe oilfield, Tarim Basin},
abstract = {To improve the efficiency and accuracy of carbonate reservoir research, a unified reservoir knowledge base linking geological knowledge management with reservoir research is proposed. The reservoir knowledge base serves high-quality analysis, evaluation, description and geological modeling of reservoirs. The knowledge framework is divided into three categories: technical service standard, technical research method and professional knowledge and cases related to geological objects. In order to build a knowledge base, first of all, it is necessary to form a knowledge classification system and knowledge description standards; secondly, to sort out theoretical understandings and various technical methods for different geologic objects and work out a technical service standard package according to the technical standard; thirdly, to collect typical outcrop and reservoir cases, constantly expand the content of the knowledge base through systematic extraction, sorting and saving, and construct professional knowledge about geological objects. Through the use of encyclopedia based collaborative editing architecture, knowledge construction and sharing can be realized. Geological objects and related attribute parameters can be automatically extracted by using natural language processing (NLP) technology, and outcrop data can be collected by using modern fine measurement technology, to enhance the efficiency of knowledge acquisition, extraction and sorting. In this paper, the geological modeling of fracture-cavity reservoir in the Tarim Basin is taken as an example to illustrate the construction of knowledge base of carbonate reservoir and its application in geological modeling of fracture-cavity carbonate reservoir.}
}
@article{XUE2022104230,
title = {Regulatory information transformation ruleset expansion to support automated building code compliance checking},
journal = {Automation in Construction},
volume = {138},
pages = {104230},
year = {2022},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2022.104230},
url = {https://www.sciencedirect.com/science/article/pii/S0926580522001030},
author = {Xiaorui Xue and Jiansong Zhang},
keywords = {Automated compliance checking, Automated information extraction, Natural language processing, Part-of-speech tagging, Building design review, Automated construction management systems},
abstract = {The traditional building code compliance checking process mainly relies on design reviewers to review design documents or models manually. The intensive manual effort needed makes this process time-consuming, costly, and error-prone. Automated compliance checking (ACC) could be a promising upgrade of the traditional manual code compliance checking. With a reduced workload on design reviewers, ACC is cheaper, faster, and immune to human errors. To support ACC, building code requirements need to be represented in a computer-processable format to enable automated reasoning, which will in turn allow an automated assessment of the building design's compliance status with building codes. A major limitation of many existing ACC systems/methods is their limited range of checkable building code requirements. To address that, the state of the art uses pattern matching-based rules to transform building code requirements into computable formats automatically, but the ruleset was developed and tested only on a few chapters of building code requirements. An efficient ruleset expansion method is needed to increase its range of checkable building code requirements at a low cost, to bring ACC systems closer to full deployment. In this paper, the authors proposed a new regulatory information transformation ruleset expansion method for expanding an existing ruleset. This method can expand the range of checkable code requirements of ACC systems without significant manual effort. The proposed ruleset expansion method takes an iterative approach to ensure the generality and validity of new pattern matching-based rules and the quality of information transformation results. The expanded ruleset was tested on generating logic clauses from Chapter 5 of the International Building Code 2015. Compared to the baseline ruleset, the expanded ruleset increased the predicate-level precision, recall, and F1-score of the logic clause generation by 10.44%, 25.72%, and 18.02%, to 95.17%, 96.60%, and 95.88%, respectively.}
}
@article{DERKINDEREN2024109130,
title = {Semirings for probabilistic and neuro-symbolic logic programming},
journal = {International Journal of Approximate Reasoning},
volume = {171},
pages = {109130},
year = {2024},
note = {Synergies between Machine Learning and Reasoning},
issn = {0888-613X},
doi = {https://doi.org/10.1016/j.ijar.2024.109130},
url = {https://www.sciencedirect.com/science/article/pii/S0888613X24000173},
author = {Vincent Derkinderen and Robin Manhaeve and Pedro {Zuidberg Dos Martires} and Luc {De Raedt}},
keywords = {Probabilistic logic programming, Neuro-symbolic AI, Semiring programming, Model counting},
abstract = {The field of probabilistic logic programming (PLP) focuses on integrating probabilistic models into programming languages based on logic. Over the past 30 years, numerous languages and frameworks have been developed for modeling, inference and learning in probabilistic logic programs. While originally PLP focused on discrete probability, more recent approaches have incorporated continuous distributions as well as neural networks, effectively yielding neuro-symbolic methods. We provide an overview and synthesis of this domain, thereby contributing a unified algebraic perspective on the different flavors of PLP, showing that many if not most of the extensions of PLP can be cast within a common algebraic logic programming framework, in which facts are labeled with elements of a semiring and disjunction and conjunction are replaced by addition and multiplication. This does not only hold for the PLP variations itself but also for the underlying execution mechanism that is based on (algebraic) model counting. In order to showcase and explain this unified perspective, we focus on the ProbLog language and its extensions.}
}
@article{LIU2024100041,
title = {The genomic database of fruits: A comprehensive fruit information database for comparative and functional genomic studies},
journal = {Agriculture Communications},
volume = {2},
number = {2},
pages = {100041},
year = {2024},
issn = {2949-7981},
doi = {https://doi.org/10.1016/j.agrcom.2024.100041},
url = {https://www.sciencedirect.com/science/article/pii/S2949798124000176},
author = {Jingyi Liu and Chenchen Huang and Dingsheng Xing and Shujing Cui and Yanhong Huang and Can Wang and Ruohan Qi and Zhuo Liu and Rong Zhou and Xiao Ma and Xiaoming Song},
keywords = {The genomic databases of fruits, Fruit, Functional gene, Gene annotation, CRISPR, Tool},
abstract = {Fruit has an important role in human nutrition and health; therefore, the systematic study of fruit genomic data is essential. The Genomic Database of Fruits (TGDF, http://tgdf.bio2db.com/), established through whole-genome analyses of 44 fruit species, is a comprehensive, user-friendly fruit database. TGDF contains a wealth of functional genes, including 11,350 flowering genes, 3161 auxin signaling genes, 2164 anthocyanin synthesis genes, 1464 abscisic acid (ABA) synthesis genes, 10,931 ​cell division and expansion genes, 1786 starch synthesis genes, 294 fruit size genes, and 6311 sugar transporter genes. Additionally, TGDF contains 1,433,368 CRISPR guide sequences from various fruit genomes, along with information on homologous genes and duplication types for the 44 fruit species. TGDF contains 6,417,060 gene annotations sourced from TrEMBL, SwissProt, Nr, and Gene Ontology databases, along with tools such as Sequence Fetch, BLAST, Synteny, and JBrowse for bioinformatics analyses. Transcriptomic data were also collected and collated from fruits, including details on instruments, tissues, or growth stages. This comprehensive, user-friendly resource is the first collection of fruit genomic data. Users can easily download genomic sequences, gene annotations, and bioinformatics analysis results from TGDF, which will be updated continually. We anticipate that TGDF will become a primary resource for fruit comparative and functional genomic studies.}
}
@article{GALPHADE2024820,
title = {Semantic Analysis Using Deep Learning for Predicting Stock Trends},
journal = {Procedia Computer Science},
volume = {235},
pages = {820-829},
year = {2024},
note = {International Conference on Machine Learning and Data Engineering (ICMLDE 2023)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.04.078},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924007543},
author = {Manisha Galphade and V.B. Nikam and Dhanalekshmi Yedurkar and Prabhishek Singh and Thompson Stephan},
keywords = {Deep learning, emotion mining, financial analysts, investors, sentiment analysis},
abstract = {Company Investors and financial professionals mostly rely on quarterly reports to help them decide the ways to invest in stocks and assess the company's current performance. Quarterly company reports offer an abstracted perspective of the company's overall past performance, as well as its present situation and the market value of its market share. Financial text streams in quarterly report are unstructured naturally, but they represent cooperative expressions that are of important in any financial decision for stake holder. It will be both daunting and necessary to procedure intelligence of unstructured textual data. In this study, we address important queries related with the explosion of interest in a method to extract useful information from unstructured data and the way to work out if such insight provides any hints regarding the trends of financial markets. There is a lack of availability in the labeled dataset for financial sentiment analysis applications. The pre-trained language model employs very little labeled parameters that is used for a variety of domain specific corpora including financial sentiment analysis. In this paper, FinBERT, a model built on the BERT framework, to address linguistics challenges in the financial domain. The proposed work uses twelve transformer layers and twelve attention layers with several million parameters. The design of encoder and decoder comprises of several attention layers along with RNN. This arrangement aids to recognize instances processing the strongest relation between the words within a particular sentence. The experimentation results shows that the presented method surpass the state-of-the-art methods for financial datasets. The results are also compared with other existing models using the same financial dataset. It is observed that the FinBERT attains an accuracy of 84.77% on quarterly reports despite using a lesser training set.}
}
@article{BAWDEN20182,
title = {Curating the infosphere},
journal = {Journal of Documentation},
volume = {74},
number = {1},
pages = {2-17},
year = {2018},
issn = {0022-0418},
doi = {https://doi.org/10.1108/JD-07-2017-0096},
url = {https://www.sciencedirect.com/science/article/pii/S0022041818000152},
author = {David Bawden and Lyn Robinson},
keywords = {Ontology, Philosophy, Epistemology, Library and information science, Floridi, Philosophy of information},
abstract = {Purpose
The purpose of this paper is to re-examine the proposal that Luciano Floridi’s philosphy of information (PI) may be an appropriate conceptual foundation for the discipline of library and information science (LIS).
Design/methodology/approach
A selective literature review and analysis are carried out.
Findings
It is concluded that LIS is in need of a new conceptual framework, and that PI is appropriate for this purpose.
Originality/value
Floridi proposed a close relationship between PI and LIS more than a decade ago. Although various authors have addressed the aspects of this relationship since then, this is the first proposal from an LIS perspective that PI be adopted as a basis for LIS.}
}
@article{SUDIGYO2023722,
title = {Literature study of stunting supplementation in Indonesian utilizing text mining approach},
journal = {Procedia Computer Science},
volume = {216},
pages = {722-729},
year = {2023},
note = {7th International Conference on Computer Science and Computational Intelligence 2022},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2022.12.189},
url = {https://www.sciencedirect.com/science/article/pii/S1877050922022670},
author = {Digdo Sudigyo and Alam Ahmad Hidayat and Rudi Nirwantono and Reza Rahutomo and Joko Pebrianto Trinugroho and Bens Pardamean},
keywords = {text mining, data mining, literature study, stunting supplementation, Indonesian},
abstract = {Numerous research on stunting supplementation interventions in Indonesia have been published. The information can be extracted through data mining, especially from academic research databases. In this paper, we presented a text mining-based literature review strategy to create a pipeline that researchers can use to accelerate the development of stunting supplementation intervention research in Indonesia. Utilizing various NLP (Natural Language Processing) techniques, data were crawled, processed, and visualized using Python. The crawling dataset used a module from the Pubmed API (Application Programming Interface) to collect literature papers. The NLTK (Natural Language Toolkit) module and itertools were used to process text data. The n-grams model was applied to process tokens into bigrams and trigrams. Text information was visualized using Matplotlib and Word cloud packages. There is an increasing number of publication in stunting supplementation intervention according to our result, which was observed from 2015 to 2021. West Java was the province where most of the stunting research has been conducted, as determined by research abstracts. Top occurrences obtained from the bigram and trigrams models calculation produced different terms. The word pairings that occurred the most frequently in the bigram and trigram model analyses were "child-aged" and "iron-folic-acid," respectively. The findings of this study are expected to help researchers to obtain the latest research topics related to stunting supplementation interventions in Indonesia.}
}
@article{SONG2019133,
title = {Toward any-language zero-shot topic classification of textual documents},
journal = {Artificial Intelligence},
volume = {274},
pages = {133-150},
year = {2019},
issn = {0004-3702},
doi = {https://doi.org/10.1016/j.artint.2019.02.002},
url = {https://www.sciencedirect.com/science/article/pii/S0004370219300414},
author = {Yangqiu Song and Shyam Upadhyay and Haoruo Peng and Stephen Mayhew and Dan Roth},
keywords = {Multilingual text classification, Cross-lingual text classification, Zero-shot text classification, Semantic Supervision},
abstract = {In this paper, we present a zero-shot classification approach to document classification in any language into topics which can be described by English keywords. This is done by embedding both labels and documents into a shared semantic space that allows one to compute meaningful semantic similarity between a document and a potential label. The embedding space can be created by either mapping into a Wikipedia-based semantic representation or learning cross-lingual embeddings. But if the Wikipedia in the target language is small or there is not enough training corpus to train a good embedding space for low-resource languages, then performance can suffer. Thus, for low-resource languages, we further use a word-level dictionary to convert documents into a high-resource language, and then perform classification based on the high-resource language. This approach can be applied to thousands of languages, which can be contrasted with machine translation, which is a supervision-heavy approach feasible for about 100 languages. We also develop a ranking algorithm that makes use of language similarity metrics to automatically select a good pivot or bridging high-resource language, and show that this significantly improves classification of low-resource language documents, performing comparably to the best bridge possible.}
}
@article{CRISTIA2020100914,
title = {Language input and outcome variation as a test of theory plausibility: The case of early phonological acquisition},
journal = {Developmental Review},
volume = {57},
pages = {100914},
year = {2020},
issn = {0273-2297},
doi = {https://doi.org/10.1016/j.dr.2020.100914},
url = {https://www.sciencedirect.com/science/article/pii/S0273229720300204},
author = {Alejandrina Cristia},
keywords = {Input, Phonological acquisition, Individual variation, Socioeconomic status, Cultural variation},
abstract = {There is wide individual, social, and cultural variation in experiences afforded to young children, yet current evidence suggests there is little variation in phonological outcomes in the first year of life. This paper provides a classification of phonological acquisition theories, revealing that few of them predict no variation in phonological acquisition outcomes, and thus are plausible in view of observed patterns: Only theories with strong priors and informational filters, and where phonological acquisition does not depend on lexical development, are compatible with great variation in early language experiences resulting in minimal or no outcome variation. The approach is then extended to consider proposals contemplating acquisition of other linguistic levels, including joint learning frameworks, and testable predictions are drawn for the acquisition of morphosyntax and vocabulary.}
}
@article{GEISZLER202322,
title = {Imitation in automata and robots: A philosophical case study on Kempelen},
journal = {Studies in History and Philosophy of Science},
volume = {100},
pages = {22-31},
year = {2023},
issn = {0039-3681},
doi = {https://doi.org/10.1016/j.shpsa.2023.05.004},
url = {https://www.sciencedirect.com/science/article/pii/S0039368123000845},
author = {Lukas Geiszler},
keywords = {Automata and robots, Synthetic method, Imitation, representation and simulation, Speech and language, Historiography of mechanical engineering},
abstract = {With robots being of far-ranging public and academic interest, attempts are made to set these into relation to earlier self-moving machines. Automata from European Enlightenment, especially in the 18th century, are such machines being referenced. The debate revolves around the question whether the design and the purpose of the construction of these automata can be viewed as antedating epistemological conceptualizations formulated with regards to the scientific employment of robotics as a synthetic modeling practice in contemporary life sciences. This paper reflects on a claim made in this context, namely that the construction of 18th century automata and 21st century robots share the epistemic role of simulating the core processes of living organisms and are thus indicative of an epistemological continuity in how organisms are conceived as machines. To philosophically investigate whether such a statement is taking changes in material, political, and technological conditions into account, a case study of Kempelen's Sprechmaschine from 1791 is done. The paper asserts that it should be historicized what makes a machine fit the concept of an automaton––and thus also poses the broader question what extent of caution must be taken in identifying automata with robots.}
}
@article{KATARZYNIAK20203283,
title = {Extracting categories with prototypes in artificial cognitive agents},
journal = {Procedia Computer Science},
volume = {176},
pages = {3283-3292},
year = {2020},
note = {Knowledge-Based and Intelligent Information & Engineering Systems: Proceedings of the 24th International Conference KES2020},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2020.09.120},
url = {https://www.sciencedirect.com/science/article/pii/S1877050920320202},
author = {Radosław Katarzyniak and Grzegorz Popek and Marcin Żurawski},
keywords = {category extraction, prototype theory, artificial cognition, autonomous system},
abstract = {In this paper a general strategy of determining categories with prototypes is presented and its variations are discussed. It is assumed that the task is carried out by an artificial agent which autonomously develops and maintains its private ontological knowledge base. The computation of a category and its prototype is based on a learning set consisting of messages obtained by the agent from other participants of external communication processes who are considered teachers and treated as sources of new meanings. The teachers communicate their beliefs related to an inclusion of particular objects to a category which the listening agent is trying to learn. Potential categories are defined over a related cognitive space defined with respect to a particular distance or similarity measure, both available to the artificial agent along with computational mechanisms for determining central objects in learning sets. Simplified computational examples of calculations performed within the proposed strategy are presented.}
}
@article{BIAN2024105127,
title = {Quantitative proteomics analysis identified new interacting proteins of JAL30 in Arabidopsis},
journal = {Journal of Proteomics},
volume = {297},
pages = {105127},
year = {2024},
issn = {1874-3919},
doi = {https://doi.org/10.1016/j.jprot.2024.105127},
url = {https://www.sciencedirect.com/science/article/pii/S1874391924000599},
author = {Jianghu Bian and Rongqing Chen and Shiting Gu and Wenfei Wang and Xuelian Yang},
keywords = {Jacalin related lectin, JAL30, ESM1, O-GlcNAcylation, },
abstract = {Jacalin-related lectins (JALs) are a unique group of plant lectins derived from the jacalin protein family, which play important roles in plant defense responses. JAL30/PBP1 (PYK10 binding protein 1) interacts with inactive PYK10, exerting negative regulatory control over the size of the PYK10 complex, which is formed and activated upon insect or pathogen invasion. However, the precise interplay between JAL30 and other components remains elusive. In this study, we found JAL30 as a nucleocytoplasmic protein, but no obvious phenotype was observed in jal30–1 single mutant. Through immunoprecipitation (IP) enrichment combined with liquid chromatography-tandem mass spectrometry (LC-MS/MS), dozens of new JAL30 interacting proteins were found in addition to several reported ones. Gene Ontology (GO) analysis revealed that these interacting proteins were highly related to the wounding and bacterial stimuli, suggesting their potential involvement in the jasmonate (JA) response. Importantly, the expression of JAL30 was induced by MeJA treatment, further highlighting its relevance in plant defense mechanisms. A novel JAL30 interacting protein, ESM1, was identified and its interaction with JAL30 was confirmed by Co-immunoprecipitation. Moreover, ESM1 was found as an O-GlcNAcylated protein, suggesting that JAL30 may possess glycosylated protein binding ability, particularly in O-GlcNAcylated protein and peptide recognition. Overall, our study provides valuable insights into the interacting protein network and biological function of JAL30, demonstrates the interaction between JAL30 and ESM1, and uncovers the potential significance of JAL30 in plant defense system, potentially through its association with PYK10 complex or JA response.
Significance
The biological functions of lectin proteins, including defense responses, immunity responses, signal transduction, have been well studied. Lectin proteins were also utilized to enrich glycosylated proteins for their specific carbohydrates binding capability. Jacalin-related lectins (JALs) were found to involve in plant defense mechanism. However, it is not yet clear whether JALs could use for enrichment of glycosylated proteins. In this study, we used label-free quantification method to identify interacting proteins of JAL30. A novel interacting protein, ESM1, as an O-GlcNAcylated protein was found. ESM1 has been reported to take part in defense against insect herbivory. Therefore, our findings provided experimental evidence to confirm that JALs have potential to be developed as the bio-tools to enrich glycosylated proteins. Finally, our data not only illustrated the vital biological role of JALs in plants, but also verified unique function of JAL30 in recognizing O-GlcNAcylated proteins.}
}
@article{DIPPOLD2020100432,
title = {A turn to language: How interactional sociolinguistics informs the redesign of prompt:response chatbot turns},
journal = {Discourse, Context & Media},
volume = {37},
pages = {100432},
year = {2020},
issn = {2211-6958},
doi = {https://doi.org/10.1016/j.dcm.2020.100432},
url = {https://www.sciencedirect.com/science/article/pii/S2211695820300659},
author = {Doris Dippold and Jenny Lynden and Rob Shrubsall and Rich Ingram},
keywords = {Chatbots, Micro-analysis, Trust, Alignment, Affiliation, Social presence},
abstract = {This paper discusses how a microlevel linguistic analysis, using interactional sociolinguistics as an umbrella framework and drawing on analytical concepts from politeness theory and conversation analysis, can be used to advise chatbot designers on the interactional features contributing to problematic human user engagement as part of a consultancy project. Existing research using a microlevel linguistic analysis has analysed human user:bot interactions using natural language. This research has identified a central role for language which promotes sociability between the machine and users in the alignment of their goals and practices. However, there is no research currently which discusses how a microlevel linguistic analysis can help identify how the discursive construction of alignment and affiliation within prompt:response chatbots supports social presence and trust. This paper addresses this gap through an analysis of a database of prompt:response chatbot interactions which identified problematic sequences involving misalignment and disaffiliation, undermining human users’ trust and sense of social presence within the interaction. It also reports on how the consultancy project suggested changes to the programming of the chatbot which have potential to lead to improved user engagement and satisfaction.}
}
@article{ALDAHMASH2024102111,
title = {Rumor gatekeepers: Unsupervised ranking of Arabic twitter authorities for information verification},
journal = {Journal of King Saud University - Computer and Information Sciences},
volume = {36},
number = {6},
pages = {102111},
year = {2024},
issn = {1319-1578},
doi = {https://doi.org/10.1016/j.jksuci.2024.102111},
url = {https://www.sciencedirect.com/science/article/pii/S1319157824002003},
author = {Hend Aldahmash and Abdulrahman Alothaim and Abdulrahman Mirza},
keywords = {Expert finding, Social media, Arabic tweets, Transfer learning, Network semantics, Rumor},
abstract = {The advent of online social networks (OSNs) has catalyzed the formation of novel learning communities. Identifying experts within OSNs has become a critical component for facilitating knowledge exchange and enhancing self-awareness, particularly in contexts such as rumor verification processes. Research efforts aimed at locating authorities in OSNs are scant, largely due to the scarcity of annotated datasets. This work represents a contribution to the domain of unsupervised learning to address the challenge of authorities’ identification in Twitter. We have employed advanced natural language processing technique to transfer knowledge concerning topics in the Arabic language and to discern the semantic connections among candidates within Twitter in zero-shot learning. We take advantage of the Single-labeled Arabic News Articles Dataset (SANAD) to perform the process of extracting domain features and applying these features in finding authorities using the Authority Finding in Arabic Twitter (AuFIN) dataset. Our evaluation assessed the extent of extracted topical features transferred and the efficacy of authorities’ retrieval in comparison to the latest unsupervised models in this domain. Our approach successfully extracted and integrated the limited available topical semantic features of the language into the representation of candidates. The findings indicate that our hybrid model surpasses those that rely solely on lexical features of language and network topology, as well as other contemporary approaches to topic-specific expert finding.}
}
@article{LI2024114168,
title = {Development of segregation and integration of functional connectomes during the first 1,000 days},
journal = {Cell Reports},
volume = {43},
number = {5},
pages = {114168},
year = {2024},
issn = {2211-1247},
doi = {https://doi.org/10.1016/j.celrep.2024.114168},
url = {https://www.sciencedirect.com/science/article/pii/S2211124724004960},
author = {Qiongling Li and Mingrui Xia and Debin Zeng and Yuehua Xu and Lianglong Sun and Xinyuan Liang and Zhilei Xu and Tengda Zhao and Xuhong Liao and Huishu Yuan and Ying Liu and Ran Huo and Shuyu Li and Yong He},
keywords = {connectomics, fMRI, gene expression, infant},
abstract = {Summary
The first 1,000 days of human life lay the foundation for brain development and later cognitive growth. However, the developmental rules of the functional connectome during this critical period remain unclear. Using high-resolution, longitudinal, task-free functional magnetic resonance imaging data from 930 scans of 665 infants aged 28 postmenstrual weeks to 3 years, we report the early maturational process of connectome segregation and integration. We show the dominant development of local connections alongside a few global connections, the shift of brain hubs from primary regions to high-order association cortices, the developmental divergence of network segregation and integration along the anterior-posterior axis, the prediction of neurocognitive outcomes, and their associations with gene expression signatures of microstructural development and neuronal metabolic pathways. These findings advance our understanding of the principles of connectome remodeling during early life and its neurobiological underpinnings and have implications for studying typical and atypical development.}
}
@article{DAROLD20189,
title = {Defining embodied cognition: The problem of situatedness},
journal = {New Ideas in Psychology},
volume = {51},
pages = {9-14},
year = {2018},
issn = {0732-118X},
doi = {https://doi.org/10.1016/j.newideapsych.2018.04.001},
url = {https://www.sciencedirect.com/science/article/pii/S0732118X17301794},
author = {Federico {Da Rold}},
keywords = {Situated cognition, Embodied and grounded cognition, Neuro-robotics, Connectionism, Dynamical systems},
abstract = {The embodied view of cognition rejects the substantial dualism between brain and body, claiming the primary role of sensorimotor experience on the development of conceptual knowledge. From this perspective, knowledge is grounded on physical properties of the body and the surrounding world. Furthermore, cognition is situated in a social and environmental context. However, the terms embodied, grounded, and situated are not univocally defined. This article focuses on the notion of situatedness, developing the discussion from the point of view of a computational modeler and roboticist, showing that minor and negligible differences on the definition of the field causes major operational divergences in synthetic models of cognition. A definition of two notions of situatedness are developed a posteriori, that is, by considering epistemological and ontological differences on artificial models. Finally, strengths and weakness of the two approaches are discussed.}
}
@article{BELLIGH2022103425,
title = {Epistemological challenges in the study of alternating constructions},
journal = {Lingua},
volume = {280},
pages = {103425},
year = {2022},
issn = {0024-3841},
doi = {https://doi.org/10.1016/j.lingua.2022.103425},
url = {https://www.sciencedirect.com/science/article/pii/S0024384122001899},
author = {Thomas Belligh and Klaas Willems},
keywords = {Alternating constructions, Semantics-pragmatics interface, Allostructions, Rules and regularities, Correlation and causality},
abstract = {In this article we identify and discuss a number of epistemological challenges in the study of alternating constructions in natural languages. After proposing a working definition for the concept of ‘alternating constructions’, we address the following three specific issues: (i) the need to distinguish between qualitatively different types of alternating constructions, (ii) the need to distinguish between rules of grammar and regularities of language use in the study of alternating constructions, and (iii) the various challenges related to assessing correlation and causation in the study of alternating constructions. On the basis of these three challenges, we take stock of current research on alternating constructions and provide a number of suggestions for future research.}
}
@article{AN2025100250,
title = {Complex adaptive systems science in the era of global sustainability crisis},
journal = {Geography and Sustainability},
volume = {6},
number = {1},
pages = {100250},
year = {2025},
issn = {2666-6839},
doi = {https://doi.org/10.1016/j.geosus.2024.09.011},
url = {https://www.sciencedirect.com/science/article/pii/S2666683924001032},
author = {Li An and B.L. Turner and Jianguo Liu and Volker Grimm and Qi Zhang and Zhangyang Wang and Ruihong Huang},
keywords = {Social-environmental systems, Complex adaptive systems, Sustainability science, Agent-based models, Artificial intelligence, Data science},
abstract = {A significant number and range of challenges besetting sustainability can be traced to the actions and interactions of multiple autonomous agents (people mostly) and the entities they create (e.g., institutions, policies, social network) in the corresponding social-environmental systems (SES). To address these challenges, we need to understand decisions made and actions taken by agents, the outcomes of their actions, including the feedbacks on the corresponding agents and environment. The science of complex adaptive systems—complex adaptive systems (CAS) science—has a significant potential to handle such challenges. We address the advantages of CAS science for sustainability by identifying the key elements and challenges in sustainability science, the generic features of CAS, and the key advances and challenges in modeling CAS. Artificial intelligence and data science combined with agent-based modeling promise to improve understanding of agents’ behaviors, detect SES structures, and formulate SES mechanisms.}
}
@article{CHEN20231424,
title = {Pitongshu Alleviates the Adverse Symptoms in Rats with Functional Dyspepsia Through Regulating Visceral Hypersensitivity Caused by 5-HT Overexpression},
journal = {Combinatorial Chemistry & High Throughput Screening},
volume = {26},
number = {7},
pages = {1424-1436},
year = {2023},
issn = {1386-2073},
doi = {https://doi.org/10.2174/1386207325666220827152654},
url = {https://www.sciencedirect.com/science/article/pii/S1386207323000253},
author = {Su-Hong Chen and Li-Jie Zhu and Yi-Hui Zhi and Han-Song Wu and Lin-Zi Li and Bo Li and Shu-Hua Shen and Gui-Yuan Lv and Kun-Gen Wang},
keywords = {Pitongshu, functional dyspepsia, visceral hypersensitivity, serotonin synapse, 5-HT, CGRP},
abstract = {Aim
The aim of the study was to explore the efficacy as well as the mechanism of action of Pitongshu (PTS) on rats with functional dyspepsia (FD) induced by iodoacetamide gavage and tail clamping.
Methods
The bioactive components of PTS were obtained from the Traditional Chinese Medicine Systems Pharmacology Database and Analysis Platform (TCMSP), whereas the potential targets of PTS were obtained from the Similarity Ensemble Approach (SEA), TCMSP, and Swiss Target Prediction Database. The disease targets were obtained from the DisGeNET database, whereas Gene Ontology (GO) and Kyoto Encyclopedia of Genes and Genomes (KEGG) enrichment analyses were performed using the R Software. The method of iodoacetamide gavage combined with tail clamping was used to establish the FD rat model in this study. Body weight, food intake, gastrointestinal motility, gastric acidity and secretion, and the mechanical pain threshold of rats were measured. The open-field test was also performed. The stomach and duodenum were histologically observed. The levels of serotonin (5-HT), Calcitonin Gene-Related Peptide (CGRP), Motilin (MTL), and Gastrin (GAS) in gastric tissues were detected by ELISA.
Results
A total of 139 bioactive components and 17 potential targets of PTS were identified through a network pharmacology approach. The results of GO and KEGG enrichment analyses indicated that PTS could reduce the 5-HT secretion of gastric tissues through the serotonergic synaptic pathway and alleviate the symptoms of FD, indicating that PTS plays a therapeutic role. The results of animal experiments showed that PTS could increase body weight and food intake, improve autonomous activity, and decrease gastric acidity and secretion in FD rats. Furthermore, gastric sensitivity increased in FD rats, and PTS treatment could significantly decrease it. The results of ELISA showed that the overexpression of 5-HT and CGRP was decreased after PTS treatment in FD rats. Lastly, PTS could significantly improve gastrointestinal motility, as well as the levels of GAS and MTL in FD rats.
Conclusion
PTS may reduce 5-HT secretion by regulating the serotonergic synaptic pathway, thereby reducing visceral sensitivity and alleviating the symptoms of FD.}
}
@article{NEUMANN2025101493,
title = {Cross-domain dynamic vocabulary in metrological use cases: Linkage, automatization and implementation},
journal = {Measurement: Sensors},
volume = {38},
pages = {101493},
year = {2025},
note = {Proceedings of the XXIV IMEKO World Congress},
issn = {2665-9174},
doi = {https://doi.org/10.1016/j.measen.2024.101493},
url = {https://www.sciencedirect.com/science/article/pii/S2665917424004690},
author = {Julia Neumann},
keywords = {Controlled vocabulary, Semantic representation form, Semantics, Thesaurus, Dynamic digital processes},
abstract = {This paper with the title “Cross-Domain Dynamic Vocabulary in Metrological Use Cases: Linkage, Automatization and Implementation” describes concepts of controlled vocabulary in digital metrological workflows. Controlled vocabulary usually either focuses on flexibility at the loss of control or it represents a strict structure at the loss of flexibility. This paper discusses an approach which is called dynamic vocabulary. This concept enables the metrological workflow to maintain a high level of flexibility and to have control over the contents. The five levels of digitalization are used as a reference source to explain the idea of dynamic controlled vocabulary. A concept for domain linkage is described afterwards. To showcase this concept, the representation form of a thesaurus is used. The final topics of the paper consider automatization processes for dynamic vocabulary implementations. It also provides an outlook of the importance for the interaction with artificial intelligence and/or machine learning processes.}
}
@article{RUDEL2024384,
title = {Layer-based information model for 5-axis milling processes using a GraphQL schema},
journal = {Procedia CIRP},
volume = {126},
pages = {384-389},
year = {2024},
note = {17th CIRP Conference on Intelligent Computation in Manufacturing Engineering (CIRP ICME ‘23)},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2024.08.381},
url = {https://www.sciencedirect.com/science/article/pii/S2212827124009533},
author = {Viktor Rudel and David Wichter and Sven Schiller and Georg Vinogradov and Aleksandra Müller and Philipp Ganser and Thomas Bergs},
keywords = {Information model, data model, Compuer Aided Manufacturing (CAM), GraphQL, digital twin, blisk, 5-axis milling, data processing},
abstract = {The view of process-related information in NC-bound manufacturing technologies can range from a perspective of a single cutter location within a considered toolpath to aggregated data which represent the whole operation sequence of a manufacturing process. Data processing pipelines are often individually programmed for the process planning or machining stage addressing an isolated database abstraction layer. This paper proposes a data modeling approach based on a GraphQL schema empowering the user to query planning and actual process data cross-linked with different aggregation layers by a single request.}
}
@article{MARTINRODILLA201929,
title = {Metainformation scenarios in Digital Humanities: Characterization and conceptual modelling strategies},
journal = {Information Systems},
volume = {84},
pages = {29-48},
year = {2019},
issn = {0306-4379},
doi = {https://doi.org/10.1016/j.is.2019.04.009},
url = {https://www.sciencedirect.com/science/article/pii/S030643791830663X},
author = {Patricia Martin-Rodilla and Cesar Gonzalez-Perez},
keywords = {Metadata, Metainformation, Digital Humanities, Conceptual modelling, ConML},
abstract = {Requirements for the analysis, interpretation and reuse of information are becoming more and more ambitious as we generate larger and more complex datasets. This is leading to the development and widespread use of information about information, often called metainformation (or metadata) in most disciplines. The Digital Humanities are not an exception. We often assume that metainformation helps us in documenting information for future reference by recording who has created it, when and how, among other aspects. We also assume that recording metainformation will facilitate the tasks of interpreting information at later stages. However, some works have identified some issues with existing metadata approaches, related to 1) the proliferation of too many “standards” and difficulties to choose between them; 2) the generalized assumption that metadata and data (or metainformation and information) are essentially different, and the subsequent development of separate sets of languages and tools for each (introducing redundant models); and 3) the combination of conceptual and implementation concerns within most approaches, violating basic engineering principles of modularity and separation of concerns. Some of these problems are especially relevant in Digital Humanities. In addition, we argue here that the lack of characterization of the scenarios in which metainformation plays a relevant role in humanistic projects often results in metainformation being recorded and managed without a specific purpose in mind. In turn, this hinders the process of decision making on issues such as what metainformation must be recorded in a specific project, and how it must be conceptualized, stored and managed. This paper presents a review of the most used metadata approaches in Digital Humanities and, taking a conceptual modelling perspective, analyses their major issues as outlined above. It also describes what the most common scenarios for the use of metainformation in Digital Humanities are, presenting a characterization that can assist in the setting of goals for metainformation recording and management in each case. Based on these two aspects, a new approach is proposed for the conceptualization, recording and management of metainformation in the Digital Humanities, using the ConML conceptual modelling language, and adopting the overall view that metainformation is not essentially different to information. The proposal is validated in Digital Humanities scenarios through case studies employing real-world datasets.}
}
@article{MARTENS2025103928,
title = {Conceptualising tourist experience as Gadamerian Erfahrung},
journal = {Annals of Tourism Research},
volume = {111},
pages = {103928},
year = {2025},
issn = {0160-7383},
doi = {https://doi.org/10.1016/j.annals.2025.103928},
url = {https://www.sciencedirect.com/science/article/pii/S0160738325000349},
author = {Hanno Martens and Nigel Jarvis and Clare Weeden},
keywords = {Tourist, Tourist experience, , Gadamer, Hermeneutics},
abstract = {Tourist experience research frequently disregards underlying philosophical debates on experience particularly neglecting the dynamic and subjective processes occurring before, during and after trips. This conceptual paper addresses these limitations by envisaging tourist experience through the Gadamerian hermeneutic approach of Erfahrung, entailing consideration of life experiences and historicity, dynamics of memories as remembering and forgetting, and language and subjective interpretation. The paper guides researchers on what to consider when implementing the alternative tourist experience conceptualisation in their research, discusses changed perspectives on key concepts in tourism and resulting methodological insights. This has major implications for future research on tourist experience providing the growing research area with more dynamic and holistic approaches considering travellers as people and not an economic dimension.}
}
@article{ABRILJIMENEZ2025106603,
title = {Practical deployment and validation of an IoT based semantic interoperability approach for industrial interoperability in smart manufacturing},
journal = {Results in Engineering},
volume = {27},
pages = {106603},
year = {2025},
issn = {2590-1230},
doi = {https://doi.org/10.1016/j.rineng.2025.106603},
url = {https://www.sciencedirect.com/science/article/pii/S2590123025026726},
author = {Patricia Abril-Jimenez and Diego Carvajal-Flores and Leire Bastida and Ana Moya and María Fernanda Cabrera-Umpierrez},
keywords = {Industry 5.0, Interoperability, Web of things, FIWARE, Industrial automation},
abstract = {Industrial 5.0 emphasizes human central, resilient, and sustainable manufacturing. Achieving this vision requires seamless interoperability between various systems on the shop floor, including both automated systems and human workers. However, fragmentation of industrial protocols hampers efficient data exchange, delaying intelligent automation and digitalization. This paper presents SHOP4CF smooth data exchange and intelligent automation vision through the use case validation of the Web of Things Interoperability Layer (WoT-IL) as a solution to bridge the communication gaps between the heterogeneous industrial protocols. everaging FIWARE’s context broker and OpenAPI specifications, WoT-IL enables standardized, semantic interoperability across sensors, PLCs, and higher-level systems. The component was deployed and evaluated in two real-world industrial pilots, demonstrating its ability to reduce manual configuration, enhance system flexibility, and support vendor-agnostic integration. Validation used a structured framework that evaluated functionality, integration, process improvement, human factors, and worker acceptance. Results confirm that WoT-IL significantly improves interoperability and automation readiness, positioning it as a key enabler for scalable, human-aware, and future-proof industrial ecosystems. This position WoT-IL as an enabler to improve automation, reduce system fragmentation, and support a more efficient, connected, and worker-friendly industrial environment.}
}
@article{HUANG2022121,
title = {A novel deep generative model based on imaginal thinking for automating design},
journal = {CIRP Annals},
volume = {71},
number = {1},
pages = {121-124},
year = {2022},
issn = {0007-8506},
doi = {https://doi.org/10.1016/j.cirp.2022.04.053},
url = {https://www.sciencedirect.com/science/article/pii/S0007850622000993},
author = {Lei Huang and Yuehong Yin and Soh Khim Ong},
keywords = {Design method, Machine learning, Deep generative model},
abstract = {Automating design faces a thorny problem: insight modeling based on knowledge and experience. In particular, it is difficult for artificial intelligence to perform incomplete conditional reasoning. The deep generative model (DGM) is an emerging approach of machine learning, which typically uses deep networks to learn from various data sets and synthesize new designs. This paper proposes a novel DGM based on imaginal thinking to realize the creative leap from the invisible functional domain to the concrete physical domain. An experiment is conducted to verify the effectiveness of the proposed model in designing wheels for mobile robots in granular media.}
}
@article{SALIGNON2024110858,
title = {Cactus: A user-friendly and reproducible ATAC-Seq and mRNA-Seq analysis pipeline for data preprocessing, differential analysis, and enrichment analysis},
journal = {Genomics},
volume = {116},
number = {4},
pages = {110858},
year = {2024},
issn = {0888-7543},
doi = {https://doi.org/10.1016/j.ygeno.2024.110858},
url = {https://www.sciencedirect.com/science/article/pii/S088875432400079X},
author = {Jérôme Salignon and Lluís Millan-Ariño and Maxime U. Garcia and Christian G. Riedel},
keywords = {Pipeline, ATAC-Seq, mRNA-Seq, User-friendly, Reproducible, Enrichment analysis, Data integration},
abstract = {The ever decreasing cost of Next-Generation Sequencing coupled with the emergence of efficient and reproducible analysis pipelines has rendered genomic methods more accessible. However, downstream analyses are basic or missing in most workflows, creating a significant barrier for non-bioinformaticians. To help close this gap, we developed Cactus, an end-to-end pipeline for analyzing ATAC-Seq and mRNA-Seq data, either separately or jointly. Its Nextflow-, container-, and virtual environment-based architecture ensures efficient and reproducible analyses. Cactus preprocesses raw reads, conducts differential analyses between conditions, and performs enrichment analyses in various databases, including DNA-binding motifs, ChIP-Seq binding sites, chromatin states, and ontologies. We demonstrate the utility of Cactus in a multi-modal and multi-species case study as well as by showcasing its unique capabilities as compared to other ATAC-Seq pipelines. In conclusion, Cactus can assist researchers in gaining comprehensive insights from chromatin accessibility and gene expression data in a quick, user-friendly, and reproducible manner.}
}
@article{HUANG2024117155,
title = {Identification of endocrine-disrupting chemicals targeting key OP-associated genes via bioinformatics and machine learning},
journal = {Ecotoxicology and Environmental Safety},
volume = {286},
pages = {117155},
year = {2024},
issn = {0147-6513},
doi = {https://doi.org/10.1016/j.ecoenv.2024.117155},
url = {https://www.sciencedirect.com/science/article/pii/S0147651324012314},
author = {Xin-Zhou Huang and He Huang and Hui Chen and Yong-Kun Wei},
keywords = {Osteoporosis, Endocrine-disrupting chemicals, Bioinformatics analysis, Machine learning, Molecular docking},
abstract = {Osteoporosis (OP), a metabolic disorder predominantly impacting postmenopausal women, has seen considerable progress in diagnosis and treatment over the past few decades. However, the intricate interplay between genetic factors and endocrine disruptors (EDCs) in the pathogenesis of OP remains inadequately elucidated. The objective of this research is to examine the environmental pollutants and their regulatory mechanisms that could potentially influence the pathogenesis of OP, in order to establish a theoretical foundation for the targeted prevention and medical management of individuals with OP. Utilizing CTD and GEO datasets, network toxicology and bioinformatics analyses were conducted to identify target genes from a pool of 98 co-associated genes. Subsequently, a novel prediction model was developed employing a multiple machine learning algorithm. The efficacy of the model was validated based on the area under the receiver operating characteristic curve. Finally, real-time quantitative polymerase chain reaction (qRT-PCR) was used to confirm the expression levels of key genes in clinical samples. We have identified significant genes (FOXO3 and LUM) associated with OP and conducted Gene Ontology, Kyoto Encyclopedia of Genes and Genomes enrichment analysis, immune infiltration analysis, and molecular docking analysis. Through the analysis of these key genes, we have identified 13 EDCs that have the potential to impact OP. Several endocrine disruptors, such as Dexamethasone, Perfluorononanoic acid, genistein, cadmium, and bisphenol A, have been identified as notable environmental pollutants that impact the OP. Molecular docking analysis revealed significant binding affinity of major EDCs to the post-translational protein structures of key genes. This study demonstrates that EDCs, including dexamethasone, perfluorononanoic acid, genistein, cadmium, and bisphenol A, can be identified as important environmental pollutants affecting OP, and that FOXO3 and LUM have the potential to be diagnostic markers for OP. These results elucidate a novel association between EDCs regulated by key genes and the onset of OP.}
}
@article{XU2025128584,
title = {LAAP: Learning the Argument of An Entity with Event Prompts for document-level event extraction},
journal = {Neurocomputing},
volume = {613},
pages = {128584},
year = {2025},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2024.128584},
url = {https://www.sciencedirect.com/science/article/pii/S0925231224013559},
author = {Jinghan Xu and Cheng Yang and Xiaojun Kang},
keywords = {Deep learning, Natural Language Processing, Information extraction, Information retrieval, Event extraction},
abstract = {Document-level Event Extraction (DEE) aims to identify event types within a document and extract their corresponding arguments, which is essential for structured information provision in various NLP applications. Unlike sentence-level extraction, DEE requires handling events and arguments scattered across a document. Existing methods often focus on intricate feature interactions, neglecting explicit argument–entity relationships. We introduce a novel method, Learning the Argument of an Entity with Event Prompts (LAAP), which constructs event prompts for type detection, incorporating sentence placeholders to elicit event-specific information. Additionally, we propose an entity argument learning strategy that narrows down entity types to find the most suitable one. Experiments on the ChFinAnn and three other public datasets show that our method surpasses state-of-the-art approaches in accuracy and effectiveness.}
}
@article{ISKAROUS2022101195,
title = {Advancements of phonetics in the 21st century: A critical appraisal of time and space in Articulatory Phonology},
journal = {Journal of Phonetics},
volume = {95},
pages = {101195},
year = {2022},
issn = {0095-4470},
doi = {https://doi.org/10.1016/j.wocn.2022.101195},
url = {https://www.sciencedirect.com/science/article/pii/S0095447022000705},
author = {Khalil Iskarous and Marianne Pouplier},
keywords = {Articulatory Phonology, Task Dynamics, Dynamical systems, π-gesture, Syllable, Prosody, Planning},
abstract = {Articulatory Phonology and Task Dynamics model spoken language mathematically based on dynamical systems, expressing the view that speaking is similar in nature to many other biological phenomena that have been described in this way. In this paper, we present a critical appraisal of developments in Articulatory Phonology and Task Dynamics in the 21st century, illustrating how this point of view addresses some fundamental questions in phonetics. Our paper identifies some of the key areas in which progress has been made, and others in which more progress is warranted. We thereby touch on recent work contributing to the empirical underpinning of some assumptions of the Task Dynamic model, then consider recent proposals of how Articulatory Phonology can deal with linguistically structured macro- and microscopic variation in constriction gestures induced by syllabic and phrasal prosodic structure. Part and parcel of these developments is the integration of the dynamical expression of phonological contrast into a model of utterance planning, and the structuring of the timeflow of speech by prosody. We finish our overview with a discussion on how a stronger link between articulation and acoustics could further enhance the dynamical approach to spoken language.}
}
@incollection{KALLAS2025,
title = {Dictionary Writing Systems},
booktitle = {Reference Module in Social Sciences},
publisher = {Elsevier},
year = {2025},
isbn = {978-0-443-15785-1},
doi = {https://doi.org/10.1016/B978-0-323-95504-1.00688-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780323955041006888},
author = {Jelena Kallas and Arvi Tavast},
keywords = {Lexicography, Dictionary writing system, Data storage, Data exchange, Data presentation},
abstract = {Dictionary Writing Systems (DWS) are specialized tools used in modern lexicography for compiling dictionaries and other lexical resources such as thesauri and vocabularies. Their benefits over the earlier practice of compiling dictionaries in generic office software is modularization and structured data, ensuring consistency and reusability. A wide range of DWSs is available, differing by their license type, data model, customizability and features. This article provides an overview of the main components and features of DWSs related to editing, searching, and publishing of dictionary content. Special attention is given to data storage, presentation, exchange, administration and safety issues.}
}
@article{MOSQUERA2024107492,
title = {Understanding the landscape of software modelling assistants for MDSE tools: A systematic mapping},
journal = {Information and Software Technology},
volume = {173},
pages = {107492},
year = {2024},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2024.107492},
url = {https://www.sciencedirect.com/science/article/pii/S0950584924000971},
author = {David Mosquera and Marcela Ruiz and Oscar Pastor and Jürgen Spielberger},
keywords = {Modelling assistance, Model-driven development, Systematic mapping, State of the practice, Low code, No-code},
abstract = {Context
Model Driven Software Engineering (MDSE) and low-code/no-code software development tools promise to increase quality and productivity by modelling instead of coding software. One of the major advantages of modelling software is the increased possibility of involving diverse stakeholders since it removes the barrier of being IT experts to actively participate in software production processes. From an academic and industry point of view, the main question remains: What has been proposed to assist humans in software modelling tasks?
Objective
In this paper, we systematically elucidate the state of the art in assistants for software modelling and their use in MDSE and low-code/no-code tools.
Method
We conducted a systematic mapping to review the state of the art and answer the following research questions: i) how is software modelling assisted? ii) what goals and limitations do existing modelling assistance proposals report? iii) which evaluation metrics and target users do existing modelling assistance proposals consider? For this purpose, we selected 58 proposals from 3.176 screened records and reviewed 17 MDSE and low-code/no-code tools from main market players published by the Gartner Magic Quadrant.
Result
We clustered existing proposals regarding their modelling assistance strategies, goals, limitations, evaluation metrics, and target users, both in research and practice.
Conclusions
We found that both academic and industry proposals recognise the value of assisting software modelling. However, documentation about MDSE assistants’ limitations, evaluation metrics, and target users is scarce or non-existent. With the advent of artificial intelligence, we expect more assistants for MDSE and low-code/no-code software development will emerge, making imperative the need for well-founded frameworks for designing modelling assistants focused on addressing target users’ needs and advancing the state of the art.}
}
@article{KO2021101620,
title = {Machine learning and knowledge graph based design rule construction for additive manufacturing},
journal = {Additive Manufacturing},
volume = {37},
pages = {101620},
year = {2021},
issn = {2214-8604},
doi = {https://doi.org/10.1016/j.addma.2020.101620},
url = {https://www.sciencedirect.com/science/article/pii/S2214860420309921},
author = {Hyunwoong Ko and Paul Witherell and Yan Lu and Samyeon Kim and David W. Rosen},
keywords = {Additive manufacturability, Data, Design for additive manufacturing, Design rule, Machine learning, Knowledge},
abstract = {Additive Manufacturing (AM) is becoming data-intensive while increasingly generating newly available data. The availability of AM data provides Design for AM (DfAM) with a newfound opportunity to construct AM design rules with improved understanding of AM’s influence on part qualities. To seize the opportunity, this paper proposes a novel approach for AM design rule construction based on machine learning and knowledge graph. First, this paper presents a framework that enables i) deploying machine learning for extracting knowledge on predictive additive manufacturability from data, ii) adopting ontology with knowledge graphs as a knowledge base for storing both a priori and newfound AM knowledge, and iii) reasoning with knowledge for deriving data-driven prescriptive AM design rules. Second, this paper presents a methodology that constructs knowledge on predictive additive manufacturability and prescriptive AM design rules. In the methodology, we formalize knowledge representations, extractions, and reasoning, which enhances automated and autonomous construction and improvements of AM design rules. The methodology then employs a machine learning algorithm of Classification and Regression Tree on measurement data from National Institute of Standards and Technology for construction of a Laser Powder Bed Fusion-specific design rule for overhang features. This work supports AI related decision-making in additive manufacturability analysis and (re-)design for AM and guides machine learning to addressing problems related to AM design rules. This work is also meaningful as it provides sharable AM design rule knowledge with the AM society.}
}
@article{WU2021871,
title = {The Chinese philosophy of information by Kun Wu},
journal = {Journal of Documentation},
volume = {77},
number = {4},
pages = {871-886},
year = {2021},
issn = {0022-0418},
doi = {https://doi.org/10.1108/JD-06-2020-0110},
url = {https://www.sciencedirect.com/science/article/pii/S0022041821000291},
author = {Tianqi Wu and Kaiyan Da},
keywords = {Information theory, Information, Philosophy of information, Chinese philosophy, Information ontology, Kun Wu},
abstract = {Purpose
By introducing the basic concepts and theories of the philosophy of information created by Kun Wu, and making some comparisons of the philosophy of information and related information theories between Wu and other scholars, this paper aims to have Chinese philosophy of information widely known and understood by more people in the world, thus promoting the international exchanges between Chinese and Western scholars on the topic of philosophy of information.
Design/methodology/approach
The main research methods used in this paper are the literature review and the comparative study. On the one hand, it reviews some related concepts and theories in Kun Wu's academic works of philosophy of information. On the other hand, it compares the thoughts and viewpoints of Kun Wu with those of other scholars.
Findings
First, Kun Wu is the first person who has established a complete and comprehensive theoretical system of philosophy of information in China; second, Kun Wu's philosophy of information is significant in originality and value, which could be thought as the intellectual quintessence of information age, thus worth learning. Third, with more international exchanges, Chinese philosophy of information created by Wu will surely be more and more influential in philosophical circles at home and abroad.
Originality/value
It is a very valuable first-hand material for Western scholars to know and understand Chinese philosophy of information.}
}
@article{LIU2019152436,
title = {Identification of core genes and potential molecular mechanisms in breast cancer using bioinformatics analysis},
journal = {Pathology - Research and Practice},
volume = {215},
number = {7},
pages = {152436},
year = {2019},
issn = {0344-0338},
doi = {https://doi.org/10.1016/j.prp.2019.152436},
url = {https://www.sciencedirect.com/science/article/pii/S0344033819300561},
author = {Fei Liu and Yunyan Wu and Yunzhe Mi and Lina Gu and Meixiang Sang and Cuizhi Geng},
keywords = {Breast cancer, Differentially expressed genes, Gene ontology, Kyoto encyclopedia of genes and genomes, Protein–protein interaction, Kaplan–Meier analysis},
abstract = {Background
Breast cancer is the most frequently diagnosed cancer in women worldwide. This study aimed to elucidate the potential key candidate genes and pathways in breast cancer.
Methods
The gene expression profile dataset GSE65212 was downloaded from GEO database. Differentially expressed genes (DEGs) were obtained by the R Bioconductor packages. The Gene ontology (GO) and Kyoto Encyclopedia of Genes and Genomes (KEGG) pathway enrichment analysis of DEGs were performed using DAVID database. The protein–protein interaction (PPI) network was then established by STRING and visualized by Cytoscape software. Module analysis of the PPI network was performed by the plug-in Molecular Complex Detection (MCODE). Then, the identified genes were verified by Kaplan–Meier plotter online database and quantitative real-time PCR (qPCR) in breast cancer tissue samples.
Results
A total of 857 differential expressed genes were identified, of which, the upregulated genes were mainly enriched in the cell cycle, while the downregulated genes were mainly enriched in PPAR signaling pathway. Moreover, six hub genes with high degree were identified, including TOP2A, PCNA, CCNB1, CDC20, BIRC5 and CCNA2. Lastly, the Kaplan–Meier plotter online database confirmed that higher expression levels of these hub genes were related to lower overall survival. Experimental validation showed that all six hub genes had the same expression trend as predicted.
Conclusion
These results identified key genes, which could be used as a new biomarker for breast cancer diagnosis and treatment.}
}
@article{BEURET2025106852,
title = {A generic marine protected area model, challenged by indigenous peoples and local communities: How can the model be adapted or reinvented?},
journal = {Marine Policy},
volume = {181},
pages = {106852},
year = {2025},
issn = {0308-597X},
doi = {https://doi.org/10.1016/j.marpol.2025.106852},
url = {https://www.sciencedirect.com/science/article/pii/S0308597X25002684},
author = {Jean-Eudes Beuret and Anne Cadoret and Newton José Rodrigues {Da Silva}},
keywords = {Biodiversity, Conflict, Conservation, Marine protected area, Political ecology},
abstract = {Many Marine Protected Areas (MPAs) face difficulties of social acceptance. This comparative analysis of 13 MPAs spanning five continents aims to explain these problems by comparing their localization processes in order to identify possible recurring mechanisms. Analyzing their trajectories and the conflicts they cause reveal the existence of a generic model of Marine Protected AreaS which is mostly implicit and applied everywhere. It enables us to identify 7 components of this model: who decides, what legitimizes the decision, the decision’s temporalities and vectors, and then, inside the action modalities, the relationship with the area, with nature, with exchange and the action presentation and organization. Laying bare this model makes it possible to explain the misunderstandings that arise and many acceptance problems that lead to conflict and inefficiency. Based on observations of local adaptations or reinventions of the MPA model, proposals are made for a global overhaul of the model. to make it more flexible and open to multiple ways of thinking about nature and conservation.}
}
@article{XI2024149031,
title = {GRN knockdown regulates the expression and alternative splicing of genes associated with aphasia-related diseases in PC12 cells},
journal = {Brain Research},
volume = {1840},
pages = {149031},
year = {2024},
issn = {0006-8993},
doi = {https://doi.org/10.1016/j.brainres.2024.149031},
url = {https://www.sciencedirect.com/science/article/pii/S0006899324002853},
author = {Yanling Xi and Munire Abuduxiku and Mei Qu},
keywords = {Post-stroke aphasia, GRN, Alternative splicing, Gene expression},
abstract = {Background
Prior research has shown that granulin precursor (GRN, also termed PGRN) is closely linked to aphasia. However, there has been little research on the mechanism of action of GRN in post-stroke aphasia (PSA).
Methods
In this study, RT-qPCR was used to identify variations in gene expression, while RNA sequencing (RNA-seq) was utilized to acquire transcriptional profiles. The Gene Ontology (GO) and Kyoto Encyclopedia of Genes and Genomes (KEGG) databases were employed for bioinformatics analysis.
Results
GRN was considerably more active in PSA subjects. After silencing the GRN, 197 transcripts had differential expression, and 237 alternative splicing events (ASEs) were substantially affected. The analysis of differentially expressed genes (DEGs) using GO and KEGG approaches showed that these genes have various molecular functions and are significantly enriched in metabolic signaling pathways. Regarding Alternative Splicing (AS), the GO and KEGG analyses revealed numerous functional genes involved in transcription and metabolism.
Conclusions
The knockdown of GRN has been shown to be associated with alterations in transcription, metabolism, and ASEs, potentially impacting transcriptional and metabolic pathways through its involvement in AS. Furthermore, GRN knockdown is associated with nervous system disease-related gene transcription and AS processes, as well as its involvement in G protein-coupled receptor (GPCR) and wingless/integrated (Wnt) signaling pathways, which impact the initiation and resolution of PSA.}
}
@article{WOLK2025112883,
title = {Semantic building energy modeling: Analysis across geospatial scales},
journal = {Building and Environment},
volume = {276},
pages = {112883},
year = {2025},
issn = {0360-1323},
doi = {https://doi.org/10.1016/j.buildenv.2025.112883},
url = {https://www.sciencedirect.com/science/article/pii/S0360132325003658},
author = {Samuel Wolk and Christoph Reinhart},
keywords = {Geographic information systems (GIS), Urban building energy modeling (UBEM), Decarbonization, Electrification},
abstract = {Rapid decarbonization of the building sector is critical for mitigating climate change. While simulation-based stock level approaches such as urban building energy modeling (UBEM) help develop carbon reduction plans, they have not reached their full potential convincing individual building owners to act: by relying on archetypes averaged across multiple buildings, UBEM saving predictions can be unreliable at the building-level. Meanwhile, at larger scales, heterogeneity in building stocks requires excessive efforts to accommodate the growing number of archetypes and handle patchworks of geographic information system (GIS) datasets. This paper introduces Semantic Building Energy Modeling (SBEM), a novel framework evolved from UBEMs. It replaces UBEM's static templates with problem-specific semantic building descriptions which are decoupled from model translation layers. By decoupling high-level, human-readable building features from computational representations, SBEM accommodates incomplete or probabilistic data and facilitates coordination between teams, including GIS experts, stock-modeling experts, and software engineers. UBEMs can be seen as a special case of SBEMs appropriate for urban-scale analysis, where SBEMs represent a complementary, augmented set of capabilities. To illustrate the flexibility offered by SBEM, a case study was conducted modeling 2.5 million residential buildings in Massachusetts to assess the economic viability of heat pump adoption. The SBEM approach enables detailed, building-specific analyses, revealing significant variations in economic outcomes based on heating systems and regional characteristics. These insights underscore the importance of semantic granularity for individual homeowner decision-making. By providing a scalable and adaptable framework, SBEM can resolve some existing challenges with UBEMs by allowing consistent model use across scales.}
}
@article{KEDWAN20226564,
title = {NLQ into SQL translation using computational linguistics},
journal = {Journal of King Saud University - Computer and Information Sciences},
volume = {34},
number = {9},
pages = {6564-6582},
year = {2022},
issn = {1319-1578},
doi = {https://doi.org/10.1016/j.jksuci.2022.03.010},
url = {https://www.sciencedirect.com/science/article/pii/S1319157822000945},
author = {Ftoon Kedwan},
keywords = {Natural language processing, Query language, Relational DATABASE, Structured query language, Computational linguistics},
abstract = {This research discusses the implementation experiment of an automatic translation of an unstructured Natural Language Question (NLQ) into a Structured Query Language (SQL) statement. SQL is used as a Relational DataBase (RDB) interaction language with special query syntax and a computer- executable artificial language. This way, DataBase (DB) administrators or general users with little or no SQL querying abilities can perform queries on RDBs in an interactive manner. The main goal of this work is to exploit a manually written rule- based mapping constraints algorithm. This algorithm maps NLQ tokens’ semantic/syntactic information into RDB elements’ semantic roles (i.e., value, attribute) via pairing and matching means. The matching RDB elements, called “identified lexica”, are then mapped into the SQL clauses consistently for SQL generation and execution. The matching process uses a computational linguistic analysis mapping algorithm, represented in the MetaTables. This mapping algorithm proved to be efficient especially with small RDBs with an accuracy of 95% and is about 93% accurate with larger RDBS.}
}
@article{GOULARTE2020105017,
title = {MSC+: Language pattern learning for word sense induction and disambiguation},
journal = {Knowledge-Based Systems},
volume = {188},
pages = {105017},
year = {2020},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2019.105017},
url = {https://www.sciencedirect.com/science/article/pii/S0950705119304253},
author = {Fábio Bif Goularte and Danielly Sorato and Silvia Modesto Nassar and Renato Fileto and Horacio Saggion},
keywords = {Lexical semantics, Information extraction, Linguistic pattern mining, Word sense induction, Word sense disambiguation},
abstract = {Identifying the correct meaning of words in context or discovering new word senses is particularly useful for several tasks such as question answering, information extraction, information retrieval, and text summarization. However, specially in the context of user-generated contents and on-line communication (e.g. Twitter), new meanings are continuously crafted by speakers as the result of existing words being used in novel contexts. Consequently, lexical semantics inventories and systems have difficulties to cope with semantic drifting problems. In this work, we propose an approach to induce and disambiguate word senses of some target words in collections of short texts, such as tweets, through the use of fuzzy lexico-semantic patterns that we define as sequences of Morpho-semantic Components (MSC). We learn these patterns, that we call MSC+ patterns, from text data automatically. Experimental results show that instances of some MSC+ patterns arise in a number of tweets, but sometimes using different words to convey the sense of the respective MSC in some tweets where pattern instances appear. The exploitation of MSC+ patterns when they induce semantics on target words enable effective word sense disambiguation mechanisms leading to improvements in the state of the art.}
}
@article{STORCH201848,
title = {At the fringes of language: On the semiotics of noise},
journal = {Language Sciences},
volume = {65},
pages = {48-57},
year = {2018},
note = {The Sociolinguistics of Everyday Linguistic Creativity},
issn = {0388-0001},
doi = {https://doi.org/10.1016/j.langsci.2017.03.008},
url = {https://www.sciencedirect.com/science/article/pii/S0388000117301766},
author = {Anne Storch},
keywords = {Noise, Unintelligibility, Gendered speech, Voice, Jukun, Nigeria},
abstract = {‘Words and alternative ways of talking […] have served as weapons against oppressive authority, vehicles for solidarity among all manner of disenfranchised peoples, and instruments of extraordinary art’, Ana Cara observes (Cara, A.C. (2011). Creole talk. The poetics and politics of Argentine verbal art. In R. Baron & A.C. Cara (eds.), Creolization as cultural creativity (pp. 198–227). Jackson: University Press of Mississippi). Linguistic creativity doesn't have to be playful and amusing; it can also be about experiences of marginalization, injustice and pain. There are, consequently, different creativities and different indexicalities of creatively manipulated speech. In this article, the focus is on noisy, nonsensical, sometimes unsettling performances of linguistic creativity and on their contexts. These are only slightly different from those Cara refers to – sociolinguistic settings of inequality, based on a history of experiences of othering and subjugation among women in a small northeastern Nigerian village. The artful unmaking of words and meaning that is in the center of this contribution addresses reality in a variety of ways: it aims at evoking ideas and memories of what cannot always be seen and heard (such as spirits), of a performer's feelings of otherness. Noisy and messy communicative practice such as ‘gibberish’, screaming and swearing need to be seen, I argue, as performances rather than as deviations from ‘proper linguistic practice’. They might digress from certain norms, but nevertheless remain interpersonal in their communicative design; they are powerful yet individual and original attempts to reach out to the other, in order to say something which might otherwise not be said. The noisy and unintelligible in language can be an attempt to retrieve what has been discarded and to put the marginal into the center. It is art that intents to remind audiences of the powers of horror, disgust, and ugliness. In practices that highlight linguistic creativity, a particularly radical way of transforming language into such abject art is to make speech (at least initially) incomprehensible, to work with obscurity, noise and disruption. The strategies used in these pieces of art are diverse: utterances are interrupted by made-up speech, and spoken text turns into sung, screamed or murmured text; noise is presented as that what belongs to the Other, and audiences are left with the task not just of listening and evaluating these performances, but also with the task of decoding them. However, noise bears in it the potential of rejection: audiences have to power to decide whether they accept, after all, the invitation to decode whatever meaning the sound of a voice may have.}
}
@article{RALYTE2023102231,
title = {Preface - special issue on conceptual modeling – ER 2022},
journal = {Data & Knowledge Engineering},
volume = {148},
pages = {102231},
year = {2023},
issn = {0169-023X},
doi = {https://doi.org/10.1016/j.datak.2023.102231},
url = {https://www.sciencedirect.com/science/article/pii/S0169023X23000915},
author = {Jolita Ralyté and Manfred Jeusfeld and Mukesh Mohania}
}
@article{CHEN2021182,
title = {Cultural heritage as rural economic development: Batik production amongst China's Miao population},
journal = {Journal of Rural Studies},
volume = {81},
pages = {182-193},
year = {2021},
issn = {0743-0167},
doi = {https://doi.org/10.1016/j.jrurstud.2020.10.024},
url = {https://www.sciencedirect.com/science/article/pii/S0743016720300097},
author = {Zhengfu Chen and Xiaodong Ren and Zaijie Zhang},
keywords = {Cultural heritage, Batik production, Ethnic minority population, Rural economic development, Rooted networks, Development projects, China},
abstract = {Cultural heritage has become a development resource for many rural areas in China driven by developmentalism and capitalism. This article takes handcrafts revival as a case study to demonstrate that how cultural heritage as rural economic development involves various power entanglements and interactions. In this process of development, we see how Miao people use their agency to enact different strategies to react to a multiplicity of circumstances. This research uses Rocheleau's rooted networks framework as a tool but expands the concept based on critical discussion and ambivalent experiences in Danzhai county, Guizhou Province, China. Collecting data from participatory observation, and a series of unstructured and semi-structured interviews in Danzhai, we explore the entangled web of network relations in the process of batik production, and examine how Miao artisans employ their agency to negotiate with different stakeholders and develop a regional batik market. Research demonstrates that making batik weaves Miao people's economic demand, social relations and cultural meaning to form a new social integration mechanism. This mechanism is networked by various relationships in Miao villages including production, distribution, exchange and cooperation. We find that the networks framework allows us to see how powers multiply, but could not explicitly explain some cases and concepts within local knowledge and social contexts. We find that it is necessary to modify Rocheleau's framework in order to incorporate non-western indigenous concepts in China.}
}
@article{STETTER2023109,
title = {Geometric and kinetic digital twin of a body-in-white assembly system for virtual commissioning},
journal = {Procedia CIRP},
volume = {119},
pages = {109-114},
year = {2023},
note = {The 33rd CIRP Design Conference},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2022.12.001},
url = {https://www.sciencedirect.com/science/article/pii/S2212827123004559},
author = {Ralf Stetter and Tobias Grüble and Markus Till},
keywords = {Digital twin, graph-based design languages, digital engineering, model-based systems engineering},
abstract = {Producing companies face enormous challenges due to increasing customer expectations, global competition and sustainability considerations. In recent years, the concept of the digital twin (DT) has found rising attention, because this concept has the potential to enable, amongst others, superior monitoring, process control, diagnosis, traceability and quality control. Additionally, the concept of a DT may intensify the integration of product development, production planning and production, because it is sensible to initiate the creation of the digital twin already in product development and the potential of this concept can only be fully realized if all phases of the system lifecycle are considered. Extensive research has already covered the application of DTs during production operation, but concerning the application in the product design stage many questions remain. The research described in this paper is focused on the question how design automation concepts can contribute to an automated creation of a DT. The paper explains a novel concept for realizing a digital twin. The novel concept is employing an engineering framework based on graph-based design languages. It is applied to an automotive body-in-white assembly system and aims at supporting virtual commissioning. The digital twin includes geometric and kinetic models and simulations and its creation already starts in product development.}
}
@article{BANNOUR20201063,
title = {Case-based Reasoning for Crisis Response: Case Representation and Case Retrieval},
journal = {Procedia Computer Science},
volume = {176},
pages = {1063-1072},
year = {2020},
note = {Knowledge-Based and Intelligent Information & Engineering Systems: Proceedings of the 24th International Conference KES2020},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2020.09.102},
url = {https://www.sciencedirect.com/science/article/pii/S1877050920320020},
author = {Walid Bannour and Ahmed Maalel and Henda Hajjami {Ben Ghezala}},
keywords = {Crisis Response, Emergency Response, Case-based Reasoning, Case Representation, Case Retrieval, Cumulative Prospect Theory},
abstract = {With the multiple occurrences of natural and man-made disasters, supporting emergency decision makers (EDMs) in crisis response is primordial. Case-based reasoning (CBR) is a fitting problem-solving paradigm to solve crisis response issues. The performance of the CBR method depends on the steps of case representation and case retrieval. This paper firstly proposes the use of an ontology in order to represent crisis response cases. Then, it develops a two-stage case retrieval method. This latter firstly matches crisis events in order to generate a set of potential similar cases and then matches crisis impacts to obtain a set of the most similar cases. In addition, the proposed case retrieval method integrates cumulative prospect theory (CPT) in similarity measurement for the purpose of taking into account the psychological behavior of the EDM in the process of case retrieval. Finally, a case study using flood crisis real cases is used to illustrate our proposed method.}
}
@article{PARAMASIVAM20229644,
title = {A survey on textual entailment based question answering},
journal = {Journal of King Saud University - Computer and Information Sciences},
volume = {34},
number = {10, Part B},
pages = {9644-9653},
year = {2022},
issn = {1319-1578},
doi = {https://doi.org/10.1016/j.jksuci.2021.11.017},
url = {https://www.sciencedirect.com/science/article/pii/S1319157821003311},
author = {Aarthi Paramasivam and S. Jaya Nirmala},
keywords = {Natural Language Processing, Question Answering, Textual Entailment},
abstract = {Question answering, an information retrieval system that seeks knowledge, is one of the classic applications in Natural Language Processing. A question answering system comprises numerous sets of subtasks. Some of the subtasks are Passage Retrieval, Answer Ranking, Question Similarity, Question Generation, Question Classification, Answer Selection, and Answer Validation. Numerous approaches have been experimented on in the question answering system to achieve accurate results. One such approach for the question answering system is Textual Entailment. Textual Entailment is a framework that captures significant semantic inference. Textual Entailment of two text fragments can be defined as the task of deciding whether the meaning of one text fragment can be inferred from another text fragment. This survey discusses how and why Textual Entailment is applied to various subtasks in question answering.}
}
@article{MENNENGA2025249,
title = {Interface Design in System of Systems Engineering: Enhancing a Sustainable Circular Economy through Interoperable Business Models},
journal = {Procedia CIRP},
volume = {135},
pages = {249-254},
year = {2025},
note = {32nd CIRP Conference on Life Cycle Engineering (LCE2025)},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2024.12.020},
url = {https://www.sciencedirect.com/science/article/pii/S2212827125002690},
author = {Mark Mennenga and Christopher Dormeier and Zahra Ghazanfarpour and Jan Felix Niemeyer and Sandro Süß and Reza Asghari},
keywords = {System of Systems Engineering, Interoperability, Interface Design, Circular Economy, Business Model, Photovoltaic Panels, Sustainability},
abstract = {Circular Economy (CE) addresses resource scarcity and climate change, requiring collaboration among stakeholders in a dynamic and multi-faceted business environment, which can be understood as a System of Systems (SoS). To ensure seamless interactions and interoperability, a key challenge is designing the SoS architecture, particularly the interfaces between interconnected business models. This research highlights the importance of interface design in SoS Engineering (SoSE) to enable desirable emergent functionalities, like circularity. We conduct a systematic literature review to identify key interoperability and interface design approaches, proposing a contract-based, multi-level, multi-perspective framework to support circular system engineering. The case of a CE of photovoltaic panels illustrates the potential benefits for the engineering of circular systems and the business model design of a focal company.}
}
@article{ZHANG201873,
title = {Web service discovery based on goal-oriented query expansion},
journal = {Journal of Systems and Software},
volume = {142},
pages = {73-91},
year = {2018},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2018.04.046},
url = {https://www.sciencedirect.com/science/article/pii/S0164121218300748},
author = {Neng Zhang and Jian Wang and Yutao Ma and Keqing He and Zheng Li and Xiaoqing (Frank) Liu},
keywords = {Web service, Service discovery, Service-based system (SBS), Service goal knowledge, Query expansion},
abstract = {With the broad adoption of service-oriented architecture, many software systems have been developed by composing loosely-coupled Web services. Service discovery, a critical step of building service-based systems (SBSs), aims to find a set of candidate services for each functional task to be performed by an SBS. The keyword-based search technology adopted by existing service registries is insufficient to retrieve semantically similar services for queries. Although many semantics-aware service discovery approaches have been proposed, they are hard to apply in practice due to the difficulties in ontology construction and semantic annotation. This paper aims to help service requesters (e.g., SBS designers) obtain relevant services accurately with a keyword query by exploiting domain knowledge about service functionalities (i.e., service goals) mined from textual descriptions of services. We firstly extract service goals from services’ textual descriptions using an NLP-based method and cluster service goals by measuring their semantic similarities. A query expansion approach is then proposed to help service requesters refine initial queries by recommending similar service goals. Finally, we develop a hybrid service discovery approach by integrating goal-based matching with two practical approaches: keyword-based and topic model-based. Experiments conducted on a real-world dataset show the effectiveness of our approach.}
}
@article{GREAVES2023104048,
title = {A history of violence; exploring Lebanese university faculty mental health and professional lived experiences following the 4th of August 2020 port blast},
journal = {Teaching and Teacher Education},
volume = {125},
pages = {104048},
year = {2023},
issn = {0742-051X},
doi = {https://doi.org/10.1016/j.tate.2023.104048},
url = {https://www.sciencedirect.com/science/article/pii/S0742051X23000367},
author = {Morten Greaves and Rima Bahous},
keywords = {Emergency education, Tertiary education, Lived experience, Mental health, Online learning},
abstract = {This qualitative research uses lived experience data to explore the mental health and professional experiences of faculty members in the education department of an English language university in Beirut, following the August 4, 2020 Beirut port blast. The data shows how our participants managed adverse mental health issues, while simultaneously re-engaging with teaching in the aftermath of the explosion. The study concludes that university emergency plans should aim to provide continuous professional development for faculty; utilize unambiguous language in cross-university communications; and offer personalized psychosocial support strategies for staff and students alike.}
}
@article{WANG2025103755,
title = {Formalized representation of eco-design rules for additive manufacturing design advisor system},
journal = {Advanced Engineering Informatics},
volume = {68},
pages = {103755},
year = {2025},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2025.103755},
url = {https://www.sciencedirect.com/science/article/pii/S1474034625006482},
author = {Yanan Wang and Tao Peng and Yi Xiong and Samyeon Kim and Renzhong Tang},
keywords = {Sustainability, Design for additive manufacturing, Eco-design, Rule representation, Design advisor system},
abstract = {Sustainability has emerged as one of the most critical requirements in product design. Additive Manufacturing (AM), characterized by advantages such as design flexibility, economic low-volume customization, and reduced material waste, holds significant potential to enhance product sustainability performance from a life cycle perspective. Design for additive manufacturing (DfAM) is thereby an essential topic to leverage such potentials, which needs intelligent AM design advisor systems to assist designers in making informative decisions. While a few of system that support decisions in DfAM processes have been developed, their functions do not effectively address eco-design requirements in practical applications. The main challenge is the lack of accessible sustainability-related knowledge in the system to inform designers in various eco-design tasks such as sustainable material selection, lightweight structure design, and support material optimization. These tasks involve three different DfAM stages: conceptual, embodiment, and detail stages. Existing AM-related research has documented eco-design guidelines, either process-specific or task-specific. However, these guidelines are often presented in inconsistent formats, making them difficult for designers to interpret and for software systems to reuse directly. To address this issue, this study aims to establish a formalized representation of eco-design rules (EDRs) that enables system to reason and generate design advice related to sustainability. A three-layer framework, consisting of a raw knowledge layer, a semantic model layer, and a formalized rule layer, is then proposed to transform existing text-based eco-design guidelines with multi-dimensional product information into a formalized, human–machine equally readable EDRs representation. This formalized representation ensures that the rules are consistent, reusable, extendable, and computable. A rule-based AM eco-design advisor system is then developed to illustrate the application mechanism of the formalized EDRs within the system. Case studies involving the design of a hydraulic manifold fabricated by AM were conducted, where decision-making guidance in two eco-design tasks demonstrated the practical application of these formalized rules. The results indicate that the proposed formalized representation of EDRs enables the design system to provide valuable eco-design advice for designers in various tasks within three different DfAM stages, thereby significantly contributing to achieving sustainability in AM-fabricated products.}
}
@article{CHEN2024101985,
title = {A knowledge graph-supported information fusion approach for multi-faceted conceptual modelling},
journal = {Information Fusion},
volume = {101},
pages = {101985},
year = {2024},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2023.101985},
url = {https://www.sciencedirect.com/science/article/pii/S1566253523003019},
author = {Zheyuan Chen and Yuwei Wan and Ying Liu and Agustin Valera-Medina},
keywords = {Information integration, Multi-faceted modelling, Knowledge graph-supported data fusion},
abstract = {It has become progressively more evident that a single data source is unable to comprehensively capture the variability of a multi-faceted concept, such as product design, driving behaviour or human trust, which has diverse semantic orientations. Therefore, multi-faceted conceptual modelling is often conducted based on multi-sourced data covering indispensable aspects, and information fusion is frequently applied to cope with the high dimensionality and data heterogeneity. The consideration of intra-facets relationships is also indispensable. In this context, a knowledge graph (KG), which can aggregate the relationships of multiple aspects by semantic associations, was exploited to facilitate the multi-faceted conceptual modelling based on heterogeneous and semantic-rich data. Firstly, rules of fault mechanism are extracted from the existing domain knowledge repository, and node attributes are extracted from multi-sourced data. Through abstraction and tokenisation of existing knowledge repository and concept-centric data, rules of fault mechanism were symbolised and integrated with the node attributes, which served as the entities for the concept-centric knowledge graph (CKG). Subsequently, the transformation of process data to a stack of temporal graphs was conducted under the CKG backbone. Lastly, the graph convolutional network (GCN) model was applied to extract temporal and attribute correlation features from the graphs, and a temporal convolution network (TCN) was built for conceptual modelling using these features. The effectiveness of the proposed approach and the close synergy between the KG-supported approach and multi-faceted conceptual modelling is demonstrated and substantiated in a case study using real-world data.}
}
@article{DIMITSAKI2024,
title = {Applying AI to Structured Real-World Data for Pharmacovigilance Purposes: Scoping Review},
journal = {Journal of Medical Internet Research},
volume = {26},
year = {2024},
issn = {1438-8871},
doi = {https://doi.org/10.2196/57824},
url = {https://www.sciencedirect.com/science/article/pii/S1438887124010094},
author = {Stella Dimitsaki and Pantelis Natsiavas and Marie-Christine Jaulent},
keywords = {pharmacovigilance, drug safety, artificial intelligence, machine learning, real-world data, scoping review},
abstract = {Background
Artificial intelligence (AI) applied to real-world data (RWD; eg, electronic health care records) has been identified as a potentially promising technical paradigm for the pharmacovigilance field. There are several instances of AI approaches applied to RWD; however, most studies focus on unstructured RWD (conducting natural language processing on various data sources, eg, clinical notes, social media, and blogs). Hence, it is essential to investigate how AI is currently applied to structured RWD in pharmacovigilance and how new approaches could enrich the existing methodology.
Objective
This scoping review depicts the emerging use of AI on structured RWD for pharmacovigilance purposes to identify relevant trends and potential research gaps.
Methods
The scoping review methodology is based on the PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) methodology. We queried the MEDLINE database through the PubMed search engine. Relevant scientific manuscripts published from January 2010 to January 2024 were retrieved. The included studies were “mapped” against a set of evaluation criteria, including applied AI approaches, code availability, description of the data preprocessing pipeline, clinical validation of AI models, and implementation of trustworthy AI criteria following the guidelines of the FUTURE (Fairness, Universality, Traceability, Usability, Robustness, and Explainability)-AI initiative.
Results
The scoping review ultimately yielded 36 studies. There has been a significant increase in relevant studies after 2019. Most of the articles focused on adverse drug reaction detection procedures (23/36, 64%) for specific adverse effects. Furthermore, a substantial number of studies (34/36, 94%) used nonsymbolic AI approaches, emphasizing classification tasks. Random forest was the most popular machine learning approach identified in this review (17/36, 47%). The most common RWD sources used were electronic health care records (28/36, 78%). Typically, these data were not available in a widely acknowledged data model to facilitate interoperability, and they came from proprietary databases, limiting their availability for reproducing results. On the basis of the evaluation criteria classification, 10% (4/36) of the studies published their code in public registries, 16% (6/36) tested their AI models in clinical environments, and 36% (13/36) provided information about the data preprocessing pipeline. In addition, in terms of trustworthy AI, 89% (32/36) of the studies followed at least half of the trustworthy AI initiative guidelines. Finally, selection and confounding biases were the most common biases in the included studies.
Conclusions
AI, along with structured RWD, constitutes a promising line of work for drug safety and pharmacovigilance. However, in terms of AI, some approaches have not been examined extensively in this field (such as explainable AI and causal AI). Moreover, it would be helpful to have a data preprocessing protocol for RWD to support pharmacovigilance processes. Finally, because of personal data sensitivity, evaluation procedures have to be investigated further.}
}
@article{LEWONIEWSKI20233977,
title = {Understanding the Use of Scientific References in Multilingual Wikipedia across Various Topics},
journal = {Procedia Computer Science},
volume = {225},
pages = {3977-3986},
year = {2023},
note = {27th International Conference on Knowledge Based and Intelligent Information and Engineering Sytems (KES 2023)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2023.10.393},
url = {https://www.sciencedirect.com/science/article/pii/S187705092301551X},
author = {Włodzimierz Lewoniewski and Krzysztof Węcel and Witold Abramowicz},
keywords = {Wikipedia, references, information sources, DBpedia, Wikidata, WikiProject, topic classification},
abstract = {To maintain information quality, Wikipedia articles are required to be based on reliable sources that readers can verify. However, assessing the reliability of sources is subjective and can vary depending on the language and topic. As a result, different language versions of Wikipedia may have their own criteria for determining the credibility of sources. Some Wikipedia references point to scientific sources that are generally considered more reliable than websites because they are subject to a rigorous peer review process and are published by reputable academic publishers. This means that the information presented in scientific sources has been thoroughly evaluated by experts in the relevant field, ensuring a higher degree of accuracy and credibility. In this study, we analyzed 325 million references from 60 million Wikipedia articles in 310 language versions to find scientific sources of information. Additionally, we divided the articles into different topics using three approaches: Wikipedia Projects, Wikidata and DBpedia. This allowed us to find and compare Sci score of each language version of Wikipedia and the topic.}
}
@article{LIU20233267,
title = {Physiological Dynamics and Transcriptomic Analysis of Cut Roses ‘Carola’ Treated with KNO3},
journal = {Phyton-International Journal of Experimental Botany},
volume = {92},
number = {12},
pages = {3267-3290},
year = {2023},
issn = {0031-9457},
doi = {https://doi.org/10.32604/phyton.2023.045453},
url = {https://www.sciencedirect.com/science/article/pii/S0031945723000060},
author = {Songmei Liu and Yuheng Wu and Hongmei Li and Dongli Cai and Huiling Liang and Changchun Ye and Shenggen He},
keywords = {Cut rose, stomatal opening, KNO, transcriptome, water loss},
abstract = {The consumption of cut roses (Rosa hybrida) has always ranked first in the world. However, it is vulnerable to rapid petal and leaf wilting due to leaf stomatal water loss, which seriously affects its ornamental quality and economic value. Stomatal movement, a key in plant physiological processes, is influenced by potassium and nitrate. Advancing comprehension of its physiological and molecular mechanism holds promise for preserving the freshness of cut roses. This study observed the impacts of different concentrations of KNO3 vase treatments on stomatal opening and water loss in cut rose ‘Carola’ leaves, as well as their transcriptional responses to KNO3. Water loss rates were influenced by KNO3 concentrations, with the 25 and 75 mmol/L treatments exhibiting the highest water loss rates. The stomatal aperture reached its widest value when treated with 75 mmol/L KNO3. Transcriptional sequencing analysis was performed to identify differentially expressed genes (DEGs) of which 5456 were up-regulated, and 6607 were down-regulated associated with photosynthesis, starch and sucrose metabolism, metabolic pathways, plant-pathogen interaction, plant hormone signal transduction, and related pathways. 246 DEGs were selected related to response to KNO3 treatment, of which gene ontology (GO) enrichment were nitrate and terpenoid metabolism, ion transport, and response to stimuli. Further heatmap analysis revealed that several genes related to nitrate transport a metabolism, K+ transport, vacuoles, and aquaporin were in close association with the response to KNO3 treatment. Weighted gene co-expression network analysis (WGCNA) revealed that hub genes, including LAX2, TSJT1, and SCPL34 were identified in turquoise, black, and darkgreen module. Transcription factors such as NAC021, CDF3, ERF053, ETR2, and ARF6 exhibited regulatory roles in the response to KNO3 treatment under light conditions. These findings provide valuable insights into the physiological and molecular mechanisms underlying the response of cut rose leaves to KNO3 treatment.}
}
@article{ZOMORODI2024102981,
title = {RECOMED: A comprehensive pharmaceutical recommendation system},
journal = {Artificial Intelligence in Medicine},
volume = {157},
pages = {102981},
year = {2024},
issn = {0933-3657},
doi = {https://doi.org/10.1016/j.artmed.2024.102981},
url = {https://www.sciencedirect.com/science/article/pii/S0933365724002239},
author = {Mariam Zomorodi and Ismail Ghodsollahee and Jennifer H Martin and Nicholas J Talley and Vahid Salari and Paweł Pławiak and Kazem Rahimi and U.R. Acharya},
keywords = {Recommendation system, Drug recommendation system, Drug information extraction, Hybrid recommendation method},
abstract = {Objectives
To build datasets containing useful information from drug databases and recommend a list of drugs to physicians and patients with high accuracy by considering a wide range of features of people, diseases, and chemicals.
Methods
A comprehensive pharmaceutical recommendation system was designed based on the features of people, diseases, and medicines extracted from two major drug databases and the created datasets of patients and drug information. Then, the recommendation was given based on recommender system algorithms using patient and caregiver ratings and the knowledge obtained from drug specifications and interactions. Sentiment analysis was employed by natural language processing approaches in pre-processing, along with neural network-based methods and recommender system algorithms for modelling the system. Patient conditions and medicine features were used to make two models based on matrix factorization. Then, we used drug interaction criteria to filter drugs with severe or mild interactions with other drugs. We developed a deep learning model for recommending drugs using data from 2304 patients as a training set and 660 patients as our validation set. We used knowledge from drug information and combined the model's outcome into a knowledge-based system with the rules obtained from constraints on taking medicine.
Results
Our recommendation system can recommend an acceptable combination of medicines similar to the existing prescriptions available in real life. Compared with conventional matrix factorization, our proposed model improves the accuracy, sensitivity, and hit rate by 26 %, 34 %, and 40 %, respectively. In addition, it improves the accuracy, sensitivity, and hit rate by an average of 31 %, 29 %, and 28 % compared to other machine learning methods. We have open-sourced our implementation in Python.
Conclusion
Compared to conventional machine learning approaches, we obtained average accuracy, sensitivity, and hit rates of 31 %, 29 %, and 28 %, respectively. Compared to conventional matrix factorisation our proposed method improved the accuracy, sensitivity, and hit rate by 26 %, 34 %, and 40 %, respectively. However, it is acknowledged that this is not the same as clinical accuracy or sensitivity, and more accurate results can be obtained by gathering larger datasets.}
}
@article{FLETCHER2019112553,
title = {Circularity, psychiatry & biomarkers: The operationalisation of Alzheimer's & stress in research},
journal = {Social Science & Medicine},
volume = {239},
pages = {112553},
year = {2019},
issn = {0277-9536},
doi = {https://doi.org/10.1016/j.socscimed.2019.112553},
url = {https://www.sciencedirect.com/science/article/pii/S0277953619305477},
author = {James Rupert Fletcher and Rasmus Hoffman Birk},
keywords = {Biomarkers, Circularity, Gestalt, Alzheimer's, Amyloid, Stress, Cortisol},
abstract = {This paper analyses the use of biomarkers in contemporary psychiatric research, arguing that this research has problems of circularity. Focusing on the specific cases of Alzheimer's disease and stress research, we show how these fields have a circular usage of two biomarkers - amyloid-beta and cortisol respectively. We argue that the resulting circularity can be understood as a case of ontological gestalt switching, wherein one object (e.g. Alzheimer's disease) is switched with an object that differs in some way (e.g. protein aggregation). Such circularity can impede research because it entails stripping away important specificities, whereby characteristics that are not directly shared between two switched objects are inevitably forfeited. The losing of specificities can exacerbate discrepancies between illness and disease and lead to the homogenisation of diverse populations and disease subtypes, as has been shown to hamper Alzheimer's research. In response, we suggest that the use of biomarkers in psychiatric research should be subject to guidelines, under which such practices must be articulated in a simplified vocabulary that encourages reflexivity regarding potential instances of circularity.}
}
@article{BHAGWAT2021243,
title = {A systematic review of construction safety research: quantitative and qualitative content analysis approach},
journal = {Built Environment Project and Asset Management},
volume = {12},
number = {2},
pages = {243-261},
year = {2021},
issn = {2044-124X},
doi = {https://doi.org/10.1108/BEPAM-04-2021-0068},
url = {https://www.sciencedirect.com/science/article/pii/S2044124X21000238},
author = {Kishor Bhagwat and Venkata Santosh Kumar Delhi},
keywords = {Construction safety, Safety management, Literature review, Content analysis},
abstract = {Purpose
Construction safety management (CSM) has been intensively researched in the last four decades but hitherto mostly aimed at understanding root causes of accidents, recommending preventive measures and evaluating their implications. However, a systematic effort to present a comprehensive picture of construction safety research is hardly witnessed. Therefore, the study aims to investigate construction safety research contributors, ontologies, themes, evolution, emerging trends and future directions using quantitative and qualitative content analysis.
Design/methodology/approach
A total of 877 journal articles were extracted using preferred reporting items for systematic reviews and meta-analyses (PRISMA) guidelines and Scopus literature database and were analyzed using VOSviewer and Nvivo tools to present a comprehensive picture of the CSM body of knowledge.
Findings
The study observed rapid growth in construction safety research with contributions from various countries, organizations and researchers. This study identified 3 research levels, 8 project phases, 10 project types, 6 research instruments and 19 research data sources along with their usage in the research domain. Further, the study identified 13 emerging research themes, 4 emerging research trends and an observed paradigm shift from reactive to proactive CSM approach.
Research limitations/implications
The comprehensive study on the emerging themes and findings on proactive CSM has strategic implications to practice to incorporate safety. The identified future directions can assist researchers in bridging the existing gaps and strengthening emerging research trends.
Originality/value
The study presents a comprehensive picture of the CSM body of knowledge using the content analysis approach that was absent in past literature and opened future research avenues.}
}
@article{JIANG2023149,
title = {Unveiling the Time Course Mechanism of Bone Fracture Healing by Transcriptional Profiles},
journal = {Combinatorial Chemistry & High Throughput Screening},
volume = {26},
number = {1},
pages = {149-162},
year = {2023},
issn = {1386-2073},
doi = {https://doi.org/10.2174/1386207325666220412134311},
url = {https://www.sciencedirect.com/science/article/pii/S1386207323000320},
author = {Tong-Meng Jiang},
keywords = {Bone fracture healing, hematoma formation, callus formation, callus molding, mature lamellar bone formation, bioinformatics},
abstract = {Background
Bone fracture healing is a time-consuming and high-priority orthopedic problem worldwide.
Objective
Discovering the potential mechanism of bone healing at a time course and transcriptional level may better help manage bone fracture.
Methods
In this study, we analyze a time-course bone fracture healing transcriptional dataset in a rat model (GSE592, GSE594, and GSE1371) of Gene Expression Omnibus (GEO). RNA was obtained from female Sprague-Dawley rats with a femoral fracture at the initial time (day 3) as well as early (week 1), middle (week 2), and late (week 4) time periods, with nonfracture rats used as control. Gene Ontology (GO) functional analysis and pathway examinations were performed for further measurements of GSEA and hub genes.
Results
Results indicated that the four stages of bone fracture healing at the initial, early, middle, and late time periods represent the phases of hematoma formation, callus formation, callus molding, and mature lamellar bone formation, respectively. Extracellular organization was positively employed throughout the four stages. At the hematoma formation phase, the muscle contraction process was downregulated. Antibacterial peptide pathway was downregulated at all phases. The upregulation of Fn1 (initial, early, middle, and late time periods), Col3a1 (initial, early, and middle time periods), Col11a1 (initial and early time periods), Mmp9 (middle and late time periods), Mmp13 (early, middle, and late time periods) and the downregulation of RatNP-3b (initial, early, middle, and late time periods) were possible symbols for bone fracture healing and may be used as therapeutic targets.
Conclusion
These findings suggest some new potential pathways and genes in the process of bone fracture healing and further provide insights that can be used in targeted molecular therapy for bone fracture healing.}
}
@article{LARAHERNANDEZ2023104854,
title = {Emergent temporary appropriation versus lockdown regulations: The case of Venice},
journal = {Sustainable Cities and Society},
volume = {99},
pages = {104854},
year = {2023},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2023.104854},
url = {https://www.sciencedirect.com/science/article/pii/S2210670723004651},
author = {Jose Antonio Lara-Hernandez},
keywords = {Temporary appropriation, Sense of community, Assemblage theory, Agential realism, Venice},
abstract = {This paper explores the nexus between temporary appropriation (TA) and the sense of community (SOC) in the context of Venice, Italy. Inspired by an agential realism and diffractive methodology, it focuses on spatial material composition of matter, examining the emergent assemblage of TA and its role in enhancing SOC. The findings reveal the interplay between cultural, legal, and built-environment factors in shaping TA opportunities. The human-scale and fractal design of Venice, the coexistence of various legal and customary laws, and the social bonds amongst residents contribute to the emergence of TA, fostering a strong sense of community. It selects Sestiere Santa Croce, examining the laws set out by the Italian government which regulate public space's use during the last pandemic lockdown. The study emphasises the temporal dimension, highlighting the dynamic relationships and intra-actions amongst these elements. However, limitations such as a small sample size and contextual specificity to Venice are acknowledged. By understanding and harnessing the potential of TA, architects, urban designers and policymakers can create more inclusive and vibrant public spaces that promote social resilience. This research contributes to alternative ways of knowing and understanding the world, calling for interdisciplinary approaches to analyse urban dynamics and community development.}
}
@article{MITCHELL2022102276,
title = {Bioinformatic prediction of putative conveyers of O-GlcNAc transferase intellectual disability},
journal = {Journal of Biological Chemistry},
volume = {298},
number = {9},
pages = {102276},
year = {2022},
issn = {0021-9258},
doi = {https://doi.org/10.1016/j.jbc.2022.102276},
url = {https://www.sciencedirect.com/science/article/pii/S0021925822007189},
author = {Conor W. Mitchell and Ignacy Czajewski and Daan M.F. {van Aalten}},
keywords = {O-GlcNAc, neurodevelopment, intellectual disability, bioinformatics, glycobiology, cell signaling, gene expression},
abstract = {Protein O-GlcNAcylation is a dynamic posttranslational modification that is catalyzed by the enzyme O-GlcNAc transferase (OGT) and is essential for neurodevelopment and postnatal neuronal function. Missense mutations in OGT segregate with a novel X-linked intellectual disability syndrome, the OGT congenital disorder of glycosylation (OGT-CDG). One hypothesis for the etiology of OGT-CDG is that loss of OGT activity leads to hypo-O-GlcNAcylation of as yet unidentified, specific neuronal proteins, affecting essential embryonic, and postnatal neurodevelopmental processes; however, the identity of these O-GlcNAcylated proteins is not known. Here, we used bioinformatic techniques to integrate sequence conservation, structural data, clinical data, and the available literature to identify 22 candidate proteins that convey OGT-CDG. We found using gene ontology and PANTHER database data that these candidate proteins are involved in diverse processes including Ras/MAPK signaling, translational repression, cytoskeletal dynamics, and chromatin remodeling. We also identify pathogenic missense variants at O-GlcNAcylation sites that segregate with intellectual disability. This work establishes a preliminary platform for the mechanistic dissection of the links between protein O-GlcNAcylation and neurodevelopment in OGT-CDG.}
}
@article{GARG2025112969,
title = {ATSumm: Auxiliary information enhanced approach for abstractive disaster tweet summarization with sparse training data},
journal = {Knowledge-Based Systems},
volume = {311},
pages = {112969},
year = {2025},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2025.112969},
url = {https://www.sciencedirect.com/science/article/pii/S0950705125000176},
author = {Piyush Kumar Garg and Roshni Chakraborty and Sourav Kumar Dandapat},
keywords = {Disasters, Abstractive summarization, Social media, Crisis scenario, Pointer generator network model, Deep learning, Data sparsity},
abstract = {The abundance of situational information on Twitter poses a challenge for users to manually discern vital and relevant information during disasters. A concise and human-interpretable overview of this information can aid decision makers implement efficient and quick disaster responses. Existing abstractive summarization approaches can be categorized as sentence- or key-phrase-based. This study focused on a sentence-based approach, which is typically implemented as a dual-phase procedure. The initial phase, known as the extractive phase, involves the identification of the most relevant tweets. The subsequent phase, which is referred to as the abstractive phase, generates a more human-interpretable summary. In this study, we adopted a methodology from prior research for the extractive phase. Most existing approaches employ deep learning-based frameworks for the abstractive phase of summarization. Such frameworks can either be pre-trained or require training from scratch. However, to achieve an appropriate level of performance, it is imperative to have substantial training data for both methods, which are not readily available. This study proposed an abstractive tweet summarizer (ATSumm) that effectively addresses the issue of data sparsity using auxiliary information. We introduced the auxiliary pointer generator network (AuxPGN) model, which utilizes a unique attention mechanism called key-phrase attention. This attention mechanism incorporates auxiliary information in the form of key-phrases and their corresponding importance scores from the input tweets. We evaluated the proposed approach through comparisons with 10 state-of-the-art approaches across 13 disaster datasets. The evaluation results indicated that ATSumm achieved superior performance compared with state-of-the-art approaches, with an improvement of 4−80% in the ROUGE-N F1-score.}
}
@article{ALI2020208,
title = {A smart healthcare monitoring system for heart disease prediction based on ensemble deep learning and feature fusion},
journal = {Information Fusion},
volume = {63},
pages = {208-222},
year = {2020},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2020.06.008},
url = {https://www.sciencedirect.com/science/article/pii/S1566253520303055},
author = {Farman Ali and Shaker El-Sappagh and S.M. Riazul Islam and Daehan Kwak and Amjad Ali and Muhammad Imran and Kyung-Sup Kwak},
keywords = {Feature extraction, Feature fusion, Heart disease prediction, Deep learning, Ontology},
abstract = {The accurate prediction of heart disease is essential to efficiently treating cardiac patients before a heart attack occurs. This goal can be achieved using an optimal machine learning model with rich healthcare data on heart diseases. Various systems based on machine learning have been presented recently to predict and diagnose heart disease. However, these systems cannot handle high-dimensional datasets due to the lack of a smart framework that can use different sources of data for heart disease prediction. In addition, the existing systems utilize conventional techniques to select features from a dataset and compute a general weight for them based on their significance. These methods have also failed to enhance the performance of heart disease diagnosis. In this paper, a smart healthcare system is proposed for heart disease prediction using ensemble deep learning and feature fusion approaches. First, the feature fusion method combines the extracted features from both sensor data and electronic medical records to generate valuable healthcare data. Second, the information gain technique eliminates irrelevant and redundant features, and selects the important ones, which decreases the computational burden and enhances the system performance. In addition, the conditional probability approach computes a specific feature weight for each class, which further improves system performance. Finally, the ensemble deep learning model is trained for heart disease prediction. The proposed system is evaluated with heart disease data and compared with traditional classifiers based on feature fusion, feature selection, and weighting techniques. The proposed system obtains accuracy of 98.5%, which is higher than existing systems. This result shows that our system is more effective for the prediction of heart disease, in comparison to other state-of-the-art methods.}
}
@article{BAYRAKTAR2025110467,
title = {Enhancing drug-drug interaction classification by leveraging textual drug arguments},
journal = {Computers in Biology and Medicine},
volume = {194},
pages = {110467},
year = {2025},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2025.110467},
url = {https://www.sciencedirect.com/science/article/pii/S0010482525008182},
author = {Kivanc Bayraktar and Ebru Akcapinar Sezer and Begum Mutlu and Suat Özdemir},
keywords = {Classification of drug-drug interaction, Text embedding, Neural network, DrugBank},
abstract = {Background:
The accurate identification and classification of drug-drug interactions (DDIs) are critical for ensuring patient safety and optimizing treatment outcomes in modern healthcare. Traditional methods for DDI classification primarily focus on analyzing the chemical properties and pharmacological data of drugs.
Methods:
This study introduces a novel methodology that incorporates textual arguments from DrugBank in addition to the conventional reliance on chemical properties. It explored the impact of integrating text embeddings and text-based similarity matrices alongside the existing chemical properties. To achieve this, types and concepts extracted from the Unified Medical Language System (UMLS), as well as entities, were utilized to create similarity matrices as new input features. The impact of these features was evaluated through a series of experiments conducted across various implementation scenarios by utilizing a deep neural network.
Results:
The results highlighted the most discriminative feature types and demonstrated the overall contribution of the proposed approach to the existing literature. The code and associated resources for this study are available for download at the following link: https://github.com/kivancbayraktar/enhancing-ddi-classification-via-textual-arguments.}
}
@article{ZHAO2025101780,
title = {Developing an innovative design model for Xinjiang brocades based on design thinking},
journal = {Thinking Skills and Creativity},
volume = {56},
pages = {101780},
year = {2025},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2025.101780},
url = {https://www.sciencedirect.com/science/article/pii/S187118712500029X},
author = {Yu Zhao and Zhou Li and Wenliang Li and Zirui Huang},
keywords = {Innovative design model, Xinjiang brocades, Design Thinking (DT), Action Design Research (ADR)},
abstract = {The Xinjiang brocade as a significant cultural textile records the historical and cultural information. Public awareness of this cultural heritage often involves related product development efforts. However, the current development of Xinjiang brocades faces challenges, including insufficient refinement of design elements and a lack of sustainable innovation methods. To address these issues, this study proposed a Xinjiang Brocade Innovative Design Model by applying design thinking (DT). The DT process for the Xinjiang Brocade Innovative Design Model was first constructed in terms of applying Action Design Research (ADR). In addition, primary issues of Xinjiang Brocade Innovative Design were identified by applying Empathize Map and Delphi Method. The prototype for Xinjiang Brocade Innovative Design was then obtained through brainstorming, Adobe Experience Design, and so on. Moreover, the application of this Xinjiang Brocade Innovative Design Model was conducted with developing a Xinjiang brocade innovative design system, and it was validated. The results show the effectiveness of the Xinjiang Brocade Innovative Design Model, which not only organizes the knowledge and product information of existing Xinjiang brocades but also facilitates innovative customization, thereby enhancing user satisfaction.}
}
@article{HAGHRAH2025102146,
title = {PyIT2FLS: An open-source Python framework for flexible and scalable development of type 1 and interval type 2 fuzzy logic models},
journal = {SoftwareX},
volume = {30},
pages = {102146},
year = {2025},
issn = {2352-7110},
doi = {https://doi.org/10.1016/j.softx.2025.102146},
url = {https://www.sciencedirect.com/science/article/pii/S235271102500113X},
author = {Amir Arslan Haghrah and Sehraneh Ghaemi and Mohammad Ali Badamchizadeh},
keywords = {Fuzzy logics, Soft computing, Computational intelligence, Decision-making systems, Open-source software, Python},
abstract = {Fuzzy set theory and fuzzy logic have become essential tools for converting expert knowledge into mathematical models and extracting meaningful insights from numerical data. Despite their wide application, a comprehensive and integrated tool for fuzzy logic development in Python has been lacking. To address this gap, we developed PyIT2FLS, an open-source framework for creating both Type-1 and Interval Type-2 fuzzy logic models. In addition to supporting a broad range of membership functions, t-norms, s-norms, and fuzzy operators, and facilitating the development of TSK and Mamdani systems, PyIT2FLS distinguishes itself from other toolkits by offering an easy integration of optimization algorithms, such as meta-heuristic techniques, for efficiently tuning fuzzy system parameters. This comprehensive toolkit bridges the divide between fuzzy logic theory and practical applications, enabling the rapid development of novel intelligent methods and schemes.}
}
@article{GOMES2021138,
title = {Angular momentum without rotation: Turbocharging relationalism},
journal = {Studies in History and Philosophy of Science},
volume = {88},
pages = {138-155},
year = {2021},
issn = {0039-3681},
doi = {https://doi.org/10.1016/j.shpsa.2021.05.006},
url = {https://www.sciencedirect.com/science/article/pii/S0039368121000704},
author = {Henrique Gomes and Sean Gryb},
keywords = {Rotation, Absolute-relational debate, Relationalism, Angular momentum, Fibre bundles, Kaluza–Klein theory},
abstract = {Rotation is a challenging riddle for the relationalist. In early versions of the absolute-relational debate for example, Newton’s rotating bucket poured cold water on the relationalist position. While the parameters of the debate have changed, a more recent analysis in 1999 by Belot proclaimed rotation to be “the downfall of relationalism.” In this paper, we provide a relational response to the riddle of rotation. We present a theory that, contrary to orthodoxy, can account for all rotational effects without introducing, as the absolutist does, a fixed standard of rotation. Instead, our theory posits a universal SO(3) charge that plays the role of global angular momentum and couples to inter-particle relations via terms commonly seen in standard gauge theories such as electromagnetism and the Standard Model of particle physics. Our theory makes use of an enriched form of relationalism: it adds an SO(3) structure to the traditional relational description. Our construction is made possible by the modern tools of gauge theory, which reveal a simple relational law describing rotational effects. In this way, we can save all the phenomena of Newtonian mechanics using conserved charges and relationalism. In a second paper, we will further explore the ontological and explanatory implications of the theory developed here.}
}
@article{SAKOR2023100760,
title = {Knowledge4COVID-19: A semantic-based approach for constructing a COVID-19 related knowledge graph from various sources and analyzing treatments’ toxicities},
journal = {Journal of Web Semantics},
volume = {75},
pages = {100760},
year = {2023},
issn = {1570-8268},
doi = {https://doi.org/10.1016/j.websem.2022.100760},
url = {https://www.sciencedirect.com/science/article/pii/S1570826822000440},
author = {Ahmad Sakor and Samaneh Jozashoori and Emetis Niazmand and Ariam Rivas and Konstantinos Bougiatiotis and Fotis Aisopos and Enrique Iglesias and Philipp D. Rohde and Trupti Padiya and Anastasia Krithara and Georgios Paliouras and Maria-Esther Vidal},
keywords = {Knowledge graphs, COVID-19, Drug–drug interactions},
abstract = {In this paper, we present Knowledge4COVID-19, a framework that aims to showcase the power of integrating disparate sources of knowledge to discover adverse drug effects caused by drug–drug interactions among COVID-19 treatments and pre-existing condition drugs. Initially, we focus on constructing the Knowledge4COVID-19 knowledge graph (KG) from the declarative definition of mapping rules using the RDF Mapping Language. Since valuable information about drug treatments, drug–drug interactions, and side effects is present in textual descriptions in scientific databases (e.g., DrugBank) or in scientific literature (e.g., the CORD-19, the Covid-19 Open Research Dataset), the Knowledge4COVID-19 framework implements Natural Language Processing. The Knowledge4COVID-19 framework extracts relevant entities and predicates that enable the fine-grained description of COVID-19 treatments and the potential adverse events that may occur when these treatments are combined with treatments of common comorbidities, e.g., hypertension, diabetes, or asthma. Moreover, on top of the KG, several techniques for the discovery and prediction of interactions and potential adverse effects of drugs have been developed with the aim of suggesting more accurate treatments for treating the virus. We provide services to traverse the KG and visualize the effects that a group of drugs may have on a treatment outcome. Knowledge4COVID-19 was part of the Pan-European hackathon#EUvsVirus in April 2020 and is publicly available as a resource through a GitHub repository and a DOI.}
}
@article{YU2023e15034,
title = {Identification of potential biomarkers and pathways for sepsis using RNA sequencing technology and bioinformatic analysis},
journal = {Heliyon},
volume = {9},
number = {4},
pages = {e15034},
year = {2023},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2023.e15034},
url = {https://www.sciencedirect.com/science/article/pii/S2405844023022417},
author = {Rongjie Yu and Yingchen Wang and Qi Liang and Yuzhi Xu and Amina Elmi Yusf and Liqun Sun},
keywords = {Sepsis, Biomarkers, Bioinformatic analysis, Differentially expressed gene (DEG), Hub gene},
abstract = {Long non-coding RNAs (lncRNAs) has been proven by many to play a crucial part in the process of sepsis. To obtain a better understanding of sepsis, the molecular biomarkers associated with it, and its possible pathogenesis, we obtained data from RNA-sequencing analysis using serum from three sepsis patients and three healthy controls (HCs). Using edgeR (one of the Bioconductor software package), we identified 1118 differentially expressed mRNAs (DEmRNAs) and 1394 differentially expressed long noncoding RNAs (DElncRNAs) between sepsis patients and HCs. We identified the biological functions of these disordered genes using Gene Ontology (GO) and Kyoto Encyclopedia of Genes and Genomes (KEGG) signaling pathway analyses. The GO analysis showed that the homophilic cell adhesion via plasma membrane adhesion molecules was the most significantly enriched category. The KEGG signaling pathway analysis indicated that the differentially expressed genes (DEGs) were most significantly enriched in retrograde endocannabinoid signaling. Using STRING, a protein-protein interaction network was also created, and Cytohubba was used to determine the top 10 hub genes. To examine the relationship between the hub genes and sepsis, we examined three datasets relevant to sepsis that were found in the gene expression omnibus (GEO) database. PTEN and HIST2H2BE were recognized as hub gene in both GSE4607, GSE26378, and GSE9692 datasets. The receiver operating characteristic (ROC) curves indicate that PTEN and HIST2H2BE have good diagnostic value for sepsis. In conclusion, this two hub genes may be biomarkers for the early diagnosis of sepsis, our findings should deepen our understanding of the pathogenesis of sepsis.}
}
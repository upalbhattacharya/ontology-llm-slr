@article{ZHANG2025105504,
title = {Risk assessment of flammable liquid transportation on waterways: An ontology-driven dynamic Bayesian network approach},
journal = {Journal of Loss Prevention in the Process Industries},
volume = {93},
pages = {105504},
year = {2025},
issn = {0950-4230},
doi = {https://doi.org/10.1016/j.jlp.2024.105504},
url = {https://www.sciencedirect.com/science/article/pii/S0950423024002626},
author = {Fan Zhang and Xinrong Pu and Xi Huang and Yuanqiao Wen and Junyu Liu and Zhongyi Sui},
keywords = {Waterway transportation, Flammable liquid, Transportation risk assessment, Ontology, Dynamic Bayesian networks},
abstract = {Accidents involving the transportation of flammable liquids on waterways often lead to severe consequences, highlighting the importance of effective risk assessment under conditions of uncertainty. This paper presents a novel methodology for evaluating the risk associated with the spatiotemporal evolution of flammable liquid transportation on waterways. By leveraging ontology models and dynamic Bayesian networks, the approach involves analyzing factors that impact risk, constructing a standardized knowledge representation model, and mapping this onto a dynamic Bayesian network for comprehensive risk assessment. The methodology incorporates fuzzy theory and the Best-Worst Method to calculate probabilities within the Bayesian framework, enabling detailed analysis of factor impacts on transportation risk. A practical application is illustrated through the development of a dynamic risk evaluation model for octane transportation in the Yangtze River, demonstrating the model's capability to predict risk under varying conditions. This ontology-driven Bayesian network model provides a robust foundation for making informed management decisions in the transportation of flammable liquids, effectively addressing the challenges of semantic expression and inferencing under uncertainty to enhance safety in waterway transportation.}
}
@article{TOK2025301883,
title = {A Smart City Infrastructure ontology for threats, cybercrime, and digital forensic investigation},
journal = {Forensic Science International: Digital Investigation},
volume = {52},
pages = {301883},
year = {2025},
issn = {2666-2817},
doi = {https://doi.org/10.1016/j.fsidi.2025.301883},
url = {https://www.sciencedirect.com/science/article/pii/S2666281725000228},
author = {Yee Ching Tok and Davis Yang Zheng and Sudipta Chattopadhyay},
keywords = {Smart City Infrastructure, Smart City ontological paradigm expression, SCOPE, Smart City threats, Cybercrime, Digital forensics},
abstract = {Cybercrime and the market for cyber-related compromises are becoming attractive revenue sources for state-sponsored actors, cybercriminals and technical individuals affected by financial hardships. Due to burgeoning cybercrime on new technological frontiers, efforts have been made to assist digital forensic investigators (DFI) and law enforcement agencies (LEA) in their investigative efforts. Forensic tool innovations and ontology developments, such as the Unified Cyber Ontology (UCO) and Cyber-investigation Analysis Standard Expression (CASE), have been proposed to assist DFI and LEA. Although these tools and ontologies are useful, they lack extensive information sharing and tool interoperability features, and the ontologies lack the latest Smart City Infrastructure (SCI) context that was proposed. To mitigate the weaknesses in both solutions and to ensure a safer cyber-physical environment for all, we propose the Smart City Ontological Paradigm Expression (Scope), an expansion profile of the UCO and CASE ontology that implements SCI threat models, SCI digital forensic evidence, attack techniques, patterns and classifications from MITRE. We showcase how Scope could present complex data such as SCI-specific threats, cybercrime, investigation data and incident handling workflows via an incident scenario modeled after publicly reported real-world incidents attributed to Advanced Persistent Threat (APT) groups. We also make Scope available to the community so that threats, digital evidence and cybercrime in emerging trends such as SCI can be identified, represented, and shared collaboratively.}
}
@article{GARCIAS2023102242,
title = {Assessing the value of ontologically unpacking a conceptual model for human genomics},
journal = {Information Systems},
volume = {118},
pages = {102242},
year = {2023},
issn = {0306-4379},
doi = {https://doi.org/10.1016/j.is.2023.102242},
url = {https://www.sciencedirect.com/science/article/pii/S0306437923000789},
author = {Alberto {García S.} and Anna Bernasconi and Giancarlo Guizzardi and Oscar Pastor and Veda C. Storey and Ignacio Panach},
keywords = {Ontological unpacking, Conceptual modeling, Foundational ontology, OntoUML, Genomics, Metabolic pathways, Data explanation},
abstract = {Although the knowledge about human genomics is available to all scientists, information about this scientific breakthrough can often be difficult to fully comprehend and share. A Conceptual Schema of the Human Genome was previously developed to assist in describing human genome-related knowledge, by representing a holistic view of the relevant concepts regarding its biology and underlying mechanisms. This model should become helpful for any researcher who works with human genomics data. We, therefore, perform the process of ontological unpacking on a portion of the model, to facilitate domain understanding and data exchange among heterogeneous systems. The ontological unpacking is a transformation of an input conceptual model into an enriched model based on a foundational ontology. The preliminary analysis and enrichment process are supported by the ontological conceptual modeling language OntoUML, which has been applied previously to complex models to gain ontological clarity. The value of the used method is first assessed from a theoretical point of view: the transformation results in significant, diverse modeling implications regarding the characterization of biological entities, the representation of their changes over time, and, more specifically, the description of chemical compounds. Since the ontological unpacking process is costly, an empirical evaluation is conducted to study the practical implications of applying it in a real learning setting. A particularly complex domain such as metabolic pathways is either described by adopting a traditional conceptual model or explained through an ontologically unpacked model obtained from a traditional model. Our research is evidence that including a strong ontological foundation in traditional conceptual models is useful. It contributes to designing models that convey biological domains better than the original models.}
}
@article{BJORNSKOV2025115228,
title = {Automated model generation and parameter estimation of building energy models using an ontology-based framework},
journal = {Energy and Buildings},
volume = {329},
pages = {115228},
year = {2025},
issn = {0378-7788},
doi = {https://doi.org/10.1016/j.enbuild.2024.115228},
url = {https://www.sciencedirect.com/science/article/pii/S0378778824013446},
author = {Jakob Bjørnskov and Muhyiddine Jradi and Michael Wetter},
keywords = {Digital twin, Ontology, Data-driven, Building energy model, Building performance simulation},
abstract = {This study presents a methodology for automated model generation and parameter estimation of building energy models using semantic modeling and Bayesian estimation. Semantic modeling techniques are used to represent the system components and their interactions, facilitating the automatic generation of a simulation model from dynamic component models. The proposed approach is applied to a case study of a ventilation system where a simulation model is generated, calibrated, and assessed through different performance metrics. These metrics demonstrate the accuracy and reliability of both model point estimates and probabilistic prediction intervals across all model outputs. Overall, the proposed methodology offers a systematic and automated approach to model development and calibration in building energy systems, with potential applications in building performance analysis, monitoring, and optimization.}
}
@article{WANG2024102430,
title = {An ontology of eco-design for additive manufacturing with informative sustainability analysis},
journal = {Advanced Engineering Informatics},
volume = {60},
pages = {102430},
year = {2024},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2024.102430},
url = {https://www.sciencedirect.com/science/article/pii/S1474034624000788},
author = {Yanan Wang and Tao Peng and Yi Xiong and Samyeon Kim and Yi Zhu and Renzhong Tang},
keywords = {Additive manufacturing, Eco-design for AM, Ontology, Sustainability},
abstract = {Design for Additive Manufacturing (DfAM) offers a unique opportunity to consider the sustainability of industrial components fabricated by additive manufacturing in the early stage of product development. This leads to the emergence of a novel cross-subject field known as Eco-Design for AM (EcoDfAM). Sustainability analysis of industrial components is critical in EcoDfAM but demands substantial domain knowledge not yet modeled within existing DfAM knowledge. This paper addresses the gap by developing an EcoDfAM ontology using the Web Ontology Language (OWL). This ontology aims to enable knowledge reuse for sustainability analysis in AM design by structurally organizing life cycle process information of industrial components and then semantically modeling Sustainable Design Knowledge (SDK). SDK captures implicit knowledge from AM, design, and sustainability domains, highlighting the correlation of design and sustainability in EcoDfAM through introducing a novel concept, the Material-Process-Structure-ecoProperty (MPSeP) relationships, to extend knowledge in the AM domain for considering sustainability. A six-step ontology development process was employed to create the EcoDfAM ontology which comprises three important concepts: eco-parameters, eco-property, and performance. The representation of SDK focused on the Laser Powder Bed Fusion (LPBF) process in the developed ontology. Implementation of the ontology is carried out using the Protégé tool, and reasoning and queries within EcoDfAM are accomplished through the Semantic Web Rule Language (SWRL) and Semantic Query-enhanced Web Rule Language (SQWRL). The proposed EcoDfAM ontology is demonstrated through a case study on a hydraulic manifold to be fabricated by SLM, showcasing its effectiveness in retrieving key inventory data related to carbon emission and cost, eco-parameters used in DfAM, and recommending eco-design recommendations, facilitating the development of an eco-friendly and economical AM solution for the hydraulic manifold. In conclusion, this study contributes a structured knowledge model, serving as a professional, reusable, and upgradable knowledge base for sustainability analysis in AM design, empowering designers to fully leverage AM’s potential for sustainable outcomes}
}
@article{LIU2025115890,
title = {Large language model enabled knowledge discovery of building-level electrification using permit data},
journal = {Energy and Buildings},
volume = {343},
pages = {115890},
year = {2025},
issn = {0378-7788},
doi = {https://doi.org/10.1016/j.enbuild.2025.115890},
url = {https://www.sciencedirect.com/science/article/pii/S0378778825006206},
author = {Tony Liu and Chad Zanocco and Zhecheng Wang and Tianyuan Huang and June Flora and Ram Rajagopal},
keywords = {Building permits, Large language models, Distributed energy resources, Electrification, Spatiotemporal mapping},
abstract = {Wide scale electrification is essential for decarbonization of the building sector, yet there is a significant knowledge gap regarding the specific locations, timelines, and types of electrification technologies that are being deployed. To address this gap, we developed an information framework powered by large language models (LLMs) to extract detailed electrification-related technology information from building permit text data. While U.S. building permit data is publicly available, it is often unstructured, incomplete, and highly variable. Our LLM-enabled system addresses these challenges by constructing a comprehensive building-level ontology that captures detailed attributes for six key electrification technologies: photovoltaics, electric vehicle chargers, energy storage systems, electric service panels, water heaters, and heat pumps. Our information extraction system exhibits strong performance, achieving 0.96 recall and 0.88 precision on our human-annotated test dataset. We experimentally deploy our framework on permit data in San Francisco County, California, demonstrating that it surpasses all existing public sources of electrification information in both spatiotemporal resolution and coverage. Our work provides new visibility into building electrification trends at scale, offering valuable insights for grid planners, policymakers, installers, and end-users to inform decision-making processes.}
}
@article{SHIMIZU2024100823,
title = {Ontology design facilitating Wikibase integration — and a worked example for historical data},
journal = {Journal of Web Semantics},
volume = {82},
pages = {100823},
year = {2024},
issn = {1570-8268},
doi = {https://doi.org/10.1016/j.websem.2024.100823},
url = {https://www.sciencedirect.com/science/article/pii/S157082682400009X},
author = {Cogan Shimizu and Andrew Eells and Seila Gonzalez and Lu Zhou and Pascal Hitzler and Alicia Sheill and Catherine Foley and Dean Rehberger},
keywords = {Wikibase, Modular ontology modeling, Ontology design pattern},
abstract = {Wikibase – which is the software underlying Wikidata – is a powerful platform for knowledge graph creation and management. However, it has been developed with a crowd-sourced knowledge graph creation scenario in mind, which in particular means that it has not been designed for use case scenarios in which a tightly controlled high-quality schema, in the form of an ontology, is to be imposed, and indeed, independently developed ontologies do not necessarily map seamlessly to the Wikibase approach. In this paper, we provide the key ingredients needed in order to combine traditional ontology modeling with use of the Wikibase platform, namely a set of axiom patterns that bridge the paradigm gap, together with usage instructions and a worked example for historical data.}
}
@article{BRUCKER2025103231,
title = {Parametric ontologies in formal software engineering},
journal = {Science of Computer Programming},
volume = {241},
pages = {103231},
year = {2025},
issn = {0167-6423},
doi = {https://doi.org/10.1016/j.scico.2024.103231},
url = {https://www.sciencedirect.com/science/article/pii/S0167642324001540},
author = {Achim D. Brucker and Idir Ait-Sadoune and Nicolas Méric and Burkhart Wolff},
keywords = {Ontologies, Generic classes, Ontology mapping, Formal development, Formal documents, Isabelle/HOL, Software engineering, Certification},
abstract = {Isabelle/DOF is an ontology framework on top of Isabelle/HOL. It allows for the formal development of ontologies and continuous conformity-checking of integrated documents, including the tracing of typed meta-data of documents. Isabelle/DOF deeply integrates into the Isabelle/HOL ecosystem, allowing to write documents containing (informal) text, executable code, (formal and semiformal) definitions, and proofs. Users of Isabelle/DOF can either use HOL or one of the many formal methods that have been embedded into Isabelle/HOL to express formal parts of their documents. In this paper, we extend Isabelle/DOF with annotations of Image 1-terms, a pervasive data-structure underlying Isabelle to syntactically represent expressions and formulas. We achieve this by using Higher-order Logic (HOL) itself for query-expressions and data-constraints (ontological invariants) executed via code-generation and reflection. Moreover, we add support for parametric ontological classes, thus exploiting HOL's polymorphic type system. The benefits are: First, the HOL representation allows for flexible and efficient run-time checking of abstract properties of formal content under evolution. Second, it is possible to prove properties over generic ontological classes. We demonstrate these new features by a number of smaller ontologies from various domains and a case study using a substantial ontology for formal system development targeting certification according to CENELEC 50128.}
}
@article{PELEG2024104655,
title = {How can we reward you? A compliance and reward ontology (CaRO) for eliciting quantitative reward rules for engagement in mHealth app and healthy behaviors},
journal = {Journal of Biomedical Informatics},
volume = {154},
pages = {104655},
year = {2024},
issn = {1532-0464},
doi = {https://doi.org/10.1016/j.jbi.2024.104655},
url = {https://www.sciencedirect.com/science/article/pii/S153204642400073X},
author = {Mor Peleg and Nicole Veggiotti and Lucia Sacchi and Szymon Wilk},
abstract = {Objective
When developing mHealth apps with point reward systems, knowledge engineers and domain experts should define app requirements capturing quantitative reward patterns that reflect patient compliance with health behaviors. This is a difficult task, and they could be aided by an ontology that defines systematically quantitative behavior goals that address more than merely the recommended behavior but also rewards for partial compliance or practicing the behavior more than recommended. No ontology and algorithm exist for defining point rewards systematically.
Methods
We developed an OWL ontology for point rewards that leverages the Basic Formal Ontology, the Behaviour Change Intervention Ontology and the Gamification Domain Ontology. This Compliance and Reward Ontology (CaRO) allows defining temporal elementary reward patterns for single and multiple sessions of practicing a behavior. These could be assembled to define more complex temporal patterns for persistence behavior over longer time intervals as well as logical combinations of simpler reward patterns. We also developed an algorithm for calculating the points that should be rewarded to users, given data regarding their actual performance. A natural language generation algorithm generates from ontology instances app requirements in the form of user stories. To assess the usefulness of the ontology and algorithms, information system students who are trained to be system analysts/knowledge engineers evaluated whether the ontology and algorithms can improve the requirement elicitation of point rewards for compliance patterns more completely and correctly.
Results
For single-session rewards, the ontology improved formulation of two of the six requirements as well as the total time for specifying them. For multi-session rewards, the ontology improved formulation of five of the 11 requirements.
Conclusion
CaRO is a first attempt of its kind, and it covers all of the cases of compliance and reward pattern definitions that were needed for a full-scale system that was developed as part of a large European project. The ontology and algorithm are available at https://github.com/capable-project/rewards.}
}
@article{SCHONFELDER2025100638,
title = {A steel element reuse ontology for building audits in circular construction},
journal = {Developments in the Built Environment},
volume = {21},
pages = {100638},
year = {2025},
issn = {2666-1659},
doi = {https://doi.org/10.1016/j.dibe.2025.100638},
url = {https://www.sciencedirect.com/science/article/pii/S2666165925000389},
author = {Leonhard Schönfelder and Brandon S. Byers and Meliha Honic and Catherine {De Wolf}},
keywords = {Ontology, Circular economy, Reuse, Construction, Steel reuse},
abstract = {The construction sector's transition to a circular economy necessitates the closure of material loops through reuse. However, there is little consensus regarding the information to assess the reusability of building elements. This paper determines the necessary information for evaluating steel member reusability and explores the structure of an ontology for conducting building audits. The methodology involves surveys and interviews with European experts in reuse to create the Steel Element Reuse Ontology (SERO). The results show 1) that economic, technical, and condition factors are important to define reusability, and 2) an ontology to assess the reusability should account for the condition and documentation of steel members. SERO establishes definitions and a human- and machine-readable framework for assessing the reuse potential of steel H- and I-profiles in a European context. This framework could be employed in developing digital tools aimed at streamlining inventory procedures in construction, fostering the practical implementation of circular economy principles.}
}
@article{MA2024105394,
title = {An ontology-driven method for urban building energy modeling},
journal = {Sustainable Cities and Society},
volume = {106},
pages = {105394},
year = {2024},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2024.105394},
url = {https://www.sciencedirect.com/science/article/pii/S2210670724002221},
author = {Rui Ma and Qi Li and Botao Zhang and Hao Huang and Chendi Yang},
keywords = {Ontology, Urban building energy modeling, Resource description framework, Semantic web technology},
abstract = {The field of urban building energy modeling, embracing diverse aspects such as geography, construction, and materials. There is a lack of a comprehensive information integration framework to streamline cross-domain data in a systematic manner and generate simulation files that are easily calculable. This study addresses this gap by proposing two key ontologies: Building Template Ontology for managing building energy simulation templates and Urban Building Ontology for organizing building physics information. Utilizing this ontology-driven method, this study enhances flexibility in information fusion, exploits logical relationships between simulation inputs, and provides a lightweight solution for structured urban energy performance analysis. Energy simulations were conducted on over 5,000 buildings across three cities, and the impact of energy retrofit measures was further quantified, revealing potential savings of 0.1 % to 4.0 %, 1.2 % to 10.2 %, and 2.5 % to 6.9 % for building envelope, lighting, and air conditioning improvements, respectively. This study empowers urban stakeholders, designers, and managers to streamline the model construction and provides valuable insights into energy consumption patterns. Acknowledging limitations in current ontologies, including restricted building type templates, lack of real-time instance information, and absence of direct energy verification, this study underscores the imperative to address these for future advancements.}
}
@article{R201869,
title = {Ontology based knowledge representation technique, domain modeling languages and planners for robotic path planning: A survey},
journal = {ICT Express},
volume = {4},
number = {2},
pages = {69-74},
year = {2018},
note = {Artificial Intelligence and Machine Learning Approaches to Communication},
issn = {2405-9595},
doi = {https://doi.org/10.1016/j.icte.2018.04.008},
url = {https://www.sciencedirect.com/science/article/pii/S2405959518300985},
author = {Gayathri R. and V. Uma},
keywords = {Path planning, Knowledge representation, Reasoning, Ontology, Spatial, Temporal, Semantic knowledge, Planners, Modeling languages},
abstract = {Knowledge Representation and Reasoning (KR & R) has become one of the promising fields of Artificial Intelligence. KR is dedicated towards representing information about the domain that can be utilized in path planning. Ontology based knowledge representation and reasoning techniques provide sophisticated knowledge about the environment for processing tasks or methods. Ontology helps in representing the knowledge about environment, events and actions that help in path planning and making robots more autonomous. Knowledge reasoning techniques can infer new conclusion and thus aids planning dynamically in a non-deterministic environment. In the initial sections, the representation of knowledge using ontology and the techniques for reasoning that could contribute in path planning are discussed in detail. In the following section, we also provide comparison of various planning domain modeling languages, ontology editors, planners and robot simulation tools.}
}
@article{MUSA2025103092,
title = {Integrating and retrieving learning analytics data from heterogeneous platforms using ontology alignment: Graph-based approach},
journal = {MethodsX},
volume = {14},
pages = {103092},
year = {2025},
issn = {2215-0161},
doi = {https://doi.org/10.1016/j.mex.2024.103092},
url = {https://www.sciencedirect.com/science/article/pii/S2215016124005430},
author = {Mohd Hafizan Musa and Sazilah Salam and Siti Feirusz Ahmad Fesol and Muhammad Syahmie Shabarudin and Jack Febrian Rusdi and Mohd Adili Norasikin and Ibrahim Ahmad},
keywords = {Learning analytics, University ontology, Graph databases, Knowledge graphs, Heterogenous learning platforms},
abstract = {This study explores the possibility of integrating and retrieving heterogenous data across platforms by using ontology graph databases to enhance educational insights and enabling advanced data-driven decision-making. Motivated by some of the well-known universities and other Higher Education Institutions ontology, this study improvises the existing entities and introduces new entities in order to tackle a new topic identified from the preliminary interview conducted in the study to cover the study objective. The paper also proposes an innovative ontology, referred to as Student Performance and Course, to enhance resource management and evaluation mechanisms on course, students, and MOOC performance by the faculty. The model solves the issues of data accumulation and their heterogeneity, including the problem of having data in different formats and various semantic similarities, and is suitable for processing large amounts of data in terms of scalability. Thus, it also offers a way to confirm the process of data retrieval that is based on performance assessment with the help of an evaluation matrix.}
}
@article{JUNWU2024102906,
title = {Integrating Bayesian networks and ontology to improve safety knowledge management in construction behavior: A conceptual framework},
journal = {Ain Shams Engineering Journal},
volume = {15},
number = {9},
pages = {102906},
year = {2024},
issn = {2090-4479},
doi = {https://doi.org/10.1016/j.asej.2024.102906},
url = {https://www.sciencedirect.com/science/article/pii/S2090447924002818},
author = {Wang Junwu and Liu Yipeng and Feng Jingtao},
keywords = {Behavioral safety management, Bayesian network, Ontology, SWRL, Knowledge management, Conceptual framework},
abstract = {Addressing the challenges of intelligent decision support within traditional management approaches, this study presents a novel conceptual framework for enhancing sustainability in construction behavioral safety management. By integrating Bayesian network (BN) modeling and ontology, our framework enables robust decision-making and fosters knowledge sharing. Key to our approach is the encoding and storage of BN-modeled properties within the ontology, facilitating a formal representation of behavioral safety knowledge. Leveraging SWRL rules for reasoning and judgment, our study effectively elucidates causal relationships and interactions within the behavioral safety system. Rigorous verification, including consistency checks and task evaluations, ensures the reliability and validity of our ontology. Ultimately, our framework facilitates seamless communication and retrieval of traditional construction behavioral safety knowledge, underpinning sustainability efforts through the integrated BN model and ontology storage and sharing mechanism.}
}
@article{WANG2023e21502,
title = {Multi-ontology embeddings approach on human-aligned multi-ontologies representation for gene-disease associations prediction},
journal = {Heliyon},
volume = {9},
number = {11},
pages = {e21502},
year = {2023},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2023.e21502},
url = {https://www.sciencedirect.com/science/article/pii/S2405844023087108},
author = {Yihao Wang and Philipp Wegner and Daniel Domingo-Fernández and Alpha {Tom Kodamullil}},
keywords = {Multi-ontology, Natural language processing},
abstract = {Objectives
Knowledge graphs and ontologies in the biomedical domain provide rich contextual knowledge for a variety of challenges. Employing that for knowledge-driven NLP tasks such as gene-disease association prediction represents a promising way to increase the predictive power of a model.
Methods
We investigated the power of infusing the embedding of two aligned ontologies as prior knowledge to the NLP models. We evaluated the performance of different models on some large-scale gene-disease association datasets and compared it with a model without incorporating contextualized knowledge (BERT).
Results
The experiments demonstrated that the knowledge-infused model slightly outperforms BERT by creating a small number of bridges. Thus, indicating that incorporating cross-references across ontologies can enhance the performance of base models without the need for more complex and costly training. However, further research is needed to explore the generalizability of the model. We expected that adding more bridges would bring further improvement based on the trend we observed in the experiments. In addition, the use of state-of-the-art knowledge graph embedding methods on a joint graph from connecting OGG and DOID with bridges also yielded promising results.
Conclusion
Our work shows that allowing language models to leverage structured knowledge from ontologies does come with clear advantages in the performance. Besides, the annotation stage brought out in this paper is constrained in reasonable complexity.}
}
@article{SILVA2025301912,
title = {A review study of digital forensics in IoT: Process models, phases, architectures, and ontologies},
journal = {Forensic Science International: Digital Investigation},
volume = {53},
pages = {301912},
year = {2025},
issn = {2666-2817},
doi = {https://doi.org/10.1016/j.fsidi.2025.301912},
url = {https://www.sciencedirect.com/science/article/pii/S2666281725000514},
author = {Thiago J. Silva and Edson OliveiraJr and Maximiano Eduardo Pereira and Avelino F. Zorzo},
keywords = {Digital forensics, Formalization, IoT forensics, Models, Recommendations, Research gaps, Systematic literature review},
abstract = {The Internet of Things (IoT) involves integrating uniquely identifiable computing devices into various infrastructures. Technological advancements have led to a proliferation of interconnected devices in public and private infrastructures, such as healthcare, transportation, and manufacturing. However, this expansion also presents significant challenges, including managing large volumes of data, navigating diverse infrastructures, dealing with network limitations, and lacking standards in IoT device formats. The increase in digital crimes has spurred the growth of the Digital Forensics (DF) field, which plays a crucial role in various interdisciplinary contexts. DF involves analyzing digital crime-related data and going through phases such as identification, collection, organization, and presentation of evidence. As DF develops, there are emerging structural and methodological initiatives aimed at formalizing concepts and establishing a common vocabulary. The literature has proposed various frameworks, conceptual models, methodologies, and ontologies to support this area. To identify and examine existing models, frameworks, methodologies, or ontologies for digital forensics on the Internet of Things (IoT), this article presents a systematic literature review (SLR). The systematic literature review outlined methods for constructing models, different types of models, feasibility criteria, evaluation methods, and models for different stages and aspects of DF. The findings were derived from an analysis of 23 primary studies, which helped address four specific research questions. Additionally, the paper suggests further model-based assistance for DF research, aiming to assist researchers and professionals in addressing current research gaps. The contributions of this work aim to fill the gaps imposed by the practical implications for digital forensic investigators in IoT. In this case, one can mention the use of DF models and phases to assist in the analysis of evidence, recoveries, information, and identification of data patterns sent via IoT.}
}
@article{KHALIL2025104015,
title = {CyberROAD: A cybersecurity risk assessment ontology for automotive domain aligned with ISO/SAE 21434:2021},
journal = {Journal of Information Security and Applications},
volume = {90},
pages = {104015},
year = {2025},
issn = {2214-2126},
doi = {https://doi.org/10.1016/j.jisa.2025.104015},
url = {https://www.sciencedirect.com/science/article/pii/S2214212625000535},
author = {Karim Khalil and Christian Gehrmann and Günther Vogel},
keywords = {Cybersecurity risk assessment, Ontology, ISO/SAE 21434:2021, Automotive domain, Threat analysis and risk assessment (TARA), Design science research method},
abstract = {The automotive domain is becoming increasingly complex through the integration of new technologies. As a result, cybersecurity is recognized as a pressing issue. This study focuses on the ISO/SAE 21434:2021 standard for road vehicles cybersecurity engineering, evaluating the effectiveness of the standard’s risk assessment approach. The standard suggests a set of assessment steps, and previous research has shown that practitioners often face challenges during assessment execution. The absence of clear, structured guidelines within the standard leads to different interpretations, resulting in inconsistent assessment approaches. This inconsistency makes it difficult to compare and measure the quality of the assessments. Our study uses design science methodology to create a new cybersecurity risk assessment ontology in the automotive domain, describing the relationships and interdependencies between cybersecurity risk assessment activities, stakeholders, and work packages. The ontology model is evaluated in a case study at a leading automotive systems supplier to validate the model’s suitability for developing a cybersecurity risk assessment method. The findings indicate that the ontology model provides an improved understanding of the underlying risk assessment activities and allows for a structured method for extracting procedural steps according to the standard. This systematic approach increases the cybersecurity risk assessment conformity and the consistency of assessment results. In conclusion, this paper gives valuable insights and actionable recommendations for stakeholders, researchers, and organizations seeking to improve the cybersecurity risk assessment process in the automotive domain.}
}
@article{ALREFAIE2024108654,
title = {Chemical, biological, radiological and nuclear event detection and classification using ontology interrogation and social media data},
journal = {Engineering Applications of Artificial Intelligence},
volume = {135},
pages = {108654},
year = {2024},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2024.108654},
url = {https://www.sciencedirect.com/science/article/pii/S0952197624008121},
author = {Mohamed Taher Alrefaie and Tom W. Jackson and Ejovwoke Onojeharho and Suzanne Elayan},
keywords = {Ontology, Disaster management, Information retrieval, Social media analysis, Machine learning, Natural language processing},
abstract = {In an era where chemical, biological, radiological, and nuclear (CBRN) incidents present a grave threat to public safety, timely and accurate information is paramount. The complexity of the CBRN concept encompasses a range of incidents, each with unique and overlapping symptoms, related substances, and event descriptions. This study introduces an innovative approach to the development of a CBRN-specific ontology, uniting diverse data sources and domain expertise to construct a comprehensive repository of CBRN events, sub-events, their causes, symptoms, and toxic substances. Unlike prior methodologies reliant on keyword searches and predefined categories, our approach enables a holistic analysis of textual data by capturing intricate relationships between symptoms and toxic substances. We leverage this ontology in conjunction with a tailored interrogation algorithm to detect potential CBRN incidents through social media data. The algorithm was then tested on datasets of three actual CBRN incidents, one fictional incident (TV show) that simulated a nuclear incident and one non-CBRN. The interrogation algorithm was able to detect the five CBRN incidents accurately. However, the study showcased the need to extend the algorithm to distinguish between real and fictional CBRN incidents. These findings underscore the potential of this approach to deliver timely information on potential CBRN incidents. Nevertheless, the study acknowledged the inherent challenges and limitations in utilizing social media data, including the risk of misinformation, fictional events, fake news, and interference from malicious actors, all of which can affect the accuracy and reliability of the information collected.}
}
@article{FALDUTI2024105999,
title = {Ontological models for representing image-based sexual abuses},
journal = {Computer Law & Security Review},
volume = {54},
pages = {105999},
year = {2024},
issn = {2212-473X},
doi = {https://doi.org/10.1016/j.clsr.2024.105999},
url = {https://www.sciencedirect.com/science/article/pii/S0267364924000669},
author = {Mattia Falduti and Cristine Griffo},
keywords = {Legal ontology, UFO-L, Image-based sexual abuse, Sextortion},
abstract = {In recent years, there has been extensive discourse on the moderation of abusive content online. Image-based Sexual Abuses (IBSAs) represent a type of abusive content that involves sexual images or videos. Platforms must moderate user-generated online content to tackle this issue effectively. One way to achieve this is by allowing users to report content, which can be flagged as abusive. In such instances, platforms may enforce their terms of service and prohibit certain types of content or users. Alongside these efforts, numerous countries have been making progress in defining and regulating this subject by implementing dedicated regulations. However, national solutions alone are insufficient for addressing a constantly increasing global emergency. Consequently, digital platforms create their own definitions of abusive conduct to overcome obstacles arising from conflicting national laws. In this paper, we use an ontological approach to model two types of abusive behavior. To do this, we applied the UFO-L patterns to build ontological models and based them on a top-level ontology, the Unified Foundational Ontology (UFO). The outcome is a set of ontological models that digital platforms can use to monitor and manage user compliance with the service provider’s code of conduct.}
}
@article{BOTTRIGHI2025103226,
title = {Ontology-based student testing through clinical guidelines: An AI approach},
journal = {Artificial Intelligence in Medicine},
volume = {168},
pages = {103226},
year = {2025},
issn = {0933-3657},
doi = {https://doi.org/10.1016/j.artmed.2025.103226},
url = {https://www.sciencedirect.com/science/article/pii/S0933365725001617},
author = {Alessio Bottrighi and Antonio Maconi and Stefano Nera and Luca Piovesan and Erica Raina and Paolo Terenziani},
keywords = {Computer interpretable clinical guidelines, Medical education, Knowledge representation and reasoning, Ontologies, Testing and explanation},
abstract = {On the basis of our 25-year experience with the GLARE (Guideline Acquisition, Representation and Execution) clinical decision support system, we have started to analyze the adoption of computer-interpretable clinical guidelines (CIGs) and AI techniques to train and test medical students about how to act on patients. Moving from decision support to the educational task involves significant research challenges. In this paper, we propose a new facility that supports teachers in the definition of tests, by selecting and hiding to students specific parts of the CIG, and asking students how they would act on the given case study (patient) in the selected parts. Students are provided with a medical ontology to identify proper actions/decisions, and students' proposals are then automatically compared with what the CIG (considered as a “golden standard”) would suggest to do to the patient through knowledge representation and reasoning techniques. Our basic explanation mechanism exploits the medical ontology to show to students the differences (if any) between their proposals and the ones of the CIG.}
}
@article{VEGGI2025e00409,
title = {The Brancacci Chapel from the Quattrocento to the semantic web: An ontology-assisted case study of cultural data management and site reconstruction},
journal = {Digital Applications in Archaeology and Cultural Heritage},
volume = {37},
pages = {e00409},
year = {2025},
issn = {2212-0548},
doi = {https://doi.org/10.1016/j.daach.2025.e00409},
url = {https://www.sciencedirect.com/science/article/pii/S2212054825000116},
author = {Manuele Veggi and Ivana Cerato},
keywords = {Knowledge representation, 3D semantic annotation, Digital art history, Ontology engineering, Cultural site reconstruction, Semantic web},
abstract = {This study proposes an ontological model for cultural heterogeneous data and cultural site reconstructions. It is based on the concept of interpretative unit, which extends the semantics of stratigraphic units also to non-archaeological contexts. The ontology is named after the case study of this research, the Brancacci Chapel in Florence. Indeed, after a state of the art overview of the development methodology and the description of the most relevant entities, a first test case is proposed. An entry of the catalogue of a recent exhibition on Masolino, a 15th century painter who worked at the decoration of the chapel, has been serialised as Turtle file and the semantics of knowledge graph has been assessed via competency questions. The positive results encourage the deepening of this line of research in the direction of connecting linked data with nodes in 3D models, as well as their visualisation and communication to non-specialist audiences.}
}
@article{SILVA20253049,
title = {Classifying Forest Supply Chain Traceability Data with an Ontological Approach},
journal = {Procedia Computer Science},
volume = {253},
pages = {3049-3058},
year = {2025},
note = {6th International Conference on Industry 4.0 and Smart Manufacturing},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2025.02.029},
url = {https://www.sciencedirect.com/science/article/pii/S1877050925003722},
author = {Hugo Silva and Reinaldo Gomes and Cristóvão Sousa},
keywords = {Traceability, Forest Supply Chain, Ontology, Data Integration, Semantic Classification},
abstract = {In the context of Industry 4.0, effective traceability within Forest Supply Chains is essential for ensuring sustainability and transparency. This paper introduces an ontological framework for classifying Forest Supply Chain traceability data, addressing the critical need for accurate tracking from forest to final product. While existing methods often face challenges with semantic interoperability, our approach leverages ontologies to create a standardized data representation that enhances communication and decision-making among stakeholders. The proposed ontology encompasses all phases of the wood cycle and aligns with industry standards, facilitating integration into existing systems. Unlike previous studies that used simulated data, this work validates the ontology with real data, demonstrating its practical applicability. Our ontology serves as a reference for business organizations and researchers in the forestry sector, promoting efficient data management and advancing sustainable forest supply chain practices.}
}
@article{CHEN2019100959,
title = {An automatic literature knowledge graph and reasoning network modeling framework based on ontology and natural language processing},
journal = {Advanced Engineering Informatics},
volume = {42},
pages = {100959},
year = {2019},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2019.100959},
url = {https://www.sciencedirect.com/science/article/pii/S1474034619302642},
author = {Hainan Chen and Xiaowei Luo},
keywords = {Representation ontology, Natural language processing, Knowledge graph, Knowledge reasoning},
abstract = {With the advancement of scientific and engineering research, a huge number of academic literature are accumulated. Manually reviewing the existing literature is the main way to explore embedded knowledge, and the process is quite time-consuming and labor intensive. As the quantity of literature is increasing exponentially, it would be more difficult to cover all aspects of the literature using the traditional manual review approach. To overcome this drawback, bibliometric analysis is used to analyze the current situation and trend of a specific research field. In the bibliometric analysis, only a few key phrases (e.g., authors, publishers, journals, and citations) are usually used as the inputs for analysis. Information other than those phrases is not extracted for analysis, while that neglected information (e.g., abstract) might provide more detailed knowledge in the article. To tackle with this problem, this study proposed an automatic literature knowledge graph and reasoning network modeling framework based on ontology and Natural Language Processing (NLP), to facilitate the efficient knowledge exploration from literature abstract. In this framework, a representation ontology is proposed to characterize the literature abstract data into four knowledge elements (background, objectives, solutions, and findings), and NLP technology is used to extract the ontology instances from the abstract automatically. Based on the representation ontology, a four-space integrated knowledge graph is built using NLP technology. Then, reasoning network is generated according to the reasoning mechanism defined in the proposed ontology model. To validate the proposed framework, a case study is conducted to analyze the literature in the field of construction management. The case study proves that the proposed ontology model can be used to represent the knowledge embedded in the literatures’ abstracts, and the ontology elements can be automatically extracted by NLP models. The proposed framework can be an enhancement for the bibliometric analysis to explore more knowledge from the literature.}
}
@article{BALALI2025101702,
title = {COfEE: A comprehensive ontology for event extraction from text},
journal = {Computer Speech & Language},
volume = {89},
pages = {101702},
year = {2025},
issn = {0885-2308},
doi = {https://doi.org/10.1016/j.csl.2024.101702},
url = {https://www.sciencedirect.com/science/article/pii/S0885230824000858},
author = {Ali Balali and Masoud Asadpour and Seyed Hossein Jafari},
keywords = {Information extraction, Event extraction, Event ontology, Deep learning, Persian language, Online media monitoring},
abstract = {Large volumes of data are constantly being published on the web; however, the majority of this data is often unstructured, making it difficult to comprehend and interpret. To extract meaningful and structured information from such data, researchers and practitioners have turned to Information Extraction (IE) methods. One of the most challenging IE tasks is Event Extraction (EE), which involves extracting information related to specific incidents and their associated actors from text. EE has broad applications, including building a knowledge base, information retrieval, summarization, and online monitoring systems. Over the past few decades, various event ontologies, such as ACE, CAMEO, and ICEWS, have been developed to define event forms, actors, and dimensions of events observed in text. However, these ontologies have some limitations, such as covering only a few topics like political events, having inflexible structures in defining argument roles, lacking analytical dimensions, and insufficient gold-standard data. To address these concerns, we propose a new event ontology, COfEE, which integrates expert domain knowledge, previous ontologies, and a data-driven approach for identifying events from text. COfEE comprises two hierarchy levels (event types and event sub-types) that include new categories related to environmental issues, cyberspace, criminal activity, and natural disasters that require real-time monitoring. In addition, dynamic roles are defined for each event sub-type to capture various dimensions of events. The proposed ontology is evaluated on Wikipedia events, and it is shown to be comprehensive and general. Furthermore, to facilitate the preparation of gold-standard data for event extraction, we present a language-independent online tool based on COfEE. A gold-standard dataset annotated by ten human experts consisting of 24,000 news articles in Persian according to the COfEE ontology is also prepared. To diversify the data, news articles from the Wikipedia event portal and the 100 most popular Persian news agencies between 2008 and 2021 were collected. Finally, we introduce a supervised method based on deep learning techniques to automatically extract relevant events and their corresponding actors.}
}
@article{ZHENG2025115173,
title = {Mastering building management systems data points tagging with minimal examples: unveiling the power of large language models},
journal = {Energy and Buildings},
volume = {328},
pages = {115173},
year = {2025},
issn = {0378-7788},
doi = {https://doi.org/10.1016/j.enbuild.2024.115173},
url = {https://www.sciencedirect.com/science/article/pii/S0378778824012891},
author = {Zhiyu Zheng and Sylvain Marié and Elham Farazdaghi and Esma Yahia and Khal Makhoul and Théo Lagarde and Rani El Meouche and Fakhreddine Ababsa},
keywords = {Large Language Models, Building Management Systems, Brick Ontology, Semantic Web Technologies, Metadata Tagging, Few-Shot Learning, Prompt Engineering},
abstract = {The heterogeneity of metadata within Building Management Systems (BMS) poses substantial challenges for advanced analytics, including cross-building analysis. Over the past decade, metadata standard schemas such as Brick have been developed to address this challenge. Nevertheless, mapping BMS metadata with such standards accurately and efficiently continues to be a demanding task across both new and existing buildings. This work explores the application of Large Language Models (LLMs) to tag BMS data points, thus facilitating metadata standardization efforts. Manual or rule-based methods are not only labor-intensive but also error-prone. Similarly, supervised learning approaches using Machine Learning (ML) and Natural Language Processing (NLP) demand extensive labeled datasets, often making them laborious and inflexible to new BMS metadata types and tasks. We propose a novel three-step framework that enhances the tagging process by integrating a LLM with few-shot prompting and an embedding model. This approach not only improves result interpretability but also effectively mitigates hallucinations. This framework is further supported by analyses of the LLM’s inherent capabilities, prompt-aided specific interpretation and output formatting, and evaluations of few-shot sizes. Tested across five different building datasets, our approach, leveraging few-shot examples, achieves performance comparable to state-of-the-art supervised learning methods that rely on large labeled datasets.}
}
@article{LEE202463,
title = {Developing a data quality assurance ontology for research data repositories},
journal = {Journal of Documentation},
volume = {81},
number = {7},
pages = {63-84},
year = {2024},
issn = {0022-0418},
doi = {https://doi.org/10.1108/JD-09-2024-0212},
url = {https://www.sciencedirect.com/science/article/pii/S0022041825000128},
author = {Dong Joon Lee and Besiki Stvilia and Fatih Gunaydin and Yuanying Pang},
keywords = {Data quality, Data quality assurance, Research data repositories, Research data curation, Ontologies, FAIR},
abstract = {Purpose
Data quality assurance (DQA) is essential for enabling the sharing and reuse of research data, especially given the increasing focus on data transparency, reproducibility, credibility and validity in research. Although the literature on research data curation is vast, there remains a lack of theory-guided exploration of DQA modeling in research data repositories (RDRs).
Design/methodology/approach
This study addresses this gap by examining 12 distinct cases of DQA-related knowledge organization tools, including four metadata vocabularies, three metadata schemas, one ontology and four standards used to guide DQA work in RDRs.
Findings
The study analyzed the cases utilizing a theoretical framework based on activity theory and data quality literature and synthesized a model and a knowledge artifact, a DQA ontology (DQAO, Lee et al., 2024), that encodes a DQA theory for RDRs. The ontology includes 127 classes, 44 object properties, 7 data properties and 18 instances. The article also uses problem scenarios to illustrate how the DQAO can be integrated into the FAIR ecosystem.
Originality/value
The study provides valuable insights into DQA theory and practice in RDRs and offers a DQA ontology for designing, evaluating and integrating DQA workflows within RDRs.}
}
@article{GUEDDES2024121840,
title = {Remote intervention assistance system for a person in difficulty based on probabilistic ontologies},
journal = {Expert Systems with Applications},
volume = {238},
pages = {121840},
year = {2024},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2023.121840},
url = {https://www.sciencedirect.com/science/article/pii/S0957417423023424},
author = {Abdelweheb Gueddes and Mohamed Ali Mahjoub},
keywords = {Ontology, Probabilistic ontology, Semantic Web, Home support system, Bayesian Networks, Decision Support System},
abstract = {The proposed theme of this paper is to develop a system for remote intervention assistance with a person in difficulty, which is becoming increasingly important as the world’s population ages. The goal is to provide effective long-term care to reduce hospitalizations of the elderly and alleviate the burden of care for hospitals and governments. The system requires careful consideration of costs, resources, and efficiency due to the complexity and heterogeneity of the data involved, making human analysis nearly impossible. To enable machine analysis and decision-making, the proposed system is based on an ontological approach that combines medical, social, temporary, and geographical factors, along with Semantic Web Rule Language (SWRL). The system is further enhanced by the integration of probabilistic reasoning through Probabilistic Web Ontology Language (PR-OWL), which allows for the use of ontological resources in a probabilistic environment. The paper also proposes two additional approaches in the form of Jena Application Programming Interfaces (API), including ontological enrichment based on Bayesian Network (BN) knowledge bases and structural/parametric learning based on ontological knowledge bases, as well as a probabilistic clause integrated into the ontological format. As results, the proposed approaches were tested in a simulation, and feedback was collected from users. The feedback was compared, and an increase in precision was observed from one approach to another with varying execution times. These results demonstrate the effectiveness of the proposed system for remote intervention assistance and provide a foundation for future research and development in this area.}
}
@article{SHIMIZU2025100842,
title = {The KnowWhereGraph ontology},
journal = {Journal of Web Semantics},
volume = {84},
pages = {100842},
year = {2025},
issn = {1570-8268},
doi = {https://doi.org/10.1016/j.websem.2024.100842},
url = {https://www.sciencedirect.com/science/article/pii/S1570826824000283},
author = {Cogan Shimizu and Shirly Stephen and Adrita Barua and Ling Cai and Antrea Christou and Kitty Currier and Abhilekha Dalal and Colby K. Fisher and Pascal Hitzler and Krzysztof Janowicz and Wenwen Li and Zilong Liu and Mohammad Saeid Mahdavinejad and Gengchen Mai and Dean Rehberger and Mark Schildhauer and Meilin Shi and Sanaz Saki Norouzi and Yuanyuan Tian and Sizhe Wang and Zhangyu Wang and Joseph Zalewski and Lu Zhou and Rui Zhu},
keywords = {Modular ontology modeling, Ontology, Spatially enabled knowledge graphs},
abstract = {KnowWhereGraph is one of the largest fully publicly available geospatial knowledge graphs. It includes data from 30 layers on natural hazards (e.g., hurricanes, wildfires), climate variables (e.g., air temperature, precipitation), soil properties, crop and land-cover types, demographics, and human health, various place and region identifiers, among other themes. These have been leveraged through the graph by a variety of applications to address challenges in food security and agricultural supply chains; sustainability related to soil conservation practices and farm labor; and delivery of emergency humanitarian aid following a disaster. In this paper, we introduce the ontology that acts as the schema for KnowWhereGraph. This broad overview provides insight into the requirements and design specifications for the graph and its schema, including the development methodology (modular ontology modeling) and the resources utilized to implement, materialize, and deploy KnowWhereGraph with its end-user interfaces and public query SPARQL endpoint.}
}
@article{LIN2024,
title = {Dermoscopy Differential Diagnosis Explorer (D3X) Ontology to Aggregate and Link Dermoscopic Patterns to Differential Diagnoses: Development and Usability Study},
journal = {JMIR Medical Informatics},
volume = {12},
year = {2024},
issn = {2291-9694},
doi = {https://doi.org/10.2196/49613},
url = {https://www.sciencedirect.com/science/article/pii/S2291969424000693},
author = {Rebecca Z Lin and Muhammad Tuan Amith and Cynthia X Wang and John Strickley and Cui Tao},
keywords = {medical informatics, biomedical ontology, ontology, ontologies, vocabulary, OWL, web ontology language, skin, semiotic, web app, web application, visual, visualization, dermoscopic, diagnosis, diagnoses, diagnostic, information storage, information retrieval, skin lesion, skin diseases, dermoscopy differential diagnosis explorer, dermatology, dermoscopy, differential diagnosis, information storage and retrieval},
abstract = {Background
Dermoscopy is a growing field that uses microscopy to allow dermatologists and primary care physicians to identify skin lesions. For a given skin lesion, a wide variety of differential diagnoses exist, which may be challenging for inexperienced users to name and understand.
Objective
In this study, we describe the creation of the dermoscopy differential diagnosis explorer (D3X), an ontology linking dermoscopic patterns to differential diagnoses.
Methods
Existing ontologies that were incorporated into D3X include the elements of visuals ontology and dermoscopy elements of visuals ontology, which connect visual features to dermoscopic patterns. A list of differential diagnoses for each pattern was generated from the literature and in consultation with domain experts. Open-source images were incorporated from DermNet, Dermoscopedia, and open-access research papers.
Results
D3X was encoded in the OWL 2 web ontology language and includes 3041 logical axioms, 1519 classes, 103 object properties, and 20 data properties. We compared D3X with publicly available ontologies in the dermatology domain using a semiotic theory–driven metric to measure the innate qualities of D3X with others. The results indicate that D3X is adequately comparable with other ontologies of the dermatology domain.
Conclusions
The D3X ontology is a resource that can link and integrate dermoscopic differential diagnoses and supplementary information with existing ontology-based resources. Future directions include developing a web application based on D3X for dermoscopy education and clinical practice.}
}
@incollection{GUZZI2025360,
title = {Ontology in Bioinformatics},
editor = {Shoba Ranganathan and Mario Cannataro and Asif M. Khan},
booktitle = {Encyclopedia of Bioinformatics and Computational Biology (Second Edition)},
publisher = {Elsevier},
edition = {Second Edition},
address = {Oxford},
pages = {360-363},
year = {2025},
isbn = {978-0-323-95503-4},
doi = {https://doi.org/10.1016/B978-0-323-95502-7.00018-X},
url = {https://www.sciencedirect.com/science/article/pii/B978032395502700018X},
author = {Pietro H. Guzzi and Elisabetta Pedace},
keywords = {Controlled Vocabularies, Gene Ontology, Ontology for Bioinformatics, Semantics},
abstract = {In this section, we describe the main ideas of developing ontologies in the bioin-formatics field. In computer science, an ontology is defined as a specification ofconceptualizations about a domain.}
}
@article{AZZI2024850,
title = {Ontology-Boosted Deep Learning for Multi-Label Classification of Arabic Abusive Messages on Social Networks},
journal = {Procedia Computer Science},
volume = {246},
pages = {850-859},
year = {2024},
note = {28th International Conference on Knowledge Based and Intelligent information and Engineering Systems (KES 2024)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.09.504},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924025493},
author = {Salma Abid Azzi and Chiraz {Ben Othmane Zribi}},
keywords = {Ontology, Knowledge engineering, Deep Learning, BERT, Classifier Chains, Multi-label Classification, Natural Language Processing, Arabic Language, Abusive Texts, Social Media},
abstract = {With the interconnection of today’s world and the exponential growth of users’ generated data on social network, an unprecedented propagation of abusive content has emerged, particularly within the Arabic-speaking community. Deep learning models have shown promise in tackling this issue, yet they demand a substantial amount of data while having a ”black-box” nature and a limited interoperability. To address these deficits, we propose to create a representative ontology of abusive messages in Arabic as a way to replicate the domain knowledge of human beings. As part of a broader study, we have already presented a deep learning multi-label model for detecting Arabic abusive messages. However, it is worth noting that this model necessitates a substantial volume of data to demonstrate its efficacy. Our objective here is to enhance our initial contribution by creating a structured and abstract knowledge representation that aims to enrich and specialize our multi-label model while remedying to the aforementioned problems. Exploiting the ontology allows the extraction of additional features that will be fed to the initial model. These features encompass not only effective semantic knowledge but also textual and linguistic forms. Experimental results showed that our model attained a 91% micro-averaged F1-score, marking a 6-point increase compared to the initial deep learning model. Furthermore, it achieved a precision of 91% and a recall of 89%.}
}
@article{JCARLOS2025734,
title = {Semantic Mediation: a literature review on semantic interoperability through ontologies},
journal = {Procedia Computer Science},
volume = {263},
pages = {734-743},
year = {2025},
note = {International Conference on Industry Sciences and Computer Science Innovation (iSCSi’24)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2025.07.088},
url = {https://www.sciencedirect.com/science/article/pii/S1877050925021386},
author = {Martins {J. Carlos} and Baptista {Ana Alice} and Sousa {Rui M.} and Martins {Paulo J.}},
keywords = {Semantic Mediation, Semantic Interoperability, Ontology, Information Systems, Integration},
abstract = {Organisations operate in increasingly complex and dynamic environments where different Information Systems (IS) must interact efficiently and quickly. The diversity of meanings or interpretations of data in different contexts present in these IS raises problems of semantic heterogeneity, an obstacle to their integration and synchronisation. Through Semantic Mediation, it is possible to achieve the goal of Semantic Interoperability, where different informatic systems can interact and understand each other’s data in an efficient and meaningful way. This can help solve the problem of semantic heterogeneity, using a common ontology for the syntactic and semantic representation of information, and creating a semantic mediator. This study presents a systematic review of the literature on the use of ontologies to achieve semantic interoperability between informatic systems in order to determine the relevance of the Semantic Mediation Model. Databases containing articles published between 2013 and September 2024 were searched. The use of ontologies to facilitate semantic interoperability was present in 66% of the articles in this review. The most important research contexts and relevant case studies were then identified. These case study articles will be included in future research.}
}
@article{WANG2025103427,
title = {From analogy to innovation: A creative conceptual design approach leveraging large language models},
journal = {Advanced Engineering Informatics},
volume = {67},
pages = {103427},
year = {2025},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2025.103427},
url = {https://www.sciencedirect.com/science/article/pii/S1474034625003209},
author = {Boheng Wang and Xiaoyang Zhao and Haoyu Zuo and Yaxuan Song and Ji Han and Peter Childs and Liuqing Chen},
keywords = {Large language models, Conceptual product design, Analogy, Creativity, Innovation, Artificial intelligence},
abstract = {Integrating creative concepts into Product Design and Manufacturing Systems (PDMS) is important for product innovation. However, current PDMS lack cognitive capabilities, particularly in reasoning and synthesis, which are essential for conceptual design. As a result, designers face challenges in retrieving relevant analogies, establishing meaningful mappings, and integrating knowledge into new design concepts. This paper proposes a computational conceptual product design approach that integrates Large Language Models’ (LLMs) knowledge representation with an analogy-based structured retrieval mechanism, supporting designers to explore and recombine design patterns and functionalities in an intuitive manner. Benefiting from the zero-shot learning and prompting capabilities of LLMs, given a source domain, this approach allows reasoning target domain based on abstract correspondences in both morphological and semantic associations. A template for the combinational regulation of the reuse of analogical knowledge has also been formulated. By decomposing analogical knowledge into ontological distinction, inspirational feature recognition, and associative mapping explanation, a creative conceptual design stimulation path is formed. An interactive tool named ViMimic based on this approach has been developed through a case study with 18 participants. Evaluation results demonstrate that the approach improves creative performance, increasing the novelty and functionality of conceptual designs by 51% and 22% respectively according to expert evaluations. It also boosts the efficiency and diversity of analogy mapping by 30% based on objective measures, while enhancing creative experiences and reducing cognitive load as measured in the participants’ self-assessment.}
}
@incollection{ALKHALAF2025422,
title = {Biological and Medical Ontologies: Human Phenotype Ontology (HPO)},
editor = {Shoba Ranganathan and Mario Cannataro and Asif M. Khan},
booktitle = {Encyclopedia of Bioinformatics and Computational Biology (Second Edition)},
publisher = {Elsevier},
edition = {Second Edition},
address = {Oxford},
pages = {422-431},
year = {2025},
isbn = {978-0-323-95503-4},
doi = {https://doi.org/10.1016/B978-0-323-95502-7.00063-4},
url = {https://www.sciencedirect.com/science/article/pii/B9780323955027000634},
author = {Ruba {Al Khalaf} and Anna Bernasconi and Marco Masseroli},
keywords = {Biomedical ontology, Deep phenotyping, Disease, Genomic tools, Genomic variation, Health, Human phenotype, Open source ontology, Phenomic tools, Phenotypic abnormalities},
abstract = {The Human Phenotype Ontology, known as HPO, provides a standardized vocabulary of phenotypic abnormalities involved in human disease, including both clinical and pathological features, with definitions and synonyms. It is widely used in the field of human genomics and has been integrated into many databases and tools for the analysis of genetic diseases. The primary aim of the ontology is to provide the scientific community with a thorough and logical framework for delineating phenotypic anomalies associated with human diseases. Moreover, it facilitates computational inference and algorithms for integrated genomics and phenotypic analyses. The HPO is constantly updated, and it is a valuable resource for researchers and clinicians working in the field of human genetics and genomics.}
}
@article{SCHLENGER2025106111,
title = {Reference architecture and ontology framework for digital twin construction},
journal = {Automation in Construction},
volume = {174},
pages = {106111},
year = {2025},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2025.106111},
url = {https://www.sciencedirect.com/science/article/pii/S0926580525001517},
author = {Jonas Schlenger and Kacper Pluta and Alwyn Mathew and Timson Yeung and Rafael Sacks and André Borrmann},
keywords = {Digital Twin Construction (DTC), Ontology, Reference architecture, Building construction, Data management, Linked building data (LBD), Data integration, Interoperability, Digital twin (DT)},
abstract = {The application of digital twins in building construction faces challenges due to limited guidance on the necessary data management layers. This paper addresses this gap by investigating how the reference architecture for Digital Twin Construction (DTC) should be structured to manage planning information, raw monitoring data, and derived knowledge, as well as its data schema to compare project plans with status. By defining platform requirements and using Design Science Research Methodology, a solution was implemented and validated using a case study based on the ConSLAM dataset. A plugin-based DTC reference architecture employing multiple RDF graphs linked to specialized databases and the DTC Ontology as the internal data schema are introduced. This architecture guides construction companies in data-driven decision-making during execution. It establishes a foundation for managing digital twins and fosters the development of domain-specific services that benefit from clear data structures, supporting a holistic digital twin adaptable to project-specific needs.}
}
@article{DEMURO2021101307,
title = {Languages/languaging as world-making: the ontological bases of language},
journal = {Language Sciences},
volume = {83},
pages = {101307},
year = {2021},
issn = {0388-0001},
doi = {https://doi.org/10.1016/j.langsci.2020.101307},
url = {https://www.sciencedirect.com/science/article/pii/S0388000120300395},
author = {E. Demuro and L. Gurney},
keywords = {Language ideology, Ontology, Ontological turn, , Languaging, Assemblage},
abstract = {This article makes a case for an engagement with language ontologies. Rather than asking what we know about language, theorising with ontologies prompts us to engage with what language is – or, might be. This focus has potential to broaden our work from examining different perspectives on, or ideological approaches to, a single assumed phenomenon (Language), to potentially seeing multiple, different phenomena. To develop our argument theoretically, we draw primarily on research stemming from the ontological turn in anthropology (Blaser, 2009, 2013; Holbraad, 2009; Holbraad and Pedersen, 2017; Viveiros de Castro, 2013 among others), as well as linguistic anthropology (Chernela, 2018; Seargeant, 2010). We dialogue across fields and disciplines—with philosophy, science and technology studies (Latour, 1993; Law, 2015), decolonial studies (Escobar, 2016) and language studies (García and Li, 2014; Li, 2018; Makoni and Pennycook, 2006; Pennycook, 2017, among others)—to situate language ontologies as worlded through linguistic practices. To contextualise the discussion, the paper explores three ontologies of language: language as object, language as practice, and language as assemblage.}
}
@article{DALLY2024,
title = {A Semantic Approach to Describe Social and Economic Characteristics That Impact Health Outcomes (Social Determinants of Health): Ontology Development Study},
journal = {Online Journal of Public Health Informatics},
volume = {16},
year = {2024},
issn = {1947-2579},
doi = {https://doi.org/10.2196/52845},
url = {https://www.sciencedirect.com/science/article/pii/S1947257924000045},
author = {Daniela Dally and Muhammad Amith and Rebecca L Mauldin and Latisha Thomas and Yifang Dang and Cui Tao},
keywords = {social determinants of health, ontology, semantics, knowledge representation},
abstract = {Background
Social determinants of health (SDoH) have been described by the World Health Organization as the conditions in which individuals are born, live, work, and age. These conditions can be grouped into 3 interrelated levels known as macrolevel (societal), mesolevel (community), and microlevel (individual) determinants. The scope of SDoH expands beyond the biomedical level, and there remains a need to connect other areas such as economics, public policy, and social factors.
Objective
Providing a computable artifact that can link health data to concepts involving the different levels of determinants may improve our understanding of the impact SDoH have on human populations. Modeling SDoH may help to reduce existing gaps in the literature through explicit links between the determinants and biological factors. This in turn can allow researchers and clinicians to make better sense of data and discover new knowledge through the use of semantic links.
Methods
An experimental ontology was developed to represent knowledge of the social and economic characteristics of SDoH. Information from 27 literature sources was analyzed to gather concepts and encoded using Web Ontology Language, version 2 (OWL2) and Protégé. Four evaluators independently reviewed the ontology axioms using natural language translation. The analyses from the evaluations and selected terminologies from the Basic Formal Ontology were used to create a revised ontology with a broad spectrum of knowledge concepts ranging from the macrolevel to the microlevel determinants.
Results
The literature search identified several topics of discussion for each determinant level. Publications for the macrolevel determinants centered around health policy, income inequality, welfare, and the environment. Articles relating to the mesolevel determinants discussed work, work conditions, psychosocial factors, socioeconomic position, outcomes, food, poverty, housing, and crime. Finally, sources found for the microlevel determinants examined gender, ethnicity, race, and behavior. Concepts were gathered from the literature and used to produce an ontology consisting of 383 classes, 109 object properties, and 748 logical axioms. A reasoning test revealed no inconsistent axioms.
Conclusions
This ontology models heterogeneous social and economic concepts to represent aspects of SDoH. The scope of SDoH is expansive, and although the ontology is broad, it is still in its early stages. To our current understanding, this ontology represents the first attempt to concentrate on knowledge concepts that are currently not covered by existing ontologies. Future direction will include further expanding the ontology to link with other biomedical ontologies, including alignment for granular semantics.}
}
@article{ABDALAZEIM2021328,
title = {A review of the generation of requirements specification in natural language using objects UML models and domain ontology},
journal = {Procedia Computer Science},
volume = {189},
pages = {328-334},
year = {2021},
note = {AI in Computational Linguistics},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2021.05.102},
url = {https://www.sciencedirect.com/science/article/pii/S1877050921012266},
author = {Alaa Abdalazeim and Farid Meziane},
keywords = {Requirements Specification, Natural Language Generation, Object UML Model, Ontology},
abstract = {In the software development life cycle, requirements engineering is the main process that is derived from users by informal interviews written in natural language by requirements engineers (analysts). The requirements may suffer from incompleteness and ambiguity when transformed into formal or semi-formal models that are not well understood by stakeholders. Hence, the stakeholder cannot verify if the formal or semi-formal models satisfy their needs and requirements. Another problem faced by requirements is that when code and/or designs are updated, it is often the case that requirements and specifically the requirements document are not updated. Hence ending with a requirements document not reflecting the implemented software. Generating requirements from the design and/or implementation document is seen by many researchers as a way to address the latter issue. This paper presents a survey of some works undertaken in the field of generation natural language specifications from object UML model using the support of an ontology. and analyzing the robustness and limitations of these existing approaches. This includes studying the generation of natural language from a formal model, review the generation of natural language from ontologies, and finally reviews studies about check to generate natural language from OntoUML.}
}
@article{DU2023101991,
title = {City infrastructure ontologies},
journal = {Computers, Environment and Urban Systems},
volume = {104},
pages = {101991},
year = {2023},
issn = {0198-9715},
doi = {https://doi.org/10.1016/j.compenvurbsys.2023.101991},
url = {https://www.sciencedirect.com/science/article/pii/S0198971523000546},
author = {Heshan Du and Lijun Wei and Vania Dimitrova and Derek Magee and Barry Clarke and Richard Collins and David Entwisle and Mehran {Eskandari Torbaghan} and Giulio Curioni and Ross Stirling and Helen Reeves and Anthony G. Cohn},
keywords = {City infrastructure, Model, Ontology, Integrated inter-asset management},
abstract = {Sustainable urban infrastructure planning and maintenance require an integrated approach that considers various infrastructure assets (e.g., the ground, roads, and buried pipes) and their inter-linkages as a holistic system. To facilitate the usage of this integrated approach, we propose a model of city infrastructure assets and their interdependencies, providing details on how asset properties and processes affect each other. This model is represented as ontologies in OWL 2 Web Ontology Language Manchester Syntax, which can be read and interpreted by machines automatically. These ontologies cover the classifications, properties and processes of the ground, roads and buried water pipes, as well as some related human activities and natural phenomena (e.g., precipitation). The ontologies not only provide a foundation for integrating various types of infrastructure and environmental data, but also for understanding the potential knock-on effects of asset failures. The ontologies have been utilised in a decision support system for integrated urban inter-asset management.}
}
@article{ANTONIOU2024102323,
title = {Semantic requirements construction using ontologies and boilerplates},
journal = {Data & Knowledge Engineering},
volume = {152},
pages = {102323},
year = {2024},
issn = {0169-023X},
doi = {https://doi.org/10.1016/j.datak.2024.102323},
url = {https://www.sciencedirect.com/science/article/pii/S0169023X24000478},
author = {Christina Antoniou and Kalliopi Kravari and Nick Bassiliades},
keywords = {Requirement boilerplates, Requirements, Ontology, Requirement specification},
abstract = {This paper presents a combination of an ontology and boilerplates, which are requirements templates for the syntactic structure of individual requirements that try to alleviate the problem of ambiguity caused using natural language and make it easier for inexperienced engineers to create requirements. However, still the use of boilerplates restricts the use of natural language only syntactically and not semantically. Boilerplates consists of fixed and attributes elements. Using ontologies, restricts the vocabulary of the words used in the requirements boilerplates to entities, their properties and entity relationships that are semantically meaningful to the application domain, leading thus to fewer errors. In this work we combine the advantages of boilerplates and ontologies. Usually, the attributes of boilerplates are completed with the help of the ontology. The contribution of this paper is that the whole boilerplates are stored in the ontology, based on the fact that RDF triples have similar syntax to the boilerplate syntax, so that attributes and fixed elements are part of the ontology. This combination helps to construct semantically and syntactically correct requirements. The contribution and novelty of our method is that we exploit the natural language syntax of boilerplates mapping them to Resource Description Framework triples which have also a linguistic nature. In this paper we created and present the development of a domain-specific ontology as well as a minimal set of boilerplates for a specific application domain, namely that of engineering software for an ATM, while maintaining flexibility on the one hand and generality on the other.}
}
@article{DEBARROSVANZIN2025103204,
title = {LLM-based approaches for automated vocabulary mapping between SIGTAP and OMOP CDM concepts},
journal = {Artificial Intelligence in Medicine},
volume = {168},
pages = {103204},
year = {2025},
issn = {0933-3657},
doi = {https://doi.org/10.1016/j.artmed.2025.103204},
url = {https://www.sciencedirect.com/science/article/pii/S0933365725001393},
author = {Vinícius João {de Barros Vanzin} and Dilvan {de Abreu Moreira} and Ricardo {Marcondes Marcacini}},
keywords = {Ontology mapping, Retrieval-augmented generation, LLM agent},
abstract = {In the context of global healthcare systems, integrating diverse medical terminologies and classification systems has become a priority due to the adoption of Electronic Health Record (EHR) systems and the imperative for information exchange between healthcare systems. This study addresses the necessity for mapping between the SIGTAP vocabulary used in Brazilian healthcare systems and the broader medical terms of the OMOP CDM terminologies. Two distinct pipelines are evaluated for the vocabulary mapping process, focusing on two subsets of the SIGTAP vocabulary: medicines and medical procedures. The first pipeline utilizes textual embeddings for semantic similarity evaluation, followed by Large Language Models (LLMs) for correspondences selection through a retrieval-augmented generation (RAG) approach. In the second pipeline, LLM agents employ predefined protocols for vocabulary mapping and query refinement. Our results show comparable performance between pipelines in both the Procedures subset (F1 of 0.684 versus 0.678), and the Medicines subset (F1 of 0.846 versus 0.839), indicating the viability of the multi-stage filtering approach. The second pipeline demonstrates an advantage over the first in terms of recall, highlighting the efficacy of dynamic query refinement by the agent. These findings provide evidence that LLM-based methods significantly reduce manual effort required by experts, enabling domain specialists to focus on more challenging cases.}
}
@article{HOSEINI2024100819,
title = {A survey on semantic data management as intersection of ontology-based data access, semantic modeling and data lakes},
journal = {Journal of Web Semantics},
volume = {81},
pages = {100819},
year = {2024},
issn = {1570-8268},
doi = {https://doi.org/10.1016/j.websem.2024.100819},
url = {https://www.sciencedirect.com/science/article/pii/S1570826824000052},
author = {Sayed Hoseini and Johannes Theissen-Lipp and Christoph Quix},
keywords = {Semantic data management, Semantic web, Big data, Data lakes, Ontology-based data-access},
abstract = {In recent years, data lakes emerged as a way to manage large amounts of heterogeneous data for modern data analytics. One way to prevent data lakes from turning into inoperable data swamps is semantic data management. Such approaches propose the linkage of metadata to knowledge graphs based on the Linked Data principles to provide more meaning and semantics to the data in the lake. Such a semantic layer may be utilized not only for data management but also to tackle the problem of data integration from heterogeneous sources, in order to make data access more expressive and interoperable. In this survey, we review recent approaches with a specific focus on the application within data lake systems and scalability to Big Data. We classify the approaches into (i) basic semantic data management, (ii) semantic modeling approaches for enriching metadata in data lakes, and (iii) methods for ontology-based data access. In each category, we cover the main techniques and their background, and compare latest research. Finally, we point out challenges for future work in this research area, which needs a closer integration of Big Data and Semantic Web technologies.}
}
@article{ZHANG2025106189,
title = {Integration of BIM and ontologies for pumped storage hydropower design change management in EPC projects},
journal = {Automation in Construction},
volume = {175},
pages = {106189},
year = {2025},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2025.106189},
url = {https://www.sciencedirect.com/science/article/pii/S0926580525002298},
author = {Shihang Zhang and Sherong Zhang and Han Liu and Xiaohua Wang and Zhiyong Zhao and Chao Wang and Lei Yan},
keywords = {Building Information Modeling (BIM), Engineering, Procurement and Construction, Ontology integration, Industry Foundation Classes (IFC), BIM Collaboration Format (BCF), Pumped hydro energy storage, Carbon neutrality},
abstract = {Design changes are an inevitable multidisciplinary issue in the Engineering, Procurement, and Construction (EPC) projects for pumped storage hydropower systems. However, semantic heterogeneity poses significant challenges making Building Information Modeling (BIM) workflows for design change management time-consuming and error-prone. To address this issue, this paper proposes an ontology integration approach that unifies decentralized knowledge of Industry Foundation Classes (IFC) and the BIM Collaboration Format (BCF). A Semantic Design Change Management System (SDCMS) is developed for EPC contractors and validated through a case study. The results indicate that the proposed approach achieves significant improvements in system efficiency and data standardization. This paper highlights the potential for knowledge reuse to automate BIM workflows and provides practical insights into renewable energy construction management in the context of energy transition and carbon neutrality.}
}
@article{KANG2025103145,
title = {LLM-DG: Leveraging large language model for enhanced disease prediction via inter-patient and intra-patient modeling},
journal = {Information Fusion},
volume = {121},
pages = {103145},
year = {2025},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2025.103145},
url = {https://www.sciencedirect.com/science/article/pii/S1566253525002180},
author = {Yan Kang and Mingjian Yang and Yue Peng and Jingwen Cai and Lei Zhao and Zhan Gao and Ningshu Li and Bin Pu},
keywords = {Electronic health records, Large language model, Diseases prediction, Multiple domain knowledge fusion},
abstract = {Existing methods play a crucial role in clinical decision support by enabling disease prediction and personalizing healthcare based on swiftly accumulated electronic Health Records (EHRs). However, these methods often overlook multi-source data integration by relying solely on specific domain knowledge and fail to model intricate relationships among patients as focusing on inter or intra-patient relationships, respectively. To address these limitations, we propose LLM-DG, a multi-level health event prediction framework enhanced by large language models (LLMs). Specifically, LLM performs semantic enhancement for patient and discharge summary representations and injects domain knowledge into disease modeling, improving prediction accuracy and robustness. Moreover, LLM-DG synchronously models inter-patient and intra-patient relationships by capturing high-order patient correlations and fusing dynamic and static patient features. At the inter-patient level, LLM-DG clusters patients based on LLM-enhanced features, identifying similar health trajectories. At the intra-patient level, it models disease evolution characteristics through a dynamic graph and extracts textual information from LLM-enhanced discharge summaries using a text encoder. Experiments on MIMIC-III and MIMIC-IV datasets demonstrate that LLM-DG significantly outperforms state-of-the-art models, achieving a 12.39% improvement in w-F1 on the diagnosis prediction task of the MIMIC-IV dataset. Overall, LLM-DG demonstrates strong potential in complex healthcare environments by integrating patient histories and cross-patient health patterns, highlighting its applicability in clinical decision support and personalized treatment planning.}
}
@incollection{GUZZI2025432,
title = {Ontology-based Annotation Methods},
editor = {Shoba Ranganathan and Mario Cannataro and Asif M. Khan},
booktitle = {Encyclopedia of Bioinformatics and Computational Biology (Second Edition)},
publisher = {Elsevier},
edition = {Second Edition},
address = {Oxford},
pages = {432-437},
year = {2025},
isbn = {978-0-323-95503-4},
doi = {https://doi.org/10.1016/B978-0-323-95502-7.00194-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780323955027001949},
author = {Pietro H. Guzzi and Pietro Cinaglia and Marianna Milano},
keywords = {Annotations, Ontology-based annotations and Ontology for bioinformatics},
abstract = {Automated indexing of biological data is crucial for searching and retrieving relevant information. Annotations provide a reference to biological data by marking up the meaning of simple information, such as protein sequences or experimental observations. They help represent biologically significant data that supports analysis, comparison, and browsing. Ontology-based annotation is a process of annotating data using metadata extracted from existing ontologies. In this section, we will describe the key principles behind the methods of ontology-based annotation.}
}
@article{CARMELITI2025443,
title = {CRMrp: An ontology to support the digital documentation of the conservation and restoration practice},
journal = {Journal of Cultural Heritage},
volume = {73},
pages = {443-453},
year = {2025},
issn = {1296-2074},
doi = {https://doi.org/10.1016/j.culher.2025.04.021},
url = {https://www.sciencedirect.com/science/article/pii/S1296207425000779},
author = {Maria Carmeliti and Chiara Eva Catalano},
keywords = {Cultural heritage, Conservation and restoration process, Ontologies, 3D Semantic annotation},
abstract = {Restoration is the moment when a work of art is rediscovered and becomes part of its history. For this reason, the numerous data that usually accompany each intervention must be archived, structured, and shared among different practitioners in the domain of conservation of cultural heritage. This sector is moving towards a complete digitisation and then the generated information is wide, complex and heterogeneous: data are not only textual, such as restoration projects and reports, but also include diagnostic analysis results, photographs obtained by archaeometric investigations, photogrammetric datasets and 3D models, vector graphs and information related to the history of the considered artwork. The main aim of this research is to provide a sound methodology for the digital documentation of the restoration process. The contribution is twofold. On the one hand, a specific restoration knowledge organisation system has been defined to support data classification, based on international regulations and vocabularies. On the other hand, the CRMrp ontology has been realised, based on CIDOC CRM and specifically designed to represent all the restoration activities carried out on an artwork throughout its life cycle.}
}
@article{MENOTTI2023100332,
title = {Modelling digital health data: The ExaMode ontology for computational pathology},
journal = {Journal of Pathology Informatics},
volume = {14},
pages = {100332},
year = {2023},
issn = {2153-3539},
doi = {https://doi.org/10.1016/j.jpi.2023.100332},
url = {https://www.sciencedirect.com/science/article/pii/S2153353923001463},
author = {Laura Menotti and Gianmaria Silvello and Manfredo Atzori and Svetla Boytcheva and Francesco Ciompi and Giorgio Maria {Di Nunzio} and Filippo Fraggetta and Fabio Giachelle and Ornella Irrera and Stefano Marchesin and Niccolò Marini and Henning Müller and Todor Primov},
keywords = {Computational pathology, Ontology, Semantic integration, Histopathology},
abstract = {Computational pathology can significantly benefit from ontologies to standardize the employed nomenclature and help with knowledge extraction processes for high-quality annotated image datasets. The end goal is to reach a shared model for digital pathology to overcome data variability and integration problems. Indeed, data annotation in such a specific domain is still an unsolved challenge and datasets cannot be steadily reused in diverse contexts due to heterogeneity issues of the adopted labels, multilingualism, and different clinical practices.
Material and methods
This paper presents the ExaMode ontology, modeling the histopathology process by considering 3 key cancer diseases (colon, cervical, and lung tumors) and celiac disease. The ExaMode ontology has been designed bottom-up in an iterative fashion with continuous feedback and validation from pathologists and clinicians. The ontology is organized into 5 semantic areas that defines an ontological template to model any disease of interest in histopathology.
Results
The ExaMode ontology is currently being used as a common semantic layer in: (i) an entity linking tool for the automatic annotation of medical records; (ii) a web-based collaborative annotation tool for histopathology text reports; and (iii) a software platform for building holistic solutions integrating multimodal histopathology data.
Discussion
The ontology ExaMode is a key means to store data in a graph database according to the RDF data model. The creation of an RDF dataset can help develop more accurate algorithms for image analysis, especially in the field of digital pathology. This approach allows for seamless data integration and a unified query access point, from which we can extract relevant clinical insights about the considered diseases using SPARQL queries.}
}
@article{MONTANARO2024,
title = {Beyond natural language: an ontology-based description of a new Scarabaeus dung beetle from Madagascar (Coleoptera, Scarabaeinae)},
journal = {Biodiversity Data Journal},
volume = {12},
year = {2024},
issn = {1314-2836},
doi = {https://doi.org/10.3897/BDJ.12.e134364},
url = {https://www.sciencedirect.com/science/article/pii/S1314283624002823},
author = {Giulio Montanaro and Sergei Tarasov},
keywords = {dung beetles, computable phenotypes, taxonomy, semantic technologies, Phenoscript, nanopublications, FAIR data},
abstract = {Background
The dung beetle genus Scarabaeus (Coleoptera, Scarabaeinae, Scarabaeini), predominantly found in the arid regions of the Old World, includes three endemic species inhabiting the dry ecosystems of western and southern Madagascar. These species are presumed to form a monophyletic clade nested within the African Scarabaeus. Semantic modelling of phenotypes using ontologies represents a transformative approach to species description in biology, making phenotypic data FAIR and computable. The recently developed Phenoscript language enables the creation of semantic, computable species descriptions using a syntax akin to human natural language (NL). However, Phenoscript has not yet been tested as a tool for describing new taxa.
New information
In this study, we test the utility of Phenoscript by describing a new species, Scarabaeus (sensu lato) sakalava sp. nov. from Madagascar. The initial description is composed directly in Phenoscript, replacing the traditional natural language format. This Phenoscript description is then translated into a human-readable form using the Phenospy tool for publication purposes. Additionally, the Phenoscript description is converted into an RDF graph, making it understandable by computers using semantic technologies. Scarabaeus sakalava sp. nov. is found in western central Madagascar and is closely related to S. viettei (Paulian, 1953) from north-western Madagascar. We provide an updated identification key and distribution map for all Malagasy Scarabaeus and discuss their systematic placement.}
}
@article{ALKHUZAEY20243542,
title = {Generating Complex Questions from Ontologies with Query Graphs},
journal = {Procedia Computer Science},
volume = {246},
pages = {3542-3555},
year = {2024},
note = {28th International Conference on Knowledge Based and Intelligent information and Engineering Systems (KES 2024)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.09.694},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924027546},
author = {Samah AlKhuzaey and Floriana Grasso and Terry R. Payne and Valentina Tamma},
keywords = {Ontologies, Automatic Question Generation, Assessment, Education},
abstract = {This paper presents a novel approach to ontology-based automatic question generation (AQG), which aims to facilitate the creation of ‘complex’ educational questions, i.e. questions requiring larger knowledge cover and higher cognitive/reasoning processes. We leverage on the notion of Query Graphs, a graph-like structure that can represent natural language queries through appropriate mappings, previously used for semantic parsing. We propose the use of Query Graphs as a formalism for representing templates that incorporate multiple ontology-based constraints during question generation, which can then guide the selection of relevant ontology elements and properties. By incorporating these constraints, our approach elevates the level of reasoning required to answer the questions, therefore overcoming the limitations of existing methodologies. We evaluate the approach by modelling templates for AQG and comparing the resulting questions with existing state-of-the-art methods, on performance based on complexity levels. The empirical evaluation demonstrates that our model is indeed able to generate questions that demand higher cognitive skills.}
}
@article{BHUSHAN2024109000,
title = {An ontological knowledge-based method for handling feature model defects due to dead feature},
journal = {Engineering Applications of Artificial Intelligence},
volume = {136},
pages = {109000},
year = {2024},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2024.109000},
url = {https://www.sciencedirect.com/science/article/pii/S0952197624011588},
author = {Megha Bhushan and José Ángel {Galindo Duarte} and Arun Negi and Piyush Samant},
keywords = {Software product line, Dead feature, Knowledge-based method, Knowledge representation, Feature model, Ontology},
abstract = {The specifications of a certain domain are addressed by a portfolio of software products, known as Software Product Line (SPL). Feature Model (FM) supports domain engineering by modeling domain knowledge along with variability among SPL. The quality of FM is one of the significant factors for the successful SPL in order to attain high quality software products. However, the benefits of SPL can be reduced due to defects in FM. Dead Feature (DF) is one of such defects. Several approaches exist in the literature to detect defects due to DF in FMs. But only a few can handle their sources and solutions which are cumbersome and difficult to understand by humans. An ontological knowledge-based method for handling defects due to DF in FMs is described in this paper. It specifies FM in the form of ontology-based knowledge representation. The rules based on first-order logic are created and implemented using Prolog to detect defects due to DF with sources as well as suggest solutions to resolve these defects. A case study of the product line available on SPLOT repository is utilized for illustrating the proposed work. The experiments are performed with real-world FMs of varied sizes from SPLOT and FMs created with the FeatureIDE tool. The results prove the efficiency, scalability (up to model with 32,000 features) and accuracy of the presented method. Therefore, reusability of DFs free knowledge enables deriving defect free products from SPL and eventually enhances the quality of SPL.}
}
@article{YI2025104250,
title = {Domain ontology to integrate building-integrated photovoltaic, battery energy storage, and building energy flexibility information for explicable operation and maintenance},
journal = {Computers in Industry},
volume = {166},
pages = {104250},
year = {2025},
issn = {0166-3615},
doi = {https://doi.org/10.1016/j.compind.2025.104250},
url = {https://www.sciencedirect.com/science/article/pii/S0166361525000156},
author = {Xiaoyue Yi and Llewellyn Tang and Reynold Cheng and Mengtian Yin and Yu Zheng},
keywords = {Building-integrated photovoltaics, Battery energy storage systems, Building energy flexible control, Ontology, Operation and maintenance, Data interoperability},
abstract = {Building-integrated photovoltaics (BIPV) incorporated with battery energy storage (BES) and building energy flexibility (BEF) system is nowadays increasingly prevalent. During the operation and maintenance (O&M) of BIPV, BES, and BEF, various knowledge is contained and generated. This highlights information interaction among systems and the demand for incorporating diverse domain knowledge. However, these systems remain relatively isolated during O&M and suffer from inadequate machine-readable knowledge representation. In the era of semantic web technology, ontology-based methods are promising to integrate heterogeneous information. This study developed a domain ontology named “BIPV-BES-BEF” to integrate BIPV, BES, and BEF O&M information by enriching ontology semantics through relevant standards and leveraging existing ontology resources. In the process ontology construction, classes associated with BIPV, BES, and BEF were initially identified from relevant ontologies based on concepts in authorized codes. The classes with high cosine similarity within these recognized classes were subsequently integrated. Concepts and rules concerning the O&M of BIPV, BES, and BEF from relevant standards were then incorporated to the ontology and semantic web rules. The resulting ontology consists of a total of 2595 axioms and 649 classes, encompassing comprehensive concepts related to BIPV, BES, and BEF components, system specifics, assessment criteria, as well as O&M elements. The built ontology was assessed to be coherent and capable of reasoning through the built knowledge. This study contributes to an ontology purposing BIPV, BES, and BEF O&M, highlighting the potential of ontology-based approaches in BIPV, BES, and BEF data integration and knowledge inference.}
}
@article{WANG2024102065,
title = {Knowledge ontology enhanced model for explainable knowledge tracing},
journal = {Journal of King Saud University - Computer and Information Sciences},
volume = {36},
number = {5},
pages = {102065},
year = {2024},
issn = {1319-1578},
doi = {https://doi.org/10.1016/j.jksuci.2024.102065},
url = {https://www.sciencedirect.com/science/article/pii/S131915782400154X},
author = {Yao Wang and Yujia Huo and Changxiao Yang and Xingchen Huang and Dawen Xia and Fujian Feng},
keywords = {Intelligent Tutoring Systems, Knowledge tracing, Knowledge ontology, Evaluation performance},
abstract = {Knowledge Tracing (KT) aims to predict learners’ future learning outcomes based on their past learning interactions. Deep Knowledge Tracing (DKT) is a technology developed in recent years that employs deep learning techniques to dynamically track students’ learning progress and offer personalized learning support. Yet, existing research often miss the complex interplay between student characteristics and knowledge components, limiting interpretability and adaptability in assessments. Addressing this gap, we introduce the Ontology Perceptible Knowledge Tracing (OPKT) model, a novel approach that reconceptualizes student-knowledge interaction by integrating both student and knowledge ontologies directly into the tracing process. This integration allows for a more nuanced representation of learning interactions, significantly enhancing the predictive precision and interpretability of the model. The OPKT model extracts and utilizes ontology features—deriving student attributes from behavioral data and aligning them with knowledge aspects through sophisticated relationship mapping. This dual-layer integration captures the evolution of knowledge states more accurately, facilitating targeted educational interventions. The results of prediction on two publicly available datasets demonstrate that our proposed OPKT model achieves at least a 2% improvement in AUC, accurately assessing students’ learning outcomes and knowledge proficiency. Additionally, we conducted dimensionality reduction experiments and ablation studies to validate the interpretability of the model.}
}
@article{TRAPPEY2025102332,
title = {Patent litigation mining using a large language model—Taking unmanned aerial vehicle development as the case domain},
journal = {World Patent Information},
volume = {80},
pages = {102332},
year = {2025},
issn = {0172-2190},
doi = {https://doi.org/10.1016/j.wpi.2024.102332},
url = {https://www.sciencedirect.com/science/article/pii/S0172219024000723},
author = {Amy J.C. Trappey and Shao-Chien Chou and Gi-Kuen J. Li},
keywords = {Unmanned aerial vehicle (UAV), Drone, Patent analysis, Patent litigation mining, Technology function matrix, Dynamic topic modeling, Large language model},
abstract = {As unmanned aerial vehicle (UAV), also called “drone”, swiftly advances with innovative functions and applications, the surge in patent applications has profoundly reshaped the intellectual property (IP) landscape in the UAV industry, leading to a growing number of litigations. This study is structured in two phases, aiming to develop an intelligent approach to analyzing the trend and evolution of patent litigations. The first phase involves macro- and micro-patent analyses of the related technology domain. Macro patent analysis elucidates the fundamental patent information in the drone industry, while micro patent analysis leverages the technology function matrix (TFM) to identify R&D hotspots and potentials. The second phase involves litigation (judgement) mining based on large language model (LLM). Beginning with the construction of a knowledge ontology, the domain infringement landscape can be detected through TFMs. A comparative analysis of the two-phase TFMs (i.e., both TFMs of patent and infringement allocations) is then conducted to pinpoint the key legal actions and the relevant technology. To drill deeper in infringement mining, dynamic topic modeling (DTM) is applied to analyze trends and dynamics in drone controller technology over time. This study aims to strengthen IP protection by developing an intelligent litigation mining approach that adopts large language model (LLM) and uses UAV/drone litigation studies as examples to show how the approach being applied in the industry.}
}
@article{WEN2023100134,
title = {Construction and application of a multilevel geohazard domain ontology: A case study of landslide geohazards},
journal = {Applied Computing and Geosciences},
volume = {20},
pages = {100134},
year = {2023},
issn = {2590-1974},
doi = {https://doi.org/10.1016/j.acags.2023.100134},
url = {https://www.sciencedirect.com/science/article/pii/S259019742300023X},
author = {Min Wen and Qinjun Qiu and Shiyu Zheng and Kai Ma and Shuai Zheng and Zhong Xie and Liufeng Tao},
keywords = {Geological hazard ontology, Landslide geohazard, Unified description model, Information retrieval},
abstract = {The occurrence of geohazards entails sudden, unpredictable, and cascading effects, with numerous conceptual frameworks and intricate spatiotemporal relationships existing between hazard events. Presently, the absence of a unified mechanism for describing and expressing geohazard knowledge poses substantial challenges in terms of sharing and reusing domain-specific knowledge pertaining to geohazards. Therefore, it is imperative to address the issue of constructing a cohesive descriptive model that facilitates the sharing and reuse of geohazard knowledge. In this study, we propose a multilayered ontology construction method tailored specifically for the domain of landslide geological hazards. By comparing existing methods, we establish a hierarchical structure and expression framework for the geological hazard ontology. Notably, our approach seamlessly integrates the conceptual and semantic layers in the relationship description at each level, enabling association representation of hazard data across multiple tiers. We define essential concepts and attributes related to landslide geological hazards, along with their respective interrelationships. To achieve effective knowledge sharing and reuse, we model the ontology of the landslide geological disaster domain using the Web Ontology Language (OWL). This modeling approach serves as a powerful tool that facilitates the sharing and reuse of disaster-related knowledge. Finally, we verify the method's validity and reliability by employing illustrative case studies. The results demonstrate that the proposed approach imposes an affordable workload on human resources. Additionally, the foundational domain ontology significantly enhances information retrieval performance, thereby yielding satisfactory outcomes.}
}
@article{JHA20251925,
title = {A Domain Ontology For Safety of Road Users – SafeOn: Overview & Design},
journal = {Transportation Research Procedia},
volume = {82},
pages = {1925-1948},
year = {2025},
note = {World Conference on Transport Research - WCTR 2023 Montreal 17-21 July 2023},
issn = {2352-1465},
doi = {https://doi.org/10.1016/j.trpro.2024.12.164},
url = {https://www.sciencedirect.com/science/article/pii/S2352146524004630},
author = {Alok Nikhil Jha and Rajesh Kr. Gupta and Niladri Chatterjee and Geetam Tiwari},
keywords = {Road user safety, Accident Analysis, Ontology, Cyrus Mistry. Modelling Safety},
abstract = {Road traffic incidents are a matter of global concern. The accident data plays a significant role in prevention and accident management and getting deeper insights for designing better policies and guidelines. Effective management of the collected accident information should ensure the effective utilization of the information so that multiple outputs can be created and used in various types of safety analysis. We are developing SafeOn – a domain ontology for road user safety ontology. SafeOn is developed for India and uses a bottom-up approach in Protégé and OWL. Our proposed Safety Ontology (SafeOn) organizes accident for detailed analysis of various aspects of road safety. It offers features of interoperability to integrate with crash data of other departments like healthcare, and road design for better insights, policy decisions, and accident prevention plans. We instantiated SafeOn with the accident case of Cyrus Mistry. We integrated the accident information with SafeOn and generated the knowledge graph. This graph is capable of speedy analysis of road accidents and can efficiently answer all the questions related to that accident. SafeOn is useful for road safety departments to design better policies, resolve problems of missing information in hit-and-run crashes, and ensure the saving life of road users.}
}
@article{SHI202443,
title = {Research of Parts Geometric Tolerance Measurement and Certification Based on Ontology},
journal = {Procedia CIRP},
volume = {129},
pages = {43-48},
year = {2024},
note = {18th CIRP Conference on Computer Aided Tolerancing (CAT2024)},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2024.10.009},
url = {https://www.sciencedirect.com/science/article/pii/S2212827124011454},
author = {Zhongkun Shi and Meifa Huang and Yanru Zhong and Weihao Hu and Zhecheng Hu},
keywords = {Tolerance measurement and certification, Ontology, Relational rules, Automatic generation},
abstract = {Geometric tolerance measurement certification of parts is a key factor in determining product quality, production cost and competitiveness. The existing certification schemes for tolerance measurement rely heavily on the experience and proficiency of surveyors, which increases the uncertainty of the certification results for tolerance measurement. In this paper, the ontology is introduced into the geometric tolerance measurement certification, which provides a feasible method for the automation and intelligence of the geometric tolerance measurement certification of parts. Firstly, the engineering semantics of the tolerance measurement and certification process is extracted from the part drawings, and the OWL ontology representation model of the product is established. Secondly, according to the expert knowledge in the field of tolerance measurement certification, the semantic Web rule language SWRL is used to extract, induce and summarize the terminology relations involved in tolerance measurement certification, and these relations are converted into inference rules. Then, according to the semantic model and relation rules established above, the geometric tolerance measurement certification scheme of parts is automatically generated, so as to construct the ontology knowledge base of geometric tolerance measurement certification of parts. Finally, taking reducer box hole as an example, the automatic generation process of box hole coaxiality measurement authentication scheme is demonstrated, and its effectiveness is verified.}
}
@article{HU2024102766,
title = {An ontology and rule-based method for human–robot collaborative disassembly planning in smart remanufacturing},
journal = {Robotics and Computer-Integrated Manufacturing},
volume = {89},
pages = {102766},
year = {2024},
issn = {0736-5845},
doi = {https://doi.org/10.1016/j.rcim.2024.102766},
url = {https://www.sciencedirect.com/science/article/pii/S0736584524000528},
author = {Youxi Hu and Chao Liu and Ming Zhang and Yuqian Lu and Yu Jia and Yuchun Xu},
keywords = {Human–Robot Collaborative Disassembly (HRCD), Ontology, Semantic Web Rule Language (SWRL) rule, Disassembly planning, Remanufacturing},
abstract = {Disassembly is a decisive step in the remanufacturing process of End-of-Life (EoL) products. As an emerging semi-automatic disassembly paradigm, human–robot collaborative disassembly (HRCD) offers multiple disassembly methods to enhance flexibility and efficiency. However, HRCD increases the complexity of planning and determining the optimal disassembly sequence and scheme. Currently, the optimisation process of heuristic methods is difficult to interpret, and the results cannot be guaranteed as globally optimal. Consequently, this paper introduces a general ontology model for HRCD, along with a rule-based reasoning method, to automatically generate the optimal disassembly sequence and scheme. Firstly, the HRCD ontology model establishes the disassembly-related information for EoL products in a standardised approach. Then, customised disassembly-related rules are proposed to regulate the precedence constraints and optional disassembly methods for each disassembly task of EoL products. The optimal disassembly sequence and scheme are automatically generated by combining supportive rules with the ontology model. Lastly, the human–robot collaborative disassembly planning of a gearbox is presented as a case study to validate the feasibility of the proposed methods. Our method generates an optimal disassembly scheme compared with other heuristic algorithms, achieving the shortest process time of 308 units and the fewest number of disassembly direction change of 3 times. Additionally, the reasoning procedure can be easily tracked and modified. The proposed method is both universal and easily reproducible, allowing it to be extended to support the entire remanufacturing process.}
}
@article{MANN2023108446,
title = {SUSIE: Pharmaceutical CMC ontology-based information extraction for drug development using machine learning},
journal = {Computers & Chemical Engineering},
volume = {179},
pages = {108446},
year = {2023},
issn = {0098-1354},
doi = {https://doi.org/10.1016/j.compchemeng.2023.108446},
url = {https://www.sciencedirect.com/science/article/pii/S0098135423003162},
author = {Vipul Mann and Shekhar Viswanath and Shankar Vaidyaraman and Jeya Balakrishnan and Venkat Venkatasubramanian},
keywords = {Ontology, Pharmaceutical drug development, Information extraction, Hybrid machine learning, Chemistry manufacturing and control},
abstract = {Automatically extracting information from unstructured text in pharmaceutical documents is important for drug discovery and development. This information can be integrated with structured datasets to ultimately accelerate pharmaceutical product development. To this end, we report an end-to-end information extraction framework based on a custom-built pharmaceutical drug development ontology, a weak supervision framework, contextualization algorithms, and a fine-tuned BioBERT model (adaptation of BERT or Bidirectional Encoder Representations from Transformers for biomedical text). The proposed framework, SUSIE (Schema-based Unsupervised Semantic Information Extraction), was trained on ICH (International Conference on Harmonization) documents to identify important entities and relations from unstructured text and auto-generate knowledge graphs representing crucial information in a structured format. On the entity identification task, the framework achieves a test accuracy and F1-score of 96% and 88%, respectively, on out-of-sample documents. A major contribution of this work is to build an automated, unsupervised information extraction framework around a domain-specific, custom-built pharmaceutical drug development ontology without the need for manual curation of training datasets for specific tasks. The efficacy of the approach was tested on out-of-sample documents including an internal Eli Lilly technical document.}
}
@article{ALMUHAMMED2022108012,
title = {Ontology-aware dynamically adaptable free-form natural language agent interface for querying databases},
journal = {Knowledge-Based Systems},
volume = {239},
pages = {108012},
year = {2022},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2021.108012},
url = {https://www.sciencedirect.com/science/article/pii/S0950705121011163},
author = {Muhammed Jassem Al-Muhammed and Deryle W. Lonsdale},
keywords = {Dynamic natural language interfaces, Database interfaces, Ontology-based agent interface, On-the-fly ontology-metadata association, Dynamically adaptable interface, Ontology-based process auto-configuration},
abstract = {Studying the literature, one can see a large number of systems that provide natural language interfaces to databases. Despite their importance, these interfaces address only one part of the problem: transforming natural language queries to SQL queries and perhaps executing them against the underlying database. To truly handle the problem, it should be possible to develop dynamically adaptable database interfaces that can (1) adjust their functional behavior on the fly using only domain knowledge and (2) dynamically bind themselves to arbitrary databases and interface with them with no (or very little) human intervention. In particular, the interfaces should have a fixed process (algorithms and codes) and rely only on domain knowledge for adapting their functionality to any arbitrary database. This paper addresses this problem by offering a free-form natural language interface agent that, given domain ontologies, can bind itself to a target database and provide a natural language interface to it. The agent system uses its ontologies to establish mappings on-the-fly between a specific domain ontology and the underlying database’s metadata, and then to transform free-form natural language queries to formal SQL queries that can execute against the underlying database. The preliminary simulations using our proof-of-concept prototype showed that our system successfully attached itself to databases and achieved high recall and precision in transforming natural language queries to formal ones.}
}
@article{HASAN2023822,
title = {Process Defects Knowledge Modeling in Laser Powder Bed Fusion Additive Manufacturing: An Ontological Framework},
journal = {Manufacturing Letters},
volume = {35},
pages = {822-833},
year = {2023},
note = {51st SME North American Manufacturing Research Conference (NAMRC 51)},
issn = {2213-8463},
doi = {https://doi.org/10.1016/j.mfglet.2023.08.132},
url = {https://www.sciencedirect.com/science/article/pii/S2213846323001931},
author = {Nazmul Hasan and Md {Habibor Rahman} and Andrew Wessman and Timothy Smith and Mohammed Shafae},
keywords = {Additive Manufacturing, 3D Printing, Laser Powder Bed Fusion, Knowledge Representation and Modeling, Ontology, Defects, Causal Factors},
abstract = {Comprehensive knowledge of the laser powder bed fusion (LPBF) process defects, their causal factors, and relationships can enable proactive prevention and/or mitigation of those defects to ensure the production of high-quality products. However, this knowledge is scattered in a plethora of research articles, and there is a need for a formal and structured knowledge base to document the LPBF process defects knowledge and model the complex network of relationships among those defects and their causal factors. In response, this paper proposes an ontological framework to systematically structure and represent the knowledge of LPBF defects in a sustainable, reusable, and extensible way. In doing so, we first conducted a detailed literature review and analysis of current LPBF defect surveys to systematically develop a consistent and comprehensive classification of defects and potential causal factors. Then, to effectively represent the gathered knowledge, the ontological framework was designed to: (1) organize and formalize knowledge on LPBF defects and the causal factors, (2) model the complex network of causal links and cascading effects among the defects and causal factors, (3) enable easy querying of the stored knowledge, and (4) include ontological entities that are suitable for extension and reuse. A prototype LPBF defects ontology was developed in Web Ontology Language (OWL)/Resource Description Framework (RDF) formalism using the Protégé tool to effectively realize those design requirements. The developed ontology covers thirty-one unique defects and knowledge of their causal factors, including defect-to-defect causal relationships and hierarchical categorization under four major categories of high-level defect classes. Similarly, forty-five unique causal factors were categorized under twelve major categories. The proposed ontological framework and knowledge model offer a pathway to (1) provide a comprehensive knowledge base on LPBF defects for in-depth tutoring and training of novice researchers and practitioners; (2) help investigators to identify root causes of detected defects for informed corrective action; (3) guide process planning tasks from a defect control perspective; and (4) support future application and reuse of the knowledge. This study also provides several examples to illustrate the modeling of cascading effects in causal relationships, discovering knowledge using an ontology reasoner, visualizing the complex network of causal links using OntoGraph, and retrieving stored knowledge by answering competency questions using SPARQL queries. In the future, the reasoning capabilities of our proposed ontology can also be leveraged to develop expert systems for optimizing the AM workflow and quantitatively predict and diagnose LPBF defects. © 2023 Society of Manufacturing Engineers (SME). Published by Elsevier Ltd. All rights reserved. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/) Peer-review under responsibility of the Scientific Committee of the NAMRI/SME.}
}
@article{CECO2025113198,
title = {Death obsession to ontological well-being mediating role of future anxiety and sleep disturbance: A longitudinal study},
journal = {Personality and Individual Differences},
volume = {241},
pages = {113198},
year = {2025},
issn = {0191-8869},
doi = {https://doi.org/10.1016/j.paid.2025.113198},
url = {https://www.sciencedirect.com/science/article/pii/S0191886925001606},
author = {Gamze Ceco and Büşra Kocyigit and Seydi Ahmet Satici},
keywords = {Death obsession, Dark future, Future anxiety, Sleep disturbance, Ontological well-being},
abstract = {Unlike other creatures, human beings possess the unique awareness of their own mortality. This awareness can lead individuals to develop preoccupations or obsessions with the concept of death. Obsession with death refers to individuals' persistent and recurrent thoughts about mortality. Individuals experiencing this condition may develop a pessimistic outlook towards the future. Such preoccupations can also have a negative impact on sleep quality. In other words, it is suggested that obsessive preoccupation with death may adversely influence ontological well-being by contributing to future anxiety and affecting sleep quality. To investigate these concepts, we collected data from the same participants at three-month intervals utilizing a quasi-longitudinal design. A serial mediation analysis using Model 6 of the PROCESS V4.1 macro for SPSS 26 (Hayes, 2022) with 275 paired data revealed that future anxiety and sleep disturbance played a full mediating role in the relationship between death obsession and ontological well-being. This finding emphasizes the significance of considering these mediating factors for both theoretical models and practical interventions. The findings suggest that individuals with a preoccupation with death may benefit from focusing on their own life projects and receiving psychological support to enhance ontological well-being.}
}
@article{PERINI2025102121,
title = {BrickLLM: A Python library for generating Brick-compliant RDF graphs using LLMs},
journal = {SoftwareX},
volume = {30},
pages = {102121},
year = {2025},
issn = {2352-7110},
doi = {https://doi.org/10.1016/j.softx.2025.102121},
url = {https://www.sciencedirect.com/science/article/pii/S2352711025000883},
author = {Marco Perini and Daniele Antonucci and Rocco Giudice and Marco Savino Piscitelli and Alfonso Capozzoli},
keywords = {Brick, RDF, Large Language Models, Portability, Energy Management and Information Systems},
abstract = {One of the key challenges of Energy Management and Information Systems in buildings is related to the lack of interoperability, due to the absence of standardization of the underlying data models. In recent years, there has been a growing interest in using ontology-based metadata models to address this issue, as they offer a structured approach to organize and share information across diverse systems (e.g. Brick ontology). However, the creation of ontology-based metadata models is often a labor-intensive task that requires specific domain expertise, hindering the practical use of such data models. For this reason, in this work the BrickLLM Python library is introduced, which addresses this issue by generating Brick-compliant Resource Description Framework graphs through Large Language Models, automating the process of converting natural language building descriptions into machine-readable metadata. The library supports both cloud-based APIs (e.g., OpenAI, Anthropic, Fireworks AI), local models (e.g. LLaMa3.2, etc.) and evenfine-tuned ones. This paper explores the architecture, key functionalities, and practical applications of BrickLLM, showcasing its potential impact on the future of building systems monitoring and automation.}
}
@article{TUZUN20252575,
title = {Granular and Relational SWOT Analysis: An Ontological Approach},
journal = {Procedia Computer Science},
volume = {253},
pages = {2575-2585},
year = {2025},
note = {6th International Conference on Industry 4.0 and Smart Manufacturing},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2025.01.317},
url = {https://www.sciencedirect.com/science/article/pii/S1877050925003254},
author = {Alican Tüzün and Shailesh Tripathi and Nadine Bachmann and Ann-Kristin Thienemann and Manuel Brunner and Herbert Jodlbauer},
keywords = {Protege, Ontology, SWOT, SOFT, SWOT Analysis, TOWS, TOWS Matrix},
abstract = {The traditional Strength, Weakness, Opportunity, and Threat (SWOT) analysis, despite its popularity [37], faces a significant challenge in interpreting information through the ”SWOT Matrix (SM)” [20]. The conventional matrix fails to capture the complexity, semantics, and detailed characteristics necessary for comprehensive decision-making. Therefore, this paper introduces an innovative approach to address these limitations by an ontology SWOTONT [45] representing the domain of SWOT analysis. SWOTONT is developed through a literature review and a bottom-up ontology development approach [23], providing context to the SWOT attributes by introducing finer subcategories and mapping their interrelationships. By developing a structured semantic approach, authors aimed to enable more precise knowledge extraction and support advanced strategic analysis. Future work will focus on empirical validation through case studies and domain expert feedback, integrating an upper ontology and exploring additional applications and integrations of the model.}
}
@article{BERGES2025100863,
title = {Two ontology design patterns in the domain of collections},
journal = {Journal of Web Semantics},
volume = {85},
pages = {100863},
year = {2025},
issn = {1570-8268},
doi = {https://doi.org/10.1016/j.websem.2025.100863},
url = {https://www.sciencedirect.com/science/article/pii/S1570826825000034},
author = {Idoia Berges and Arantza Illarramendi},
keywords = {Ontology design pattern, Collection},
abstract = {Collections are objects used to arrange, into a single unit, multiple data items that form a natural group. Different types of collections exist, due to different constraints based on whether or not they impose an order on their elements and whether or not they allow repetition of elements. Any of them are easily found in several domains of our everyday life. For instance, a deck of cards, the prime divisors of a number or the teams that compete in a championship can be seen as a collection. Thus, an effective modeling of collections is a recurring issue in information management. In the ontology design field, recurring modeling problems can be addressed by the use of Ontology Design Patterns (ODPs). In the case of collections, ODPs have been proposed for representing sequences, lists, sets and bags. However, none of these patterns are completely adequate for representing collections of ordered elements without repetition. In this paper we present an ODP for representing that notion, which we have named Permutation. Moreover, another ODP named ListOfPermutations is also introduced, which allows to represent how the order of a Permutation varies along time. Because not all constraints required by these ODPs can be represented in OWL 2, SHACL shapes have been used in their definitions.}
}
@article{AWUKLU2025104808,
title = {Ontology-driven identification of inconsistencies in clinical data: A case study in lung cancer phenotyping},
journal = {Journal of Biomedical Informatics},
volume = {165},
pages = {104808},
year = {2025},
issn = {1532-0464},
doi = {https://doi.org/10.1016/j.jbi.2025.104808},
url = {https://www.sciencedirect.com/science/article/pii/S1532046425000371},
author = {Yvon K. Awuklu and Fleur Mougin and Romain Griffier and Meghyn Bienvenu and Vianney Jouhet},
keywords = {Data quality, OMQA, Lung cancer, Phenotyping, EHR},
abstract = {Objective:
To illustrate the use of an ontology in evaluating data quality in the medical field, focusing on phenotyping lung cancers.
Materials and Methods:
We crafted an ontology to encapsulate crucial domain knowledge, leveraging it to query the Clinical Data Warehouse (CDW) of Bordeaux University Hospital. Our work aimed at accurately representing domain knowledge and identifying inconsistencies through ontological axioms. Specifically, our aim was to pinpoint lung cancer patients with EGFR or ALK mutations treated with tyrosine kinase inhibitors (TKIs). We evaluated the ability of this ontology to retrieve and characterize patients in comparison with a traditional SQL queries executed on the CDW.
Results:
The ontology’s results closely aligned with those of the SQL queries. A sub-cohort of 60 lung cancer patients with conflicting information was identified, highlighting inconsistencies in the data. Moreover, the ontology complemented the existing data, uncovering additional information and enriching the dataset.
Discussion:
This work has highlighted challenges in managing temporal data and handling imperfect data. Addressing these challenges is essential for the effective use of CDW in phenotyping.
Conclusion:
Ontologies improve data quality by identifying inconsistencies, enhancing data completeness, facilitating complex SQL queries, and standardize processes. Developing a framework to manage inconsistent healthcare data, considering its temporal nature, is essential.}
}
@article{IQBAL2024102257,
title = {Blockchain-based ontology driven reference framework for security risk management},
journal = {Data & Knowledge Engineering},
volume = {149},
pages = {102257},
year = {2024},
issn = {0169-023X},
doi = {https://doi.org/10.1016/j.datak.2023.102257},
url = {https://www.sciencedirect.com/science/article/pii/S0169023X23001179},
author = {Mubashar Iqbal and Aleksandr Kormiltsyn and Vimal Dwivedi and Raimundas Matulevičius},
keywords = {Blockchain, Security risk management, Ontology framework, Web ontology language, Unified foundational ontology, CPNs tool},
abstract = {Security risk management (SRM) is crucial for protecting valuable assets from malicious harm. While blockchain technology has been proposed to mitigate security threats in traditional applications, it is not a perfect solution, and its security threats must be managed. This paper addresses the research problem of having no unified and formal knowledge models to support the SRM of traditional applications using blockchain and the SRM of blockchain-based applications. In accordance with this, we present a blockchain-based reference model (BbRM) and an ontology driven reference framework (OntReF) for the SRM of traditional and blockchain-based applications. The BbRM consolidates security threats of traditional and blockchain-based applications, structured following the SRM domain model and offers guidance for creating the OntReF using the domain model. OntReF is grounded on unified foundational ontology (UFO) and provides semantic interoperability and supporting the dynamic knowledge representation and instantiation of information security knowledge for the SRM. Our evaluation approaches demonstrate that OntReF is practical to use.}
}
@article{NARCISSE2024866,
title = {An intelligent research environment on cotton diseases and pests based on a cotton phytosanitary surveillance ontology ontoSYSPARCOTCI.},
journal = {Procedia Computer Science},
volume = {237},
pages = {866-873},
year = {2024},
note = {International Conference on Industry Sciences and Computer Science Innovation},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.05.175},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924011918},
author = {Téhia Kouaho N'Guessan Narcisse and Malo Sadouanouan and Kouakou Malanno and Bini Kouadio Kra Norbert and Ochou Ochou Germain},
keywords = {Natural Language Processing, SPARQL, ontology, vector model},
abstract = {User-centred systems need to incorporate solutions to make them easier to use. Based on a domain ontology, our system has an extensive knowledge base that is populated by a semantic web platform that we have built. This knowledge base needs to be queried on demand by users due to the limitations of the search engine integrated into the semantic web platform. However, this task is not trivial for a human being due to the complexity of the schemas making up the knowledge base and the inability to perform SPARQL queries to obtain answers. In this paper, we propose an approach based on skills questions that we have defined with domain experts and that have helped validate our domain ontology. This approach allows users to ask their questions in natural language to obtain an answer. To achieve our goal, we used natural language processing tools, in particular Spacy's pre-trained French pipeline. The TF-IDF weighting method was used to calculate the similarity score between two sentences.}
}
@article{FAILLA2025100820,
title = {Managing lifecycle of product information with an ontology-based knowledge framework},
journal = {Journal of Industrial Information Integration},
volume = {45},
pages = {100820},
year = {2025},
issn = {2452-414X},
doi = {https://doi.org/10.1016/j.jii.2025.100820},
url = {https://www.sciencedirect.com/science/article/pii/S2452414X25000445},
author = {Lorenzo Failla and Marco Rossoni and Marco Quirini and Giorgio Colombo},
keywords = {Product Lifecycle Management (PLM), Ontologies, Linked data, Product information management, Product knowledge formalization},
abstract = {The effective management of product information within a formalized, digital and interoperable infrastructure remains a significant gap in realizing the full potential of modern Product Lifecycle Management (PLM) implementations in industrial contexts. While the academic paradigm of PLM has been extensively emphasized in the scientific literature for over two decades as a sustainable company strategy, contemporary PLM implementations prove inadequate in handling the extensive volume and variety of information generated throughout a product’s lifecycle. Starting from a comprehensive overview of the evolution of the PLM paradigm and of its inherent implications, the analysis of the PLM implementation of a big player in engineering and manufacturing of turbomachinery products for Oil & Gas and Energy markets is analyzed, allowing to identify existing major general contradictions from an industrial perspective. While it is reaffirmed that the attainment of a neutral, harmonized and universally agreed standardization is nowadays missing and is crucial in the enabling of the PLM paradigm through digital technologies, the present study attempts to demonstrate how a general and agnostic ontology-based framework may straightforwardly fulfill all the identified demands of the PLM paradigm and, therefore, how ontologies play a central role in this field of research by bridging different domains to enable a holistic product conceptualization, lifecycle management, and data interoperability among different digital agents.}
}
@article{BENAMARA2025105526,
title = {Ontological framework for horizon scanning of business continuity of essential services},
journal = {International Journal of Disaster Risk Reduction},
volume = {124},
pages = {105526},
year = {2025},
issn = {2212-4209},
doi = {https://doi.org/10.1016/j.ijdrr.2025.105526},
url = {https://www.sciencedirect.com/science/article/pii/S2212420925003504},
author = {Oussema {Ben Amara} and Antonio {De Nicola} and Daouda Kamissoko and Frédérick Bénaben and Ygal Fijalkow},
keywords = {Business continuity, Risk management, Systematic literature review, Ontology engineering, Disaster recovery},
abstract = {Keeping up essential operations in the face of more complicated disruptions from crises that impact essential services such as healthcare, public transit, and government operations is a major challenge for business continuity (BC) research. Taking up this issue in the midst of increased academic discussion emphasizes how urgent it is to create a thorough reference on BC principles. This paper uses a recently developed BC ontological framework to give a comprehensive review of the literature focused on BC research. The report summarizes a comprehensive investigation of important BC aspects, including technological aspects and the urgent difficulties in maintaining BC sustainability. Through the integration of many viewpoints, this study advances a unified awareness of BC dynamics, promoting a general understanding that is necessary for risk management which is both efficient and lasting for organizations.}
}
@article{FU202545,
title = {Enrichment Analysis and Deep Learning in Biomedical Ontology: Applications and Advancements},
journal = {Chinese Medical Sciences Journal},
volume = {40},
number = {1},
pages = {45-56},
year = {2025},
issn = {1001-9294},
doi = {https://doi.org/10.24920/004464},
url = {https://www.sciencedirect.com/science/article/pii/S1001929425000161},
author = {Hong-Yu Fu and Yang-Yang Liu and Mei-Yi Zhang and Hai-Xiu Yang},
keywords = {biomedical ontology, enrichment analysis, deep learning, ontology hierarchy, ontology annotation},
abstract = {Biomedical big data, characterized by its massive scale, multi-dimensionality, and heterogeneity, offers novel perspectives for disease research, elucidates biological principles, and simultaneously prompts changes in related research methodologies. Biomedical ontology, as a shared formal conceptual system, not only offers standardized terms for multi-source biomedical data but also provides a solid data foundation and framework for biomedical research. In this review, we summarize enrichment analysis and deep learning for biomedical ontology based on its structure and semantic annotation properties, highlighting how technological advancements are enabling the more comprehensive use of ontology information. Enrichment analysis represents an important application of ontology to elucidate the potential biological significance for a particular molecular list. Deep learning, on the other hand, represents an increasingly powerful analytical tool that can be more widely combined with ontology for analysis and prediction. With the continuous evolution of big data technologies, the integration of these technologies with biomedical ontologies is opening up exciting new possibilities for advancing biomedical research.}
}
@article{POURJAFARIAN2025930,
title = {An ODP-based Ontology for the Digital Product Passport},
journal = {Procedia CIRP},
volume = {135},
pages = {930-935},
year = {2025},
note = {32nd CIRP Conference on Life Cycle Engineering (LCE2025)},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2024.12.125},
url = {https://www.sciencedirect.com/science/article/pii/S2212827125003750},
author = {Monireh Pourjafarian and Christiane Plociennik and Simon Bergweiler and Nastaran Moarefvand and Jonas Brozeit and Mahdi Rezapour and Martin Ruskowski},
keywords = {Circular Economy, Digital Product Passport, Ontology, Ontology Design Patterns, Asset Administration Shell},
abstract = {The challenges posed by climate change can only be met by changing the economic mindset to one that focuses on the idea of a circular economy (CE). Digitalization, data collection and data storage play a crucial role here: Product-related data should be collected in a consistent manner throughout the entire life cycle of the product and stored in a Digital Product Passport (DPP). The DPP should give all stakeholders of the CE access to the necessary data. Overarching modelling is required to ensure that a DPP can be used as a structure across application domains in an interoperable way. Ontologies can act as an interlingua between domains, incorporating the required domain knowledge and the full range of requirements for the DPP. Following a modular approach based on Ontology Design Patterns, this paper develops a DPP ontology with a focus on the R-strategies within the CE. Furthermore, the paper builds a bridge to the standardized approach of Industry 4.0, the modelling and storage of structured domain knowledge in Asset Administration Shells (AAS). Data can be seamlessly integrated and used for decision-making in each product life cycle phase. In addition, the reuse of existing concepts defined by others is demonstrated. The developed ontology is then evaluated on a CE use case.}
}
@article{NAQVI20223679,
title = {Ontological Model for Cohesive Smart Health Services Management},
journal = {Computers, Materials and Continua},
volume = {74},
number = {2},
pages = {3679-3695},
year = {2022},
issn = {1546-2218},
doi = {https://doi.org/10.32604/cmc.2023.030340},
url = {https://www.sciencedirect.com/science/article/pii/S1546221822004052},
author = {Muhammad Raza Naqvi and Muhammad Waseem Iqbal and Syed Khuram Shahzad and M. {Usman Ashraf} and Khalid Alsubhi and Hani Moaiteq Aljahdali},
keywords = {Ontology, internet of things, smart health, services integration},
abstract = {Health care has become an essential social-economic concern for all stakeholders (e.g., patients, doctors, hospitals etc.), health needs, private care and the elderly class of society. The massive increase in the usage of health care Internet of things (IoT) applications has great technological evolvement in human life. There are various smart health care services like remote patient monitoring, diagnostic, disease-specific remote treatments and telemedicine. These applications are available in a split fashion and provide solutions for variant diseases, medical resources and remote service management. The main objective of this research is to provide a management platform where all these services work as a single unit to facilitate the users. The ontological model of integrated healthcare services is proposed by getting requirements from various existing healthcare services. There were 26 smart health care services and 26 smart health care services to classify the knowledge-based ontological model. The proposed ontological model is derived from different classes, relationships, and constraints to integrate health care services. This model is developed using Protégé based on each interrelated/correlated health care service having different values. Semantic querying SPARQL protocol and RDF query language (SPARQL) were used for knowledge acquisition. The Pellet Reasoner is used to check the validity and relations coherency of the proposed ontology model. Comparative to other smart health care services integration systems, the proposed ontological model provides more cohesiveness.}
}
@article{HADJMABROUK20254399,
title = {Expert System Based on Ontology and Interpretable Machine Learning to Assist in the Discovery of Railway Accident Scenarios},
journal = {Computers, Materials and Continua},
volume = {84},
number = {3},
pages = {4399-4430},
year = {2025},
issn = {1546-2218},
doi = {https://doi.org/10.32604/cmc.2025.067143},
url = {https://www.sciencedirect.com/science/article/pii/S1546221825007283},
author = {Habib Hadj-Mabrouk},
keywords = {Artificial intelligence, ontology, semi-supervised learning, expert system, association rules, railways, safety, hazard, accident scenarios, classification, assessment},
abstract = {A literature review on AI applications in the field of railway safety shows that the implemented approaches mainly concern the operational, maintenance, and feedback phases following railway incidents or accidents. These approaches exploit railway safety data once the transport system has received authorization for commissioning. However, railway standards and regulations require the development of a safety management system (SMS) from the specification and design phases of the railway system. This article proposes a new AI approach for analyzing and assessing safety from the specification and design phases of the railway system with a view to improving the development of the SMS. Unlike some learning methods, the proposed approach, which is dedicated in particular to safety assessment bodies, is based on semi-supervised learning carried out in close collaboration with safety experts who contributed to the development of a database of potential accident scenarios (learning example database) relating to the risk of rail collision. The proposed decision support is based on the use of an expert system whose knowledge base is automatically generated by inductive learning in the form of an association rule (rule base) and whose main objective is to suggest to the safety expert possible hazards not considered during the development of the SMS to complete the initial hazard register.}
}
@article{DELNOSTRO2025104203,
title = {Battery testing ontology: An EMMO-based semantic framework for representing knowledge in battery testing and battery quality control},
journal = {Computers in Industry},
volume = {164},
pages = {104203},
year = {2025},
issn = {0166-3615},
doi = {https://doi.org/10.1016/j.compind.2024.104203},
url = {https://www.sciencedirect.com/science/article/pii/S0166361524001313},
author = {Pierluigi {Del Nostro} and Gerhard Goldbeck and Ferry Kienberger and Manuel Moertelmaier and Andrea Pozzi and Nawfal Al-Zubaidi-R-Smith and Daniele Toti},
keywords = {Application ontology, Battery quality control, Battery testing, Materials modeling, Semantic framework},
abstract = {The demand for advanced battery management systems (BMSs) and battery test procedures is growing due to the rising importance of electric vehicles (EVs) and energy storage systems. The diversity of battery types, chemistries and application scenarios presents challenges in designing and optimizing BMSs and determining optimal battery test strategies. To address these challenges, semantic web technologies and ontologies offer a structured and common vocabulary for information sharing and reuse in battery management and testing. This work introduces the Battery Testing Ontology (BTO), a standardized, comprehensive, and semantically flexible framework for representing knowledge in electrical battery testing and quality control. BTO models a variety of electrical battery cell tests, specifying required test hardware and calibration procedures, mechanical fixturing of batteries, and referencing electrical measurement data. For example, it supports electrochemical impedance spectroscopy, self-discharge and high-voltage separator tests, the latter specifically demonstrating separator requirements, hardware specifications, and measurement details. Positioned within the ontology ecosystem of materials science, BTO aligns with the Elementary Multiperspective Material Ontology (EMMO) and related domain ontologies such as the Characterization Methodology Ontology (CHAMEO). This work elaborates on BTO’s development, structure, components and applications, highlighting its significant contributions to the field of battery testing.}
}
@article{ZHANG2024102531,
title = {Onto-SAGCN: Ontology modeling and spatial attention-based graph convolution networks for aircraft assembly quality prediction},
journal = {Advanced Engineering Informatics},
volume = {60},
pages = {102531},
year = {2024},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2024.102531},
url = {https://www.sciencedirect.com/science/article/pii/S1474034624001794},
author = {Qiang Zhang and Qun Luo and Anan Zhao and Cijun Yu and Qing Wang and Yinglin Ke},
keywords = {Aircraft assembly, Ontology, Graph convolution, Spatial attention, Quality monitoring},
abstract = {Aircraft assembly is an essential stage in the aircraft manufacturing industry, and the increasing complexity of aircraft functionality has put higher requirements for assembly quality. Various deep learning methods based on image or structural data have been used to predict assembly quality. However, these methods focus more on the structural relationships and interactions between assembled products and are difficult to adapt to scenarios where products and equipment may change. This paper proposes a graph convolutional neural network based on ontology modeling and spatial attention mechanism (Onto-SAGCN) for assembly quality analysis and prediction. Specifically, formal representations of assembly equipment, products, and assembly processes are established using ontologies, enabling the unified modeling of spatial and temporal relationships between entities and resolving the issues of data representation inconsistency. Then, the ontologies are transformed into undirected graphs, where nodes represent entities, node attributes represent feature data, and edges represent relationships or constraints between nodes. Designed to process data from the assembly process, the Onto-SAGCN model is subsequently applied to the assembly of aircraft moving wings. It predicts the diameters of holes by gathering operational data from equipment during the assembly and benchmarks these predictions against other established methods. Experimental outcomes affirm the method's elevated accuracy and dependability in forecasting assembly quality.}
}
@article{ARMARY2025100693,
title = {Ontology learning towards expressiveness: A survey},
journal = {Computer Science Review},
volume = {56},
pages = {100693},
year = {2025},
issn = {1574-0137},
doi = {https://doi.org/10.1016/j.cosrev.2024.100693},
url = {https://www.sciencedirect.com/science/article/pii/S1574013724000765},
author = {Pauline Armary and Cheikh Brahim El-Vaigh and Ouassila {Labbani Narsis} and Christophe Nicolle},
keywords = {Ontology learning, Heavyweight ontology, Ontology, Axioms, Rules},
abstract = {Ontology learning, particularly axiom learning, is a challenging task that focuses on building expressive and decidable ontologies. The literature proposes several research efforts aimed to resolve the complexities inherent in axiom and rule learning, which seeks to automatically infer logical constructs from diverse data sources. The goal of this paper is to conduct a comprehensive review of existing work in this domain. It aims to critically analyze the contributions and limitations of current approaches, providing a clear understanding of the state-of-the-art and identifying areas where further research is needed.}
}
@article{BARAKU2025100108,
title = {Defining personal data Sovereignty: An ontologically-based framework facilitating subject privacy control},
journal = {Data and Information Management},
pages = {100108},
year = {2025},
issn = {2543-9251},
doi = {https://doi.org/10.1016/j.dim.2025.100108},
url = {https://www.sciencedirect.com/science/article/pii/S2543925125000166},
author = {Vijon Baraku and Edon Ramadani and Iraklis Paraskakis and Simeon Veloudis and Poonam Yadav},
keywords = {Data sovereignty, Data ownership, Ontologies, Data Federation},
abstract = {This paper presents the implementation and evaluation of the Data Capsule framework, a novel approach for achieving personal data sovereignty. Our framework uses formal knowledge representation to understand both the context of personal data collection across heterogeneous systems and define comprehensive usage policies - from access control to monetisation opportunities. As organisations increasingly collect and process personal data, individuals continue to lack effective mechanisms to control how their information is processed and/or shared across heterogeneous systems. We tackle this problem with two key contributions: (1) an ontology-based federation system that allows for seamless federation of personal data across databases using schema.org as a semantic foundation, and (2) a semantically driven dynamic usage control mechanism that allows individuals to define and enforce granular access rules. Our implementation demonstrates that effective personal data sovereignty can be achieved and serves as a foundation for future systems contributing to the empowerment of individuals in the digital economy.}
}
@article{ZHOU2024100659,
title = {Knowledge reuse for ontology modelling and application of maintenance motion state sequence},
journal = {Journal of Industrial Information Integration},
volume = {41},
pages = {100659},
year = {2024},
issn = {2452-414X},
doi = {https://doi.org/10.1016/j.jii.2024.100659},
url = {https://www.sciencedirect.com/science/article/pii/S2452414X24001031},
author = {Qidi Zhou and Dong Zhou and Yan Wang and Ziyue Guo and Chao Dai},
keywords = {Knowledge reuse, Ontology modelling, Ontology application, Maintenance motion, Time prediction},
abstract = {With the current digital transformation and the development of complex manufacturing systems, advanced maintenance is proposed to improve the competitiveness of complex products, generating a large amount of heterogeneous maintenance data and information. There is a lack of standardized representations of motion-centred maintenance knowledge which leads to semantic ambiguity and poor intertranslatability. In addition, it causes subjective deviations and human resource investments in related time prediction applications. Therefore, a knowledge reuse method for ontology modelling and the application of maintenance motion state sequences is proposed. First, a framework for reusing maintenance motion state sequence (MMSS) knowledge is established, which is defined as the state sets of time-sequence maintenance motion. Second, maintenance motion state sequence ontology (MMSSO) is constructed to standardize the definition of MMSS, as a supplement to the current maintenance ontologies. Third, an MMSSO application for automatic maintenance time prediction is proposed by incorporating the standardized specifications of MMSSO and improving the MODAPTS method. Finally, using aviation equipment as an example, the rationality and superiority of MMSSO in real applications are verified. MMSSO is a new practice of integrating multi-source information in advanced maintenance. It can also provide predicted time as an iterative reference for industrial practitioners in the digital design stage.}
}
@article{CHANMEE2025127592,
title = {Advancing COVID-19 data classification and prediction: A fresh perspective from an ontological machine–learning algorithm},
journal = {Expert Systems with Applications},
volume = {279},
pages = {127592},
year = {2025},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2025.127592},
url = {https://www.sciencedirect.com/science/article/pii/S095741742501214X},
author = {Sirichanya Chanmee and Wanarat Juraphanthong and Kraisak Kesorn},
keywords = {Decision tree, Time series, Semantic processing, Knowledge base, Ontology, Autoregressive Integrated Moving Average with eXogenous Semantic Information},
abstract = {This research introduces a unified framework for preparing, analyzing, and predicting COVID-19 data patterns using an ontological approach. Leveraging ontology models as a knowledge base, our framework enables more intelligent data analysis than existing state-of-the-art approaches. We also integrate two new concepts into the framework: a semantic decision tree that computes the involved information gain in decision tree construction, thereby improving the classification performance, and a method of autoregressive integrated moving average with exogenous semantic variables that forecasts the number of COVID-19 cases. This method is seamlessly integrated into the knowledge base to enhance the predictive power of the traditional approach such as autoregressive integrated moving average with explanatory variable. The core of our system is the COVID-19 knowledge base, which extracts the relevant data and leverages metadata for effective analysis and pattern learning. Experimental results demonstrate the superiority of our contributions over those corresponding to baseline methods. The higher accuracy and lower error rates of our approach than those of comparable methods are demonstrated using various criteria: mean square error, mean absolute error, root mean square error, area under the receiver operating characteristic curve, and classification accuracy.}
}
@article{BARBAGONZALEZ2024107378,
title = {BIGOWL4DQ: Ontology-driven approach for Big Data quality meta-modelling, selection and reasoning},
journal = {Information and Software Technology},
volume = {167},
pages = {107378},
year = {2024},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2023.107378},
url = {https://www.sciencedirect.com/science/article/pii/S0950584923002331},
author = {Cristóbal Barba-González and Ismael Caballero and Ángel Jesús Varela-Vaca and José A. Cruz-Lemus and María Teresa Gómez-López and Ismael Navas-Delgado},
keywords = {Data quality evaluation and measurement, Data quality information model, Big Data, Ontology, Decision model and notation},
abstract = {Context:
Data quality should be at the core of many Artificial Intelligence initiatives from the very first moment in which data is required for a successful analysis. Measurement and evaluation of the level of quality are crucial to determining whether data can be used for the tasks at hand. Conscientious of this importance, industry and academia have proposed several data quality measurements and assessment frameworks over the last two decades. Unfortunately, there is no common and shared vocabulary for data quality terms. Thus, it is difficult and time-consuming to integrate data quality analysis within a (Big) Data workflow for performing Artificial Intelligence tasks. One of the main reasons is that, except for a reduced number of proposals, the presented vocabularies are neither machine-readable nor processable, needing human processing to be incorporated.
Objective:
This paper proposes a unified data quality measurement and assessment information model. This model can be used in different environments and contexts to describe data quality measurement and evaluation concerns.
Method:
The model has been developed as an ontology to make it interoperable and machine-readable. For better interoperability and applicability, this ontology, BIGOWL4DQ, has been developed as an extension of a previously developed ontology for describing knowledge management in Big Data analytics.
Conclusions:
This extended ontology provides a data quality measurement and assessment framework required when designing Artificial Intelligence workflows and integrated reasoning capacities. Thus, BIGOWL4DQ can be used to describe Big Data analysis and assess the data quality before the analysis.
Result:
Our proposal has been validated with two use cases. First, the semantic proposal has been assessed using an academic use case. And second, a real-world case study within an Artificial Intelligence workflow has been conducted to endorse our work.}
}
@article{GUO2025106374,
title = {Advancing BIM information retrieval with an LLM-based query-domain-specific language and library code function alignment system},
journal = {Automation in Construction},
volume = {178},
pages = {106374},
year = {2025},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2025.106374},
url = {https://www.sciencedirect.com/science/article/pii/S0926580525004145},
author = {Peizhuo Guo and Huiyuan Xue and Jun Ma and Jack Chin Pang Cheng},
keywords = {Building information modelling (BIM), Automatic information retrieval, Query understanding, Large language model (LLM), Domain specific language and library code, Retrieval-augmented generation (RAG), Revit C# API},
abstract = {The complexity of BIM data calls for efficient automatic information retrieval methods, yet aligning queries with BIM information, especially domain code packages, remains challenging due to intricate data structures, naming conventions, and varying query complexities. Existing techniques require manual training and merely solve the IFC format, while recent exploration of LLMs remains preliminary in BIM automation. This paper introduces Synergistic BIM Aligners, a framework leveraging LLMs to automatically align human queries with BIM domain code functions, thereby assisting subsequent retrieval code generation stages. The framework features eight agents based on hierarchical alignment, hybrid search, and complementary routing strategies. The framework was evaluated using 80 queries from the Revit C# API of varying complexity. The results demonstrated high accuracy (78.75 %) and significantly reduced errors, with our system's 0.30 errors per query on average compared to Standalone Agent's 2.03 errors. These findings highlight the potential of LLM-assisted methods for BIM information retrieval.}
}
@article{MONTANARO2024,
title = {Computable species descriptions and nanopublications: applying ontology-based technologies to dung beetles (Coleoptera, Scarabaeinae)},
journal = {Biodiversity Data Journal},
volume = {12},
year = {2024},
issn = {1314-2836},
doi = {https://doi.org/10.3897/BDJ.12.e121562},
url = {https://www.sciencedirect.com/science/article/pii/S1314283624001660},
author = {Giulio Montanaro and James P. Balhoff and Jennifer C. Girón and Max Söderholm and Sergei Tarasov},
keywords = {Phenoscript, taxonomy, semantic data, phenotypic traits, characters, morphology,   , microCT},
abstract = {Background
Taxonomy has long struggled with analysing vast amounts of phenotypic data due to computational and accessibility challenges. Ontology-based technologies provide a framework for modelling semantic phenotypes that are understandable by computers and compliant with FAIR principles. In this paper, we explore the use of Phenoscript, an emerging language designed for creating semantic phenotypes, to produce computable species descriptions. Our case study centers on the application of this approach to dung beetles (Coleoptera, Scarabaeinae).
New information
We illustrate the effectiveness of Phenoscript for creating semantic phenotypes. We also demonstrate the ability of the Phenospy python package to automatically translate Phenoscript descriptions into natural language (NL), which eliminates the need for writing traditional NL descriptions. We introduce a computational pipeline that streamlines the generation of semantic descriptions and their conversion to NL. To demonstrate the power of the semantic approach, we apply simple semantic queries to the generated phenotypic descriptions. This paper addresses the current challenges in crafting semantic species descriptions and outlines the path towards future improvements. Furthermore, we discuss the promising integration of semantic phenotypes and nanopublications, as emerging methods for sharing scientific information. Overall, our study highlights the pivotal role of ontology-based technologies in modernising taxonomy and aligning it with the evolving landscape of big data analysis and FAIR principles.}
}
@article{KALTENEGGER2025112565,
title = {An ontology-driven framework for digital transformation and performance assessment of building materials},
journal = {Building and Environment},
volume = {271},
pages = {112565},
year = {2025},
issn = {0360-1323},
doi = {https://doi.org/10.1016/j.buildenv.2025.112565},
url = {https://www.sciencedirect.com/science/article/pii/S0360132325000472},
author = {Julia Kaltenegger and Kirstine Meyer Frandsen and Ekaterina Petrova},
keywords = {Material information modelling, Building information modelling, Material classification, Semantic web, Ontologies},
abstract = {Material Information Modelling (MIM) is a cornerstone of Building Performance Simulation (BPS). However, defining and exchanging data between building modelling and simulation tools is cumbersome due to notable deficiencies in the granularity of material information descriptions. The inadequacies in the data models and exchanges lead to faulty interpretations of material properties in building performance assessment. The material science domain strives to advance material research and expedite the market readiness of novel materials through intricate data modelling, performance computations, and interdisciplinary communication channels. In addition to the latter, adopting the Findable, Accessible, Interoperable, and Reusable principles holds significant potential in promoting accurate MIM within Architecture, Engineering and Construction. This study introduces an ontology-driven framework leveraging Semantic Web technologies and Linked Data to support MIM in the context of Building Information Modelling and BPS. The framework implementation is demonstrated in a web-based application that enables the dynamic assessment and benchmarking of building materials based on the Guggenheim, Anderson and de Boer model and thermal resistance computations. The development of the framework relies on ontology engineering principles to represent domain knowledge in a Building Material Performance ontology, as well as Systems Engineering coupled with test-driven development for requirement engineering, system design, implementation, and validation. The results include a novel MIM data model enabling material classification and property definitions in alignment with international standards. The implementation validates and assesses the logic of the proposed data model and software application by conducting hygric and thermal performance assessments applied on case studies.}
}
@incollection{ALKHALIL2025579,
title = {Chapter 27 - Lexical analysis of biomedical ontologies},
editor = {Sujata Dash and Subhendu Kumar Pani and Wellington Pinheiro Dos Santos and Jake Y. Chen},
booktitle = {Mining Biomedical Text, Images and Visual Features for Information Retrieval},
publisher = {Academic Press},
pages = {579-586},
year = {2025},
isbn = {978-0-443-15452-2},
doi = {https://doi.org/10.1016/B978-0-443-15452-2.00027-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780443154522000273},
author = {Samia S. Alkhalil and Charles Oluwaseun Adetunji and Oluwafemi Adebayo Oyewole},
keywords = {HFO, Lexicalization, LSTM, Natural language processing, NCBO-BioPortal, Ontology},
abstract = {Today is the era of digital technology with computational linguistics and natural language processing. Everything is in digital form from teaching-learning material to doctors' perception and diagnosis. People are interacting with teachers, doctors, and other consultants in natural language through the internet. Doctors are also using telemedicine (consultation over smartphone) and further speech-based transcription nowadays. To support this, many doctors' appointment web portals, such as Practo, Docplus, PubMed, and WebMD, are available. So, these sites contain numerous prescriptions and diagnosis texts and a collection of biomedical terms. Physically, the reports can be collected from hospitals and diagnostic centers, following ethical protocols. The COVID-19 pandemic has also increased the online testing and reporting mechanisms such as COVISELF kits. The doctors' scripts and the computer-generated reports are in their own format. The final diagnostic remark is the region of interest for us and becomes the source input for further processing. Next, we discuss the different biomedical ontologies available on the internet such as the National Center for Biomedical Ontology (NCBO) in BioPortal, ontology for biomedical investigation (OBI), human phenotype ontology, and disease ontology, and then select one of them for our case study. These are a great source of biomedical terms for different diseases in natural language. There is a need to build a dynamic biomedical lexical model that can easily identify the medical terms with their synonyms and can normalize these words to infer actual medical terms. In this chapter, we have proposed an LSTM model for categorization of heart failure diagnosis and inference, after proper lexicalization of transcripts, further matching the term(s) with the ontology, using an n-gram model and converging to an inference by best first traversal of the ontology. Lexicalization is the process of realization of a meaning in a single word rather than in a grammatical structure. For the case study, the heart failure ontology (HFO) from NCBO-BioPortal is used to map its terms with the terms or words from doctors' transcripts, to infer actual medical diagnostic terms associated with heart failure.}
}
@article{CHATTERJEE2022,
title = {Personalized Recommendations for Physical Activity e-Coaching (OntoRecoModel): Ontological Modeling},
journal = {JMIR Medical Informatics},
volume = {10},
number = {6},
year = {2022},
issn = {2291-9694},
doi = {https://doi.org/10.2196/33847},
url = {https://www.sciencedirect.com/science/article/pii/S2291969422001892},
author = {Ayan Chatterjee and Andreas Prinz},
keywords = {descriptive logic, ontology, e-coach, reasoning, recommendation generation},
abstract = {Background
Automatic e-coaching may motivate individuals to lead a healthy lifestyle with early health risk prediction, personalized recommendation generation, and goal evaluation. Multiple studies have reported on uninterrupted and automatic monitoring of behavioral aspects (such as sedentary time, amount, and type of physical activity); however, e-coaching and personalized feedback techniques are still in a nascent stage. Current intelligent coaching strategies are mostly based on the handcrafted string messages that rarely individualize to each user’s needs, context, and preferences. Therefore, more realistic, flexible, practical, sophisticated, and engaging strategies are needed to model personalized recommendations.
Objective
This study aims to design and develop an ontology to model personalized recommendation message intent, components (such as suggestion, feedback, argument, and follow-ups), and contents (such as spatial and temporal content and objects relevant to perform the recommended activities). A reasoning technique will help to discover implied knowledge from the proposed ontology. Furthermore, recommendation messages can be classified into different categories in the proposed ontology.
Methods
The ontology was created using Protégé (version 5.5.0) open-source software. We used the Java-based Jena Framework (version 3.16) to build a semantic web application as a proof of concept, which included Resource Description Framework application programming interface, World Wide Web Consortium Web Ontology Language application programming interface, native tuple database, and SPARQL Protocol and Resource Description Framework Query Language query engine. The HermiT (version 1.4.3.x) ontology reasoner available in Protégé 5.x implemented the logical and structural consistency of the proposed ontology. To verify the proposed ontology model, we simulated data for 8 test cases. The personalized recommendation messages were generated based on the processing of personal activity data in combination with contextual weather data and personal preference data. The developed ontology was processed using a query engine against a rule base to generate personalized recommendations.
Results
The proposed ontology was implemented in automatic activity coaching to generate and deliver meaningful, personalized lifestyle recommendations. The ontology can be visualized using OWLViz and OntoGraf. In addition, we developed an ontology verification module that behaves similar to a rule-based decision support system to analyze the generation and delivery of personalized recommendation messages following a logical structure.
Conclusions
This study led to the creation of a meaningful ontology to generate and model personalized recommendation messages for physical activity coaching.}
}
@article{PENG2025101304,
title = {From holocene to anthropocene: A spacetime perspective on the ontology, epistemology, and methodology of space tourism},
journal = {Journal of Hospitality and Tourism Management},
pages = {101304},
year = {2025},
issn = {1447-6770},
doi = {https://doi.org/10.1016/j.jhtm.2025.101304},
url = {https://www.sciencedirect.com/science/article/pii/S1447677025000804},
author = {Kang-Lin Peng and Myung Ja Kim and Zhilun Huang and Ivan K.W. Lai and Xi Ji},
keywords = {Space tourism, Ontology-epistemology-methodology, Spacetime, Systematic literature review, Focus group, Delphi method},
abstract = {The rise and progression of space tourism has transformed the tourism paradigm. This study aims to systematically compare the fundamental differences between space tourism and terrestrial tourism in terms of ontology, epistemology, and methodology, to clarify the theoretical boundaries of space tourism and identify future research directions. A mixed-method approach was employed, integrating the systematic review technique with the focus group and the Delphi method to develop a cohesive conceptual framework. Two systematic reviews synthesized evidence from the literature on space tourism compared to terrestrial tourism, utilizing the Web of Science and Scopus databases. The Focus group and Delphi method were used to iteratively consult interdisciplinary experts to reach a consensus on the ontological, epistemological, and methodological distinctions between space and terrestrial tourism. Ultimately, this study developed a nine-dimensional integrated conceptual typology for space and terrestrial tourism studies. The typology framework combines essential philosophical elements, including ontology, epistemology, and methodology, with theoretical dimensions encompassing the current, incremental, and innovative components of the two types of tourism, into a unified analytical matrix. This study addresses the philosophical comparative research gap between space and terrestrial tourism through theoretical deconstruction, multiple methods, and proposition construction. It advances the evolution of the spacetime paradigm of tourism science, providing theoretical foundations and practical guidance for academia to navigate tourism reform in the new space era.}
}
@article{DJURICA2024114327,
title = {Effective presentation of ontological overlap of multiple conceptual models},
journal = {Decision Support Systems},
volume = {187},
pages = {114327},
year = {2024},
issn = {0167-9236},
doi = {https://doi.org/10.1016/j.dss.2024.114327},
url = {https://www.sciencedirect.com/science/article/pii/S016792362400160X},
author = {Djordje Djurica and Araz Jabbari and Jan Mendling and Jan Recker},
keywords = {Conceptual modeling, Ontological overlap, Combined ontological completeness, Color highlighting, Eye-tracking, Experiment, Problem-solving},
abstract = {Conceptual models are used to help professionals understand complex information systems and solve problems during systems analysis and design. Because single model often do not represent all relevant information, typically multiple models are used in combination. To design effective combinations of models, we propose a systematic approach that uses color highlighting to foreground overlapping concepts between multiple models to help readers identify corresponding information between models. We conducted two empirical studies – an online experiment and an eye-tracking experiment – to evaluate the cognitive efficacy of this approach. Our findings suggest that color highlighting can somewhat improve participants’ domain understanding but not the efficiency of problem-solving. Findings from the eye-tracking study suggest that the use of color can have both beneficial and harmful effects, depending on the extent of overlap.}
}
@article{JALALI2023105532,
title = {MSLE: An ontology for materials science laboratory equipment – Large-scale devices for materials characterization},
journal = {Materials Today Communications},
volume = {35},
pages = {105532},
year = {2023},
issn = {2352-4928},
doi = {https://doi.org/10.1016/j.mtcomm.2023.105532},
url = {https://www.sciencedirect.com/science/article/pii/S2352492823002222},
author = {Mehrdad Jalali and Matthias Mail and Rossella Aversa and Christian Kübel},
keywords = {Lab Equipment Ontology, Electron Microscopy, SHACL, Semantic Sensor Networks, MatVoc, SKOS},
abstract = {This paper introduces a new ontology for Materials Science Laboratory Equipment, termed MSLE. A fundamental issue with materials science laboratory (hereafter lab) equipment in the real world is that scientists work with various types of equipment with multiple specifications. For example, there are many electron microscopes with different parameters in chemical and physical labs. A critical development to unify the description is to build an equipment domain ontology as basic semantic knowledge and to guide the user to work with the equipment appropriately. Here, we propose to develop a consistent ontology for equipment, the MSLE ontology. In the MSLE, two main existing ontologies, the Semantic Sensor Network (SSN) and the Material Vocabulary (MatVoc), have been integrated into the MSLE core to build a coherent ontology. Since various acronyms and terms have been used for equipment, this paper proposes as an approach to use a Simple Knowledge Organization System (SKOS) to represent the hierarchical structure of equipment terms. Equipment terms were collected in various languages and abbreviations, and coded into the MSLE using the SKOS model. The ontology development was conducted in close collaboration with domain experts and focused on the large-scale devices for materials characterization available in our research group. Competency questions are expected to be addressed through the MSLE ontology. Constraints are modeled in the Shapes Query Language (SHACL); a prototype is shown and validated to prove the value of the modeling constraints.}
}
@article{LI2025130519,
title = {A dual medical ontology and relational graph framework with neural ordinary differential equations for diagnostic prediction},
journal = {Neurocomputing},
volume = {647},
pages = {130519},
year = {2025},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2025.130519},
url = {https://www.sciencedirect.com/science/article/pii/S0925231225011919},
author = {Shibo Li and Fanglin Dong and Runze Li and Weihua Li},
keywords = {Electronic health records, Diagnostic prediction, Medical ontology, Relational graph convolution, Neural ordinary differential equation},
abstract = {Accurate diagnostic prediction from Electronic Health Records (EHRs) is critical for advancing clinical decision-making and improving patient outcomes. Current works often struggle to systematically integrate medical domain knowledge, leverage unstructured data effectively, and model irregular temporal patterns in patient encounters. To address these limitations, we propose a dual medical ontology and relational graph framework with neural ordinary differential equations (DORI) for diagnostic prediction. DORI integrates hierarchical medical ontology structures and disease co-occurrence relationships to refine medical code embeddings, employs graph-based relational learning to capture intricate disease interactions, and simulates the continuous evolution of patient health states using neural ordinary differential equations (ODEs). Empirical evaluations on the MIMIC-III and MIMIC-IV datasets show that DORI achieves state-of-the-art performance in weighted F1 score and recall, confirming its enhanced ability to process irregular time intervals and capture complex disease relationships. Our framework increases interpretability by explicitly modeling multi-source medical knowledge and dynamic patient states, underscoring its potential for real-world clinical implementation. These results further underscore the importance of integrating multi-source medical knowledge and dynamic patient states for the precise prediction and interpretation of health events. Our code is released on https://github.com/1245505490/DORI.}
}
@article{LIAO2025103134,
title = {Large language model assisted fine-grained knowledge graph construction for robotic fault diagnosis},
journal = {Advanced Engineering Informatics},
volume = {65},
pages = {103134},
year = {2025},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2025.103134},
url = {https://www.sciencedirect.com/science/article/pii/S1474034625000278},
author = {Xingming Liao and Chong Chen and Zhuowei Wang and Ying Liu and Tao Wang and Lianglun Cheng},
keywords = {Knowledge Graph, Large Language Model, Fault Diagnosis, Industrial Robots},
abstract = {With the rapid deployment of industrial robots in manufacturing, the demand for advanced maintenance techniques to sustain operational efficiency has become crucial. Fault diagnosis Knowledge Graph (KG) is essential as it interlinks multi-source data related to industrial robot faults, capturing multi-level semantic associations among different fault events. However, the construction and application of fine-grained fault diagnosis KG face significant challenges due to the inherent complexity of nested entities in maintenance texts and the severe scarcity of annotated industrial data. In this study, we propose a Large Language Model (LLM) assisted data augmentation approach, which handles the complex nested entities in maintenance corpora and constructs a more fine-grained fault diagnosis KG. Firstly, the fine-grained ontology is constructed via LLM Assistance in Industrial Nested Named Entity Recognition (assInNNER). Then, an Industrial Nested Label Classification Template (INCT) is designed, enabling the use of nested entities in Attention-map aware keyword selection for the Industrial Nested Language Model (ANLM) data augmentation methods. ANLM can effectively improve the model’s performance in nested entity extraction when corpora are scarce. Subsequently, a Confidence Filtering Mechanism (CFM) is introduced to evaluate and select the generated data for enhancement, and assInNNER is further deployed to recall the negative samples corpus again to further improve performance. Experimental studies based on multi-source corpora demonstrate that compared to existing algorithms, our method achieves an average F1 increase of 8.25 %, 3.31 %, and 1.96 % in 5%, 10 %, and 25 % in few-shot settings, respectively.}
}
@article{LI2024102747,
title = {Comprehensive digital twin for infrastructure: A novel ontology and graph-based modelling paradigm},
journal = {Advanced Engineering Informatics},
volume = {62},
pages = {102747},
year = {2024},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2024.102747},
url = {https://www.sciencedirect.com/science/article/pii/S1474034624003951},
author = {Tao Li and Yi Rui and Hehua Zhu and Linhai Lu and Xiaojun Li},
keywords = {Digital twin, Infrastructure, Modelling, Ontology, Property graph model, Knowledge graph, BIM},
abstract = {The inherent uncertainty and complexity of infrastructure systems present significant challenges for precise management. By providing real-time status tracking and decision support capabilities, Digital Twin (DT) has shown significant promise in enhancing decision-making and improving efficiency and quality of management. To create a knowledge-rich and scalable DT capable of tracing the distinctive features and performance of infrastructure, this article develops a comprehensive IDT (Infrastructure DT) modelling paradigm. The ontology-based paradigm comprises five elements: scenario, virtual model, physical entity, relation, and component, supporting interoperability and multidisciplinary collaboration. By employing a graph-based modelling approach, the paradigm integrates various types of discrete data to link infrastructure entities into a cohesive system, thereby effectively capturing their dynamic characteristics. A case study comprising supported foundation excavation, subway tunnels, and pipe networks demonstrates the IDT’s capability to facilitate coordination across multidisciplinary, multi-scale, and multi-stage contexts, thereby establishing a transparent, effective, and secure pattern of infrastructure management.}
}
@article{PICKEL2025659,
title = {A survey on the utilization of ontologies for decision-making in industrial product development},
journal = {Procedia CIRP},
volume = {136},
pages = {659-664},
year = {2025},
note = {35th CIRP Design 2025},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2025.08.113},
url = {https://www.sciencedirect.com/science/article/pii/S2212827125008662},
author = {Jessica Pickel and Stefan Goetz and Sandro Wartzack},
keywords = {Knowledge Management, Ontology, Decision-Making, Product Development Process},
abstract = {Several studies highlight the potential of ontologies for effectively connecting knowledge in complex industrial environments. However, their practical application in decision-making remains insufficiently explored, limiting their adoption in industry. This paper addresses this gap by conducting an empirical study with two objectives: (1) examining the current use of knowledge management solutions and ontologies in industrial product development, and (2) identifying key challenges in their utilization for decision-making. The study compares the theoretical advantages of ontologies with their practical applications, highlighting discrepancies and barriers to adoption. Key challenges include data issues, implementation difficulties, and cultural barriers. Based on these findings, this paper proposes strategic measures to overcome these obstacles and facilitate ontology-driven decision support.}
}
@article{MA2024105656,
title = {Automatic compliance checking of BIM models against quality standards based on ontology technology},
journal = {Automation in Construction},
volume = {166},
pages = {105656},
year = {2024},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2024.105656},
url = {https://www.sciencedirect.com/science/article/pii/S0926580524003923},
author = {Zhiliang Ma and Honggang Zhu and Xinglei Xiang and Žiga Turk and Robert Klinc},
keywords = {Building information model (BIM), Industry foundation classes (IFC), Quality, Ontology technology, Automatic compliance checking},
abstract = {Many countries have issued standards to stipulate the quality of BIM models. However, due to the complexity of BIM models and the textual expression of the standards, checking the quality of BIM models against the standards manually is challenging and time-consuming. In order to solve the problem, this paper presents an ontology-based approach for the automatic compliance checking of BIM models against the standards. Taking the Chinese standard as an example, it is represented in OWL to obtain an ontology, and SWRL is used for representing the checking rules. Then, an inference process is established to fulfill the checking. Finally, a prototype system is developed to validate the approach. It is concluded that the approach can be applied to check the quality of BIM models in IFC format automatically. This research contributes to the development of automatic compliance checking systems for the quality of BIM models against real standards.}
}
@article{CASTIGLIONE2025104150,
title = {SecOnto: Ontological Representation of Security Directives},
journal = {Computers & Security},
volume = {148},
pages = {104150},
year = {2025},
issn = {0167-4048},
doi = {https://doi.org/10.1016/j.cose.2024.104150},
url = {https://www.sciencedirect.com/science/article/pii/S0167404824004553},
author = {Gianpietro Castiglione and Giampaolo Bella and Daniele Francesco Santamaria},
keywords = {Semantic web, Reasoning, NIS 2},
abstract = {The current digital landscape demands robust security requirements and, for doing so, the institutions enact complex security directives to protect the citizens and the infrastructures, particularly in the European Union. These directives aim to safeguard data and harmonise security across the European region, and institutions must navigate this evolving legal landscape in order to implement and keep up-to-date the prescribed security measures. However, understanding and implementing these directives towards full compliance can be difficult and expensive. Ontological representation can be employed to represent and operationalise such security directives, ultimately contributing to the effectiveness and efficiency of the compliance process. Ontologies in fact promote a structured approach to represent knowledge, making the applicable directives more simply understandable by humans and more readily processable by machines. This article introduces SecOnto, a novel methodology for representing security directives as ontologies. SecOnto breaks down the process of transforming the juridical language of modern security directives into full-fledged ontologies by means of five semi-automated steps: Preprocessing, Interpretation, Structuring, Representation and Verification. Each step is described and validated by means of operational examples based upon Directive 2022/2555 of the European Parliament and of the Council of the European Union on security of network and information systems, better known as NIS 2.}
}
@article{SHI2024678,
title = {Interoperable information modelling leveraging asset administration shell and large language model for quality control toward zero defect manufacturing},
journal = {Journal of Manufacturing Systems},
volume = {77},
pages = {678-696},
year = {2024},
issn = {0278-6125},
doi = {https://doi.org/10.1016/j.jmsy.2024.10.011},
url = {https://www.sciencedirect.com/science/article/pii/S0278612524002395},
author = {Dachuan Shi and Philipp Liedl and Thomas Bauernhansl},
keywords = {Interoperability, Large language model, Ontology, Asset administration shell, Zero defect manufacturing, Information modelling, Quality control, Industry 4.0},
abstract = {In the era of Industry 4.0, Zero Defect Manufacturing (ZDM) has emerged as a prominent strategy for quality improvement, emphasizing data-driven approaches for defect prediction, prevention, and mitigation. The success of ZDM heavily depends on the availability and quality of data typically collected from diverse and heterogeneous sources during production and quality control, presenting challenges in data interoperability. Addressing this, we introduce a novel approach leveraging Asset Administration Shell (AAS) and Large Language Models (LLMs) for creating interoperable information models that incorporate semantic contextual information to enhance the interoperability of data integration in the quality control process. AAS, initiated by German industry stakeholders, shows a significant advancement in information modeling, blending ontology and digital twin concepts for the virtual representation of assets. In this work, we develop a systematic, use-case-driven methodology for AAS-based information modeling. This methodology guides the design and implementation of AAS models, ensuring model properties are presented in a unified structure and reference external standardized vocabularies to maintain consistency across different systems. To automate this referencing process, we propose a novel LLM-based algorithm to semantically search model properties within a standardized vocabulary repository. This algorithm significantly reduces manual intervention in model development. A case study in the injection molding domain demonstrates the practical application of our approach, showcasing the integration and linking of product quality and machine process data with the help of the developed AAS models. Statistical evaluation of our LLM-based semantic search algorithm confirms its efficacy in enhancing data interoperability. This methodology offers a scalable and adaptable solution for various industrial use cases, promoting widespread data interoperability in the context of Industry 4.0.}
}
@incollection{ALKHALAF2025410,
title = {Biological and Medical Ontologies: Disease Ontology (DO)},
editor = {Shoba Ranganathan and Mario Cannataro and Asif M. Khan},
booktitle = {Encyclopedia of Bioinformatics and Computational Biology (Second Edition)},
publisher = {Elsevier},
edition = {Second Edition},
address = {Oxford},
pages = {410-421},
year = {2025},
isbn = {978-0-323-95503-4},
doi = {https://doi.org/10.1016/B978-0-323-95502-7.00038-5},
url = {https://www.sciencedirect.com/science/article/pii/B9780323955027000385},
author = {Ruba {Al Khalaf} and Anna Bernasconi and Marco Masseroli},
keywords = {Biomedical ontology, Disease classification, Disease definitions, Disease ontology, Health, Hierarchical structure, Human disease, Open source ontology},
abstract = {Human Disease Ontology (DO) is a standardized vocabulary for annotating and classifying diseases and their clinical features. It includes over 18,000 disease concepts (classes) and is organized hierarchically, with each concept representing a specific disease or condition. The DO is designed to facilitate the exchange and integration of disease-related information and to support the identification of relationships between diseases. It is widely used in the biomedical community for a variety of purposes, including disease classification, data integration, and knowledge representation.}
}
@article{GUO2024104124,
title = {An ontology-based method for knowledge reuse in the design for maintenance of complex products},
journal = {Computers in Industry},
volume = {161},
pages = {104124},
year = {2024},
issn = {0166-3615},
doi = {https://doi.org/10.1016/j.compind.2024.104124},
url = {https://www.sciencedirect.com/science/article/pii/S0166361524000526},
author = {Ziyue Guo and Dong Zhou and Dequan Yu and Qidi Zhou and Hongduo Wu and Aimin Hao},
keywords = {Knowledge management, Ontology development, Product design, Industrial maintenance},
abstract = {In the context of the Fourth Industrial Revolution, a large amount of heterogeneous data and information is generated during the lifecycle of complex products, which poses a considerable challenge for manufacturers and effective knowledge integration. It has been challenging for traditional experience-based design methods to meet the diverse needs of customers and maintain competitiveness in fierce global markets. Capturing, formalizing and reusing multidisciplinary knowledge that is scattered among different departments and stages to help make effective decisions has been a crucial way for digital enterprises to improve manufacturing efficiency. Design for maintenance is typical work requiring cross-domain knowledge and involving stakeholder collaboration. This paper presents a structured domain-specific ontology and its development method, namely, the Maintainability Design Ontology for Complex prOducts (MDOCO), to formalize heterogeneous knowledge and improve semantic interoperability in the maintainability design area. The MDOCO has a rigorous semantic structure and complies with well-designed top-level and middle ontologies such as the Basic Formal Ontology and the Industrial Ontology Foundry (IOF) Core Ontology to ensure semantic interoperability. A set of reasoning rules is carefully designed to enable the MDOCO to perform knowledge reasoning. In a practical case, the effectiveness of the MDOCO is validated at both the semantic and application levels. The MDOCO combines recent methodology and best practices, enabling the well-structured modeling of heterogeneous knowledge and good semantic interoperability.}
}
@article{XUE2024101758,
title = {Efficient ontology matching through compact linear genetic programming with surrogate-assisted local search},
journal = {Swarm and Evolutionary Computation},
volume = {91},
pages = {101758},
year = {2024},
issn = {2210-6502},
doi = {https://doi.org/10.1016/j.swevo.2024.101758},
url = {https://www.sciencedirect.com/science/article/pii/S2210650224002967},
author = {Xingsi Xue and Jerry Chun-Wei Lin and Tong Su},
keywords = {Ontology matching, Compact linear genetic programming, Multi-program encoding, Surrogate-assisted local search},
abstract = {Ontology is a foundational technique of Semantic Web, which enables meaningful interpretation of Web data. However, ontology heterogeneity obstructs the communications among different ontologies, which is a key hindrance in realizing Semantic Web. To leverage different ontologies, it is important to match ontologies by identifying their semantically related entities. Given the vast number of entities and rich vocabulary semantics, this task presents considerable challenges. To tackle this challenge, this paper proposes a novel Compact Linear Genetic Programming with Surrogate-Assisted Local Search (CLGP-SALS). First, a compact multi-program encoding mechanism is developed to reduce the computational cost while ensuring the reusability of building blocks in Linear Genetic Programming. Moreover, it coordinates multiple programs within one solution to improve the quality of ontology alignment. Second, to enhance convergence speed, a new Surrogate-Assisted Local Search is designed, incorporating semantic distance and fitness discrepancies for a focused local search process. The surrogate model presents a superior approach for approximating the fitness of individuals, thereby improving search efficiency in the ontology matching task. Experimental results demonstrate that CLGP-SALS outperforms the state-of-the-art ontology matching methods on the ontology alignment evaluation initiative’s benchmark. The results show that our method can efficiently determine high-quality ontology alignments, and its performance outperforms the compared methods in terms of both effectiveness and efficiency.}
}
@article{KEBEDE2024248,
title = {A modular ontology modeling approach to developing digital product passports to promote circular economy in the built environment},
journal = {Sustainable Production and Consumption},
volume = {48},
pages = {248-268},
year = {2024},
issn = {2352-5509},
doi = {https://doi.org/10.1016/j.spc.2024.05.007},
url = {https://www.sciencedirect.com/science/article/pii/S2352550924001362},
author = {Rahel Kebede and Annika Moscati and He Tan and Peter Johansson},
keywords = {Circular economy, Digital product passports, Modular ontology, Ontology design pattern, Information requirements, Built environment},
abstract = {The significant impact of the built environment on resource consumption and waste production has led to calls for a shift towards a circular economy model that maximizes the efficient use of resources. This study explores the use of digital product passports (DPPs) to improve how we manage products throughout their lifecycle. However, dealing with the complexity and large volume of data in DPPs can be challenging in terms of effective information management and utilization. We address this issue by adopting a modular ontological approach to systematically capture product lifecycle information from its origin to its end-of-life phase. To ensure interoperability and reusability of the ontology, we annotate key concepts and relationships using International Organization for Standardization (ISO) standards that promote circular economy. Our research led to the development of several ontology modules derived from literature reviews and interviews conducted with industry and academia experts who specialize in sustainability. These modules were then integrated to create a digital product passport ontology. The study demonstrates the feasibility of using a modular ontology approach to manage the complex information inherent in DPPs paving the way for more sustainable management practices in the built environment sector.}
}
@article{SANJUSARAVANAN2024101675,
title = {Innovative agricultural ontology construction using NLP methodologies and graph neural network},
journal = {Engineering Science and Technology, an International Journal},
volume = {52},
pages = {101675},
year = {2024},
issn = {2215-0986},
doi = {https://doi.org/10.1016/j.jestch.2024.101675},
url = {https://www.sciencedirect.com/science/article/pii/S2215098624000612},
author = {Krithikha {Sanju Saravanan} and Velammal Bhagavathiappan},
keywords = {Term extraction, Relation extraction, Natural language processing, Regular expressions, Graph neural network},
abstract = {Advancements in technology brought various innovations to agricultural practices. As a part of the development, establishing an agricultural ontology would unleash the growth of cross-domain agriculture and Natural Language Processing (NLP). For constructing such domain-based ontology, semantic and syntactic understanding of the domain data is needed. In agriculture, the availability of pre-determined domain-based data is not sufficient hence, a standard methodology with syntactic and general semantic features are required for processing the data. In this research work, Agricultural Domain based Ontology Construction (ADOC) is proposed and the overall framework has three approaches for establishing the agriculture domain based ontologies. The input text documents undergo anaphora resolution phase utilizing the semantic-based method. In the first method of ADOC the ontology is developed using the terms and relationships that are extracted from the NLP techniques. The second method of ADOC uses pretrained BERT model and Hearst patterns while the third model of ADOC is based on pretrained BERT with regular expressions and unsupervised Graph Neural Network (GNN) for creating the agricultural ontology. The efficacy of the proposed ADOC utilizing BERT with regular expressions and GNN method shows an outstanding result when compared to other proposed and prevailing systems, with a precision and recall of 96.67% and 98.31%.}
}
@article{KJAERGAARD2020106848,
title = {Current practices and infrastructure for open data based research on occupant-centric design and operation of buildings},
journal = {Building and Environment},
volume = {177},
pages = {106848},
year = {2020},
issn = {0360-1323},
doi = {https://doi.org/10.1016/j.buildenv.2020.106848},
url = {https://www.sciencedirect.com/science/article/pii/S0360132320302079},
author = {Mikkel B. Kjærgaard and Omid Ardakanian and Salvatore Carlucci and Bing Dong and Steven K. Firth and Nan Gao and Gesche Margarethe Huebner and Ardeshir Mahdavi and Mohammad Saiedur Rahaman and Flora D. Salim and Fisayo Caleb Sangogboye and Jens Hjort Schwee and Dawid Wolosiuk and Yimin Zhu},
keywords = {Open data, Data publishing, Data use, Occupant behavior, FAIR Data, Ontology, Anonymi, z, ation, Metadata schema},
abstract = {Many new tools for improving the design and operation of buildings try to realize the potential of big data. In particular, data is an important element for occupant-centric design and operation as occupants’ presence and actions are affected by a high degree of uncertainty and, hence, are hard to model in general. For such research, data handling is an important challenge, and following an open science paradigm based on open data can increase efficiency and transparency of scientific work. This article reviews current practices and infrastructure for open data-driven research on occupant-centric design and operation of buildings. In particular, it covers related work on open data in general and for the built environment in particular, presents survey results for existing scientific practices, reviews technical solutions for handling data and metadata, discusses ethics and privacy protection and analyses principles for the sharing of open data. In summary, this study establishes the status quo and presents an outlook on future work for methods and infrastructures to support the open data community within the built environment.}
}
@article{BELETE2024200417,
title = {Enhancing Word Sense Disambiguation for Amharic homophone words using Bidirectional Long Short-Term Memory network},
journal = {Intelligent Systems with Applications},
volume = {23},
pages = {200417},
year = {2024},
issn = {2667-3053},
doi = {https://doi.org/10.1016/j.iswa.2024.200417},
url = {https://www.sciencedirect.com/science/article/pii/S2667305324000917},
author = {Mequanent Degu Belete and Lijalem Getanew Shiferaw and Girma Kassa Alitasb and Tariku Sinshaw Tamir},
keywords = {Amharic language, Homophone, Machine learning, Deep learning, Bidirectional, BiLSTM, BiGRU, TFIDF, BoW, Word embedding, Amharic word sense disambiguation},
abstract = {Given the Amharic language has a lot of perplexing terminology since it features duplicate homophone letters, fidel's ሀ, ሐ, and ኀ (three of which are pronounced as HA), ሠ and ሰ (both pronounced as SE), አ and ዐ (both pronounced as AE), and ጸ and ፀ (both pronounced as TSE). The WSD (Word Sense Disambiguation) model, which tackles the issue of lexical ambiguity in the context of the Amharic language, is developed using a deep learning technique. Due to the unavailability of the Amharic wordnet, a total of 1756 examples of paired Amharic ambiguous homophonic words were collected. These words were ድህነት(dhnet) and ድኅነት(dhnet), ምሁር(m'hur) and ምሑር(m'hur), በአል(be'al) and በዢል(be'al), አቢይ (abiy) and ዐቢይ(abiy), with a total of 1756 examples. Following word preprocessing, word2vec, fasttext, Term Frequency-Inverse Document Frequency (TFIDF), and bag of words (BoW) were used to vectorize the text. The vectorized text was divided into train and test data. The train data was then analysed using Naive Bayes (NB), K-nearest neighbour (KNN), logistic regression (LG), decision trees (DT), random forests (RF), and random oversampling technique. Bidirectional Gate Recurrent Unit (BiGRU) and Bidirectional Long Short-Term Memory (BiLSTM) improved to 99.99 % accuracy even with limited datasets.}
}
@article{ANGERRI2025101388,
title = {A machine-readable metadata model for intelligent data analysis},
journal = {Cognitive Systems Research},
volume = {93},
pages = {101388},
year = {2025},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2025.101388},
url = {https://www.sciencedirect.com/science/article/pii/S1389041725000683},
author = {Xavier Angerri and Joan Vázquez and Karina Gibert},
keywords = {Metadata, Metainformation, Automatic Reporting, Preprocessing, Intelligent Data Analysis, Knowledge Discovery, Knowledge Representation},
abstract = {Metadata, or data about data, is essential in Knowledge Discovery from Data (KDD) and Artificial Intelligence (AI) processes, providing details about the meanings and technical aspects of dataset variables. Historically, research has focused on software to store and manage metadata, mainly describing data structure and formats for analyst understanding. However, little has been done to analyze the metadata required for automating advanced KDD processes. Traditionally, metadata creation has been a manual process, relying on analysts to gather information from stakeholders. This paper introduces the GeMeDaFi methodology, enabling stakeholders to automatically generate machine-readable metadata files, facilitating the automatic management of metadata. GeMeDaFi is a key component of the AM4IDA methodology, which guides intelligent data analysis using automatically generated metadata. This process spans from data preprocessing to result interpretation, including modeling. The metadata file, based on the MdM formal model, incorporates semantic information from stakeholders and the dataset’s structure, supporting automated intelligent preprocessing and analysis. The proposal also enhances the INSESS methodology for intelligent data analysis and has been applied in four real-world scenarios. The primary contributions are the significant reduction in time and errors in creating metadata files, accelerating the preprocessing phase, and enabling automation in the analytical step of KDD processes.}
}
@article{LU2023110752,
title = {SympGAN: A systematic knowledge integration system for symptom–gene associations network},
journal = {Knowledge-Based Systems},
volume = {276},
pages = {110752},
year = {2023},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2023.110752},
url = {https://www.sciencedirect.com/science/article/pii/S0950705123005026},
author = {Kezhi Lu and Kuo Yang and Hailong Sun and Qian Zhang and Qiguang Zheng and Kuan Xu and Jianxin Chen and Xuezhong Zhou},
keywords = {Deep learning, Knowledge graph, Relationship inference, Health care},
abstract = {Phenotypes (i.e., symptoms and clinical signs) are essential for clinical diagnosis and research related to symptom science and precision health. As clinical observational manifestations of a disease, symptoms are clinically significant because they act as direct causes for patients to seek medical care and the primary indicators for clinicians to provide diagnosis/treatments. However, a comprehensive phenotypic knowledge base and high-quality symptom–gene associations are lacking. Therefore, a thorough understanding of the relationships between symptoms and other entities is urgently needed to support scientific research and clinical health care. In this paper, we constructed a systematic, large-scale, and high-quality symptom-gene associations network system named SympGAN (accessible at http://www.sympgan.org/). We provide access to the database with millions of associations between symptoms, genes, diseases, and drugs, as well as the system for users to search, analyze, knowledge inference, and present data visualization. We utilize state-of-the-art machine learning and deep learning algorithms as the backbone to form the final dataset. In addition, we utilize the RoBERTa-PubMed neural network for name entity recognition to assist in data screening. The knowledge graph is adopted to organize the relationships between different entities. We adopt ConvE, TuckER, and HypER methods for knowledge completion experiments to validate the quality of final knowledge graph triples. Based on the results, we provide online automatic knowledge inference interfaces. The system, SympGAN, has promising value for disease diagnosis, decision support in health care, precision health, and scientific research, as researchers and practitioners can easily access information about symptoms, diseases, targets, gene ontology, and drugs.}
}
@article{DEIMAZAR2023105246,
title = {Machine learning models to detect and predict patient safety events using electronic health records: A systematic review},
journal = {International Journal of Medical Informatics},
volume = {180},
pages = {105246},
year = {2023},
issn = {1386-5056},
doi = {https://doi.org/10.1016/j.ijmedinf.2023.105246},
url = {https://www.sciencedirect.com/science/article/pii/S1386505623002642},
author = {Ghasem Deimazar and Abbas Sheikhtaheri},
keywords = {Artificial intelligence, Machine learning, Deep learning, Natural language processing (NLP), Patient safety, Electronic health record (EHR), Adverse drug event, Adverse drug reaction},
abstract = {Introduction
Identifying patient safety events using electronic health records (EHRs) and automated machine learning-based detection methods can help improve the efficiency and quality of healthcare service provision.
Objective
This study aimed to systematically review machine learning-based methods and techniques, as well as their results for patient safety event management using EHRs.
Methods
We reviewed the studies that focused on machine learning techniques, including automatic prediction and detection of patient safety events and medical errors through EHR analysis to manage patient safety events. The data were collected by searching Scopus, PubMed (Medline), Web of Science, EMBASE, and IEEE Xplore databases.
Results
After screening, 41 papers were reviewed. Support vector machine (SVM), random forest, conditional random field (CRF), and bidirectional long short-term memory with conditional random field (BiLSTM-CRF) algorithms were mostly applied to predict, identify, and classify patient safety events using EHRs; however, they had different performances. BiLSTM-CRF was employed in most of the studies to extract and identify concepts, e.g., adverse drug events (ADEs) and adverse drug reactions (ADRs), as well as relationships between drug and severity, drug and ADEs, drug and ADRs. Recurrent neural networks (RNN) and BiLSTM-CRF had the best results in detecting ADEs compared to other patient safety events. Linear classifiers and Naive Bayes (NB) had the highest performance for ADR detection. Logistic regression had the best results in detecting surgical site infections. According to the findings, the quality of articles has non-significantly improved in recent years, but they had low average scores.
Conclusions
Machine learning can be useful in automatic detection and prediction of patient safety events. However, most of these algorithms have not yet been externally validated or prospectively tested. Therefore, further studies are required to improve the performance of these automated systems.}
}
@article{PENG2018319,
title = {Linking Health Web Services as Resource Graph by Semantic REST Resource Tagging},
journal = {Procedia Computer Science},
volume = {141},
pages = {319-326},
year = {2018},
note = {The 9th International Conference on Emerging Ubiquitous Systems and Pervasive Networks (EUSPN-2018) / The 8th International Conference on Current and Future Trends of Information and Communication Technologies in Healthcare (ICTH-2018) / Affiliated Workshops},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2018.10.194},
url = {https://www.sciencedirect.com/science/article/pii/S1877050918318441},
author = {Cong Peng and Prashant Goswami and Guohua Bai},
keywords = {health data integration, eHealth, Web service description, Semantic Web, REST},
abstract = {Various health Web services host a huge amount of health data about patients. The heterogeneity of the services hinders the collaborative utilization of these health data, which can provide a valuable support for the self-management of chronic diseases. The combination of REST Web services and Semantic Web technologies has proven to be a viable approach to address the problem. This paper proposes a method to add semantic annotations to the REST Web services. The service descriptions and the resource representations with semantic annotations can be transformed into a resource graph. It integrates health data from different services, and can link to the health-domain ontologies and Linked Open Health Data to support health management and imaginative applications. The feasibility of our method is demonstrated by realizing with OpenAPI service description and JSON-LD representation in an example use case.}
}
@article{BARRETT2021345,
title = {Situated observation in Bohmian mechanics},
journal = {Studies in History and Philosophy of Science},
volume = {88},
pages = {345-357},
year = {2021},
issn = {0039-3681},
doi = {https://doi.org/10.1016/j.shpsa.2021.06.009},
url = {https://www.sciencedirect.com/science/article/pii/S0039368121000935},
author = {Jeffrey A. Barrett},
keywords = {Quantum measurement problem, Situated observation, Situated empirical adequacy, Bohmian mechanics, Primitive ontology},
abstract = {Here we investigate what it might mean for a formulation of quantum mechanics to be empirically adequate. We begin by considering the measurement problem as an empirical problem and distinguishing between stronger and weaker varieties of empirical adequacy. A strongly adequate theory is one that explains the experiences of a physically situated observer. A formulation of quantum mechanics that provides such situated empirical adequacy also provides a particularly compelling response to the measurement problem. As a concrete example we consider how Bohmian mechanics explains the experience of a physically situated observer.}
}
@article{BENMILED2023e14636,
title = {Feature engineering from medical notes: A case study of dementia detection},
journal = {Heliyon},
volume = {9},
number = {3},
pages = {e14636},
year = {2023},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2023.e14636},
url = {https://www.sciencedirect.com/science/article/pii/S2405844023018431},
author = {Zina {Ben Miled} and Paul R. Dexter and Randall W. Grout and Malaz Boustani},
keywords = {Dementia, BERT, Clinical BERT, UMLS, Medical notes, EMR},
abstract = {Background and objectives
Medical notes are narratives that describe the health of the patient in free text format. These notes can be more informative than structured data such as the history of medications or disease conditions. They are routinely collected and can be used to evaluate the patient's risk for developing chronic diseases such as dementia. This study investigates different methodologies for transforming routine care notes into dementia risk classifiers and evaluates the generalizability of these classifiers to new patients and new health care institutions.
Methods
The notes collected over the relevant history of the patient are lengthy. In this study, TF-ICF is used to select keywords with the highest discriminative ability between at risk dementia patients and healthy controls. The medical notes are then summarized in the form of occurrences of the selected keywords. Two different encodings of the summary are compared. The first encoding consists of the average of the vector embedding of each keyword occurrence as produced by the BERT or Clinical BERT pre-trained language models. The second encoding aggregates the keywords according to UMLS concepts and uses each concept as an exposure variable. For both encodings, misspellings of the selected keywords are also considered in an effort to improve the predictive performance of the classifiers. A neural network is developed over the first encoding and a gradient boosted trees model is applied to the second encoding. Patients from a single health care institution are used to develop all the classifiers which are then evaluated on held-out patients from the same health care institution as well as test patients from two other health care institutions.
Results
The results indicate that it is possible to identify patients at risk for dementia one year ahead of the onset of the disease using medical notes with an AUC of 75% when a gradient boosted trees model is used in conjunction with exposure variables derived from UMLS concepts. However, this performance is not maintained with an embedded feature space and when the classifier is applied to patients from other health care institutions. Moreover, an analysis of the top predictors of the gradient boosted trees model indicates that different features inform the classification depending on whether or not spelling variants of the keywords are included.
Conclusion
The present study demonstrates that medical notes can enable risk prediction models for complex chronic diseases such as dementia. However, additional research efforts are needed to improve the generalizability of these models. These efforts should take into consideration the length and localization of the medical notes; the availability of sufficient training data for each disease condition; and the variabilities resulting from different feature engineering techniques.}
}
@article{KIM2024111396,
title = {Emotion-oriented recommender system for personalized control of indoor environmental quality},
journal = {Building and Environment},
volume = {254},
pages = {111396},
year = {2024},
issn = {0360-1323},
doi = {https://doi.org/10.1016/j.buildenv.2024.111396},
url = {https://www.sciencedirect.com/science/article/pii/S0360132324002385},
author = {Hakpyeong Kim and Taehoon Hong},
keywords = {Indoor environmental quality, Affective computing, Fuzzy logic, Recommender system, Graph attention network},
abstract = {Indoor Environmental Quality (IEQ) significantly influences health, cognitive abilities, and even moods. With the rise of smart homes and the Internet of Things (IoT), the need for personalized IEQ control has become paramount. Traditional systems, primarily focusing on explicit feedback (i.e., preference), often neglect the role of emotions in shaping this feedback. Therefore, this study presents the Emotion-oriented Recommender System for personalized control of IEQ (ERS-IEQ), based on the R-E-C-S ontology, focusing on (i) Recognizing user's continuous emotional states, (ii) Estimating emotional similarity between users, (iii) Collecting user's feedback on IEQ conditions, and (iv) Systemizing an emotion-oriented recommender system using a graph neural network. In order to confirm the predictive performance of the ERS-IEQ and verify its higher level of excellence compared to traditional recommender systems, a private dataset composed of IEQ conditions, users' explicit feedback, and users' emotional states was built via a human participant experiment using a climate chamber. As a result, the ERS-IEQ significantly enhances the recommender system's predictive performance, particularly in thermal preferences. The number of linguistic terms of emotional similarity has a profound effect on the system's predictions, with four terms proving most effective. In the near future, ERS-IEQ will play a role as a personal assistant in smart home automation, offering emotion-based recommendations. It addresses key challenges in traditional recommender systems, such as the cold start problem and rating sparsity, and ensures personalized adjustments to IEQ conditions in both private and public spaces.}
}
@incollection{GALITSKY2025363,
title = {Chapter 10 - Explainability discourse},
editor = {Boris Galitsky},
booktitle = {Healthcare Applications of Neuro-Symbolic Artificial Intelligence},
publisher = {Academic Press},
pages = {363-409},
year = {2025},
isbn = {978-0-443-30046-2},
doi = {https://doi.org/10.1016/B978-0-443-30046-2.00001-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780443300462000016},
author = {Boris Galitsky},
keywords = {Discourse analysis, meta-reasoning, human–machine explainability, medical complaints},
abstract = {We investigate explanations through the lenses of discourse analysis and meta-reasoning. Our approach formalizes explainability using discourse trees, where explanations are defined by features such as elementary discourse units and rhetorical relations. We identify two levels of explainability: object-level explanations and meta-explanations, structured within a learning framework. Building on this, we examine human–machine mutual explainability, focusing on how diagnoses can be derived from these interactions. Lastly, we develop a computational model to detect requests for explanations in patients' medical complaints. Findings reveal that nearly a quarter of complainants explicitly or implicitly sought explanations from hospitals regarding care decisions and treatment plans.}
}
@article{BOUGDIRA2020509,
title = {Conceptual framework for general traceability solution: description and bases},
journal = {Journal of Modelling in Management},
volume = {15},
number = {2},
pages = {509-530},
year = {2020},
issn = {1746-5664},
doi = {https://doi.org/10.1108/JM2-12-2018-0207},
url = {https://www.sciencedirect.com/science/article/pii/S1746566420000220},
author = {Abdesselam Bougdira and Abdelaziz Ahaitouf and Ismail Akharraz},
keywords = {Knowledge management, Modelling, Design, Development, Food industry, Information flow},
abstract = {Purpose
The purpose of this paper is to describe a proposed framework for traceability purpose. Hence, the framework provides a formal and structured way of viewing a traceability solution. This structure lays the required bases for a traceability system before starting development and deployment.
Design/methodology/approach
The paper examines several traceability publications, including systems and literature review. The study covers the traceability implementation phase. Therefore, this research approaches the traceability issue from three perspectives (description, engineering and executive one). The separation between aspects is essential when describing and comparing traceability systems. This distinction is also helpful when recommending solution improvements.
Findings
The framework identifies six traceability bases: aims, functions, specifications, data classification, processes and procedures. These can establish a basis for a general purpose tool that can enable users to develop an efficient traceability solution. Thus, the first ontology expresses the framework domain and ensures optimal use of it. The second one represents the bases that can serve as a knowledge base to manage the product data.
Research limitations/implications
The suggested framework tackles the implementation of traceability. Therefore, the design emphasizes the importance of technological concerns. Some studied cases could require more research angles (i.e. economic and legislative). Thus, framework enrichment is essential for further improvements.
Practical implications
The framework helps users to develop a general, interoperable and scalable traceability solution. These are important to promote the generalization of traceability systems.
Originality/value
The framework fulfills a requirement for establishing general traceability foundations. Therefore, the guide independently operates of the product or the industry specificity. Moreover, the bases aim to bridge the gap between solution engineering and traceability requirements.}
}
@article{MANZANARESSALOR2025112945,
title = {Enhancing text anonymization via re-identification risk-based explainability},
journal = {Knowledge-Based Systems},
volume = {310},
pages = {112945},
year = {2025},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2024.112945},
url = {https://www.sciencedirect.com/science/article/pii/S095070512401579X},
author = {Benet Manzanares-Salor and David Sánchez},
keywords = {Privacy protection, Neural language models, Explainability, Text anonymization, Re-identification},
abstract = {Text anonymization is a challenging task usually carried out by human annotators, thereby incurring significant economic and temporal costs. Even though automated approaches have been proposed to mitigate those costs, practical mechanisms for text anonymization mostly rely on named entity recognition (NER), which is acknowledged to offer insufficient privacy protection. To tackle this issue, we propose a methodology to enhance the privacy protection attained by any text anonymization mechanism –with a focus on NER-based ones–, while providing empirical guarantees against re-identification rooted on the k-anonymity privacy model. Our method relies on a neural language model trained on the aggregated background knowledge that can be leveraged to conduct re-identification attacks. Then, it employs explainability techniques to detect and iteratively mask the unprotected terms that caused the greatest re-identification risk until a user-defined k-anonymity level is reached. On the contrary to most existing methods in the text anonymization literature, our approach allows to intuitively configure the desired level of protection, and to tune the trade-off between privacy and data utility preservation. Experiments show that our method is able to significantly and consistently lower the re-identification risk of NER-based anonymizations, and to compete against more sophisticated state-of-the-art text anonymization methods while being free of their costs and external dependencies.}
}
@article{SINHA2020224,
title = {Blockchain-based smart contract for international business – a framework},
journal = {Journal of Global Operations and Strategic Sourcing},
volume = {14},
number = {1},
pages = {224-260},
year = {2020},
issn = {2398-5364},
doi = {https://doi.org/10.1108/JGOSS-06-2020-0031},
url = {https://www.sciencedirect.com/science/article/pii/S2398536420000119},
author = {Deepankar Sinha and Shuvo {Roy Chowdhury}},
keywords = {International trade, Qualitative, Ontology, Value chain analysis, Smart contract, Blockchain technology, INCO terms, Side chains},
abstract = {Purpose
Cross border trade, involving different business environments between the sellers’ and buyers’ countries, may result in conflicts because of asymmetry in the information structure across the borders. The International Chambers of Commerce (ICC) has laid down ground rules on terms of shipment and payment, enabling harmonization and standardization of business process, and fixing of responsibilities for international trade. The international commercial (INCO) terms by ICC define the duties, obligations and cost borne by the exporter and the importer. An exporter’s uncertainty looms once the goods cross his/her border. Therefore, there is a need for a smart contract that is secured, transparent, legitimate and trustworthy. The authors propose a blockchain technology-based smart global contract (BTGC) framework for international trade.
Design/methodology/approach
In this paper, the authors develop the framework based on value chain analysis (VCA) of international trade and an ontology-driven-blockchain-design approach. The paper analyzes the sequence of activities in the value chain of global trade, the terms of the contract, the data structure templates, the validation rules and the points-of-failure, and proposes the smart contract blockchain structure.
Findings
This paper proposes the BTGC framework considering the INCO terms 2020; it provides the validation rules and the probability of failures; and identifies the elements that cause the halting of contracts and conditions of creation of side blockchains. The framework also includes the governance of the BTGC system.
Research limitations/implications
The proposed framework not only has implications at the firm level as it automates and secures a global sale contract but also is expected to harmonize the global-trade process as well. The developers may use the attributes, data structure templates and the rules identified in this paper for developing the GC software. Future research may consider using case analysis, class diagrams and the related steps for developing the blockchain software.
Originality/value
This paper proposes a complete value chain of global contract (GC) concerning exports, an ontology of GC and a blockchain-based smart-contract framework based on global standards. Besides, it specifies the elements of fraud (such as the non-integration of side chains) and uncertainty, i.e. the probability of failures. Such a framework will harmonize the global-trade process and build an international standards for smart GC based on blockchain technology (ISSGCBT), which is not yet done.}
}
@article{ZHANG2024100115,
title = {Researching L2 investment in EMI courses: Techno-reflective narrative interviews},
journal = {Research Methods in Applied Linguistics},
volume = {3},
number = {2},
pages = {100115},
year = {2024},
issn = {2772-7661},
doi = {https://doi.org/10.1016/j.rmal.2024.100115},
url = {https://www.sciencedirect.com/science/article/pii/S2772766124000211},
author = {Yue Zhang},
keywords = {Investment, L2 investment, Identity, Translanguaging, Interview},
abstract = {In response to the call for integrating a praxis orientation to understand processes of language development through active engagement with teachers and learners, this article introduces techno-reflective narrative interview (TRNI) as a tool to understand how learners invest in their English as a second language (ESL) language and literacy practices as social practices in English medium instruction (EMI) courses. It is timely in integrating both technical and critical guidance for methodological innovations in the field of applied linguistics. To illustrate how this aim is achieved, this article first justifies the significance and theoretical basis of TRNI by elaborating on the definitions of and underpinning rationale for it, followed by the relationship among second language (L2) learners, investment, and TRNI. It then discusses the methods adopted by the 69 most cited empirical studies from Google Scholar that used the model of L2 investment as the theoretical model and compares these methods with TRNI. Finally, it discusses how TRNI was developed and adopted in two action research projects conducted by the author and two lecturers among local undergraduate students in the Hong Kong context. Through these steps, I demonstrate how TRNIs can be adopted or adapted to provide an interactive space for ESL learners to reconstruct and perform their English speaker and learner identities, share their learning experiences with the agency to introduce their positions, voices, and stories, and therefore, claim legitimacy as English users in EMI courses.}
}
@article{GUVEN2021101169,
title = {Gene expression analysis of MCF7 cell lines of breast cancer treated with herbal extract of Cissampelos pareira revealed association with viral diseases},
journal = {Gene Reports},
volume = {23},
pages = {101169},
year = {2021},
issn = {2452-0144},
doi = {https://doi.org/10.1016/j.genrep.2021.101169},
url = {https://www.sciencedirect.com/science/article/pii/S2452014421001540},
author = {Emine Güven},
keywords = {MCF7 cell lines, Biomarker, IL-1R1, IL-13RA1, Viral and infectious diseases, COVID-19},
abstract = {Background
It is necessary to assess the cellular, molecular, and pathogenetic characteristics of COVID-19 and attention is required to understand highly effective gene targets and mechanisms. In this study, we suggest understandings into the fundamental pathogenesis of COVID-19 through gene expression analyses using the microarray data set GSE156445 publicly reachable at NIH/NCBI Gene Expression Omnibus database. The data set consists of MCF7 which is a human breast cancer cell line with estrogen, progesterone and glucocorticoid receptors. The cell lines treated with different quantities of Cissampelos pareira (Cipa). Cipa is a traditional medicinal plant which would possess an antiviral potency in preventing viral diseases such as severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) infection.
Methods
Utilizing Biobase, GEOquery, gplots packages in R studio, the differentially expressed genes (DEGs) were identified. The gene ontology (GO) of pathway enrichments employed by utilizing DAVID and KEGG enrichment analyses were studied. We further constructed a human protein-protein interaction (PPI) network and performed, based upon that, a subnetwork module analysis for significant signaling pathways.
Results
The study identified 418 differentially expressed genes (DEGs) using bioinformatics tools. The gene ontology of pathway enrichments employed by GO and KEGG enrichment analyses of down-regulated and up-regulated DEGs were studied. Gene expression analysis utilizing gene ontology and KEGG results uncovered biological and signaling pathways such as “cell adhesion molecules”, “plasma membrane adhesion molecules”, “synapse assembly”, and “Interleukin-3-mediated signaling” which are mostly linked to COVID-19. Our results provide in silico evidence for candidate genes which are vital for the inhibition, adhesion, and encoding cytokine protein including LYN, IGFBP5, IL-1R1, and IL-13RA1 that may have strong biomarker potential for infectious diseases such as COVID-19 related therapy targets.}
}
@article{SEHGAL20221614,
title = {Development of Food Allergy Data Dictionary: Toward a Food Allergy Data Commons},
journal = {The Journal of Allergy and Clinical Immunology: In Practice},
volume = {10},
number = {6},
pages = {1614-1621.e1},
year = {2022},
issn = {2213-2198},
doi = {https://doi.org/10.1016/j.jaip.2022.02.024},
url = {https://www.sciencedirect.com/science/article/pii/S2213219822002252},
author = {Shruti Sehgal and Ruchi S. Gupta and Mark Wlodarski and Lucy A. Bilaver and Firas H. Wehbe and Jonathan M. Spergel and Julie Wang and Christina E. Ciaccio and Melanie Makhija and Justin B. Starren},
keywords = {Food allergy, Data dictionary, Data commons},
abstract = {Background
Food allergy (FA) data lacks a common base of terminology and hinders data exchange among institutions.
objective
To examine the current FA concept coverage by clinical terminologies and to develop and evaluate a Food Allergy Data Dictionary (FADD).
Methods
Allergy/immunology templates and patient intake forms from 4 academic medical centers with expertise in FA were systematically reviewed, and in-depth discussions with a panel of FA experts were conducted to identify important FA clinical concepts and data elements. The candidate ontology was iteratively refined through a series of virtual meetings. The concepts were mapped to existing clinical terminologies manually with the ATHENA vocabulary browser. Finally, the revised dictionary document was vetted with experts across 22 academic FA centers and 3 industry partners.
Results
A consensus version 1.0 FADD was finalized in November 2020. The FADD v1.0 contained 936 discrete FA concepts that were grouped into 14 categories. The categories included both FA-specific concepts, such as foods triggering reactions, and general health care categories, such as medications. Although many FA concepts are included in existing clinical terminologies, some critical concepts are missing.
Conclusions
The FADD provides a pragmatic tool that can enable improved structured coding of FA data for both research and clinical uses, as well as lay the foundation for the development of standardized FA structured data entry forms.}
}
@article{YU2025118120,
title = {Cancer framing and psychological characteristics in online cancer diaries: A mixed-methods study in China},
journal = {Social Science & Medicine},
volume = {377},
pages = {118120},
year = {2025},
issn = {0277-9536},
doi = {https://doi.org/10.1016/j.socscimed.2025.118120},
url = {https://www.sciencedirect.com/science/article/pii/S0277953625004502},
author = {Lisai Yu and Yuhang Li and Chenghui Wu},
keywords = {Cancer frame, Cancer treatment, Text analysis, Sentiment, Social media, LIWC},
abstract = {Drawing upon previous research, this paper creatively combines different methods to conduct text analysis of cancer diaries related to cancer treatment on Chinese social media Weibo, and explores the sentiment, adoption of cancer frames, and psychological aspects of language. Initially, sentiment analysis technology is employed to investigate the sentiment in cancer diaries. Subsequently, the cancer frames in the text data are encoded, and similarity analysis is conducted to depict the associations among different frames. Lastly, the psycholinguistic dictionary of Linguistic Inquiry and Word Count (LIWC) and Multiple Correspondence Analysis (MCA) are utilized to explore the multivariate associations among different sentiment orientations, frames, and psychological states. Our study aims to aid in understanding the concerns and communication of patient groups regarding the cancer treatment process, provide actionable insights for healthcare professionals and researchers to better understand patient experiences and improve cancer care communication.}
}
@article{HOSE2022101929,
title = {Trends in Design, Optimization, Languages, and Analytical Processing of Big Data (DOLAP 2020)},
journal = {Information Systems},
volume = {104},
pages = {101929},
year = {2022},
issn = {0306-4379},
doi = {https://doi.org/10.1016/j.is.2021.101929},
url = {https://www.sciencedirect.com/science/article/pii/S0306437921001319},
author = {Katja Hose and Oscar Romero and Il-Yeol Song},
keywords = {Data management, Data analytics, Design, Optimization, Processing, Big data},
abstract = {Data science requires the creation of complex data ecosystems to support data analysis, which we refer to as data-based information systems (DBIS). The diversity of techniques to manage and analyse data has contributed to a wide variety of DBIS. On the one hand, current data management solutions span classical relational databases, distributed (relational and non-relational) systems, document-oriented databases, column stores, in-memory databases, property and knowledge graph databases, stream processors, scientific databases, etc. On the other hand, data analytics techniques range from classical statistical-based data mining, to machine learning, process-oriented data analysis, stream and complex event processing, graph analytics, etc. On top of that, hardware-accelerated solutions, specially related to deep learning and CPU-intensive analytical solutions are complicating the big picture. Nowadays, a prominent research trend is to devise specific data management techniques to accelerate and improve the overall throughput and answer time of DBIS. DOLAP, the International Workshop On Design, Optimization, Languages and Analytical Processing of Big Data, has become a reference discussion forum where to witness the current advances in data management for modern data analytics needs. We summarize the advances presented in DOLAP 2020 and the best papers selected for the DOLAP 2020 Information Systems Special Issue.}
}
@article{AMMAR2020,
title = {Explainable Artificial Intelligence Recommendation System by Leveraging the Semantics of Adverse Childhood Experiences: Proof-of-Concept Prototype Development},
journal = {JMIR Medical Informatics},
volume = {8},
number = {11},
year = {2020},
issn = {2291-9694},
doi = {https://doi.org/10.2196/18752},
url = {https://www.sciencedirect.com/science/article/pii/S2291969420000411},
author = {Nariman Ammar and Arash Shaban-Nejad},
keywords = {mental health surveillance, semantic web, knowledge-based recommendation, digital assistant, explainable artificial intelligence, adverse childhood experiences},
abstract = {Background
The study of adverse childhood experiences and their consequences has emerged over the past 20 years. Although the conclusions from these studies are available, the same is not true of the data. Accordingly, it is a complex problem to build a training set and develop machine-learning models from these studies. Classic machine learning and artificial intelligence techniques cannot provide a full scientific understanding of the inner workings of the underlying models. This raises credibility issues due to the lack of transparency and generalizability. Explainable artificial intelligence is an emerging approach for promoting credibility, accountability, and trust in mission-critical areas such as medicine by combining machine-learning approaches with explanatory techniques that explicitly show what the decision criteria are and why (or how) they have been established. Hence, thinking about how machine learning could benefit from knowledge graphs that combine “common sense” knowledge as well as semantic reasoning and causality models is a potential solution to this problem.
Objective
In this study, we aimed to leverage explainable artificial intelligence, and propose a proof-of-concept prototype for a knowledge-driven evidence-based recommendation system to improve mental health surveillance.
Methods
We used concepts from an ontology that we have developed to build and train a question-answering agent using the Google DialogFlow engine. In addition to the question-answering agent, the initial prototype includes knowledge graph generation and recommendation components that leverage third-party graph technology.
Results
To showcase the framework functionalities, we here present a prototype design and demonstrate the main features through four use case scenarios motivated by an initiative currently implemented at a children’s hospital in Memphis, Tennessee. Ongoing development of the prototype requires implementing an optimization algorithm of the recommendations, incorporating a privacy layer through a personal health library, and conducting a clinical trial to assess both usability and usefulness of the implementation.
Conclusions
This semantic-driven explainable artificial intelligence prototype can enhance health care practitioners’ ability to provide explanations for the decisions they make.}
}
@article{SMITH2019403,
title = {The characteristics of problem structuring methods: A literature review},
journal = {European Journal of Operational Research},
volume = {274},
number = {2},
pages = {403-416},
year = {2019},
issn = {0377-2217},
doi = {https://doi.org/10.1016/j.ejor.2018.05.003},
url = {https://www.sciencedirect.com/science/article/pii/S0377221718303783},
author = {Chris M. Smith and Duncan Shaw},
keywords = {Problem structuring methods, OR methodology, Soft OR, Literature review},
abstract = {Problem structuring methods (PSMs) are a class of qualitative operational research (OR) modelling approaches that were first developed approximately 40 years ago. Different definitions of PSMs have been proposed, some focusing on the types of problems that PSMs typically address, others on how they address these problems. Despite this, there is no clear framework for what characteristics need to be present in an approach to warrant it being regarded as a PSM. This presents a challenge to understanding what constitutes a PSM and the acceptance of new PSMs. This exploratory paper develops a framework from a literature review to identify similarities between PSMs. The framework reflects that PSMs hold different philosophical assumptions to traditional OR and, thus, the framework is structured according to the four pillars of ontological, epistemological, axiological and methodological assumptions an approach makes. Across these assumptions, the framework poses 13 questions to determine if an approach could be a PSM. The effectiveness of the framework is understood by applying it to eight OR approaches to see if it successfully identifies PSMs.}
}
@article{SEYFI2025103,
title = {The ethics of eating: how do lifestyle politics shape tourists’ ethical food consumption behaviours?},
journal = {International Journal of Contemporary Hospitality Management},
volume = {37},
number = {13},
pages = {103-122},
year = {2025},
issn = {0959-6119},
doi = {https://doi.org/10.1108/IJCHM-10-2024-1537},
url = {https://www.sciencedirect.com/science/article/pii/S095961192500004X},
author = {Siamak Seyfi and Alicia Orea-Giner and Colin Michael Hall and Mustafeed Zaman},
keywords = {Food consumerism, Political food consumption, Lifestyle politics, Tourist behaviour, Ethical consumerism},
abstract = {Purpose
Guided by the lifestyle politics theory, this study aims to examine how ethical food commitments are negotiated and reshaped within tourism experiences. It explores how travel settings affect political food consumerism by disrupting familiar routines, introducing new cultural and logistical constraints and leading individuals to adjust their food choices in ways that reflect ongoing ethical engagement.
Design/methodology/approach
Adopting a constructivist ontology and interpretivist epistemology, the study uses a qualitative design based on semi-structured interviews with politically and ethically conscious consumers. The analysis, informed by the grounded theory, identifies key themes related to motivations, emotional dimensions and barriers in travel-related political and ethical food consumption.
Findings
Tourism disrupts the routines that political food consumerism usually relies on. In everyday life, ethical food choices are supported by habit, familiar products and like-minded social settings. But when people travel, they face new cultures and lose control over what food is available. From a lifestyle politics perspective, ethical choices are not fixed – they shift as situations change. In tourism, political food decisions often involve compromise, shaped by practical limits, cultural differences and being more visible. Tourism, therefore, functions as a space for ethical expression and as a context in which political food commitments are tested and redefined.
Practical implications
Understanding how ethical food commitments shift during travel can help providers better support value-driven consumption. This includes improving access to verified ethical food options, clearer sourcing information and recognising the cultural and emotional significance of food choices for ethically motivated travellers. By addressing the challenges faced in unfamiliar settings, industry actors can create more inclusive environments that align with expectations around ethical and sustainable consumption.
Originality/value
A lifestyle politics perspective is applied to political food consumerism in tourism, highlighting food as a highly moralised and contested area of consumption. It offers new insight into how ethical eating practices are shaped through travel and how these practices may contribute to sustainability transitions within tourism and hospitality.}
}
@article{KALMYKOV2025103352,
title = {Towards eXplicitly eXplainable Artificial Intelligence},
journal = {Information Fusion},
volume = {123},
pages = {103352},
year = {2025},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2025.103352},
url = {https://www.sciencedirect.com/science/article/pii/S1566253525004257},
author = {Vyacheslav L. Kalmykov and Lev V. Kalmykov},
keywords = {Industry 5.0, AI transparency, Trustworthiness of AI, Symbolic AI, Agent-based models, Cellular automata},
abstract = {Artificial Intelligence (AI) plays a leading role in Industry 4.0 and future Industry 5.0. Concerns about the opacity of today's neural network AI solutions have led to the Explainable AI (XAI) project, which attempts to open the black box of neural networks. While XAI can help to partially interpret and explain the workings of neural networks, it has not changed their original subsymbolic nature and the opaque statistical nature of their workings. Significant uncertainties remain about the safety, reliability, and accountability of modern neural network AI solutions. Here we present a novel AI method that has a fully transparent white-box nature - eXplicitly eXplainable Artificial Intelligence (XXAI). XXAI is implemented on deterministic cellular automata whose rules are based on first principles of the problem domain. XXAI overcomes the limitations for a broader application of symbolic AI. The practical value of XXAI lies in its ability to make autonomous, fully transparent decisions due to its multi-component, multi-level, networked, hyper-logical nature. Looking ahead, XXAI has the potential to become a leading strategic partner in the field of neuro-symbolic hybrid AI systems. XXAI is able to systematically validate neural network solutions, ensuring that the required standards of reliability, security and ethics are met throughout the AI lifecycle, from training to deployment. By creating a clear cognitive framework, XXAI will enable the development of advanced autonomous solutions to achieve the human-centric values of the future Industry 5.0. A comprehensive program for the further development of the proposed approach is presented.}
}
@article{SUNNETCI2025103068,
title = {Biomedical text-based detection of colon, lung, and thyroid cancer: A deep learning approach with novel dataset},
journal = {Displays},
volume = {89},
pages = {103068},
year = {2025},
issn = {0141-9382},
doi = {https://doi.org/10.1016/j.displa.2025.103068},
url = {https://www.sciencedirect.com/science/article/pii/S0141938225001052},
author = {Kubilay Muhammed Sünnetci},
keywords = {Colon cancer, Lung cancer, Thyroid cancer, LSTM, GRU, BiLSTM},
abstract = {Pre-trained Language Models (PLMs) are widely used nowadays and increasingly popular. These models can be used to solve Natural Language Processing (NLP) challenges, and their focus on specific topics allows the models to provide answers to directly relevant issues. As a sub-branch of this, Biomedical Text Classification (BTC) is a fundamental task that can be used in various applications and is used to aid clinical decisions. Therefore, this study detects colon, lung, and thyroid cancer from biomedical texts. A dataset including 3070 biomedical texts is generated by artificial intelligence and used in the study. In this dataset, there are 1020 texts labeled colon cancer, while the number of samples labeled lung and thyroid cancer is equal to 1020 and 1030, respectively. In the study, 70 % of the data is used in the training set, while the remaining data is split for validation and test sets. After preprocessing all the data used in the study, word encoding is used to prepare the model inputs. Furthermore, these documents in the dataset are converted into sequences of numeric indices. Afterward, Long Short-Term Memory (LSTM), Gated Recurrent Unit (GRU), Bidirectional LSTM (BiLSTM), LSTM+LSTM, GRU+GRU, BiLSTM+BiLSTM, and LSTM+GRU+BiLSTM architectures are trained with train and validation sets, and these models are tested with the test set. Both validation and test performances of all developed models are determined, and a Graphical User Interface (GUI) software is prepared in which the most successful architecture has been embedded. The results show that LSTM is the most successful model, and the accuracy and specificity values achieved by this model in the validation set are equal to 91.32 % and 95.67 %, respectively. The F1 score value achieved by this model for the validation set is also equal to 91.32 %. The accuracy, specificity, and F1 score values achieved by this model in the test set are equal to 85.87 %, 92.94 %, and 85.90 %, respectively. The sensitivity values achieved by this model for the validation and test set are 91.33 % and 85.88 %, respectively. These developed models both provide comparative results and have shown successful performances. Focusing these models on specific issues can provide more effective results for related problems. Furthermore, the presentation of a user-friendly GUI application developed in the study allows users to use the models effectively.}
}
@article{BOUCHAKWA2020508,
title = {An ambiguous tag-based query reformulation technique for an effective semantic-based social image research},
journal = {Procedia Computer Science},
volume = {176},
pages = {508-520},
year = {2020},
note = {Knowledge-Based and Intelligent Information & Engineering Systems: Proceedings of the 24th International Conference KES2020},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2020.08.053},
url = {https://www.sciencedirect.com/science/article/pii/S1877050920318779},
author = {Mariam Bouchakwa and Yassine Ayadi and Ikram Amous},
keywords = {social image research, ambiguous tag-based query, semantic-based query, semantic rules, semantic reformulation, search result diversification},
abstract = {The Tag-based Document Retrieval technique was adopted for long time as an intuitive way to search for images shared on social networks. Nevertheless, the tag-based queries are often too ambiguous, and consequently they do not constitute an efficient solution for retrieving the most relevant images that meet the users’ needs. As an alternative, the Semantic-based Social Image Retrieval technique has emerged. The policy of this technique consists in retrieving the relevant images covering as much possible the topics that a given ambiguous query may have. In this paper, we propose a novel technique at the ambiguous query pre-processing level, which aims at moving from an ambiguous tag-based query towards a semantic-based one, by relying on a set of predefined ontological semantic rules. Thorough experiments using 8 ambiguous queries over a collection of 25.000 socio-tagged images shared on Flickr service prove the effectiveness of our technique.}
}
@article{ALVAREZRODRIGUEZ2023103744,
title = {Towards a method to quantitatively measure toolchain interoperability in the engineering lifecycle: A case study of digital hardware design},
journal = {Computer Standards & Interfaces},
volume = {86},
pages = {103744},
year = {2023},
issn = {0920-5489},
doi = {https://doi.org/10.1016/j.csi.2023.103744},
url = {https://www.sciencedirect.com/science/article/pii/S0920548923000259},
author = {Jose María Alvarez-Rodríguez and Roy Mendieta and Eduardo Cibrián and Juan Llorens},
keywords = {Software tools, Software reusability, Web services, Software as a service, Internet},
abstract = {The engineering lifecycle of cyber-physical systems is becoming more challenging than ever. Multiple engineering disciplines must be orchestrated to produce both a virtual and physical version of the system. Each engineering discipline makes use of their own methods and tools generating different types of work products that must be consistently linked together and reused throughout the lifecycle. Requirements, logical/descriptive and physical/analytical models, 3D designs, test case descriptions, product lines, ontologies, evidence argumentations, and many other work products are continuously being produced and integrated to implement the technical engineering and technical management processes established in standards such as the ISO/IEC/IEEE 15288:2015 “Systems and software engineering-System life cycle processes”. Toolchains are then created as a set of collaborative tools to provide an executable version of the required technical processes. In this engineering environment, there is a need for technical interoperability enabling tools to easily exchange data and invoke operations among them under different protocols, formats, and schemas. However, this automation of tasks and lifecycle processes does not come free of charge. Although enterprise integration patterns, shared and standardized data schemas and business process management tools are being used to implement toolchains, the reality shows that in many cases, the integration of tools within a toolchain is implemented through point-to-point connectors or applying some architectural style such as a communication bus to ease data exchange and to invoke operations. In this context, the ability to measure the current and expected degree of interoperability becomes relevant: 1) to understand the implications of defining a toolchain (need of different protocols, formats, schemas and tool interconnections) and 2) to measure the effort to implement the desired toolchain. To improve the management of the engineering lifecycle, a method is defined: 1) to measure the degree of interoperability within a technical engineering process implemented with a toolchain and 2) to estimate the effort to transition from an existing toolchain to another. A case study in the field of digital hardware design comprising 6 different technical engineering processes and 7 domain engineering tools is conducted to demonstrate and validate the proposed method.}
}
@article{BOYLE2021103515,
title = {Coaching practices: Building teacher capability to enhance continuity in the early years},
journal = {Teaching and Teacher Education},
volume = {108},
pages = {103515},
year = {2021},
issn = {0742-051X},
doi = {https://doi.org/10.1016/j.tate.2021.103515},
url = {https://www.sciencedirect.com/science/article/pii/S0742051X21002407},
author = {Tess Boyle and Anne Petriwskyj and Susan Grieshaber and Lesley Jones},
keywords = {Continuity, Coaching practices, Teacher capability, Transitions to school},
abstract = {Continuity of learning and development for children transitioning from pre-compulsory to compulsory education remains challenging in many educational contexts. There is little evidence about the potential of coaching to build teacher capability as a strategy to enhance continuity for children. This article reports details of how a collective case study and the theory of practice architectures framed an investigation of coaching practices aimed at building teacher capability to address student continuity issues. The research endorses a situated (site ontological) approach to building teacher capability to enhance continuity in the early years. Findings identify how site-based conditions influenced (enabled and constrained) coaching practices and transitional continuity.}
}
@article{HOFMEYR2021104463,
title = {A biochemically-realisable relational model of the self-manufacturing cell},
journal = {Biosystems},
volume = {207},
pages = {104463},
year = {2021},
issn = {0303-2647},
doi = {https://doi.org/10.1016/j.biosystems.2021.104463},
url = {https://www.sciencedirect.com/science/article/pii/S0303264721001167},
author = {Jan-Hendrik S. Hofmeyr},
keywords = {Relational biology, Self-manufacture, Fabrication, Self-assembly, Metabolism-repair systems, Closure to efficient causation, Autopoiesis, Formal cause},
abstract = {As shown by Hofmeyr, the processes in the living cell can be divided into three classes of efficient causes that produce each other, so making the cell closed to efficient causation, the hallmark of an organism. They are the enzyme catalysts of covalent metabolic chemistry, the intracellular milieu that drives the supramolecular processes of chaperone-assisted folding and self-assembly of polypeptides and nucleic acids into functional catalysts and transporters, and the membrane transporters that maintain the intracellular milieu, in particular its electrolyte composition. Each class of efficient cause can be modelled as a relational diagram in the form of a mapping in graph-theoretic form, and a minimal model of a self-manufacturing system that is closed to efficient causation can be constructed from these three mappings using the formalism of relational biology. This fabrication-assembly or (F,A)-system serves as an alternative to Robert Rosen’s replicative metabolism-repair or (M,R)-system, which has been notoriously problematic to realise in terms of real biochemical processes. A key feature of the model is the explicit incorporation of formal cause, which arrests the infinite regress that plagues all relational models of the cell. The (F,A)-system is extended into a detailed relational model of the self-manufacturing cell that has a clear biochemical realisation. This (F,A) cell model allows the interpretation and visualisation of concepts such as the metabolism and repair components of Rosen’s (M,R)-system, John von Neumann’s universal constructor, Howard Pattee’s symbol-function split via the symbol-folding transformation, Marcello Barbieri’s genotype–ribotype–phenotype ontology, and Tibor Gánti’s chemoton.}
}
@article{SABOUR2025202,
title = {An integrated systematic method for interlaced unmanned spatial systems (IUSS) design process},
journal = {Acta Astronautica},
volume = {226},
pages = {202-214},
year = {2025},
issn = {0094-5765},
doi = {https://doi.org/10.1016/j.actaastro.2024.10.009},
url = {https://www.sciencedirect.com/science/article/pii/S0094576524005836},
author = {M.H. Sabour and S. Nematiyan and P. Mazhari},
keywords = {Unmanned Aerial Systems, Spatial Systems Design, Model-Based Systems Engineering, Systems of Systems},
abstract = {Unmanned Aerial Systems (UAS) have garnered significant interest in recent years. These systems, commonly consisting of one or more Unmanned Aerial Vehicles (UAV) and satellite systems, have been extensively used to enhance the effectiveness of various SOSs, such as disaster management and relief efforts. In addition, the inaugural Mars unmanned helicopter, Ingenuity (Ginny), successfully took flight in April 2021, marking the beginning of the utilization of these systems on Mars. This research aims to build an integrated approach for developing Interlaced Unmanned Spatial Systems, considering the high level of precision required for space systems. This study aims to set up and optimize all parts of the proposed architecture for the design of IUSS, using Model-Based Systems Engineering theories and Dependency Structural Matrix foundations. This research introduces a comprehensive coherence architecture that considers all design domains, including the design process, design office, products, and requirements. Additionally, a design workflow model is provided.}
}
@article{HUNT202128,
title = {Interpreting the Wigner–Eckart Theorem},
journal = {Studies in History and Philosophy of Science Part A},
volume = {87},
pages = {28-43},
year = {2021},
issn = {0039-3681},
doi = {https://doi.org/10.1016/j.shpsa.2021.01.007},
url = {https://www.sciencedirect.com/science/article/pii/S0039368121000078},
author = {Josh Hunt},
keywords = {Wigner-Eckart theorem, Symmetry arguments, Understanding, Conceptualism, Unification, Modularization},
abstract = {The Wigner–Eckart theorem is central to the application of symmetry principles throughout atomic, molecular, and nuclear physics. Nevertheless, the theorem has a puzzling feature: it is dispensable for solving problems within these domains, since elementary methods suffice. To account for the significance of the theorem, I first contrast it with an elementary approach to calculating matrix elements. Next, I consider three broad strategies for interpreting the theorem: conventionalism, fundamentalism, and conceptualism. I argue that the conventionalist framework is unnecessarily pragmatic, while the fundamentalist framework requires more ontological commitments than necessary. Conceptualism avoids both defects, accounting for the theorem’s significance in terms of how it epistemically restructures the calculation of matrix elements. Specifically, the Wigner–Eckart theorem modularizes and unifies matrix element problems, thereby changing what we need to know to solve them.}
}
@article{JOBST2025S215,
title = {P18-66 Chemical intervention on the mitochondria affects biomechanical properties of T24 bladder cancer cells},
journal = {Toxicology Letters},
volume = {411},
pages = {S215-S216},
year = {2025},
note = {Abstracts of the 59th Congress of the European Societies of Toxicology (EUROTOX 2025) TOXICOLOGY ADDRESSES SOCIETY'S REAL LIFE RISKS FOR SUSTAINABLE HEALTH AND WELL BEING},
issn = {0378-4274},
doi = {https://doi.org/10.1016/j.toxlet.2025.07.515},
url = {https://www.sciencedirect.com/science/article/pii/S0378427425020983},
author = {M. Jobst and G. {Del Favero}},
abstract = {Bladder cells face a challenging biochemical and biophysical environment; this is defined by chemical stressors from urinary occurring contaminants and low nutrient availability, and by physical stressors stemming from the expansion of the organ and the flow of the urine. [1] Growth and survival under these conditions require chemical and mechanical adaptability. 2, 3 For this, bladder cells can tune their metabolism in response to external stimuli, such as low glucose and hypoxia. [4] Typical endpoints of screening for metabolic impairment include changes in cell viability and proliferation; however these might not depict completely the adaptive capacity of the bladder epithelium. Particularly, how cells tune biomechanical properties and response to mechanical cues upon metabolic challenges remains largely unexplored. In this work, two model substances were selected to study the mechano-chemical homeostasis of T24 bladder cancer cells, namely mitoTEMPOL (MT, 1 µM, mitochondrial antioxidant) and 2-desoxyglucose (2-DG, 2 mM, inhibitor of glycolysis and trigger of oxidative stress at mitochondrial level). After 24h incubation neither MT nor 2DG altered cell viability, however significant changes in the intracellular pan-acetylation profile could be measured. Changes in acetylation support post-translational protein modifications (PTMs) that enables for instance rapid reorganization of the cytoskeletal network. 2, 5 Aligning to the acetylation profile, coherent adaption of the actin signal distribution could be observed. Additionally, cells displayed distinctive morphologies depending on the two treatments, which was also reflected in the cells’ mechanical phenotypes. Migration experiments revealed that MT treated cells were more motile when compared to controls. Cells incubated with 2DG reduced migration speed. In parallel, atomic force microscopy (AFM) measurements enabled the detection of significant increase in cell stiffness (Young's modulus) in the nuclear, perinuclear and cytoplasmic regions of cells incubated with 2DG. In cells exposed to MT the increase in cell stiffness was limited to the cytoplasmic compartment. In sum, the two compounds enabled tailored manipulation of cellular acetylation and cytoskeletal organization, including functional effects on cell motility and stiffness. While more work is needed to fully elucidate the underlying pathways, the results of the model substances (MT and 2DG) support the existence of adverse outcome pathways potentially connecting cell metabolism to cell biomechanics that promise to be of relevance for the elucidation of the molecular mechanism of toxicity of a broad range of xenobiotics.}
}
@article{SHANLEY2024100085,
title = {A place where “You can be who you've always wanted to be…” Examining the ethics of intelligent virtual environments},
journal = {Journal of Responsible Technology},
volume = {18},
pages = {100085},
year = {2024},
issn = {2666-6596},
doi = {https://doi.org/10.1016/j.jrt.2024.100085},
url = {https://www.sciencedirect.com/science/article/pii/S2666659624000118},
author = {Danielle Shanley and Darian Meacham},
keywords = {Intelligent virtual environments, Artificial intelligence, Virtual reality, Ethics, Emerging technology, Responsible innovation},
abstract = {The rapid development of interactive virtual reality (VR) spaces like VRChat has been made possible due to continuing increases in computer processing power, advances in artificial intelligence (AI) technologies such as natural language processing (NLP), and advances in 3D modelling and spatial and edge computing. Perhaps because these spaces rely on new ways of integrating different forms of advanced computing, such as AI and VR, little is yet known about their potential ethical implications. In this contribution, we provide an overview of key themes frequently discussed in the context of these so-called Intelligent Virtual Environments (IVEs). We highlight different ethical questions and the ways in which they are typically taken up in the literature. We first map how common concerns tend to revolve around technological feasibility and psychological impacts. We then ask how shifting the focus towards more philosophical perspectives might reorient discussions surrounding IVEs, opening up important avenues for future research. Our contribution in this review is to highlight how as active mediators of experience these technologies require critical reflection and should not be evaluated solely in terms of their functionality.}
}
@article{HUANG2025110976,
title = {Risk propagation mechanisms in railway systems under extreme weather: A knowledge graph-based unsupervised causation chain approach},
journal = {Reliability Engineering & System Safety},
volume = {260},
pages = {110976},
year = {2025},
issn = {0951-8320},
doi = {https://doi.org/10.1016/j.ress.2025.110976},
url = {https://www.sciencedirect.com/science/article/pii/S0951832025001796},
author = {Yujie Huang and Zhipeng Zhang and Hao Hu},
keywords = {Railway accidents, Extreme weathers, Domino effect, Event logic graph, Data-driven},
abstract = {Frequent and intensive adverse weathers can cause severe rail accidents through domino effect, posing significant challenges to railway safety and operational reliability. A detailed elucidation of the risk propagation mechanism across hazardous events is critical for effective risk management in rail transportation. Risk pathways involve various meteorological factors, infrastructure vulnerabilities, and consequences, in which each exhibits distinct causation strengths, trigger probabilities, severity levels, and high-impact points. To disclose the characteristics of weather-related railway domino effect accidents, this paper develops a novel railway causation analysis methodology based on an event logic graph. This framework enhances existing knowledge graph-based methodologies by emphasizing the evolution and logical progression of sequential hazardous events. Besides, an unsupervised accident causation chain linking technique is proposed, which integrates historical accident data into the knowledge graph to build a comprehensive graph database. It facilitates data-driven analysis of both structured and unstructured accident records without requiring laborious annotations. By thoroughly evaluating topological features and statistical indicators via a real-world dataset of weather-related railway accidents, key risk propagation patterns such as risk path dependence, path convergence, and risk escalation curves are recognized. Critical nodes including risk amplifiers, critical junctures, and marginal risk contributors within six critical domino chains are identified. These findings inform targeted risk mitigation strategies to prevent risk propagation and escalation. The proposed methodology and results offer theoretical support and actionable insights for enhancing safety and reliability management of railway systems under extreme weather conditions.}
}
@article{LEWIS2021113184,
title = {If only they had accessed the data: Governmental failure to monitor pulp mill impacts on human health in Pictou Landing First Nation},
journal = {Social Science & Medicine},
volume = {288},
pages = {113184},
year = {2021},
note = {18th International Medical Geography Symposium},
issn = {0277-9536},
doi = {https://doi.org/10.1016/j.socscimed.2020.113184},
url = {https://www.sciencedirect.com/science/article/pii/S0277953620304032},
author = {Diana Lewis and Sheila Francis and Kim Francis-Strickland and Heather Castleden and Richard Apostle},
keywords = {Canada, Indigenous, First Nation, Environment, Health, Pulp mill, Impacts},
abstract = {For over fifty years, Pictou Landing First Nation (PLFN), a small Mi'kmaw community on the northern shore of mainland Nova Scotia, Canada, has been told by a Joint Environmental Health Monitoring Committee (JEHMC) mandated to oversee the health of the community that their health has not been impacted by exposure to 85 million litres of pulp mill effluent dumped every day into what was once a culturally significant body of water bordering their community. Yet, based on lived experience, the community knows otherwise, and despite countless dollars spent on government and industry-sponsored research, their concerns have not gone away. Using biopolitical theory, we explore why JEHMC never fully implemented its mandate. We will use a Mi'kmaw environmental ‘theoretical’ framework to demonstrate that indicators of a relational epistemology and ontology that have been consistently and persistently overlooked in Indigenous environmental health research demands that Indigenous connections to the air, land and water must be taken into consideration to get a full understanding of environmental health impacts. Guided by the principle of Etuaptmumk (Two-Eyed Seeing), which brings together the strengths of both western and Indigenous knowledge, and employing a community-based participatory research approach, we use data that could have been accessed by the JEHMC that might have signaled that human health studies were warranted. Further, we developed an environmental health survey that more appropriately assesses the impacts on the community. Finally, we will discuss how an Indigenous-developed framework can adequately assess the impacts of land displacement and environmental dispossession on the health of Indigenous communities and illustrate how our framework can serve as a guide to others when exploring Indigenous environmental health more broadly.}
}
@article{CHAKRABORTY2025109305,
title = {Rough sets, modal logic and approximate reasoning},
journal = {International Journal of Approximate Reasoning},
volume = {176},
pages = {109305},
year = {2025},
issn = {0888-613X},
doi = {https://doi.org/10.1016/j.ijar.2024.109305},
url = {https://www.sciencedirect.com/science/article/pii/S0888613X24001920},
author = {Mihir Kr. Chakraborty and Sandip Majumder and Samarjit Kar},
keywords = {Rough sets, Modal logic, Approximate reasoning, Modus ponens},
abstract = {This paper introduces an approximate reasoning method based on rough sets and modal logic. Various Approximate Modus Ponens rules are investigated and defined in Modal Logic systems interpreted in the rough set language. Although this is primarily theoretical work, we expect natural applications of the technique in real-life scenarios. An attempt in this direction is made in a real case analysis to logically model some issues of legal interest.}
}
@article{JANG2021114042,
title = {TechWord: Development of a technology lexical database for structuring textual technology information based on natural language processing},
journal = {Expert Systems with Applications},
volume = {164},
pages = {114042},
year = {2021},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2020.114042},
url = {https://www.sciencedirect.com/science/article/pii/S0957417420308101},
author = {Hyejin Jang and Yujin Jeong and Byungun Yoon},
keywords = {Patent mining, Natural language processing, Text mining, Lexical analysis, WordNet},
abstract = {The role of text mining based on technological documents such as patents is important in the research field of technology intelligence for technology R&D planning. In addition, WordNet, an English-based lexical database, is widely used for pre-processing text data such as word lemmatization and synonym search. However, technological vocabulary information is complex and specific, and WordNet’s ability to analyze technological information is limited in its reflecting technological features. Thus, to improve the text mining performance of technological information, this study proposes a methodology for designing a TechWord-based lexical database that is based on the lexical characteristics of technological words that are differentiated from general words. To do this, we define TechWord, a technology lexical information, and construct a TechSynset, a synonym set between TechWords. First, through dependency parsing between words, TechWord, a unit word that describes a technology, is structured and identifies nouns and verbs. The importance of connectivity is investigated by a network centrality index analysis based on the dependency relations of words. Subsequently, to search for synonyms suitable for the target technology domain, a TechSynset is constructed through synset information, with an additional analysis that calculates cosine similarity based on a word embedding vector. Applying the proposed methodology to the actual technology-related information analysis, we collect patent data on the technological fields of the automotive field, and present the results of the TechWord and TechSynset. This study improves technological information-based text mining by structuring the word-to-word link information in technological documents based on an automated process.}
}
@incollection{CAVILL2022399,
title = {Chapter 11 - Pathway analysis},
editor = {Jacopo Troisi},
booktitle = {Metabolomics Perspectives},
publisher = {Academic Press},
pages = {399-412},
year = {2022},
isbn = {978-0-323-85062-9},
doi = {https://doi.org/10.1016/B978-0-323-85062-9.00011-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780323850629000118},
author = {Rachel Cavill and Jildau Bouwman},
keywords = {Metabolic pathways, metabolomic data, ontology, metabolite, LipidMaps},
abstract = {Metabolic pathways are the foundation for understanding metabolomic data in its biochemical context. By mapping metabolomic results to these pathways and identifying those which are altered in the experiment, we can easily add biological interpretability to our experimental results. However, to perform these analyses in a robust, reproducible way, we first need to describe the measured metabolites in a standardized manner; hence, we begin this chapter by examining ontologies. We then proceed to shortly review the pathway databases available for metabolomic data. We explain the range of methods applied for these analyzes, examining their key differences and focusing on the potential sources of bias in the results from each and we conclude with a section about the tools available for metabolomic pathway analysis.}
}
@article{BARUA2021102577,
title = {Mental health ecologies and urban wellbeing},
journal = {Health & Place},
volume = {69},
pages = {102577},
year = {2021},
issn = {1353-8292},
doi = {https://doi.org/10.1016/j.healthplace.2021.102577},
url = {https://www.sciencedirect.com/science/article/pii/S1353829221000733},
author = {Maan Barua and Sushrut Jadhav and Gunjesh Kumar and Urvi Gupta and Priyanka Justa and Anindya Sinha},
keywords = {Urban, Mental health, Psychiatry, Clinical anthropology, Multispecies ethnography, Animal},
abstract = {How might urban mental health be understood when animals reconfigure human wellbeing in the lived city? Drawing upon ethnographic fieldwork on people and macaques in New Delhi and forging novel conversations between urban studies, ecology and psychiatry, our ontology of urban mental health moves from lived experience of the built environment to those configured by dwelling with various interlocutors: animals, astral bodies and supernatural currents. These relations create microspaces of wellbeing, keeping forces of urban precarity at bay. This paper discusses mental health ecologies in different registers: subjectivity being environmental, its scale being relational rather than binary, enmeshed in the dynamics of other-than-human life, and involving conversations between medical and vernacular practices rather than hierarchies of knowledge.}
}
@article{ATCHISON2022102774,
title = {Abject life and disaster: Opportunity and invasive species governance following the 2019–2020 Australian bushfires},
journal = {Political Geography},
volume = {99},
pages = {102774},
year = {2022},
issn = {0962-6298},
doi = {https://doi.org/10.1016/j.polgeo.2022.102774},
url = {https://www.sciencedirect.com/science/article/pii/S0962629822001883},
author = {Jennifer Atchison and Mary Pilkinton},
keywords = {Invasive species governance, Country, Bushfire, Disaster, Decolonising, Moral geographies},
abstract = {The 2019–2020 Australian bushfire disaster witnessed extraordinary wildlife death. A key component of the response was killing invasive life that might opportunistically colonise freshly burnt landscapes or prey on what survived. This paper considers the notion of disaster as opportunity in order to examine the ontological politics of governing invasive life. Our focus is twofold: the re-articulation of power over invasive life during disaster reproducing its abjection, and the colonial context in which invasive species management and disaster responses occur. We first consider how invasive life is rendered abject in governance through the application of the ‘invasion curve’ which preconditions opposition to invasive life, and through a moral politics of neglect, maintains it as unworthy of care. Presenting new empirical analysis of media discourse and responses to invasive life during and after the Australian 2019-2020 bushfires, we then consider the moral geographies of opportunity, including the moral status of different species, and Indigenous responses to the disaster. Responses to invasive species during the fires tended to reproduce existing approaches but responses from Indigenous people suggest that the opportunity of this disaster might be otherwise imagined. In this case, questioning the terms of engagement with invasive life provides possibilities for decolonising invasive species governance, ushering in new obligations and responsibilities.}
}
@article{HECKLER2022107095,
title = {Machine learning for suicidal ideation identification: A systematic literature review},
journal = {Computers in Human Behavior},
volume = {128},
pages = {107095},
year = {2022},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2021.107095},
url = {https://www.sciencedirect.com/science/article/pii/S0747563221004180},
author = {Wesllei Felipe Heckler and Juliano Varella {de Carvalho} and Jorge Luis Victória Barbosa},
keywords = {Machine learning, Suicidal ideation identification, Suicide prevention, Mental health, Systematic literature review},
abstract = {Suicide causes approximately one death every 40 s. Suicidal ideation is the first stage in the risk scale, being a potential gate for suicide prevention. Machine learning emerged as a promising tool for helping in preventing suicide through the identification of individuals at risk. Therefore, this paper presents a systematic literature review aiming to answer how machine learning can help in suicidal ideation identification. This study addresses the state-of-the-art for this research field by filtering 4,002 articles from eleven databases published up to February 2021. We analyzed the 54 filtered articles to explore twelve research questions, addressing techniques, data, devices, explainability, and additional resources. We propose a taxonomy of machine learning techniques explored in this area and a taxonomy for highlighting the current research challenges. This review found a growing interest in suicidal ideation in the last few years. In a general way, studies explored data from social media and performed a text analysis to investigate suicidal tendencies in the individuals' language. Moreover, deep learning models seem to be a tendency in this area nowadays. Future studies in suicidal ideation should investigate generic and proactive models that do not depend on users' self-report.}
}
@article{WANG2024103785,
title = {DCTM: Dual Contrastive Topic Model for identifiable topic extraction},
journal = {Information Processing & Management},
volume = {61},
number = {5},
pages = {103785},
year = {2024},
issn = {0306-4573},
doi = {https://doi.org/10.1016/j.ipm.2024.103785},
url = {https://www.sciencedirect.com/science/article/pii/S0306457324001456},
author = {Rui Wang and Peng Ren and Xing Liu and Shuyu Chang and Haiping Huang},
keywords = {Contrastive learning, Neural-based topic model, Topic modeling},
abstract = {The recent advanced Contrastive Neural Topic Model (CNTM) was proposed to tackle topic collapse through document-level contrastive learning. However, limited by its usage of the Logistic-Normal prior in topic space and document level contrastive learning, it is less capable of disentangling semantically similar topics. To address the limitation, we propose a novel Dual Contrastive Topic Model (DCTM) that utilizes the Dirichlet prior to capture interpretable patterns. Besides, it incorporates dual (document-level and topic-level) contrastive learning on the topic distribution matrix which helps generate discriminative topic representations and mine identifiable topics. Our proposed DCTM outperforms the state-of-the-art neural topic models in terms of topic coherence and diversity, which is verified by extensive experimentation on three publicly available text corpora. In detail, the proposed DCTM surpasses baselines on almost all the used topic coherence metrics (CP, CA, NPMI for 20Newsgroups, CP, CA, NPMI and UCI for Grolier and DBPedia), and it also obtains higher topic diversity with 1 datasets respectively. Moreover, when performing text clustering, DCTM also achieves significant improvements, with observed increases of more than 1% (20Newsgroups) and 6% (DBPedia) in accuracy.}
}
@article{ALMUZAINI2023101695,
title = {TaSbeeb: A judicial decision support system based on deep learning framework},
journal = {Journal of King Saud University - Computer and Information Sciences},
volume = {35},
number = {8},
pages = {101695},
year = {2023},
issn = {1319-1578},
doi = {https://doi.org/10.1016/j.jksuci.2023.101695},
url = {https://www.sciencedirect.com/science/article/pii/S1319157823002495},
author = {Huda A. Almuzaini and Aqil M. Azmi},
keywords = {Arabic NLP, Deep learning, Legal AI, Judicial decision support system},
abstract = {Since the early 1980s, the legal domain has shown a growing interest in Artificial Intelligence approaches to tackle the increasing number of cases worldwide. TaSbeeb is a deep learning (DL)-based judicial decision support system (JDSS) designed for legal professionals in Saudi courts by retrieving judicial reasoning, Qur’anic verses, and hadiths from a knowledge base. The proposed system consists of three phases: annotation, classification, and information retrieval. To annotate judicial text, we developed Ann-Judicial, a semi-automatic method. To handle the imbalanced corpus for classification, we devised homogeneous and heterogeneous stacking DL models. For information retrieval, we proposed Jud_RoBERTa, a judicial language model. TaSbeeb achieved high accuracy and F-scores in both the classification and information retrieval blocks, showing good accuracy despite complexities in the judicial field and interference between cases. Specifically, the classification phase achieved an accuracy and F-score of 95.8%, while the information retrieval phase achieved an accuracy of 79.8% and F-score of 79.3%. The proposed JDSS has potential for extension to other courts and can be used in judicial inspection. TaSbeeb represents a significant stride towards a more efficient and accurate judicial decision-making process in the Arabic legal system, which has been hindered by a lack of research on Arabic JDSS.}
}
@article{2025301886,
title = {Editorial},
journal = {Forensic Science International: Digital Investigation},
volume = {52},
pages = {301886},
year = {2025},
issn = {2666-2817},
doi = {https://doi.org/10.1016/j.fsidi.2025.301886},
url = {https://www.sciencedirect.com/science/article/pii/S2666281725000253}
}
@article{LEE2021136,
title = {Identifying Goals of Care Conversations in the Electronic Health Record Using Natural Language Processing and Machine Learning},
journal = {Journal of Pain and Symptom Management},
volume = {61},
number = {1},
pages = {136-142.e2},
year = {2021},
issn = {0885-3924},
doi = {https://doi.org/10.1016/j.jpainsymman.2020.08.024},
url = {https://www.sciencedirect.com/science/article/pii/S0885392420307107},
author = {Robert Y. Lee and Lyndia C. Brumback and William B. Lober and James Sibley and Elizabeth L. Nielsen and Patsy D. Treece and Erin K. Kross and Elizabeth T. Loggers and James A. Fausto and Charlotta Lindvall and Ruth A. Engelberg and J. Randall Curtis},
keywords = {Natural language processing, machine learning, goals of care, electronic health record, quality improvement, medical informatics},
abstract = {Context
Goals-of-care discussions are an important quality metric in palliative care. However, goals-of-care discussions are often documented as free text in diverse locations. It is difficult to identify these discussions in the electronic health record (EHR) efficiently.
Objectives
To develop, train, and test an automated approach to identifying goals-of-care discussions in the EHR, using natural language processing (NLP) and machine learning (ML).
Methods
From the electronic health records of an academic health system, we collected a purposive sample of 3183 EHR notes (1435 inpatient notes and 1748 outpatient notes) from 1426 patients with serious illness over 2008–2016, and manually reviewed each note for documentation of goals-of-care discussions. Separately, we developed a program to identify notes containing documentation of goals-of-care discussions using NLP and supervised ML. We estimated the performance characteristics of the NLP/ML program across 100 pairs of randomly partitioned training and test sets. We repeated these methods for inpatient-only and outpatient-only subsets.
Results
Of 3183 notes, 689 contained documentation of goals-of-care discussions. The mean sensitivity of the NLP/ML program was 82.3% (SD 3.2%), and the mean specificity was 97.4% (SD 0.7%). NLP/ML results had a median positive likelihood ratio of 32.2 (IQR 27.5–39.2) and a median negative likelihood ratio of 0.18 (IQR 0.16–0.20). Performance was better in inpatient-only samples than outpatient-only samples.
Conclusion
Using NLP and ML techniques, we developed a novel approach to identifying goals-of-care discussions in the EHR. NLP and ML represent a potential approach toward measuring goals-of-care discussions as a research outcome and quality metric.}
}
@article{YUSKEVICH2021121103,
title = {A metamodel of an informational structure for model-based technology roadmapping},
journal = {Technological Forecasting and Social Change},
volume = {173},
pages = {121103},
year = {2021},
issn = {0040-1625},
doi = {https://doi.org/10.1016/j.techfore.2021.121103},
url = {https://www.sciencedirect.com/science/article/pii/S0040162521005369},
author = {Ilya Yuskevich and Andreas Makoto Hein and Kahina Amokrane-Ferka and Abdelkrim Doufene and Marija Jankovic},
keywords = {Technology roadmapping, Model-driven Engineering, Metamodeling},
abstract = {Recent contributions in the field of technology roadmapping often aim to apply various numerical models and tools to facilitate the roadmapping process and enrich its outcomes. This trend resulted in the emergence of so-called model-based technology roadmapping. We consider it as the future development of the traditional document-based paradigm. One of the general approaches to support the model-based roadmapping is to develop a roadmap's metamodel that would define it independently from the application context and link it to the existing roadmapping literature. In this paper, we attempt to create such a metamodel by generalizing and formalizing existing document-based roadmaps. We validate our metamodel via reproducing three very different roadmaps from the literature, not included in the set of roadmaps from which the metamodel was created, using the novel formal approach. The fact that these roadmaps were reproduced using the proposed metamodel indicates its applicability to many classes of real roadmaps. The results of this work seem beneficial for architects of the software tools for roadmapping and for the regular participants of roadmapping sessions.}
}
@article{YANG2023115196,
title = {AMPFinder: A computational model to identify antimicrobial peptides and their functions based on sequence-derived information},
journal = {Analytical Biochemistry},
volume = {673},
pages = {115196},
year = {2023},
issn = {0003-2697},
doi = {https://doi.org/10.1016/j.ab.2023.115196},
url = {https://www.sciencedirect.com/science/article/pii/S0003269723001616},
author = {Sen Yang and Zexi Yang and Xinye Ni},
keywords = {Antimicrobial peptide identification, Function prediction, Pre-train language model, Deep learning},
abstract = {Antimicrobial peptides (AMPs) called host defense peptides have existed among all classes of life with 5–100 amino acids generally and can kill mycobacteria, envelop viruses, bacteria, fungi, cancerous cells and so on. Owing to the non-drug resistance of AMP, it has been a wonderful agent to find novel therapies. Therefore, it is urgent to identify AMPs and predict their function in a high-throughput way. In this paper, we propose a cascaded computational model to identify AMPs and their functional type based on sequence-derived and life language embedding, called AMPFinder. Compared with other state-of-the-art methods, AMPFinder obtains higher performance both on AMP identification and AMP function prediction. AMPFinder shows better performance with improvement of F1-score (1.45%–6.13%), MCC (2.92%–12.86%) and AUC (5.13%–8.56%) and AP (9.20%–21.07%) on an independent test dataset. And AMPFinder achieve lower bias of R2 on a public dataset by 10-fold cross-validation with an improvement of (18.82%–19.46%). The comparison with other state-of-the-art methods shows that AMP can accurately identify AMP and its function types. The datasets, source code and user-friendly application are available at https://github.com/abcair/AMPFinder.}
}
@article{PHANUSUPAWIMOL2025101099,
title = {Innovation through intelligent computer-aided formulation design},
journal = {Current Opinion in Chemical Engineering},
volume = {47},
pages = {101099},
year = {2025},
issn = {2211-3398},
doi = {https://doi.org/10.1016/j.coche.2025.101099},
url = {https://www.sciencedirect.com/science/article/pii/S2211339825000103},
author = {Thunyaras Phanusupawimol and Kris Prasopsanti and Naz P Taskiran and Venkat Venkatasubramanian and Rafiqul Gani},
abstract = {This perspective paper presents a focused review of a selected topic of chemical-based products, namely, formulations. As formulations cover a wide range of chemical-based products, we highlight opportunities for innovation in three types of formulations — liquid blends, which are mixtures of chemicals that are in the liquid state at standard conditions; liquid formulations, which are mixtures of chemicals that may exist in different states but the final product is a single-phase liquid; and emulsions, which are also mixtures of chemicals that may exist in different states, but the final product is in the form of an emulsion. In each case, we discuss aspects of design, analysis, and innovation together with issues and challenges that could be tackled to find better and more sustainable products. In particular, the potential of hybrid artificial intelligence augmented computer-aided techniques that can aid in the design, analysis, and innovation of formulations is highlighted.}
}
@article{LOPES2024105087,
title = {Proteomic analysis of the mucus of the photosynthetic sea slug Elysia crispata},
journal = {Journal of Proteomics},
volume = {294},
pages = {105087},
year = {2024},
issn = {1874-3919},
doi = {https://doi.org/10.1016/j.jprot.2024.105087},
url = {https://www.sciencedirect.com/science/article/pii/S1874391924000198},
author = {Diana Lopes and Susana S. Aveiro and Sónia Cruz and Paulo Cartaxana and Pedro Domingues},
keywords = {, Kleptoplasty, Mucus, Proteomics, HPLC-MS/MS, Blue biotechnology},
abstract = {Elysia crispata is a tropical sea slug that can retain intracellular functional chloroplasts from its algae prey, a mechanism termed kleptoplasty. This sea slug, like other gastropods, secretes mucus, a viscous secretion with multiple functions, including lubrication, protection, and locomotion. This study presents the first comprehensive analysis of the mucus proteome of the sea slug E. crispata using gel electrophoresis and HPLC-MS/MS. We identified 306 proteins in the mucus secretions of this animal, despite the limited entries for E. crispata in the Uniprot database. The functional annotation of the mucus proteome using Gene Ontology identified proteins involved in different functions such as hydrolase activity (molecular function), carbohydrate-derived metabolic processes (biological processes) and cytoskeletal organization (cell component). Moreover, a high proportion of proteins with enzymatic activity in the mucus of E. crispata suggests potential biotechnological applications including antimicrobial and antitumor activities. Putative antimicrobial properties are reinforced by the high abundance of hydrolases. This study also identified proteins common in mucus samples from various species, supporting a common mechanism of mucus in protecting cells and tissues while facilitating animal movement.
Significance
Marine species are increasingly drawing the interest of researchers for their role in discovering new bioactive compounds. The study “Proteomic Analysis of the Mucus of the Photosynthetic Sea Slug Elysia crispata” is a pioneering effort that uncovers the complex protein content in this fascinating sea slug's mucus. This detailed proteomic study has revealed proteins with potential use in biotechnology, particularly for antimicrobial and antitumor purposes. This research is a first step in exploring the possibilities within the mucus of Elysia crispata, suggesting the potential for new drug discoveries. These findings could be crucial in developing treatments for severe diseases, especially those caused by multidrug-resistant bacteria, and may lead to significant advances in medical research.}
}
@article{BAGSTAD2025101705,
title = {Interoperability for ecosystem service assessments: Why, how, who, and for whom?},
journal = {Ecosystem Services},
volume = {72},
pages = {101705},
year = {2025},
issn = {2212-0416},
doi = {https://doi.org/10.1016/j.ecoser.2025.101705},
url = {https://www.sciencedirect.com/science/article/pii/S2212041625000099},
author = {Kenneth J. Bagstad and Stefano Balbi and Greta Adamo and Ioannis N. Athanasiadis and Flavio Affinito and Simon Willcock and Ainhoa Magrach and Kiichiro Hayashi and Zuzana V. Harmáčková and Aidin Niamir and Bruno Smets and Marcel Buchhorn and Evangelia G. Drakou and Alessandra Alfieri and Bram Edens and Luis Gonzalez Morales and Ágnes Vári and María-José Sanz and Ferdinando Villa},
keywords = {Artificial Intelligence, Ecosystem service monitoring, FAIR, Interoperability, Knowledge reuse, Semantics},
abstract = {Despite continued, rapid growth in the literature, the fragmentation of information is a major barrier to more timely and credible ecosystem services (ES) assessments. A major reason for this fragmentation is the currently limited state of interoperability of ES data, models, and software. The FAIR Principles, a recent reformulation of long-standing open science goals, highlight the importance of making scientific knowledge Findable, Accessible, Interoperable, and Reusable. Critically, FAIR aims to make science more transparent and transferable by both people and computers. However, it is easier to make data and models findable and accessible through data and code repositories than to achieve interoperability and reusability. Achieving interoperability will require more consistent adherence to current technical best practices and, more critically, to build consensus about and consistently use semantics that can represent ES-relevant phenomena. Building on recent examples from major international initiatives for ES (IPBES, SEEA, GEO BON), we illustrate strategies to address interoperability, discuss their importance, and describe potential gains for individual researchers and practitioners and the field of ES. Although interoperability comes with many challenges, including greater scientific coordination than today’s status quo, it is technically achievable and offers potentially transformative advantages to ES assessments needed to mainstream their use by decision makers. Individuals and organizations active in ES research and practice can play critical roles in creating widespread interoperability and reusability of ES science. A representative community of practice targeting interoperability for ES would help advance these goals.}
}
@article{ERLACH20241295,
title = {Evaluating predictive patterns of antigen-specific B cells by single-cell transcriptome and antibody repertoire sequencing},
journal = {Cell Systems},
volume = {15},
number = {12},
pages = {1295-1303.e5},
year = {2024},
issn = {2405-4712},
doi = {https://doi.org/10.1016/j.cels.2024.11.005},
url = {https://www.sciencedirect.com/science/article/pii/S2405471224003387},
author = {Lena Erlach and Raphael Kuhn and Andreas Agrafiotis and Danielle Shlesinger and Alexander Yermanos and Sai.T. Reddy},
keywords = {B cell immune response, antibody repertoire sequencing, single-cell transcriptome sequencing, machine learning for antibody discovery, single-cell sequencing dataset, antigen-specificity prediction, antigen-specific B cells},
abstract = {Summary
The field of antibody discovery typically involves extensive experimental screening of B cells from immunized animals. Machine learning (ML)-guided prediction of antigen-specific B cells could accelerate this process but requires sufficient training data with antigen-specificity labeling. Here, we introduce a dataset of single-cell transcriptome and antibody repertoire sequencing of B cells from immunized mice, which are labeled as antigen specific or non-specific through experimental selections. We identify gene expression patterns associated with antigen specificity by differential gene expression analysis and assess their antibody sequence diversity. Subsequently, we benchmark various ML models, both linear and non-linear, trained on different combinations of gene expression and antibody repertoire features. Additionally, we assess transfer learning using features from general and antibody-specific protein language models (PLMs). Our findings show that gene expression-based models outperform sequence-based models for antigen-specificity predictions, highlighting a promising avenue for computationally guided antibody discovery.}
}
@article{WANG202536,
title = {Molecular mechanism of selenite reduction by Bacillus amyloliquefaciens BB61 based on transcriptome analysis},
journal = {Biochimie},
volume = {233},
pages = {36-46},
year = {2025},
issn = {0300-9084},
doi = {https://doi.org/10.1016/j.biochi.2025.02.005},
url = {https://www.sciencedirect.com/science/article/pii/S0300908425000409},
author = {Yujie Wang and Fan Wan and Huiqin Xue and Yiqiong Hang and Caixia Pei and Yang Lu},
keywords = {Transcriptomics, , SeNPs, Selenite reduction},
abstract = {The microbial conversion of selenite represents an effective detoxification and assimilation process, although the underlying mechanisms remain incompletely understood. In this study, strain BB61 was a probiotic isolated from piglet feces and identified as Bacillus amyloliquefaciens, which could almost completely reduce 0.1 g/L Na2SeO3 to SeNPs within 48h. We investigated the potential mechanisms of selenite reduction in this strain through transcriptome sequencing and qPCR. The transcriptome analysis revealed the up-regulation of 829 genes and the down-regulation of 892 genes in response to 1 g/L Se treatment (padj <0.05) in Bacillus amyloliquefaciens BB61. GO (Gene Ontology) enrichment analysis indicated that DEGs (Differentially expressed genes) were predominantly associated with transmembrane transporters, ion transmembrane transport, cytoplasmic and cell membrane composition, cell movement and localization, and carbon metabolism. Additionally, the KEGG (Encyclopedia of Genes and Genomes) pathway annotation analysis revealed that the DEGs were primarily involved in the pentose phosphate pathway, pyruvate metabolism, pyrimidine metabolism, cofactor biosynthesis, and other pathways (P < 0.05). Among the highly expressed reductases, thioredoxin reductase (TrxA/B), nitrite reductase (NfsA), and selenite reductase (NamA) were all found to be up-regulated. Consequently, this study established a reduction pathway model for Se (IV), offering new insights into the molecular mechanisms underlying the bioreduction of selenite to form SeNPs.}
}
@article{BHUIYAN2025,
title = {Harnessing Artificial Intelligence and Precision Diets for Brain Health and Cognitive Resilience},
journal = {The Journal of Nutrition},
year = {2025},
issn = {0022-3166},
doi = {https://doi.org/10.1016/j.tjnut.2025.08.007},
url = {https://www.sciencedirect.com/science/article/pii/S0022316625004857},
author = {Mohammad Nazrul Islam Bhuiyan and Barun Kanti Saha and Mohammed A Satter},
keywords = {smart neuronutrition, precision diets, cognitive resilience, artificial intelligence in nutrition, gut–brain axis},
abstract = {Smart neuronutrition represents an emerging interdisciplinary field at the intersection of nutritional science, neuroscience, and artificial intelligence (AI), to enhance cognitive resilience, mental well-being, and healthy brain aging through precision dietary strategies. This review critically examined the current body of evidence on the impact of dietary patterns and nutrients on neurobiological processes involved in cognitive decline, such as oxidative stress, mitochondrial dysfunction, neuroinflammation, neurotransmitter imbalance, and gut–brain axis dysregulation. Neuroprotective dietary approaches, including the Mediterranean, Mediterranean dietary approaches to stop hypertension (DASH) diet intervention for neurodegenerative delay, DASH, and ketogenic diets, are highlighted for their anti-inflammatory effects, alongside specific nutrients— ω−3 fatty acids, B-complex vitamins, polyphenols, and microbiota-directed fibers—that have demonstrated benefits for memory, executive function, and emotional stability. Recent advancements in AI are driving the development of personalized nutrition tools that integrate multimodal data sources, including wearable biosensors, image-based dietary tracking, and machine learning models predicting cognitive trajectories. These technologies enable real-time nutrient monitoring, individualized dietary planning, and early identification of neurodegenerative risks. However, challenges remain in the validation, scalability, and generalizability of AI models, especially across diverse populations. Ethical concerns such as data privacy, algorithmic bias, and transparency further emphasize the need for careful regulation and interdisciplinary collaboration. This review offers a comprehensive synthesis of smart neuronutrition, aligning biological mechanisms with digital innovations, and proposes future research priorities. These include the development of explainable AI systems, integration of microbiome and omics data, and implementation of standardized frameworks for clinical applications. By bridging neuroscience, nutrition, and AI, smart neuronutrition has the potential to revolutionize cognitive healthcare, offering scalable, precise, and equitable strategies to combat the rising global burden of neurodegenerative disorders.}
}
@article{ALHASSAN2025104783,
title = {Discontinuous named entities in clinical text: A systematic literature review},
journal = {Journal of Biomedical Informatics},
volume = {162},
pages = {104783},
year = {2025},
issn = {1532-0464},
doi = {https://doi.org/10.1016/j.jbi.2025.104783},
url = {https://www.sciencedirect.com/science/article/pii/S1532046425000127},
author = {Areej Alhassan and Viktor Schlegel and Monira Aloud and Riza Batista-Navarro and Goran Nenadic},
keywords = {Discontinuous named entity recognition, Disjoint mentions, Unified NER, Biomedical text, Clinical text},
abstract = {Objective
Extracting named entities from clinical free-text presents unique challenges, particularly when dealing with discontinuous entities—mentions that are separated by unrelated words. Traditional NER methods often struggle to accurately identify these entities, prompting the development of specialised computational solutions. This paper systematically reviews and presents the methodologies developed for Discontinuous Named Entity Recognition in clinical texts, highlighting their effectiveness and the challenges they face.
Method
We conducted a systematic literature review focused on discontinuous named entities, using structured searches across four Computer Science-related and one medical-related electronic database. A combination of search terms, grouped into three synonym categories—problem, entity/approach, and task—yielded 2,442 articles. Guided by our research objectives, we identified five key dimensions to systematically annotate and normalise the data for comprehensive analysis.
Result
The review included 44 studies which were coded across several key dimensions: the chronological development of approaches, the corpora used, the downstream tasks affected by discontinuous named entities, the methodological approaches proposed to address the issue, and the reported performance outcomes. The discussion section examines the challenges encountered in this area and suggests potential directions for future research.
Conclusion
Significant progress has been made in discontinuous named entity recognition; however, there remains a need for more adaptable, generalisable solutions that are independent of custom annotation schemes. Exploring various configurations of generative language models presents a promising avenue for advancing this area. Additionally, future research should investigate the impact of precise versus imprecise recognition of discontinuous entities on clinical downstream tasks to better understand its practical implications in healthcare applications.}
}
@article{KUHN202428,
title = {A landscape of consciousness: Toward a taxonomy of explanations and implications},
journal = {Progress in Biophysics and Molecular Biology},
volume = {190},
pages = {28-169},
year = {2024},
issn = {0079-6107},
doi = {https://doi.org/10.1016/j.pbiomolbio.2023.12.003},
url = {https://www.sciencedirect.com/science/article/pii/S0079610723001128},
author = {Robert Lawrence Kuhn},
keywords = {Consciousness, Mind-body problem, Materialism, Monism, Dualism, Idealism},
abstract = {Diverse explanations or theories of consciousness are arrayed on a roughly physicalist-to-nonphysicalist landscape of essences and mechanisms. Categories: Materialism Theories (philosophical, neurobiological, electromagnetic field, computational and informational, homeostatic and affective, embodied and enactive, relational, representational, language, phylogenetic evolution); Non-Reductive Physicalism; Quantum Theories; Integrated Information Theory; Panpsychisms; Monisms; Dualisms; Idealisms; Anomalous and Altered States Theories; Challenge Theories. There are many subcategories, especially for Materialism Theories. Each explanation is self-described by its adherents, critique is minimal and only for clarification, and there is no attempt to adjudicate among theories. The implications of consciousness explanations or theories are assessed with respect to four questions: meaning/purpose/value (if any); AI consciousness; virtual immortality; and survival beyond death. A Landscape of Consciousness, I suggest, offers perspective.}
}
@article{ZHAO2025102628,
title = {AI-driven multi-modal framework for prognostic modeling in glioblastoma: Enhancing clinical decision support},
journal = {Computerized Medical Imaging and Graphics},
volume = {124},
pages = {102628},
year = {2025},
issn = {0895-6111},
doi = {https://doi.org/10.1016/j.compmedimag.2025.102628},
url = {https://www.sciencedirect.com/science/article/pii/S0895611125001375},
author = {Zihan Zhao and Nguyen Quoc Khanh Le and Matthew Chin Heng Chua},
keywords = {Clinical decision support system, Multi-omics integration, Glioblastoma, Survival prediction, Vision transformer, Explainable AI, Attention-based deep learning},
abstract = {Objective
Glioblastoma (GBM) is the most aggressive malignant brain tumor, associated with poor prognosis and limited therapeutic options. Accurate prognostic modeling is essential for guiding personalized treatment strategies. However, existing models often rely on single-modality data, limiting their ability to capture the complex molecular and histopathological heterogeneity of GBM. This study proposes an AI-driven, multi-modal framework for clinical decision support, encompassing both early triage and prognostic evaluation stages. A Vision Transformer (ViT) is first employed to classify tumor grades (WHO grades 2–4) using radiological images. Subsequently, an attention-based deep learning model integrates histopathological and transcriptomic data to improve risk stratification and inform treatment planning.
Methods
The ViT model was trained on FLAIR MRI scans from the UCSF-PDGM dataset to perform tumor grading during the early triage phase. For prognostic modeling, whole-slide histopathological images and RNA sequencing profiles were integrated using an attention-based deep learning architecture. Model performance was evaluated using the area under the curve (AUC), concordance index (C-index), and Kaplan–Meier survival analysis across independent CPTAC-GBM and TCGA-GBM cohorts.
Results
The ViT model achieved F1-scores exceeding 0.89 across all WHO tumor grades. The multi-modal model significantly outperformed single-modality baselines, demonstrating higher C-index values and superior prognostic accuracy. Kaplan–Meier analysis revealed statistically significant differences (p < 0.0001) between high- and low-risk patient groups.
Conclusion
This AI-enabled, multi-modal framework improves clinical decision support in GBM by enabling accurate risk stratification and treatment planning. The integration of radiological imaging, histopathology, and transcriptomics offers a comprehensive and personalized approach to GBM prognosis.}
}
@article{WANG2024,
title = {Promoting Personalized Reminiscence Among Cognitively Intact Older Adults Through an AI-Driven Interactive Multimodal Photo Album: Development and Usability Study},
journal = {JMIR Aging},
volume = {7},
year = {2024},
issn = {2561-7605},
doi = {https://doi.org/10.2196/49415},
url = {https://www.sciencedirect.com/science/article/pii/S2561760524000057},
author = {Xin Wang and Juan Li and Tianyi Liang and Wordh Ul Hasan and Kimia Tuz Zaman and Yang Du and Bo Xie and Cui Tao},
keywords = {aging, knowledge graph, machine learning, reminiscence, voice assistant},
abstract = {Background
Reminiscence, a therapy that uses stimulating materials such as old photos and videos to stimulate long-term memory, can improve the emotional well-being and life satisfaction of older adults, including those who are cognitively intact. However, providing personalized reminiscence therapy can be challenging for caregivers and family members.
Objective
This study aimed to achieve three objectives: (1) design and develop the GoodTimes app, an interactive multimodal photo album that uses artificial intelligence (AI) to engage users in personalized conversations and storytelling about their pictures, encompassing family, friends, and special moments; (2) examine the app’s functionalities in various scenarios using use-case studies and assess the app’s usability and user experience through the user study; and (3) investigate the app’s potential as a supplementary tool for reminiscence therapy among cognitively intact older adults, aiming to enhance their psychological well-being by facilitating the recollection of past experiences.
Methods
We used state-of-the-art AI technologies, including image recognition, natural language processing, knowledge graph, logic, and machine learning, to develop GoodTimes. First, we constructed a comprehensive knowledge graph that models the information required for effective communication, including photos, people, locations, time, and stories related to the photos. Next, we developed a voice assistant that interacts with users by leveraging the knowledge graph and machine learning techniques. Then, we created various use cases to examine the functions of the system in different scenarios. Finally, to evaluate GoodTimes’ usability, we conducted a study with older adults (N=13; age range 58-84, mean 65.8 years). The study period started from January to March 2023.
Results
The use-case tests demonstrated the performance of GoodTimes in handling a variety of scenarios, highlighting its versatility and adaptability. For the user study, the feedback from our participants was highly positive, with 92% (12/13) reporting a positive experience conversing with GoodTimes. All participants mentioned that the app invoked pleasant memories and aided in recollecting loved ones, resulting in a sense of happiness for the majority (11/13, 85%). Additionally, a significant majority found GoodTimes to be helpful (11/13, 85%) and user-friendly (12/13, 92%). Most participants (9/13, 69%) expressed a desire to use the app frequently, although some (4/13, 31%) indicated a need for technical support to navigate the system effectively.
Conclusions
Our AI-based interactive photo album, GoodTimes, was able to engage users in browsing their photos and conversing about them. Preliminary evidence supports GoodTimes’ usability and benefits cognitively intact older adults. Future work is needed to explore its potential positive effects among older adults with cognitive impairment.}
}
@article{VASQUEZFERNANDEZ202065,
title = {Resurgence of relationality: reflections on decolonizing and indigenizing ‘sustainable development’},
journal = {Current Opinion in Environmental Sustainability},
volume = {43},
pages = {65-70},
year = {2020},
note = {Indigenous Conceptualizations of ‘Sustainability’},
issn = {1877-3435},
doi = {https://doi.org/10.1016/j.cosust.2020.03.005},
url = {https://www.sciencedirect.com/science/article/pii/S1877343520300178},
author = {Andrea M Vásquez-Fernández and Cash {Ahenakew pii tai poo taa}},
abstract = {Many Indigenous Peoples around the world find the dominant model of sustainable development disrespectful and hypocritical. The terms ‘sustainable’ and ‘development’ when combined reproduce patterns of exploitation that destroy Mother Earth while imposing a regime of colonial praxis on Indigenous Peoples and Lands under a benevolent appearance of civilization, salvation, novelty, and progress. Sustainable development models are rooted within western paradigms (a specific set of epistemology, ontology, axiology and methodology) such as the neoliberal capitalism approach, which structures relationships with Indigenous Peoples and Land based on disrespectful relationships. In this article, we offer an approach that aspires to be decolonial. First, we examine the current model of ‘sustainable development’ through Indigenous and modernity/coloniality approaches. Second, through Indigenous Peoples’ paradigms, along with the concepts respectful inter-being-relationality and Land revitalization, we provide Indigenous perspectives on ‘sustainability’ and ‘development’ that may strengthen sovereignty and wellbeing.}
}
@article{BLAGEC2023104274,
title = {Benchmark datasets driving artificial intelligence development fail to capture the needs of medical professionals},
journal = {Journal of Biomedical Informatics},
volume = {137},
pages = {104274},
year = {2023},
issn = {1532-0464},
doi = {https://doi.org/10.1016/j.jbi.2022.104274},
url = {https://www.sciencedirect.com/science/article/pii/S1532046422002799},
author = {Kathrin Blagec and Jakob Kraiger and Wolfgang Frühwirt and Matthias Samwald},
keywords = {Artificial intelligence, Benchmarks, Natural language processing, Healthcare, Clinical, Medical},
abstract = {Publicly accessible benchmarks that allow for assessing and comparing model performances are important drivers of progress in artificial intelligence (AI). While recent advances in AI capabilities hold the potential to transform medical practice by assisting and augmenting the cognitive processes of healthcare professionals, the coverage of clinically relevant tasks by AI benchmarks is largely unclear. Furthermore, there is a lack of systematized meta-information that allows clinical AI researchers to quickly determine accessibility, scope, content and other characteristics of datasets and benchmark datasets relevant to the clinical domain. To address these issues, we curated and released a comprehensive catalogue of datasets and benchmarks pertaining to the broad domain of clinical and biomedical natural language processing (NLP), based on a systematic review of literature and. A total of 450 NLP datasets were manually systematized and annotated with rich metadata, such as targeted tasks, clinical applicability, data types, performance metrics, accessibility and licensing information, and availability of data splits. We then compared tasks covered by AI benchmark datasets with relevant tasks that medical practitioners reported as highly desirable targets for automation in a previous empirical study. Our analysis indicates that AI benchmarks of direct clinical relevance are scarce and fail to cover most work activities that clinicians want to see addressed. In particular, tasks associated with routine documentation and patient data administration workflows are not represented despite significant associated workloads. Thus, currently available AI benchmarks are improperly aligned with desired targets for AI automation in clinical settings, and novel benchmarks should be created to fill these gaps.}
}
@article{CAI2023104418,
title = {Integrating domain knowledge for biomedical text analysis into deep learning: A survey},
journal = {Journal of Biomedical Informatics},
volume = {143},
pages = {104418},
year = {2023},
issn = {1532-0464},
doi = {https://doi.org/10.1016/j.jbi.2023.104418},
url = {https://www.sciencedirect.com/science/article/pii/S1532046423001399},
author = {Linkun Cai and Jia Li and Han Lv and Wenjuan Liu and Haijun Niu and Zhenchang Wang},
keywords = {Domain knowledge, Biomedical text analysis, Deep learning, Natural language processing},
abstract = {The past decade has witnessed an explosion of textual information in the biomedical field. Biomedical texts provide a basis for healthcare delivery, knowledge discovery, and decision-making. Over the same period, deep learning has achieved remarkable performance in biomedical natural language processing, however, its development has been limited by well-annotated datasets and interpretability. To solve this, researchers have considered combining domain knowledge (such as biomedical knowledge graph) with biomedical data, which has become a promising means of introducing more information into biomedical datasets and following evidence-based medicine. This paper comprehensively reviews more than 150 recent literature studies on incorporating domain knowledge into deep learning models to facilitate typical biomedical text analysis tasks, including information extraction, text classification, and text generation. We eventually discuss various challenges and future directions.}
}
@article{LAPENA2022106873,
title = {Leveraging execution traces to enhance traceability links recovery in BPMN models},
journal = {Information and Software Technology},
volume = {146},
pages = {106873},
year = {2022},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2022.106873},
url = {https://www.sciencedirect.com/science/article/pii/S0950584922000398},
author = {Raúl Lapeña and Francisca Pérez and Óscar Pastor and Carlos Cetina},
keywords = {Traceability links recovery, BPMN models, Model-driven engineering},
abstract = {Context:
Traceability Links Recovery has been a topic of interest for many years, resulting in techniques that perform traceability based on the linguistic clues of the software artifacts under study. However, BPMN models tend to present an overall lack of linguistic clues when compared to code-based artifacts or code generation models. Hence, TLR becomes a harder task when performed among requirements and BPMN models.
Objective:
This paper proposes a novel approach, called METRA, that leverages the execution traces of BPMN to expand the BPMN models. The expansion of the BPMN models enhances their linguistic clues, bridging the language between BPMN models and other software artifacts, and improving the TLR process between requirements and BPMN models.
Methods:
The proposed approach is evaluated through a real-world industrial case study, comparing its outcomes against two state-of-the-art baselines, TLR and LORE. The paper also evaluates the combination of METRA with LORE against the rest of the approaches, including standalone METRA. The evaluation process generates a report of measurements (precision, recall, f-measure, and MCC), over which a statistical analysis is conducted.
Results:
Results show that approaches based on METRA maintain the excellent precision results obtained by baseline approaches (74.2% for METRA, 78.8% for METRA+LORE), whilst also improving the recall results from the unacceptable values obtained by the baselines to good values (72.4% for METRA, 73.9% for METRA+LORE). Moreover, according to the statistical analysis, the differences in the results obtained by the evaluated approaches are statistically significant.
Conclusions:
This paper opens a novel field of work in TLR by analyzing the improvement of the TLR process through the inclusion of linguistic clues present in execution traces, and discusses ideas for further research that can delve into this promising direction explored by our work.}
}
@article{DEMEESTER2020946,
title = {Implementation-independent function reuse},
journal = {Future Generation Computer Systems},
volume = {110},
pages = {946-959},
year = {2020},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2019.10.006},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X19303723},
author = {Ben {De Meester} and Tom Seymoens and Anastasia Dimou and Ruben Verborgh},
keywords = {Function, Linked data, Reuse},
abstract = {Functions are essential building blocks of information retrieval and information management. However, efforts implementing these functions are fragmented: one function has multiple implementations, within specific development contexts. This inhibits reuse: metadata of functions and associated implementations need to be found across various search interfaces, and implementation integration requires human interpretation and manual adjustments. An approach is needed, independent of development context and enabling description and exploration of functions and (automatic) instantiation of associated implementations. In this paper, after collecting scenarios and deriving corresponding requirements, we (i) propose an approach that facilitates functions’ description, publication, and exploration by modeling and publishing abstract function descriptions and their links to concrete implementations; and (ii) enable implementations’ automatic instantiation by exploiting those published descriptions. This way, we can link to existing implementations, and provide a uniform detailed search interface across development contexts. The proposed model (the Function Ontology) and the publication method following the Linked Data principles using standards, are deemed sufficient for this task, and are extensible to new development contexts. The proposed set of tools (the Function Hub and Function Handler) are shown to fulfill the collected requirements, and the user evaluation proves them being perceived as a valuable asset during software retrieval. Our work thus improves developer experience for function exploration and implementation instantiation.}
}
@article{MEYERHOFF2023101570,
title = {Responses to CAT at 50: Reflections on accommodation from a sociolinguist},
journal = {Language Sciences},
volume = {99},
pages = {101570},
year = {2023},
issn = {0388-0001},
doi = {https://doi.org/10.1016/j.langsci.2023.101570},
url = {https://www.sciencedirect.com/science/article/pii/S0388000123000359},
author = {Miriam Meyerhoff},
keywords = {Communication accommodation theory, Sociolinguistics, Speech production, Speech perception, Focussing, Acts of identity},
abstract = {Communication accommodation theory (CAT) has shown remarkable staying power. To what can we attribute this? I suggest several reasons: first, the general phenomenon of accommodation has been long recognised by researchers and skilled practitioners of language, hence a systematic approach predicated on clear principles and experimental methods was attractive to the fields of linguistics, social psychology of language and communication. Second, CAT researchers have adopted a syncretic approach to changes in focus and methods, building on and not rejecting previous stages of CAT. Third, CAT has proven amenable to both qualitative and quantitative methods. This last attribute has, I suggest, enabled it to be incorporated into sociolinguistic research on perception. I conclude with some reflections on how the social psychology of language and sociolinguistics differ in their objects of enquiry, and I look ahead to possible areas of synergies between the fields based on principles of accommodation theory.}
}
@article{LI2025115471,
title = {Integrating urban building energy modeling (UBEM) and urban-building environmental impact assessment (UB-EIA) for sustainable urban development: A comprehensive review},
journal = {Renewable and Sustainable Energy Reviews},
volume = {213},
pages = {115471},
year = {2025},
issn = {1364-0321},
doi = {https://doi.org/10.1016/j.rser.2025.115471},
url = {https://www.sciencedirect.com/science/article/pii/S1364032125001443},
author = {Yang Li and Haibo Feng},
keywords = {Urban building energy modeling, Urban building environmental impact assessment, Energy efficiency, Environmental impact, Urban sustainability, Life cycle assessment},
abstract = {Rapid urbanization has increased energy demand and environmental impacts in urban buildings, highlighting the need to understand building interactions and energy transfer. This has led to various methodologies for large-scale building assessment, such as Urban Building Energy Modeling (UBEM) and Urban-Building Environmental Impact Assessment (UB-EIA). Both have been separately and widely studied to support urban planning and building design, develop sustainable and smart cities, and enable stakeholders to optimize resource use and make informed decisions. However, a detailed comparative analysis of various UBEM and UB-EIA methodologies and their integrations have not been thoroughly reviewed in current existing research. To fill this research gap, this comprehensive review systematically investigated 157 articles to understand the evolution, methodologies, challenges of UBEM and UB-EIA. This review provides a holistic understanding, highlighting complementary strengths and identifying opportunities for integration to enhance urban building sustainability assessments. The findings of the review found that integrating UBEM and UB-EIA holds significant potential for enhancing urban sustainability usually through a comprehensive, data-driven approach. UBEM can serve as a foundation for UB-EIA by using similar data and methods, improving validation, and addressing gaps. UB-EIA's reliance on Building Information Management (BIM) can be enhanced by UBEM's detailed 2D and 3D models for precise EIA. This integration fosters more informed decision-making, promoting resilient and sustainable urban development by accurately reflecting complex urban interactions. Further research should explore the social and economic impacts of urban buildings using integrated UBEM and UB-EIA strategies for thorough and robust assessments.}
}
@incollection{KRISHNA2022149,
title = {Chapter 7 - Distributed semantic architecture for smart grids: an industrial approach},
editor = {B.D. Deebak and Fadi Al-Turjman},
booktitle = {Sustainable Networks in Smart Grid},
publisher = {Academic Press},
pages = {149-177},
year = {2022},
isbn = {978-0-323-85626-3},
doi = {https://doi.org/10.1016/B978-0-323-85626-3.00010-7},
url = {https://www.sciencedirect.com/science/article/pii/B9780323856263000107},
author = {D. Siva Krishna and B. Raja Koti and P. Muralidhara Rao},
keywords = {Smart grid, distributed architecture, ontology, distributed systems, semantic web interoperability},
abstract = {Nowadays, the automation industry is focusing on smart grid (SG)-based distributed architectures for safety improvement. These architectures show interoperability which improves smart components that can reduce power consumption in energy management systems. In the latest Industry 4.0 scenario, home-automation applications’ privacy requirements have captured a wide variety in industry and societal safety. It can have a significant impact on the redesign and enhancements of power networks. These networks with smart energy components play a key role in the development of smart grids. In this context, integrating renewable energies with smart semantic distributed architectures help a new novel paradigm, which improves the safety hazard. Besides, various architectures can provide different sources of data elements, data sharing, and transformation into reusable information that has been considered in recent related surveys. This chapter focuses on providing state-of-the-art smart components that integrate energy sources in the distributed networks of renewable energies. Also, we present a comprehensive study of advanced architectures that bring numerous benefits to the SG. Moreover, these energy elements manage the SGs to optimize energy consumption, load balancing, and dynamic bandwidth. Nevertheless, these distributed semantic architectures require distributed upgrades to ontology-based smart grids. Besides, ontologies have proved that they could successfully integrate the knowledge necessitated to solve complex industrial energy management problems. As a result, novel semantic architectures for SG minimize power consumption, maximize dynamic energy resource utilization and load balancing, and enhance safety.}
}
@article{DEBAUCHE2020542,
title = {Edge Computing and Artificial Intelligence Semantically Driven. Application to a Climatic Enclosure},
journal = {Procedia Computer Science},
volume = {175},
pages = {542-547},
year = {2020},
note = {The 17th International Conference on Mobile Systems and Pervasive Computing (MobiSPC),The 15th International Conference on Future Networks and Communications (FNC),The 10th International Conference on Sustainable Energy Information Technology},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2020.07.077},
url = {https://www.sciencedirect.com/science/article/pii/S1877050920317774},
author = {Olivier Debauche and Said Mahmoudi and Sidi Ahmed Mahmoudi and Pierre Manneback and Frédéric Lebeau},
keywords = {phytotron, climatic enclosure, growth chamber, pogona, semantic rules, Internet of Things},
abstract = {Climatic chamber are enclosures where the ambient conditions, i.e. the temperature and humidity, are finely controlled. This one can play multiple roles such as the cultivation of plants (phytotron), the breeding of insects or habitat for exotic animals. The availability on the market of a wide variety of equipment makes it difficult to share settings and operating recipes. In this paper, we propose a versatile and automated modular climatic enclosure system that can be adapted according to the use cases and available material. In this paper, we use IoT device virtual representation, data validation by means AI algorithm, the semantic description of material, and ontology locally deployed from the cloud allowing to automate the local installation with container technology.}
}
@incollection{ABUALQUMBOZ2025,
title = {The nexus of knowledge, risk, and artificial intelligence: A new frontier in project risk management},
booktitle = {Reference Module in Social Sciences},
publisher = {Elsevier},
year = {2025},
isbn = {978-0-443-15785-1},
doi = {https://doi.org/10.1016/B978-0-443-28993-4.00206-7},
url = {https://www.sciencedirect.com/science/article/pii/B9780443289934002067},
author = {Moheeb Abualqumboz},
keywords = {AI-augmented risk management, Artificial intelligence, Knowledge based project risk management, Knowledge management, Risk decision-making},
abstract = {This chapter explores the integration of artificial intelligence (AI) knowledge management (KM) to enhance project risk management (PRM) to enhance project risk management and decision-making. The fusion of AI, KM and PRM with AI-driven data analysis at its core, is poised to yield transformative advancements in project outcomes. The chapter presents several benefits, such as computational analysis and empowered risk scenarios, alongside challenges that include maintaining human expertise and addressing ethical concerns related to AI's role in decision-making. The chapter concludes by highlighting the need for hybrid models to combine AI capabilities with human-centric approaches for proactive risk management.}
}
@incollection{CANNATARO20251,
title = {Introduction to Methods Section},
editor = {Shoba Ranganathan and Mario Cannataro and Asif M. Khan},
booktitle = {Encyclopedia of Bioinformatics and Computational Biology (Second Edition)},
publisher = {Elsevier},
edition = {Second Edition},
address = {Oxford},
pages = {1-2},
year = {2025},
isbn = {978-0-323-95503-4},
doi = {https://doi.org/10.1016/B978-0-323-95502-7.00294-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780323955027002943},
author = {Mario Cannataro},
abstract = {The Methods section presents the theoretical methodologies underpinning bioinformatics and computational biology. The section includes 14 subsections that present basic and advanced computer science methods, biological data models as well as specialized bioinformatics methods. It describes well-established bioinformatics methods as well as novel data analysis methods, including data science and artificial intelligence methods. The section is completed by two subsections dedicated to recent advances in epidemiology and pandemic surveillance and in bioimage analytics.}
}
@article{EICKHOFF2020249,
title = {A Metadata Repository for Semantic Product Lifecycle Management},
journal = {Procedia CIRP},
volume = {91},
pages = {249-254},
year = {2020},
note = {Enhancing design through the 4th Industrial Revolution Thinking},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2019.11.006},
url = {https://www.sciencedirect.com/science/article/pii/S2212827120308155},
author = {Thomas Eickhoff and Andreas Eiden and Jens Christian Göbel and Martin Eigner},
keywords = {PLM, smart products, data modeling, interoperability, ontology, data integration},
abstract = {Current processes for highly interdisciplinary and complex smart products rely on the support of a big variety of IT systems. At the lowest level, authoring systems are used to create digital models and engineering data objects. A multitude of data management systems which in turn have to be integrated into comprehensive Product Lifecycle Management (PLM) and Enterprise Resource Planning (ERP) solutions enable the management of this product information and engineering processes (e.g. for engineering change and release management) along the entire product lifecycle. Engineers use these information management approaches for their daily work processes like engineering change or release management. In industrial environments, several heterogeneous IT systems coexist but cannot easily be connected and thus provide critical barriers for engineering collaboration. Being able to flexible access required engineering information from these IT systems supported by a platform that provides integrated metadata repository engineering could improve engineering workflows like change management dramatically. The approach introduced in this paper describes a Metadata Repository for Semantic Product Lifecycle Management (SP2IDER) which provides an additional information management layer that uses an IT architecture based on a minimalistic core to view and access data from a multitude of IT source systems. Instead of storing data from these source systems in SP2IDER, open web technologies like Linked Data principles and JSON-LD allow providing real-time access to the source systems.}
}
@article{STEPHAN2024102884,
title = {Agent-based approaches for biological modeling in oncology: A literature review},
journal = {Artificial Intelligence in Medicine},
volume = {152},
pages = {102884},
year = {2024},
issn = {0933-3657},
doi = {https://doi.org/10.1016/j.artmed.2024.102884},
url = {https://www.sciencedirect.com/science/article/pii/S093336572400126X},
author = {Simon Stephan and Stéphane Galland and Ouassila {Labbani Narsis} and Kenji Shoji and Sébastien Vachenc and Stéphane Gerart and Christophe Nicolle},
keywords = {Artificial intelligence, Agent-based modeling, Oncology, Metaheuristic algorithms, Precision medicine, Therapeutic targeting, Pathway},
abstract = {Context:
Computational modeling involves the use of computer simulations and models to study and understand real-world phenomena. Its application is particularly relevant in the study of potential interactions between biological elements. It is a promising approach to understand complex biological processes and predict their behavior under various conditions.
Methodology:
This paper is a review of the recent literature on computational modeling of biological systems. Our study focuses on the field of oncology and the use of artificial intelligence (AI) and, in particular, agent-based modeling (ABM), between 2010 and May 2023.
Results:
Most of the articles studied focus on improving the diagnosis and understanding the behaviors of biological entities, with metaheuristic algorithms being the models most used. Several challenges are highlighted regarding increasing and structuring knowledge about biological systems, developing holistic models that capture multiple scales and levels of organization, reproducing emergent behaviors of biological systems, validating models with experimental data, improving computational performance of models and algorithms, and ensuring privacy and personal data protection are discussed.}
}
@article{LEIPZIG2021100322,
title = {The role of metadata in reproducible computational research},
journal = {Patterns},
volume = {2},
number = {9},
pages = {100322},
year = {2021},
issn = {2666-3899},
doi = {https://doi.org/10.1016/j.patter.2021.100322},
url = {https://www.sciencedirect.com/science/article/pii/S2666389921001707},
author = {Jeremy Leipzig and Daniel Nüst and Charles Tapley Hoyt and Karthik Ram and Jane Greenberg},
keywords = {reproducible research, reproducible computational research, RCR, reproducibility, replicability, metadata, provenance, workflows, pipelines, ontologies, notebooks, containers, software dependencies, semantic, FAIR},
abstract = {Summary
Reproducible computational research (RCR) is the keystone of the scientific method for in silico analyses, packaging the transformation of raw data to published results. In addition to its role in research integrity, improving the reproducibility of scientific studies can accelerate evaluation and reuse. This potential and wide support for the FAIR principles have motivated interest in metadata standards supporting reproducibility. Metadata provide context and provenance to raw data and methods and are essential to both discovery and validation. Despite this shared connection with scientific data, few studies have explicitly described how metadata enable reproducible computational research. This review employs a functional content analysis to identify metadata standards that support reproducibility across an analytic stack consisting of input data, tools, notebooks, pipelines, and publications. Our review provides background context, explores gaps, and discovers component trends of embeddedness and methodology weight from which we derive recommendations for future work.}
}
@article{LOBOV2020932,
title = {Formalization of engineering knowledge for industrial robots using Knowledge Fusion language},
journal = {Procedia Manufacturing},
volume = {51},
pages = {932-937},
year = {2020},
note = {30th International Conference on Flexible Automation and Intelligent Manufacturing (FAIM2021)},
issn = {2351-9789},
doi = {https://doi.org/10.1016/j.promfg.2020.10.131},
url = {https://www.sciencedirect.com/science/article/pii/S2351978920319880},
author = {Andrei Lobov and Tuan Anh Tran and Sarah Ann {Oxman Prescott}},
keywords = {knowledge-based engineering, product design, robotics, manufacturing},
abstract = {Knowledge-based engineering aims to automate product design processes. Researches in manufacturing try to find optimal way to reduce the time required to go from intangible idea to a product in hands of a customer. With the advances of Information and Communication Technologies, it becomes possible to integrate and use information generated at different phases of a product lifecycle. That includes deciding on how robots should operate, which have got a key role in automation of manufacturing processes. Use of formalized representation of engineering knowledge for industrial robots’ application can allow for better decision making. This paper proposes an approach for integrating product design with robot applications using Knowledge Fusion language. The Knowledge Fusion allows to capture engineering knowledge in computer-processable format that can be later used for automating design and manufacturing processes. An approach is illustrated with Siemens NX tools framework.}
}
@article{KUGIC2023104497,
title = {Embedding-based terminology expansion via secondary use of large clinical real-world datasets},
journal = {Journal of Biomedical Informatics},
volume = {147},
pages = {104497},
year = {2023},
issn = {1532-0464},
doi = {https://doi.org/10.1016/j.jbi.2023.104497},
url = {https://www.sciencedirect.com/science/article/pii/S1532046423002186},
author = {Amila Kugic and Bastian Pfeifer and Stefan Schulz and Markus Kreuzthaler},
keywords = {Natural language processing, Big data, Electronic health records, International classification of diseases, Machine learning},
abstract = {A log-likelihood based co-occurrence analysis of ∼1.9 million de-identified ICD-10 codes and related short textual problem list entries generated possible term candidates at a significance level of p<0.01. These top 10 term candidates, consisting of 1 to 5-grams, were used as seed terms for an embedding based nearest neighbor approach to fetch additional synonyms, hypernyms and hyponyms in the respective n-gram embedding spaces by leveraging two different language models. This was done to analyze the lexicality of the resulting term candidates and to compare the term classifications of both models. We found no difference in system performance during the processing of lexical and non-lexical content, i.e. abbreviations, acronyms, etc. Additionally, an application-oriented analysis of the SapBERT (Self-Alignment Pretraining for Biomedical Entity Representations) language model indicates suitable performance for the extraction of all term classifications such as synonyms, hypernyms, and hyponyms.}
}
@article{ALIBAKHSHI2020286,
title = {Exploring the antecedents of English language teachers' teaching self-efficacy: a qualitative study},
journal = {Qualitative Research Journal},
volume = {21},
number = {3},
pages = {286-303},
year = {2020},
issn = {1443-9883},
doi = {https://doi.org/10.1108/QRJ-05-2020-0040},
url = {https://www.sciencedirect.com/science/article/pii/S144398832000017X},
author = {Goudarz Alibakhshi and Hossein Abdollahi and Behzad Nezakatgoo},
keywords = {Foreign language teachers, Self-efficacy, Antecedents, Efficacious teachers},
abstract = {Purpose
This study aimed at exploring the antecedents of English as a Foreign Language (EFL) teachers' self-efficacy (SE). That is, the main purpose was to deeply delve into the main variables and latent which lead to a high sense of SE among teachers of English as a foreign language.
Design/methodology/approach
A phenomenological inquiry was employed to explore the antecedents of language teachers from their eyes. In this study, the phenomenon is SE antecedents. The researchers employed this method to help identify the meaning behind the human experience as it is related to a phenomenon or notable collective occurrence. A semistructured interview checklist was developed, carefully worded, reviewed by five teacher educators known as experts in qualitative research methodology and teacher education and edited based on the experts' feedback
Findings
The findings showed that the antecedents of SE can be categorized into personal variables, educational variables and institutional variables. Personal variables include verbal intelligence, language proficiency and some other traits. The institutional variables include support from administration, support from colleagues, support from the community and quality of work life. The educational antecedents include preservice and in-service training courses. Preservice training courses included the following: the courses on general language skills, courses on teaching methods, practicum courses, etc.
Originality/value
This study was undertaken in a specific context and the participants are specific. Almost all studies on SE are quantitative, and this qualitative study explored the antecedents of teachers' SE from their own eyes. Some of the explored studies were not mentioned in any of the related studies.}
}
@article{HARRISON202028,
title = {Indigenous music sustainability during climate change},
journal = {Current Opinion in Environmental Sustainability},
volume = {43},
pages = {28-34},
year = {2020},
note = {Indigenous Conceptualizations of ‘Sustainability’},
issn = {1877-3435},
doi = {https://doi.org/10.1016/j.cosust.2020.01.003},
url = {https://www.sciencedirect.com/science/article/pii/S1877343520300038},
author = {Klisala Harrison},
abstract = {Indigenous music sustainability forms a cohesive concept due to shared sustainability threats globally among different Indigenous peoples historically and contemporaneously, shared aspects of music culture, and current ways of Indigenous pursuing music sustainability. During colonization, forced geographical relocations and cultural assimilations of Indigenous peoples threatened or extinguished their musical cultures, ecosystems and habitats. This, as well as current pressures of neocolonialism, negatively impacts how Indigenous music cultures can engage traditional Indigenous lands and environments plus ontologies, epistemologies and natural materials emergent from them. As Indigenous peoples are among the most impacted by climate change, and historical Indigenous musics have close relationships with natural environments, new threats to the sustainability of Indigenous music cultures — natural materials needed for musical instruments; ontologies and epistemologies of historical Indigenous places articulated in musics — are emerging, particularly as climate change threatens and changes the ecosystems of traditional Indigenous places. In addition to offering a summary of such general trends of the sustainability of Indigenous music, this review article reflects on how scholarly pursuit of the topic engages and does not engage indigenism, or the promotion and protection of the rights of the world’s first peoples.}
}
@article{ZAMECNIK2025105587,
title = {On Some Models of Extended Mechanism in Code Biology},
journal = {BioSystems},
pages = {105587},
year = {2025},
issn = {0303-2647},
doi = {https://doi.org/10.1016/j.biosystems.2025.105587},
url = {https://www.sciencedirect.com/science/article/pii/S0303264725001972},
author = {Lukáš Zámečník and Barbora Jurková},
keywords = {Code Biology, Biological Meaning, Extended Mechanism, Self-reproducing Machine, Self-propagating Machine},
abstract = {Barbieri’s semantic biology (originally Barbieri 1985) provides an extension of the standard biological ontology, through a new theoretical entity: the code. A specific feature of Barbieri’s semantic turn in biology is the use of mechanistic explanations of living systems. This approach allows to work with meaning as the ‘new observable’ of biology. The relationship between meaning and code is expressed by Barbieri as follows: “[...] meaning is an entity which is related to another entity by a code.” (Barbieri 2015, 26). Barbieri refers to the mechanistic model of meaning as an ‘extended mechanism’. This work is a follow-up to a previously published paper in which we concluded that the von Neumann probe (and thus the Turing machine) can serve as a “minimal sufficient model of Barbieri’s extended mechanism” (Jurková and Zámečník 2023a). We now build on this by connecting the concept of self-reproduction as conceived by Norbert Wiener. Firstly, in order to further explore the ‘extended mechanism’, but also in an attempt to highlight the importance of self-reproduction as a model of biological processes. We want to highlight the extent to which von Neumann and Wiener collaborated, but also where their understanding and conception of self-reproduction diverge. Wiener, unlike von Neumann, emphasizes that such a machine is “an agency for accomplishing certain definite purposes” (Wiener 2019/1948, 245) and self-propagation “is the creation of a replica capable of the same functions” (Wiener 2019/1948, 245). We suggest that when Wiener views the machine in terms of an ‘operative procedure’ that enables machine self-propagation, he is implicitly referring to the role of code as thematized in Barbieri’s extended mechanism (Wiener 2019/1948, 249). We want to focus not only on classical scientific publications, but also to analyse the personal correspondence between von Neumann and Wiener in which they discussed the issue and how it can change the way we perceive self-reproducing machine.}
}
@article{LV2024109398,
title = {VEG-MMKG: Multimodal knowledge graph construction for vegetables based on pre-trained model extraction},
journal = {Computers and Electronics in Agriculture},
volume = {226},
pages = {109398},
year = {2024},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2024.109398},
url = {https://www.sciencedirect.com/science/article/pii/S0168169924007890},
author = {Bowen Lv and Huarui Wu and Wenbai Chen and Cheng Chen and Yisheng Miao and Chunjiang Zhao},
keywords = {Knowledge graph, Multimodal fusion, Image-text pairs, Pre-trained model},
abstract = {Knowledge graph technology is of great significance to modern agricultural information management and data-driven decision support. However, agricultural knowledge is rich in types, and agricultural knowledge graph databases built only based on text are not conducive to users’ intuitive perception and comprehensive understanding of knowledge. In view of this, this paper proposes a solution to extract knowledge and construct an agricultural multimodal knowledge graph using a pre-trained language model. This paper takes two plants, cabbage and corn, as research objects. First, a text-image collaborative representation learning method with a two-stream structure is adopted to combine the image modal information of vegetables with the text modal information, and the correlation and complementarity between the two types of information are used to achieve entity alignment. In addition, in order to solve the problem of high similarity of vegetable entities in small categories, a cross-modal fine-grained contrastive learning method is introduced, and the problem of insufficient semantic association between modalities is solved by contrastive learning of vocabulary and small areas of images. Finally, a visual multimodal knowledge graph user interface is constructed using the results of image and text matching. Experimental results show that the image and text matching efficiency of the fine-tuned pre-trained model on the vegetable dataset is 76.7%, and appropriate images can be matched for text entities. The constructed visual multimodal knowledge graph database allows users to query and filter knowledge according to their needs, providing assistance for subsequent research on various applications in specific fields such as multimodal agricultural intelligent question and answer, crop pest and disease identification, and agricultural product recommendations.}
}
@article{PANCHALINGAM2023106266,
title = {Differential gene expression analysis combined with molecular dynamics simulation study to elucidate the novel potential biomarker involved in pulmonary TB},
journal = {Microbial Pathogenesis},
volume = {182},
pages = {106266},
year = {2023},
issn = {0882-4010},
doi = {https://doi.org/10.1016/j.micpath.2023.106266},
url = {https://www.sciencedirect.com/science/article/pii/S0882401023002991},
author = {Santhiya Panchalingam and Govindaraju Kasivelu and Manikandan Jayaraman and Rajalakshmi Kumar and Santhiya Kalimuthu and Jeyakanthan Jeyaraman},
keywords = {Tuberculosis, Drug resistant, Differentially expressed genes (DEG), TNFAIP6, Molecular dynamics simulation, Principal component analysis},
abstract = {Tuberculosis (TB) is a lethal multisystem disease that attacks the lungs' first line of defense. A substantial threat to public health and a primary cause of death is pulmonary TB. This study aimed to identify and investigate the probable differentially expressed genes (DEGs) primarily involved in Pulmonary TB. Accordingly, three independent gene expression data sets, numbered GSE139825, GSE139871, and GSE54992, were utilized for this purpose. The identified DEGs were used for bioinformatics-based analysis, including physical gene interaction, Gene Ontology (GO), network analysis and pathway studies using the Kyoto Encyclopedia of Genes and Genomes pathway (KEGG). The computational analysis predicted that TNFAIP6 is the significant DEG in the gene expression profiling of TB datasets. According to gene ontology analysis, TNFAIP6 is also essential in injury and inflammation. Further, TNFA1P6 is strongly linked to arsenic poisoning, evident from the results of NetworkAnalyst, a comprehensive and interactive platform for gene expression profiling via network visual analytics. As a result, the TNFAIP6 gene was ultimately chosen as a candidate DEG and subsequently employed for in silico structural characterization studies. The tertiary structure of TNFAIP6 was modelled using the ROBETTA server, followed by validation with SAVES and ProSA webserver. Additionally, structural dynamic studies, including molecular dynamics simulation (MDS) and essential dynamics analysis, including principal component (PC) based free energy landscape (FEL) analysis, was used for checking the stability of TNFAIP6 models. The dynamics result established the structural rigidity of modelled TNFAIP6 through RMSD, RMSF and RoG results. The FEL analysis revealed the restricted conformational flexibility of TNFAIP6 by displaying a single minimum energy basin in the contour plot. The comprehensive computational analysis established that TNFAIP6 could serve as a viable biomarker to assess the severity of pulmonary TB.}
}
@article{GUO2024102254,
title = {Integrated modeling for retired mechanical product genes in remanufacturing: A knowledge graph-based approach},
journal = {Advanced Engineering Informatics},
volume = {59},
pages = {102254},
year = {2024},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2023.102254},
url = {https://www.sciencedirect.com/science/article/pii/S1474034623003828},
author = {Yuyao Guo and Lei Wang and Zelin Zhang and Jianhua Cao and Xuhui Xia and Ying Liu},
keywords = {Information modeling, Retired mechanical product genes, Knowledge graph, Multidimensional information integration},
abstract = {Retired mechanical product genes refer to a collection of information that describes the structure, status, and related characteristics of retired mechanical products. Leveraging this information, along with its implicit knowledge, is a key approach to enhance the intelligence and efficiency of the remanufacturing process. This study aims to automatically obtain and integrate multi-source, heterogeneous, multilayer, and multidimensional retired mechanical product information and its implicit knowledge through a knowledge graph to form a gene bank, providing data basis for the remanufacturing process. First, the conceptual model of retired mechanical product genes and overall modeling framework based on knowledge graph are established. Next, according to the gene characteristics on different product layers, appropriate modeling methods were designed for part genes, product function and structure genes, product performance and failure genes respectively. For implicit rules and knowledge that pose challenges for direct representation, we express them in the IF-THEN form and convert them into triples. Then, an information fusion method is employed to integrate genes information on various layers into a gene graph. Finally, the proposed integrated modeling approach was evaluated in a scenario of remanufacturing an eleven-roll straightening machine. The results indicate that it can automatically obtain part genes information quickly and effectively. Additionally, it was confirmed that the constructed gene graph exhibits good accuracy and completeness, demonstrating the promising application prospects of the proposed method in remanufacturing.}
}
@article{LI2024108280,
title = {Experiencing the body as play: Cultivating older adults’ exergame experiences using embodied metaphors and multimodal feedback},
journal = {Computers in Human Behavior},
volume = {158},
pages = {108280},
year = {2024},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2024.108280},
url = {https://www.sciencedirect.com/science/article/pii/S0747563224001481},
author = {Qingchuan Li and Simin Yang},
keywords = {Exergame, Body-based interaction, Older adults, Embodiment, Embodied metaphor, Multimodal feedback},
abstract = {Physical activity (PA) is promising in increasing active life for older adults, but its repetitive and fatigue-inducing nature greatly harms older adults’ motivation to participate. Recently, there has been a growing interest in applying exergames to improve older adults’ PA adherence and engagement. To better support body-based interactions, embodied metaphors and multimodal feedback are suggested to ensure effective and meaningful mapping between elderly players’ input actions and exergame responses, but their effectiveness have not been fully investigated. After developing a list of embodied and ontological metaphors based a series of user-centered approaches, two experiments were conducted to investigate how embodied metaphors and multimodal feedback impact older adults'’ playing experience of PA exergames, among fifty-nine and twenty-five older adults, respectively. Regarding the embodied metaphor design, the results indicated that a higher embodiment level significantly and positively influenced the participants’ acceptance behavior in terms of their attitudes toward the exergame, and a higher information richness level demonstrated significantly positive effects on familiarity perception and all aspects of acceptance behavior. For the multimodal feedback design, the results indicated that 3D visual feedback better facilitated the participants’ sense of embodiment and immersion, as well as their acceptance behavior, compared to 2D visual feedback. Furthermore, constant tactile feedback in a continuous-only or continuous-and-augmented way significantly improved the participants’ PA movement performance and sense of embodiment, rather than instant feedback. Accordingly, a list of design guidelines for PA exergame development is proposed, with the possible contributions and limitations of this research addressed.}
}
@article{MAJOR2021104501,
title = {Archetypes and code biology},
journal = {Biosystems},
volume = {208},
pages = {104501},
year = {2021},
issn = {0303-2647},
doi = {https://doi.org/10.1016/j.biosystems.2021.104501},
url = {https://www.sciencedirect.com/science/article/pii/S0303264721001489},
author = {J.C. Major},
keywords = {Code biology, Analytical psychology, C.G. Jung, Marcello Barbieri, Archetypes, Patterns of behavior, Instincts},
abstract = {As a clinical psychologist, I observe stereotyped formulas of behavior in action every day in the consulting room, despite differences in age, race, or culture; they present themselves as codified rules or typical modes of behavior in archetypical situations. Such circumstances coincide with what C.G. Jung defended: the existence of archetypes stored in an inherited/phylogenetic repository, which he called the collective unconscious – somewhat similar to the notion of an ethogram, as shown by ethology. Psychologists can use a perspective to facilitate understanding the phenomenon: the code biology perspective (Barbieri 2014). This approach can help us recognize how these phenomenological events have an ontological reality based not only on the existence of organic information but also on the existence of organic meaning. We are not a tabula rasa (Wilson 2000): despite the explosive diversification of the brain and the emergence of conscience and intentionality, we observe the conservation of basic instincts and emotions (Ekman 2004; Damasio 2010) not only in humans but in all mammals and other living beings; we refer to the neural activity on which the discrimination behavior is based, i.e., the neural codes. The conservation of these fundamental set-of-rules or conventions suggests that one or more neural codes have been highly conserved and serves as an interpretive basis for what happens to the living being who owns them (Barbieri 2003). Thus, archetypes’ phenomenological reality can be understood not as something metaphorical but as an ontological (phylogenetic) fact (Goodwyn 2019). Furthermore, epigenetic regulation theories present the possibility that the biomolecular process incorporates elements of the context where it takes place; something fundamental to understand our concept – the archetype presents itself as the mnesic remnant of the behavioral history of individuals who preceded us on the evolutionary scale. In short: brains are optimized for processing ethologically relevant sensory signals (Clemens et al., 2015). From the perspective of the corporeal mind (Searle 2002), in this paper, we will show the parallels between code biology and the concept of the archetype, as Jung defended it and as it appears in clinical practice.}
}
@article{YI2025102146,
title = {Network pharmacology and in vitro experiments reveal the potential therapeutic effects of Scrophularia ningpoensis Hemsl in the treatment of ameloblastoma},
journal = {Journal of Stomatology, Oral and Maxillofacial Surgery},
volume = {126},
number = {6},
pages = {102146},
year = {2025},
issn = {2468-7855},
doi = {https://doi.org/10.1016/j.jormas.2024.102146},
url = {https://www.sciencedirect.com/science/article/pii/S246878552400435X},
author = {Jing-Rui Yi and Bang Zeng and Bing Liu and Rui-Fang Li and Yin-Fu Che and Qi-Wen Man},
keywords = {Scrophularia ningpoensis Hemsl, ameloblastoma, network pharmacology, molecular docking},
abstract = {Purpose
This study aimed to explore active ingredients in Scrophularia ningpoensis Hemsl (SNH) with potential effects on ameloblastoma (AM) using network pharmacological approach, bioinformatic gene analysis and in vitro cell experiments.
Methods
The active ingredients and their corresponding targets of SNH were identified from the Traditional Chinese Medicine Systems Pharmacology (TCMSP), as well as SwissTargetPrediction. Disease targets of AM were selected from GeneCards and DisGeNET databases. Differentially expressed genes (DEGs) of AM were identified, and Gene Ontology enrichment analysis were performed using the Gene Expression Omnibus (GEO) dataset GSE38494 through bioinformatic analysis. The STRING database platform was utilized to generate a protein–protein interaction network diagram, followed by hub gene analysis using Cytoscape software. AutoDock Vina software was used to perform molecular docking verification of the effects of the active ingredients on potential core targets. Additionally, in vitro experiments including quantitative reverse transcription polymerase chain reaction (RT-qPCR), EdU assay and CCK-8 cell proliferation assay were conducted using AM cell line AM-1 after SNH extract treatment.
Result
The study revealed that SNH contains eight active ingredients and a total of 388 drug targets, including 10 potential core targets in AM. Hub genes identified in the analysis were CCNA2, HRAS, PTGS2, PIK3CB, FGFR1, CASP3, MMP1, SLC2A1, MMP14, and MME. Molecular docking analysis demonstrated strong binding activity between key active ingredients (β-sitosterol, scropolioside A_qt, scropolioside D, scropolioside D_qt, and sugiol) and target genes (CASP3, FGFR1, HRAS, PTGS2, and SLC2A1). Gene Ontology enrichment analysis indicated that SNH exerts its effects on AM through pathways related to cellular response to abiotic stimulus, cellular response to hypoxia, and exopeptidase activity. Immunohistochemical analysis using tissue microarray showed higher expression of MMP14 and PTGS2 in AM compared to dentigerous cyst. Using AM-1 cell line, RT-qPCR results confirmed that SNH suppressed the expression of MMP14 and PTGS2 at mRNA level. Additionally, the EdUassay and CCK-8 assay indicated the inhibitory effect of SNH on the proliferation of AM-1 cells.
Conclusion
These findings showed that SNH could suppress expression of MMP14 and PTGS2 and restrain the proliferation of AM. Our study highlights the potential of SNH as a promising therapeutic candidate for AM, which may provide more options for clinical treatment.}
}
@article{ROTURIER2022164,
title = {Digital technologies and ILK in the Arctic: In search of epistemological pluralism},
journal = {Environmental Science & Policy},
volume = {133},
pages = {164-171},
year = {2022},
issn = {1462-9011},
doi = {https://doi.org/10.1016/j.envsci.2022.03.025},
url = {https://www.sciencedirect.com/science/article/pii/S1462901122001186},
author = {Samuel Roturier and Rémi Beau},
keywords = {Cultural diversity, Digital revolution, Indigenous and Local Knowledge (ILK), Ethics, Participatory research, Reindeer husbandry, Sámi},
abstract = {The digital revolution is profoundly challenging to Indigenous societies in their relationships with non-humans. To guide research that involves Indigenous communities and digital technology, we analysed the impacts of such technologies on Indigenous knowledge systems from the perspective of environmental ethics and anthropology. Using the example of Sámi reindeer husbandry in Sweden, we found that digital technologies, rather than relying on sensitive ways of understanding and experiencing nature, potentially reinforce a Western worldview of reindeer husbandry, instead of valuing a Sámi ontology. Therefore, they have the potential to compete with Indigenous ways of interacting with humans and non-humans. Our analysis also underlines that research with Indigenous people using digital technology in participatory research projects may contribute to this competition rather than empower the Indigenous knowledge system. Based on these findings, we distinguish two ethical directions – co-construction and strong epistemological pluralism – that can be followed to address concerns about the effects of the development of digital technologies on the diversity of knowledge systems in the Arctic, and elsewhere.}
}
@article{FEYAERTS2021784,
title = {Uncovering the realities of delusional experience in schizophrenia: a qualitative phenomenological study in Belgium},
journal = {The Lancet Psychiatry},
volume = {8},
number = {9},
pages = {784-796},
year = {2021},
issn = {2215-0366},
doi = {https://doi.org/10.1016/S2215-0366(21)00196-6},
url = {https://www.sciencedirect.com/science/article/pii/S2215036621001966},
author = {Jasper Feyaerts and Wouter Kusters and Zeno {Van Duppen} and Stijn Vanheule and Inez Myin-Germeys and Louis Sass},
abstract = {Summary
Background
Delusions in schizophrenia are commonly approached as empirical false beliefs about everyday reality. Phenomenological accounts, by contrast, have suggested that delusions are more adequately understood as pertaining to a different kind of reality experience. How this alteration of reality experience should be characterised, which dimensions of experiential life are involved, and whether delusional reality might differ from standard reality in various ways is unclear and little is known about how patients with delusions value and relate to these experiential alterations. This study aimed to investigate the nature of delusional reality experience, and its subjective apprehension, in individuals with lived experience of delusions and a schizophrenia-spectrum diagnosis.
Methods
In this qualitative phenomenological study, we recruited individuals with lived experience of delusions and a schizophrenia-spectrum diagnosis from two psychiatric-hospital services in Belgium using homogenous sampling. Criteria for participation were having undergone at least one psychotic episode with occurring delusional symptoms, present at least 1 year before participation, on the basis of clinical notes assessed by the attending psychiatrist; a schizophrenia-spectrum diagnosis, ascertained through clinical interview by the attending psychiatrist upon admission; being aged between 18 years and 65 years; and having the capacity to give informed consent. Exclusion criteria included worries concerning capacity to consent and risk of distress caused by participation. We did phenomenologically driven semi-structured interviews with the participants to explore the nature of delusional reality experience and their subjective valuation of these experiences. We used interpretative phenomenological analysis, a qualitative method tailored to the in-depth exploration of participants' first-person perspective, to analyse their accounts.
Findings
Between March 2, 2020, and Sept 30, 2020, 18 adults (13 men and five women, aged 19–62 years) participated in the interview study. The findings suggest that delusions are often embedded in wide-ranging alterations of basic reality experience, involving quasi-ineffable atmospheric and ontological qualities that undermine participants' sense of the world as unambiguously real, fully present, and shared with others. We also found that delusional reality experience can differ from standard reality in various ways (ie, in a hypo-real and hyper-real form), across multiple dimensions (eg, meaningfulness, necessity and contingency, and detachment and engagement), and that participants are often implicitly or explicitly aware of the distinction between delusional and standard reality. Delusional experience can have an enduring value and meaning that is not fully captured by a strictly medical perspective.
Interpretation
Increased awareness and recognition of the distinctive nature of delusional reality experience, in both clinical and research settings, can improve diagnostic accuracy, explanatory models, and therapeutic support for individuals with delusions whose lived realities are not always evident from an everyday perspective.
Funding
FWO Flanders.
Translation
For the Dutch translation of the abstract see Supplementary Materials section.}
}
@article{OUESLATI2020408,
title = {A review of sentiment analysis research in Arabic language},
journal = {Future Generation Computer Systems},
volume = {112},
pages = {408-430},
year = {2020},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2020.05.034},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X19311537},
author = {Oumaima Oueslati and Erik Cambria and Moez Ben HajHmida and Habib Ounelli},
keywords = {Arabic sentiment analysis, Arabic sentiments resources, Arabic dialects},
abstract = {Sentiment analysis is a task of natural language processing that has recently attracted increasing attention. However, sentiment analysis research has mainly been carried out for the English language. Although Arabic is ramping up as one of the most used languages on the Internet, only a few studies have focused on Arabic sentiment analysis so far. In this paper, we carry out an in-depth qualitative study of the most important research works in this context by discussing strengths and limitations of existing approaches. In particular, we survey both approaches that leverage machine translation or transfer learning to adapt English resources to Arabic and approaches that stem directly from the Arabic language.}
}
@article{LI2025107412,
title = {Key genes linking gut microbiota, immune cells, and osteoporosis: A multi-omics approach},
journal = {Microbial Pathogenesis},
volume = {202},
pages = {107412},
year = {2025},
issn = {0882-4010},
doi = {https://doi.org/10.1016/j.micpath.2025.107412},
url = {https://www.sciencedirect.com/science/article/pii/S0882401025001378},
author = {Qiuwei Li and Ruocheng Guo and Zuomeng Wu and Chenhao Zhao and Cailiang Shen},
keywords = {Gut microbiota, Immune cell, Glyoxylate cycle, HLA DR on HSC, Single-cell RNA sequencing},
abstract = {Background
Osteoporosis, a debilitating condition characterized by decreased bone mass and increased fracture risk, requires novel insights into its molecular mechanisms for improved therapeutic approaches. In this study, we comprehensively explore the causal links between gut microbiota, immune cell regulation, and osteoporosis by integrating Mendelian randomization (MR), single-cell RNA sequencing (scRNA-seq), and bioinformatics analyses.
Methods
We employed a two-sample MR approach to investigate the causal associations between 412 gut microbiota species and two osteoporosis traits using data from the UK Biobank and Finnish cohorts. Additionally, 731 immune cell types were analyzed as potential mediators between the gut microbiota and osteoporosis. Bioinformatics analysis, including gene ontology (GO) and KEGG pathway enrichment, was used to assess the functional implications of differentially expressed genes. ScRNA-seq from publicly available datasets was conducted to profile the expression of key genes, including USP6NL, SELENOT, and TAF1A, in osteoporotic and control samples.
Results
The MR analysis identified significant causal relationships between the gut microbiota (notably the glyoxylate cycle) and osteoporosis outcomes. Furthermore, HLA-DR expression on hematopoietic stem cells (HSCs) was identified as a crucial immune cell mediator between the gut microbiota and osteoporosis, highlighting the immune-microbiota-bone axis. Differential expression analysis from scRNA-seq confirmed the upregulation of USP6NL, SELENOT, and TAF1A in osteoporotic samples. Functional enrichment analysis revealed that these genes play significant roles in pathways related to oxidative stress, calcium homeostasis, and immune modulation. These findings were validated through GTEX data integration, identifying USP6NL, SELENOT, and TAF1A as potential therapeutic targets for osteoporosis.
Conclusions
This study provides novel insights into the interplay between gut microbiota, immune regulation, and bone metabolism in osteoporosis. The integration of Mendelian randomization, single-cell RNA sequencing, and bioinformatics analyses uncovers USP6NL, SELENOT, and TAF1A as key mediators and potential therapeutic targets in osteoporosis. These findings open up new avenues for personalized treatment strategies targeting the gut-immune-bone axis in osteoporosis management.}
}
@article{BUNNELL2020113306,
title = {FinPathlight: Framework for an multiagent recommender system designed to increase consumer financial capability},
journal = {Decision Support Systems},
volume = {134},
pages = {113306},
year = {2020},
issn = {0167-9236},
doi = {https://doi.org/10.1016/j.dss.2020.113306},
url = {https://www.sciencedirect.com/science/article/pii/S0167923620300610},
author = {Lawrence Bunnell and Kweku-Muata Osei-Bryson and Victoria Y. Yoon},
keywords = {Knowledge-based recommender systems, Ontology-based recommendation agents, Multiagent systems, Financial capability, Consumer finance, Financial planning},
abstract = {In consideration of the general lack of trust in human professional financial advisors due to conflicts of interest, and given inadequacies in terms of the utility of FinTech alternatives for financial goal recommendations, this study establishes a framework for an ontology-based, multiagent recommender system designed to improve financial capability through the recommendation of financial goals, called FinPathlight. The FinPathlight framework provides an architecture for a personal financial recommender system designed to identify and recommend specific, achievable financial goals appropriate to a wide range of financially situated users. This framework contributes principles of implementation for a novel financial technology (FinTech) application aimed at addressing a pervasive lack of trust surrounding traditional financial advisory services, as well as utility inadequacies within the current landscape for FinTech applications, providing a comprehensive set of practical and explicit financial goal recommendations. Considering the importance of users' adoption of an innovation, this study empirically tests its utility in terms of trust and perceived usefulness. The experimental evaluation results show that an application built using this framework would likely be perceived as trustworthy and useful to users for identification and selection of financial capability enhancing objectives.}
}
@article{LIANG2025578570,
title = {Bioinformatics exploration of SPHKAP's role in IDH-mutant glioma involving energy metabolism, prognosis, and immune modulation},
journal = {Journal of Neuroimmunology},
volume = {402},
pages = {578570},
year = {2025},
issn = {0165-5728},
doi = {https://doi.org/10.1016/j.jneuroim.2025.578570},
url = {https://www.sciencedirect.com/science/article/pii/S0165572825000505},
author = {Xi Liang and Shi Tan and Yuecheng Chen and Cuirong Wei and Zhongqiao Qin},
keywords = {-mutant glioma, , Anti-cancer},
abstract = {Background
The current understanding of glioma pathogenesis is limited by the lack of comprehensive insights into the metabolic reprogramming associated with isocitrate dehydrogenase (IDH) mutations. This study aims to contribute a step to this gap by investigating the role of energy metabolism-related genes in glioma. Our objective is to identify key molecular markers that could serve as prognostic markers and potential therapeutic targets for more effective treatment strategies in IDH-mutant glioma patients.
Methods
We conducted an in-depth analysis of gene expression data from TCGA, CGGA, and GEO databases, employing Weighted Gene Co-expression Network Analysis (WGCNA) and differential gene expression analysis to pinpoint candidate genes. Gene Ontology (GO) and Kyoto Encyclopedia of Genes and Genomes (KEGG) enrichment analyses were performed to elucidate the biological pathways implicated by these genes. Protein-Protein Interaction (PPI) and Gene Multiple Association Network Integration Algorithm (GeneMANIA) networks were constructed to map gene interactions, and survival analysis and Cox regression models were utilized to assess the prognostic value of the identified genes. Additionally, CIBERSORT was used to evaluate immune cell infiltration in the tumor microenvironment.
Results
Our findings identified SPHKAP as a gene significantly downregulated in glioma tissues compared to control samples. Specifically, low SPHKAP expression was associated with a poorer prognosis of patients with IDH-mutant glioma and linked to the expression of key enzymes involved in energy metabolism. Meanwhile, in IDH-mutant gliomas, reduced SPHKAP expression was correlated with increased macrophage infiltration, enhanced T cell response, and upregulation of immune checkpoint genes, highlighting its role as an independent prognostic marker.
Conclusion
This study reveals the differential expression of SPHKAP in glioma, suggesting its potential as a prognostic marker for IDH-mutant gliomas, providing information for future studies aimed at developing targeted therapies for glioma patients.}
}
@article{GACHKAR2025144448,
title = {Text-based algorithms for automating life cycle inventory analysis in building sector life cycle assessment studies},
journal = {Journal of Cleaner Production},
volume = {486},
pages = {144448},
year = {2025},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2024.144448},
url = {https://www.sciencedirect.com/science/article/pii/S0959652624038976},
author = {Sadaf Gachkar and Darya Gachkar and Erfan Ghofrani and Antonio {García Martínez} and Cecilio {Angulo Bahón}},
keywords = {Life cycle assessment, Inventory data collection, Text-based algorithms, Sustainability, Artificial intelligence, Natural language processing},
abstract = {Life Cycle Assessment (LCA) is essential for evaluating the environmental impact of sustainable activities in industry. Despite its importance, there exist challenges negatively impacting its deployment, particularly the time-consuming process of gathering inventory data. This research introduces a novel framework that leverages advanced text-based algorithms from Natural Language Processing (NLP), significantly enhancing the efficiency of data collection in LCA studies. Focusing on the inventory phase, the novelty of this research lies in its ability to reduce data collection time by an estimated 80%–90% compared to conventional methods and improve accuracy by directly extracting materials from bills of quantities (BoQs), which usually list all the construction materials. While our methodology shows promise, it faces challenges due to project complexity, particularly the need for consistent terminology between BoQ and reference databases, though future advancements in matching algorithms may enhance our approach’s efficiency. Real-world case studies demonstrate the framework’s effectiveness, offering flexibility across industries and system complexities.}
}
@article{SCHMID2024711,
title = {Concept of hybrid-modelled digital twins for energy optimisation and flexible manufacturing systems for SMEs},
journal = {Procedia CIRP},
volume = {130},
pages = {711-717},
year = {2024},
note = {57th CIRP Conference on Manufacturing Systems 2024 (CMS 2024)},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2024.10.153},
url = {https://www.sciencedirect.com/science/article/pii/S2212827124013106},
author = {Jonas Schmid and Lutz Sommer and Joao Ramos and Xiao Guo},
keywords = {Hybrid Digital Twin, Asset Administration Shell, Manufacturing, Energy Optimisation},
abstract = {Digital twins (DTs) are virtual representations that reproduce the behaviour and characteristics of real manufacturing systems dynamically and in detail by combining information from different data sources. The behaviour is usually represented and digitally mapped by several models at different manufacturing levels, e.g. factory, machine, or process level. Both data-driven and physics-based digital modelling approaches can be used to monitor, analyse, and predict aspects of the corresponding manufacturing system in real time to interact with them and control them optimally. This paper presents a concept for hybrid DTs by intertwining different DT models for energy optimisation and improving the flexibility of manufacturing systems. The approach is based on the Asset Administration Shell (AAS) standard to create Industry 4.0-compliant DTs tailored for small and medium-sized enterprises (SMEs). The concept is applied to a real-world use case in the electronics industry that mainly consists of automated Surface Mount Technology (SMT) Printed-Circuit Boards (PCB) assembly lines.}
}
@article{SHAKED2025103954,
title = {BridgeSec: Facilitating effective communication between security engineering and systems engineering},
journal = {Journal of Information Security and Applications},
volume = {89},
pages = {103954},
year = {2025},
issn = {2214-2126},
doi = {https://doi.org/10.1016/j.jisa.2024.103954},
url = {https://www.sciencedirect.com/science/article/pii/S2214212624002564},
author = {Avi Shaked and Nan Messe},
keywords = {Security by design, Model-driven engineering, System development, Vulnerability management, Threat modelling, Security engineering, Systems engineering},
abstract = {We increasingly rely on systems to perform reliably and securely. Therefore, it is imperative that security aspects are properly considered when designing and maintaining systems. However, achieving the security by design ideal is challenging. Security information is typically unstructured, dispersed, hard to communicate, and its assessment is somewhat subjective and tacit. Additionally, the inclusion of security information within design requires integrating the efforts of two knowledge-intensive disciplines: security engineering and systems engineering. In this paper, we introduce BridgeSec, a novel conceptual information-exchange interface to systemise the communication of security information between these two disciplines. The main contribution of BridgeSec lies in its explicit identification of concepts related to vulnerability management, which allows systems engineering and security engineering teams to codify pertinent information. The disciplines involved in the system design can thus coordinate policies, implementations and, ultimately, the security posture. Furthermore, based on the newly unveiled interface, an automated reasoning mechanism is specified. This mechanism allows to reason about the vulnerability posture of systems in a scalable and systematic way. First, we describe and formalise the information-exchange interface BridgeSecand how it can be used to reason about the security of systems designs. Next, we present an open-source prototype – integrated into a threat modelling tool – which rigorously implements the interface and the reasoning mechanism. Finally, we detail two diverse and prominent applications of the interface for communicating security aspects of systems designs. These applications show how BridgeSec can rigorously support the design of systems’ security in two representative scenarios: in coordinating security features and policy during design, and in coordinating mitigation to disclosed implementation vulnerabilities.}
}
@article{YOU2024102390,
title = {TransLSTD: Augmenting hierarchical disease risk prediction model with time and context awareness via disease clustering},
journal = {Information Systems},
volume = {124},
pages = {102390},
year = {2024},
issn = {0306-4379},
doi = {https://doi.org/10.1016/j.is.2024.102390},
url = {https://www.sciencedirect.com/science/article/pii/S0306437924000486},
author = {Tao You and Qiaodong Dang and Qing Li and Peng Zhang and Guanzhong Wu and Wei Huang},
keywords = {Disease risk prediction, Electronic health records, Disease classification, Interpretability, Data mining},
abstract = {The use of electronic health records has become widespread, providing a valuable source of information for predicting disease risk. While deep neural network models have been proposed and shown to be effective in this task, supplemented with medical domain knowledge for interpretability, several limitations still exist. Firstly, there is often a lack of differentiation between chronic and acute diseases leading to biased modeling of diseases. Secondly, the extraction of patient single-layer temporal patterns is limited, which hinders comprehensive representation and predictive power. Thirdly, weak interpretability based on deep neural networks prevents the extraction of valuable medical knowledge, limiting practical applications. To overcome these challenges, we propose TransLSTD, a hierarchical model that incorporates time awareness and context awareness while distinguishing between long-term and short-term diseases. TransLSTD uses clustering algorithms to classify disease types based on the occurrence feature matrix of diseases from EHR dataset and updates disease representation at the code level while creating patient visit embeddings. The model utilizes query vectors to incorporate visit context information and combines time data to capture the patient’s overall health status. Finally, the prediction module generates outcomes and provides effective interpretations. We demonstrate the effectiveness of TransLSTD using two real-world datasets, outperforming state-of-the-art models in terms of both AUC and F1 values. The data and code are released at https://github.com/DangQD/TransLSTD-master.}
}
@article{TEUNIS2025S29,
title = {S15-01 Building a virtual human for chemical risk assessment from software and data; integrating reproducible research and predictive modelling},
journal = {Toxicology Letters},
volume = {411},
pages = {S29-S30},
year = {2025},
note = {Abstracts of the 59th Congress of the European Societies of Toxicology (EUROTOX 2025) TOXICOLOGY ADDRESSES SOCIETY'S REAL LIFE RISKS FOR SUSTAINABLE HEALTH AND WELL BEING},
issn = {0378-4274},
doi = {https://doi.org/10.1016/j.toxlet.2025.07.091},
url = {https://www.sciencedirect.com/science/article/pii/S0378427425016741},
author = {M. Teunis and E. Willighagen and O. Cinar and M. Martens and M. Klaassen and M. Liem and F. Hepkema and I. Djidrovski and A. Kienhuis and C. Evelo},
abstract = {The ever-increasing scientific body of knowledge on health and disease, together with the ongoing development of innovative in vitro and in silico Non-Animal Methods (NAM), offer opportunities for animal-free safety assessment. To fully leverage the promise of NAMs and at the same time ensure safety, intersectoral and -disciplinary collaborations are necessary. This is explored in the Virtual Human Platform for Safety Assessment project (VHP4Safety). VHP4Safety is a Dutch funded research project that runs from 2021 to 2026 and brings together international partners from 32 organisations representing scientists, industry, regulators, policy makers, clinicians and Non-Animal Methods. During the projects’ Designathons and Hackathons, data scientists, toxicologists and social scholars collaborate: (1) to build a data infrastructure to integrate existing and newly developed data and services at the Virtual Human Platform (VHP), (2) to feed the VHP with toxicological knowledge and NAM data and (3) to implement the VHP taking into account stakeholder perspectives [1]. Here, we will demonstrate how principles of reproducible science are applied throughout the development of the VHP. We will address the most crucial technical solutions to build, test and host the VHP platform, using open science community standards. To build the VHP, an interdiciplinary development team with mixed expertise in bioinformatics, cheminformatics, molecular biology, artificial intelligence, toxicology, statistics and cloud development, work together in short sprints to deliver tangible minimal-viable products. The team has recently adopted an Agile way of working and we will share some insights on the benefits of using such an approach above the more classical ‘waterfall’ project stucture. The VHP consists of artifacts being: software, models, documentation, standard operating procedures, workflows and data. In this presentation we will dive into how we are structuring these artifacts to form a coherent and user-friendly platform that can be used to address chemical risk-assessment questions. The VHP design and implementation is revolving around three specific case-studies: thyroid toxicity, kidney toxicity and neuro-toxicity. These case studies guide the direction of the platform development and are aimed at showcasing its capabilities. We will focus on how we are generating a sustainable platform in terms of reuse and the ability to further the develop the VHP after project end. We will showcase specific technologies that are geared towards sharing all the artifacts in the platform in a reproducible and consistent manner. The VHP4Safety project is funded by the Netherlands Research Council (NWO) Netherlands Research Agenda: Research on Routes by Consortia (NWA-ORC 1292.19.272).}
}
@article{LEFF2021100844,
title = {Expanding feminist affective atmospheres},
journal = {Emotion, Space and Society},
volume = {41},
pages = {100844},
year = {2021},
issn = {1755-4586},
doi = {https://doi.org/10.1016/j.emospa.2021.100844},
url = {https://www.sciencedirect.com/science/article/pii/S1755458621000827},
author = {Jack R. Leff},
keywords = {Affective atmospheres, Affect theory, Feminist theory, Breathing, Porosity},
abstract = {Atmospheres are increasingly used as a metaphor for thinking about worldly relations and the life-making projects contained therein. Picking up on this phenomenon, geographer Ben Anderson helpfully develops the term “affective atmospheres” into a tool for mapping affectively charged spaces (Anderson, 2009). While Anderson's affective atmosphere is useful for examining the ways in which the excessive nature of affective atmospheres create space and time, this paper seeks to expand on the critical implications of the term and embed feminist considerations of how atmospheres are felt unevenly. Taking advantage of the porous ontology of the body, affective atmospheres have the potential to reinforce social inequity or build coalitions of resistance. The histories we carry with us mingle with the material composition of atmosphere in ways that we need critical feminist analysis to grapple with. Building from existing literature on breath, breathing, and atmosphere, I blend Anderson's formulation of affective atmospheres with ongoing debates within feminist theories of affect in order to produce an account of how affective atmospheres can help us navigate political worlds.}
}
@article{QIN2024457,
title = {Towards machine-readable semantic-based E-business contract representations using Network of Timed Automata (NTA)},
journal = {Future Generation Computer Systems},
volume = {158},
pages = {457-471},
year = {2024},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2024.04.040},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X24001699},
author = {Peng Qin and Quanyi Hu and Menglin Cui},
keywords = {E-business, Smart contract, Semantic analysis, Information processing, Knowledge engineering},
abstract = {The smart contract is generally stored and executed by a computer program in the blockchain platform. However, the representation of program code is unfriendly for non-software developers since the process of a smart contract involves multiple parties such as lawyers, which is not easy to understand for most humans. To consider a broad acceptance of contracts, we design a novel contract representation to narrow the gap between smart contracts and e-business contracts. This paper proposes a novel semantic-based e-business contract model - Simple Natural Contract (SimNC) to represent a universal contract created by a Supervised Sentence Contract (SSC), which is inputted via a Semantic Input Method (SIM) with strict grammar from a human-understandable natural language contract. Then, the SSC is analyzed through Machine Natural Language (MNL) to enhance contract semantic understanding by enabling case grammar for crossing language parties. In doing so, SimNC analyses various deontic components, and combines them with the operational aspects of a legal contract, to achieve a common and better understanding between hard-code and natural language. In addition, we apply the SimNC into a Network of Timed Automata (NTA) for supporting automation, which builds a formal model including temporal constraints and then translates into an executable SimNC-NTA model. This paper aims to provide a bridge between natural language contracts and e-business contracts, making them universal and intelligible.}
}
@article{ZHANG2023104540,
title = {Transformer-based approach for automated context-aware IFC-regulation semantic information alignment},
journal = {Automation in Construction},
volume = {145},
pages = {104540},
year = {2023},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2022.104540},
url = {https://www.sciencedirect.com/science/article/pii/S0926580522004113},
author = {Ruichuan Zhang and Nora El-Gohary},
keywords = {Information alignment, Automated code checking, Building codes, Building information modeling, Industry foundation classes, Deep learning, Transformers},
abstract = {One of the main challenges of automated compliance checking systems is aligning the semantics of the building information models (BIMs), in Industry Foundation Classes (IFC) format, and the semantics of the regulations, in natural language, to allow for checking the compliance of the BIM with the regulations. Existing information alignment methods typically require intensive manual effort and their ability to deal with the complex regulatory concepts in the regulations is limited. To address this gap, this paper proposes a deep learning method for IFC-regulation semantic information alignment. The proposed method uses a relation classification model to relate and align the IFC and regulatory concepts. The method uses a transformer-based model and leverages the definitions of the concepts and an IFC knowledge graph to provide additional contextual information and knowledge for improved classification and alignment. The proposed method was evaluated on IFC concepts from IFC 4 and regulatory concepts from different building codes and standards. The experimental results showed good information alignment performance.}
}
@article{DOUMBOUYA201816,
title = {Argumentation graphs with constraint-based reasoning for collaborative expertise},
journal = {Future Generation Computer Systems},
volume = {81},
pages = {16-29},
year = {2018},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2017.09.081},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X17311706},
author = {Mamadou Bilo Doumbouya and Bernard Kamsu-Foguem and Hugues Kenfack and Clovis Foguem},
keywords = {Argumentation theory, Decision making, Conceptual graphs, Inconsistencies, Weighting, Medical deontology},
abstract = {Collaborative processes are very important in telemedicine domain since they allow for making right decisions in complex situations with multidisciplinary staff. When modelling these collaborative processes, some inconsistencies can appear. In semantic modelling (conceptual graphs), these inconsistencies are verified using constraints. In this work, collaborative processes are represented using an argumentation system modelled in a conceptual graph formalism where inconsistencies could be particular bad attack relation between arguments. To overcome these inconsistencies, two solutions are proposed. The first one is to weight the arguments evolving in the argumentation system on the basis of the competencies of the health professionals and the credibility of the sources justifying their advice (arguments), and the second one is to model some law concepts as constraints in order to check their compliance of the collaborative process.}
}
@incollection{CANNATARO20251,
title = {Introduction to Methods section},
editor = {Shoba Ranganathan and Mario Cannataro and Asif M. Khan},
booktitle = {Encyclopedia of Bioinformatics and Computational Biology (Second Edition)},
publisher = {Elsevier},
edition = {Second Edition},
address = {Oxford},
pages = {1-2},
year = {2025},
isbn = {978-0-323-95503-4},
doi = {https://doi.org/10.1016/B978-0-323-95502-7.00377-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780323955027003778},
author = {Mario Cannataro},
abstract = {The Methods section presents the theoretical methodologies underpinning bioinformatics and computational biology. The section includes 14 subsections that present basic and advanced computer science methods, biological data models as well as specialized bioinformatics methods. It describes well-established bioinformatics methods as well as novel data analysis methods, including data science and artificial intelligence methods. The section is completed by two subsections dedicated to recent advances in epidemiology and pandemic surveillance and in bioimage analytics.}
}
@article{SABATUCCI2023101845,
title = {A model for automatic selection of IoT services in ambient assisted living for the elderly},
journal = {Pervasive and Mobile Computing},
volume = {95},
pages = {101845},
year = {2023},
issn = {1574-1192},
doi = {https://doi.org/10.1016/j.pmcj.2023.101845},
url = {https://www.sciencedirect.com/science/article/pii/S1574119223001037},
author = {Luca Sabatucci and Massimo Cossentino and Claudia {Di Napoli} and Angelo Susi},
keywords = {Model at run-time, Reasoning, AAL},
abstract = {Context:
Engineering Ambient Assisted Living applications for the elderly is challenging due to the diversity and rapid changes of both end users’ needs and technological environment equipment.
Objective:
Assistive applications can be provided as combinations of functionalities provided by IoT devices. With the pervasive availability of functionally equivalent IoT devices, they should be selected according to the specific deployment context in terms of user needs and conditions, device availability, and regulations when the operative context dynamic conditions can be set. Such selection is the objective of this work.
Methods:
We rely on a conceptual framework for self-adaptation as the enabler for a run-time decision-making process. It allows for representing relations among IoT devices, the functionalities they deliver, and the different modalities these functionalities are provided with in terms of goals, devices, and norms. The framework is based on three fundamental principles: (1) high-level abstractions separating the expected functionality, how it can be delivered, and who is responsible for its delivery; (2) AAL applications as the run-time composition of atomic functionalities; (3) centrality of the user in the system.
Result:
The Device-Goal-Norm framework is proposed to specify diagrams for different AAL applications, together with the semantics to transform these diagrams into run-time models. We also provide a running implementation of a run-time model based on the belief–desire–intention paradigm.}
}
@article{ADITYA201833,
title = {Image Understanding using vision and reasoning through Scene Description Graph},
journal = {Computer Vision and Image Understanding},
volume = {173},
pages = {33-45},
year = {2018},
issn = {1077-3142},
doi = {https://doi.org/10.1016/j.cviu.2017.12.004},
url = {https://www.sciencedirect.com/science/article/pii/S1077314217302291},
author = {Somak Aditya and Yezhou Yang and Chitta Baral and Yiannis Aloimonos and Cornelia Fermüller},
keywords = {Image Understanding, Commonsense Reasoning, Vision, Reasoning},
abstract = {Two of the fundamental tasks in image understanding using text are caption generation and visual question answering (Antol et al., 2015; Xiong et al., 2016). This work presents an intermediate knowledge structure that can be used for both tasks to obtain increased interpretability. We call this knowledge structure Scene Description Graph (SDG), as it is a directed labeled graph, representing objects, actions, regions, as well as their attributes, along with inferred concepts and semantic (from KM-Ontology (Clark et al., 2004)), ontological (i.e. superclass, hasProperty), and spatial relations. Thereby a general architecture is proposed in which a system can represent both the content and underlying concepts of an image using an SDG. The architecture is implemented using generic visual recognition techniques and commonsense reasoning to extract graphs from images. The utility of the generated SDGs is demonstrated in the applications of image captioning, image retrieval, and through examples in visual question answering. The experiments in this work show that the extracted graphs capture syntactic and semantic content of images with reasonable accuracy.}
}
@article{ZHANG2025127429,
title = {Research on constructing and reasoning the collision knowledge graph of autonomous navigation ship based on enhanced BERT model},
journal = {Expert Systems with Applications},
volume = {278},
pages = {127429},
year = {2025},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2025.127429},
url = {https://www.sciencedirect.com/science/article/pii/S0957417425010516},
author = {Zizhao Zhang and Xinyue Yang and Liping Sun and Yu Sun and Jichuan Kang},
keywords = {Named entity recognition, Collision accident, Autonomous navigation ship, Bidirectional encoder representations from transformers model, Knowledge graph reasoning},
abstract = {This study proposes a Lexicon-enhanced BERT model (LEBERT) to enhance the analysis of autonomous ship collisions, addressing the challenges posed by limited annotated data and imbalanced entity type distribution. The LEBERT model integrates character-level and lexicon-level semantics through a Lexicon Adapter module and employs a span-based decoding approach to supplant traditional Conditional Random Fields (CRF). The experimental findings, drawn from an analysis of 257 accident reports, demonstrate that the proposed model attains an F1-score of 0.711, signifying enhancements of 2.3% and 21.3% over baseline models in the domains of general and long-entity recognition, respectively. The impact of entity label granularity on model performance was further explored, confirming that enhanced granularity greatly improves prediction accuracy and clustering consistency. Utilizing the entity prediction results derived from 60 accident cases, a novel conversion framework was developed that translates human error factors identified in conventional maritime analyses into failure modes applicable to autonomous ship systems. Through the selection of causal factors and the reconfiguration of case labels, a specialized knowledge graph tailored for autonomous navigation was developed. The knowledge graph incorporates advanced BERT-based reasoning within a multimodal data framework, thereby enabling the extraction of entities from unstructured text and supporting the development of scalable domain knowledge repositories. This study proposes a series of concepts relating to the implementation of knowledge graphs in the domain of autonomous navigation ships.}
}
@article{JIMENEZ2025104909,
title = {Embodied knowing: Toward a teacher education pedagogy of relational witnessing},
journal = {Teaching and Teacher Education},
volume = {155},
pages = {104909},
year = {2025},
issn = {0742-051X},
doi = {https://doi.org/10.1016/j.tate.2024.104909},
url = {https://www.sciencedirect.com/science/article/pii/S0742051X24004426},
author = {Justin Phillip Jiménez and Mistilina Sato and Jake Knaus and Amanda C. Shopa and Margaret Smith-Peterson},
keywords = {Embodied knowledge, Teacher education, Teaching dispositions, Equity, Witnessing, Embodied knowing},
abstract = {This paper introduces a model for teacher education that gives shape and meaning to witnessing one's own reactions to and development of equity-based teaching. Data from a school-based teacher inquiry group provide two illustrations of how the model, based on a conceptual framework from feminist ethics, can be used to guide relational witnessing for teachers who are striving toward equity-based practice. We conclude with recommendations for understanding and mobilizing embodied encounters in teacher education toward a pedagogy of relational witnessing for teacher education with a focus on bringing dysconscious assumptions to the surface through the use of dispositional language.}
}
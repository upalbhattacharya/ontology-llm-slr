@article{STOREY2025102480,
title = {Large language models for conceptual modeling: Assessment and application potential},
journal = {Data & Knowledge Engineering},
volume = {160},
pages = {102480},
year = {2025},
issn = {0169-023X},
doi = {https://doi.org/10.1016/j.datak.2025.102480},
url = {https://www.sciencedirect.com/science/article/pii/S0169023X25000758},
author = {Veda C. Storey and Oscar Pastor and Giancarlo Guizzardi and Stephen W. Liddle and Wolfgang Maaß and Jeffrey Parsons and Jolita Ralyté and Maribel Yasmina Santos},
keywords = {Conceptual modeling, Large language models, Artificial intelligence, Semantics},
abstract = {Large Language Models (LLMs) are being rapidly adopted for many activities in organizations, business, and education. Included in their applications are capabilities to generate text, code, and models. This leads to questions about their potential role in the conceptual modeling part of information systems development. This paper reports on a panel presented at the 43rd International Conference on Conceptual Modeling where researchers discussed the current and potential role of LLMs in conceptual modeling. The panelists discussed applications and interest levels and expressed both optimism and caution in the adoption of LLMs. Suggested is a need for much continued research by the conceptual modeling community on LLM development and their role in research and teaching.}
}
@article{SIEBRA2022109152,
title = {Engineering uncertain time for its practical integration in ontologies},
journal = {Knowledge-Based Systems},
volume = {251},
pages = {109152},
year = {2022},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2022.109152},
url = {https://www.sciencedirect.com/science/article/pii/S095070512200572X},
author = {Clauirton A. Siebra and Katarzyna Wac},
keywords = {Ontology design, Rule-based processing, Uncertainty, Temporal logic},
abstract = {Ontologies are commonly used as a strategy for knowledge representation. However, they are still presenting limitations to model domains that require broad forms of temporal reasoning. This study is part of the Onto-mQoL project and was motivated by the real need to extend static ontologies with diverse time concepts, relations and properties, which go beyond the commonly used Allen’s Interval Algebra. Therefore, we use the n-ary relations as the basis for temporal structures, which minimally modify the original ontology, and extend these structures with a generic set of time concepts (moments and intervals), time concept properties (precise and uncertain), time relations (interval–interval, interval–moment, and moment–moment), and time relation properties (qualitative and quantitative). We divided the scientific contribution of this study into three parts. Firstly, we present the ontological temporal model (classes and properties) and how it is integrated into static ontologies. Secondly, we discuss the creation of axioms that give the semantics for precise temporal elements. Finally, as our main contribution, these ideas are extended with axioms for uncertain time. All these elements follow the Ontology Web Language (OWL) standards, so this proposal is still compatible with the main ontology editors and reasoners currently available. A case example demonstrates the use of this approach in the nutrition assessment domain.}
}
@article{KELLNER2025104097,
title = {Mineral extraction on Indigenous land: employing a relational approach to navigate the convergence of Indigenous and other ontologies and practices},
journal = {Energy Research & Social Science},
volume = {125},
pages = {104097},
year = {2025},
issn = {2214-6296},
doi = {https://doi.org/10.1016/j.erss.2025.104097},
url = {https://www.sciencedirect.com/science/article/pii/S2214629625001781},
author = {Elke Kellner},
keywords = {Energy transition, Mineral extraction, Justice, Indigenous communities, Sustainable development, Climate change mitigation.},
abstract = {The transition to low-carbon technologies, essential for energy transition, significantly increases the demand for minerals, with projections indicating a sixfold rise by 2040. A substantial portion of these minerals is located on Indigenous lands, placing policymakers in (1) a governance paradox between rapid mineral extraction and the protection of Indigenous rights and (2) a justice paradox between respecting Indigenous self-determination—including the right to reject mining—versus accelerating the energy transition to prevent broader climate injustices. This perspective explores how a relational approach can help navigate the convergence of Indigenous and other ontologies and practices to address justice issues in mineral extraction. It contrasts the holistic, relational worldview of Indigenous peoples with the resource-centered, extractive logic embedded in the governance approaches of many mining companies and governments. The environmental, social, and cultural impacts of mineral extraction on Indigenous lands are discussed, revealing that Indigenous communities bear disproportionate negative consequences despite their minimal contribution to carbon emissions. The paper proposes a paradigm shift towards a process-relational framework that acknowledges Indigenous ways of knowing, being, and relating to land. This framework aims to enhance procedural, distributive, recognitional, and epistemic justice in mineral extraction and promote new governance approaches. This perspective aims to support a more just and sustainable energy transition that respects Indigenous ontologies and practices and constitutes a start towards a broader political movement of decolonization.}
}
@article{THOMSEN2025113594,
title = {Ontology-based Digital Twins for informed decision-making: Scenario testing and optimization in hospital building operations},
journal = {Journal of Building Engineering},
volume = {112},
pages = {113594},
year = {2025},
issn = {2352-7102},
doi = {https://doi.org/10.1016/j.jobe.2025.113594},
url = {https://www.sciencedirect.com/science/article/pii/S2352710225018315},
author = {August M.S. Thomsen and Jakob Bjørnskov and Muhyiddine Jradi},
keywords = {Digital Twin, Scenario testing, Hospital building case study, Building operation optimization, Building simulation, Occupant-centered KPIs},
abstract = {With the increasing urgency to achieve ambitious energy reduction targets in both existing and newly constructed buildings, Digital Twins have emerged as a transformative solution for optimizing building operations. By enabling data-driven decision-making, these virtual replicas help minimize energy waste while enhancing occupant comfort and overall building performance. This study explores the potential of ontology-based Digital Twins by demonstrating their scenario implementation and testing capabilities. A case study is conducted on a hospital building, which includes 12 conditioned thermal zones and an integrated HVAC system. The scenario development is performed by employing three strategy complexity levels: Flexible strategies, Rule-based strategies, and Preheating strategies. The scenarios are evaluated using occupant-centered KPIs for indoor comfort while determining energy consumption and cost of operation. The main aim is to limit thermal discomfort while maintaining a energy consumption. Different alternatives for lowering thermal discomfort are evaluated, providing building operators with the possibility of informed decision-making. By increasing CO2 setpoints in each thermal zone while increasing the heating setpoints in all spaces, the thermal discomfort was lowered by 82% and related monetary energy costs by 22.7%. By increasing the supplied air temperature, the thermal discomfort decreased by 98%; however, this strategy resulted in a 129.7% increase in monetary energy costs. Preheating strategies proved relevant, lowering thermal discomfort by 15%, and ensuring air quality while marginally decreasing consumption and cost. The proposed work demonstrates how ontology-based digital twins can be used for informed decision-making by implementing and testing various operation scenarios as a service.}
}
@article{AKREMI20243512,
title = {Hyperbolic Geometry Embedding for Complex Ontology Matching},
journal = {Procedia Computer Science},
volume = {246},
pages = {3512-3521},
year = {2024},
note = {28th International Conference on Knowledge Based and Intelligent information and Engineering Systems (KES 2024)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.09.205},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924022208},
author = {Houda Akremi and Mouhamed Gaith Ayadi and Sami Zghal},
keywords = {Ontology, Complex matching, Similarity, Hyperbolic geometry embedding},
abstract = {Complex matching ontology involves measuring the distance between ontological elements. The objective of complex matching ontology is to locate semantically equivalent concepts in two ontologies. The main focus of current complex matching methods is on capturing features related to terminological, structural, and contextual semantics in ontologies. The features of based techniques are intensive but also neglect the hidden semantic relations in ontologies. In this study, we introduce a complex matching ontology model based on hyperbolic geometry embedding. We examine the Hyperbolic geometry embedding for measuring similarity between ontologies, and discovering complex matchings between elements. Our experiments with the Ontology Alignment Evaluation Initiative (OAEI) achieved competitive results compared to the leading systems.}
}
@article{FERNANDEZIZQUIERDO202289,
title = {Ontology verification testing using lexico-syntactic patterns},
journal = {Information Sciences},
volume = {582},
pages = {89-113},
year = {2022},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2021.09.011},
url = {https://www.sciencedirect.com/science/article/pii/S0020025521009324},
author = {Alba Fernández-Izquierdo and Raul García-Castro},
keywords = {Ontology testing, Ontology verification, Ontology requirements},
abstract = {Ontology verification refers to the activity where an ontology is tested against its ontology requirements to ensure that it is built correctly in compliance with its ontology requirements specification. Therefore, it is an important activity that should be performed in any ontology development process. Since manual verification can be a time-consuming and repetitive task, testing processes to automatically verify an ontology facilitate this activity. Moreover, the involvement of not only ontology engineers during the ontology verification process, but also domain experts and users, can provide valuable feedback to avoid misunderstandings and lack of information. This paper proposes a method for ontology verification that defines the testing activities to be performed. The method uses a testing language based on lexico-syntactic patterns to facilitate the definition of tests and an ontology to store and publish such tests. Moreover, this verification testing method proposes an online tool to execute tests on one or more ontologies. The method was compared in terms of time and errors by user evaluation with other tools for ontology verification; the evaluation showed that the tools that use testing languages had better results in terms of reducing errors in the verification activity compared to the tools that do not.}
}
@article{PEDRO2024105597,
title = {Learning from construction accidents in virtual reality with an ontology-enabled framework},
journal = {Automation in Construction},
volume = {166},
pages = {105597},
year = {2024},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2024.105597},
url = {https://www.sciencedirect.com/science/article/pii/S0926580524003339},
author = {Akeem Pedro and Quy Lan Bao and Rahat Hussain and Mehrtash Soltani and Hai Chien Pham and Chansik Park},
keywords = {Construction safety, Virtual reality, Ontology, Game engine, Learning from accidents},
abstract = {Learning from accidents is essential in preventing their recurrence; however, the unstructured nature of construction accident data poses a significant challenge to the retrieval of insightful information from past incidents. The absence of engaging training tools that facilitate access to such information also impedes learning. This paper aims to develop an ontology-enabled Virtual Reality (VR) framework to provide access to incident data in immersive educational settings. The framework comprises three modules: 1) Ontology module for structuring information from accidents; 2) VR module for interactive learning based on accident cases; and 3) Semantic enrichment module for embedding accident information in VR scenarios. A prototype was developed to verify the frameworks' technical feasibility, usability, and educational potential. User trials confirm that the solution offers a promising medium for learning from accidents. It is anticipated that the framework would enhance practices for learning from accidents and contribute to improved safety outcomes in construction.}
}
@article{MAJEED2023601,
title = {Ontology-Based Crime News Semantic Retrieval System},
journal = {Computers, Materials and Continua},
volume = {77},
number = {1},
pages = {601-614},
year = {2023},
issn = {1546-2218},
doi = {https://doi.org/10.32604/cmc.2023.036074},
url = {https://www.sciencedirect.com/science/article/pii/S1546221823000887},
author = {Fiaz Majeed and Afzaal Ahmad and Muhammad Awais Hassan and Muhammad Shafiq and Jin-Ghoo Choi and Habib Hamam},
keywords = {Web 3.0, crime ontology, semantic web, knowledge representation},
abstract = {Every day, the media reports tons of crimes that are considered by a large number of users and accumulate on a regular basis. Crime news exists on the Internet in unstructured formats such as books, websites, documents, and journals. From such homogeneous data, it is very challenging to extract relevant information which is a time-consuming and critical task for the public and law enforcement agencies. Keyword-based Information Retrieval (IR) systems rely on statistics to retrieve results, making it difficult to obtain relevant results. They are unable to understand the user's query and thus face word mismatches due to context changes and the inevitable semantics of a given word. Therefore, such datasets need to be organized in a structured configuration, with the goal of efficiently manipulating the data while respecting the semantics of the data. An ontological semantic IR system is needed that can find the right investigative information and find important clues to solve criminal cases. The semantic system retrieves information in view of the similarity of the semantics among indexed data and user queries. In this paper, we develop an ontology-based semantic IR system that leverages the latest semantic technologies including resource description framework (RDF), semantic protocol and RDF query language (SPARQL), semantic web rule language (SWRL), and web ontology language (OWL). We have conducted two experiments. In the first experiment, we implemented a keyword-based textual IR system using Apache Lucene. In the second experiment, we implemented a semantic system that uses ontology to store the data and retrieve precise results with high accuracy using SPARQL queries. The keyword-based system has filtered results with 51% accuracy, while the semantic system has filtered results with 95% accuracy, leading to significant improvements in the field and opening up new horizons for researchers.}
}
@article{ZHANG202420,
title = {A conceptual model for ancient Chinese ceramics based on metadata and ontology: A case study of collections in the Nankai University Museum},
journal = {Journal of Cultural Heritage},
volume = {66},
pages = {20-36},
year = {2024},
issn = {1296-2074},
doi = {https://doi.org/10.1016/j.culher.2023.10.012},
url = {https://www.sciencedirect.com/science/article/pii/S1296207423002030},
author = {Jingwen Zhang and Tianlin Ren},
keywords = {Ancient Chinese Ceramics, Metadata, Ontology, Information management},
abstract = {In the era of digital information, metadata, and ontology technology have increasingly promoted the information management and utilization of museum collections. As one of the most important collection categories in Chinese and even the world's historical museums, the information management of ancient Chinese ceramics has made some progress, but there are still some shortcomings as well. Based on the current need for the information management and utilization of ancient Chinese ceramics, the article used the ceramics in the Nankai University Museum as research samples, constructing the Metadata of Ancient Chinese Ceramics through the comprehensive analysis, integration, and improvement of existing metadata. Moreover, based on that, the study reused and expanded the CIDOC CRM to establish “the Ontology of Ancient Chinese Ceramics” through Protégé, with 20 pieces of ceramics in the Nankai University Museum being added as instances. Last but not least, the study took the Kang Xi Polychrome Cup with Winter Jasmine as an instance and presented its knowledge map through visualization to demonstrate the structure of “the Ontology of Ancient Chinese Ceramics” more clearly.}
}
@article{DEBELLIS2022432,
title = {From ontology to knowledge graph with agile methods: the case of COVID-19 CODO knowledge graph},
journal = {International Journal of Web Information Systems},
volume = {18},
number = {56},
pages = {432-452},
year = {2022},
issn = {1744-0084},
doi = {https://doi.org/10.1108/IJWIS-03-2022-0047},
url = {https://www.sciencedirect.com/science/article/pii/S1744008422000076},
author = {Michael DeBellis and Biswanath Dutta},
keywords = {Agile, COVID-19, ETL, Health care, Knowledge graph, OWL, SDLC, SPARQL, Protégé, Triplestore, FAIR},
abstract = {Purpose
The purpose of this paper is to describe the CODO ontology (COviD-19 Ontology) that captures epidemiological data about the COVID-19 pandemic in a knowledge graph that follows the FAIR principles. This study took information from spreadsheets and integrated it into a knowledge graph that could be queried with SPARQL and visualized with the Gruff tool in AllegroGraph.
Design/methodology/approach
The knowledge graph was designed with the Web Ontology Language. The methodology was a hybrid approach integrating the YAMO methodology for ontology design and Agile methods to define iterations and approach to requirements, testing and implementation.
Findings
The hybrid approach demonstrated that Agile can bring the same benefits to knowledge graph projects as it has to other projects. The two-person team went from an ontology to a large knowledge graph with approximately 5 M triples in a few months. The authors gathered useful real-world experience on how to most effectively transform “from strings to things.”
Originality/value
This study is the only FAIR model (to the best of the authors’ knowledge) to address epidemiology data for the COVID-19 pandemic. It also brought to light several practical issues that generalize to other studies wishing to go from an ontology to a large knowledge graph. This study is one of the first studies to document how the Agile approach can be used for knowledge graph development.}
}
@article{DAVID2023359,
title = {Deploying OWL ontologies for semantic mediation of mixed-reality interactions for human–robot collaborative assembly},
journal = {Journal of Manufacturing Systems},
volume = {70},
pages = {359-381},
year = {2023},
issn = {0278-6125},
doi = {https://doi.org/10.1016/j.jmsy.2023.07.013},
url = {https://www.sciencedirect.com/science/article/pii/S0278612523001450},
author = {Joe David and Eric Coatanéa and Andrei Lobov},
keywords = {Human–robot collaboration, Mixed reality, Multi-agent systems, OWL ontology, SHACL, Belief–desire–intent, Digital thread},
abstract = {For effective human–robot collaborative assembly, it is paramount to view both robots and humans as autonomous entities in that they can communicate, undertake different roles, and not be bound to pre-planned routines and task sequences. However, with very few exceptions, most of recent research assumes static pre-defined roles during collaboration with centralised architectures devoid of runtime communication that can influence task responsibility and execution. Furthermore, from an information system standpoint, they lack the self-organisation needed to cope with today’s manufacturing landscape that is characterised by product variants. Therefore, this study presents collaborative agents for manufacturing ontology (CAMO), which is an information model based on description logic that maintains a self-organising team network between collaborating human–robot multi-agent system (MAS). CAMO is implemented using the Web Ontology Language (OWL). It models popular notions of net systems and represents the agent, manufacturing, and interaction contexts that accommodate generalisability to different assemblies and agent capabilities. As a novel element, a dynamic consensus-driven collaboration based on parametric validation of semantic representations of agent capabilities via runtime dynamic communication is presented. CAMO is instantiated as agent beliefs in a framework that benefits from real-time dynamic communication with the assembly design environment and incorporates a mixed-reality environment for use by the operator. The employment of web technologies to project scalable notions of intentions via mixed reality is discussed for its novelty from a technology standpoint and as an intention projection mechanism. A case study with a real diesel engine assembly provides appreciable results and demonstrates the feasibility of CAMO and the framework.}
}
@article{XU2021101288,
title = {Ontology and rule-based natural language processing approach for interpreting textual regulations on underground utility infrastructure},
journal = {Advanced Engineering Informatics},
volume = {48},
pages = {101288},
year = {2021},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2021.101288},
url = {https://www.sciencedirect.com/science/article/pii/S1474034621000422},
author = {Xin Xu and Hubo Cai},
keywords = {Ontology, Natural language processing, Pattern-matching rules, Information extraction, Information formalization, Utility regulations},
abstract = {The nation’s massive underground utility infrastructure must comply with a multitude of regulations. The regulatory compliance checking of underground utilities requires an objective and consistent interpretation of the regulations. However, utility regulations contain a variety of domain-specific terms and numerous spatial constraints regarding the location and clearance of underground utilities. It is challenging for the interpreters to understand both the domain and spatial semantics in utility regulations. To address the challenge, this paper adopts an ontology and rule-based Natural Language Processing (NLP) framework to automate the interpretation of utility regulations – the extraction of regulatory information and the subsequent transformation into logic clauses. Two new ontologies have been developed. The urban product ontology (UPO) is domain-specific to model domain concepts and capture domain semantics on top of heterogeneous terminologies in utility regulations. The spatial ontology (SO) consists of two layers of semantics – linguistic spatial expressions and formal spatial relations – for better understanding the spatial language in utility regulations. Pattern-matching rules defined on syntactic features (captured using common NLP techniques) and semantic features (captured using ontologies) were encoded for information extraction. The extracted information elements were then mapped to their semantic correspondences via ontologies and finally transformed into deontic logic (DL) clauses to achieve the semantic and logical formalization. The approach was tested on the spatial configuration-related requirements in utility accommodation policies. Results show it achieves a 98.2% precision and a 94.7% recall in information extraction, a 94.4% precision and a 90.1% recall in semantic formalization, and an 83% accuracy in logical formalization.}
}
@article{CIMA2025100841,
title = {Indistinguishability in controlled query evaluation over prioritized description logic ontologies},
journal = {Journal of Web Semantics},
volume = {84},
pages = {100841},
year = {2025},
issn = {1570-8268},
doi = {https://doi.org/10.1016/j.websem.2024.100841},
url = {https://www.sciencedirect.com/science/article/pii/S1570826824000271},
author = {Gianluca Cima and Domenico Lembo and Lorenzo Marconi and Riccardo Rosati and Domenico Fabio Savo},
keywords = {Description logics, Ontologies, Confidentiality preservation, Query answering, Data complexity},
abstract = {In this paper we study Controlled Query Evaluation (CQE), a declarative approach to privacy-preserving query answering over databases, knowledge bases, and ontologies. CQE is based on the notion of censor, which defines the answers to each query posed to the data/knowledge base. We investigate both semantic and computational properties of CQE in the context of OWL ontologies, and specifically in the description logic DL-LiteR, which underpins the OWL 2 QL profile. In our analysis, we focus on semantics of CQE based on censors (called optimal GA censors) that enjoy the so-called indistinguishability property, analyzing the trade-off between maximizing the amount of data disclosed by query answers and minimizing the computational cost of privacy-preserving query answering. We first study the data complexity of skeptical entailment of unions of conjunctive queries under all the optimal GA censors, showing that the computational cost of query answering in this setting is intractable. To overcome this computational issue, we then define a different semantics for CQE centered around the notion of intersection of all the optimal GA censors. We show that query answering over OWL 2 QL ontologies under the new intersection-based semantics for CQE enjoys tractability and is first-order rewritable, i.e. amenable to be implemented through SQL query rewriting techniques and the use of standard relational database systems; on the other hand, this approach shows limitations in terms of amount of data disclosed. To improve this aspect, we add preferences between ontology predicates to the CQE framework, and identify a semantics under which query answering over OWL 2 QL ontologies maintains the same computational properties of the intersection-based approach without preferences.}
}
@article{FAN2022,
title = {Telehealth System Based on the Ontology Design of a Diabetes Management Pathway Model in China: Development and Usability Study},
journal = {JMIR Medical Informatics},
volume = {10},
number = {12},
year = {2022},
issn = {2291-9694},
doi = {https://doi.org/10.2196/42664},
url = {https://www.sciencedirect.com/science/article/pii/S2291969422000588},
author = {ZhiYuan Fan and LiYuan Cui and Ying Ye and ShouCheng Li and Ning Deng},
keywords = {diabetes, chronic disease management, Chronic Disease Management Pathway, ontology, Semantic Web Rule Language rules, SWRL rules},
abstract = {Background
Diabetes needs to be under control through management and intervention. Management of diabetes through mobile health is a practical approach; however, most diabetes mobile health management systems do not meet expectations, which may be because of the lack of standardized management processes in the systems and the lack of intervention implementation recommendations in the management knowledge base.
Objective
In this study, we aimed to construct a diabetes management care pathway suitable for the actual situation in China to express the diabetes management care pathway using ontology and develop a diabetes closed-loop system based on the construction results of the diabetes management pathway and apply it practically.
Methods
This study proposes a diabetes management care pathway model in which the management process of diabetes is divided into 9 management tasks, and the Diabetes Care Pathway Ontology (DCPO) is constructed to represent the knowledge contained in this pathway model. A telehealth system, which can support the comprehensive management of patients with diabetes while providing active intervention by physicians, was designed and developed based on the DCPO. A retrospective study was performed based on the data records extracted from the system to analyze the usability and treatment effects of the DCPO.
Results
The diabetes management pathway ontology constructed in this study contains 119 newly added classes, 28 object properties, 58 data properties, 81 individuals, 426 axioms, and 192 Semantic Web Rule Language rules. The developed mobile medical system was applied to 272 patients with diabetes. Within 3 months, the average fasting blood glucose of the patients decreased by 1.34 mmol/L (P=.003), and the average 2-hour postprandial blood glucose decreased by 2.63 mmol/L (P=.003); the average systolic and diastolic blood pressures decreased by 11.84 mmHg (P=.02) and 8.8 mmHg (P=.02), respectively. In patients who received physician interventions owing to abnormal attention or low-compliance warnings, the average fasting blood glucose decreased by 2.45 mmol/L (P=.003), and the average 2-hour postprandial blood glucose decreased by 2.89 mmol/L (P=.003) in all patients with diabetes; the average systolic and diastolic blood pressure decreased by 20.06 mmHg (P=.02) and 17.37 mmHg (P=.02), respectively, in patients with both hypertension and diabetes during the 3-month management period.
Conclusions
This study helps guide the timing and content of interactive interventions between physicians and patients and regulates physicians’ medical service behavior. Different management plans are formulated for physicians and patients according to different characteristics to comprehensively manage various cardiovascular risk factors. The application of the DCPO in the diabetes management system can provide effective and adequate management support for patients with diabetes and those with both diabetes and hypertension.}
}
@article{ANCIONE2024105453,
title = {An ontological approach increasing the knowledge about equipment ageing including the effects of current transitions},
journal = {Journal of Loss Prevention in the Process Industries},
volume = {92},
pages = {105453},
year = {2024},
issn = {0950-4230},
doi = {https://doi.org/10.1016/j.jlp.2024.105453},
url = {https://www.sciencedirect.com/science/article/pii/S0950423024002110},
author = {Giuseppa Ancione and Silvia Maria Ansaldi and Paolo Bragatto and Patrizia Agnello and Maria Francesca Milazzo},
keywords = {Equipment ageing, Inspection, Ontology, Digital transition, Energy transition, Deterioration mechanism},
abstract = {Ageing management of critical equipment is essential for major accident hazard prevention. In European Union, the Seveso Directive explicitly refers to equipment ageing and specific procedures and tools have been developed in some countries to verify the adequacy of ageing management plans. Ageing management requires up-to-date knowledge of damage mechanisms, failure rates, and inspection techniques. Although the energy transition is moving towards innovative and low-impact processes, the issue of equipment ageing remains a concern for the future due to several factors as many existing petroleum industries will be kept operating for years and green fuels will partially use existing plants. The use of digital technologies, such as inspection robots and pervasive sensors, is increasing in order to optimize maintenance costs and extend the useful lifetime of critical equipment. This poses challenges for stakeholders in the establishment, control bodies, and competent authorities, which need to effectively manage knowledge in the face of digital and energy transitions. Ontologies represent a fundamental methodology for organizing and integrating information throughout the equipment life cycle. These are beneficial for activities with high cognitive content such as incident analysis, risk assessment, maintenance management, and inspection planning. This work aims to strengthen an ontology for ageing management by making it able to incorporate emerging digital inspection technologies and damage mechanisms related to green fuels; finally, through the developed web-application, the ontology is available to establishment operators and auditors for the evaluation of the adequacy of ageing management.}
}
@article{CUI2024e36936,
title = {Ontology-based inference decision support system for emergency response in tunnel vehicle accidents},
journal = {Heliyon},
volume = {10},
number = {17},
pages = {e36936},
year = {2024},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2024.e36936},
url = {https://www.sciencedirect.com/science/article/pii/S2405844024129672},
author = {Gongyousheng Cui and Yuchun Zhang and Haowen Tao and Xineng Yan and Zihao Liu},
keywords = {Tunnel vehicle accident, Emergency response, Ontology, SWRL, Decision support system},
abstract = {Emergency response plans for tunnel vehicle accidents are crucial to ensure human safety, protect critical infrastructure, and maintain the smooth operation of transportation networks. However, many decision-support systems for emergency responses still rely significantly on predefined response strategies, which may not be sufficiently flexible to manage unexpected or complex incidents. Moreover, existing systems may lack the ability to effectively respond effectively to the impact different emergency scenarios and responses. In this study, semantic web technologies were used to construct a digital decision-support system for emergency responses to tunnel vehicle accidents. A basic digital framework was developed by analysing the knowledge system of the tunnel emergency response, examining its critical elements and intrinsic relationships, and mapping it to the ontology. In addition, the strategies of previous pre-plans are summarised and transformed into semantic rules. Finally, different accident scenarios were modelled to validate the effectiveness of the developed emergency response system.}
}
@article{KOZIOL20203263,
title = {Dealing with Polysemy in the Polish Sign Language Using the OWL Ontology},
journal = {Procedia Computer Science},
volume = {176},
pages = {3263-3272},
year = {2020},
note = {Knowledge-Based and Intelligent Information & Engineering Systems: Proceedings of the 24th International Conference KES2020},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2020.09.122},
url = {https://www.sciencedirect.com/science/article/pii/S1877050920320226},
author = {Wojciech Kozioł and Krzysztof Pancerz and Kazimierz Sikora and Kamil Dudek},
keywords = {Modelling, Polysemy, Polish Sign Language, OWL Ontology},
abstract = {A common problem of natural language processing is synonymy, polysemy, and homonymy. In the paper, we propose to deal with polysemy in the Polish sign language using the knowledge included in the OWL2 ontology created for this purpose. The proposed approach aids the translation process of the Polish sign language into the Polish language by selection from the possible phrases, only those, with the reasonable meaning.}
}
@article{GRISIUTE2024102178,
title = {An ontology-based approach for harmonizing metrics in bike network evaluations},
journal = {Computers, Environment and Urban Systems},
volume = {113},
pages = {102178},
year = {2024},
issn = {0198-9715},
doi = {https://doi.org/10.1016/j.compenvurbsys.2024.102178},
url = {https://www.sciencedirect.com/science/article/pii/S0198971524001078},
author = {Ayda Grisiute and Nina Wiedemann and Pieter Herthogs and Martin Raubal},
keywords = {Active mobility, Multi-criteria evaluation, Standardization, Applied ontology},
abstract = {The urgency to decarbonize the transportation sector has accelerated the adoption of micro-mobility solutions, with cycling network development witnessing remarkable growth. Robust and quantitative evaluation frameworks are needed to evaluate the quality of such developments. While a plethora of bike network evaluation approaches exist, their diversity creates issues of interpretability and comparability due to varying metrics and domain-specific terms. We present three contributions to address these challenges. First, we construct a formal ontology, VeloNEMO, that captures key attributes of evaluation metrics for harmonizing bike network evaluation metrics. Second, we generate a machine-readable knowledge base containing these metrics, enabling meta-analyses and resolving some of the existing terminological discrepancies. Third, we propose recommendations for transparent and comparable metric descriptions across various evaluation approaches, illustrated by exploratory metric selection scenarios for a forthcoming bike network evaluation tool. In summary, our research addresses the need for a structured and shared vocabulary for bike network evaluations. This ontology-based approach aims to improve the coherence of evaluation methods as the field of bike network planning continues to evolve, ultimately supporting decision-making for sustainable transportation planning.}
}
@article{QIU2023105294,
title = {A question answering system based on mineral exploration ontology generation: A deep learning methodology},
journal = {Ore Geology Reviews},
volume = {153},
pages = {105294},
year = {2023},
issn = {0169-1368},
doi = {https://doi.org/10.1016/j.oregeorev.2023.105294},
url = {https://www.sciencedirect.com/science/article/pii/S0169136823000094},
author = {Qinjun Qiu and Miao Tian and Kai Ma and Yong Jian Tan and Liufeng Tao and Zhong Xie},
keywords = {Geological ontology, Question answering, Natural language processing, BERT model, Corpus construction},
abstract = {Mineral exploration reports and documents are a rich data source that contains a large amount of geological environments in which mineral deposits form. Among them, it is difficult to extract the required answers from the large amount of geological data. Despite the availability of search engines and digital databases that can be used to store geological data, users are unable to retrieve the information needed for a specific field in a timely manner. As a result, users usually have to contend with the burden of browsing and filtering information, which can be a time-consuming process. To address this issue, we propose a robust end-to-end approach that can improve the efficiency and effectiveness of retrieving queries related to mineral exploration terms. First, we present an automated workflow for constructing automatic question-and-answer datasets based on the names and definitions in the mineral exploration ontology. The Bidirectional Encoder Representation from Transformers (BERT) model is trained to test the answers generated from the user input question. Finally, a prototype chatbot system based on the WeChat platform and constructed experiments for evaluation is presented. Our proposed method has powerful feature representation and learning capabilities and thus has the potential to be adopted by other specialized fields (especially where a large number of mineral exploration ontologies already exist).}
}
@article{CIROKU2024107997,
title = {Automated multimodal sensemaking: Ontology-based integration of linguistic frames and visual data},
journal = {Computers in Human Behavior},
volume = {150},
pages = {107997},
year = {2024},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2023.107997},
url = {https://www.sciencedirect.com/science/article/pii/S0747563223003485},
author = {Fiorela Ciroku and Stefano {De Giorgis} and Aldo Gangemi and Delfina S. Martinez-Pandiani and Valentina Presutti},
keywords = {Multimodal sensemaking, Ontology engineering, Knowledge graph construction, Frame-based reasoning, Visual and linguistic frames},
abstract = {Frame evocation from visual data is an essential process for multimodal sensemaking, due to the multimodal abstraction provided by frame semantics. However, there is a scarcity of data-driven approaches and tools to automate it. We propose a novel approach for explainable automated multimodal sensemaking by linking linguistic frames to their physical visual occurrences, using ontology-based knowledge engineering techniques. We pair the evocation of linguistic frames from text to visual data as “framal visual manifestations”. We present a deep ontological analysis of the implicit data model of the Visual Genome image dataset, and its formalization in the novel Visual Sense Ontology (VSO). To enhance the multimodal data from this dataset, we introduce a framal knowledge expansion pipeline that extracts and connects linguistic frames – including values and emotions – to images, using multiple linguistic resources for disambiguation. It then introduces the Visual Sense Knowledge Graph (VSKG), a novel resource. VSKG is a queryable knowledge graph that enhances the accessibility and comprehensibility of Visual Genome’s multimodal data, based on SPARQL queries. VSKG includes frame visual evocation data, enabling more advanced forms of explicit reasoning, analysis and sensemaking. Our work represents a significant advancement in the automation of frame evocation and multimodal sense-making, performed in a fully interpretable and transparent way, with potential applications in various fields, including the fields of knowledge representation, computer vision, and natural language processing.}
}
@article{CHANG2024102314,
title = {Exploring technological applications through LDA-based patent mining: A metaverse ontology construction},
journal = {World Patent Information},
volume = {79},
pages = {102314},
year = {2024},
issn = {0172-2190},
doi = {https://doi.org/10.1016/j.wpi.2024.102314},
url = {https://www.sciencedirect.com/science/article/pii/S0172219024000541},
author = {Ai-Che Chang and Jie-Shan Lin},
keywords = {Intellectual property, Ontology, Latent Dirichlet allocation topic modeling, Metaverse, Patent mining},
abstract = {The development of the metaverse ecosystem drives technological innovations and economic benefits, which correlate well with patent technologies. Ontology is crucial for formulating strategies and practices in metaverse technology by providing a clear knowledge map to navigate this complex domain. The proposed methodology aims to discover implicit domain knowledge and construct an ontology, allowing for dynamic and efficient visualization of domain knowledge. Clustering analysis categorizes patent technologies into subdomains, while LDA topic modeling structures knowledge properties into an ontology schema. The study analyzes 1967 metaverse technology patents granted between 2020 and 2022 from the InnovationQ Plus database. The research confirms that metaverse ecosystems encompass multiple international patent classifications (IPCs) and the three advanced technology clusters (i.e., immersive technology, AI-based computing networks, and financial security authentication) with their topics. Recent metaverse patent trends highlight applications in autonomous vehicles, entertainment and advertising, and privacy/security protections. This method is applicable for tracking technology trends across various domains.}
}
@article{BATISTA2022102012,
title = {Ontologically correct taxonomies by construction},
journal = {Data & Knowledge Engineering},
volume = {139},
pages = {102012},
year = {2022},
issn = {0169-023X},
doi = {https://doi.org/10.1016/j.datak.2022.102012},
url = {https://www.sciencedirect.com/science/article/pii/S0169023X22000246},
author = {Jeferson O. Batista and João Paulo A. Almeida and Eduardo Zambon and Giancarlo Guizzardi},
keywords = {Taxonomies, Conceptual modeling, Ontologies, Graph grammars, Correctness by construction},
abstract = {Taxonomies play a central role in conceptual domain modeling, having a direct impact in areas such as knowledge representation, ontology engineering, and software engineering, as well as knowledge organization in information sciences. Despite this, there is little guidance on how to build high-quality taxonomies, with notable exceptions being the OntoClean methodology, and the ontology-driven conceptual modeling language OntoUML. These techniques take into account the ontological meta-properties of types to establish well-founded rules on the formation of taxonomic structures. In this paper, we show how to leverage the formal rules underlying these techniques in order to build taxonomies which are correct by construction. We define a set of correctness-preserving operations to systematically introduce types and subtyping relations into taxonomic structures. In addition to considering the ontological micro-theory of endurant types underlying OntoClean and OntoUML, we also employ the MLT (Multi-Level Theory) micro-theory of high-order types, which allows us to address multi-level taxonomies based on the powertype pattern. To validate our proposal, we formalize the model building operations as a graph grammar that incorporates both micro-theories. We apply automatic verification techniques over the grammar language to show that the graph grammar is sound, i.e., that all taxonomies produced by the grammar rules are correct, at least up to a certain size. We also show that the rules can generate all correct taxonomies up to a certain size (a completeness result).}
}
@article{GUO20241027,
title = {Ontology and production rules-based dynamic knowledge base construction methodology for machining process},
journal = {Journal of Manufacturing Systems},
volume = {77},
pages = {1027-1044},
year = {2024},
issn = {0278-6125},
doi = {https://doi.org/10.1016/j.jmsy.2024.11.006},
url = {https://www.sciencedirect.com/science/article/pii/S0278612524002607},
author = {Longxue Guo and Tianliang Hu and Lili Dong and Songhua Ma},
keywords = {Knowledge base, Knowledge update, Ontology, Production rules},
abstract = {With advancements in manufacturing, knowledge engineering has become important in supporting intelligent decision-making within manufacturing systems. However, existing process knowledge bases, integral to knowledge engineering, and essential for machining efficiency, product cost, and production cycles by integrating multi-source knowledge, are limited to generality, scalability, and adaptability to real production environments. These constraints undermine the application and reliability of process knowledge bases in decision-making. To overcome these challenges, an approach to constructing a dynamic machining process knowledge base (DMPKB) utilizing ontology and production rules is proposed. Firstly, a machining process knowledge model is developed by reorganizing concepts and relations to restructure process cases and experiences, thereby building a comprehensive knowledge base. Secondly, different update strategies are devised to fulfill the requirements of various components within the knowledge base. Finally, the effectiveness is validated by constructing a DMPKB for CNC boring machine bearing seats. Meanwhile, application verification is performed by generating process plans for a CNC boring machine bearing seat, showcasing the feasibility and utility of the developed knowledge base.}
}
@incollection{GALITSKY202559,
title = {Chapter 3 - Enabling large language model with plug-and-play symbolic reasoning components},
editor = {Boris Galitsky},
booktitle = {Healthcare Applications of Neuro-Symbolic Artificial Intelligence},
publisher = {Academic Press},
pages = {59-79},
year = {2025},
isbn = {978-0-443-30046-2},
doi = {https://doi.org/10.1016/B978-0-443-30046-2.00014-4},
url = {https://www.sciencedirect.com/science/article/pii/B9780443300462000144},
author = {Boris Galitsky},
keywords = {Large language models, probabilistic logic program, answer set program, abstract meaning representation, subjective trust, commonsense reasoning},
abstract = {We explore various architectures and methodologies to extend large language models (LLMs) with symbolic reasoning capabilities that LLMs experience difficulties acquiring on its own. We start with logic programming, proceed with probabilistic logic programming, and combine it with pre-LLM deep learning. We then extend a logic program toward answer set programming to handle complex reasoning domains about action, time, and space. We also extend LLMs with explicit commonsense reasoning and explore how discourse analysis helps with automatic construction of ontologies. We conduct evaluation of the contribution of individual reasoning components acting on top of LLMs and also a combine these reasoning components together in the consecutive Chapter 4. Whereas individual reasoning component yields 1.3%–2.6% in accuracy, being applied to a commonsense benchmark data set, all these components together provide a 4.2% boost in performance. This chapter is foundational for other chapters where we rely on LLM + logic program architecture for various applications in health.}
}
@article{ZITOUNI20241319,
title = {Toward Anomaly Representation in Lithium-Ion Batteries: An Ontology-Based Approach},
journal = {Procedia Computer Science},
volume = {246},
pages = {1319-1328},
year = {2024},
note = {28th International Conference on Knowledge Based and Intelligent information and Engineering Systems (KES 2024)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.09.563},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924026115},
author = {Marwa Zitouni and Franco Giustozzi and Ahmed Samet and Tedjani Mesbahi},
keywords = {Lithium-Ion Batteries, Anomaly Representation, Ontology},
abstract = {In today’s energy-dependent world, ensuring the safety and efficiency of lithium-ion batteries is crucial. Early representation of anomalies becomes essential for optimizing performance, reducing disruptions, and prolonging battery lifetime in electric vehicle applications. This objective necessitates the integration of data from distributed and heterogeneous sources, a challenge traditionally tackled by semantic web technologies. In response, this paper introduces an ontology-based model that capitalizes on representing anomalies in lithium-ion batteries. Ontologies play a vital role in representing knowledge in a machine-interpretable format. Our approach enriches sensor data with contextual information, employing structured concepts, rules, and semantics specifically designed for representing anomalies in lithium-ion batteries.}
}
@article{GRIFFO2023102219,
title = {Legal powers, subjections, disabilities, and immunities: Ontological analysis and modeling patterns},
journal = {Data & Knowledge Engineering},
volume = {148},
pages = {102219},
year = {2023},
issn = {0169-023X},
doi = {https://doi.org/10.1016/j.datak.2023.102219},
url = {https://www.sciencedirect.com/science/article/pii/S0169023X23000794},
author = {Cristine Griffo and João Paulo A. Almeida and João A.O. Lima and Tiago {Prince Sales} and Giancarlo Guizzardi},
keywords = {UFO, UFO-L, Conceptual modeling, Legal ontology, Legal power, Disability, Immunity},
abstract = {The development of dependable information systems in legal contexts requires a precise understanding of the subtleties of the underlying legal phenomena. According to a modern understanding in the philosophy of law, much of these phenomena are relational in nature. In this paper, we employ a theoretically well-grounded legal core ontology (UFO-L) to conduct an ontological analysis focused on fundamental legal relations, namely, the power–subjection and the disability–immunity relations. We show that in certain cases, power–subjection relations are primitive in the sense that by means of institutional acts other legal relations can be generated from them. Examples include relations of rights and duties, permissions and no-rights, liberties, secondary power–subjection, etc. We further show that legal disabilities (and their correlative immunities) are key in constraining the reach of legal powers; together with powers, they form a comprehensive framework for representing the grounds of valid legal acts and to account for the life-cycle of the legal positions that powers create, alter, and possibly extinguish. As a contribution to the practice of conceptual modeling, and leveraging the result of our analysis, we propose conceptual modeling patterns for legal relations, which are then applied to model a real-world case in tax law.}
}
@incollection{GALITSKY2025107,
title = {Chapter 5 - Differential diagnosis making with large language models and probabilistic logic program},
editor = {Boris Galitsky},
booktitle = {Healthcare Applications of Neuro-Symbolic Artificial Intelligence},
publisher = {Academic Press},
pages = {107-165},
year = {2025},
isbn = {978-0-443-30046-2},
doi = {https://doi.org/10.1016/B978-0-443-30046-2.00010-7},
url = {https://www.sciencedirect.com/science/article/pii/B9780443300462000107},
author = {Boris Galitsky},
keywords = {Large language models (LLMs), probabilistic logic programming, differential diagnosis, medical LLM fine-tuning, hybrid LLM architecture},
abstract = {We investigate how to leverage large language models (LLMs) and probabilistic logic programming to enhance differential diagnosis (DDx). We define the problem of DDx, consider multiple possible diagnoses, and analyze the limitations of stand-alone LLMs for this task, such as accuracy issues, hallucinations, input sensitivity, and lack of explainability. After introducing medical LLMs with a focus on prompting, answer generation with attribution, and fine-tuning, we move on to integrating LLMs with probabilistic logic programming and constructing necessary ontologies. The hybrid system is evaluated and compared with other LLM-based architectures in healthcare. By employing the proposed hybrid architecture of LLMs and probabilistic logic programming, we achieve a 3%–6% improvement in diagnostic performance.}
}
@article{ADIB2022417,
title = {Ontological user profile for E-orientation platforms},
journal = {Procedia Computer Science},
volume = {198},
pages = {417-422},
year = {2022},
note = {12th International Conference on Emerging Ubiquitous Systems and Pervasive Networks / 11th International Conference on Current and Future Trends of Information and Communication Technologies in Healthcare},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2021.12.263},
url = {https://www.sciencedirect.com/science/article/pii/S1877050921025023},
author = {Jihad Adib and Rachida Ait Abdelouahid and Abdelaziz Marzak and Hicham Moutachaouik},
keywords = {E-Orientation, User profile, Platform, Ontologies, Model},
abstract = {In recent years, E-orientation systems have played an increasingly significant role in the proposal of an academic and professional orientation to students. Research efforts have grown to provide more useful and effective E-orientation systems for research or other purposes. The implementation of E-orientation systems resulting from these efforts utilizes several techniques including Artificial Intelligence (AI) methodologies. This study proposes a personalised approach to support an E-orientation system that is tailored to the student’s characteristics. A key component of this system comprises an ontological model of the user profile. The objective of this research was to propose an ontology that is able to collect and analyze the user related information as well as customize the profiles with the most appropriate recommendation or orientation. The ontology employed in this study was developed using the OWL (Ontology Web Language), a knowledge representation language for authoring ontologies. In this paper we will present a definition for the user profile, and then we present our methodology of ontological modeling of the user profile, and finally the conceptual model of the user model for e-orientation systems.}
}
@article{MUNCH2022117406,
title = {Combining ontology and probabilistic models for the design of bio-based product transformation processes},
journal = {Expert Systems with Applications},
volume = {203},
pages = {117406},
year = {2022},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2022.117406},
url = {https://www.sciencedirect.com/science/article/pii/S0957417422007485},
author = {Mélanie Munch and Patrice Buche and Stéphane Dervaux and Juliette Dibie and Liliana Ibanescu and Cristina Manfredotti and Pierre-Henri Wuillemin and Hélène Angellier-Coussy},
keywords = {Ontologies, Probabilistic relational models, Knowledge discovery, Causality},
abstract = {This paper presents a workflow for the design of transformation processes using different kinds of expert’s knowledge. It introduces POND (Process and observation ONtology Discovery), a workflow dedicated to answer expert’s questions about processes. It addresses two main issues: (1) how to represent the processes inner complexity, and (2) how to reason about processes taking into account uncertainty and causality. First, we show how to use a semantic model, an ontology, and its associated data to answer some of the expert’s questions concerning the processes, using semantic web languages and technologies. Then, we describe how to learn a predictive model, to discover new knowledge and provide explicative models by integrating the semantic model into a probabilistic relational model. The result is a complete workflow able to extensively analyze transformation processes through all their granularity levels and answer expert’s questions about their domains. An example of this workflow is given on biocomposites manufacturing for food packaging.}
}
@article{GUYO2023101992,
title = {An ontology to represent firefighters data requirements during building fire emergencies},
journal = {Advanced Engineering Informatics},
volume = {56},
pages = {101992},
year = {2023},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2023.101992},
url = {https://www.sciencedirect.com/science/article/pii/S1474034623001209},
author = {Eyosias Dawit Guyo and Timo Hartmann and Sean Snyders},
keywords = {Ontology, Building fire response, Firefighters, Data requirements},
abstract = {Firefighters require accurate and timely information regarding a building and its environment to perform their duty safely and successfully during a fire emergency. However, due to the chaotic nature of building fires, firefighters often receive erroneous, conflicting, or delayed information that can affect the outcome of an emergency. In this paper, we propose a solution in the form of an ontology that defines building and environmental data that is needed by firefighters during a building fire emergency. The ontology development followed the METHONTOLOGY method and was implemented using the web ontology language (OWL) in Protégé 5.5.0. Built-in reasoners in Protégé and an ontology pitfall scanning tool were employed to verify the structure and consistency of the new ontology. To validate the ontology efficacy, we developed a prototype web application to represent and visualise relevant information based on the ontology and used that as a basis for conducting interviews with firefighters. Finally, a specification document that describes the ontology was created and published online. The proposed ontology can be a basis for developing intelligent tools and systems that support firefighters.}
}
@article{MARTINSAMORIM2025114154,
title = {Using natural language definitions and language models for relationship classification},
journal = {Knowledge-Based Systems},
volume = {327},
pages = {114154},
year = {2025},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2025.114154},
url = {https://www.sciencedirect.com/science/article/pii/S0950705125011955},
author = {Marina {Martins Amorim} and Alcides {Gonçalves Lopes Junior} and  {Fabrício Henrique Rodrigues} and Joel {Luís Carbonera}},
keywords = {BERT, Machine learning, Lexical classification, Relation classification, NLP},
abstract = {Identifying relationships between concepts is a very important task for several NLP tasks, as well as for building explicit knowledge models (ontologies and knowledge graphs). In many of these tasks, experts usually manually establish these relationships by carefully analyzing each concept’s meaning and considering the domain knowledge elicited from domain practitioners or from domain literature. While some studies automate parts of the process of building knowledge models, most focus on identifying general concepts or rely on static word embeddings, which fail to address challenges like polysemy and contextual ambiguity. This research addresses the problem of classifying semantic relationships between concepts, focusing on hypernym and holonym relations. We propose an approach based on the pre-trained language model BERT to classify these relationships between concepts. We assume that we can represent the concept’s semantics using their definitions in natural language. To evaluate this approach, we developed a methodology to construct a labeled dataset of definitions of concepts using WordNet as a reference. Thus, our proposed approach classifies the relations based solely on natural language expressions representing the concept’s definition. Our experiments showed notable classification results, achieving an F1 score of 96 % in the classification of holonyms, hypernyms, and concepts that are not related by any of these relations, indicating that our approach can accurately predict semantic relations between concepts using only their natural language definitions as input.}
}
@article{ZHUANG2023101919,
title = {Knowledge-enhanced event relation extraction via event ontology prompt},
journal = {Information Fusion},
volume = {100},
pages = {101919},
year = {2023},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2023.101919},
url = {https://www.sciencedirect.com/science/article/pii/S156625352300235X},
author = {Ling Zhuang and Hao Fei and Po Hu},
keywords = {Event temporal relation extraction, Subevent relation extraction, Knowledge enhancement, Neural networks},
abstract = {Identifying temporal and subevent relationships between different events (i.e., event relation extraction) is an important step towards event-centric natural language processing, which can help understand how events evolve and potentially facilitate many downstream tasks, such as timeline generation and event knowledge graph construction. Existing work has extensively leveraged external knowledge to improve the performance of relation extraction. Despite the progress made, the current knowledge-enhanced approach still has some shortcomings, e.g., knowledge missing, knowledge noise, and suboptimal knowledge injection. In this paper, we propose OntoEnhance, a novel event relation extraction framework that fuses semantic information from event ontologies to enhance event representation. Specifically, we first inject the latent knowledge in the event ontology into the prompt text to address the issue of knowledge missing. Then a dual-stack attention fusion mechanism is further introduced to enhance the injection of key knowledge to alleviate knowledge noise. In order to prevent the knowledge in the event ontology from being wrongly dominated, we use the event direction induction mechanism to obtain the event context-based relational sequence representation. Finally, a gate mechanism is used to fuse ontology-based knowledge and context-based event features dynamically. Extensive experiments demonstrate that OntoEnhance outperforms all comparison baselines by a large margin on all four datasets under both standard and few-shot settings.}
}
@article{PALACZ2025109452,
title = {Ontology-based integration and querying of heterogeneous rare disease data sources — POLVAS perspective},
journal = {Computers in Biology and Medicine},
volume = {185},
pages = {109452},
year = {2025},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2024.109452},
url = {https://www.sciencedirect.com/science/article/pii/S0010482524015373},
author = {Wojciech Palacz and Sabina Lichołai and Jacek Musiał and Katarzyna Wawrzycka-Adamczyk and Grażyna Ślusarczyk and Barbara Strug and Beyza Yaman and Michelangelo Tesi and Karl Gisslander and Declan O’Sullivan and Augusto Vaglio and Giacomo Emmi and Mark A. Little and Krzysztof Wójcik},
keywords = {Rare diseases, Ontologies, Data integration, Federated queries},
abstract = {The integration of rare disease medical databases belonging to different countries is an important problem, as a large number of observations are required for reliable statistical inference of patient data in order to facilitate clinical research. Such integration of national registry data, which requires harmonization of the heterogeneous data sets into a unified view, is facilitated in the European FAIRVASC project by developing a domain-specific ontology. The FAIRVASC project is dedicated to the rare disease of anti-neutrophil cytoplasmic antibody (ANCA) associated vasculitis (AAV). This paper focuses on the practical issues and challenges, encountered during the process of integrating the Polish national database POLVAS into the federated database within the FAIRVASC project. It discusses the use of ontology-based methods for data integration and the importance of ensuring patient privacy and data protection. It addresses the problem of missing information in POLVAS, which can be obtained by aggregating other data available within the database, incompatibility of data types and formats, and mapping polish data names into the common vocabulary. The modifications of mappings used to ‘uplift’ national data into the Resource Description Framework (RDF) triplestore are also proposed. The described methods allow for integrating the Polish national database into the European network over which federated queries are performed.}
}
@article{VALIENTE2024100830,
title = {Web3-DAO: An ontology for decentralized autonomous organizations},
journal = {Journal of Web Semantics},
volume = {82},
pages = {100830},
year = {2024},
issn = {1570-8268},
doi = {https://doi.org/10.1016/j.websem.2024.100830},
url = {https://www.sciencedirect.com/science/article/pii/S1570826824000167},
author = {María-Cruz Valiente and Juan Pavón},
keywords = {Blockchain, Web3, DAO, Decentralized autonomous organization, Digital governance, E-government, Online entity, Ontology, Voting system},
abstract = {Decentralized autonomous organizations (DAOs) are relatively a newly emerging type of online entity related to governance or business models where all their members work together and participate in the decision-making processes affecting the DAO in a decentralized, collective, fair, and democratic manner. In a DAO, members interaction is mediated by software agents running on a blockchain that encode the governance of the specific entity in terms of rules that optimize their business and goals. In this context, most popular DAO software frameworks provide decision-making models aiming to facilitate digital governance and the collaboration among their members intertwining social and economic concerns. However, these models are complex, not interoperable among them and lack a common understanding and shared knowledge concerning DAOs, as well as the computational semantics needed to enable automated validation, simulation or execution. Thus, this paper presents an ontology (Web3-DAO), which can support machine-readable digital governance of DAOs adding semantics to their decision-making models. The proposed ontology captures the domain logic that allows the sharing of updated information and decisions for all the members that interact with a DAO by the interoperability of their own assessment and decision tools. Furthermore, the ontology detects semantic ambiguities, uncertainties and contradictions. The Web3-DAO ontology is available in open access at https://github.com/Grasia/semantic-web3-dao.}
}
@article{SHI2023102114,
title = {An ontology-based methodology to establish city information model of digital twin city by merging BIM, GIS and IoT},
journal = {Advanced Engineering Informatics},
volume = {57},
pages = {102114},
year = {2023},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2023.102114},
url = {https://www.sciencedirect.com/science/article/pii/S1474034623002422},
author = {Jianyong Shi and Zeyu Pan and Liu Jiang and Xiaohui Zhai},
keywords = {CIM, Ontology, Linked data, Semantic integration, BIM-GIS-IoT integration},
abstract = {With the development of digital city and smart city construction, the City Information Model (CIM) has played a critical role as a container of spatial–temporal data to establish the Digital Twin City. For a digital twin city, a virtual high-fidelity CIM model that corresponds closely to the real physical world is the premise and cornerstone of its construction. Therefore, the integration of BIM, GIS and IoT has become the preferred topic for researchers and has received much more attention from a wide academic circle. However, traditional integration mainly focuses on the conversion of both IFC and CityGML, and IoT data are also often used as visualizations. More importantly, the underlying data formats of GIS, BIM and IoT are still independent of each other without a unified data structure expression, so real data-driven analysis and decision-making cannot be implemented. This study aims to establish a general CIM ontology to integrate heterogeneous BIM, GIS and IoT data. First, the related work of BIM, GIS and IoT integration is studied and analyzed. A comparison of three mainstream approaches, data conversion, standard extension and data linking, is conducted, and it illustrates the advantages of ontology techniques in solving data interoperability problems. Second, a technical framework of BIM, GIS and IoT data integration based on ontology technology is proposed. The approach is mainly divided into five steps: geometry processing, data instantiation, ontology construction, ontology mapping and querying application. On the basis of the CIM ontology, an application ontology is built for a specific application domain to illustrate rule-based mapping, querying and inferring. Finally, the case study shows that the Ontology-based methodology in this paper has contributed to establish a general pattern for CIM data integration by mapping and linking concepts from the semantic level. It avoids changes in the original data sources and the missing data problem.}
}
@article{SANTOSO2021114856,
title = {Named entity recognition for extracting concept in ontology building on Indonesian language using end-to-end bidirectional long short term memory},
journal = {Expert Systems with Applications},
volume = {176},
pages = {114856},
year = {2021},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2021.114856},
url = {https://www.sciencedirect.com/science/article/pii/S0957417421002979},
author = {Joan Santoso and Esther Irawati Setiawan and Christian Nathaniel Purwanto and Eko Mulyanto Yuniarno and Mochamad Hariadi and Mauridhi Hery Purnomo},
keywords = {Named entity recognition, Ontology building, Concept extraction, Indonesian language, Information extraction, End-to-end model},
abstract = {Information Extraction has been widely used to extract information from text. Named Entity Recognition (NER) is one of the primary tasks of Information Extraction to extract entities such as person, location, and organization. Extraction from text collection is essential to obtain information from unstructured text. Moreover, Named Entity Recognition is part of ontology building, which is the main objective of this research. Ontology can be built on the basis of a collection of concepts and relation between concepts. Concepts in ontology usually consist of a group of entities and are obtained using Noun Phrase Extraction or Named Entity Recognition. Our main focus in this research is to extract concepts in Ontology Building automatically using Named Entity Recognition. In this paper, Named Entity Recognition was chosen as our approach due to the lack of results from the previous Noun Phrase Extraction works, which is not all nouns obtained are entities. Our proposed methodology for Named Entity Recognition is applying an end-to-end model using Bidirectional Long Short Term Memory (Bi-LSTM). Bi-LSTM is able to perform a sequence classification task by understanding the context of the input. Named Entity Recognition approaches in the previous study uses Part-of-Speech (POS) Tagging in the preprocessing phase by using other tools or models. This Part-of Speech is also used as a feature to improve the performance of Named Entity Recognition. Our proposed methodology provides an end-to-end system that can be used for both POS Tagging and Named Entity Recognition. By using our proposed end-to-end model, no additional tool is needed for Part-of-Speech Tagging. This the advantage of our model compared to other models. Experiments were conducted on news documents that were labeled with four types of entity classes and 35 types of part-of-speech. The target entities that we have extracted in this study are person, location, organization, and miscellaneous. We evaluated the performance of our model using F1-Score. We have achieved the best F1-Score for Part-of-Speech Tagging of 91.79% and Named Entity Recognition of 83.18%.}
}
@article{BODENBENNER2025101455,
title = {Providing FAIR sensor data models using semantic web technologies and ontologies},
journal = {Measurement: Sensors},
volume = {38},
pages = {101455},
year = {2025},
note = {Proceedings of the XXIV IMEKO World Congress},
issn = {2665-9174},
doi = {https://doi.org/10.1016/j.measen.2024.101455},
url = {https://www.sciencedirect.com/science/article/pii/S2665917424004318},
author = {Matthias Bodenbenner and Dominik Wolfschläger and Robert H. Schmitt},
keywords = {FAIR data, Ontologies, Semantic web, Measurement uncertainty, Sensor services, Internet of things},
abstract = {The extended usage time of measurement data due to current trends and regulations demands richly described and FAIR measurement data to ensure (re-) usability by third parties, after long periods, and for different applications. Semantic web technologies and ontologies are key for providing FAIR data, but they significantly increase modelling complexity and effort and lack domain-specific standards. We acknowledge the latter by proposing a semantic data metamodel for measurement data based on domain-agnostic ontologies. To compensate for the increasing complexity, we introduce a mapping to a simple data meta-structure, which can be used to define a measuring system-specific structure and automatically generate the complete semantic measuring system-specific model. Based on these structures and models, we implemented three virtual measuring systems. A FAIRness assessment of the data acquired shows a promising result for the FAIRness of the data but also revealed further possibilities for improving the proposed models and methods.}
}
@article{HALL2020100817,
title = {Educators’ beliefs about English and languages beyond English: From ideology to ontology and back again},
journal = {Linguistics and Education},
volume = {57},
pages = {100817},
year = {2020},
issn = {0898-5898},
doi = {https://doi.org/10.1016/j.linged.2020.100817},
url = {https://www.sciencedirect.com/science/article/pii/S0898589820300541},
author = {Christopher J Hall and Clare Cunningham},
keywords = {English as an Additional Language, Languages beyond English, Language ideology, Language ontology, Monolingual habitus, Teacher development},
abstract = {In this paper we propose that careful analysis of educators’ ontological beliefs concerning English and other languages can be interpreted from their attitudinal discourse and can shed light on how potentially harmful ideological beliefs persist in educational systems. We explore the relationship between ideological and ontological beliefs about language(s) and argue that the ontological dimension has been overlooked in previous work on educator ideologies. Analysis of interview data from educators working with English as an Additional Language (EAL) students at seven primary schools in the north of England suggests a pervasive hegemonic ideological belief, consistent with the ‘monolingual habitus’, in which English is commonly positioned as ‘language itself’ and other languages are associated with stratified levels of cultural capital. From this analysis, we infer shared conceptualizations of English and other languages, and of nation and national identity, separately from the values associated with them. We address how a process of ontological interpretation can potentially be used in teacher development programmes to allow educators to understand and reassess their own ideologies and professional practices, challenging and more effectively resisting unhelpful narratives from those in positions of greater power.}
}
@article{CHEN2025131230,
title = {Knowledge graph and large language model integration with focus on educational applications: A survey},
journal = {Neurocomputing},
volume = {654},
pages = {131230},
year = {2025},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2025.131230},
url = {https://www.sciencedirect.com/science/article/pii/S0925231225019022},
author = {Guanyu Chen and Tao Song and Quanyu Wang and Zheng Ma and Jun Hu and Qi Li and Chunming Wu},
keywords = {Knowledge graph, Large language model, Educational application, Retrieval augmented generation, Pre-training},
abstract = {In recent years, artificial intelligence (AI) technology has made significant advancements, particularly in the areas of large language models (LLMs) and knowledge graphs (KGs). KGs excel at structured knowledge representation and reasoning, offering interpretability; however, they are costly to construct, have limited coverage, and lack natural language processing capabilities. Conversely, LLMs possess powerful language understanding and generation abilities, but they rely heavily on vast amounts of data, are prone to “hallucinations," and lack interpretability. The integration of these two approaches is an inevitable trend for achieving stronger and more reliable AI applications, and has become a hot topic of research. Simultaneously, the combination of LLMs and KGs perfectly aligns with the pressing needs of the education field for precise reasoning and personalized services, addressing the shortcomings of traditional teaching methods and providing support for intelligent education. In light of this, this paper undertakes work in the following three key areas. Firstly, the concepts and technologies of both LLMs and KGs, along with their applications in education, are introduced. On this basis, the paper then delves into a discussion of the methods for integrating LLMs and KGs, and reviews related research progress. Finally, the paper focuses on specific educational scenarios, such as intelligent tutoring systems, intelligent learning companions, and intelligent evaluation systems, to explore the collaborative application of LLMs and KGs. The aim of this paper is to provide researchers in the field with a systematic understanding of LLMs and KGs, and to offer valuable references for future AI-driven educational innovation.}
}
@article{TURKI2024e38448,
title = {A framework for integrating biomedical knowledge in Wikidata with open biological and biomedical ontologies and MeSH keywords},
journal = {Heliyon},
volume = {10},
number = {19},
pages = {e38448},
year = {2024},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2024.e38448},
url = {https://www.sciencedirect.com/science/article/pii/S2405844024144799},
author = {Houcemeddine Turki and Khalil Chebil and Bonaventure F.P. Dossou and Chris Chinenye Emezue and Abraham Toluwase Owodunni and Mohamed Ali {Hadj Taieb} and Mohamed {Ben Aouicha}},
keywords = {Wikidata, Open biological and biomedical ontologies, MeSH keywords, Biomedical relation identification, Crowdsourcing, PubMed},
abstract = {This study presents a comprehensive framework to enhance Wikidata as an open and collaborative knowledge graph by integrating Open Biological and Biomedical Ontologies (OBO) and Medical Subject Headings (MeSH) keywords from PubMed publications. The primary data sources include OBO ontologies and MeSH keywords, which were collected and classified using SPARQL queries for RDF knowledge graphs. The semantic alignment between OBO ontologies and Wikidata was evaluated, revealing significant gaps and distorted representations that necessitate both automated and manual interventions for improvement. We employed pointwise mutual information to extract biomedical relations among the 5000 most common MeSH keywords in PubMed, achieving an accuracy of 89.40 % for superclass-based classification and 75.32 % for relation type-based classification. Additionally, Integrated Gradients were utilized to refine the classification by removing irrelevant MeSH qualifiers, enhancing overall efficiency. The framework also explored the use of MeSH keywords to identify PubMed reviews supporting unsupported Wikidata relations, finding that 45.8 % of these relations were not present in PubMed, indicating potential inconsistencies in Wikidata. The contributions of this study include improved methodologies for enriching Wikidata with biomedical information, validated semantic alignments, and efficient classification processes. This work enhances the interoperability and multilingual capabilities of biomedical ontologies and demonstrates the critical role of MeSH keywords in verifying semantic relations, thereby contributing to the robustness and accuracy of collaborative biomedical knowledge graphs.}
}
@incollection{BISWAS2025499,
title = {Chapter 23 - Medical ontology for text categorization system and its applications},
editor = {Sujata Dash and Subhendu Kumar Pani and Wellington Pinheiro Dos Santos and Jake Y. Chen},
booktitle = {Mining Biomedical Text, Images and Visual Features for Information Retrieval},
publisher = {Academic Press},
pages = {499-512},
year = {2025},
isbn = {978-0-443-15452-2},
doi = {https://doi.org/10.1016/B978-0-443-15452-2.00023-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780443154522000236},
author = {Payel Biswas and Arnab Hazra and Himadri Nath Saha},
keywords = {Artificial intelligence, Machine learning, Medical ontology, Natural language processing, Text categorization},
abstract = {Ontology refers to a bunch of knowledge on a subject domain and its category to find suitable relationships among them. Combining with recent technologies, nowadays it is highly used in medical fields also. Medical ontology interprets the knowledge of medical concepts and terminologies and acts as a bridge between them. Text categorization, sometimes referred to as text tagging or text classification, is the process of categorizing text into various structured classifications by natural language processing (NLP). By using NLP, text classifiers can analyze text data and then assign a set of predefined text categories depending on its content accordingly applying machine learning and deep leaning algorithms. State-of-the-art artificial intelligence (AI) techniques using NLP and linguistics help machine to read, understand, and act accordingly in the field of healthcare, transportation, media, development, human resources, child care, and other welfare applications. In this chapter, we will discuss a brief overview of medical ontology for text categorization systems based on their objective, categories, and design methodologies using some case studies.}
}
@article{DIAZ2025179,
title = {Knowledge graphs in heterogeneous catalysis: Recent advances and future opportunities},
journal = {Chinese Journal of Chemical Engineering},
volume = {84},
pages = {179-189},
year = {2025},
issn = {1004-9541},
doi = {https://doi.org/10.1016/j.cjche.2025.06.008},
url = {https://www.sciencedirect.com/science/article/pii/S1004954125002393},
author = {Raúl Díaz and Hongliang Xin},
keywords = {Heterogeneous catalysis, Knowledge graph, Ontology, Large language models, Deep learning},
abstract = {Knowledge graphs (KGs) offer a structured, machine-readable format for organizing complex information. In heterogeneous catalysis, where data on catalytic materials, reaction conditions, mechanisms, and synthesis routes are dispersed across diverse sources, KGs provide a semantic framework that supports data integration under the FAIR (Findable, Accessible, Interoperable, and Reusable) principles. This review aims to survey recent developments in catalysis KGs, describe the main techniques for graph construction, and highlight how artificial intelligence, particularly large language models (LLMs), enhances graph generation and query. We conducted a systematic analysis of the literature, focusing on ontology-guided text mining pipelines, graph population methods, and maintenance strategies. Our review identifies key trends: ontology-based approaches enable the automated extraction of domain knowledge, LLM-driven retrieval-augmented generation supports natural-language queries, and scalable graph architectures range from a few thousand to over a million triples. We discuss state-of-the-art applications, such as catalyst recommendation systems and reaction mechanism discovery tools, and examine the major challenges, including data heterogeneity, ontology alignment, and long-term graph curation. We conclude that KGs, when combined with AI methods, hold significant promise for accelerating catalyst discovery and knowledge management, but progress depends on establishing community standards for ontology development and maintenance. This review provides a roadmap for researchers seeking to leverage KGs to advance heterogeneous catalysis research.}
}
@article{SINGLE2020104747,
title = {Knowledge acquisition from chemical accident databases using an ontology-based method and natural language processing},
journal = {Safety Science},
volume = {129},
pages = {104747},
year = {2020},
issn = {0925-7535},
doi = {https://doi.org/10.1016/j.ssci.2020.104747},
url = {https://www.sciencedirect.com/science/article/pii/S0925753520301442},
author = {Johannes I. Single and Jürgen Schmidt and Jens Denecke},
keywords = {Ontology-based accident database, Natural language processing, Chemical accident database, Automatic ontology population, Knowledge-based systems},
abstract = {Accident databases are used to learn from past accidents and avoid future accidents in the chemical process industry. Classical accident databases can be tedious to use because the database entries were written over the years by various persons in different styles. Thus, accident case entries must be interpreted to identify cause-effect relationships and recognize lessons learned. Semantically enriched accident databases can make information retrieval more efficient. In this research approach Natural Language Processing methods are used to extract information from a chemical accident database. Additionally, substance information is enriched using web scraping techniques. Afterwards, a predefined ontology structure is automatically populated with the extracted information. The ontology-based chemical accident database provides additional accident exploration capabilities that can be used by human experts or computer systems. The results indicate that the proposed extraction method is well suited to extract accident information. The ontology is useful to discover causal accident relations due to the semantically described context of accident information. The method described can be adapted to other databases with minor adaptations and refinements. By combining various ontology-based accident databases a human and machine-processable, and sharable knowledge structure can be provided to reuse knowledge across companies and countries.}
}
@article{GURBUZ20181208,
title = {Process ontology development using natural language processing: a multiple case study},
journal = {Business Process Management Journal},
volume = {25},
number = {6},
pages = {1208-1227},
year = {2018},
issn = {1463-7154},
doi = {https://doi.org/10.1108/BPMJ-05-2018-0144},
url = {https://www.sciencedirect.com/science/article/pii/S1463715418001541},
author = {Ozge Gurbuz and Fethi Rabhi and Onur Demirors},
keywords = {Process ontology, Ontology development, Business process modelling, Natural language processing},
abstract = {Purpose
Integrating ontologies with process modeling has gained increasing attention in recent years since it enhances data representations and makes it easier to query, store and reuse knowledge at the semantic level. The authors focused on a process and ontology integration approach by extracting the activities, roles and other concepts related to the process models from organizational sources using natural language processing techniques. As part of this study, a process ontology population (PrOnPo) methodology and tool is developed, which uses natural language parsers for extracting and interpreting the sentences and populating an event-driven process chain ontology in a fully automated or semi-automated (user assisted) manner. The purpose of this paper is to present applications of PrOnPo tool in different domains.
Design/methodology/approach
A multiple case study is conducted by selecting five different domains with different types of guidelines. Process ontologies are developed using the PrOnPo tool in a semi-automated and fully automated fashion and manually. The resulting ontologies are compared and evaluated in terms of time-effort and recall-precision metrics.
Findings
From five different domains, the results give an average of 70 percent recall and 80 percent precision for fully automated usage of the PrOnPo tool, showing that it is applicable and generalizable. In terms of efficiency, the effort spent for process ontology development is decreased from 250 person-minutes to 57 person-minutes (semi-automated).
Originality/value
The PrOnPo tool is the first one to automatically generate integrated process ontologies and process models from guidelines written in natural language.}
}
@article{CUI2023105055,
title = {An ontology-based probabilistic framework for comprehensive seismic risk evaluation of subway stations by combining Monte Carlo simulation},
journal = {Tunnelling and Underground Space Technology},
volume = {135},
pages = {105055},
year = {2023},
issn = {0886-7798},
doi = {https://doi.org/10.1016/j.tust.2023.105055},
url = {https://www.sciencedirect.com/science/article/pii/S0886779823000755},
author = {Chunyi Cui and Minze Xu and Chengshun Xu and Peng Zhang and Jingtong Zhao},
keywords = {Subway station, Seismic risk evaluation, Monte Carlo simulation, Ontology, Semantic web rules},
abstract = {The development of subways is currently at its peak and underground structures including subway stations are being constructed on a large scale. However, previous research on seismic risk evaluation of underground structures mainly focuses on the analysis of influencing factors and seismic fragility. There is a lack of research on comprehensive automated seismic risk evaluation from a macro perspective based on economic losses, casualties, disaster relief costs and post-earthquake recovery time etc. The emergence of semantic web technologies provides an effective way for multi-objective automated seismic risk evaluation of subway stations. This paper aims to develop a framework for comprehensive seismic risk evaluation of subway stations based on Monte Carlo simulation and ontology theory. In the developed framework, the seismic risk probabilities of subway stations are determined using Monte Carlo simulation. Taking economic losses, casualties, disaster relief costs and post-earthquake recovery time as indicators, an ontology-based model for seismic risk evaluation of subway stations is then developed by combining the knowledge base and the semantic web rules to achieve automated evaluations. A case study is also conducted to demonstrate the practicability of the proposed framework and further validate the semantic web rule language and the semantic query-enhanced web rule language}
}
@article{WANG2024760,
title = {An Ontology-based Knowledge Modeling towards Eco-Design for Additive Manufacturing},
journal = {Procedia CIRP},
volume = {122},
pages = {760-765},
year = {2024},
note = {31st CIRP Conference on Life Cycle Engineering},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2024.01.105},
url = {https://www.sciencedirect.com/science/article/pii/S2212827124001446},
author = {Yanan Wang and Tao Peng and Samyeon Kim and Yi Xiong and Yunlong Tang and Renzhong Tang},
keywords = {additive manufacturing, eco-design for additive manufacturing, ontology model, sustainability},
abstract = {Owing to the unique technological merits of additive manufacturing (AM), design for AM, particularly eco-design for AM, has been gaining attention in improving the sustainable performance of AM-fabricated (AMed) parts. The main challenge in harvesting potential sustainability benefits is how to capture the impact of design on sustainable performance. Though several existing studies adopted quantitative evaluation on AM sustainability and investigated the relationships between design information and sustainability information of AMed part, the sustainability information is still unavailable in the design phase. This hardly guides eco-design for AM in practice. To support the increasing industrial applications of AM, this paper illustrates related knowledge, that is, material-process-structure-ecoProperty (MPSeP) relationships to connect design and sustainability information in eco-design for AM. An ontology-based method is proposed to model the MPSeP relationships of the AMed part in a structured way. An example of an AMed hydraulic valve body was used to demonstrate the MPSeP modeling process. It is discussed that how the constructed model effectively assists AM designers through providing eco-design recommendation, and enables design software tools to perform sustainability analysis towards eco-design for AM.}
}
@article{ZUO2025102037,
title = {Large language models for batteries},
journal = {Joule},
volume = {9},
number = {8},
pages = {102037},
year = {2025},
issn = {2542-4351},
doi = {https://doi.org/10.1016/j.joule.2025.102037},
url = {https://www.sciencedirect.com/science/article/pii/S2542435125002181},
author = {Wenhua Zuo and Huihuo Zheng and Tanjin He and Venkatram Vishwanath and Maria K.Y. Chan and Rick L. Stevens and Khalil Amine and Gui-Liang Xu},
keywords = {batteries, large language models, text mining, aging mechanisms, SoH, SoC, artificial intelligence, natural language processing},
abstract = {Summary
Large language models (LLMs) are advanced artificial intelligence systems capable of solving diverse tasks using language, reasoning, and external tools. Despite their growing deployment in academia and industry, their potential remains underexplored in battery research. This review presents a comprehensive overview of existing and emerging applications of LLMs in the battery field, addressing two critical questions: what can LLMs offer to support battery-related tasks, and how can more effective models be developed for this purpose? We begin by outlining the principles of LLMs and criteria for selecting appropriate models and tools for battery research and development. We then explore the roles of LLMs in text mining, data interpretation, and the development of intelligent battery systems. In parallel, we discuss technical challenges, such as data standardization and sharing, model evaluation, and tool integration. Finally, we propose future research directions with short-, medium-, and long-term goals and highlight more broad perspectives for connecting experts and cross-disciplinary collaborations.}
}
@article{JUANESCORTES2021194766,
title = {Formalization of gene regulation knowledge using ontologies and gene ontology causal activity models},
journal = {Biochimica et Biophysica Acta (BBA) - Gene Regulatory Mechanisms},
volume = {1864},
number = {11},
pages = {194766},
year = {2021},
issn = {1874-9399},
doi = {https://doi.org/10.1016/j.bbagrm.2021.194766},
url = {https://www.sciencedirect.com/science/article/pii/S1874939921000845},
author = {Belén {Juanes Cortés} and José Antonio Vera-Ramos and Ruth C. Lovering and Pascale Gaudet and Astrid Laegreid and Colin Logie and Stefan Schulz and María del Mar Roldán-García and Martin Kuiper and Jesualdo Tomás Fernández-Breis},
keywords = {Gene regulation, Bioinformatics, Knowledge representation, Ontologies, Gene ontology},
abstract = {Gene regulation computational research requires handling and integrating large amounts of heterogeneous data. The Gene Ontology has demonstrated that ontologies play a fundamental role in biological data interoperability and integration. Ontologies help to express data and knowledge in a machine processable way, which enables complex querying and advanced exploitation of distributed data. Contributing to improve data interoperability in gene regulation is a major objective of the GREEKC Consortium, which aims to develop a standardized gene regulation knowledge commons. GREEKC proposes the use of ontologies and semantic tools for developing interoperable gene regulation knowledge models, which should support data annotation. In this work, we study how such knowledge models can be generated from cartoons of gene regulation scenarios. The proposed method consists of generating descriptions in natural language of the cartoons; extracting the entities from the texts; finding those entities in existing ontologies to reuse as much content as possible, especially from well known and maintained ontologies such as the Gene Ontology, the Sequence Ontology, the Relations Ontology and ChEBI; and implementation of the knowledge models. The models have been implemented using Protégé, a general ontology editor, and Noctua, the tool developed by the Gene Ontology Consortium for the development of causal activity models to capture more comprehensive annotations of genes and link their activities in a causal framework for Gene Ontology Annotations. We applied the method to two gene regulation scenarios and illustrate how to apply the models generated to support the annotation of data from research articles.}
}
@article{JUNG2022103785,
title = {Logical separability of labeled data examples under ontologies},
journal = {Artificial Intelligence},
volume = {313},
pages = {103785},
year = {2022},
issn = {0004-3702},
doi = {https://doi.org/10.1016/j.artint.2022.103785},
url = {https://www.sciencedirect.com/science/article/pii/S0004370222001254},
author = {Jean Christoph Jung and Carsten Lutz and Hadrien Pulcini and Frank Wolter},
keywords = {Logical separability, Decidable fragments of first-order logic, Description logic, Learning from examples, Complexity, Ontologies},
abstract = {Finding a logical formula that separates positive and negative examples given in the form of labeled data items is fundamental in applications such as concept learning, reverse engineering of database queries, generating referring expressions, and entity comparison in knowledge graphs. In this paper, we investigate the existence of a separating formula for data in the presence of an ontology. Both for the ontology language and the separation language, we concentrate on first-order logic and the following important fragments thereof: the description logic ALCI, the guarded fragment, the two-variable fragment, and the guarded negation fragment. For separation, we also consider (unions of) conjunctive queries. We consider several forms of separability that differ in the treatment of negative examples and in whether or not they admit the use of additional helper symbols to achieve separation. Our main results are model-theoretic characterizations of (all variants of) separability, the comparison of the separating power of different languages, and the investigation of the computational complexity of deciding separability.}
}
@article{ANTUNES2022100131,
title = {Incorporation of Ontologies in Data Warehouse/Business Intelligence Systems - A Systematic Literature Review},
journal = {International Journal of Information Management Data Insights},
volume = {2},
number = {2},
pages = {100131},
year = {2022},
issn = {2667-0968},
doi = {https://doi.org/10.1016/j.jjimei.2022.100131},
url = {https://www.sciencedirect.com/science/article/pii/S266709682200074X},
author = {António Lorvão Antunes and Elsa Cardoso and José Barateiro},
keywords = {Ontologies, Semantic web, Data warehouse, Business intelligence, Systematic literature review},
abstract = {Semantic Web (SW) techniques, such as ontologies, are used in Information Systems (IS) to cope with the growing need for sharing and reusing data and knowledge in various research areas. Despite the increasing emphasis on unstructured data analysis in IS, structured data and its analysis remain critical for organizational performance management. This systematic literature review aims at analyzing the incorporation and impact of ontologies in Data Warehouse/Business Intelligence (DW/BI) systems, contributing to the current literature by providing a classification of works based on the field of each case study, SW techniques used, and the authors’ motivations for using them, with a focus on DW/BI design, development and exploration tasks. A search strategy was developed, including the definition of keywords, inclusion and exclusion criteria, and the selection of search engines. Ontologies are mainly defined using the Ontology Web Language standard to support multiple DW/BI tasks, such as Dimensional Modeling, Requirement Analysis, Extract-Transform-Load, and BI Application Design. Reviewed authors present a variety of motivations for ontology-driven solutions in DW/BI, such as eliminating or solving data heterogeneity/semantics problems, increasing interoperability, facilitating integration, or providing semantic content for requirements and data analysis. Further, implications for practice and research agenda are indicated.}
}
@article{DAWANDE2024238,
title = {An ontology-based knowledge framework for selection of joining process in plastic assembly},
journal = {Materials Today: Proceedings},
volume = {115},
pages = {238-244},
year = {2024},
note = {4th Innovative Product Design and Intelligent Manufacturing Systems},
issn = {2214-7853},
doi = {https://doi.org/10.1016/j.matpr.2023.08.136},
url = {https://www.sciencedirect.com/science/article/pii/S2214785323043973},
author = {Hemant Dawande and Shantanu {Kumar Das} and Padmanabh {Arun Gadge}},
keywords = {Ontology, Knowledge Based Framework, Joining Process, Plastic Assembly},
abstract = {Selection of assembly process is one of the important stage of product development which need to tackle at the earlier stage product realization. Selecting the most appropriate joining process needs various assembly joint information (liaison) which includes both the geometric and non-geometric information. To capture, represent, and reuse this information across domains is a highly knowledge-intensive process that necessitates the use of an active artificial intelligence (AI) tool. In this research, an AI tool called ontology-based knowledge framework is used to assist with identifying the best plastic assembly process to effectively support designers and process planners. The methodology for selecting a joining process and developing a knowledge-based framework is described, together with industrial application of the suggested approach is proposed. To express many key concepts like liaison, process, requirement for variant product etc., a joining process selection (JPS) ontology is created. To get the necessary knowledge for process selection that integrates several instances and knowledge rules, ontology mapping of joining method selection concepts is done using Semantic Web Rule Language (SWRL). The suggested method uses rule-based reasoning to automatically infer the best joining methods. Finally, industrial application of the suggested framework is proposed to assess the applicability of this approach.}
}
@article{GONG2025110396,
title = {The application progress and research trends of knowledge graphs and large language models in agriculture},
journal = {Computers and Electronics in Agriculture},
volume = {235},
pages = {110396},
year = {2025},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2025.110396},
url = {https://www.sciencedirect.com/science/article/pii/S0168169925005022},
author = {Ruizi Gong and Xinxing Li},
keywords = {Knowledge graphs, Large language models, Agricultural knowledge intelligent services},
abstract = {Enhancing agricultural productivity remains a crucial issue in agriculture, wherein agricultural knowledge intelligent services can improve the scientific and intelligent level of agricultural production through technologies such as knowledge coupling and inference decision-making. The application of knowledge graphs (KGs) in agriculture effectively supports the structured representation of agricultural data and helps manage agricultural data. On the other hand, the recent emergence of large language models (LLMs), with their strong language understanding and generation capabilities, provides new methods and ideas for knowledge services in agriculture. Though KGs and LLMs each have different strengths and limitations, their integration is believed to complement each other and has great potential to promote the development of agricultural knowledge intelligent services. In this paper, we review the current status of the application of KGs and LLMs in agriculture. We also discuss their complementary fusion as well as the prospect of their agricultural application, hoping to provide some references for the future development of agricultural knowledge intelligent services.}
}
@article{WU2024e35963,
title = {Eliminating ontology contradictions based on the Myerson value},
journal = {Heliyon},
volume = {10},
number = {16},
pages = {e35963},
year = {2024},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2024.e35963},
url = {https://www.sciencedirect.com/science/article/pii/S2405844024119949},
author = {Juanyong Wu and Wei Peng},
keywords = {Ontology contradictions, Cooperative game theory, Lexicographic approach, Myerson value, Shapley value},
abstract = {Ontologies play a pivotal role in knowledge representation across various artificial intelligence domains, serving as foundational frameworks for organizing data and concepts. However, the construction and evolution of ontologies frequently lead to logical contradictions that undermine their utility and accuracy. Typically, these contradictions are addressed using an Integer Linear Programming (ILP) model, which traditionally treats all formulas with equal importance, thereby neglecting the distinct impacts of individual formulas within minimal conflict sets. To advance this method, we integrate cooperative game theory to compute the Shapley value for each formula, reflecting its marginal contribution towards resolving logical contradictions. We further construct a graph-based representation of the ontology, enabling the extension of Shapley values to Myerson values. Subsequently, we introduce a Myerson-weighted ILP model that employs a lexicographic approach to eliminate logical contradictions in ontologies. The model ensures the minimum number of formula deletions, subsequently applying Myerson values to guide the prioritization of deletions. Our comparative analysis across 18 ontologies confirms that our approach not only preserves more graph edges than traditional ILP models but also quantifies formula contributions and establishes deletion priorities, presenting a novel approach to ILP-based contradiction resolution.}
}
@article{ABUSALIH2025819,
title = {Using large language models for semantic interoperability: A systematic literature review},
journal = {ICT Express},
volume = {11},
number = {4},
pages = {819-837},
year = {2025},
issn = {2405-9595},
doi = {https://doi.org/10.1016/j.icte.2025.06.011},
url = {https://www.sciencedirect.com/science/article/pii/S240595952500092X},
author = {Bilal Abu-Salih and Salihah Alotaibi and Albandari Lafi Alanazi and Ruba {Abu Khurma} and Bashar Al-Shboul and Ansar Khouri and Mohammed Aljaafari},
keywords = {ICT, Submission guideline, Template (8p)},
abstract = {Semantic Interoperability (SI) enables cross-domain data integration by allowing diverse systems to share and process information effectively. While existing reviews focus on general AI-driven interoperability, this systematic literature review (SLR) is the first to exclusively analyze the integration of Large Language Models (LLMs) with SI. This SLR uniquely evaluates LLMs' role in schema alignment, knowledge integration, and security risks. It also introduces a novel taxonomy and identifies challenges like bias propagation and computational costs, providing a new research framework for adversarial robustness, ethical AI, and real-world SI optimization. This is an open access article under the CC BY-NCND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).}
}
@incollection{FIONDA2019790,
title = {Ontology: Definition Languages},
editor = {Shoba Ranganathan and Michael Gribskov and Kenta Nakai and Christian Schönbach},
booktitle = {Encyclopedia of Bioinformatics and Computational Biology},
publisher = {Academic Press},
address = {Oxford},
pages = {790-799},
year = {2019},
isbn = {978-0-12-811432-2},
doi = {https://doi.org/10.1016/B978-0-12-809633-8.20393-2},
url = {https://www.sciencedirect.com/science/article/pii/B9780128096338203932},
author = {Valeria Fionda and Giuseppe Pirrò},
keywords = {Ontology, OWL, RDF, RDFS},
abstract = {Ontologies are artifacts used to model and represent in an explicit way knowledge related to a particular domain in terms of concepts, relations between concepts and axioms. In this article we provide an overview of ontology languages that have been defined under the umbrella of the W3C consortium. These language are characterized by different levels of expressiveness, starting from RDF, a simple language to express statements in the form of triples, to OWL, which enables very expressive forms of inference.}
}
@article{BAVARESCO2024110310,
title = {An ontology-based framework for worker’s health reasoning enabled by machine learning},
journal = {Computers & Industrial Engineering},
volume = {193},
pages = {110310},
year = {2024},
issn = {0360-8352},
doi = {https://doi.org/10.1016/j.cie.2024.110310},
url = {https://www.sciencedirect.com/science/article/pii/S0360835224004315},
author = {Rodrigo Bavaresco and Yutian Ren and Jorge Barbosa and G.P. Li},
keywords = {Knowledge representation, Ontology, Deep learning, Reasoning, Occupational health and safety},
abstract = {Reports of fatal and nonfatal workplace injuries depict severe circumstances involving health and safety in industries. This leads to workers staying away from work in U.S. for an average of 12 days in 2020, implicating in managerial, financial, and organizational losses. In this context, Vision-Based Deep Learning (VBDL) and Knowledge Representation and Reasoning (KRR) allow real-time data retrieval of situations along with the semantic modeling and expressivity of the real world to mitigate injuries. This article presents a framework that interoperates vision-based deep learning and ontology reasoning to identify adverse working situations, introducing a novel ontology composed of a holistic perspective of workers’ health and safety. Moreover, the article provides multi-agent framework modeling to orchestrate the components’ interoperability, describing the framework’s architecture and deployment in workrooms. As a result, a practical evaluation over five days produced 8395 axioms constituted by 1210 individuals in the ontology, which allowed a temporal analysis of harmful conditions and their multiple overlapping using SPARQL and reasoning rules, particularly relevant to understanding explanations of overexertion, physical and environmental injuries. Therefore, the proposed ontology-based framework corroborates the long-term support in identifying, assessing, and controlling risks in the industries due to a well-defined knowledge model.}
}
@article{CHANG2024,
title = {Use of SNOMED CT in Large Language Models: Scoping Review},
journal = {JMIR Medical Informatics},
volume = {12},
year = {2024},
issn = {2291-9694},
doi = {https://doi.org/10.2196/62924},
url = {https://www.sciencedirect.com/science/article/pii/S2291969424001364},
author = {Eunsuk Chang and Sumi Sung},
keywords = {SNOMED CT, ontology, knowledge graph, large language models, natural language processing, language models},
abstract = {Background
Large language models (LLMs) have substantially advanced natural language processing (NLP) capabilities but often struggle with knowledge-driven tasks in specialized domains such as biomedicine. Integrating biomedical knowledge sources such as SNOMED CT into LLMs may enhance their performance on biomedical tasks. However, the methodologies and effectiveness of incorporating SNOMED CT into LLMs have not been systematically reviewed.
Objective
This scoping review aims to examine how SNOMED CT is integrated into LLMs, focusing on (1) the types and components of LLMs being integrated with SNOMED CT, (2) which contents of SNOMED CT are being integrated, and (3) whether this integration improves LLM performance on NLP tasks.
Methods
Following the PRISMA-ScR (Preferred Reporting Items for Systematic Reviews and Meta-Analyses extension for Scoping Reviews) guidelines, we searched ACM Digital Library, ACL Anthology, IEEE Xplore, PubMed, and Embase for relevant studies published from 2018 to 2023. Studies were included if they incorporated SNOMED CT into LLM pipelines for natural language understanding or generation tasks. Data on LLM types, SNOMED CT integration methods, end tasks, and performance metrics were extracted and synthesized.
Results
The review included 37 studies. Bidirectional Encoder Representations from Transformers and its biomedical variants were the most commonly used LLMs. Three main approaches for integrating SNOMED CT were identified: (1) incorporating SNOMED CT into LLM inputs (28/37, 76%), primarily using concept descriptions to expand training corpora; (2) integrating SNOMED CT into additional fusion modules (5/37, 14%); and (3) using SNOMED CT as an external knowledge retriever during inference (5/37, 14%). The most frequent end task was medical concept normalization (15/37, 41%), followed by entity extraction or typing and classification. While most studies (17/19, 89%) reported performance improvements after SNOMED CT integration, only a small fraction (19/37, 51%) provided direct comparisons. The reported gains varied widely across different metrics and tasks, ranging from 0.87% to 131.66%. However, some studies showed either no improvement or a decline in certain performance metrics.
Conclusions
This review demonstrates diverse approaches for integrating SNOMED CT into LLMs, with a focus on using concept descriptions to enhance biomedical language understanding and generation. While the results suggest potential benefits of SNOMED CT integration, the lack of standardized evaluation methods and comprehensive performance reporting hinders definitive conclusions about its effectiveness. Future research should prioritize consistent reporting of performance comparisons and explore more sophisticated methods for incorporating SNOMED CT’s relational structure into LLMs. In addition, the biomedical NLP community should develop standardized evaluation frameworks to better assess the impact of ontology integration on LLM performance.}
}
@article{MASSARI20232392,
title = {Effectiveness of applying Machine Learning techniques and Ontologies in Breast Cancer detection},
journal = {Procedia Computer Science},
volume = {218},
pages = {2392-2400},
year = {2023},
note = {International Conference on Machine Learning and Data Engineering},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2023.01.214},
url = {https://www.sciencedirect.com/science/article/pii/S1877050923002144},
author = {Hakim El Massari and Noreddine Gherabi and Sajida Mhammedi and Zineb Sabouri and Hamza Ghandi and Fatima Qanouni},
keywords = {Prediction, Ontology, Machine Learning, SWRL, Breast cancer},
abstract = {Breast cancer is a disease that primarily affects women, but it can also affect men, although in a much smaller percentage. Recently, doctors have made great strides in this trend of early detection and treatment of breast cancer to reduce the number of deaths caused by this serious disease. Moreover, researchers are analyzing massive amounts of sophisticated medical data using a combination of statistical and machine learning approaches to help clinicians predict breast cancer. In the presented work, an ontological model based on the decision tree algorithm capable of reliably predicting breast cancer has been demonstrated. The method consists of extracting rules from the decision tree algorithm that distinguish between malignant and benign breast cancer patients, and then implementing these rules in the ontological reasoner via the Semantic Web Rule Language (SWRL). The results indicated that the ontological model achieved the highest prediction accuracy of 97.10%.}
}
@article{ZHOU2025127520,
title = {The status, evolution, and future challenges of multimodal large language models (LLMs) in parametric CAD},
journal = {Expert Systems with Applications},
volume = {282},
pages = {127520},
year = {2025},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2025.127520},
url = {https://www.sciencedirect.com/science/article/pii/S095741742501142X},
author = {Jiwei Zhou and Jorge D. Camba},
keywords = {Artificial intelligence, Large language models, LLMs, CAD, Parametric CAD modeling, Engineering design, Product development},
abstract = {Parametric Computer-Aided Design (CAD) systems are fundamental tools in mechanical and product design to facilitate the precise generation of complex geometries. However, their steep learning curve restricts accessibility to non-experts, hindering collaboration and creativity in engineering workflows. Recent breakthroughs in Artificial Intelligence (AI), especially Large Language Models (LLMs), are providing new opportunities to redefine parametric CAD workflows. By enabling natural language and multimodal interactions, LLMs can reduce technical obstacles and allow users to intuitively convey design intents and requirements. This work critically examines the intersection between LLMs and parametric CAD modeling, emphasizing key advancements in automating tasks such as 2D sketching, 3D model generation, and design optimization. It also discusses progress in natural language interface development and identifies current challenges. Although LLMs exhibit the capacity to improve productivity and design accessibility, obstacles remain in understanding design intent and context, managing intricate geometries, optimizing model training with diverse datasets and benchmarking frameworks, guaranteeing interoperability, scalability, and security within CAD systems, and expanding industrial applications. Through a thorough analysis, this review identifies essential areas for future research to enable the practical integration of LLMs and parametric CAD modeling. The results highlight the potential of LLMs to simplify design processes, stimulate creativity, and reshape engineering design practices across applications in mechanical product development.}
}
@article{RAMESH2024100677,
title = {An interoperable ontology for CPS-enabled Polyhouse Solar Dryer: A case study of the AgroESP project},
journal = {Journal of Industrial Information Integration},
volume = {42},
pages = {100677},
year = {2024},
issn = {2452-414X},
doi = {https://doi.org/10.1016/j.jii.2024.100677},
url = {https://www.sciencedirect.com/science/article/pii/S2452414X24001171},
author = {Gowtham Ramesh and P. {Dheepan Kanna} and C. {Shunmuga Velayutham} and Jancirani Ramaswamy},
keywords = {Polyhouse solar dryer, Polyhouse ontology, Interoperability, CPS, Food preservation},
abstract = {Polyhouse is a commonly used conventional method for solar drying of food products. These Polyhouse Solar Driers (PSDs) are characterized by their enclosed structure and translucent covering, providing a controlled environment conducive to efficient food drying. Smart polyhouses, equipped with a Cyber-Physical System (CPS), further enhance this process by optimizing environmental conditions and enabling real-time monitoring. In smart PSDs, the data are obtained from diverse sources with different specifications in accuracy, resolution, and range. This multifaceted nature of the information obtained from various sources significantly compounds the complexity of the system. This complexity of data from diverse sources within smart polyhouses necessitates a standardized knowledge representation. Ontologies serve this purpose by establishing a common vocabulary and structure for data integration, promoting semantic interoperability and effective communication among diverse systems. This paper proposes a novel unified ontology designed to model complex polyhouse CPSs, aiming to address semantic interoperability issues and streamline data integration across various domains. The proposed polyhouse ontology attempts to reuse the concepts defined in existing ontologies rather defining new concepts for efficient knowledge sharing and enhanced understanding of polyhouse operations. The practical applicability of the polyhouse ontology has been verified with competency questions and through field deployment in a CPS enabled smart Polyhouse Solar Dryer.}
}
@article{YANG2023102185,
title = {Ontology-based knowledge representation of industrial production workflow},
journal = {Advanced Engineering Informatics},
volume = {58},
pages = {102185},
year = {2023},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2023.102185},
url = {https://www.sciencedirect.com/science/article/pii/S1474034623003130},
author = {Chao Yang and Yuan Zheng and Xinyi Tu and Riku Ala-Laurinaho and Juuso Autiosalo and Olli Seppänen and Kari Tammi},
keywords = {Production workflow, Ontology, System integration, Knowledge representation, Semantic interoperability},
abstract = {Industry 4.0 is helping to unleash a new age of digitalization across industries, leading to a data-driven, interoperable, and decentralized production process. To achieve this major transformation, one of the main requirements is to achieve interoperability across various systems and multiple devices. Ontologies have been used in numerous industrial projects to tackle the interoperability challenge in digital manufacturing. However, there is currently no semantic model in the literature that can be used to represent the industrial production workflow comprehensively while also integrating digitalized information from a variety of systems and contexts. To fill this gap, this paper proposed industrial production workflow ontologies (InPro) for formalizing and integrating production process information. We implemented the 5 M model (manpower, machine, material, method, and measurement) for InPro partitioning and module extraction. The InPro comprises seven main domain ontology modules including Entities, Agents, Machines, Materials, Methods, Measurements, and Production Processes. The Machines ontology module was developed leveraging the OPC Unified Architecture (OPC UA) information model. The presented InPro ontology was further evaluated by a hybrid combination of approaches. Additionally, the InPro ontology was implemented with practical use cases to support production planning and failure analysis by retrieving relevant information via SPARQL queries. The validation results also demonstrated that using the proposed InPro ontology allows for efficiently formalizing, integrating, and retrieving information within the industrial production process context.}
}
@article{DEEPAK2022107736,
title = {An artificially intelligent approach for automatic speech processing based on triune ontology and adaptive tribonacci deep neural networks},
journal = {Computers & Electrical Engineering},
volume = {98},
pages = {107736},
year = {2022},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2022.107736},
url = {https://www.sciencedirect.com/science/article/pii/S0045790622000489},
author = {Gerard Deepak and Deepak Surya and Ishdutt Trivedi and Ayush Kumar and Amrutha Lingampalli and Santhana vijayan},
keywords = {Acoustic model, Automatic speech recognition, Tribonacci deep neural network},
abstract = {Automatic Speech Recognition systems have become essential for an independent automation during the present-day era. A hybrid approach for Automatic Speech Recognition, the TriNNOnto has been proposed in this paper which, integrates different approaches like Language Model integrated with dynamic Triune Ontology generation scheme, Acoustic Model and Feature modelling are hybridised based on the Tribonacci based Deep Neural Network, which decides upon the number of layers depending on the size of the samples and their count. The dynamic generation of Ontologies based on the language models and triune ontology for automatic speech recognition is quite novel. The strategies for feature extraction as and the Tribonacci based deep neural network, based the dynamic adjustment of the number of layers using Tribonacci series contributes towards novelty as well as enhances the performance of speech recognition. The proposed strategy has been evaluated for two datasets and an accuracy of 98.15% and 95.18%, have been achieved for the CMUKids and the TIMIT datasets, respectively with low word error rates.}
}
@article{MELIN2024103427,
title = {Tomorrow let’s all be pangolins! Western affirmation of a relational ontology in thinking and acting for a multi-species future},
journal = {Futures},
volume = {162},
pages = {103427},
year = {2024},
issn = {0016-3287},
doi = {https://doi.org/10.1016/j.futures.2024.103427},
url = {https://www.sciencedirect.com/science/article/pii/S0016328724001101},
author = {Hélène Melin},
keywords = {Justice, Multi-species, Naturalism, Other-than-humans, Relational ontology, Solidarity},
abstract = {How should we envision the future of environmental justice in a context where the imbalances between part of humanity and other living beings seem irreversible and could compromise the survival of the majority? The scientific world and activist movements, both in the West and among indigenous peoples, are making their voices heard to denounce an industrial, productivist and extractivisit lifestyle that is predatory and incompatible with ensuring the well-being and intentionalities of all living beings. The ontological framework of the Anthropocene era seems to support this type of social relationship of domination. Indeed, naturalism puts humans as distinct from the rest of the animal kingdom and as having the right to use the different components of the environment as material resources. Due to the succession of environmental and social crises, whether worldwide or local, these power relationships need to be re-examined. The study of scientific results and observations from the last forty years, listening to people’s accounts of their attachments to their living environment, and the observation of new social and environmental movements all point to the emergence of hybrid ontologies that question naturalism, opening the door to the possibility of multi-species justice as an alternative to inequality.}
}
@article{RICKARD2024103755,
title = {Dam the river: Ontological exclusion in global and Brazilian Integrated Water Resources Management},
journal = {Environmental Science & Policy},
volume = {156},
pages = {103755},
year = {2024},
issn = {1462-9011},
doi = {https://doi.org/10.1016/j.envsci.2024.103755},
url = {https://www.sciencedirect.com/science/article/pii/S1462901124000893},
author = {Thomas Rickard and David Ludwig},
keywords = {Ontology, Brazil, Water Governance, Policy, Participation},
abstract = {Integrated Water Resource Management (IWRM) has been widely adopted as a norm that promises to increase equality and sustainability of water governance through participatory decision-making. After decades of policy implementation, however, inequalities in outcomes and large-scale water-related disasters raise questions about the ability of IWRM to deliver on its promises. This article explores these questions by putting the history of IWRM at the global scale in conversation with the national scale of water governance in Brazil and the local scale of the Rio Doce, the site of the largest single environmental disaster in Brazilian history. This conversation highlights truncated practices of inclusion in which participation of diverse actors is possible only within an account of water as a resource system. Mobilizing recent debates about the Ontological Turn in social sciences and humanities, we argue that the appeal to inclusion in IWRM masks ontological exclusion in which participation is dependent on an ontology of water as a resource system. The case of the Rio Doce shows how promises of equality and sustainability through inclusion fail in the light of rendering local ontologies invisible or illegitimate for governance. In framing IWRM as a site of ontological inequality, groundwork is laid for a renewed promise of participation.}
}
@article{DU2025106317,
title = {OFPO & KGFPO: Ontology and knowledge graph for flood process observation},
journal = {Environmental Modelling & Software},
volume = {185},
pages = {106317},
year = {2025},
issn = {1364-8152},
doi = {https://doi.org/10.1016/j.envsoft.2025.106317},
url = {https://www.sciencedirect.com/science/article/pii/S1364815225000015},
author = {Wenying Du and Chang Liu and Qingyun Xia and Mengtian Wen and Ying Hu and Zeqiang Chen and Lei Xu and Xiang Zhang and Berhanu Keno Terfa and Nengcheng Chen},
keywords = {Flood, Process observation, Ontology, Knowledge graph},
abstract = {Flooding is the most frequent natural disaster globally, resulting in the highest economic losses. Efficient resource retrieval is crucial for improving flood response. Constructing a knowledge graph aids in the precise discovery of flood observation resources. However, current research faces issues: phased flood process observation is neglected, and effective correlation among disaster elements, such as tasks, data, methods, and sensors, is lacking. To address this, we construct the Ontology for Flood Process Observation (OFPO) and develop the Knowledge Graph for Flood Process Observation (KGFPO), providing integrated management and decision-making support. These are validated using the “7–20 Henan Extremely Heavy Rainfall” and “7-21 Xinxiang Extremely Heavy Rainfall” cases. OFPO and KGFPO achieve integrated management of flood observation resources, improve retrieval efficiency and accuracy, facilitate decision-making, and support other natural disasters.}
}
@article{SANTOS2024122104,
title = {O3PO: A domain ontology for offshore petroleum production plants},
journal = {Expert Systems with Applications},
volume = {238},
pages = {122104},
year = {2024},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2023.122104},
url = {https://www.sciencedirect.com/science/article/pii/S0957417423026064},
author = {Nicolau O. Santos and Fabrício H. Rodrigues and Daniela Schmidt and Régis K. Romeu and Givanildo Nascimento and Mara Abel},
keywords = {Petroleum, Ontology, Production plants, Offshore, Digital twins},
abstract = {The challenge of integrating data from many data sources has persisted as an issue in several industry areas. With the evolution of technology in the upstream petroleum sector (i.e., exploration and production), the petroleum business must contend with technological silos from diverse service providers and suffers from the associated waste of time to locate data and information throughout siloed databases. Based on a thorough compilation of industry-oriented requirements in the form of use cases and competency questions, this document defines a domain ontology for defining entities in offshore petroleum production plants. The objective is to develop a uniform and clearly defined reference vocabulary to aid engineers and information technology professionals in labeling and relating production plant monitoring, simulation measures, and facilities. BFO is the top-level ontology, while GeoCore and a continuing version of the core ontology developed by the Industry Ontology Foundry (IOF) configure the middle-level ontologies. We have studied and combined several other resources to build the ontology, such as glossaries from the industry and related ontologies. The research resulted in a well-founded domain ontology that provides universals, defined classes, and relations that can be useful in several types of applications in the domain. We have demonstrated the utility of the ontology within an actual scenario in an offshore petroleum field in Brazil, where we conceived and applied the domain ontology. This study is a component of the PeTWIN project,22Petwin is an academic cooperation between UFRGS, UiO, and Libra, Equinor, and Shell companies (www.petwin.org). which looks at the best approaches for creating digital twins of offshore petroleum plants.}
}
@article{WU2024120804,
title = {Unveiling the core functional networks of cognition: An ontology-guided machine learning approach},
journal = {NeuroImage},
volume = {298},
pages = {120804},
year = {2024},
issn = {1053-8119},
doi = {https://doi.org/10.1016/j.neuroimage.2024.120804},
url = {https://www.sciencedirect.com/science/article/pii/S105381192400301X},
author = {Guowei Wu and Zaixu Cui and Xiuyi Wang and Yi Du},
keywords = {Cognitive ontology, Functional networks, Machine learning},
abstract = {Deciphering the functional architecture that underpins diverse cognitive functions is fundamental quest in neuroscience. In this study, we employed an innovative machine learning framework that integrated cognitive ontology with functional connectivity analysis to identify brain networks essential for cognition. We identified a core assembly of functional connectomes, primarily located within the association cortex, which showed superior predictive performance compared to two conventional methods widely employed in previous research across various cognitive domains. Our approach achieved a mean prediction accuracy of 0.13 across 16 cognitive tasks, including working memory, reading comprehension, and sustained attention, outperforming the traditional methods' accuracy of 0.08. In contrast, our method showed limited predictive power for sensory, motor, and emotional functions, with a mean prediction accuracy of 0.03 across 9 relevant tasks, slightly lower than the traditional methods' accuracy of 0.04. These cognitive connectomes were further characterized by distinctive patterns of resting-state functional connectivity, structural connectivity via white matter tracts, and gene expression, highlighting their neurogenetic underpinnings. Our findings reveal a domain-general functional network fingerprint that pivotal to cognition, offering a novel computational approach to explore the neural foundations of cognitive abilities.}
}
@article{SOYLU2024104416,
title = {A new ontology for numerical cognition: Integrating evolutionary, embodied, and data informatics approaches},
journal = {Acta Psychologica},
volume = {249},
pages = {104416},
year = {2024},
issn = {0001-6918},
doi = {https://doi.org/10.1016/j.actpsy.2024.104416},
url = {https://www.sciencedirect.com/science/article/pii/S0001691824002932},
author = {Firat Soylu},
keywords = {Numerical cognition, Mathematics, Embodied cognition, Evolution, Neuroimaging, Ontology},
abstract = {Numerical cognition is a field that investigates the sociocultural, developmental, cognitive, and biological aspects of mathematical abilities. Recent findings in cognitive neuroscience suggest that cognitive skills are facilitated by distributed, transient, and dynamic networks in the brain, rather than isolated functional modules. Further, research on the bodily and evolutionary bases of cognition reveals that our cognitive skills harness capacities originally evolved for action and that cognition is best understood in conjunction with perceptuomotor capacities. Despite these insights, neural models of numerical cognition struggle to capture the relation between mathematical skills and perceptuomotor systems. One front to addressing this issue is to identify building block sensorimotor processes (BBPs) in the brain that support numerical skills and develop a new ontology connecting the sensorimotor system with mathematical cognition. BBPs here are identified as sensorimotor functions, associated with distributed networks in the brain, and are consistently identified as supporting different cognitive abilities. BBPs can be identified with new approaches to neuroimaging; by examining an array of sensorimotor and cognitive tasks in experimental designs, employing data-driven informatics approaches to identify sensorimotor networks supporting cognitive processes, and interpreting the results considering the evolutionary and bodily foundations of mathematical abilities. New empirical insights on the BBPs can eventually lead to a revamped embodied cognitive ontology in numerical cognition. Among other mathematical skills, numerical magnitude processing and its sensorimotor origins are discussed to substantiate the arguments presented. Additionally, an fMRI study design is provided to illustrate the application of the arguments presented in empirical research.}
}
@article{RJIBA20243158,
title = {Ontological model for intelligent assessment in collaborative environment based on serious games},
journal = {Procedia Computer Science},
volume = {246},
pages = {3158-3167},
year = {2024},
note = {28th International Conference on Knowledge Based and Intelligent information and Engineering Systems (KES 2024)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.09.719},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924027881},
author = {Ameny Rjiba and Lilia Cheniti Belcadhi and Judita Kasperiuniene},
keywords = {Serious Games, Artificial Intelligence, Collaborative Learning, Intelligent Assessment, Ontological Model, Adaptivity, Personalization, Stealth Assessment},
abstract = {In today’s collaborative learning environments, effective assessment plays an important role in assessing knowledge acquisition and fostering skill development. The integration of serious games adds an interactive and engaging dimension to these environments, offering opportunities for immersive learning experiences. This combination not only evaluates learners’ progress but also enhances their engagement and motivation, contributing to more effective educational outcomes. This research proposes an innovative ontological model specifically designed for intelligent assessment scenarios with serious games in collaborative environments. Our research aims to enhance learning experiences and skill development by integrating artificial intelligence, education, and serious games. The suggested ontological model incorporates stealthy assessment methods, personalization, and adaptivity to accurately represent the dynamics of collaborative serious gaming. Our approach fills in the gaps in the research by integrating personalized instruction, stealth assessment, and adaptive gameplay in a collaborative environment. We validate the model to make sure it is accurate and consistent and to make sure there are no logical conflicts. This work creates paths for future research, focusing on intelligent assessment and collaborative learning within the context of educational serious games.}
}
@article{GHELFI2025117,
title = {Hayai-Annotation: A functional gene prediction tool that integrates orthologs and gene ontology for network analysis in plant species},
journal = {Computational and Structural Biotechnology Journal},
volume = {27},
pages = {117-126},
year = {2025},
issn = {2001-0370},
doi = {https://doi.org/10.1016/j.csbj.2024.12.011},
url = {https://www.sciencedirect.com/science/article/pii/S2001037024004331},
author = {Andrea Ghelfi and Sachiko Isobe},
keywords = {Functional annotation, Network analysis, GO enrichment, Ortholog inferences, Co-occurrence of orthologs and Gene Ontologies},
abstract = {Hayai-Annotation, an annotation tool powered by the R-shinydashboard browser interface, implements a workflow that integrates sequence alignment using DIAMOND against UniProtKB Plants and ortholog inference using OrthoLoger. We here propose a pipeline to explore genome evolution and adaptation from a different perspective, by creating a network considering orthologs and gene ontology as nodes, with edges based on the annotation for each gene. This approach aims to improve the visualization of conserved biological processes and functions, highlight species-specific adaptations, and enhance the ability to infer the functions of uncharacterized genes by comparing edge patterns across species. To our knowledge, this is the first attempt to build a network using annotated OrthoDB orthologs and Gene Ontology terms (Molecular Function and Biological Process) as nodes, providing a comprehensive view of gene distribution and function in plant species. The GO annotation accuracy was assessed by the CAFA-evaluator, demonstrating that the accuracy of this version of Hayai-Annotation exceeded that of the benchmark, InterProScan. The updated Hayai-Annotation enhances ortholog analysis functionality, allowing for evolutionary insights from gene sequences, and is expected to contribute significantly to the future development of plant genome analysis.}
}
@article{SANDHU2025100248,
title = {Supporting secure and efficient collaborative health information exchange: A hybrid blockchain and ontology based approach},
journal = {Blockchain: Research and Applications},
volume = {6},
number = {1},
pages = {100248},
year = {2025},
issn = {2096-7209},
doi = {https://doi.org/10.1016/j.bcra.2024.100248},
url = {https://www.sciencedirect.com/science/article/pii/S2096720924000617},
author = {Ramandeep Kaur Sandhu and Manoj A Thomas and Kweku Muata Osei-Bryson},
keywords = {Security, Semantic interoperability, Trust, Blockchain, Interactive ontology mapping},
abstract = {Patients visit different healthcare institutions during their lifetime, and as a result, their personal health records are stored across different healthcare information systems. Cross-institutional patient data sharing is essential to provide caregivers with a comprehensive view of patients’ health profiles and improving the quality of care. However, security, semantic interoperability, and trust are major barriers that limit seamless exchange of healthcare data. To address these concerns, we apply the Design Science Research (DSR) methodology to propose and develop a functional blockchain-based healthcare information exchange system. At its core, the DSR artifact, called Blockchain-based Healthcare Information Exchange System (B-HIES), integrates private permissioned blockchain technology and interactive ontology mapping techniques. The efficacy and complementarity of the solution are evaluated based on a combination of scenario-based simulation and logically informed arguments. The integration of permissioned blockchain technology and interactive ontology mapping techniques in our proposed solution provides secure, reliable, and trustworthy data exchange among healthcare institutions. This paper discusses how the solution streamlines patent data exchange in heterogeneous healthcare networks. We note that developing such a system is a complex process and requires the involvement of experts with specialized knowledge in a variety of disciplines, such as blockchain, ontologies, healthcare, and medicine.}
}
@article{SANCHEZZAS2024101267,
title = {A methodology for ontology-based interoperability of dynamic risk assessment frameworks in IoT environments},
journal = {Internet of Things},
volume = {27},
pages = {101267},
year = {2024},
issn = {2542-6605},
doi = {https://doi.org/10.1016/j.iot.2024.101267},
url = {https://www.sciencedirect.com/science/article/pii/S2542660524002087},
author = {Carmen Sánchez-Zas and Xavier Larriva-Novo and Víctor A. Villagrá and Diego Rivera and Andrés Marín-Lopez},
keywords = {Methodology, Risk assessment, Ontology, Internet of Things, Cybersecurity, Support to decision making},
abstract = {Proper cyber risk management is essential for organizations to make informed decisions and avoid potential financial losses, reputational damage, operational disruptions and other negative impacts. To this end, different institutions have defined risk analysis and risk management methodologies to address the problem and monitor cyber security in organizations. In this aspect, ontologies provide a very powerful tool for interoperability in risk management, given the heterogeneity of input information considered in the different steps of each framework and the ability they provide to perform logical reasoning in order to infer new knowledge. Throughout this study we analyze the different properties of some of the methodologies with the highest adoption rate, proposing an interoperable framework based on an ontology that allows compatibility between different systems, with a dynamic, flexible and efficient operation.}
}
@article{HARI2023367,
title = {WSD based Ontology Learning from Unstructured Text using Transformer},
journal = {Procedia Computer Science},
volume = {218},
pages = {367-374},
year = {2023},
note = {International Conference on Machine Learning and Data Engineering},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2023.01.019},
url = {https://www.sciencedirect.com/science/article/pii/S1877050923000194},
author = {Akshay Hari and Priyanka Kumar},
keywords = {Deep Learning, Transformers, Ontology, Word Sense Disambiguation, RDF},
abstract = {Representation of knowledge and making it machine comprehensible has become a necessity in modern times but with the large amount of data being generated nowadays, this process has to be automated as much as possible. In this work, we propose a deep-learning based model to build an RDF based Ontology from Unstructured Text. We aim to evaluate the proposed model by creating a general knowledge ontology from newspaper article corpora. The proposed model is based on transformer, Natural Language Processing and contains a Relation Extraction model and novel implementation of RDF mapping algorithm. The main highlight of our model is its ability to handle the Word Sense Disambiguation problem. The model was able to perform well and achieved very high accuracy scores.}
}
@article{HASSEN2024380,
title = {Business View Specification of Enterprise Information Systems Based on Core Ontologies},
journal = {Procedia Computer Science},
volume = {237},
pages = {380-388},
year = {2024},
note = {International Conference on Industry Sciences and Computer Science Innovation},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.05.118},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924011347},
author = {Mariem Ben Hassen and Sahbi Zahaf and Faiez Gargouri},
keywords = {Enterprise Information Systems, Business Process modeling, Knowledge Management, Sensitive Business Process, Core Domain Ontologies, BPMN 2.0.2},
abstract = {Enterprise Information Systems (EIS) supporting Business Processes (BPs), particularly Sensitive Business Processes (SBPs), should be characterized by integrity, flexibility, and interoperability. However, the urbanization approach, which we rely on to implement these systems, must address the “three fit” problems that hinder the realization of these desired features at both the business and technical infrastructures: “vertical fit” problems – concerning the business infrastructure; “horizontal fit” problems and “transversal fit” problems – concerning the technical infrastructure. We argue that for overcoming those problems, it is necessary to define an explicit framework for specifying BPs/SBPs. We present in this paper our conceptual specification for the BPs/SBPs modeling domain in the form of a core domain ontology, in order to overcome “horizontal fit” and “transversal fit” problems. Specifically, we introduce (i) our reference ontological framework and (ii) provide an overview of the Core Ontology of Sensitive Business Processes (COSBP). Our focus lies in the representation of SBPs in order to overcome “vertical fit” problems.}
}
@article{WU2023113267,
title = {An ontology-based framework for automatic building energy modeling with thermal zoning},
journal = {Energy and Buildings},
volume = {296},
pages = {113267},
year = {2023},
issn = {0378-7788},
doi = {https://doi.org/10.1016/j.enbuild.2023.113267},
url = {https://www.sciencedirect.com/science/article/pii/S0378778823004978},
author = {Zhaoji Wu and Jack C.P. Cheng and Zhe Wang and Helen H.L. Kwok},
keywords = {Building energy modeling, Ontology, Data integration, Thermal zone, Model translation},
abstract = {Building Energy Modeling (BEM) has wide application in building design and operation stages. Developing BEM requires numerous data from multiple sources, and therefore is time consuming and expertise demanding. Building Information Modeling can provide information needed for BEM, but a seamless transfer of BIM to BEM is not available yet. This study proposes an ontology-based automatic framework aimed at integrating multiple data sources and automatically generating BEM models, in which the ontology model could integrate data from weather, building, internal heat gain, and Heating, Ventilation, and Air Conditioning system. We developed a cross-domain and rule-based reasoning method for thermal zoning, and an automatic ontology model to BEM model translation method using instance-based mapping and dynamic data conversion. We demonstrated our approach by developing a BEM model for one floor of a campus building. The results showed that the proposed framework could automatically generate the model that has the potential to reduce the modeling time by over 99% comparing with manual modeling.}
}
@article{BERNARDO2025104861,
title = {Ontological framework for high-level task replanning for autonomous robotic systems},
journal = {Robotics and Autonomous Systems},
volume = {184},
pages = {104861},
year = {2025},
issn = {0921-8890},
doi = {https://doi.org/10.1016/j.robot.2024.104861},
url = {https://www.sciencedirect.com/science/article/pii/S0921889024002458},
author = {Rodrigo Bernardo and João M.C. Sousa and Paulo J.S. Gonçalves},
keywords = {Semantic knowledge, Ontologies, Autonomous robotic systems, Replanning, Robot control platforms},
abstract = {Several frameworks for robot control platforms have been developed in recent years. However, strategies that incorporate automatic replanning have to be explored, which is a requirement for Autonomous Robotic Systems (ARS) to be widely adopted. Ontologies can play an essential role by providing a structured representation of knowledge. This paper proposes a new framework capable of replanning high-level tasks in failure situations for ARSs. The framework utilizes an ontology-based reasoning engine to overcome constraints and execute tasks through Behavior Trees (BTs). The proposed framework was implemented and validated in a real experimental environment using an Autonomous Mobile Robot (AMR) sharing a plan with a human operator. The proposed framework uses semantic reasoning in the planning system, offering a promising solution to improve the adaptability and efficiency of ARSs.}
}
@article{GOLEC2023,
title = {Comprehensive Ontology of Fibroproliferative Diseases: Protocol for a Semantic Technology Study},
journal = {JMIR Research Protocols},
volume = {12},
year = {2023},
issn = {1929-0748},
doi = {https://doi.org/10.2196/48645},
url = {https://www.sciencedirect.com/science/article/pii/S1929074823003359},
author = {Marcin Golec and Maulik Kamdar and Sandra Barteit},
keywords = {fibroproliferative disease, fibrosis, fibrotic disease, ontology, OWL, semantic technology, Web Ontology Language},
abstract = {Background
Fibroproliferative or fibrotic diseases (FDs), which represent a significant proportion of age-related pathologies and account for over 40% of mortality in developed nations, are often underrepresented in focused research. Typically, these conditions are studied individually, such as chronic obstructive pulmonary disease or idiopathic pulmonary fibrosis (IPF), rather than as a collective entity, thereby limiting the holistic understanding and development of effective treatments. To address this, we propose creating and publicizing a comprehensive fibroproliferative disease ontology (FDO) to unify the understanding of FDs.
Objective
This paper aims to delineate the study protocol for the creation of the FDO, foster transparency and high quality standards during its development, and subsequently promote its use once it becomes publicly available.
Methods
We aim to establish an ontology encapsulating the broad spectrum of FDs, constructed in the Web Ontology Language format using the Protégé ontology editor, adhering to ontology development life cycle principles. The modeling process will leverage Protégé in accordance with a methodologically defined process, involving targeted scoping reviews of MEDLINE and PubMed information, expert knowledge, and an ontology development process. A hybrid top-down and bottom-up strategy will guide the identification of core concepts and relations, conducted by a team of domain experts based on systematic iterations of scientific literature reviews.
Results
The result will be an exhaustive FDO accommodating a wide variety of crucial biomedical concepts, augmented with synonyms, definitions, and references. The FDO aims to encapsulate diverse perspectives on the FD domain, including those of clinicians, health informaticians, medical researchers, and public health experts.
Conclusions
The FDO is expected to stimulate broader and more in-depth FD research by enabling reasoning, inference, and the identification of relationships between concepts for application in multiple contexts, such as developing specialized software, fostering research communities, and enhancing domain comprehension. A common vocabulary and understanding of relationships among medical professionals could potentially expedite scientific progress and the discovery of innovative solutions. The publicly available FDO will form the foundation for future research, technological advancements, and public health initiatives.
International Registered Report Identifier (IRRID)
PRR1-10.2196/48645}
}
@article{HU20223016,
title = {Ontology-centric industrial requirements validation for aircraft assembly system design},
journal = {IFAC-PapersOnLine},
volume = {55},
number = {10},
pages = {3016-3021},
year = {2022},
note = {10th IFAC Conference on Manufacturing Modelling, Management and Control MIM 2022},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2022.10.191},
url = {https://www.sciencedirect.com/science/article/pii/S2405896322022054},
author = {Xiaodu Hu and Rebeca Arista and Joachim Lentes and Jinzhi Lu and Xiaochen Zheng and Jyri Sorvari and Fernando Ubis and Dimitris Kiritsis},
keywords = {Ontology based system, ontology integration, industrial requirements validation, MBSE},
abstract = {The development of an aircraft industrial system faces the challenge of integrative requirements validation with de-correlated modelling languages and distributed proprietary formats. This paper specifies an ontology-centric industrial requirements validation based on a cognitive digital twin approach, aiming at addressing the potentials of utilizing MBSE ontology integration for different models and leveraging a top level ontology BFO as a semantic core to integrate cross-disciplinary requirement validation, heterogonous models and simulations towards an optimized digital consistency, interoperability and reusability, with an example of such requirements validation presented.}
}
@article{MEERWIJK2024104582,
title = {Development of a 3-Step theory of suicide ontology to facilitate 3ST factor extraction from clinical progress notes},
journal = {Journal of Biomedical Informatics},
volume = {150},
pages = {104582},
year = {2024},
issn = {1532-0464},
doi = {https://doi.org/10.1016/j.jbi.2023.104582},
url = {https://www.sciencedirect.com/science/article/pii/S1532046423003039},
author = {Esther L. Meerwijk and Gabrielle A. Jones and Asqar S. Shotqara and Sofia Reyes and Suzanne R. Tamang and Hyrum S. Eddington and Ruth M. Reeves and Andrea K. Finlay and Alex H.S. Harris},
keywords = {Suicide, Natural language processing, Electronic health records, Controlled vocabulary, Veterans health services, Psychological pain},
abstract = {Objective
Suicide risk prediction algorithms at the Veterans Health Administration (VHA) do not include predictors based on the 3-Step Theory of suicide (3ST), which builds on hopelessness, psychological pain, connectedness, and capacity for suicide. These four factors are not available from structured fields in VHA electronic health records, but they are found in unstructured clinical text. An ontology and controlled vocabulary that maps psychosocial and behavioral terms to these factors does not exist. The objectives of this study were 1) to develop an ontology with a controlled vocabulary of terms that map onto classes that represent the 3ST factors as identified within electronic clinical progress notes, and 2) to determine the accuracy of automated extractions based on terms in the controlled vocabulary.
Methods
A team of four annotators did linguistic annotation of 30,000 clinical progress notes from 231 Veterans in VHA electronic health records who attempted suicide or who died by suicide for terms relating to the 3ST factors. Annotation involved manually assigning a label to words or phrases that indicated presence or absence of the factor (polarity). These words and phrases were entered into a controlled vocabulary that was then used by our computational system to tag 14 million clinical progress notes from Veterans who attempted or died by suicide after 2013. Tagged text was extracted and machine-labelled for presence or absence of the 3ST factors. Accuracy of these machine-labels was determined for 1000 randomly selected extractions for each factor against a ground truth created by our annotators.
Results
Linguistic annotation identified 8486 terms that related to 33 subclasses across the four factors and polarities. Precision of machine-labeled extractions ranged from 0.73 to 1.00 for most factor-polarity combinations, whereas recall was somewhat lower 0.65–0.91.
Conclusion
The ontology that was developed consists of classes that represent each of the four 3ST factors, subclasses, relationships, and terms that map onto those classes which are stored in a controlled vocabulary (https://bioportal.bioontology.org/ontologies/THREE-ST). The use case that we present shows how scores based on clinical notes tagged for terms in the controlled vocabulary capture meaningful change in the 3ST factors during weeks preceding a suicidal event.}
}
@article{TSE2024103772,
title = {Ontological conceptions of information cannot account for consciousness},
journal = {Consciousness and Cognition},
volume = {126},
pages = {103772},
year = {2024},
issn = {1053-8100},
doi = {https://doi.org/10.1016/j.concog.2024.103772},
url = {https://www.sciencedirect.com/science/article/pii/S1053810024001399},
author = {Peter Ulric Tse},
keywords = {Consciousness, Panpsychism, Information, Decoding},
abstract = {Epistemological and ontological conceptions of information are contrasted. The former are based on acts of decoding of extrinsic inputs that result in a decoder becoming informed. The latter are based on intrinsic states or state changes of the system independent of any external factors such as inputs to the system. Ontological conceptions of information, such as those that underlie integrated information theory or any theory that allies itself with panpsychism, are not able to account for consciousness. In the only physical systems that are known to be conscious, namely, animal brains, acts of decoding extrinsic inputs are central to creating consciousness and its contents. Moreover, only a very specific subset of decodings should realize consciousness, because consciousness in animals evolved to create an evaluative experience of what is intrinsically true about the world and the body, which is then used in a perception–action cycle that affords choices among options for behaving in the world in order to accomplish goals.}
}
@article{CASTILLOBARRERA2023107282,
title = {Verifying contracts among software components: An ontology-based approach},
journal = {Information and Software Technology},
volume = {163},
pages = {107282},
year = {2023},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2023.107282},
url = {https://www.sciencedirect.com/science/article/pii/S0950584923001362},
author = {Francisco-Edgar Castillo-Barrera and Hector A. Duran-Limon},
keywords = {Component-based development, Contract verification, Software components, ADL, Ontology, SPARQL},
abstract = {Context:
The goal of Component-Based Software Engineering (CBSE) is the development of software systems in terms of an assembly of pre-fabricated software components. One of the main aims of CBSE is to increase software reuse whereby a software component becomes part of different software systems. Verification is an important task that ensures contract conformance among components. However, current techniques for verification of component matching are poorly used in industry due to the fact that the use of these techniques is complex since they require specialized expertise. Also, the use of such techniques can be time-consuming.
Objective:
In this paper, we present Moctezuma, a framework for verifying the matching of software components that does not require the user possessing highly specialized skills and is able to check contract conformance of functional semantics aspects.
Method:
Our approach relies on a core ontology of software components, which captures the concepts, properties, relationships, requirements, and software component functionality. We make use of architecture description languages (ADLs) to specify configurations of component interconnections. Interface contracts are specified with a customized version of CORBA-IDL. We employ ontology reasoning engines to check conformance among interface contracts.
Results:
The accuracy evaluation results have shown that our verifier has a high accuracy for detecting semantics errors. The scalability evaluation shows that our framework exhibits almost a linear behavior.
Conclusions:
It is concluded that our framework is suitable for verifying the conformance of interface contracts, involving semantics aspects, along a configuration of component interconnections.}
}
@article{KUKKONEN2022104067,
title = {An ontology to support flow system descriptions from design to operation of buildings},
journal = {Automation in Construction},
volume = {134},
pages = {104067},
year = {2022},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2021.104067},
url = {https://www.sciencedirect.com/science/article/pii/S0926580521005185},
author = {Ville Kukkonen and Ali Kücükavci and Mikki Seidenschnur and Mads Holten Rasmussen and Kevin Michael Smith and Christian Anker Hviid},
keywords = {Building information modeling, HVAC, Semantic web, Ontology, Linked data},
abstract = {The interoperability of information from design to operations is an acknowledged challenge in the fields of architecture, engineering and construction (AEC). As a potential solution to the interoperability issues, there has been increasing interest in how linked data and semantic web technologies can be used to establish an extendable data model. Semantic web ontologies have been developed for the AEC domain, but an ontology for describing the energy and mass flow between systems and components is missing. This study proposes the Flow Systems Ontology (FSO) for describing the composition of flow systems, and their mass and energy flows. Two example models are expressed using FSO vocabulary. SPARQL Protocol and RDF Query Language (SPARQL) queries are performed to further demonstrate and validate the ontology. The main contribution consists of developing FSO as an ontology complementary to the existing ontologies. Finally, the paper introduces a roadmap for future developments building on FSO.}
}
@article{HERTWIG2025372,
title = {Ontology-based matchmaking and scheduling for Manufacturing as a Service},
journal = {Procedia CIRP},
volume = {134},
pages = {372-377},
year = {2025},
note = {58th CIRP Conference on Manufacturing Systems 2025},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2025.02.144},
url = {https://www.sciencedirect.com/science/article/pii/S2212827125005165},
author = {Michael Hertwig and Frauke Schuseil and Joachim Lentes and Valeria Borodin and Cristian Duran-Mateluna and Alexandre Dolgui and Simon Thevenin},
keywords = {Manufacturing as a Service, Ontology, Matchmaking, Scheduling as a Service},
abstract = {The pressure to develop a resilient value chain is currently a significant challenge due to a wide range of influences and disruptive factors. In achieving resilience, Manufacturing as a Service (MaaS) is a new approach with the potential to increase the responsiveness, flexibility, and scalability of manufacturing industries. The manufacturing services offered must match the specific requirements of the companies requesting them. Based on the analysis of the current state of knowledge, a three-stage ontology-based matchmaking approach is proposed to support human decision-makers in satisfying on-demand needs through the use of shared manufacturing resources offered as services. The capability of the proposed approach to semantically connect MaaS users is demonstrated for a MaaS scheduling service, which coordinates the execution of a set of on-demand manufacturing jobs by shared resources. Despite the constraints associated with the technical and organizational dimensions of industrial sectors, as well as with the complexity of supply chain dynamics, several key levers for expanding the adoption of MaaS are discussed throughout this paper.}
}
@article{YAN2022104059,
title = {PhenoRerank: A re-ranking model for phenotypic concept recognition pre-trained on human phenotype ontology},
journal = {Journal of Biomedical Informatics},
volume = {129},
pages = {104059},
year = {2022},
issn = {1532-0464},
doi = {https://doi.org/10.1016/j.jbi.2022.104059},
url = {https://www.sciencedirect.com/science/article/pii/S1532046422000752},
author = {Shankai Yan and Ling Luo and Po-Ting Lai and Daniel Veltri and Andrew J. Oler and Sandhya Xirasagar and Rajarshi Ghosh and Morgan Similuk and Peter N. Robinson and Zhiyong Lu},
keywords = {Phenotypic concept recognition, Natural language processing, Machine learning, Human phenotype ontology},
abstract = {The study aims at developing a neural network model to improve the performance of Human Phenotype Ontology (HPO) concept recognition tools. We used the terms, definitions, and comments about the phenotypic concepts in the HPO database to train our model. The document to be analyzed is first split into sentences and annotated with a base method to generate candidate concepts. The sentences, along with the candidate concepts, are then fed into the pre-trained model for re-ranking. Our model comprises the pre-trained BlueBERT and a feature selection module, followed by a contrastive loss. We re-ranked the results generated by three robust HPO annotation tools and compared the performance against most of the existing approaches. The experimental results show that our model can improve the performance of the existing methods. Significantly, it boosted 3.0% and 5.6% in F1 score on the two evaluated datasets compared with the base methods. It removed more than 80% of the false positives predicted by the base methods, resulting in up to 18% improvement in precision. Our model utilizes the descriptive data in the ontology and the contextual information in the sentences for re-ranking. The results indicate that the additional information and the re-ranking model can significantly enhance the precision of HPO concept recognition compared with the base method.}
}
@article{PSAROMMATIS2023103832,
title = {Zero Defect Manufacturing ontology: A preliminary version based on standardized terms},
journal = {Computers in Industry},
volume = {145},
pages = {103832},
year = {2023},
issn = {0166-3615},
doi = {https://doi.org/10.1016/j.compind.2022.103832},
url = {https://www.sciencedirect.com/science/article/pii/S0166361522002287},
author = {Foivos Psarommatis and Francisco Fraile and Farhad Ameri},
keywords = {Zero Defect Manufacturing, ZDM, Ontology, Semantics, Quality assurance, Defect, Industry 4.0},
abstract = {The global transition from traditional manufacturing systems to Industry 4.0 compatible systems has already begun. Therefore, the digitization of the manufacturing systems across the globe is increasing with exponential growth which implies a significant increase in the volume and variety of the generated data. Industry 4.0 technologies are mostly data driven and therefore, manufacturers need to be equipped with the appropriate tools and skill sets to extract useful knowledge and insights from the plethora of data continually collected form shop floors. Furthermore, quality assurance is a key domain in manufacturing that uses almost all the industry 4.0 technologies and has great impact on the sustainability of a manufacturing systems. The latest approach to higher quality and manufacturing sustainability is named Zero Defect Manufacturing (ZDM). ZDM interest has spiked the last three years illustrating the need for an alternative quality assurance approach from the traditional such as Six Sigma and Lean manufacturing. Therefore, the goal of this paper is to create a ZDM ontology that can semantically align multiple software systems that interact in a ZDM ecosystem. The development of the proposed ZDM ontology was performed using the principles introduced by Industrial Ontology Foundry (IOF) and with the use of Basic formal ontology (BFO) as an upper level ontology. The proposed ontology was utilized in the Prediction Optimization Designer tool developed, to assist developers to create new projects reusing existing resources, or to respond to a specific challenge. The use case validation results show that the combination of Natural Language Processing (NLP) using Sentence-BERT and ontology-based search methods rooted in the ZDM ontology is a promising strategy to implement effective search engines for applications in the ZDM domain.}
}
@incollection{CASCIANELLI2025392,
title = {Biological and Medical Ontologies: GO and GOA},
editor = {Shoba Ranganathan and Mario Cannataro and Asif M. Khan},
booktitle = {Encyclopedia of Bioinformatics and Computational Biology (Second Edition)},
publisher = {Elsevier},
edition = {Second Edition},
address = {Oxford},
pages = {392-403},
year = {2025},
isbn = {978-0-323-95503-4},
doi = {https://doi.org/10.1016/B978-0-323-95502-7.00100-7},
url = {https://www.sciencedirect.com/science/article/pii/B9780323955027001007},
author = {Silvia Cascianelli and Marco Masseroli},
keywords = {Annotation enrichment and semantic similarity analyses, Annotation prediction and prioritization, Directed acyclic graph (DAG), Gene Ontology (GO), Gene Ontology annotation, GO browsers, GO evidence codes, GO semantic relations, OBO, RDF-XML format, True-path-rule},
abstract = {The Gene Ontology (GO) is the most developed and relevant biomolecular ontology available. In a species-independent manner, it defines the functional categories, i.e., the biological concepts represented by the terms of its controlled vocabulary, to which the genes or gene products related to some biological process, molecular function, or cellular component belong. Using the functional classification of genes or gene products in GO categories provided by several databases (e.g., Entrez Gene and Uniprot), it is possible to perform semantic evaluations on a given gene or protein list, such as those produced by high-throughput experiments, which may foster new biological discoveries.}
}
@article{SHARMA2023108940,
title = {Machine learning and ontology-based novel semantic document indexing for information retrieval},
journal = {Computers & Industrial Engineering},
volume = {176},
pages = {108940},
year = {2023},
issn = {0360-8352},
doi = {https://doi.org/10.1016/j.cie.2022.108940},
url = {https://www.sciencedirect.com/science/article/pii/S0360835222009287},
author = {Anil Sharma and Suresh Kumar},
keywords = {Document indexing, Concept extraction, Machine learning, Computer science ontology, Semantic web, Information retrieval, Natural language processing},
abstract = {The goal of information retrieval (IR) systems is to find the contents most closely related to the user's information needs from a pool of information. However, conventional IR methods neglect semantic descriptions of document contents and index documents based on the words that they include. When users and indexing systems use different terms to express the same subject, a vocabulary gap emerges. To overcome this limitation and to enhance the effectiveness of the IR systems, this paper introduced a novel hybrid semantic document indexing employing machine learning and domain ontology. The presented technique uses a skip-gram with negative sampling-based machine learning model and a domain ontology to determine the concepts for annotating unstructured documents. The proposed work also introduced multiple feature based novel concept ranking algorithm where statistical, semantic, and scientific named entity features of the concept were used to assign relevance weight to the annotations. The fuzzy analytical hierarchy process was used to derive the parameters of these feature weights. The final step is to rank the concepts according to their relevance to the document. Five benchmark publicly accessible datasets from the computer science domain were used in a series of experiments to validate the results of presented method. Experiment findings showed that the proposed method performs better than state-of-the-art techniques on these datasets, by improving average accuracy by 29%, while an improvement of 25% was recorded in F-measure. The improvement in average accuracy demonstrates that the performance of the proposed approach is better than the state-of-the-art methods in extracting document concepts accurately even when the same concept is referred to by distinct terms in the document and domain ontologies. The proposed system's ability to find similar concepts when the documents possess no concept from domain ontology is demonstrated by the improvement in F-measure, which is attributed to high recall rates of the proposed indexing scheme while maintaining high accuracy.}
}
@article{LORVAOANTUNES2024200366,
title = {Ontology-based BIM-AMS integration in European Highways},
journal = {Intelligent Systems with Applications},
volume = {22},
pages = {200366},
year = {2024},
issn = {2667-3053},
doi = {https://doi.org/10.1016/j.iswa.2024.200366},
url = {https://www.sciencedirect.com/science/article/pii/S2667305324000425},
author = {António {Lorvão Antunes} and José Barateiro and Vânia Marecos and Jelena Petrović and Elsa Cardoso},
keywords = {Building Information Modeling (BIM), Decision support, Risk and condition data, Ontology development, Ontology validation},
abstract = {BIM tools enable decision-making during the lifecycle of engineering structures, such as bridges, tunnels, and roads. National Road Authorities use Asset Management Systems (AMS) to manage and monitor operational information of assets from European Highways, including access to sensor and inspection data. Interoperability between BIM and AMS systems is vital for a timely and effective decision-making process during the operational phase of these assets. The European project Connected Data for Effective Collaboration (CoDEC) designed a framework to support the connections between AMS and BIM platforms, using linked data principles. The CoDEC Data Dictionary was developed to provide standard data formats for AMS used by European NRA. This paper presents the design and development of an Engineering Structures ontology used to encode the shared conceptualization provided by the CoDEC Data Dictionary. The ontology is evaluated, validated, and demonstrated as a base for data exchange between BIM and AMS.}
}
@article{PAUEN2024105502,
title = {Integrated representation of technical systems with BIM and linked data: TUBES system ontology},
journal = {Automation in Construction},
volume = {165},
pages = {105502},
year = {2024},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2024.105502},
url = {https://www.sciencedirect.com/science/article/pii/S0926580524002383},
author = {Nicolas Pauen and Jérôme Frisch and Christoph {van Treeck}},
keywords = {Building information modeling, TSO, HVAC, Linked data, Semantic web, Ontology},
abstract = {Technical systems in the Architecture, Engineering, Construction, and Operations (AECO) industry are complex interconnected structures. To cope with this high complexity, large amounts of data must be processed and exchanged throughout the whole life cycle of these systems. Building Information Modeling (BIM) and Semantic Web Technologies (SWT) offer the possibility to structure and link this data as well as to define common terminology. Semantic Web ontologies describing HVAC systems in the AECO industry have been developed, but an ontology for an integrated representation based on general system theory is missing. Therefore, this study proposes the TUBES System Ontology (TSO) as a knowledge representation for an integrated, explicit representation of linked technical systems, their hierarchical subdivision, structural and functional interconnections, and relationships to spatial entities. The contribution is validated on two example models, and the results are critically discussed, pointing out corresponding limitations as well as the need for further research.}
}
@article{CHASSERAY2024108571,
title = {A generic hybrid method combining rules and machine learning to automate domain independent ontology population},
journal = {Engineering Applications of Artificial Intelligence},
volume = {133},
pages = {108571},
year = {2024},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2024.108571},
url = {https://www.sciencedirect.com/science/article/pii/S0952197624007292},
author = {Yohann Chasseray and Anne-Marie Barthe-Delanoë and Jérome Volkman and Stéphane Négny and Jean Marc {Le Lann}},
keywords = {Knowledge acquisition, Knowledge base, Word vector, Semantic approach, Unsupervised information extraction},
abstract = {Knowledge management has become a cornerstone of decision support and system engineering. Knowledge acquisition has traditionally been performed manually, and the trend now is to automate knowledge extraction from the huge amount of information contained in daily produced data. This article proposes a contribution in the artificial intelligence domain through a hybrid approach for the discovery of concept-instance couples to populate an ontology. The proposed framework combines automated domain-independent rule-based extraction for unsupervised relation extraction and semantic-oriented machine learning techniques for knowledge base enrichment. In the engineering field, another contribution resides in the generic aspect of the framework, leading to the possibility to populate ontologies and automatically build knowledge bases in various domains. The case study supporting this framework and its technical implementation show that the proposed method can be applied identically (1) to different data sources and (2) with different ontologies, regardless of the domain or subdomain they describe or the structure they have. Changing these inputs can be done without affecting the performance of the rule-based extraction, which is around 60% in terms of precision. Three different matching methods are also presented. Their ability to match new instances to their corresponding ontological class (or concept) is evaluated through a case study on biochemistry annotated textual data. The best matching method achieves an average precision score of 70% and an average recall of 74%.}
}
@article{TAO20231,
title = {Semantic ontology enabled modeling, retrieval and inference for incomplete mobile trajectory data},
journal = {Future Generation Computer Systems},
volume = {145},
pages = {1-11},
year = {2023},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2023.03.012},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X23000894},
author = {Ming Tao},
keywords = {Incomplete mobile trajectory, Semantic ontology, Modeling, Retrieval and inference, Markov logic network},
abstract = {Prevalence of vehicular terminals enables more and more mobile trajectory data to be collected. To promote the intelligent urban planning, traffic management and service in smart city applications, how to analyze and reasoning the inherent patterns in mobile trajectory has grabbed considerable research attentions from academia and industry. Current widely used popular methods are subject to the check-in dataset, and the pattern inference results greatly suffer from the sparsity and incompleteness in mobile trajectory data. To address this issue, a method of semantic ontology enabled modeling, retrieval and inference for incomplete mobile trajectory is investigated in this paper. To enhance the interpretability of mobile trajectory data, the latitude and longitude coordinates in spatio-temporal sequence are converted into semantic locations, and an ontology model with constraints then is constructed for vehicle movement through defining the corresponding semantic rules with the considerations of the location relationships both between road intersections and between vehicle movements. On the basis, by taking the constructed ontology model as the knowledge base and taking the semantic query results as the training set, an ontology based markov logic network is investigated for the mobile trajectory inference problem with incomplete data. Through comprehensive comparison and analysis, the experimental results achieved on real-world data finally have been shown to demonstrate the efficiency of the investigations, and verify the influence of weight configurations on the inference performance achieved by the proposed ontology based markov logic network.}
}
@article{MILOSZ2024e29046,
title = {Ontological approach for competency-based curriculum analysis},
journal = {Heliyon},
volume = {10},
number = {7},
pages = {e29046},
year = {2024},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2024.e29046},
url = {https://www.sciencedirect.com/science/article/pii/S2405844024050771},
author = {Marek Milosz and Aizhan Nazyrova and Assel Mukanova and Gulmira Bekmanova and Dmitrii Kuzin and Gaukhar Aimicheva},
keywords = {Ontology, Educational program, Prerequisites, SPARQL, Owlready2, Curriculum, Python, Semantic web, Protégé},
abstract = {This article is dedicated to the development of a model for competencies within an educational program and its implementation through the use of semantic technologies. The model proposed by the authors is distinctive in that competencies are organized into a hierarchical data structure with arbitrary levels of nesting. Furthermore, the article presents an original solution for modelling the input requirements for studying a course, which is defined in the form of dependencies between the competencies generated by the course and the competencies of other courses. The outcome of this work is an ontological model of a competency-based curriculum, for which the authors have developed and implemented algorithms for data addition and retrieval, as well as for analyzing the consistency of the curriculum in terms of the input requirements for studying a discipline and the learning outcomes from previous periods. The findings presented in the article will prove to be valuable in the development of educational process management information systems and educational program constructors. They will also be instrumental in aligning diverse educational programs within the context of academic mobility.}
}
@article{DOMINGUEZ2024100630,
title = {The role of ontologies in smart contracts: A systematic literature review},
journal = {Journal of Industrial Information Integration},
volume = {40},
pages = {100630},
year = {2024},
issn = {2452-414X},
doi = {https://doi.org/10.1016/j.jii.2024.100630},
url = {https://www.sciencedirect.com/science/article/pii/S2452414X24000748},
author = {Johnny Alvarado Dominguez and Silvio Gonnet and Marcela Vegetti},
keywords = {Ontology, Smart contract, Blockchain},
abstract = {The aim of this systematic literature review is to provide a comprehensive understanding of how ontologies address current Smart Contract challenges, identify application scenarios, and present tools and technologies associated with their use. This systematic literature review (SLR), following Kitchenham's methodology, analyses peer-reviewed articles from 2015 to August 2022 from databases such as Scopus, IEEE, Science Direct, Springer Link and ACM. Of the 501 publications identified, 21 are selected for in-depth review based on inclusion, exclusion and quality assessment criteria. The results of this SLR show that ontologies provide solutions to the challenges faced by Smart Contracts mainly at the creation stage. They allow the terms of the contract and the roles of the parties to be defined. Ontologies also enable the development of Smart Contract templates. This facilitates their use by people without technical programming expertise. Despite these potential solutions to the challenges that Smart Contracts face throughout their lifecycle, they lack verification. This increases the vulnerabilities to which Smart Contracts are exposed. Developing validation and verification tools could facilitate using ontologies to create Smart Contracts for different real-world cases.}
}
@article{HERNANDEZ2024105284,
title = {HeNeCOn: An ontology for integrative research in Head and Neck cancer},
journal = {International Journal of Medical Informatics},
volume = {181},
pages = {105284},
year = {2024},
issn = {1386-5056},
doi = {https://doi.org/10.1016/j.ijmedinf.2023.105284},
url = {https://www.sciencedirect.com/science/article/pii/S1386505623003027},
author = {Liss Hernández and Estefanía Estévez-Priego and Laura López-Pérez and María {Fernanda Cabrera-Umpiérrez} and María Teresa Arredondo and Giuseppe Fico and Tito Poli and Silvia Rossi and Elena Martinelli and Lisa Licitra and Stefano Cavalieri and Loris {De Cecco} and Silvana Canevari and Kathrin Scheckenbach and Ruud H. Brakenhoff and Irene Nauta and Frank J.P. Hoebers and Frederik W.R. Wesseling and Annalisa Trama and Gemma Gatta},
keywords = {Ontology, Head and neck cancer, Data modeling, Data standardization, Clinical information system, Ontology-based knowledge, Protégé},
abstract = {Background
Head and Neck Cancer (HNC) has a high incidence and prevalence in the worldwide population. The broad terminology associated with these diseases and their multimodality treatments generates large amounts of heterogeneous clinical data, which motivates the construction of a high-quality harmonization model to standardize this multi-source clinical data in terms of format and semantics. The use of ontologies and semantic techniques is a well-known approach to face this challenge.
Objective
This work aims to provide a clinically reliable data model for HNC processes during all phases of the disease: prognosis, treatment, and follow-up. Therefore, we built the first ontology specifically focused on the HNC domain, named HeNeCOn (Head and Neck Cancer Ontology).
Methods
First, an annotated dataset was established to provide a formal reference description of HNC. Then, 170 clinical variables were organized into a taxonomy, and later expanded and mapped to formalize and integrate multiple databases into the HeNeCOn ontology. The outcomes of this iterative process were reviewed and validated by clinicians and statisticians.
Results
HeNeCOn is an ontology consisting of 502 classes, a taxonomy with a hierarchical structure, semantic definitions of 283 medical terms and detailed relations between them, which can be used as a tool for information extraction and knowledge management.
Conclusion
HeNeCOn is a reusable, extendible and standardized ontology which establishes a reference data model for terminology structure and standard definitions in the Head and Neck Cancer domain. This ontology allows handling both current and newly generated knowledge in Head and Neck cancer research, by means of data linking and mapping with other public ontologies.}
}
@article{KUSUMA2022108906,
title = {Automatic question generation with various difficulty levels based on knowledge ontology using a query template},
journal = {Knowledge-Based Systems},
volume = {249},
pages = {108906},
year = {2022},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2022.108906},
url = {https://www.sciencedirect.com/science/article/pii/S0950705122004336},
author = {Selvia Ferdiana Kusuma and Daniel Oranova Siahaan and Chastine Fatichah},
keywords = {Knowledge ontology, Ontology, Question generation, Query template, Question classification},
abstract = {Ontology is a concepts and relationships that can be used to support the question-generation process. However, until now, the ontology models and question templates commonly used to support the question-generation process have remained domain-specific, allowing three weaknesses to persist. First, the role of experts is dominant in the process of ontology generation. Second, the process needs adjustment if it is to be used for other domains. Third, question templates are formed based on the vocabulary of ontology, so they cannot be used to generate questions in other domains. In response to these problems, this research focused on forming an ontology generation model and a template model for generating questions that are not domain-specific. We used a combination of two types of ontology — namely, taxonomy ontology and sentence ontology to form ontology models and question templates that were not domain-specific. We labeled this combination as “knowledge ontology”. We used template queries to retrieve information on the ontology and then translated the results of the query template into questions in natural language. The ratios from our experiments demonstrated that the proposed method was effective for generating questions. Moreover, the method produced good question quality, as evidenced by its high accuracy rate of 90.71%. This research can be applied to help e-learning developers represent information in the form of ontology without involving experts. Furthermore, this research can also help teachers to generate questions automatically with consistent question quality.}
}
@article{SPOLADORE2024102859,
title = {Ontology-based decision support systems for diabetes nutrition therapy: A systematic literature review},
journal = {Artificial Intelligence in Medicine},
volume = {151},
pages = {102859},
year = {2024},
issn = {0933-3657},
doi = {https://doi.org/10.1016/j.artmed.2024.102859},
url = {https://www.sciencedirect.com/science/article/pii/S0933365724001015},
author = {Daniele Spoladore and Martina Tosi and Erna Cecilia Lorenzini},
keywords = {Domain ontologies, Diabetes nutrition therapy, Knowledge-based systems, PRISMA (preferred reporting items for systematic reviews and meta-analyses statement), Decision support systems},
abstract = {Diabetes is a non-communicable disease that has reached epidemic proportions, affecting 537 million people globally. Artificial Intelligence can support patients or clinicians in diabetes nutrition therapy – the first medical therapy in most cases of Type 1 and Type 2 diabetes. In particular, ontology-based recommender and decision support systems can deliver a computable representation of experts' knowledge, thus delivering patient-tailored nutritional recommendations or supporting clinical personnel in identifying the most suitable diet. This work proposes a systematic literature review of the domain ontologies describing diabetes in such systems, identifying their underlying conceptualizations, the users targeted by the systems, the type(s) of diabetes tackled, and the nutritional recommendations provided. This review also delves into the structure of the domain ontologies, highlighting several aspects that may hinder (or foster) their adoption in recommender and decision support systems for diabetes nutrition therapy. The results of this review process allow to underline how recommendations are formulated and the role of clinical experts in developing domain ontologies, outlining the research trends characterizing this research area. The results also allow for identifying research directions that can foster a preeminent role for clinical experts and clinical guidelines in a cooperative effort to make ontologies more interoperable – thus enabling them to play a significant role in the decision-making processes about diabetes nutrition therapy.}
}
@article{BLANCO2023100989,
title = {Onto-CARMEN: Ontology-driven approach for Cyber–Physical System Security Requirements meta-modelling and reasoning},
journal = {Internet of Things},
volume = {24},
pages = {100989},
year = {2023},
issn = {2542-6605},
doi = {https://doi.org/10.1016/j.iot.2023.100989},
url = {https://www.sciencedirect.com/science/article/pii/S2542660523003128},
author = {Carlos Blanco and David G. Rosado and Ángel Jesús Varela-Vaca and María Teresa Gómez-López and Eduardo Fernández-Medina},
keywords = {Cyber–physical system, Cybersecurity, Security, Configuration models, Security requirements, Security verification, Diagnosis},
abstract = {In the last years, Cyber–physical systems (CPS) have attracted substantial mainstream, especially in the industrial sector, since they have become the focus of cyber-attacks. CPS are complex systems that encompass a great variety of hardware and software components with a countless number of configurations and features. For this reason, the construction, validation, and diagnosis of security in CPS become a major challenge. An invalid security requirement for the CPS can produce partial or incomplete configuration, even misconfigurations, and hence catastrophic consequences. Therefore, it is crucial to ensure the validation of the security requirements specification from the earlier design stages. To this end, Onto-CARMEN is proposed, a semantic approach that enables the automatic verification and diagnosis of security requirements according to the ENISA and OWASP recommendations. Our approach provides a mechanism for the specification of security requirements on top of ontologies, and automatic diagnosis through semantic axioms and SPARQL rules. The approach has been validated using security requirements from a real case study.}
}
@article{FAUTH2023102216,
title = {Ontology for building permit authorities (OBPA) for advanced building permit processes},
journal = {Advanced Engineering Informatics},
volume = {58},
pages = {102216},
year = {2023},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2023.102216},
url = {https://www.sciencedirect.com/science/article/pii/S1474034623003440},
author = {Judith Fauth and Sebastian Seiß},
keywords = {Building permit, Building official, Building application, Ontology, Assignment process, Shapes Constraint Language (SHACL)},
abstract = {Building permit processes lie on the divide between architecture, engineering, and construction (AEC) and public administration. To ensure consistent and effective digitization in building permitting, it is necessary to consider and merge both areas. Hence, for advanced building permit processes, foundations must be developed, which begins with understanding and formalizing building permit authorities’ organizational structures and processes. Therefore, this study developed an ontology that covers a semantic representation of a building permit authority along with a subprocess of the building permit process called the assignment process. The assignment process describes how and on what basis building applications are assigned to appropriate building officials. Proposing a semantic representation of the assignment process, tacit knowledge from previously conducted data sets was analyzed and implemented in the ontology. As a case study, a sample building permit authority was described and implemented in the ontology. On the one hand, the developed ontology serves as a basis for decision support for building permit processes, while on the other hand, it enables a fully automated assignment process in a building permit authority. The approach not only makes the assignment process more objective and transparent for all parties involved in the building permit process but also allows time and personnel capacities to be used in its other subprocesses.}
}
@article{XUE2024112392,
title = {Automatic similarity feature selection for ontology matching with semantic sampling},
journal = {Knowledge-Based Systems},
volume = {302},
pages = {112392},
year = {2024},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2024.112392},
url = {https://www.sciencedirect.com/science/article/pii/S0950705124010268},
author = {Xingsi Xue and Jerry Chun-Wei Lin and Zhaoyun Xu},
keywords = {Ontology matching, Similarity feature selection, Semantic sampling, Compact genetic algorithm, Relaxed Naive Bayes classifier},
abstract = {Ontology provides a formal representation of knowledge as a set of concepts within a domain and the relationships between them. Ontology Matching (OM) identifies similar entities across different ontologies. Similarity Features (SFs) characterize the similarity between two entities from different perspectives, which serves as the foundation of OM method. However, noisy and redundant SFs can obstruct the relevance of useful ones, reducing the quality of matching results. To offer a practical and efficient SF selection, this work proposes a new automatic SF selection framework for OM, which consists of two new components. First, a semantic sampling method is proposed to automatically construct a balanced and representative training dataset, without the need for expert intervention. This method first generates a basic sample set that considers both the representativeness of the concepts and the heterogeneous characteristics of the two ontologies, and then over-samples the minority samples based on their semantic context. Second, a wrapper-based SF selection method is designed, which includes an Adaptive Compact Genetic Algorithm (ACGA) and a Relaxed Naive Bayes (RNB) classifier. The ACGA is able to efficiently identify the SF subset, reducing the computational cost by adaptively maintaining a population probability model based on the diversity and confidence of the SFs. Moreover, the RNB can effectively evaluate the quality of selected SFs by modifying the feature independence assumption with recombination and weighting strategies. Experimental results on the ontology alignment evaluation initiative’s Benchmark demonstrate that our method can efficiently find accurate OM results, and significantly outperform the state-of-the-art matching techniques.}
}
@article{MBAKOUHOUE2025112897,
title = {Enhancing associative classification on imbalanced data through ontology-based feature extraction and resampling},
journal = {Knowledge-Based Systems},
volume = {309},
pages = {112897},
year = {2025},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2024.112897},
url = {https://www.sciencedirect.com/science/article/pii/S0950705124015314},
author = {Joel {Mba Kouhoue} and Jerry Lonlac and Alexis Lesage and Arnaud Doniec and Stéphane Lecoeuche},
keywords = {Imbalanced associative classification, Ontologies, Feature extraction, Oversampling, Building maintenance},
abstract = {Associative classification models are valuable for discovering relationships within heterogeneous data systems, making them particularly useful for data integration tasks. However, they struggle with imbalanced and sparse data. This paper addresses the problem of imbalanced classification in building maintenance data by providing several updates based both on algorithms and preprocessing. Experiments conducted on real maintenance datasets demonstrate significant improvements in accuracy and precision.}
}
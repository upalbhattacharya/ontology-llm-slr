@INPROCEEDINGS{10677303,
  author={Gupta, Pranav and Sharma, Raunak and Kumari, Rashmi and Aditya, Sri Krishna and Choudhary, Shwetank and Kumar, Sumit and M, Kanchana and R, Thilagavathy},
  booktitle={2024 IEEE International Conference on Electronics, Computing and Communication Technologies (CONECCT)}, 
  title={ECHO: Environmental Sound Classification with Hierarchical Ontology-guided Semi-Supervised Learning}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={Environment Sound Classification has been a well-studied research problem in the field of signal processing and till now more focus has been laid on fully supervised approaches. Recently, the focus has moved towards semi-supervised methods which concentrate on utilizing unlabeled data, and self-supervised methods which learn the intermediate representation through pretext tasks or contrastive learning. However, both approaches require a vast amount of unlabelled data to improve performance. In this work, we propose a novel framework called Environmental Sound Classification with Hierarchical Ontology-guided semi-supervised Learning (ECHO) that utilizes label ontology-based hierarchy to learn semantic representation by defining a novel pretext task. The model tries to predict coarse labels represented by the Large Language Model (LLM) based on ground truth label ontology, then further fine-tuned in a supervised way to predict the actual task. ECHO achieves a 1% to 8% accuracy improvement over baseline systems across UrbanSound8K, ESC-10, and ESC-50 datasets.},
  keywords={Accuracy;Large language models;Semantics;Contrastive learning;Ontologies;Semisupervised learning;Signal processing;semi-supervised learning;Environment Sound Classification;Label ontology},
  doi={10.1109/CONECCT62155.2024.10677303},
  ISSN={2766-2101},
  month={July},}@INPROCEEDINGS{10655250,
  author={Quan, Ruijie and Wang, Wenguan and Ma, Fan and Fan, Hehe and Yang, Yi},
  booktitle={2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Clustering for Protein Representation Learning}, 
  year={2024},
  volume={},
  number={},
  pages={319-329},
  abstract={Protein representation learning is a challenging task that aims to capture the structure and function of proteins from their amino acid sequences. Previous methods largely ignored the fact that not all amino acids are equally important for protein folding and activity. In this article, we propose a neural clustering framework that can automatically discover the critical components of a protein by considering both its primary and tertiary structure information. Our framework treats a protein as a graph, where each node represents an amino acid and each edge represents a spatial or sequential connection between amino acids. We then apply an iterative clustering strategy to group the nodes into clusters based on their 1D and 3D positions and assign scores to each cluster. We select the highest-scoring clusters and use their medoid nodes for the next iteration of clustering, until we obtain a hierarchical and informative representation of the protein. We evaluate on four protein-related tasks: protein fold classification, enzyme reaction classification, gene ontology term prediction, and enzyme commission number prediction. Experimental results demonstrate that our method achieves state-of-the-art performance.},
  keywords={Proteins;Representation learning;Enzymes;Computer vision;Three-dimensional displays;Ontologies;Amino acids;Protein Representation Learning;Clustering},
  doi={10.1109/CVPR52733.2024.00038},
  ISSN={2575-7075},
  month={June},}@INPROCEEDINGS{10655304,
  author={Ma, Jiawei and Huang, Po-Yao and Xie, Saining and Li, Shang-Wen and Zettlemoyer, Luke and Chang, Shih-Fu and Yih, Wen-Tau and Xu, Hu},
  booktitle={2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={MoDE: CLIP Data Experts via Clustering}, 
  year={2024},
  volume={},
  number={},
  pages={26344-26353},
  abstract={The success of contrastive language-image pretraining (CLIP) relies on the supervision from the pairing between images and captions, which tends to be noisy in web- crawled data. We present Mixture of Data Experts (MoDE) and learn a system of CLIP data experts via clustering. Each data expert is trained on one data cluster, being less sensitive to false negative noises in other clusters. At inference time, we ensemble their outputs by applying weights determined through the correlation between task metadata and cluster conditions. To estimate the correlation pre-cisely, the samples in one cluster should be semantically similar, but the number of data experts should still be rea-sonable for training and inference. As such, we consider the ontology in human language and propose to use fine- grained cluster centers to represent each data expert at a coarse-grained level. Experimental studies show that four CLIP data experts on ViT-B/16 outperform the ViT-L/14 by OpenAI CLIP and OpenCLIP on zero-shot image classification but with less (<35%) training cost. Meanwhile, MoDE can train all data expert asynchronously and can flexibly include new data experts. The code is available here.},
  keywords={Training;Adaptation models;Correlation;Costs;Computational modeling;Noise;Semantics;Data Expert;Multi-Modal;Data Clustering},
  doi={10.1109/CVPR52733.2024.02489},
  ISSN={2575-7075},
  month={June},}@INPROCEEDINGS{10651359,
  author={Liu, Xu and Chen, Xinming and Zhu, Yangfu and Wu, Bin},
  booktitle={2024 International Joint Conference on Neural Networks (IJCNN)}, 
  title={Prompt-Enhanced Prototype Framework for Few-shot Event Detection}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={Few-shot event detection (ED) aims at identifying and typing event mentions from text with limited annotations. Most existing methods for few-shot ED use event ontology and related knowledge to construct prototypes and fail to fully leverage the rich knowledge of pre-trained language models (PLMs) which could help improve the representation of prototypes. Motivated by this, we propose an prompt-enhanced prototype framework which combines prototype and prompt for few-shot ED. Considering the scarcity of labeled data, we also introduce contrastive learning to enrich prototypes. Specifically, we use heuristic rules to align FrameNet with annotated data to get corresponding prompts for each event and convert them into prompt prototype. We then leverage contrastive learning to aggregate event mentions into prototypes and maintain these prototypes for few-shot ED. Furthermore, We explore diverse prompt formats for representing prompt prototypes and introduce a more comprehensive lexical prompt which improves the performance of few-shot ED. We conduct extensive experiments on the MAVEN corpus to reveal the effectiveness of the proposed framework compared to state-of-the-art methods.},
  keywords={Event detection;Annotations;Aggregates;Semantics;Neural networks;Prototypes;Contrastive learning},
  doi={10.1109/IJCNN60899.2024.10651359},
  ISSN={2161-4407},
  month={June},}@INPROCEEDINGS{10650745,
  author={Jian, Zhaorui and Liu, Shengquan and Gao, Wei and Cheng, Jianming},
  booktitle={2024 International Joint Conference on Neural Networks (IJCNN)}, 
  title={Distantly Supervised Relation Extraction based on Non-taxonomic Relation and Self-Optimization}, 
  year={2024},
  volume={},
  number={},
  pages={1-9},
  abstract={Distantly supervised relation extraction (DS-RE) leverages existing knowledge bases to generate annotated data for relation extraction (RE), addressing the issue of scarce labeled data. However, distant supervision (DS) is often limited by coarse annotations and insufficient contextual awareness, leading to relational ambiguity and introducing noise in the labeled results. Moreover, although one can optimize the classifiers in DS-RE models through weight updates, the static nature of the guiding rules for such adjustments often falls short when addressing the challenges posed by diverse non-taxonomic relations and complex noise patterns in datasets. In this paper, we propose a DS-RE framework that capitalizes on non-taxonomic relations and a self-optimizing mechanism. We define a set of consistent DS relation candidates and combine DS with a LLM to enhance the perception of entities’ contextual states during the DS process. Then, we design a Self-Optimizing Ontology-Enhanced Non-taxonomic Relation Extraction Model (SO-NRE). The model incorporates additional entity-relation knowledge to enhance the semantic depth of Non-taxonomic relation ontologies and uses an adaptive dynamic scheduling mechanism to refine the classification strategy through iterations informed by self-perception outcomes. The experimental results show that the improved DS annotation workflow has enhanced accuracy, and SO-NRE outperforms mainstream baselines in RE performance.},
  keywords={Adaptation models;Accuracy;Annotations;Large language models;Noise;Semantics;Neural networks;Distantly Supervised Relation Extraction;Non-taxonomic Relation;LLM;Self-Optimization},
  doi={10.1109/IJCNN60899.2024.10650745},
  ISSN={2161-4407},
  month={June},}@ARTICLE{10666776,
  author={Achintalwar, Swapnaja and Baldini, Ioana and Bouneffouf, Djallel and Byamugisha, Joan and Chang, Maria and Dognin, Pierre and Farchi, Eitan and Makondo, Ndivhuwo and Mojsilović, Aleksandra and Nagireddy, Manish and Natesan Ramamurthy, Karthikeyan and Padhi, Inkit and Raz, Orna and Rios, Jesus and Sattigeri, Prasanna and Singh, Moninder and Thwala, Siphiwe A. and Uceda-Sosa, Rosario A. and Varshney, Kush R.},
  journal={IEEE Internet Computing}, 
  title={Alignment Studio: Aligning Large Language Models to Particular Contextual Regulations}, 
  year={2024},
  volume={28},
  number={5},
  pages={28-36},
  abstract={The alignment of large language models is usually done by model providers to add or control behaviors that are common or universally understood across use cases and contexts. By contrast, in this article, we present an approach and architecture that empowers application developers to tune a model to their particular values, social norms, laws, and other regulations and orchestrate between potentially conflicting requirements in context. We lay out three main components of such an Alignment Studio architecture: Framers, Instructors, and Auditors, which work in concert to control the behavior of a language model. We illustrate this approach with a running example of aligning a company’s internal-facing enterprise chatbot to its business conduct guidelines.},
  keywords={Data models;Regulation;Internet;Guidelines;Synthetic data;Chatbots;Large language models;Context modeling;Context-aware services},
  doi={10.1109/MIC.2024.3453671},
  ISSN={1941-0131},
  month={Sep.},}@INPROCEEDINGS{10633526,
  author={Yang, Hang and Xiao, Liang and Zhu, Rujun and Liu, Ziji and Chen, Jianxia},
  booktitle={2024 IEEE 48th Annual Computers, Software, and Applications Conference (COMPSAC)}, 
  title={Interlinking Clinical Guidelines via Mining Medical Literature Knowledge for Multi-Morbidity Decision-Making}, 
  year={2024},
  volume={},
  number={},
  pages={1250-1255},
  abstract={Independently developed clinical guidelines present a systematic challenge in managing patients with multi-morbidity in a consistent and integrated manner. Existing approaches mainly focus on combining multiple guidelines and lack approaches that combine with additional medical resources. The correlations and conflicts between treatment plans in the management of multi-morbidity are well-documented in medical literature but are less explored in the Clinical Decision Support line of research. In this paper, we propose a literature-based guideline interlinking method to address these challenges through the integration of clinical guidelines and the harmonization of conflicting recommendations, thereby providing a more holistic and efficient way to manage patients with multi-morbidity conditions. This method employs an ontology model and knowledge graph technology to represent and analyze the complexity and interrelations of diseases, with the aim of transcending the limitations of traditional single disease guidelines and providing a holistic and integrated framework for multi-morbidity management. The objective is to construct a multi-morbidity knowledge graph by correlating medical literature with clinical guidelines and to provide optimal decision support for patients with multi-morbidity complications in a clinical decision support system (CDSS).},
  keywords={Accuracy;Systematics;Databases;Computational modeling;Biological system modeling;Knowledge graphs;Ontologies;multi-morbidity management;clinical guidelines;ontology model;knowledge graph},
  doi={10.1109/COMPSAC61105.2024.00165},
  ISSN={2836-3795},
  month={July},}@INPROCEEDINGS{10638283,
  author={Hendawi, Rasha and Alian, Shadi and Li, Juan},
  booktitle={2024 15th International Conference on Information and Communication Systems (ICICS)}, 
  title={Breaking Down Barriers: Empowering Diabetes Patients with User-Friendly Medical Explanations}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Effective management of diabetes is contingent upon patients' understanding of their medical conditions and treatments. However, medical documents often contain complex jargon and technical details that can be challenging for patients, especially those with limited health literacy. This paper presents DiaKnow, an innovative tool that simplifies medical documents and customizes explanations to suit individual health literacy levels. Employing a robust self-attention transformer model and a comprehensive diabetes-focused knowledge graph, DiaKnow enhances patient comprehension by providing contextually relevant, simplified medical information. This study assesses DiaKnow’s efficacy in real-world clinical settings through a structured use case evaluation method. We tested the tool’s ability to accurately identify, link, and simplify crucial medical terms using a diverse set of medical documents. Our findings confirm that DiaKnow not only improves the readability of medical documents but also ensures that explanations are medically accurate, clear, and comprehensive.},
  keywords={Accuracy;Communication systems;Transforms;Knowledge graphs;Transformers;Diabetes;Context modeling;health literacy;knowledge graph;ontology;self-attention transformers;medical entity recognition;entity linking},
  doi={10.1109/ICICS63486.2024.10638283},
  ISSN={2573-3346},
  month={Aug},}@INPROCEEDINGS{10628803,
  author={Liu, Hao and Zhou, Shuxin and Chen, Zhehuan and Perl, Yehoshua and Wang, Jiayin},
  booktitle={2024 IEEE 12th International Conference on Healthcare Informatics (ICHI)}, 
  title={Using Generative Large Language Models for Hierarchical Relationship Prediction in Medical Ontologies}, 
  year={2024},
  volume={},
  number={},
  pages={248-256},
  abstract={This study extends the exploration of ontology enrichment by evaluating the performance of various open-sourced Large Language Models (LLMs) on the task of predicting hierarchical relationships (IS-A) in medical ontologies including SNOMED CT Clinical Finding and Procedure hierarchies and the human Disease Ontology. With the previous finetuned BERT models for hierarchical relationship prediction as the baseline, we assessed eight open-source generative LLMs for the same task. We observed only three models, without finetuning, demonstrated comparable or superior performance compared to the baseline BERT -based models. The best performance model OpenChat achieved a macro average F1 score of 0.96 (0.95) on SNOMED CT Clinical Finding (Procedure) hierarchy, an increase over 7% from the baseline 0.89 (0.85). On human Disease Ontology, OpenChat excels with an F1 score of 0.91, outperforming the second-best performance model Vicuna (0.84). Notably, some LLMs prove unsuitable for hierarchical relationship prediction tasks or appliable for concept placement of medical ontologies. We also explored various prompt templates and ensemble techniques to uncover potential confounding factors in applying LLMs for IS-A relation predictions for medical ontologies.},
  keywords={Accuracy;Large language models;Medical services;Ontologies;Predictive models;Task analysis;Informatics;Hieratical Relation Prediction;Large Language Models;Medical Ontology;Prompts Design;SNOMED CT},
  doi={10.1109/ICHI61247.2024.00040},
  ISSN={2575-2634},
  month={June},}@INPROCEEDINGS{10628465,
  author={Lian, Xiaoli and Ma, Jieping and Lv, Heyang and Zhang, Li},
  booktitle={2024 IEEE 32nd International Requirements Engineering Conference (RE)}, 
  title={ReqCompletion: Domain-Enhanced Automatic Completion for Software Requirements}, 
  year={2024},
  volume={},
  number={},
  pages={142-154},
  abstract={Software requirements are the driving force behind software development. As the cornerstone of the entire software lifecycle, the efficiency of crafting requirement specifications and the quality of these requirements significantly influence the duration of software development. Despite massive research on requirements elicitation, the reality is that requirements are often painstakingly crafted manually, word by word. This manual process is not only time-consuming but also prone to issues such as the misuse of terminology. To address these challenges, we introduce ReqCompletion, an approach designed to recommend the next token in real-time for given prefix of requirements description. ReqCompletion comprises two primary components. First, we have devised and integrated a knowledge-injection module into GPT-2—which stands as the largest available GPT model that allows for fine-tuning on specialized downstream tasks. This injection imbues GPT-2 with richer domain-specific knowledge, thus improving the relevance of the suggested tokens. Additionally, we employ a pointer network to optimize the recommendation quality by utilizing completed requirements as contextual support. Empirical evaluations using two public datasets demonstrate that ReqCompletion surpasses all baselines in performance (Recall@7 gains up to 65.87% than the second-best model). Furthermore, the effectiveness of its two pivotal design elements has been substantiated through rigorous ablation studies. The utility of our work has been evaluated preliminarily through a small user study.},
  keywords={Terminology;Force;Manuals;Computer architecture;Benchmark testing;Software;Real-time systems;Software Requirements;Automatic Text Completion;Knowledge Injection},
  doi={10.1109/RE59067.2024.00023},
  ISSN={2332-6441},
  month={June},}@INPROCEEDINGS{10628558,
  author={Fieblinger, Romy and Alam, Md Tanvirul and Rastogi, Nidhi},
  booktitle={2024 IEEE European Symposium on Security and Privacy Workshops (EuroS&PW)}, 
  title={Actionable Cyber Threat Intelligence Using Knowledge Graphs and Large Language Models}, 
  year={2024},
  volume={},
  number={},
  pages={100-111},
  abstract={Cyber threats are constantly evolving. Extracting actionable insights from unstructured Cyber Threat Intelligence (CTI) data is essential to guide cybersecurity decisions. Increasingly, organizations like Microsoft, Trend Micro, and CrowdS trike are using generative AI to facilitate CTI extraction. This paper addresses the challenge of automating the extraction of actionable CTI using advancements in Large Language Models (LLMs) and Knowledge Graphs (KGs). We explore the application of state-of-the-art open-source LLMs, including the Llama 2 series, Mistral 7B Instruct, and Zephyr for extracting meaningful triples from CTI texts. Our methodology evaluates techniques such as prompt engineering, the guidance framework, and fine-tuning to optimize information extraction and structuring. The extracted data is then utilized to construct a KG, offering a structured and queryable representation of threat intelligence. Experimental results demonstrate the effectiveness of our approach in extracting relevant information, with guidance and fine-tuning showing superior performance over prompt engineering. However, while our methods prove effective in small-scale tests, applying LLMs to large-scale data for KG construction and Link Prediction presents ongoing challenges.},
  keywords={Large language models;Refining;Knowledge graphs;Organizations;Predictive models;Ontologies;Cyber threat intelligence;Cyber Threat Intelligence;Large Language Models;Knowledge Graphs;Threat Prediction},
  doi={10.1109/EuroSPW61312.2024.00018},
  ISSN={2768-0657},
  month={July},}@ARTICLE{10633699,
  author={Woods, Caitlin and Hodkiewicz, Melinda and French, Tim},
  journal={IEEE Access}, 
  title={Semantic Quality Assurance of Industrial Maintenance Procedures}, 
  year={2024},
  volume={12},
  number={},
  pages={122029-122046},
  abstract={Maintenance technicians in industry follow procedures that guide them through inspection, repair, and service tasks. Organisations seek to convert procedure documentation to machine-readable formats as their digital capabilities improve and regulatory requirements tighten. In this paper, we consider the opportunity for semantic quality assurance of digital procedures. We demonstrate a configurable and repeatable workflow containing three modules. The completeness module makes implicit information in procedures explicit using OpenAI’s Generative Pre-trained Transformer (GPT) model. The consistency module creates Resource Description Framework (RDF) triples that are aligned with, and checked against, the axioms of the open-source Ontology for Maintenance Procedure Documentation (OMPD). Finally, the correctness module performs closed-world checks on the RDF triples using the Shapes Constraints Language (SHACL). Each module can be used in isolation, or together, to realise an end-to-end semi-automated quality assurance workflow. Pre-processing of the raw maintenance procedure documents to extract entities (tools, materials and activities) and relations is achieved in a novel manner using prompt engineering with OpenAI’s GPT-3.5 Turbo model and few-shot learning. This end-to-end workflow enables organisations to perform quality assurance such as assessing the correct order for task sequences, and checking that all maintenance procedures have at least one maintenance task. We demonstrate this workflow on six procedures from the iFixit repository. The outputs of this workflow support maintenance technicians, planners and engineers by realising high-quality procedure documentation and automated procedure management update processes. The code and data used in this work is publicly available at https://github.com/equonto/quokka/.},
  keywords={Maintenance;Ontologies;OWL;Resource description framework;Data models;Documentation;Task analysis;Industrial ontology;ontology templates;OpenAI GPT;OTTR;SHACL;technical language processing},
  doi={10.1109/ACCESS.2024.3441757},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10621570,
  author={Motevallian, Mahsa and Esfar-E-Alam, AM and Taherkordi, Amir and Abbasi, Golnoush},
  booktitle={2024 20th International Conference on Distributed Computing in Smart Systems and the Internet of Things (DCOSS-IoT)}, 
  title={Semantic Modeling of Waste Dataflow for Automating Circular Economy Systems}, 
  year={2024},
  volume={},
  number={},
  pages={677-684},
  abstract={Circular Economy (CE) is a model with a concrete action plan covering the whole life cycle of a product, from production and consumption to waste management (WM). Information technologies considerably contribute to the transition towards CE, e.g., waste tracking using Internet of Things (IoT). This will cause the businesses and organizations to confront a large diversity of data (i.e. waste amount, types, locations, etc.). The generated data is often stored and processed through manual or semi-manual methods by each business or organization. However, an automated method which can also interpret and integrate the diverse data in WM fields across different organizations is still in its infancy. Often, such data is not organized and falls short of reaching its full potential in facilitating coordinated management and enabling Circular Economy initiatives. In this paper, we aim to address this need through automated interpretation and integration of municipal waste data by applying semantic data modeling. Our approach proposes to capture the semantical description of entities in the WM process and their relations, which can appear between waste producers, authorities and consumers. Then, the obtained semantic model will facilitate and automate the required interpretation and integration of waste data, both for intra- and inter-organization scenarios. We realize intelligent semantic-based searching using natural language processing and large language models.},
  keywords={Waste management;Computational modeling;Large language models;Semantics;Organizations;Production;Manuals;Circular Economy;Waste Data Modeling;Semantic Data;Neural Search;NLP;Large Language Models},
  doi={10.1109/DCOSS-IoT61029.2024.00105},
  ISSN={2325-2944},
  month={April},}@INPROCEEDINGS{10611970,
  author={Lee, Chang-Shing and Wang, Mei-Hui and Chiang, Jun-Kui and Kubota, Naoyuki and Sato-Shimokawara, Eri and Nojima, Yusuke and Acampora, Giovanni and Wu, Pei-Yu and Chiu, Szu-Chi and Yang, Sheng-Chi and Siow, Chyan-Zheng},
  booktitle={2024 IEEE International Conference on Fuzzy Systems (FUZZ-IEEE)}, 
  title={Quantum Computational Intelligence with Generative AI Image for Human-Machine Interaction}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={This paper introduces a Quantum Computational Intelligence (QCI) agent equipped with a content attention ontology model, specifically designed to enhance human-machine interaction based on a Generative Artificial Intelligence (GAI) image generation agent for Taiwanese/English learning and experience. Its diverse primary applications include social media analysis on Facebook groups and YouTube learning videos related to the 2023 IEEE CIS Education Portal (EP) Subcommittee, as well as in the areas of Taiwanese/English language learning and dialogue experience with GAI image generation. To establish the knowledge and inference models for the QCI agent, we initially developed a Taiwanese/English learning and experience ontology, including a content attention ontology, and an image attention ontology. The QCI agent utilizes metrics such as the number of views, posts, and comments to predict the fuzzy number of reactions. In addition, the GAI image agent generates Taiwanese speech-based/English text-based images and evaluates the fuzzy similarity score between Taiwanese/English and the attention ontology together with the Sentence BERT (SBERT) agent. This Taiwanese/English fuzzy similarity score is further validated through human assessments, with these evaluations subsequently serving as an additional metric for comparative analysis of Human-Machine Interaction (HMI). Furthermore, the GAI image agent is designed to create images and Chinese/English texts from text/speech translated by the Meta AI Universal Speech Translator (UST) Taiwanese/English agent. A Particle Swarm Optimization (PSO)-based machine learning mechanism is employed to train the QCI model for assessing learners' performance and predicting the performance of others. The National University of Tainan (NUTN) Taiwan-Large Language Model (NUTN.TW-LLM) agent has been further enhanced to support interactive learning experiences for HMI. An SBERT-based assessment agent is used to calculate fuzzy similarities between questions and answers in Taiwanese/English experiences and dialogues. Experimental results demonstrate the feasibility and efficacy of the proposed QCI model, equipped with QCI&AI-FML (Artificial Intelligence-Fuzzy Markup Language) and machine learning capabilities, for social media and language learning applications on HMI. In the future, we will extend the QCI model to various HMI applications for student learning around the world.},
  keywords={Human computer interaction;Measurement;Quantum computing;Social networking (online);Image synthesis;Generative AI;Computational modeling;Quantum CI Agent;Content Attention Ontology;ChatGPT;Generative AI Image Agent;IEEE CIS Education Portal;Fuzzy Markup Language;Sentence BERT;NUTN.TW-LLM},
  doi={10.1109/FUZZ-IEEE60900.2024.10611970},
  ISSN={1558-4739},
  month={June},}@INPROCEEDINGS{10605700,
  author={Safronov, Artyom A.},
  booktitle={2024 4th International Conference on Technology Enhanced Learning in Higher Education (TELE)}, 
  title={Using Neural Networks in Building an Ontology of Educational Subjects for Solving Educational Tasks}, 
  year={2024},
  volume={},
  number={},
  pages={189-191},
  abstract={In the modern world, information technologies have become an integral part of a human life, including the professional level. The rapid development of technologies based on artificial intelligence over the past few years has opened up new opportunities for their application in solving various educational tasks. One of the relevant topics for study is the investigation of ontological constructs in texts, identifying the terminology of concepts and determining the relationships between them. This article is dedicated to studying artificial intelligence systems as a tool for solving educational process tasks: it proposes the use of chatbots based on AI systems in conjunction with various digital tools in researching ontological constructs in educational texts. As part of the research, an example is provided with the processing an educational text on mathematics. Methodological characteristics are considered and a model for researching educational text using the ChatGPT is briefly described. Conclusions are drawn about the existing possibilities and difficulties in implementing the aforementioned model.},
  keywords={Systematics;Terminology;Neural networks;Chatbots;Educational courses;Mathematical models;Thesauri;artificial intelligence systems;ontology;thesaurus;chatbot;educational texts;digital tools},
  doi={10.1109/TELE62556.2024.10605700},
  ISSN={},
  month={June},}@INPROCEEDINGS{10605389,
  author={Schoch, Nicolai and Hoernicke, Mario},
  booktitle={2024 IEEE Conference on Artificial Intelligence (CAI)}, 
  title={NL2IBE – Ontology-controlled Transformation of Natural Language into Formalized Engineering Artefacts}, 
  year={2024},
  volume={},
  number={},
  pages={997-1004},
  abstract={Looking at Process and Automation Engineering (P&AE) today, for the technically adept engineer, there are many different tools available to support the engineering work from translation of engineering intentions into module and plant descriptions, to definition and parametrization of entire process plant setups, for export to a control system. However, still today, in the very early engineering phases, engineering intentions either need to be entered already in a structured and controlled expert language or require a human expert’s manual efforts for translation from unstructured language into formalized representations, in order for thereon-based consistent further processing in the existing tools. This process is time-consuming, fuzzy, and error-prone due to potential misconceptions and ambiguities, even for domain experts. In this work, we therefore present our NL2IBE Tool, which makes use of modern Natural Language Processing in combination with Ontology Mining, and which, based on and controlled by an underlying ontology, allows for the deterministic transformation of natural language intentions into structured and consistent engineering artefacts. We describe the overall tool architecture as well as crucial functionalities and implementation features, followed by an evaluation by the example of a hydrogen generation and CCSU use case. We conclude with a discussion of the proposed tool and give an outlook on future research. (Abstract)},
  keywords={Automation;Hydrogen;Process control;Manuals;Ontologies;Control systems;Natural language processing;process &Amp; automation engineering;intend-based engineering;natural language processing;NLP;generative AI;ontological domain representation},
  doi={10.1109/CAI59869.2024.00182},
  ISSN={},
  month={June},}@INPROCEEDINGS{10595652,
  author={Arrotta, Luca and Bettini, Claudio and Civitarese, Gabriele and Fiori, Michele},
  booktitle={2024 IEEE International Conference on Smart Computing (SMARTCOMP)}, 
  title={ContextGPT: Infusing LLMs Knowledge into Neuro-Symbolic Activity Recognition Models}, 
  year={2024},
  volume={},
  number={},
  pages={55-62},
  abstract={Context-aware Human Activity Recognition (HAR) is a hot research area in mobile computing, and the most effective solutions in the literature are based on supervised deep learning models. However, the actual deployment of these systems is limited by the scarcity of labeled data that is required for training. Neuro-Symbolic AI (NeSy) provides an interesting research direction to mitigate this issue, by infusing common-sense knowledge about human activities and the contexts in which they can be performed into HAR deep learning classifiers. Existing NeSy methods for context-aware HAR rely on knowledge encoded in logic-based models (e.g., ontologies) whose design, implementation, and maintenance to capture new activities and contexts require significant human engineering efforts, technical knowledge, and domain expertise. Recent works show that pre-trained Large Language Models (LLMs) effectively encode common-sense knowledge about human activities. In this work, we propose ContextGPT: a novel prompt engineering approach to retrieve from LLMs common-sense knowledge about the relationship between human activities and the context in which they are performed. Unlike ontologies, ContextGPT requires limited human effort and expertise, while sharing similar privacy concerns if the reasoning is performed in the cloud. An extensive evaluation using two public datasets shows how a NeSy model obtained by infusing common-sense knowledge from ContextGPT is effective in data scarcity scenarios, leading to similar (and sometimes better) recognition rates than logic-based approaches with a fraction of the effort.},
  keywords={Knowledge engineering;Deep learning;Training;Privacy;Computational modeling;Ontologies;Human activity recognition;human activity recognition;context-awareness;large language models},
  doi={10.1109/SMARTCOMP61445.2024.00029},
  ISSN={2693-8340},
  month={June},}@INPROCEEDINGS{10597753,
  author={Helali, Mossad and Monjazeb, Niki and Vashisth, Shubham and Carrier, Philippe and Helal, Ahmed and Cavalcante, Antonio and Ammar, Khaled and Hose, Katja and Mansour, Essam},
  booktitle={2024 IEEE 40th International Conference on Data Engineering (ICDE)}, 
  title={KGLiDS: A Platform for Semantic Abstraction, Linking, and Automation of Data Science}, 
  year={2024},
  volume={},
  number={},
  pages={179-192},
  abstract={In recent years, we have witnessed the growing interest from academia and industry in applying data science technologies to analyze large amounts of data. In this process, a myriad of artifacts (datasets, pipeline scripts, etc.) are created. However, there has been no systematic attempt to holistically collect and exploit all the knowledge and experiences that are implicitly contained in those artifacts. Instead, data scientists recover information and expertise from colleagues or learn via trial and error. Hence, this paper presents a scalable platform, KGLiDS, that employs machine learning and knowledge graph technologies to abstract and capture the semantics of data science artifacts and their connections. Based on this information, KGLiDS enables various downstream applications, such as data discovery and pipeline automation. Our comprehensive evaluation covers use cases in data discovery, data cleaning, transformation, and AutoML. It shows that KGLiDS is significantly faster with a lower memory footprint than the state-of-the-art systems while achieving comparable or better accuracy.},
  keywords={Automation;Accuracy;Systematics;Semantics;Pipelines;Machine learning;Knowledge graphs;Linked Data Science;Knowledge Graphs;Graph Neural Networks;Data Integration;Data Discovery},
  doi={10.1109/ICDE60146.2024.00021},
  ISSN={2375-026X},
  month={May},}@INPROCEEDINGS{10597810,
  author={Cavalleri, Emanuele and Mesiti, Marco},
  booktitle={2024 IEEE 40th International Conference on Data Engineering (ICDE)}, 
  title={Construction and Enhancement of an RNA-Based Knowledge Graph for Discovering New RNA Drugs}, 
  year={2024},
  volume={},
  number={},
  pages={5639-5643},
  abstract={Cutting-edge technologies in RNA biology are pushing the study of fundamental biological processes and human diseases and accelerate the development of new drugs tailored to the patient's biomolecular characteristics. Even if many structured and unstructured data sources report the interaction among different RNA molecules and some other biomedical entities (e.g., drugs, diseases, genes), we still lack a comprehensive and well-described RNA-centered Knowledge Graph (KG) that contains such information and sophisticated services that support the user in its creation, maintenance, and enhancement. This PhD project aims to create a biomedical KG (named RNA-KG) to represent, and eventually infer, biological, experimentally validated interactions between different RNA molecules. We also wish to enhance the KG content and develop sophisticated services designed ad-hoc to support the user in predicting uncovered relationships and identifying new RNA-based drugs. Services will rely on deep learning methods that consider the heterogeneity of the graph and the presence of an ontology that describes the possible relationships existing among the involved entities. Moreover, we will consider Large Language Models (LLMs) in combination with RNA-KG for interacting with the user with the ground truth information contained in our KG for extracting relationships from unstructured data sources.},
  keywords={Drugs;Knowledge engineering;Deep learning;RNA;Soft sensors;Large language models;Knowledge graphs;Biomedical knowledge graphs;Graph representation learning;LLMs;RNA therapeutics},
  doi={10.1109/ICDE60146.2024.00453},
  ISSN={2375-026X},
  month={May},}@INPROCEEDINGS{10588309,
  author={Peng, Tao and Rao, Taiwen and Xu, Yansong and Yang, Chao and Xie, Xiaotian and Yang, Chunhua},
  booktitle={2024 36th Chinese Control and Decision Conference (CCDC)}, 
  title={Construction of Rail Transit Network Fault Knowledge Graph Based on Pseudo-Dynamic Relationship Ontology Architecture}, 
  year={2024},
  volume={},
  number={},
  pages={4582-4587},
  abstract={In this paper, an approach to construction of rail transit network fault knowledge graph based on pseudo-dynamic relationship ontology architecture is proposed. Firstly, an ontology architecture that includes pseudo-dynamic relationships is employed to completely separate fault patterns from fault entities without losing semantics. Secondly, a named entity recognition method based on the BERT-BiGRU-CRF model is adopted, which performs well in short entity extraction tasks. Thirdly, a pseudo-dynamic relationship extraction method based on the BERT-MEA(multi entities attention) model is adopted to extract static simple relationships, followed by treating triples as head and tail entities to determine pseudo-dynamic relationships. The implementation of rail transit network fault knowledge graph demonstrates the effectiveness of the proposed approach.},
  keywords={Rails;Databases;Semantics;Knowledge graphs;Tail;Named entity recognition;Ontologies;Ontology architecture;Pseudo-dynamic relationship;Short entity;Fault knowledge graph},
  doi={10.1109/CCDC62350.2024.10588309},
  ISSN={1948-9447},
  month={May},}@INPROCEEDINGS{10582050,
  author={Vanitha, V. and Antony Rai, A. Stephan and Vinodhini, D. and Gnanaprasanambikai, L. and Kumar, L. Senthil and Renukadevi, S.},
  booktitle={2024 International Conference on Advances in Modern Age Technologies for Health and Engineering Science (AMATHE)}, 
  title={Synergy of Human Language Processing and Artificial Intelligence}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={This study explores the intriguing harmony between human language processing and artificial intelligence (AI). We delve into the intricate process of translating mental concepts into linguistic expressions, akin to the capabilities of AI language models. Through a survey of existing research, we uncover the parallelism between the ontological taxonomy guiding human cognition and AI's language understanding mechanisms. Moreover, we investigate how AI's multilingual proficiency mirrors the cognitive multilingualism found in individuals. This convergence holds implications for cross-lingual communication and AI-human collaboration. Our analysis anticipates a symbiotic future where the interplay of cognitive insights and AI advancements amplifies the potential of both realms.},
  keywords={Symbiosis;Surveys;Computational modeling;Taxonomy;Semantics;Linguistics;Mathematical models;Language Cognition;Artificial Intelligence;On tological Taxonomy;Multilingualism;Cross-Lingual Communication},
  doi={10.1109/AMATHE61652.2024.10582050},
  ISSN={},
  month={May},}@ARTICLE{10592819,
  author={Sun, Zhigang and Wang, Zixu and Halilaj, Lavdim and Luettin, Juergen},
  journal={IEEE Robotics and Automation Letters}, 
  title={SemanticFormer: Holistic and Semantic Traffic Scene Representation for Trajectory Prediction Using Knowledge Graphs}, 
  year={2024},
  volume={9},
  number={9},
  pages={7381-7388},
  abstract={Trajectory prediction in autonomous driving relies on accurate representation of all relevant contexts of the driving scene, including traffic participants, road topology, traffic signs, as well as their semantic relations to each other. Despite increased attention to this issue, most approaches in trajectory prediction do not consider all of these factors sufficiently. We present SemanticFormer, an approach for predicting multimodal trajectories by reasoning over a semantic traffic scene graph using a hybrid approach. It utilizes high-level information in the form of meta-paths, i.e. trajectories on which an agent is allowed to drive from a knowledge graph which is then processed by a novel pipeline based on multiple attention mechanisms to predict accurate trajectories. SemanticFormer comprises a hierarchical heterogeneous graph encoder to capture spatio-temporal and relational information across agents as well as between agents and road elements. Further, it includes a predictor to fuse different encodings and decode trajectories with probabilities. Finally, a refinement module assesses permitted meta-paths of trajectories and speed profiles to obtain final predicted trajectories. Evaluation of the nuScenes benchmark demonstrates improved performance compared to several SOTA methods. In addition, we demonstrate that our knowledge graph can be easily added to two graph-based existing SOTA methods, namely VectorNet and LaFormer, replacing their original homogeneous graphs. The evaluation results suggest that by adding our knowledge graph the performance of the original methods is enhanced by 5% and 4%, respectively.},
  keywords={Trajectory;Knowledge graphs;Semantics;Ontologies;Encoding;Predictive models;Transformers;Semantic scene understanding;autonomous agents;intelligent transportation systems},
  doi={10.1109/LRA.2024.3426386},
  ISSN={2377-3766},
  month={Sep.},}@INPROCEEDINGS{10578858,
  author={Lehmann, Alexander and Landes, Dieter},
  booktitle={2024 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Extracting Metadata from Learning Videos for Ontology-Based Recommender Systems Using Whisper & GPT}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={In modern education, individualized learning environments play a vital role by allowing learners to tailor their learning paths based on personal needs, interests, and abilities. Achieving effective individualization relies on dynamic adaptation of the learning path, typically facilitated by recommender systems. These systems offer personalized suggestions, commonly employing content-based or collaborative filtering approaches. However, traditional recommender systems often lack consideration of the semantics of learning elements. To address this limitation, ontology-based recommender systems integrate semantic modeling, establishing additional connections within a domain to enhance precision and context in recommendations. Notably, these systems mitigate the cold start problem and are particularly advantageous in learning environments with limited data. While videos are prevalent in learning platforms, their unstructured nature poses challenges for processing. This paper introduces an innovative approach, leveraging Large Language Models, specifically GPT, to extract metadata from learning videos. The proposed method intelligently augments videos and links them to a domain ontology, enabling the integration of videos into ontology-based recommender systems. The application of this approach is demonstrated through a case study in software engineering education, showcasing its potential to enhance individualized learning experiences in specific domains. The presented method offers an automated alternative to manual video processing, aligning with the evolving landscape of education technology.},
  keywords={Large language models;Semantics;Manuals;Metadata;Ontologies;Engineering education;Recommender systems;learning analytics;adaptive learning environments;generative AI;large language models;ontology-based recommender systems;learning videos},
  doi={10.1109/EDUCON60312.2024.10578858},
  ISSN={2165-9567},
  month={May},}@INPROCEEDINGS{10569741,
  author={Keber, M. and Grubišić, I. and Barešić, A. and Jović, A.},
  booktitle={2024 47th MIPRO ICT and Electronics Convention (MIPRO)}, 
  title={A Review on Neuro-symbolic AI Improvements to Natural Language Processing}, 
  year={2024},
  volume={},
  number={},
  pages={66-72},
  abstract={Symbolic artificial intelligence (AI) reflects the domain knowledge of experts and adheres to the logic of the subject area, rules, or any relations between entities. Connectionist (neuro) approaches based on artificial neural networks are excellent for extracting abstract features, contextualizing, and embedding interactions between features. When connectionist and symbolic approaches are properly aligned in a model, they benefit from complementary strengths; the combination is referred to as a hybrid or neuro-symbolic artificial intelligence (NSAI) model. The advantages that NSAI brings to the field of natural language processing (NLP) have received little attention from researchers in recent years. Therefore, in this review, we focus on the impact of neuro-symbolic approaches for NLP tasks, i.e. text classification, information extraction, machine translation, and language understanding. Relevant research articles from Scopus, Web of Science, and Google Scholar were carefully examined using appropriate keywords in the period from 2019 to 2024. The review aims to show the types of NSAI systems, identify the motivation for using NSAI, evaluate the use of additional annotations for content description, and briefly describe how the neuro-symbolic connection improves the methodology and enables trustworthy and explainable AI systems in current NLP research. The review also highlights areas of application and improvements achieved by NSAI approaches in benchmarks.},
  keywords={Training;Reviews;Annotations;Text categorization;Feature extraction;Natural language processing;Machine translation;neuro-symbolic artificial intelligence;natural language processing;knowledge representation;deep learning},
  doi={10.1109/MIPRO60963.2024.10569741},
  ISSN={2623-8764},
  month={May},}@INPROCEEDINGS{10553629,
  author={Melzer, Sylvia and Weilkiens, Tim and Muggeo, Christian and Berres, Axel},
  booktitle={2024 IEEE International Systems Conference (SysCon)}, 
  title={Sustainable Development of Information Systems Using SysML, FAS and DOL}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={The use of product families can improve the efficiency of product development as opposed to develop a single-product by reusing existing artefacts and optimizing variability, which leads to a saving of resources and is therefore a sustainable approach. To extend new variants of an already modelled product via the approach of a product family the challenge is to merge the product models, so that the same and varying parts in the model are semantically correct identified and mapped to each other. This paper proposes a comprehensive approach for sustainable development of product families using the Distributed Ontology Language (DOL), Functional Architectures for Systems (FAS), and Systems Modeling Language (SysML). The proposed approach integrates the idea of DOL to represent an ontology of sustainability criteria and to map them to the functional architecture of a product family. FAS is used to model the functional architecture of the product family, while the FAS ontology is used to formalize the functional architecture and provide a standardized vocabulary and set of rules for modelling the functional aspects of the product family. SysML is used to model the product family. The proposed method is demonstrated through a case study of developing a sustainable product family of vacuum cleaner robots. The results show that the proposed method can help to identify opportunities for reducing environ-mental impact and improving social responsibility in the product family design while ensuring that functional requirements and design constraints are met semantically correct.},
  keywords={Vocabulary;Biological system modeling;Ontologies;Systems Modeling Language;Product development;Product design;Sustainable development;sustainability;functional architectures for systems;Distributed Ontology Language;product family;SysML},
  doi={10.1109/SysCon61195.2024.10553629},
  ISSN={2472-9647},
  month={April},}@INPROCEEDINGS{10554074,
  author={Chiş, Andrei and Stoica, Oliviu Ionuţ and Ghiran, Ana-Maria and Buchmann, Robert Andrei},
  booktitle={2024 IEEE International Conference on Automation, Quality and Testing, Robotics (AQTR)}, 
  title={A Knowledge Graph Approach to Cyber Threat Mitigation Derived from Data Flow Diagrams}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Data Flow Diagrams (DFD) have proven effective in designing and analyzing the flow of data in enterprise systems. They serve as indispensable tools for enterprises that are undergoing transition to cloud services. DFDs aid in understanding the current processes, identifying interfaces and integration points that require security measures. This paper reports a Design Science project to mitigate the cyber security threats at the design phase of a system and to perform auditing of an existing system through knowledge graphs. The proposal leverages knowledge gathered from various sources in a knowledge graph to identify semantic relationships and patterns, enabling automated inference, analysis and detection of vulnerability patterns. Furthermore, LLM-based (large language models) capabilities transform data management details captured as Data Flow Diagrams (DFD) into knowledge graphs for semantic querying and improved decision support.},
  keywords={Current measurement;Semantics;Knowledge graphs;Transforms;Data models;Security;Proposals;knowledge graphs;security;privacy;data flow diagrams;threat modeling;LLMs},
  doi={10.1109/AQTR61889.2024.10554074},
  ISSN={1844-7872},
  month={May},}@ARTICLE{10553231,
  author={Li, Xiaodong and Tian, Guohui and Cui, Yongcheng},
  journal={IEEE Robotics and Automation Letters}, 
  title={Fine-Grained Task Planning for Service Robots Based on Object Ontology Knowledge via Large Language Models}, 
  year={2024},
  volume={9},
  number={8},
  pages={6872-6879},
  abstract={In domestic environment, the successful execution of service tasks heavily relies on the robot's capability to identify and understand objects within its surrounding. This crucial process predominantly takes place during task planning, prior to the actual performance of service tasks. Therefore, it is vital that the robot is capable of formulating object-specific action sequences through task planning. In this letter, we propose the Fine-Grained Task Planning (FGTP) framework, an innovative method that combines object ontology knowledge with Large Language Models (LLMs) to create detailed action sequences. The FGTP framework is uniquely designed to process both text descriptions of service tasks and images of relevant objects, enabling a thorough comprehension of object attributes essential for task execution. Moreover, we have developed a set of rules based on these attributes to assist in the robot's decision-making process. In scenarios where service tasks fail because the object is in an unsuitable state, our framework deploys a logic-based reasoning method, concentrating on object attributes to identify suitable substitutes. This process leverages a pre-established semantic map to locate these alternatives, thus enabling a transition back to standard task planning. Our evaluations, conducted in both the VirtualHome simulation environment and with the TIAGo real robot, demonstrate the efficacy of our approach. This confirms our framework's capability to generate practical and implementable plans for various service tasks.},
  keywords={Task analysis;Planning;Ontologies;Service robots;Robot kinematics;Object recognition;Task planning;service robotics},
  doi={10.1109/LRA.2024.3412593},
  ISSN={2377-3766},
  month={Aug},}@ARTICLE{10552698,
  author={Larhrib, Mohamed and Escribano, Miguel and Cerrada, Carlos and Escribano, Juan Jose},
  journal={IEEE Access}, 
  title={An Ontological Behavioral Modeling Approach With SHACL, SPARQL, and RDF Applied to Smart Grids}, 
  year={2024},
  volume={12},
  number={},
  pages={82041-82056},
  abstract={Every engineering process, especially software, involves two complementary aspects: structural and behavioral. Behavior is, in essence, transforming the structure associated with the system. As a language for the object-oriented paradigm, Unified Modeling Language (UML) offers constructs for both aspects, for example, class diagrams for the structural aspect and activity diagrams for the behavioral aspect. However, without obtaining directly executable models, in glass-box terms, or reasoning support, on the other hand, when software engineering is approached with ontologies, only constructs for structural aspects are provided to develop a directly executable model, thanks to their reasoning capability. However, there are no constructs or approaches for this paradigm’s specification or definition of behavior. This lack appears mainly in the early stages of the software engineering process, where there are no constructs similar to, e.g., the activity diagram in the object-oriented domain. Object Management Group (OMG) already addressed the transformation between the two paradigms in structural terms throughout Ontology Definition Metamodel (ODM) from UML to Resource Description Framework (RDF) and Web Ontology Language (OWL). However, there is no transformation of the object-oriented behavioral constructs into ontologies because they are not defined in the ontological paradigm. This paper addresses the definition of behavior in the ontology paradigm and the transformation of behavioral constructs between the two paradigms. The foundation of behavior specification is the flow concept, and the basis of this is the transformation of the structural model in an evaluative sense. Therefore, once the behavior has been defined in the ontology domain, the artifacts obtained throughout the life cycle are directly executable, and their validation and testing are automatic. With this approach, the life cycle is reduced to a modeling process. Thus, the resulting software engineering process improves features such as agility, simplicity, productivity, and formalism. The target audience for this work is the software engineering community, especially in the Model-Driven Engineering (MDE) paradigm approached from object-oriented and ontology perspectives. The evaluation of the proposed approach has been performed in the electric utilities, solving the problem of the validation flow for the interoperability process specified by the Common Grid Model Exchange Standard (CGMES) standard.},
  keywords={Unified modeling language;Ontologies;Object oriented modeling;Resource description framework;Software engineering;OWL;Cognition;Behavioral sciences;Behavioral modeling;CIM for ENTSO-E (CGMES);directly executable;ontology RDF/RDFS/OWL/SHACL},
  doi={10.1109/ACCESS.2024.3412656},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10544941,
  author={Dequan, Gao and Pengyu, Zhu and Sheng, Wang and Ziyan, Zhao},
  booktitle={2024 6th Asia Energy and Electrical Engineering Symposium (AEEES)}, 
  title={Deep Learning-Based Fault Knowledge Graph Construction for Power Communication Networks}, 
  year={2024},
  volume={},
  number={},
  pages={1088-1093},
  abstract={Power communication network is a crucial infrastructure in the model power system, and its maintenance capability are crucial to ensuring the stable operation of power grid business. As an organized semantic knowledge base, the knowledge graph effectively organizes power communication network fault documentation and expert experience to enhance intelligent maintenance. This paper outlines a top-down approach to systematically construct a fault knowledge graph in the domain of power communication networks. The approach utilizes a seven-step method to establish a domain ontology model and integrates deep learning algorithms, including pre-trained language models, bidirectional long short time memory networks, convolutional neural networks and attention mechanisms. These algorithms process unstructured text to extract key entities and relationships. The effectiveness of the approach is verified through experiments using a product device document as a test case. Extracted knowledge is then visualized and stored using Neo4j database. Finally, this paper proposes a knowledge service model centered on fault knowledge graph and explores its application in fault diagnosis.},
  keywords={Deep learning;Patents;Semantics;Knowledge graphs;Ontologies;Real-time systems;Power grids;power communication networks;fault knowledge graph;deep learning;fault diagnosis},
  doi={10.1109/AEEES61147.2024.10544941},
  ISSN={},
  month={March},}@INPROCEEDINGS{10540801,
  author={Libro, Mario and Gaiardelli, Sebastiano and Lora, Michele and Fummi, Franco},
  booktitle={2024 IEEE International Conference on Industrial Technology (ICIT)}, 
  title={Integrating Modeling Languages with Ontologies in the Context of Industry 4.0}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={The evolving landscape of manufacturing systems and the increasing complexity of production lines necessitate innovative approaches for efficient information management and process modeling. The System Modeling Language (SysML) provides a powerful language to express such information. However, the expressiveness comes at a cost: on the one hand, the modeling phase requires a deep understanding of the domain; on the other, SysML lacks rigorous semantics. This work introduces a novel methodology that enriches the SysML with ontology reasoning in the context of manufacturing systems. The approach uses ontologies as a comprehensive knowledge base that encapsulates essential details about the machinery, their provided functions, and the associated constraints. The approach offers a reliable and efficient way to verify the consistency and correctness of production recipes: it ensures recipes' practical applicability in the manufacturing process while reducing errors that can occur in the modeling phase. The proposed methodology has been validated through its application to a fully-fledged manufacturing line, showing its applicability in real-world scenarios.},
  keywords={Manufacturing processes;Process modeling;Knowledge based systems;Ontologies;Cognition;Systems Modeling Language;Reliability;Computer-aided manufacturing;process modeling;knowledge representation},
  doi={10.1109/ICIT58233.2024.10540801},
  ISSN={2643-2978},
  month={March},}@INPROCEEDINGS{10521188,
  author={Timperley, Louis and Berthoud, Lucy and Snider, Chris and Tryfonas, Theo},
  booktitle={2024 IEEE Aerospace Conference}, 
  title={Mapping the MBSE Environment and Complementary Design Space Exploration Techniques}, 
  year={2024},
  volume={},
  number={},
  pages={1-20},
  abstract={Today’s MBSE tools and environments are highly varied and therefore present a challenge for organizations looking to implement MBSE. Furthermore, while MBSE environments are highly capable of supporting the description of design baselines, the current capabilities within these environments could be further refined for exploring alternative designs. As a result it is important to gain an understanding of the limitations of current MBSE tooling in performing the valuable activity of design space exploration, and identify a set of candidate techniques to combat these. This paper reviews the various options available to MBSE practitioners by comparing some of the most common MBSE languages, tools and methods. The possible issues that can be encountered when exploring different designs have been identified and assigned a severity rating. A set of design space exploration techniques are presented, and where possible these have been sourced from existing literature. A knowledge graph has been constructed to collect all this data into a structured format, containing all the MBSE languages, tools, methods, design space exploration-related issues and techniques, as well as the relationships between each of these. This knowledge graph, implemented as a Neo4j graph database, allowed deeper insights to be drawn from the collected information. By defining a selected MBSE environment, including language, tool and method, the knowledge graph could be used to identify the least troublesome sequence (with minimum number of related issues) to arrive at a desired design artifact, for example a set of optimized system parameters. Beside this, the knowledge graph could be used to display the relationships and clusters of MBSE languages, tools and methods, to assist organizations with selecting suitable MBSE environment elements. Future work will bring greater depth to the analysis available with the knowledge graph, for instance, differentiation between different types of design space exploration issues and techniques.},
  keywords={Codes;Reviews;Databases;Design methodology;Knowledge based systems;Knowledge graphs;Organizations},
  doi={10.1109/AERO58975.2024.10521188},
  ISSN={1095-323X},
  month={March},}@INPROCEEDINGS{10521022,
  author={Peer, Jordan and Mordecai, Yaniv and Reich, Yoram},
  booktitle={2024 IEEE Aerospace Conference}, 
  title={NLP4ReF: Requirements Classification and Forecasting: From Model-Based Design to Large Language Models}, 
  year={2024},
  volume={},
  number={},
  pages={1-16},
  abstract={We introduce Natural Language Processing for Requirement Forecasting (NLP4ReF), a model-based machine learning and natural language processing solution for enhancing the Requirements Engineering (RE) process. RE continues to face significant challenges and demands innovative approaches for process efficiency. Traditional RE methods relying on natural language struggle with incomplete, hidden, forgotten, and evolving requirements during and after the critical design review, risking project failures and setbacks. NLP4ReF tackles several key challenges: a) distinguishing between functional and non-functional requirements, b) classification of requirements by their respective system classes, and c) generation of unanticipated requirements to enhance project success. NLP4ReF employs a common natural language toolkit (NLTK) package and the recently-trending Chat-GPT. We tested NLP4ReF on PROMISE_exp, a pre-existing dataset with 1000 software requirements, and PROMISE_IoT, an enhanced dataset with 2000 software and IoT requirements. We validated NLP4ReF on a genuine IoT project. NLP4ReF swiftly generated dozens of new requirements, verified by a team of systems engineers, of which over 70% were crucial for project success. We found that GPT is superior in authentic requirement generation, while NLTK excels at requirement classification. NLP4ReF offers significant time saving, effort reduction, and improved future-proofing. Our model-based design approach provides a foundation for enhanced RE practices and future research in this domain.},
  keywords={Software algorithms;Training data;Software;Natural language processing;Data models;Classification algorithms;Requirements engineering;Natural Language Processing;Requirements Engineering Requirement Forecasting;Internet of Things;Machine Learning;Model-Based Systems Engineering},
  doi={10.1109/AERO58975.2024.10521022},
  ISSN={1095-323X},
  month={March},}@ARTICLE{10508456,
  author={Yang, Puhai and Huang, Heyan and Shi, Shumin and Mao, Xian-Ling},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing}, 
  title={STN4DST: A Scalable Dialogue State Tracking Based on Slot Tagging Navigation}, 
  year={2024},
  volume={32},
  number={},
  pages={2494-2507},
  abstract={Dialogue state tracking plays a key role in tracking user intentions in task-oriented dialogue systems. Traditional dialogue state tracking methods usually rely on selecting slot values from a fixed ontology to represent the dialogue state. In recent years, more flexible open vocabulary based approaches have become the mainstream focus which are mainly divided into two categories: generative methods and span extraction methods. Among them, the span extraction method is favored for its outstanding ability to predict unknown slot values. However, the span extraction method only focuses on the predicted slot values, but ignores other potential slot values in the utterance, which leads to insufficient semantic understanding of the utterance and difficulty in dealing with complex utterance scenarios, such as more or longer unknown slot values. To tackle the above drawbacks, in this paper, we propose a novel scalable dialogue state tracking method, which employs slot tagging to locate all potential slot values in the utterances and jointly learns slot pointers to select the predicted slot value from them. Specifically, our STN4DST (Slot Tagging Navigation for Dialogue State Tracking) model not only adopts the above joint learning strategy, which we call slot tagging navigation, to extract slot values from utterances, but also uses previous dialogue states as dialogue contexts to track the change of slot values, and introduces appendix slot values to predict special slot values that cannot be extracted. Extensive experiments show that in the open vocabulary setting, STN4DST achieves the state-of-the-art joint goal accuracy of 85.4% and 96.5% on Sim-M and Sim-R datasets with a large number of unknown slot values, and is also comparable to other state-of-the-art models in the absence of token-level slot annotations for all potential slot values.},
  keywords={Tagging;Navigation;Speech processing;Vocabulary;Semantics;Predictive models;Ontologies;Task-oriented dialogue system;dialogue state tracking;scalable DST;unknown slot value},
  doi={10.1109/TASLP.2024.3393733},
  ISSN={2329-9304},
  month={},}@INPROCEEDINGS{10507138,
  author={Anass, Bayaga},
  booktitle={2024 Conference on Information Communications Technology and Society (ICTAS)}, 
  title={Advancing STEM cognition with current AI landscape and systems}, 
  year={2024},
  volume={},
  number={},
  pages={20-25},
  abstract={Application of AI explores the potential of algorithms to ensure fairness, accuracy, and efficiency in grading students' performance, offering valuable insights into their strengths and areas for improvement. While the current AI landscape showcases remarkable progress, there are several areas ripe for exploration. One such avenue is AI steps to consider in STEM, wherein researchers aim to develop specialised steps/models to understand and generate domain-specific STEM content. The systematic literature review highlighted the importance of domain adaptation techniques for enhancing STEM comprehension by fine-tuning transformer-based language models like BERT. Integrating domain knowledge through ontology-based and context of STEM disciplines. Future research should focus on building domain-specific annotated datasets to improve the performance models in STEM comprehension. Additionally, exploring unsupervised domain adaptation techniques and leveraging domain-specific knowledge graphs can further enhance the NLP models’ adaptability to diverse STEM domains.},
  keywords={Adaptation models;Vocabulary;Systematics;Bibliographies;Laboratories;Knowledge graphs;Transformers;Data models;Artificial intelligence;STEM;Artificial Intelligence;STEM Education;Explainable AI;Natural Language Processing;AI-Augmented Laboratories},
  doi={10.1109/ICTAS59620.2024.10507138},
  ISSN={},
  month={March},}@INPROCEEDINGS{10485759,
  author={Zhu, Ruiliang and Song, Xiangshuai and Zhang, Hao and Cai, Xuli},
  booktitle={2024 IEEE 3rd International Conference on Electrical Engineering, Big Data and Algorithms (EEBDA)}, 
  title={Joint Extraction of Entity Relationships in Walnut Disease and Pest Based on Chinese NLP Models}, 
  year={2024},
  volume={},
  number={},
  pages={1027-1035},
  abstract={This study addresses the limited application of deep learning techniques in the field of walnut disease and pest and the challenges posed by complex relationships and diverse entity types in this domain. We propose a deep learning-based method for constructing a knowledge graph in the walnut disease and pest domain, incorporating ontologies to establish a conceptual model for the disease and pest knowledge graph. To overcome issues such as relationship overlap (e.g., one-to-many, many-to-many) and loss of relationship chains, we introduce a novel labeling scheme called “based on ontology binding BIESO (Begin-Inside-End-Single-Other)” that directly models triplets. By employing a label matching algorithm, we obtain triplet data. We train and predict on the dataset using an end-to-end model consisting of Bidirectional Encoder Representations from Transformers (BERT), Bi-directional Gate Recurrent Unit (BiGRU), and Conditional Random Field (CRF). Experimental results show an F1 score of 75.79%, outperforming models such as BERT-BiLSTM-CRF and word2vec-BiGRU-CRF. We semiautomatically extract unstructured knowledge and store the extracted triplets in a Neo4j graph database, enabling visualization of the knowledge. The research methodology of this knowledge graph can serve as a reference for constructing knowledge graphs in walnut agriculture and developing intelligent question-answering systems for walnut disease and pest.},
  keywords={Knowledge graphs;Bidirectional control;Ontologies;Predictive models;Logic gates;Transformers;Prediction algorithms;Walnut disease and pest;ontology;BERTBiGRU-CRF;knowledge graph;deep learning},
  doi={10.1109/EEBDA60612.2024.10485759},
  ISSN={},
  month={Feb},}@ARTICLE{10487851,
  author={Strader, Jared and Hughes, Nathan and Chen, William and Speranzon, Alberto and Carlone, Luca},
  journal={IEEE Robotics and Automation Letters}, 
  title={Indoor and Outdoor 3D Scene Graph Generation Via Language-Enabled Spatial Ontologies}, 
  year={2024},
  volume={9},
  number={6},
  pages={4886-4893},
  abstract={This letter proposes an approach to build 3D scene graphs in arbitrary indoor and outdoor environments. Such extension is challenging; the hierarchy of concepts that describe an outdoor environment is more complex than for indoors, and manually defining such hierarchy is time-consuming and does not scale. Furthermore, the lack of training data prevents the straightforward application of learning-based tools used in indoor settings. To address these challenges, we propose two novel extensions. First, we develop methods to build a spatial ontology defining concepts and relations relevant for indoor and outdoor robot operation. In particular, we use a Large Language Model (LLM) to build such an ontology, thus largely reducing the amount of manual effort required. Second, we leverage the spatial ontology for 3D scene graph construction using Logic Tensor Networks (LTN) to add logical rules, or axioms (e.g., “a beach contains sand”), which provide additional supervisory signals at training time thus reducing the need for labelled data, providing better predictions, and even allowing predicting concepts unseen at training time. We test our approach in a variety of datasets, including indoor, rural, and coastal environments, and show that it leads to a significant increase in the quality of the 3D scene graph generation with sparsely annotated data.},
  keywords={Three-dimensional displays;Ontologies;Semantics;Training data;Solid modeling;Artificial intelligence;Semantics;Image analysis;Spatial resolution;Indoor environment;AI-based methods;3D scene graphs;semantic scene understanding;spatial ontologies},
  doi={10.1109/LRA.2024.3384084},
  ISSN={2377-3766},
  month={June},}@INPROCEEDINGS{10475639,
  author={Vizcarra, Julio and Haruta, Shuichiro and Kurokawa, Mori},
  booktitle={2024 IEEE 18th International Conference on Semantic Computing (ICSC)}, 
  title={Representing the Interaction between Users and Products via LLM-assisted Knowledge Graph Construction}, 
  year={2024},
  volume={},
  number={},
  pages={231-232},
  abstract={To understand user behavior, representing the semantic knowledge of user-product interaction is essential. In this paper, we represent the interaction between user and product via large language model (LLM)-assisted knowledge graph construction. We capture users’ behavioral actions and static properties of the products from raw text data of “user review” and “product catalog”. Moreover, the information needed for updating the knowledge graph is captured by raw texts of “news related to the products”. The proposed methodology integrates them as a single knowledge graph to provide causal reasoning on user-product interaction. To alleviate the situation where a small quantity of annotated text exists in these data, we use LLM as a data annotator and augmentor.},
  keywords={Text mining;Reviews;Annotations;Semantics;Knowledge graphs;Data augmentation;Cognition;Knowledge graph;text mining;ontology;causality;LLM;user-product interaction},
  doi={10.1109/ICSC59802.2024.00043},
  ISSN={2472-9671},
  month={Feb},}@INPROCEEDINGS{10446860,
  author={Luo, Zhizhao and Wang, Youchen and Ke, Wenjun and Qi, Rui and Guo, Yikai and Wang, Peng},
  booktitle={ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Boosting LLMS with Ontology-Aware Prompt for Ner Data Augmentation}, 
  year={2024},
  volume={},
  number={},
  pages={12361-12365},
  abstract={Named Entity Recognition (NER) data augmentation (DA) aims to improve the performance and generalization capabilities of NER models by generating scalable training data. The key challenge lies in ensuring the generated samples maintain contextual diversity while preserving label consistency. However, existing dominant methods fail to simultaneously satisfy both criteria. Inspired by the extensive generative capabilities of large language models (LLMs), we propose ANGEL, a frAmework integrating the oNtoloGy structure and instructivE prompting within LLMs. Specifically, the hierarchical ontology structure guides prompt ranking, while instructive prompting enhances LLMs’ mastery of domain knowledge, empowering synthetic sample generation and annotation. Experiments show ANGEL surpasses state-of-the-art (SOTA) baselines, conferring absolute F1 increases of 2.86% and 0.93% on two benchmark datasets, respectively.},
  keywords={Training data;Speech recognition;Ontologies;Syntactics;Signal processing;Data augmentation;Boosting;Named Entity Recognition;Data Augmentation;Large language Model;Knowledge Graph},
  doi={10.1109/ICASSP48485.2024.10446860},
  ISSN={2379-190X},
  month={April},}@INPROCEEDINGS{10446928,
  author={Liu, Wuyang and Ren, Yanzhen},
  booktitle={ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Semantic Proximity Alignment: Towards Human Perception-Consistent Audio Tagging by Aligning with Label Text Description}, 
  year={2024},
  volume={},
  number={},
  pages={541-545},
  abstract={Most audio tagging models are trained with one-hot labels as supervised information. However, one-hot labels treat all sound events equally, ignoring the semantic hierarchy and proximity relationships between sound events. In contrast, the event descriptions contains richer information, describing the distance between different sound events with semantic proximity. In this paper, we explore the impact of training audio tagging models with auxiliary text descriptions of sound events. By aligning the audio features with the text features of corresponding labels, we inject the hierarchy and proximity information of sound events into audio encoders, improving the performance while making the prediction more consistent with human perception. We refer to this approach as Semantic Proximity Alignment (SPA). We use Ontology-aware mean Average Precision (OmAP) as the main evaluation metric for the models. OmAP reweights the false positives based on Audioset ontology distance and is more consistent with human perception compared to mAP. Experimental results show that the audio tagging models trained with SPA achieve higher OmAP compared to models trained with one-hot labels solely (+1.8 OmAP). Human evaluations also demonstrate that the predictions of SPA models are more consistent with human perception.},
  keywords={Training;Measurement;Semantics;Natural languages;Tagging;Signal processing;Predictive models;Audio Classification;Sound Event Detection;Multi-modality;Audio-text Pretraining;Transformer},
  doi={10.1109/ICASSP48485.2024.10446928},
  ISSN={2379-190X},
  month={April},}@INPROCEEDINGS{10446325,
  author={Xu, Hongshen and Cao, Ruisheng and Zhu, Su and Jiang, Sheng and Zhang, Hanchong and Chen, Lu and Yu, Kai},
  booktitle={ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={A Birgat Model for Multi-Intent Spoken Language Understanding with Hierarchical Semantic Frames}, 
  year={2024},
  volume={},
  number={},
  pages={12251-12255},
  abstract={Previous work on spoken language understanding (SLU) mainly focuses on single-intent settings, where each input utterance merely contains one user intent. This configuration significantly limits the surface form of user utterances and the capacity of output semantics. In this work, we firstly propose a Multi-Intent dataset which is collected from a realistic in-Vehicle dialogue System, called MIVS. The target semantic frame is organized in a 3-layer hierarchical structure to tackle the alignment and assignment problems in multi-intent cases. Accordingly, we devise a BiRGAT model to encode the hierarchy of ontology items, the backbone of which is a dual relational graph attention network. Coupled with the 3-way pointer-generator decoder, our method outperforms traditional sequence labeling and classification-based schemes by a large margin. Ablation study in transfer learning settings further uncovers the poor generalizability of current models in multi-intent cases.},
  keywords={Semantics;Transfer learning;Ontologies;Signal processing;Acoustics;Decoding;Labeling;Spoken Language Understanding;relational graph attention network;hierarchical semantic frame},
  doi={10.1109/ICASSP48485.2024.10446325},
  ISSN={2379-190X},
  month={April},}@ARTICLE{10465250,
  author={Ma, Wenjian and Bi, Xiangpeng and Jiang, Huasen and Zhang, Shugang and Wei, Zhiqiang},
  journal={IEEE Journal of Biomedical and Health Informatics}, 
  title={CollaPPI: A Collaborative Learning Framework for Predicting Protein-Protein Interactions}, 
  year={2024},
  volume={28},
  number={5},
  pages={3167-3177},
  abstract={Exploring protein-protein interaction (PPI) is of paramount importance for elucidating the intrinsic mechanism of various biological processes. Nevertheless, experimental determination of PPI can be both time-consuming and expensive, motivating the exploration of data-driven deep learning technologies as a viable, efficient, and accurate alternative. Nonetheless, most current deep learning-based methods regarded a pair of proteins to be predicted for possible interaction as two separate entities when extracting PPI features, thus neglecting the knowledge sharing among the collaborative protein and the target protein. Aiming at the above issue, a collaborative learning framework CollaPPI was proposed in this study, where two kinds of collaboration, i.e., protein-level collaboration and task-level collaboration, were incorporated to achieve not only the knowledge-sharing between a pair of proteins, but also the complementation of such shared knowledge between biological domains closely related to PPI (i.e., protein function, and subcellular location). Evaluation results demonstrated that CollaPPI obtained superior performance compared to state-of-the-art methods on two PPI benchmarks. Besides, evaluation results of CollaPPI on the additional PPI type prediction task further proved its excellent generalization ability.},
  keywords={Proteins;Collaboration;Task analysis;Feature extraction;Protein engineering;Deep learning;Vectors;Graph neural network;multi-task learning;protein-protein interaction;protein representation learning},
  doi={10.1109/JBHI.2024.3375621},
  ISSN={2168-2208},
  month={May},}@ARTICLE{10452779,
  author={Hu, Fan and Zhang, Weihong and Huang, Huazhen and Li, Wang and Li, Yang and Yin, Peng},
  journal={IEEE Journal of Biomedical and Health Informatics}, 
  title={A Transferability-Based Method for Evaluating the Protein Representation Learning}, 
  year={2024},
  volume={28},
  number={5},
  pages={3158-3166},
  abstract={Self-supervised pre-trained language models have recently risen as a powerful approach in learning protein representations, showing exceptional effectiveness in various biological tasks, such as drug discovery. Amidst the evolving trend in protein language model development, there is an observable shift towards employing large-scale multimodal and multitask models. However, the predominant reliance on empirical assessments using specific benchmark datasets for evaluating these models raises concerns about the comprehensiveness and efficiency of current evaluation methods. Addressing this gap, our study introduces a novel quantitative approach for estimating the performance of transferring multi-task pre-trained protein representations to downstream tasks. This transferability-based method is designed to quantify the similarities in latent space distributions between pre-trained features and those fine-tuned for downstream tasks. It encompasses a broad spectrum, covering multiple domains and a variety of heterogeneous tasks. To validate this method, we constructed a diverse set of protein-specific pre-training tasks. The resulting protein representations were then evaluated across several downstream biological tasks. Our experimental results demonstrate a robust correlation between the transferability scores obtained using our method and the actual transfer performance observed. This significant correlation highlights the potential of our method as a more comprehensive and efficient tool for evaluating protein representation learning.},
  keywords={Task analysis;Proteins;Protein engineering;Biological system modeling;Computational modeling;Predictive models;Biological information theory;Transferability;protein representation learning;optimal transport},
  doi={10.1109/JBHI.2024.3370680},
  ISSN={2168-2208},
  month={May},}@ARTICLE{10440197,
  author={Chen, Long and Li, Yuchen and Silamu, Wushour and Li, Qingquan and Ge, Shirong and Wang, Fei-Yue},
  journal={IEEE Transactions on Intelligent Vehicles}, 
  title={Smart Mining With Autonomous Driving in Industry 5.0: Architectures, Platforms, Operating Systems, Foundation Models, and Applications}, 
  year={2024},
  volume={9},
  number={3},
  pages={4383-4393},
  abstract={The increasing importance of mineral resources in contemporary society is becoming more prominent, playing an indispensable and crucial role in the global economy. These resources not only provide essential raw materials for the global economic system but also play an irreplaceable role in supporting the development of modern industry, technology, and infrastructure. With the rapid development of intelligent technologies such as Industry 5.0 and advanced Large Language Models (LLMs), the mining industry is facing unprecedented opportunities and challenges. The development of smart mines has become a crucial direction for industry progress. This article aims to explore the strategic requirements for the development of smart mines by combining advanced products or technologies such as Chat-GPT (one of the successful applications of LLMs), digital twins, and scenario engineering. We propose a comprehensive architecture consisting of three different levels, the mining industrial Internet of Things (IoT) platform, mining operating systems, and foundation models. The systems and models empower the mining equipment for transportation. The architecture delivers a comprehensive solution that aligns perfectly with the demands of Industry 5.0. The application and validation outcomes of this intelligent solution showcase a noteworthy enhancement in mining efficiency and a reduction in safety risks, thereby laying a sturdy groundwork for the advent of Mining 5.0.},
  keywords={Digital twins;Fifth Industrial Revolution;Ontologies;Autonomous driving;Mining industry;Network architecture;Large language models;Mining 5.0;smart mining;autonomous driving;industry 5.0;architectures;mining transportation trucks},
  doi={10.1109/TIV.2024.3365997},
  ISSN={2379-8904},
  month={March},}@ARTICLE{10423114,
  author={Zhao, Yingwen and Yang, Zhihao and Wang, Lei and Zhang, Yin and Lin, Hongfei and Wang, Jian},
  journal={IEEE Journal of Biomedical and Health Informatics}, 
  title={Predicting Protein Functions Based on Heterogeneous Graph Attention Technique}, 
  year={2024},
  volume={28},
  number={4},
  pages={2408-2415},
  abstract={In bioinformatics, protein function prediction stands as a fundamental area of research and plays a crucial role in addressing various biological challenges, such as the identification of potential targets for drug discovery and the elucidation of disease mechanisms. However, known functional annotation databases usually provide positive experimental annotations that proteins carry out a given function, and rarely record negative experimental annotations that proteins do not carry out a given function. Therefore, existing computational methods based on deep learning models focus on these positive annotations for prediction and ignore these scarce but informative negative annotations, leading to an underestimation of precision. To address this issue, we introduce a deep learning method that utilizes a heterogeneous graph attention technique. The method first constructs a heterogeneous graph that covers the protein-protein interaction network, ontology structure, and positive and negative annotation information. Then, it learns embedding representations of proteins and ontology terms by using the heterogeneous graph attention technique. Finally, it leverages these learned representations to reconstruct the positive protein-term associations and score unobserved functional annotations. It can enhance the predictive performance by incorporating these known limited negative annotations into the constructed heterogeneous graph. Experimental results on three species (i.e., Human, Mouse, and Arabidopsis) demonstrate that our method can achieve better performance in predicting new protein annotations than state-of-the-art methods.},
  keywords={Proteins;Protein engineering;Annotations;Feature extraction;Predictive models;Deep learning;Amino acids;Protein function prediction;positive and negative annotations;constructed heterogeneous graph;heterogeneous graph attention},
  doi={10.1109/JBHI.2024.3357834},
  ISSN={2168-2208},
  month={April},}@ARTICLE{10418085,
  author={Sewunetie, Walelign Tewabe and Kovács, László},
  journal={IEEE Access}, 
  title={Exploring Sentence Parsing: OpenAI API-Based and Hybrid Parser-Based Approaches}, 
  year={2024},
  volume={12},
  number={},
  pages={38801-38815},
  abstract={This study focuses on the fundamental process of parsing sentences to create semantic graphs from textual documents. It introduces novel techniques for parsing phrases within semantic graph-based induction, employing both ChatGPT-based and Hybrid parser-based approaches. Through a thorough analysis, the study evaluates the performance of these methods in generating semantic networks from text, particularly in capturing detailed event descriptions and relationships. Results indicate a slight advantage in accuracy for the Hybrid parser-based approach (87%) compared to ChatGPT (85%) in sentence parsing tasks. Furthermore, efficiency analysis reveals that ChatGPT’s response quality varies with prompt sizes, while the Hybrid parser-based method consistently maintains excellent response quality.},
  keywords={Semantics;Chatbots;Adaptation models;Knowledge graphs;Task analysis;Context modeling;Training;Natural language processing;Predictive models;Application of sentence parsing;adverb prediction;ChatGPT;hybrid parser;natural language processing;sentence parsing;semantic graph},
  doi={10.1109/ACCESS.2024.3360480},
  ISSN={2169-3536},
  month={},}@ARTICLE{10320368,
  author={Quevedo, Ernesto and Cerny, Tomas and Rodriguez, Alejandro and Rivas, Pablo and Yero, Jorge and Sooksatra, Korn and Zhakubayev, Alibek and Taibi, Davide},
  journal={IEEE Access}, 
  title={Legal Natural Language Processing From 2015 to 2022: A Comprehensive Systematic Mapping Study of Advances and Applications}, 
  year={2024},
  volume={12},
  number={},
  pages={145286-145317},
  abstract={The surge in legal text production has amplified the workload for legal professionals, making many tasks repetitive and time-consuming. Furthermore, the complexity and specialized language of legal documents pose challenges not just for those in the legal domain but also for the general public. This emphasizes the potential role and impact of Legal Natural Language Processing (Legal NLP). Although advancements have been made in this domain, particularly after 2015 with the advent of Deep Learning and Large Language Models (LLMs), a systematic exploration of this progress until 2022 is nonexistent. In this research, we perform a Systematic Mapping Study (SMS) to bridge this gap. We aim to provide a descriptive statistical analysis of the Legal NLP research between 2015 and 2022. Categorize and sub-categorize primary publications based on their research problems. Identify limitations and areas of improvement in current research. Using a robust search methodology across four reputable indexers, we filtered 536 papers down to 75 pivotal articles. Our findings reveal the diverse methods employed for tasks such as Multiclass Classification, Summarization, and Question Answering in the Legal NLP field. We also highlight resources, challenges, and gaps in current methodologies and emphasize the need for curated datasets, ontologies, and a focus on inherent difficulties like data accessibility. As the legal sector gradually embraces Natural Language Processing (NLP), understanding the capabilities and limitations of Legal NLP becomes vital for ensuring efficient and ethical application. The research offers insights for both Legal NLP researchers and the broader legal community, advocating for continued advancements in automation while also addressing ethical concerns.},
  keywords={Law;Natural language processing;Task analysis;Systematics;Information retrieval;Surveys;Search problems;Deep learning;Systematic-mapping-study;legal-NLP;deep learning},
  doi={10.1109/ACCESS.2023.3333946},
  ISSN={2169-3536},
  month={},}@ARTICLE{10313062,
  author={Zhang, Liyuan and Jiang, Yongquan and Yang, Yan},
  journal={IEEE Transactions on Knowledge and Data Engineering}, 
  title={GNNGO3D: Protein Function Prediction Based on 3D Structure and Functional Hierarchy Learning}, 
  year={2024},
  volume={36},
  number={8},
  pages={3867-3878},
  abstract={Protein sequences accumulate in large quantities, and the traditional method of annotating protein function by experiment has been unable to bridge the gap between annotated proteins and unannotated proteins. Machine learning-based protein function prediction is an effective approach to solve this problem. Most of the existing methods only use the protein sequence but ignore the three-dimensional structure which is closely related to the protein function. And the hierarchy of protein functions is not adequately considered. To solve this problem, we propose a graph neural network (GNNGO3D) that combines the three-dimensional structure and functional hierarchy learning. GNNGO3D simultaneously uses three kinds of information: protein sequence, tertiary structure, and hierarchical relationship of protein function to predict protein function. The novelty of GNNGO3D lies in that it integrates the learning of functional level information into the method of predicting protein function by using tertiary structure information, fully learning the relationship between protein functions, and helping to better predict protein function. Experimental results show that our method is superior to existing methods for predicting protein function based on sequence and structure.},
  keywords={Proteins;Feature extraction;Protein sequence;Three-dimensional displays;Task analysis;Ontologies;Convolutional neural networks;Graph neural networks;gene ontology;language model;machine learning;protein function prediction},
  doi={10.1109/TKDE.2023.3331005},
  ISSN={1558-2191},
  month={Aug},}@INPROCEEDINGS{10708094,
  author={Wang, Dan and Li, Xiaofeng and Gu, Bin and Cao, Yue and Liu, Yusheng},
  booktitle={2023 6th International Conference on Mechatronics, Robotics and Automation (ICMRA)(}, 
  title={An Architecture Modeling Framework for Distributed Automation Systems Using SysML and Semantic Web Technologies}, 
  year={2023},
  volume={},
  number={},
  pages={191-200},
  abstract={The rising interdisciplinarity and complexity of the Distributed Automation Systems (DASs) require the systems to be modeled in an unambiguous and high-level abstract way for cross-discipline/stage communication and interoperability in the Model-Driven Development (MDD) lifecycle. The concept of the System Architecture Model in systems engineering has been adopted for this challenge. To support the creation and analysis of this model, a modeling framework with a modeling methodology, modeling language, knowledge base, and related toolkit is established based on SysML and Semantic Web Technologies. A modeling methodology which is the core of the framework for modeling the architecture of DASs is formally defined with domain-specificity, comprehensiveness, discipline-neutrality, and platform-independency. Based on it, the SysML-DAS modeling language is extended from SysML, and the System Architecture Ontology is built with the help of the Knowledge Extraction Tool. This ontology works as the knowledge base not only to provide a unified and unambiguous view of the system but also to support the automated accomplishment of tasks in the MDD process. As a typical task, the semantic correctness and integrity of the system architecture model can be assessed by the Knowledge Analysis Tool in this framework.},
  keywords={Semantic Web;Analytical models;Automation;Mechatronics;Knowledge based systems;Semantics;Systems architecture;Ontologies;Service-oriented architecture;Model-driven development;distributed automation system;SysML;Semantic Web technologies;System Architecture Model},
  doi={10.1109/ICMRA59796.2023.10708094},
  ISSN={2996-380X},
  month={Nov},}@INPROCEEDINGS{10568296,
  author={Tona, Claudia and Juárez-Ramírez, Reyes and Jiménez, Samantha and Murillo-Muñoz, Fernanda},
  booktitle={2023 11th International Conference in Software Engineering Research and Innovation (CONISOFT)}, 
  title={Q-Story: An Ontology-Based on Quality of User Stories in Scrum. A Quantitative Assessment}, 
  year={2023},
  volume={},
  number={},
  pages={55-64},
  abstract={Q-Story ontology was created utilizing the Methontology approach and further represented through the Meta Object Facility (MOF) and Unified Modeling Language (UML). Because aspects such as their structure, level of granularity, and comprehensibility hold considerable signifi-cance in ensuring a favorable project execution. That is, the quality of user stories significantly impacts the outcome of a software project, influencing its success or failure. Therefore, we performed a quantitative evaluation using the OntoQA method, resulting in a relationship richness value of 0.95, an attribute richness of 4.00, and an inheritance richness of 1.26. The outcome of this work will contribute to developing an ontology that can effectively create user stories with quality. Furthermore, it will serve as a valuable guide for development teams, aiding them in the creation, analysis, and development processes of user stories.},
  keywords={Technological innovation;Unified modeling language;Ontologies;Software;Software engineering;Ontology;Quantitative Assessment;Quality Met-rics;Software Engineering;User Story;Ontology Quality Evaluation},
  doi={10.1109/CONISOFT58849.2023.00017},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10522716,
  author={Mateiu, Patricia and Groza, Adrian},
  booktitle={2023 25th International Symposium on Symbolic and Numeric Algorithms for Scientific Computing (SYNASC)}, 
  title={Ontology engineering with Large Language Models}, 
  year={2023},
  volume={},
  number={},
  pages={226-229},
  abstract={We tackle the task of enriching ontologies by automatically translating natural language (NL) into Description Logic (DL). Since Large Language Models (LLMs) are the best tools for translations, we fine-tuned a GPT-3 model to convert NL into OWL Functional Syntax. For fine-tuning, we designed pairs of sentences in NL and the corresponding translations. This training pairs cover various aspects from ontology engineering: instances, class subsumption, domain and range of relations, object properties relationships, disjoint classes, complements, or cardinality restrictions. The resulted axioms are used to enrich an ontology, in a human supervised manner. The developed tool is publicly provided as a Protégé plugin.},
  keywords={Training;Scientific computing;Description logic;OWL;Natural languages;Syntactics;Task analysis;ontology engineering;large language models;Protege plugin;fine-tuning},
  doi={10.1109/SYNASC61333.2023.00038},
  ISSN={2470-881X},
  month={Sep.},}@INPROCEEDINGS{10479303,
  author={Ferchichi, Olfa and Beltaifa, Raoudha and Labed Jilani, Lamia},
  booktitle={2023 20th ACS/IEEE International Conference on Computer Systems and Applications (AICCSA)}, 
  title={Artificial Intelligence Based SysML Block Diagram Extension and Evolution for Product Lines}, 
  year={2023},
  volume={},
  number={},
  pages={1-8},
  abstract={SysML is a standard language that permits to model systems of any type such as plane, ships and software intensive systems. Software Product Line large scale reuse approach has demonstrated its success. The industry provides benefits in term of cost savings and acceleration of time to maket. The available literature indicates that there have been efforts to enhance the capability of SysML in handling product families. However, these attempts are not yet fully systematic, and there remains a significant amount of work to be undertaken in this area. In this present paper, we deal with the SysML Block Diagram in order to investigate to what extent it permits variability representation and how it can evolve during the system evolution or when agility is needed. We want to capitalize on the knowledge necessary for block diagram extention and evolution and take advantage of knowledge from Product Line domain engineering and application engineering. So, we decide to use an ontology which is an articifial intelligence artifact. An ontology is a powerful mean to represent knowledge and reason about it. Here, we use the ontology to help decision making for Block diagram evolution as well.},
  keywords={Industries;Systematics;Description logic;Systems architecture;Ontologies;Software;Mobile handsets;SysML block diagram;Product Line Engineering;Variability;Evolution;Artificial Intelligence Artifact;Ontology},
  doi={10.1109/AICCSA59173.2023.10479303},
  ISSN={2161-5330},
  month={Dec},}@INPROCEEDINGS{10466986,
  author={Du, Zhihong and Xu, Duo and Huang, Danruo and Hu, Yuren and He, Keqing and Wang, Chong and Wang, Jian and Zhang, Hong-Yu and Mayer, Wolfgang and Duan, Yucong and Wang, Ying and Feng, Zaiwen},
  booktitle={2023 IEEE International Conference on High Performance Computing & Communications, Data Science & Systems, Smart City & Dependability in Sensor, Cloud & Big Data Systems & Application (HPCC/DSS/SmartCity/DependSys)}, 
  title={An Ontology-based Method for Heterogeneous Data Governance with MFI and MDR}, 
  year={2023},
  volume={},
  number={},
  pages={1106-1113},
  abstract={Currently, data governance and integration in the fields are hindered by semantic ambiguity and syntactic inconsistencies among different sub domain data and models, making it difficult to use these valuable data for further application and research jointly. Therefore, it is necessary to unify and integrate existing metadata and meta-models more effectively for information resource sharing and interoperability in the field. This paper proposes an ontology-based approach with a hybrid ISO/IEC 11179 (MDR) and ISO/IEC 19763 (MFI) framework for data governance and integration. This framework takes a Global Ontology Model (GOM) constructed for the global domain as a bridge and basis for integrating and aligning heterogeneous sub domains. It extends MDR by adding ontology registration items to implement the mapping between the GOM and multiple subdomains, thereby promoting the semantic sharing of metadata between subdomains. In addition, the MFI-12 and MFI-10 are used to solve the model interoperability between different subdomains. A detailed case study is provided to illustrate the concrete registration process and demonstrate the validity of our method.},
  keywords={Information resources;ISO Standards;Semantics;Standardization;Metadata;Ontologies;Syntactics;Ontology;MDR;MFI;Data Governance;Data Standardization},
  doi={10.1109/HPCC-DSS-SmartCity-DependSys60770.2023.00158},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10471711,
  author={Qin, Xiaodong and He, Yuxuan and Ma, Jie and Peng, Weiyuan and Zio, Enrico and Su, Huai},
  booktitle={2023 International Conference on Computer Science and Automation Technology (CSAT)}, 
  title={An Effective Knowledge Mining Method for Compressor Fault Text Data Based on Large Language Model}, 
  year={2023},
  volume={},
  number={},
  pages={44-48},
  abstract={The fault diagnosis method of compressors determines the reliability of the gas transmission pipeline station. Existing compressor fault diagnosis methods mostly relies on data-driven, which leads to a high application threshold from the mechanism. To address this issue, this paper introduces the knowledge graph into the compressor fault diagnosis for the first time and proposes a compressor fault text data knowledge mining method based on large language model. Firstly, the characteristics and principles of compressor faults are analyzed. Then, a text data knowledge mining model called CFRTE for compressors is constructed. Experimental results show that the Fl score of the CFRTE model can reach 0.98, meeting the requirements of compressor fault knowledge mining. Finally, combined with the results of knowledge mining and the graph database, a new system for the storage and indexing of the compressor fault knowledge graph is proposed. To further verify the role of the large language model in compressor fault knowledge mining, this paper conducts a comparative experiment of CFRTE models based on RNN encoder and BERT encoder. Experimental results show that compared with GRU, BiGRU, LSTM, and BiLSTM as the encoder layer, the Fl score of the CFRTE model with BERT as the encoder layer has increased by 26.78%, 6.18%, 21.89%, and 5.49% respectively. This work provides a systematic feasible scheme for introducing knowledge graphs into compressor fault diagnosis, which can be used for reference in the fault diagnosis of related equipment.},
  keywords={Fault diagnosis;Systematics;Computational modeling;Pipelines;Knowledge graphs;Ontologies;Compressors;compressor station;compressor;large language model;knowledge mining;knowledge graph},
  doi={10.1109/CSAT61646.2023.00024},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10471842,
  author={Do, Nhon V. and Mai, Thanh T.},
  booktitle={2023 RIVF International Conference on Computing and Communication Technologies (RIVF)}, 
  title={A Knowledge Representation Model for Designing the Knowledge Querying System in Programming Language C/C++}, 
  year={2023},
  volume={},
  number={},
  pages={366-371},
  abstract={Knowledge querying support systems need to assist users in querying the knowledge, relationships, or combination of multiple requirements. A proper knowledge representation model and the well-structured query language play important roles in the developing the knowledge querying systems. There are knowledge representation models and systems that support the querying or searching on the knowledge-based, but they have not supported well for various query requirements on the knowledge. Specially, the structured query sentences combine the multiple requirements. The paper will propose a knowledge representation model for the programming language C/C++ knowledge domain. Moreover, the paper will present structured query sentences that meet various requirements from users. Especially, the combination of multiple requirements based on the operators AND, OR, and NOT. Results of the research will be applied to design the knowledge querying system in the programming language C/C++ knowledge domain. The system is useful for first and second-year students in the field of technology information.},
  keywords={Computational modeling;Knowledge based systems;Knowledge representation;Communications technology;Database languages;ontology;structured query sentences;knowledge representation;knowledge querying system;programming language},
  doi={10.1109/RIVF60135.2023.10471842},
  ISSN={2473-0130},
  month={Dec},}@INPROCEEDINGS{10456842,
  author={Ollier, Guillaume and Adedjouma, Morayo and Gerasimou, Simos and Mraidha, Chokri},
  booktitle={2023 26th Euromicro Conference on Digital System Design (DSD)}, 
  title={An Ontological Approach for the Dependability Analysis of Automated Systems}, 
  year={2023},
  volume={},
  number={},
  pages={593-601},
  abstract={This paper presents the Ontology Language for the Dependability of Automated Systems (OLDAS), a modeling language based on Unified Modeling Language (UML) that aims to support dependability assessment for Automated Systems (ASs), i.e., systems intended to perform a function with minimal or no human intervention. OLDAS extends the Unified Foundational Ontology (UFO) and embeds validation rules to prevent constraint violations in ASs analysis. Specifically, the paper presents how OLDAS can support different activities during the design of ASs, from the definition of the Operational Design Domain to scenario-based analysis. OLDAS is available as a plugin of the open-source Papyrus for Robotics framework.},
  keywords={Analytical models;Runtime;Unified modeling language;Redundancy;Ontologies;Probabilistic logic;Hazards;Autonomous Systems;Automated Driving Systems;Artificial Intelligence;Safety Engineering;ODD;ML-based Systems},
  doi={10.1109/DSD60849.2023.00087},
  ISSN={2771-2508},
  month={Sep.},}@INPROCEEDINGS{10459922,
  author={Sazzed, Salim},
  booktitle={2023 International Conference on Machine Learning and Applications (ICMLA)}, 
  title={Comprehending Lexical and Affective Ontologies in the Demographically Diverse Spatial Social Media Discourse}, 
  year={2023},
  volume={},
  number={},
  pages={2247-2252},
  abstract={This study aims to comprehend linguistic and sociodemographic features, encompassing English language styles, conveyed sentiments, and lexical diversity within spatial online social media review data. To this end, we undertake a case study that scrutinizes reviews composed by two distinct and demographically diverse groups. Our analysis entails the extraction and examination of various statistical, grammatical, and sentimental features from these two groups. Subsequently, we leverage these features with machine learning (ML) classifiers to discern their potential in effectively differentiating between the groups. Our investigation unveils substantial disparities in certain linguistic attributes between the two groups. When integrated into ML classifiers, these attributes exhibit a marked efficacy in distinguishing the groups, yielding a macro F1 score of approximately 0.85. Furthermore, we conduct a comparative evaluation of these linguistic features with word n-gram-based lexical features in discerning demographically diverse review data. As expected, the n-gram lexical features, coupled with finetuned transformer-based models, show superior performance, attaining accuracies surpassing 95% and macro F1 scores exceeding 0.96. Our meticulous analysis and comprehensive evaluations substantiate the efficacy of linguistic and sentimental features in effectively discerning demographically diverse review data. The findings of this study provide valuable guidelines for future research endeavors concerning the analysis of demographic patterns in textual content across various social media platforms.},
  keywords={Reviews;Social networking (online);Machine learning;Linguistics;Ontologies;Feature extraction;Transformers;n/a},
  doi={10.1109/ICMLA58977.2023.00339},
  ISSN={1946-0759},
  month={Dec},}@INPROCEEDINGS{10453813,
  author={Albokae, Nazeer and AlKhtib, Bassel and Omar, Khaled},
  booktitle={2023 24th International Arab Conference on Information Technology (ACIT)}, 
  title={Hybrid Method for ICD Prediction Using Word Embedding and Natural Language Processing}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={The international classification of diseases is a standard in medical coding, and it is contains all information and description of diseases in heroical structure, and finding the International Classification of Diseases (ICD) code for diseases is important and essential thing in medical sector, the coding process takes a lot of time and money to find the correct and the exact code of the patient disease, researchers in artificial intelligence and in natural language processing and in machine learning make a huge efforts to build and develop automatic systems and algorithms for automatic ICD encoding, in this paper we propose a hybrid method for automatic ICD encoding from patient claims, the proposed method contains two main parts first for ICD chapter, ICD group classification, and the second one for find the most relevant ICD code based on patient claim diagnosis description, the first step was implemented by using natural language processing techniques, that it include stemming (Porter Stemmer was used for stemming), stop word removing, and the implementation of the second step was done by using PubMed BERT model for embedding for the ICD codes the embedding done based on the descriptions, and also the embedding done for the patient claim diagnosis description, we have tested the developed algorithm on medical dataset The results of our tests indicate that the proposed method is highly efficient, with a precision rate of 87%.},
  keywords={Codes;Prediction algorithms;Natural language processing;Encoding;Classification algorithms;Medical diagnostic imaging;Diseases;automatic ICD coding;PubMed BERT;ICD ontology},
  doi={10.1109/ACIT58888.2023.10453813},
  ISSN={2831-4948},
  month={Dec},}@INPROCEEDINGS{10450023,
  author={Pal, Suman and Gaur, Monica and Chaudhuri, Rupanjali and Benny Anto, Oshin and R, Kalaivanan and KV, Chetan and Pradhan, Pragnya},
  booktitle={2023 International Conference on Computational Intelligence, Networks and Security (ICCINS)}, 
  title={Recommendation System for Clinical Concept Mapping}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={In the past decade, the healthcare industry has shifted from paper-based document storage to Electronic Health Records (EHR), enabling quick, safe access to patient data. A key role is played by Semantic Interoperability (SI) which enables seamless data exchange between diverse care settings and clinical software. SI necessitates the linking of bio-medical data (aka. clinical events) with shared, standardized, and controlled vocabularies like SNOMED, LOINC, etc. However, the healthcare data across various client domains are filled with ambiguous textual representations of clinical events that may be present in the form of synonyms, acronyms, and abbreviations. To make interoperability work, Healthcare IT service providers must map related clinical events with the appropriate standard concepts, which requires additional time and resources. Natural Language Processing (NLP) plays a vital role in addressing the challenges of SI by learning effective representations of text words in the bio-medical domain thereby capturing their semantic meaning. Our method utilizes various pre-trained word embeddings trained on the bio-medical corpus like BioWordVec fastText and SapBERT that captures fine-grained semantic relationships. In this study, we have developed a recommendation system that provides recommendations of Top ‘N’ clinical events for mapping to a standard concept. The recommendation system showed good performance with a sensitivity of above 99 % using both the pre-trained word embedding. Further, this product can be integrated into the mapping workflow to help make accurate automated suggestions that minimize manual effort.},
  keywords={Sensitivity;Semantics;Medical services;Manuals;Natural language processing;Recommender systems;Interoperability;semantic interoperability;ontology;mapping;natural language processing;word embeddings;SapBERT},
  doi={10.1109/ICCINS58907.2023.10450023},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10449869,
  author={Omar, Mussa A.},
  booktitle={2023 IEEE 11th International Conference on Systems and Control (ICSC)}, 
  title={Measurement of ChatGPT Performance in Mapping Natural Language Speficaction into an Entity Relationship Diagram}, 
  year={2023},
  volume={},
  number={},
  pages={530-535},
  abstract={This paper explores the entity relationship diagram, a popular conceptual model used to depict entities, attributes, and relationships graphically. To help with this, we use ChatGPT, a sophisticated language model based on the GPT architecture, which can translate natural language text into an entity relationship diagram. The paper details the process of evaluating how well ChatGPT can perform compared to other state-of-the-art approaches for entity and relationship extraction. Our experimental findings demonstrate the strong ability of ChatGPT to translate natural language text into entity relationship diagrams, which has potential applications for knowledge graph building, data integration, and database schema design. Moreover, it can aid in automating the extraction and organization of information from unstructured text data, thereby simplifying the study of complex systems.},
  keywords={Adaptation models;Natural languages;Machine learning;Companies;Chatbots;Task analysis;Software engineering;entity relationship diagram;ChatGPT;natural language processing},
  doi={10.1109/ICSC58660.2023.10449869},
  ISSN={2379-0067},
  month={Dec},}@INPROCEEDINGS{10429736,
  author={Wang, Yanfeng and Zhang, Liangji and Peng, Chao and Wang, Junhui and Zhu, Yingying},
  booktitle={2023 9th International Conference on Big Data and Information Analytics (BigDIA)}, 
  title={Study on the Construction and Application of Combat Simulation Models Knowledge Graph}, 
  year={2023},
  volume={},
  number={},
  pages={442-449},
  abstract={Exploiting the knowledge graph effectively enables the integration, the management, the illustration, the retrieval, the mining, and the reasoning of the knowledge. As for the combat simulation experiments, the combat simulation knowledge graph shall enhance the efficiency and quality and reduce the complexity and cost for developing the models, as well as support the agile construction of the simulation applications. Thus, this paper focused on the requirements analysis, creation idea, construction methods and typical applications of the combat simulation models knowledge graph, which provides some guiding significance for using knowledge graphs to boost the combat simulations.},
  keywords={Deep learning;Analytical models;Costs;Semantic search;Knowledge graphs;Ontologies;Research and development;Combat simulation experiments;Combat simulation models;Knowledge graph construction;Knowledge graph application},
  doi={10.1109/BigDIA60676.2023.10429736},
  ISSN={2771-6902},
  month={Dec},}@INPROCEEDINGS{10422308,
  author={Tang, Yun and Da Costa, Antonio A. Bruto and Zhang, Xizhe and Patrick, Irvine and Khastgir, Siddartha and Jennings, Paul},
  booktitle={2023 IEEE 26th International Conference on Intelligent Transportation Systems (ITSC)}, 
  title={Domain Knowledge Distillation from Large Language Model: An Empirical Study in the Autonomous Driving Domain}, 
  year={2023},
  volume={},
  number={},
  pages={3893-3900},
  abstract={Engineering knowledge-based (or expert) systems require extensive manual effort and domain knowledge. As Large Language Models (LLMs) are trained using an enormous amount of cross-domain knowledge, it becomes possible to automate such engineering processes. This paper presents an empirical automation and semi-automation framework for domain knowledge distillation using prompt engineering and the LLM ChatGPT. We assess the framework empirically in the autonomous driving domain and present our key observations. In our implementation, we construct the domain knowledge ontology by “chatting” with ChatGPT. The key finding is that while fully automated domain ontology construction is possible, human supervision and early intervention typically improve efficiency and output quality as they lessen the effects of response randomness and the butterfly effect. We, therefore, also develop a web-based distillation assistant enabling supervision and flexible intervention at runtime. We hope our findings and tools could inspire future research toward revolutionizing the engineering of knowledge-based systems across application domains.},
  keywords={Knowledge engineering;Runtime;Manuals;Ontologies;Chatbots;Autonomous vehicles;Intelligent transportation systems;large language model;domain ontology distillation;autonomous driving},
  doi={10.1109/ITSC57777.2023.10422308},
  ISSN={2153-0017},
  month={Sep.},}@INPROCEEDINGS{10412761,
  author={Vijayakumar, Senthilkumar and Louis, Filious},
  booktitle={2023 IEEE International Conference on Knowledge Graph (ICKG)}, 
  title={Revolutionizing Staffing and Recruiting with Contextual Knowledge Graphs and QNLP: An End-to-End Quantum Training Paradigm}, 
  year={2023},
  volume={},
  number={},
  pages={45-51},
  abstract={The staffing and recruiting industry is continuously evolving, and recent advancements in Knowledge Graphs (KG) and Quantum Natural Language Processing (QNLP) has garnered considerable attention. The integration of these state-of-the-art technologies is fueled by the necessity to improve language models' capacity to comprehend context and make precise decisions. This research paper presents a novel approach to revolutionize the staffing and recruiting industry by integrating Knowledge Graph (KG) and Quantum Natural Language Processing (QNLP) to formulate an end-to-end QNLP training pipeline. The proposed solution consists of three interdependent subsystems that work in unison to construct contextual KG and train language models. The Information Extraction subsystem extracts semantic relationships and connections between entities from large and complex recruitment data to construct domain specific contextual KG. The QNLP model training pipeline subsystem, which is fed with domain-rich KG data, runs on Quantum Circuits, accelerates the training process by effectively incorporating high-dimensional features to the deep layers of language models. Finally, the Information Retrieval subsystem is based on semantic data taxonomy, retrieving contextual data from the KG for the trained language models to be implemented on various distinctive use cases in the staffing and recruiting industry. This solution provides a faster and more contextual approach to analyze recruitment data, empowering recruiters to concentrate on strategic tasks such as candidate engagement and client relationship building, ultimately leading to better business decision-making capabilities.},
  keywords={Training;Industries;Knowledge graphs;Natural language processing;Data models;Integrated circuit modeling;Context modeling;Artificial Intelligence (AI);Knowledge Graph (KG);Quantum Natural Language Processing (QNLP);Large Language Models (LLM);Contextual Information Extraction & Retrieval Systems},
  doi={10.1109/ICKG59574.2023.00011},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10407599,
  author={Tu, Ming-Yu and Ehm, Hans and Ismail, Abdelgafar and Ulrich, Philipp},
  booktitle={2023 Winter Simulation Conference (WSC)}, 
  title={Reusable Ontology Generation and Matching from Simulation Models}, 
  year={2023},
  volume={},
  number={},
  pages={2298-2309},
  abstract={As simulating semiconductor manufacturing grows complex, model reuse becomes appealing since it can reduce the time incurred in developing future models. Also, considering a large network of the semiconductor supply chain, knowledge sharing can enable the efficient development of simulation models in a collaborative organization. Such necessity of reusability and interoperability of simulation models motivates this paper. We will address these challenges through ontological modeling and linking of the simulation components. The first application is generating reusable ontologies from simulation models. Another discussed application is ontology matching for knowledge sharing between simulation components and a meta-model of the semiconductor supply chain. The proposed approach succeeds in automatically transforming simulation into reusable knowledge and identifying interconnection in a semiconductor manufacturing system.},
  keywords={Semiconductor device modeling;Knowledge engineering;Supply chains;Organizations;Ontologies;Semiconductor device manufacture;Interoperability},
  doi={10.1109/WSC60868.2023.10407599},
  ISSN={1558-4305},
  month={Dec},}@INPROCEEDINGS{10402219,
  author={Liem, Truc Nguyen and Cao Hoai, Sinh Nguyen and Quoc, Hung Nguyen and Van, Tien Nguyen and Pham Trung, Hieu and Quoc, Trung Nguyen and Hoang, Vinh Truong},
  booktitle={2023 IEEE 15th International Conference on Computational Intelligence and Communication Networks (CICN)}, 
  title={GradTOD - A Unified Dialogue State Tracking Model for Task-Oriented and Open Domain Dialogues}, 
  year={2023},
  volume={},
  number={},
  pages={711-719},
  abstract={The task-oriented dialogue domain system requires classifying intent and replying to a specific goal domain. In the sub-module of Task-oriented, the Dialogue State Tracker (DST) is well-known as a variety processing tracker. However, existing DST models often specialize in only task-oriented domains (ToD), leading to limited performance when applied to scenarios. In this paper, we propose GradTOD, a unified DST model that predicts both two task types, task-oriented dialogue (TOD) and open-domain dialogue (ODD). Our model leverages the recent advances in prompt engineering and conditional generation to perform zero-shot learning. After experiments, GradTOD has achieved an 88.6% and 82.5% score on Joint Goal Accuracy metrics when evaluating the Scheme-Guided Dialogue (SGD) and FusedChat test sets correspondingly, demonstrating the adaption ability for multi-domains.},
  keywords={Measurement;Adaptation models;Zero-shot learning;Computational modeling;Predictive models;Task analysis;Computational intelligence;component;formatting;style;styling;insert},
  doi={10.1109/CICN59264.2023.10402219},
  ISSN={2472-7555},
  month={Dec},}@INPROCEEDINGS{10386182,
  author={Kosten, Catherine and Cudré-Mauroux, Philippe and Stockinger, Kurt},
  booktitle={2023 IEEE International Conference on Big Data (BigData)}, 
  title={Spider4SPARQL: A Complex Benchmark for Evaluating Knowledge Graph Question Answering Systems}, 
  year={2023},
  volume={},
  number={},
  pages={5272-5281},
  abstract={With the recent spike in the number and availability of Large Language Models (LLMs), it has become increasingly important to provide large and realistic benchmarks for evaluating Knowledge Graph Question Answering (KGQA) systems. So far the majority of benchmarks rely on pattern-based SPARQL query generation approaches. The subsequent natural language (NL) question generation is conducted through crowdsourcing or other automated methods, such as rule-based paraphrasing or NL question templates. Although some of these datasets are of considerable size, their pitfall lies in their pattern-based generation approaches, which do not always generalize well to the vague and linguistically diverse questions asked by humans in real-world contexts. In this paper, we introduce Spider4SPARQL -a new SPARQL benchmark dataset featuring 9,693 previously existing manually generated NL questions and 4,721 unique, novel, and complex SPARQL queries of varying complexity. In addition to the NL/SPARQL pairs, we also provide their corresponding 166 knowledge graphs and ontologies, which cover 138 different domains. Our complex benchmark enables novel ways of evaluating the strengths and weaknesses of modern KGQA systems. We evaluate the system with state-of-the-art KGQA systems as well as LLMs, which achieve only up to 45% execution accuracy, demonstrating that Spider4SPARQL is a challenging benchmark for future research.},
  keywords={Measurement;Crowdsourcing;Natural languages;Knowledge graphs;Benchmark testing;Ontologies;Question answering (information retrieval);Benchmark for Question Answering over Knowledge Graphs;Language Models;Performance Evaluation},
  doi={10.1109/BigData59044.2023.10386182},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10386611,
  author={Liu, Jiehui and Zhan, Jieyu},
  booktitle={2023 IEEE International Conference on Big Data (BigData)}, 
  title={Constructing Knowledge Graph from Cyber Threat Intelligence Using Large Language Model}, 
  year={2023},
  volume={},
  number={},
  pages={516-521},
  abstract={Cyber Threat Intelligence (CTI) reports are valuable resources in various applications but manually extracting information from them is time-consuming. Existing approaches for automating extraction require specialized models trained on a substantial corpus. In this paper, we present an efficient methodology for constructing knowledge graphs from CTI by leveraging the Large Language Model (LLM), using ChatGPT for instance. Our approach automatically extracts attack-related entities and their relationships, organizing them within a CTI knowledge graph. We evaluate our approach on 13 CTIs, demonstrating better performance compared to AttacKG and REBEL while requiring less manual intervention and computational resources. This proves the feasibility and suitability of our method in low-resource scenarios, specifically within the domain of cyber threat intelligence.},
  keywords={Computational modeling;Knowledge graphs;Manuals;Ontologies;Information retrieval;Data models;Cognition;knowledge graph;threat intelligence;large language model;ChatGPT},
  doi={10.1109/BigData59044.2023.10386611},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10391425,
  author={Sharma, Hemendra Shanker and Sharma, Ashish},
  booktitle={2023 Second International Conference On Smart Technologies For Smart Nation (SmartTechCon)}, 
  title={Query Expansion Using Word Embedding, Ontology and Natural Language Processing}, 
  year={2023},
  volume={},
  number={},
  pages={410-414},
  abstract={Query Expansion (QE) is the art of reconstructing specific queries to expand validation presentation, especially in the data mining process in a requirement understanding environment. Expanding requirements is one of the techniques involved in finding information. In the search engine environment, the query extension includes the evaluation of the value of the construction and the extension of search queries to match new documents. In natural language processing (NLP), word embedding is a term used in textbook parsing, usually as a real-valued vector that encodes the meaning of adjacent words in the vector. It is assumed that the space will be analogous in meaning. Word embedding can be achieved using a set of language models and point literacy methods where vocabulary words or expressions are mapped to vectors of real numbers. For query expansion, one method used is natural language processing through word embedding. Other approaches are ontology, machine learning, and deep learning for automatic query expansion. This paper proposes a hybrid approach for query expansion by combining NLP and ontology through word embedding.},
  keywords={Deep learning;Vocabulary;Art;Ontologies;Search engines;Natural language processing;Data mining;Query expansion;word embedding;natural language processing;Data mining;information retrieval},
  doi={10.1109/SmartTechCon57526.2023.10391425},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10386048,
  author={Guo, Kuo and Li, Yifan and Chen, Hao and Shen, Hong-Bin and Yang, Yang},
  booktitle={2023 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)}, 
  title={Isoform Function Prediction Based on Heterogeneous Graph Attention Networks}, 
  year={2023},
  volume={},
  number={},
  pages={522-527},
  abstract={Isoforms refer to different mRNA molecules transcribed from the same gene, which can be translated into proteins with varying structures and functions. Predicting the functions of isoforms is an essential topic in bioinformatics as it can provide valuable insights into the intricate mechanisms of gene regulation and biological processes. Conventionally, gene function labels are standardized in Gene Ontology (GO) terms. However, traditional methods for predicting isoform function are largely limited by the absence of isoform-specific labels, sparse annotations, and the vast number of GO terms. To address these issues, we propose HANIso, a deep learning-based method for isoform function prediction. HANIso leverages a pretrained protein language model to extract features from protein sequences. It also integrates heterogeneous information, such as isoform sequence features, GO annotations, and isoform interaction data, using a Heterogeneous Graph Attention Network (HAN). This allows the model to learn the importance of different sources of information and their semantic relationships through the attention mechanism. Our method can predict function labels at both the gene level and isoform level. We conduct experiments on two species datasets, and the results demonstrate that our method outperforms existing methods on both AUROC and AUPRC. HANIso has the potential to overcome the limitations of traditional methods and provide a more accurate and comprehensive understanding of isoform function.},
  keywords={Proteins;Annotations;Biological system modeling;Semantics;Predictive models;Ontologies;Feature extraction;alternative splicing;isoform function prediction;protein language model;gene ontology;heterogeneous graph attention network},
  doi={10.1109/BIBM58861.2023.10386048},
  ISSN={2156-1133},
  month={Dec},}@INPROCEEDINGS{10385754,
  author={Wang, Xun and Qu, Peng and Meng, Xiangyu and Yang, Qing and Qiao, Lian and Zhang, Chaogang and Xie, Xianjin},
  booktitle={2023 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)}, 
  title={MulAxialGO: Multi-Modal Feature-Enhanced Deep Learning Model for Protein Function Prediction}, 
  year={2023},
  volume={},
  number={},
  pages={132-137},
  abstract={Predicting protein function from sequences through machine learning can improve the understanding of novel proteins and biological mechanisms. Existing methods mainly rely on one-dimensional convolution or natural language processing (NLP) techniques to extract features from sequences, but they suffer from limited predictive performance. To address this challenge, we propose MulAxialGO, a new method that leverages multi-modal feature fusion to improve prediction accuracy. MulAxialGO integrates the prior features of a large-scale pre-trained protein language model and the posterior features of dynamic embedding coding and sequence homology. In addition, MulAxialGO employs a comprehensive image feature encoder to extract features from sequences, providing a novel perspective for protein function prediction. MulAxialGO is tested on two benchmark datasets and achieves state-of-the-art results. On the 2016 dataset, MulAxialGO significantly outperforms DeepGOPlus, improving molecular function by 4.5 points, biological process by 2.4 points and cellular component by 1.6 points for the AUPR metric. Similarly, on the NetGO dataset, MulAxialGO outperforms the state-of-the-art NetGO2.0, improving Fmax by 1.1 points for biological process and 2.3 points for cellular component.},
  keywords={Proteins;Measurement;Deep learning;Protein engineering;Convolution;Biological processes;Predictive models;Protein function prediction;Sequence analysis;Bioinformatics;Attention mechanism;Deep learning},
  doi={10.1109/BIBM58861.2023.10385754},
  ISSN={2156-1133},
  month={Dec},}@INPROCEEDINGS{10385760,
  author={Shuai, Yunyan and Wang, Wenkang and Li, Yiming and Zeng, Min and Li, Min},
  booktitle={2023 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)}, 
  title={Protein function prediction using graph neural network with multi-type biological knowledge}, 
  year={2023},
  volume={},
  number={},
  pages={30-35},
  abstract={Proteins play crucial roles in diverse biological functions, and accurately annotating their functions is essential for understanding cellular mechanisms and developing therapies for complex diseases. Computational methods have been proposed as alternatives to laborious experimental approaches. However, existing network-based methods focus on the protein-protein interaction (PPI) networks, while the proteins without interactions are ignored. To address this limitation, we propose a novel deep learning framework for protein function prediction, named PFP-GMB, which incorporates multi-type biological knowledge to consider the proteins not present in the PPI networks. PFP-GMB leverages a pre-trained protein language model to extract sequence representations. Moreover, PPIs and orthology relationships are used to generate functional related features via graph neural networks and attention mechanisms. Finally, these multi-type features are fused for protein function prediction. Compared to eight state-of-the-art methods, PFP-GMB outperforms all of them in terms of F-max and AUPR. The ablation studies further confirm the relevance and significance of the multi-type biological knowledge incorporated into PFP-GMB for protein function prediction.},
  keywords={Proteins;Knowledge engineering;Protein engineering;Medical treatment;Feature extraction;Graph neural networks;Diseases;protein function;orthology network;PPI network;protein sequence;graph neural network},
  doi={10.1109/BIBM58861.2023.10385760},
  ISSN={2156-1133},
  month={Dec},}@INPROCEEDINGS{10385745,
  author={Fu, Chengcheng and Yao, Yanan and Wu, Jieyu and Zhao, Weizhong and He, Tingting and Jiang, Xingpeng},
  booktitle={2023 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)}, 
  title={Multimodal reasoning for nutrition and human health via knowledge graph embedding}, 
  year={2023},
  volume={},
  number={},
  pages={1901-1904},
  abstract={The established links between nutrition and human health are widely acknowledged. Dietary nutrients play a crucial role in regulating gut microbial communities, influencing various human diseases. With a growing number of related studies, there’s a need to systematically organize these associations for coherent knowledge reasoning. However, due to the diverse and extensive nature of the knowledge landscape, significant challenges persist. To address this, we propose an approach using multimodal data and knowledge embeddings for effective knowledge reasoning in nutrition and human health. We create a comprehensive knowledge graph, KG4NH, covering dietary nutrition, gut microbiota, and human diseases. To ensure efficient knowledge representation, we employ knowledge embedding techniques to develop modality-specific encoders for structure, category, and description. Additionally, we introduce a mul-timodal fusion method to capture shared information across modalities. Our experimental results demonstrate the superiority of our approach over other state-of-the-art methods.},
  keywords={Knowledge graphs;Ontologies;Feature extraction;Cognition;Bioinformatics;Diseases;Knowledge graph;Multimodal embedding;Knowledge reasoning;Nutrition;Human health},
  doi={10.1109/BIBM58861.2023.10385745},
  ISSN={2156-1133},
  month={Dec},}@INPROCEEDINGS{10386763,
  author={Jesus, Vitor and Patel, Asma and Kumar, Deepak},
  booktitle={2023 10th International Conference on Behavioural and Social Computing (BESC)}, 
  title={Feasibility of Structured, Machine-Readable Privacy Notices}, 
  year={2023},
  volume={},
  number={},
  pages={1-8},
  abstract={This paper offers a novel approach to the long standing problem of the interface of humans and online privacy notices. As literature and practice, and even art, for more than a decade have identified, privacy notices are nearly always ignored and "accepted" with little thought, mostly because it is not practical nor user-friendly to depend on reading a long text simply to access, e.g., a news website. Nevertheless, privacy notices are a central element, often mandated by law.We approach the problem by (partially) relieving the human from the task of inspecting such documents. Because they are documents written in natural language, often legal language, we assess the feasibility of representing privacy notices in a machine-readable format. Should this be feasible, automated processing of notices that still respect individual choices could be enabled. To this end, we manually inspected privacy notices under EU/UK's GDPR from common websites, and designed a JSON schema that captures their structure.},
  keywords={Privacy;Social computing;Art;Law;Natural languages;Task analysis},
  doi={10.1109/BESC59560.2023.10386763},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10391548,
  author={Taye, Mohammad Mustafa and Abulail, Rawan and Al-Oudat, Mohammad},
  booktitle={2023 7th International Symposium on Innovative Approaches in Smart Technologies (ISAS)}, 
  title={An Ontology Learning Framework for unstructured Arabic Text}, 
  year={2023},
  volume={},
  number={},
  pages={1-12},
  abstract={Ontologies are widely regarded as valuable sources of semantics and interoperability in all artificially intelligent systems. Due to the rapid growth of unstructured data on the web, studying how to automatically get ontology from unstructured text is important. Therefore, ontology learning (OL) is an important process in the business world. It involves finding and extracting concepts from the text so that these concepts can be used for things such as information retrieval. Unfortunately, learning ontology is not easy for some reasons, and there has not been much research on how to automatically learn a domain-specific ontology from data.Ontology Studying Arabic text is not as developed as learning Latin text. There is almost no automated support for using Arabic literary knowledge in semantically enabled systems. Machine learning (ML) has proven beneficial in numerous fields, including text mining. By employing neural language models such as AraBERT, it is possible to obtain word embeddings as distributed word representations from textual input using machine learning. However, the application of machine learning to aid the development of Arabic ontology is largely unexplored. This research examines the performance of AraBERT for ontology learning tasks in Arabic. Early performance results as an application of Arabic ontology learning are promising. In this research, we provide a method for populating an existing ontology with instance information extracted from the input natural language text. This prototype has achieved an information extraction accuracy of 91%.},
  keywords={Text mining;Semantics;Natural languages;Prototypes;Machine learning;Ontologies;Information retrieval;Arabic Ontology;Natural language Processing (NLP);Ontology;Ontology Learning (OL);Semantic Web;semantic representation},
  doi={10.1109/ISAS60782.2023.10391548},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10387602,
  author={Leventi-Peetz, Anastasia-Maria and Raber, Frederic and Rüll, Annika and Weber, Kai},
  booktitle={2023 Fifth International Conference on Transdisciplinary AI (TransAI)}, 
  title={Biotechnology Machine Learning Techniques for Natural Language Processing}, 
  year={2023},
  volume={},
  number={},
  pages={118-119},
  abstract={The possibility to transfer machine learning techniques from biotechnology to natural language processing models to increase training efficiency will be generally discussed. The motivation and reasoning behind the idea will be briefly outlined.},
  keywords={Training;Biotechnology;Biological system modeling;Machine learning;Natural language processing;Cognition;Sustainable development;Machine learning;natural language processing;gene ontology;protein function;model sustainability},
  doi={10.1109/TransAI60598.2023.00029},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10387600,
  author={Procko, Tyler Thomas and Elvira, Timothy and Ochoa, Omar},
  booktitle={2023 Fifth International Conference on Transdisciplinary AI (TransAI)}, 
  title={GPT-4: A Stochastic Parrot or Ontological Craftsman? Discovering Implicit Knowledge Structures in Large Language Models}, 
  year={2023},
  volume={},
  number={},
  pages={147-154},
  abstract={Ontologies are representational artifacts that purport to accurately portray the aspect of reality under the purview of the ontologists laboring upon them. Ontologies exist in a spectrum of formality, from lexical thesauri to knowledge graphs, to collections of statements of first-order logic. The recent proliferation of Large Language Models (LLMs) has brought to bear interactive “knowledge bases” with general awareness of most things. As ontologists create ontologies from their understanding of reality; and as LLMs, presumably, possess some “understanding” of reality, embedded in their vector matrices corresponding to lexical terms from massive quantities of learned texts, a question is posed: what form of ontology can an LLM create when prompted about some novel facet of reality, without explicitly asking it for an ontology? I.e., will an LLM categorize things into bins, or a subsumption hierarchy, or perhaps something else? LLMs, as they are understood, respond when prompted with the most likely response, because they are predictors of next tokens, i.e., they are stochastic parrots. In any case, it is posited that, if prompted without any explicit request for an ontology, an LLM can produce an ontology of novel form, effectively granting insight into the “understanding” an LLM has of the world, as all humans possess an understanding of the world that ontologies are based upon. This paper explores the use of the flagship LLM, GPT-4, in forming an ontology of a novel domain.},
  keywords={Visualization;Taxonomy;Natural languages;Supervised learning;OWL;Stochastic processes;Organizations;ontology;taxonomy;large language models;GPT},
  doi={10.1109/TransAI60598.2023.00043},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10387634,
  author={Procko, Tyler Thomas and Ochoa, Omar and Elvira, Timothy},
  booktitle={2023 Fifth International Conference on Transdisciplinary AI (TransAI)}, 
  title={Automatic Generation of BFO-Compliant Aristotelian Definitions in OWL Ontologies with GPT}, 
  year={2023},
  volume={},
  number={},
  pages={141-146},
  abstract={Ontologies are representational artifacts that purport to accurately describe some aspect of reality, including the entities and the relations that hold between them. In computer science, ontologies are software artifacts containing the schematic structure for machine-readable knowledge, typically formed as a graph of subject-predicate-object triples, constrained through Description Logics. These resources and their relations are self-defining, i.e., some resource may be defined by considering all its stated relations. Resources are often attended with natural language annotations, that humans may read and interpret, such as labels and definitions. Many long-standing ontologies have useless lexical definitions that define resources cyclically, e.g., a FOAF: Person is simply defined as “A person”. In Aristotelian terms, the definition of a thing should be reducible, by using terms simpler than itself, such that every definition can be unpacked up to the most general thing, which can only be defined by stating examples and use cases. This paper presents an innovative technique that leverages the Generative Pre-trained Transformer (GPT) large language model, GPT -4, for automatically generating Aristotelian definition annotations for OWL classes that engenders compliance with the Basic Formal Ontology standard.},
  keywords={Annotations;Description logic;OWL;Natural languages;Maintenance engineering;Transformers;Software;ontology;epistemology;Linked Data;BFO;GPT},
  doi={10.1109/TransAI60598.2023.00042},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10343171,
  author={Reynolds, Sarah and Pate, William C. and Ochoa, Omar},
  booktitle={2023 IEEE Frontiers in Education Conference (FIE)}, 
  title={An Ontology and Management System for Learning Outcomes and Student Mastery}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={Universities, faculty, and students use Learning Outcomes (LO) to create a shared understanding of the content provided in an individual course, known as Outcome-Based Education (OBE). One area of interest in OBE is evaluating whether the instructor and individual student performance have met the LO, which is integral to ensuring all invested parties are on the same page about class content and student performance. This work proposes a system for the management and evaluation of LO. Primarily, this work defines an ontology to support the management and evaluation of LO via Knowledge Graphs (KG). The KG links individual LO with individual assessment items. Two state-of-the-art Natural Language Processing models, BERT and ChatGPT, are evaluated in respect to their effectiveness in automating this linking. This data allows the educational professional to reflect on how well their assessments match the course's LO. The second part of this system harnesses student data to measure performance in relation to LO. In this Work-in-Progress paper, the system is prototyped and tested on the midterm results of a course in the Software Engineering curriculum. Student performance is documented in relation to each assessment question on the exams to measure student mastery of course material. Through this approach, courses can be evaluated and improved to deliver better quality education to all students. This includes improvements at the course level and possibilities for early intervention to ensure student success. This paper details the development of this system and through its implementation shows how it benefits engineering educators and their students.},
  keywords={Knowledge engineering;Taxonomy;Knowledge graphs;Ontologies;Market research;Chatbots;Software measurement;Learning outcomes;BERT;ontology;knowledge graph;assessment;Bloom's taxonomy},
  doi={10.1109/FIE58773.2023.10343171},
  ISSN={2377-634X},
  month={Oct},}@INPROCEEDINGS{10350744,
  author={Guizzardi, Giancarlo},
  booktitle={2023 ACM/IEEE International Conference on Model Driven Engineering Languages and Systems Companion (MODELS-C)}, 
  title={An Ontological View on Types}, 
  year={2023},
  volume={},
  number={},
  pages={634-634},
  abstract={Types are fundamental for modeling, being an essential construct in all major modeling languages. These include traditional conceptual modeling languages - such as Entity-Relationship models, UML class diagrams, or Object-Role-Modeling (ORM) specifications, and knowledge representation languages alike (e.g., the Web Ontology Language - OWL).},
  keywords={Unified modeling language;OWL;Knowledge representation;Model driven engineering;Ontological Foundations for Modeling;Types and Taxonomic Structures;Multi-Level Modeling},
  doi={10.1109/MODELS-C59198.2023.00103},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10350821,
  author={Henzgen, Arne and Strey, Lukas},
  booktitle={2023 ACM/IEEE International Conference on Model Driven Engineering Languages and Systems Companion (MODELS-C)}, 
  title={Model-Driven Approach for Automatic Model Information Aggregation in Structured Documents}, 
  year={2023},
  volume={},
  number={},
  pages={403-413},
  abstract={While models are widely used in software development projects originating from industry and academic research, their documentation can be a time-intensive process. This paper focuses on providing a Proof of Concept for the automatic aggregation of various model data in two different document types conforming to ISO/IEC/IEEE 42010 architecture descriptions or instructional information documents according to ISO/IEC/IEEE 26514. Therefore, this work leverages a model-driven mapping approach of model information to the required document structure, dynamic templating algorithms to transform model data into text and a prototypical implementation that executes the defined mapping and transformation logic in practice. The generation results show that most of the documentation standard requirements can be fulfilled automatically and therefore, reduce the manual processing effort while enhancing consistency.},
  keywords={Industries;ISO Standards;Heuristic algorithms;Documentation;Computer architecture;Transforms;Data models;Model-Driven Engineering;Documentation;BPMN;UML;GSN;Model-to-Document;Architecture Description;Instructional Information},
  doi={10.1109/MODELS-C59198.2023.00072},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10350471,
  author={Chen, Boqi and Yi, Fandi and Varró, Dániel},
  booktitle={2023 ACM/IEEE International Conference on Model Driven Engineering Languages and Systems Companion (MODELS-C)}, 
  title={Prompting or Fine-tuning? A Comparative Study of Large Language Models for Taxonomy Construction}, 
  year={2023},
  volume={},
  number={},
  pages={588-596},
  abstract={Taxonomies represent hierarchical relations between entities, frequently applied in various software modeling and natural language processing (NLP) activities. They are typically subject to a set of structural constraints restricting their content. However, manual taxonomy construction can be time-consuming, incomplete, and costly to maintain. Recent studies of large language models (LLMs) have demonstrated that appropriate user inputs (called prompting) can effectively guide LLMs, such as GPT-3, in diverse NLP tasks without explicit (re-)training. However, existing approaches for automated taxonomy construction typically involve fine-tuning a language model by adjusting model parameters. In this paper, we present a general framework for taxonomy construction that takes into account structural constraints. We subsequently conduct a systematic comparison between the prompting and fine-tuning approaches performed on a hypernym taxonomy and a novel computer science taxonomy dataset. Our result reveals the following: (1) Even without explicit training on the dataset, the prompting approach outperforms fine-tuning-based approaches. Moreover, the performance gap between prompting and fine-tuning widens when the training dataset is small. However, (2) taxonomies generated by the fine-tuning approach can be easily post-processed to satisfy all the constraints, whereas handling violations of the taxonomies produced by the prompting approach can be challenging. These evaluation findings provide guidance on selecting the appropriate method for taxonomy construction and highlight potential enhancements for both approaches.},
  keywords={Training;Computer science;Systematics;Computational modeling;Taxonomy;Ontologies;Software;taxonomy construction;domain-specific constraints;large language models;few-shot learning;fine-tuning},
  doi={10.1109/MODELS-C59198.2023.00097},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10350365,
  author={Ali, Syed Juned and Gavric, Aleksandar and Proper, Henderik and Bork, Dominik},
  booktitle={2023 ACM/IEEE International Conference on Model Driven Engineering Languages and Systems Companion (MODELS-C)}, 
  title={Encoding Conceptual Models for Machine Learning: A Systematic Review}, 
  year={2023},
  volume={},
  number={},
  pages={562-570},
  abstract={Conceptual models are essential in Software and Information Systems Engineering to meet many purposes since they explicitly represent the subject domains. Machine Learning (ML) approaches have recently been used in conceptual modeling to realize, among others, intelligent modeling assistance, model transformation, and metamodel classification. These works en-code models in various ways, making the encoded models suitable for applying ML algorithms. The encodings capture the models' structure and/or semantics, making this information available to the ML model during training. Therefore, the choice of the encoding for any ML-driven task is crucial for the ML model to learn the relevant contextual information. In this paper, we report findings from a systematic literature review which yields insights into the current research in machine learning for conceptual modeling (ML4CM). The review focuses on the various encodings used in existing ML4CM solutions and provides insights into i) which are the information sources, ii) how is the conceptual model's structure and/or semantics encoded, iii) why is the model encoded, i.e., for which conceptual modeling task and, iv) which ML algorithms are applied. The results aim to structure the state of the art in encoding conceptual models for ML.},
  keywords={Training;Analytical models;Systematics;Machine learning algorithms;Bibliographies;Semantics;Machine learning;Machine learning;Model-driven engineering;Model Encoding;Systematic Literature Review},
  doi={10.1109/MODELS-C59198.2023.00094},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10350790,
  author={Majumder, Mainak},
  booktitle={2023 ACM/IEEE International Conference on Model Driven Engineering Languages and Systems Companion (MODELS-C)}, 
  title={A Domain-Driven Model Generation Framework for Cyber-Physical Production Systems}, 
  year={2023},
  volume={},
  number={},
  pages={172-178},
  abstract={The growing influence of Information Technologies in the manufacturing domain has led to the fourth industrial revolution (Industry 4.0). Cyber-Physical Production System (CPPS) is one of the fundamental concepts of Industry 4.0 that aims to develop an intelligent manufacturing environment by leveraging concepts like the Internet of Things (IoT), cloud computing, virtualization, and Artificial Intelligence (AI). However, the challenges originating from the technological heterogeneity in the manufacturing domain remain primary obstacles towards realising a fully automated CPPS. Among them, semantic heterogeneity in manufacturing information is the most crucial which can be attributed to technology and vendor-specific information modelling mechanisms. A CPPS requires seamless machine-to-machine communication which could be hindered due to the non-interoperability among machine data on a semantic level. Therefore, the primary focus of this thesis work is to understand the semantic interoperability challenges of CPPS and propose solutions to address those challenges. The proposed solution revolves around the development of semantic domain models using the modelling philosophies of Domain-Driven Design (DDD).},
  keywords={Production systems;Machine-to-machine communications;Philosophical considerations;Semantics;Model driven engineering;Fourth Industrial Revolution;Internet of Things;CPPS;Domain-Driven Design (DDD);Information Model;Industry 4.0},
  doi={10.1109/MODELS-C59198.2023.00044},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10350785,
  author={Dhaouadi, Mouna and Oakes, Bentley James and Famelis, Michalis},
  booktitle={2023 ACM/IEEE International Conference on Model Driven Engineering Languages and Systems Companion (MODELS-C)}, 
  title={Towards Understanding and Analyzing Rationale in Commit Messages Using a Knowledge Graph Approach}, 
  year={2023},
  volume={},
  number={},
  pages={622-630},
  abstract={Extracting rationale information from commit messages allows developers to better understand a system and its past development. Here we present our ongoing work on the Kantara end-to-end rationale reconstruction pipeline to a) structure rationale information in an ontologically-based knowledge graph, b) extract and classify this information from commits, and c) produce analysis reports and visualizations for developers. We also present our work on creating a labelled dataset for our running example of the Out-of-Memory component of the Linux kernel. This dataset is used as ground truth for our evaluation of NLP classification techniques which show promising results, especially the multi-classification technique XGBoost.},
  keywords={Visualization;Analytical models;Linux;Pipelines;Knowledge graphs;Model driven engineering;Data mining;rationale structuring;rationale extraction;Natural Language Processing;Linux;ontology;dataset;openCAESAR},
  doi={10.1109/MODELS-C59198.2023.00101},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10350773,
  author={Lange, Arne and Atkinson, Colin},
  booktitle={2023 ACM/IEEE International Conference on Model Driven Engineering Languages and Systems Companion (MODELS-C)}, 
  title={Modeling in LML with DOCL: A Contribution to the MULTI Warehouse Challenge}, 
  year={2023},
  volume={},
  number={},
  pages={649-658},
  abstract={This paper responds to the “Warehouse” challenge that was posed to the community of multi-level modeling researchers for the MULTI 2023 workshop. Given the many flavors of multi-level modeling approaches, the purpose of this and other similar challenges defined by the MULTI workshop community is to clarify the trade-offs entailed by the design choices underpinning the different approaches. This challenge revolves around product copies, product specifications, and product type specifications and how to guarantee certain properties at the product instance level. After first providing an overview of our modeling approach, and summarising the requirements laid out in the challenge, we present our solution using the LML and DOCL languages. We then discuss how well the solution fulfills the requirements laid out in the challenge.},
  keywords={Conferences;Semantics;Syntactics;Model driven engineering;Complexity theory;Safety;Currencies;Multi-level modeling;LML;DOCL},
  doi={10.1109/MODELS-C59198.2023.00106},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10350799,
  author={Elaasar, Maged and Rouquette, Nicolas and Wagner, David and Oakes, Bentley James and Hamou-Lhadj, Abdelwahab and Hamdaqa, Mohammad},
  booktitle={2023 ACM/IEEE International Conference on Model Driven Engineering Languages and Systems Companion (MODELS-C)}, 
  title={openCAESAR: Balancing Agility and Rigor in Model-Based Systems Engineering}, 
  year={2023},
  volume={},
  number={},
  pages={221-230},
  abstract={Model-Based System Engineering (MBSE) employs models and formal languages to support development of complex (systems-of-) systems. NASA Jet Propulsion Laboratory (JPL) sees MBSE as a key approach to managing the complexity of system development. However, balancing agility and rigor in MBSE has been reported as a challenging task not yet addressed by modeling tools and frameworks. This is because existing MBSE approaches may enable agility but compromise rigor, or enhance rigor but impede agility. We discuss the challenges of balancing agility and rigor in MBSE across seven systems engineering architectural functions defined by the JPL Integrated Model-Centric Engineering (IMCE) initiative. We demonstrate how openCAESAR, an open-source MBSE methodology and framework created at JPL, can strike a balance between agility and rigor through a case study of the Kepler16b project and discussion of lessons learned from past projects.},
  keywords={NASA;Formal languages;Propulsion;Model driven engineering;Complexity theory;Modeling;Task analysis;Systems Engineering;Model-Based Systems Engineering;Ontology-based Modeling;OML;openCAESAR},
  doi={10.1109/MODELS-C59198.2023.00051},
  ISSN={},
  month={Oct},}@ARTICLE{10367969,
  author={Fatemi, Bahareh and Rabbi, Fazle and Opdahl, Andreas L.},
  journal={IEEE Access}, 
  title={Evaluating the Effectiveness of GPT Large Language Model for News Classification in the IPTC News Ontology}, 
  year={2023},
  volume={11},
  number={},
  pages={145386-145394},
  abstract={News classification plays a vital role in newsrooms, as it involves the time-consuming task of categorizing news articles and requires domain knowledge. Effective news classification is essential for categorizing and organizing a constant flow of information, serving as the foundation for subsequent tasks, such as news aggregation, monitoring, filtering, and organization. The automation of this process can significantly benefit newsrooms by saving time and resources. In this study, we explore the potential of the GPT large language model in a zero-shot setting for multi-class classification of news articles within the widely accepted International Press Telecommunications Council (IPTC) news ontology. The IPTC news ontology provides a structured framework for categorizing news, facilitating the efficient organization and retrieval of news content. By investigating the effectiveness of the GPT language model in this classification task, we aimed to understand its capabilities and potential applications in the news domain. This study was conducted as part of our ongoing research in the field of automated journalism.},
  keywords={Task analysis;Annotations;Ontologies;Adaptation models;Tag clouds;Support vector machines;Sports;IPTC media topics;journalism;large language models;news classification},
  doi={10.1109/ACCESS.2023.3345414},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10348639,
  author={Palagin, Oleksandr and Kaverinsky, Vladislav and Petrenko, Mykola and Malakhov, Kyrylo},
  booktitle={2023 IEEE 12th International Conference on Intelligent Data Acquisition and Advanced Computing Systems: Technology and Applications (IDAACS)}, 
  title={Digital Health Systems: Ontology-Based Universal Dialog Service for Hybrid E-Rehabilitation Activities Support}, 
  year={2023},
  volume={1},
  number={},
  pages={84-89},
  abstract={The medical rehabilitation system in Ukraine encountered a set of crucial challenges that demanded immediate attention and action. The primary objective revolves around rehabilitating patients with Combat stress reaction. Ukraine possesses a network of medical and preventive institutions that cater to the psycho-physiological rehabilitation needs of military personnel. These institutions employ contemporary rehabilitation technologies. Nonetheless, not all individuals have access to long-term rehabilitation within these centers. Hence, the integration of telerehabilitation technology becomes crucial for patients dealing with post-traumatic stress disorder and related conditions. This integration, combined with objective monitoring of the functional state, holds significant importance. Remote patient-centered rehabilitation emerges as one of the most effective approaches within the realm of medical rehabilitation assistance. Moreover, there is a need for efficient methods that support the “Physical therapist - Patient - Multidisciplinary team” system in the field of rehabilitation. Hence, in this paper, we not only explore conventional rehabilitation techniques but also present and elucidate the following advancements: a revised and comprehensive understanding of the hybrid e-rehabilitation concept and its underlying principles, an enhanced formalization notion of the Smart-system for remote support in hybrid e-rehabilitation services and activities, and the conceptual framework and software implementation of the ontology-based universal dialog service within the Smart-system.},
  keywords={Data acquisition;Ontologies;Software;Electronic healthcare;Personnel;IEEE activities;Stress;Ontology engineering;hybrid e-rehabilitation;Telerehabilitation;Transdisciplinary research;Computational linguistics;Universal dialog service},
  doi={10.1109/IDAACS58523.2023.10348639},
  ISSN={2770-4254},
  month={Sep.},}@INPROCEEDINGS{10357717,
  author={Sevastjanova, Rita and Vogelbacher, Simon and Spitz, Andreas and Keim, Daniel and El-Assady, Mennatallah},
  booktitle={2023 IEEE Visualization in Data Science (VDS)}, 
  title={Visual Comparison of Text Sequences Generated by Large Language Models}, 
  year={2023},
  volume={},
  number={},
  pages={11-20},
  abstract={Causal language models have emerged as the leading technology for automating text generation tasks. Although these models tend to produce outputs that resemble human writing, they still suffer from quality issues (e.g., social biases). Researchers typically use automatic analysis methods to evaluate the model limitations, such as statistics on stereotypical words. Since different types of issues are embedded in the model parameters, the development of automated methods that capture all relevant aspects remains a challenge. To tackle this challenge, we propose a visual analytics approach that supports the exploratory analysis of text sequences generated by causal language models. Our approach enables users to specify starting prompts and effectively groups the resulting text sequences. To this end, we leverage a unified, ontology-driven embedding space, serving as a shared foundation for the thematic concepts present in the generated text sequences. Visual summaries provide insights into various levels of granularity within the generated data. Among others, we propose a novel comparison visualization that slices the embedding space and represents the differences between two prompt outputs in a radial layout. We demonstrate the effectiveness of our approach through case studies, showcasing its potential to reveal model biases and other quality issues.},
  keywords={Analytical models;Visual analytics;Semantics;Layout;Data visualization;Writing;Linguistics;Causal Language Models;Text Generation;Prompt Output Comparison},
  doi={10.1109/VDS60365.2023.00007},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10339738,
  author={Stoyanov, Stanimir and Kumurdjieva, Milena and Tabakova-Komsalova, Veneta and Doukovska, Lyubka},
  booktitle={2023 International Conference on Big Data, Knowledge and Control Systems Engineering (BdKCSE)}, 
  title={Using LLMs in Cyber-Physical Systems for Agriculture - ZEMELA}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={This paper presents the idea of developing an advisory service using the capabilities of generative artificial intelligence and in particular of Large Language Model. The service will assess the risks for farmers when preparing projects under different programs, taking into account the Bulgarian legislation related to agriculture, as well as the requirements of the relevant program. The results of a feasibility analysis are summarized in the article. Furthermore, two architectural approaches are discussed. The service will be integrated in the platform for smart agriculture named ZEMELA. A brief overview of this platform is also given in the article.},
  keywords={Smart agriculture;Knowledge engineering;Prototypes;Legislation;Cyber-physical systems;Big Data;Control systems;generative artificial intelligence;large language model;advisory service;smart agriculture},
  doi={10.1109/BdKCSE59280.2023.10339738},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10339730,
  author={Samardzhiev, Georgi and Nisheva-Pavlova, Maria},
  booktitle={2023 International Conference on Big Data, Knowledge and Control Systems Engineering (BdKCSE)}, 
  title={Application of Machine Learning and Natural Language Technologies in Building Semantic Search Systems: Case Study of a Virtual Legal Assistant}, 
  year={2023},
  volume={},
  number={},
  pages={1-7},
  abstract={Semantic search is a type of advanced information search that is based on the searcher's intent as well as on the meaning of the searched terms and phrases in the relevant context, rather than relying only on their individual dictionary meanings. Classical approaches to the design and implementation of semantic search systems are primarily associated with the appropriate use of different types of ontologies or knowledge graphs, but recently these approaches are increasingly enriched or replaced by the utilization of modern language technologies and machine learning techniques. The paper discusses a methodology for application of specific machine learning methods and language technologies and information retrieval techniques in the development of a type of semantic search systems and presents its application in the creation of a virtual legal assistant.},
  keywords={Semantic search;Law;Heuristic algorithms;Natural languages;Neural networks;Machine learning;User interfaces;semantic search;language technology;machine learning;information retrieval;virtual assistant},
  doi={10.1109/BdKCSE59280.2023.10339730},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10340611,
  author={Labbé, Thomas and Castel, Pierre and Sanner, Jean-Michel and Saleh, Majd},
  booktitle={2023 45th Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC)}, 
  title={ChatGPT for phenotypes extraction: one model to rule them all?}, 
  year={2023},
  volume={},
  number={},
  pages={1-4},
  abstract={Information Extraction (IE) is a core task in Natural Language Processing (NLP) where the objective is to identify factual knowledge in textual documents (often unstructured), and feed downstream use cases with the resulting output. In genomic medicine for instance, being able to extract the most precise list of phenotypes associated to a patient allows to improve genetic disease diagnostic, which represents a vital step in the modern deep phenotyping approach. As most of the phenotypic information lies in clinical reports, the challenge is to build an IE pipeline to automatically recognize phenotype concepts from free-text notes. A new machine learning paradigm around large language models (LLM) has given rise of an increasing number of academic works on this topic lately, where sophisticated combinations of different technics have been employed to improve the phenotypes extraction accuracy. Even more recently released, the ChatGPT1 application nevertheless raises the question of the relevance of these approches compared to this new generic one based on an instruction-oriented LLM. In this paper, we propose a rigorous evaluation of ChatGPT and the current state-of-the-art solutions on this specific task, and discuss the possible impacts and the technical evolutions to consider in the medical domain.Clinical relevance— Deep phenotyping on electronic health records has proven its ability to improve genetic diagnosis by clinical exomes [10]. Thus, comparing state-of-the-art solutions in order to derive insights and improving research paths is essential.},
  keywords={Temperature distribution;Pipelines;Statistical distributions;Machine learning;Ontologies;Chatbots;Information retrieval},
  doi={10.1109/EMBC40787.2023.10340611},
  ISSN={2694-0604},
  month={July},}@INPROCEEDINGS{10327850,
  author={Tothfalusi, Tamas and Varga, Eszter and Csiszar, Zoltan and Varga, Pal},
  booktitle={2023 19th International Conference on Network and Service Management (CNSM)}, 
  title={ML-Based Translation Methods for Protocols and Data Formats}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={In order to exchange information between systems, the information must get encoded into a predefined data format, and it must be transferred in a protocol that the communicating parties have agreed upon. This works well if all parties follow the same protocol standard and use the same data description schemes. If systems use different data formats or protocols, then some sort of translation is required. Protocol and data format translation has been attempted previously through rule-based approaches, ontologies, and also by using machine learning (ML) techniques. Due to the current advances related to AI/ML methods, tools, and infrastructure, the accuracy and feasibility of “translation” with ML-approaches improved significantly. This paper introduces a generic approach and methodology for translating data formats and protocols with ML-based methods and presents our initial results through JSON-XML and JSON-SenML translation.},
  keywords={Protocols;Machine learning;Ontologies;Standards;protocol translation;machine learning;neural machine translation;natural language processing;LLM},
  doi={10.23919/CNSM59352.2023.10327850},
  ISSN={2165-963X},
  month={Oct},}@ARTICLE{10328733,
  author={Wang, Songsong and Xu, Ouguan},
  journal={IEEE Access}, 
  title={Semantic Information Modeling and Implementation Method for Water Conservancy Equipment}, 
  year={2023},
  volume={11},
  number={},
  pages={133879-133890},
  abstract={Water conservancy equipment (WCE) has a large amount of information, structural heterogeneity and complex relationship leads to the difficulty of semantic interoperability in smart water conservancy. To overcome this issue, we propose the WCE information interaction dimension theory, modeling process and instancing method. First, we analyze the smart water conservancy ontology and information factor, and propose semantic information interaction dimension structure of water conservancy Ontology. Second, we construct the network information model structure of water conservancy, through the relationship degree, a tree model which can realize semantic expression and interoperability is formed through the dimensionality reduction of the model. Third, the component attribute set hierarchical relationship architecture water conservancy information model is established, which use XML language to describe this model. Moreover, the three types of instancing methods are proposed. Through OPC unified architecture (OPC UA) technology, water conservancy information model can implement semantic interoperability. The experimental show that the proposed method of semantic information modeling and semantic interoperability of WCE is feasible, and obvious advantages of complete semantic interoperability than in the model architecture, semantic structure and technical implementation.},
  keywords={Water conservation;Ontologies;Optical wavelength conversion;Semantics;Data models;Interoperability;Water resources;Information model;semantics;smart water conservancy;water conservancy equipment;OPC UA},
  doi={10.1109/ACCESS.2023.3336817},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10313152,
  author={Ermakov, Ivan and Lanin, Viacheslav and Lyadova, Lyudmila and Proskuryakov, Kirill},
  booktitle={2023 IEEE 17th International Conference on Application of Information and Communication Technologies (AICT)}, 
  title={Approach to the Development of Ontology-Driven Language Toolkits Based on Metamodeling}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={The information systems are to be conforming to the requirements defined by domain experts. These requirements are formalized as models created with modeling tools. Applying these tools is complicated for domain experts. Domain specific modeling (DSM) with domain specific languages (DSL) reduces the semantic gap. However, the system development complication shifts to the creation of languages and tools for transforming models and code generation. An approach to automating DSL creation and facilitating code generation based on using multifaceted ontology is proposed. The generalized description of the multifaceted ontology is given. Tools of automating generation of new DSL metamodels based on mapping the corresponding domain ontology onto the metamodels of the selected base languages are described. Metamodels of the visual languages, grammars of the target text languages and transformation rules are also included into the ontology. The proposed approach is implemented as a research prototype of the language toolkits. Examples of metamodels and rules described in the ontology, as well as the results of their application are shown. The results of experiments confirmed practical significance of the approach to the ontology-driven language toolkits development.},
  keywords={Visualization;Codes;Prototypes;Metamodeling;Ontologies;Grammar;DSL;domain-specific modeling;domain-specific languages;metamodeling;multifaceted ontology;metamodel generation;model transformation rules},
  doi={10.1109/AICT59525.2023.10313152},
  ISSN={2472-8586},
  month={Oct},}@INPROCEEDINGS{10309534,
  author={Nanwani, Laksh and Agarwal, Anmol and Jain, Kanishk and Prabhakar, Raghav and Monis, Aaron and Mathur, Aditya and Jatavallabhula, Krishna Murthy and Abdul Hafez, A. H. and Gandhi, Vineet and Krishna, K. Madhava},
  booktitle={2023 32nd IEEE International Conference on Robot and Human Interactive Communication (RO-MAN)}, 
  title={Instance-Level Semantic Maps for Vision Language Navigation}, 
  year={2023},
  volume={},
  number={},
  pages={507-512},
  abstract={Humans have a natural ability to perform semantic associations with the surrounding objects in the environment. This allows them to create a mental map of the environment, allowing them to navigate on-demand when given linguistic instructions. A natural goal in Vision Language Navigation (VLN) research is to impart autonomous agents with similar capabilities. Recent works take a step towards this goal by creating a semantic spatial map representation of the environment without any labeled data. However, their representations are limited for practical applicability as they do not distinguish between different instances of the same object. In this work, we address this limitation by integrating instance-level information into spatial map representation using a community detection algorithm and utilizing word ontology learned by large language models (LLMs) to perform open-set semantic associations in the mapping representation. The resulting map representation improves the navigation performance by two-fold (233%) on realistic language commands with instance-specific descriptions compared to the baseline. We validate the practicality and effectiveness of our approach through extensive qualitative and quantitative experiments.},
  keywords={Measurement;Visualization;Three-dimensional displays;Navigation;Semantics;Linguistics;Ontologies},
  doi={10.1109/RO-MAN57019.2023.10309534},
  ISSN={1944-9437},
  month={Aug},}@INPROCEEDINGS{10309510,
  author={Wilcock, Graham and Jokinen, Kristiina},
  booktitle={2023 32nd IEEE International Conference on Robot and Human Interactive Communication (RO-MAN)}, 
  title={To Err Is Robotic; to Earn Trust, Divine: Comparing ChatGPT and Knowledge Graphs for HRI}, 
  year={2023},
  volume={},
  number={},
  pages={1396-1401},
  abstract={The paper discusses two current approaches to conversational AI, using large language models and knowledge graphs, and compares types of errors that occur in human-robot interactions based on these approaches. It provides example dialogues and describes solutions to several error types including false implications, ontological errors, theory of mind errors, and handling of speech recognition errors. The paper addresses issues of particular concern for earning user trust.},
  keywords={Visualization;Terminology;Semantics;Human-robot interaction;Knowledge graphs;Oral communication;Speech recognition},
  doi={10.1109/RO-MAN57019.2023.10309510},
  ISSN={1944-9437},
  month={Aug},}@INPROCEEDINGS{10298592,
  author={Li, Linyu and Xu, Sihan and Liu, Yang and Gao, Ya and Cai, Xiangrui and Wu, Jiarun and Song, Wenli and Liu, Zheli},
  booktitle={2023 38th IEEE/ACM International Conference on Automated Software Engineering (ASE)}, 
  title={LiSum: Open Source Software License Summarization with Multi-Task Learning}, 
  year={2023},
  volume={},
  number={},
  pages={787-799},
  abstract={Open source software (OSS) licenses regulate the conditions under which users can reuse, modify, and distribute the software legally. However, there exist various OSS licenses in the community, written in a formal language, which are typically long and complicated to understand. In this paper, we conducted a 661-participants online survey to investigate the perspectives and practices of developers towards OSS licenses. The user study revealed an indeed need for an automated tool to facilitate license understanding. Motivated by the user study and the fast growth of licenses in the community, we propose the first study towards automated license summarization. Specifically, we released the first high quality text summarization dataset and designed two tasks, i.e., license text summarization (LTS), aiming at generating a relatively short summary for an arbitrary license, and license term classification (LTC), focusing on the attitude inference towards a predefined set of key license terms (e.g., Distribute). Aiming at the two tasks, we present LiSum, a multi-task learning method to help developers overcome the obstacles of understanding OSS licenses. Comprehensive experiments demonstrated that the proposed jointly training objective boosted the performance on both tasks, surpassing state-of-the-art baselines with gains of at least 5 points w.r.t. F1 scores of four summarization metrics and achieving 95.13% micro average F1 score for classification simultaneously. We released all the datasets, the replication package, and the questionnaires for the community.},
  keywords={Training;Measurement;Learning systems;Surveys;Formal languages;Licenses;Multitasking;Open Source Software Licenses;Multi-Task Learning;License comprehension},
  doi={10.1109/ASE56229.2023.00150},
  ISSN={2643-1572},
  month={Sep.},}@INPROCEEDINGS{10298429,
  author={Phokela, Kanchanjot Kaur and Sikand, Samarth and Singi, Kapil and Dey, Kuntal and Sharma, Vibhu Saujanya and Kaulgud, Vikrant},
  booktitle={2023 38th IEEE/ACM International Conference on Automated Software Engineering (ASE)}, 
  title={Smart Prompt Advisor: Multi-Objective Prompt Framework for Consistency and Best Practices}, 
  year={2023},
  volume={},
  number={},
  pages={1846-1848},
  abstract={Recent breakthroughs in Large Language Models (LLM), comprised of billions of parameters, have achieved the ability to unveil exceptional insight into a wide range of Natural Language Processing (NLP) tasks. The onus of the performance of these models lies in the sophistication and completeness of the input prompt. Minimizing the enhancement cycles of prompt with improvised keywords becomes critically important as it directly affects the time to market and cost of the developing solution. However, this process inevitably has a trade-off between the learning curve/proficiency of the user and completeness of the prompt, as generating such a solutions is an incremental process. In this paper, we have designed a novel solution and implemented it in the form of a plugin for Visual Studio Code IDE, which can optimize this trade-off, by learning the underlying prompt intent to enhance with keywords. This will tend to align with developers' collection of semantics while developing a secure code, ensuring parameter and local variable names, return expressions, simple pre and post-conditions. and basic control and data flow are met.},
  keywords={Visualization;Codes;Costs;Semantics;Time to market;Natural language processing;Task analysis;Prompt Engineering;Artificial Intelligence;Deep Learning;LLM;Ontology},
  doi={10.1109/ASE56229.2023.00019},
  ISSN={2643-1572},
  month={Sep.},}@INPROCEEDINGS{10296153,
  author={Elkodssi, Iman and Sbai, Hanae},
  booktitle={2023 International Conference on Digital Age & Technological Advances for Sustainable Development (ICDATA)}, 
  title={Toward Semantic Framework for Internet of Things-Aware Business Process Discovery}, 
  year={2023},
  volume={},
  number={},
  pages={12-16},
  abstract={The Internet of Things (IoT) is often considered a disruptive technology [1]. By using smart devices, it has the potential to change everyone's daily life. With large sets of advanced sensors and actuators, it can create opportunities for commercial organizations to establish new business models. A fundamental barrier to automatic business process sensing is the lack of modeling concepts that explicitly express Internet elements as components of a business process model. Thus, there is a clear need to model these processes associated with IoT elements in a formal and unambiguous manner. However, in the context of business processes, there is a lack of formalized and explicit descriptions of IoT elements, which hinders their effective modeling and management. This article proposes a semantic formalization of the business process management perspective in an IoT environment by proposing Extended BPMNO for IoT and Domain Ontology. It uses standard semantic technologies to give a semantic representation that allows us to describe concepts relating to the IoT and the elements of an executable business process described in BPMN.},
  keywords={Annotations;Semantics;Ontologies;Data models;Business process management;Internet of Things;Sustainable development;Business Process Management Notation (BPMN);IoT element;The IoT-aware BP;Ontology},
  doi={10.1109/ICDATA58816.2023.00012},
  ISSN={},
  month={May},}@INPROCEEDINGS{10284477,
  author={Ayad, Sarah},
  booktitle={2023 9th International Conference on Control, Decision and Information Technologies (CoDIT)}, 
  title={Towards a Meta-Modeling Approach for Business Process Models Improvement Based on Ontological Analysis}, 
  year={2023},
  volume={},
  number={},
  pages={1021-1026},
  abstract={Business process modeling enable smoother and more efficient decision making in the organizations as it achieve consistency and standardization of their operations, facilitate communication and collaboration between different stakeholders. Therefore, it is important to be able to model real world aspects. To this end, we have carried out a thorough review of the relevant literature which focuses on real-world aspects that Business process modeling languages BPMLs are not able to model. These aspects are based on ontological analysis and characterization of process modeling constructs. Our research aims to propose an approach for business process model modeling improvement by defining Object Constraint Language OCL rules written at the meta-model level making them independent from specific notations. We exploited IS domain knowledge, defined a meta-model, and added semantics to the meta-model by the mean of OCL constraints. As formalism we use the (OCL) with Ecore from the Eclipse Modeling Framework (EMF).},
  keywords={Analytical models;Process modeling;Semantics;Standards organizations;Metamodeling;Transforms;Standardization},
  doi={10.1109/CoDIT58514.2023.10284477},
  ISSN={2576-3555},
  month={July},}

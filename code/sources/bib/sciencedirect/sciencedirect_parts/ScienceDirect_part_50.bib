@article{WANG2018167,
title = {Rethinking foundations of “Rethinking foundations of language from a multidisciplinary perspective” by T. Gong et al.},
journal = {Physics of Life Reviews},
volume = {26-27},
pages = {167-172},
year = {2018},
issn = {1571-0645},
doi = {https://doi.org/10.1016/j.plrev.2018.07.004},
url = {https://www.sciencedirect.com/science/article/pii/S1571064518300873},
author = {Qiang Wang}
}
@incollection{SHARP2020117,
title = {Subjectivity},
editor = {Audrey Kobayashi},
booktitle = {International Encyclopedia of Human Geography (Second Edition)},
publisher = {Elsevier},
edition = {Second Edition},
address = {Oxford},
pages = {117-120},
year = {2020},
isbn = {978-0-08-102296-2},
doi = {https://doi.org/10.1016/B978-0-08-102295-5.10869-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780081022955108698},
author = {Joanne Sharp},
keywords = {Agency, Body, Decolonial, Discourse, Epistemology, European enlightenment, Hermeneutics, Methodology, Objectivity, Performance, Situated knowledge, Structure, Subaltern, Subject},
abstract = {Subjectivity is the claim that perception emerges from a subject's point of view. Subjectivity is usually opposed to objectivity, where knowledge is seen to be independent of the subject who is producing it. In most of geography's history, subjectivity has meant understanding the role of various social locations (such as class, gender, ethnicity, and sexuality) on the construction of the individual's relationship with the world, which shapes their knowledge and understanding of the world. This suggests that there will always be a bias to this perception and the knowledge that emerges from it. Besides having profound epistemological and ontological implications, this has a significant effect on the development of research methodology: The subject's experiences and biography influence their knowledge and understanding of the world. There has been considerable debate around the extent to which the subject is able to act freely or whether actions are constrained by higher powers. More recently, geographers have also considered the effects of less visible or conscious markers of identity such as psychological and emotional characteristics, the influence of bodily knowledge, and the subjectivity of things external to the individual: networks, collectivities, technologies, and nonhuman animals.}
}
@article{SHAN2025113448,
title = {SANTM: A Sparse Access Neural Turing Machine with local multi-head self-attention for long-term memorization},
journal = {Applied Soft Computing},
volume = {181},
pages = {113448},
year = {2025},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2025.113448},
url = {https://www.sciencedirect.com/science/article/pii/S1568494625007598},
author = {Dongjing Shan and Jing Zhu and Yamei Luo},
keywords = {Neural Turing Machine, Sparse representation, Long short-term memory, ChebNet spectral graph convolution, Memory-augmented neural networks},
abstract = {In this paper, we propose a Sparse Access Neural Turing Machine (SANTM) to address long-term memorization challenges in sequence learning. The SANTM integrates a three-level neural controller with external memory: (1) a bottom layer for segmenting inputs into variable-length chunks, (2) a middle layer for short-term memory integration, and (3) a top layer that selectively accesses external memory via a locality-biased multi-head self-attention mechanism based on ChebNet spectral graph convolution. A sparse mask, trained through an ℓ0-constrained optimization scheme, reduces memory access rates while enabling pre-fetching. Theoretical analysis derives an optimal access rate under idealized conditions. Experiments on sequential image classification (MNIST, CIFAR10), text classification, speaker discrimination, and language modeling (WikiText-103, enwik8) demonstrate SANTM’s superiority over state-of-the-art sequential models. Key results include 95.7% accuracy on permuted MNIST (vs. NTM’s 94.0%), 85.4% on TC-Speech (vs. 79.6% for NTM), and 24.2 perplexity on WikiText-103 (vs. Transformer-XL’s 27.0). The sparse mask reduces FLOPs by 37%–54% compared to traditional NTMs, validating its efficiency.}
}
@article{REN2024112595,
title = {Self-labeling in multivariate causality and quantification for adaptive machine learning},
journal = {Knowledge-Based Systems},
volume = {305},
pages = {112595},
year = {2024},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2024.112595},
url = {https://www.sciencedirect.com/science/article/pii/S0950705124012292},
author = {Yutian Ren and Aaron Haohua Yen and G.P. Li},
keywords = {Adaptive learning, Self-supervised learning, Machine learning, Causality inspired learning, Causal time delay, Noisy label},
abstract = {Adaptive machine learning (ML) aims to allow ML models to adapt to ever-changing environments with potential concept drift after model deployment. Traditionally, adaptive ML requires a new dataset to be manually labeled to tailor deployed models to altered data distributions. Recently, an interactive causality based self-labeling method was proposed to autonomously associate causally related data streams for domain adaptation, showing promising results compared to traditional feature similarity-based semi-supervised learning. Several unanswered research questions remain, including self-labeling’s compatibility with multivariate causality and the quantitative analysis of the auxiliary models used in the self-labeling. The auxiliary models, the interaction time model (ITM) and the effect state detector (ESD), are vital to the success of self-labeling. This paper further develops the self-labeling framework and its theoretical foundations to address these research questions. A framework for the application of self-labeling to multivariate causal graphs is proposed using four basic causal relationships, and the impact of non-ideal ITM and ESD performance is analyzed. A simulated experiment is conducted based on a multivariate causal graph, validating the proposed theory.}
}
@article{WAN2025104287,
title = {A systematic mapping study of information retrieval-based requirements traceability methods},
journal = {Information Processing & Management},
volume = {62},
number = {6},
pages = {104287},
year = {2025},
issn = {0306-4573},
doi = {https://doi.org/10.1016/j.ipm.2025.104287},
url = {https://www.sciencedirect.com/science/article/pii/S0306457325002286},
author = {Hongyan Wan and Xinyu He and Yang Deng and Bangchao Wang},
keywords = {Requirements traceability, Systematic mapping study, Information retrieval},
abstract = {Requirements traceability (RT) is critical for ensuring consistency, quality, and maintainability in software development. While learning-based approaches have gained increasing attention, traditional information retrieval (IR) methods remain widely used in practice. However, existing literature lacks a systematic synthesis of their best practices and recent advancements. To address this gap, we conducted a systematic mapping study (SMS) of 40 primary studies published between 2014 and 2024, selected from an initial pool of 2,052 publications. Our review examines widely adopted IR models, enhancement strategies, evaluation datasets, performance metrics, and baseline methods. Specifically, we identify and categorize 32 representative enhancement strategies into four methodological types: (1) artifact text information, (2) artifact structural information, (3) model-based optimization, and (4) human intervention. Furthermore, we analyze 53 commonly used datasets and 9 evaluation metrics for validation. Our findings indicate that among various IR models, the Vector Space Model (VSM) and Latent Semantic Indexing (LSI) typically achieve stronger performance in RT tasks. This study provides a comprehensive synthesis of IR-based RT research and offers practical insights to advance traceability in software engineering.}
}
@article{CHEN2021102831,
title = {Network analysis identifies DAPK3 as a potential biomarker for lymphatic invasion and colon adenocarcinoma prognosis},
journal = {iScience},
volume = {24},
number = {8},
pages = {102831},
year = {2021},
issn = {2589-0042},
doi = {https://doi.org/10.1016/j.isci.2021.102831},
url = {https://www.sciencedirect.com/science/article/pii/S2589004221007999},
author = {Huey-Miin Chen and Justin A. MacDonald},
keywords = {Molecular biology, Systems biology, Transcriptomics},
abstract = {Summary
Colon adenocarcinoma is a prevalent malignancy with significant mortality. Hence, the identification of molecular biomarkers with prognostic significance is important for improved treatment and patient outcomes. Clinical traits and RNA-Seq of 551 patient samples in the UCSC Toil Recompute Compendium of The Cancer Genome Atlas TARGET and Genotype Tissue Expression project datasets (primary_site = colon) were used for weighted gene co-expression network analysis to reveal the association between gene networks and cancer cell invasion. One module, containing 151 genes, was significantly correlated with lymphatic invasion, a histopathological feature of higher risk colon cancer. DAPK3 (death-associated protein kinase 3) was identified as the pseudohub of the module. Gene ontology identified gene enrichment related to cytoskeletal organization and apoptotic signaling processes, suggesting modular involvement in tumor cell survival, migration, and epithelial-mesenchymal transformation. Although DAPK3 expression was reduced in patients with colon cancer, high expression of DAPK3 was significantly correlated with greater lymphatic invasion and poor overall survival.}
}
@article{PREMANANDAN2023,
title = {Designing a Mobile e-Coaching App for Immigrant Informal Caregivers: Qualitative Study Using the Persuasive System Design Model},
journal = {JMIR mHealth and uHealth},
volume = {11},
year = {2023},
issn = {2291-5222},
doi = {https://doi.org/10.2196/50038},
url = {https://www.sciencedirect.com/science/article/pii/S2291522223000980},
author = {Shweta Premanandan and Awais Ahmad and Åsa Cajander and Pär Ågerfalk and Michal Dolezel and Lisette {van Gemert-Pijnen}},
keywords = {e-coaching, mobile health, mHealth, immigrant informal caregivers, designing app, persuasive system design, user needs, caregiver, app, design, users, aging, development, diversity, language barrier, inclusion, training, mental health, mobile phone},
abstract = {Background
Informal caregivers are vital in caring for their family and friends at home who may have illnesses or disabilities. In particular, the demands for caregiving can be even more challenging for those with limited resources, support systems, and language barriers, such as immigrant informal caregivers. They face complex challenges in providing care for their relatives. These challenges can be related to sociocultural diversity, language barriers, and health care system navigation. Acknowledging the global context of the increasing number of immigrants is essential in designing inclusive mobile health apps.
Objective
This study aims to investigate the needs of immigrant informal caregivers in Sweden and discuss the application of the Persuasive System Design Model (PSDM) to develop an e-coaching prototype. By addressing the unique challenges faced by immigrant informal caregivers, this study will contribute to the development of more effective and inclusive mobile health apps.
Methods
The participants were considered immigrants and included in the study if they and their parents were born outside of Sweden. Through various channels, such as the National Association of Relatives, rehabilitation departments at municipalities, and immigrant groups, we recruited 13 immigrant informal caregivers. These immigrant informal caregivers were primarily women aged 18 to 40 years. Most participants belonged to the Middle Eastern region whereas some were from North Africa. However, all of them spoke Arabic. We used semistructured interviews to gather data from the participants in Arabic, which were translated into English. Data were analyzed using thematic analysis and discussed in relation to the extended PSDM. The needs of the caregivers were compared with the description of persuasive design principles, and a design principle was chosen based on the match. The PSDM was extended if the need description did not match any principles. Several brainstorming and prototyping sessions were conducted to design the mobile e-coaching app.
Results
Immigrant informal caregivers have various needs in their caregiving role. They reported a need for training on the illness and future caregiving needs, assistance with understanding the Swedish language and culture, and help with accessing internet-based information and services. They also required recognition and appreciation for their efforts, additional informal support, and easy access to health care services, which can be important for their mental health. The PSDM was adapted to the informal caregiving context by adding “facilitating conditions” and “verbal encouragement” as additional persuasive design principles. This study also presents the subsequent mobile e-coaching app for immigrant informal caregivers in Sweden.
Conclusions
This study revealed important immigrant informal caregivers’ needs based on which design suggestions for a mobile e-coaching app were presented. We also proposed an adapted PSDM, for the informal caregiving context. The adapted PSDM can be further used to design digital interventions for caregiving.}
}
@article{WANG201979,
title = {Quantifying sequential subsumption},
journal = {Theoretical Computer Science},
volume = {793},
pages = {79-99},
year = {2019},
issn = {0304-3975},
doi = {https://doi.org/10.1016/j.tcs.2019.05.025},
url = {https://www.sciencedirect.com/science/article/pii/S030439751930372X},
author = {Hui Wang and Cees H. Elzinga and Zhiwei Lin and Jordan Vincent},
keywords = {Subsumption characterisation, Subsumption quantification, Sequence and subsequence analysis, Sequence similarity, Grid algorithm},
abstract = {Subsumption is used in knowledge representation and ontology to describe the relationship between concepts. Concept A is subsumed by concept B if the extension of A is always a subset of the extension of B, irrespective of the interpretation. The subsumption relation is also useful in other data analysis tasks such as pattern recognition – for example in image analysis to detect objects in an image, and in spectral data analysis to detect the presence of a reference pattern in a given spectrum. Sometimes the subsumption relation may not be 100% true, so it is useful to quantify this relationship. In this paper we study how to quantify subsumption for sequential patterns. We review existing work on subsumption, give an axiomatic characterisation of subsumption, and present one general approach to quantification in terms of set intersection operation over concept extension. Constructing the concept extension set explicitly is impossible without specifying the domain of discourse and the interpretation. Instead, we focus on concept intension for sequences as patterns and propose to represent concept intension of a sequence by its subsequences. We further consider different types of concept intension set – subsequence set, subsequence multiset, embedding set and embedding set with constraints such as warping and selection. We then present a general algorithmic framework for computing set intersections, and specific algorithms for computing different concept intension sets. We also present an experimental evaluation of these algorithms with regard to their runtime performance.}
}
@article{SAAD2025110306,
title = {Navigating nutrients: A scoping review on real-time food nutrition classification and recommendation systems},
journal = {Computers in Biology and Medicine},
volume = {192},
pages = {110306},
year = {2025},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2025.110306},
url = {https://www.sciencedirect.com/science/article/pii/S0010482525006572},
author = {Asim Moin Saad and Md. Manirul Islam},
keywords = {Nutrient-based meal recommendation Personalized nutrition, Artificial intelligence, Convolutional Neural Network (CNN), Machine learning, Deep learning},
abstract = {In an era where fast-paced lifestyles often conflict with the pursuit of healthy eating, the demand for innovative solutions to aid nutritional decision-making has never been more pressing. Real-time food nutrition classification and recommendation systems offer an effective solution to this growing issue. By harnessing state-of-the-art technologies such as sensor-based data collection and machine learning algorithms, these systems can conduct a precise analysis of the nutritional composition of foods. This scoping review presents a comprehensive investigation of real-time food nutrition recommendation and classification systems, encompassing their capabilities, effectiveness, and potential ramifications for public health, focusing on identifying and evaluating the technological approaches, nutritional parameters, and applications of these systems. By synthesizing prior research, we can reveal the complex web of methodologies, trends, and obstacles that influence this ever-evolving discipline. We included only peer-reviewed studies and conference proceedings, published within the last decade. A systematic search of Scopus, IEEE Xplore, and PubMed databases yielded 166 papers, of which 36 studies were selected for further evaluation. The findings highlight the importance of technological advancements and the need for further research to improve the effectiveness of these systems in promoting healthy eating habits. The study unveils a landscape filled with possibilities, from machine learning algorithms to sensor-based technologies, each offering unique pathways for users to make smart dietary decisions on the go.}
}
@article{CHEN2024100155,
title = {A novel few-shot learning framework for rock images dually driven by data and knowledge},
journal = {Applied Computing and Geosciences},
volume = {21},
pages = {100155},
year = {2024},
issn = {2590-1974},
doi = {https://doi.org/10.1016/j.acags.2024.100155},
url = {https://www.sciencedirect.com/science/article/pii/S2590197424000028},
author = {Zhongliang Chen and Feng Yuan and Xiaohui Li and Mingming Zhang and Chaojie Zheng},
keywords = {Rock image recognition, Transfer learning, Knowledge graph, Knowledge reasoning, Node similarity},
abstract = {In the field of geosciences, the integration of artificial intelligence is transitioning from perceptual intelligence to cognitive intelligence. The simultaneous utilization of knowledge and data in the geoscience domain is a universally addressed concern. In this paper, based on the interpretability of deep learning models for rock images, rock features such as structure, texture, mineral and macroscopic identification characteristics were selected to extract a rock identification subgraph from the petrographic knowledge graph and carry out rock type similarity reasoning. Comparative experiments were conducted on few-shot learning of rock images under the supervision of rock type similarity knowledge. The results of the few-shot learning comparisons demonstrate that the supervision of rock type similarity knowledge significantly enhances performance. Additionally, rock type similarity knowledge exhibits a marginal effect on improving few-shot learning performance. Given the absence of Chinese word embedding and large-scale Chinese pre-trained language models in the geological domain, graph embedding based on domain-specific knowledge graphs in geosciences can offer computable geoscience knowledge for research dually propelled by data and knowledge.}
}
@article{SARAVANAKUMAR2020106518,
title = {Effective information retrieval and feature minimization technique for semantic web data},
journal = {Computers & Electrical Engineering},
volume = {81},
pages = {106518},
year = {2020},
issn = {0045-7906},
doi = {https://doi.org/10.1016/j.compeleceng.2019.106518},
url = {https://www.sciencedirect.com/science/article/pii/S004579061931701X},
author = {C.S. {Saravana Kumar} and R. Santhosh},
keywords = {Feature extraction, Dimensionality reduction, Semantic web mining, Text mining, Data mining, Feature selection, Information retrieval, Feature vector},
abstract = {The Internet contains both structured and unstructured data. The enormous flow of Internet data creates challenges in relation to effective information retrieval. Semantic Web Mining explores Web addresses using ontological and semantic structures. For effective information retrieval in Web Mining and Text Mining, text feature extraction plays an important role. The effectiveness of the text processing is determined by the complexity and dimensionality reduction of the feature vector. In this paper, a new approach is proposed based on the semantic structure of the Web data. It combines both feature extraction and feature selection techniques for data mapping and retrieval, involving standard features for effective text mapping. This process reduces the dimension complexity in the feature vector for effective information retrieval.}
}
@article{MING2025110992,
title = {Harnessing high-quality pseudo-labels for robust few-shot nested named entity recognition},
journal = {Engineering Applications of Artificial Intelligence},
volume = {156},
pages = {110992},
year = {2025},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2025.110992},
url = {https://www.sciencedirect.com/science/article/pii/S0952197625009923},
author = {Hong Ming and Jiaoyun Yang and Shuo Liu and Lili Jiang and Ning An},
keywords = {Few-shot, Nested named entity recognition, Cross-lingual, High-quality pseudo-labels},
abstract = {Few-shot Named Entity Recognition (NER) methods have shown initial effectiveness in flat NER tasks. However, these methods often prioritize optimizing models with a small annotated support set, neglecting the high-quality data within the unlabeled query set. Furthermore, existing few-shot NER models struggle with nested entity challenges due to linguistic or structural complexities. In this study, we introduce Retrieving high-quality pseudo-label Tuning, RiTNER, a framework designed to address few-shot nested named entity recognition tasks by leveraging high-quality data from the query set. RiTNER comprises two main components: (1) contrastive span classification, which clusters entities into corresponding prototypes and generates high-quality pseudo-labels from the unlabeled data, and (2) masked pseudo-data tuning, which generates a masked pseudo dataset and then uses it to optimize the model and enhance span classification. We train RiTNER on an English dataset and evaluate it on both English nested datasets and cross-lingual nested datasets. The results show that RiTNER outperforms the top-performing baseline models by 1.67%, and 3.04% in the English 5-shot task, as well as the cross-lingual 5-shot tasks, respectively.}
}
@article{YU2025,
title = {Exploring plant protein functions through structure-based clustering},
journal = {Trends in Plant Science},
year = {2025},
issn = {1360-1385},
doi = {https://doi.org/10.1016/j.tplants.2025.03.014},
url = {https://www.sciencedirect.com/science/article/pii/S1360138525000913},
author = {Minxiang Yu and Jie Wu and Cuihuan Zhao and Jin-Long Qiu},
keywords = {structure prediction, artificial intelligence, structure similarity, structure-based clustering, function annotation},
abstract = {The upsurge in new plant protein sequences has far outpaced experimental functional characterization efforts. Prediction of protein function based on sequence homology often falls short when dealing with proteins that have low sequence similarity. Artificial intelligence (AI) programs, such as AlphaFold, have transformed computational protein structure prediction with remarkable accuracy. By leveraging the availability of predicted structures for nearly all protein sequences, clustering proteins based on their similarity in structural features has become a powerful tool for function annotation and discovery. Structure-based protein clustering enables the identification of distant evolutionary relationships and novel protein families, and offers an effective strategy for exploring plant protein functions, bridging the gap between sequence data and function annotation while also assisting in protein design.}
}
@article{DONG2022151847,
title = {High S100A7 expression is associated with early muscle invasion and poor survival in bladder carcinoma},
journal = {Annals of Diagnostic Pathology},
volume = {56},
pages = {151847},
year = {2022},
issn = {1092-9134},
doi = {https://doi.org/10.1016/j.anndiagpath.2021.151847},
url = {https://www.sciencedirect.com/science/article/pii/S1092913421001477},
author = {Yang Dong and Guang-yuan Zhu and Lin Hao and Qing Liang and Jia-he Zhou and Zhen-duo Shi and Hui Yu and Wei-ming Ma and Tao Fan and Wen-da Zhang and Guang-hui Zang and Cong-hui Han},
keywords = {Bladder carcinoma, Muscle invasion, Bioinformatics, Prognosis, S100A7},
abstract = {Muscle-invasive bladder carcinoma (MIBC) accounts for 25% of newly diagnosed bladder carcinomas (BCs) and presents a high risk of progression and metastasis. This study aimed to identify reliable biomarkers associated with muscle invasion and prognosis to identify potential therapeutic targets for MIBC. Four gene datasets were downloaded from the Gene Expression Omnibus, and the integrated differentially expressed genes (DEGs) were then subjected to gene ontology (GO) terms and pathway enrichment analyses. Correlation analysis between the expression of the top-ranking DEGs and pathological T stages was performed to identify the genes associated with early muscle invasion. The corresponding prognostic values were evaluated, and co-expressed genes mined in the cBioPortal database were loaded into ClueGo in Cytoscape for pathway enrichment analysis. Using data mining from the STRING and TCGA databases, protein–protein interaction and competitive endogenous RNA networks were constructed. In total, 645 integrated DEGs were identified and these were mainly enriched in 26 pathways, including cell cycle, bladder cancer, DNA replication, and PPAR signaling pathway. S100A7 expression was significantly increased from the T2 stage and showed significantly worse overall survival and disease-specific survival in patients with BC. In total, 144 genes co-expressed with S100A7 in BC were significantly enriched in the IL-17 pathway. S100A7 was predicted to directly interact with LYZ, which potentially shows competitive binding with hsa-mir-140 to affect the expression of six lncRNAs in MIBC. In conclusion, high S100A7 expression was predicted to be associated with early muscle invasion and poor survival in patients with BC.}
}
@article{SMIRNOV20211206,
title = {Natural Language Processing Workflow for Customer Request Analysis in a Company},
journal = {IFAC-PapersOnLine},
volume = {54},
number = {1},
pages = {1206-1211},
year = {2021},
note = {17th IFAC Symposium on Information Control Problems in Manufacturing INCOM 2021},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2021.08.143},
url = {https://www.sciencedirect.com/science/article/pii/S240589632100906X},
author = {Alexander Smirnov and Nikolay Teslya and Nikolay Shilov and Diethard Frank and Dirk Weidig and Elena Minina and Kathrin Evers},
keywords = {text analysis, natural language processing, machine learning, classification, named entity recognition},
abstract = {The paper presents a comparison of existing text analysis systems from the point of view of their applicability to customer request analysis tasks for company needs. The tasks of named entity search and text classification for preliminary analysis of customer requests to the company’s support department are considered. In the course of work, five systems were considered and preliminarily evaluated in terms of the functionality required for solving the above tasks. The final assessment was based on training of the systems using a marked-up corpus of texts provided by the company’s support department.}
}
@article{SCHATZKI2025100553,
title = {Agency},
journal = {Information and Organization},
volume = {35},
number = {1},
pages = {100553},
year = {2025},
issn = {1471-7727},
doi = {https://doi.org/10.1016/j.infoandorg.2024.100553},
url = {https://www.sciencedirect.com/science/article/pii/S1471772724000538},
author = {Theodore R. Schatzki},
keywords = {Agency, Acting, Doing, Distributed agency, Agencements, Practices},
abstract = {This essay urges researchers to respect differences among the agencies of different kinds of entities as well as among types of “distributed agency” understood as the agentic character of combinations of entities and events. In opposition, moreover, to the strong approach to sociomateriality in IS, the essay holds that most nexuses to which human people are integral aggregate the different agencies of the entities and events that compose them. The essay develops these theses by carefully sorting out different conceptions of agency and by both disambiguating and exploring four prominent claims contained in the idea that agency is tied to combinations of entities and events. Sorting out different conceptions of agency also shows that agency is causality, that is, particular forms of causality. The overall result is a defense of the integrity of the concept of agency as a reflection of the noun-verb structure of human languages.}
}
@article{LAWRENCE2022212,
title = {An overview, empirical application, and discussion of the future research potential of Q&A models in B2B contexts},
journal = {Industrial Marketing Management},
volume = {107},
pages = {212-221},
year = {2022},
issn = {0019-8501},
doi = {https://doi.org/10.1016/j.indmarman.2022.10.002},
url = {https://www.sciencedirect.com/science/article/pii/S0019850122002346},
author = {Benjamin Lawrence and Yanqing Wang and Yinghao Pan and Charlotte S. Alexander},
keywords = {Automated text analytics, Franchise disclosure, BERT, Natural language processing},
abstract = {We present a proof of concept for using automated text analytic techniques to extract key information from lengthy B2B legal documents using BERT (Bidirectional Encoder Representations from Transformers), a machine learning-based natural language-processing framework. Our methodological contributions overcome the text length limitations of applying BERT to long legal documents. We identify franchise disclosure documents (FDDs) as an initial use case for these methodologies and a fruitful avenue for further exploration. From FDDs, we successfully extract answers to questions about firm structure, contractual obligations, finances, and litigation disclosures while also overcoming the technical challenges of applying BERT to large bodies of text. Question-and-answer techniques such as these, deployed in a B2B context, potentially can increase transparency and clarity for prospective exchange partners, addressing concerns in the literature about legal document readability and associated problems of information asymmetry and disclosure misunderstanding. Our discussion identifies promising contexts and an agenda for future scholarship focused on question-and-answer in B2B research.}
}
@article{WU2022104108,
title = {Rule-based information extraction for mechanical-electrical-plumbing-specific semantic web},
journal = {Automation in Construction},
volume = {135},
pages = {104108},
year = {2022},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2021.104108},
url = {https://www.sciencedirect.com/science/article/pii/S0926580521005598},
author = {Lang-Tao Wu and Jia-Rui Lin and Shuo Leng and Jiu-Lin Li and Zhen-Zhong Hu},
keywords = {Information extraction, MEP, Rule match, Named entity recognition, Relation extraction, Natural language understanding, Semantic web},
abstract = {Information extraction (IE), which aims to retrieve meaningful information from plain text, has been widely studied in general and professional domains to support downstream applications. However, due to the lack of labeled data and the complexity of professional mechanical, electrical and plumbing (MEP) information, it is challenging to apply current common deep learning IE methods to the MEP domain. To solve this problem, this paper proposes a rule-based approach for MEP IE task, including a “snowball” strategy to collect large-scale MEP corpora, a suffix-based matching algorithm on text segments for named entity recognition (NER), and a dependency-path-based matching algorithm on dependency tree for relationship extraction (RE). 2 ideas called “meta linking” and “path filtering” for RE are proposed as well, to discover the out-of-pattern entities/relationships as many as possible. To verify the feasibility of the proposed approach, 65 MB MEP corpora have been collected as input of the proposed approach and an MEP semantic web which consists of 15,978 entities and 65,110 relationship triples established, with an accuracy of 81% to entities and 75% to relationship triples, respectively. A comparison experiment between classical deep learning models and the proposed rule-based approach was carried out, illustrating that the performance of our method is 37% and 49% better than the selected deep learning NER and RE models, respectively, in the aspect of extraction precision.}
}
@article{SINGH2021508,
title = {Morphological evaluation and sentiment analysis of Punjabi text using deep learning classification},
journal = {Journal of King Saud University - Computer and Information Sciences},
volume = {33},
number = {5},
pages = {508-517},
year = {2021},
issn = {1319-1578},
doi = {https://doi.org/10.1016/j.jksuci.2018.04.003},
url = {https://www.sciencedirect.com/science/article/pii/S1319157818300612},
author = {Jaspreet Singh and Gurvinder Singh and Rajinder Singh and Prithvipal Singh},
abstract = {Morphological processing of Indian languages is one of the most escalating fields in the era of Natural Language Processing (NLP) since the last decade. The evaluation of Asian languages is a highly relevant field in the times of text mining and information retrieval. The morphological evaluation of a text can be employed for extraction and classification of knowledge. This paper amalgamates morphological evaluation and sentiment prediction of Punjabi language text. The textual data for Punjabi language is concerned with farmer suicide cases reported for Punjab state of India. The pre-processing phase of this study involves morphological evaluation and normalization of Punjabi words to their respective canonical forms. The next phase carries out training and testing of deep neural network model on refined Punjabi tokens obtained from the earlier phase. The proposed model classifies Punjabi tokens into four negatively oriented classes tailored for farmer suicide cases. The average accuracies of sentiment prediction obtained after 10-fold cross validation are 93.85%, 88.53%, 83.3%, and 95.45% for the four respective classes. The proposed framework yields satisfactory results on 275 Punjabi text documents with the overall accuracy of 90.29% for sentiment classification.}
}
@article{ZHAO202472,
title = {Interoperability performance evaluation for discrete event simulation models: A step towards multi-level data exchange},
journal = {Procedia CIRP},
volume = {128},
pages = {72-77},
year = {2024},
note = {34th CIRP Design Conference},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2024.06.007},
url = {https://www.sciencedirect.com/science/article/pii/S2212827124006516},
author = {Jiaqi Zhao and El-Houssaine Aghezzaf and Johannes Cottyn},
keywords = {Multi-level interoperability, Discrete event simulation, Design methodology, tools, technologies},
abstract = {According to use scenarios, 3D-based virtual commissioning can be divided into three levels: machine, cell and plant. As virtual commissioning at each level focuses on different contents, corresponding applications are developed in different data models. The resulting 3D emulation and simulation models are thus not easily exchangeable or reusable. At machine level, a physics-based model is used to conduct emulation. While at plant level discrete event simulation models are quite common. A framework for exchanging 3D emulation and simulation models between software at different levels would stimulate model reuse and lower the effort for model creation. To date, no interoperability performance evaluation for discrete event simulation models has been presented. This paper investigates industrial standards and related work on discrete event model generation and data exchange. The interoperability performance of discrete event simulation tools is evaluated by the example case of exchanging models between two commercial tools (i.e., FlexSim and Visual Components) via Core Manufacturing Simulation Data and AutomationML. The result shows the former converts 7% more attributes than the latter. Furthermore, an element-based comparison is conducted to reveal overlaps and assess the potential of (partial) model reuse during the data exchange between 3D emulation and simulation models.}
}
@article{WESTIN2024135,
title = {Time, technique and text: scoping review of temporal information extraction and categorisation in documents},
journal = {Journal of Documentation},
volume = {81},
number = {7},
pages = {135-156},
year = {2024},
issn = {0022-0418},
doi = {https://doi.org/10.1108/JD-11-2024-0267},
url = {https://www.sciencedirect.com/science/article/pii/S0022041825000086},
author = {Fereshta Westin},
keywords = {Time as aboutness, Temporal information, Event, Ctegorisation, Classification, Automated methods},
abstract = {Purpose
This paper presents an investigation of the concept of “time as aboutness” in various texts, including news articles, social media posts and historical documents. The purpose of this paper is to analyse different forms of temporal information and map the techniques used to extract and categorise this information.
Design/methodology/approach
A scoping review method was adopted to analyse the chosen literature set. This approach allowed for an overview of the different text document types, the techniques used and their temporal information.
Findings
The findings reveal six temporal types of time-related data analysis: social events, socio-political events, news events, temporal expressions, historical events and time periods. Studies analysing social media, news articles, Wikipedia entries and historical documents provide insights into event detection and categorisation. In these documents, time appears as sequences of events, temporal expressions or distinct periods. In news articles, time appears as a series of occurrences, while temporal expressions reveal how time is linguistically articulated and perceived. The analysis also covers event categorisation methods, emphasising machine learning techniques, natural language processing, large language models and rule-based systems.
Originality/value
The analysis of different types of time and methods of extracting temporal information from various texts contributes original insights to the understanding of temporal information. The findings reveal a need for expanding document variety, particularly to include fiction literature and point to the potential use of language models for future temporal information categorisation.}
}
@article{GOLYAGINA2021449,
title = {Importing a management accounting concept into the Russian language: a case of resistance from Russian academics},
journal = {Journal of Accounting in Emerging Economies},
volume = {11},
number = {3},
pages = {449-476},
year = {2021},
issn = {2042-1168},
doi = {https://doi.org/10.1108/JAEE-02-2020-0025},
url = {https://www.sciencedirect.com/science/article/pii/S2042116821000121},
author = {Alena Golyagina},
keywords = {History, Language, Management accounting, Russia, Translation},
abstract = {Purpose
Drawing on the semantic field theory, the paper aims to uncover the challenges of importing and translating a management accounting concept into the Russian language and the semantic nature of resistance towards the imported management accounting concept.
Design/methodology/approach
The paper draws on the extensive literature review of the histories of accounting in the Soviet Union and the United States in the first part of the twentieth century and 17 interviews conducted with the Russian accounting academics.
Findings
We demonstrate the case of resistance in adopting the imported Anglo-Saxon management accounting concept. We also discuss historical underpinning and origins of this resistance in light of semantic field theory.
Research limitations/implications
The paper calls for more research in the non-Anglo-Saxon contexts problematizing conventional assumptions and beliefs about objectivity and universality of accounting language.
Practical implications
The study demonstrates the importance of understanding historical and cross-cultural developments of accounting language for accounting educators and practitioners. Critical awareness of the differences in semantic fields of accounting can help accounting researchers and educators to develop contextualized research projects and context-relevant teaching practices.
Originality/value
The study contributes to the literature on translations of accounting concepts by demonstrating that accounting concepts are not understood in isolation, instead, they are interpreted in relation to each other. The present study demonstrates that the relationship between the management accounting concept (the signifier) and its meanings (signifieds) is fluid, culturally and historically contingent. To understand this relationship, we should attend to the historical development of semantic fields and associative relations between concepts.}
}
@article{IANNACONE2023102319,
title = {Addressing participation, belonging, and temporality in public formation and maintenance: Advancing a rhetorical approach to publics},
journal = {Public Relations Review},
volume = {49},
number = {2},
pages = {102319},
year = {2023},
issn = {0363-8111},
doi = {https://doi.org/10.1016/j.pubrev.2023.102319},
url = {https://www.sciencedirect.com/science/article/pii/S0363811123000346},
author = {Jeannette I. Iannacone and Drew T. Ashby-King},
keywords = {Publics, Rhetoric, Ontology, Critical, Cocreational, Postmodern},
abstract = {This paper expands the conceptualization of publics as rhetorical constructs in recognition of non-functional perspectives to public relations scholarship. After reviewing the functional/issue-based approaches and the non-functional/discursive-based approaches to theorizing publics within public relations research, we note the significance of the stranger relationality and temporality that is invoked when considering the circulation of discourse and texts as the basis for public existence. We suggest four premises to a rhetorical understanding of publics, expanding upon the public relations literature that has previously suggested a discursive nature of publics, but has not articulated the consequential details of public formation, maintenance, and existence. These premises decenter the organization by highlighting the circulation of and attention to texts, emphasize public existence as allowing a fluidity of participation, suggest further understanding belonging rather than behavior, and underscore questions of temporality and collective memory. We then suggest some implications for public relations research, including how a rhetorical understanding connects to the non-functional approaches of the field, as well as how it may extend studies of relationships and counterpublics.}
}
@article{ZHOU2022101717,
title = {Creating spatially-detailed heterogeneous synthetic populations for agent-based microsimulation},
journal = {Computers, Environment and Urban Systems},
volume = {91},
pages = {101717},
year = {2022},
issn = {0198-9715},
doi = {https://doi.org/10.1016/j.compenvurbsys.2021.101717},
url = {https://www.sciencedirect.com/science/article/pii/S0198971521001241},
author = {Meng Zhou and Jason Li and Rounaq Basu and Joseph Ferreira},
keywords = {Synthetic population, Built environment, Agent-based microsimulation, Bayesian Network, Land use-transport interaction (LUTI) model},
abstract = {Agent-based models (ABMs) of urban systems have grown in popularity and complexity due to the widespread availability of high-performance computing resources and large data storage capabilities. Credible synthetic populations are crucial for the application of ABMs to understand urban phenomena. Although several (agent) population synthesis methods have been suggested over the years, the spatial dimension of synthetic populations has not received as much attention. This study addresses this myopic treatment of synthetic populations by creating two distinct components – agents and the built environment – that are integrated to form a ‘full’ spatially-detailed synthetic population. To generate agents, we used multiple Bayesian Networks (BN) to probabilistically draw pools from the microsample, followed by a Generalized Raking (GR) adjustment to match marginal controls. Using various measures, we demonstrate that our BN+GR framework outperforms more commonly used synthesis methods in both capturing the heterogeneity in the microsample and matching marginal controls. We also highlight the importance of accounting for heterogeneity by using separate type-specific models based on an explicitly defined household typology. For built environment synthesis, we generated various spatial entities such as buildings, housing units, establishments, and jobs at distinct spatial locations by fusing data from various spatial datasets. Their spatial distributions are found to effectively approximate the ‘real’ built environment in our study area. Our proposed framework can be used to generate a ‘full’ synthetic population for use in ABMs with more spatio-demographic heterogeneity than can otherwise be estimated using traditional methods.}
}
@article{WU2025121069,
title = {A novel method for functional brain networks based on static cerebral blood flow},
journal = {NeuroImage},
volume = {308},
pages = {121069},
year = {2025},
issn = {1053-8119},
doi = {https://doi.org/10.1016/j.neuroimage.2025.121069},
url = {https://www.sciencedirect.com/science/article/pii/S1053811925000710},
author = {Changwen Wu and Yu He and Junle Li and Xiaofan Qiu and Qihong Zou and Jinhui Wang},
keywords = {Brain network, Cerebral blood flow, Arterial spin labeling, Gene expression, Neurotransmitter},
abstract = {Cerebral blood flow (CBF) offers a quantitative and reliable measurement for brain activity and is increasingly used to study functional networks. However, current methods evaluate inter-regional relations mainly based on CBF temporal dynamics, which suffers from low signal-to-noise ratio and poor temporal resolution. Here we proposed a method to construct functional brain networks by estimating shape similarity (index by Jensen–Shannon divergence) in probability distributions of regional static CBF measured by arterial spin labeling perfusion imaging over a scanning period. Based on CBF data of 30 healthy participants from 10 visits, we found that the CBF networks exhibited non-trivial topological features (e.g., small-world organization, modular architecture, and hubs) and showed low-to-fair test-retest reliability and high between-subject consistency. We further found that interregional CBF similarities were depended on anatomical distance and differed between high- and lower-order subnetworks. Moreover, interregional CBF similarities within high-order subnetworks showed significantly lower reliability than those within low-order subnetworks. Finally, we showed that nodal degree of the CBF networks were related to regional sizes and CBF levels and spatially aligned with maps of the dopamine transporter and metabolic glutamate receptor 5 intensities, expression levels of genes primarily enriched in cholesterol-related pathways and endothelial cells, and meta-analytic activations related to memory, language, and executive function. Altogether, our proposed method provide a novel, relatively reliable, and neurobiologically meaningful means to study functional network organization of the human brain.}
}
@article{CREMONESI2023104338,
title = {The need for multimodal health data modeling: A practical approach for a federated-learning healthcare platform},
journal = {Journal of Biomedical Informatics},
volume = {141},
pages = {104338},
year = {2023},
issn = {1532-0464},
doi = {https://doi.org/10.1016/j.jbi.2023.104338},
url = {https://www.sciencedirect.com/science/article/pii/S153204642300059X},
author = {Francesco Cremonesi and Vincent Planat and Varvara Kalokyri and Haridimos Kondylakis and Tiziana Sanavia and Victor {Miguel Mateos Resinas} and Babita Singh and Silvia Uribe},
keywords = {Federated learning, Data model, Healthcare, Medical research, Omics, Lessons learned},
abstract = {Federated learning initiatives in healthcare are being developed to collaboratively train predictive models without the need to centralize sensitive personal data. GenoMed4All is one such project, with the goal of connecting European clinical and –omics data repositories on rare diseases through a federated learning platform. Currently, the consortium faces the challenge of a lack of well-established international datasets and interoperability standards for federated learning applications on rare diseases. This paper presents our practical approach to select and implement a Common Data Model (CDM) suitable for the federated training of predictive models applied to the medical domain, during the initial design phase of our federated learning platform. We describe our selection process, composed of identifying the consortium’s needs, reviewing our functional and technical architecture specifications, and extracting a list of business requirements. We review the state of the art and evaluate three widely-used approaches (FHIR, OMOP and Phenopackets) based on a checklist of requirements and specifications. We discuss the pros and cons of each approach considering the use cases specific to our consortium as well as the generic issues of implementing a European federated learning healthcare platform. A list of lessons learned from the experience in our consortium is discussed, from the importance of establishing the proper communication channels for all stakeholders to technical aspects related to –omics data. For federated learning projects focused on secondary use of health data for predictive modeling, encompassing multiple data modalities, a phase of data model convergence is sorely needed to gather different data representations developed in the context of medical research, interoperability of clinical care software, imaging, and –omics analysis into a coherent, unified data model. Our work identifies this need and presents our experience and a list of actionable lessons learned for future work in this direction.}
}
@article{WORNOW2023104319,
title = {APLUS: A Python library for usefulness simulations of machine learning models in healthcare},
journal = {Journal of Biomedical Informatics},
volume = {139},
pages = {104319},
year = {2023},
issn = {1532-0464},
doi = {https://doi.org/10.1016/j.jbi.2023.104319},
url = {https://www.sciencedirect.com/science/article/pii/S1532046423000400},
author = {Michael Wornow and Elsie {Gyang Ross} and Alison Callahan and Nigam H. Shah},
keywords = {Machine learning, Utility, Model deployment, Discrete-event simulation, Clinical workflows, Usefulness assessment},
abstract = {Despite the creation of thousands of machine learning (ML) models, the promise of improving patient care with ML remains largely unrealized. Adoption into clinical practice is lagging, in large part due to disconnects between how ML practitioners evaluate models and what is required for their successful integration into care delivery. Models are just one component of care delivery workflows whose constraints determine clinicians’ abilities to act on models’ outputs. However, methods to evaluate the usefulness of models in the context of their corresponding workflows are currently limited. To bridge this gap we developed APLUS, a reusable framework for quantitatively assessing via simulation the utility gained from integrating a model into a clinical workflow. We describe the APLUS simulation engine and workflow specification language, and apply it to evaluate a novel ML-based screening pathway for detecting peripheral artery disease at Stanford Health Care.}
}
@article{YANG2024167263,
title = {Autophagy and machine learning: Unanswered questions},
journal = {Biochimica et Biophysica Acta (BBA) - Molecular Basis of Disease},
volume = {1870},
number = {6},
pages = {167263},
year = {2024},
issn = {0925-4439},
doi = {https://doi.org/10.1016/j.bbadis.2024.167263},
url = {https://www.sciencedirect.com/science/article/pii/S0925443924002527},
author = {Ying Yang and Zhaoying Pan and Jianhui Sun and Joshua Welch and Daniel J. Klionsky},
keywords = {Artificial intelligence, Lysosome, Macroautophagy, Stress},
abstract = {Autophagy is a critical conserved cellular process in maintaining cellular homeostasis by clearing and recycling damaged organelles and intracellular components in lysosomes and vacuoles. Autophagy plays a vital role in cell survival, bioenergetic homeostasis, organism development, and cell death regulation. Malfunctions in autophagy are associated with various human diseases and health disorders, such as cancers and neurodegenerative diseases. Significant effort has been devoted to autophagy-related research in the context of genes, proteins, diagnosis, etc. In recent years, there has been a surge of studies utilizing state of the art machine learning (ML) tools to analyze and understand the roles of autophagy in various biological processes. We taxonomize ML techniques that are applicable in an autophagy context, comprehensively review existing efforts being taken in this direction, and outline principles to consider in a biomedical context. In recognition of recent groundbreaking advances in the deep-learning community, we discuss new opportunities in interdisciplinary collaborations and seek to engage autophagy and computer science researchers to promote autophagy research with joint efforts.}
}
@article{LI2025113795,
title = {Ribonucleic-Acid protein interaction prediction based on deep learning: A comprehensive survey},
journal = {Applied Soft Computing},
volume = {184},
pages = {113795},
year = {2025},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2025.113795},
url = {https://www.sciencedirect.com/science/article/pii/S1568494625011081},
author = {Danyu Li and Rubing Huang and Chenhui Cui and Dave Towey and Ling Zhou and Jinyu Tian and Bin Zou},
keywords = {Ribonucleic acids, Protein, Interaction prediction, Artificial intelligence application, Deep learning},
abstract = {The interaction between Ribonucleic Acids (RNAs) and proteins, also called RNA Protein Interaction (RPI), governs biological processes, including gene regulation and disease pathogenesis. This comprehensive survey examines Artificial Intelligence (AI) applications in Deep Learning-based RPI Prediction (DL-based RPIP) through eight Research Questions (RQs), analyzing 179 studies (2014–2023). The key findings include: sustained technical evolution through embryonic (2014–2017), accelerated (2018–2022), and expansion phases (2023) (RQ1); hybrid models integrating Graph Neural Networks (GNNs) (for topological interface modeling) and Transformers (for long-range dependencies) achieve state-of-the-art performance (RQ4); pretrained language models enhance small-sample learning, but the cross-species generalization declines sharply with evolutionary distance (RQ5). Critical challenges persist, including data heterogeneity across databases, the scarcity of standardized benchmarks (RQ2), and balancing the trade-off between feature encoding and information preservation (RQ3). Future advancements require biologically informed DL architectures, multi-feature fusion, and rigorous cross-validation to bridge the generalization-interpretability gap (RQ8): This would accelerate the clinical translation of predictive tools (RQ6/RQ7). As the first comprehensive analysis spanning feature encoding, modeling, evaluation, applications, and tools, this work fills a critical gap in the DL-based RPIP literature.}
}
@article{WU202236,
title = {Visual Coding of Intents for Safety of Substation Design},
journal = {Procedia Computer Science},
volume = {208},
pages = {36-44},
year = {2022},
note = {7th International Conference on Intelligent, Interactive Systems and Applications},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2022.10.007},
url = {https://www.sciencedirect.com/science/article/pii/S187705092201448X},
author = {Bing Wu and Yuanbin Song},
keywords = {Intent representation, visual coding, knowledge representation, safety constraint, design review},
abstract = {The automatic safety review of substation design model greatly depends on the formal representation of the safety constraints residing in the building codes written in natural language. In order to overcome the difficulties arising from the hard coding and semantic web approaches, the visual coding method has been studied for representing safety constraints. Nevertheless, very little research explores the formal representation of safety constraints from the query intent viewpoint. Therefore, seven basic query intents are categorized, and simultaneously their mapping with Gremlin query segments is also defined. Then, the visually coding framework is also developed to simplify the representation of query intents. The case study implies that the visual coding of query intents provides an effective and explicit vehicle to describe the safety constraints. In this way, the natural language safety constraints can be automatically converted into Gremlin codes, and moreover the declarative manner of integrating Gremlin queries not only further save time on manually sequencing multiple query tasks, but also can optimize the traversal of graph database.}
}
@article{JAHANIAN2025101672,
title = {Multimodal transformers for joint diagnosis and retrieval from chest X-rays and radiology reports},
journal = {Informatics in Medicine Unlocked},
volume = {58},
pages = {101672},
year = {2025},
issn = {2352-9148},
doi = {https://doi.org/10.1016/j.imu.2025.101672},
url = {https://www.sciencedirect.com/science/article/pii/S2352914825000607},
author = {Mojtaba Jahanian and Abbas Karimi and Nafiseh Osati Eraghi and Faraneh Zarafshan},
keywords = {Multimodal learning, Transformers, Radiology reports, Medical imaging, Deep learning, Clinical NLP},
abstract = {Background:
Radiological diagnosis frequently hinges on the joint interpretation of medical images and their corresponding narrative reports. However, most existing automated approaches treat these modalities in isolation, thereby overlooking their rich semantic interplay—an essential element for robust clinical understanding.
Methods:
We introduce RadFuse, a unified multimodal transformer framework that concurrently analyzes chest radiographs and associated free-text radiology reports. The model integrates a Vision Transformer (ViT) for visual representation learning and ClinicalBERT for processing clinical narratives. These modalities are fused through stacked self-attention and bidirectional cross-attention mechanisms, enabling fine-grained semantic alignment. RadFuse is optimized via a composite objective that combines binary cross-entropy for multi-label disease classification and a contrastive InfoNCE loss for image-text retrieval.
Results:
We evaluate RadFuse on two benchmark datasets—MIMIC-CXR and IU X-ray—across two key tasks: disease classification and cross-modal retrieval. On MIMIC-CXR, RadFuse achieves an AUC of 0.847 and a Recall@10 of 78.2, outperforming prior unimodal and shallow multimodal baselines. Ablation studies demonstrate the critical contribution of cross-attention and contrastive training to the model’s performance.
Conclusion:
RadFuse provides a scalable and interpretable solution for vision-language integration in clinical settings. Its unified architecture enables multi-task learning, facilitates robust semantic grounding, and sets a new benchmark for multimodal modeling in radiology AI.}
}
@article{TIAN2022495,
title = {Evaluation System Framework of Artificial Intelligence Applications in Medical Diagnosis and Treatment},
journal = {Procedia Computer Science},
volume = {214},
pages = {495-502},
year = {2022},
note = {9th International Conference on Information Technology and Quantitative Management},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2022.11.204},
url = {https://www.sciencedirect.com/science/article/pii/S1877050922019147},
author = {Xueqing Tian and Haocheng Tang and Long Cheng and Zirui Liao and Yuxiao Li and Jing He and Ping Ren and Mao You and Zhen Pang},
keywords = {Diagnosis, Treatment, Medical artificial intelligence, Evaluation system applications, Pharmaceutical agent for gray matter volume damage},
abstract = {Current medical artificial intelligence applications and products are confronted the dilemma of lacking standardized practical evaluation guidelines and management methods. This research adopts the Donabedian medical quality management classic model and the DeLone & Mclean benefit evaluation model to develop a basic framework of the medical artificial intelligence application evaluation system for auxiliary diagnosis and treatment and to design the corresponding evaluation procedures. This paper illustrates the overall project framework, followed by a detailed structure and construction process of the model proposed for fast and accurate medical evaluations, NHCKG. NHCKG provides a holistic view of diseases, medical regulations and evaluations. The proposed NHCKG can provide partial solutions to significant challenges faced by knowledge graphs and natural language processing (NLP). Based on the knowledge graph, the structure of a related medical question answering system is elaborated along with its advantages and disadvantages. The evaluation process can take this procedure as a blueprint for exploring standardized and practical evaluation of medical artificial intelligence applications. The process aims to build a concrete measurement basis for medical artificial intelligence products and to promote the healthy and stable development of the medical artificial intelligence industry.}
}
@article{SYED2024100238,
title = {Airline reviews processing: Abstractive summarization and rating-based sentiment classification using deep transfer learning},
journal = {International Journal of Information Management Data Insights},
volume = {4},
number = {2},
pages = {100238},
year = {2024},
issn = {2667-0968},
doi = {https://doi.org/10.1016/j.jjimei.2024.100238},
url = {https://www.sciencedirect.com/science/article/pii/S2667096824000272},
author = {Ayesha Ayub Syed and Ford Lumban Gaol and Alfred Boediman and Widodo Budiharto},
keywords = {Airline reviews, Domain adaptation, Opinion summarization, Review rating, Sentiment classification, Two-stage finetuning},
abstract = {Opinion summarization and sentiment classification are key processes for understanding, analyzing, and leveraging information from customer opinions. The rapid and ceaseless increase in big data of reviews on e-commerce platforms, social media, or review portals becomes a stimulus for the automation of these processes. In recent years, deep transfer learning has opted to solve many challenging tasks in Natural Language Processing (NLP) relieving the hassles of exhaustive training and the requirement of extensive labelled datasets. In this work, we propose frameworks for Abstractive Summarization (ABS) and Sentiment Analysis (SA) of airline reviews using Pretrained Language Models (PLM). The abstractive summarization model goes through two finetuning stages, the first one, for domain adaptation and the second one, for final task learning. Several studies in the literature empirically demonstrate that review rating has a positive correlation with sentiment valence. For the sentiment classification framework, we used the rating value as a signal to determine the review sentiment, and the model is built on top of BERT (Bidirectional Encoder Representations from Transformers) architecture. We evaluated our models comprehensively with multiple metrics. Our results indicate competitive performance of the models in terms of most of the evaluation metrics.}
}
@article{SPIVEY201840,
title = {Discovery in complex adaptive systems},
journal = {Cognitive Systems Research},
volume = {51},
pages = {40-55},
year = {2018},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2018.05.001},
url = {https://www.sciencedirect.com/science/article/pii/S1389041718301062},
author = {Michael J. Spivey},
keywords = {Complex systems, Dynamical systems, Cognitive science, Measurement, Cellular automata},
abstract = {The distinction between ontological ground-truth phenomena and epistemic measurements of those phenomena is discussed and analyzed in the context of complex cognitive systems research. A common style of computational simulation is identified as a Dissect-the-Simulation motif. In this style, a model of cognition is designed and when it generally mimics some cognitive behavior, its own ontic processes (which are fully accessible because it is a simulation) are proposed as potential ontic processes inside actual human cognition. I propose here a second style of modeling, which might be called Measure-the-Simulation. In this style, simulated versions of coarse-grained epistemic measurements are performed on the model with the intent of discovering how those epistemic measurements themselves may transform the actual ontic data, and thus induce a variety of mis-categorizations of phenomena. When our epistemic measurements are better understood, such mis-categorizations can perhaps be avoided. As a proof of concept, Conway’s Game of Life is analyzed and measured with two different types of coarse-grained epistemic measures. Dramatic differences are identified in how a binary coarse-graining, versus a graded coarse-graining, transforms the discovery process for activity patterns on the lattice of this cellular automaton.}
}
@article{DEARAUJOSILVA2021101021,
title = {A survey of Model Driven Engineering in robotics},
journal = {Journal of Computer Languages},
volume = {62},
pages = {101021},
year = {2021},
issn = {2590-1184},
doi = {https://doi.org/10.1016/j.cola.2020.101021},
url = {https://www.sciencedirect.com/science/article/pii/S2590118420300812},
author = {Edson {de Araújo Silva} and Eduardo Valentin and Jose Reginaldo Hughes Carvalho and Raimundo {da Silva Barreto}},
keywords = {Robotics, Model-Driven Engineering, Domain-specific language},
abstract = {Robots are complex to develop due to the diversity of hardware, software components and the absence of common standards. To deal with these problems, Model-Driven Engineering (MDE) is used to systematize the software development. This work aims to provide a comprehensive overview of existing model-based approaches in robotics. We present a classification of the 63 papers selected comparing past expectations with present achievements, and showing that the self-adaptation of robots has been poorly explored. With advances in machine learning, there has been an increase in the possibilities of using model-based approaches aiming at greater autonomy of robotic software.}
}
@article{JUNGEBLOUD2025104543,
title = {Model-based structural and behavioral cybersecurity risk assessment in system designs},
journal = {Computers & Security},
volume = {157},
pages = {104543},
year = {2025},
issn = {0167-4048},
doi = {https://doi.org/10.1016/j.cose.2025.104543},
url = {https://www.sciencedirect.com/science/article/pii/S0167404825002329},
author = {Tino Jungebloud and Nhung H. Nguyen and Dan Dongseong Kim and Armin Zimmermann},
keywords = {Cybersecurity, Model-based systems engineering, Attack graph, UML, Graphical security modeling},
abstract = {Cybersecurity risk assessment has become a critical task in systems development and the operation of complex networked systems. However, current state-of-the-art approaches for detecting vulnerabilities, such as automated security testing or penetration testing, often result in late detection. Thus, there is a growing need for security by design, which involves conducting security-related analyses as early as possible in the system development life cycle. This paper proposes an integrated approach that combines static and dynamic hierarchical model-based security risk assessment. The approach enables early identification of security risks during system design, utilizing various models based on the Unified Modeling Language (UML), with lightweight extensions using profiles and stereotypes to capture security attributes like vulnerabilities and asset values. These security attributes are then used to compute relevant properties, including threat space, possible attack paths, and selected network-based security metrics. To facilitate dynamic security analysis, the UML model is subsequently translated into a deterministic and stochastic Petri net (DSPN). This translation allows for the dynamic analysis and simulation of the system’s state and behavior during an attack, capturing temporal aspects and probabilistic transitions. By representing system components and their interactions as modular Petri nets, the DSPN framework facilitates comprehensive simulation and analysis of possible attack scenarios. This also allows us to estimate time-based security metrics such as the duration required for an attacker to compromise system components. Consequently, this combined approach effectively addresses both static security analysis and dynamic state behavior, providing an integrated understanding of the system’s resilience against cyber threats. A real-world industrial case study illustrates the effectiveness of this approach. The underlying data originates from security assessments performed by Keen Security Labs, which were independently verified by BMW (Cai et al., 2019). Specifically, we present an infotainment system network model as implemented in multiple car models along with corresponding attack and defense models. We then demonstrate how the approach assesses the cybersecurity risk of such in-vehicle networks.}
}
@article{BOMBIERI2023106415,
title = {Machine understanding surgical actions from intervention procedure textbooks},
journal = {Computers in Biology and Medicine},
volume = {152},
pages = {106415},
year = {2023},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2022.106415},
url = {https://www.sciencedirect.com/science/article/pii/S0010482522011234},
author = {Marco Bombieri and Marco Rospocher and Simone Paolo Ponzetto and Paolo Fiorini},
keywords = {Semantic role labeling, Surgical data science, Procedural knowledge, Information extraction, Natural language processing},
abstract = {The automatic extraction of procedural surgical knowledge from surgery manuals, academic papers or other high-quality textual resources, is of the utmost importance to develop knowledge-based clinical decision support systems, to automatically execute some procedure’s step or to summarize the procedural information, spread throughout the texts, in a structured form usable as a study resource by medical students. In this work, we propose a first benchmark on extracting detailed surgical actions from available intervention procedure textbooks and papers. We frame the problem as a Semantic Role Labeling task. Exploiting a manually annotated dataset, we apply different Transformer-based information extraction methods. Starting from RoBERTa and BioMedRoBERTa pre-trained language models, we first investigate a zero-shot scenario and compare the obtained results with a full fine-tuning setting. We then introduce a new ad-hoc surgical language model, named SurgicBERTa, pre-trained on a large collection of surgical materials, and we compare it with the previous ones. In the assessment, we explore different dataset splits (one in-domain and two out-of-domain) and we investigate also the effectiveness of the approach in a few-shot learning scenario. Performance is evaluated on three correlated sub-tasks: predicate disambiguation, semantic argument disambiguation and predicate-argument disambiguation. Results show that the fine-tuning of a pre-trained domain-specific language model achieves the highest performance on all splits and on all sub-tasks. All models are publicly released.}
}
@article{ZHUAN202264,
title = {Proteomic profile of mouse oocytes after vitrification: A quantitative analysis based on 4D label-free technique},
journal = {Theriogenology},
volume = {187},
pages = {64-73},
year = {2022},
issn = {0093-691X},
doi = {https://doi.org/10.1016/j.theriogenology.2022.04.028},
url = {https://www.sciencedirect.com/science/article/pii/S0093691X22001698},
author = {Qingrui Zhuan and Xingzhu Du and Jiachen Bai and Dan Zhou and Yuwen Luo and Hongyu Liu and Wenquan Sun and Pengcheng Wan and Yunpeng Hou and Jun Li and Xiangwei Fu},
keywords = {Mice, Oocyte, Vitrification, Proteome, 4D label-free},
abstract = {Mature oocyte cryopreservation represents an important trend for future fertility preservation, however, the relatively low efficiency has hampered its clinical application. Proteomic profiling is a method of choice for the exploration of the molecular mechanism underlying cryoinjuries. Here, a systematic comparison of protein expression between fresh and vitrified oocytes was performed based on the 4D label-free technique, an informative method with high sensitivity. Our results indicated that the oocyte survival rate was significantly reduced after vitrification. Proteomic results showed that 32 proteins were up-regulated, while 77 proteins were down-regulated in vitrified oocytes compared with the fresh counterparts. Gene Ontology (GO) functional analysis revealed that differentially expressed proteins (DEPs) were involved in metabolism, mitochondrial function, cytoskeleton and other cell functions. Moreover, proteins that participated in signaling transduction mechanisms were the largest category based on Clusters of Orthologous Groups of protein/EuKaryotic Orthologous Groups (COG/KOG) functional classification. In addition, over-expressed DEPs were enriched for “nucleus”, “protein binding”, “membrane”, “cytoplasm” as well as mitochondrial function. Furthermore, we discovered that the DEPs were clustered in pyruvate metabolism, citric acid (TCA) cycle and glucose metabolism by Protein-Protein Interaction (PPI) network evaluation. In conclusion, our data demonstrate that vitrification induces multi-level damages in oocytes, the dynamic proteomic profiling will provide systematic insights into uncovering the mechanism underlying cryoinjuries.}
}
@article{ASTABURUAGA2022100029,
title = {Maps, volunteered geographic information (VGI) and the spatio-discursive construction of nature},
journal = {Digital Geography and Society},
volume = {3},
pages = {100029},
year = {2022},
issn = {2666-3783},
doi = {https://doi.org/10.1016/j.diggeo.2022.100029},
url = {https://www.sciencedirect.com/science/article/pii/S2666378322000046},
author = {Juan Astaburuaga and Michael E. Martin and Agnieszka Leszczynski and JC Gaillard},
keywords = {VGI, Digital representation of nature, Discourse of nature, Poststructuralism, Critical GIScience},
abstract = {This paper interrogates the role that spatial media such as maps and Volunteered Geographic Information (VGI) play in the construction and mobilisation of representations of nature. Drawing on poststructural political ecology, critical cartography, and GIScience, this article engages maps and VGI as discursive mechanisms that solidify and convey meanings and representations of nature tied to broader strategies of commodification. Particularly, we explore how spatial media reproduces and legitimises discursive strategies that rationalise the reconciliation of economic development and conservation through nature-based tourism by producing new ways of nature commodification. Drawing on evidence from Patagonia-Aysén, Chile, this paper examines the intersections between the discourse of nature encoded within institutional tourist maps and advertisements, and within the VGI platform for travellers, TripAdvisor. This illustrative case shows, firstly, how tourist maps and advertisements have contributed to normalising a discursive construction of nature as pristine, grandiose, sublime and wild that has not only secured aesthetics as ontological qualities of nature, but also as embedded values that protect ‘nature’ as a commodity to consume. Secondly, our findings evidence that TripAdvisor emerges out of this context as content that mobilises individual perceptions of and narratives about Patagonian nature that is already mediated by this dominant discourse. This dynamic suggests that VGI constitutes a new form of discursive power that digitally reproduces and mobilises a dominant discourse of nature, (re)producing what we term ‘discursive digital nature’.}
}
@article{HERRMANNPILLATH2018212,
title = {The Case for a New Discipline: Technosphere Science},
journal = {Ecological Economics},
volume = {149},
pages = {212-225},
year = {2018},
issn = {0921-8009},
doi = {https://doi.org/10.1016/j.ecolecon.2018.03.024},
url = {https://www.sciencedirect.com/science/article/pii/S0921800917315677},
author = {Carsten Herrmann-Pillath},
keywords = {Anthropocene, Technosphere, Anthropocentrism, Artefacts, General theory of evolution, Functions, Networks, Agency, Energy and information, Thermodynamics, Maximum power, Categorical imperative},
abstract = {This paper submits the philosophical case for establishing ‘technosphere science’ that draws on results of many other disciplines, reaching from physics to the social sciences and humanities. I present claims about the type of entities that are studied by technosphere science and their causal relationships, and introduce central organizing concepts, such as ‘information’ and ‘function’. Agency is no longer seen as a property exclusive to humans, but as being distributed in networks of ontologically diverse entities. Technosphere science draws on various uses of the concept of ‘networks’ across disciplines, such as scaling laws and builds on a universal evolutionary framework that generalizes over biological evolution. In this perspective, the economy is the medium by which human action becomes functional relative to the reproduction and growth of the technosphere. I conclude with showing how human autonomy and ethical commitments remain possible.}
}
@article{GRECHI2025112251,
title = {Model-driven safety and security co-analysis: A systematic literature review},
journal = {Journal of Systems and Software},
volume = {220},
pages = {112251},
year = {2025},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2024.112251},
url = {https://www.sciencedirect.com/science/article/pii/S0164121224002954},
author = {Victor Luiz Grechi and André Luiz {de Oliveira} and Rosana T. Vaccare Braga},
keywords = {Safety, Security, Safety and security co-analysis, Model-driven engineering, Safety–critical systems, Security-critical systems},
abstract = {Failures in systems that can lead to loss of life, property, and environmental damage, make them safety–critical systems requiring the analysis and demonstration of dependability properties. When those systems can connect/disconnect to each other, it raises security issues, making them also security-critical. Safety and security are crucial in safety- and security-critical design. The complexity of a connected world impacts safety and security, requiring dependability assurance processes in compliance with standards like ISO 26262, ISO 21434, IEC 61511, and IEC 61508. Model-Driven Engineering (MDE) plays a significant role by using models to represent and analyze safety and security properties, facilitating their integration. This study aims to explore the role of MDE in supporting safety and security co-engineering through a Systematic Literature Review. We identified 119 studies that were analyzed and categorized based on the life-cycle phase, risk assessment activity, application domain, methodology type (integrated or unified), methodology goal (co-engineering or cross-fertilization), measurement (qualitative, quantitative, or both), modeling approach, representation, evaluation method, and supporting tools. Though model-driven contributions are less prevalent than model-based ones, tools widely support them. Studies primarily focus on transportation (especially automotive) and industrial domains, but there is potential for broader participation with increasing IoT adoption. Editor’s note: Open Science material was validated by the Journal of Systems and Software Open Science Board.}
}
@article{CANNA2020112725,
title = {Dealing with the unknown. Functional neurological disorder (FND) and the conversion of cultural meaning},
journal = {Social Science & Medicine},
volume = {246},
pages = {112725},
year = {2020},
issn = {0277-9536},
doi = {https://doi.org/10.1016/j.socscimed.2019.112725},
url = {https://www.sciencedirect.com/science/article/pii/S0277953619307208},
author = {Maddalena Canna and Rebecca Seligman},
keywords = {Functional neurological disorder, Somatization, Psychogenic non-epileptic seizures (PNES), Cultural meaning, Conversion, Interoceptive affordances, Healthcare, Medical ontology},
abstract = {Functional Neurological Disorder (FND), otherwise known as Conversion Disorder, is characterized by abnormal sensory or motor symptoms that are determined to be “incompatible” with neurological disease. FND patients are a challenge for contemporary medicine. They experience high levels of distress, disability, and social isolation, yet a large proportion of those treated do not get better. Patients with FNDs are often misdiagnosed and suffer from stigma, dysfunctional medical encounters and scarcity of adequate treatments. In this paper we argue that an anthropological understanding of these phenomena is needed for improving diagnosis and therapies. We argue that cultural meaning is pivotal in the development of FND on three levels. 1) The embodiment of cultural models, as shared representations and beliefs about illnesses shape the manifestation of symptoms and the meanings of sensations; 2) The socialization of personal trauma and chronic stress, as the way in which individuals are socially primed to cope or to reframe personal trauma and chronic stress affects bodily symptoms; 3) Moral judgment, as stigma and ethical evaluations of symptoms impact coping abilities and resilience. In particular, we focus on the disorder known as PNES (Psychogenic-Non-Epileptic Seizure) to show how cultural meaning co-determines the development of such seizures. We introduce the notion of interoceptive affordances to account for the cultural scaffolding of patients’ bodily experiences. Finally, we suggest that effective treatments of FND must act upon meaning in all of its aspects, and treatment adequacy must be assessed according to the cultural diversity of patients.}
}
@article{XIA2024e37048,
title = {Epithelial cell-related prognostic risk model in breast cancer based on single-cell and bulk RNA sequencing},
journal = {Heliyon},
volume = {10},
number = {17},
pages = {e37048},
year = {2024},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2024.e37048},
url = {https://www.sciencedirect.com/science/article/pii/S2405844024130794},
author = {Man-zhi Xia and Hai-chao Yan},
keywords = {Breast cancer, Epithelial cell, Single-cell sequencing, Bulk RNA sequencing, Prognosis},
abstract = {Objective
This study aims to construct an epithelial cell-related prognostic risk model for breast cancer (BRCA) and explore its significance.
Methods
GSE42568, GSE10780, GSE245601, and TCGA-BRCA datasets were sourced from public databases. Epithelial cell-related differentially expressed genes were identified using single-cell data analysis. Venn diagrams determined the intersecting genes between epithelial cell-related and BRCA-related genes. Batch Kaplan-Meier (K-M) survival analysis identified core intersecting genes for BRCA overall survival. Consensus clustering, enrichment, LASSO, and COX regression analyses were performed on the core intersecting genes, and then a prognostic risk model was constructed. The diagnostic and prognostic effectiveness of the risk model was subsequently evaluated and immune infiltration analysis was conducted. Finally, qRT-PCR was used to verify the expression of genes in the risk model.
Results
There were 374 intersecting genes between epithelial cell-related and BRCA-related genes, among which 51 core intersecting genes were associated with BRCA prognosis. Consensus clustering categorized TCGA-BRCA into C1 and C2, with shared regulation of the estrogen signaling pathway. Three genes (DIRC3, SLC6A2, TUBA3D) were independent predictors of BRCA prognosis, forming the basis for a risk model. Except for exhibiting satisfactory diagnostic efficacy, the risk score elevation correlated with poor prognosis, elevated matrix, immune, and ESTIMATE scores, and negative correlation with microsatellite instability. The in vitro results confirmed the differential expression levels of DIRC3, SLC6A2, and TUBA3D.
Conclusion
The prognostic risk model associated with epithelial cells demonstrates effective diagnostic performance in BRCA, serving as an independent prognostic factor for BRCA patients. Additionally, it exhibits a correlation with immune scores.}
}
@article{ZHAO2025105660,
title = {Automated information mining in hazardous chemical accident reporting: An improved deep learning approach},
journal = {Journal of Loss Prevention in the Process Industries},
volume = {97},
pages = {105660},
year = {2025},
issn = {0950-4230},
doi = {https://doi.org/10.1016/j.jlp.2025.105660},
url = {https://www.sciencedirect.com/science/article/pii/S0950423025001184},
author = {Kai Zhao and Lining Wan and Xilei Lu and Jun Zhao and Fei Chen and Miao He and Jinhao Gao and Qibo Wang and Linlin Zhang and Li Zhang},
keywords = {Accident reports, Named entity recognition, Topic mining, Pre-trained, Hazardous chemicals, Safety},
abstract = {Mining and accumulating lessons learned from incident reports, accurately identifying and extracting accident knowledge, can help managers recognize patterns, analyze common attributes, and thus prevent the recurrence of similar incidents. Due to the limitations of unstructured or semi-structured text records, current hazardous chemical accident research heavily relies on expert evaluations, often resulting in inefficiency, lack of intelligence, and subjectivity. To overcome this limitation, we propose an accident analysis framework that combines deep learning-based Named Entity Recognition (NER) and topic mining algorithms. First, we employ a RoBERTa-BiLSTM-Attention-CRF method based on a pre-trained model to automatically recognize and extract information from accident reports according to predefined accident entities. Second, we construct a dictionary specific to the hazardous chemicals domain and apply the Latent Dirichlet Allocation (LDA) model to analyze the causes of accidents within the “CAUSE” entity, thereby deriving the hazardous themes implied in the accidents. Finally, we validate the model on a self-constructed hazardous chemical named entity recognition incident report dataset (HCNER). The research findings indicate that the methodology proposed in this study effectively addresses the challenges associated with dispersed textual information, specialized terminology, and data formatting in the digital processing of hazardous chemical incidents. This advancement propels the development within the domain of hazardous chemical safety management and serves as a viable approach for investigating the causes of such incidents.}
}
@article{VANDERSPEK20221283,
title = {Inherited variants in CHD3 show variable expressivity in Snijders Blok-Campeau syndrome},
journal = {Genetics in Medicine},
volume = {24},
number = {6},
pages = {1283-1296},
year = {2022},
issn = {1098-3600},
doi = {https://doi.org/10.1016/j.gim.2022.02.014},
url = {https://www.sciencedirect.com/science/article/pii/S1098360022006724},
author = {Jet {van der Spek} and Joery {den Hoed} and Lot {Snijders Blok} and Alexander J.M. Dingemans and Dick Schijven and Christoffer Nellaker and Hanka Venselaar and Galuh D.N. Astuti and Tahsin Stefan Barakat and E. Martina Bebin and Stefanie Beck-Wödl and Gea Beunders and Natasha J. Brown and Theresa Brunet and Han G. Brunner and Philippe M. Campeau and Goran Čuturilo and Christian Gilissen and Tobias B. Haack and Irina Hüning and Ralf A. Husain and Benjamin Kamien and Sze Chern Lim and Luca Lovrecic and Janine Magg and Ales Maver and Valancy Miranda and Danielle C. Monteil and Charlotte W. Ockeloen and Lynn S. Pais and Vasilica Plaiasu and Laura Raiti and Christopher Richmond and Angelika Rieß and Eva M.C. Schwaibold and Marleen E.H. Simon and Stephanie Spranger and Tiong Yang Tan and Michelle L. Thompson and Bert B.A. {de Vries} and Ella J. Wilkins and Marjolein H. Willemsen and Clyde Francks and Lisenka E.L.M. Vissers and Simon E. Fisher and Tjitske Kleefstra},
keywords = {CHD3, Inherited variants, Neurodevelopmental disorder, Reduced penetrance, Variable expressivity},
abstract = {Purpose
Common diagnostic next-generation sequencing strategies are not optimized to identify inherited variants in genes associated with dominant neurodevelopmental disorders as causal when the transmitting parent is clinically unaffected, leaving a significant number of cases with neurodevelopmental disorders undiagnosed.
Methods
We characterized 21 families with inherited heterozygous missense or protein-truncating variants in CHD3, a gene in which de novo variants cause Snijders Blok-Campeau syndrome.
Results
Computational facial and Human Phenotype Ontology–based comparisons showed that the phenotype of probands with inherited CHD3 variants overlaps with the phenotype previously associated with de novo CHD3 variants, whereas heterozygote parents are mildly or not affected, suggesting variable expressivity. In addition, similarly reduced expression levels of CHD3 protein in cells of an affected proband and of healthy family members with a CHD3 protein-truncating variant suggested that compensation of expression from the wild-type allele is unlikely to be an underlying mechanism. Notably, most inherited CHD3 variants were maternally transmitted.
Conclusion
Our results point to a significant role of inherited variation in Snijders Blok-Campeau syndrome, a finding that is critical for correct variant interpretation and genetic counseling and warrants further investigation toward understanding the broader contributions of such variation to the landscape of human disease.}
}
@article{WITT2023799,
title = {Application of a product-centred process-independent meta-model for multi-stage production data to enable predictive quality for additive manufacturing},
journal = {Procedia CIRP},
volume = {118},
pages = {799-804},
year = {2023},
note = {16th CIRP Conference on Intelligent Computation in Manufacturing Engineering},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2023.06.137},
url = {https://www.sciencedirect.com/science/article/pii/S2212827123003645},
author = {Ronja Witt and Anna-Lena Knott and Simon Cramer and Robert H. Schmitt},
keywords = {Additive manufacturing, Data analytics, Meta-model, Medical technology, Process data, Predictive quality, Digital shadow, Smart production},
abstract = {In multi-step production processes with countless information sources, it is vital to accompany process data with meta-information to enable an efficient aggregation of the collected data. The relationships of process- and meta-data has been described through a previously presented flexible and process-independent meta-model, which is especially suitable for predictive quality applications. We propose an enhancement for the attribution of process parameters and quality characteristics. The two novel meta-classes provide information about tolerances and hence increase the process and product model. Our results show how the refined meta-model enhances the mapping of an additive manufacturing process. Further, we introduce an industry-ready implementation and make the code accessible on Github.}
}
@article{LIANG2019e455,
title = {Galectin-9: A Predictive Biomarker Negatively Regulating Immune Response in Glioma Patients},
journal = {World Neurosurgery},
volume = {132},
pages = {e455-e462},
year = {2019},
issn = {1878-8750},
doi = {https://doi.org/10.1016/j.wneu.2019.08.117},
url = {https://www.sciencedirect.com/science/article/pii/S1878875019322739},
author = {Tingyu Liang and Xiaoxuan Wang and Fang Wang and Enshan Feng and Gan You},
keywords = {GAL-9, Glioma, Immune response, Prognosis},
abstract = {Background
Glioma is the most frequent primary brain tumor. Immunotherapy is one of the most promising therapeutic approaches for gliomas. T cell immunoglobulin domain and mucin domain-3 can induce the malignancy of gliomas. The function of galectin-9 (GAL-9), as one of the ligands of T cell immunoglobulin domain and mucin domain-3, in glioma has remained elusive. The aim of this study was to characterize the expression of GAL-9 in patients with glioma.
Methods
This study enrolled 1292 patients with glioma from the GSE 16011 array set, the Chinese Glioma Genome Atlas, and The Cancer Genome Atlas datasets. Kaplan-Meier analysis was undertaken to explore the prognostic value of GAL-9. Graphpad software and R language were used for statistical analysis.
Results
Expression of GAL-9 was highly correlated with major clinical and molecular features. Patients with high expression of GAL-9 were more susceptible to development of malignant tumors. Gene Ontology analysis revealed that expression of GAL-9 was closely associated with function of immune response in glioma. Clinically, the results of Kaplan-Meier analysis showed that expression of GAL-9 was negatively associated with overall survival in all grades of glioma including high-grade gliomas. High expression of GAL-9 was an independent indicator of poor prognosis.
Conclusions
Our results highlight the pivotal role of GAL-9 in regulation of immune suppressive features of gliomas and indicate that GAL-9 is a promising target for cancer immunotherapy and may lead to development of further therapies.}
}
@article{ALNUAIMI2020589,
title = {ICT ethics-related cognition among undergraduate students},
journal = {Journal of Information, Communication and Ethics in Society},
volume = {18},
number = {4},
pages = {589-607},
year = {2020},
issn = {1477-996X},
doi = {https://doi.org/10.1108/JICES-08-2019-0097},
url = {https://www.sciencedirect.com/science/article/pii/S1477996X20000087},
author = {Maryam Nasser Al-Nuaimi and AbdelMajid Bouazza and Maher M. Abu-Hilal},
keywords = {Privacy, Cognition, Grounded theory, Undergraduates, Academic integrity, ICT ethics},
abstract = {Purpose
Moor (1985) designated two major problem sources typifying the social and ethical implications of computer technologies, namely, “policy vacuum” and “conceptual muddles.” Motivated by Moor’s seminal definition and Floridi’s (2013) conceptualization of information and communication technologies (ICTs) as re-ontologizing technologies, this study aims to explore Omani undergraduates’ cognition regarding ICT ethics.
Design/methodology/approach
Adopting a grounded theory approach for the constant comparative thematic analysis, the constituents of ICT ethics-related cognition among undergraduates and influencing factors were scrutinized. Qualitative data were gathered via focus group discussions with undergraduates and interviews with academics and information systems professionals at Sultan Qaboos University.
Findings
In total, 10 thematic categories revolving around a core category, constructing conceptual perceptions of and attitudes toward the realms constituting ICT ethics using an ontological, object-oriented approach, emerged from the comparative analysis. Undergraduates were found to adopt an applied approach when defining professional ICT ethics codes and policies, with a particular focus on information privacy and integrity.
Research limitations/implications
This qualitative study was conducted at a single research site. This may restrict the generalizability of the findings. Postgraduates were not considered when designing this qualitative inquiry.
Originality/value
The findings of the study hold theoretical and methodological significance with regard to ICT ethics-related cognition in the era following the fourth industrial revolution by sustaining feminist ethics in this research. Ultimately, the study developed a substantive theory scrutinizing the constitutive elements of ICT ethics-related cognition among Generation Z.}
}
@article{AN2025100250,
title = {Complex adaptive systems science in the era of global sustainability crisis},
journal = {Geography and Sustainability},
volume = {6},
number = {1},
pages = {100250},
year = {2025},
issn = {2666-6839},
doi = {https://doi.org/10.1016/j.geosus.2024.09.011},
url = {https://www.sciencedirect.com/science/article/pii/S2666683924001032},
author = {Li An and B.L. Turner and Jianguo Liu and Volker Grimm and Qi Zhang and Zhangyang Wang and Ruihong Huang},
keywords = {Social-environmental systems, Complex adaptive systems, Sustainability science, Agent-based models, Artificial intelligence, Data science},
abstract = {A significant number and range of challenges besetting sustainability can be traced to the actions and interactions of multiple autonomous agents (people mostly) and the entities they create (e.g., institutions, policies, social network) in the corresponding social-environmental systems (SES). To address these challenges, we need to understand decisions made and actions taken by agents, the outcomes of their actions, including the feedbacks on the corresponding agents and environment. The science of complex adaptive systems—complex adaptive systems (CAS) science—has a significant potential to handle such challenges. We address the advantages of CAS science for sustainability by identifying the key elements and challenges in sustainability science, the generic features of CAS, and the key advances and challenges in modeling CAS. Artificial intelligence and data science combined with agent-based modeling promise to improve understanding of agents’ behaviors, detect SES structures, and formulate SES mechanisms.}
}
@article{DOUVILLE2024105350,
title = {Reality and imagination intertwined: A sensorimotor paradox interpretation},
journal = {BioSystems},
volume = {246},
pages = {105350},
year = {2024},
issn = {0303-2647},
doi = {https://doi.org/10.1016/j.biosystems.2024.105350},
url = {https://www.sciencedirect.com/science/article/pii/S0303264724002351},
author = {Clémence Ortega Douville},
abstract = {As a hypothesis on the origins of mind and language, the evolutionary theory of the sensorimotor paradox suggests that capacities for imagination, self-representation and abstraction would operate from a dissociation in what is known as the forward model. In some studies, sensory perception is understood as a system of prediction and confirmation (feedforward and feedback processes) that would share common yet distinct and overlapping neural networks with mental imagery. The latter would then mostly operate through internal feedback processes. The hypothesis of our theory is that dissociation and parallelism between those processes would make it less likely for imaginary prediction to match and simultaneously coincide with any sensory feedback, contradicting the stimulus/response pattern. The gap between the two and the effort required to maintain this gap, born from the development of bipedal stance and a radical change to our relation to our own hands, would be the very structural foundation to our capacity to elaborate abstract thoughts, by partially blocking and inhibiting motor action. Mental imagery would structurally be dissociated from perception, though maintaining an intricated relation of interdependence. Moreover, the content of the images would be subordinate to their function as emotional regulators, prioritising consistency with some global, conditional and socially learnt body-image. As a higher-level and proto-aesthetic function, we can speculate that the action and instrumentalisation of dissociating imagination from perception would become the actual prediction and their coordination, the expected feedback.}
}
@article{ROCHE2021106582,
title = {Understanding why impact assessment fails; a case study of theory and practice from Wafi-Golpu, Papua New Guinea},
journal = {Environmental Impact Assessment Review},
volume = {89},
pages = {106582},
year = {2021},
issn = {0195-9255},
doi = {https://doi.org/10.1016/j.eiar.2021.106582},
url = {https://www.sciencedirect.com/science/article/pii/S0195925521000329},
author = {Charles Roche and Martin Brueckner and Nawasio Walim and Howard Sindana and Eugene John},
keywords = {Impact assessment (IA), Mining, Community based impact assessment (CBIA), Indigenous Knowledge, Papua New Guinea (PNG)},
abstract = {From an instrumental or management perspective, impact assessment (IA) is a process of identifying impacts, finding solutions and achieving project approval. A recipient community, however, has a completely different perspective. For them the IA is about living with impacts, individually and collectively, perhaps over generations, and contested processes of self-determination, consultation and exclusion. IA practitioners live in a third space, usually bound to the proponent but also aware of responsibilities to communities and eco-systems. Seeking to better understand how IA is practiced and experienced, we explore the proposed Wafi-Golpu mine, located in the Morobe Province of Papua New Guinea. Determinably focused on local effects we situate the proposed mine within the context of the national mining experience and discuss how IA practices see local and/or Indigenous communities. We find that the Wafi-Golpu IA is blind to local ways of being and seeing the world, with an opaque and arbitrary assessment that reflects its technical and Western basis and bias. We finish with observations about the proposed Wafi-Golpu mine and IA that is relevant to the approval process, as well as making a decolonial, Southern contribution to IA theory and practice, extractive industry regulation and mining-affected communities elsewhere.}
}
@article{ZHOU2024888,
title = {Deciphering the Underlying Mechanisms of Sanleng-Ezhu for the Treatment of Idiopathic Pulmonary Fibrosis Based on Network Pharmacology and Single-cell RNA Sequencing Data},
journal = {Current Computer-Aided Drug Design},
volume = {20},
number = {6},
pages = {888-910},
year = {2024},
issn = {1573-4099},
doi = {https://doi.org/10.2174/1573409920666230808120504},
url = {https://www.sciencedirect.com/science/article/pii/S1573409924000119},
author = {Xianqiang Zhou and Fang Tan and Suxian Zhang and Tiansong Zhang},
keywords = { (SL),  (EZ), Idiopathic Pulmonary Fibrosis (IPF), network analysis, single-cell RNA sequencing, molecular docking, animal experiment},
abstract = {Aims
To decipher the underlying mechanisms of Sanleng-Ezhu for the treatment of idiopathic pulmonary fibrosis based on network pharmacology and single-cell RNA sequencing data.
Background
Idiopathic Pulmonary Fibrosis (IPF) is the most common type of interstitial lung disease. Although the combination of herbs Sanleng (SL) and Ezhu (EZ) has shown reliable efficacy in the management of IPF, its underlying mechanisms remain unknown.
Methods
Based on LC-MS/MS analysis and the Traditional Chinese Medicine Systems Pharmacology Database and Analysis Platform (TCMSP) database, we identified the bioactive components of SL-EZ. After obtaining the IPF-related dataset GSE53845 from the Gene Expression Omnibus (GEO) database, we performed the differential expression analysis and the weighted gene co-expression network analysis (WGCNA), respectively. We obtained lowly and highly expressed IPF subtype gene sets by comparing Differentially Expressed Genes (DEGs) with the most significantly negatively and positively related IPF modules in WGCNA. Subsequently, we performed Gene Ontology (GO), and Kyoto Encyclopedia of Genes and Genomes (KEGG) enrichment analyses on IPF subtype gene sets. The low- and high-expression MCODE subgroup feature genes were identified by the MCODE plug-in and were adopted for Disease Ontology (DO), GO, and KEGG enrichment analyses. Next, we performed the immune cell infiltration analysis of the MCODE subgroup feature genes. Single-cell RNA sequencing analysis demonstrated the cell types which expressed different MCODE subgroup feature genes. Molecular docking and animal experiments validated the effectiveness of SL-EZ in delaying the progression of pulmonary fibrosis.
Results
We obtained 5 bioactive components of SL-EZ as well as their corresponding 66 candidate targets. After normalizing the samples of the GSE53845 dataset from the GEO database source, we obtained 1907 DEGs of IPF. Next, we performed a WGCNA analysis on the dataset and got 11 modules. Notably, we obtained 2 IPF subgroups by contrasting the most significantly up- and down-regulated modular genes in IPF with DEGs, respectively. The different IPF subgroups were compared with drug-candidate targets to obtain direct targets of action. After constructing the protein interaction networks between IPF subgroup genes and drug candidate targets, we applied the MCODE plug-in to filter the highest-scoring MCODE components. DO, GO, and KEGG enrichment analyses were applied to drug targets, IPF subgroup genes, and MCODE component signature genes. In addition, we downloaded the single-cell dataset GSE157376 from the GEO database. By performing quality control and dimensionality reduction, we clustered the scattered primary sample cells into 11 clusters and annotated them into 2 cell subtypes. Drug sensitivity analysis suggested that SL-EZ acts on different cell subtypes in IPF subgroups. Molecular docking revealed the mode of interaction between targets and their corresponding components. Animal experiments confirmed the efficacy of SL-EZ.
Conclusion
We found SL-EZ acted on epithelial cells mainly through the calcium signaling pathway in the lowly-expressed IPF subtype, while in the highly-expressed IPF subtype, SL-EZ acted on smooth muscle cells mainly through the viral infection, apoptosis, and p53 signaling pathway.}
}
@incollection{RENZ2021362,
title = {Clinical Applications of Metabolic Models in SBML Format},
editor = {Olaf Wolkenhauer},
booktitle = {Systems Medicine},
publisher = {Academic Press},
address = {Oxford},
pages = {362-371},
year = {2021},
isbn = {978-0-12-816078-7},
doi = {https://doi.org/10.1016/B978-0-12-801238-3.11524-7},
url = {https://www.sciencedirect.com/science/article/pii/B9780128012383115247},
author = {Alina Renz and Reihaneh Mostolizadeh and Andreas Dräger},
keywords = {Cancer treatment, Clinical application, Modeling, Personalized medicine, SBML, Systems biology, Systems medicine},
abstract = {The diagnosis and prognosis of diseases are still a severe problem in the clinical environment. It remains challenging to find the right drug with only minimal side effects while maximizing the patient׳s outcome. The fact that individual patients respond differently to the same treatment exacerbates this situation. For these reasons, it has become increasingly important to look at the intracellular environment. This intricate biological system with thousands of interactions is too complex to be fully comprehended. A promising way to analyze biological systems is by applying computer modeling and simulations. In many studies, such methods have successfully demonstrated their ability to describe and visualize biological behavior and complexity. Due to the increasing use of computational models in systems biology, the development of a standard model interchange language is prerequisite. A standardized modeling language enables clinicians, biologists, and bioinformaticians to exchange models between various software tools. Furthermore, incorporating clinical data into such models becomes straightforward and applicable to a wide range of analyses. The Systems Biology Markup Language (SBML) constitutes the most commonly accepted representation format. A plethora of databases provides systems biology models in SBML format for download. Various tools are available for working with these models, including editing, visualization, simulation, the de novo model construction, and more. This chapter introduces fundamental aspects of systems biology modeling in personalized medicine, including the basics of SBML and selected software applications. A use-case example of modeling glycolysis in human cancer cells concludes the discussion.}
}
@article{ARYA2024,
title = {FANE:},
journal = {International Journal on Semantic Web and Information Systems},
volume = {20},
number = {1},
year = {2024},
issn = {1552-6283},
doi = {https://doi.org/10.4018/IJSWIS.360785},
url = {https://www.sciencedirect.com/science/article/pii/S1552628324001388},
author = {Varsha Arya and Razaz Waheeb Attar and Ahmed Alhomoud and Mario Casillo and Francesco Colace and Dajana Conte and Marco Lombardi and Domenico Santaniello and Carmine Valentino},
keywords = {Fake News, Fake News Detection, Information Reliability, Natural Language Processing (NLP), Bayesian Networks, Social Media, Information Veracity, Information Systems},
abstract = {ABSTRACT
In today’s society, the continuous exchange of vast amounts of information, often irrelevant or misleading, highlights the need for greater awareness to distinguish between accurate and false information. Recognizing the reliability of information is critical to limiting the spread of fake news, a pervasive problem affecting various sectors, influencing public opinion, and shaping decisions in health care, politics, culture, and history. This paper proposes a methodology to assess the veracity of information, leveraging natural language processing (NLP) and probabilistic models to extract relevant features and predict the reliability of content. The features analyzed include semantic, syntactic, and social dimensions. The proposed methodology was tested using datasets that include social media news and comments captured during the lockdown due to COVID-19, providing relevant context for the analysis. Experimental validation of these different datasets yields promising results, demonstrating the effectiveness of the proposed approach.}
}
@article{WEI2025110873,
title = {The use of knowledge graphs for drug repurposing: From classical machine learning algorithms to graph neural networks},
journal = {Computers in Biology and Medicine},
volume = {196},
pages = {110873},
year = {2025},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2025.110873},
url = {https://www.sciencedirect.com/science/article/pii/S0010482525012247},
author = {Siqi Wei and Christo Sasi and Jelle Piepenbrock and Martijn A. Huynen and Peter A.C. {’t Hoen}},
keywords = {Drug repositioning, Knowledge graph, Graph convolutional networks, Machine learning, Deep learning},
abstract = {Drug repurposing, the development of new therapeutic indications for existing drugs, is a promising strategy in drug development. Computational methods and artificial intelligence may be used to identify new drug repurposing candidates. Knowledge graph (KG) based methods have emerged as powerful tools for modeling and predicting drug–disease relationships, because of their intuitive way of exploiting biomedical knowledge and data. This review provides an overview of computational drug repurposing methods based on KGs. The motivation for adopting KG-based knowledge representations, traditional machine learning and deep learning approaches are discussed, followed by an analysis of selected tools, their construction, link prediction capabilities, and inherent advantages and limitations.}
}
@article{CHENG2025103098,
title = {Enhancing diagnosis prediction with adaptive disease representation learning},
journal = {Artificial Intelligence in Medicine},
volume = {163},
pages = {103098},
year = {2025},
issn = {0933-3657},
doi = {https://doi.org/10.1016/j.artmed.2025.103098},
url = {https://www.sciencedirect.com/science/article/pii/S0933365725000338},
author = {Hengliang Cheng and Shibo Li and Tao Shen and Weihua Li},
keywords = {Deep learning, Diagnosis prediction, Electronic health records},
abstract = {Diagnosis prediction predicts which diseases a patient is most likely to suffer from in the future based on their historical electronic health records. The time series model can better capture the temporal progression relationship of patient diseases, but ignores the semantic correlation between all diseases; in fact, multiple diseases that are often diagnosed at the same time reflect hidden patterns that are conducive to diagnosis, so predefined global disease co-occurrence graph can help the model understand disease relationships. But it may contain a lot of noise and ignore the semantic adaptation of the disease under the diagnosis target. To this end, we propose a graph-driven end-to-end framework, named Adaptive Disease Representation Learning (ADRL), obtain disease representation after learning complex disease relationships, and then use it to improve diagnosis prediction performance. This model introduces an adaptive mechanism to dynamically adjust and optimize disease relationships by performing self-supervised perturbations on a predefined global disease co-occurrence graph, thereby learning a global disease relationship graph that contains complex semantic association information between diseases. The computational burden of adaptive global disease graph can be further alleviated by the proposed SVD-based accelerator. Finally, experimental results on two real-world EHR datasets show that the proposed model outperforms existing models in diagnosis prediction.}
}
@article{AGARWAL2022100498,
title = {A systematic literature review on web service clustering approaches to enhance service discovery, selection and recommendation},
journal = {Computer Science Review},
volume = {45},
pages = {100498},
year = {2022},
issn = {1574-0137},
doi = {https://doi.org/10.1016/j.cosrev.2022.100498},
url = {https://www.sciencedirect.com/science/article/pii/S157401372200034X},
author = {Neha Agarwal and Geeta Sikka and Lalit Kumar Awasthi},
keywords = {Systematic literature review, Web services, Clustering, Web API, Natural language processing},
abstract = {With the advancement of web 2.0 and the development of the Internet of Things (IoT), all tasks can be handled with the help of handheld devices. Web APIs or web services are providing immense power to IoT and are working as a backbone in the successful journey of IoT. Web services can perform any task on a single click event, and these are available over the internet in terms of quantity, quality, and variety. It leads to the requirement of service management in the service repository. The well-managed and structured service repository is still challenging as services are dynamic, and documentation is limited. It is also not a piece of cake to discover, select and recommend services easily from a pool of services. Web service clustering (WSC) plays a vital role in enhancing the service discovery, selection, and recommendation process by analyzing the similarity among services. In this paper, with a systematic process total of 84 research papers are selected, and different state-of-the-art techniques based on web service clustering are investigated and analyzed. Furthermore, this Systematic Literature Review (SLR) also presents the various mandatory and optional steps of WSC, evaluation measures, and datasets. Research challenges and future directions are also identified, which will help the researchers to provide innovative solutions in this area.}
}
@article{ANDERSEN2021990,
title = {Grammar and social action: two schools of thought in knowledge organization research},
journal = {Journal of Documentation},
volume = {77},
number = {4},
pages = {990-1002},
year = {2021},
issn = {0022-0418},
doi = {https://doi.org/10.1108/JD-11-2020-0191},
url = {https://www.sciencedirect.com/science/article/pii/S0022041821000333},
author = {Jack Andersen},
keywords = {Digital communications, Digital culture, Knowledge organization, Digital media, Social action, Grammar approach},
abstract = {Purpose
The purpose is to map and discuss two schools of thought in knowledge organization research. The objective of this mapping is to examine the conceptual views and the derived questions and concerns voiced in these two schools and whether they fit with concerns in contemporary digital culture.
Design/methodology/approach
The approach is a comparative analysis and discussion.
Findings
The comparative analysis and discussion point out the different sets of questions the two schools are concerned with distinct epistemological and ontological implications.
Originality/value
The originality of this article is the naming, mapping and discussion of two schools of research in knowledge with a view to how they fit with problems of ordering, archiving and searching in digital culture.}
}
@article{WIKLUNDGUSTIN2020102870,
title = {Nursing teachers’ experiences of the process of recovery while participating in a group programme for reducing work-related stress: A qualitative content analysis},
journal = {Nurse Education in Practice},
volume = {48},
pages = {102870},
year = {2020},
issn = {1471-5953},
doi = {https://doi.org/10.1016/j.nepr.2020.102870},
url = {https://www.sciencedirect.com/science/article/pii/S1471595318306942},
author = {Lena {Wiklund Gustin} and Lennart Fredriksson and Sarah G. Rakovshik},
keywords = {Nursing theory, Recovery, Self-compassion, Work-related stress},
abstract = {Work-related stress is an increasing health problem among nursing teachers, contributing to health problems, disengagement and poor job satisfaction. Negative coping strategies impact on both teachers' and students' teaching-learning experiences. Several interventions have been developed to address work-related stress. There has been less focus on how nursing teachers can learn to recover from work-related stress before it has severe consequences for their health, and to understand it from a nursing perspective. The aim of this study was to explore how nursing teachers who participated in a cognitive relational group programme experienced the process of recovery from work-related stress. Data were collected by means of three focus groups and subjected to qualitative content analysis, resulting in three categories: relatedness, evoking the inner caregiver, and re-orientation in life. These categories were reflected on in relation to Benner and Wrubel's “primacy of caring” and synthesised into a metaphorical theme: “finding one's footings”. The findings imply that the development of positive coping strategies as well as knowledge and understanding about psychological processes are vehicles in the process of recovery. We conclude that interventions also need to account for the process of recovery as related to an ontological level and the person's Being-in-the-World.}
}
@article{ARAMOIMMONEN202047,
title = {Charting the reach and contribution of IMP literature in other disciplines: A bibliometric analysis},
journal = {Industrial Marketing Management},
volume = {87},
pages = {47-62},
year = {2020},
issn = {0019-8501},
doi = {https://doi.org/10.1016/j.indmarman.2020.02.022},
url = {https://www.sciencedirect.com/science/article/pii/S0019850118307442},
author = {Heli Aramo-Immonen and Per Carlborg and Nina Hasche and Jari Jussila and Johan Kask and Gabriel Linton and Navonil Mustafee and Christina Öberg},
keywords = {Bibliometric, Cluster analysis, Co-citation analysis, IMP, Imprint, Travel of idea},
abstract = {The acknowledgement of a research tradition by other disciplines shows its contribution to the development of the broader body of scientific knowledge. This paper investigates the contribution of IMP (Industrial Marketing and Purchasing) research to broader research disciplines by analyzing how researchers within and beyond IMP have cited core IMP articles. First, through quantitative bibliometric analysis, the paper identifies the diffusion to other research disciplines. Thereafter, through qualitative analysis, the impact of the IMP perspective is captured to understand how strong these imprints are. The analyses show that IMP research has been noticed among a range of adjacent research disciplines. However, the use of IMP references has generally been rudimentary, and without a deeper understanding of the IMP ontology, meaning that IMP still has some “weak ties” to the other disciplines. Establishing IMP's contribution through enduring imprints would need further engagement with researchers from other research disciplines and publications in top journals. The paper contributes empirically with how the IMP perspective has spread beyond the IMP Group and theoretically by adding insight into how research ideas travel and transform to other disciplines.}
}
@article{HOARE2022101719,
title = {A linked data approach to multi-scale energy modelling},
journal = {Advanced Engineering Informatics},
volume = {54},
pages = {101719},
year = {2022},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2022.101719},
url = {https://www.sciencedirect.com/science/article/pii/S147403462200177X},
author = {Cathal Hoare and Reihaneh Aghamolaei and Muireann Lynch and Ankita Gaur and James O’Donnell},
keywords = {Energy assessment, Data inter-operability, Linked data},
abstract = {Interactions between built infrastructure are complex and nuanced; changes to any one component can have disproportionate effects on the system as a whole. For instance, adoption of heat pumps or electric vehicles by a significant proportion of a population in an urban centre would place new demands on both electricity transmission and distribution networks. It is essential that planners – both national and local – can understand and share information about the resource demands that this type of change places on national and local infrastructure. Access to integrated sources of information – from building component to national levels – is key to supporting policy makers and decision takers. However, over time, information – and as a consequence, the software that manages it – has evolved into functional silos; this has, in turn, affected the definition of data exchange standards. This limits the ability of experts in functional areas to exchange data and implement broader decision support systems. This paper describes the use of linked data approaches to permit queries across large, diverse information sources to provide reasoning about complex questions at multiple scales. The methodology defines a central context to which various external sources can be attached. These distributed sources are, in themselves, registered in a central catalogue; they remain, however, under the control of their source organisations. In this way a large, extensible, interconnected network of distributed data describing, for example, a built environment or electricity transmission network; this network of data resources can be queried centrally to provide customised views of subsets of the data, and so provide a richer view than one source in isolation. The approach was applied to prepare and integrate information about Ireland’s transmission grid and administrative boundaries, along with domestic housing stock into a single data source. The resulting data network is queried by a scenario exploration tool. This tool successfully allows analysis, at a national level by economists, of the effects of the adoption of new technologies on the national grid of Ireland.}
}
@article{FERRARI2024105870,
title = {Understanding empathy and De Waal’s contribution within the fields of social neurosciences},
journal = {Neuroscience & Biobehavioral Reviews},
volume = {167},
pages = {105870},
year = {2024},
issn = {0149-7634},
doi = {https://doi.org/10.1016/j.neubiorev.2024.105870},
url = {https://www.sciencedirect.com/science/article/pii/S0149763424003397},
author = {Pier Francesco Ferrari},
keywords = {Action-perception, Mirror neurons, Motor simulation, Motor system, Emotions, Higher cognitive functions, Morality},
abstract = {This review delves into the remarkable career and scientific contributions of Frans de Waal, a renowned figure in the field of ethology, primatology with important implications for the field of social neurosciences. Rooted in the Dutch tradition of ethology, influenced by luminaries like Niko Tinbergen and Jan Van Hooff, De Waal's career began with groundbreaking research on chimpanzees, which questioned long-held beliefs about dominance and aggression in animal behavior. His work, epitomized in his influential books, such as "Chimpanzee Politics", “The ape and the sushi master”, “The age of empathy”, not only revolutionized scientific thinking but also ignited discussions about empathy, morality, and complex cognitive functions in animals. De Waal's interdisciplinary approach extended to neuroscience, particularly in understanding empathy, contributing to the development of an original model: the Perception-Action Model (PAM). The fundamental concept of PAM is that even the most intricate forms of empathy stem from basic neural mechanisms of action-perception, such as mirror neurons. Some behavioral phenomena like motor mimicry and emotional contagion arise from a direct neuroanatomical network activity where sensory information about others' emotional states triggers corresponding behavioral responses. Intriguingly, even the most intricate forms of empathy such as concern, consolation and targeted helping, may have evolved from basic neural mechanisms of action-perception.Through these investigations and theoretical explorations, he advocated for a bottom-up approach to comprehending the cognitive abilities of animals. This approach challenged conventional anthropocentric perspectives and underscored the interconnected emotional and cognitive terrain shared among humans and other species. Beyond academia, De Waal's work has profound implications for how we perceive and interact with animals. By debunking notions of human exceptionalism, he highlights the rich tapestry of emotions that bind all living beings. Through his efforts, De Waal has not only advanced our scientific understanding of animal minds but also fostered a more profound appreciation for the depth of emotional connections across species}
}
@article{DELACALLECABRERA2024102393,
title = {Literacy practices in childhood from a posthumanist perspective: A systematic review},
journal = {International Journal of Educational Research},
volume = {127},
pages = {102393},
year = {2024},
issn = {0883-0355},
doi = {https://doi.org/10.1016/j.ijer.2024.102393},
url = {https://www.sciencedirect.com/science/article/pii/S088303552400079X},
author = {Ana Mª {De la Calle Cabrera} and María-Rosario Leal-Bonmati and Elena Guichot-Muñoz and Mª Jesús Balbás Ortega},
keywords = {Literacy, Posthuman, Childhood, Reviews of literature},
abstract = {The posthumanist perspective implies a change in the consideration of the non-human and more-than-human in literacy practices from an ethical-onto-epistemological approach. This research is a systematic review that aims to understand how literacy studies with a posthuman lens host literacy practices at a young age from the relational-material language model, in a broad domain where the human, more-than-human and non-human are connected. This is developed according to the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) method, with a selection of 15 research articles from the WOS and Scopus databases. This review highlights the (re)conceptualisation of children's literacy practices from the understanding of the role of the human, non-human and more-than-human, that materials and discourse and literacy practices are indivisible and give rise to the configuration of new narratives - integrating movement, sound, digital, space, time, improvisation, sensations and affections, etc. - and the challenge to the humanist assumptions of literacy practices.}
}
@article{MORRISON2018196,
title = {Empires as ecosystem engineers: Toward a nonbinary political ecology},
journal = {Journal of Anthropological Archaeology},
volume = {52},
pages = {196-203},
year = {2018},
issn = {0278-4165},
doi = {https://doi.org/10.1016/j.jaa.2018.09.002},
url = {https://www.sciencedirect.com/science/article/pii/S027841651830059X},
author = {Kathleen D. Morrison},
keywords = {Empires, Ecosystem engineer, Land use-land cover change, Political ecology, Colonial economies, Archaeology, Nature/culture, Anthropocene, ALCC},
abstract = {Calls to eliminate nature/culture dualities in favor of nondualist ontologies present analytical challenges; how might we approach entangled socionatural worlds in ways that neither reduce the complexity and diversity of human experience and yet also allow nonhuman agents their ‘voices’? The disparate analytical vocabularies of the human and natural sciences were not designed for this purpose. The use of ecological concepts in anthropology has been contentious, while humans have continued to be located outside of most ecological thinking. Comparative analysis of past empires provides an opportunity to address this challenge. If we view the actions of past empires in terms of their environmental effects, we can also conceptualize these effects as specific forms of ecological action. Using the concept of ‘ecosystem engineer,’ this essay explores how this concept may facilitate comparison of imperial and colonial systems and, critically, how it may inflect and improve anthropogenic land cover change (ALCC) models which posit historical relationships between past population and land cover. At the same time, this exercise points to the analytical limits of this concept and perhaps of nondualist ontologies themselves.}
}
@article{WEBB2025101235,
title = {Dialogic entanglements in researcher identity: A duoethnographic exploration of critical (self)reflexive moments of two transnational L2 writing scholars},
journal = {Journal of Second Language Writing},
volume = {69},
pages = {101235},
year = {2025},
issn = {1060-3743},
doi = {https://doi.org/10.1016/j.jslw.2025.101235},
url = {https://www.sciencedirect.com/science/article/pii/S1060374325000608},
author = {Marie Webb and Young Wha Lee},
keywords = {(self)reflexivity, Teacher identity, Duoethnography, Second language writing, Researcher identity},
abstract = {Utilizing duoethnography during a collaborative post-dissertation research period, this study investigates the evolving research skills and professional identities of two transnational second language (L2) writing teacher-scholars. Through critical reflection on their L2 writing teacher identity dissertation scholarship, the authors respond to calls for transparent and reflexive research that addresses the complexities of language teacher-scholar practices (Lee et al., 2022, Sánchez-Martín and Seloni, 2019) and decolonized methodologies in the field of Second Language Writing (Kubota, 2022). The authors explore how their transnational experiences, intersectional identities, and disciplinary expertise as L2 writing scholars shaped their understandings of reflexivity during and beyond their doctoral dissertation journeys. Their narratives highlight critical (self)reflexive moments, unpacking the development of diverse researcher reflexivity orientations (Olmos-Vega et al., 2022). The narratives culminate by showcasing the transformative journey of the authors’ researcher identities and positionalities at the nexus of TESOL/writing teacher educator (TE) and L2 writing teacher identity research. Key findings highlight the role of methodological, contextual, and (self)reflexivity in fostering decolonizing views of methodology and critical perspectives on L2 writing scholarship. The authors underscore the value of duoethnographic or narrative analytic strategies in addressing the political challenges inherent in transnational scholarship, doctoral mentoring, and academic writing.}
}
@article{RAUSCH2022104394,
title = {Tolerance management domain model for semantic enrichment of BIMs},
journal = {Automation in Construction},
volume = {141},
pages = {104394},
year = {2022},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2022.104394},
url = {https://www.sciencedirect.com/science/article/pii/S0926580522002679},
author = {Christopher Rausch and Saeed Talebi and Mani Poshdar and Beidi Li and Carl Schultz},
keywords = {Domain model, Dependency structure matrix, Tolerance management, Building information model, Tolerance analysis, Risk management},
abstract = {Dimensional variability of components and assemblies in construction can lead to significant defects, rework, and project risk if not managed effectively. Given the complexity of using tolerance management to control dimensional variability, an automated BIM-based approach is highly propitious, while currently elusive. This paper develops the first iteration of a domain model for tolerance management (ToleranceDM) using two case study examples within the domain of building construction. The results are shown to (1) consolidate the scattered, disparate existing “knowledge” and research on tolerance management into a single standardised, uniform framework, and (2) formalise this knowledge so that it can be unambiguously interpreted and parsed into software systems for automated tolerance management in construction. ToleranceDM functions as a key step towards benchmarking process capabilities, computing tolerance compliance automatically, and enabling in-field communication of tolerance requirements. Future research should explore case studies in different construction domains, along with developing an improved abduction framework and integrating as-built project data for tolerance compliance checking.}
}
@incollection{JILANI2019135,
title = {Chapter Three - Advances in Applications of Object Constraint Language for Software Engineering},
editor = {Atif M. Memon},
series = {Advances in Computers},
publisher = {Elsevier},
volume = {112},
pages = {135-184},
year = {2019},
issn = {0065-2458},
doi = {https://doi.org/10.1016/bs.adcom.2017.12.003},
url = {https://www.sciencedirect.com/science/article/pii/S0065245817300554},
author = {Atif A. Jilani and Muhammad Z. Iqbal and Muhammad U. Khan and Muhammad Usman},
keywords = {Object Constraint Language, Model-driven engineering, Secondary study, Software engineering},
abstract = {Object Constraint Language (OCL) is a standard language defined by Object Management Group for specifying constraints on models. Since its introduction as part of Unified Modeling Language, OCL has received significant attention by researchers with works in the literature ranging from temporal extensions of OCL to automated test generation by solving OCL constraints. In this chapter, we provide a survey of the various works discussed in literature related to OCL with the aim of highlighting the advances made in the field. We classify the literature into five broad categories and provide summaries for various works in the literature. The chapter also provides insights and highlights the potentials areas of further research in the field.}
}
@article{CALAUTTI2021114297,
title = {Existential active integrity constraints},
journal = {Expert Systems with Applications},
volume = {168},
pages = {114297},
year = {2021},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2020.114297},
url = {https://www.sciencedirect.com/science/article/pii/S0957417420309982},
author = {Marco Calautti and Luciano Caroprese and Sergio Greco and Cristian Molinaro and Irina Trubitsyna and Ester Zumpano},
keywords = {Knowledge representation and management, Knowledge bases, Repair, Certain query answering},
abstract = {Active integrity constraints (AICs) are a useful formalism to express integrity constraints and policies to restore consistency in databases violating them. However, AICs do not allow users to express different kinds of constraints commonly arising in practice, such as foreign keys. In this paper, we propose existential active integrity constraints (EAICs), a powerful extension of AICs that allows us to express a wide range of constraints used in databases and ontological systems. We investigate different properties of EAICs. Specifically, we show that there exists a “representative” set of founded updates, called universal, which suffices for query answering. As such a set might contain an infinite number of founded updates, each of infinite size, we study syntactic restrictions ensuring finiteness, as well as the existence of a single universal founded update.}
}
@article{BEREA2025101711,
title = {Towards a generalized framework for planetary communication},
journal = {Space Policy},
pages = {101711},
year = {2025},
issn = {0265-9646},
doi = {https://doi.org/10.1016/j.spacepol.2025.101711},
url = {https://www.sciencedirect.com/science/article/pii/S0265964625000359},
author = {Anamaria Berea and Karen S. Lewis and Bettina Beinhoff and Arik Kershenbaum and Eng Sengsavang and Nick Searra}
}
@article{BENITEZANDRADES2022,
title = {Traditional Machine Learning Models and Bidirectional Encoder Representations From Transformer (BERT)–Based Automatic Classification of Tweets About Eating Disorders: Algorithm Development and Validation Study},
journal = {JMIR Medical Informatics},
volume = {10},
number = {2},
year = {2022},
issn = {2291-9694},
doi = {https://doi.org/10.2196/34492},
url = {https://www.sciencedirect.com/science/article/pii/S2291969422001004},
author = {José Alberto Benítez-Andrades and José-Manuel Alija-Pérez and Maria-Esther Vidal and Rafael Pastor-Vargas and María Teresa García-Ordás},
keywords = {natural language processing, NLP, social media, data, bidirectional encoder representations from transformer, BERT, deep learning, machine learning, eating disorder, mental health, model, classification, Twitter, nutrition, diet, weight, disorder, performance},
abstract = {Background
Eating disorders affect an increasing number of people. Social networks provide information that can help.
Objective
We aimed to find machine learning models capable of efficiently categorizing tweets about eating disorders domain.
Methods
We collected tweets related to eating disorders, for 3 consecutive months. After preprocessing, a subset of 2000 tweets was labeled: (1) messages written by people suffering from eating disorders or not, (2) messages promoting suffering from eating disorders or not, (3) informative messages or not, and (4) scientific or nonscientific messages. Traditional machine learning and deep learning models were used to classify tweets. We evaluated accuracy, F1 score, and computational time for each model.
Results
A total of 1,058,957 tweets related to eating disorders were collected. were obtained in the 4 categorizations, with The bidirectional encoder representations from transformer–based models had the best score among the machine learning and deep learning techniques applied to the 4 categorization tasks (F1 scores 71.1%-86.4%).
Conclusions
Bidirectional encoder representations from transformer–based models have better performance, although their computational cost is significantly higher than those of traditional techniques, in classifying eating disorder–related tweets.}
}
@article{HARDISTY201922,
title = {The Bari Manifesto: An interoperability framework for essential biodiversity variables},
journal = {Ecological Informatics},
volume = {49},
pages = {22-31},
year = {2019},
issn = {1574-9541},
doi = {https://doi.org/10.1016/j.ecoinf.2018.11.003},
url = {https://www.sciencedirect.com/science/article/pii/S1574954118301961},
author = {Alex R. Hardisty and William K. Michener and Donat Agosti and Enrique {Alonso García} and Lucy Bastin and Lee Belbin and Anne Bowser and Pier Luigi Buttigieg and Dora A.L. Canhos and Willi Egloff and Renato {De Giovanni} and Rui Figueira and Quentin Groom and Robert P. Guralnick and Donald Hobern and Wim Hugo and Dimitris Koureas and Liqiang Ji and Wouter Los and Jeffrey Manuel and David Manset and Jorrit Poelen and Hannu Saarenmaa and Dmitry Schigel and Paul F. Uhlir and W. Daniel Kissling},
keywords = {Essential biodiversity variables, Cyberinfrastructure, E-infrastructure, Data products, Informatics, Interoperability},
abstract = {Essential Biodiversity Variables (EBV) are fundamental variables that can be used for assessing biodiversity change over time, for determining adherence to biodiversity policy, for monitoring progress towards sustainable development goals, and for tracking biodiversity responses to disturbances and management interventions. Data from observations or models that provide measured or estimated EBV values, which we refer to as EBV data products, can help to capture the above processes and trends and can serve as a coherent framework for documenting trends in biodiversity. Using primary biodiversity records and other raw data as sources to produce EBV data products depends on cooperation and interoperability among multiple stakeholders, including those collecting and mobilising data for EBVs and those producing, publishing and preserving EBV data products. Here, we encapsulate ten principles for the current best practice in EBV-focused biodiversity informatics as ‘The Bari Manifesto’, serving as implementation guidelines for data and research infrastructure providers to support the emerging EBV operational framework based on trans-national and cross-infrastructure scientific workflows. The principles provide guidance on how to contribute towards the production of EBV data products that are globally oriented, while remaining appropriate to the producer's own mission, vision and goals. These ten principles cover: data management planning; data structure; metadata; services; data quality; workflows; provenance; ontologies/vocabularies; data preservation; and accessibility. For each principle, desired outcomes and goals have been formulated. Some specific actions related to fulfilling the Bari Manifesto principles are highlighted in the context of each of four groups of organizations contributing to enabling data interoperability - data standards bodies, research data infrastructures, the pertinent research communities, and funders. The Bari Manifesto provides a roadmap enabling support for routine generation of EBV data products, and increases the likelihood of success for a global EBV framework.}
}
@article{STOREY2025102482,
title = {Domain knowledge in artificial intelligence: Using conceptual modeling to increase machine learning accuracy and explainability},
journal = {Data & Knowledge Engineering},
volume = {160},
pages = {102482},
year = {2025},
issn = {0169-023X},
doi = {https://doi.org/10.1016/j.datak.2025.102482},
url = {https://www.sciencedirect.com/science/article/pii/S0169023X25000771},
author = {Veda C. Storey and Jeffrey Parsons and Arturo Castellanos Bueso and Monica Chiarini Tremblay and Roman Lukyanenko and Alfred Castillo and Wolfgang Maaß},
keywords = {Artificial intelligence, Machine learning, Conceptual modeling for machine learning (cmml) method, Machine learning model performance, transparency, data preparation, domain knowledge},
abstract = {Machine learning enables the extraction of useful information from large, diverse datasets. However, despite many successful applications, machine learning continues to suffer from performance and transparency issues. These challenges can be partially attributed to the limited use of domain knowledge by machine learning models. This research proposes using the domain knowledge represented in conceptual models to improve the preparation of the data used to train machine learning models. We develop and demonstrate a method, called the Conceptual Modeling for Machine Learning (CMML), which is comprised of guidelines for data preparation in machine learning and based on conceptual modeling constructs and principles. To assess the impact of CMML on machine learning outcomes, we first applied it to two real-world problems to evaluate its impact on model performance. We then solicited an assessment by data scientists on the applicability of the method. These results demonstrate the value of CMML for improving machine learning outcomes.}
}
@article{HILL202412,
title = {Semantic (dis)continuity and institutional transformation: The decline of Afrikaans at Stellenbosch University},
journal = {Language & Communication},
volume = {98},
pages = {12-31},
year = {2024},
issn = {0271-5309},
doi = {https://doi.org/10.1016/j.langcom.2024.05.002},
url = {https://www.sciencedirect.com/science/article/pii/S0271530924000351},
author = {Lloyd Hill},
keywords = {Language planning, Afrikaans, South African universities, Science, Semantic discontinuity},
abstract = {To what extent is the language of higher education continuous with the language of everyday life? The decline of Afrikaans at Stellenbosch University over a period of roughly three decades provides an insightful context for exploring the debate on language status in higher education. This article explores the shift from Afrikaans to English – and the attendant taaldebat or language debate – at Stellenbosch University. This shift is situated within a transforming South African higher education sector and within transnational teaching and research networks. The analysis focuses on conceptual issues relating to the concept of “language” implicit in university language planning initiatives. These include the intersection of language, race and social class, and semantic (dis)continuity within the domains of science.}
}
@article{KABIR2023100011,
title = {ASPER: Attention-based approach to extract syntactic patterns denoting semantic relations in sentential context},
journal = {Natural Language Processing Journal},
volume = {3},
pages = {100011},
year = {2023},
issn = {2949-7191},
doi = {https://doi.org/10.1016/j.nlp.2023.100011},
url = {https://www.sciencedirect.com/science/article/pii/S2949719123000080},
author = {Md. Ahsanul Kabir and Tyler Phillips and Xiao Luo and Mohammad {Al Hasan}},
keywords = {Syntactic pattern, Syntactic pattern extraction},
abstract = {Semantic relationships, such as hyponym–hypernym, cause–effect, meronym–holonym etc., between a pair of entities in a sentence are usually reflected through syntactic patterns. Automatic extraction of such patterns benefits several downstream tasks, including, entity extraction, ontology building, and question answering. Unfortunately, automatic extraction of such patterns has not yet received much attention from NLP and information retrieval researchers. In this work, we propose an attention-based supervised deep learning model, ASPER, which extracts syntactic patterns between entities exhibiting a given semantic relation in the sentential context. We validate the performance of ASPER on three distinct semantic relations—hyponym–hypernym, cause–effect, and meronym–holonym on six datasets. Experimental results show that for all these semantic relations, ASPER can automatically identify a collection of syntactic patterns reflecting the existence of such a relation between a pair of entities in a sentence. In comparison to the existing methodologies of syntactic pattern extraction, ASPER’s performance is substantially superior.}
}
@article{LIVELEY2021102663,
title = {Futures literacy through narrative},
journal = {Futures},
volume = {125},
pages = {102663},
year = {2021},
issn = {0016-3287},
doi = {https://doi.org/10.1016/j.futures.2020.102663},
url = {https://www.sciencedirect.com/science/article/pii/S0016328720301531},
author = {Genevieve Liveley and Will Slocombe and Emily Spiers},
keywords = {Narrative, Futures, Literacy, Storytelling, Fiction, Speculative, Character},
abstract = {This paper explores the particular role of narrative in developing futures literacy. As literacy denotes the ability to express and absorb meaning through language, enabling individuals to parse information and relate to others, then futures literacy also needs to draw on the insights of narrative to embrace its full emancipatory potential. We set out the importance of narrative in (1) framing, (2) shaping, and (3) critiquing the world-building techniques that form the foundation of futures thinking and futures literacy. These insights into the “storiness” of futurity, we argue, enhance critical reflexivity and illuminate our wider understanding of the dynamics that drive assumptions about the future(s). This paper offers three examples of how working with narrative tools can enhance futures literacy. First, we show how narrative theory can help us understand the limitations of the human imagination when it comes to futures thinking. Second, we offer an overview of how collaborative, character-led storytelling can activate an agentic relationship with uncertain and complex futures. Finally, we explore how speculative fiction reveals the importance of context in futures thinking. Overall, we demonstrate how proficiency in narrative theory and literary studies can shed more light on the cultural and ontological perspectives and specificities to be considered in how we anticipate and engage in futures thinking.}
}
@article{SPICHIGER2025101314,
title = {Please mind the gap: A taxonomy for addressing the issue of linking person, account and device},
journal = {Science & Justice},
volume = {65},
number = {5},
pages = {101314},
year = {2025},
issn = {1355-0306},
doi = {https://doi.org/10.1016/j.scijus.2025.101314},
url = {https://www.sciencedirect.com/science/article/pii/S135503062500098X},
author = {Hannes Spichiger},
keywords = {Person-device gap, Person-account gap, Digital forensic science},
abstract = {Courts throughout several jurisdictions have dismissed cases on the basis that the link between a device or account and the accused person had not sufficiently been established. This core challenge of digital forensic science is named here the “Person-Device Gap” or the “Person-Account Gap” respectively. The gap illustrates the challenge of linking a person to a specific account or device, either in general or at the moment of interest. This article aims to explain this problem through modelling relevant identities and explains traces that have the potential to bridge the gap.}
}
@article{SHI2022,
title = {Andrographolide in atherosclerosis: integrating network pharmacology and in vitro pharmacological evaluation},
journal = {Bioscience Reports},
volume = {42},
number = {7},
year = {2022},
issn = {1573-4935},
doi = {https://doi.org/10.1042/BSR20212812},
url = {https://www.sciencedirect.com/science/article/pii/S1573493522000893},
author = {Shuai Shi and Xinyu Ji and Jingjing Shi and Shuqing Shi and Fei She and Qiuyan Zhang and Yu Dong and Hanming Cui and Yuanhui Hu},
keywords = {Andrographolide, Atherosclerosis, Network pharmacology, Reverse cholesterol transport},
abstract = {Objective: Andrographis paniculata (Burm.f.) Nees is a medicinal plant that has been traditionally used as an anti-inflammatory and antibacterial remedy for several conditions. Andrographolide (AG), the active constituent of A. paniculata (Burm.f.) Nees, has anti-lipidic and anti-inflammatory properties as well as cardiovascular protective effects. The present study aimed to explore the effects of AG on the progression of atherosclerosis and to investigate related mechanisms via network pharmacology.
Materials and methods: Compound-related information was obtained from the PubChem database. Potential target genes were identified using STITCH, SwissTargetPrediction, Bioinformatics Analysis Tool for Molecular mechANism of Traditional Chinese Medicine, and Comparative Toxicogenomics Database. Genes involved in atherosclerosis were obtained from DisGeNet and compared with AG target genes to obtain an overlapping set. Protein–protein interactions were determined by STRING. Gene ontology (GO) analysis was performed at WebGestalt, and Kyoto Encyclopedia of Genes and Genomes (KEGG) pathway enrichment was analyzed using Metascape. The final network showing the relationship between compounds, targets, and pathways was constructed using Cytoscape. After that, oxLDL-induced RAW264.7 cells were used to further validate a part of the network pharmacology results.
Result: Eighty-one potential AG target genes were identified. PPI, GO, and KEGG enrichment revealed genes closely related to tumor progression, lipid transport, inflammation, and related pathways. AG improves the reverse cholesterol transport (RCT) through NF-κB/CEBPB/PPARG signaling in oxLDL-induced RAW264.7 cells.
Conclusion: We successfully predict AG’s potential targets and pathways in atherosclerosis and illustrate the mechanism of action. AG may regulate NF-κB/CEBPB/PPARG signaling to alleviate atherosclerosis.}
}
@article{MOWBRAY2023105772,
title = {Representing legislative Rules as Code: Reducing the problems of ‘scaling up’},
journal = {Computer Law & Security Review},
volume = {48},
pages = {105772},
year = {2023},
issn = {2212-473X},
doi = {https://doi.org/10.1016/j.clsr.2022.105772},
url = {https://www.sciencedirect.com/science/article/pii/S0267364922001157},
author = {Andrew Mowbray and Philip Chung and Graham Greenleaf},
abstract = {We propose an approach to analysing the nature of existing legal rules, particularly legislative rules, that regards legislation as fundamentally a set of related propositions. We propose a method for representing these rules, using a coding language developed for the project that uses a quasi-natural language representation. It enables the interpreter program for that coding language to process these rules so as to produce ‘consultations’ to determine the values of goals which the legislation is capable of determining, with dialogues and explanations generated ‘on the fly’. Progress that has been made in automating this coding process to create rules in that coding language directly from existing legislation, using a pre-processor program developed for the project. This can also be described as ‘scaling up’ the production of ‘Rules as Code’ or ‘Law as Code’. If successfully developed further this has potential to make a significant contribution toward realising the practical potential of Rules as Code. We conclude there is now evidence that these processes can be generalised (‘scaled up’) to deal with the conversion or production of large bodies of legislation, and that this has considerable value. The pre-processor software is evolving rapidly, in the variety of structural forms of legislation that it can convert into the coding language, and this work will continue. Based on this experience, we also demonstrate how the drafting of legislation could be changed so that appropriately drafted legislation is directly readable and understandable by humans and also directly usable by machines. To be effective, laws drafted in this way will need to be simultaneously authoritative legislative rules and code.}
}
@article{KASALICA20212157,
title = {APE in the Wild: Automated Exploration of Proteomics Workflows in the bio.tools Registry},
journal = {Journal of Proteome Research},
volume = {20},
number = {4},
pages = {2157-2165},
year = {2021},
issn = {1535-3907},
doi = {https://doi.org/10.1021/acs.jproteome.0c00983},
url = {https://www.sciencedirect.com/science/article/pii/S1535390721002031},
author = {Vedran Kasalica and Veit Schwämmle and Magnus Palmblad and Jon Ison and Anna-Lena Lamprecht},
keywords = {proteomics, scientific workflows, computational pipelines, workflow exploration, automated workflow composition, semantic tool annotation},
abstract = {The bio.tools registry is a main catalogue of computational tools in the life sciences. More than 17 000 tools have been registered by the international bioinformatics community. The bio.tools metadata schema includes semantic annotations of tool functions, that is, formal descriptions of tools’ data types, formats, and operations with terms from the EDAM bioinformatics ontology. Such annotations enable the automated composition of tools into multistep pipelines or workflows. In this Technical Note, we revisit a previous case study on the automated composition of proteomics workflows. We use the same four workflow scenarios but instead of using a small set of tools with carefully handcrafted annotations, we explore workflows directly on bio.tools. We use the Automated Pipeline Explorer (APE), a reimplementation and extension of the workflow composition method previously used. Moving “into the wild” opens up an unprecedented wealth of tools and a huge number of alternative workflows. Automated composition tools can be used to explore this space of possibilities systematically. Inevitably, the mixed quality of semantic annotations in bio.tools leads to unintended or erroneous tool combinations. However, our results also show that additional control mechanisms (tool filters, configuration options, and workflow constraints) can effectively guide the exploration toward smaller sets of more meaningful workflows.
}
}
@article{FILTER2022100834,
title = {Towards efficient use of data, models and tools in food microbiology},
journal = {Current Opinion in Food Science},
volume = {46},
pages = {100834},
year = {2022},
issn = {2214-7993},
doi = {https://doi.org/10.1016/j.cofs.2022.100834},
url = {https://www.sciencedirect.com/science/article/pii/S2214799322000364},
author = {Matthias Filter and Maarten Nauta and Sara M. Pires and Laurent Guillier and Tasja Buschhardt},
abstract = {Food microbiology researchers, risk assessment agencies and food business operators rely heavily on the reuse of knowledge that is available as data, models and tools. Unfortunately, such knowledge reuse remains challenging, as food safety data sets, models and tools are usually only available in platform-dependent or software-dependent formats that rarely comply to the Findability, Accessibility, Interoperability, and Reusability data principles. In recent years, the Risk Assessment Modelling and Knowledge Integration Platform (RAKIP) Initiative developed the so-called Food Safety Knowledge Exchange (FSKX) format. This development was accompanied by the creation of open-source software that facilitates the adoption of FSKX. Future work within RAKIP will focus on creating semantic interoperability in FSKX-related solutions and on the extension of the FSKX format towards other food microbiology knowledge.}
}
@article{CHEN20254132,
title = {Construction of a New Ferroptosis-related Prognosis Model for Survival Prediction in Colorectal Cancer},
journal = {Current Medicinal Chemistry},
volume = {32},
number = {20},
pages = {4132-4146},
year = {2025},
issn = {0929-8673},
doi = {https://doi.org/10.2174/0109298673296767240116215814},
url = {https://www.sciencedirect.com/science/article/pii/S0929867325000845},
author = {Lin Chen and Mengxiao Ge and Shaocong Mo and Menglin Shi and Jun Zhang and Jie Liu},
keywords = {Ferroptosis, CRC, prognosis, scRNA-seq, immune, gene signature},
abstract = {Aim
This study was designed to develop a ferroptosis-related gene signature for guiding the prognostic prediction in colorectal cancer (CRC) and to explore the potential in the molecular functions of the gene signature.
Background
Ferroptosis is mainly characterized by lipid peroxide accumulation on the cell membranes in an iron-dependent manner, resulting in cellular oxidative stress, metabolic disorders, and, ultimately, cell death. This study aimed to develop a prognostic ferroptosis signature in CRC and explore its potential molecular function.
Objective
The present work was designed to devise a ferroptosis signature for CRC prognosis and explore its potential molecular function.
Methods
Single-cell RNA sequencing data GSE161277 and transcriptome sequencing data GSE17537 and TCGA-CRC from the Gene Expression Omnibus (GEO) and the Cancer Genome Atlas (TCGA) databases were downloaded, respectively. Quality control, dimension reduction, clustering, and clustering of single-cell RNA sequencing (scRNA-seq) data were performed using the Seurat package. A total of 259 ferroptosis-correlated genes from the FerrDb database were acquired. The single sample gene set enrichment analysis (ssGSEA) was performed to calculate the scores of genes related to ferroptosis. ESTIMATE was used to calculate immune infiltration. Independent prognostic factors were determined by performing Weighted Gene Co-Expression Network Analysis (WGCNA), univariate and Cox analyses, and Lasso analyses were used to search for independent prognostic factors.
Results
From the scRNA-seq (GSE161277) dataset, 22 cell clusters were initially identified, and according to immune cell markers, only 8 types of cells (Follicular B, central memory T cell, Epithelial, Natural killer T cell, Plasma B, M1 macrophage, Fibroblasts, and Mast cell) were finally determined to be related to CRC prognosis. The results of the scRNA-seq analysis showed that the score of ferroptosis-related genes was higher in tumour tissues and in 8 types of cells in tumour samples. In the TCGA dataset, CRC samples were divided into ferroptosis-related high scores, ferroptosis-related median scores, and ferroptosis-related low scores. Immune cell analysis revealed that ferroptosis-related high scores had the highest abundance of immune cells. An 11-gene signature was developed by WGCNA, univariate Cox, and Lasso Cox regression. The prediction ability of the signature was successfully validated in the GSE17537 dataset. A comprehensive nomogram combining the 11 signature genes and clinical parameters could effectively predict the overall survival of CRC patients.
Conclusions
The present molecular signature established based on the 11 ferroptosis-related genes performed well in assessing CRC prognosis. The present discoveries could inspire further research on ferroptosis, providing a new direction for CRC management.}
}
@article{LI2023114888,
title = {An unified CAD/CAE/VR tool for ship structure design and evaluation based on multi-domain feature mapping},
journal = {Ocean Engineering},
volume = {280},
pages = {114888},
year = {2023},
issn = {0029-8018},
doi = {https://doi.org/10.1016/j.oceaneng.2023.114888},
url = {https://www.sciencedirect.com/science/article/pii/S0029801823012726},
author = {Chuntong Li and Pengyu Wei and Xiaomeng Luo and Ze Jiang and Deyu Wang},
keywords = {CAD/CAE/VR integration, Ship structure, Knowledge-based engineering, Multi-domain feature mapping},
abstract = {Computer-aided design (CAD), computer-aided engineering (CAE), and virtual reality (VR) are three distinct disciplines. For the collaborative design and interactive evaluation of ship structures, the main obstacle lies in the large differences in model data structures. In this regard, a unified tool for ship structure design/analysis/virtual evaluation based on Multi-Domain Feature Mapping (MDFM) is proposed. The multi-layer transmission and matching mechanism between data, information and knowledge established by Extensible Markup Language (XML) can realize the feature association among design, analysis and evaluation domain, so that CAD, CAE and VR become an organic entity. In the virtual scene, a visual expression strategy of CAD model and FEA data based on Unified Mesh Model (UMM) is proposed. The advantage of this unified tool lies in the intelligent generation of finite element models, as well as the virtual visualization and model reconstruction and evaluation of models with different topologies. Intelligent finite element (FE) meshing and analysis applications integrating knowledge templates represent a major subset of unified CAD/CAE/VR tools for structural models from CAD systems. The structure and data flow management of this unified tool is based on a common design process, which allows designers to link anticipated scenarios with proposed engineering changes. Finally, the effectiveness of the proposed tool is demonstrated by engineering examples.}
}
@article{ENGLMEIER20202069,
title = {Named Entities and Their Role in Creating Context Information},
journal = {Procedia Computer Science},
volume = {176},
pages = {2069-2076},
year = {2020},
note = {Knowledge-Based and Intelligent Information & Engineering Systems: Proceedings of the 24th International Conference KES2020},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2020.09.243},
url = {https://www.sciencedirect.com/science/article/pii/S1877050920321463},
author = {Kurt Englmeier},
keywords = {Information Extraction, Named-Entity Recognition, Bag of Words, Information Summarization, Entity Linking, Semantic Markers, Context-Awareness, Economic Information},
abstract = {Context encompasses the classification of a certain environment by its key attributes that take the role of semantic markers. It is an abstract representation of a certain data environment. In texts, the context classifies and represents a piece of text in a generalized form. Context can be a recursive construct when summarizing information on a more coarse-grained level. This paper presents identification and standardization of context on different levels of granularity that finally supports faster and more precise information retrieval. The prototypical system presented here applies supervised learning for a semi-automatic approach to extract, distil, and standardize data from text. The approach is based on named-entity recognition and simple ontologies for identification and disambiguation of context. Even though the prototype shown here still represents work in progress, it already demonstrates its potential for mining texts on different levels of context granularity. The paper presents the design of the Contexter system that supports identification and classification of misinformation and fake news around the topic Covid-19.}
}
@article{SU2025113423,
title = {RAICL-DSC: Retrieval-Augmented In-Context Learning for Dialogue State Correction},
journal = {Knowledge-Based Systems},
volume = {317},
pages = {113423},
year = {2025},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2025.113423},
url = {https://www.sciencedirect.com/science/article/pii/S0950705125004708},
author = {Haoxiang Su and Hongyan Xie and Jie Shi and Di Wu and Liting Jiang and Hao Huang and Zhongjiang He and Yongxiang Li and Ruiyu Fang and Jianyu Zhao and Shuangyong Song},
keywords = {Dialogue state tracking, Error propagation, Dialogue state correction, Retrieval augmentation, In-context learning},
abstract = {Dialogue State Tracking (DST) is a crucial component of task-oriented dialogue systems. However, most DST methods face the issue of error propagation, which limits the response success rate of dialogue systems. Therefore, some researchers have proposed Dialogue State Correction (DSC) methods to correct errors in the dialogue state predicted by the DST model, thereby mitigating the error propagation issue in DST. Although these methods have achieved impressive improvements, they still cannot effectively correct all types of errors and may introduce new errors during the correction process. To address this issue, we propose Retrieval-Augmented In-Context Learning for Dialogue State Correction (RAICL-DSC), which can correct errors of the same type in the target sample under the guidance of in-context examples of specific types. Specifically, to better correct the target samples, we use a simulator to generate in-context example databases with examples of correcting errors. Next, we used the retriever and evaluator to find the most relevant in-context examples from the databases based on the semantics and error types of the target sample. Finally, we use these in-context examples to assist the state corrector in correcting the predicted dialogue state in the target sample. The experiment demonstrates that the proposed method not only effectively corrects the erroneous predictions of the DST model but also shows excellent potential in correcting annotation errors in the MultiWOZ dataset.}
}
@article{ZHUHADAR2019507,
title = {Leveraging learning innovations in cognitive computing with massive data sets: Using the offshore Panama papers leak to discover patterns},
journal = {Computers in Human Behavior},
volume = {92},
pages = {507-518},
year = {2019},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2017.12.013},
url = {https://www.sciencedirect.com/science/article/pii/S0747563217306933},
author = {Leyla Zhuhadar and Mark Ciampa},
keywords = {Cognitive computing, Learning analytics, Panama papers, Ontology, GraphDB},
abstract = {Exposing learners to cognitive computing concepts involves new learning strategies. Because cognitive computing is probabilistic, using massive sets of data is fundamental in understanding these concepts. One data set is the release of the Offshore Panama Papers Leaks Database (LeaksDB) in May 2016, in which researchers were able to access this graph database as part of the International Consortium of Investigative Journalists (ICIJ) Offshore Leaks investigation and to draw conclusions about companies, trusts, foundations, and funds incorporated in 21 tax havens. For the purpose of this research, GraphDB Server was installed and configured by faculty members from a mid-western university. In addition, DBPedia and GeoNames repositories were linked to LeaksDB, leading to the discovery of interesting patterns about these Geo facade relationships between Officers (persons or companies) and Countries.}
}
@article{CREMASCHI2020478,
title = {A fully automated approach to a complete Semantic Table Interpretation},
journal = {Future Generation Computer Systems},
volume = {112},
pages = {478-500},
year = {2020},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2020.05.019},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X19302663},
author = {Marco Cremaschi and Flavio {De Paoli} and Anisa Rula and Blerina Spahiu},
keywords = {Semantic Web, Ontology, Linked Data, Knowledge Graph, Semantic Table Interpretation},
abstract = {In recent years, there has been an increasing interest in extracting and annotating tables on the Web. This activity allows the transformation of text data into machine-readable formats to enable the execution of various artificial intelligence tasks, e.g. semantic search and dataset extension. Semantic Table Interpretation is the process of annotating elements in a table. Current approaches are mainly based on lexical matching algorithms that rely on metadata associated with tables or custom Knowledge Graphs. Their main limitations are due to the lack of metadata, the little use of contextual semantics, and the incompleteness of the proposed methods that do not include all the necessary steps. In this paper, we propose a comprehensive approach and a tool that provides an unsupervised method to annotate independent tables, possibly without header row or other external information. The approach is based on the definition of a context created from the elements within the table in order to discriminate among matching entities found in shared Knowledge Graphs and create high-quality annotations. The approach has achieved excellent results in an international challenge, thus proving its effectiveness.}
}
@article{CONSTANTINOU2025103112,
title = {Reimagining self-determination: Relational, decolonial, and intersectional perspectives},
journal = {Political Geography},
volume = {118},
pages = {103112},
year = {2025},
issn = {0962-6298},
doi = {https://doi.org/10.1016/j.polgeo.2024.103112},
url = {https://www.sciencedirect.com/science/article/pii/S0962629824000611},
author = {Costas M. Constantinou and Fiona McConnell and Dilar Dirik and Asebe Regassa and Shona Loong and Rauna Kuokkanen},
keywords = {Self-determination, Relationality, Intersectionality, Decoloniality, State, Indigenous peoples},
abstract = {Self-determination language and practice are increasingly perplexing in the 21st century. Historically linked to decolonization processes and post-imperial transformations of the international system, self-determination has espoused both violent and non-violent resistance, and supported both existing and emergent sovereignty. With the Janus-faced relationship between self-determination and colonialism continuing to this day, the contemporary moment is an opportune time to take stock of self-determination. However, as conventional jurisprudence and international legalism framings have, in many ways, hampered its emancipatory potential, alternative ways of reimagining self-determination are needed. Bringing together scholars from the fields of political and development geography, indigenous studies, international relations, and sociology, this intervention demonstrates how articulations of self-determination in specific sites offer powerful critiques of the state system and the liberal world order and unsettle hegemonic forms of knowledge production. These articulations open up conceptual space to push self-determination beyond the realm of rights, allowing us to reimagine self-determination as a vision and practice, and to recover and reconceptualize the hopeful, emancipatory and aspirational politics that have always underpinned self-determination. This intervention seeks to re-envision self-determination from three novel and interlinked angles: decoloniality, intersectionality, and relationality. Drawing on a range of examples of contemporary and historical self-determination claims and contestations, each author focuses on one or more of these angles to examine the extent to which current practices of and visions for self-determination engender novel understandings of emancipation from ‘foreign’ domination and/or colonial systems of governance.}
}
@article{ZHAO2024104759,
title = {Information retrieval and classification of real-time multi-source hurricane evacuation notices},
journal = {International Journal of Disaster Risk Reduction},
volume = {111},
pages = {104759},
year = {2024},
issn = {2212-4209},
doi = {https://doi.org/10.1016/j.ijdrr.2024.104759},
url = {https://www.sciencedirect.com/science/article/pii/S2212420924005211},
author = {Tingting Zhao and Shubo Tian and Jordan Daly and Melissa Geiger and Minna Jia and Jinfeng Zhang},
keywords = {Government protective action information, Information retrieval, Text classification, Natural language processing, Deep learning, Web GIS},
abstract = {In the United States, tracking time-sensitive critical information such as evacuation notices for approaching natural hazards like hurricanes poses a significant challenge. This difficulty arises from the rapid issuing and distribution of these notices by numerous local authorities that may span multiple states. Additionally, evacuation notices often undergo frequent updates, and they are distributed through various online portals lacking standard formats. Unlike weather warnings, there is no centralized database for live (or past) evacuation notices. To meet the demand of data for crisis-related government notices, we developed an approach to detect and retrieve locally issued hurricane evacuation notices in real time. Evacuation-related text data were collected mainly through spatially targeted information retrieval. These data were then manually labeled and used to train natural language processing (NLP) models. The NLP models in turn classified all text data into one of the three notice categories, i.e., mandatory evacuation notices, voluntary evacuation notices, and not an evacuation notice. The classification of mandatory evacuation notices achieved a very high accuracy (recall = 96 %). These NLP models, when applied to future hurricanes, will provide real-time evacuation notices for situation awareness to higher-level government agencies and news outlets. The archived evacuation notices serve as a valuable resource for scholars to study government responses to weather warnings and individual behaviors influenced by evacuation history. Our research framework may extend to other disaster types, allowing for rapid and targeted retrieval, classification, redistribution, and archiving of real-time government orders and notifications.}
}
@article{VANBEEK2023103195,
title = {Plausibility in models and fiction: What integrated assessment modellers can learn from an interaction with climate fiction},
journal = {Futures},
volume = {151},
pages = {103195},
year = {2023},
issn = {0016-3287},
doi = {https://doi.org/10.1016/j.futures.2023.103195},
url = {https://www.sciencedirect.com/science/article/pii/S001632872300099X},
author = {L. {Van Beek} and W. Versteeg},
keywords = {Integrated assessment model, Climate fiction, Storytelling, Mitigation scenario, Low-carbon futures, Plausibility},
abstract = {Integrated assessment models (IAMs) are critical tools to explore possible pathways to a low-carbon future. By simulating complex interactions between social and climatic processes, they help policymakers to systematically compare mitigation policies. However, their authoritative projections of cost-effective and technically feasible pathways restrict more transformative low-carbon imaginaries, especially because IAM pathways are often understood in terms of probability rather than plausibility. We suggest an interaction with climate fiction could be helpful to address this situation. Despite fundamental differences, we argue that both IAMs and climate fiction can be seen as practices of storytelling about plausible future worlds. For this exploratory article, we staged conversations between modellers and climate fiction writers to compare their respective processes of storytelling and the content of both their stories and story-worlds, focusing specifically on how they build plausibility. Whereas modellers rely on historical observations, expert judgment, transparency and rationality to build plausibility, fiction writers build plausibility by engaging with readers’ life worlds and experience, concreteness and emotionally meaningful details. Key similarities were that both modellers and fiction writers work with what-if questions, a causally connected story and build their stories through an iterative process. Based on this comparison, we suggest that an interaction between IAMs and climate fiction could be useful for improving the democratic and epistemic qualities of the IAM practice by 1) enabling a more equal dialogue between modellers and societal actors on plausible futures and 2) critically reflecting upon and broadening the spectrum of plausible futures provided by IAMs.}
}
@article{THANIKACHALAM20251971,
title = {EffNet-CNN: A Semantic Model for Image Mining & Content-Based Image Retrieval},
journal = {CMES - Computer Modeling in Engineering and Sciences},
volume = {143},
number = {2},
pages = {1971-2000},
year = {2025},
issn = {1526-1492},
doi = {https://doi.org/10.32604/cmes.2025.063063},
url = {https://www.sciencedirect.com/science/article/pii/S1526149225001456},
author = {Rajendran Thanikachalam and Anandhavalli Muniasamy and Ashwag Alasmari and Rajendran Thavasimuthu},
keywords = {Image mining, CBIR, semantic features, EffNet-CNN, image retrieval},
abstract = {Content-Based Image Retrieval (CBIR) and image mining are becoming more important study fields in computer vision due to their wide range of applications in healthcare, security, and various domains. The image retrieval system mainly relies on the efficiency and accuracy of the classification models. This research addresses the challenge of enhancing the image retrieval system by developing a novel approach, EfficientNet-Convolutional Neural Network (EffNet-CNN). The key objective of this research is to evaluate the proposed EffNet-CNN model’s performance in image classification, image mining, and CBIR. The novelty of the proposed EffNet-CNN model includes the integration of different techniques and modifications. The model includes the Mahalanobis distance metric for feature matching, which enhances the similarity measurements. The model extends EfficientNet architecture by incorporating additional convolutional layers, batch normalization, dropout, and pooling layers for improved hierarchical feature extraction. A systematic hyperparameter optimization using SGD, performance evaluation with three datasets, and data normalization for improving feature representations. The EffNet-CNN is assessed utilizing precision, accuracy, F-measure, and recall metrics across MS-COCO, CIFAR-10 and 100 datasets. The model achieved accuracy values ranging from 90.60% to 95.90% for the MS-COCO dataset, 96.8% to 98.3% for the CIFAR-10 dataset and 92.9% to 98.6% for the CIFAR-100 dataset. A validation of the EffNet-CNN model’s results with other models reveals the proposed model’s superior performance. The results highlight the potential of the EffNet-CNN model proposed for image classification and its usefulness in image mining and CBIR.}
}
@article{XU2025,
title = {Model-Driven Integration of Deep Learning for Artifact Classification in Museum Information Systems},
journal = {International Journal of Information Technology and Web Engineering},
volume = {20},
number = {1},
year = {2025},
issn = {1554-1045},
doi = {https://doi.org/10.4018/IJITWE.387650},
url = {https://www.sciencedirect.com/science/article/pii/S1554104525000038},
author = {Ke Xu and Qiong Wu and Yujiao Hou},
keywords = {Museum Information Systems, Deep Learning, Convolutional Neural Networks, Model-Driven Architecture, Artifact Classification, Cultural Heritage, Image Retrieval, Semantic},
abstract = {ABSTRACT
Museum Information Systems (MIS) often rely on manual classification and keyword search, limiting accuracy and scalability. Deep learning offers a solution, but effective integration requires alignment with curatorial workflows. This study proposes a model-driven framework for integrating Convolutional Neural Networks (CNNs) into MIS to enhance artifact classification and retrieval. A prototype was built using ReactJS, Django, and TensorFlow, and it was trained on a curated subset of The Met’s Open Access Images. The system employs a Hybrid-E Loss for improved classification accuracy. The model achieved 94.3% classification accuracy and real-time retrieval latency below 100 ms, with throughput exceeding 14 queries per second. The framework successfully bridges AI performance with curatorial logic, demonstrating a scalable and interpretable solution for digital heritage systems.}
}
@article{AMOR2024102764,
title = {Digital regulatory compliance checking for the construction industry},
journal = {Advanced Engineering Informatics},
volume = {61},
pages = {102764},
year = {2024},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2024.102764},
url = {https://www.sciencedirect.com/science/article/pii/S1474034624004129},
author = {Robert Amor and Bimal Kumar and Richard Watson}
}
@article{OSTBERG202219,
title = {Domain Models and Data Modeling as Drivers for Data Management: The ASSISTANT Data Fabric Approach},
journal = {IFAC-PapersOnLine},
volume = {55},
number = {10},
pages = {19-24},
year = {2022},
note = {10th IFAC Conference on Manufacturing Modelling, Management and Control MIM 2022},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2022.09.362},
url = {https://www.sciencedirect.com/science/article/pii/S2405896322016287},
author = {Per-Olov Östberg and Eduardo Vyhmeister and Gabriel G. Castañé and Bart Meyers and Johan {Van Noten}},
keywords = {Domain Models, Knowledge Graph, Data Modeling, Data Fabric, Data Base, Data Lake, AI, adaptive manufacturing},
abstract = {To develop AI-based models capable of governing or providing decision support to complex manufacturing environments, abstractions and mechanisms for unified management of data storage and processing capabilities are needed. Specifically, as such models tend to include and rely on detailed representations of systems, components, and tools with complex interactions, mechanisms for simplifying, integrating, and scaling management capabilities in the presence of complex data requirements (e.g., high volume, velocity, and diversity of data) are of particular interest. A data fabric is a system that provides a unified architecture for management and provisioning of data. In this work we present the background, design requirements, and high-level outline of the ASSISTANT data fabric - a flexible data management tool designed for use in adaptive manufacturing contexts. The paper outlines the implementation of the system with specific focus on the use of domain models and the data modeling approach used, as well as provides a generic use case structure reusable in many industrial contexts.}
}
@article{DAO2024100367,
title = {Interlinking BIM and GIS data for a semantic pedestrian network and applications in high-density cities},
journal = {Developments in the Built Environment},
volume = {17},
pages = {100367},
year = {2024},
issn = {2666-1659},
doi = {https://doi.org/10.1016/j.dibe.2024.100367},
url = {https://www.sciencedirect.com/science/article/pii/S2666165924000486},
author = {Jicao Dao and S. Thomas Ng and Chung Yee Kwok},
keywords = {BIM, GIS, Linked data, Data integration, Pedestrian network},
abstract = {In high-density cities, pedestrians frequently traverse many publicly accessible indoor spaces, such as metro stations and footbridges, which seamlessly connect with outdoor sidewalks, forming indoor-outdoor combined pedestrian networks. However, the information island phenomenon hinders these connections in the digital world because outdoor sidewalks and indoor spaces are modelled using Geographical Information Systems (GIS) and Building Information Modelling (BIM) technologies, respectively, which challenges obtaining integrated information for intelligent pedestrian services. This study presents an approach for interlinking BIM and GIS data for a semantic pedestrian network using semantic web technologies. The proposed approach automatically converts BIM and GIS data into linked data and establishes interlinkages between BIM and GIS data through semantic queries and inferences. The resulting semantic pedestrian network based on integrated linked data graphs forms a knowledge base, including topological and geometrical information and abundant semantic information from BIM and GIS datasets. The application potential of the semantic pedestrian network is demonstrated through information query and semantic route planning. This research contributes to establishing indoor-outdoor combined semantic pedestrian networks ensuring seamless data integration.}
}
@article{ZHANG2022104535,
title = {Automatic construction site hazard identification integrating construction scene graphs with BERT based domain knowledge},
journal = {Automation in Construction},
volume = {142},
pages = {104535},
year = {2022},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2022.104535},
url = {https://www.sciencedirect.com/science/article/pii/S092658052200406X},
author = {Lite Zhang and Junjie Wang and Yanbo Wang and Hai Sun and Xuebing Zhao},
keywords = {Scene graph, BERT, Hazards, Natural language processing, Safety},
abstract = {Hazards often arise from interactions of different parties and can cost great loss. Proactively identification can prevent it from happening. Computer vision currently can identify the entities and attributes inside the construction scenes but fail to generate interaction-level scene descriptions and integrate them with domain knowledge for hazards inference. This paper proposed an automatic hazard inference method using construction scene graphs and C-BERT network. First, computer vision was utilized to build the construction scene graphs with interaction-level scene descriptions including entities, attributes, and their interactions. Second, C-BERT network was designed to infer hazards by integrating scene graphs with domain knowledge like construction regulations. 5 different working scenes were used to demonstrate the validity of the proposed approach and reached 97.82% of hazard identification accuracy. It provided an efficient method for combining visual information and domain knowledge for automated safety monitoring, and path for the industry's massive multimodal information fusion.}
}
@article{PIADMORFFIS2020103517,
title = {A computational ecosystem to support eHealth Knowledge Discovery technologies in Spanish},
journal = {Journal of Biomedical Informatics},
volume = {109},
pages = {103517},
year = {2020},
issn = {1532-0464},
doi = {https://doi.org/10.1016/j.jbi.2020.103517},
url = {https://www.sciencedirect.com/science/article/pii/S1532046420301453},
author = {Alejandro Piad-Morffis and Yoan Gutiérrez and Yudivian Almeida-Cruz and Rafael Muñoz},
keywords = {Knowledge discovery, Annotated corpora, Semantic annotation models, Entity recognition, Relation extraction, Natural language processing},
abstract = {The massive amount of biomedical information published online requires the development of automatic knowledge discovery technologies to effectively make use of this available content. To foster and support this, the research community creates linguistic resources, such as annotated corpora, and designs shared evaluation campaigns and academic competitive challenges. This work describes an ecosystem that facilitates research and development in knowledge discovery in the biomedical domain, specifically in Spanish language. To this end, several resources are developed and shared with the research community, including a novel semantic annotation model, an annotated corpus of 1045 sentences, and computational resources to build and evaluate automatic knowledge discovery techniques. Furthermore, a research task is defined with objective evaluation criteria, and an online evaluation environment is setup and maintained, enabling researchers interested in this task to obtain immediate feedback and compare their results with the state-of-the-art. As a case study, we analyze the results of a competitive challenge based on these resources and provide guidelines for future research. The constructed ecosystem provides an effective learning and evaluation environment to encourage research in knowledge discovery in Spanish biomedical documents.}
}
@article{TANG2020,
title = {Novel prognostic prediction model constructed through machine learning on the basis of methylation-driven genes in kidney renal clear cell carcinoma},
journal = {Bioscience Reports},
volume = {40},
number = {7},
year = {2020},
issn = {1573-4935},
doi = {https://doi.org/10.1042/BSR20201604},
url = {https://www.sciencedirect.com/science/article/pii/S1573493520006384},
author = {Weihao Tang and Yiling Cao and Xiaoke Ma},
keywords = {KIRC, methylation-driven gene, methylation, prognostic prediction model},
abstract = {Kidney renal clear cell carcinoma (KIRC) is a common tumor with poor prognosis and is closely related to many aberrant gene expressions. DNA methylation is an important epigenetic modification mechanism and a novel research target. Thus, exploring the relationship between methylation-driven genes and KIRC prognosis is important. The methylation profile, methylation-driven genes, and methylation characteristics in KIRC was revealed through the integration of KIRC methylation, RNA-seq, and clinical information data from The Cancer Genome Atlas. The Lasso regression was used to establish a prognosis model on the basis of methylation-driven genes. Then, a trans-omics prognostic nomogram was constructed and evaluated by combining clinical information and methylated prognosis model. A total of 242 methylation-driven genes were identified. The Gene Ontology terms of these methylation-driven genes mainly clustered in the activation, adhesion, and proliferation of immune cells. The methylation prognosis prediction model that was established using the Lasso regression included four genes in the methylation data, namely, FOXI2, USP44, EVI2A, and TRIP13. The areas under the receiver operating characteristic curve of 1-, 3-, and 5-year survival rates were 0.810, 0.824, and 0.799, respectively, in the training group and 0.794, 0.752, and 0.731, respectively, in the testing group. An easy trans-omics nomogram was successfully established. The C-indices of the nomogram in the training and the testing groups were 0.8015 and 0.8389, respectively. The present study revealed the overall perspective of methylation-driven genes in KIRC and can help in the evaluation of the prognosis of KIRC patients and provide new clues for further study.}
}
@article{ZHAO201839,
title = {Exploiting the semantic graph for the representation and retrieval of medical documents},
journal = {Computers in Biology and Medicine},
volume = {101},
pages = {39-50},
year = {2018},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2018.08.009},
url = {https://www.sciencedirect.com/science/article/pii/S0010482518302270},
author = {Qing Zhao and Yangyang Kang and Jianqiang Li and Dan Wang},
keywords = {Semantic information retrieval, Medical search, Document ranking, Electronic medical records},
abstract = {Objective
The objective of this study was to propose a graph-based semantic search approach by addressing the inherent complexity and ambiguity of medical terminology in queries and clinical text for enhanced medical information retrieval.
Methods
The supportive use of a medical domain ontology exploits the light-weight semantics discovered from queries and documents for enhanced document ranking. First, the implicit information regarding concepts and the relations between them is discovered in the documents and queries and is used to evaluate the relevance of the query-document; then, the semantic linkages between concepts distributed in target documents and reference documents are built and used to score the document's popularity; finally, the above two evaluations are integrated to produce the final ranking list for document ranking.
Results
Empirical experiments are conducted on two different datasets. The results demonstrate that the proposed graph-based approach significantly outperforms the baselines. For example, the average performance improvement on two datasets of the best variant of GSRM compared to the best baseline achieve 7.2% and 7.9% in terms of P@20 and NDCG@20, respectively, which illustrates the effectiveness of the proposed approach.}
}
@article{YUAN2023108498,
title = {EDC-DTI: An end-to-end deep collaborative learning model based on multiple information for drug-target interactions prediction},
journal = {Journal of Molecular Graphics and Modelling},
volume = {122},
pages = {108498},
year = {2023},
issn = {1093-3263},
doi = {https://doi.org/10.1016/j.jmgm.2023.108498},
url = {https://www.sciencedirect.com/science/article/pii/S1093326323000967},
author = {Yongna Yuan and Yuhao Zhang and Xiangbo Meng and Zhenyu Liu and Bohan Wang and Ruidong Miao and Ruisheng Zhang and Wei Su and Lei Liu},
keywords = {DTIs prediction, Deep learning, Graph attention network, Heterogeneous network},
abstract = {Innovations in drug–target interactions (DTIs) prediction accelerate the progression of drug development. The introduction of deep learning models has a dramatic impact on DTIs prediction, with a distinct influence on saving time and money in drug discovery. This study develops an end-to-end deep collaborative learning model for DTIs prediction, called EDC-DTI, to identify new targets for existing drugs based on multiple drug-target-related information including homogeneous information and heterogeneous information by the way of deep learning. Our end-to-end model is composed of a feature builder and a classifier. Feature builder consists of two collaborative feature construction algorithms that extract the molecular properties and the topology property of networks, and the classifier consists of a feature encoder and a feature decoder which are designed for feature integration and DTIs prediction, respectively. The feature encoder, mainly based on the improved graph attention network, incorporates heterogeneous information into drug features and target features separately. The feature decoder is composed of multiple neural networks for predictions. Compared with six popular baseline models, EDC-DTI achieves highest predictive performance in the case of low computational costs. Robustness tests demonstrate that EDC-DTI is able to maintain strong predictive performance on sparse datasets. As well, we use the model to predict the most likely targets to interact with Simvastatin (DB00641), Nifedipine (DB01115) and Afatinib (DB08916) as examples. Results show that most of the predictions can be confirmed by literature with clear evidence.}
}
@article{LI2024106593,
title = {Comparative transcriptomics reveals common and strain-specific responses of human macrophages to infection with Mycobacterium tuberculosis and Mycobacterium bovis BCG},
journal = {Microbial Pathogenesis},
volume = {189},
pages = {106593},
year = {2024},
issn = {0882-4010},
doi = {https://doi.org/10.1016/j.micpath.2024.106593},
url = {https://www.sciencedirect.com/science/article/pii/S0882401024000603},
author = {Pei Li and Yang Li and Cun Chuan Wang and Li Gang Xia},
keywords = {Macrophages, Transcriptomics, , Bacillus Calmette–Guérin, Apoptosis},
abstract = {Mycobacterium tuberculosis (MTB) and Mycobacterium bovis (M. bovis) are closely related pathogenic mycobacteria known to cause chronic pulmonary infections in both humans and animals. Despite sharing nearly identical genomes and virulence factors, these two bacteria display variations in host tropism, epidemiology, and clinical presentations. M. bovis Bacillus Calmette–Guérin (BCG) is an attenuated strain of M. bovis commonly utilized as a vaccine for tuberculosis (TB). Nevertheless, the molecular underpinnings of these distinctions and the intricacies of host-pathogen interactions remain areas of ongoing research. In this study, a comparative transcriptomic analysis was conducted on human leukemia macrophages (THP-1) infected with either MTB H37Rv or M. bovis BCG (Tokyo strain) to elucidate common and strain-specific responses at the transcriptional level. RNA sequencing was utilized to characterize the transcriptomes of human primary macrophages infected with MTB or BCG at 6 and 24 h post-infection. The findings indicate that both MTB and BCG induce substantial and dynamic alterations in the transcriptomes of THP-1, with a notable overlap in the quantity and extent of differentially expressed genes (DEGs). Moreover, gene ontology (GO) enrichment analysis unveiled shared pathways related to immune response, cytokine signaling, and apoptosis. The immune response of macrophages to bacterial infections at 6 h exhibited significantly greater intensity compared to that at 24 h. Furthermore, distinct gene sets displaying notable variances between MTB and BCG infections were identified. The profound impact of MTB infection on macrophage gene expression, particularly within the initial 6 h, was evident. Additionally, downregulation of pathways such as Focal adhesion, Rap1 signaling pathway, and Regulation of actin cytoskeleton was observed. The pathways associated with inflammation reactions and cell apoptosis exhibited significant differences, with BCG triggering macrophage apoptosis and MTB enhancing the survival of intracellular bacteria. Our findings reveal that MTB and BCG provoke similar yet distinct transcriptional responses in human macrophages, indicating variations in their pathogenesis and ability to adapt to host environments. These results offer novel insights into the molecular mechanisms governing host-pathogen interactions and may contribute to a deeper understanding of TB pathogenesis.}
}
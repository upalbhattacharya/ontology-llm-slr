"Key","Item Type","Publication Year","Author","Title","Publication Title","ISBN","ISSN","DOI","Url","Abstract Note","Date","Date Added","Date Modified","Access Date","Pages","Num Pages","Issue","Volume","Number Of Volumes","Journal Abbreviation","Short Title","Series","Series Number","Series Text","Series Title","Publisher","Place","Language","Rights","Type","Archive","Archive Location","Library Catalog","Call Number","Extra","Notes","File Attachments","Link Attachments","Manual Tags","Automatic Tags","Editor","Series Editor","Translator","Contributor","Attorney Agent","Book Author","Cast Member","Commenter","Composer","Cosponsor","Counsel","Interviewer","Producer","Recipient","Reviewed Author","Scriptwriter","Words By","Guest","Number","Edition","Running Time","Scale","Medium","Artwork Size","Filing Date","Application Number","Assignee","Issuing Authority","Country","Meeting Name","Conference Name","Court","References","Reporter","Legal Status","Priority Numbers","Programming Language","Version","System","Code","Code Number","Section","Session","Committee","History","Legislative Body"
"JIV5NVK9","conferencePaper","2018","Gritz, Maria","Towards Lexical Meaning Formal Representation by virtue of the NL-DL Definition Transformation Method","Proceedings of the Third International Conference on Computational Linguistics in Bulgaria (CLIB 2018)","","","","https://aclanthology.org/2018.clib-1.5/","The paper represents a part of an extensive study devoted to the issues of lexical meaning formal representation in OWL 2 DL notation. Both theoretical and methodological aspects of lexical meaning formalization within the framework of an ontology are observed in the paper. Model-theoretic semantics paradigm and Kripke model are considered to form a theoretical background for formalization of lexical meaning, whereas the NL-DL definition transformation method is investigated as a method designed to provide us with acceptable formal definitions in OWL 2 DL notation with natural language definitions given at the input. A brief critical study of the method has allowed to reveal particular problematic cases of the method application, which arise due to syntactic peculiarities of natural language definitions given at the input.","2018-05","2025-09-10 13:17:16","2025-09-10 13:17:16","","23–33","","","","","","","","","","","Department of Computational Linguistics, Institute for Bulgarian Language, Bulgarian Academy of Sciences","Sofia, Bulgaria","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"T2JUVG2Z","conferencePaper","2018","Maziarz, Marek; Piasecki, Maciej","Towards Mapping Thesauri onto plWordNet","Proceedings of the 9th Global Wordnet Conference","","","","https://aclanthology.org/2018.gwc-1.6/","plWordNet, the wordnet of Polish, has become a very comprehensive description of the Polish lexical system. This paper presents a plan of its semi-automated integration with thesauri, terminological databases and ontologies, as a further necessary step in its development. This will improve linking of plWordNet into Linked Open Data, and facilitate applications in, e.g., WSD, keyword extraction or automated metadata generation. We present an overview of resources relevant to Polish and a plan for their linking to plWordNet.","2018-01","2025-09-10 13:17:16","2025-09-10 13:17:16","","44–52","","","","","","","","","","","Global Wordnet Association","Nanyang Technological University (NTU), Singapore","","","","","","","","","","","","","","Bond, Francis; Vossen, Piek; Fellbaum, Christiane","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8BBYNJ34","conferencePaper","2018","Pease, Adam; Cheung, Andrew","Toward a Semantic Concordancer","Proceedings of the 9th Global Wordnet Conference","","","","https://aclanthology.org/2018.gwc-1.12/","Concordancers are an accepted and valuable part of the tool set of linguists and lexicographers. They allow the user to see the context of use of a word or phrase in a corpus. A large enough corpus, such as the Corpus Of Contemporary American English, provides the data needed to enumerate all common uses or meanings. One challenge is that there may be too many results for short search phrases or common words when only a specific context is desired. However, finding meaningful groupings of usage may be impractical if it entails enumerating long lists of possible values, such as city names. If a tool existed that could create some semantic abstractions, it would free the lexicographer from the need to resort to customized development of analysis software. To address this need, we have developed a Semantic Concordancer that uses dependency parsing and the Suggested Upper Merged Ontology (SUMO) to support linguistic analysis at a level of semantic abstraction above the original textual elements. We show how this facility can be employed to analyze the use of English prepositions by non-native speakers. We briefly introduce condordancers and then describe the corpora on which we applied this work. Next we provide a detailed description of the NLP pipeline followed by how this captures detailed semantics. We show how the semantics can be used to analyze errors in the use of English prepositions by non-native speakers of English. Then we provide a description of a tool that allows users to build semantic search specifications from a set of English examples and how those results can be employed to build rules that translate sentences into logical forms. Finally, we summarize our conclusions and mention future work.","2018-01","2025-09-10 13:17:16","2025-09-10 13:17:16","","97–104","","","","","","","","","","","Global Wordnet Association","Nanyang Technological University (NTU), Singapore","","","","","","","","","","","","","","Bond, Francis; Vossen, Piek; Fellbaum, Christiane","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EPVV4MDS","conferencePaper","2018","Muniz, Henrique; Chalub, Fabricio; Rademaker, Alexandre; Paiva, Valeria De","Extending Wordnet to Geological Times","Proceedings of the 9th Global Wordnet Conference","","","","https://aclanthology.org/2018.gwc-1.17/","This paper describes work extending Princeton WordNet to the domain of geological texts, associated with the time periods of the geological eras of the Earth History. We intend this extension to be considered as an example for any other domain extension that we might want to pursue. To provide this extension, we first produce a textual version of Princeton WordNet. Then we map a fragment of the International Commission on Stratigraphy (ICS) ontologies to WordNet and create the appropriate new synsets. We check the extended ontology on a small corpus of sentences from Gas and Oil technical reports and realize that more work needs to be done, as we need new words, new senses and new compounds in our extended WordNet.","2018-01","2025-09-10 13:17:16","2025-09-10 13:17:16","","145–152","","","","","","","","","","","Global Wordnet Association","Nanyang Technological University (NTU), Singapore","","","","","","","","","","","","","","Bond, Francis; Vossen, Piek; Fellbaum, Christiane","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8AS35IZG","conferencePaper","2018","Pedersen, Bolette; Agirrezabal, Manex; Nimb, Sanni; Olsen, Ida; Olsen, Sussi","Towards a principled approach to sense clustering – a case study of wordnet and dictionary senses in Danish","Proceedings of the 9th Global Wordnet Conference","","","","https://aclanthology.org/2018.gwc-1.21/","Our aim is to develop principled methods for sense clustering which can make existing lexical resources practically useful in NLP – not too fine-grained to be operational and yet finegrained enough to be worth the trouble. Where traditional dictionaries have a highly structured sense inventory typically describing the vocabulary by means of mainand subsenses, wordnets are generally fine-grained and unstructured. We present a series of clustering and annotation experiments with 10 of the most polysemous nouns in Danish. We combine the structured information of a traditional Danish dictionary with the ontological types found in the Danish wordnet, DanNet. This constellation enables us to automatically cluster senses in a principled way and improve inter-annotator agreement and wsd performance.","2018-01","2025-09-10 13:17:16","2025-09-10 13:17:16","","182–189","","","","","","","","","","","Global Wordnet Association","Nanyang Technological University (NTU), Singapore","","","","","","","","","","","","","","Bond, Francis; Vossen, Piek; Fellbaum, Christiane","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NGVVEWXM","conferencePaper","2019","Iyer, Vivek; Mohan, Lalit; Bhatia, Mehar; Reddy, Y. Raghu","A Survey on Ontology Enrichment from Text","Proceedings of the 16th International Conference on Natural Language Processing","","","","https://aclanthology.org/2019.icon-1.11/","Increased internet bandwidth at low cost is leading to the creation of large volumes of unstructured data. This data explosion opens up opportunities for the creation of a variety of data-driven intelligent systems, such as the Semantic Web. Ontologies form one of the most crucial layers of semantic web, and the extraction and enrichment of ontologies given this data explosion becomes an inevitable research problem. In this paper, we survey the literature on semi-automatic and automatic ontology extraction and enrichment and classify them into four broad categories based on the approach. Then, we proceed to narrow down four algorithms from each of these categories, implement and analytically compare them based on parameters like context relevance, efficiency and precision. Lastly, we propose a Long Short Term Memory Networks (LSTM) based deep learning approach to try and overcome the gaps identified in these approaches.","2019-12","2025-09-10 13:17:16","2025-09-10 13:17:16","","95–104","","","","","","","","","","","NLP Association of India","International Institute of Information Technology, Hyderabad, India","","","","","","","","","","","","","","Sharma, Dipti Misra; Bhattacharya, Pushpak","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"T29SGTXX","conferencePaper","2020","Campagna, Giovanni; Foryciarz, Agata; Moradshahi, Mehrad; Lam, Monica","Zero-Shot Transfer Learning with Synthesized Data for Multi-Domain Dialogue State Tracking","Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics","","","10.18653/v1/2020.acl-main.12","https://aclanthology.org/2020.acl-main.12/","Zero-shot transfer learning for multi-domain dialogue state tracking can allow us to handle new domains without incurring the high cost of data acquisition. This paper proposes new zero-short transfer learning technique for dialogue state tracking where the in-domain training data are all synthesized from an abstract dialogue model and the ontology of the domain. We show that data augmentation through synthesized data can improve the accuracy of zero-shot learning for both the TRADE model and the BERT-based SUMBT model on the MultiWOZ 2.1 dataset. We show training with only synthesized in-domain data on the SUMBT model can reach about 2/3 of the accuracy obtained with the full training dataset. We improve the zero-shot learning state of the art on average across domains by 21%.","2020-07","2025-09-10 13:17:16","2025-09-10 13:17:16","","122–132","","","","","","","","","","","Association for Computational Linguistics","Online","","","","","","","","","","","","","","Jurafsky, Dan; Chai, Joyce; Schluter, Natalie; Tetreault, Joel","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IA7ZEV5H","conferencePaper","2020","Sotudeh Gharebagh, Sajad; Goharian, Nazli; Filice, Ross","Attend to Medical Ontologies: Content Selection for Clinical Abstractive Summarization","Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics","","","10.18653/v1/2020.acl-main.172","https://aclanthology.org/2020.acl-main.172/","Sequence-to-sequence (seq2seq) network is a well-established model for text summarization task. It can learn to produce readable content; however, it falls short in effectively identifying key regions of the source. In this paper, we approach the content selection problem for clinical abstractive summarization by augmenting salient ontological terms into the summarizer. Our experiments on two publicly available clinical data sets (107,372 reports of MIMIC-CXR, and 3,366 reports of OpenI) show that our model statistically significantly boosts state-of-the-art results in terms of ROUGE metrics (with improvements: 2.9% RG-1, 2.5% RG-2, 1.9% RG-L), in the healthcare domain where any range of improvement impacts patients' welfare.","2020-07","2025-09-10 13:17:16","2025-09-10 13:17:16","","1899–1905","","","","","","","","","","","Association for Computational Linguistics","Online","","","","","","","","","","","","","","Jurafsky, Dan; Chai, Joyce; Schluter, Natalie; Tetreault, Joel","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KZNUDZIF","conferencePaper","2020","Xu, Dongfang; Zhang, Zeyu; Bethard, Steven","A Generate-and-Rank Framework with Semantic Type Regularization for Biomedical Concept Normalization","Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics","","","10.18653/v1/2020.acl-main.748","https://aclanthology.org/2020.acl-main.748/","Concept normalization, the task of linking textual mentions of concepts to concepts in an ontology, is challenging because ontologies are large. In most cases, annotated datasets cover only a small sample of the concepts, yet concept normalizers are expected to predict all concepts in the ontology. In this paper, we propose an architecture consisting of a candidate generator and a list-wise ranker based on BERT. The ranker considers pairings of concept mentions and candidate concepts, allowing it to make predictions for any concept, not just those seen during training. We further enhance this list-wise approach with a semantic type regularizer that allows the model to incorporate semantic type information from the ontology during training. Our proposed concept normalization framework achieves state-of-the-art performance on multiple datasets.","2020-07","2025-09-10 13:17:17","2025-09-10 13:17:17","","8452–8464","","","","","","","","","","","Association for Computational Linguistics","Online","","","","","","","","","","","","","","Jurafsky, Dan; Chai, Joyce; Schluter, Natalie; Tetreault, Joel","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MS2L5IXM","conferencePaper","2020","Schumacher, Elliot; Mulyar, Andriy; Dredze, Mark","Clinical Concept Linking with Contextualized Neural Representations","Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics","","","10.18653/v1/2020.acl-main.760","https://aclanthology.org/2020.acl-main.760/","In traditional approaches to entity linking, linking decisions are based on three sources of information – the similarity of the mention string to an entity's name, the similarity of the context of the document to the entity, and broader information about the knowledge base (KB). In some domains, there is little contextual information present in the KB and thus we rely more heavily on mention string similarity. We consider one example of this, concept linking, which seeks to link mentions of medical concepts to a medical concept ontology. We propose an approach to concept linking that leverages recent work in contextualized neural models, such as ELMo (Peters et al. 2018), which create a token representation that integrates the surrounding context of the mention and concept name. We find a neural ranking approach paired with contextualized embeddings provides gains over a competitive baseline (Leaman et al. 2013). Additionally, we find that a pre-training step using synonyms from the ontology offers a useful initialization for the ranker.","2020-07","2025-09-10 13:17:17","2025-09-10 13:17:17","","8585–8592","","","","","","","","","","","Association for Computational Linguistics","Online","","","","","","","","","","","","","","Jurafsky, Dan; Chai, Joyce; Schluter, Natalie; Tetreault, Joel","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GKX4VKIF","conferencePaper","2020","Li, Manling; Zareian, Alireza; Lin, Ying; Pan, Xiaoman; Whitehead, Spencer; Chen, Brian; Wu, Bo; Ji, Heng; Chang, Shih-Fu; Voss, Clare; Napierski, Daniel; Freedman, Marjorie","GAIA: A Fine-grained Multimedia Knowledge Extraction System","Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: System Demonstrations","","","10.18653/v1/2020.acl-demos.11","https://aclanthology.org/2020.acl-demos.11/","We present the first comprehensive, open source multimedia knowledge extraction system that takes a massive stream of unstructured, heterogeneous multimedia data from various sources and languages as input, and creates a coherent, structured knowledge base, indexing entities, relations, and events, following a rich, fine-grained ontology. Our system, GAIA, enables seamless search of complex graph queries, and retrieves multimedia evidence including text, images and videos. GAIA achieves top performance at the recent NIST TAC SM-KBP2019 evaluation. The system is publicly available at GitHub and DockerHub, with a narrated video that documents the system.","2020-07","2025-09-10 13:17:17","2025-09-10 13:17:17","","77–86","","","","","","","","","","","Association for Computational Linguistics","Online","","","","","","","","","","","","","","Celikyilmaz, Asli; Wen, Tsung-Hsien","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CCHZGTSP","conferencePaper","2020","Dong, Xin Luna; Hajishirzi, Hannaneh; Lockard, Colin; Shiralkar, Prashant","Multi-modal Information Extraction from Text, Semi-structured, and Tabular Data on the Web","Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics: Tutorial Abstracts","","","10.18653/v1/2020.acl-tutorials.6","https://aclanthology.org/2020.acl-tutorials.6/","The World Wide Web contains vast quantities of textual information in several forms: unstructured text, template-based semi-structured webpages (which present data in key-value pairs and lists), and tables. Methods for extracting information from these sources and converting it to a structured form have been a target of research from the natural language processing (NLP), data mining, and database communities. While these researchers have largely separated extraction from web data into different problems based on the modality of the data, they have faced similar problems such as learning with limited labeled data, defining (or avoiding defining) ontologies, making use of prior knowledge, and scaling solutions to deal with the size of the Web. In this tutorial we take a holistic view toward information extraction, exploring the commonalities in the challenges and solutions developed to address these different forms of text. We will explore the approaches targeted at unstructured text that largely rely on learning syntactic or semantic textual patterns, approaches targeted at semi-structured documents that learn to identify structural patterns in the template, and approaches targeting web tables which rely heavily on entity linking and type information. While these different data modalities have largely been considered separately in the past, recent research has started taking a more inclusive approach toward textual extraction, in which the multiple signals offered by textual, layout, and visual clues are combined into a single extraction model made possible by new deep learning approaches. At the same time, trends within purely textual extraction have shifted toward full-document understanding rather than considering sentences as independent units. With this in mind, it is worth considering the information extraction problem as a whole to motivate solutions that harness textual semantics along with visual and semi-structured layout information. We will discuss these approaches and suggest avenues for future work.","2020-07","2025-09-10 13:17:17","2025-09-10 13:17:17","","23–26","","","","","","","","","","","Association for Computational Linguistics","Online","","","","","","","","","","","","","","Savary, Agata; Zhang, Yue","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"85SZRJRV","conferencePaper","2020","Arnold, Taylor; Tilton, Lauren","Enriching Historic Photography with Structured Data using Image Region Segmentation","Proceedings of the 1st International Workshop on Artificial Intelligence for Historical Image Enrichment and Access","979-10-95546-63-4","","","https://aclanthology.org/2020.ai4hi-1.1/","Cultural institutions such as galleries, libraries, archives and museums continue to make commitments to large scale digitization of collections. An ongoing challenge is how to increase discovery and access through structured data and the semantic web. In this paper we describe a method for using computer vision algorithms that automatically detect regions of “stuff” — such as the sky, water, and roads — to produce rich and accurate structured data triples for describing the content of historic photography. We apply our method to a collection of 1610 documentary photographs produced in the 1930s and 1940 by the FSA-OWI division of the U.S. federal government. Manual verification of the extracted annotations yields an accuracy rate of 97.5%, compared to 70.7% for relations extracted from object detection and 31.5% for automatically generated captions. Our method also produces a rich set of features, providing more unique labels (1170) than either the captions (1040) or object detection (178) methods. We conclude by describing directions for a linguistically-focused ontology of region categories that can better enrich historical image data. Open source code and the extracted metadata from our corpus are made available as external resources.","2020-05","2025-09-10 13:17:17","2025-09-10 13:17:17","","1–10","","","","","","","","","","","European Language Resources Association (ELRA)","Marseille, France","eng","","","","","","","","","","","","","Abgaz, Yalemisew; Dorn, Amelie; Diaz, Jose Luis Preza; Koch, Gerda","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TE6MQ7J2","conferencePaper","2020","Breit, Anna","Interlinking Iconclass Data with Concepts of Art & Architecture Thesaurus","Proceedings of the 1st International Workshop on Artificial Intelligence for Historical Image Enrichment and Access","979-10-95546-63-4","","","https://aclanthology.org/2020.ai4hi-1.2/","Iconclass, being a a well established classification system, could benefit from interconnections with other ontologies in order to semantically enrich its content. This work presents a disambiguating and interlinking approach which is used to map Iconclass Subjects to concepts of the Art and Architecture Thesaurus. In a preliminary evaluation, the system is able to produce promising predictions, though the task is highly challenging due to conceptual and schema heterogeneity. Several algorithmic improvements for this specific interlinking task, as well as and future research directions are suggestions. The produced mappings, as well as the source code and additional information can be found at https://github.com/annabreit/taxonomy-interlinking.","2020-05","2025-09-10 13:17:17","2025-09-10 13:17:17","","11–15","","","","","","","","","","","European Language Resources Association (ELRA)","Marseille, France","eng","","","","","","","","","","","","","Abgaz, Yalemisew; Dorn, Amelie; Diaz, Jose Luis Preza; Koch, Gerda","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IZPZM936","conferencePaper","2020","Roberto, John; Ortego, Diego; Davis, Brian","Toward the Automatic Retrieval and Annotation of Outsider Art images: A Preliminary Statement","Proceedings of the 1st International Workshop on Artificial Intelligence for Historical Image Enrichment and Access","979-10-95546-63-4","","","https://aclanthology.org/2020.ai4hi-1.3/","The aim of this position paper is to establish an initial approach to the automatic classification of digital images about the Outsider Art style of painting. Specifically, we explore whether is it possible to classify non-traditional artistic styles by using the same features that are used for classifying traditional styles? Our research question is motivated by two facts. First, art historians state that non-traditional styles are influenced by factors “outside” of the world of art. Second, some studies have shown that several artistic styles confound certain classification techniques. Following current approaches to style prediction, this paper utilises Deep Learning methods to encode image features. Our preliminary experiments have provided motivation to think that, as is the case with traditional styles, Outsider Art can be computationally modelled with objective means by using training datasets and CNN models. Nevertheless, our results are not conclusive due to the lack of a large available dataset on Outsider Art. Therefore, at the end of the paper, we have mapped future lines of action, which include the compilation of a large dataset of Outsider Art images and the creation of an ontology of Outsider Art.","2020-05","2025-09-10 13:17:17","2025-09-10 13:17:17","","16–22","","","","","","","","","","","European Language Resources Association (ELRA)","Marseille, France","eng","","","","","","","","","","","","","Abgaz, Yalemisew; Dorn, Amelie; Diaz, Jose Luis Preza; Koch, Gerda","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"I2F6Q8XS","conferencePaper","2020","Das, Manirupa; Li, Juanxi; Fosler-Lussier, Eric; Lin, Simon; Rust, Steve; Huang, Yungui; Ramnath, Rajiv","Sequence-to-Set Semantic Tagging for Complex Query Reformulation and Automated Text Categorization in Biomedical IR using Self-Attention","Proceedings of the 19th SIGBioMed Workshop on Biomedical Language Processing","","","10.18653/v1/2020.bionlp-1.2","https://aclanthology.org/2020.bionlp-1.2/","Novel contexts, comprising a set of terms referring to one or more concepts, may often arise in complex querying scenarios such as in evidence-based medicine (EBM) involving biomedical literature. These may not explicitly refer to entities or canonical concept forms occurring in a fact-based knowledge source, e.g. the UMLS ontology. Moreover, hidden associations between related concepts meaningful in the current context, may not exist within a single document, but across documents in the collection. Predicting semantic concept tags of documents can therefore serve to associate documents related in unseen contexts, or categorize them, in information filtering or retrieval scenarios. Thus, inspired by the success of sequence-to-sequence neural models, we develop a novel sequence-to-set framework with attention, for learning document representations in a unique unsupervised setting, using no human-annotated document labels or external knowledge resources and only corpus-derived term statistics to drive the training, that can effect term transfer within a corpus for semantically tagging a large collection of documents. Our sequence-to-set modeling approach to predict semantic tags, gives to the best of our knowledge, the state-of-the-art for both, an unsupervised query expansion (QE) task for the TREC CDS 2016 challenge dataset when evaluated on an Okapi BM25–based document retrieval system; and also over the MLTM system baseline baseline (Soleimani and Miller, 2016), for both supervised and semi-supervised multi-label prediction tasks on the del.icio.us and Ohsumed datasets. We make our code and data publicly available.","2020-07","2025-09-10 13:17:17","2025-09-10 13:17:17","","14–27","","","","","","","","","","","Association for Computational Linguistics","Online","","","","","","","","","","","","","","Demner-Fushman, Dina; Cohen, Kevin Bretonnel; Ananiadou, Sophia; Tsujii, Junichi","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YXQALK9K","conferencePaper","2020","Chang, David; Balažević, Ivana; Allen, Carl; Chawla, Daniel; Brandt, Cynthia; Taylor, Andrew","Benchmark and Best Practices for Biomedical Knowledge Graph Embeddings","Proceedings of the 19th SIGBioMed Workshop on Biomedical Language Processing","","","10.18653/v1/2020.bionlp-1.18","https://aclanthology.org/2020.bionlp-1.18/","Much of biomedical and healthcare data is encoded in discrete, symbolic form such as text and medical codes. There is a wealth of expert-curated biomedical domain knowledge stored in knowledge bases and ontologies, but the lack of reliable methods for learning knowledge representation has limited their usefulness in machine learning applications. While text-based representation learning has significantly improved in recent years through advances in natural language processing, attempts to learn biomedical concept embeddings so far have been lacking. A recent family of models called knowledge graph embeddings have shown promising results on general domain knowledge graphs, and we explore their capabilities in the biomedical domain. We train several state-of-the-art knowledge graph embedding models on the SNOMED-CT knowledge graph, provide a benchmark with comparison to existing methods and in-depth discussion on best practices, and make a case for the importance of leveraging the multi-relational nature of knowledge graphs for learning biomedical knowledge representation. The embeddings, code, and materials will be made available to the community.","2020-07","2025-09-10 13:17:17","2025-09-10 13:17:17","","167–176","","","","","","","","","","","Association for Computational Linguistics","Online","","","","","","","","","","","","","","Demner-Fushman, Dina; Cohen, Kevin Bretonnel; Ananiadou, Sophia; Tsujii, Junichi","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KGM2I4VZ","conferencePaper","2020","Peng, Yifan; Lee, Sungwon; Elton, Daniel C.; Shen, Thomas; Tang, Yu-xing; Chen, Qingyu; Wang, Shuai; Zhu, Yingying; Summers, Ronald; Lu, Zhiyong","Automatic recognition of abdominal lymph nodes from clinical text","Proceedings of the 3rd Clinical Natural Language Processing Workshop","","","10.18653/v1/2020.clinicalnlp-1.12","https://aclanthology.org/2020.clinicalnlp-1.12/","Lymph node status plays a pivotal role in the treatment of cancer. The extraction of lymph nodes from radiology text reports enables large-scale training of lymph node detection on MRI. In this work, we first propose an ontology of 41 types of abdominal lymph nodes with a hierarchical relationship. We then introduce an end-to-end approach based on the combination of rules and transformer-based methods to detect these abdominal lymph node mentions and classify their types from the MRI radiology reports. We demonstrate the superior performance of a model fine-tuned on MRI reports using BlueBERT, called MriBERT. We find that MriBERT outperforms the rule-based labeler (0.957 vs 0.644 in micro weighted F1-score) as well as other BERT-based variations (0.913 - 0.928). We make the code and MriBERT publicly available at https://github.com/ncbi-nlp/bluebert, with the hope that this method can facilitate the development of medical report annotators to produce labels from scratch at scale.","2020-11","2025-09-10 13:17:17","2025-09-10 13:17:17","","101–110","","","","","","","","","","","Association for Computational Linguistics","Online","","","","","","","","","","","","","","Rumshisky, Anna; Roberts, Kirk; Bethard, Steven; Naumann, Tristan","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"J4WC3TUL","conferencePaper","2020","Sen, Jaydeep; Babtiwale, Tanaya; Saxena, Kanishk; Butala, Yash; Bhatia, Sumit; Sankaranarayanan, Karthik","Schema Aware Semantic Reasoning for Interpreting Natural Language Queries in Enterprise Settings","Proceedings of the 28th International Conference on Computational Linguistics","","","10.18653/v1/2020.coling-main.115","https://aclanthology.org/2020.coling-main.115/","Natural Language Query interfaces allow the end-users to access the desired information without the need to know any specialized query language, data storage, or schema details. Even with the recent advances in NLP research space, the state-of-the-art QA systems fall short of understanding implicit intents of real-world Business Intelligence (BI) queries in enterprise systems, since Natural Language Understanding still remains an AI-hard problem. We posit that deploying ontology reasoning over domain semantics can help in achieving better natural language understanding for QA systems. In this paper, we specifically focus on building a Schema Aware Semantic Reasoning Framework that translates natural language interpretation as a sequence of solvable tasks by an ontology reasoner. We apply our framework on top of an ontology based, state-of-the-art natural language question-answering system ATHENA, and experiment with 4 benchmarks focused on BI queries. Our experimental numbers empirically show that the Schema Aware Semantic Reasoning indeed helps in achieving significantly better results for handling BI queries with an average accuracy improvement of \textasciitilde30%","2020-12","2025-09-10 13:17:17","2025-09-10 13:17:17","","1334–1345","","","","","","","","","","","International Committee on Computational Linguistics","Barcelona, Spain (Online)","","","","","","","","","","","","","","Scott, Donia; Bel, Nuria; Zong, Chengqing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JW5E8H29","conferencePaper","2020","Wan, Mingyu; Xing, Baixi","Modality Enriched Neural Network for Metaphor Detection","Proceedings of the 28th International Conference on Computational Linguistics","","","10.18653/v1/2020.coling-main.270","https://aclanthology.org/2020.coling-main.270/","Metaphor as a cognitive mechanism in human's conceptual system manifests itself an effective way for language communication. Although being intuitively sensible for human, metaphor detection is still a challenging task due to the subtle ontological differences between metaphorical and non-metaphorical expressions. This work proposes a modality enriched deep learning model for tackling this unsolved issue. It provides a new perspective for understanding metaphor as a modality shift, as in `sweet voice'. It also attempts to enhance metaphor detection by combining deep learning with effective linguistic insight. Extending the work at Wan et al. (2020), we concatenate word sensorimotor scores (Lynott et al., 2019) with word vectors as the input of attention-based Bi-LSTM using a benchmark dataset–the VUA corpus. The experimental results show great F1 improvement (above 0.5%) of the proposed model over other methods in record, demonstrating the usefulness of leveraging modality norms for metaphor detection.","2020-12","2025-09-10 13:17:17","2025-09-10 13:17:17","","3036–3042","","","","","","","","","","","International Committee on Computational Linguistics","Barcelona, Spain (Online)","","","","","","","","","","","","","","Scott, Donia; Bel, Nuria; Zong, Chengqing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"85HJR837","conferencePaper","2020","Betti, Arianna; Reynaert, Martin; Ossenkoppele, Thijs; Oortwijn, Yvette; Salway, Andrew; Bloem, Jelke","Expert Concept-Modeling Ground Truth Construction for Word Embeddings Evaluation in Concept-Focused Domains","Proceedings of the 28th International Conference on Computational Linguistics","","","10.18653/v1/2020.coling-main.586","https://aclanthology.org/2020.coling-main.586/","We present a novel, domain expert-controlled, replicable procedure for the construction of concept-modeling ground truths with the aim of evaluating the application of word embeddings. In particular, our method is designed to evaluate the application of word and paragraph embeddings in concept-focused textual domains, where a generic ontology does not provide enough information. We illustrate the procedure, and validate it by describing the construction of an expert ground truth, QuiNE-GT. QuiNE-GT is built to answer research questions concerning the concept of naturalized epistemology in QUINE, a 2-million-token, single-author, 20th-century English philosophy corpus of outstanding quality, cleaned up and enriched for the purpose. To the best of our ken, expert concept-modeling ground truths are extremely rare in current literature, nor has the theoretical methodology behind their construction ever been explicitly conceptualised and properly systematised. Expert-controlled concept-modeling ground truths are however essential to allow proper evaluation of word embeddings techniques, and increase their trustworthiness in specialised domains in which the detection of concepts through their expression in texts is important. We highlight challenges, requirements, and prospects for future work.","2020-12","2025-09-10 13:17:17","2025-09-10 13:17:17","","6690–6702","","","","","","","","","","","International Committee on Computational Linguistics","Barcelona, Spain (Online)","","","","","","","","","","","","","","Scott, Donia; Bel, Nuria; Zong, Chengqing","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NIXTMHTV","conferencePaper","2020","Giacomini, Laura; Schäfer, Johannes","Computational Aspects of Frame-based Meaning Representation in Terminology","Proceedings of the 6th International Workshop on Computational Terminology","979-10-95546-57-3","","","https://aclanthology.org/2020.computerm-1.11/","Our contribution is part of a wider research project on term variation in German and concentrates on the computational aspects of a frame-based model for term meaning representation in the technical field. We focus on the role of frames (in the sense of Frame-Based Terminology) as the semantic interface between concepts covered by a domain ontology and domain-specific terminology. In particular, we describe methods for performing frame-based corpus annotation and frame-based term extraction. The aim of the contribution is to discuss the capacity of the model to automatically acquire semantic knowledge suitable for terminographic information tools such as specialised dictionaries, and its applicability to further specialised languages.","2020-05","2025-09-10 13:17:17","2025-09-10 13:17:17","","80–84","","","","","","","","","","","European Language Resources Association","Marseille, France","eng","","","","","","","","","","","","","Daille, Béatrice; Kageura, Kyo; Terryn, Ayla Rigouts","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QA7L82TY","conferencePaper","2020","Wang, Yexiang; Guo, Yi; Zhu, Siqi","Slot Attention with Value Normalization for Multi-Domain Dialogue State Tracking","Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)","","","10.18653/v1/2020.emnlp-main.243","https://aclanthology.org/2020.emnlp-main.243/","Incompleteness of domain ontology and unavailability of some values are two inevitable problems of dialogue state tracking (DST). Existing approaches generally fall into two extremes: choosing models without ontology or embedding ontology in models leading to over-dependence. In this paper, we propose a new architecture to cleverly exploit ontology, which consists of Slot Attention (SA) and Value Normalization (VN), referred to as SAVN. Moreover, we supplement the annotation of supporting span for MultiWOZ 2.1, which is the shortest span in utterances to support the labeled value. SA shares knowledge between slots and utterances and only needs a simple structure to predict the supporting span. VN is designed specifically for the use of ontology, which can convert supporting spans to the values. Empirical results demonstrate that SAVN achieves the state-of-the-art joint accuracy of 54.52% on MultiWOZ 2.0 and 54.86% on MultiWOZ 2.1. Besides, we evaluate VN with incomplete ontology. The results show that even if only 30% ontology is used, VN can also contribute to our model.","2020-11","2025-09-10 13:17:17","2025-09-10 13:17:17","","3019–3028","","","","","","","","","","","Association for Computational Linguistics","Online","","","","","","","","","","","","","","Webber, Bonnie; Cohn, Trevor; He, Yulan; Liu, Yang","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"G2ASXYJF","conferencePaper","2020","Epure, Elena V.; Salha, Guillaume; Moussallam, Manuel; Hennequin, Romain","Modeling the Music Genre Perception across Language-Bound Cultures","Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)","","","10.18653/v1/2020.emnlp-main.386","https://aclanthology.org/2020.emnlp-main.386/","The music genre perception expressed through human annotations of artists or albums varies significantly across language-bound cultures. These variations cannot be modeled as mere translations since we also need to account for cultural differences in the music genre perception. In this work, we study the feasibility of obtaining relevant cross-lingual, culture-specific music genre annotations based only on language-specific semantic representations, namely distributed concept embeddings and ontologies. Our study, focused on six languages, shows that unsupervised cross-lingual music genre annotation is feasible with high accuracy, especially when combining both types of representations. This approach of studying music genres is the most extensive to date and has many implications in musicology and music information retrieval. Besides, we introduce a new, domain-dependent cross-lingual corpus to benchmark state of the art multilingual pre-trained embedding models.","2020-11","2025-09-10 13:17:17","2025-09-10 13:17:17","","4765–4779","","","","","","","","","","","Association for Computational Linguistics","Online","","","","","","","","","","","","","","Webber, Bonnie; Cohn, Trevor; He, Yulan; Liu, Yang","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Z4VDKJMG","conferencePaper","2020","Moradshahi, Mehrad; Campagna, Giovanni; Semnani, Sina; Xu, Silei; Lam, Monica","Localizing Open-Ontology QA Semantic Parsers in a Day Using Machine Translation","Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)","","","10.18653/v1/2020.emnlp-main.481","https://aclanthology.org/2020.emnlp-main.481/","We propose Semantic Parser Localizer (SPL), a toolkit that leverages Neural Machine Translation (NMT) systems to localize a semantic parser for a new language. Our methodology is to (1) generate training data automatically in the target language by augmenting machine-translated datasets with local entities scraped from public websites, (2) add a few-shot boost of human-translated sentences and train a novel XLMR-LSTM semantic parser, and (3) test the model on natural utterances curated using human translators. We assess the effectiveness of our approach by extending the current capabilities of Schema2QA, a system for English Question Answering (QA) on the open web, to 10 new languages for the restaurants and hotels domains. Our model achieves an overall test accuracy ranging between 61% and 69% for the hotels domain and between 64% and 78% for restaurants domain, which compares favorably to 69% and 80% obtained for English parser trained on gold English data and a few examples from validation set. We show our approach outperforms the previous state-of-the-art methodology by more than 30% for hotels and 40% for restaurants with localized ontologies for the subset of languages tested. Our methodology enables any software developer to add a new language capability to a QA system for a new domain, leveraging machine translation, in less than 24 hours. Our code is released open-source.","2020-11","2025-09-10 13:17:17","2025-09-10 13:17:17","","5970–5983","","","","","","","","","","","Association for Computational Linguistics","Online","","","","","","","","","","","","","","Webber, Bonnie; Cohn, Trevor; He, Yulan; Liu, Yang","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ADTD9IZM","conferencePaper","2020","Michael, Julian; Botha, Jan A.; Tenney, Ian","Asking without Telling: Exploring Latent Ontologies in Contextual Representations","Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)","","","10.18653/v1/2020.emnlp-main.552","https://aclanthology.org/2020.emnlp-main.552/","The success of pretrained contextual encoders, such as ELMo and BERT, has brought a great deal of interest in what these models learn: do they, without explicit supervision, learn to encode meaningful notions of linguistic structure? If so, how is this structure encoded? To investigate this, we introduce latent subclass learning (LSL): a modification to classifier-based probing that induces a latent categorization (or ontology) of the probe's inputs. Without access to fine-grained gold labels, LSL extracts emergent structure from input representations in an interpretable and quantifiable form. In experiments, we find strong evidence of familiar categories, such as a notion of personhood in ELMo, as well as novel ontological distinctions, such as a preference for fine-grained semantic roles on core arguments. Our results provide unique new evidence of emergent structure in pretrained encoders, including departures from existing annotations which are inaccessible to earlier methods.","2020-11","2025-09-10 13:17:17","2025-09-10 13:17:17","","6792–6812","","","","","","","","","","","Association for Computational Linguistics","Online","","","","","","","","","","","","","","Webber, Bonnie; Cohn, Trevor; He, Yulan; Liu, Yang","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6I95J4AZ","conferencePaper","2020","Joshi, Anirudh; Katariya, Namit; Amatriain, Xavier; Kannan, Anitha","Dr. Summarize: Global Summarization of Medical Dialogue by Exploiting Local Structures.","Findings of the Association for Computational Linguistics: EMNLP 2020","","","10.18653/v1/2020.findings-emnlp.335","https://aclanthology.org/2020.findings-emnlp.335/","Understanding a medical conversation between a patient and a physician poses unique natural language understanding challenge since it combines elements of standard open-ended conversation with very domain-specific elements that require expertise and medical knowledge. Summarization of medical conversations is a particularly important aspect of medical conversation understanding since it addresses a very real need in medical practice: capturing the most important aspects of a medical encounter so that they can be used for medical decision making and subsequent follow ups. In this paper we present a novel approach to medical conversation summarization that leverages the unique and independent local structures created when gathering a patient's medical history. Our approach is a variation of the pointer generator network where we introduce a penalty on the generator distribution, and we explicitly model negations. The model also captures important properties of medical conversations such as medical knowledge coming from standardized medical ontologies better than when those concepts are introduced explicitly. Through evaluation by doctors, we show that our approach is preferred on twice the number of summaries to the baseline pointer generator model and captures most or all of the information in 80% of the conversations making it a realistic alternative to costly manual summarization by medical experts.","2020-11","2025-09-10 13:17:17","2025-09-10 13:17:17","","3755–3763","","","","","","","","","","","Association for Computational Linguistics","Online","","","","","","","","","","","","","","Cohn, Trevor; He, Yulan; Liu, Yang","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9NNB46VX","conferencePaper","2020","Zhang, Yanjian; Chen, Qin; Zhang, Yiteng; Wei, Zhongyu; Gao, Yixu; Peng, Jiajie; Huang, Zengfeng; Sun, Weijian; Huang, Xuanjing","Automatic Term Name Generation for Gene Ontology: Task and Dataset","Findings of the Association for Computational Linguistics: EMNLP 2020","","","10.18653/v1/2020.findings-emnlp.422","https://aclanthology.org/2020.findings-emnlp.422/","Terms contained in Gene Ontology (GO) have been widely used in biology and bio-medicine. Most previous research focuses on inferring new GO terms, while the term names that reflect the gene function are still named by the experts. To fill this gap, we propose a novel task, namely term name generation for GO, and build a large-scale benchmark dataset. Furthermore, we present a graph-based generative model that incorporates the relations between genes, words and terms for term name generation, which exhibits great advantages over the strong baselines.","2020-11","2025-09-10 13:17:17","2025-09-10 13:17:17","","4705–4710","","","","","","","","","","","Association for Computational Linguistics","Online","","","","","","","","","","","","","","Cohn, Trevor; He, Yulan; Liu, Yang","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JRA9TQSE","conferencePaper","2020","Uresova, Zdenka; Fucikova, Eva; Hajicova, Eva; Hajic, Jan","SynSemClass Linked Lexicon: Mapping Synonymy between Languages","Proceedings of the 2020 Globalex Workshop on Linked Lexicography","979-10-95546-46-7","","","https://aclanthology.org/2020.globalex-1.2/","This paper reports on an extended version of a synonym verb class lexicon, newly called SynSemClass (formerly CzEngClass). This lexicon stores cross-lingual semantically similar verb senses in synonym classes extracted from a richly annotated parallel corpus, the Prague Czech-English Dependency Treebank. When building the lexicon, we make use of predicate-argument relations (valency) and link them to semantic roles; in addition, each entry is linked to several external lexicons of more or less “semantic” nature, namely FrameNet, WordNet, VerbNet, OntoNotes and PropBank, and Czech VALLEX. The aim is to provide a linguistic resource that can be used to compare semantic roles and their syntactic properties and features across languages within and across synonym groups (classes, or `synsets'), as well as gold standard data for automatic NLP experiments with such synonyms, such as synonym discovery, feature mapping, etc. However, perhaps the most important goal is to eventually build an event type ontology that can be referenced and used as a human-readable and human-understandable “database” for all types of events, processes and states. While the current paper describes primarily the content of the lexicon, we are also presenting a preliminary design of a format compatible with Linked Data, on which we are hoping to get feedback during discussions at the workshop. Once the resource (in whichever form) is applied to corpus annotation, deep analysis will be possible using such combined resources as training data.","2020-05","2025-09-10 13:17:17","2025-09-10 13:17:17","","10–19","","","","","","","","","","","European Language Resources Association","Marseille, France","eng","","","","","","","","","","","","","Kernerman, Ilan; Krek, Simon; McCrae, John P.; Gracia, Jorge; Ahmadi, Sina; Kabashi, Besim","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WTTHXQHV","conferencePaper","2020","Mambrini, Francesco; Passarotti, Marco","Representing Etymology in the LiLa Knowledge Base of Linguistic Resources for Latin","Proceedings of the 2020 Globalex Workshop on Linked Lexicography","979-10-95546-46-7","","","https://aclanthology.org/2020.globalex-1.3/","In this paper we describe the process of inclusion of etymological information in a knowledge base of interoperable Latin linguistic resources developed in the context of the LiLa: Linking Latin project. Interoperability is obtained by applying the Linked Open Data principles. Particularly, an extensive collection of Latin lemmas is used to link the (distributed) resources. For the etymology, we rely on the Ontolex-lemon ontology and the lemonEty extension to model the information, while the source data are taken from a recent etymological dictionary of Latin. As a result, the collection of lemmas LiLa is built around now includes 1,465 Proto-Italic and 1,393 Proto-Indo-European reconstructed forms that are used to explain the history of 1,400 Latin words. We discuss the motivation, methodology and modeling strategies of the work, as well as its possible applications and potential future developments.","2020-05","2025-09-10 13:17:17","2025-09-10 13:17:17","","20–28","","","","","","","","","","","European Language Resources Association","Marseille, France","eng","","","","","","","","","","","","","Kernerman, Ilan; Krek, Simon; McCrae, John P.; Gracia, Jorge; Ahmadi, Sina; Kabashi, Besim","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ENC667M5","conferencePaper","2020","Sanjurjo-González, Hugo","Increasing accuracy of a semantic word labelling tool based on a small lexicon","Proceedings of the 17th International Conference on Natural Language Processing (ICON)","","","","https://aclanthology.org/2020.icon-main.2/","Semantic annotation has become an important piece of information within corpus linguistics. This information is usually included for every lexical unit of the corpus providing a more exhaustive analysis of language. There are some resources such as lexicons or ontologies that allow this type of annotation. However, expanding these resources is a time-consuming task. This paper describes a simple NLP baseline for increasing accuracy of the existing semantic resources of the UCREL Semantic Analysis System (USAS). In our experiments, Spanish token accuracy is improved by up to 30% using this method.","2020-12","2025-09-10 13:17:17","2025-09-10 13:17:17","","10–14","","","","","","","","","","","NLP Association of India (NLPAI)","Indian Institute of Technology Patna, Patna, India","","","","","","","","","","","","","","Bhattacharyya, Pushpak; Sharma, Dipti Misra; Sangal, Rajeev","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"V27I5CEX","conferencePaper","2020","Reed, Toby; Cutsuridis, Vassilis","Demonstration of a Literature Based Discovery System based on Ontologies, Semantic Filters and Word Embeddings for the Raynaud Disease-Fish Oil Rediscovery","Proceedings of the 17th International Conference on Natural Language Processing (ICON): System Demonstrations","","","","https://aclanthology.org/2020.icon-demos.1/","A novel literature-based discovery system based on UMLS Ontologies, Semantic Filters, Statistics, and Word Embed-dings was developed and validated against the well-established Raynaud's disease – Fish Oil discovery by min-ing different size and specificity corpora of Pubmed titles and abstracts. Results show an `inverse effect' between open ver-sus closed discovery search modes. In open discovery, a more general and bigger corpus (Vascular disease or Peri-vascular disease) produces better results than a more specific and smaller in size corpus (Raynaud disease), whereas in closed discovery, the exact opposite is true.","2020-12","2025-09-10 13:17:17","2025-09-10 13:17:17","","1–3","","","","","","","","","","","NLP Association of India (NLPAI)","Patna, India","","","","","","","","","","","","","","Goyal, Vishal; Ekbal, Asif","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6XAM48NE","conferencePaper","2020","Moneglia, Massimo; Varvara, Rossella","The Annotation of Thematic Structure and Alternations face to the Semantic Variation of Action Verbs. Current Trends in the IMAGACT Ontology","Proceedings of the 16th Joint ACL-ISO Workshop on Interoperable Semantic Annotation","979-10-95546-48-1","","","https://aclanthology.org/2020.isa-1.8/","We present some issues in the development of the semantic annotation of IMAGACT, a multimodal and multilingual ontology of actions. The resource is structured on action concepts that are meant to be cognitive entities and to which a linguistic caption is attached. For each of these concepts, we annotate the minimal thematic structure of the caption and the possible argument alternations allowed. We present some insights on this process with regards to the notion of thematic structure and the relationship between action concepts and linguistic expressions. From the empirical evidence provided by the annotation, we discuss on the very nature of thematic structure, arguing that it is neither a property of the verb itself nor a property of action concepts. We further show what is the relation between thematic structure and 1- the semantic variation of action verbs; 2- the lexical variation of action concepts.","2020-05","2025-09-10 13:17:17","2025-09-10 13:17:17","","67–74","","","","","","","","","","","European Language Resources Association","Marseille","eng","","","","","","","","","","","","","Bunt, Harry","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NKAWEVUY","conferencePaper","2020","Roberto, John; Davis, Brian","Towards the Ontologization of the Outsider Art Domain: Position Paper","Proceedings of the 16th Joint ACL-ISO Workshop on Interoperable Semantic Annotation","979-10-95546-48-1","","","https://aclanthology.org/2020.isa-1.11/","The purpose of this paper is to present a prospective and interdisciplinary research project seeking to ontologize knowledge of the domain of Outsider Art, that is, the art created outside the boundaries of official culture. The goal is to combine ontology engineering methodologies to develop a knowledge base which i) examines the relation between social exclusion and cultural productions, ii) standardizes the terminology of Outsider Art and iii) enables semantic interoperability between cultural metadata relevant to Outsider Art. The Outsider Art ontology will integrate some existing ontologies and terminologies, such as the CIDOC - Conceptual Reference Model (CRM), the Art & Architecture Thesaurus and the Getty Union List of Artist Names, among other resources. Natural Language Processing and Machine Learning techniques will be fundamental instruments for knowledge acquisition and elicitation. NLP techniques will be used to annotate bibliographies of relevant outsider artists and descriptions of outsider artworks with linguistic information. Machine Learning techniques will be leveraged to acquire knowledge from linguistic features embedded in both types of texts.","2020-05","2025-09-10 13:17:17","2025-09-10 13:17:17","","94–101","","","","","","","","","","","European Language Resources Association","Marseille","eng","","","","","","","","","","","","","Bunt, Harry","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PZYE6286","conferencePaper","2020","Sheremetyeva, Svetlana","Towards Creating Interoperable Resources for Conceptual Annotation of Multilingual Domain Corpora","Proceedings of the 16th Joint ACL-ISO Workshop on Interoperable Semantic Annotation","979-10-95546-48-1","","","https://aclanthology.org/2020.isa-1.12/","In this paper we focus on creation of interoperable annotation resources that make up a significant proportion of an on-going project on the development of conceptually annotated multilingual corpora for the domain of terrorist attacks in three languages (English, French and Russian) that can be used for comparative linguistic research, intelligent content and trend analysis, summarization, machine translation, etc. Conceptual annotation is understood as a type of task-oriented domain-specific semantic annotation. The annotation process in our project relies on ontological analysis. The paper details on the issues of the development of both static and dynamic resources such as a universal conceptual annotation scheme, multilingual domain ontology and multipurpose annotation platform with flexible settings, which can be used for the automation of the conceptual resource acquisition and of the annotation process, as well as for the documentation of the annotated corpora specificities. The resources constructed in the course of the research are also to be used for developing concept disambiguation metrics by means of qualitative and quantitative analysis of the golden portion of the conceptually annotated multilingual corpora and of the annotation platform linguistic knowledge.","2020-05","2025-09-10 13:17:17","2025-09-10 13:17:17","","102–109","","","","","","","","","","","European Language Resources Association","Marseille","eng","","","","","","","","","","","","","Bunt, Harry","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JVHDSA3Q","conferencePaper","2020","Tittel, Sabine; Gillis-Webber, Frances; Nannini, Alessandro A.","Towards an Ontology Based on Hallig-Wartburg's Begriffssystem for Historical Linguistic Linked Data","Proceedings of the 7th Workshop on Linked Data in Linguistics (LDL-2020)","979-10-95546-36-8","","","https://aclanthology.org/2020.ldl-1.1/","To empower end users in searching for historical linguistic content with a performance that far exceeds the research functions offered by websites of, e.g., historical dictionaries, is undoubtedly a major advantage of (Linguistic) Linked Open Data ([L]LOD). An important aim of lexicography is to enable a language-independent, onomasiological approach, and the modelling of linguistic resources following the LOD paradigm facilitates the semantic mapping to ontologies making this approach possible. Hallig-Wartburg's Begriffssystem (HW) is a well-known extra-linguistic conceptual system used as an onomasiological framework by many historical lexicographical and lexicological works. Published in 1952, HW has meanwhile been digitised. With proprietary XML data as the starting point, our goal is the transformation of HW into Linked Open Data in order to facilitate its use by linguistic resources modelled as LOD. In this paper, we describe the particularities of the HW conceptual model and the method of converting HW: We discuss two approaches, (i) the representation of HW in RDF using SKOS, the SKOS thesaurus extension, and XKOS, and (ii) the creation of a lightweight ontology expressed in OWL, based on the RDF/SKOS model. The outcome is illustrated with use cases of medieval Gascon, and Italian.","2020-05","2025-09-10 13:17:17","2025-09-10 13:17:17","","1–10","","","","","","","","","","","European Language Resources Association","Marseille, France","eng","","","","","","","","","","","","","Ionov, Maxim; McCrae, John P.; Chiarcos, Christian; Declerck, Thierry; Bosque-Gil, Julia; Gracia, Jorge","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3ZB4KSZT","conferencePaper","2020","Fiorelli, Manuel; Stellato, Armando","A Lime-Flavored REST API for Alignment Services","Proceedings of the 7th Workshop on Linked Data in Linguistics (LDL-2020)","979-10-95546-36-8","","","https://aclanthology.org/2020.ldl-1.8/","A practical alignment service should be flexible enough to handle the varied alignment scenarios that arise in the real world, while minimizing the need for manual configuration. MAPLE, an orchestration framework for ontology alignment, supports this goal by coordinating a few loosely coupled actors, which communicate and cooperate to solve a matching task using explicit metadata about the input ontologies, other available resources and the task itself. The alignment task is thus summarized by a report listing its characteristics and suggesting alignment strategies. The schema of the report is based on several metadata vocabularies, among which the Lime module of the OntoLex-Lemon model is particularly important, summarizing the lexical content of the input ontologies and describing external language resources that may be exploited for performing the alignment. In this paper, we propose a REST API that enables the participation of downstream alignment services in the process orchestrated by MAPLE, helping them self-adapt in order to handle heterogeneous alignment tasks and scenarios. The realization of this alignment orchestration effort has been performed through two main phases: we first described its API as an OpenAPI specification (a la API-first), which we then exploited to generate server stubs and compliant client libraries. Finally, we switched our focus to the integration of existing alignment systems, with one fully integrated system and an additional one being worked on, in the effort to propose the API as a valuable addendum to any system being developed.","2020-05","2025-09-10 13:17:17","2025-09-10 13:17:17","","52–60","","","","","","","","","","","European Language Resources Association","Marseille, France","eng","","","","","","","","","","","","","Ionov, Maxim; McCrae, John P.; Chiarcos, Christian; Declerck, Thierry; Bosque-Gil, Julia; Gracia, Jorge","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LAT97P9S","conferencePaper","2020","Eric, Mihail; Goel, Rahul; Paul, Shachi; Sethi, Abhishek; Agarwal, Sanchit; Gao, Shuyang; Kumar, Adarsh; Goyal, Anuj; Ku, Peter; Hakkani-Tur, Dilek","MultiWOZ 2.1: A Consolidated Multi-Domain Dialogue Dataset with State Corrections and State Tracking Baselines","Proceedings of the Twelfth Language Resources and Evaluation Conference","979-10-95546-34-4","","","https://aclanthology.org/2020.lrec-1.53/","MultiWOZ 2.0 (Budzianowski et al., 2018) is a recently released multi-domain dialogue dataset spanning 7 distinct domains and containing over 10,000 dialogues. Though immensely useful and one of the largest resources of its kind to-date, MultiWOZ 2.0 has a few shortcomings. Firstly, there are substantial noise in the dialogue state annotations and dialogue utterances which negatively impact the performance of state-tracking models. Secondly, follow-up work (Lee et al., 2019) has augmented the original dataset with user dialogue acts. This leads to multiple co-existent versions of the same dataset with minor modifications. In this work we tackle the aforementioned issues by introducing MultiWOZ 2.1. To fix the noisy state annotations, we use crowdsourced workers to re-annotate state and utterances based on the original utterances in the dataset. This correction process results in changes to over 32% of state annotations across 40% of the dialogue turns. In addition, we fix 146 dialogue utterances by canonicalizing slot values in the utterances to the values in the dataset ontology. To address the second problem, we combined the contributions of the follow-up works into MultiWOZ 2.1. Hence, our dataset also includes user dialogue acts as well as multiple slot descriptions per dialogue state slot. We then benchmark a number of state-of-the-art dialogue state tracking models on the MultiWOZ 2.1 dataset and show the joint state tracking performance on the corrected state annotations. We are publicly releasing MultiWOZ 2.1 to the community, hoping that this dataset resource will allow for more effective models across various dialogue subproblems to be built in the future.","2020-05","2025-09-10 13:17:17","2025-09-10 13:17:17","","422–428","","","","","","","","","","","European Language Resources Association","Marseille, France","eng","","","","","","","","","","","","","Calzolari, Nicoletta; Béchet, Frédéric; Blache, Philippe; Choukri, Khalid; Cieri, Christopher; Declerck, Thierry; Goggi, Sara; Isahara, Hitoshi; Maegaard, Bente; Mariani, Joseph; Mazo, Hélène; Moreno, Asuncion; Odijk, Jan; Piperidis, Stelios","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YRMJ44QH","conferencePaper","2020","Min, Bonan; Chan, Yee Seng; Zhao, Lingjun","Towards Few-Shot Event Mention Retrieval: An Evaluation Framework and A Siamese Network Approach","Proceedings of the Twelfth Language Resources and Evaluation Conference","979-10-95546-34-4","","","https://aclanthology.org/2020.lrec-1.216/","Automatically analyzing events in a large amount of text is crucial for situation awareness and decision making. Previous approaches treat event extraction as “one size fits all” with an ontology defined a priori. The resulted extraction models are built just for extracting those types in the ontology. These approaches cannot be easily adapted to new event types nor new domains of interest. To accommodate personalized event-centric information needs, this paper introduces the few-shot Event Mention Retrieval (EMR) task: given a user-supplied query consisting of a handful of event mentions, return relevant event mentions found in a corpus. This formulation enables “query by example”, which drastically lowers the bar of specifying event-centric information needs. The retrieval setting also enables fuzzy search. We present an evaluation framework leveraging existing event datasets such as ACE. We also develop a Siamese Network approach, and show that it performs better than ad-hoc retrieval models in the few-shot EMR setting.","2020-05","2025-09-10 13:17:17","2025-09-10 13:17:17","","1747–1752","","","","","","","","","","","European Language Resources Association","Marseille, France","eng","","","","","","","","","","","","","Calzolari, Nicoletta; Béchet, Frédéric; Blache, Philippe; Choukri, Khalid; Cieri, Christopher; Declerck, Thierry; Goggi, Sara; Isahara, Hitoshi; Maegaard, Bente; Mariani, Joseph; Mazo, Hélène; Moreno, Asuncion; Odijk, Jan; Piperidis, Stelios","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WS5S5CAC","conferencePaper","2020","Ferré, Arnaud; Bossy, Robert; Ba, Mouhamadou; Deléger, Louise; Lavergne, Thomas; Zweigenbaum, Pierre; Nédellec, Claire","Handling Entity Normalization with no Annotated Corpus: Weakly Supervised Methods Based on Distributional Representation and Ontological Information","Proceedings of the Twelfth Language Resources and Evaluation Conference","979-10-95546-34-4","","","https://aclanthology.org/2020.lrec-1.241/","Entity normalization (or entity linking) is an important subtask of information extraction that links entity mentions in text to categories or concepts in a reference vocabulary. Machine learning based normalization methods have good adaptability as long as they have enough training data per reference with a sufficient quality. Distributional representations are commonly used because of their capacity to handle different expressions with similar meanings. However, in specific technical and scientific domains, the small amount of training data and the relatively small size of specialized corpora remain major challenges. Recently, the machine learning-based CONTES method has addressed these challenges for reference vocabularies that are ontologies, as is often the case in life sciences and biomedical domains. And yet, its performance is dependent on manually annotated corpus. Furthermore, like other machine learning based methods, parametrization remains tricky. We propose a new approach to address the scarcity of training data that extends the CONTES method by corpus selection, pre-processing and weak supervision strategies, which can yield high-performance results without any manually annotated examples. We also study which hyperparameters are most influential, with sometimes different patterns compared to previous work. The results show that our approach significantly improves accuracy and outperforms previous state-of-the-art algorithms.","2020-05","2025-09-10 13:17:17","2025-09-10 13:17:17","","1959–1966","","","","","","","","","","","European Language Resources Association","Marseille, France","eng","","","","","","","","","","","","","Calzolari, Nicoletta; Béchet, Frédéric; Blache, Philippe; Choukri, Khalid; Cieri, Christopher; Declerck, Thierry; Goggi, Sara; Isahara, Hitoshi; Maegaard, Bente; Mariani, Joseph; Mazo, Hélène; Moreno, Asuncion; Odijk, Jan; Piperidis, Stelios","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FAG8YKB9","conferencePaper","2020","Shafran, Izhak; Du, Nan; Tran, Linh; Perry, Amanda; Keyes, Lauren; Knichel, Mark; Domin, Ashley; Huang, Lei; Chen, Yu-hui; Li, Gang; Wang, Mingqiu; El Shafey, Laurent; Soltau, Hagen; Paul, Justin Stuart","The Medical Scribe: Corpus Development and Model Performance Analyses","Proceedings of the Twelfth Language Resources and Evaluation Conference","979-10-95546-34-4","","","https://aclanthology.org/2020.lrec-1.250/","There is a growing interest in creating tools to assist in clinical note generation using the audio of provider-patient encounters. Motivated by this goal and with the help of providers and medical scribes, we developed an annotation scheme to extract relevant clinical concepts. We used this annotation scheme to label a corpus of about 6k clinical encounters. This was used to train a state-of-the-art tagging model. We report ontologies, labeling results, model performances, and detailed analyses of the results. Our results show that the entities related to medications can be extracted with a relatively high accuracy of 0.90 F-score, followed by symptoms at 0.72 F-score, and conditions at 0.57 F-score. In our task, we not only identify where the symptoms are mentioned but also map them to canonical forms as they appear in the clinical notes. Of the different types of errors, in about 19-38% of the cases, we find that the model output was correct, and about 17-32% of the errors do not impact the clinical note. Taken together, the models developed in this work are more useful than the F-scores reflect, making it a promising approach for practical applications.","2020-05","2025-09-10 13:17:17","2025-09-10 13:17:17","","2036–2044","","","","","","","","","","","European Language Resources Association","Marseille, France","eng","","","","","","","","","","","","","Calzolari, Nicoletta; Béchet, Frédéric; Blache, Philippe; Choukri, Khalid; Cieri, Christopher; Declerck, Thierry; Goggi, Sara; Isahara, Hitoshi; Maegaard, Bente; Mariani, Joseph; Mazo, Hélène; Moreno, Asuncion; Odijk, Jan; Piperidis, Stelios","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WVIUR2HF","conferencePaper","2020","Vanetik, Natalia; Litvak, Marina; Shevchuk, Sergey; Reznik, Lior","Automated Discovery of Mathematical Definitions in Text","Proceedings of the Twelfth Language Resources and Evaluation Conference","979-10-95546-34-4","","","https://aclanthology.org/2020.lrec-1.256/","Automatic definition extraction from texts is an important task that has numerous applications in several natural language processing fields such as summarization, analysis of scientific texts, automatic taxonomy generation, ontology generation, concept identification, and question answering. For definitions that are contained within a single sentence, this problem can be viewed as a binary classification of sentences into definitions and non-definitions. Definitions in scientific literature can be generic (Wikipedia) or more formal (mathematical articles). In this paper, we focus on automatic detection of one-sentence definitions in mathematical texts, which are difficult to separate from surrounding text. We experiment with several data representations, which include sentence syntactic structure and word embeddings, and apply deep learning methods such as convolutional neural network (CNN) and recurrent neural network (RNN), in order to identify mathematical definitions. Our experiments demonstrate the superiority of CNN and its combination with RNN, applied on the syntactically-enriched input representation. We also present a new dataset for definition extraction from mathematical texts. We demonstrate that the use of this dataset for training learning models improves the quality of definition extraction when these models are then used for other definition datasets. Our experiments with different domains approve that mathematical definitions require special treatment, and that using cross-domain learning is inefficient.","2020-05","2025-09-10 13:17:17","2025-09-10 13:17:17","","2086–2094","","","","","","","","","","","European Language Resources Association","Marseille, France","eng","","","","","","","","","","","","","Calzolari, Nicoletta; Béchet, Frédéric; Blache, Philippe; Choukri, Khalid; Cieri, Christopher; Declerck, Thierry; Goggi, Sara; Isahara, Hitoshi; Maegaard, Bente; Mariani, Joseph; Mazo, Hélène; Moreno, Asuncion; Odijk, Jan; Piperidis, Stelios","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AAKPVWMI","conferencePaper","2020","Humphreys, Llio; Boella, Guido; Di Caro, Luigi; Robaldo, Livio; van der Torre, Leon; Ghanavati, Sepideh; Muthuri, Robert","Populating Legal Ontologies using Semantic Role Labeling","Proceedings of the Twelfth Language Resources and Evaluation Conference","979-10-95546-34-4","","","https://aclanthology.org/2020.lrec-1.264/","This paper is concerned with the goal of maintaining legal information and compliance systems: the `resource consumption bottleneck' of creating semantic technologies manually. The use of automated information extraction techniques could significantly reduce this bottleneck. The research question of this paper is: How to address the resource bottleneck problem of creating specialist knowledge management systems? In particular, how to semi-automate the extraction of norms and their elements to populate legal ontologies? This paper shows that the acquisition paradox can be addressed by combining state-of-the-art general-purpose NLP modules with pre- and post-processing using rules based on domain knowledge. It describes a Semantic Role Labeling based information extraction system to extract norms from legislation and represent them as structured norms in legal ontologies. The output is intended to help make laws more accessible, understandable, and searchable in legal document management systems such as Eunomos (Boella et al., 2016).","2020-05","2025-09-10 13:17:17","2025-09-10 13:17:17","","2157–2166","","","","","","","","","","","European Language Resources Association","Marseille, France","eng","","","","","","","","","","","","","Calzolari, Nicoletta; Béchet, Frédéric; Blache, Philippe; Choukri, Khalid; Cieri, Christopher; Declerck, Thierry; Goggi, Sara; Isahara, Hitoshi; Maegaard, Bente; Mariani, Joseph; Mazo, Hélène; Moreno, Asuncion; Odijk, Jan; Piperidis, Stelios","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ESFF8DSI","conferencePaper","2020","de Boer, Maaike; Verhoosel, Jack P. C.","Towards Data-driven Ontologies: a Filtering Approach using Keywords and Natural Language Constructs","Proceedings of the Twelfth Language Resources and Evaluation Conference","979-10-95546-34-4","","","https://aclanthology.org/2020.lrec-1.278/","Creating ontologies is an expensive task. Our vision is that we can automatically generate ontologies based on a set of relevant documents to create a kick-start in ontology creating sessions. In this paper, we focus on enhancing two often used methods, OpenIE and co-occurrences. We evaluate the methods on two document sets, one about pizza and one about the agriculture domain. The methods are evaluated using two types of F1-score (objective, quantitative) and through a human assessment (subjective, qualitative). The results show that 1) Cooc performs both objectively and subjectively better than OpenIE; 2) the filtering methods based on keywords and on Word2vec perform similarly; 3) the filtering methods both perform better compared to OpenIE and similar to Cooc; 4) Cooc-NVP performs best, especially considering the subjective evaluation. Although, the investigated methods provide a good start for extracting an ontology out of a set of domain documents, various improvements are still possible, especially in the natural language based methods.","2020-05","2025-09-10 13:17:17","2025-09-10 13:17:17","","2285–2292","","","","","","","","","","","European Language Resources Association","Marseille, France","eng","","","","","","","","","","","","","Calzolari, Nicoletta; Béchet, Frédéric; Blache, Philippe; Choukri, Khalid; Cieri, Christopher; Declerck, Thierry; Goggi, Sara; Isahara, Hitoshi; Maegaard, Bente; Mariani, Joseph; Mazo, Hélène; Moreno, Asuncion; Odijk, Jan; Piperidis, Stelios","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5IULBTP8","conferencePaper","2020","Jabbari, Ali; Sauvage, Olivier; Zeine, Hamada; Chergui, Hamza","A French Corpus and Annotation Schema for Named Entity Recognition and Relation Extraction of Financial News","Proceedings of the Twelfth Language Resources and Evaluation Conference","979-10-95546-34-4","","","https://aclanthology.org/2020.lrec-1.279/","In financial services industry, compliance involves a series of practices and controls in order to meet key regulatory standards which aim to reduce financial risk and crime, e.g. money laundering and financing of terrorism. Faced with the growing risks, it is imperative for financial institutions to seek automated information extraction techniques for monitoring financial activities of their customers. This work describes an ontology of compliance-related concepts and relationships along with a corpus annotated according to it. The presented corpus consists of financial news articles in French and allows for training and evaluating domain-specific named entity recognition and relation extraction algorithms. We present some of our experimental results on named entity recognition and relation extraction using our annotated corpus. We aim to furthermore use the the proposed ontology towards construction of a knowledge base of financial relations.","2020-05","2025-09-10 13:17:17","2025-09-10 13:17:17","","2293–2299","","","","","","","","","","","European Language Resources Association","Marseille, France","eng","","","","","","","","","","","","","Calzolari, Nicoletta; Béchet, Frédéric; Blache, Philippe; Choukri, Khalid; Cieri, Christopher; Declerck, Thierry; Goggi, Sara; Isahara, Hitoshi; Maegaard, Bente; Mariani, Joseph; Mazo, Hélène; Moreno, Asuncion; Odijk, Jan; Piperidis, Stelios","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SCVZGSME","conferencePaper","2020","Himoro, Marcelo Yuji; Pareja-Lora, Antonio","Towards a Spell Checker for Zamboanga Chavacano Orthography","Proceedings of the Twelfth Language Resources and Evaluation Conference","979-10-95546-34-4","","","https://aclanthology.org/2020.lrec-1.327/","Zamboanga Chabacano (ZC) is the most vibrant variety of Philippine Creole Spanish, with over 400,000 native speakers in the Philippines (as of 2010). Following its introduction as a subject and a medium of instruction in the public schools of Zamboanga City from Grade 1 to 3 in 2012, an official orthography for this variety - the so-called “Zamboanga Chavacano Orthography” - has been approved in 2014. Its complexity, however, is a barrier to most speakers, since it does not necessarily reflect the particular phonetic evolution in ZC, but favours etymology instead. The distance between the correct spelling and the different spelling variations is often so great that delivering acceptable performance with the current de facto spell checking technologies may be challenging. The goals of this research have been to propose i) a spelling error taxonomy for ZC, formalised as an ontology and ii) an adaptive spell checking approach using Character-Based Statistical Machine Translation to correct spelling errors in ZC. Our results show that this approach is suitable for the goals mentioned and that it could be combined with other current spell checking technologies to achieve even higher performance.","2020-05","2025-09-10 13:17:17","2025-09-10 13:17:17","","2685–2697","","","","","","","","","","","European Language Resources Association","Marseille, France","eng","","","","","","","","","","","","","Calzolari, Nicoletta; Béchet, Frédéric; Blache, Philippe; Choukri, Khalid; Cieri, Christopher; Declerck, Thierry; Goggi, Sara; Isahara, Hitoshi; Maegaard, Bente; Mariani, Joseph; Mazo, Hélène; Moreno, Asuncion; Odijk, Jan; Piperidis, Stelios","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"446T4GH9","conferencePaper","2020","Li, Peng-Hsuan; Yang, Tsan-Yu; Ma, Wei-Yun","CA-EHN: Commonsense Analogy from E-HowNet","Proceedings of the Twelfth Language Resources and Evaluation Conference","979-10-95546-34-4","","","https://aclanthology.org/2020.lrec-1.365/","Embedding commonsense knowledge is crucial for end-to-end models to generalize inference beyond training corpora. However, existing word analogy datasets have tended to be handcrafted, involving permutations of hundreds of words with only dozens of pre-defined relations, mostly morphological relations and named entities. In this work, we model commonsense knowledge down to word-level analogical reasoning by leveraging E-HowNet, an ontology that annotates 88K Chinese words with their structured sense definitions and English translations. We present CA-EHN, the first commonsense word analogy dataset containing 90,505 analogies covering 5,656 words and 763 relations. Experiments show that CA-EHN stands out as a great indicator of how well word representations embed commonsense knowledge. The dataset is publicly available at https://github.com/ckiplab/CA-EHN.","2020-05","2025-09-10 13:17:17","2025-09-10 13:17:17","","2984–2990","","","","","","","","","","","European Language Resources Association","Marseille, France","eng","","","","","","","","","","","","","Calzolari, Nicoletta; Béchet, Frédéric; Blache, Philippe; Choukri, Khalid; Cieri, Christopher; Declerck, Thierry; Goggi, Sara; Isahara, Hitoshi; Maegaard, Bente; Mariani, Joseph; Mazo, Hélène; Moreno, Asuncion; Odijk, Jan; Piperidis, Stelios","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"944QLABX","conferencePaper","2020","Allen, James; An, Hannah; Bose, Ritwik; de Beaumont, Will; Teng, Choh Man","A Broad-Coverage Deep Semantic Lexicon for Verbs","Proceedings of the Twelfth Language Resources and Evaluation Conference","979-10-95546-34-4","","","https://aclanthology.org/2020.lrec-1.396/","Progress on deep language understanding is inhibited by the lack of a broad coverage lexicon that connects linguistic behavior to ontological concepts and axioms. We have developed COLLIE-V, a deep lexical resource for verbs, with the coverage of WordNet and syntactic and semantic details that meet or exceed existing resources. Bootstrapping from a hand-built lexicon and ontology, new ontological concepts and lexical entries, together with semantic role preferences and entailment axioms, are automatically derived by combining multiple constraints from parsing dictionary definitions and examples. We evaluated the accuracy of the technique along a number of different dimensions and were able to obtain high accuracy in deriving new concepts and lexical entries. COLLIE-V is publicly available.","2020-05","2025-09-10 13:17:17","2025-09-10 13:17:17","","3243–3251","","","","","","","","","","","European Language Resources Association","Marseille, France","eng","","","","","","","","","","","","","Calzolari, Nicoletta; Béchet, Frédéric; Blache, Philippe; Choukri, Khalid; Cieri, Christopher; Declerck, Thierry; Goggi, Sara; Isahara, Hitoshi; Maegaard, Bente; Mariani, Joseph; Mazo, Hélène; Moreno, Asuncion; Odijk, Jan; Piperidis, Stelios","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"57LQYIER","conferencePaper","2020","Evert, Stefan; Harlamov, Oleg; Heinrich, Philipp; Banski, Piotr","Corpus Query Lingua Franca part II: Ontology","Proceedings of the Twelfth Language Resources and Evaluation Conference","979-10-95546-34-4","","","https://aclanthology.org/2020.lrec-1.410/","The present paper outlines the projected second part of the Corpus Query Lingua Franca (CQLF) family of standards: CQLF Ontology, which is currently in the process of standardization at the International Standards Organization (ISO), in its Technical Committee 37, Subcommittee 4 (TC37SC4) and its national mirrors. The first part of the family, ISO 24623-1 (henceforth CQLF Metamodel), was successfully adopted as an international standard at the beginning of 2018. The present paper reflects the state of the CQLF Ontology at the moment of submission for the Committee Draft ballot. We provide a brief overview of the CQLF Metamodel, present the assumptions and aims of the CQLF Ontology, its basic structure, and its potential extended applications. The full ontology is expected to emerge from a community process, starting from an initial version created by the authors of the present paper.","2020-05","2025-09-10 13:17:18","2025-09-10 13:17:18","","3346–3352","","","","","","","","","","","European Language Resources Association","Marseille, France","eng","","","","","","","","","","","","","Calzolari, Nicoletta; Béchet, Frédéric; Blache, Philippe; Choukri, Khalid; Cieri, Christopher; Declerck, Thierry; Goggi, Sara; Isahara, Hitoshi; Maegaard, Bente; Mariani, Joseph; Mazo, Hélène; Moreno, Asuncion; Odijk, Jan; Piperidis, Stelios","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BK5JMDZE","conferencePaper","2020","Labropoulou, Penny; Gkirtzou, Katerina; Gavriilidou, Maria; Deligiannis, Miltos; Galanis, Dimitris; Piperidis, Stelios; Rehm, Georg; Berger, Maria; Mapelli, Valérie; Rigault, Michael; Arranz, Victoria; Choukri, Khalid; Backfried, Gerhard; Gómez-Pérez, José Manuel; Garcia-Silva, Andres","Making Metadata Fit for Next Generation Language Technology Platforms: The Metadata Schema of the European Language Grid","Proceedings of the Twelfth Language Resources and Evaluation Conference","979-10-95546-34-4","","","https://aclanthology.org/2020.lrec-1.420/","The current scientific and technological landscape is characterised by the increasing availability of data resources and processing tools and services. In this setting, metadata have emerged as a key factor facilitating management, sharing and usage of such digital assets. In this paper we present ELG-SHARE, a rich metadata schema catering for the description of Language Resources and Technologies (processing and generation services and tools, models, corpora, term lists, etc.), as well as related entities (e.g., organizations, projects, supporting documents, etc.). The schema powers the European Language Grid platform that aims to be the primary hub and marketplace for industry-relevant Language Technology in Europe. ELG-SHARE has been based on various metadata schemas, vocabularies, and ontologies, as well as related recommendations and guidelines.","2020-05","2025-09-10 13:17:18","2025-09-10 13:17:18","","3428–3437","","","","","","","","","","","European Language Resources Association","Marseille, France","eng","","","","","","","","","","","","","Calzolari, Nicoletta; Béchet, Frédéric; Blache, Philippe; Choukri, Khalid; Cieri, Christopher; Declerck, Thierry; Goggi, Sara; Isahara, Hitoshi; Maegaard, Bente; Mariani, Joseph; Mazo, Hélène; Moreno, Asuncion; Odijk, Jan; Piperidis, Stelios","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KGICI2B5","conferencePaper","2020","Löffler, Felicitas; Abdelmageed, Nora; Babalou, Samira; Kaur, Pawandeep; König-Ries, Birgitta","Tag Me If You Can! Semantic Annotation of Biodiversity Metadata with the QEMP Corpus and the BiodivTagger","Proceedings of the Twelfth Language Resources and Evaluation Conference","979-10-95546-34-4","","","https://aclanthology.org/2020.lrec-1.560/","Dataset Retrieval is gaining importance due to a large amount of research data and the great demand for reusing scientific data. Dataset Retrieval is mostly based on metadata, structured information about the primary data. Enriching these metadata with semantic annotations based on Linked Open Data (LOD) enables datasets, publications and authors to be connected and expands the search on semantically related terms. In this work, we introduce the BiodivTagger, an ontology-based Information Extraction pipeline, developed for metadata from biodiversity research. The system recognizes biological, physical and chemical processes, environmental terms, data parameters and phenotypes as well as materials and chemical compounds and links them to concepts in dedicated ontologies. To evaluate our pipeline, we created a gold standard of 50 metadata files (QEMP corpus) selected from five different data repositories in biodiversity research. To the best of our knowledge, this is the first annotated metadata corpus for biodiversity research data. The results reveal a mixed picture. While materials and data parameters are properly matched to ontological concepts in most cases, some ontological issues occurred for processes and environmental terms.","2020-05","2025-09-10 13:17:18","2025-09-10 13:17:18","","4557–4564","","","","","","","","","","","European Language Resources Association","Marseille, France","eng","","","","","","","","","","","","","Calzolari, Nicoletta; Béchet, Frédéric; Blache, Philippe; Choukri, Khalid; Cieri, Christopher; Declerck, Thierry; Goggi, Sara; Isahara, Hitoshi; Maegaard, Bente; Mariani, Joseph; Mazo, Hélène; Moreno, Asuncion; Odijk, Jan; Piperidis, Stelios","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EK5I8IMX","conferencePaper","2020","Alsudias, Lama; Rayson, Paul","Developing an Arabic Infectious Disease Ontology to Include Non-Standard Terminology","Proceedings of the Twelfth Language Resources and Evaluation Conference","979-10-95546-34-4","","","https://aclanthology.org/2020.lrec-1.596/","Building ontologies is a crucial part of the semantic web endeavour. In recent years, research interest has grown rapidly in supporting languages such as Arabic in NLP in general but there has been very little research on medical ontologies for Arabic. We present a new Arabic ontology in the infectious disease domain to support various important applications including the monitoring of infectious disease spread via social media. This ontology meaningfully integrates the scientific vocabularies of infectious diseases with their informal equivalents. We use ontology learning strategies with manual checking to build the ontology. We applied three statistical methods for term extraction from selected Arabic infectious diseases articles: TF-IDF, C-value, and YAKE. We also conducted a study, by consulting around 100 individuals, to discover the informal terms related to infectious diseases in Arabic. In future work, we will automatically extract the relations for infectious disease concepts but for now these are manually created. We report two complementary experiments to evaluate the ontology. First, a quantitative evaluation of the term extraction results and an additional qualitative evaluation by a domain expert.","2020-05","2025-09-10 13:17:18","2025-09-10 13:17:18","","4842–4850","","","","","","","","","","","European Language Resources Association","Marseille, France","eng","","","","","","","","","","","","","Calzolari, Nicoletta; Béchet, Frédéric; Blache, Philippe; Choukri, Khalid; Cieri, Christopher; Declerck, Thierry; Goggi, Sara; Isahara, Hitoshi; Maegaard, Bente; Mariani, Joseph; Mazo, Hélène; Moreno, Asuncion; Odijk, Jan; Piperidis, Stelios","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CLL3UZA9","conferencePaper","2020","Bou, Savong; Suzuki, Naoki; Miwa, Makoto; Sasaki, Yutaka","Ontology-Style Relation Annotation: A Case Study","Proceedings of the Twelfth Language Resources and Evaluation Conference","979-10-95546-34-4","","","https://aclanthology.org/2020.lrec-1.599/","This paper proposes an Ontology-Style Relation (OSR) annotation approach. In conventional Relation Extraction (RE) datasets, relations are annotated as links between entity mentions. In contrast, in our OSR annotation, a relation is annotated as a relation mention (i.e., not a link but a node) and domain and range links are annotated from the relation mention to its argument entity mentions. We expect the following benefits: (1) the relation annotations can be easily converted to Resource Description Framework (RDF) triples to populate an Ontology, (2) some part of conventional RE tasks can be tackled as Named Entity Recognition (NER) tasks. The relation classes are limited to several RDF properties such as domain, range, and subClassOf, and (3) OSR annotations can be clear documentations of Ontology contents. As a case study, we converted an in-house corpus of Japanese traffic rules in conventional annotations into the OSR annotations and built a novel OSR-RoR (Rules of the Road) corpus. The inter-annotator agreements of the conversion were 85-87%. We evaluated the performance of neural NER and RE tools on the conventional and OSR annotations. The experimental results showed that the OSR annotations make the RE task easier while introducing slight complexity into the NER task.","2020-05","2025-09-10 13:17:18","2025-09-10 13:17:18","","4867–4876","","","","","","","","","","","European Language Resources Association","Marseille, France","eng","","","","","","","","","","","","","Calzolari, Nicoletta; Béchet, Frédéric; Blache, Philippe; Choukri, Khalid; Cieri, Christopher; Declerck, Thierry; Goggi, Sara; Isahara, Hitoshi; Maegaard, Bente; Mariani, Joseph; Mazo, Hélène; Moreno, Asuncion; Odijk, Jan; Piperidis, Stelios","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UYB576C2","conferencePaper","2020","Dekova, Rositsa","The Ontology of Bulgarian Dialects – Architecture and Information Retrieval","Proceedings of the Twelfth Language Resources and Evaluation Conference","979-10-95546-34-4","","","https://aclanthology.org/2020.lrec-1.600/","Following a concise description of the structure, the paper focuses on the potential of the Ontology of the Bulgarian Dialects, which demonstrates a novel usage of the ontological modelling for the purposes of dialect digital archiving and information processing. The ontology incorporates information on the dialects of the Bulgarian language and includes data from 84 dialects, spoken not only on the territory of the Republic of Bulgaria, but also abroad. It encodes both their geographical distribution and some of their main diagnostic features, such as the different mutations (also referred to as reflexes) of some of the Old Bulgarian vowels. The mutations modelled so far in the ontology include the reflex of the back nasal vowel /\cyrbyus/ under stress, the reflex of the back er vowel /\cyrhrdsn/ under stress, and the reflex of the yat vowel /\cyryat/ under stress when it precedes a syllable with a back vowel. Besides the opportunity for formal structuring of the considerable amount of data gathered through the years by dialectologists, the ontology also provides numerous possibilities for information retrieval – searches by dialect, country, dialect region, city or village, various combinations of diagnostic features.","2020-05","2025-09-10 13:17:18","2025-09-10 13:17:18","","4877–4882","","","","","","","","","","","European Language Resources Association","Marseille, France","eng","","","","","","","","","","","","","Calzolari, Nicoletta; Béchet, Frédéric; Blache, Philippe; Choukri, Khalid; Cieri, Christopher; Declerck, Thierry; Goggi, Sara; Isahara, Hitoshi; Maegaard, Bente; Mariani, Joseph; Mazo, Hélène; Moreno, Asuncion; Odijk, Jan; Piperidis, Stelios","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"33ES59PD","conferencePaper","2020","Bick, Eckhard","Syntax and Semantics in a Treebank for Esperanto","Proceedings of the Twelfth Language Resources and Evaluation Conference","979-10-95546-34-4","","","https://aclanthology.org/2020.lrec-1.630/","In this paper we describe and evaluate syntactic and semantic aspects of Arbobanko, a treebank for the artificial language Esperanto, as well as tools and methods used in the production of the treebank. In addition to classical morphosyntax and dependency structure, the treebank was enriched with a lexical-semantic layer covering named entities, a semantic type ontology for nouns and adjectives and a framenet-inspired semantic classification of verbs. For an under-resourced language, the quality of automatic syntactic and semantic pre-annotation is of obvious importance, and by evaluating the underlying parser and the coverage of its semantic ontologies, we try to answer the question whether the language's extremely regular morphology and transparent semantic affixes translate into a more regular syntax and higher parsing accuracy. On the linguistic side, the treebank allows us to address and quantify typological issues such as the question of word order, auxiliary constructions, lexical transparency and semantic type ambiguity in Esperanto.","2020-05","2025-09-10 13:17:18","2025-09-10 13:17:18","","5120–5127","","","","","","","","","","","European Language Resources Association","Marseille, France","eng","","","","","","","","","","","","","Calzolari, Nicoletta; Béchet, Frédéric; Blache, Philippe; Choukri, Khalid; Cieri, Christopher; Declerck, Thierry; Goggi, Sara; Isahara, Hitoshi; Maegaard, Bente; Mariani, Joseph; Mazo, Hélène; Moreno, Asuncion; Odijk, Jan; Piperidis, Stelios","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FL7KGM3R","conferencePaper","2020","Bento, Alexandre; Zouaq, Amal; Gagnon, Michel","Ontology Matching Using Convolutional Neural Networks","Proceedings of the Twelfth Language Resources and Evaluation Conference","979-10-95546-34-4","","","https://aclanthology.org/2020.lrec-1.693/","In order to achieve interoperability of information in the context of the Semantic Web, it is necessary to find effective ways to align different ontologies. As the number of ontologies grows for a given domain, and as overlap between ontologies grows proportionally, it is becoming more and more crucial to develop accurate and reliable techniques to perform this task automatically. While traditional approaches to address this challenge are based on string metrics and structure analysis, in this paper we present a methodology to align ontologies automatically using machine learning techniques. Specifically, we use convolutional neural networks to perform string matching between class labels using character embeddings. We also rely on the set of superclasses to perform the best alignment. Our results show that we obtain state-of-the-art performance on ontologies from the Ontology Alignment Evaluation Initiative (OAEI). Our model also maintains good performance when tested on a different domain, which could lead to potential cross-domain applications.","2020-05","2025-09-10 13:17:18","2025-09-10 13:17:18","","5648–5653","","","","","","","","","","","European Language Resources Association","Marseille, France","eng","","","","","","","","","","","","","Calzolari, Nicoletta; Béchet, Frédéric; Blache, Philippe; Choukri, Khalid; Cieri, Christopher; Declerck, Thierry; Goggi, Sara; Isahara, Hitoshi; Maegaard, Bente; Mariani, Joseph; Mazo, Hélène; Moreno, Asuncion; Odijk, Jan; Piperidis, Stelios","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9G7J6CG8","conferencePaper","2020","El-Haj, Mahmoud; Rutherford, Nathan; Coole, Matthew; Ezeani, Ignatius; Prentice, Sheryl; Ide, Nancy; Knight, Jo; Piao, Scott; Mariani, John; Rayson, Paul; Suderman, Keith","Infrastructure for Semantic Annotation in the Genomics Domain","Proceedings of the Twelfth Language Resources and Evaluation Conference","979-10-95546-34-4","","","https://aclanthology.org/2020.lrec-1.855/","We describe a novel super-infrastructure for biomedical text mining which incorporates an end-to-end pipeline for the collection, annotation, storage, retrieval and analysis of biomedical and life sciences literature, combining NLP and corpus linguistics methods. The infrastructure permits extreme-scale research on the open access PubMed Central archive. It combines an updatable Gene Ontology Semantic Tagger (GOST) for entity identification and semantic markup in the literature, with a NLP pipeline scheduler (Buster) to collect and process the corpus, and a bespoke columnar corpus database (LexiDB) for indexing. The corpus database is distributed to permit fast indexing, and provides a simple web front-end with corpus linguistics methods for sub-corpus comparison and retrieval. GOST is also connected as a service in the Language Application (LAPPS) Grid, in which context it is interoperable with other NLP tools and data in the Grid and can be combined with them in more complex workflows. In a literature based discovery setting, we have created an annotated corpus of 9,776 papers with 5,481,543 words.","2020-05","2025-09-10 13:17:18","2025-09-10 13:17:18","","6921–6929","","","","","","","","","","","European Language Resources Association","Marseille, France","eng","","","","","","","","","","","","","Calzolari, Nicoletta; Béchet, Frédéric; Blache, Philippe; Choukri, Khalid; Cieri, Christopher; Declerck, Thierry; Goggi, Sara; Isahara, Hitoshi; Maegaard, Bente; Mariani, Joseph; Mazo, Hélène; Moreno, Asuncion; Odijk, Jan; Piperidis, Stelios","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YLYT7JEA","conferencePaper","2020","Fiorelli, Manuel; Stellato, Armando; Lorenzetti, Tiziano; Turbati, Andrea; Schmitz, Peter; Francesconi, Enrico; Hajlaoui, Najeh; Batouche, Brahim","Editing OntoLex-Lemon in VocBench 3","Proceedings of the Twelfth Language Resources and Evaluation Conference","979-10-95546-34-4","","","https://aclanthology.org/2020.lrec-1.889/","OntoLex-Lemon is a collection of RDF vocabularies for specifying the verbalization of ontologies in natural language. Beyond its original scope, OntoLex-Lemon, as well as its predecessor Monnet lemon, found application in the Linguistic Linked Open Data cloud to represent and interlink language resources on the Semantic Web. Unfortunately, generic ontology and RDF editors were considered inconvenient to use with OntoLex-Lemon because of its complex design patterns and other peculiarities, including indirection, reification and subtle integrity constraints. This perception led to the development of dedicated editors, trading the flexibility of RDF in combining different models (and the features already available in existing RDF editors) for a more direct and streamlined editing of OntoLex-Lemon patterns. In this paper, we investigate on the benefits gained by extending an already existing RDF editor, VocBench 3, with capabilities closely tailored to OntoLex-Lemon and on the challenges that such extension implies. The outcome of such investigation is twofold: a vertical assessment of a new editor for OntoLex-Lemon and, in the broader scope of RDF editor design, a new perspective on which flexibility and extensibility characteristics an editor should meet in order to cover new core modeling vocabularies, for which OntoLex-Lemon represents a use case.","2020-05","2025-09-10 13:17:18","2025-09-10 13:17:18","","7194–7203","","","","","","","","","","","European Language Resources Association","Marseille, France","eng","","","","","","","","","","","","","Calzolari, Nicoletta; Béchet, Frédéric; Blache, Philippe; Choukri, Khalid; Cieri, Christopher; Declerck, Thierry; Goggi, Sara; Isahara, Hitoshi; Maegaard, Bente; Mariani, Joseph; Mazo, Hélène; Moreno, Asuncion; Odijk, Jan; Piperidis, Stelios","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7SJ6HTT6","conferencePaper","2020","Fäth, Christian; Chiarcos, Christian; Ebbrecht, Björn; Ionov, Maxim","Fintan - Flexible, Integrated Transformation and Annotation eNgineering","Proceedings of the Twelfth Language Resources and Evaluation Conference","979-10-95546-34-4","","","https://aclanthology.org/2020.lrec-1.891/","We introduce the Flexible and Integrated Transformation and Annotation eNgeneering (Fintan) platform for converting heterogeneous linguistic resources to RDF. With its modular architecture, workflow management and visualization features, Fintan facilitates the development of complex transformation pipelines by integrating generic RDF converters and augmenting them with extended graph processing capabilities: Existing converters can be easily deployed to the system by means of an ontological data structure which renders their properties and the dependencies between transformation steps. Development of subsequent graph transformation steps for resource transformation, annotation engineering or entity linking is further facilitated by a novel visual rendering of SPARQL queries. A graphical workflow manager allows to easily manage the converter modules and combine them to new transformation pipelines. Employing the stream-based graph processing approach first implemented with CoNLL-RDF, we address common challenges and scalability issues when transforming resources and showcase the performance of Fintan by means of a purely graph-based transformation of the Universal Morphology data to RDF.","2020-05","2025-09-10 13:17:18","2025-09-10 13:17:18","","7212–7221","","","","","","","","","","","European Language Resources Association","Marseille, France","eng","","","","","","","","","","","","","Calzolari, Nicoletta; Béchet, Frédéric; Blache, Philippe; Choukri, Khalid; Cieri, Christopher; Declerck, Thierry; Goggi, Sara; Isahara, Hitoshi; Maegaard, Bente; Mariani, Joseph; Mazo, Hélène; Moreno, Asuncion; Odijk, Jan; Piperidis, Stelios","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DTA2EGZ5","conferencePaper","2020","Gonzalez-Dios, Itziar; Alvez, Javier; Rigau, German","Towards modelling SUMO attributes through WordNet adjectives: a Case Study on Qualities","Proceedings of the LREC 2020 Workshop on Multimodal Wordnets (MMW2020)","979-10-95546-41-2","","","https://aclanthology.org/2020.mmw-1.1/","Previous studies have shown that the knowledge about attributes and properties in the SUMO ontology and its mapping to WordNet adjectives lacks of an accurate and complete characterization. A proper characterization of this type of knowledge is required to perform formal commonsense reasoning based on the SUMO properties, for instance to distinguish one concept from another based on their properties. In this context, we propose a new semi-automatic approach to model the knowledge about properties and attributes in SUMO by exploiting the information encoded in WordNet adjectives and its mapping to SUMO. To that end, we considered clusters of semantically related groups of WordNet adjectival and nominal synsets. Based on these clusters, we propose a new semi-automatic model for SUMO attributes and their mapping to WordNet, which also includes polarity information. In this paper, as an exploratory approach, we focus on qualities.","2020-05","2025-09-10 13:17:18","2025-09-10 13:17:18","","1–6","","","","","","","","","","","The European Language Resources Association (ELRA)","Marseille, France","eng","","","","","","","","","","","","","Declerk, Thierry; Gonzalez-Dios, Itziar; Rigau, German","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JNR5ILW8","conferencePaper","2020","Marciniak, Jacek","Wordnet As a Backbone of Domain and Application Conceptualizations in Systems with Multimodal Data","Proceedings of the LREC 2020 Workshop on Multimodal Wordnets (MMW2020)","979-10-95546-41-2","","","https://aclanthology.org/2020.mmw-1.5/","Information systems gathering big amounts of resources growing with time containing distinct modalities (text, audio, video, images, GIS) and aggregating content in various ways (modular e-learning modules, Web systems presenting cultural artefacts) require tools supporting content description. The subject of the description may be the topic and the characteristics of the content expressed by sets of attributes. To describe such resources one can just use some of existing indexing languages like thesauri, classification systems, domain and upper ontologies, terminologies or dictionaries. When appropriate language does not exist, it is necessary to build a new system, which will have to serve both experts who describe resources and non-experts who search through them. The solution presented in this paper used to resource description, allows experts to freely select words and expressions, which are organized in hierarchies of various nature, including that of domain and application character. This is based on the wordnet structure, which introduces a clear order for each of these groups due to its lexical nature. The paper presents two systems where such approach was applied: the E-archaeology.org e-learning content repository in which domain knowledge was integrated to describe content topics and the Hatch system gathering multimodal information about the archaeological site targeted at a wide audience, where application conceptualization was applied to describe the content by a set of attributes.","2020-05","2025-09-10 13:17:18","2025-09-10 13:17:18","","25–32","","","","","","","","","","","The European Language Resources Association (ELRA)","Marseille, France","eng","","","","","","","","","","","","","Declerk, Thierry; Gonzalez-Dios, Itziar; Rigau, German","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GZNP26JM","conferencePaper","2020","Bouscarrat, Léo; Bonnefoy, Antoine; Capponi, Cécile; Ramisch, Carlos","Multilingual enrichment of disease biomedical ontologies","Proceedings of the LREC 2020 Workshop on Multilingual Biomedical Text Processing (MultilingualBIO 2020)","979-10-95546-65-8","","","https://aclanthology.org/2020.multilingualbio-1.4/","Translating biomedical ontologies is an important challenge, but doing it manually requires much time and money. We study the possibility to use open-source knowledge bases to translate biomedical ontologies. We focus on two aspects: coverage and quality. We look at the coverage of two biomedical ontologies focusing on diseases with respect to Wikidata for 9 European languages (Czech, Dutch, English, French, German, Italian, Polish, Portuguese and Spanish) for both, plus Arabic, Chinese and Russian for the second. We first use direct links between Wikidata and the studied ontologies and then use second-order links by going through other intermediate ontologies. We then compare the quality of the translations obtained thanks to Wikidata with a commercial machine translation tool, here Google Cloud Translation.","2020-05","2025-09-10 13:17:18","2025-09-10 13:17:18","","21–28","","","","","","","","","","","European Language Resources Association","Marseille, France","eng","","","","","","","","","","","","","Melero, Maite","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"87XLTTXE","conferencePaper","2020","Bhutani, Nikita; Zheng, Xinyi; Qian, Kun; Li, Yunyao; Jagadish, H.","Answering Complex Questions by Combining Information from Curated and Extracted Knowledge Bases","Proceedings of the First Workshop on Natural Language Interfaces","","","10.18653/v1/2020.nli-1.1","https://aclanthology.org/2020.nli-1.1/","Knowledge-based question answering (KB_QA) has long focused on simple questions that can be answered from a single knowledge source, a manually curated or an automatically extracted KB. In this work, we look at answering complex questions which often require combining information from multiple sources. We present a novel KB-QA system, Multique, which can map a complex question to a complex query pattern using a sequence of simple queries each targeted at a specific KB. It finds simple queries using a neural-network based model capable of collective inference over textual relations in extracted KB and ontological relations in curated KB. Experiments show that our proposed system outperforms previous KB-QA systems on benchmark datasets, ComplexWebQuestions and WebQuestionsSP.","2020-07","2025-09-10 13:17:18","2025-09-10 13:17:18","","1–10","","","","","","","","","","","Association for Computational Linguistics","Online","","","","","","","","","","","","","","Awadallah, Ahmed Hassan; Su, Yu; Sun, Huan; Yih, Scott Wen-tau","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"982RX94E","conferencePaper","2020","Zang, Xiaoxue; Rastogi, Abhinav; Sunkara, Srinivas; Gupta, Raghav; Zhang, Jianguo; Chen, Jindong","MultiWOZ 2.2 : A Dialogue Dataset with Additional Annotation Corrections and State Tracking Baselines","Proceedings of the 2nd Workshop on Natural Language Processing for Conversational AI","","","10.18653/v1/2020.nlp4convai-1.13","https://aclanthology.org/2020.nlp4convai-1.13/","MultiWOZ is a well-known task-oriented dialogue dataset containing over 10,000 annotated dialogues spanning 8 domains. It is extensively used as a benchmark for dialogue state tracking. However, recent works have reported presence of substantial noise in the dialogue state annotations. MultiWOZ 2.1 identified and fixed many of these erroneous annotations and user utterances, resulting in an improved version of this dataset. This work introduces MultiWOZ 2.2, which is a yet another improved version of this dataset. Firstly, we identify and fix dialogue state annotation errors across 17.3% of the utterances on top of MultiWOZ 2.1. Secondly, we redefine the ontology by disallowing vocabularies of slots with a large number of possible values (e.g., restaurant name, time of booking). In addition, we introduce slot span annotations for these slots to standardize them across recent models, which previously used custom string matching heuristics to generate them. We also benchmark a few state of the art dialogue state tracking models on the corrected dataset to facilitate comparison for future work. In the end, we discuss best practices for dialogue data collection that can help avoid annotation errors.","2020-07","2025-09-10 13:17:18","2025-09-10 13:17:18","","109–117","","","","","","","","","","","Association for Computational Linguistics","Online","","","","","","","","","","","","","","Wen, Tsung-Hsien; Celikyilmaz, Asli; Yu, Zhou; Papangelis, Alexandros; Eric, Mihail; Kumar, Anuj; Casanueva, Iñigo; Shah, Rushin","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8M8E4RWB","conferencePaper","2020","Barros, Marcia Afonso; Lamurias, Andre; Sousa, Diana; Ruas, Pedro; Couto, Francisco M.","COVID-19: A Semantic-Based Pipeline for Recommending Biomedical Entities","Proceedings of the 1st Workshop on NLP for COVID-19 (Part 2) at EMNLP 2020","","","10.18653/v1/2020.nlpcovid19-2.20","https://aclanthology.org/2020.nlpcovid19-2.20/","With the increasing number of publications about COVID-19, it is a challenge to extract personalized knowledge suitable for each researcher. This work aims to build a new semantic-based pipeline for recommending biomedical entities to scientific researchers. To this end, we developed a pipeline that creates an implicit feedback matrix based on Named Entity Recognition (NER) on a corpus of documents, using multidisciplinary ontologies for recognizing and linking the entities. Our hypothesis is that by using ontologies from different fields in the NER phase, we can improve the results for state-of-the-art collaborative-filtering recommender systems applied to the dataset created. The tests performed using the COVID-19 Open Research Dataset (CORD-19) dataset show that when using four ontologies, the results for precision@k, for example, reach the 80%, whereas when using only one ontology, the results for precision@k drops to 20%, for the same users. Furthermore, the use of multi-fields entities may help in the discovery of new items, even if the researchers do not have items from that field in their set of preferences.","2020-12","2025-09-10 13:17:18","2025-09-10 13:17:18","","","","","","","","","","","","","Association for Computational Linguistics","Online","","","","","","","","","","","","","","Verspoor, Karin; Cohen, Kevin Bretonnel; Conway, Michael; de Bruijn, Berry; Dredze, Mark; Mihalcea, Rada; Wallace, Byron","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YXTDBXQ8","conferencePaper","2020","Amith, Muhammad; Cui, Licong; Roberts, Kirk; Tao, Cui","Towards an Ontology-based Medication Conversational Agent for PrEP and PEP","Proceedings of the First Workshop on Natural Language Processing for Medical Conversations","","","10.18653/v1/2020.nlpmc-1.5","https://aclanthology.org/2020.nlpmc-1.5/","ABSTRACT: HIV (human immunodeficiency virus) can damage a human's immune system and cause Acquired Immunodeficiency Syndrome (AIDS) which could lead to severe outcomes, including death. While HIV infections have decreased over the last decade, there is still a significant population where the infection permeates. PrEP and PEP are two proven preventive measures introduced that involve periodic dosage to stop the onset of HIV infection. However, the adherence rates for this medication is low in part due to the lack of information about the medication. There exist several communication barriers that prevent patient-provider communication from happening. In this work, we present our ontology-based method for automating the communication of this medication that can be deployed for live conversational agents for PrEP and PEP. This method facilitates a model of automated conversation between the machine and user can also answer relevant questions.","2020-07","2025-09-10 13:17:18","2025-09-10 13:17:18","","31–40","","","","","","","","","","","Association for Computational Linguistics","Online","","","","","","","","","","","","","","Bhatia, Parminder; Lin, Steven; Gangadharaiah, Rashmi; Wallace, Byron; Shafran, Izhak; Shivade, Chaitanya; Du, Nan; Diab, Mona","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2EIWUWCM","conferencePaper","2020","Zad, Samira; Finlayson, Mark","Systematic Evaluation of a Framework for Unsupervised Emotion Recognition for Narrative Text","Proceedings of the First Joint Workshop on Narrative Understanding, Storylines, and Events","","","10.18653/v1/2020.nuse-1.4","https://aclanthology.org/2020.nuse-1.4/","Identifying emotions as expressed in text (a.k.a. text emotion recognition) has received a lot of attention over the past decade. Narratives often involve a great deal of emotional expression, and so emotion recognition on narrative text is of great interest to computational approaches to narrative understanding. Prior work by Kim et al. 2010 was the work with the highest reported emotion detection performance, on a corpus of fairy tales texts. Close inspection of that work, however, revealed significant reproducibility problems, and we were unable to reimplement Kim's approach as described. As a consequence, we implemented a framework inspired by Kim's approach, where we carefully evaluated the major design choices. We identify the highest-performing combination, which outperforms Kim's reported performance by 7.6 F_1 points on average. Close inspection of the annotated data revealed numerous missing and incorrect emotion terms in the relevant lexicon, WordNetAffect (WNA; Strapparava and Valitutti, 2004), which allowed us to augment it in a useful way. More generally, this showed that numerous clearly emotive words and phrases are missing from WNA, which suggests that effort invested in augmenting or refining emotion ontologies could be useful for improving the performance of emotion recognition systems. We release our code and data to definitely enable future reproducibility of this work.","2020-07","2025-09-10 13:17:18","2025-09-10 13:17:18","","26–37","","","","","","","","","","","Association for Computational Linguistics","Online","","","","","","","","","","","","","","Bonial, Claire; Caselli, Tommaso; Chaturvedi, Snigdha; Clark, Elizabeth; Huang, Ruihong; Iyyer, Mohit; Jaimes, Alejandro; Ji, Heng; Martin, Lara J.; Miller, Ben; Mitamura, Teruko; Peng, Nanyun; Tetreault, Joel","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AU86KBZK","conferencePaper","2020","Ogrodniczuk, Maciej; Nitoń, Bartłomiej","New Developments in the Polish Parliamentary Corpus","Proceedings of the Second ParlaCLARIN Workshop","979-10-95546-47-4","","","https://aclanthology.org/2020.parlaclarin-1.1/","This short paper presents the current (as of February 2020) state of preparation of the Polish Parliamentary Corpus (PPC)—an extensive collection of transcripts of Polish parliamentary proceedings dating from 1919 to present. The most evident developments as compared to the 2018 version is harmonization of metadata, standardization of document identifiers, uploading contents of all documents and metadata to the database (to enable easier modification, maintenance and future development of the corpus), linking utterances to the political ontology, linking corpus texts to source data and processing historical documents.","2020-05","2025-09-10 13:17:18","2025-09-10 13:17:18","","1–4","","","","","","","","","","","European Language Resources Association","Marseille, France","eng","","","","","","","","","","","","","Fišer, Darja; Eskevich, Maria; de Jong, Franciska","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QVZGFT73","conferencePaper","2020","Reed, Lena; Harrison, Vrindavan; Oraby, Shereen; Hakkani-Tur, Dilek; Walker, Marilyn","Learning from Mistakes: Combining Ontologies via Self-Training for Dialogue Generation","Proceedings of the 21th Annual Meeting of the Special Interest Group on Discourse and Dialogue","","","10.18653/v1/2020.sigdial-1.3","https://aclanthology.org/2020.sigdial-1.3/","Natural language generators (NLGs) for task-oriented dialogue typically take a meaning representation (MR) as input, and are trained end-to-end with a corpus of MR/utterance pairs, where the MRs cover a specific set of dialogue acts and domain attributes. Creation of such datasets is labor intensive and time consuming. Therefore, dialogue systems for new domain ontologies would benefit from using data for pre-existing ontologies. Here we explore, for the first time, whether it is possible to train an NLG for a new larger ontology using existing training sets for the restaurant domain, where each set is based on a different ontology. We create a new, larger combined ontology, and then train an NLG to produce utterances covering it. For example, if one dataset has attributes for family friendly and rating information, and the other has attributes for decor and service, our aim is an NLG for the combined ontology that can produce utterances that realize values for family friendly, rating, decor and service. Initial experiments with a baseline neural sequence-to-sequence model show that this task is surprisingly challenging. We then develop a novel self-training method that identifies (errorful) model outputs, automatically constructs a corrected MR input to form a new (MR, utterance) training pair, and then repeatedly adds these new instances back into the training data. We then test the resulting model on a new test set. The result is a self-trained model whose performance is an absolute 75.4% improvement over the baseline model. We also report a human qualitative evaluation of the final model showing that it achieves high naturalness, semantic coherence and grammaticality.","2020-07","2025-09-10 13:17:18","2025-09-10 13:17:18","","21–34","","","","","","","","","","","Association for Computational Linguistics","1st virtual meeting","","","","","","","","","","","","","","Pietquin, Olivier; Muresan, Smaranda; Chen, Vivian; Kennington, Casey; Vandyke, David; Dethlefs, Nina; Inoue, Koji; Ekstedt, Erik; Ultes, Stefan","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"P84M7YPC","conferencePaper","2020","Chen, Yunmo; Chen, Tongfei; Ebner, Seth; White, Aaron Steven; Van Durme, Benjamin","Reading the Manual: Event Extraction as Definition Comprehension","Proceedings of the Fourth Workshop on Structured Prediction for NLP","","","10.18653/v1/2020.spnlp-1.9","https://aclanthology.org/2020.spnlp-1.9/","We ask whether text understanding has progressed to where we may extract event information through incremental refinement of bleached statements derived from annotation manuals. Such a capability would allow for the trivial construction and extension of an extraction framework by intended end-users through declarations such as, “Some person was born in some location at some time.” We introduce an example of a model that employs such statements, with experiments illustrating we can extract events under closed ontologies and generalize to unseen event types simply by reading new definitions.","2020-11","2025-09-10 13:17:18","2025-09-10 13:17:18","","74–83","","","","","","","","","","","Association for Computational Linguistics","Online","","","","","","","","","","","","","","Agrawal, Priyanka; Kozareva, Zornitsa; Kreutzer, Julia; Lampouras, Gerasimos; Martins, André; Ravi, Sujith; Vlachos, Andreas","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MGH4DI46","conferencePaper","2020","Zhang, Jianguo; Hashimoto, Kazuma; Wu, Chien-Sheng; Wang, Yao; Yu, Philip; Socher, Richard; Xiong, Caiming","Find or Classify? Dual Strategy for Slot-Value Predictions on Multi-Domain Dialog State Tracking","Proceedings of the Ninth Joint Conference on Lexical and Computational Semantics","","","","https://aclanthology.org/2020.starsem-1.17/","Dialog state tracking (DST) is a core component in task-oriented dialog systems. Existing approaches for DST mainly fall into one of two categories, namely, ontology-based and ontology-free methods. An ontology-based method selects a value from a candidate-value list for each target slot, while an ontology-free method extracts spans from dialog contexts. Recent work introduced a BERT-based model to strike a balance between the two methods by pre-defining categorical and non-categorical slots. However, it is not clear enough which slots are better handled by either of the two slot types, and the way to use the pre-trained model has not been well investigated. In this paper, we propose a simple yet effective dual-strategy model for DST, by adapting a single BERT-style reading comprehension model to jointly handle both the categorical and non-categorical slots. Our experiments on the MultiWOZ datasets show that our method significantly outperforms the BERT-based counterpart, finding that the key is a deep interaction between the domain-slot and context information. When evaluated on noisy (MultiWOZ 2.0) and cleaner (MultiWOZ 2.1) settings, our method performs competitively and robustly across the two different settings. Our method sets the new state of the art in the noisy setting, while performing more robustly than the best model in the cleaner setting. We also conduct a comprehensive error analysis on the dataset, including the effects of the dual strategy for each slot, to facilitate future research.","2020-12","2025-09-10 13:17:18","2025-09-10 13:17:18","","154–167","","","","","","","","","","","Association for Computational Linguistics","Barcelona, Spain (Online)","","","","","","","","","","","","","","Gurevych, Iryna; Apidianaki, Marianna; Faruqui, Manaal","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9DN9D347","conferencePaper","2020","Mahlaza, Zola; Keet, C. Maria","OWLSIZ: An isiZulu CNL for structured knowledge validation","Proceedings of the 3rd International Workshop on Natural Language Generation from the Semantic Web (WebNLG+)","","","","https://aclanthology.org/2020.webnlg-1.2/","In iterative knowledge elicitation, engineers are expected to be directly involved in validating the already captured knowledge and obtaining new knowledge increments, thus making the process time consuming. Languages such as English have controlled natural languages than can be repurposed to generate natural language questions from an ontology in order to allow a domain expert to independently validate the contents of an ontology without understanding a ontology authoring language such as OWL. IsiZulu, South Africa's main L1 language by number speakers, does not have such a resource, hence, it is not possible to build a verbaliser to generate such questions. Therefore, we propose an isiZulu controlled natural language, called OWL Simplified isiZulu (OWLSIZ), for producing grammatical and fluent questions from an ontology. Human evaluation of the generated questions showed that participants' judgements agree that most (83%) questions are positive for grammaticality or understandability.","2020-12","2025-09-10 13:17:18","2025-09-10 13:17:18","","15–25","","","","","","","","","","","Association for Computational Linguistics","Dublin, Ireland (Virtual)","","","","","","","","","","","","","","Castro Ferreira, Thiago; Gardent, Claire; Ilinykh, Nikolai; van der Lee, Chris; Mille, Simon; Moussallem, Diego; Shimorina, Anastasia","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9TJS7S6H","conferencePaper","2020","Woldemariyam, Kidane; Getahun, Dr. Fekade","Embedding Oriented Adaptable Semantic Annotation Framework for Amharic Web Documents","Proceedings of the Fourth Widening Natural Language Processing Workshop","","","10.18653/v1/2020.winlp-1.3","https://aclanthology.org/2020.winlp-1.3/","The Web has become a source of information, where information is provided by humans for humans and its growth has increased necessity to get solutions that intelligently extract valuable knowledge from existing and newly added web documents with no (minimal) supervisions. However, due to the unstructured nature of existing data on the Web, effective extraction of this knowledge is limited for both human beings and software agents. Thus, this research work designed generic and embedding oriented framework that automatically annotates semantically Amharic web documents using ontology. This framework significantly reduces manual annotation and learning cost used for semantic annotation of Amharic web documents with its nature of adaptability with minimal modification. The results have also implied that neural network techniques are promising for semantic annotation, especially for less resourced languages like Amharic in comparison to language dependent techniques that have cost of speed and challenge of adaptation into new domains and languages. We experiment the feasibility of the proposed approach using Amharic news collected from WALTA news agency and Amharic Wikipedia. Our results show that the proposed solution exhibits 70.68% of precision, 66.89% of recall and 68.53% of f-measure in semantic annotation for a morphologically complex Amharic language with limited size dataset.","2020-07","2025-09-10 13:17:18","2025-09-10 13:17:18","","7","","","","","","","","","","","Association for Computational Linguistics","Seattle, USA","","","","","","","","","","","","","","Cunha, Rossana; Shaikh, Samira; Varis, Erika; Georgi, Ryan; Tsai, Alicia; Anastasopoulos, Antonios; Chandu, Khyathi Raghavi","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UDRI4QLW","conferencePaper","2021","Onoe, Yasumasa; Boratko, Michael; McCallum, Andrew; Durrett, Greg","Modeling Fine-Grained Entity Types with Box Embeddings","Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)","","","10.18653/v1/2021.acl-long.160","https://aclanthology.org/2021.acl-long.160/","Neural entity typing models typically represent fine-grained entity types as vectors in a high-dimensional space, but such spaces are not well-suited to modeling these types' complex interdependencies. We study the ability of box embeddings, which embed concepts as d-dimensional hyperrectangles, to capture hierarchies of types even when these relationships are not defined explicitly in the ontology. Our model represents both types and entity mentions as boxes. Each mention and its context are fed into a BERT-based model to embed that mention in our box space; essentially, this model leverages typological clues present in the surface text to hypothesize a type representation for the mention. Box containment can then be used to derive both the posterior probability of a mention exhibiting a given type and the conditional probability relations between types themselves. We compare our approach with a vector-based typing model and observe state-of-the-art performance on several entity typing benchmarks. In addition to competitive typing performance, our box-based model shows better performance in prediction consistency (predicting a supertype and a subtype together) and confidence (i.e., calibration), demonstrating that the box-based model captures the latent type hierarchies better than the vector-based model does.","2021-08","2025-09-10 13:17:18","2025-09-10 13:17:18","","2051–2064","","","","","","","","","","","Association for Computational Linguistics","Online","","","","","","","","","","","","","","Zong, Chengqing; Xia, Fei; Li, Wenjie; Navigli, Roberto","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"J3WY5MZ8","conferencePaper","2021","Deng, Shumin; Zhang, Ningyu; Li, Luoqiu; Hui, Chen; Huaixiao, Tou; Chen, Mosha; Huang, Fei; Chen, Huajun","OntoED: Low-resource Event Detection with Ontology Embedding","Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)","","","10.18653/v1/2021.acl-long.220","https://aclanthology.org/2021.acl-long.220/","Event Detection (ED) aims to identify event trigger words from a given text and classify it into an event type. Most current methods to ED rely heavily on training instances, and almost ignore the correlation of event types. Hence, they tend to suffer from data scarcity and fail to handle new unseen event types. To address these problems, we formulate ED as a process of event ontology population: linking event instances to pre-defined event types in event ontology, and propose a novel ED framework entitled OntoED with ontology embedding. We enrich event ontology with linkages among event types, and further induce more event-event correlations. Based on the event ontology, OntoED can leverage and propagate correlation knowledge, particularly from data-rich to data-poor event types. Furthermore, OntoED can be applied to new unseen event types, by establishing linkages to existing ones. Experiments indicate that OntoED is more predominant and robust than previous approaches to ED, especially in data-scarce scenarios.","2021-08","2025-09-10 13:17:18","2025-09-10 13:17:18","","2828–2839","","","","","","","","","","","Association for Computational Linguistics","Online","","","","","","","","","","","","","","Zong, Chengqing; Xia, Fei; Li, Wenjie; Navigli, Roberto","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"X2SBBZKK","conferencePaper","2021","Zhang, Zixuan; Parulian, Nikolaus; Ji, Heng; Elsayed, Ahmed; Myers, Skatje; Palmer, Martha","Fine-grained Information Extraction from Biomedical Literature based on Knowledge-enriched Abstract Meaning Representation","Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)","","","10.18653/v1/2021.acl-long.489","https://aclanthology.org/2021.acl-long.489/","Biomedical Information Extraction from scientific literature presents two unique and non-trivial challenges. First, compared with general natural language texts, sentences from scientific papers usually possess wider contexts between knowledge elements. Moreover, comprehending the fine-grained scientific entities and events urgently requires domain-specific background knowledge. In this paper, we propose a novel biomedical Information Extraction (IE) model to tackle these two challenges and extract scientific entities and events from English research papers. We perform Abstract Meaning Representation (AMR) to compress the wide context to uncover a clear semantic structure for each complex sentence. Besides, we construct the sentence-level knowledge graph from an external knowledge base and use it to enrich the AMR graph to improve the model's understanding of complex scientific concepts. We use an edge-conditioned graph attention network to encode the knowledge-enriched AMR graph for biomedical IE tasks. Experiments on the GENIA 2011 dataset show that the AMR and external knowledge have contributed 1.8% and 3.0% absolute F-score gains respectively. In order to evaluate the impact of our approach on real-world problems that involve topic-specific fine-grained knowledge elements, we have also created a new ontology and annotated corpus for entity and event extraction for the COVID-19 scientific literature, which can serve as a new benchmark for the biomedical IE community.","2021-08","2025-09-10 13:17:18","2025-09-10 13:17:18","","6261–6270","","","","","","","","","","","Association for Computational Linguistics","Online","","","","","","","","","","","","","","Zong, Chengqing; Xia, Fei; Li, Wenjie; Navigli, Roberto","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9SRXHC28","conferencePaper","2021","Cao, Shuyang; Wang, Lu","Controllable Open-ended Question Generation with A New Question Type Ontology","Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)","","","10.18653/v1/2021.acl-long.502","https://aclanthology.org/2021.acl-long.502/","We investigate the less-explored task of generating open-ended questions that are typically answered by multiple sentences. We first define a new question type ontology which differentiates the nuanced nature of questions better than widely used question words. A new dataset with 4,959 questions is labeled based on the new ontology. We then propose a novel question type-aware question generation framework, augmented by a semantic graph representation, to jointly predict question focuses and produce the question. Based on this framework, we further use both exemplars and automatically generated templates to improve controllability and diversity. Experiments on two newly collected large-scale datasets show that our model improves question quality over competitive comparisons based on automatic metrics. Human judges also rate our model outputs highly in answerability, coverage of scope, and overall quality. Finally, our model variants with templates can produce questions with enhanced controllability and diversity.","2021-08","2025-09-10 13:17:18","2025-09-10 13:17:18","","6424–6439","","","","","","","","","","","Association for Computational Linguistics","Online","","","","","","","","","","","","","","Zong, Chengqing; Xia, Fei; Li, Wenjie; Navigli, Roberto","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ICAYECHG","conferencePaper","2021","Lyu, Qing; Zhang, Hongming; Sulem, Elior; Roth, Dan","Zero-shot Event Extraction via Transfer Learning: Challenges and Insights","Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers)","","","10.18653/v1/2021.acl-short.42","https://aclanthology.org/2021.acl-short.42/","Event extraction has long been a challenging task, addressed mostly with supervised methods that require expensive annotation and are not extensible to new event ontologies. In this work, we explore the possibility of zero-shot event extraction by formulating it as a set of Textual Entailment (TE) and/or Question Answering (QA) queries (e.g. “A city was attacked” entails “There is an attack”), exploiting pretrained TE/QA models for direct transfer. On ACE-2005 and ERE, our system achieves acceptable results, yet there is still a large gap from supervised approaches, showing that current QA and TE technologies fail in transferring to a different domain. To investigate the reasons behind the gap, we analyze the remaining key challenges, their respective impact, and possible improvement directions.","2021-08","2025-09-10 13:17:18","2025-09-10 13:17:18","","322–332","","","","","","","","","","","Association for Computational Linguistics","Online","","","","","","","","","","","","","","Zong, Chengqing; Xia, Fei; Li, Wenjie; Navigli, Roberto","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"D9CZIYD9","conferencePaper","2021","Harrigan, Atticus; Arppe, Antti","Leveraging English Word Embeddings for Semi-Automatic Semantic Classification in Nêhiyawêwin (Plains Cree)","Proceedings of the First Workshop on Natural Language Processing for Indigenous Languages of the Americas","","","10.18653/v1/2021.americasnlp-1.12","https://aclanthology.org/2021.americasnlp-1.12/","This paper details a semi-automatic method of word clustering for the Algonquian language, Nêhiyawêwin (Plains Cree). Although this method worked well, particularly for nouns, it required some amount of manual postprocessing. The main benefit of this approach over implementing an existing classification ontology is that this method approaches the language from an endogenous point of view, while performing classification quicker than in a fully manual context.","2021-06","2025-09-10 13:17:18","2025-09-10 13:17:18","","113–121","","","","","","","","","","","Association for Computational Linguistics","Online","","","","","","","","","","","","","","Mager, Manuel; Oncevay, Arturo; Rios, Annette; Ruiz, Ivan Vladimir Meza; Palmer, Alexis; Neubig, Graham; Kann, Katharina","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2MAMXNUR","conferencePaper","2021","Dacanay, Daniel; Harrigan, Atticus; Wolvengrey, Arok; Arppe, Antti","The More Detail, the Better? – Investigating the Effects of Semantic Ontology Specificity on Vector Semantic Classification with a Plains Cree / nêhiyawêwin Dictionary","Proceedings of the First Workshop on Natural Language Processing for Indigenous Languages of the Americas","","","10.18653/v1/2021.americasnlp-1.15","https://aclanthology.org/2021.americasnlp-1.15/","One problem in the task of automatic semantic classification is the problem of determining the level on which to group lexical items. This is often accomplished using pre-made, hierarchical semantic ontologies. The following investigation explores the computational assignment of semantic classifications on the contents of a dictionary of nêhiyawêwin / Plains Cree (ISO: crk, Algonquian, Western Canada and United States), using a semantic vector space model, and following two semantic ontologies, WordNet and SIL's Rapid Words, and compares how these computational results compare to manual classifications with the same two ontologies.","2021-06","2025-09-10 13:17:18","2025-09-10 13:17:18","","143–152","","","","","","","","","","","Association for Computational Linguistics","Online","","","","","","","","","","","","","","Mager, Manuel; Oncevay, Arturo; Rios, Annette; Ruiz, Ivan Vladimir Meza; Palmer, Alexis; Neubig, Graham; Kann, Katharina","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PQZN9553","conferencePaper","2021","Boschee, Elizabeth","Keynote Abstract: Events on a Global Scale: Towards Language-Agnostic Event Extraction","Proceedings of the 4th Workshop on Challenges and Applications of Automated Extraction of Socio-political Events from Text (CASE 2021)","","","10.18653/v1/2021.case-1.2","https://aclanthology.org/2021.case-1.2/","Event extraction is a challenging and exciting task in the world of machine learning & natural language processing. The breadth of events of possible interest, the speed at which surrounding socio-political event contexts evolve, and the complexities involved in generating representative annotated data all contribute to this challenge. One particular dimension of difficulty is the intrinsically global nature of events: many downstream use cases for event extraction involve reporting not just in a few major languages but in a much broader context. The languages of interest for even a fixed task may still shift from day to day, e.g. when a disease emerges in an unexpected location. Early approaches to multi-lingual event extraction (e.g. ACE) relied wholly on supervised data provided in each language of interest. Later approaches leveraged the success of machine translation to side-step the issue, simply translating foreign-language content to English and deploying English models on the result (often leaving some significant portion of the original content behind). Most recently, however, the community has begun to shown significant progress applying zero-shot transfer techniques to the problem, developing models using supervised English data but decoding in a foreign language without translation, typically using embedding spaces specifically designed to capture multi-lingual semantic content. In this talk I will discuss multiple dimensions of these promising new approaches and the linguistic representations that underlie them. I will compare them with approaches based on machine translation (as well as with models trained using in-language training data, where available), and discuss their strengths and weaknesses in different contexts, including the amount of English/foreign bitext available and the nature of the target event ontology. I will also discuss possible future directions with an eye to improving the quality of event extraction no matter its source around the globe.","2021-08","2025-09-10 13:17:18","2025-09-10 13:17:18","","10","","","","","","","","","","","Association for Computational Linguistics","Online","","","","","","","","","","","","","","Hürriyetoğlu, Ali","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MSTNYTXB","conferencePaper","2021","Eck, Kristine","Keynote Abstract: Machine Learning in Conflict Studies: Reflections on Ethics, Collaboration, and Ongoing Challenges","Proceedings of the 4th Workshop on Challenges and Applications of Automated Extraction of Socio-political Events from Text (CASE 2021)","","","10.18653/v1/2021.case-1.3","https://aclanthology.org/2021.case-1.3/","Advances in machine learning are nothing short of revolutionary in their potential to analyze massive amounts of data and in doing so, create new knowledge bases. But there is a responsibility in wielding the power to analyze these data since the public attributes a high degree of confidence to results which are based on big datasets. In this keynote, I will first address our ethical imperative as scholars to “get it right.” This imperative relates not only to model precision but also to the quality of the underlying data, and to whether the models inadvertently reproduce or obscure political biases in the source material. In considering the ethical imperative to get it right, it is also important to define what is “right”: what is considered an acceptable threshold for classification success needs to be understood in light of the project's objectives. I then reflect on the different topics and data which are sourced in this field. Much of the existing research has focused on identifying conflict events (e.g. battles), but scholars are also increasingly turning to ML approaches to address other facets of the conflict environment. Conflict event extraction has long been a challenge for the natural language processing (NLP) community because it requires sophisticated methods for defining event ontologies, creating language resources, and developing algorithmic approaches. NLP machine-learning tools are ill-adapted to the complex, often messy, and diverse data generated during conflicts. Relative to other types of NLP text corpora, conflicts tend to generate less textual data, and texts are generated non-systematically. Conflict-related texts are often lexically idiosyncratic and tend to be written differently across actors, periods, and conflicts. Event definition and adjudication present tough challenges in the context of conflict corpora. Topics which rely on other types of data may be better-suited to NLP and machine learning methods. For example, Twitter and other social media data lend themselves well to studying hate speech, public opinion, social polarization, or discursive aspects of conflictual environments. Likewise, government-produced policy documents have typically been analyzed with historical, qualitative methods but their standardized formats and quantity suggest that ML methods can provide new traction. ML approaches may also allow scholars to exploit local sources and multi-language sources to a greater degree than has been possible. Many challenges remain, and these are best addressed in collaborative projects which build on interdisciplinary expertise. Classification projects need to be anchored in the theoretical interests of scholars of political violence if the data they produce are to be put to analytical use. There are few ontologies for classification that adequately reflect conflict researchers' interests, which highlights the need for conceptual as well as technical development.","2021-08","2025-09-10 13:17:18","2025-09-10 13:17:18","","11","","","","","","","","","","","Association for Computational Linguistics","Online","","","","","","","","","","","","","","Hürriyetoğlu, Ali","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KE24ZRJU","journalArticle","2021","Kouris, Panagiotis; Alexandridis, Georgios; Stafylopatis, Andreas","Abstractive Text Summarization: Enhancing Sequence-to-Sequence Models Using Word Sense Disambiguation and Semantic Content Generalization","Computational Linguistics","","","10.1162/coli_a_00417","https://aclanthology.org/2021.cl-4.27/","Nowadays, most research conducted in the field of abstractive text summarization focuses on neural-based models alone, without considering their combination with knowledge-based approaches that could further enhance their efficiency. In this direction, this work presents a novel framework that combines sequence-to-sequence neural-based text summarization along with structure and semantic-based methodologies. The proposed framework is capable of dealing with the problem of out-of-vocabulary or rare words, improving the performance of the deep learning models. The overall methodology is based on a well-defined theoretical model of knowledge-based content generalization and deep learning predictions for generating abstractive summaries. The framework is composed of three key elements: (i) a pre-processing task, (ii) a machine learning methodology, and (iii) a post-processing task. The pre-processing task is a knowledge-based approach, based on ontological knowledge resources, word sense disambiguation, and named entity recognition, along with content generalization, that transforms ordinary text into a generalized form. A deep learning model of attentive encoder-decoder architecture, which is expanded to enable a coping and coverage mechanism, as well as reinforcement learning and transformer-based architectures, is trained on a generalized version of text-summary pairs, learning to predict summaries in a generalized form. The post-processing task utilizes knowledge resources, word embeddings, word sense disambiguation, and heuristic algorithms based on text similarity methods in order to transform the generalized version of a predicted summary to a final, human-readable form. An extensive experimental procedure on three popular data sets evaluates key aspects of the proposed framework, while the obtained results exhibit promising performance, validating the robustness of the proposed approach.","2021-12","2025-09-10 13:17:18","2025-09-10 13:17:18","","813–859","","4","47","","","","","","","","","","","","","","","","","Place: Cambridge, MA Publisher: MIT Press","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HNV5FZU3","conferencePaper","2021","Saxena, Krati; Singh, Tushita; Patil, Ashwini; Sunkle, Sagar; Kulkarni, Vinay","Leveraging Wikipedia Navigational Templates for Curating Domain-Specific Fuzzy Conceptual Bases","Proceedings of the Second Workshop on Data Science with Human in the Loop: Language Advances","","","10.18653/v1/2021.dash-1.1","https://aclanthology.org/2021.dash-1.1/","Domain-specific conceptual bases use key concepts to capture domain scope and relevant information. Conceptual bases serve as a foundation for various downstream tasks, including ontology construction, information mapping, and analysis. However, building conceptual bases necessitates domain awareness and takes time. Wikipedia navigational templates offer multiple articles on the same/similar domain. It is possible to use the templates to recognize fundamental concepts that shape the domain. Earlier work in this domain used Wikipedia's structured and unstructured data to construct open-domain ontologies, domain terminologies, and knowledge bases. We present a novel method for leveraging navigational templates to create domain-specific fuzzy conceptual bases in this work. Our system generates knowledge graphs from the articles mentioned in the template, which we then process using Wikidata and machine learning algorithms. We filter important concepts using fuzzy logic on network metrics to create a crude conceptual base. Finally, the expert helps by refining the conceptual base. We demonstrate our system using an example of RNA virus antiviral drugs.","2021-06","2025-09-10 13:17:18","2025-09-10 13:17:18","","1–7","","","","","","","","","","","Association for Computational Linguistics","Online","","","","","","","","","","","","","","Dragut, Eduard; Li, Yunyao; Popa, Lucian; Vucetic, Slobodan","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VCX7XTTS","conferencePaper","2021","Li, Shuyang; Cao, Jin; Sridhar, Mukund; Zhu, Henghui; Li, Shang-Wen; Hamza, Wael; McAuley, Julian","Zero-shot Generalization in Dialog State Tracking through Generative Question Answering","Proceedings of the 16th Conference of the European Chapter of the Association for Computational Linguistics: Main Volume","","","10.18653/v1/2021.eacl-main.91","https://aclanthology.org/2021.eacl-main.91/","Dialog State Tracking (DST), an integral part of modern dialog systems, aims to track user preferences and constraints (slots) in task-oriented dialogs. In real-world settings with constantly changing services, DST systems must generalize to new domains and unseen slot types. Existing methods for DST do not generalize well to new slot names and many require known ontologies of slot types and values for inference. We introduce a novel ontology-free framework that supports natural language queries for unseen constraints and slots in multi-domain task-oriented dialogs. Our approach is based on generative question-answering using a conditional language model pre-trained on substantive English sentences. Our model improves joint goal accuracy in zero-shot domain adaptation settings by up to 9% (absolute) over the previous state-of-the-art on the MultiWOZ 2.1 dataset.","2021-04","2025-09-10 13:17:18","2025-09-10 13:17:18","","1063–1074","","","","","","","","","","","Association for Computational Linguistics","Online","","","","","","","","","","","","","","Merlo, Paola; Tiedemann, Jorg; Tsarfaty, Reut","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2WLK3E4D","conferencePaper","2021","Falis, Matúš; Dong, Hang; Birch, Alexandra; Alex, Beatrice","CoPHE: A Count-Preserving Hierarchical Evaluation Metric in Large-Scale Multi-Label Text Classification","Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing","","","10.18653/v1/2021.emnlp-main.69","https://aclanthology.org/2021.emnlp-main.69/","Large-Scale Multi-Label Text Classification (LMTC) includes tasks with hierarchical label spaces, such as automatic assignment of ICD-9 codes to discharge summaries. Performance of models in prior art is evaluated with standard precision, recall, and F1 measures without regard for the rich hierarchical structure. In this work we argue for hierarchical evaluation of the predictions of neural LMTC models. With the example of the ICD-9 ontology we describe a structural issue in the representation of the structured label space in prior art, and propose an alternative representation based on the depth of the ontology. We propose a set of metrics for hierarchical evaluation using the depth-based representation. We compare the evaluation scores from the proposed metrics with previously used metrics on prior art LMTC models for ICD-9 coding in MIMIC-III. We also propose further avenues of research involving the proposed ontological representation.","2021-11","2025-09-10 13:17:18","2025-09-10 13:17:18","","907–912","","","","","","","","","","","Association for Computational Linguistics","Online and Punta Cana, Dominican Republic","","","","","","","","","","","","","","Moens, Marie-Francine; Huang, Xuanjing; Specia, Lucia; Yih, Scott Wen-tau","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EWMWFHRQ","conferencePaper","2021","Moghe, Nikita; Steedman, Mark; Birch, Alexandra","Cross-lingual Intermediate Fine-tuning improves Dialogue State Tracking","Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing","","","10.18653/v1/2021.emnlp-main.87","https://aclanthology.org/2021.emnlp-main.87/","Recent progress in task-oriented neural dialogue systems is largely focused on a handful of languages, as annotation of training data is tedious and expensive. Machine translation has been used to make systems multilingual, but this can introduce a pipeline of errors. Another promising solution is using cross-lingual transfer learning through pretrained multilingual models. Existing methods train multilingual models with additional code-mixed task data or refine the cross-lingual representations through parallel ontologies. In this work, we enhance the transfer learning process by intermediate fine-tuning of pretrained multilingual models, where the multilingual models are fine-tuned with different but related data and/or tasks. Specifically, we use parallel and conversational movie subtitles datasets to design cross-lingual intermediate tasks suitable for downstream dialogue tasks. We use only 200K lines of parallel data for intermediate fine-tuning which is already available for 1782 language pairs. We test our approach on the cross-lingual dialogue state tracking task for the parallel MultiWoZ (English -\ensuremath> Chinese, Chinese -\ensuremath> English) and Multilingual WoZ (English -\ensuremath> German, English -\ensuremath> Italian) datasets. We achieve impressive improvements (\ensuremath> 20% on joint goal accuracy) on the parallel MultiWoZ dataset and the Multilingual WoZ dataset over the vanilla baseline with only 10% of the target language task data and zero-shot setup respectively.","2021-11","2025-09-10 13:17:18","2025-09-10 13:17:18","","1137–1150","","","","","","","","","","","Association for Computational Linguistics","Online and Punta Cana, Dominican Republic","","","","","","","","","","","","","","Moens, Marie-Francine; Huang, Xuanjing; Specia, Lucia; Yih, Scott Wen-tau","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HA266ETR","conferencePaper","2021","Pyatkin, Valentina; Roit, Paul; Michael, Julian; Goldberg, Yoav; Tsarfaty, Reut; Dagan, Ido","Asking It All: Generating Contextualized Questions for any Semantic Role","Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing","","","10.18653/v1/2021.emnlp-main.108","https://aclanthology.org/2021.emnlp-main.108/","Asking questions about a situation is an inherent step towards understanding it. To this end, we introduce the task of role question generation, which, given a predicate mention and a passage, requires producing a set of questions asking about all possible semantic roles of the predicate. We develop a two-stage model for this task, which first produces a context-independent question prototype for each role and then revises it to be contextually appropriate for the passage. Unlike most existing approaches to question generation, our approach does not require conditioning on existing answers in the text. Instead, we condition on the type of information to inquire about, regardless of whether the answer appears explicitly in the text, could be inferred from it, or should be sought elsewhere. Our evaluation demonstrates that we generate diverse and well-formed questions for a large, broad-coverage ontology of predicates and roles.","2021-11","2025-09-10 13:17:18","2025-09-10 13:17:18","","1429–1441","","","","","","","","","","","Association for Computational Linguistics","Online and Punta Cana, Dominican Republic","","","","","","","","","","","","","","Moens, Marie-Francine; Huang, Xuanjing; Specia, Lucia; Yih, Scott Wen-tau","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"L6QPR8MN","conferencePaper","2021","Li, Xinmeng; Li, Qian; Wu, Wansen; Yin, Quanjun","Generation and Extraction Combined Dialogue State Tracking with Hierarchical Ontology Integration","Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing","","","10.18653/v1/2021.emnlp-main.171","https://aclanthology.org/2021.emnlp-main.171/","Recently, the focus of dialogue state tracking has expanded from single domain to multiple domains. The task is characterized by the shared slots between domains. As the scenario gets more complex, the out-of-vocabulary problem also becomes severer. Current models are not satisfactory for solving the challenges of ontology integration between domains and out-of-vocabulary problems. To address the problem, we explore the hierarchical semantic of ontology and enhance the interrelation between slots with masked hierarchical attention. In state value decoding stage, we solve the out-of-vocabulary problem by combining generation method and extraction method together. We evaluate the performance of our model on two representative datasets, MultiWOZ in English and CrossWOZ in Chinese. The results show that our model yields a significant performance gain over current state-of-the-art state tracking model and it is more robust to out-of-vocabulary problem compared with other methods.","2021-11","2025-09-10 13:17:18","2025-09-10 13:17:18","","2241–2249","","","","","","","","","","","Association for Computational Linguistics","Online and Punta Cana, Dominican Republic","","","","","","","","","","","","","","Moens, Marie-Francine; Huang, Xuanjing; Specia, Lucia; Yih, Scott Wen-tau","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DBTGSCFF","conferencePaper","2021","Wang, Xuan; Hu, Vivian; Song, Xiangchen; Garg, Shweta; Xiao, Jinfeng; Han, Jiawei","ChemNER: Fine-Grained Chemistry Named Entity Recognition with Ontology-Guided Distant Supervision","Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing","","","10.18653/v1/2021.emnlp-main.424","https://aclanthology.org/2021.emnlp-main.424/","Scientific literature analysis needs fine-grained named entity recognition (NER) to provide a wide range of information for scientific discovery. For example, chemistry research needs to study dozens to hundreds of distinct, fine-grained entity types, making consistent and accurate annotation difficult even for crowds of domain experts. On the other hand, domain-specific ontologies and knowledge bases (KBs) can be easily accessed, constructed, or integrated, which makes distant supervision realistic for fine-grained chemistry NER. In distant supervision, training labels are generated by matching mentions in a document with the concepts in the knowledge bases (KBs). However, this kind of KB-matching suffers from two major challenges: incomplete annotation and noisy annotation. We propose ChemNER, an ontology-guided, distantly-supervised method for fine-grained chemistry NER to tackle these challenges. It leverages the chemistry type ontology structure to generate distant labels with novel methods of flexible KB-matching and ontology-guided multi-type disambiguation. It significantly improves the distant label generation for the subsequent sequence labeling model training. We also provide an expert-labeled, chemistry NER dataset with 62 fine-grained chemistry types (e.g., chemical compounds and chemical reactions). Experimental results show that ChemNER is highly effective, outperforming substantially the state-of-the-art NER methods (with .25 absolute F1 score improvement).","2021-11","2025-09-10 13:17:19","2025-09-10 13:17:19","","5227–5240","","","","","","","","","","","Association for Computational Linguistics","Online and Punta Cana, Dominican Republic","","","","","","","","","","","","","","Moens, Marie-Francine; Huang, Xuanjing; Specia, Lucia; Yih, Scott Wen-tau","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"R5YNYJ23","conferencePaper","2021","Yu, Pengfei; Ji, Heng; Natarajan, Prem","Lifelong Event Detection with Knowledge Transfer","Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing","","","10.18653/v1/2021.emnlp-main.428","https://aclanthology.org/2021.emnlp-main.428/","Traditional supervised Information Extraction (IE) methods can extract structured knowledge elements from unstructured data, but it is limited to a pre-defined target ontology. In reality, the ontology of interest may change over time, adding emergent new types or more fine-grained subtypes. We propose a new lifelong learning framework to address this challenge. We focus on lifelong event detection as an exemplar case and propose a new problem formulation that is also generalizable to other IE tasks. In event detection and more general IE tasks, rich correlations or semantic relatedness exist among hierarchical knowledge element types. In our proposed framework, knowledge is being transferred between learned old event types and new event types. Specifically, we update old knowledge with new event types' mentions using a self-training loss. In addition, we aggregate old event types' representations based on their similarities with new event types to initialize the new event types' representations. Experimental results show that our framework outperforms competitive baselines with a 5.1% absolute gain in the F1 score. Moreover, our proposed framework can boost the F1 score for over 30% absolute gain on some new long-tail rare event types with few training instances. Our knowledge transfer module improves performance on both learned event types and new event types under the lifelong learning setting, showing that it helps consolidate old knowledge and improve novel knowledge acquisition.","2021-11","2025-09-10 13:17:19","2025-09-10 13:17:19","","5278–5290","","","","","","","","","","","Association for Computational Linguistics","Online and Punta Cana, Dominican Republic","","","","","","","","","","","","","","Moens, Marie-Francine; Huang, Xuanjing; Specia, Lucia; Yih, Scott Wen-tau","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MIVHSIF3","conferencePaper","2021","Iyer, Vivek; Agarwal, Arvind; Kumar, Harshit","VeeAlign: Multifaceted Context Representation Using Dual Attention for Ontology Alignment","Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing","","","10.18653/v1/2021.emnlp-main.842","https://aclanthology.org/2021.emnlp-main.842/","Ontology Alignment is an important research problem applied to various fields such as data integration, data transfer, data preparation, etc. State-of-the-art (SOTA) Ontology Alignment systems typically use naive domain-dependent approaches with handcrafted rules or domain-specific architectures, making them unscalable and inefficient. In this work, we propose VeeAlign, a Deep Learning based model that uses a novel dual-attention mechanism to compute the contextualized representation of a concept which, in turn, is used to discover alignments. By doing this, not only is our approach able to exploit both syntactic and semantic information encoded in ontologies, it is also, by design, flexible and scalable to different domains with minimal effort. We evaluate our model on four different datasets from different domains and languages, and establish its superiority through these results as well as detailed ablation studies. The code and datasets used are available at https://github.com/Remorax/VeeAlign.","2021-11","2025-09-10 13:17:19","2025-09-10 13:17:19","","10780–10792","","","","","","","","","","","Association for Computational Linguistics","Online and Punta Cana, Dominican Republic","","","","","","","","","","","","","","Moens, Marie-Francine; Huang, Xuanjing; Specia, Lucia; Yih, Scott Wen-tau","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"74GY87TU","conferencePaper","2021","Shrivastava, Akshat; Chuang, Pierce; Babu, Arun; Desai, Shrey; Arora, Abhinav; Zotov, Alexander; Aly, Ahmed","Span Pointer Networks for Non-Autoregressive Task-Oriented Semantic Parsing","Findings of the Association for Computational Linguistics: EMNLP 2021","","","10.18653/v1/2021.findings-emnlp.161","https://aclanthology.org/2021.findings-emnlp.161/","An effective recipe for building seq2seq, non-autoregressive, task-oriented parsers to map utterances to semantic frames proceeds in three steps: encoding an utterance x, predicting a frame's length |y|, and decoding a |y|-sized frame with utterance and ontology tokens. Though empirically strong, these models are typically bottlenecked by length prediction, as even small inaccuracies change the syntactic and semantic characteristics of resulting frames. In our work, we propose span pointer networks, non-autoregressive parsers which shift the decoding task from text generation to span prediction; that is, when imputing utterance spans into frame slots, our model produces endpoints (e.g., [i, j]) as opposed to text (e.g., “6pm”). This natural quantization of the output space reduces the variability of gold frames, therefore improving length prediction and, ultimately, exact match. Furthermore, length prediction is now responsible for frame syntax and the decoder is responsible for frame semantics, resulting in a coarse-to-fine model. We evaluate our approach on several task-oriented semantic parsing datasets. Notably, we bridge the quality gap between non-autogressive and autoregressive parsers, achieving 87 EM on TOPv2 (Chen et al. 2020). Furthermore, due to our more consistent gold frames, we show strong improvements in model generalization in both cross-domain and cross-lingual transfer in low-resource settings. Finally, due to our diminished output vocabulary, we observe 70% reduction in latency and 83% reduction in memory at beam size 5 compared to prior non-autoregressive parsers.","2021-11","2025-09-10 13:17:19","2025-09-10 13:17:19","","1873–1886","","","","","","","","","","","Association for Computational Linguistics","Punta Cana, Dominican Republic","","","","","","","","","","","","","","Moens, Marie-Francine; Huang, Xuanjing; Specia, Lucia; Yih, Scott Wen-tau","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9AU3LTM4","conferencePaper","2021","Chen, Zhiyu; Liu, Honglei; Xu, Hu; Moon, Seungwhan; Zhou, Hao; Liu, Bing","NUANCED: Natural Utterance Annotation for Nuanced Conversation with Estimated Distributions","Findings of the Association for Computational Linguistics: EMNLP 2021","","","10.18653/v1/2021.findings-emnlp.337","https://aclanthology.org/2021.findings-emnlp.337/","Existing conversational systems are mostly agent-centric, which assumes the user utterances will closely follow the system ontology. However, in real-world scenarios, it is highly desirable that users can speak freely and naturally. In this work, we attempt to build a user-centric dialogue system for conversational recommendation. As there is no clean mapping for a user's free form utterance to an ontology, we first model the user preferences as estimated distributions over the system ontology and map the user's utterances to such distributions. Learning such a mapping poses new challenges on reasoning over various types of knowledge, ranging from factoid knowledge, commonsense knowledge to the users' own situations. To this end, we build a new dataset named NUANCED that focuses on such realistic settings, with 5.1k dialogues, 26k turns of high-quality user responses. We conduct experiments, showing both the usefulness and challenges of our problem setting. We believe NUANCED can serve as a valuable resource to push existing research from the agent-centric system to the user-centric system. The code and data are publicly available.","2021-11","2025-09-10 13:17:19","2025-09-10 13:17:19","","4016–4024","","","","","","","","","","","Association for Computational Linguistics","Punta Cana, Dominican Republic","","","","","","","","","","","","","","Moens, Marie-Francine; Huang, Xuanjing; Specia, Lucia; Yih, Scott Wen-tau","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TMVKY8KZ","conferencePaper","2021","Svetla, Koeva","Towards Expanding WordNet with Conceptual Frames","Proceedings of the 11th Global Wordnet Conference","","","","https://aclanthology.org/2021.gwc-1.21/","The paper presents the project Semantic Network with a Wide Range of Semantic Relations and its main achievements. The ultimate objective of the project is to expand Princeton WordNet with conceptual frames that define the syntagmatic relations of verb synsets and the semantic classes of nouns felicitous to combine with particular verbs. At this stage of the work: a) over 5,000 WordNet verb synsets have been supplied with manually evaluated FrameNet semantic frames, b) 253 semantic types have been manually mapped to the appropriate WordNet concepts providing detailed ontological representation of the semantic classes of nouns.","2021-01","2025-09-10 13:17:19","2025-09-10 13:17:19","","182–191","","","","","","","","","","","Global Wordnet Association","University of South Africa (UNISA)","","","","","","","","","","","","","","Vossen, Piek; Fellbaum, Christiane","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CW4KL22F","conferencePaper","2021","Weber, Sabine; Steedman, Mark","Zero-Shot Cross-Lingual Transfer is a Hard Baseline to Beat in German Fine-Grained Entity Typing","Proceedings of the Second Workshop on Insights from Negative Results in NLP","","","10.18653/v1/2021.insights-1.7","https://aclanthology.org/2021.insights-1.7/","The training of NLP models often requires large amounts of labelled training data, which makes it difficult to expand existing models to new languages. While zero-shot cross-lingual transfer relies on multilingual word embeddings to apply a model trained on one language to another, Yarowski and Ngai (2001) propose the method of annotation projection to generate training data without manual annotation. This method was successfully used for the tasks of named entity recognition and coarse-grained entity typing, but we show that it is outperformed by zero-shot cross-lingual transfer when applied to the similar task of fine-grained entity typing. In our study of fine-grained entity typing with the FIGER type ontology for German, we show that annotation projection amplifies the English model's tendency to underpredict level 2 labels and is beaten by zero-shot cross-lingual transfer on three novel test sets.","2021-11","2025-09-10 13:17:19","2025-09-10 13:17:19","","42–48","","","","","","","","","","","Association for Computational Linguistics","Online and Punta Cana, Dominican Republic","","","","","","","","","","","","","","Sedoc, João; Rogers, Anna; Rumshisky, Anna; Tafreshi, Shabnam","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AFJ7VR8E","conferencePaper","2021","Stowe, Kevin; Preciado, Jenette; Conger, Kathryn; Brown, Susan Windisch; Kazeminejad, Ghazaleh; Gung, James; Palmer, Martha","SemLink 2.0: Chasing Lexical Resources","Proceedings of the 14th International Conference on Computational Semantics (IWCS)","","","","https://aclanthology.org/2021.iwcs-1.21/","The SemLink resource provides mappings between a variety of lexical semantic ontologies, each with their strengths and weaknesses. To take advantage of these differences, the ability to move between resources is essential. This work describes advances made to improve the usability of the SemLink resource: the automatic addition of new instances and mappings, manual corrections, sense-based vectors and collocation information, and architecture built to automatically update the resource when versions of the underlying resources change. These updates improve coverage, provide new tools to leverage the capabilities of these resources, and facilitate seamless updates, ensuring the consistency and applicability of these mappings in the future.","2021-06","2025-09-10 13:17:19","2025-09-10 13:17:19","","222–227","","","","","","","","","","","Association for Computational Linguistics","Groningen, The Netherlands (online)","","","","","","","","","","","","","","Zarrieß, Sina; Bos, Johan; van Noord, Rik; Abzianidze, Lasha","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8GI76HYR","conferencePaper","2021","Schleider, Thomas; Troncy, Raphael","Zero-Shot Information Extraction to Enhance a Knowledge Graph Describing Silk Textiles","Proceedings of the 5th Joint SIGHUM Workshop on Computational Linguistics for Cultural Heritage, Social Sciences, Humanities and Literature","","","10.18653/v1/2021.latechclfl-1.16","https://aclanthology.org/2021.latechclfl-1.16/","The knowledge of the European silk textile production is a typical case for which the information collected is heterogeneous, spread across many museums and sparse since rarely complete. Knowledge Graphs for this cultural heritage domain, when being developed with appropriate ontologies and vocabularies, enable to integrate and reconcile this diverse information. However, many of these original museum records still have some metadata gaps. In this paper, we present a zero-shot learning approach that leverages the ConceptNet common sense knowledge graph to predict categorical metadata informing about the silk objects production. We compared the performance of our approach with traditional supervised deep learning-based methods that do require training data. We demonstrate promising and competitive performance for similar datasets and circumstances and the ability to predict sometimes more fine-grained information. Our results can be reproduced using the code and datasets published at https://github.com/silknow/ZSL-KG-silk.","2021-11","2025-09-10 13:17:19","2025-09-10 13:17:19","","138–146","","","","","","","","","","","Association for Computational Linguistics","Punta Cana, Dominican Republic (online)","","","","","","","","","","","","","","Degaetano-Ortlieb, Stefania; Kazantseva, Anna; Reiter, Nils; Szpakowicz, Stan","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TK94PSCJ","conferencePaper","2021","Nan, Linyong; Radev, Dragomir; Zhang, Rui; Rau, Amrit; Sivaprasad, Abhinand; Hsieh, Chiachun; Tang, Xiangru; Vyas, Aadit; Verma, Neha; Krishna, Pranav; Liu, Yangxiaokang; Irwanto, Nadia; Pan, Jessica; Rahman, Faiaz; Zaidi, Ahmad; Mutuma, Mutethia; Tarabar, Yasin; Gupta, Ankit; Yu, Tao; Tan, Yi Chern; Lin, Xi Victoria; Xiong, Caiming; Socher, Richard; Rajani, Nazneen Fatema","DART: Open-Domain Structured Data Record to Text Generation","Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies","","","10.18653/v1/2021.naacl-main.37","https://aclanthology.org/2021.naacl-main.37/","We present DART, an open domain structured DAta Record to Text generation dataset with over 82k instances (DARTs). Data-to-text annotations can be a costly process, especially when dealing with tables which are the major source of structured data and contain nontrivial structures. To this end, we propose a procedure of extracting semantic triples from tables that encodes their structures by exploiting the semantic dependencies among table headers and the table title. Our dataset construction framework effectively merged heterogeneous sources from open domain semantic parsing and spoken dialogue systems by utilizing techniques including tree ontology annotation, question-answer pair to declarative sentence conversion, and predicate unification, all with minimum post-editing. We present systematic evaluation on DART as well as new state-of-the-art results on WebNLG 2017 to show that DART (1) poses new challenges to existing data-to-text datasets and (2) facilitates out-of-domain generalization. Our data and code can be found at https://github.com/Yale-LILY/dart.","2021-06","2025-09-10 13:17:19","2025-09-10 13:17:19","","432–447","","","","","","","","","","","Association for Computational Linguistics","Online","","","","","","","","","","","","","","Toutanova, Kristina; Rumshisky, Anna; Zettlemoyer, Luke; Hakkani-Tur, Dilek; Beltagy, Iz; Bethard, Steven; Cotterell, Ryan; Chakraborty, Tanmoy; Zhou, Yichao","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"P8VVS9PI","conferencePaper","2021","Prabhumoye, Shrimai; Boldt, Brendon; Salakhutdinov, Ruslan; Black, Alan W","Case Study: Deontological Ethics in NLP","Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies","","","10.18653/v1/2021.naacl-main.297","https://aclanthology.org/2021.naacl-main.297/","Recent work in natural language processing (NLP) has focused on ethical challenges such as understanding and mitigating bias in data and algorithms; identifying objectionable content like hate speech, stereotypes and offensive language; and building frameworks for better system design and data handling practices. However, there has been little discussion about the ethical foundations that underlie these efforts. In this work, we study one ethical theory, namely deontological ethics, from the perspective of NLP. In particular, we focus on the generalization principle and the respect for autonomy through informed consent. We provide four case studies to demonstrate how these principles can be used with NLP systems. We also recommend directions to avoid the ethical issues in these systems.","2021-06","2025-09-10 13:17:19","2025-09-10 13:17:19","","3784–3798","","","","","","","","","","","Association for Computational Linguistics","Online","","","","","","","","","","","","","","Toutanova, Kristina; Rumshisky, Anna; Zettlemoyer, Luke; Hakkani-Tur, Dilek; Beltagy, Iz; Bethard, Steven; Cotterell, Ryan; Chakraborty, Tanmoy; Zhou, Yichao","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"C98R4JEZ","conferencePaper","2021","Liu, Fangyu; Shareghi, Ehsan; Meng, Zaiqiao; Basaldella, Marco; Collier, Nigel","Self-Alignment Pretraining for Biomedical Entity Representations","Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies","","","10.18653/v1/2021.naacl-main.334","https://aclanthology.org/2021.naacl-main.334/","Despite the widespread success of self-supervised learning via masked language models (MLM), accurately capturing fine-grained semantic relationships in the biomedical domain remains a challenge. This is of paramount importance for entity-level tasks such as entity linking where the ability to model entity relations (especially synonymy) is pivotal. To address this challenge, we propose SapBERT, a pretraining scheme that self-aligns the representation space of biomedical entities. We design a scalable metric learning framework that can leverage UMLS, a massive collection of biomedical ontologies with 4M+ concepts. In contrast with previous pipeline-based hybrid systems, SapBERT offers an elegant one-model-for-all solution to the problem of medical entity linking (MEL), achieving a new state-of-the-art (SOTA) on six MEL benchmarking datasets. In the scientific domain, we achieve SOTA even without task-specific supervision. With substantial improvement over various domain-specific pretrained MLMs such as BioBERT, SciBERTand and PubMedBERT, our pretraining scheme proves to be both effective and robust.","2021-06","2025-09-10 13:17:19","2025-09-10 13:17:19","","4228–4238","","","","","","","","","","","Association for Computational Linguistics","Online","","","","","","","","","","","","","","Toutanova, Kristina; Rumshisky, Anna; Zettlemoyer, Luke; Hakkani-Tur, Dilek; Beltagy, Iz; Bethard, Steven; Cotterell, Ryan; Chakraborty, Tanmoy; Zhou, Yichao","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZA546CY5","conferencePaper","2021","Pham, Nhi; Pham, Lachlan; Meyers, Adam L.","Legal Terminology Extraction with the Termolator","Proceedings of the Natural Legal Language Processing Workshop 2021","","","10.18653/v1/2021.nllp-1.16","https://aclanthology.org/2021.nllp-1.16/","Domain-specific terminology is ubiquitous in legal documents. Despite potential utility in populating glossaries and ontologies or as arguments in information extraction and document classification tasks, there has been limited work done for legal terminology extraction. This paper describes some work to remedy this omission. In the described research, we make some modifications to the Termolator, a high-performing, open-source terminology extractor which has been tuned to scientific articles. Our changes are designed to improve the Termolator's results when applied to United States Supreme Court decisions. Unaltered and using the recommended settings, the original Termolator provides a list of terminology with a precision of 23% and 25% for the categories of economic activity (development set) and criminal procedures (test set) respectively. These were the most frequently occurring broad issues in Washington University in St. Louis Database corpus, a database of Supreme Court decisions that have been manually classified by topic. Our contribution includes the introduction of several legal domain-specific filtration steps and changes to the web search relevance score; each incrementally improved precision culminating in a combined precision of 63% and 65%. We also evaluated the baseline version of the Termolator on more specific subcategories and on broad issues with fewer cases. Our results show that a narrowed scope as well as smaller document numbers significantly lower the precision. In both cases, the modifications to the Termolator improve precision.","2021-11","2025-09-10 13:17:19","2025-09-10 13:17:19","","155–162","","","","","","","","","","","Association for Computational Linguistics","Punta Cana, Dominican Republic","","","","","","","","","","","","","","Aletras, Nikolaos; Androutsopoulos, Ion; Barrett, Leslie; Goanta, Catalina; Preotiuc-Pietro, Daniel","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9LRN9AL2","conferencePaper","2021","Aceta, Cristina; Fernández, Izaskun; Soroa, Aitor","Ontology Population Reusing Resources for Dialogue Intent Detection: Generic and Multilingual Approach","Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2021)","","","","https://aclanthology.org/2021.ranlp-1.2/","This work presents a generic semi-automatic strategy to populate the domain ontology of an ontology-driven task-oriented dialogue system, with the aim of performing successful intent detection in the dialogue process, reusing already existing multilingual resources. This semi-automatic approach allows ontology engineers to exploit available resources so as to associate the potential situations in the use case to FrameNet frames and obtain the relevant lexical units associated to them in the target language, following lexical and semantic criteria, without linguistic expert knowledge. This strategy has been validated and evaluated in two use cases, from industrial scenarios, for interaction in Spanish with a guide robot and with a Computerized Maintenance Management System (CMMS). In both cases, this method has allowed the ontology engineer to instantiate the domain ontology with the intent-relevant information with quality data in a simple and low-resource-consuming manner.","2021-09","2025-09-10 13:17:19","2025-09-10 13:17:19","","10–18","","","","","","","","","","","INCOMA Ltd.","Held Online","","","","","","","","","","","","","","Mitkov, Ruslan; Angelova, Galia","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3PVT87JQ","conferencePaper","2021","Hristov, Anton; Tahchiev, Aleksandar; Papazov, Hristo; Tulechki, Nikola; Primov, Todor; Boytcheva, Svetla","Application of Deep Learning Methods to SNOMED CT Encoding of Clinical Texts: From Data Collection to Extreme Multi-Label Text-Based Classification","Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2021)","","","","https://aclanthology.org/2021.ranlp-1.63/","Concept normalization of clinical texts to standard medical classifications and ontologies is a task with high importance for healthcare and medical research. We attempt to solve this problem through automatic SNOMED CT encoding, where SNOMED CT is one of the most widely used and comprehensive clinical term ontologies. Applying basic Deep Learning models, however, leads to undesirable results due to the unbalanced nature of the data and the extreme number of classes. We propose a classification procedure that features a multiple-step workflow consisting of label clustering, multi-cluster classification, and clusters-to-labels mapping. For multi-cluster classification, BioBERT is fine-tuned over our custom dataset. The clusters-to-labels mapping is carried out by a one-vs-all classifier (SVC) applied to every single cluster. We also present the steps for automatic dataset generation of textual descriptions annotated with SNOMED CT codes based on public data and linked open data. In order to cope with the problem that our dataset is highly unbalanced, some data augmentation methods are applied. The results from the conducted experiments show high accuracy and reliability of our approach for prediction of SNOMED CT codes relevant to a clinical text.","2021-09","2025-09-10 13:17:19","2025-09-10 13:17:19","","557–565","","","","","","","","","","","INCOMA Ltd.","Held Online","","","","","","","","","","","","","","Mitkov, Ruslan; Angelova, Galia","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8KLBZP44","conferencePaper","2021","Koeva, Svetla","Multilingual Image Corpus: Annotation Protocol","Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2021)","","","","https://aclanthology.org/2021.ranlp-1.80/","In this paper, we present work in progress aimed at the development of a new image dataset with annotated objects. The Multilingual Image Corpus consists of an ontology of visual objects (based on WordNet) and a collection of thematically related images annotated with segmentation masks and object classes. We identified 277 dominant classes and 1,037 parent and attribute classes, and grouped them into 10 thematic domains such as sport, medicine, education, food, security, etc. For the selected classes a large-scale web image search is being conducted in order to compile a substantial collection of high-quality copyright free images. The focus of the paper is the annotation protocol which we established to facilitate the annotation process: the Ontology of visual objects and the conventions for image selection and for object segmentation. The dataset is designed both for image classification and object detection and for semantic segmentation. In addition, the object annotations will be supplied with multilingual descriptions by using freely available wordnets.","2021-09","2025-09-10 13:17:19","2025-09-10 13:17:19","","701–707","","","","","","","","","","","INCOMA Ltd.","Held Online","","","","","","","","","","","","","","Mitkov, Ruslan; Angelova, Galia","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"B9EN2LTH","conferencePaper","2021","Sahnoun, Sihem; Lejeune, Gaël","Multilingual Epidemic Event Extraction : From Simple Classification Methods to Open Information Extraction (OIE) and Ontology","Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2021)","","","","https://aclanthology.org/2021.ranlp-1.138/","There is an incredible amount of information available in the form of textual documents due to the growth of information sources. In order to get the information into an actionable way, it is common to use information extraction and more specifically the event extraction, it became crucial in various domains even in public health. In this paper, we address the problem of the epidemic event extraction in potentially any language, so that we tested different corpuses on an existed multilingual system for tele-epidemiology: the Data Analysis for Information Extraction in any Language(DANIEL) system. We focused on the influence of the number of documents on the performance of the system, on average results show that it is able to achieve a precision and recall around 82%, but when we resorted to the evaluation by event by checking whether it has been really detected or not, the results are not satisfactory according to this paper's evaluation. Our idea is to propose a system that uses an ontology which includes information in different languages and covers specific epidemiological concepts, it is also based on the multilingual open information extraction for the relation extraction step to reduce the expert intervention and to restrict the content for each text. We describe a methodology of five main stages: Pre-processing, relation extraction, named entity recognition (NER), event recognition and the matching between the information extracted and the ontology.","2021-09","2025-09-10 13:17:19","2025-09-10 13:17:19","","1227–1233","","","","","","","","","","","INCOMA Ltd.","Held Online","","","","","","","","","","","","","","Mitkov, Ruslan; Angelova, Galia","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BU758KWP","conferencePaper","2021","Velichkov, Boris; Vassileva, Sylvia; Gerginov, Simeon; Kraychev, Boris; Ivanov, Ivaylo; Ivanov, Philip; Koychev, Ivan; Boytcheva, Svetla","Comparative Analysis of Fine-tuned Deep Learning Language Models for ICD-10 Classification Task for Bulgarian Language","Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2021)","","","","https://aclanthology.org/2021.ranlp-1.162/","The task of automatic diagnosis encoding into standard medical classifications and ontologies, is of great importance in medicine - both to support the daily tasks of physicians in the preparation and reporting of clinical documentation, and for automatic processing of clinical reports. In this paper we investigate the application and performance of different deep learning transformers for automatic encoding in ICD-10 of clinical texts in Bulgarian. The comparative analysis attempts to find which approach is more efficient to be used for fine-tuning of pretrained BERT family transformer to deal with a specific domain terminology on a rare language as Bulgarian. On the one side are used SlavicBERT and MultiligualBERT, that are pretrained for common vocabulary in Bulgarian, but lack medical terminology. On the other hand in the analysis are used BioBERT, ClinicalBERT, SapBERT, BlueBERT, that are pretrained for medical terminology in English, but lack training for language models in Bulgarian, and more over for vocabulary in Cyrillic. In our research study all BERT models are fine-tuned with additional medical texts in Bulgarian and then applied to the classification task for encoding medical diagnoses in Bulgarian into ICD-10 codes. Big corpora of diagnosis in Bulgarian annotated with ICD-10 codes is used for the classification task. Such an analysis gives a good idea of which of the models would be suitable for tasks of a similar type and domain. The experiments and evaluation results show that both approaches have comparable accuracy.","2021-09","2025-09-10 13:17:19","2025-09-10 13:17:19","","1448–1454","","","","","","","","","","","INCOMA Ltd.","Held Online","","","","","","","","","","","","","","Mitkov, Ruslan; Angelova, Galia","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"G82FN9H5","conferencePaper","2021","Balaraman, Vevake; Sheikhalishahi, Seyedmostafa; Magnini, Bernardo","Recent Neural Methods on Dialogue State Tracking for Task-Oriented Dialogue Systems: A Survey","Proceedings of the 22nd Annual Meeting of the Special Interest Group on Discourse and Dialogue","","","10.18653/v1/2021.sigdial-1.25","https://aclanthology.org/2021.sigdial-1.25/","This paper aims at providing a comprehensive overview of recent developments in dialogue state tracking (DST) for task-oriented conversational systems. We introduce the task, the main datasets that have been exploited as well as their evaluation metrics, and we analyze several proposed approaches. We distinguish between static ontology DST models, which predict a fixed set of dialogue states, and dynamic ontology models, which can predict dialogue states even when the ontology changes. We also discuss the model's ability to track either single or multiple domains and to scale to new domains, both in terms of knowledge transfer and zero-shot learning. We cover a period from 2013 to 2020, showing a significant increase of multiple domain methods, most of them utilizing pre-trained language models.","2021-07","2025-09-10 13:17:19","2025-09-10 13:17:19","","239–251","","","","","","","","","","","Association for Computational Linguistics","Singapore and Online","","","","","","","","","","","","","","Li, Haizhou; Levow, Gina-Anne; Yu, Zhou; Gupta, Chitralekha; Sisman, Berrak; Cai, Siqi; Vandyke, David; Dethlefs, Nina; Wu, Yan; Li, Junyi Jessy","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CEMZVG3Z","conferencePaper","2021","Dayanik, Erenay; Blessing, Andre; Blokker, Nico; Haunss, Sebastian; Kuhn, Jonas; Lapesa, Gabriella; Padó, Sebastian","Using Hierarchical Class Structure to Improve Fine-Grained Claim Classification","Proceedings of the 5th Workshop on Structured Prediction for NLP (SPNLP 2021)","","","10.18653/v1/2021.spnlp-1.6","https://aclanthology.org/2021.spnlp-1.6/","The analysis of public debates crucially requires the classification of political demands according to hierarchical <i>claim ontologies</i> (e.g. for immigration, a supercategory “Controlling Migration” might have subcategories “Asylum limit” or “Border installations”). A major challenge for automatic claim classification is the large number and low frequency of such subclasses. We address it by jointly predicting pairs of matching super- and subcategories. We operationalize this idea by (a) encoding soft constraints in the claim classifier and (b) imposing hard constraints via Integer Linear Programming. Our experiments with different claim classifiers on a German immigration newspaper corpus show consistent performance increases for joint prediction, in particular for infrequent categories and discuss the complementarity of the two approaches.","2021-08","2025-09-10 13:17:19","2025-09-10 13:17:19","","53–60","","","","","","","","","","","Association for Computational Linguistics","Online","","","","","","","","","","","","","","Kozareva, Zornitsa; Ravi, Sujith; Vlachos, Andreas; Agrawal, Priyanka; Martins, André","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"C42VPK5R","conferencePaper","2022","Xu, Fangyuan; Li, Junyi Jessy; Choi, Eunsol","How Do We Answer Complex Questions: Discourse Structure of Long-form Answers","Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)","","","10.18653/v1/2022.acl-long.249","https://aclanthology.org/2022.acl-long.249/","Long-form answers, consisting of multiple sentences, can provide nuanced and comprehensive answers to a broader set of questions. To better understand this complex and understudied task, we study the functional structure of long-form answers collected from three datasets, ELI5, WebGPT and Natural Questions. Our main goal is to understand how humans organize information to craft complex answers. We develop an ontology of six sentence-level functional roles for long-form answers, and annotate 3.9k sentences in 640 answer paragraphs. Different answer collection methods manifest in different discourse structures. We further analyze model-generated answers – finding that annotators agree less with each other when annotating model-generated answers compared to annotating human-written answers. Our annotated data enables training a strong classifier that can be used for automatic analysis. We hope our work can inspire future research on discourse-level modeling and evaluation of long-form QA systems.","2022-05","2025-09-10 13:17:19","2025-09-10 13:17:19","","3556–3572","","","","","","","","","","","Association for Computational Linguistics","Dublin, Ireland","","","","","","","","","","","","","","Muresan, Smaranda; Nakov, Preslav; Villavicencio, Aline","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8V6E93W4","conferencePaper","2022","Hu, Jinpeng; Li, Zhuo; Chen, Zhihong; Li, Zhen; Wan, Xiang; Chang, Tsung-Hui","Graph Enhanced Contrastive Learning for Radiology Findings Summarization","Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)","","","10.18653/v1/2022.acl-long.320","https://aclanthology.org/2022.acl-long.320/","The impression section of a radiology report summarizes the most prominent observation from the findings section and is the most important section for radiologists to communicate to physicians. Summarizing findings is time-consuming and can be prone to error for inexperienced radiologists, and thus automatic impression generation has attracted substantial attention. With the encoder-decoder framework, most previous studies explore incorporating extra knowledge (e.g., static pre-defined clinical ontologies or extra background information). Yet, they encode such knowledge by a separate encoder to treat it as an extra input to their models, which is limited in leveraging their relations with the original findings. To address the limitation, we propose a unified framework for exploiting both extra knowledge and the original findings in an integrated way so that the critical information (i.e., key words and their relations) can be extracted in an appropriate way to facilitate impression generation. In detail, for each input findings, it is encoded by a text encoder and a graph is constructed through its entities and dependency tree. Then, a graph encoder (e.g., graph neural networks (GNNs)) is adopted to model relation information in the constructed graph. Finally, to emphasize the key words in the findings, contrastive learning is introduced to map positive samples (constructed by masking non-key words) closer and push apart negative ones (constructed by masking key words). The experimental results on two datasets, OpenI and MIMIC-CXR, confirm the effectiveness of our proposed method, where the state-of-the-art results are achieved.","2022-05","2025-09-10 13:17:19","2025-09-10 13:17:19","","4677–4688","","","","","","","","","","","Association for Computational Linguistics","Dublin, Ireland","","","","","","","","","","","","","","Muresan, Smaranda; Nakov, Preslav; Villavicencio, Aline","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Z6G97EG7","conferencePaper","2022","Dou, Yao; Forbes, Maxwell; Koncel-Kedziorski, Rik; Smith, Noah A.; Choi, Yejin","Is GPT-3 Text Indistinguishable from Human Text? Scarecrow: A Framework for Scrutinizing Machine Text","Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)","","","10.18653/v1/2022.acl-long.501","https://aclanthology.org/2022.acl-long.501/","Modern neural language models can produce remarkably fluent and grammatical text. So much, in fact, that recent work by Clark et al. (2021) has reported that conventional crowdsourcing can no longer reliably distinguish between machine-authored (GPT-3) and human-authored writing. As errors in machine generations become ever subtler and harder to spot, it poses a new challenge to the research community for robust machine text evaluation. We propose a new framework called Scarecrow for scrutinizing machine text via crowd annotation. To support the broad range of real machine errors that can be identified by laypeople, the ten error categories of Scarecrow—such as redundancy, commonsense errors, and incoherence—are identified through several rounds of crowd annotation experiments without a predefined ontology. We then use Scarecrow to collect over 41k error spans in human-written and machine-generated paragraphs of English language news text. We isolate factors for detailed analysis, including parameter count, training data, and various decoding-time configurations. Our approach successfully quantifies measurable gaps between human authored text and generations from models of several sizes, including fourteen configurations of GPT-3. In addition, our analysis unveils new insights, with detailed rationales provided by laypeople, e.g., that the commonsense capabilities have been improving with larger models while math capabilities have not, and that the choices of simple decoding hyperparameters can make remarkable differences on the perceived quality of machine text. We release our training material, annotation toolkit and dataset at https://yao-dou.github.io/scarecrow/.","2022-05","2025-09-10 13:17:19","2025-09-10 13:17:19","","7250–7274","","","","","","","","","","","Association for Computational Linguistics","Dublin, Ireland","","","","","","","","","","","","","","Muresan, Smaranda; Nakov, Preslav; Villavicencio, Aline","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"S6WGNCKN","conferencePaper","2022","Cao, Shulin; Shi, Jiaxin; Yao, Zijun; Lv, Xin; Yu, Jifan; Hou, Lei; Li, Juanzi; Liu, Zhiyuan; Xiao, Jinghui","Program Transfer for Answering Complex Questions over Knowledge Bases","Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)","","","10.18653/v1/2022.acl-long.559","https://aclanthology.org/2022.acl-long.559/","Program induction for answering complex questions over knowledge bases (KBs) aims to decompose a question into a multi-step program, whose execution against the KB produces the final answer. Learning to induce programs relies on a large number of parallel question-program pairs for the given KB. However, for most KBs, the gold program annotations are usually lacking, making learning difficult. In this paper, we propose the approach of program transfer, which aims to leverage the valuable program annotations on the rich-resourced KBs as external supervision signals to aid program induction for the low-resourced KBs that lack program annotations. For program transfer, we design a novel two-stage parsing framework with an efficient ontology-guided pruning strategy. First, a sketch parser translates the question into a high-level program sketch, which is the composition of functions. Second, given the question and sketch, an argument parser searches the detailed arguments from the KB for functions. During the searching, we incorporate the KB ontology to prune the search space. The experiments on ComplexWebQuestions and WebQuestionSP show that our method outperforms SOTA methods significantly, demonstrating the effectiveness of program transfer and our framework. Our codes and datasets can be obtained from https://github.com/THU-KEG/ProgramTransfer.","2022-05","2025-09-10 13:17:19","2025-09-10 13:17:19","","8128–8140","","","","","","","","","","","Association for Computational Linguistics","Dublin, Ireland","","","","","","","","","","","","","","Muresan, Smaranda; Nakov, Preslav; Villavicencio, Aline","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4Y4F73P7","conferencePaper","2022","Socrates, Vimig","Extraction of Diagnostic Reasoning Relations for Clinical Knowledge Graphs","Proceedings of the 60th Annual Meeting of the Association for Computational Linguistics: Student Research Workshop","","","10.18653/v1/2022.acl-srw.33","https://aclanthology.org/2022.acl-srw.33/","Clinical knowledge graphs lack meaningful diagnostic relations (e.g. comorbidities, sign/symptoms), limiting their ability to represent real-world diagnostic processes. Previous methods in biomedical relation extraction have focused on concept relations, such as gene-disease and disease-drug, and largely ignored clinical processes. In this thesis, we leverage a clinical reasoning ontology and propose methods to extract such relations from a physician-facing point-of-care reference wiki and consumer health resource texts. Given the lack of data labeled with diagnostic relations, we also propose new methods of evaluating the correctness of extracted triples in the zero-shot setting. We describe a process for the intrinsic evaluation of new facts by triple confidence filtering and clinician manual review, as well extrinsic evaluation in the form of a differential diagnosis prediction task.","2022-05","2025-09-10 13:17:19","2025-09-10 13:17:19","","413–421","","","","","","","","","","","Association for Computational Linguistics","Dublin, Ireland","","","","","","","","","","","","","","Louvan, Samuel; Madotto, Andrea; Madureira, Brielen","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"N4YUZD23","conferencePaper","2022","Falis, Matúš; Dong, Hang; Birch, Alexandra; Alex, Beatrice","Horses to Zebras: Ontology-Guided Data Augmentation and Synthesis for ICD-9 Coding","Proceedings of the 21st Workshop on Biomedical Language Processing","","","10.18653/v1/2022.bionlp-1.39","https://aclanthology.org/2022.bionlp-1.39/","Medical document coding is the process of assigning labels from a structured label space (ontology – e.g., ICD-9) to medical documents. This process is laborious, costly, and error-prone. In recent years, efforts have been made to automate this process with neural models. The label spaces are large (in the order of thousands of labels) and follow a big-head long-tail label distribution, giving rise to few-shot and zero-shot scenarios. Previous efforts tried to address these scenarios within the model, leading to improvements on rare labels, but worse results on frequent ones. We propose data augmentation and synthesis techniques in order to address these scenarios. We further introduce an analysis technique for this setting inspired by confusion matrices. This analysis technique points to the positive impact of data augmentation and synthesis, but also highlights more general issues of confusion within families of codes, and underprediction.","2022-05","2025-09-10 13:17:19","2025-09-10 13:17:19","","389–401","","","","","","","","","","","Association for Computational Linguistics","Dublin, Ireland","","","","","","","","","","","","","","Demner-Fushman, Dina; Cohen, Kevin Bretonnel; Ananiadou, Sophia; Tsujii, Junichi","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VEI8T2PE","conferencePaper","2022","Kim, Juhyeon; Choe, Yesong; Lee, Sanghack","SNU-Causality Lab @ Causal News Corpus 2022: Detecting Causality by Data Augmentation via Part-of-Speech tagging","Proceedings of the 5th Workshop on Challenges and Applications of Automated Extraction of Socio-political Events from Text (CASE)","","","10.18653/v1/2022.case-1.6","https://aclanthology.org/2022.case-1.6/","Finding causal relations in texts has been a challenge since it requires methods ranging from defining event ontologies to developing proper algorithmic approaches. In this paper, we developed a framework which classifies whether a given sentence contains a causal event. As our approach, we exploited an external corpus that has causal labels to overcome the small size of the original corpus (Causal News Corpus) provided by task organizers. Further, we employed a data augmentation technique utilizing Part-Of-Speech (POS) based on our observation that some parts of speech are more (or less) relevant to causality. Our approach especially improved the recall of detecting causal events in sentences.","2022-12","2025-09-10 13:17:19","2025-09-10 13:17:19","","44–49","","","","","","","","","","","Association for Computational Linguistics","Abu Dhabi, United Arab Emirates (Hybrid)","","","","","","","","","","","","","","Hürriyetoğlu, Ali; Tanev, Hristo; Zavarella, Vanni; Yörük, Erdem","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"R8ECZBE3","conferencePaper","2022","Kralev, Jordan; Koeva, Svetla","Image Models for large-scale Object Detection and Classification","Proceedings of the Fifth International Conference on Computational Linguistics in Bulgaria (CLIB 2022)","","","","https://aclanthology.org/2022.clib-1.22/","Recent developments in computer vision applications that are based on machine learning models allow real-time object detection, segmentation and captioning in image or video streams. The paper presents the development of an extension of the 80 COCO categories into a novel ontology with more than 700 classes covering 130 thematic subdomains related to Sport, Transport, Arts and Security. The development of an image dataset of object segmentation was accelerated by machine learning for automatic generation of objects' boundaries and classes. The Multilingual image dataset contains over 20,000 images and 200,000 annotations. It was used to pre-train 130 models for object detection and classification. We show the established approach for the development of the new models and their integration into an application and evaluation framework.","2022-09","2025-09-10 13:17:19","2025-09-10 13:17:19","","190–201","","","","","","","","","","","Department of Computational Linguistics, IBL – BAS","Sofia, Bulgaria","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MA2FUUDT","conferencePaper","2022","Song, Ran; He, Shizhu; Zheng, Suncong; Gao, Shengxiang; Liu, Kang; Yu, Zhengtao; Zhao, Jun","Decoupling Mixture-of-Graphs: Unseen Relational Learning for Knowledge Graph Completion by Fusing Ontology and Textual Experts","Proceedings of the 29th International Conference on Computational Linguistics","","","","https://aclanthology.org/2022.coling-1.196/","Knowledge Graph Embedding (KGE) has been proposed and successfully utilized to knowledge Graph Completion (KGC). But classic KGE paradigm often fail in unseen relation representations. Previous studies mainly utilize the textual descriptions of relations and its neighbor relations to represent unseen relations. In fact, the semantics of a relation can be expressed by three kinds of graphs: factual graph, ontology graph, textual description graph, and they can complement each other. A more common scenario in the real world is that seen and unseen relations appear at the same time. In this setting, the training set (only seen relations) and testing set (both seen and unseen relations) own different distributions. And the train-test inconsistency problem will make KGE methods easiy overfit on seen relations and under-performance on unseen relations. In this paper, we propose decoupling mixture-of-graph experts (DMoG) for unseen relations learning, which could represent the unseen relations in the factual graph by fusing ontology and textual graphs, and decouple fusing space and reasoning space to alleviate overfitting for seen relations. The experiments on two unseen only public datasets and a mixture dataset verify the effectiveness of the proposed method, which improves the state-of-the-art methods by 6.84% in Hits@10 on average.","2022-10","2025-09-10 13:17:19","2025-09-10 13:17:19","","2237–2246","","","","","","","","","","","International Committee on Computational Linguistics","Gyeongju, Republic of Korea","","","","","","","","","","","","","","Calzolari, Nicoletta; Huang, Chu-Ren; Kim, Hansaem; Pustejovsky, James; Wanner, Leo; Choi, Key-Sun; Ryu, Pum-Mo; Chen, Hsin-Hsi; Donatelli, Lucia; Ji, Heng; Kurohashi, Sadao; Paggio, Patrizia; Xue, Nianwen; Kim, Seokhwan; Hahm, Younggyun; He, Zhong; Lee, Tony Kyungil; Santus, Enrico; Bond, Francis; Na, Seung-Hoon","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WHXUFYMU","conferencePaper","2022","Yu, Pengfei; Zhang, Zixuan; Voss, Clare; May, Jonathan; Ji, Heng","Building an Event Extractor with Only a Few Examples","Proceedings of the Third Workshop on Deep Learning for Low-Resource Natural Language Processing","","","10.18653/v1/2022.deeplo-1.11","https://aclanthology.org/2022.deeplo-1.11/","Supervised event extraction models require a substantial amount of training data to perform well. However, event annotation requires a lot of human effort and costs much time, which limits the application of existing supervised approaches to new event types. In order to reduce manual labor and shorten the time to build an event extraction system for an arbitrary event ontology, we present a new framework to train such systems much more efficiently without large annotations. Our event trigger labeling model uses a weak supervision approach, which only requires a set of keywords, a small number of examples and an unlabeled corpus, on which our approach automatically collects weakly supervised annotations. Our argument role labeling component performs zero-shot learning, which only requires the names of the argument roles of new event types. The source codes of our event trigger detection1 and event argument extraction2 models are publicly available for research purposes. We also release a dockerized system connecting the two models into an unified event extraction pipeline.","2022-07","2025-09-10 13:17:19","2025-09-10 13:17:19","","102–109","","","","","","","","","","","Association for Computational Linguistics","Hybrid","","","","","","","","","","","","","","Cherry, Colin; Fan, Angela; Foster, George; Haffari, Gholamreza (Reza); Khadivi, Shahram; Peng, Nanyun (Violet); Ren, Xiang; Shareghi, Ehsan; Swayamdipta, Swabha","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7F9BWEAC","conferencePaper","2022","Mahapatra, Aniruddha; Nangi, Sharmila Reddy; Garimella, Aparna; N, Anandhavelu","Entity Extraction in Low Resource Domains with Selective Pre-training of Large Language Models","Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing","","","10.18653/v1/2022.emnlp-main.61","https://aclanthology.org/2022.emnlp-main.61/","Transformer-based language models trained on large natural language corpora have been very useful in downstream entity extraction tasks. However, they often result in poor performances when applied to domains that are different from those they are pretrained on. Continued pretraining using unlabeled data from target domains can help improve the performances of these language models on the downstream tasks. However, using all of the available unlabeled data for pretraining can be time-intensive; also, it can be detrimental to the performance of the downstream tasks, if the unlabeled data is not aligned with the data distribution for the target tasks. Previous works employed external supervision in the form of ontologies for selecting appropriate data samples for pretraining, but external supervision can be quite hard to obtain in low-resource domains. In this paper, we introduce effective ways to select data from unlabeled corpora of target domains for language model pretraining to improve the performances in target entity extraction tasks. Our data selection strategies do not require any external supervision. We conduct extensive experiments for the task of named entity recognition (NER) on seven different domains and show that language models pretrained on target domain unlabeled data obtained using our data selection strategies achieve better performances compared to those using data selection strategies in previous works that use external supervision. We also show that these pretrained language models using our data selection strategies outperform those pretrained on all of the available unlabeled target domain data.","2022-12","2025-09-10 13:17:19","2025-09-10 13:17:19","","942–951","","","","","","","","","","","Association for Computational Linguistics","Abu Dhabi, United Arab Emirates","","","","","","","","","","","","","","Goldberg, Yoav; Kozareva, Zornitsa; Zhang, Yue","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HKVDMGCF","conferencePaper","2022","Reid, Machel; Zhong, Victor; Gururangan, Suchin; Zettlemoyer, Luke","M2D2: A Massively Multi-Domain Language Modeling Dataset","Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing","","","10.18653/v1/2022.emnlp-main.63","https://aclanthology.org/2022.emnlp-main.63/","We present M2D2, a fine-grained, massively multi-domain corpus for studying domain adaptation in language models (LMs). M2D2 consists of 8.5B tokens and spans 145 domains extracted from Wikipedia and Semantic Scholar. Using ontologies derived from Wikipedia and ArXiv categories, we organize the domains in each data source into 22 groups. This two-level hierarchy enables the study of relationships between domains and their effects on in- and out-of-domain performance after adaptation. We also present a number of insights into the nature of effective domain adaptation in LMs, as examples of the new types of studies M2D2 enables. To improve in-domain performance, we show the benefits of adapting the LM along a domain hierarchy; adapting to smaller amounts of fine-grained domain-specific data can lead to larger in-domain performance gains than larger amounts of weakly relevant data. We further demonstrate a trade-off between in-domain specialization and out-of-domain generalization within and across ontologies, as well as a strong correlation between out-of-domain performance and lexical overlap between domains.","2022-12","2025-09-10 13:17:19","2025-09-10 13:17:19","","964–975","","","","","","","","","","","Association for Computational Linguistics","Abu Dhabi, United Arab Emirates","","","","","","","","","","","","","","Goldberg, Yoav; Kozareva, Zornitsa; Zhang, Yue","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HWS6K2PI","conferencePaper","2022","Lal, Yash Kumar; Tandon, Niket; Aggarwal, Tanvi; Liu, Horace; Chambers, Nathanael; Mooney, Raymond; Balasubramanian, Niranjan","Using Commonsense Knowledge to Answer Why-Questions","Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing","","","10.18653/v1/2022.emnlp-main.79","https://aclanthology.org/2022.emnlp-main.79/","Answering questions in narratives about why events happened often requires commonsense knowledge external to the text. What aspects of this knowledge are available in large language models? What aspects can be made accessible via external commonsense resources? We study these questions in the context of answering questions in the TellMeWhy dataset using COMET as a source of relevant commonsense relations. We analyze the effects of model size (T5 and GPT3) along with methods of injecting knowledge (COMET) into these models. Results show that the largest models, as expected, yield substantial improvements over base models. Injecting external knowledge helps models of various sizes, but the amount of improvement decreases with larger model size. We also find that the format in which knowledge is provided is critical, and that smaller models benefit more from larger amounts of knowledge. Finally, we develop an ontology of knowledge types and analyze the relative coverage of the models across these categories.","2022-12","2025-09-10 13:17:19","2025-09-10 13:17:19","","1204–1219","","","","","","","","","","","Association for Computational Linguistics","Abu Dhabi, United Arab Emirates","","","","","","","","","","","","","","Goldberg, Yoav; Kozareva, Zornitsa; Zhang, Yue","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DZRZ74AL","conferencePaper","2022","Li, Sha; Ji, Heng; Han, Jiawei","Open Relation and Event Type Discovery with Type Abstraction","Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing","","","10.18653/v1/2022.emnlp-main.461","https://aclanthology.org/2022.emnlp-main.461/","Conventional “closed-world” information extraction (IE) approaches rely on human ontologies to define the scope for extraction. As a result, such approaches fall short when applied to new domains. This calls for systems that can automatically infer new types from given corpora, a task which we refer to as type discovery.To tackle this problem, we introduce the idea of type abstraction, where the model is prompted to generalize and name the type. Then we use the similarity between inferred names to induce clusters. Observing that this abstraction-based representation is often complementary to the entity/trigger token representation, we set up these two representations as two views and design our model as a co-training framework. Our experiments on multiple relation extraction and event extraction datasets consistently show the advantage of our type abstraction approach.","2022-12","2025-09-10 13:17:19","2025-09-10 13:17:19","","6864–6877","","","","","","","","","","","Association for Computational Linguistics","Abu Dhabi, United Arab Emirates","","","","","","","","","","","","","","Goldberg, Yoav; Kozareva, Zornitsa; Zhang, Yue","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8E3VYFNJ","conferencePaper","2022","Portelli, Beatrice; Scaboro, Simone; Santus, Enrico; Sedghamiz, Hooman; Chersoni, Emmanuele; Serra, Giuseppe","Generalizing over Long Tail Concepts for Medical Term Normalization","Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing","","","10.18653/v1/2022.emnlp-main.588","https://aclanthology.org/2022.emnlp-main.588/","Medical term normalization consists in mapping a piece of text to a large number of output classes.Given the small size of the annotated datasets and the extremely long tail distribution of the concepts, it is of utmost importance to develop models that are capable to generalize to scarce or unseen concepts.An important attribute of most target ontologies is their hierarchical structure. In this paper we introduce a simple and effective learning strategy that leverages such information to enhance the generalizability of both discriminative and generative models.The evaluation shows that the proposed strategy produces state-of-the-art performance on seen concepts and consistent improvements on unseen ones, allowing also for efficient zero-shot knowledge transfer across text typologies and datasets.","2022-12","2025-09-10 13:17:19","2025-09-10 13:17:19","","8580–8591","","","","","","","","","","","Association for Computational Linguistics","Abu Dhabi, United Arab Emirates","","","","","","","","","","","","","","Goldberg, Yoav; Kozareva, Zornitsa; Zhang, Yue","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YFUBLST9","conferencePaper","2022","Tittel, Sabine","Towards an Ontology for Toponyms in Nepalese Historical Documents","Proceedings of the Workshop on Resources and Technologies for Indigenous, Endangered and Lesser-resourced Languages in Eurasia within the 13th Language Resources and Evaluation Conference","","","","https://aclanthology.org/2022.eurali-1.2/","Nepalese historical legal documents contain a plethora of valuable information on the history of what is today Nepal. An empirical study based on such documents enables a deep understanding of religion and ritual, legal practice, rulership, and many other aspects of the society through time. The aim of the research project `Documents on the History of Religion and Law of Pre-modern Nepal' is to make accessible a text corpus with 18 th to 20 th century documents both through cataloging and digital text editions, building a database called Documenta Nepalica. However, the lack of interoperability with other resources hampers its seamless integration into broader research contexts. To address this problem, we target the modeling of the Documenta Nepalica as Linked Data. This paper presents one module of this larger endeavour: It describes a proof of concept for an ontology for Nepalese toponyms that provides the means to classify toponyms attested in the documents and to model their entanglement with other toponyms, persons, events, and time. The ontology integrates and extends standard ontologies and increases interoperability through aligning the ontology individuals to the respective entries of geographic authority files such as GeoNames. Also, we establish a mapping of the individuals to DBpedia entities.","2022-06","2025-09-10 13:17:19","2025-09-10 13:17:19","","7–16","","","","","","","","","","","European Language Resources Association","Marseille, France","","","","","","","","","","","","","","Ojha, Atul Kr.; Ahmadi, Sina; Liu, Chao-Hong; McCrae, John P.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8Y2YWKVS","conferencePaper","2022","Wang, Sijia; Yu, Mo; Chang, Shiyu; Sun, Lichao; Huang, Lifu","Query and Extract: Refining Event Extraction as Type-oriented Binary Decoding","Findings of the Association for Computational Linguistics: ACL 2022","","","10.18653/v1/2022.findings-acl.16","https://aclanthology.org/2022.findings-acl.16/","Event extraction is typically modeled as a multi-class classification problem where event types and argument roles are treated as atomic symbols. These approaches are usually limited to a set of pre-defined types. We propose a novel event extraction framework that uses event types and argument roles as natural language queries to extract candidate triggers and arguments from the input text. With the rich semantics in the queries, our framework benefits from the attention mechanisms to better capture the semantic correlation between the event types or argument roles and the input text. Furthermore, the query-and-extract formulation allows our approach to leverage all available event annotations from various ontologies as a unified model. Experiments on ACE and ERE demonstrate that our approach achieves state-of-the-art performance on each dataset and significantly outperforms existing methods on zero-shot event extraction.","2022-05","2025-09-10 13:17:19","2025-09-10 13:17:19","","169–182","","","","","","","","","","","Association for Computational Linguistics","Dublin, Ireland","","","","","","","","","","","","","","Muresan, Smaranda; Nakov, Preslav; Villavicencio, Aline","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KA85UDU3","conferencePaper","2022","Nesterov, Alexandr; Zubkova, Galina; Miftahutdinov, Zulfat; Kokh, Vladimir; Tutubalina, Elena; Shelmanov, Artem; Alekseev, Anton; Avetisian, Manvel; Chertok, Andrey; Nikolenko, Sergey","RuCCoN: Clinical Concept Normalization in Russian","Findings of the Association for Computational Linguistics: ACL 2022","","","10.18653/v1/2022.findings-acl.21","https://aclanthology.org/2022.findings-acl.21/","We present RuCCoN, a new dataset for clinical concept normalization in Russian manually annotated by medical professionals. It contains over 16,028 entity mentions manually linked to over 2,409 unique concepts from the Russian language part of the UMLS ontology. We provide train/test splits for different settings (stratified, zero-shot, and CUI-less) and present strong baselines obtained with state-of-the-art models such as SapBERT. At present, Russian medical NLP is lacking in both datasets and trained models, and we view this work as an important step towards filling this gap. Our dataset and annotation guidelines are available at https://github.com/AIRI-Institute/RuCCoN.","2022-05","2025-09-10 13:17:19","2025-09-10 13:17:19","","239–245","","","","","","","","","","","Association for Computational Linguistics","Dublin, Ireland","","","","","","","","","","","","","","Muresan, Smaranda; Nakov, Preslav; Villavicencio, Aline","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UVJMC759","conferencePaper","2022","Li, Tianyi; Weber, Sabine; Hosseini, Mohammad Javad; Guillou, Liane; Steedman, Mark","Cross-lingual Inference with A Chinese Entailment Graph","Findings of the Association for Computational Linguistics: ACL 2022","","","10.18653/v1/2022.findings-acl.96","https://aclanthology.org/2022.findings-acl.96/","Predicate entailment detection is a crucial task for question-answering from text, where previous work has explored unsupervised learning of entailment graphs from typed open relation triples. In this paper, we present the first pipeline for building Chinese entailment graphs, which involves a novel high-recall open relation extraction (ORE) method and the first Chinese fine-grained entity typing dataset under the FIGER type ontology. Through experiments on the Levy-Holt dataset, we verify the strength of our Chinese entailment graph, and reveal the cross-lingual complementarity: on the parallel Levy-Holt dataset, an ensemble of Chinese and English entailment graphs outperforms both monolingual graphs, and raises unsupervised SOTA by 4.7 AUC points.","2022-05","2025-09-10 13:17:19","2025-09-10 13:17:19","","1214–1233","","","","","","","","","","","Association for Computational Linguistics","Dublin, Ireland","","","","","","","","","","","","","","Muresan, Smaranda; Nakov, Preslav; Villavicencio, Aline","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EMRMWSXC","conferencePaper","2022","Dayanik, Erenay; Blessing, Andre; Blokker, Nico; Haunss, Sebastian; Kuhn, Jonas; Lapesa, Gabriella; Pado, Sebastian","Improving Neural Political Statement Classification with Class Hierarchical Information","Findings of the Association for Computational Linguistics: ACL 2022","","","10.18653/v1/2022.findings-acl.186","https://aclanthology.org/2022.findings-acl.186/","Many tasks in text-based computational social science (CSS) involve the classification of political statements into categories based on a domain-specific codebook. In order to be useful for CSS analysis, these categories must be fine-grained. The typically skewed distribution of fine-grained categories, however, results in a challenging classification problem on the NLP side. This paper proposes to make use of the hierarchical relations among categories typically present in such codebooks:e.g., markets and taxation are both subcategories of economy, while borders is a subcategory of security. We use these ontological relations as prior knowledge to establish additional constraints on the learned model, thusimproving performance overall and in particular for infrequent categories. We evaluate several lightweight variants of this intuition by extending state-of-the-art transformer-based textclassifiers on two datasets and multiple languages. We find the most consistent improvement for an approach based on regularization.","2022-05","2025-09-10 13:17:19","2025-09-10 13:17:19","","2367–2382","","","","","","","","","","","Association for Computational Linguistics","Dublin, Ireland","","","","","","","","","","","","","","Muresan, Smaranda; Nakov, Preslav; Villavicencio, Aline","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IMWY42JG","conferencePaper","2022","Casanueva, Inigo; Vulić, Ivan; Spithourakis, Georgios; Budzianowski, Paweł","NLU++: A Multi-Label, Slot-Rich, Generalisable Dataset for Natural Language Understanding in Task-Oriented Dialogue","Findings of the Association for Computational Linguistics: NAACL 2022","","","10.18653/v1/2022.findings-naacl.154","https://aclanthology.org/2022.findings-naacl.154/","We present NLU++, a novel dataset for natural language understanding (NLU) in task-oriented dialogue (ToD) systems, with the aim to provide a much more challenging evaluation environment for dialogue NLU models, up to date with the current application and industry requirements. NLU++ is divided into two domains (BANKING and HO℡S) and brings several crucial improvements over current commonly used NLU datasets. 1) NLU++ provides fine-grained domain ontologies with a large set of challenging multi-intent sentences combined with finer-grained and thus more challenging slot sets. 2) The ontology is divided into domain-specific and generic (i.e., domain-universal) intents that overlap across domains, promoting cross-domain reusability of annotated examples. 3) The dataset design has been inspired by the problems observed in industrial ToD systems, and 4) it has been collected, filtered and carefully annotated by dialogue NLU experts, yielding high-quality annotated data. Finally, we benchmark a series of current state-of-the-art NLU models on NLU++; the results demonstrate the challenging nature of the dataset, especially in low-data regimes, and call for further research on ToD NLU.","2022-07","2025-09-10 13:17:19","2025-09-10 13:17:19","","1998–2013","","","","","","","","","","","Association for Computational Linguistics","Seattle, United States","","","","","","","","","","","","","","Carpuat, Marine; de Marneffe, Marie-Catherine; Meza Ruiz, Ivan Vladimir","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4DCV9AGT","conferencePaper","2022","Zhang, Sheng; Cheng, Hao; Vashishth, Shikhar; Wong, Cliff; Xiao, Jinfeng; Liu, Xiaodong; Naumann, Tristan; Gao, Jianfeng; Poon, Hoifung","Knowledge-Rich Self-Supervision for Biomedical Entity Linking","Findings of the Association for Computational Linguistics: EMNLP 2022","","","10.18653/v1/2022.findings-emnlp.61","https://aclanthology.org/2022.findings-emnlp.61/","Entity linking faces significant challenges such as prolific variations and prevalent ambiguities, especially in high-value domains with myriad entities. Standard classification approaches suffer from the annotation bottleneck and cannot effectively handle unseen entities. Zero-shot entity linking has emerged as a promising direction for generalizing to new entities, but it still requires example gold entity mentions during training and canonical descriptions for all entities, both of which are rarely available outside of Wikipedia. In this paper, we explore Knowledge-RIch Self-Supervision (KRISS) for biomedical entity linking, by leveraging readily available domain knowledge. In training, it generates self-supervised mention examples on unlabeled text using a domain ontology and trains a contextual encoder using contrastive learning. For inference, it samples self-supervised mentions as prototypes for each entity and conducts linking by mapping the test mention to the most similar prototype. Our approach can easily incorporate entity descriptions and gold mention labels if available. We conducted extensive experiments on seven standard datasets spanning biomedical literature and clinical notes. Without using any labeled information, our method produces KRISSBERT, a universal entity linker for four million UMLS entities that attains new state of the art, outperforming prior self-supervised methods by as much as 20 absolute points in accuracy. We released KRISSBERT at https://aka.ms/krissbert.","2022-12","2025-09-10 13:17:19","2025-09-10 13:17:19","","868–880","","","","","","","","","","","Association for Computational Linguistics","Abu Dhabi, United Arab Emirates","","","","","","","","","","","","","","Goldberg, Yoav; Kozareva, Zornitsa; Zhang, Yue","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"76VD675F","conferencePaper","2022","Remy, François; Demuynck, Kris; Demeester, Thomas","BioLORD: Learning Ontological Representations from Definitions for Biomedical Concepts and their Textual Descriptions","Findings of the Association for Computational Linguistics: EMNLP 2022","","","10.18653/v1/2022.findings-emnlp.104","https://aclanthology.org/2022.findings-emnlp.104/","This work introduces BioLORD, a new pre-training strategy for producing meaningful representations for clinical sentences and biomedical concepts. State-of-the-art methodologies operate by maximizing the similarity in representation of names referring to the same concept, and preventing collapse through contrastive learning. However, because biomedical names are not always self-explanatory, it sometimes results in non-semantic representations. BioLORD overcomes this issue by grounding its concept representations using definitions, as well as short descriptions derived from a multi-relational knowledge graph consisting of biomedical ontologies. Thanks to this grounding, our model produces more semantic concept representations that match more closely the hierarchical structure of ontologies. BioLORD establishes a new state of the art for text similarity on both clinical sentences (MedSTS) and biomedical concepts (MayoSRS).","2022-12","2025-09-10 13:17:19","2025-09-10 13:17:19","","1454–1465","","","","","","","","","","","Association for Computational Linguistics","Abu Dhabi, United Arab Emirates","","","","","","","","","","","","","","Goldberg, Yoav; Kozareva, Zornitsa; Zhang, Yue","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"I2BCJWJ4","conferencePaper","2022","Yu, Dian; Wang, Mingqiu; Cao, Yuan; El Shafey, Laurent; Shafran, Izhak; Soltau, Hagen","Knowledge-grounded Dialog State Tracking","Findings of the Association for Computational Linguistics: EMNLP 2022","","","10.18653/v1/2022.findings-emnlp.250","https://aclanthology.org/2022.findings-emnlp.250/","Knowledge (including structured knowledge such as schema and ontology and unstructured knowledge such as web corpus) is a critical part of dialog understanding, especially for unseen tasks and domains. Traditionally, such domain-specific knowledge is encoded implicitly into model parameters for the execution of downstream tasks, which makes training inefficient. In addition , such models are not easily transferable to new tasks with different schemas. In this work, we propose to perform dialog state tracking grounded on knowledge encoded externally. We query relevant knowledge of various forms based on the dialog context where such information can grounds the prediction of dialog states. We demonstrate superior performance of our proposed method over strong baselines, especially in the few-shot learning setting.","2022-12","2025-09-10 13:17:19","2025-09-10 13:17:19","","3428–3435","","","","","","","","","","","Association for Computational Linguistics","Abu Dhabi, United Arab Emirates","","","","","","","","","","","","","","Goldberg, Yoav; Kozareva, Zornitsa; Zhang, Yue","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"V4WZ56ZG","conferencePaper","2022","Zhang, Hongming; Yao, Wenlin; Yu, Dong","Efficient Zero-shot Event Extraction with Context-Definition Alignment","Findings of the Association for Computational Linguistics: EMNLP 2022","","","10.18653/v1/2022.findings-emnlp.531","https://aclanthology.org/2022.findings-emnlp.531/","Event extraction (EE) is the task of identifying interested event mentions from text.Conventional efforts mainly focus on the supervised setting. However, these supervised models cannot generalize to event types out of the pre-defined ontology. To fill this gap, many efforts have been devoted to the zero-shot EE problem. This paper follows the trend of modeling event-type semantics but moves one step further. We argue that using the static embedding of the event type name might not be enough because a single word could be ambiguous, and we need a sentence to define the type semantics accurately. To model the definition semantics, we use two separate transformer models to project the contextualized event mentions and corresponding definitions into the same embedding space and then minimize their embedding distance via contrastive learning. On top of that, we also propose a warming phase to help the model learn the minor difference between similar definitions. We name our approach Zero-shot Event extraction with Definition (ZED). Experiments on the MAVEN dataset show that our model significantly outperforms all previous zero-shot EE methods with fast inference speed due to the disjoint design. Further experiments also show that can be easily applied to the few-shot setting when the annotation is available and consistently outperforms baseline supervised methods.","2022-12","2025-09-10 13:17:19","2025-09-10 13:17:19","","7169–7179","","","","","","","","","","","Association for Computational Linguistics","Abu Dhabi, United Arab Emirates","","","","","","","","","","","","","","Goldberg, Yoav; Kozareva, Zornitsa; Zhang, Yue","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UR7MBXU4","conferencePaper","2022","Declerck, Thierry","Towards the Linking of a Sign Language Ontology with Lexical Data","Proceedings of Globalex Workshop on Linked Lexicography within the 13th Language Resources and Evaluation Conference","","","","https://aclanthology.org/2022.gwll-1.2/","We describe our current work for linking a new ontology for representing constitutive elements of Sign Languages with lexical data encoded within the OntoLex-Lemon framework. We first present very briefly the current state of the ontology, and show how transcriptions of signs can be represented in OntoLex-Lemon, in a minimalist manner, before addressing the challenges of linking the elements of the ontology to full lexical descriptions of the spoken languages.","2022-06","2025-09-10 13:17:19","2025-09-10 13:17:19","","6–9","","","","","","","","","","","European Language Resources Association","Marseille, France","","","","","","","","","","","","","","Kernerman, Ilan; Krek, Simon","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"M4IAR4IN","conferencePaper","2022","Varvara, Rossella; Salvadori, Justine; Huyghe, Richard","Annotating complex words to investigate the semantics of derivational processes","Proceedings of the 18th Joint ACL - ISO Workshop on Interoperable Semantic Annotation within LREC2022","","","","https://aclanthology.org/2022.isa-1.18/","In this paper, we present and test an annotation scheme designed to analyse the semantic properties of derived nouns in context. Aiming at a general semantic comparison of morphological processes, we use a descriptive model that seeks to capture semantic regularities among lexemes and affixes, rather than match occurrences to word sense inventories. We annotate two distinct features of target words: the ontological type of the entity they denote and their semantic relationship with the word they derive from. As illustrated through an annotation experiment on French corpus data, this procedure allows us to highlight semantic differences and similarities between affixes by investigating the number and frequency of their semantic functions, as well as the relation between affix polyfunctionality and lexical ambiguity.","2022-06","2025-09-10 13:17:19","2025-09-10 13:17:19","","133–141","","","","","","","","","","","European Language Resources Association","Marseille, France","","","","","","","","","","","","","","Bunt, Harry","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CM22B87K","conferencePaper","2022","Ricchiardi, Marta; Jezek, Elisabetta","Annotating Propositional Attitude Verbs and their Arguments","Proceedings of the 18th Joint ACL - ISO Workshop on Interoperable Semantic Annotation within LREC2022","","","","https://aclanthology.org/2022.isa-1.19/","This paper describes the results of an empirical study on attitude verbs and propositional attitude reports in Italian. Within the framework of a project aiming at acquiring argument structures for Italian verbs from corpora, we carried out a systematic annotation that aims at individuating which verbs are actually attitude verbs in Italian. The result is a list of 179 argument structures based on corpus-derived pattern of use for 126 verbs that behave as attitude verbs. The distribution of these verbs in the corpus suggests that not only the canonical that-clauses, i.e. subordinates introduced by the complementizerte che, but also direct speech, infinitives introduced by the complementizer di, and some nominals are good candidates to express propositional contents in propositional attitude reports. The annotation also enlightens some issues between semantics and ontology, concerning the relation between events and propositions.","2022-06","2025-09-10 13:17:19","2025-09-10 13:17:19","","142–149","","","","","","","","","","","European Language Resources Association","Marseille, France","","","","","","","","","","","","","","Bunt, Harry","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5F3TZLSH","conferencePaper","2022","Fantoli, Margherita; Passarotti, Marco; Mambrini, Francesco; Moretti, Giovanni; Ruffolo, Paolo","Linking the LASLA Corpus in the LiLa Knowledge Base of Interoperable Linguistic Resources for Latin","Proceedings of the 8th Workshop on Linked Data in Linguistics within the 13th Language Resources and Evaluation Conference","","","","https://aclanthology.org/2022.ldl-1.4/","This paper describes the process of interlinking the 130 Classical Latin texts provided by an annotated corpus developed at the LASLA laboratory with the LiLa Knowledge Base, which makes linguistic resources for Latin interoperable by following the principles of the Linked Data paradigm and making reference to classes and properties of widely adopted ontologies to model the relevant information. After introducing the overall architecture of the LiLa Knowledge Base and the LASLA corpus, the paper details the phases of the process of linking the corpus with the collection of lemmas of LiLa and presents a federated query to exemplify the added value of interoperability of LASLA's texts with other resources for Latin.","2022-06","2025-09-10 13:17:19","2025-09-10 13:17:19","","26–34","","","","","","","","","","","European Language Resources Association","Marseille, France","","","","","","","","","","","","","","Declerck, Thierry; McCrae, John P.; Montiel, Elena; Chiarcos, Christian; Ionov, Maxim","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"96RUDAST","conferencePaper","2022","Bobillo, Fernando; Bosque-Gil, Julia; Gracia, Jorge; Lanau-Coronas, Marta","Fuzzy Lemon: Making Lexical Semantic Relations More Juicy","Proceedings of the 8th Workshop on Linked Data in Linguistics within the 13th Language Resources and Evaluation Conference","","","","https://aclanthology.org/2022.ldl-1.6/","The OntoLex-Lemon model provides a vocabulary to enrich ontologies with linguistic information that can be exploited by Natural Language Processing applications. The increasing uptake of Lemon illustrates the growing interest in combining linguistic information and Semantic Web technologies. In this paper, we present Fuzzy Lemon, an extension of Lemon that allows to assign an uncertainty degree to lexical semantic relations. Our approach is based on an OWL ontology that defines a hierarchy of data properties encoding different types of uncertainty. We also illustrate the usefulness of Fuzzy Lemon by showing that it can be used to represent the confidence degrees of automatically discovered translations between pairs of bilingual dictionaries from the Apertium family.","2022-06","2025-09-10 13:17:19","2025-09-10 13:17:19","","45–51","","","","","","","","","","","European Language Resources Association","Marseille, France","","","","","","","","","","","","","","Declerck, Thierry; McCrae, John P.; Montiel, Elena; Chiarcos, Christian; Ionov, Maxim","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FBS56VGA","conferencePaper","2022","Fäth, Christian; Chiarcos, Christian","Spicy Salmon: Converting between 50+ Annotation Formats with Fintan, Pepper, Salt and Powla","Proceedings of the 8th Workshop on Linked Data in Linguistics within the 13th Language Resources and Evaluation Conference","","","","https://aclanthology.org/2022.ldl-1.8/","Heterogeneity of formats, models and annotations has always been a primary hindrance for exploiting the ever increasing amount of existing linguistic resources for real world applications in and beyond NLP. Fintan - the Flexible INtegrated Transformation and Annotation eNgineering platform introduced in 2020 is designed to rapidly convert, combine and manipulate language resources both in and outside the Semantic Web by transforming it into segmented RDF representations which can be processed in parallel on a multithreaded environment and integrating it with ontologies and taxonomies. Fintan has recently been extended with a set of additional modules increasing the amount of supported non-RDF formats and the interoperability with existing non-JAVA conversion tools, and parts of this work are demonstrated in this paper. In particular, we focus on a novel recipe for resource transformation in which Fintan works in tandem with the Pepper toolset to allow computational linguists to transform their data between over 50 linguistic corpus formats with a graphical workflow manager.","2022-06","2025-09-10 13:17:19","2025-09-10 13:17:19","","61–68","","","","","","","","","","","European Language Resources Association","Marseille, France","","","","","","","","","","","","","","Declerck, Thierry; McCrae, John P.; Montiel, Elena; Chiarcos, Christian; Ionov, Maxim","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WJZG6TUR","conferencePaper","2022","Feder, Amir; Laish, Itay; Agarwal, Shashank; Lerner, Uri; Atias, Avel; Cheung, Cathy; Clardy, Peter; Peled-Cohen, Alon; Fellinger, Rachana; Liu, Hengrui; Huong Nguyen, Lan; Patel, Birju; Potikha, Natan; Taubenfeld, Amir; Xu, Liwen; Yang, Seung Doo; Benjamini, Ayelet; Hassidim, Avinatan","Building a Clinically-Focused Problem List From Medical Notes","Proceedings of the 13th International Workshop on Health Text Mining and Information Analysis (LOUHI)","","","10.18653/v1/2022.louhi-1.8","https://aclanthology.org/2022.louhi-1.8/","Clinical notes often contain useful information not documented in structured data, but their unstructured nature can lead to critical patient-related information being missed. To increase the likelihood that this valuable information is utilized for patient care, algorithms that summarize notes into a problem list have been proposed. Focused on identifying medically-relevant entities in the free-form text, these solutions are often detached from a canonical ontology and do not allow downstream use of the detected text-spans. Mitigating these issues, we present here a system for generating a canonical problem list from medical notes, consisting of two major stages. At the first stage, annotation, we use a transformer model to detect all clinical conditions which are mentioned in a single note. These clinical conditions are then grounded to a predefined ontology, and are linked to spans in the text. At the second stage, summarization, we develop a novel algorithm that aggregates over the set of clinical conditions detected on all of the patient's notes, and produce a concise patient summary that organizes their most important conditions.","2022-12","2025-09-10 13:17:19","2025-09-10 13:17:19","","60–68","","","","","","","","","","","Association for Computational Linguistics","Abu Dhabi, United Arab Emirates (Hybrid)","","","","","","","","","","","","","","Lavelli, Alberto; Holderness, Eben; Jimeno Yepes, Antonio; Minard, Anne-Lyse; Pustejovsky, James; Rinaldi, Fabio","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"B83B3ZXE","conferencePaper","2022","Barros, Jose; Rojas, Matias; Dunstan, Jocelyn; Abeliuk, Andres","Divide and Conquer: An Extreme Multi-Label Classification Approach for Coding Diseases and Procedures in Spanish","Proceedings of the 13th International Workshop on Health Text Mining and Information Analysis (LOUHI)","","","10.18653/v1/2022.louhi-1.16","https://aclanthology.org/2022.louhi-1.16/","Clinical coding is the task of transforming medical documents into structured codes following a standard ontology. Since these terminologies are composed of hundreds of codes, this problem can be considered an Extreme Multi-label Classification task. This paper proposes a novel neural network-based architecture for clinical coding. First, we take full advantage of the hierarchical nature of ontologies to create clusters based on semantic relations. Then, we use a Matcher module to assign the probability of documents belonging to each cluster. Finally, the Ranker calculates the probability of each code considering only the documents in the cluster. This division allows a fine-grained differentiation within the cluster, which cannot be addressed using a single classifier. In addition, since most of the previous work has focused on solving this task in English, we conducted our experiments on three clinical coding corpora in Spanish. The experimental results demonstrate the effectiveness of our model, achieving state-of-the-art results on two of the three datasets. Specifically, we outperformed previous models on two subtasks of the CodiEsp shared task: CodiEsp-D (diseases) and CodiEsp-P (procedures). Automatic coding can profoundly impact healthcare by structuring critical information written in free text in electronic health records.","2022-12","2025-09-10 13:17:19","2025-09-10 13:17:19","","138–147","","","","","","","","","","","Association for Computational Linguistics","Abu Dhabi, United Arab Emirates (Hybrid)","","","","","","","","","","","","","","Lavelli, Alberto; Holderness, Eben; Jimeno Yepes, Antonio; Minard, Anne-Lyse; Pustejovsky, James; Rinaldi, Fabio","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3KUZXIVG","conferencePaper","2022","Bagherzadeh, Parsa; Bergler, Sabine","Integration of Heterogeneous Knowledge Sources for Biomedical Text Processing","Proceedings of the 13th International Workshop on Health Text Mining and Information Analysis (LOUHI)","","","10.18653/v1/2022.louhi-1.25","https://aclanthology.org/2022.louhi-1.25/","Recently, research into bringing outside knowledge sources into current neural NLP models has been increasing. Most approaches that leverage external knowledge sources require laborious and non-trivial designs, as well as tailoring the system through intensive ablation of different knowledge sources, an effort that discourages users to use quality ontological resources. In this paper, we show that multiple large heterogeneous KSs can be easily integrated using a decoupled approach, allowing for an automatic ablation of irrelevant KSs, while keeping the overall parameter space tractable. We experiment with BERT and pre-trained graph embeddings, and show that they interoperate well without performance degradation, even when some do not contribute to the task.","2022-12","2025-09-10 13:17:19","2025-09-10 13:17:19","","229–238","","","","","","","","","","","Association for Computational Linguistics","Abu Dhabi, United Arab Emirates (Hybrid)","","","","","","","","","","","","","","Lavelli, Alberto; Holderness, Eben; Jimeno Yepes, Antonio; Minard, Anne-Lyse; Pustejovsky, James; Rinaldi, Fabio","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EC5IDIBY","conferencePaper","2022","Winter, Benjamin; Rosero, Alexei Figueroa; Löser, Alexander; Gers, Felix Alexander; Siu, Amy","KIMERA: Injecting Domain Knowledge into Vacant Transformer Heads","Proceedings of the Thirteenth Language Resources and Evaluation Conference","","","","https://aclanthology.org/2022.lrec-1.38/","Training transformer language models requires vast amounts of text and computational resources. This drastically limits the usage of these models in niche domains for which they are not optimized, or where domain-specific training data is scarce. We focus here on the clinical domain because of its limited access to training data in common tasks, while structured ontological data is often readily available. Recent observations in model compression of transformer models show optimization potential in improving the representation capacity of attention heads. We propose KIMERA (Knowledge Injection via Mask Enforced Retraining of Attention) for detecting, retraining and instilling attention heads with complementary structured domain knowledge. Our novel multi-task training scheme effectively identifies and targets individual attention heads that are least useful for a given downstream task and optimizes their representation with information from structured data. KIMERA generalizes well, thereby building the basis for an efficient fine-tuning. KIMERA achieves significant performance boosts on seven datasets in the medical domain in Information Retrieval and Clinical Outcome Prediction settings. We apply KIMERA to BERT-base to evaluate the extent of the domain transfer and also improve on the already strong results of BioBERT in the clinical domain.","2022-06","2025-09-10 13:17:19","2025-09-10 13:17:19","","363–373","","","","","","","","","","","European Language Resources Association","Marseille, France","","","","","","","","","","","","","","Calzolari, Nicoletta; Béchet, Frédéric; Blache, Philippe; Choukri, Khalid; Cieri, Christopher; Declerck, Thierry; Goggi, Sara; Isahara, Hitoshi; Maegaard, Bente; Mariani, Joseph; Mazo, Hélène; Odijk, Jan; Piperidis, Stelios","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"B63WZKQI","conferencePaper","2022","Hudeček, Vojtěch; Schaub, Léon-Paul; Stancl, Daniel; Paroubek, Patrick; Dušek, Ondřej","DIASER: A Unifying View On Task-oriented Dialogue Annotation","Proceedings of the Thirteenth Language Resources and Evaluation Conference","","","","https://aclanthology.org/2022.lrec-1.137/","Every model is only as strong as the data that it is trained on. In this paper, we present a new dataset, obtained by merging four publicly available annotated corpora for task-oriented dialogues in several domains (MultiWOZ 2.2, CamRest676, DSTC2 and Schema-Guided Dialogue Dataset). This way, we assess the feasibility of providing a unified ontology and annotation schema covering several domains with a relatively limited effort. We analyze the characteristics of the resulting dataset along three main dimensions: language, information content and performance. We focus on aspects likely to be pertinent for improving dialogue success, e.g. dialogue consistency. Furthermore, to assess the usability of this new corpus, we thoroughly evaluate dialogue generation performance under various conditions with the help of two prominent recent end-to-end dialogue models: MarCo and GPT-2. These models were selected as popular open implementations representative of the two main dimensions of dialogue modelling. While we did not observe a significant gain for dialogue state tracking performance, we show that using more training data from different sources can improve language modelling capabilities and positively impact dialogue flow (consistency). In addition, we provide the community with one of the largest open dataset for machine learning experiments.","2022-06","2025-09-10 13:17:19","2025-09-10 13:17:19","","1286–1296","","","","","","","","","","","European Language Resources Association","Marseille, France","","","","","","","","","","","","","","Calzolari, Nicoletta; Béchet, Frédéric; Blache, Philippe; Choukri, Khalid; Cieri, Christopher; Declerck, Thierry; Goggi, Sara; Isahara, Hitoshi; Maegaard, Bente; Mariani, Joseph; Mazo, Hélène; Odijk, Jan; Piperidis, Stelios","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DBSXUQFH","conferencePaper","2022","Uresova, Zdenka; Zaczynska, Karolina; Bourgonje, Peter; Fučíková, Eva; Rehm, Georg; Hajic, Jan","Making a Semantic Event-type Ontology Multilingual","Proceedings of the Thirteenth Language Resources and Evaluation Conference","","","","https://aclanthology.org/2022.lrec-1.142/","We present an extension of the SynSemClass Event-type Ontology, originally conceived as a bilingual Czech-English resource. We added German entries to the classes representing the concepts of the ontology. Having a different starting point than the original work (unannotated parallel corpus without links to a valency lexicon and, of course, different existing lexical resources), it was a challenge to adapt the annotation guidelines, the data model and the tools used for the original version. We describe the process and results of working in such a setup. We also show the next steps to adapt the annotation process, data structures and formats and tools necessary to make the addition of a new language in the future more smooth and efficient, and possibly to allow for various teams to work on SynSemClass extensions to many languages concurrently. We also present the latest release which contains the results of adding German, freely available for download as well as for online access.","2022-06","2025-09-10 13:17:19","2025-09-10 13:17:19","","1332–1343","","","","","","","","","","","European Language Resources Association","Marseille, France","","","","","","","","","","","","","","Calzolari, Nicoletta; Béchet, Frédéric; Blache, Philippe; Choukri, Khalid; Cieri, Christopher; Declerck, Thierry; Goggi, Sara; Isahara, Hitoshi; Maegaard, Bente; Mariani, Joseph; Mazo, Hélène; Odijk, Jan; Piperidis, Stelios","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KM7S4TCL","conferencePaper","2022","Koeva, Svetla; Stoyanova, Ivelina; Kralev, Jordan","Multilingual Image Corpus – Towards a Multimodal and Multilingual Dataset","Proceedings of the Thirteenth Language Resources and Evaluation Conference","","","","https://aclanthology.org/2022.lrec-1.162/","One of the processing tasks for large multimodal data streams is automatic image description (image classification, object segmentation and classification). Although the number and the diversity of image datasets is constantly expanding, still there is a huge demand for more datasets in terms of variety of domains and object classes covered. The goal of the project Multilingual Image Corpus (MIC 21) is to provide a large image dataset with annotated objects and object descriptions in 24 languages. The Multilingual Image Corpus consists of an Ontology of visual objects (based on WordNet) and a collection of thematically related images whose objects are annotated with segmentation masks and labels describing the ontology classes. The dataset is designed both for image classification and object detection and for semantic segmentation. The main contributions of our work are: a) the provision of large collection of high quality copyright-free images; b) the formulation of the Ontology of visual objects based on WordNet noun hierarchies; c) the precise manual correction of automatic object segmentation within the images and the annotation of object classes; and d) the association of objects and images with extended multilingual descriptions based on WordNet inner- and interlingual relations. The dataset can be used also for multilingual image caption generation, image-to-text alignment and automatic question answering for images and videos.","2022-06","2025-09-10 13:17:19","2025-09-10 13:17:19","","1509–1518","","","","","","","","","","","European Language Resources Association","Marseille, France","","","","","","","","","","","","","","Calzolari, Nicoletta; Béchet, Frédéric; Blache, Philippe; Choukri, Khalid; Cieri, Christopher; Declerck, Thierry; Goggi, Sara; Isahara, Hitoshi; Maegaard, Bente; Mariani, Joseph; Mazo, Hélène; Odijk, Jan; Piperidis, Stelios","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NIA2TRZI","conferencePaper","2022","Meisinger, Nino; Trippel, Thorsten; Zinn, Claus","Increasing CMDI's Semantic Interoperability with schema.org","Proceedings of the Thirteenth Language Resources and Evaluation Conference","","","","https://aclanthology.org/2022.lrec-1.290/","The CLARIN Concept Registry (CCR) is the common semantic ground for most CMDI-based profiles to describe language-related resources in the CLARIN universe. While the CCR supports semantic interoperability within this universe, it does not extend beyond it. The flexibility of CMDI, however, allows users to use other term or concept registries when defining their metadata components. In this paper, we describe our use of schema.org, a light ontology used by many parties across disciplines.","2022-06","2025-09-10 13:17:19","2025-09-10 13:17:19","","2714–2720","","","","","","","","","","","European Language Resources Association","Marseille, France","","","","","","","","","","","","","","Calzolari, Nicoletta; Béchet, Frédéric; Blache, Philippe; Choukri, Khalid; Cieri, Christopher; Declerck, Thierry; Goggi, Sara; Isahara, Hitoshi; Maegaard, Bente; Mariani, Joseph; Mazo, Hélène; Odijk, Jan; Piperidis, Stelios","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RDCFZV2P","conferencePaper","2022","Osenova, Petya; Simov, Kiril; Marinova, Iva; Berbatova, Melania","The Bulgarian Event Corpus: Overview and Initial NER Experiments","Proceedings of the Thirteenth Language Resources and Evaluation Conference","","","","https://aclanthology.org/2022.lrec-1.374/","The paper describes the Bulgarian Event Corpus (BEC). The annotation scheme is based on CIDOC-CRM ontology and on the English Framenet, adjusted for our task. It includes two main layers: named entities and events with their roles. The corpus is multi-domain and mainly oriented towards Social Sciences and Humanities (SSH). It will be used for: extracting knowledge and making it available through the Bulgaria-centric Knowledge Graph; further developing an annotation scheme that handles multiple domains in SSH; training automatic modules for the most important knowledge-based tasks, such as domain-specific and nested NER, NEL, event detection and profiling. Initial experiments were conducted on standard NER task due to complexity of the dataset and the rich NE annotation scheme. The results are promising with respect to some labels and give insights on handling better other ones. These experiments serve also as error detection modules that would help us in scheme re-design. They are a basis for further and more complex tasks, such as nested NER, NEL and event detection.","2022-06","2025-09-10 13:17:19","2025-09-10 13:17:19","","3491–3499","","","","","","","","","","","European Language Resources Association","Marseille, France","","","","","","","","","","","","","","Calzolari, Nicoletta; Béchet, Frédéric; Blache, Philippe; Choukri, Khalid; Cieri, Christopher; Declerck, Thierry; Goggi, Sara; Isahara, Hitoshi; Maegaard, Bente; Mariani, Joseph; Mazo, Hélène; Odijk, Jan; Piperidis, Stelios","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JVQ8J9Y7","conferencePaper","2022","Zotova, Elena; Cuadros, Montse; Rigau, German","ClinIDMap: Towards a Clinical IDs Mapping for Data Interoperability","Proceedings of the Thirteenth Language Resources and Evaluation Conference","","","","https://aclanthology.org/2022.lrec-1.390/","This paper presents ClinIDMap, a tool for mapping identifiers between clinical ontologies and lexical resources. ClinIDMap interlinks identifiers from UMLS, SMOMED-CT, ICD-10 and the corresponding Wikipedia articles for concepts from the UMLS Metathesaurus. Our main goal is to provide semantic interoperability across the clinical concepts from various knowledge bases. As a side effect, the mapping enriches already annotated corpora in multiple languages with new labels. For instance, spans manually annotated with IDs from UMLS can be annotated with Semantic Types and Groups, and its corresponding SNOMED CT and ICD-10 IDs. We also experiment with sequence labelling models for detecting Diagnosis and Procedures concepts and for detecting UMLS Semantic Groups trained on Spanish, English, and bilingual corpora obtained with the new mapping procedure. The ClinIDMap tool is publicly available.","2022-06","2025-09-10 13:17:19","2025-09-10 13:17:19","","3661–3669","","","","","","","","","","","European Language Resources Association","Marseille, France","","","","","","","","","","","","","","Calzolari, Nicoletta; Béchet, Frédéric; Blache, Philippe; Choukri, Khalid; Cieri, Christopher; Declerck, Thierry; Goggi, Sara; Isahara, Hitoshi; Maegaard, Bente; Mariani, Joseph; Mazo, Hélène; Odijk, Jan; Piperidis, Stelios","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"E3CYXIMM","conferencePaper","2022","Declerck, Thierry","Towards a new Ontology for Sign Languages","Proceedings of the Thirteenth Language Resources and Evaluation Conference","","","","https://aclanthology.org/2022.lrec-1.423/","We present the current status of a new ontology for representing constitutive elements of Sign Languages (SL). This development emerged from investigations on how to represent multimodal lexical data in the OntoLex-Lemon framework, with the goal to publish such data in the Linguistic Linked Open Data (LLOD) cloud. While studying the literature and various sites dealing with sign languages, we saw the need to harmonise all the data categories (or features) defined and used in those sources, and to organise them in an ontology to which lexical descriptions in OntoLex-Lemon could be linked. We make the code of the first version of this ontology available, so that it can be further developed collaboratively by both the Linked Data and the SL communities","2022-06","2025-09-10 13:17:19","2025-09-10 13:17:19","","3977–3983","","","","","","","","","","","European Language Resources Association","Marseille, France","","","","","","","","","","","","","","Calzolari, Nicoletta; Béchet, Frédéric; Blache, Philippe; Choukri, Khalid; Cieri, Christopher; Declerck, Thierry; Goggi, Sara; Isahara, Hitoshi; Maegaard, Bente; Mariani, Joseph; Mazo, Hélène; Odijk, Jan; Piperidis, Stelios","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TDIYEH6M","conferencePaper","2022","Kühn, Ramona; Mitrović, Jelena; Granitzer, Michael","GRhOOT: Ontology of Rhetorical Figures in German","Proceedings of the Thirteenth Language Resources and Evaluation Conference","","","","https://aclanthology.org/2022.lrec-1.426/","GRhOOT, the German RhetOrical OnTology, is a domain ontology of 110 rhetorical figures in the German language. The overall goal of building an ontology of rhetorical figures in German is not only the formal representation of different rhetorical figures, but also allowing for their easier detection, thus improving sentiment analysis, argument mining, detection of hate speech and fake news, machine translation, and many other tasks in which recognition of non-literal language plays an important role. The challenge of building such ontologies lies in classifying the figures and assigning adequate characteristics to group them, while considering their distinctive features. The ontology of rhetorical figures in the Serbian language was used as a basis for our work. Besides transferring and extending the concepts of the Serbian ontology, we ensured completeness and consistency by using description logic and SPARQL queries. Furthermore, we show a decision tree to identify figures and suggest a usage scenario on how the ontology can be utilized to collect and annotate data.","2022-06","2025-09-10 13:17:19","2025-09-10 13:17:19","","4001–4010","","","","","","","","","","","European Language Resources Association","Marseille, France","","","","","","","","","","","","","","Calzolari, Nicoletta; Béchet, Frédéric; Blache, Philippe; Choukri, Khalid; Cieri, Christopher; Declerck, Thierry; Goggi, Sara; Isahara, Hitoshi; Maegaard, Bente; Mariani, Joseph; Mazo, Hélène; Odijk, Jan; Piperidis, Stelios","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5W3W5PDY","conferencePaper","2022","Parmar, Maulik; Narayan, Apurva","HyperBox: A Supervised Approach for Hypernym Discovery using Box Embeddings","Proceedings of the Thirteenth Language Resources and Evaluation Conference","","","","https://aclanthology.org/2022.lrec-1.652/","Hypernymy plays a fundamental role in many AI tasks like taxonomy learning, ontology learning, etc. This has motivated the development of many automatic identification methods for extracting this relation, most of which rely on word distribution. We present a novel model HyperBox to learn box embeddings for hypernym discovery. Given an input term, HyperBox retrieves its suitable hypernym from a target corpus. For this task, we use the dataset published for SemEval 2018 Shared Task on Hypernym Discovery. We compare the performance of our model on two specific domains of knowledge: medical and music. Experimentally, we show that our model outperforms existing methods on the majority of the evaluation metrics. Moreover, our model generalize well over unseen hypernymy pairs using only a small set of training data.","2022-06","2025-09-10 13:17:19","2025-09-10 13:17:19","","6069–6076","","","","","","","","","","","European Language Resources Association","Marseille, France","","","","","","","","","","","","","","Calzolari, Nicoletta; Béchet, Frédéric; Blache, Philippe; Choukri, Khalid; Cieri, Christopher; Declerck, Thierry; Goggi, Sara; Isahara, Hitoshi; Maegaard, Bente; Mariani, Joseph; Mazo, Hélène; Odijk, Jan; Piperidis, Stelios","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DS8ASKGM","conferencePaper","2022","Faralli, Stefano; Lenzi, Andrea; Velardi, Paola","A Large Interlinked Knowledge Graph of the Italian Cultural Heritage","Proceedings of the Thirteenth Language Resources and Evaluation Conference","","","","https://aclanthology.org/2022.lrec-1.675/","Knowledge is the lifeblood for a plethora of applications such as search, recommender systems and natural language understanding. Thanks to the efforts in the fields of Semantic Web and Linked Open Data a growing number of interlinked knowledge bases are supporting the development of advanced knowledge-based applications. Unfortunately, for a large number of domain-specific applications, these knowledge bases are unavailable. In this paper, we present a resource consisting of a large knowledge graph linking the Italian cultural heritage entities (defined in the ArCo ontology) with the concepts defined on well-known knowledge bases (i.e., DBpedia and the Getty GVP ontology). We describe the methodologies adopted for the semi-automatic resource creation and provide an in-depth analysis of the resulting interlinked graph.","2022-06","2025-09-10 13:17:19","2025-09-10 13:17:19","","6280–6289","","","","","","","","","","","European Language Resources Association","Marseille, France","","","","","","","","","","","","","","Calzolari, Nicoletta; Béchet, Frédéric; Blache, Philippe; Choukri, Khalid; Cieri, Christopher; Declerck, Thierry; Goggi, Sara; Isahara, Hitoshi; Maegaard, Bente; Mariani, Joseph; Mazo, Hélène; Odijk, Jan; Piperidis, Stelios","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HUTGH5QI","conferencePaper","2022","Weinzierl, Maxwell; Harabagiu, Sanda","VaccineLies: A Natural Language Resource for Learning to Recognize Misinformation about the COVID-19 and HPV Vaccines","Proceedings of the Thirteenth Language Resources and Evaluation Conference","","","","https://aclanthology.org/2022.lrec-1.753/","Billions of COVID-19 vaccines have been administered, but many remain hesitant. Misinformation about the COVID-19 vaccines and other vaccines, propagating on social media, is believed to drive hesitancy towards vaccination. The ability to automatically recognize misinformation targeting vaccines on Twitter depends on the availability of data resources. In this paper we present VaccineLies, a large collection of tweets propagating misinformation about two vaccines: the COVID-19 vaccines and the Human Papillomavirus (HPV) vaccines. Misinformation targets are organized in vaccine-specific taxonomies, which reveal the misinformation themes and concerns. The ontological commitments of the misinformation taxonomies provide an understanding of which misinformation themes and concerns dominate the discourse about the two vaccines covered in VaccineLies. The organization into training, testing and development sets of VaccineLies invites the development of novel supervised methods for detecting misinformation on Twitter and identifying the stance towards it. Furthermore, VaccineLies can be a stepping stone for the development of datasets focusing on misinformation targeting additional vaccines.","2022-06","2025-09-10 13:17:19","2025-09-10 13:17:19","","6967–6975","","","","","","","","","","","European Language Resources Association","Marseille, France","","","","","","","","","","","","","","Calzolari, Nicoletta; Béchet, Frédéric; Blache, Philippe; Choukri, Khalid; Cieri, Christopher; Declerck, Thierry; Goggi, Sara; Isahara, Hitoshi; Maegaard, Bente; Mariani, Joseph; Mazo, Hélène; Odijk, Jan; Piperidis, Stelios","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XY2PRF64","conferencePaper","2022","Sajjad, Hassan; Durrani, Nadir; Dalvi, Fahim; Alam, Firoj; Khan, Abdul; Xu, Jia","Analyzing Encoded Concepts in Transformer Language Models","Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies","","","10.18653/v1/2022.naacl-main.225","https://aclanthology.org/2022.naacl-main.225/","We propose a novel framework ConceptX, to analyze how latent concepts are encoded in representations learned within pre-trained lan-guage models. It uses clustering to discover the encoded concepts and explains them by aligning with a large set of human-defined concepts. Our analysis on seven transformer language models reveal interesting insights: i) the latent space within the learned representations overlap with different linguistic concepts to a varying degree, ii) the lower layers in the model are dominated by lexical concepts (e.g., affixation) and linguistic ontologies (e.g. Word-Net), whereas the core-linguistic concepts (e.g., morphology, syntactic relations) are better represented in the middle and higher layers, iii) some encoded concepts are multi-faceted and cannot be adequately explained using the existing human-defined concepts.","2022-07","2025-09-10 13:17:19","2025-09-10 13:17:19","","3082–3101","","","","","","","","","","","Association for Computational Linguistics","Seattle, United States","","","","","","","","","","","","","","Carpuat, Marine; de Marneffe, Marie-Catherine; Meza Ruiz, Ivan Vladimir","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Z772W4UU","conferencePaper","2022","Jose, Kevin; Gueudre, Thomas","Constraining word alignments with posterior regularization for label transfer","Proceedings of the 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies: Industry Track","","","10.18653/v1/2022.naacl-industry.15","https://aclanthology.org/2022.naacl-industry.15/","Unsupervised word alignments offer a lightweight and interpretable method to transfer labels from high- to low-resource languages, as long as semantically related words have the same label across languages. But such an assumption is often not true in industrial NLP pipelines, where multilingual annotation guidelines are complex and deviate from semantic consistency due to various factors (such as annotation difficulty, conflicting ontology, upcoming feature launches etc.);We address this difficulty by constraining the alignments models to remain consistent with both source and target annotation guidelines , leveraging posterior regularization and labeled examples. We illustrate the overall approach using IBM 2 (fast_align) as a base model, and report results on both internal and external annotated datasets. We measure consistent accuracy improvements on the MultiATIS++ dataset over AWESoME, a popular transformer-based alignment model, in the label projection task (+2.7% at word-level and +15% at sentence-level), and show how even a small amount of target language annotations help substantially.","2022-07","2025-09-10 13:17:19","2025-09-10 13:17:19","","121–129","","","","","","","","","","","Association for Computational Linguistics","Hybrid: Seattle, Washington + Online","","","","","","","","","","","","","","Loukina, Anastassia; Gangadharaiah, Rashmi; Min, Bonan","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TUB4KR2Q","conferencePaper","2022","Perçin, Sezen; Galassi, Andrea; Lagioia, Francesca; Ruggeri, Federico; Santin, Piera; Sartor, Giovanni; Torroni, Paolo","Combining WordNet and Word Embeddings in Data Augmentation for Legal Texts","Proceedings of the Natural Legal Language Processing Workshop 2022","","","10.18653/v1/2022.nllp-1.4","https://aclanthology.org/2022.nllp-1.4/","Creating balanced labeled textual corpora for complex tasks, like legal analysis, is a challenging and expensive process that often requires the collaboration of domain experts. To address this problem, we propose a data augmentation method based on the combination of GloVe word embeddings and the WordNet ontology. We present an example of application in the legal domain, specifically on decisions of the Court of Justice of the European Union.Our evaluation with human experts confirms that our method is more robust than the alternatives.","2022-12","2025-09-10 13:17:20","2025-09-10 13:17:20","","47–52","","","","","","","","","","","Association for Computational Linguistics","Abu Dhabi, United Arab Emirates (Hybrid)","","","","","","","","","","","","","","Aletras, Nikolaos; Chalkidis, Ilias; Barrett, Leslie; Goanță, Cătălina; Preoțiuc-Pietro, Daniel","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"44X4YPHZ","conferencePaper","2022","Gnehm, Ann-sophie; Bühlmann, Eva; Buchs, Helen; Clematide, Simon","Fine-Grained Extraction and Classification of Skill Requirements in German-Speaking Job Ads","Proceedings of the Fifth Workshop on Natural Language Processing and Computational Social Science (NLP+CSS)","","","10.18653/v1/2022.nlpcss-1.2","https://aclanthology.org/2022.nlpcss-1.2/","Monitoring the development of labor market skill requirements is an information need that is more and more approached by applying text mining methods to job advertisement data. We present an approach for fine-grained extraction and classification of skill requirements from German-speaking job advertisements. We adapt pre-trained transformer-based language models to the domain and task of computing meaningful representations of sentences or spans. By using context from job advertisements and the large ESCO domain ontology we improve our similarity-based unsupervised multi-label classification results. Our best model achieves a mean average precision of 0.969 on the skill class level.","2022-11","2025-09-10 13:17:20","2025-09-10 13:17:20","","14–24","","","","","","","","","","","Association for Computational Linguistics","Abu Dhabi, UAE","","","","","","","","","","","","","","Bamman, David; Hovy, Dirk; Jurgens, David; Keith, Katherine; O'Connor, Brendan; Volkova, Svitlana","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VPL9L6CG","conferencePaper","2022","Stranisci, Marco Antonio; Frenda, Simona; Lai, Mirko; Araque, Oscar; Cignarella, Alessandra Teresa; Basile, Valerio; Bosco, Cristina; Patti, Viviana","O-Dang! The Ontology of Dangerous Speech Messages","Proceedings of the 2nd Workshop on Sentiment Analysis and Linguistic Linked Data","","","","https://aclanthology.org/2022.salld-1.2/","Inside the NLP community there is a considerable amount of language resources created, annotated and released every day with the aim of studying specific linguistic phenomena. Despite a variety of attempts in order to organize such resources has been carried on, a lack of systematic methods and of possible interoperability between resources are still present. Furthermore, when storing linguistic information, still nowadays, the most common practice is the concept of “gold standard”, which is in contrast with recent trends in NLP that aim at stressing the importance of different subjectivities and points of view when training machine learning and deep learning methods. In this paper we present O-Dang!: The Ontology of Dangerous Speech Messages, a systematic and interoperable Knowledge Graph (KG) for the collection of linguistic annotated data. O-Dang! is designed to gather and organize Italian datasets into a structured KG, according to the principles shared within the Linguistic Linked Open Data community. The ontology has also been designed to account a perspectivist approach, since it provides a model for encoding both gold standard and single-annotator labels in the KG. The paper is structured as follows. In Section 1 the motivations of our work are outlined. Section 2 describes the O-Dang! Ontology, that provides a common semantic model for the integration of datasets in the KG. The Ontology Population stage with information about corpora, users, and annotations is presented in Section 3. Finally, in Section 4 an analysis of offensiveness across corpora is provided as a first case study for the resource.","2022-06","2025-09-10 13:17:20","2025-09-10 13:17:20","","2–8","","","","","","","","","","","European Language Resources Association","Marseille, France","","","","","","","","","","","","","","Kernerman, Ilan; Carvalho, Sara; Iglesias, Carlos A.; Sprugnoli, Rachele","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"P9I44WTH","conferencePaper","2022","Lin, Hsien-chin; Geishauser, Christian; Feng, Shutong; Lubis, Nurul; van Niekerk, Carel; Heck, Michael; Gasic, Milica","GenTUS: Simulating User Behaviour and Language in Task-oriented Dialogues with Generative Transformers","Proceedings of the 23rd Annual Meeting of the Special Interest Group on Discourse and Dialogue","","","10.18653/v1/2022.sigdial-1.28","https://aclanthology.org/2022.sigdial-1.28/","User simulators (USs) are commonly used to train task-oriented dialogue systems via reinforcement learning. The interactions often take place on semantic level for efficiency, but there is still a gap from semantic actions to natural language, which causes a mismatch between training and deployment environment. Incorporating a natural language generation (NLG) module with USs during training can partly deal with this problem. However, since the policy and NLG of USs are optimised separately, these simulated user utterances may not be natural enough in a given context. In this work, we propose a generative transformer-based user simulator (GenTUS). GenTUS consists of an encoder-decoder structure, which means it can optimise both the user policy and natural language generation jointly. GenTUS generates both semantic actions and natural language utterances, preserving interpretability and enhancing language variation. In addition, by representing the inputs and outputs as word sequences and by using a large pre-trained language model we can achieve generalisability in feature representation. We evaluate GenTUS with automatic metrics and human evaluation. Our results show that GenTUS generates more natural language and is able to transfer to an unseen ontology in a zero-shot fashion. In addition, its behaviour can be further shaped with reinforcement learning opening the door to training specialised user simulators.","2022-09","2025-09-10 13:17:20","2025-09-10 13:17:20","","270–282","","","","","","","","","","","Association for Computational Linguistics","Edinburgh, UK","","","","","","","","","","","","","","Lemon, Oliver; Hakkani-Tur, Dilek; Li, Junyi Jessy; Ashrafzadeh, Arash; Garcia, Daniel Hernández; Alikhani, Malihe; Vandyke, David; Dušek, Ondřej","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CXIRHI56","conferencePaper","2022","Vukovic, Renato; Heck, Michael; Ruppik, Benjamin; van Niekerk, Carel; Zibrowius, Marcus; Gasic, Milica","Dialogue Term Extraction using Transfer Learning and Topological Data Analysis","Proceedings of the 23rd Annual Meeting of the Special Interest Group on Discourse and Dialogue","","","10.18653/v1/2022.sigdial-1.53","https://aclanthology.org/2022.sigdial-1.53/","Goal oriented dialogue systems were originally designed as a natural language interface to a fixed data-set of entities that users might inquire about, further described by domain, slots and values. As we move towards adaptable dialogue systems where knowledge about domains, slots and values may change, there is an increasing need to automatically extract these terms from raw dialogues or related non-dialogue data on a large scale. In this paper, we take an important step in this direction by exploring different features that can enable systems to discover realisations of domains, slots and values in dialogues in a purely data-driven fashion. The features that we examine stem from word embeddings, language modelling features, as well as topological features of the word embedding space. To examine the utility of each feature set, we train a seed model based on the widely used MultiWOZ data-set. Then, we apply this model to a different corpus, the Schema-guided dialogue data-set. Our method outperforms the previously proposed approach that relies solely on word embeddings. We also demonstrate that each of the features is responsible for discovering different kinds of content. We believe our results warrant further research towards ontology induction, and continued harnessing of topological data analysis for dialogue and natural language processing research.","2022-09","2025-09-10 13:17:20","2025-09-10 13:17:20","","564–581","","","","","","","","","","","Association for Computational Linguistics","Edinburgh, UK","","","","","","","","","","","","","","Lemon, Oliver; Hakkani-Tur, Dilek; Li, Junyi Jessy; Ashrafzadeh, Arash; Garcia, Daniel Hernández; Alikhani, Malihe; Vandyke, David; Dušek, Ondřej","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3QH82X44","conferencePaper","2022","Ortega-Martín, Miguel; Ardoiz, Alfonso; Garcia, Oscar; Álvarez, Jorge; Alonso, Adrián","dezzai@SMM4H'22: Tasks 5 & 10 - Hybrid models everywhere","Proceedings of the Seventh Workshop on Social Media Mining for Health Applications, Workshop & Shared Task","","","","https://aclanthology.org/2022.smm4h-1.3/","This paper presents our approaches to SMM4H'22 task 5 - Classification of tweets of self-reported COVID-19 symptoms in Spanish, and task 10 - Detection of disease mentions in tweets – SocialDisNER (in Spanish). We have presented hybrid systems that combine Deep Learning techniques with linguistic rules and medical ontologies, which have allowed us to achieve outstanding results in both tasks.","2022-10","2025-09-10 13:17:20","2025-09-10 13:17:20","","7–10","","","","","","","","","","","Association for Computational Linguistics","Gyeongju, Republic of Korea","","","","","","","","","","","","","","Gonzalez-Hernandez, Graciela; Weissenbacher, Davy","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IGS9C8E7","journalArticle","2022","Heck, Michael; Lubis, Nurul; van Niekerk, Carel; Feng, Shutong; Geishauser, Christian; Lin, Hsien-Chin; Gašić, Milica","Robust Dialogue State Tracking with Weak Supervision and Sparse Data","Transactions of the Association for Computational Linguistics","","","10.1162/tacl_a_00513","https://aclanthology.org/2022.tacl-1.68/","Generalizing dialogue state tracking (DST) to new data is especially challenging due to the strong reliance on abundant and fine-grained supervision during training. Sample sparsity, distributional shift, and the occurrence of new concepts and topics frequently lead to severe performance degradation during inference. In this paper we propose a training strategy to build extractive DST models without the need for fine-grained manual span labels. Two novel input-level dropout methods mitigate the negative impact of sample sparsity. We propose a new model architecture with a unified encoder that supports value as well as slot independence by leveraging the attention mechanism. We combine the strengths of triple copy strategy DST and value matching to benefit from complementary predictions without violating the principle of ontology independence. Our experiments demonstrate that an extractive DST model can be trained without manual span labels. Our architecture and training strategies improve robustness towards sample sparsity, new concepts, and topics, leading to state-of-the-art performance on a range of benchmarks. We further highlight our model's ability to effectively learn from non-dialogue data.","2022","2025-09-10 13:17:20","2025-09-10 13:17:20","","1175–1192","","","10","","","","","","","","","","","","","","","","","Place: Cambridge, MA Publisher: MIT Press","","","","","","Roark, Brian; Nenkova, Ani","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VZBERFMY","conferencePaper","2022","Han, Lifeng; Erofeev, Gleb; Sorokina, Irina; Gladkoff, Serge; Nenadic, Goran","Examining Large Pre-Trained Language Models for Machine Translation: What You Don't Know about It","Proceedings of the Seventh Conference on Machine Translation (WMT)","","","","https://aclanthology.org/2022.wmt-1.84/","Pre-trained language models (PLMs) often take advantage of the monolingual and multilingual dataset that is freely available online to acquire general or mixed domain knowledge before deployment into specific tasks. Extra-large PLMs (xLPLMs) are proposed very recently to claim supreme performances over smaller-sized PLMs such as in machine translation (MT) tasks. These xLPLMs include Meta-AI's wmt21-dense-24-wide-en-X (2021) and NLLB (2022). In this work, we examine if xLPLMs are absolutely superior to smaller-sized PLMs in fine-tuning toward domain-specific MTs. We use two different in-domain data of different sizes: commercial automotive in-house data and clinical shared task data from the ClinSpEn2022 challenge at WMT2022. We choose the popular Marian Helsinki as smaller sized PLM and two massive-sized Mega-Transformers from Meta-AI as xLPLMs.Our experimental investigation shows that 1) on smaller-sized in-domain commercial automotive data, xLPLM wmt21-dense-24-wide-en-X indeed shows much better evaluation scores using SacreBLEU and hLEPOR metrics than smaller-sized Marian, even though its score increase rate is lower than Marian after fine-tuning; 2) on relatively larger-size well prepared clinical data fine-tuning, the xLPLM NLLB tends to lose its advantage over smaller-sized Marian on two sub-tasks (clinical terms and ontology concepts) using ClinSpEn offered metrics METEOR, COMET, and ROUGE-L, and totally lost to Marian on Task-1 (clinical cases) on all official metrics including SacreBLEU and BLEU; 3) metrics do not always agree with each other on the same tasks using the same model outputs; 4) clinic-Marian ranked No.2 on Task- 1 (via SacreBLEU/BLEU) and Task-3 (via METEOR and ROUGE) among all submissions.","2022-12","2025-09-10 13:17:20","2025-09-10 13:17:20","","908–919","","","","","","","","","","","Association for Computational Linguistics","Abu Dhabi, United Arab Emirates (Hybrid)","","","","","","","","","","","","","","Koehn, Philipp; Barrault, Loïc; Bojar, Ondřej; Bougares, Fethi; Chatterjee, Rajen; Costa-jussà, Marta R.; Federmann, Christian; Fishel, Mark; Fraser, Alexander; Freitag, Markus; Graham, Yvette; Grundkiewicz, Roman; Guzman, Paco; Haddow, Barry; Huck, Matthias; Jimeno Yepes, Antonio; Kocmi, Tom; Martins, André; Morishita, Makoto; Monz, Christof; Nagata, Masaaki; Nakazawa, Toshiaki; Negri, Matteo; Névéol, Aurélie; Neves, Mariana; Popel, Martin; Turchi, Marco; Zampieri, Marcos","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8HKPNV65","conferencePaper","2022","Manchanda, Sahil; Bhagwat, Saurabh","Optum's Submission to WMT22 Biomedical Translation Tasks","Proceedings of the Seventh Conference on Machine Translation (WMT)","","","","https://aclanthology.org/2022.wmt-1.86/","This paper describes Optum's submission to the Biomedical Translation task of the seventh conference on Machine Translation (WMT22). The task aims at promoting the development and evaluation of machine translation systems in their ability to handle challenging domain-specific biomedical data. We made submissions to two sub-tracks of ClinSpEn 2022, namely, ClinSpEn-CC (clinical cases) and ClinSpEn-OC (ontology concepts). These sub-tasks aim to test translation from English to Spanish. Our approach involves fine-tuning a pre-trained transformer model using in-house clinical domain data and the biomedical data provided by WMT. The fine-tuned model results in a test BLEU score of 38.12 in the ClinSpEn-CC (clinical cases) subtask, which is a gain of 1.23 BLEU compared to the pre-trained model.","2022-12","2025-09-10 13:17:20","2025-09-10 13:17:20","","925–929","","","","","","","","","","","Association for Computational Linguistics","Abu Dhabi, United Arab Emirates (Hybrid)","","","","","","","","","","","","","","Koehn, Philipp; Barrault, Loïc; Bojar, Ondřej; Bougares, Fethi; Chatterjee, Rajen; Costa-jussà, Marta R.; Federmann, Christian; Fishel, Mark; Fraser, Alexander; Freitag, Markus; Graham, Yvette; Grundkiewicz, Roman; Guzman, Paco; Haddow, Barry; Huck, Matthias; Jimeno Yepes, Antonio; Kocmi, Tom; Martins, André; Morishita, Makoto; Monz, Christof; Nagata, Masaaki; Nakazawa, Toshiaki; Negri, Matteo; Névéol, Aurélie; Neves, Mariana; Popel, Martin; Turchi, Marco; Zampieri, Marcos","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IRZNYCZ7","conferencePaper","2023","Wu, Weiqi; Jiang, Chengyue; Jiang, Yong; Xie, Pengjun; Tu, Kewei","Do PLMs Know and Understand Ontological Knowledge?","Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)","","","10.18653/v1/2023.acl-long.173","https://aclanthology.org/2023.acl-long.173/","Ontological knowledge, which comprises classes and properties and their relationships, is integral to world knowledge. It is significant to explore whether Pretrained Language Models (PLMs) know and understand such knowledge. However, existing PLM-probing studies focus mainly on factual knowledge, lacking a system- atic probing of ontological knowledge. In this paper, we focus on probing whether PLMs store ontological knowledge and have a semantic un- derstanding of the knowledge rather than rote memorization of the surface form. To probe whether PLMs know ontological knowledge, we investigate how well PLMs memorize: (1) types of entities; (2) hierarchical relationships among classes and properties, e.g., Person is a subclass of Animal and Member of Sports Team is a subproperty of Member of ; (3) domain and range constraints of properties, e.g., the subject of Member of Sports Team should be a Person and the object should be a Sports Team. To further probe whether PLMs truly understand ontological knowledge beyond memorization, we comprehensively study whether they can reliably perform logical reasoning with given knowledge according to ontological entailment rules. Our probing results show that PLMs can memorize certain ontological knowledge and utilize implicit knowledge in reasoning. How- ever, both the memorizing and reasoning per- formances are less than perfect, indicating in- complete knowledge and understanding.","2023-07","2025-09-10 13:17:20","2025-09-10 13:17:20","","3080–3101","","","","","","","","","","","Association for Computational Linguistics","Toronto, Canada","","","","","","","","","","","","","","Rogers, Anna; Boyd-Graber, Jordan; Okazaki, Naoaki","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6HTL5RFE","conferencePaper","2023","Parekh, Tanmay; Hsu, I-Hung; Huang, Kuan-Hao; Chang, Kai-Wei; Peng, Nanyun","GENEVA: Benchmarking Generalizability for Event Argument Extraction with Hundreds of Event Types and Argument Roles","Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)","","","10.18653/v1/2023.acl-long.203","https://aclanthology.org/2023.acl-long.203/","Recent works in Event Argument Extraction (EAE) have focused on improving model generalizability to cater to new events and domains. However, standard benchmarking datasets like ACE and ERE cover less than 40 event types and 25 entity-centric argument roles. Limited diversity and coverage hinder these datasets from adequately evaluating the generalizability of EAE models. In this paper, we first contribute by creating a large and diverse EAE ontology. This ontology is created by transforming FrameNet, a comprehensive semantic role labeling (SRL) dataset for EAE, by exploiting the similarity between these two tasks. Then, exhaustive human expert annotations are collected to build the ontology, concluding with 115 events and 220 argument roles, with a significant portion of roles not being entities. We utilize this ontology to further introduce GENEVA, a diverse generalizability benchmarking dataset comprising four test suites aimed at evaluating models' ability to handle limited data and unseen event type generalization. We benchmark six EAE models from various families. The results show that owing to non-entity argument roles, even the best-performing model can only achieve 39% F1 score, indicating how GENEVA provides new challenges for generalization in EAE. Overall, our large and diverse EAE ontology can aid in creating more comprehensive future resources, while GENEVA is a challenging benchmarking dataset encouraging further research for improving generalizability in EAE. The code and data can be found at https://github.com/PlusLabNLP/GENEVA.","2023-07","2025-09-10 13:17:20","2025-09-10 13:17:20","","3664–3686","","","","","","","","","","","Association for Computational Linguistics","Toronto, Canada","","","","","","","","","","","","","","Rogers, Anna; Boyd-Graber, Jordan; Okazaki, Naoaki","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WCYEMSIC","conferencePaper","2023","Wei, Kaiwen; Yang, Yiran; Jin, Li; Sun, Xian; Zhang, Zequn; Zhang, Jingyuan; Li, Xiao; Zhang, Linhao; Liu, Jintao; Zhi, Guo","Guide the Many-to-One Assignment: Open Information Extraction via IoU-aware Optimal Transport","Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)","","","10.18653/v1/2023.acl-long.272","https://aclanthology.org/2023.acl-long.272/","Open Information Extraction (OIE) seeks to extract structured information from raw text without the limitations of close ontology. Recently, the detection-based OIE methods have received great attention from the community due to their parallelism. However, as the essential step of those models, how to assign ground truth labels to the parallelly generated tuple proposals remains under-exploited. The commonly utilized Hungarian algorithm for this procedure is restricted to handling one-to-one assignment among the desired tuples and tuple proposals, which ignores the correlation between proposals and affects the recall of the models. To solve this problem, we propose a dynamic many-to-one label assignment strategy named IOT. Concretely, the label assignment process in OIE is formulated as an Optimal Transport (OT) problem. We leverage the intersection-over-union (IoU) as the assignment quality measurement, and convert the problem of finding the best assignment solution to the one of solving the optimal transport plan by maximizing the IoU values. To further utilize the knowledge from the assignment, we design an Assignment-guided Multi-granularity loss (AM) by simultaneously considering word-level and tuple-level information. Experiment results show the proposed method outperforms the state-of-the-art models on three benchmarks.","2023-07","2025-09-10 13:17:20","2025-09-10 13:17:20","","4971–4984","","","","","","","","","","","Association for Computational Linguistics","Toronto, Canada","","","","","","","","","","","","","","Rogers, Anna; Boyd-Graber, Jordan; Okazaki, Naoaki","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3P5NN527","conferencePaper","2023","Stengel-Eskin, Elias; Guallar-Blasco, Jimena; Zhou, Yi; Van Durme, Benjamin","Why Did the Chicken Cross the Road? Rephrasing and Analyzing Ambiguous Questions in VQA","Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)","","","10.18653/v1/2023.acl-long.569","https://aclanthology.org/2023.acl-long.569/","Natural language is ambiguous. Resolving ambiguous questions is key to successfully answering them. Focusing on questions about images, we create a dataset of ambiguous examples. We annotate these, grouping answers by the underlying question they address and rephrasing the question for each group to reduce ambiguity. Our analysis reveals a linguistically-aligned ontology of reasons for ambiguity in visual questions. We then develop an English question-generation model which we demonstrate via automatic and human evaluation produces less ambiguous questions. We further show that the question generation objective we use allows the model to integrate answer group information without any direct supervision.","2023-07","2025-09-10 13:17:20","2025-09-10 13:17:20","","10220–10237","","","","","","","","","","","Association for Computational Linguistics","Toronto, Canada","","","","","","","","","","","","","","Rogers, Anna; Boyd-Graber, Jordan; Okazaki, Naoaki","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZYPX5MXH","conferencePaper","2023","Sharma, Megha; Vatsal, Tushar; Merugu, Srujana; Rajan, Aruna","Automated Digitization of Unstructured Medical Prescriptions","Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 5: Industry Track)","","","10.18653/v1/2023.acl-industry.76","https://aclanthology.org/2023.acl-industry.76/","Automated digitization of prescription images is a critical prerequisite to scale digital healthcare services such as online pharmacies. This is challenging in emerging markets since prescriptions are not digitized at source and patients lack the medical expertise to interpret prescriptions to place orders. In this paper, we present prescription digitization system for online medicine ordering built with minimal supervision. Our system uses a modular pipeline comprising a mix of ML and rule-based components for (a) image to text extraction, (b) segmentation into blocks and medication items, (c) medication attribute extraction, (d) matching against medicine catalog, and (e) shopping cart building. Our approach efficiently utilizes multiple signals like layout, medical ontologies, and semantic embeddings via LayoutLMv2 model to yield substantial improvement relative to strong baselines on medication attribute extraction. Our pipeline achieves +5.9% gain in precision@3 and +5.6% in recall@3 over catalog-based fuzzy matching baseline for shopping cart building for printed prescriptions.","2023-07","2025-09-10 13:17:20","2025-09-10 13:17:20","","794–805","","","","","","","","","","","Association for Computational Linguistics","Toronto, Canada","","","","","","","","","","","","","","Sitaram, Sunayana; Beigman Klebanov, Beata; Williams, Jason D","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8VHLB6UM","conferencePaper","2023","Remy, François; Demuynck, Kris; Demeester, Thomas","Automatic Glossary of Clinical Terminology: a Large-Scale Dictionary of Biomedical Definitions Generated from Ontological Knowledge","Proceedings of the 22nd Workshop on Biomedical Natural Language Processing and BioNLP Shared Tasks","","","10.18653/v1/2023.bionlp-1.23","https://aclanthology.org/2023.bionlp-1.23/","Background: More than 400.000 biomedical concepts and some of their relationships are contained in SnomedCT, a comprehensive biomedical ontology. However, their concept names are not always readily interpretable by non-experts, or patients looking at their own electronic health records (EHR). Clear definitions or descriptions in understandable language or often not available. Therefore, generating human-readable definitions for biomedical concepts might help make the information they encode more accessible and understandable to a wider public. Objective: In this article, we introduce the Automatic Glossary of Clinical Terminology (AGCT), a large-scale biomedical dictionary of clinical concepts generated using high-quality information extracted from the biomedical knowledge contained in SnomedCT.Methods: We generate a novel definition for every SnomedCT concept, after prompting the OpenAI Turbo model, a variant of GPT 3.5, using a high-quality verbalization of the SnomedCT relationships of the to-be-defined concept. A significant subset of the generated definitions was subsequently evaluated by NLP researchers with biomedical expertise on 5-point scales along the following three axes: factuality, insight, and fluency. Results: AGCT contains 422,070 computer-generated definitions for SnomedCT concepts, covering various domains such as diseases, procedures, drugs, and anatomy. The average length of the definitions is 49 words. The definitions were assigned average scores of over 4.5 out of 5 on all three axes, indicating a majority of factual, insightful, and fluent definitions. Conclusion: AGCT is a novel and valuable resource for biomedical tasks that require human-readable definitions for SnomedCT concepts. It can also serve as a base for developing robust biomedical retrieval models or other applications that leverage natural language understanding of biomedical knowledge.","2023-07","2025-09-10 13:17:20","2025-09-10 13:17:20","","265–272","","","","","","","","","","","Association for Computational Linguistics","Toronto, Canada","","","","","","","","","","","","","","Demner-fushman, Dina; Ananiadou, Sophia; Cohen, Kevin","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5JKM23IL","conferencePaper","2023","Slavcheva, Milena; Tanev, Hristo; Uca, Onur","On the Road to a Protest Event Ontology for Bulgarian: Conceptual Structures and Representation Design","Proceedings of the 6th Workshop on Challenges and Applications of Automated Extraction of Socio-political Events from Text","","","","https://aclanthology.org/2023.case-1.13/","The paper presents a semantic model of protest events, called Semantic Interpretations of Protest Events (SemInPE). The analytical framework used for building the semantic representations is inspired by the object-oriented paradigm in computer science and a cognitive approach to the linguistic analysis. The model is a practical application of the Unified Eventity Representation (UER) formalism, which is based on the Unified Modeling Language (UML). The multi-layered architecture of the model provides flexible means for building the semantic representations of the language objects along a scale of generality and specificity. Thus, it is a suitable environment for creating the elements of ontologies on various topics and for different languages.","2023-09","2025-09-10 13:17:20","2025-09-10 13:17:20","","92–100","","","","","","","","","","","INCOMA Ltd., Shoumen, Bulgaria","Varna, Bulgaria","","","","","","","","","","","","","","Hürriyetoğlu, Ali; Tanev, Hristo; Zavarella, Vanni; Yeniterzi, Reyyan; Yörük, Erdem; Slavcheva, Milena","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7KIWZ2EY","conferencePaper","2023","Xiong, Xiong; Chen, Wang; Yunfei, Liu; Shengyang, Li","Enhancing Ontology Knowledge for Domain-Specific Joint Entity and Relation Extraction","Proceedings of the 22nd Chinese National Conference on Computational Linguistics","","","","https://aclanthology.org/2023.ccl-1.61/","“Pre-trained language models (PLMs) have been widely used in entity and relation extractionmethods in recent years. However, due to the semantic gap between general-domain text usedfor pre-training and domain-specific text, these methods encounter semantic redundancy anddomain semantics insufficiency when it comes to domain-specific tasks. To mitigate this issue,we propose a low-cost and effective knowledge-enhanced method to facilitate domain-specificsemantics modeling in joint entity and relation extraction. Precisely, we use ontology and entitytype descriptions as domain knowledge sources, which are encoded and incorporated into thedownstream entity and relation extraction model to improve its understanding of domain-specificinformation. We construct a dataset called SSUIE-RE for Chinese entity and relation extractionin space science and utilization domain of China Manned Space Engineering, which contains awealth of domain-specific knowledge. The experimental results on SSUIE-RE demonstrate theeffectiveness of our method, achieving a 1.4% absolute improvement in relation F1 score overprevious best approach. Introduction”","2023-08","2025-09-10 13:17:20","2025-09-10 13:17:20","","713–725","","","","","","","","","","","Chinese Information Processing Society of China","Harbin, China","eng","","","","","","","","","","","","","Sun, Maosong; Qin, Bing; Qiu, Xipeng; Jiang, Jing; Han, Xianpei","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"E8YJ2LK5","conferencePaper","2023","Han, Lifeng; Erofeev, Gleb; Sorokina, Irina; Gladkoff, Serge; Nenadic, Goran","Investigating Massive Multilingual Pre-Trained Machine Translation Models for Clinical Domain via Transfer Learning","Proceedings of the 5th Clinical Natural Language Processing Workshop","","","10.18653/v1/2023.clinicalnlp-1.5","https://aclanthology.org/2023.clinicalnlp-1.5/","Massively multilingual pre-trained language models (MMPLMs) are developed in recent years demonstrating superpowers and the pre-knowledge they acquire for downstream tasks. This work investigates whether MMPLMs can be applied to clinical domain machine translation (MT) towards entirely unseen languages via transfer learning. We carry out an experimental investigation using Meta-AI's MMPLMs “wmt21-dense-24-wide-en-X and X-en (WMT21fb)” which were pre-trained on 7 language pairs and 14 translation directions including English to Czech, German, Hausa, Icelandic, Japanese, Russian, and Chinese, and the opposite direction. We fine-tune these MMPLMs towards English-<i>Spanish</i> language pair which <i>did not exist at all</i> in their original pre-trained corpora both implicitly and explicitly.We prepare carefully aligned <i>clinical</i> domain data for this fine-tuning, which is different from their original mixed domain knowledge.Our experimental result shows that the fine-tuning is very successful using just 250k well-aligned in-domain EN-ES segments for three sub-task translation testings: clinical cases, clinical terms, and ontology concepts. It achieves very close evaluation scores to another MMPLM NLLB from Meta-AI, which included Spanish as a high-resource setting in the pre-training.To the best of our knowledge, this is the first work on using MMPLMs towards <i>clinical domain transfer-learning NMT</i> successfully for totally unseen languages during pre-training.","2023-07","2025-09-10 13:17:20","2025-09-10 13:17:20","","31–40","","","","","","","","","","","Association for Computational Linguistics","Toronto, Canada","","","","","","","","","","","","","","Naumann, Tristan; Ben Abacha, Asma; Bethard, Steven; Roberts, Kirk; Rumshisky, Anna","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"T7NQCRMG","conferencePaper","2023","Blankemeier, Louis; Zhao, Theodore; Tinn, Robert; Kiblawi, Sid; Gu, Yu; Chaudhari, Akshay; Poon, Hoifung; Zhang, Sheng; Wei, Mu; Preston, J.","Interactive Span Recommendation for Biomedical Text","Proceedings of the 5th Clinical Natural Language Processing Workshop","","","10.18653/v1/2023.clinicalnlp-1.40","https://aclanthology.org/2023.clinicalnlp-1.40/","Motivated by the scarcity of high-quality labeled biomedical text, as well as the success of data programming, we introduce KRISS-Search. By leveraging the Unified Medical Language Systems (UMLS) ontology, KRISS-Search addresses an interactive few-shot span recommendation task that we propose. We first introduce unsupervised KRISS-Search and show that our method outperforms existing methods in identifying spans that are semantically similar to a given span of interest, with \ensuremath>50% AUPRC improvement relative to PubMedBERT. We then introduce supervised KRISS-Search, which leverages human interaction to improve the notion of similarity used by unsupervised KRISS-Search. Through simulated human feedback, we demonstrate an enhanced F1 score of 0.68 in classifying spans as semantically similar or different in the low-label setting, outperforming PubMedBERT by 2 F1 points. Finally, supervised KRISS-Search demonstrates competitive or superior performance compared to PubMedBERT in few-shot biomedical named entity recognition (NER) across five benchmark datasets, with an average improvement of 5.6 F1 points. We envision KRISS-Search increasing the efficiency of programmatic data labeling and also providing broader utility as an interactive biomedical search engine.","2023-07","2025-09-10 13:17:20","2025-09-10 13:17:20","","373–384","","","","","","","","","","","Association for Computational Linguistics","Toronto, Canada","","","","","","","","","","","","","","Naumann, Tristan; Ben Abacha, Asma; Bethard, Steven; Roberts, Kirk; Rumshisky, Anna","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Q9CDMU8V","conferencePaper","2023","Karlgren, Jussi","High-dimensional vector spaces can accommodate constructional features quite conveniently","Proceedings of the First International Workshop on Construction Grammars and NLP (CxGs+NLP, GURT/SyntaxFest 2023)","","","","https://aclanthology.org/2023.cxgsnlp-1.4/","Current language processing tools presuppose input in the form of a sequence of high-dimensional vectors with continuous values. Lexical items can be converted to such vectors with standard methodology and subsequent processing is assumed to handle structural features of the string. Constructional features do typically not fit in that processing pipeline: they are not as clearly sequential, they overlap with other items, and the fact that they are combinations of lexical items obscures their ontological status as observable linguistic items in their own right. Constructional grammar frameworks allow for a more general view on how to understand lexical items and their configurations in a common framework. This paper introduces an approach to accommodate that understanding in a vector symbolic architecture, a processing framework which allows for combinations of continuous vectors and discrete items, convenient for various downstream processing using e.g. neural processing or other tools which expect input in vector form.","2023-03","2025-09-10 13:17:20","2025-09-10 13:17:20","","31–35","","","","","","","","","","","Association for Computational Linguistics","Washington, D.C.","","","","","","","","","","","","","","Bonial, Claire; Tayyar Madabushi, Harish","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XIFQVLCC","conferencePaper","2023","Jiang, Chengyue; Jiang, Yong; Wu, Weiqi; Zheng, Yuting; Xie, Pengjun; Tu, Kewei","COMBO: A Complete Benchmark for Open KG Canonicalization","Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics","","","10.18653/v1/2023.eacl-main.26","https://aclanthology.org/2023.eacl-main.26/","Open knowledge graph (KG) consists of (subject, relation, object) triples extracted from millions of raw text. The subject and object noun phrases and the relation in open KG have severe redundancy and ambiguity and need to be canonicalized. Existing datasets for open KG canonicalization only provide gold entity-level canonicalization for noun phrases. In this paper, we present COMBO, a Complete Benchmark for Open KG canonicalization. Compared with existing datasets, we additionally provide gold canonicalization for relation phrases, gold ontology-level canonicalization for noun phrases, as well as source sentences from which triples are extracted. We also propose metrics for evaluating each type of canonicalization. On the COMBO dataset, we empirically compare previously proposed canonicalization methods as well as a few simple baseline methods based on pretrained language models. We find that properly encoding the phrases in a triple using pretrained language models results in better relation canonicalization and ontology-level canonicalization of the noun phrase. We release our dataset, baselines, and evaluation scripts at path/to/url.","2023-05","2025-09-10 13:17:20","2025-09-10 13:17:20","","340–357","","","","","","","","","","","Association for Computational Linguistics","Dubrovnik, Croatia","","","","","","","","","","","","","","Vlachos, Andreas; Augenstein, Isabelle","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HMU9V5DN","conferencePaper","2023","Shrivastava, Akshat; Desai, Shrey; Gupta, Anchit; Elkahky, Ali; Livshits, Aleksandr; Zotov, Alexander; Aly, Ahmed","Retrieve-and-Fill for Scenario-based Task-Oriented Semantic Parsing","Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics","","","10.18653/v1/2023.eacl-main.32","https://aclanthology.org/2023.eacl-main.32/","Task-oriented semantic parsing models have achieved strong results in recent years, but unfortunately do not strike an appealing balance between model size, runtime latency, and cross-domain generalizability. We tackle this problem by introducing scenario-based semantic parsing: a variant of the original task which first requires disambiguating an utterance's “scenario” (an intent-slot template with variable leaf spans) before generating its frame, complete with ontology and utterance tokens. This formulation enables us to isolate coarse-grained and fine-grained aspects of the task, each of which we solve with off-the-shelf neural modules, also optimizing for the axes outlined above. Concretely, we create a Retrieve-and-Fill (RAF) architecture comprised of (1) a retrieval module which ranks the best scenario given an utterance and (2) a filling module which imputes spans into the scenario to create the frame. Our model is modular, differentiable, interpretable, and allows us to garner extra supervision from scenarios. RAF achieves strong results in high-resource, low-resource, and multilingual settings, outperforming recent approaches by wide margins despite, using base pre-trained encoders, small sequence lengths, and parallel decoding.","2023-05","2025-09-10 13:17:20","2025-09-10 13:17:20","","430–447","","","","","","","","","","","Association for Computational Linguistics","Dubrovnik, Croatia","","","","","","","","","","","","","","Vlachos, Andreas; Augenstein, Isabelle","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AT52FQLA","conferencePaper","2023","Edwards, Carl; Ji, Heng","Semi-supervised New Event Type Induction and Description via Contrastive Loss-Enforced Batch Attention","Proceedings of the 17th Conference of the European Chapter of the Association for Computational Linguistics","","","10.18653/v1/2023.eacl-main.275","https://aclanthology.org/2023.eacl-main.275/","Most event extraction methods have traditionally relied on an annotated set of event types. However, creating event ontologies and annotating supervised training data are expensive and time-consuming. Previous work has proposed semi-supervised approaches which leverage seen (annotated) types to learn how to automatically discover new event types. State-of-the-art methods, both semi-supervised or fully unsupervised, use a form of reconstruction loss on specific tokens in a context. In contrast, we present a novel approach to semi-supervised new event type induction using a masked contrastive loss, which learns similarities between event mentions by enforcing an attention mechanism over the data minibatch. We further disentangle the discovered clusters by approximating the underlying manifolds in the data, which allows us to achieve an adjusted rand index score of 48.85%. Building on these clustering results, we extend our approach to two new tasks: predicting the type name of the discovered clusters and linking them to FrameNet frames.","2023-05","2025-09-10 13:17:20","2025-09-10 13:17:20","","3805–3827","","","","","","","","","","","Association for Computational Linguistics","Dubrovnik, Croatia","","","","","","","","","","","","","","Vlachos, Andreas; Augenstein, Isabelle","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JP3JINNJ","conferencePaper","2023","Cao, Pengfei; Hao, Yupu; Chen, Yubo; Liu, Kang; Xu, Jiexin; Li, Huaijun; Jiang, Xiaojian; Zhao, Jun","Event Ontology Completion with Hierarchical Structure Evolution Networks","Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing","","","10.18653/v1/2023.emnlp-main.21","https://aclanthology.org/2023.emnlp-main.21/","Traditional event detection methods require predefined event schemas. However, manually defining event schemas is expensive and the coverage of schemas is limited. To this end, some works study the event type induction (ETI) task, which discovers new event types via clustering. However, the setting of ETI suffers from two limitations: event types are not linked into the existing hierarchy and have no semantic names. In this paper, we propose a new research task named Event Ontology Completion (EOC), which aims to simultaneously achieve event clustering, hierarchy expansion and type naming. Furthermore, we develop a Hierarchical Structure Evolution Network (HalTon) for this new task. Specifically, we first devise a Neighborhood Contrastive Clustering module to cluster unlabeled event instances. Then, we propose a Hierarchy-Aware Linking module to incorporate the hierarchical information for event expansion. Finally, we generate meaningful names for new types via an In-Context Learning-based Naming module. Extensive experiments indicate that our method achieves the best performance, outperforming the baselines by 8.23%, 8.79% and 8.10% of ARI score on three datasets.","2023-12","2025-09-10 13:17:20","2025-09-10 13:17:20","","306–320","","","","","","","","","","","Association for Computational Linguistics","Singapore","","","","","","","","","","","","","","Bouamor, Houda; Pino, Juan; Bali, Kalika","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YCM5XUHB","conferencePaper","2023","Makhervaks, Dave; Gillis, Plia; Radinsky, Kira","Clinical Contradiction Detection","Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing","","","10.18653/v1/2023.emnlp-main.80","https://aclanthology.org/2023.emnlp-main.80/","Detecting contradictions in text is essential in determining the validity of the literature and sources that we consume. Medical corpora are riddled with conflicting statements. This is due to the large throughput of new studies and the difficulty in replicating experiments, such as clinical trials. Detecting contradictions in this domain is hard since it requires clinical expertise. We present a distant supervision approach that leverages a medical ontology to build a seed of potential clinical contradictions over 22 million medical abstracts. We automatically build a labeled training dataset consisting of paired clinical sentences that are grounded in an ontology and represent potential medical contradiction. The dataset is used to weakly-supervise state-of-the-art deep learning models showing significant empirical improvements across multiple medical contradiction datasets.","2023-12","2025-09-10 13:17:20","2025-09-10 13:17:20","","1248–1263","","","","","","","","","","","Association for Computational Linguistics","Singapore","","","","","","","","","","","","","","Bouamor, Houda; Pino, Juan; Bali, Kalika","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AZSAH4G5","conferencePaper","2023","Li, Sha; Zhan, Qiusi; Conger, Kathryn; Palmer, Martha; Ji, Heng; Han, Jiawei","GLEN: General-Purpose Event Detection for Thousands of Types","Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing","","","10.18653/v1/2023.emnlp-main.170","https://aclanthology.org/2023.emnlp-main.170/","The progress of event extraction research has been hindered by the absence of wide-coverage, large-scale datasets. To make event extraction systems more accessible, we build a general-purpose event detection dataset GLEN, which covers 205K event mentions with 3,465 different types, making it more than 20x larger in ontology than today's largest event dataset. GLEN is created by utilizing the DWD Overlay, which provides a mapping between Wikidata Qnodes and PropBank rolesets. This enables us to use the abundant existing annotation for PropBank as distant supervision. In addition, we also propose a new multi-stage event detection model specifically designed to handle the large ontology size in GLEN. We show that our model exhibits superior performance compared to a range of baselines including InstructGPT. Finally, we perform error analysis and show that label noise is still the largest challenge for improving performance for this new dataset.","2023-12","2025-09-10 13:17:20","2025-09-10 13:17:20","","2823–2838","","","","","","","","","","","Association for Computational Linguistics","Singapore","","","","","","","","","","","","","","Bouamor, Houda; Pino, Juan; Bali, Kalika","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SQWUCVPC","conferencePaper","2023","Schulhoff, Sander; Pinto, Jeremy; Khan, Anaum; Bouchard, Louis-François; Si, Chenglei; Anati, Svetlina; Tagliabue, Valen; Kost, Anson; Carnahan, Christopher; Boyd-Graber, Jordan","Ignore This Title and HackAPrompt: Exposing Systemic Vulnerabilities of LLMs Through a Global Prompt Hacking Competition","Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing","","","10.18653/v1/2023.emnlp-main.302","https://aclanthology.org/2023.emnlp-main.302/","Large Language Models (LLMs) are increasingly being deployed in interactive contexts that involve direct user engagement, such as chatbots and writing assistants. These deployments are increasingly plagued by prompt injection and jailbreaking (collectively, prompt hacking), in which models are manipulated to ignore their original instructions and instead follow potentially malicious ones. Although widely acknowledged as a significant security threat, there is a dearth of a large-scale resource and quantitative study on prompt hacking. To address this lacuna, we launch a global prompt hacking competition, which allows for free-form human input attacks. We elicit 600K+ adversarial prompts against three state-of-the-art LLMs. We describe the dataset, which empirically verifies that current LLMs can indeed be manipulated via prompt hacking. We also present a comprehensive ontology of the types of adversarial prompts.","2023-12","2025-09-10 13:17:20","2025-09-10 13:17:20","","4945–4977","","","","","","","","","","","Association for Computational Linguistics","Singapore","","","","","","","","","","","","","","Bouamor, Houda; Pino, Juan; Bali, Kalika","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PZQKFCB9","conferencePaper","2023","Han, Xue; Wang, Yitong; Hu, Qian; Hu, Pengwei; Deng, Chao; Feng, Junlan","Log-FGAER: Logic-Guided Fine-Grained Address Entity Recognition from Multi-Turn Spoken Dialogue","Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing","","","10.18653/v1/2023.emnlp-main.432","https://aclanthology.org/2023.emnlp-main.432/","Fine-grained address entity recognition (FGAER) from multi-turn spoken dialogues is particularly challenging. The major reason lies in that a full address is often formed through a conversation process. Different parts of an address are distributed through multiple turns of a dialogue with spoken noises. It is nontrivial to extract by turn and combine them. This challenge has not been well emphasized by main-stream entity extraction algorithms. To address this issue, we propose in this paper a logic-guided fine-grained address recognition method (Log-FGAER), where we formulate the address hierarchy relationship as the logic rule and softly apply it in a probabilistic manner to improve the accuracy of FGAER. In addition, we provide an ontology-based data augmentation methodology that employs ChatGPT to augment a spoken dialogue dataset with labeled address entities. Experiments are conducted using datasets generated by the proposed data augmentation technique and derived from real-world scenarios. The results of the experiment demonstrate the efficacy of our proposal.","2023-12","2025-09-10 13:17:20","2025-09-10 13:17:20","","6988–6997","","","","","","","","","","","Association for Computational Linguistics","Singapore","","","","","","","","","","","","","","Bouamor, Houda; Pino, Juan; Bali, Kalika","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"96JPMN88","conferencePaper","2023","Shavarani, Hassan; Sarkar, Anoop","SpEL: Structured Prediction for Entity Linking","Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing","","","10.18653/v1/2023.emnlp-main.686","https://aclanthology.org/2023.emnlp-main.686/","Entity linking is a prominent thread of research focused on structured data creation by linking spans of text to an ontology or knowledge source. We revisit the use of structured prediction for entity linking which classifies each individual input token as an entity, and aggregates the token predictions. Our system, called SpEL (Structured prediction for Entity Linking) is a state-of-the-art entity linking system that uses some new ideas to apply structured prediction to the task of entity linking including: two refined fine-tuning steps; a context sensitive prediction aggregation strategy; reduction of the size of the model's output vocabulary, and; we address a common problem in entity-linking systems where there is a training vs. inference tokenization mismatch. Our experiments show that we can outperform the state-of-the-art on the commonly used AIDA benchmark dataset for entity linking to Wikipedia. Our method is also very compute efficient in terms of number of parameters and speed of inference.","2023-12","2025-09-10 13:17:20","2025-09-10 13:17:20","","11123–11137","","","","","","","","","","","Association for Computational Linguistics","Singapore","","","","","","","","","","","","","","Bouamor, Houda; Pino, Juan; Bali, Kalika","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4AZ6BFGG","conferencePaper","2023","Kartchner, David; Deng, Jennifer; Lohiya, Shubham; Kopparthi, Tejasri; Bathala, Prasanth; Domingo-Fernández, Daniel; Mitchell, Cassie","A Comprehensive Evaluation of Biomedical Entity Linking Models","Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing","","","10.18653/v1/2023.emnlp-main.893","https://aclanthology.org/2023.emnlp-main.893/","Biomedical entity linking (BioEL) is the process of connecting entities referenced in documents to entries in biomedical databases such as the Unified Medical Language System (UMLS) or Medical Subject Headings (MeSH). The study objective was to comprehensively evaluate nine recent state-of-the-art biomedical entity linking models under a unified framework. We compare these models along axes of (1) accuracy, (2) speed, (3) ease of use, (4) generalization, and (5) adaptability to new ontologies and datasets. We additionally quantify the impact of various preprocessing choices such as abbreviation detection. Systematic evaluation reveals several notable gaps in current methods. In particular, current methods struggle to correctly link genes and proteins and often have difficulty effectively incorporating context into linking decisions. To expedite future development and baseline testing, we release our unified evaluation framework and all included models on GitHub at https://github.com/davidkartchner/biomedical-entity-linking","2023-12","2025-09-10 13:17:20","2025-09-10 13:17:20","","14462–14478","","","","","","","","","","","Association for Computational Linguistics","Singapore","","","","","","","","","","","","","","Bouamor, Houda; Pino, Juan; Bali, Kalika","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"B45ST43X","conferencePaper","2023","Zhao, Jeffrey; Cao, Yuan; Gupta, Raghav; Lee, Harrison; Rastogi, Abhinav; Wang, Mingqiu; Soltau, Hagen; Shafran, Izhak; Wu, Yonghui","AnyTOD: A Programmable Task-Oriented Dialog System","Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing","","","10.18653/v1/2023.emnlp-main.1006","https://aclanthology.org/2023.emnlp-main.1006/","We propose AnyTOD, an end-to-end, zero-shot task-oriented dialog (TOD) system capable of zero-shot adaptation onto unseen tasks or domains. We view TOD as a program executed by a language model (LM), where program logic and ontology is provided by a designer as a schema. To enable generalization to unseen schemas and programs without prior training, AnyTOD adopts a neuro-symbolic approach. A neural LM keeps track of events that occur during a conversation, and a symbolic program implementing dialog policy is executed to recommend actions AnyTOD should take. This approach drastically reduces data annotation and model training requirements, addressing the enduring challenge of rapidly adapting a TOD system to unseen tasks and domains. We demonstrate state-of-the-art results on STAR, ABCD and SGD benchmarks. We also demonstrate strong zero-shot transfer ability in low-resource settings, such as zero-shot transfer onto MultiWOZ. In addition, we release STARv2, an updated version of the STAR dataset with richer annotations, for benchmarking zero-shot task transfer for end-to-end TOD models.","2023-12","2025-09-10 13:17:20","2025-09-10 13:17:20","","16189–16204","","","","","","","","","","","Association for Computational Linguistics","Singapore","","","","","","","","","","","","","","Bouamor, Houda; Pino, Juan; Bali, Kalika","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7TUUN73W","conferencePaper","2023","Yu, Lijun; Miao, Jin; Sun, Xiaoyu; Chen, Jiayi; Hauptmann, Alexander; Dai, Hanjun; Wei, Wei","DocumentNet: Bridging the Data Gap in Document Pre-training","Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing: Industry Track","","","10.18653/v1/2023.emnlp-industry.66","https://aclanthology.org/2023.emnlp-industry.66/","Document understanding tasks, in particular, Visually-rich Document Entity Retrieval (VDER), have gained significant attention in recent years thanks to their broad applications in enterprise AI. However, publicly available data have been scarce for these tasks due to strict privacy constraints and high annotation costs. To make things worse, the non-overlapping entity spaces from different datasets hinder the knowledge transfer between document types. In this paper, we propose a method to collect massive-scale and weakly labeled data from the web to benefit the training of VDER models. The collected dataset, named DocumentNet, does not depend on specific document types or entity sets, making it universally applicable to all VDER tasks. The current DocumentNet consists of 30M documents spanning nearly 400 document types organized in a four-level ontology. Experiments on a set of broadly adopted VDER tasks show significant improvements when DocumentNet is incorporated into the pre-training for both classic and few-shot learning settings. With the recent emergence of large language models (LLMs), DocumentNet provides a large data source to extend their multimodal capabilities for VDER.","2023-12","2025-09-10 13:17:20","2025-09-10 13:17:20","","707–722","","","","","","","","","","","Association for Computational Linguistics","Singapore","","","","","","","","","","","","","","Wang, Mingxuan; Zitouni, Imed","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3WAFA6JU","conferencePaper","2023","Lefebvre, Clément; Stoehr, Niklas","Rethinking the Event Coding Pipeline with Prompt Entailment","Proceedings of the Sixth Fact Extraction and VERification Workshop (FEVER)","","","10.18653/v1/2023.fever-1.1","https://aclanthology.org/2023.fever-1.1/","For monitoring crises, political events are extracted from the news. The large amount of unstructured full-text event descriptions makes a case-by-case analysis unmanageable, particularly for low-resource humanitarian aid organizations. This creates a demand to classify events into event types, a task referred to as event coding. Typically, domain experts craft an event type ontology, annotators label a large dataset and technical experts develop a supervised coding system. In this work, we propose PR-ENT, a new event coding approach that is more flexible and resource-efficient, while maintaining competitive accuracy: first, we extend an event description such as “Military injured two civilians” by a template, e.g. “People were [Z]” and prompt a pre-trained (cloze) language model to fill the slot Z. Second, we select suitable answer candidates Zstar = “injured”, “hurt”... by treating the event description as premise and the filled templates as hypothesis in a textual entailment task. In a final step, the selected answer candidate can be mapped to its corresponding event type. This allows domain experts to draft the codebook directly as labeled prompts and interpretable answer candidates. This human-in-the-loop process is guided by our codebook design tool. We show that our approach is robust through several checks: perturbing the event description and prompt template, restricting the vocabulary and removing contextual information.","2023-05","2025-09-10 13:17:20","2025-09-10 13:17:20","","1–16","","","","","","","","","","","Association for Computational Linguistics","Dubrovnik, Croatia","","","","","","","","","","","","","","Akhtar, Mubashara; Aly, Rami; Christodoulopoulos, Christos; Cocarascu, Oana; Guo, Zhijiang; Mittal, Arpit; Schlichtkrull, Michael; Thorne, James; Vlachos, Andreas","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2DKB3ZAR","conferencePaper","2023","Ajjour, Yamen; Kiesel, Johannes; Stein, Benno; Potthast, Martin","Topic Ontologies for Arguments","Findings of the Association for Computational Linguistics: EACL 2023","","","10.18653/v1/2023.findings-eacl.104","https://aclanthology.org/2023.findings-eacl.104/","Many computational argumentation tasks, such as stance classification, are topic-dependent: The effectiveness of approaches to these tasks depends largely on whether they are trained with arguments on the same topics as those on which they are tested. The key question is: What are these training topics? To answer this question, we take the first step of mapping the argumentation landscape with The Argument Ontology (TAO). TAO draws on three authoritative sources for argument topics: the World Economic Forum, Wikipedia's list of controversial topics, and Debatepedia. By comparing the topics in our ontology with those in 59 argument corpora, we perform the first comprehensive assessment of their topic coverage. While TAO already covers most of the corpus topics, the corpus topics barely cover all the topics in TAO. This points to a new goal for corpus construction to achieve a broad topic coverage and thus better generalizability of computational argumentation approaches.","2023-05","2025-09-10 13:17:20","2025-09-10 13:17:20","","1411–1427","","","","","","","","","","","Association for Computational Linguistics","Dubrovnik, Croatia","","","","","","","","","","","","","","Vlachos, Andreas; Augenstein, Isabelle","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YGQLC62I","conferencePaper","2023","Coca, Alexandru; Tseng, Bo-Hsiang; Lin, Weizhe; Byrne, Bill","More Robust Schema-Guided Dialogue State Tracking via Tree-Based Paraphrase Ranking","Findings of the Association for Computational Linguistics: EACL 2023","","","10.18653/v1/2023.findings-eacl.106","https://aclanthology.org/2023.findings-eacl.106/","The schema-guided paradigm overcomes scalability issues inherent in building task-oriented dialogue (TOD) agents with static ontologies. Rather than operating on dialogue context alone, agents have access to hierarchical schemas containing task-relevant natural language descriptions. Fine-tuned language models excel at schema-guided dialogue state tracking (DST) but are sensitive to the writing style of the schemas. We explore methods for improving the robustness of DST models. We propose a framework for generating synthetic schemas which uses tree-based ranking to jointly optimise lexical diversity and semantic faithfulness. The robust generalisation of strong baselines is improved when augmenting their training data with prompts generated by our framework, as demonstrated by marked improvements in average Joint Goal Accuracy (JGA) and schema sensitivity (SS) on the SGD-X benchmark.","2023-05","2025-09-10 13:17:20","2025-09-10 13:17:20","","1443–1454","","","","","","","","","","","Association for Computational Linguistics","Dubrovnik, Croatia","","","","","","","","","","","","","","Vlachos, Andreas; Augenstein, Isabelle","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Z3UCB7ZH","conferencePaper","2023","Weinstein, Aviv; Goldberg, Yoav","Unsupervised Mapping of Arguments of Deverbal Nouns to Their Corresponding Verbal Labels","Findings of the Association for Computational Linguistics: ACL 2023","","","10.18653/v1/2023.findings-acl.184","https://aclanthology.org/2023.findings-acl.184/","Deverbal nouns are nominal forms of verbs commonly used in written English texts to describe events or actions, as well as their arguments. However, many NLP systems, and in particular pattern-based ones, neglect to handle such nominalized constructions. The solutions that do exist for handling arguments of nominalized constructions are based on semantic annotation and require semantic ontologies, making their applications restricted to a small set of nouns. We propose to adopt instead a more syntactic approach, which maps the arguments of deverbal nouns to the universal-dependency relations of the corresponding verbal construction. We present an unsupervised mechanism—based on contextualized word representations—which allows to enrich universal-dependency trees with dependency arcs denoting arguments of deverbal nouns, using the same labels as the corresponding verbal cases. By sharing the same label set as in the verbal case, patterns that were developed for verbs can be applied without modification but with high accuracy also to the nominal constructions.","2023-07","2025-09-10 13:17:20","2025-09-10 13:17:20","","2921–2935","","","","","","","","","","","Association for Computational Linguistics","Toronto, Canada","","","","","","","","","","","","","","Rogers, Anna; Boyd-Graber, Jordan; Okazaki, Naoaki","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8UKLU55K","conferencePaper","2023","He, Yuan; Chen, Jiaoyan; Jimenez-Ruiz, Ernesto; Dong, Hang; Horrocks, Ian","Language Model Analysis for Ontology Subsumption Inference","Findings of the Association for Computational Linguistics: ACL 2023","","","10.18653/v1/2023.findings-acl.213","https://aclanthology.org/2023.findings-acl.213/","Investigating whether pre-trained language models (LMs) can function as knowledge bases (KBs) has raised wide research interests recently. However, existing works focus on simple, triple-based, relational KBs, but omit more sophisticated, logic-based, conceptualised KBs such as OWL ontologies. To investigate an LM's knowledge of ontologies, we propose OntoLAMA, a set of inference-based probing tasks and datasets from ontology subsumption axioms involving both atomic and complex concepts. We conduct extensive experiments on ontologies of different domains and scales, and our results demonstrate that LMs encode relatively less background knowledge of Subsumption Inference (SI) than traditional Natural Language Inference (NLI) but can improve on SI significantly when a small number of samples are given. We will open-source our code and datasets.","2023-07","2025-09-10 13:17:20","2025-09-10 13:17:20","","3439–3453","","","","","","","","","","","Association for Computational Linguistics","Toronto, Canada","","","","","","","","","","","","","","Rogers, Anna; Boyd-Graber, Jordan; Okazaki, Naoaki","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"35MIM2UY","conferencePaper","2023","Guo, Shaoru; Wang, Chenhao; Chen, Yubo; Liu, Kang; Li, Ru; Zhao, Jun","EventOA: An Event Ontology Alignment Benchmark Based on FrameNet and Wikidata","Findings of the Association for Computational Linguistics: ACL 2023","","","10.18653/v1/2023.findings-acl.637","https://aclanthology.org/2023.findings-acl.637/","Event ontology provides a shared and formal specification about what happens in the real world and can benefit many natural language understanding tasks. However, the independent development of event ontologies often results in heterogeneous representations that raise the need for establishing alignments between semantically related events. There exists a series of works about ontology alignment (OA), but they only focus on the entity-based OA, and neglect the event-based OA. To fill the gap, we construct an Event Ontology Alignment (EventOA) dataset based on FrameNet and Wikidata, which consists of 900+ event type alignments and 8,000+ event argument alignments. Furthermore, we propose a multi-view event ontology alignment (MEOA) method, which utilizes description information (i.e., name, alias and definition) and neighbor information (i.e., subclass and superclass) to obtain richer representation of the event ontologies. Extensive experiments show that our MEOA outperforms the existing entity-based OA methods and can serve as a strong baseline for EventOA research.","2023-07","2025-09-10 13:17:20","2025-09-10 13:17:20","","10038–10052","","","","","","","","","","","Association for Computational Linguistics","Toronto, Canada","","","","","","","","","","","","","","Rogers, Anna; Boyd-Graber, Jordan; Okazaki, Naoaki","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Y3M6QEQ4","conferencePaper","2023","Huang, Zijie; Wang, Daheng; Huang, Binxuan; Zhang, Chenwei; Shang, Jingbo; Liang, Yan; Wang, Zhengyang; Li, Xian; Faloutsos, Christos; Sun, Yizhou; Wang, Wei","Concept2Box: Joint Geometric Embeddings for Learning Two-View Knowledge Graphs","Findings of the Association for Computational Linguistics: ACL 2023","","","10.18653/v1/2023.findings-acl.642","https://aclanthology.org/2023.findings-acl.642/","Knowledge graph embeddings (KGE) have been extensively studied to embed large-scale relational data for many real-world applications. Existing methods have long ignored the fact many KGs contain two fundamentally different views: high-level ontology-view concepts and fine-grained instance-view entities. They usually embed all nodes as vectors in one latent space. However, a single geometric representation fails to capture the structural differences between two views and lacks probabilistic semantics towards concepts' granularity. We propose Concept2Box, a novel approach that jointly embeds the two views of a KG using dual geometric representations. We model concepts with box embeddings, which learn the hierarchy structure and complex relations such as overlap and disjoint among them. Box volumes can be interpreted as concepts' granularity. Different from concepts, we model entities as vectors. To bridge the gap between concept box embeddings and entity vector embeddings, we propose a novel vector-to-box distance metric and learn both embeddings jointly. Experiments on both the public DBpedia KG and a newly-created industrial KG showed the effectiveness of Concept2Box.","2023-07","2025-09-10 13:17:21","2025-09-10 13:17:21","","10105–10118","","","","","","","","","","","Association for Computational Linguistics","Toronto, Canada","","","","","","","","","","","","","","Rogers, Anna; Boyd-Graber, Jordan; Okazaki, Naoaki","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MHCJIDVN","conferencePaper","2023","Zhou, Wentao; Zhao, Jun; Gui, Tao; Zhang, Qi; Huang, Xuanjing","Inductive Relation Inference of Knowledge Graph Enhanced by Ontology Information","Findings of the Association for Computational Linguistics: EMNLP 2023","","","10.18653/v1/2023.findings-emnlp.431","https://aclanthology.org/2023.findings-emnlp.431/","The inductive inference of the knowledge graph aims to complete the potential relations between the new unknown entities in the graph. Most existing methods are based on entity-independent features such as graph structure information and relationship information to inference. However, the neighborhood of these new entities is often too sparse to obtain enough information to build these features effectively. In this work, we propose a knowledge graph inductive inference method that fuses ontology information. Based on the enclosing subgraph, we bring in feature embeddings of concepts corresponding to entities to learn the semantic information implicit in the ontology. Considering that the ontology information of entities may be missing, we build a type constraint regular loss to explicitly model the semantic connections between entities and concepts, and thus capture the missing concepts of entities. Experimental results show that our approach significantly outperforms large language models like ChatGPT on two benchmark datasets, YAGO21K-610 and DB45K-165, and improves the MRR metrics by 15.4% and 44.1%, respectively, when compared with the state-of-the-art methods.","2023-12","2025-09-10 13:17:21","2025-09-10 13:17:21","","6491–6502","","","","","","","","","","","Association for Computational Linguistics","Singapore","","","","","","","","","","","","","","Bouamor, Houda; Pino, Juan; Bali, Kalika","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7D4WG79W","conferencePaper","2023","Chen, Derek; Lee, Celine; Lu, Yunan; Rosati, Domenic; Yu, Zhou","Mixture of Soft Prompts for Controllable Data Generation","Findings of the Association for Computational Linguistics: EMNLP 2023","","","10.18653/v1/2023.findings-emnlp.988","https://aclanthology.org/2023.findings-emnlp.988/","Large language models (LLMs) effectively generate fluent text when the target output follows natural language patterns. However, structured prediction tasks confine the output format to a limited ontology, causing even very large models to struggle since they were never trained with such restrictions in mind. The difficulty of using LLMs for direct prediction is exacerbated in few-shot learning scenarios, which commonly arise due to domain shift and resource limitations. We flip the problem on its head by leveraging the LLM as a tool for data augmentation rather than direct prediction. Our proposed Mixture of Soft Prompts (MSP) serves as a parameter-efficient procedure for generating multi-attribute data in a controlled manner. Denoising mechanisms are further applied to improve the quality of synthesized data. Automatic metrics show our method is capable of producing diverse and natural text, while preserving label semantics. Moreover, MSP achieves state-of-the-art results on three benchmarks when compared against strong baselines. Our method offers an alternate data-centric approach for applying LLMs to complex prediction tasks.","2023-12","2025-09-10 13:17:21","2025-09-10 13:17:21","","14815–14833","","","","","","","","","","","Association for Computational Linguistics","Singapore","","","","","","","","","","","","","","Bouamor, Houda; Pino, Juan; Bali, Kalika","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"49Q366C8","conferencePaper","2023","Lu, Keming; Pan, Xiaoman; Song, Kaiqiang; Zhang, Hongming; Yu, Dong; Chen, Jianshu","PIVOINE: Instruction Tuning for Open-world Entity Profiling","Findings of the Association for Computational Linguistics: EMNLP 2023","","","10.18653/v1/2023.findings-emnlp.1009","https://aclanthology.org/2023.findings-emnlp.1009/","This work considers the problem of Open-world Entity Profiling, a sub-domain of Open-world Information Extraction (Open-world IE). Unlike the conventional closed-world IE, Open-world IE is considered a more general situation where entities and relations could be beyond a predefined ontology. We seek to develop a large language model (LLM) that can perform Open-world Entity Profiling with instruction tuning to extract desirable entity profiles characterized by (possibly fine-grained) natural language instructions. In particular, we construct INSTRUCTOPENWIKI, a substantial instruction-tuning dataset for Open-world Entity Profiling enriched with a comprehensive corpus, extensive annotations, and diverse instructions. We finetune pretrained BLOOM models on INSTRUCTOPENWIKI and obtain PIVOINE, an LLM for Open-world Entity Profiling with strong instruction-following capabilities. Our experiments demonstrate that PIVOINE significantly outperforms traditional methods and ChatGPT-based baselines, displaying impressive generalization capabilities on both unseen instructions and out-of-ontology cases. Consequently, PIVOINE emerges as a promising solution to tackle the open-world challenge of entity profiling.","2023-12","2025-09-10 13:17:21","2025-09-10 13:17:21","","15108–15127","","","","","","","","","","","Association for Computational Linguistics","Singapore","","","","","","","","","","","","","","Bouamor, Houda; Pino, Juan; Bali, Kalika","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KU2576EL","conferencePaper","2023","Álvez, Javier; Gonzalez-Dios, Itziar; Rigau, German","Towards Effective Correction Methods Using WordNet Meronymy Relations","Proceedings of the 12th Global Wordnet Conference","","","","https://aclanthology.org/2023.gwc-1.4/","In this paper, we analyse and compare several correction methods of knowledge resources with the purpose of improving the abilities of systems that require commonsense reasoning with the least possible human-effort. To this end, we cross-check the WordNet meronymy relation member against the knowledge encoded in a SUMO-based first-order logic ontology on the basis of the mapping between WordNet and SUMO. In particular, we focus on the knowledge in WordNet regarding the taxonomy of animals and plants. Despite being created manually, these knowledge resources — WordNet, SUMO and their mapping — are not free of errors and discrepancies. Thus, we propose three correction methods by semi-automatically improving the alignment between WordNet and SUMO, by performing some few corrections in SUMO and by combining the above two strategies. The evaluation of each method includes the required human-effort and the achieved improvement on unseen data from the WebChild project, that is tested using first-order logic automated theorem provers.","2023-01","2025-09-10 13:17:21","2025-09-10 13:17:21","","31–40","","","","","","","","","","","Global Wordnet Association","University of the Basque Country, Donostia - San Sebastian, Basque Country","","","","","","","","","","","","","","Rigau, German; Bond, Francis; Rademaker, Alexandre","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"93RJQJMN","conferencePaper","2023","Biagetti, Erica; Zanchi, Chiara; Luraghi, Silvia","Linking the Sanskrit WordNet to the Vedic Dependency Treebank: a pilot study","Proceedings of the 12th Global Wordnet Conference","","","","https://aclanthology.org/2023.gwc-1.9/","The Sanskrit WordNet is a resource currently under development, whose core was induced from a Vedic text sample semantically annotated by means of an ontology mapped on the Princeton WordNet synsets. Building on a previous case study on Ancient Greek (Zanchi et al. 2021), we show how sentence frames can be extracted from morphosyntactically parsed corpora by linking an existing dependency treebank of Vedic Sanskrit to verbal synsets in the Sanskrit WordNet. Our case study focuses on two verbs of asking, yāc- and prach-, featuring a high degree of variability in sentence frames. Treebanks enhanced with WordNet-based semantic information revealed to be of crucial help in motivating sentence frame alternations.","2023-01","2025-09-10 13:17:21","2025-09-10 13:17:21","","77–83","","","","","","","","","","","Global Wordnet Association","University of the Basque Country, Donostia - San Sebastian, Basque Country","","","","","","","","","","","","","","Rigau, German; Bond, Francis; Rademaker, Alexandre","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KIQTQZMV","conferencePaper","2023","Zinn, Claus; Hinrichs, Marie; Hinrichs, Erhard","Mapping GermaNet for the Semantic Web using OntoLex-Lemon","Proceedings of the 12th Global Wordnet Conference","","","","https://aclanthology.org/2023.gwc-1.19/","GermaNet is a large lexical-semantic net that relates German nouns, verbs, and adjectives semantically. The word net has been manually constructed over the last 25 years and hence presents a high-quality, valuable resource for German. While GermaNet is maintained in a Postgres database, all its content can be exported as an XML-based serialisation. Recently, this XML representation has been converted into RDF, largely by staying close to GermaNet's principle of arrangement where lexunits that share the same meaning are grouped together into so-called synsets. With each lexical unit and synset now globally addressable via a unique resource identifier, it has become much easier to link together GermaNet entries with other lexical and semantic resources. In terms of semantic interoperability, however, the RDF variant of GermaNet leaves much to be desired. In this paper, we describe yet another conversion from GermaNet's XML representation to RDF. The new conversion makes use of the OntoLex-Lemon ontology, and therefore, presents a decisive step toward a GermaNet representation with a much higher level of semantic interoperability, and which makes it possible to use GermaNet with other wordnets that already support this conceptualisation of lexica.","2023-01","2025-09-10 13:17:21","2025-09-10 13:17:21","","158–166","","","","","","","","","","","Global Wordnet Association","University of the Basque Country, Donostia - San Sebastian, Basque Country","","","","","","","","","","","","","","Rigau, German; Bond, Francis; Rademaker, Alexandre","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9F9VZZNQ","conferencePaper","2023","Pedersen, Bolette; Nimb, Sanni; Sørensen, Nathalie; Olsen, Sussi; Flörke, Ida; Troelsgård, Thomas","Reusing the Danish WordNet for a New Central Word Register for Danish - a Project Report","Proceedings of the 12th Global Wordnet Conference","","","","https://aclanthology.org/2023.gwc-1.26/","In this paper we report on a new Danish lexical initiative, the Central Word Register for Danish, (COR), which aims at providing an open-source, well curated and large-coverage lexicon for AI purposes. The semantic part of the lexicon (COR-S) relies to a large extent on the lexical-semantic information provided in the Danish wordnet, DanNet. However, we have taken the opportunity to evaluate and curate the wordnet information while compiling the new resource. Some information types have been simplified and more systematically curated. This is the case for the hyponymy relations, the ontological typing, and the sense inventory, i.e. the treatment of polysemy, including systematic polysemy.","2023-01","2025-09-10 13:17:21","2025-09-10 13:17:21","","214–219","","","","","","","","","","","Global Wordnet Association","University of the Basque Country, Donostia - San Sebastian, Basque Country","","","","","","","","","","","","","","Rigau, German; Bond, Francis; Rademaker, Alexandre","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QFW7NJR5","conferencePaper","2023","Simov, Kiril; Osenova, Petya","Recent Developments in BTB-WordNet","Proceedings of the 12th Global Wordnet Conference","","","","https://aclanthology.org/2023.gwc-1.27/","The paper reports on recent developments in Bulgarian BTB-WordNet (BTB-WN). This resource is viewed as playing a central role with respect to the integration and interlinking of various language resources such as: e-dictionaries (morphological, terminological, bilingual, orthographic, etymological and explanatory, etc., including editions from previous periods); corpora (coming from outside or being internal - like the corpus of definitions as well as the corpus of examples to synset meanings); ontologies (such as CIDOC-CRM, DBpedia, etc.); sources of world knowledge (such as information from the Bulgarian Encyclopedia, Wikipedia, etc.). The paper also gives information about a number of applications built on BTB-WN. These are: the Bulgaria-centered knowledge graph, the All about word application as well as some education-oriented exercises.","2023-01","2025-09-10 13:17:21","2025-09-10 13:17:21","","220–227","","","","","","","","","","","Global Wordnet Association","University of the Basque Country, Donostia - San Sebastian, Basque Country","","","","","","","","","","","","","","Rigau, German; Bond, Francis; Rademaker, Alexandre","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JY9UQTVX","conferencePaper","2023","Rademaker, Alexandre; Basu, Abhishek; Veluri, Rajkiran","Semantic Parsing and Sense Tagging the Princeton WordNet Gloss Corpus","Proceedings of the 12th Global Wordnet Conference","","","","https://aclanthology.org/2023.gwc-1.30/","In 2008, the Princeton team released the last version of the “Princeton Annotated Gloss Corpus”. In this corpus. The word forms from the definitions and examples (glosses) of Princeton WordNet are manually linked to the context-appropriate sense in WordNet. However, the annotation was not complete, and the dataset was never officially released as part of WordNet 3.0, remaining as one of the standoff files available for download. Eleven years later, in 2019, one of the authors of this paper restarted the project aiming to complete the sense annotation of the approximately 200 thousand word forms not yet annotated. Here, we provide additional motivations to complete this dataset and report the progress in the work and evaluations. Intending to provide an extra level of consistency in the sense annotation and a deep semantic representation of the definitions and examples promoting WordNet from a lexical resource to a lightweight ontology, we now employ the English Resource Grammar (ERG), a broad-coverage HPSG grammar of English to parse the sentences and project the sense annotations from the surface words to the ERG predicates. We also report some initial steps on upgrading the corpus to WordNet 3.1 to facilitate mapping the data to other lexical resources.","2023-01","2025-09-10 13:17:21","2025-09-10 13:17:21","","243–253","","","","","","","","","","","Global Wordnet Association","University of the Basque Country, Donostia - San Sebastian, Basque Country","","","","","","","","","","","","","","Rigau, German; Bond, Francis; Rademaker, Alexandre","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GUJNVDMC","conferencePaper","2023","Zotova, Elena; Cuadros, Montse; Rigau, German","Towards the integration of WordNet into ClinIDMap","Proceedings of the 12th Global Wordnet Conference","","","","https://aclanthology.org/2023.gwc-1.42/","This paper presents the integration of WordNet knowledge resource into ClinIDMap tool, which aims to map identifiers between clinical ontologies and lexical resources. ClinIDMap interlinks identifiers from UMLS, SMOMED-CT, ICD-10 and the corresponding Wikidata and Wikipedia articles for concepts from the UMLS Metathesaurus. The main goal of the tool is to provide semantic interoperability across the clinical concepts from various knowledge bases. As a side effect, the mapping enriches already annotated medical corpora in multiple languages with new labels. In this new release, we add WordNet 3.0 and 3.1 synsets using the available mappings through Wikidata. Thanks to cross-lingual links in MCR we also include the corresponding synsets in other languages and also, extend further ClinIDMap with different domain information. Finally, the final resource helps in the task of enriching of already annotated clinical corpora with additional semantic annotations.","2023-01","2025-09-10 13:17:21","2025-09-10 13:17:21","","352–362","","","","","","","","","","","Global Wordnet Association","University of the Basque Country, Donostia - San Sebastian, Basque Country","","","","","","","","","","","","","","Rigau, German; Bond, Francis; Rademaker, Alexandre","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NBK8RQLJ","conferencePaper","2023","Mustafa, Faizan E; Boutalbi, Rafika; Iurshina, Anastasiia","Annotating PubMed Abstracts with MeSH Headings using Graph Neural Network","Proceedings of the Fourth Workshop on Insights from Negative Results in NLP","","","10.18653/v1/2023.insights-1.9","https://aclanthology.org/2023.insights-1.9/","The number of scientific publications in the biomedical domain is continuously increasing with time. An efficient system for indexing these publications is required to make the information accessible according to the user's information needs. Task 10a of the BioASQ challenge aims to classify PubMed articles according to the MeSH ontology so that new publications can be grouped with similar preexisting publications in the field without the assistance of time-consuming and costly annotations by human annotators. In this work, we use Graph Neural Network (GNN) in the link prediction setting to exploit potential graph-structured information present in the dataset which could otherwise be neglected by transformer-based models. Additionally, we provide error analysis and a plausible reason for the substandard performance achieved by GNN.","2023-05","2025-09-10 13:17:21","2025-09-10 13:17:21","","75–81","","","","","","","","","","","Association for Computational Linguistics","Dubrovnik, Croatia","","","","","","","","","","","","","","Tafreshi, Shabnam; Akula, Arjun; Sedoc, João; Drozd, Aleksandr; Rogers, Anna; Rumshisky, Anna","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5VMFGG9K","conferencePaper","2023","Spaulding, Elizabeth; Conger, Kathryn; Gershman, Anatole; Uceda-Sosa, Rosario; Brown, Susan Windisch; Pustejovsky, James; Anick, Peter; Palmer, Martha","The DARPA Wikidata Overlay: Wikidata as an ontology for natural language processing","Proceedings of the 19th Joint ACL-ISO Workshop on Interoperable Semantics (ISA-19)","","","","https://aclanthology.org/2023.isa-1.1/","With 102,530,067 items currently in its crowd-sourced knowledge base, Wikidata provides NLP practitioners a unique and powerful resource for inference and reasoning over real-world entities. However, because Wikidata is very entity focused, <i>events</i> and <i>actions</i> are often labeled with eventive nouns (e.g., the process of diagnosing a person's illness is labeled “diagnosis”), and the typical participants in an event are not described or linked to that event concept (e.g., the medical professional or patient). Motivated by a need for an adaptable, comprehensive, domain-flexible ontology for information extraction, including identifying the roles entities are playing in an event, we present a curated subset of Wikidata in which events have been enriched with PropBank roles. To enable richer narrative understanding between events from Wikidata concepts, we have also provided a comprehensive mapping from temporal Qnodes and Pnodes to the Allen Interval Temporal Logic relations.","2023-06","2025-09-10 13:17:21","2025-09-10 13:17:21","","1–10","","","","","","","","","","","Association for Computational Linguistics","Nancy, France","","","","","","","","","","","","","","Bunt, Harry","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YBPQ8RUR","conferencePaper","2023","Saba, Walid","Towards Ontologically Grounded and Language-Agnostic Knowledge Graphs","Proceedings of the 15th International Conference on Computational Semantics","","","","https://aclanthology.org/2023.iwcs-1.11/","Knowledge graphs (KGs) have become the standard technology for the representation of factual information in applications such as recommendation engines, search, and question-answering systems. However, the continual updating of KGs, as well as the integration of KGs from different domains and KGs in different languages, remains to be a major challenge. What we suggest here is that by a reification of abstract objects and by acknowledging the ontological distinction between concepts and types, we arrive at an ontologically grounded and language-agnostic representation that can alleviate the difficulties in KG integration.","2023-06","2025-09-10 13:17:21","2025-09-10 13:17:21","","94–98","","","","","","","","","","","Association for Computational Linguistics","Nancy, France","","","","","","","","","","","","","","Amblard, Maxime; Breitholtz, Ellen","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ZXA4BFBS","conferencePaper","2023","Straková, Jana; Fučíková, Eva; Hajič, Jan; Urešová, Zdeňka","Extending an Event-type Ontology: Adding Verbs and Classes Using Fine-tuned LLMs Suggestions","Proceedings of the 17th Linguistic Annotation Workshop (LAW-XVII)","","","10.18653/v1/2023.law-1.9","https://aclanthology.org/2023.law-1.9/","In this project, we have investigated the use of advanced machine learning methods, specifically fine-tuned large language models, for pre-annotating data for a lexical extension task, namely adding descriptive words (verbs) to an existing (but incomplete, as of yet) ontology of event types. Several research questions have been focused on, from the investigation of a possible heuristics to provide at least hints to annotators which verbs to include and which are outside the current version of the ontology, to the possible use of the automatic scores to help the annotators to be more efficient in finding a threshold for identifying verbs that cannot be assigned to any existing class and therefore they are to be used as seeds for a new class. We have also carefully examined the correlation of the automatic scores with the human annotation. While the correlation turned out to be strong, its influence on the annotation proper is modest due to its near linearity, even though the mere fact of such pre-annotation leads to relatively short annotation times.","2023-07","2025-09-10 13:17:21","2025-09-10 13:17:21","","85–95","","","","","","","","","","","Association for Computational Linguistics","Toronto, Canada","","","","","","","","","","","","","","Prange, Jakob; Friedrich, Annemarie","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CUZIV29V","conferencePaper","2023","Pannach, Franziska; Blaschke, Theresa","Modeling and Comparison of Narrative Domains with Shallow Ontologies","Proceedings of the 4th Conference on Language, Data and Knowledge","","","","https://aclanthology.org/2023.ldk-1.26/","","2023-09","2025-09-10 13:17:21","2025-09-10 13:17:21","","274–280","","","","","","","","","","","NOVA CLUNL, Portugal","Vienna, Austria","","","","","","","","","","","","","","Carvalho, Sara; Khan, Anas Fahad; Anić, Ana Ostroški; Spahiu, Blerina; Gracia, Jorge; McCrae, John P.; Gromann, Dagmar; Heinisch, Barbara; Salgado, Ana","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WCYN4HF4","conferencePaper","2023","Remy, François; Khabibullina, Alfiya; Demeester, Thomas","Detecting Idiomatic Multiword Expressions in Clinical Terminology using Definition-Based Representation Learning","Proceedings of the 19th Workshop on Multiword Expressions (MWE 2023)","","","10.18653/v1/2023.mwe-1.11","https://aclanthology.org/2023.mwe-1.11/","This paper shines a light on the potential of definition-based semantic models for detecting idiomatic and semi-idiomatic multiword expressions (MWEs) in clinical terminology. Our study focuses on biomedical entities defined in the UMLS ontology and aims to help prioritize the translation efforts of these entities. In particular, we develop an effective tool for scoring the idiomaticity of biomedical MWEs based on the degree of similarity between the semantic representations of those MWEs and a weighted average of the representation of their constituents. We achieve this using a biomedical language model trained to produce similar representations for entity names and their definitions, called BioLORD. The importance of this definition-based approach is highlighted by comparing the BioLORD model to two other state-of-the-art biomedical language models based on Transformer: SapBERT and CODER. Our results show that the BioLORD model has a strong ability to identify idiomatic MWEs, not replicated in other models. Our corpus-free idiomaticity estimation helps ontology translators to focus on more challenging MWEs.","2023-05","2025-09-10 13:17:21","2025-09-10 13:17:21","","73–80","","","","","","","","","","","Association for Computational Linguistics","Dubrovnik, Croatia","","","","","","","","","","","","","","Bhatia, Archna; Evang, Kilian; Garcia, Marcos; Giouli, Voula; Han, Lifeng; Taslimipoor, Shiva","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AC7MHGX3","conferencePaper","2023","Yang, Longfei; Li, Jiyi; Li, Sheng; Shinozaki, Takahiro","Dialogue State Tracking with Sparse Local Slot Attention","Proceedings of the 5th Workshop on NLP for Conversational AI (NLP4ConvAI 2023)","","","10.18653/v1/2023.nlp4convai-1.4","https://aclanthology.org/2023.nlp4convai-1.4/","Dialogue state tracking (DST) is designed to track the dialogue state during the conversations between users and systems, which is the core of task-oriented dialogue systems. Mainstream models predict the values for each slot with fully token-wise slot attention from dialogue history. However, such operations may result in overlooking the neighboring relationship. Moreover, it may lead the model to assign probability mass to irrelevant parts, while these parts contribute little. It becomes severe with the increase in dialogue length. Therefore, we investigate sparse local slot attention for DST in this work. Slot-specific local semantic information is obtained at a sub-sampled temporal resolution capturing local dependencies for each slot. Then these local representations are attended with sparse attention weights to guide the model to pay attention to relevant parts of local information for subsequent state value prediction. The experimental results on MultiWOZ 2.0 and 2.4 datasets show that the proposed approach effectively improves the performance of ontology-based dialogue state tracking, and performs better than token-wise attention for long dialogues.","2023-07","2025-09-10 13:17:21","2025-09-10 13:17:21","","39–46","","","","","","","","","","","Association for Computational Linguistics","Toronto, Canada","","","","","","","","","","","","","","Chen, Yun-Nung; Rastogi, Abhinav","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4HFJIQNE","conferencePaper","2023","Olstad, Annika Willoch; Papadopoulou, Anthi; Lison, Pierre","Generation of Replacement Options in Text Sanitization","Proceedings of the 24th Nordic Conference on Computational Linguistics (NoDaLiDa)","","","","https://aclanthology.org/2023.nodalida-1.30/","The purpose of text sanitization is to edit text documents to mask text spans that may directly or indirectly reveal personal information. An important problem in text sanitization is to find less specific, yet still informative replacements for each text span to mask. We present an approach to generate possible replacements using a combination of heuristic rules and an ontology derived from Wikidata. Those replacement options are hierarchically structured and cover various types of personal identifiers. Using this approach, we extend a recently released text sanitization dataset with manually selected replacements. The outcome of this data collection shows that the approach is able to suggest appropriate replacement options for most text spans.","2023-05","2025-09-10 13:17:21","2025-09-10 13:17:21","","292–300","","","","","","","","","","","University of Tartu Library","Tórshavn, Faroe Islands","","","","","","","","","","","","","","Alumäe, Tanel; Fishel, Mark","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KX9ZSY9Y","conferencePaper","2023","Mille, Simon; Uí Dhonnchadha, Elaine; Cassidy, Lauren; Davis, Brian; Dasiopoulou, Stamatia; Belz, Anya","Generating Irish Text with a Flexible Plug-and-Play Architecture","Proceedings of the 2nd Workshop on Pattern-based Approaches to NLP in the Age of Deep Learning","","","10.18653/v1/2023.pandl-1.4","https://aclanthology.org/2023.pandl-1.4/","In this paper, we describe M-FleNS, a multilingual flexible plug-and-play architecture designed to accommodate neural and symbolic modules, and initially instantiated with rule-based modules. We focus on using M-FleNS for the specific purpose of building new resources for Irish, a language currently under-represented in the NLP landscape. We present the general M-FleNS framework and how we use it to build an Irish Natural Language Generation system for verbalising part of the DBpedia ontology and building a multilayered dataset with rich linguistic annotations. Via automatic and human assessments of the output texts we show that with very limited resources we are able to create a system that reaches high levels of fluency and semantic accuracy, while having very low energy and memory requirements.","2023-12","2025-09-10 13:17:21","2025-09-10 13:17:21","","25–42","","","","","","","","","","","Association for Computational Linguistics","Singapore","","","","","","","","","","","","","","Surdeanu, Mihai; Riloff, Ellen; Chiticariu, Laura; Frietag, Dayne; Hahn-Powell, Gus; Morrison, Clayton T.; Noriega-Atala, Enrique; Sharp, Rebecca; Valenzuela-Escarcega, Marco","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GFQ85QFD","conferencePaper","2023","Aleksic, Vera; Brems, Mona; Mathes, Anna; Bertele, Theresa","Lexicon-Driven Automatic Sentence Generation for the Skills Section in a Job Posting","Proceedings of the 14th International Conference on Recent Advances in Natural Language Processing","","","","https://aclanthology.org/2023.ranlp-1.4/","This paper presents a sentence generation pipeline as implemented on the online job board Stepstone. The goal is to automatically create a set of sentences for the candidate profile and the task description sections in a job ad, related to a given input skill. They must cover two different “tone of voice” variants in German (Du, Sie), three experience levels (junior, mid, senior), and two optionality values (skill is mandatory or optional/nice to have). The generation process considers the difference between soft skills, natural language competencies and hard skills, as well as more specific sub-categories such as IT skills, programming languages and similar. To create grammatically consistent text, morphosyntactic features from the proprietary skill ontology and lexicon are consulted. The approach is a lexicon-driven generation process that compares all lexical features of the new input skills with the ones already added to the sentence database and creates new sentences according to the corresponding templates.","2023-09","2025-09-10 13:17:21","2025-09-10 13:17:21","","32–40","","","","","","","","","","","INCOMA Ltd., Shoumen, Bulgaria","Varna, Bulgaria","","","","","","","","","","","","","","Mitkov, Ruslan; Angelova, Galia","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5ECTIADC","conferencePaper","2023","Hristov, Anton; Ivanov, Petar; Aksenova, Anna; Asamov, Tsvetan; Gyurov, Pavlin; Primov, Todor; Boytcheva, Svetla","Clinical Text Classification to SNOMED CT Codes Using Transformers Trained on Linked Open Medical Ontologies","Proceedings of the 14th International Conference on Recent Advances in Natural Language Processing","","","","https://aclanthology.org/2023.ranlp-1.57/","We present an approach for medical text coding with SNOMED CT. Our approach uses publicly available linked open data from terminologies and ontologies as training data for the algorithms. We claim that even small training corpora made of short text snippets can be used to train models for the given task. We propose a method based on transformers enhanced with clustering and filtering of the candidates. Further, we adopt a classical machine learning approach - support vector classification (SVC) using transformer embeddings. The resulting approach proves to be more accurate than the predictions given by Large Language Models. We evaluate on a dataset generated from linked open data for SNOMED codes related to morphology and topography for four use cases. Our transformers-based approach achieves an F1-score of 0.82 for morphology and 0.99 for topography codes. Further, we validate the applicability of our approach in a clinical context using labelled real clinical data that are not used for model training.","2023-09","2025-09-10 13:17:21","2025-09-10 13:17:21","","519–526","","","","","","","","","","","INCOMA Ltd., Shoumen, Bulgaria","Varna, Bulgaria","","","","","","","","","","","","","","Mitkov, Ruslan; Angelova, Galia","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7H6K3VNT","conferencePaper","2023","Conceição, Sofia I. R.; F. Sousa, Diana; Silvestre, Pedro; Couto, Francisco M","lasigeBioTM at SemEval-2023 Task 7: Improving Natural Language Inference Baseline Systems with Domain Ontologies","Proceedings of the 17th International Workshop on Semantic Evaluation (SemEval-2023)","","","10.18653/v1/2023.semeval-1.2","https://aclanthology.org/2023.semeval-1.2/","Clinical Trials Reports (CTRs) contain highly valuable health information from which Natural Language Inference (NLI) techniques determine if a given hypothesis can be inferred from a given premise. CTRs are abundant with domain terminology with particular terms that are difficult to understand without prior knowledge. Thus, we proposed to use domain ontologies as a source of external knowledge that could help with the inference process in theSemEval-2023 Task 7: Multi-evidence Natural Language Inference for Clinical Trial Data (NLI4CT). This document describes our participation in subtask 1: Textual Entailment, where Ontologies, NLP techniques, such as tokenization and named-entity recognition, and rule-based approaches are all combined in our approach. We were able to show that inputting annotations from domain ontologies improved the baseline systems.","2023-07","2025-09-10 13:17:21","2025-09-10 13:17:21","","10–15","","","","","","","","","","","Association for Computational Linguistics","Toronto, Canada","","","","","","","","","","","","","","Ojha, Atul Kr.; Doğruöz, A. Seza; Da San Martino, Giovanni; Tayyar Madabushi, Harish; Kumar, Ritesh; Sartori, Elisa","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"E73L3DWH","conferencePaper","2023","Roy Dipta, Shubhashis; Rezaee, Mehdi; Ferraro, Francis","Semantically-informed Hierarchical Event Modeling","Proceedings of the 12th Joint Conference on Lexical and Computational Semantics (*SEM 2023)","","","10.18653/v1/2023.starsem-1.31","https://aclanthology.org/2023.starsem-1.31/","Prior work has shown that coupling sequential latent variable models with semantic ontological knowledge can improve the representational capabilities of event modeling approaches. In this work, we present a novel, doubly hierarchical, semi-supervised event modeling framework that provides structural hierarchy while also accounting for ontological hierarchy. Our approach consistsof multiple layers of structured latent variables, where each successive layer compresses and abstracts the previous layers. We guide this compression through the injection of structured ontological knowledge that is defined at the type level of events: importantly, our model allows for partial injection of semantic knowledge and it does not depend on observing instances at any particular level of the semantic ontology. Across two different datasets and four different evaluation metrics, we demonstrate that our approach is able to out-perform the previous state-of-the-art approaches by up to 8.5%, demonstrating the benefits of structured and semantic hierarchical knowledge for event modeling.","2023-07","2025-09-10 13:17:21","2025-09-10 13:17:21","","353–369","","","","","","","","","","","Association for Computational Linguistics","Toronto, Canada","","","","","","","","","","","","","","Palmer, Alexis; Camacho-collados, Jose","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TRY9MQ99","journalArticle","2023","Chen, Zhi; Liu, Yuncong; Chen, Lu; Zhu, Su; Wu, Mengyue; Yu, Kai","OPAL: Ontology-Aware Pretrained Language Model for End-to-End Task-Oriented Dialogue","Transactions of the Association for Computational Linguistics","","","10.1162/tacl_a_00534","https://aclanthology.org/2023.tacl-1.5/","This paper presents an ontology-aware pretrained language model (OPAL) for end-to-end task-oriented dialogue (TOD). Unlike chit-chat dialogue models, task-oriented dialogue models fulfill at least two task-specific modules: Dialogue state tracker (DST) and response generator (RG). The dialogue state consists of the domain-slot-value triples, which are regarded as the user's constraints to search the domain-related databases. The large-scale task-oriented dialogue data with the annotated structured dialogue state usually are inaccessible. It prevents the development of the pretrained language model for the task-oriented dialogue. We propose a simple yet effective pretraining method to alleviate this problem, which consists of two pretraining phases. The first phase is to pretrain on large-scale contextual text data, where the structured information of the text is extracted by the information extracting tool. To bridge the gap between the pretraining method and downstream tasks, we design two pretraining tasks: ontology-like triple recovery and next-text generation, which simulates the DST and RG, respectively. The second phase is to fine-tune the pretrained model on the TOD data. The experimental results show that our proposed method achieves an exciting boost and obtains competitive performance even without any TOD data on CamRest676 and MultiWOZ benchmarks.","2023","2025-09-10 13:17:21","2025-09-10 13:17:21","","68–84","","","11","","","","","","","","","","","","","","","","","Place: Cambridge, MA Publisher: MIT Press","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"62NVXPA4","conferencePaper","2023","Fučíková, Eva; Hajič, Jan; Urešová, Zdeňka","Corpus-Based Multilingual Event-type Ontology: Annotation Tools and Principles","Proceedings of the 21st International Workshop on Treebanks and Linguistic Theories (TLT, GURT/SyntaxFest 2023)","","","","https://aclanthology.org/2023.tlt-1.1/","In the course of building a multilingual Event-type Ontology resource called SynSemClass, it was necessary to provide the maintainers and the annotators with a set of tools to facilitate their job, achieve data format consistency, and in general obtain high-quality data. We have adapted a previously existing tool (Urešová et al., 2018b), developed to assist the work in capturing bilingual synonymy. This tool needed to be both substantially expanded with some new features and fundamentally changed in the context of developing the resource for more languages, which necessarily is to be done in parallel. We are thus presenting here the tool, the new data structure design which had to change at the same time, and the associated workflow.","2023-03","2025-09-10 13:17:21","2025-09-10 13:17:21","","1–10","","","","","","","","","","","Association for Computational Linguistics","Washington, D.C.","","","","","","","","","","","","","","Dakota, Daniel; Evang, Kilian; Kübler, Sandra; Levin, Lori","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SPHP9282","conferencePaper","2023","Fernández-Alcaina, Cristina; Fučíková, Eva; Hajič, Jan; Urešová, Zdeňka","Spanish Verbal Synonyms in the SynSemClass Ontology","Proceedings of the 21st International Workshop on Treebanks and Linguistic Theories (TLT, GURT/SyntaxFest 2023)","","","","https://aclanthology.org/2023.tlt-1.2/","This paper presents ongoing work in the expansion of the multilingual semantic event-type ontology SynSemClass (Czech-English-German) to include Spanish. As in previous versions of the lexicon, Spanish verbal synonyms have been collected from a sentence-aligned parallel corpus and classified into classes based on their syntactic-semantic properties. Each class member is linked to a number of syntactic and/or semantic resources specific to each language, thus enriching the annotation and enabling interoperability. This paper describes the procedure for the data extraction and annotation of Spanish verbal synonyms in the lexicon.","2023-03","2025-09-10 13:17:21","2025-09-10 13:17:21","","11–20","","","","","","","","","","","Association for Computational Linguistics","Washington, D.C.","","","","","","","","","","","","","","Dakota, Daniel; Evang, Kilian; Kübler, Sandra; Levin, Lori","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4LE6XIDC","conferencePaper","2023","Fischer, Hanna; Engsterhold, Robert","Reconstructing Language History by Using a Phonological Ontology. An Analysis of German Surnames","Tenth Workshop on NLP for Similar Languages, Varieties and Dialects (VarDial 2023)","","","10.18653/v1/2023.vardial-1.10","https://aclanthology.org/2023.vardial-1.10/","This paper applies the ontology-baseddialectometric technique of Engsterhold(2020) to surnames. The method wasoriginally developed for phonetic analyses. However, as will be shown, it is also suitedfor the study of graphemic representations. Based on data from the German SurnameAtlas (DFA), the method is optimized forgraphemic analysis and illustrated with anexample case.","2023-05","2025-09-10 13:17:21","2025-09-10 13:17:21","","104–112","","","","","","","","","","","Association for Computational Linguistics","Dubrovnik, Croatia","","","","","","","","","","","","","","Scherrer, Yves; Jauhiainen, Tommi; Ljubešić, Nikola; Nakov, Preslav; Tiedemann, Jörg; Zampieri, Marcos","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"S6ZP4ACJ","conferencePaper","2024","Hu, Yibo; Skorupa Parolin, Erick; Khan, Latifur; Brandt, Patrick; Osorio, Javier; D'Orazio, Vito","Leveraging Codebook Knowledge with NLI and ChatGPT for Zero-Shot Political Relation Classification","Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)","","","10.18653/v1/2024.acl-long.35","https://aclanthology.org/2024.acl-long.35/","Is it possible accurately classify political relations within evolving event ontologies without extensive annotations? This study investigates zero-shot learning methods that use expert knowledge from existing annotation codebook, and evaluates the performance of advanced ChatGPT (GPT-3.5/4) and a natural language inference (NLI)-based model called ZSP. ChatGPT uses codebook's labeled summaries as prompts, whereas ZSP breaks down the classification task into context, event mode, and class disambiguation to refine task-specific hypotheses. This decomposition enhances interpretability, efficiency, and adaptability to schema changes. The experiments reveal ChatGPT's strengths and limitations, and crucially show ZSP's outperformance of dictionary-based methods and its competitive edge over some supervised models. These findings affirm the value of ZSP for validating event records and advancing ontology development. Our study underscores the efficacy of leveraging transfer learning and existing domain expertise to enhance research efficiency and scalability.","2024-08","2025-09-10 13:17:21","2025-09-10 13:17:21","","583–603","","","","","","","","","","","Association for Computational Linguistics","Bangkok, Thailand","","","","","","","","","","","","","","Ku, Lun-Wei; Martins, Andre; Srikumar, Vivek","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TH7WB7DD","conferencePaper","2024","Cai, Zefan; Kung, Po-Nien; Suvarna, Ashima; Ma, Mingyu; Bansal, Hritik; Chang, Baobao; Brantingham, P. Jeffrey; Wang, Wei; Peng, Nanyun","Improving Event Definition Following For Zero-Shot Event Detection","Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)","","","10.18653/v1/2024.acl-long.157","https://aclanthology.org/2024.acl-long.157/","Existing approaches on zero-shot event detection usually train models on datasets annotated with known event types, and prompt them with unseen event definitions. These approaches yield sporadic successes, yet generally fall short of expectations.In this work, we aim to improve zero-shot event detection by training models to better follow event definitions. We hypothesize that a diverse set of event types and definitions are the key for models to learn to follow event definitions while existing event extraction datasets focus on annotating many high-quality examples for a few event types. To verify our hypothesis, we construct an automatically generated Diverse Event Definition (DivED) dataset and conduct comparative studies. Our experiments reveal that a large number of event types (200) and diverse event definitions can significantly boost event extraction performance; on the other hand, the performance does not scale with over ten examples per event type.Beyond scaling, we incorporate event ontology information and hard-negative samples during training, further boosting the performance. Based on these findings, we fine-tuned a LLaMA-2-7B model on our DivED dataset, yielding performance that surpasses SOTA large language models like GPT-3.5 across three open benchmarks on zero-shot event detection.","2024-08","2025-09-10 13:17:21","2025-09-10 13:17:21","","2842–2863","","","","","","","","","","","Association for Computational Linguistics","Bangkok, Thailand","","","","","","","","","","","","","","Ku, Lun-Wei; Martins, Andre; Srikumar, Vivek","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LPF84S7P","conferencePaper","2024","Wen, Yilin; Wang, Zifeng; Sun, Jimeng","MindMap: Knowledge Graph Prompting Sparks Graph of Thoughts in Large Language Models","Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)","","","10.18653/v1/2024.acl-long.558","https://aclanthology.org/2024.acl-long.558/","Large language models (LLMs) have achieved remarkable performance in natural language understanding and generation tasks. However, they often suffer from limitations such as difficulty in incorporating new knowledge, generating hallucinations, and explaining their reasoning process. To address these challenges, we propose a novel prompting pipeline, named MindMap, that leverages knowledge graphs (KGs) to enhance LLMs' inference and transparency. Our method enables LLMs to comprehend KG inputs and infer with a combination of implicit and external knowledge. Moreover, our method elicits the mind map of LLMs, which reveals their reasoning pathways based on the ontology of knowledge. We evaluate our method on diverse question & answering tasks, especially in medical domains, and show significant improvements over baselines. We also introduce a new hallucination evaluation benchmark and analyze the effects of different components of our method. Our results demonstrate the effectiveness and robustness of our method in merging knowledge from LLMs and KGs for combined inference.","2024-08","2025-09-10 13:17:21","2025-09-10 13:17:21","","10370–10388","","","","","","","","","","","Association for Computational Linguistics","Bangkok, Thailand","","","","","","","","","","","","","","Ku, Lun-Wei; Martins, Andre; Srikumar, Vivek","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FFVQIENC","conferencePaper","2024","Qian, Ming","Automating Idiom Translation with Cross-Lingual Natural Language Generation Grounded In Semantic Analyses Using Large Language Models","Proceedings of the 16th Conference of the Association for Machine Translation in the Americas (Volume 2: Presentations)","","","","https://aclanthology.org/2024.amta-presentations.7/","Idioms exhibit varying degrees of semantic transparency, making their translation challenging. Cross-language differences in idiom usage and connotations add complexity. Using a large language modeling (LLM) approach, we automate Chinese-to-English idiom translation in three steps: (1) Semantic analysis of Chinese idioms using ontology or FrameNet to identify key concepts/relationships like action, purpose, outcome, and context. (2) Generation of multi-word English expressions reflecting these concepts. (3) Selection of the top English idiom candidate that closely matches the Chinese idiom's meaning. Applied to examples like `破釜沉舟', `刀山火海', and `抛砖引玉', our method performs on par with human experts. The semantic reasoning approach enhances transparency in LLM decisions, simulating logical inferences over the semantic framework.","2024-09","2025-09-10 13:17:21","2025-09-10 13:17:21","","95–115","","","","","","","","","","","Association for Machine Translation in the Americas","Chicago, USA","","","","","","","","","","","","","","Martindale, Marianna; Campbell, Janice; Savenkov, Konstantin; Goel, Shivali","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NYXX7V2G","conferencePaper","2024","Shlyk, Darya; Groza, Tudor; Mesiti, Marco; Montanelli, Stefano; Cavalleri, Emanuele","REAL: A Retrieval-Augmented Entity Linking Approach for Biomedical Concept Recognition","Proceedings of the 23rd Workshop on Biomedical Natural Language Processing","","","10.18653/v1/2024.bionlp-1.29","https://aclanthology.org/2024.bionlp-1.29/","Large Language Models (LLMs) offer an appealing alternative to training dedicated models for many Natural Language Processing (NLP) tasks. However, outdated knowledge and hallucination issues can be major obstacles in their application in knowledge-intensive biomedical scenarios. In this study, we consider the task of biomedical concept recognition (CR) from unstructured scientific literature and explore the use of Retrieval Augmented Generation (RAG) to improve accuracy and reliability of the LLM-based biomedical CR. Our approach, named REAL (Retrieval Augmented Entity Linking), combines the generative capabilities of LLMs with curated knowledge bases to automatically annotate natural language texts with concepts from bio-ontologies. By applying REAL to benchmark corpora on phenotype concept recognition, we show its effectiveness in improving LLM-based CR performance. This research highlights the potential of combining LLMs with external knowledge sources to advance biomedical text processing.","2024-08","2025-09-10 13:17:21","2025-09-10 13:17:21","","380–389","","","","","","","","","","","Association for Computational Linguistics","Bangkok, Thailand","","","","","","","","","","","","","","Demner-Fushman, Dina; Ananiadou, Sophia; Miwa, Makoto; Roberts, Kirk; Tsujii, Junichi","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GFTPK7IS","conferencePaper","2024","El Khettari, Oumaima; Nishida, Noriki; Liu, Shanshan; Munne, Rumana Ferdous; Yamagata, Yuki; Quiniou, Solen; Chaffron, Samuel; Matsumoto, Yuji","Mention-Agnostic Information Extraction for Ontological Annotation of Biomedical Articles","Proceedings of the 23rd Workshop on Biomedical Natural Language Processing","","","10.18653/v1/2024.bionlp-1.37","https://aclanthology.org/2024.bionlp-1.37/","Biomedical information extraction is crucial for advancing research, enhancing healthcare, and discovering treatments by efficiently analyzing extensive data. Given the extensive amount of biomedical data available, automated information extraction methods are necessary due to manual extraction's labor-intensive, expertise-dependent, and costly nature. In this paper, we propose a novel two-stage system for information extraction where we annotate biomedical articles based on a specific ontology (HOIP). The major challenge is annotating relation between biomedical processes often not explicitly mentioned in text articles. Here, we first predict the candidate processes and then determine the relationships between these processes. The experimental results show promising outcomes in mention-agnostic process identification using Large Language Models (LLMs). In relation classification, BERT-based supervised models still outperform LLMs significantly. The end-to-end evaluation results suggest the difficulty of this task and room for improvement in both process identification and relation classification.","2024-08","2025-09-10 13:17:21","2025-09-10 13:17:21","","457–473","","","","","","","","","","","Association for Computational Linguistics","Bangkok, Thailand","","","","","","","","","","","","","","Demner-Fushman, Dina; Ananiadou, Sophia; Miwa, Makoto; Roberts, Kirk; Tsujii, Junichi","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KXVD3364","conferencePaper","2024","Achara, Akshit; Sasidharan, Sanand; N, Gagan","Efficient Biomedical Entity Linking: Clinical Text Standardization with Low-Resource Techniques","Proceedings of the 23rd Workshop on Biomedical Natural Language Processing","","","10.18653/v1/2024.bionlp-1.40","https://aclanthology.org/2024.bionlp-1.40/","Clinical text is rich in information, with mentions of treatment, medication and anatomy among many other clinical terms. Multiple terms can refer to the same core concepts which can be referred as a clinical entity. Ontologies like the Unified Medical Language System (UMLS) are developed and maintained to store millions of clinical entities including the definitions, relations and other corresponding information. These ontologies are used for standardization of clinical text by normalizing varying surface forms of a clinical term through Biomedical entity linking. With the introduction of transformer-based language models, there has been significant progress in Biomedical entity linking. In this work, we focus on learning through synonym pairs associated with the entities. As compared to the existing approaches, our approach significantly reduces the training data and resource consumption. Moreover, we propose a suite of context-based and context-less reranking techniques for performing the entity disambiguation. Overall, we achieve similar performance to the state-of-the-art zero-shot and distant supervised entity linking techniques on the Medmentions dataset, the largest annotated dataset on UMLS, without any domain-based training. Finally, we show that retrieval performance alone might not be sufficient as an evaluation metric and introduce an article level quantitative and qualitative analysis to reveal further insights on the performance of entity linking methods.","2024-08","2025-09-10 13:17:21","2025-09-10 13:17:21","","493–505","","","","","","","","","","","Association for Computational Linguistics","Bangkok, Thailand","","","","","","","","","","","","","","Demner-Fushman, Dina; Ananiadou, Sophia; Miwa, Makoto; Roberts, Kirk; Tsujii, Junichi","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MCQVGNZ3","conferencePaper","2024","Frei, Johann; Kramer, Frank","Creating Ontology-annotated Corpora from Wikipedia for Medical Named-entity Recognition","Proceedings of the 23rd Workshop on Biomedical Natural Language Processing","","","10.18653/v1/2024.bionlp-1.47","https://aclanthology.org/2024.bionlp-1.47/","Acquiring annotated corpora for medical NLP is challenging due to legal and privacy constraints and costly annotation efforts, and using annotated public datasets may do not align well to the desired target application in terms of annotation style or language. We investigate the approach of utilizing Wikipedia and WikiData jointly to acquire an unsupervised annotated corpus for named-entity recognition (NER). By controlling the annotation ruleset through WikiData's ontology, we extract custom-defined annotations and dynamically impute weak annotations by an adaptive loss scaling. Our validation on German medication detection datasets yields competitive results. The entire pipeline only relies on open models and data resources, enabling reproducibility and open sharing of models and corpora. All relevant assets are shared on GitHub.","2024-08","2025-09-10 13:17:21","2025-09-10 13:17:21","","570–579","","","","","","","","","","","Association for Computational Linguistics","Bangkok, Thailand","","","","","","","","","","","","","","Demner-Fushman, Dina; Ananiadou, Sophia; Miwa, Makoto; Roberts, Kirk; Tsujii, Junichi","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FDTYNKDA","conferencePaper","2024","Torri, Vittorio; Mazzucato, Sara; Dalmiani, Stefano; Paradossi, Umberto; Passino, Claudio; Moccia, Sara; Micera, Silvestro; Ieva, Francesca","Structuring Clinical Notes of Italian ST-elevation Myocardial Infarction Patients","Proceedings of the First Workshop on Patient-Oriented Language Processing (CL4Health) @ LREC-COLING 2024","","","","https://aclanthology.org/2024.cl4health-1.5/","In recent years, it has become common for patients to get full access to their Electronic Health Records (EHRs), thanks to the advancements in the EHRs systems of many healthcare providers. While this access empowers patients and doctors with comprehensive and real-time health information, it also introduces new challenges, in particular due to the unstructured nature of much of the information within EHRs. To address this, we propose a pipeline to structure clinical notes, providing them with a clear and concise overview of their health data and its longitudinal evolution, also allowing clinicians to focus more on patient care during consultations. In this paper, we present preliminary results on extracting structured information from anamneses of patients diagnosed with ST-Elevation Myocardial Infarction from an Italian hospital. Our pipeline exploits text classification models to extract relevant clinical variables, comparing rule-based, recurrent neural network and BERT-based models. While various approaches utilized ontologies or knowledge graphs for Italian data, our work represents the first attempt to develop this type of pipeline. The results for the extraction of most variables are satisfactory (f1-score \ensuremath> 0.80), with the exception of the most rare values of certain variables, for which we propose future research directions to investigate.","2024-05","2025-09-10 13:17:21","2025-09-10 13:17:21","","37–43","","","","","","","","","","","ELRA and ICCL","Torino, Italia","","","","","","","","","","","","","","Demner-Fushman, Dina; Ananiadou, Sophia; Thompson, Paul; Ondov, Brian","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ICEMJNQB","conferencePaper","2024","Liu, Xingyu; Segonne, Vincent; Mannion, Aidan; Schwab, Didier; Goeuriot, Lorraine; Portet, François","MedDialog-FR: A French Version of the MedDialog Corpus for Multi-label Classification and Response Generation Related to Women's Intimate Health","Proceedings of the First Workshop on Patient-Oriented Language Processing (CL4Health) @ LREC-COLING 2024","","","","https://aclanthology.org/2024.cl4health-1.21/","This article presents MedDialog-FR, a large publicly available corpus of French medical conversations for the medical domain. Motivated by the lack of French dialogue corpora for data-driven dialogue systems and the paucity of available information related to women's intimate health, we introduce an annotated corpus of question-and-answer dialogues between a real patient and a real doctor concerning women's intimate health. The corpus is composed of about 20,000 dialogues automatically translated from the English version of MedDialog-EN. The corpus test set is composed of 1,400 dialogues that have been manually post-edited and annotated with 22 categories from the UMLS ontology. We also fine-tuned state-of-the-art reference models to automatically perform multi-label classification and response generation to give an initial performance benchmark and highlight the difficulty of the tasks.","2024-05","2025-09-10 13:17:21","2025-09-10 13:17:21","","173–183","","","","","","","","","","","ELRA and ICCL","Torino, Italia","","","","","","","","","","","","","","Demner-Fushman, Dina; Ananiadou, Sophia; Thompson, Paul; Ondov, Brian","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SMUWILRJ","conferencePaper","2024","Hartendorp, Fons; Seinen, Tom; van Mulligen, Erik; Verberne, Suzan","Biomedical Entity Linking for Dutch: Fine-tuning a Self-alignment BERT Model on an Automatically Generated Wikipedia Corpus","Proceedings of the First Workshop on Patient-Oriented Language Processing (CL4Health) @ LREC-COLING 2024","","","","https://aclanthology.org/2024.cl4health-1.31/","Biomedical entity linking, a main component in automatic information extraction from health-related texts, plays a pivotal role in connecting textual entities (such as diseases, drugs and body parts mentioned by patients) to their corresponding concepts in a structured biomedical knowledge base. The task remains challenging despite recent developments in natural language processing. This report presents the first evaluated biomedical entity linking model for the Dutch language. We use MedRoBERTa.nl as basemodel and perform second-phase pretraining through self-alignment on a Dutch biomedical ontology extracted from the UMLS and Dutch SNOMED. We derive a corpus from Wikipedia of ontology-linked Dutch biomedical entities in context and fine-tune our model on this dataset. We evaluate our model on the Dutch portion of the Mantra GSC-corpus and achieve 54.7% classification accuracy and 69.8% 1-distance accuracy. We then perform a case study on a collection of unlabeled, patient-support forum data and show that our model is hampered by the limited quality of the preceding entity recognition step. Manual evaluation of small sample indicates that of the correctly extracted entities, around 65% is linked to the correct concept in the ontology. Our results indicate that biomedical entity linking in a language other than English remains challenging, but our Dutch model can be used to for high-level analysis of patient-generated text.","2024-05","2025-09-10 13:17:21","2025-09-10 13:17:21","","253–263","","","","","","","","","","","ELRA and ICCL","Torino, Italia","","","","","","","","","","","","","","Demner-Fushman, Dina; Ananiadou, Sophia; Thompson, Paul; Ondov, Brian","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"K9DCKLU7","conferencePaper","2024","Penkov, Stanislav","Mitigating Hallucinations in Large Language Models via Semantic Enrichment of Prompts: Insights from BioBERT and Ontological Integration","Proceedings of the Sixth International Conference on Computational Linguistics in Bulgaria (CLIB 2024)","","","","https://aclanthology.org/2024.clib-1.30/","The advent of Large Language Models (LLMs) has been transformative for natural language processing, yet their tendency to produce “hallucinations”—outputs that are factually incorrect or entirely fabricated— remains a significant hurdle. This paper introduces a proactive methodology for reducing hallucinations by strategically enriching LLM prompts. This involves identifying key entities and contextual cues from varied domains and integrating this information into the LLM prompts to guide the model towards more accurate and relevant responses. Leveraging examples from BioBERT for biomedical entity recognition and ChEBI for chemical ontology, we illustrate a broader approach that encompasses semantic prompt enrichment as a versatile tool for enhancing LLM output accuracy. By examining the potential of semantic and ontological enrichment in diverse contexts, we aim to present a scalable strategy for improving the reliability of AI-generated content, thereby contributing to the ongoing efforts to refine LLMs for a wide range of applications.","2024-09","2025-09-10 13:17:21","2025-09-10 13:17:21","","272–276","","","","","","","","","","","Department of Computational Linguistics, Institute for Bulgarian Language, Bulgarian Academy of Sciences","Sofia, Bulgaria","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AHDCVJVL","conferencePaper","2024","Usmanova, Aida; Usbeck, Ricardo","Structuring Sustainability Reports for Environmental Standards with LLMs guided by Ontology","Proceedings of the 1st Workshop on Natural Language Processing Meets Climate Change (ClimateNLP 2024)","","","10.18653/v1/2024.climatenlp-1.13","https://aclanthology.org/2024.climatenlp-1.13/","Following the introduction of the European Sustainability Reporting Standard (ESRS), companies will have to adapt to a new policy and provide mandatory sustainability reports. However, implementing such reports entails a challenge, such as the comprehension of a large number of textual information from various sources. This task can be accelerated by employing Large Language Models (LLMs) and ontologies to effectively model the domain knowledge. In this study, we extended an existing ontology to model ESRS Topical Standard for disclosure. The developed ontology would enable automated reasoning over the data and assist in constructing Knowledge Graphs (KGs). Moreover, the proposed ontology extension would also help to identify gaps in companies' sustainability reports with regard to the ESRS requirements.Additionally, we extracted knowledge from corporate sustainability reports via LLMs guided with a proposed ontology and developed their KG representation.","2024-08","2025-09-10 13:17:21","2025-09-10 13:17:21","","168–177","","","","","","","","","","","Association for Computational Linguistics","Bangkok, Thailand","","","","","","","","","","","","","","Stammbach, Dominik; Ni, Jingwei; Schimanski, Tobias; Dutia, Kalyan; Singh, Alok; Bingler, Julia; Christiaen, Christophe; Kushwaha, Neetu; Muccione, Veruska; A. Vaghefi, Saeid; Leippold, Markus","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YSGCGHQ6","conferencePaper","2024","De Deyne, Simon; Liu, Chunhua; Frermann, Lea","Can GPT-4 Recover Latent Semantic Relational Information from Word Associations? A Detailed Analysis of Agreement with Human-annotated Semantic Ontologies.","Proceedings of the Workshop on Cognitive Aspects of the Lexicon @ LREC-COLING 2024","","","","https://aclanthology.org/2024.cogalex-1.8/","Word associations, i.e., spontaneous responses to a cue word, provide not only a window into the human mental lexicon but have also been shown to be a repository of common-sense knowledge and can underpin efforts in lexicography and the construction of dictionaries. Especially the latter tasks require knowledge about the relations underlying the associations (e.g., Taxonomic vs. Situational); however, to date, there is neither an established ontology of relations nor an effective labelling paradigm. Here, we test GPT-4's ability to infer semantic relations for human-produced word associations. We use four human-labelled data sets of word associations and semantic features, with differing relation inventories and various levels of annotator agreement. We directly prompt GPT-4 with detailed relation definitions without further fine-tuning or training. Our results show that while GPT-4 provided a good account of higher-level classifications (e.g. Taxonomic vs Situational), prompting instructions alone cannot obtain similar performance for detailed classifications (e.g. superordinate, subordinate or coordinate relations) despite high agreement among human annotators. This suggests that latent relations can at least be partially recovered from word associations and highlights ways in which LLMs could be improved and human annotation protocols could adapted to reduce coding ambiguity.","2024-05","2025-09-10 13:17:21","2025-09-10 13:17:21","","68–78","","","","","","","","","","","ELRA and ICCL","Torino, Italia","","","","","","","","","","","","","","Zock, Michael; Chersoni, Emmanuele; Hsu, Yu-Yin; de Deyne, Simon","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HIMT2R9Y","conferencePaper","2024","Cartier, Emmanuel; Peetermans, Emile","Combining Deep Learning Models and Lexical Linked Data: Some Insights from the Development of a Multilingual News Named Entity Recognition and Linking Dataset","Proceedings of the Workshop on Deep Learning and Linked Data (DLnLD) @ LREC-COLING 2024","","","","https://aclanthology.org/2024.dlnld-1.3/","This paper presents the methodology and outcomes of a Named Entity Recognition and Linking multilingual news benchmark that leverages both Deep learning approaches by using a fine-tuned transformer model to detect mentions of persons, locations and organisations in text, and Linguistic Linked Open Data, through the use of Wikidata to disambiguate mentions and link them to ontology entries. It shows all the advantages of combining both approaches, not only for building the benchmark but also for fine-tuning detection models. We also insist on several perspectives of research to improve the accuracy of a combining system and go further on leveraging the complementary approaches.","2024-05","2025-09-10 13:17:21","2025-09-10 13:17:21","","31–44","","","","","","","","","","","ELRA and ICCL","Torino, Italia","","","","","","","","","","","","","","Sérasset, Gilles; Oliveira, Hugo Gonçalo; Oleskeviciene, Giedre Valunaite","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"773Z7XFP","conferencePaper","2024","Shichman, Mollie Frances; Bonial, Claire; Hudson, Taylor A.; Blodgett, Austin; Ferraro, Francis; Rudinger, Rachel","PropBank-Powered Data Creation: Utilizing Sense-Role Labelling to Generate Disaster Scenario Data","Proceedings of the Fifth International Workshop on Designing Meaning Representations @ LREC-COLING 2024","","","","https://aclanthology.org/2024.dmr-1.1/","For human-robot dialogue in a search-and-rescue scenario, a strong knowledge of the conditions and objects a robot will face is essential for effective interpretation of natural language instructions. In order to utilize the power of large language models without overwhelming the limited storage capacity of a robot, we propose PropBank-Powered Data Creation. PropBank-Powered Data Creation is an expert-in-the-loop data generation pipeline which creates training data for disaster-specific language models. We leverage semantic role labeling and Rich Event Ontology resources to efficiently develop seed sentences for fine-tuning a smaller, targeted model that could operate onboard a robot for disaster relief. We developed 32 sentence templates, which we used to make 2 seed datasets of 175 instructions for earthquake search and rescue and train derailment response. We further leverage our seed datasets as evaluation data to test our baseline fine-tuned models.","2024-05","2025-09-10 13:17:21","2025-09-10 13:17:21","","1–10","","","","","","","","","","","ELRA and ICCL","Torino, Italia","","","","","","","","","","","","","","Bonial, Claire; Bonn, Julia; Hwang, Jena D.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GI2KASW2","conferencePaper","2024","Moneglia, Massimo; Varvara, Rossella","Aspect Variability and the Annotation of Aspect in the IMAGACT Ontology of Action","Proceedings of the Fifth International Workshop on Designing Meaning Representations @ LREC-COLING 2024","","","","https://aclanthology.org/2024.dmr-1.2/","This paper highlights some theoretical and quantitative issues related to the representation and annotation of aspectual meaning in the IMAGACT corpus-based multimodal ontology of action. Given the multimodal nature of this ontology, in which actions are represented through both prototypical visual scenes and linguistic captions, the annotation of aspect in this resource allows us to draw some important considerations about the relation between aspectual meaning and eventualities. The annotation procedure is reported and quantitative data show that, both in the English and Italian corpora, many verbs present aspectual variation, and many eventualities can be represented by locally equivalent verbs with different aspect. The reason why verb aspectual class may vary is investigated. Our analysis makes once more evident that verbs may vary their aspectual properties with respect not only to their argument structure but, more precisely, to the inner qualities of the eventualities they express. Crucially, when eventualities are expressed by equivalent verbs with different aspectual properties, the verbs put on focus different parts of the structure of the eventuality.","2024-05","2025-09-10 13:17:21","2025-09-10 13:17:21","","11–19","","","","","","","","","","","ELRA and ICCL","Torino, Italia","","","","","","","","","","","","","","Bonial, Claire; Bonn, Julia; Hwang, Jena D.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AHFIFZP2","conferencePaper","2024","Winiwarter, Werner","VOLARE - Visual Ontological LAnguage REpresentation","Proceedings of the Fifth International Workshop on Designing Meaning Representations @ LREC-COLING 2024","","","","https://aclanthology.org/2024.dmr-1.7/","In this paper, we introduce a novel meaning representation, which is based on AMR but extends it towards a visual ontological representation. We visualize concepts by representative images, and roles by emojis. All concepts are identified either by PropBank rolesets, Wikipedia page titles, WordNet synsets, or Wikidata lexeme senses. We have developed a Web-based annotation environment enabled by augmented browsing and interactive diagramming. As first application, we have implemented a multilingual annotation solution by using English as anchor language and comparing it with French and Japanese language versions. Therefore, we have extended our representation by a translation deviation annotation to document the differences between the language versions. The intended user groups are, besides professional translators and interpreters, students of translation, language, and literary studies. We describe a first use case in which we use novels by French authors and compare them with their English and Japanese translations. The main motivation for choosing Japanese is the soaring popularity of Japanese courses at our university and the particular challenges involved with trying to master this language.","2024-05","2025-09-10 13:17:21","2025-09-10 13:17:21","","54–65","","","","","","","","","","","ELRA and ICCL","Torino, Italia","","","","","","","","","","","","","","Bonial, Claire; Bonn, Julia; Hwang, Jena D.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9TZKAT8Z","conferencePaper","2024","Zhou, Wendi; Li, Tianyi; Vougiouklis, Pavlos; Steedman, Mark; Pan, Jeff Z.","A Usage-centric Take on Intent Understanding in E-Commerce","Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing","","","10.18653/v1/2024.emnlp-main.14","https://aclanthology.org/2024.emnlp-main.14/","Identifying and understanding user intents is a pivotal task for E-Commerce. Despite its essential role in product recommendation and business user profiling analysis, intent understanding has not been consistently defined or accurately benchmarked. In this paper, we focus on predicative user intents as “how a customer uses a product”, and pose intent understanding as a natural language reasoning task, independent of product ontologies. We identify two weaknesses of FolkScope, the SOTA E-Commerce Intent Knowledge Graph: category-rigidity and property-ambiguity. They limit its ability to strongly align user intents with products having the most desirable property, and to recommend useful products across diverse categories. Following these observations, we introduce a Product Recovery Benchmark featuring a novel evaluation framework and an example dataset. We further validate the above FolkScope weaknesses on this benchmark. Our code and dataset are available at https://github.com/stayones/Usgae-Centric-Intent-Understanding.","2024-11","2025-09-10 13:17:22","2025-09-10 13:17:22","","228–236","","","","","","","","","","","Association for Computational Linguistics","Miami, Florida, USA","","","","","","","","","","","","","","Al-Onaizan, Yaser; Bansal, Mohit; Chen, Yun-Nung","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BBH7HDPM","conferencePaper","2024","Weir, Nathaniel; Thomas, Ryan; d'Amore, Randolph; Hill, Kellie; Van Durme, Benjamin; Jhamtani, Harsh","Ontologically Faithful Generation of Non-Player Character Dialogues","Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing","","","10.18653/v1/2024.emnlp-main.520","https://aclanthology.org/2024.emnlp-main.520/","We introduce a language generation dataset grounded in a popular video game. KNUDGE (**KN**owledge Constrained **U**ser-NPC **D**ialogue **GE**neration) requires models to produce trees of dialogue between video game characters that accurately reflect quest and entity specifications stated in natural language. KNUDGE is constructed from side quest dialogues drawn directly from game data of Obsidian Entertainment's _The Outer Worlds_, leading to real-world complexities in generation: (1) utterances must remain faithful to the game lore, including character personas and backstories; (2) a dialogue must accurately reveal new quest details to the human player; and (3) dialogues are large trees as opposed to linear chains of utterances. We report results for a set of neural generation models using supervised and in-context learning techniques; we find competent performance but room for future work addressing the challenges of creating realistic, game-quality dialogues.","2024-11","2025-09-10 13:17:22","2025-09-10 13:17:22","","9212–9242","","","","","","","","","","","Association for Computational Linguistics","Miami, Florida, USA","","","","","","","","","","","","","","Al-Onaizan, Yaser; Bansal, Mohit; Chen, Yun-Nung","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"54U2RGN9","conferencePaper","2024","Parekh, Tanmay; Kwan, Jeffrey; Yu, Jiarui; Johri, Sparsh; Ahn, Hyosang; Muppalla, Sreya; Chang, Kai-Wei; Wang, Wei; Peng, Nanyun","SPEED++: A Multilingual Event Extraction Framework for Epidemic Prediction and Preparedness","Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing","","","10.18653/v1/2024.emnlp-main.720","https://aclanthology.org/2024.emnlp-main.720/","Social media is often the first place where communities discuss the latest societal trends. Prior works have utilized this platform to extract epidemic-related information (e.g. infections, preventive measures) to provide early warnings for epidemic prediction. However, these works only focused on English posts, while epidemics can occur anywhere in the world, and early discussions are often in the local, non-English languages. In this work, we introduce the first multilingual Event Extraction (EE) framework SPEED++ for extracting epidemic event information for any disease and language. To this end, we extend a previous epidemic ontology with 20 argument roles; and curate our multilingual EE dataset SPEED++ comprising 5.1K tweets in four languages for four diseases. Annotating data in every language is infeasible; thus we develop zero-shot cross-lingual cross-disease models (i.e., training only on English COVID data) utilizing multilingual pre-training and show their efficacy in extracting epidemic-related events for 65 diverse languages across different diseases. Experiments demonstrate that our framework can provide epidemic warnings for COVID-19 in its earliest stages in Dec 2019 (3 weeks before global discussions) from Chinese Weibo posts without any training in Chinese. Furthermore, we exploit our framework's argument extraction capabilities to aggregate community epidemic discussions like symptoms and cure measures, aiding misinformation detection and public attention monitoring. Overall, we lay a strong foundation for multilingual epidemic preparedness.","2024-11","2025-09-10 13:17:22","2025-09-10 13:17:22","","12936–12965","","","","","","","","","","","Association for Computational Linguistics","Miami, Florida, USA","","","","","","","","","","","","","","Al-Onaizan, Yaser; Bansal, Mohit; Chen, Yun-Nung","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7AFXICGA","conferencePaper","2024","Sun, Jimin; Min, So Yeon; Chang, Yingshan; Bisk, Yonatan","Tools Fail: Detecting Silent Errors in Faulty Tools","Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing","","","10.18653/v1/2024.emnlp-main.790","https://aclanthology.org/2024.emnlp-main.790/","Tools have become a mainstay of LLMs, allowing them to retrieve knowledge not in their weights, to perform tasks on the web, and even to control robots. However, most ontologies and surveys of tool-use have assumed the core challenge for LLMs is choosing the tool. Instead, we introduce a framework for tools more broadly which guides us to explore a model's ability to detect “silent” tool errors, and reflect on how to plan. This more directly aligns with the increasingly popular use of models as tools. We provide an initial approach to failure recovery with promising results both on a controlled calculator setting and embodied agent planning.","2024-11","2025-09-10 13:17:22","2025-09-10 13:17:22","","14272–14289","","","","","","","","","","","Association for Computational Linguistics","Miami, Florida, USA","","","","","","","","","","","","","","Al-Onaizan, Yaser; Bansal, Mohit; Chen, Yun-Nung","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"B39IFBSY","conferencePaper","2024","Liang, Jinggui; Wu, Yuxia; Fang, Yuan; Fei, Hao; Liao, Lizi","A Survey of Ontology Expansion for Conversational Understanding","Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing","","","10.18653/v1/2024.emnlp-main.1006","https://aclanthology.org/2024.emnlp-main.1006/","In the rapidly evolving field of conversational AI, Ontology Expansion (OnExp) is crucial for enhancing the adaptability and robustness of conversational agents. Traditional models rely on static, predefined ontologies, limiting their ability to handle new and unforeseen user needs. This survey paper provides a comprehensive review of the state-of-the-art techniques in OnExp for conversational understanding. It categorizes the existing literature into three main areas: (1) New Intent Discovery, (2) New Slot-Value Discovery, and (3) Joint OnExp. By examining the methodologies, benchmarks, and challenges associated with these areas, we highlight several emerging frontiers in OnExp to improve agent performance in real-world scenarios and discuss their corresponding challenges. This survey aspires to be a foundational reference for researchers and practitioners, promoting further exploration and innovation in this crucial domain.","2024-11","2025-09-10 13:17:22","2025-09-10 13:17:22","","18111–18127","","","","","","","","","","","Association for Computational Linguistics","Miami, Florida, USA","","","","","","","","","","","","","","Al-Onaizan, Yaser; Bansal, Mohit; Chen, Yun-Nung","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8V3CVD5Z","conferencePaper","2024","Koo, Heejoon","Next Visit Diagnosis Prediction via Medical Code-Centric Multimodal Contrastive EHR Modelling with Hierarchical Regularisation","Findings of the Association for Computational Linguistics: EACL 2024","","","","https://aclanthology.org/2024.findings-eacl.3/","Predicting next visit diagnosis using Electronic Health Records (EHR) is an essential task in healthcare, critical for devising proactive future plans for both healthcare providers and patients. Nonetheless, many preceding studies have not sufficiently addressed the heterogeneous and hierarchical characteristics inherent in EHR data, inevitably leading to sub-optimal performance. To this end, we propose NECHO, a novel medical code-centric multimodal contrastive EHR learning framework with hierarchical regularisation. First, we integrate multifaceted information encompassing medical codes, demographics, and clinical notes using a tailored network design and a pair of bimodal contrastive losses, all of which pivot around a medical codes representation. We also regularise modality-specific encoders using a parental level information in medical ontology to learn hierarchical structure of EHR data. A series of experiments on MIMIC-III data demonstrates effectiveness of our approach.","2024-03","2025-09-10 13:17:22","2025-09-10 13:17:22","","41–55","","","","","","","","","","","Association for Computational Linguistics","St. Julian's, Malta","","","","","","","","","","","","","","Graham, Yvette; Purver, Matthew","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FHT9WHJC","conferencePaper","2024","Park, Jeongwoo; Liscio, Enrico; Murukannaiah, Pradeep K.","Morality is Non-Binary: Building a Pluralist Moral Sentence Embedding Space using Contrastive Learning","Findings of the Association for Computational Linguistics: EACL 2024","","","","https://aclanthology.org/2024.findings-eacl.45/","Recent advances in NLP show that language models retain a discernible level of knowledge in deontological ethics and moral norms. However, existing works often treat morality as binary, ranging from right to wrong. This simplistic view does not capture the nuances of moral judgment. Pluralist moral philosophers argue that human morality can be deconstructed into a finite number of elements, respecting individual differences in moral judgment. In line with this view, we build a pluralist moral sentence embedding space via a state-of-the-art contrastive learning approach. We systematically investigate the embedding space by studying the emergence of relationships among moral elements, both quantitatively and qualitatively. Our results show that a pluralist approach to morality can be captured in an embedding space. However, moral pluralism is challenging to deduce via self-supervision alone and requires a supervised approach with human labels.","2024-03","2025-09-10 13:17:22","2025-09-10 13:17:22","","654–673","","","","","","","","","","","Association for Computational Linguistics","St. Julian's, Malta","","","","","","","","","","","","","","Graham, Yvette; Purver, Matthew","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UJZRFZJF","conferencePaper","2024","Jiao, Yizhu; Li, Sha; Zhou, Sizhe; Ji, Heng; Han, Jiawei","Text2DB: Integration-Aware Information Extraction with Large Language Model Agents","Findings of the Association for Computational Linguistics: ACL 2024","","","10.18653/v1/2024.findings-acl.12","https://aclanthology.org/2024.findings-acl.12/","The task of information extraction (IE) is to extract structured knowledge from text. However, it is often not straightforward to utilize IE output due to the mismatch between the IE ontology and the downstream application needs. We propose a new formulation of IE, Text2DB, that emphasizes the integration of IE output and the target database (or knowledge base). Given a user instruction, a document set, and a database, our task requires the model to update the database with values from the document set to satisfy the user instruction. This task requires understanding user instructions for <i>what to extract</i> and adapting to the given DB/KB schema for <i>how to extract</i> on the fly. To evaluate this new task, we introduce a new benchmark featuring common demands such as data infilling, row population, and column addition. In addition, we propose an LLM agent framework OPAL (Observe-Plan-Analyze LLM) which includes an Observer component that interacts with the database, the Planner component that generates a code-based plan with calls to IE models, and the Analyzer component that provides feedback regarding code quality before execution. Experiments show that OPAL can successfully adapt to diverse database schemas by generating different code plans and calling the required IE models. We also highlight difficult cases such as dealing with large databases with complex dependencies and extraction hallucination, which we believe deserve further investigation.","2024-08","2025-09-10 13:17:22","2025-09-10 13:17:22","","185–205","","","","","","","","","","","Association for Computational Linguistics","Bangkok, Thailand","","","","","","","","","","","","","","Ku, Lun-Wei; Martins, Andre; Srikumar, Vivek","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PY8ASN7C","conferencePaper","2024","Kteich, Hanane; Li, Na; Chatterjee, Usashi; Bouraoui, Zied; Schockaert, Steven","Modelling Commonsense Commonalities with Multi-Facet Concept Embeddings","Findings of the Association for Computational Linguistics: ACL 2024","","","10.18653/v1/2024.findings-acl.86","https://aclanthology.org/2024.findings-acl.86/","Concept embeddings offer a practical and efficient mechanism for injecting commonsense knowledge into downstream tasks. Their core purpose is often not to predict the commonsense properties of concepts themselves, but rather to identify commonalities, i.e. sets of concepts which share some property of interest. Such commonalities are the basis for inductive generalisation, hence high-quality concept embeddings can make learning easier and more robust. Unfortunately, standard embeddings primarily reflect basic taxonomic categories, making them unsuitable for finding commonalities that refer to more specific aspects (e.g. the colour of objects or the materials they are made of). In this paper, we address this limitation by explicitly modelling the different facets of interest when learning concept embeddings. We show that this leads to embeddings which capture a more diverse range of commonsense properties, and consistently improves results in downstream tasks such as ultra-fine entity typing and ontology completion.","2024-08","2025-09-10 13:17:22","2025-09-10 13:17:22","","1467–1480","","","","","","","","","","","Association for Computational Linguistics","Bangkok, Thailand","","","","","","","","","","","","","","Ku, Lun-Wei; Martins, Andre; Srikumar, Vivek","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IBFFAVFU","conferencePaper","2024","Wang, Keyu; Qi, Guilin; Li, Jiaqi; Zhai, Songlin","Can Large Language Models Understand DL-Lite Ontologies? An Empirical Study","Findings of the Association for Computational Linguistics: EMNLP 2024","","","10.18653/v1/2024.findings-emnlp.141","https://aclanthology.org/2024.findings-emnlp.141/","Large language models (LLMs) have shown significant achievements in solving a wide range of tasks. Recently, LLMs' capability to store, retrieve and infer with symbolic knowledge has drawn a great deal of attention, showing their potential to understand structured information. However, it is not yet known whether LLMs can understand Description Logic (DL) ontologies. In this work, we empirically analyze the LLMs' capability of understanding DL-Lite ontologies covering 6 representative tasks from syntactic and semantic aspects. With extensive experiments, we demonstrate both the effectiveness and limitations of LLMs in understanding DL-Lite ontologies. We find that LLMs can understand formal syntax and model-theoretic semantics of concepts and roles. However, LLMs struggle with understanding TBox NI transitivity and handling ontologies with large ABoxes. We hope that our experiments and analyses provide more insights into LLMs and inspire to build more faithful knowledge engineering solutions.","2024-11","2025-09-10 13:17:22","2025-09-10 13:17:22","","2503–2519","","","","","","","","","","","Association for Computational Linguistics","Miami, Florida, USA","","","","","","","","","","","","","","Al-Onaizan, Yaser; Bansal, Mohit; Chen, Yun-Nung","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"D58KWP2I","conferencePaper","2024","Seeberger, Philipp; Wagner, Dominik; Riedhammer, Korbinian","MMUTF: Multimodal Multimedia Event Argument Extraction with Unified Template Filling","Findings of the Association for Computational Linguistics: EMNLP 2024","","","10.18653/v1/2024.findings-emnlp.381","https://aclanthology.org/2024.findings-emnlp.381/","With the advancement of multimedia technologies, news documents and user-generated content are often represented as multiple modalities, making Multimedia Event Extraction (MEE) an increasingly important challenge. However, recent MEE methods employ weak alignment strategies and data augmentation with simple classification models, which ignore the capabilities of natural language-formulated event templates for the challenging Event Argument Extraction (EAE) task. In this work, we focus on EAE and address this issue by introducing a unified template filling model that connects the textual and visual modalities via textual prompts. This approach enables the exploitation of cross-ontology transfer and the incorporation of event-specific semantics. Experiments on the M2E2 benchmark demonstrate the effectiveness of our approach. Our system surpasses the current SOTA on textual EAE by +7% F1, and performs generally better than the second-best systems for multimedia EAE.","2024-11","2025-09-10 13:17:22","2025-09-10 13:17:22","","6539–6548","","","","","","","","","","","Association for Computational Linguistics","Miami, Florida, USA","","","","","","","","","","","","","","Al-Onaizan, Yaser; Bansal, Mohit; Chen, Yun-Nung","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"D9A6B49Q","conferencePaper","2024","Li, Na; Bailleux, Thomas; Bouraoui, Zied; Schockaert, Steven","CONTOR: Benchmarking Strategies for Completing Ontologies with Plausible Missing Rules","Findings of the Association for Computational Linguistics: EMNLP 2024","","","10.18653/v1/2024.findings-emnlp.488","https://aclanthology.org/2024.findings-emnlp.488/","We consider the problem of finding plausible rules that are missing from a given ontology. A number of strategies for this problem have already been considered in the literature. Little is known about the relative performance of these strategies, however, as they have thus far been evaluated on different ontologies. Moreover, existing evaluations have focused on distinguishing held-out ontology rules from randomly corrupted ones, which often makes the task unrealistically easy and leads to the presence of incorrectly labelled negative examples. To address these concerns, we introduce a benchmark with manually annotated hard negatives and use this benchmark to evaluate ontology completion models. In addition to previously proposed models, we test the effectiveness of several approaches that have not yet been considered for this task, including LLMs and simple but effective hybrid strategies.","2024-11","2025-09-10 13:17:22","2025-09-10 13:17:22","","8316–8334","","","","","","","","","","","Association for Computational Linguistics","Miami, Florida, USA","","","","","","","","","","","","","","Al-Onaizan, Yaser; Bansal, Mohit; Chen, Yun-Nung","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QNJUW7DC","conferencePaper","2024","Rajan, Sai Sathiesh; Soremekun, Ezekiel; Chattopadhyay, Sudipta","Knowledge-based Consistency Testing of Large Language Models","Findings of the Association for Computational Linguistics: EMNLP 2024","","","10.18653/v1/2024.findings-emnlp.596","https://aclanthology.org/2024.findings-emnlp.596/","In this work, we systematically expose and measure the inconsistency and knowledge gaps of Large Language Models (LLMs). Specifically, we propose an automated testing framework (called KONTEST) which leverages a knowledge graph to construct test cases. KONTEST probes and measures the inconsistencies in the LLM's knowledge of the world via a combination of semantically-equivalent queries and test oracles (metamorphic or ontological oracle). KONTEST further mitigates knowledge gaps via a weighted LLM model ensemble. Using four state-of-the-art LLMs (Falcon, Gemini, GPT3.5, and Llama2), we show that KONTEST generates 19.2% error inducing inputs (1917 errors from 9979 test inputs). It also reveals a 16.5% knowledge gap across all tested LLMs. A mitigation method informed by KONTEST's test suite reduces LLM knowledge gap by 32.48%. Our ablation study further shows that GPT3.5 is not suitable for knowledge-based consistency testing because it is only 60%-68% effective in knowledge construction.","2024-11","2025-09-10 13:17:22","2025-09-10 13:17:22","","10185–10196","","","","","","","","","","","Association for Computational Linguistics","Miami, Florida, USA","","","","","","","","","","","","","","Al-Onaizan, Yaser; Bansal, Mohit; Chen, Yun-Nung","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"G33E2T24","conferencePaper","2024","Zhang, Guobiao; Peng, Xueping; Shen, Tao; Long, Guodong; Si, Jiasheng; Qin, Libo; Lu, Wenpeng","Extractive Medical Entity Disambiguation with Memory Mechanism and Memorized Entity Information","Findings of the Association for Computational Linguistics: EMNLP 2024","","","10.18653/v1/2024.findings-emnlp.810","https://aclanthology.org/2024.findings-emnlp.810/","Medical entity disambiguation (MED) aims to ground medical mentions in text with ontological entities in knowledge bases (KBs). A notable challenge of MED is the long medical text usually contains multiple entities' mentions with intricate correlations. However, limited by computation overhead, many existing methods consider only a single candidate entity mention during the disambiguation process. As such, they focus only on local MED optimal while ignoring the sole-mention disambiguation possibly boosted by richer context from other mentions' disambiguating processes – missing global optimal on entity combination in the text. Motivated by this, we propose a new approach called Extractive Medical Entity Disambiguation with Memory Mechanism and Memorized Entity Information (M3E). Specifically, we reformulate MED as a text extraction task, which simultaneously accepts the context of medical mentions, all possible candidate entities, and entity definitions, and it is then trained to extract the text span corresponding to the correct entity. Upon our new formulation, 1) to alleviate the computation overhead from the enriched context, we devise a memory mechanism module that performs memory caching, retrieval, fusion and cross-network residual; and 2) to utilize the disambiguation clues from other mentions, we design an auxiliary disambiguation module that employs a gating mechanism to assist the disambiguation of remaining mentions. Extensive experiments on two benchmark datasets demonstrate the superiority of M3E over the state-of-the-art MED methods on all metrics.","2024-11","2025-09-10 13:17:22","2025-09-10 13:17:22","","13811–13822","","","","","","","","","","","Association for Computational Linguistics","Miami, Florida, USA","","","","","","","","","","","","","","Al-Onaizan, Yaser; Bansal, Mohit; Chen, Yun-Nung","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HZ3UZSM9","conferencePaper","2024","Ashury Tahan, Shir; Cohen, Amir David Nissan; Cohen, Nadav; Louzoun, Yoram; Goldberg, Yoav","Data-driven Coreference-based Ontology Building","Findings of the Association for Computational Linguistics: EMNLP 2024","","","10.18653/v1/2024.findings-emnlp.834","https://aclanthology.org/2024.findings-emnlp.834/","While coreference resolution is traditionally used as a component in individual document understanding, in this work we take a more global view and explore what can we learn about a domain from the set of all document-level coreference relations that are present in a large corpus. We derive coreference chains from a corpus of 30 million biomedical abstracts and construct a graph based on the string phrases within these chains, establishing connections between phrases if they co-occur within the same coreference chain. We then use the graph structure and the betweeness centrality measure to distinguish between edges denoting hierarchy, identity and noise, assign directionality to edges denoting hierarchy, and split nodes (strings) that correspond to multiple distinct concepts. The result is a rich, data-driven ontology over concepts in the biomedical domain, parts of which overlaps significantly with human-authored ontologies. We release the coreference chains and resulting ontology under a creative-commons license.","2024-11","2025-09-10 13:17:22","2025-09-10 13:17:22","","14290–14300","","","","","","","","","","","Association for Computational Linguistics","Miami, Florida, USA","","","","","","","","","","","","","","Al-Onaizan, Yaser; Bansal, Mohit; Chen, Yun-Nung","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3G48DG5R","conferencePaper","2024","Alshammari, Ibtisam Khalaf; Atwell, Eric; Alsalka, Mohammad Ammar","Linking Quran and Hadith Topics in an Ontology using Word Embeddings and Cellfie Plugin","Proceedings of the 7th International Conference on Natural Language and Speech Processing (ICNLSP 2024)","","","","https://aclanthology.org/2024.icnlsp-1.46/","","2024-10","2025-09-10 13:17:22","2025-09-10 13:17:22","","449–455","","","","","","","","","","","Association for Computational Linguistics","Trento","","","","","","","","","","","","","","Abbas, Mourad; Freihat, Abed Alhakim","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HRDRTK5A","conferencePaper","2024","Prakash, Nandhana; A, Amudhan; R, Nithish; Saravanan, Krithikha Sanju","LOC: Livestock Ontology Construction Approach From Domain based Text Documents","Proceedings of the 21st International Conference on Natural Language Processing (ICON)","","","","https://aclanthology.org/2024.icon-1.53/","Livestock plays an irreplaceable role in rural and global economies and as a part of its progression livestock ontology would unlock its potential of cross - domain applications of Natural Language Processing (NLP). Domain data is essential for the retrieval of semantic and syntactic understanding of the input text data given to the model. The paper presents a Livestock based Ontology Construction (LOC) is proposed. The input data endures anaphora resolution employing semantic methods based on rules then the pre-trained BERT model with Regular expression are utilized for retrieving terms (entities) from the data. Now the Graph Neural Network (GNN) is constructed with Regular Expressions for extricating relationships from the input documents for designing the livestock ontology. The efficaciousness of the proposed LOC based on the BERT model with regular expressions and GNN method with Regular expressions depicts noteworthy results when compared to existing methods, showing a precision and recall of 97.56% and 95.24%.","2024-12","2025-09-10 13:17:22","2025-09-10 13:17:22","","454–461","","","","","","","","","","","NLP Association of India (NLPAI)","AU-KBC Research Centre, Chennai, India","","","","","","","","","","","","","","Lalitha Devi, Sobha; Arora, Karunesh","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RA4YCF6Q","conferencePaper","2024","Petliak, Nataliia; Alcaina, Cristina Fernandéz; Fučíková, Eva; Hajič, Jan; Urešová, Zdeňka","Search tool for An Event-Type Ontology","Proceedings of the 20th Joint ACL - ISO Workshop on Interoperable Semantic Annotation @ LREC-COLING 2024","","","","https://aclanthology.org/2024.isa-1.9/","This short demo description paper presents a new tool designed for searching an event-type ontology with rich information, demonstrated on the SynSemClass ontology resource. The tool complements a web browser, created by the authors of the SynSemClass ontology previously. Due to the complexity of the resource, the search tool offers possibilities both for a linguistically-oriented researcher as well as for teams working with the resource from a technical point of view, such as building role labeling tools, automatic annotation tools, etc.","2024-05","2025-09-10 13:17:22","2025-09-10 13:17:22","","66–70","","","","","","","","","","","ELRA and ICCL","Torino, Italia","","","","","","","","","","","","","","Bunt, Harry; Ide, Nancy; Lee, Kiyong; Petukhova, Volha; Pustejovsky, James; Romary, Laurent","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6IL773GG","conferencePaper","2024","Salman, Muhammad; Haller, Armin; Rodriguez Mendez, Sergio J.; Naseem, Usman","Tiny But Mighty: A Crowdsourced Benchmark Dataset for Triple Extraction from Unstructured Text","Proceedings of the 20th Joint ACL - ISO Workshop on Interoperable Semantic Annotation @ LREC-COLING 2024","","","","https://aclanthology.org/2024.isa-1.10/","In the context of Natural Language Processing (NLP) and Semantic Web applications, constructing Knowledge Graphs (KGs) from unstructured text plays a vital role. Several techniques have been developed for KG construction from text, but the lack of standardized datasets hinders the evaluation of triple extraction methods. The evaluation of existing KG construction approaches is based on structured data or manual investigations. To overcome this limitation, this work introduces a novel dataset specifically designed to evaluate KG construction techniques from unstructured text. Our dataset consists of a diverse collection of compound and complex sentences meticulously annotated by human annotators with potential triples (subject, verb, object). The annotations underwent further scrutiny by expert ontologists to ensure accuracy and consistency. For evaluation purposes, the proposed F-measure criterion offers a robust approach to quantify the relatedness and assess the alignment between extracted triples and the ground-truth triples, providing a valuable tool for evaluating the performance of triple extraction systems. By providing a diverse collection of high-quality triples, our proposed benchmark dataset offers a comprehensive training and evaluation set for refining the performance of state-of-the-art language models on a triple extraction task. Furthermore, this dataset encompasses various KG-related tasks, such as named entity recognition, relation extraction, and entity linking.","2024-05","2025-09-10 13:17:22","2025-09-10 13:17:22","","71–81","","","","","","","","","","","ELRA and ICCL","Torino, Italia","","","","","","","","","","","","","","Bunt, Harry; Ide, Nancy; Lee, Kiyong; Petukhova, Volha; Pustejovsky, James; Romary, Laurent","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6JVS2E3I","conferencePaper","2024","Gurgurov, Daniil; Hartmann, Mareike; Ostermann, Simon","Adapting Multilingual LLMs to Low-Resource Languages with Knowledge Graphs via Adapters","Proceedings of the 1st Workshop on Knowledge Graphs and Large Language Models (KaLLM 2024)","","","10.18653/v1/2024.kallm-1.7","https://aclanthology.org/2024.kallm-1.7/","This paper explores the integration of graph knowledge from linguistic ontologies into multilingual Large Language Models (LLMs) using adapters to improve performance for low-resource languages (LRLs) in sentiment analysis (SA) and named entity recognition (NER). Building upon successful parameter-efficient fine-tuning techniques, such as K-ADAPTER and MAD-X, we propose a similar approach for incorporating knowledge from multilingual graphs, connecting concepts in various languages with each other through linguistic relationships, into multilingual LLMs for LRLs. Specifically, we focus on eight LRLs — Maltese, Bulgarian, Indonesian, Nepali, Javanese, Uyghur, Tibetan, and Sinhala — and employ language-specific adapters fine-tuned on data extracted from the language-specific section of ConceptNet, aiming to enable knowledge transfer across the languages covered by the knowledge graph. We compare various fine-tuning objectives, including standard Masked Language Modeling (MLM), MLM with full-word masking, and MLM with targeted masking, to analyze their effectiveness in learning and integrating the extracted graph data. Through empirical evaluation on language-specific tasks, we assess how structured graph knowledge affects the performance of multilingual LLMs for LRLs in SA and NER, providing insights into the potential benefits of adapting language models for low-resource scenarios.","2024-08","2025-09-10 13:17:22","2025-09-10 13:17:22","","63–74","","","","","","","","","","","Association for Computational Linguistics","Bangkok, Thailand","","","","","","","","","","","","","","Biswas, Russa; Kaffee, Lucie-Aimée; Agarwal, Oshin; Minervini, Pasquale; Singh, Sameer; de Melo, Gerard","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"3765WCAP","conferencePaper","2024","van Cauter, Zeno; Yakovets, Nikolay","Ontology-guided Knowledge Graph Construction from Maintenance Short Texts","Proceedings of the 1st Workshop on Knowledge Graphs and Large Language Models (KaLLM 2024)","","","10.18653/v1/2024.kallm-1.8","https://aclanthology.org/2024.kallm-1.8/","Large-scale knowledge graph construction remains infeasible since it requires significant human-expert involvement. Further complications arise when building graphs from domain-specific data due to their unique vocabularies and associated contexts. In this work, we demonstrate the ability of open-source large language models (LLMs), such as Llama-2 and Llama-3, to extract facts from domain-specific Maintenance Short Texts (MSTs). We employ an approach which combines ontology-guided triplet extraction and in-context learning. By using only 20 semantically similar examples with the Llama-3-70B-Instruct model, we achieve performance comparable to previous methods that relied on fine-tuning techniques like SpERT and REBEL. This indicates that domain-specific fact extraction can be accomplished through inference alone, requiring minimal labeled data. This opens up possibilities for effective and efficient semi-automated knowledge graph construction for domain-specific data.","2024-08","2025-09-10 13:17:22","2025-09-10 13:17:22","","75–84","","","","","","","","","","","Association for Computational Linguistics","Bangkok, Thailand","","","","","","","","","","","","","","Biswas, Russa; Kaffee, Lucie-Aimée; Agarwal, Oshin; Minervini, Pasquale; Singh, Sameer; de Melo, Gerard","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"F8X9WQVT","conferencePaper","2024","Spaulding, Elizabeth; Conger, Kathryn; Gershman, Anatole; Morshed, Mahir; Brown, Susan Windisch; Pustejovsky, James; Uceda-Sosa, Rosario; Ge, Sijia; Palmer, Martha","PropBank goes Public: Incorporation into Wikidata","Proceedings of the 18th Linguistic Annotation Workshop (LAW-XVIII)","","","","https://aclanthology.org/2024.law-1.16/","This paper presents the first integration of PropBank role information into Wikidata, in order to provide a novel resource for information extraction, one combining Wikidata's ontological metadata with PropBank's rich argument structure encoding for event classes. We discuss a technique for PropBank augmentation to existing eventive Wikidata items, as well as identification of gaps in Wikidata's coverage based on manual examination of over 11,300 PropBank rolesets. We propose five new Wikidata properties to integrate PropBank structure into Wikidata so that the annotated mappings can be added en masse. We then outline the methodology and challenges of this integration, including annotation with the combined resources.","2024-03","2025-09-10 13:17:22","2025-09-10 13:17:22","","166–175","","","","","","","","","","","Association for Computational Linguistics","St. Julians, Malta","","","","","","","","","","","","","","Henning, Sophie; Stede, Manfred","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Y9VKIUG2","conferencePaper","2024","Banerjee, Shubhanker; Chakravarthi, Bharathi Raja; McCrae, John Philip","Cross-Lingual Ontology Matching using Structural and Semantic Similarity","Proceedings of the 9th Workshop on Linked Data in Linguistics @ LREC-COLING 2024","","","","https://aclanthology.org/2024.ldl-1.2/","The development of ontologies in various languages is attracting attention as the amount of multilingual data available on the web increases. Cross-lingual ontology matching facilitates interoperability amongst ontologies in different languages. Although supervised machine learning-based methods have shown good performance on ontology matching, their application to the cross-lingual setting is limited by the availability of training data. Current state-of-the-art unsupervised methods for cross-lingual ontology matching focus on lexical similarity between entities. These approaches follow a two-stage pipeline where the entities are translated into a common language using a translation service in the first step followed by computation of lexical similarity between the translations to match the entities in the second step. In this paper we introduce a novel ontology matching method based on the fusion of structural similarity and cross-lingual semantic similarity. We carry out experiments using 3 language pairs and report substantial improvements on the performance of the lexical methods thus showing the effectiveness of our proposed approach. To the best of our knowledge this is the first work which tackles the problem of unsupervised ontology matching in the cross-lingual setting by leveraging both structural and semantic embeddings.","2024-05","2025-09-10 13:17:22","2025-09-10 13:17:22","","11–21","","","","","","","","","","","ELRA and ICCL","Torino, Italia","","","","","","","","","","","","","","Chiarcos, Christian; Gkirtzou, Katerina; Ionov, Maxim; Khan, Fahad; McCrae, John P.; Ponsoda, Elena Montiel; Chozas, Patricia Martín","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"P5D2JWZ6","conferencePaper","2024","Boano, Valeria Irene; Passarotti, Marco; Ginevra, Riccardo","Querying the Lexicon der indogermanischen Verben in the LiLa Knowledge Base: Two Use Cases","Proceedings of the 9th Workshop on Linked Data in Linguistics @ LREC-COLING 2024","","","","https://aclanthology.org/2024.ldl-1.3/","This paper presents two use cases of the etymological data provided by the *Lexicon der indogermanischen Verben* (LIV) after their publication as Linked Open Data and their linking to the LiLa Knowledge Base (KB) of interoperable linguistic resources for Latin. The first part of the paper briefly describes the LiLa KB and its structure. Then, the LIV and the information it contains are introduced, followed by a short description of the ontologies and the extensions used for modelling the LIV's data and interlinking them to the LiLa ecosystem. The last section details the two use cases. The first case concerns the inflection types of the Latin verbs that reflect Proto-Indo-European stems, while the second one focusses on the Latin derivatives of the inherited stems. The results of the investigations are put in relation to current research topics in Historical Linguistics, demonstrating their relevance to the discipline.","2024-05","2025-09-10 13:17:22","2025-09-10 13:17:22","","22–31","","","","","","","","","","","ELRA and ICCL","Torino, Italia","","","","","","","","","","","","","","Chiarcos, Christian; Gkirtzou, Katerina; Ionov, Maxim; Khan, Fahad; McCrae, John P.; Ponsoda, Elena Montiel; Chozas, Patricia Martín","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IAWDF3GF","conferencePaper","2024","Canning, Erin","Defining an Ontology for Museum Critical Cataloguing Terminology Guidelines","Proceedings of the 9th Workshop on Linked Data in Linguistics @ LREC-COLING 2024","","","","https://aclanthology.org/2024.ldl-1.4/","Submission type: Short paper This paper presents the proposed ontology for the project Computational Approaches for Addressing Problematic Terminology (CAAPT). This schema seeks to represent contents and structure of language guideline documents produced by cultural heritage institutions seeking to engage with critical cataloguing or reparative description work, known as terminology guidance documents. It takes the Victoria & Albert Museum's Terminology Guidance Document as a source for the initial modelling work. Ultimately, CAAPT seeks to expand the knowledge graph beyond the V&A Museum context to incorporate additional terminology guidance documents and linked open data vocabularies. The ontology seeks to bring together scholarly communities in areas relevant to this project, most notably those in cultural heritage and linguistics linked open data, by leveraging existing linked data resources in these areas: as such, OntoLex, CIDOC CRM, and SKOS are used as a foundation for this work, along with a proposed schema from a related project, CULCO. As the CAAPT project is in early stages, this paper presents the preliminary results of work undertaken thus far in order to seek feedback from the linguistics linked open data community.","2024-05","2025-09-10 13:17:22","2025-09-10 13:17:22","","32–36","","","","","","","","","","","ELRA and ICCL","Torino, Italia","","","","","","","","","","","","","","Chiarcos, Christian; Gkirtzou, Katerina; Ionov, Maxim; Khan, Fahad; McCrae, John P.; Ponsoda, Elena Montiel; Chozas, Patricia Martín","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4LQEQ8GZ","conferencePaper","2024","Gerlach, Johanna; Bouillon, Pierrette; Mutal, Jonathan; Spechbach, Hervé","A Concept Based Approach for Translation of Medical Dialogues into Pictographs","Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)","","","","https://aclanthology.org/2024.lrec-main.21/","Pictographs have been found to improve patient comprehension of medical information or instructions. However, tools to produce pictograph representations from natural language are still scarce. In this contribution we describe a system that automatically translates French speech into pictographs to enable diagnostic interviews in emergency settings, thereby providing a tool to overcome the language barrier or provide support in Augmentative and Alternative Communication (AAC) contexts. Our approach is based on a semantic gloss that serves as pivot between spontaneous language and pictographs, with medical concepts represented using the UMLS ontology. In this study we evaluate different available pre-trained models fine-tuned on artificial data to translate French into this semantic gloss. On unseen data collected in real settings, consisting of questions and instructions by physicians, the best model achieves an F0.5 score of 86.7. A complementary human evaluation of the semantic glosses differing from the reference shows that 71% of these would be usable to transmit the intended meaning. Finally, a human evaluation of the pictograph sequences derived from the gloss reveals very few additions, omissions or order issues (\ensuremath<3%), suggesting that the gloss as designed is well suited as a pivot for translation into pictographs.","2024-05","2025-09-10 13:17:22","2025-09-10 13:17:22","","233–242","","","","","","","","","","","ELRA and ICCL","Torino, Italia","","","","","","","","","","","","","","Calzolari, Nicoletta; Kan, Min-Yen; Hoste, Veronique; Lenci, Alessandro; Sakti, Sakriani; Xue, Nianwen","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7QU8MVIS","conferencePaper","2024","Gajbhiye, Amit; Bouraoui, Zied; Espinosa Anke, Luis; Schockaert, Steven","AMenDeD: Modelling Concepts by Aligning Mentions, Definitions and Decontextualised Embeddings","Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)","","","","https://aclanthology.org/2024.lrec-main.72/","Contextualised Language Models (LM) improve on traditional word embeddings by encoding the meaning of words in context. However, such models have also made it possible to learn high-quality decontextualised concept embeddings. Three main strategies for learning such embeddings have thus far been considered: (i) fine-tuning the LM to directly predict concept embeddings from the name of the concept itself, (ii) averaging contextualised representations of mentions of the concept in a corpus, and (iii) encoding definitions of the concept. As these strategies have complementary strengths and weaknesses, we propose to learn a unified embedding space in which all three types of representations can be integrated. We show that this allows us to outperform existing approaches in tasks such as ontology completion, which heavily depends on access to high-quality concept embeddings. We furthermore find that mentions and definitions are well-aligned in the resulting space, enabling tasks such as target sense verification, even without the need for any fine-tuning.","2024-05","2025-09-10 13:17:22","2025-09-10 13:17:22","","801–811","","","","","","","","","","","ELRA and ICCL","Torino, Italia","","","","","","","","","","","","","","Calzolari, Nicoletta; Kan, Min-Yen; Hoste, Veronique; Lenci, Alessandro; Sakti, Sakriani; Xue, Nianwen","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"P3NYUFW5","conferencePaper","2024","Loukachevitch, Natalia; Sakhovskiy, Andrey; Tutubalina, Elena","Biomedical Concept Normalization over Nested Entities with Partial UMLS Terminology in Russian","Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)","","","","https://aclanthology.org/2024.lrec-main.213/","We present a new manually annotated dataset of PubMed abstracts for concept normalization in Russian. It contains over 23,641 entity mentions in 756 documents linked to 4,544 unique concepts from the UMLS ontology. Compared to existing corpora, we explore two novel annotation characteristics: the nestedness of named entities and the incompleteness of the Russian medical terminology in UMLS. 4,424 entity mentions are linked to 1,535 unique English concepts absent in the Russian part of the UMLS ontology. We present several baselines for normalization over nested named entities obtained with state-of-the-art models such as SapBERT. Our experimental results show that models pre-trained on graph structural data from UMLS achieve superior performance in a zero-shot setting on bilingual terminology.","2024-05","2025-09-10 13:17:22","2025-09-10 13:17:22","","2383–2389","","","","","","","","","","","ELRA and ICCL","Torino, Italia","","","","","","","","","","","","","","Calzolari, Nicoletta; Kan, Min-Yen; Hoste, Veronique; Lenci, Alessandro; Sakti, Sakriani; Xue, Nianwen","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"URBQPV56","conferencePaper","2024","Mousavi, Ali; Zhan, Xin; Bai, He; Shi, Peng; Rekatsinas, Theodoros; Han, Benjamin; Li, Yunyao; Pound, Jeffrey; Susskind, Joshua M.; Schluter, Natalie; Ilyas, Ihab F.; Jaitly, Navdeep","Construction of Paired Knowledge Graph - Text Datasets Informed by Cyclic Evaluation","Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)","","","","https://aclanthology.org/2024.lrec-main.335/","Datasets that pair Knowledge Graphs (KG) and text together (KG-T) can be used to train forward and reverse neural models that generate text from KG and vice versa. However models trained on datasets where KG and text pairs are not equivalent can suffer from more hallucination and poorer recall. In this paper, we verify this empirically by generating datasets with different levels of noise and find that noisier datasets do indeed lead to more hallucination. We argue that the ability of forward and reverse models trained on a dataset to cyclically regenerate source KG or text is a proxy for the equivalence between the KG and the text in the dataset. Using cyclic evaluation we find that manually created WebNLG is much better than automatically created TeKGen and T-REx. Informed by these observations, we construct a new, improved dataset called <b>LAGRANGE</b> using heuristics meant to improve equivalence between KG and text and show the impact of each of the heuristics on cyclic evaluation. We also construct two synthetic datasets using large language models (LLMs), and observe that these are conducive to models that perform significantly well on cyclic generation of text, but less so on cyclic generation of KGs, probably because of a lack of a consistent underlying ontology.","2024-05","2025-09-10 13:17:22","2025-09-10 13:17:22","","3782–3803","","","","","","","","","","","ELRA and ICCL","Torino, Italia","","","","","","","","","","","","","","Calzolari, Nicoletta; Kan, Min-Yen; Hoste, Veronique; Lenci, Alessandro; Sakti, Sakriani; Xue, Nianwen","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PIDHIC69","conferencePaper","2024","Agarwal, Utkarsh; Tanmay, Kumar; Khandelwal, Aditi; Choudhury, Monojit","Ethical Reasoning and Moral Value Alignment of LLMs Depend on the Language We Prompt Them in","Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)","","","","https://aclanthology.org/2024.lrec-main.560/","Ethical reasoning is a crucial skill for Large Language Models (LLMs). However, moral values are not universal, but rather influenced by language and culture. This paper explores how three prominent LLMs – GPT-4, ChatGPT, and Llama2Chat-70B – perform ethical reasoning in different languages and if their moral judgement depend on the language in which they are prompted. We extend the study of ethical reasoning of LLMs by (CITATION) to a multilingual setup following their framework of probing LLMs with ethical dilemmas and policies from three branches of normative ethics: deontology, virtue, and consequentialism. We experiment with six languages: English, Spanish, Russian, Chinese, Hindi, and Swahili. We find that GPT-4 is the most consistent and unbiased ethical reasoner across languages, while ChatGPT and Llama2Chat-70B show significant moral value bias when we move to languages other than English. Interestingly, the nature of this bias significantly vary across languages for all LLMs, including GPT-4.","2024-05","2025-09-10 13:17:22","2025-09-10 13:17:22","","6330–6340","","","","","","","","","","","ELRA and ICCL","Torino, Italia","","","","","","","","","","","","","","Calzolari, Nicoletta; Kan, Min-Yen; Hoste, Veronique; Lenci, Alessandro; Sakti, Sakriani; Xue, Nianwen","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ETMLRNR6","conferencePaper","2024","Nie, Binling; Shao, Yiming; Wang, Yigang","Know-Adapter: Towards Knowledge-Aware Parameter-Efficient Transfer Learning for Few-shot Named Entity Recognition","Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)","","","","https://aclanthology.org/2024.lrec-main.854/","Parameter-Efficient Fine-Tuning (PEFT) is a promising approach to mitigate the challenges about the model adaptation of pretrained language models (PLMs) for the named entity recognition (NER) task. Recent studies have highlighted the improvements that can be made to the quality of information retrieved from PLMs by adding explicit knowledge from external source like KGs to otherwise naive PEFTs. In this paper, we propose a novel knowledgeable adapter, Know-adapter, to incorporate structure and semantic knowledge of knowledge graphs into PLMs for few-shot NER. First, we construct a related KG entity type sequence for each sentence using a knowledge retriever. However, the type system of a domain-specific NER task is typically independent of that of current KGs and thus exhibits heterogeneity issue inevitably, which makes matching between the original NER and KG types (e.g. Person in NER potentially matches President in KBs) less likely, or introduces unintended noises. Thus, then we design a unified taxonomy based on KG ontology for KG entity types and NER labels. This taxonomy is used to build a learnable shared representation module, which provides shared representations for both KG entity type sequences and NER labels. Based on these shared representations, our Know-adapter introduces high semantic relevance knowledge and structure knowledge from KGs as inductive bias to guide the updating process of the adapter. Additionally, the shared representations guide the learnable representation module to reduce noise in the unsupervised expansion of label words. Extensive experiments on multiple NER datasets show the superiority of Know-Adapter over other state-of-the-art methods in both full-resource and low-resource settings.","2024-05","2025-09-10 13:17:22","2025-09-10 13:17:22","","9777–9786","","","","","","","","","","","ELRA and ICCL","Torino, Italia","","","","","","","","","","","","","","Calzolari, Nicoletta; Kan, Min-Yen; Hoste, Veronique; Lenci, Alessandro; Sakti, Sakriani; Xue, Nianwen","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Q73J9URJ","conferencePaper","2024","Gnehm, Ann-Sophie; Clematide, Simon","Mapping Work Task Descriptions from German Job Ads on the O*NET Work Activities Ontology","Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)","","","","https://aclanthology.org/2024.lrec-main.963/","This work addresses the challenge of extracting job tasks from German job postings and mapping them to the fine-grained work activities classification in the O*NET labor market ontology. By utilizing ontological data with a Multiple Negatives Ranking loss and integrating a modest volume of labeled job advertisement data into the training process, our top configuration achieved a notable precision of 70% for the best mapping on the test set, representing a substantial improvement compared to the 33% baseline delivered by a general-domain SBERT. In our experiments the following factors proved to be most effective for improving SBERT models: First, the incorporation of subspan markup, both during training and inference, supports accurate classification, by streamlining varied job ad task formats with structured, uniform ontological work activities. Second, the inclusion of additional occupational information from O*NET into training supported learning by contextualizing hierarchical ontological relationships. Third, the most significant performance improvement was achieved by updating SBERT models with labeled job ad data specifically addressing challenging cases encountered during pre-finetuning, effectively bridging the semantic gap between O*NET and job ad data.","2024-05","2025-09-10 13:17:22","2025-09-10 13:17:22","","11049–11059","","","","","","","","","","","ELRA and ICCL","Torino, Italia","","","","","","","","","","","","","","Calzolari, Nicoletta; Kan, Min-Yen; Hoste, Veronique; Lenci, Alessandro; Sakti, Sakriani; Xue, Nianwen","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9W5TAU95","conferencePaper","2024","Liu, Feiyan; Li, Liangzhi; Wang, Xiaoli; Luo, Feng; Liu, Chang; Su, Jinsong; Qian, Yiming","MHGRL: An Effective Representation Learning Model for Electronic Health Records","Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)","","","","https://aclanthology.org/2024.lrec-main.985/","Electronic health records (EHRs) serve as a digital repository storing comprehensive medical information about patients. Representation learning for EHRs plays a crucial role in healthcare applications. In this paper, we propose a Multimodal Heterogeneous Graph-enhanced Representation Learning, denoted as MHGRL, aimed at learning effective EHR representations. To address the challenge posed by data insufficiency of EHRs, MHGRL utilizes a multimodal heterogeneous graph to model an EHR. Specifically, we construct a heterogeneous graph for each EHR and enrich it by incorporating multimodal information with medical ontology and textual notes. With the integration of pre-trained model, graph neural network, and attention mechanism, MHGRL effectively incorporates both node attributes and structural information across a multimodal heterogeneous graph. Moreover, we employ contrastive learning to ensure the consistency of representations for similar EHRs and improve the model robustness. The experimental results show that MHGRL outperforms all baselines on two real clinical datasets in downstream tasks, including EHR clustering and disease prediction. The code is available at https://github.com/emmali808/MHGRL.","2024-05","2025-09-10 13:17:22","2025-09-10 13:17:22","","11272–11282","","","","","","","","","","","ELRA and ICCL","Torino, Italia","","","","","","","","","","","","","","Calzolari, Nicoletta; Kan, Min-Yen; Hoste, Veronique; Lenci, Alessandro; Sakti, Sakriani; Xue, Nianwen","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TMLMJTZ9","conferencePaper","2024","Dezotti, Lucas Consolin; Passarotti, Marco; Mambrini, Francesco","Modelling and Linking an Old Latin-Portuguese Dictionary to the LiLa Knowledge Base","Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)","","","","https://aclanthology.org/2024.lrec-main.1008/","This paper describes the steps undertaken to include data from Antonio Velez's bilingual Latin-Portuguese dictionary (Index Totius Artis, 1744) into the LiLa Knowledge Base of interoperable linguistic resources for Latin. The paper focuses on how the lexical and lexicographic information of the source dictionary was modelled by using respectively the Lexicon Model for Ontologies (OntoLex-lemon) and its lexicog module. The linking process of the dictionary entries with those of the LiLa collection of Latin lemmas is detailed, discussing issues in dealing with ambiguities and typographical errors found in the source. The result is the first Latin-Portuguese lexical resource made interoperable with the (meta)data of the other linguistic resources for Latin interlinked in the LiLa Knowledge Base, providing new ways of assessing the dictionary information or using its content as starting point to explore the connections with other interlinked linguistic resources. A couple of use case scenarios illustrate those possibilities.","2024-05","2025-09-10 13:17:22","2025-09-10 13:17:22","","11537–11547","","","","","","","","","","","ELRA and ICCL","Torino, Italia","","","","","","","","","","","","","","Calzolari, Nicoletta; Kan, Min-Yen; Hoste, Veronique; Lenci, Alessandro; Sakti, Sakriani; Xue, Nianwen","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AVVAE2U2","conferencePaper","2024","Park, Dojun; Padó, Sebastian","Multi-Dimensional Machine Translation Evaluation: Model Evaluation and Resource for Korean","Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)","","","","https://aclanthology.org/2024.lrec-main.1024/","Almost all frameworks for the manual or automatic evaluation of machine translation characterize the quality of an MT output with a single number. An exception is the Multidimensional Quality Metrics (MQM) framework which offers a fine-grained ontology of quality dimensions for scoring (such as style, fluency, accuracy, and terminology). Previous studies have demonstrated the feasibility of MQM annotation but there are, to our knowledge, no computational models that predict MQM scores for novel texts, due to a lack of resources. In this paper, we address these shortcomings by (a) providing a 1200-sentence MQM evaluation benchmark for the language pair English-Korean and (b) reframing MT evaluation as the multi-task problem of simultaneously predicting several MQM scores using SOTA language models, both in a reference-based MT evaluation setup and a reference-free quality estimation (QE) setup. We find that reference-free setup outperforms its counterpart in the style dimension while reference-based models retain an edge regarding accuracy. Overall, RemBERT emerges as the most promising model. Through our evaluation, we offer an insight into the translation quality in a more fine-grained, interpretable manner.","2024-05","2025-09-10 13:17:22","2025-09-10 13:17:22","","11723–11744","","","","","","","","","","","ELRA and ICCL","Torino, Italia","","","","","","","","","","","","","","Calzolari, Nicoletta; Kan, Min-Yen; Hoste, Veronique; Lenci, Alessandro; Sakti, Sakriani; Xue, Nianwen","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UYFR3YPU","conferencePaper","2024","Phi, Van-Thuy; Teranishi, Hiroki; Matsumoto, Yuji; Oka, Hiroyuki; Ishii, Masashi","PolyNERE: A Novel Ontology and Corpus for Named Entity Recognition and Relation Extraction in Polymer Science Domain","Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)","","","","https://aclanthology.org/2024.lrec-main.1126/","Polymers are widely used in diverse fields, and the demand for efficient methods to extract and organize information about them is increasing. An automated approach that utilizes machine learning can accurately extract relevant information from scientific papers, providing a promising solution for automating information extraction using annotated training data. In this paper, we introduce a polymer-relevant ontology featuring crucial entities and relations to enhance information extraction in the polymer science field. Our ontology is customizable to adapt to specific research needs. We present PolyNERE, a high-quality named entity recognition (NER) and relation extraction (RE) corpus comprising 750 polymer abstracts annotated using our ontology. Distinctive features of PolyNERE include multiple entity types, relation categories, support for various NER settings, and the ability to assert entities and relations at different levels. PolyNERE also facilitates reasoning in the RE task through supporting evidence. While our experiments with recent advanced methods achieved promising results, challenges persist in adapting NER and RE from abstracts to full-text paragraphs. This emphasizes the need for robust information extraction systems in the polymer domain, making our corpus a valuable benchmark for future developments.","2024-05","2025-09-10 13:17:22","2025-09-10 13:17:22","","12856–12866","","","","","","","","","","","ELRA and ICCL","Torino, Italia","","","","","","","","","","","","","","Calzolari, Nicoletta; Kan, Min-Yen; Hoste, Veronique; Lenci, Alessandro; Sakti, Sakriani; Xue, Nianwen","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WSYKCX2G","conferencePaper","2024","Liu, Jianyu; Bi, Sheng; Qi, Guilin","PRIMO: Progressive Induction for Multi-hop Open Rule Generation","Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING 2024)","","","","https://aclanthology.org/2024.lrec-main.1137/","Open rules refer to the implication from premise atoms to hypothesis atoms, which captures various relationships between instances in the real world. Injecting open rule knowledge into the machine helps to improve the performance of downstream tasks such as dialogue and relation extraction. Existing approaches focus on single-hop open rule generation, ignoring scenarios involving multiple hops, leading to logical inconsistencies between premise and hypothesis atoms, as well as semantic duplication of generated rule atoms. To address these issues, we propose a progressive multi-stage open rule generation method called PRIMO. We introduce ontology information during the rule generation stage to reduce ambiguity and improve rule accuracy. PRIMO constructs a multi-stage structure consisting of generation, extraction, and rank modules to fully leverage the latent knowledge within the language model across multiple dimensions. Furthermore, we employ reinforcement learning from human feedback to further optimize model, enhancing the model's understanding of commonsense knowledge. Experimental results demonstrate that compared to baseline models, PRIMO significantly enhances rule quality and diversity while reducing the repetition rate of rule atoms.","2024-05","2025-09-10 13:17:22","2025-09-10 13:17:22","","12988–12998","","","","","","","","","","","ELRA and ICCL","Torino, Italia","","","","","","","","","","","","","","Calzolari, Nicoletta; Kan, Min-Yen; Hoste, Veronique; Lenci, Alessandro; Sakti, Sakriani; Xue, Nianwen","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"LLVSHVDJ","conferencePaper","2024","Konan, Sachin; Rudolph, Larry; Affens, Scott","Automating the Generation of a Functional Semantic Types Ontology with Foundational Models","Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 6: Industry Track)","","","10.18653/v1/2024.naacl-industry.21","https://aclanthology.org/2024.naacl-industry.21/","The rise of data science, the inherent dirtiness of data, and the proliferation of vast data providers have increased the value proposition of Semantic Types. Semantic Types are a way of encoding contextual information onto a data schema that informs the user about the definitional meaning of data, its broader context, and relationships to other types. We increasingly see a world where providing structure to this information, attached directly to data, will enable both people and systems to better understand the content of a dataset and the ability to efficiently automate data tasks such as validation, mapping/joins, and eventually machine learning. While ontological systems exist, they have not had widespread adoption due to challenges in mapping to operational datasets and lack of specificity of entity-types. Additionally, the validation checks associated with data are stored in code bases separate from the datasets that are distributed. In this paper, we address both challenges holistically by proposing a system that efficiently maps and encodes functional meaning on Semantic Types.","2024-06","2025-09-10 13:17:22","2025-09-10 13:17:22","","248–265","","","","","","","","","","","Association for Computational Linguistics","Mexico City, Mexico","","","","","","","","","","","","","","Yang, Yi; Davani, Aida; Sil, Avi; Kumar, Anoop","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JYHU7NUU","conferencePaper","2024","Chowdhury, Saurav; Joshi, Suyog; Dey, Lipika","Cross Examine: An Ensemble-based approach to leverage Large Language Models for Legal Text Analytics","Proceedings of the Natural Legal Language Processing Workshop 2024","","","10.18653/v1/2024.nllp-1.16","https://aclanthology.org/2024.nllp-1.16/","Legal documents are complex in nature, describing a course of argumentative reasoning that is followed to settle a case. Churning through large volumes of legal documents is a daily requirement for a large number of professionals who need access to the information embedded in them. Natural language processing methods that help in document summarization with key information components, insight extraction and question answering play a crucial role in legal text processing. Most of the existing document analysis systems use supervised machine learning, which require large volumes of annotated training data for every different application and are expensive to build. In this paper we propose a legal text analytics pipeline using Large Language Models (LLM), which can work with little or no training data. For document summarization, we propose an iterative pipeline using retrieval augmented generation to ensure that the generated text remains contextually relevant. For question answering, we propose a novel ontology-driven ensemble approach similar to cross-examination that exploits questioning and verification principles. A knowledge graph, created with the extracted information, stores the key entities and relationships reflecting the repository content structure. A new dataset is created with Indian court documents related to bail applications for cases filed under Protection of Children from Sexual Offences (POCSO) Act, 2012 an Indian law to protect children from sexual abuse and offences. Analysis of insights extracted from the answers reveal patterns of crime and social conditions leading to those crimes, which are important inputs for social scientists as well as legal system.","2024-11","2025-09-10 13:17:22","2025-09-10 13:17:22","","194–204","","","","","","","","","","","Association for Computational Linguistics","Miami, FL, USA","","","","","","","","","","","","","","Aletras, Nikolaos; Chalkidis, Ilias; Barrett, Leslie; Goanță, Cătălina; Preoțiuc-Pietro, Daniel; Spanakis, Gerasimos","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YVGYJ9A7","conferencePaper","2024","Vasilakis, Yannis; Bittner, Rachel; Pauwels, Johan","Evaluation of Pretrained Language Models on Music Understanding","Proceedings of the 3rd Workshop on NLP for Music and Audio (NLP4MusA)","","","","https://aclanthology.org/2024.nlp4musa-1.16/","Music-text multimodal systems have enabled new approaches to Music Information Research (MIR) applications. Despite the reported success, there has been little effort in evaluating the musical knowledge of Large Language Models (LLM). We demonstrate that LLMs suffer from prompt sensitivity, inability to model negation and sensitivity towards specific words. We quantified these properties as a triplet-based accuracy, evaluating the ability to model the relative similarity of labels in a hierarchical ontology. We leveraged Audioset ontology to generate triplets consisting of anchor, positive and negative label for genre/instruments sub-tree and use six general-purpose Transformer-based models. Triplets required filtering, as some were difficult to judge and therefore relatively uninformative for evaluation purposes. Despite the relatively high accuracy reported, inconsistencies are evident in all six models, suggesting that off-the-shelf LLMs need adaptation to music before use.","2024-11","2025-09-10 13:17:22","2025-09-10 13:17:22","","98–106","","","","","","","","","","","Association for Computational Lingustics","Oakland, USA","","","","","","","","","","","","","","Kruspe, Anna; Oramas, Sergio; Epure, Elena V.; Sordo, Mohamed; Weck, Benno; Doh, SeungHeon; Won, Minz; Manco, Ilaria; Meseguer-Brocal, Gabriel","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9YFN84Q8","conferencePaper","2024","Cominetti, Federica; Gregori, Lorenzo; Lombardi Vallauri, Edoardo; Panunzi, Alessandro","IMPAQTS: a multimodal corpus of parliamentary and other political speeches in Italy (1946-2023), annotated with implicit strategies","Proceedings of the IV Workshop on Creating, Analysing, and Increasing Accessibility of Parliamentary Corpora (ParlaCLARIN) @ LREC-COLING 2024","","","","https://aclanthology.org/2024.parlaclarin-1.15/","The paper introduces the IMPAQTS corpus of Italian political discourse, a multimodal corpus of around 2.65 million tokens including 1,500 speeches uttered by 150 prominent politicians spanning from 1946 to 2023. Covering the entire history of the Italian Republic, the collection exhibits a non-homogeneous consistency that progressively increases in quantity towards the present. The corpus is balanced according to textual and socio-linguistic criteria and includes different types of speeches. The sociolinguistic features of the speakers are carefully considered to ensure representation of Republican Italian politicians. For each speaker, the corpus contains 4 parliamentary speeches, 2 rallies, 1 party assembly, and 3 statements (in person or broadcasted). Parliamentary speeches therefore constitute the largest section of the corpus (40% of the total), enabling direct comparison with other types of political speeches. The collection procedure, including details relevant to the transcription protocols, and the processing pipeline are described. The corpus has been pragmatically annotated to include information about the implicitly conveyed questionable contents, paired with their explicit paraphrasis, providing the largest Italian collection of ecologic examples of linguistic implicit strategies. The adopted ontology of linguistic implicitness and the fine-grained annotation scheme are presented in detail.","2024-05","2025-09-10 13:17:22","2025-09-10 13:17:22","","101–109","","","","","","","","","","","ELRA and ICCL","Torino, Italia","","","","","","","","","","","","","","Fiser, Darja; Eskevich, Maria; Bordon, David","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VT47BBTD","conferencePaper","2024","Wu, Shenghan; Hsu, Wynne; Lee, Mong Li","EHDChat: A Knowledge-Grounded, Empathy-Enhanced Language Model for Healthcare Interactions","Proceedings of the Second Workshop on Social Influence in Conversations (SICon 2024)","","","10.18653/v1/2024.sicon-1.10","https://aclanthology.org/2024.sicon-1.10/","Large Language Models (LLMs) excel at a range of tasks but often struggle with issues like hallucination and inadequate empathy support. To address hallucinations, we ground our dialogues in medical knowledge sourced from external repositories such as Disease Ontology and DrugBank. To improve empathy support, we develop the Empathetic Healthcare Dialogues dataset, which utilizes multiple dialogue strategies in each response. This dataset is then used to fine-tune an LLM, and we introduce a lightweight, adaptable method called Strategy Combination Guidance to enhance the emotional support capabilities of the fine-tuned model, named EHDChat. Our evaluations show that EHDChat significantly outperforms existing models in providing emotional support and medical accuracy, demonstrating the effectiveness of our approach in enhancing empathetic and informed AI interactions in healthcare.","2024-11","2025-09-10 13:17:22","2025-09-10 13:17:22","","141–151","","","","","","","","","","","Association for Computational Linguistics","Miami, Florida, USA","","","","","","","","","","","","","","Hale, James; Chawla, Kushal; Garg, Muskan","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4WP5NRVA","conferencePaper","2024","Vukovic, Renato; Arps, David; van Niekerk, Carel; Ruppik, Benjamin Matthias; Lin, Hsien-chin; Heck, Michael; Gasic, Milica","Dialogue Ontology Relation Extraction via Constrained Chain-of-Thought Decoding","Proceedings of the 25th Annual Meeting of the Special Interest Group on Discourse and Dialogue","","","10.18653/v1/2024.sigdial-1.33","https://aclanthology.org/2024.sigdial-1.33/","State-of-the-art task-oriented dialogue systems typically rely on task-specific ontologies for fulfilling user queries. The majority of task-oriented dialogue data, such as customer service recordings, comes without ontology and annotation. Such ontologies are normally built manually, limiting the application of specialised systems. Dialogue ontology construction is an approach for automating that process and typically consists of two steps: term extraction and relation extraction. In this work, we focus on relation extraction in a transfer learning set-up. To improve the generalisation, we propose an extension to the decoding mechanism of large language models. We adapt Chain-of-Thought (CoT) decoding, recently developed for reasoning problems, to generative relation extraction. Here, we generate multiple branches in the decoding space and select the relations based on a confidence threshold. By constraining the decoding to ontology terms and relations, we aim to decrease the risk of hallucination. We conduct extensive experimentation on two widely used datasets and find improvements in performance on target ontology for source fine-tuned and one-shot prompted large language models.","2024-09","2025-09-10 13:17:22","2025-09-10 13:17:22","","370–384","","","","","","","","","","","Association for Computational Linguistics","Kyoto, Japan","","","","","","","","","","","","","","Kawahara, Tatsuya; Demberg, Vera; Ultes, Stefan; Inoue, Koji; Mehri, Shikib; Howcroft, David; Komatani, Kazunori","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"K5FN8J33","conferencePaper","2024","Bacciu, Andrea; Damonte, Marco; Basaldella, Marco; Monti, Emilio","Handling Ontology Gaps in Semantic Parsing","Proceedings of the 13th Joint Conference on Lexical and Computational Semantics (*SEM 2024)","","","10.18653/v1/2024.starsem-1.28","https://aclanthology.org/2024.starsem-1.28/","The majority of Neural Semantic Parsing (NSP) models are developed with the assumption that there are no concepts outside the ones such models can represent with their target symbols (closed-world assumption). This assumption leads to generate hallucinated outputs rather than admitting their lack of knowledge. Hallucinations can lead to wrong or potentially offensive responses to users. Hence, a mechanism to prevent this behavior is crucial to build trusted NSP-based Question Answering agents. To that end, we propose the Hallucination Simulation Framework (HSF), a general setting for stimulating and analyzing NSP model hallucinations. The framework can be applied to any NSP task with a closed-ontology. Using the proposed framework and KQA Pro as the benchmark dataset, we assess state-of-the-art techniques for hallucination detection. We then present a novel hallucination detection strategy that exploits the computational graph of the NSP model to detect the NSP hallucinations in the presence of ontology gaps, out-of-domain utterances, and to recognize NSP errors, improving the F1-Score respectively by \textasciitilde21%, \textasciitilde24% and \textasciitilde1%. This is the first work in closed-ontology NSP that addresses the problem of recognizing ontology gaps. We release our code and checkpoints at https://github.com/amazon-science/handling-ontology-gaps-in-semantic-parsing.","2024-06","2025-09-10 13:17:22","2025-09-10 13:17:22","","345–359","","","","","","","","","","","Association for Computational Linguistics","Mexico City, Mexico","","","","","","","","","","","","","","Bollegala, Danushka; Shwartz, Vered","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"H3NNEBMY","conferencePaper","2024","Saetia, Chanatip; Phruetthiset, Jiratha; Chalothorn, Tawunrat; Lertsutthiwong, Monchai; Taerungruang, Supawat; Buabthong, Pakpoom","Financial Product Ontology Population with Large Language Models","Proceedings of TextGraphs-17: Graph-based Methods for Natural Language Processing","","","","https://aclanthology.org/2024.textgraphs-1.4/","Ontology population, which aims to extract structured data to enrich domain-specific ontologies from unstructured text, typically faces challenges in terms of data scarcity and linguistic complexity, particularly in specialized fields such as retail banking. In this study, we investigate the application of large language models (LLMs) to populate domain-specific ontologies of retail banking products from Thai corporate documents. We compare traditional span-based approaches to LLMs-based generative methods, with different prompting techniques. Our findings reveal that while span-based methods struggle with data scarcity and the complex linguistic structure, LLMs-based generative approaches substantially outperform, achieving a 61.05% F1 score, with the most improvement coming from providing examples in the prompts. This improvement highlights the potential of LLMs for ontology population tasks, offering a scalable and efficient solution for structured information extraction in especially in low-resource language settings.","2024-08","2025-09-10 13:17:22","2025-09-10 13:17:22","","53–60","","","","","","","","","","","Association for Computational Linguistics","Bangkok, Thailand","","","","","","","","","","","","","","Ustalov, Dmitry; Gao, Yanjun; Panchenko, Alexander; Tutubalina, Elena; Nikishina, Irina; Ramesh, Arti; Sakhovskiy, Andrey; Usbeck, Ricardo; Penn, Gerald; Valentino, Marco","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HNC9G9A5","conferencePaper","2024","Heddaya, Mourad; Zeng, Qingcheng; Zentefis, Alexander; Voigt, Rob; Tan, Chenhao","Causal Micro-Narratives","Proceedings of the 6th Workshop on Narrative Understanding","","","10.18653/v1/2024.wnu-1.12","https://aclanthology.org/2024.wnu-1.12/","We present a novel approach to classify causal micro-narratives from text. These narratives are sentence-level explanations of the cause(s) and/or effect(s) of a target subject. The approach requires only a subject-specific ontology of causes and effects, and we demonstrate it with an application to inflation narratives. Using a human-annotated dataset spanning historical and contemporary US news articles for training, we evaluate several large language models (LLMs) on this multi-label classification task. The best-performing model—a fine-tuned Llama 3.1 8B—achieves F1 scores of 0.87 on narrative detection and 0.71 on narrative classification. Comprehensive error analysis reveals challenges arising from linguistic ambiguity and highlights how model errors often mirror human annotator disagreements. This research establishes a framework for extracting causal micro-narratives from real-world data, with wide-ranging applications to social science research.","2024-11","2025-09-10 13:17:22","2025-09-10 13:17:22","","67–84","","","","","","","","","","","Association for Computational Linguistics","Miami, Florida, USA","","","","","","","","","","","","","","Lal, Yash Kumar; Clark, Elizabeth; Iyyer, Mohit; Chaturvedi, Snigdha; Brei, Anneliese; Brahman, Faeze; Chandu, Khyathi Raghavi","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"4SJDBZKI","conferencePaper","2024","Vukovic, Renato","Ontology Construction for Task-oriented Dialogue","Proceedings of the 20th Workshop of Young Researchers' Roundtable on Spoken Dialogue Systems","","","10.18653/v1/2024.yrrsds-1.20","https://aclanthology.org/2024.yrrsds-1.20/","My research interests lie generally in dialogue ontology construction, that uses techniques from information extraction to extract relevant terms from task-oriented dialogue data and order them by finding hierarchical relations between them.","2024-09","2025-09-10 13:17:22","2025-09-10 13:17:22","","53–56","","","","","","","","","","","Association for Computational Linguistics","Kyoto, Japan","","","","","","","","","","","","","","Inoue, Koji; Fu, Yahui; Axelsson, Agnes; Ohashi, Atsumoto; Madureira, Brielen; Zenimoto, Yuki; Mohapatra, Biswesh; Stricker, Armand; Khosla, Sopan","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7DGMGEME","conferencePaper","2025","Park, Bumjin; Leejinsil, Leejinsil; Choi, Jaesik","Deontological Keyword Bias: The Impact of Modal Expressions on Normative Judgments of Language Models","Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)","979-8-89176-251-0","","10.18653/v1/2025.acl-long.360","https://aclanthology.org/2025.acl-long.360/","Large language models (LLMs) are increasingly engaging in moral and ethical reasoning, where criteria for judgment are often unclear, even for humans. While LLM alignment studies cover many areas, one important yet underexplored area is how LLMs make judgments about obligations. This work reveals a strong tendency in LLMs to judge non-obligatory contexts as obligations when prompts are augmented with modal expressions such as <i>must</i> or <i>ought to</i>. We introduce this phenomenon as Deontological Keyword Bias (DKB). We find that LLMs judge over 90% of commonsense scenarios as obligations when modal expressions are present. This tendency is consist across various LLM families, question types, and answer formats. To mitigate DKB, we propose a judgment strategy that integrates few-shot examples with reasoning prompts. This study sheds light on how modal expressions, as a form of linguistic framing, influence the normative decisions of LLMs and underscores the importance of addressing such biases to ensure judgment alignment.","2025-07","2025-09-10 13:17:22","2025-09-10 13:17:22","","7277–7296","","","","","","","","","","","Association for Computational Linguistics","Vienna, Austria","","","","","","","","","","","","","","Che, Wanxiang; Nabende, Joyce; Shutova, Ekaterina; Pilehvar, Mohammad Taher","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8WU3UWXI","conferencePaper","2025","Cui, Shaobo; Mouchel, Luca; Faltings, Boi","Uncertainty in Causality: A New Frontier","Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)","979-8-89176-251-0","","10.18653/v1/2025.acl-long.396","https://aclanthology.org/2025.acl-long.396/","Understanding uncertainty in causality is vital in various domains, including core NLP tasks like event causality extraction, commonsense reasoning, and counterfactual text generation. However, existing literature lacks a comprehensive examination of this area. This survey aims to fill this gap by thoroughly reviewing uncertainty in causality. We first introduce a novel trichotomy, categorizing causal uncertainty into aleatoric (inherent randomness in causal data), epistemic (causal model limitations), and ontological (existence of causal links) uncertainty. We then survey methods for quantifying uncertainty in causal analysis and highlight the complementary relationship between causal uncertainty and causal strength. Furthermore, we examine the challenges that large language models (LLMs) face in handling causal uncertainty, such as hallucinations and inconsistencies, and propose key traits for an optimal causal LLM. Our paper reviews current approaches and outlines future research directions, aiming to serve as a practical guide for researchers and practitioners in this emerging field.","2025-07","2025-09-10 13:17:22","2025-09-10 13:17:22","","8022–8044","","","","","","","","","","","Association for Computational Linguistics","Vienna, Austria","","","","","","","","","","","","","","Che, Wanxiang; Nabende, Joyce; Shutova, Ekaterina; Pilehvar, Mohammad Taher","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Z9W7D582","conferencePaper","2025","Liu, Runxuan; Luobei, Luobei; Li, Jiaqi; Wang, Baoxin; Liu, Ming; Wu, Dayong; Wang, Shijin; Qin, Bing","Ontology-Guided Reverse Thinking Makes Large Language Models Stronger on Knowledge Graph Question Answering","Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)","979-8-89176-251-0","","10.18653/v1/2025.acl-long.741","https://aclanthology.org/2025.acl-long.741/","Large language models (LLMs) have shown remarkable capabilities in natural language processing. However, in knowledge graph question answering tasks (KGQA), there remains the issue of answering questions that require multi-hop reasoning. Existing methods rely on entity vector matching, but the purpose of the question is abstract and difficult to match with specific entities. As a result, it is difficult to establish reasoning paths to the purpose, which leads to information loss and redundancy. To address this issue, inspired by human reverse thinking, we propose Ontology-Guided Reverse Thinking (ORT), a novel framework that constructs reasoning paths from purposes back to conditions. ORT operates in three key phases: (1) using LLM to extract purpose labels and condition labels, (2) constructing label reasoning paths based on the KG ontology, and (3) using the label reasoning paths to guide knowledge retrieval. Experiments on the WebQSP and CWQ datasets show that ORT achieves state-of-the-art performance and significantly enhances the capability of LLMs for KGQA.","2025-07","2025-09-10 13:17:22","2025-09-10 13:17:22","","15269–15284","","","","","","","","","","","Association for Computational Linguistics","Vienna, Austria","","","","","","","","","","","","","","Che, Wanxiang; Nabende, Joyce; Shutova, Ekaterina; Pilehvar, Mohammad Taher","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Z5VPBP8I","conferencePaper","2025","Ha, Hyeonjeong; Jin, Xiaomeng; Kim, Jeonghwan; Liu, Jiateng; Wang, Zhenhailong; Nguyen, Khanh Duy; Blume, Ansel; Peng, Nanyun; Chang, Kai-Wei; Ji, Heng","SYNTHIA: Novel Concept Design with Affordance Composition","Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)","979-8-89176-251-0","","10.18653/v1/2025.acl-long.1020","https://aclanthology.org/2025.acl-long.1020/","Text-to-image (T2I) models enable rapid concept design, making them widely used in AI-driven design. While recent studies focus on generating semantic and stylistic variations of given design concepts, –the integration of multiple affordances into a single coherent concept–remains largely overlooked. In this paper, we introduce SYNTHIA, a framework for generating novel, functionally coherent designs based on desired affordances. Our approach leverages a hierarchical concept ontology that decomposes concepts into parts and affordances, serving as a crucial building block for functionally coherent design. We also develop a curriculum learning scheme based on our ontology that contrastively fine-tunes T2I models to progressively learn affordance composition while maintaining visual novelty. To elaborate, we (i) gradually increase affordance distance, guiding models from basic concept-affordance association to complex affordance compositions that integrate parts of distinct affordances into a single, coherent form, and (ii) enforce visual novelty by employing contrastive objectives to push learned representations away from existing concepts. Experimental results show that SYNTHIA outperforms state-of-the-art T2I models, demonstrating absolute gains of 25.1% and 14.7% for novelty and functional coherence in human evaluation, respectively.","2025-07","2025-09-10 13:17:22","2025-09-10 13:17:22","","20939–20958","","","","","","","","","","","Association for Computational Linguistics","Vienna, Austria","","","","","","","","","","","","","","Che, Wanxiang; Nabende, Joyce; Shutova, Ekaterina; Pilehvar, Mohammad Taher","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"94PA4PR3","conferencePaper","2025","Liu, Shanshan; Nishida, Noriki; Munne, Rumana Ferdous; Tokunaga, Narumi; Yamagata, Yuki; Kozaki, Kouji; Matsumoto, Yuji","MA-COIR: Leveraging Semantic Search Index and Generative Models for Ontology-Driven Biomedical Concept Recognition","Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 4: Student Research Workshop)","979-8-89176-254-1","","10.18653/v1/2025.acl-srw.39","https://aclanthology.org/2025.acl-srw.39/","Recognizing biomedical concepts in the text is vital for ontology refinement, knowledge graph construction, and concept relationship discovery. However, traditional concept recognition methods, relying on explicit mention identification, often fail to capture complex concepts not explicitly stated in the text. To overcome this limitation, we introduce MA-COIR, a framework that reformulates concept recognition as an indexing-recognition task. By assigning semantic search indexes (ssIDs) to concepts, MA-COIR resolves ambiguities in ontology entries and enhances recognition efficiency. Using a pretrained BART-based model fine-tuned on small datasets, our approach reduces computational requirements to facilitate adoption by domain experts. Furthermore, we incorporate large language model (LLM)-generated queries and synthetic data to improve recognition in low-resource settings. Experimental results on three scenarios (CDR, HPO, and HOIP) highlight the effectiveness of MA-COIR in recognizing both explicit and implicit concepts without the need for mention-level annotations during inference, advancing ontology-driven concept recognition in biomedical domain applications. Our code and constructed data are available at https://github.com/sl-633/macoir-master.","2025-07","2025-09-10 13:17:22","2025-09-10 13:17:22","","596–607","","","","","","","","","","","Association for Computational Linguistics","Vienna, Austria","","","","","","","","","","","","","","Zhao, Jin; Wang, Mingyang; Liu, Zhu","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Y2BNQB8E","conferencePaper","2025","Caporusso, Jaya; Purver, Matthew; Pollak, Senja","A Computational Framework to Identify Self-Aspects in Text","Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 4: Student Research Workshop)","979-8-89176-254-1","","10.18653/v1/2025.acl-srw.47","https://aclanthology.org/2025.acl-srw.47/","This Ph.D. proposal introduces a plan to develop a computational framework to identify Self-aspects in text. The Self is a multifaceted construct and it is reflected in language. While it is described across disciplines like cognitive science and phenomenology, it remains underexplored in natural language processing (NLP). Many of the aspects of the Self align with psychological and other well-researched phenomena (e.g., those related to mental health), highlighting the need for systematic NLP-based analysis. In line with this, we plan to introduce an ontology of Self-aspects and a gold-standard annotated dataset. Using this foundation, we will develop and evaluate conventional discriminative models, generative large language models, and embedding-based retrieval approaches against four main criteria: interpretability, ground-truth adherence, accuracy, and computational efficiency. Top-performing models will be applied in case studies in mental health and empirical phenomenology.","2025-07","2025-09-10 13:17:22","2025-09-10 13:17:22","","725–739","","","","","","","","","","","Association for Computational Linguistics","Vienna, Austria","","","","","","","","","","","","","","Zhao, Jin; Wang, Mingyang; Liu, Zhu","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"V75BFHNB","conferencePaper","2025","Dong, Haoyu; Hu, Yue; Peng, Huailiang; Cao, Yanan","TableCoder: Table Extraction from Text via Reliable Code Generation","Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (Volume 6: Industry Track)","979-8-89176-288-6","","10.18653/v1/2025.acl-industry.98","https://aclanthology.org/2025.acl-industry.98/","This paper introduces a task aimed at extracting structured tables from text using natural language (NL) instructions. We present TableCoder, an approach that leverages the symbolic nature of code to enhance the robustness of table structure construction and content extraction. TableCoder first generates Python classes or SQL statements to explicitly construct table structures, capturing semantic ontology, computational dependencies, numerical properties, and format strings. This approach reliably mitigates issues such as structural errors, erroneous computations, and mismatched value types. Subsequently, TableCoder proposes grounded content extraction, populating table cells sequentially and maintaining the exact order in which they are mentioned in the source text. By simulating a grounded “translation” from text to code, this method reduces the likelihood of omissions and hallucinations.Experimental results demonstrate that TableCoder significantly improves F1 scores and mitigates hallucination and computational errors, crucial for high-stakes applications like government data analytics and financial compliance reporting. Moreover, the code-generation-based method naturally integrates with standard SQL databases and Python workflows, ensuring seamless deployment in existing enterprise data pipelines.","2025-07","2025-09-10 13:17:22","2025-09-10 13:17:22","","1399–1412","","","","","","","","","","","Association for Computational Linguistics","Vienna, Austria","","","","","","","","","","","","","","Rehm, Georg; Li, Yunyao","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TY6HUTEZ","conferencePaper","2025","Yoo, Hyunwoo; Sokhansanj, Bahrad; Brown, James","Enhancing Antimicrobial Drug Resistance Classification by Integrating Sequence-Based and Text-Based Representations","Proceedings of the 24th Workshop on Biomedical Language Processing","979-8-89176-275-6","","10.18653/v1/2025.bionlp-1.23","https://aclanthology.org/2025.bionlp-1.23/","Antibiotic resistance identification is essential for public health, medical treatment, and drug development. Traditional sequence-based models struggle with accurate resistance prediction due to the lack of biological context. To address this, we propose an NLP-based model that integrates genetic sequences with structured textual annotations, including gene family classifications and resistance mechanisms. Our approach leverages pretrained language models for both genetic sequences and biomedical text, aligning biological metadata with sequence-based embeddings. We construct a novel dataset based on the Antibiotic Resistance Ontology (ARO), consolidating gene sequences with resistance-related textual information. Experiments show that incorporating domain knowledge significantly improves classification accuracy over sequence-only models, reducing reliance on exhaustive laboratory testing. By integrating genetic sequence processing with biomedical text understanding, our approach provides a scalable and interpretable solution for antibiotic resistance prediction.","2025-08","2025-09-10 13:17:22","2025-09-10 13:17:22","","263–273","","","","","","","","","","","Association for Computational Linguistics","Viena, Austria","","","","","","","","","","","","","","Demner-Fushman, Dina; Ananiadou, Sophia; Miwa, Makoto; Tsujii, Junichi","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EMIFE4NB","journalArticle","2025","Zhang, Xiao; Bouma, Gosse; Bos, Johan","Neural Semantic Parsing with Extremely Rich Symbolic Meaning Representations","Computational Linguistics","","","10.1162/coli_a_00542","https://aclanthology.org/2025.cl-1.7/","Current open-domain neural semantics parsers show impressive performance. However, closer inspection of the symbolic meaning representations they produce reveals significant weaknesses: Sometimes they tend to merely copy character sequences from the source text to form symbolic concepts, defaulting to the most frequent word sense based in the training distribution. By leveraging the hierarchical structure of a lexical ontology, we introduce a novel compositional symbolic representation for concepts based on their position in the taxonomical hierarchy. This representation provides richer semantic information and enhances interpretability. We introduce a neural “taxonomical” semantic parser to utilize this new representation system of predicates, and compare it with a standard neural semantic parser trained on the traditional meaning representation format, employing a novel challenge set and evaluation metric for evaluation. Our experimental findings demonstrate that the taxonomical model, trained on much richer and complex meaning representations, is slightly subordinate in performance to the traditional model using the standard metrics for evaluation, but outperforms it when dealing with out-of-vocabulary concepts. We further show through neural model probing that training on a taxonomic representation enhances the model's ability to learn the taxonomical hierarchy. This finding is encouraging for research in computational semantics that aims to combine data-driven distributional meanings with knowledge-based symbolic representations.","2025-03","2025-09-10 13:17:22","2025-09-10 13:17:22","","235–274","","1","51","","","","","","","","","","","","","","","","","Place: Cambridge, MA Publisher: MIT Press","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MJCET45Y","conferencePaper","2025","Munne, Rumana Ferdous; Nishida, Noriki; Liu, Shanshan; Tokunaga, Narumi; Yamagata, Yuki; Kozaki, Kouji; Matsumoto, Yuji","Zero-Shot Entailment Learning for Ontology-Based Biomedical Annotation Without Explicit Mentions","Proceedings of the 31st International Conference on Computational Linguistics","","","","https://aclanthology.org/2025.coling-main.542/","Automatic biomedical annotation is essential for advancing medical research, diagnosis, and treatment. However, it presents significant challenges, especially when entities are not explicitly mentioned in the text, leading to difficulties in extraction of relevant information. These challenges are intensified by unclear terminology, implicit background knowledge, and the lack of labeled training data. Annotating with a specific ontology adds another layer of complexity, as it requires aligning text with a predefined set of concepts and relationships. Manual annotation is time-consuming and expensive, highlighting the need for automated systems to handle large volumes of biomedical data efficiently. In this paper, we propose an entailment-based zero-shot text classification approach to annotate biomedical text passages using the Homeostasis Imbalance Process (HOIP) ontology. Our method reformulates the annotation task as a multi-class, multi-label classification problem and uses natural language inference to classify text into related HOIP processes. Experimental results show promising performance, especially when processes are not explicitly mentioned, highlighting the effectiveness of our approach for ontological annotation of biomedical literature.","2025-01","2025-09-10 13:17:22","2025-09-10 13:17:22","","8148–8159","","","","","","","","","","","Association for Computational Linguistics","Abu Dhabi, UAE","","","","","","","","","","","","","","Rambow, Owen; Wanner, Leo; Apidianaki, Marianna; Al-Khalifa, Hend; Eugenio, Barbara Di; Schockaert, Steven","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"BG58A9HJ","conferencePaper","2025","Kühn, Ramona; Mitrović, Jelena; Granitzer, Michael","Enhancing Rhetorical Figure Annotation: An Ontology-Based Web Application with RAG Integration","Proceedings of the 31st International Conference on Computational Linguistics","","","","https://aclanthology.org/2025.coling-main.587/","Rhetorical figures play an important role in our communication. They are used to convey subtle, implicit meaning, or to emphasize statements. We notice them in hate speech, fake news, and propaganda. By improving the systems for computational detection of rhetorical figures, we can also improve tasks such as hate speech and fake news detection, sentiment analysis, opinion mining, or argument mining. Unfortunately, there is a lack of annotated data, as well as qualified annotators that would help us build large corpora to train machine learning models for the detection of rhetorical figures. The situation is particularly difficult in languages other than English, and for rhetorical figures other than metaphor, sarcasm, and irony. To overcome this issue, we develop a web application called “Find your Figure” that facilitates the identification and annotation of German rhetorical figures. The application is based on the German Rhetorical ontology GRhOOT which we have specially adapted for this purpose. In addition, we improve the user experience with Retrieval Augmented Generation (RAG). In this paper, we present the restructuring of the ontology, the development of the web application, and the built-in RAG pipeline. We also identify the optimal RAG settings for our application. Our approach is one of the first to practically use rhetorical ontologies in combination with RAG and shows promising results.","2025-01","2025-09-10 13:17:22","2025-09-10 13:17:22","","8774–8786","","","","","","","","","","","Association for Computational Linguistics","Abu Dhabi, UAE","","","","","","","","","","","","","","Rambow, Owen; Wanner, Leo; Apidianaki, Marianna; Al-Khalifa, Hend; Eugenio, Barbara Di; Schockaert, Steven","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FPZ6BHZE","conferencePaper","2025","Zuo, Yuxin; Jiang, Wenxuan; Liu, Wenxuan; Li, Zixuan; Bai, Long; Wang, Hanbin; Zeng, Yutao; Jin, Xiaolong; Guo, Jiafeng; Cheng, Xueqi","KnowCoder-X: Boosting Multilingual Information Extraction via Code","Findings of the Association for Computational Linguistics: ACL 2025","979-8-89176-256-5","","10.18653/v1/2025.findings-acl.748","https://aclanthology.org/2025.findings-acl.748/","Empirical evidence indicates that LLMs exhibit spontaneous cross-lingual alignment. However, although LLMs show promising cross-lingual alignment in Information Extraction (IE), a significant imbalance across languages persists, highlighting an underlying deficiency. To address this, we propose KnowCoder-X, a powerful code LLM with advanced cross-lingual and multilingual capabilities for universal IE. Firstly, it standardizes the representation of multilingual schemas using Python classes, ensuring a consistent ontology across different languages. Then, IE across languages is formulated as a unified code generation task. Secondly, we conduct IE cross-lingual alignment instruction tuning on the translated instance prediction task to enhance the model's cross-lingual transferability. During this phase, we also construct a high-quality and diverse bilingual IE parallel dataset with 257k samples, called ParallelNER, synthesized by our proposed robust three-stage pipeline, with manual annotation to ensure quality. Although without training in 29 unseen languages, KnowCoder-X surpasses ChatGPT by 30.17% and SoTA by 20.03%, thereby demonstrating superior cross-lingual IE capabilities. Comprehensive evaluations on 64 IE benchmarks in Chinese and English under various settings demonstrate that KnowCoder-X significantly enhances cross-lingual IE transfer through boosting the IE alignment. Our code and dataset are available at: https://github.com/ICT-GoKnow/KnowCoder.","2025-07","2025-09-10 13:17:22","2025-09-10 13:17:22","","14486–14509","","","","","","","","","","","Association for Computational Linguistics","Vienna, Austria","","","","","","","","","","","","","","Che, Wanxiang; Nabende, Joyce; Shutova, Ekaterina; Pilehvar, Mohammad Taher","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EBGHVI38","conferencePaper","2025","Hong, Pengfei; Majumder, Navonil; Ghosal, Deepanway; Aditya, Somak; Mihalcea, Rada; Poria, Soujanya","Evaluating LLMs' Mathematical and Coding Competency through Ontology-guided Interventions","Findings of the Association for Computational Linguistics: ACL 2025","979-8-89176-256-5","","10.18653/v1/2025.findings-acl.1172","https://aclanthology.org/2025.findings-acl.1172/","Recent advancements in Large Language Models (LLMs) have showcased striking results on existing logical reasoning benchmarks, with some models even surpassing human performance. However, the true depth of their competencies and robustness in reasoning tasks remains an open question. To this end, in this paper, we focus on two popular reasoning tasks: arithmetic reasoning and code generation. Particularly, we introduce (i) a general ontology of perturbations for math and coding questions, (ii) a semi-automatic method to apply these perturbations, and (iii) two datasets, GSMore and HumanEval-Core, respectively, of perturbed math and coding problems to probe LLM capabilities in numeric reasoning and coding tasks.Through comprehensive evaluations of both closed-source and open-source LLMs, we show a significant performance drop across all the models against the perturbed questions, suggesting that the current LLMs lack robust problem solving skills and structured reasoning abilities in many areas, as defined by our ontology.","2025-07","2025-09-10 13:17:22","2025-09-10 13:17:22","","22811–22849","","","","","","","","","","","Association for Computational Linguistics","Vienna, Austria","","","","","","","","","","","","","","Che, Wanxiang; Nabende, Joyce; Shutova, Ekaterina; Pilehvar, Mohammad Taher","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CV3UFLBM","conferencePaper","2025","Lin, Run; Liu, Yao; Gan, Yanglei; Cai, Yuxiang; Lan, Tian; Liu, Qiao","GEMS: Generation-Based Event Argument Extraction via Multi-perspective Prompts and Ontology Steering","Findings of the Association for Computational Linguistics: ACL 2025","979-8-89176-256-5","","10.18653/v1/2025.findings-acl.1353","https://aclanthology.org/2025.findings-acl.1353/","Generative methods significantly advance event argument extraction by probabilistically generating event argument sequences in a structured format. However, existing approaches primarily rely on a single prompt to generate event arguments in a fixed, predetermined order. Such a rigid approach overlooks the complex structural and dynamic interdependencies among event arguments. In this work, we present GEMS, a multi-prompt learning framework that Generates Event arguments via Multi-perspective prompts and ontology Steering. Specifically, GEMS utilizes multiple unfilled prompts for each sentence, predicting event arguments in varying sequences to explicitly capture the interrelationships between arguments. These predictions are subsequently aggregated using a voting mechanism. Furthermore, an ontology-driven steering mechanism is proposed to ensure that the generated arguments are contextually appropriate and consistent with event-specific knowledge. Extensive experiments on two benchmark datasets demonstrate that GEMS achieves state-of-the-art performance, particularly in low-resource settings. The source code is available at: https://github.com/AONE-NLP/EAE-GEMS","2025-07","2025-09-10 13:17:22","2025-09-10 13:17:22","","26392–26409","","","","","","","","","","","Association for Computational Linguistics","Vienna, Austria","","","","","","","","","","","","","","Che, Wanxiang; Nabende, Joyce; Shutova, Ekaterina; Pilehvar, Mohammad Taher","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MBI36YKL","conferencePaper","2025","Abdo, Muhammad S.; Hatekar, Yash; Cavar, Damir","AMWAL: Named Entity Recognition for Arabic Financial News","Proceedings of the Joint Workshop of the 9th Financial Technology and Natural Language Processing (FinNLP), the 6th Financial Narrative Processing (FNP), and the 1st Workshop on Large Language Models for Finance and Legal (LLMFinLegal)","","","","https://aclanthology.org/2025.finnlp-1.20/","Financial Named Entity Recognition (NER) presents a pivotal task in extracting structured information from unstructured financial data, especially when extending its application to languages beyond English. In this paper, we present AMWAL, a named entity recognition system for Arabic financial news. Our approach centered on building a specialized corpus compiled from three major Arabic financial newspapers spanning from 2000 to 2023. Entities were extracted from this corpus using a semi-automatic process that included manual annotation and review to ensure accuracy. The total number of entities identified amounts to 17.1k tokens, distributed across 20 categories, providing a comprehensive coverage of financial entities. To standardize the identified entities, we adopt financial concepts from the Financial Industry Business Ontology (FIBO, 2020), aligning our framework with industry standards. The significance of our work lies not only in the creation of the first customized NER system for Arabic financial data but also in its potential to streamline information extraction processes in the financial domain. Our NER system achieves a Precision score of 96.08, a Recall score of 95.87, and an F1 score of 95.97, which outperforms state-of-the-art general Arabic NER systems as well as other systems for financial NER in other languages.","2025-01","2025-09-10 13:17:22","2025-09-10 13:17:22","","207–213","","","","","","","","","","","Association for Computational Linguistics","Abu Dhabi, UAE","","","","","","","","","","","","","","Chen, Chung-Chi; Moreno-Sandoval, Antonio; Huang, Jimin; Xie, Qianqian; Ananiadou, Sophia; Chen, Hsin-Hsi","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JYRIL52V","conferencePaper","2025","Christou, Despina; Tsoumakas, Grigorios","Artificial Relationships in Fiction: A Dataset for Advancing NLP in Literary Domains","Proceedings of the 9th Joint SIGHUM Workshop on Computational Linguistics for Cultural Heritage, Social Sciences, Humanities and Literature (LaTeCH-CLfL 2025)","979-8-89176-241-1","","10.18653/v1/2025.latechclfl-1.13","https://aclanthology.org/2025.latechclfl-1.13/","Relation extraction (RE) in fiction presents unique NLP challenges due to implicit, narrative-driven relationships. Unlike factual texts, fiction weaves complex connections, yet existing RE datasets focus on non-fiction. To address this, we introduce Artificial Relationships in Fiction (ARF), a synthetically annotated dataset for literary RE. Built from diverse Project Gutenberg fiction, ARF considers author demographics, publication periods, and themes. We curated an ontology for fiction-specific entities and relations, and using GPT-4o, generated artificial relationships to capture narrative complexity. Our analysis demonstrates its value for finetuning RE models and advancing computational literary studies. By bridging a critical RE gap, ARF enables deeper exploration of fictional relationships, enriching NLP research at the intersection of storytelling and AI-driven literary analysis.","2025-05","2025-09-10 13:17:23","2025-09-10 13:17:23","","130–147","","","","","","","","","","","Association for Computational Linguistics","Albuquerque, New Mexico","","","","","","","","","","","","","","Kazantseva, Anna; Szpakowicz, Stan; Degaetano-Ortlieb, Stefania; Bizzoni, Yuri; Pagel, Janis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VUSL4S6H","conferencePaper","2025","Urešová, Zdeňka; Fučíková, Eva; Hajič, Jan","Creating Hierarchical Relations in a Multilingual Event-type Ontology","Proceedings of the 19th Linguistic Annotation Workshop (LAW-XIX-2025)","979-8-89176-262-6","","10.18653/v1/2025.law-1.19","https://aclanthology.org/2025.law-1.19/","This paper describes the work on hierarchization of the SynSemClass event-type ontology. The original resource has been extended by a hierarchical structure to model specialization and generalization relations between classes that are formally and technically unrelated in the original ontology. The goal is to enable one to use the ontology enriched by the hierarchical concepts for annotation of running texts in symbolic meaning representations, such as UMR or PDT. The hierarchy is in principle built bottom-up, based on existing SSC classes (concepts). This approach differs from other approaches to semantic classes, such as in WordNet or VerbNet. Although the hierarchical relations are similar, the underlying nodes in the hierarchy are not. In this paper, we describe the challenges related to the principles chosen: single-tree constraint and finding features for the definitions of specificity/generality. Also, a pilot inter-annotator experiment is described that shows the difficulty of the hierarchization task.","2025-07","2025-09-10 13:17:23","2025-09-10 13:17:23","","240–249","","","","","","","","","","","Association for Computational Linguistics","Vienna, Austria","","","","","","","","","","","","","","Peng, Siyao; Rehbein, Ines","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IVYUIZ56","conferencePaper","2025","Li, Haoran; Fan, Wei; Chen, Yulin; Jiayang, Cheng; Chu, Tianshu; Zhou, Xuebing; Hu, Peizhao; Song, Yangqiu","Privacy Checklist: Privacy Violation Detection Grounding on Contextual Integrity Theory","Proceedings of the 2025 Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)","979-8-89176-189-6","","10.18653/v1/2025.naacl-long.86","https://aclanthology.org/2025.naacl-long.86/","Privacy research has attracted wide attention as individuals worry that their private data can be easily leaked during interactions with smart devices, social platforms, and AI applications. Existing works mostly consider privacy attacks and defenses on various sub-fields. Within each field, various privacy attacks and defenses are studied to address patterns of personally identifiable information (PII). In this paper, we argue that privacy is not solely about PII patterns. We ground on the Contextual Integrity (CI) theory which posits that people's perceptions of privacy are highly correlated with the corresponding social context. Based on such an assumption, we formulate privacy as a reasoning problem rather than naive PII matching. We develop the first comprehensive checklist that covers social identities, private attributes, and existing privacy regulations. Unlike prior works on CI that either cover limited expert annotated norms or model incomplete social context, our proposed privacy checklist uses the whole Health Insurance Portability and Accountability Act of 1996 (HIPAA) as an example, to show that we can resort to large language models (LLMs) to completely cover the HIPAA's regulations. Additionally, our checklist also gathers expert annotations across multiple ontologies to determine private information including but not limited to PII. We use our preliminary results on the HIPAA to shed light on future context-centric privacy research to cover more privacy regulations, social norms and standards. We will release the reproducible code and data.","2025-04","2025-09-10 13:17:23","2025-09-10 13:17:23","","1748–1766","","","","","","","","","","","Association for Computational Linguistics","Albuquerque, New Mexico","","","","","","","","","","","","","","Chiruzzo, Luis; Ritter, Alan; Wang, Lu","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SEPEK4KL","conferencePaper","2025","Wysocka, Magdalena; Carvalho, Danilo; Wysocki, Oskar; Valentino, Marco; Freitas, Andre","SylloBio-NLI: Evaluating Large Language Models on Biomedical Syllogistic Reasoning","Proceedings of the 2025 Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)","979-8-89176-189-6","","10.18653/v1/2025.naacl-long.371","https://aclanthology.org/2025.naacl-long.371/","Syllogistic reasoning is crucial for Natural Language Inference (NLI). This capability is particularly significant in specialized domains such as biomedicine, where it can support automatic evidence interpretation and scientific discovery. This paper presents SylloBio-NLI, a novel framework that leverages external ontologies to systematically instantiate diverse syllogistic arguments for biomedical NLI. We employ SylloBio-NLI to evaluate Large Language Models (LLMs) on identifying valid conclusions and extracting supporting evidence across 28 syllogistic schemes instantiated with human genome pathways. Extensive experiments reveal that biomedical syllogistic reasoning is particularly challenging for zero-shot LLMs, which achieve an average accuracy between 70% on generalized modus ponens and 23% on disjunctive syllogism. At the same time, we found that few-shot prompting can boost the performance of different LLMs, including Gemma (+14%) and LLama-3 (+43%). However, a deeper analysis shows that both techniques exhibit high sensitivity to superficial lexical variations, highlighting a dependency between reliability, models' architecture, and pre-training regime. Overall, our results indicate that, while in-context examples have the potential to elicit syllogistic reasoning in LLMs, existing models are still far from achieving the robustness and consistency required for safe biomedical NLI applications.","2025-04","2025-09-10 13:17:23","2025-09-10 13:17:23","","7235–7258","","","","","","","","","","","Association for Computational Linguistics","Albuquerque, New Mexico","","","","","","","","","","","","","","Chiruzzo, Luis; Ritter, Alan; Wang, Lu","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WGYP8LMH","conferencePaper","2025","Dahan, Noam; Stanovsky, Gabriel","The State and Fate of Summarization Datasets: A Survey","Proceedings of the 2025 Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)","979-8-89176-189-6","","10.18653/v1/2025.naacl-long.372","https://aclanthology.org/2025.naacl-long.372/","Automatic summarization has consistently attracted attention due to its versatility and wide application in various downstream tasks. Despite its popularity, we find that annotation efforts have largely been disjointed, and have lacked common terminology. Consequently, it is challenging to discover existing resources or identify coherent research directions. To address this, we survey a large body of work spanning 133 datasets in over 100 languages, creating a novel ontology covering sample properties, collection methods and distribution. With this ontology we make key observations, including the lack of accessible high-quality datasets for low-resource languages, and the field's overreliance on the news domain and on automatically collected distant supervision. Finally, we make available a web interface that allows users to interact and explore our ontology and dataset collection, as well as a template for a summarization data card, which can be used to streamline future research into a more coherent body of work.","2025-04","2025-09-10 13:17:23","2025-09-10 13:17:23","","7259–7278","","","","","","","","","","","Association for Computational Linguistics","Albuquerque, New Mexico","","","","","","","","","","","","","","Chiruzzo, Luis; Ritter, Alan; Wang, Lu","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5K5Z8GKQ","conferencePaper","2025","Safa, Abdulfattah; Şahin, Gözde Gül","A Zero-Shot Open-Vocabulary Pipeline for Dialogue Understanding","Proceedings of the 2025 Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 1: Long Papers)","979-8-89176-189-6","","10.18653/v1/2025.naacl-long.387","https://aclanthology.org/2025.naacl-long.387/","Dialogue State Tracking (DST) is crucial for understanding user needs and executing appropriate system actions in task-oriented dialogues. Majority of existing DST methods are designed to work within predefined ontologies and assume the availability of gold domain labels, struggling with adapting to new slots values. While Large Language Models (LLMs)-based systems show promising zero-shot DST performance, they either require extensive computational resources or they underperform existing fully-trained systems, limiting their practicality. To address these limitations, we propose a zero-shot, open-vocabulary system that integrates domain classification and DST in a single pipeline. Our approach includes reformulating DST as a question-answering task for less capable models and employing self-refining prompts for more adaptable ones. Our system does not rely on fixed slot values defined in the ontology allowing the system to adapt dynamically. We compare our approach with existing SOTA, and show that it provides up to 20% better Joint Goal Accuracy (JGA) over previous methods on datasets like MultiWOZ 2.1, with up to 90% fewer requests to the LLM API.","2025-04","2025-09-10 13:17:23","2025-09-10 13:17:23","","7562–7579","","","","","","","","","","","Association for Computational Linguistics","Albuquerque, New Mexico","","","","","","","","","","","","","","Chiruzzo, Luis; Ritter, Alan; Wang, Lu","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"27HCHWNW","conferencePaper","2025","Chen, Zijian; Gamble, John-Michael; Jantzi, Micaela; Hirdes, John P.; Lin, Jimmy","Zero-Shot ATC Coding with Large Language Models for Clinical Assessments","Proceedings of the 2025 Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 3: Industry Track)","979-8-89176-194-0","","10.18653/v1/2025.naacl-industry.19","https://aclanthology.org/2025.naacl-industry.19/","Manual assignment of Anatomical Therapeutic Chemical (ATC) codes to prescription records is a significant bottleneck in healthcare research and operations at Ontario Health and InterRAI Canada, requiring extensive expert time and effort. To automate this process while maintaining data privacy, we develop a practical approach using locally deployable large language models (LLMs). Inspired by recent advances in automatic International Classification of Diseases (ICD) coding, our method frames ATC coding as a hierarchical information extraction task, guiding LLMs through the ATC ontology level by level. We evaluate our approach using GPT-4o as an accuracy ceiling and focus development on open-source Llama models suitable for privacy-sensitive deployment. Testing across Health Canada drug product data, the RABBITS benchmark, and real clinical notes from Ontario Health, our method achieves 78% exact match accuracy with GPT-4o and 60% with Llama 3.1 70B. We investigate knowledge grounding through drug definitions, finding modest improvements in accuracy. Further, we show that fine-tuned Llama 3.1 8B matches zero-shot Llama 3.1 70B accuracy, suggesting that effective ATC coding is feasible with smaller models. Our results demonstrate the feasibility of automatic ATC coding in privacy-sensitive healthcare environments, providing a foundation for future deployments.","2025-04","2025-09-10 13:17:23","2025-09-10 13:17:23","","226–232","","","","","","","","","","","Association for Computational Linguistics","Albuquerque, New Mexico","","","","","","","","","","","","","","Chen, Weizhu; Yang, Yi; Kachuee, Mohammad; Fu, Xue-Yong","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7TGB5YU3","conferencePaper","2025","Beyer, Henrike; Frassinelli, Diego","Linguistic Features in German BERT: The Role of Morphology, Syntax, and Semantics in Multi-Class Text Classification","Proceedings of the 2025 Conference of the Nations of the Americas Chapter of the Association for Computational Linguistics: Human Language Technologies (Volume 4: Student Research Workshop)","979-8-89176-192-6","","10.18653/v1/2025.naacl-srw.3","https://aclanthology.org/2025.naacl-srw.3/","Most studies on the linguistic information encoded by BERT primarily focus on English. Our study examines a monolingual German BERT model using a semantic classification task on newspaper articles, analysing the linguistic features influencing classification decisions through SHAP values. We use the TüBa-D/Z corpus, a resource with gold-standard annotations for a set of linguistic features, including POS, inflectional morphology, phrasal, clausal, and dependency structures. Semantic features of nouns are evaluated via the GermaNet ontology using shared hypernyms. Our results indicate that the features identified in English also affect classification in German but suggests important language- and task-specific features as well.","2025-04","2025-09-10 13:17:23","2025-09-10 13:17:23","","28–39","","","","","","","","","","","Association for Computational Linguistics","Albuquerque, USA","","","","","","","","","","","","","","Ebrahimi, Abteen; Haider, Samar; Liu, Emmy; Haider, Sammar; Leonor Pacheco, Maria; Wein, Shira","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JWVLQELX","conferencePaper","2025","Wu, Wenya; Deng, Weihong","What Counts Underlying LLMs' Moral Dilemma Judgments?","Proceedings of the Fourth Workshop on NLP for Positive Impact (NLP4PI)","978-1-959429-19-7","","10.18653/v1/2025.nlp4pi-1.12","https://aclanthology.org/2025.nlp4pi-1.12/","Moral judgments in LLMs increasingly capture the attention of researchers in AI ethics domain. This study explores moral judgments of three open-source large language models (LLMs)—Qwen-1.5-14B, Llama3-8B, and DeepSeek-R1 in plausible moral dilemmas, examining their sensitivity to social exposure and collaborative decision-making. Using a dual-process framework grounded in deontology and utilitarianism, we evaluate LLMs' responses to moral dilemmas under varying social contexts. Results reveal that all models are significantly influenced by moral norms rather than consequences, with DeepSeek-R1 exhibiting a stronger action tendency compared to Qwen-1.5-14B and Llama3-8B, which show higher inaction preferences. Social exposure and collaboration impact LLMs differently: Qwen-1.5-14B becomes less aligned with moral norms under observation, while DeepSeek-R1's action tendency is moderated by social collaboration. These findings highlight the nuanced moral reasoning capabilities of LLMs and their varying sensitivity to social cues, providing insights into the ethical alignment of AI systems in socially embedded contexts.","2025-07","2025-09-10 13:17:23","2025-09-10 13:17:23","","144–150","","","","","","","","","","","Association for Computational Linguistics","Vienna, Austria","","","","","","","","","","","","","","Atwell, Katherine; Biester, Laura; Borah, Angana; Dementieva, Daryna; Ignat, Oana; Kotonya, Neema; Liu, Ziyi; Wan, Ruyuan; Wilson, Steven; Zhao, Jieyu","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"566TEHPX","conferencePaper","2025","Bayrami Asl Tekanlou, Hadi; Razmara, Jafar; Sanaei, Mahsa; Rahgouy, Mostafa; Babaei Giglou, Hamed","Homa at SemEval-2025 Task 5: Aligning Librarian Records with OntoAligner for Subject Tagging","Proceedings of the 19th International Workshop on Semantic Evaluation (SemEval-2025)","979-8-89176-273-2","","","https://aclanthology.org/2025.semeval-1.312/","This paper presents our system, Homa, for SemEval-2025 Task 5: Subject Tagging, which focuses on automatically assigning subject labels to technical records from TIBKAT using the Gemeinsame Normdatei (GND) taxonomy. We leverage OntoAligner, a modular ontology alignment toolkit, to address this task by integrating retrieval-augmented generation (RAG) techniques. Our approach formulates the subject tagging problem as an alignment task, where records are matched to GND categories based on semantic similarity. We evaluate OntoAligner's adaptability for subject indexing and analyze its effectiveness in handling multilingual records. Experimental results demonstrate the strengths and limitations of this method, highlighting the potential of alignment techniques for improving subject tagging in digital libraries.","2025-07","2025-09-10 13:17:23","2025-09-10 13:17:23","","2400–2406","","","","","","","","","","","Association for Computational Linguistics","Vienna, Austria","","","","","","","","","","","","","","Rosenthal, Sara; Rosá, Aiala; Ghosh, Debanjan; Zampieri, Marcos","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"V38Q4JVY","conferencePaper","2025","Salfinger, Andrea; Zaccagna, Luca; Incitti, Francesca; De Nardi, Gianluca; Dal Fabbro, Lorenzo; Snidaro, Lauro","LA²I²F at SemEval-2025 Task 5: Reasoning in Embedding Space – Fusing Analogical and Ontology-based Reasoning for Document Subject Tagging","Proceedings of the 19th International Workshop on Semantic Evaluation (SemEval-2025)","979-8-89176-273-2","","","https://aclanthology.org/2025.semeval-1.314/","The LLMs4Subjects shared task invited system contributions that leverage a technical library's tagged document corpus to learn document subject tagging, i.e., proposing adequate subjects given a document's title and abstract. To address the imbalance of this training corpus, team LA²I²F devised a semantic retrieval-based system fusing the results of ontological and analogical reasoning in embedding vector space. Our results outperformed a naive baseline of prompting a llama 3.1-based model, whilst being computationally more efficient and competitive with the state of the art.","2025-07","2025-09-10 13:17:23","2025-09-10 13:17:23","","2413–2423","","","","","","","","","","","Association for Computational Linguistics","Vienna, Austria","","","","","","","","","","","","","","Rosenthal, Sara; Rosá, Aiala; Ghosh, Debanjan; Zampieri, Marcos","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"ADMI5I2P","journalArticle","2025","Ventura, Mor; Ben-David, Eyal; Korhonen, Anna; Reichart, Roi","Navigating Cultural Chasms: Exploring and Unlocking the Cultural POV of Text-To-Image Models","Transactions of the Association for Computational Linguistics","","","10.1162/tacl_a_00732","https://aclanthology.org/2025.tacl-1.10/","Text-To-Image (TTI) models, such as DALL-E and StableDiffusion, have demonstrated remarkable prompt-based image generation capabilities. Multilingual encoders may have a substantial impact on the cultural agency of these models, as language is a conduit of culture. In this study, we explore the cultural perception embedded in TTI models by characterizing culture across three tiers: cultural dimensions, cultural domains, and cultural concepts. Based on this ontology, we derive prompt templates to unlock the cultural knowledge in TTI models, and propose a comprehensive suite of evaluation techniques, including intrinsic evaluations using the CLIP space, extrinsic evaluations with a Visual-Question-Answer models and human assessments, to evaluate the cultural content of TTI-generated images. To bolster our research, we introduce the CulText2I dataset, based on six diverse TTI models and spanning ten languages. Our experiments provide insights regarding Do, What, Which, and How research questions about the nature of cultural encoding in TTI models, paving the way for cross-cultural applications of these models.1","2025","2025-09-10 13:17:23","2025-09-10 13:17:23","","142–166","","","13","","","","","","","","","","","","","","","","","Place: Cambridge, MA Publisher: MIT Press","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Q59I2Z2N","conferencePaper","2025","Mehryar, S","Resolution-Alignment-Completion of Tabular Electronic Health Records via Meta-Path Generative Sampling","Proceedings of the 4th Table Representation Learning Workshop","979-8-89176-268-8","","10.18653/v1/2025.trl-1.17","https://aclanthology.org/2025.trl-1.17/","The increasing availability of electronic health records (EHR) offers significant opportunities in data-driven healthcare, yet much of this data remains fragmented, semantically inconsistent, or incomplete. These issues are particularly evident in tabular patient records where important contextual information are lacking from the input for effective modeling. In this work, we introduce a system that performs ontology-based entity alignment to resolve and complete tabular data used in real-world clinical units. We transform patient records into a knowledge graph and capture its hidden structures through graph embeddings. We further propose a meta-path sample generation approach for completing the missing information. Our experiments demonstrate the system's ability to augment cardiovascular disease (CVD) data for lab event detection, diagnosis prediction, and drug recommendation, enabling more robust and precise predictive models in clinical decision-making.","2025-07","2025-09-10 13:17:23","2025-09-10 13:17:23","","200–207","","","","","","","","","","","Association for Computational Linguistics","Vienna, Austria","","","","","","","","","","","","","","Chang, Shuaichen; Hulsebos, Madelon; Liu, Qian; Chen, Wenhu; Sun, Huan","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PXG2ITTA","conferencePaper","2025","Pagano, Adriana Silvina; Chiril, Patricia; Chierchiello, Elisa; Bosco, Cristina","TreEn: A Multilingual Treebank Project on Environmental Discourse","Proceedings of the Eighth Workshop on Universal Dependencies (UDW, SyntaxFest 2025)","979-8-89176-292-3","","","https://aclanthology.org/2025.udw-1.9/","The increasing complexity of environmental discourse is directly proportional to the growing complexity of environmental debates present today in all communication media. While linguistic and communication studies have been pursued on this discourse, the development of computational linguistic tools and resources dedicated to support its analysis and interpretation is still very incipient. For one, no morphosyntactic resources specific to the environmental domain can be found on major platforms and repositories. This paper introduces TreEn, a multilingual treebank project in progress which compiles texts on environmental discourse produced in different conversational and communication contexts. In particular, it reports on the parallel component of the project and discusses issues faced during sentence-level alignment between original and translated texts, annotation of texts following UD guidelines, and labeling entities drawing on an ontology of environmental-related topics. This novel resource is expected to support environmental discourse analysis by providing morphological and syntactical data to enable cross-language and cross-cultural comparison based on the semantics of the entities annotated in the treebank.","2025-08","2025-09-10 13:17:23","2025-09-10 13:17:23","","80–96","","","","","","","","","","","Association for Computational Linguistics","Ljubljana, Slovenia","","","","","","","","","","","","","","Bouma, Gosse; Çöltekin, Çağrı","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"F5TGQUQ8","conferencePaper","2008","Montiel-Ponsoda, Elena; Aguado de Cea, Guadalupe; Gómez-Pérez, Asunción; Peters, Wim","Modelling Multilinguality in Ontologies","Coling 2008: Companion volume: Posters","","","","https://aclanthology.org/C08-2017/","","2008-08","2025-09-10 13:17:23","2025-09-10 13:17:23","","67–70","","","","","","","","","","","Coling 2008 Organizing Committee","Manchester, UK","","","","","","","","","","","","","","Scott, Donia; Uszkoreit, Hans","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"92XP9MP7","conferencePaper","2018","Chen, Lu; Tan, Bowen; Long, Sishan; Yu, Kai","Structured Dialogue Policy with Graph Neural Networks","Proceedings of the 27th International Conference on Computational Linguistics","","","","https://aclanthology.org/C18-1107/","Recently, deep reinforcement learning (DRL) has been used for dialogue policy optimization. However, many DRL-based policies are not sample-efficient. Most recent advances focus on improving DRL optimization algorithms to address this issue. Here, we take an alternative route of designing neural network structure that is better suited for DRL-based dialogue management. The proposed structured deep reinforcement learning is based on graph neural networks (GNN), which consists of some sub-networks, each one for a node on a directed graph. The graph is defined according to the domain ontology and each node can be considered as a sub-agent. During decision making, these sub-agents have internal message exchange between neighbors on the graph. We also propose an approach to jointly optimize the graph structure as well as the parameters of GNN. Experiments show that structured DRL significantly outperforms previous state-of-the-art approaches in almost all of the 18 tasks of the PyDial benchmark.","2018-08","2025-09-10 13:17:23","2025-09-10 13:17:23","","1257–1268","","","","","","","","","","","Association for Computational Linguistics","Santa Fe, New Mexico, USA","","","","","","","","","","","","","","Bender, Emily M.; Derczynski, Leon; Isabelle, Pierre","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"P2VI8WH3","conferencePaper","2018","Kazeminejad, Ghazaleh; Bonial, Claire; Brown, Susan Windisch; Palmer, Martha","Automatically Extracting Qualia Relations for the Rich Event Ontology","Proceedings of the 27th International Conference on Computational Linguistics","","","","https://aclanthology.org/C18-1224/","Commonsense, real-world knowledge about the events that entities or “things in the world” are typically involved in, as well as part-whole relationships, is valuable for allowing computational systems to draw everyday inferences about the world. Here, we focus on automatically extracting information about (1) the events that typically bring about certain entities (origins), (2) the events that are the typical functions of entities, and (3) part-whole relationships in entities. These correspond to the agentive, telic and constitutive qualia central to the Generative Lexicon. We describe our motivations and methods for extracting these qualia relations from the Suggested Upper Merged Ontology (SUMO) and show that human annotators overwhelmingly find the information extracted to be reasonable. Because ontologies provide a way of structuring this information and making it accessible to agents and computational systems generally, efforts are underway to incorporate the extracted information to an ontology hub of Natural Language Processing semantic role labeling resources, the Rich Event Ontology.","2018-08","2025-09-10 13:17:23","2025-09-10 13:17:23","","2644–2652","","","","","","","","","","","Association for Computational Linguistics","Santa Fe, New Mexico, USA","","","","","","","","","","","","","","Bender, Emily M.; Derczynski, Leon; Isabelle, Pierre","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"S63UBZ4F","conferencePaper","2018","Dasgupta, Tirthankar; Dey, Lipika; Saha, Rupsa; Naskar, Abir","Automatic Curation and Visualization of Crime Related Information from Incrementally Crawled Multi-source News Reports","Proceedings of the 27th International Conference on Computational Linguistics: System Demonstrations","","","","https://aclanthology.org/C18-2023/","In this paper, we demonstrate a system for the automatic extraction and curation of crime-related information from multi-source digitally published News articles collected over a period of five years. We have leveraged the use of deep convolution recurrent neural network model to analyze crime articles to extract different crime related entities and events. The proposed methods are not restricted to detecting known crimes only but contribute actively towards maintaining an updated crime ontology. We have done experiments with a collection of 5000 crime-reporting News articles span over time, and multiple sources. The end-product of our experiments is a crime-register that contains details of crime committed across geographies and time. This register can be further utilized for analytical and reporting purposes.","2018-08","2025-09-10 13:17:23","2025-09-10 13:17:23","","103–107","","","","","","","","","","","Association for Computational Linguistics","Santa Fe, New Mexico","","","","","","","","","","","","","","Zhao, Dongyan","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7PYVTCA2","conferencePaper","2015","Xiang, Chuncheng; Jiang, Tingsong; Chang, Baobao; Sui, Zhifang","ERSOM: A Structural Ontology Matching Approach Using Automatically Learned Entity Representation","Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing","","","10.18653/v1/D15-1289","https://aclanthology.org/D15-1289/","","2015-09","2025-09-10 13:17:23","2025-09-10 13:17:23","","2419–2429","","","","","","","","","","","Association for Computational Linguistics","Lisbon, Portugal","","","","","","","","","","","","","","Màrquez, Lluís; Callison-Burch, Chris; Su, Jian","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"NIMSD3QM","conferencePaper","2018","Pinter, Yuval; Eisenstein, Jacob","Predicting Semantic Relations using Global Graph Properties","Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing","","","10.18653/v1/D18-1201","https://aclanthology.org/D18-1201/","Semantic graphs, such as WordNet, are resources which curate natural language on two distinguishable layers. On the local level, individual relations between synsets (semantic building blocks) such as hypernymy and meronymy enhance our understanding of the words used to express their meanings. Globally, analysis of graph-theoretic properties of the entire net sheds light on the structure of human language as a whole. In this paper, we combine global and local properties of semantic graphs through the framework of Max-Margin Markov Graph Models (M3GM), a novel extension of Exponential Random Graph Model (ERGM) that scales to large multi-relational graphs. We demonstrate how such global modeling improves performance on the local task of predicting semantic relations between synsets, yielding new state-of-the-art results on the WN18RR dataset, a challenging version of WordNet link prediction in which “easy” reciprocal cases are removed. In addition, the M3GM model identifies multirelational motifs that are characteristic of well-formed lexical semantic ontologies.","2018-10","2025-09-10 13:17:23","2025-09-10 13:17:23","","1741–1751","","","","","","","","","","","Association for Computational Linguistics","Brussels, Belgium","","","","","","","","","","","","","","Riloff, Ellen; Chiang, David; Hockenmaier, Julia; Tsujii, Jun'ichi","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8HCS5GUX","conferencePaper","2018","Shen, Dinghan; Min, Martin Renqiang; Li, Yitong; Carin, Lawrence","Learning Context-Sensitive Convolutional Filters for Text Processing","Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing","","","10.18653/v1/D18-1210","https://aclanthology.org/D18-1210/","Convolutional neural networks (CNNs) have recently emerged as a popular building block for natural language processing (NLP). Despite their success, most existing CNN models employed in NLP share the same learned (and static) set of filters for all input sentences. In this paper, we consider an approach of using a small meta network to learn context-sensitive convolutional filters for text processing. The role of meta network is to abstract the contextual information of a sentence or document into a set of input-sensitive filters. We further generalize this framework to model sentence pairs, where a bidirectional filter generation mechanism is introduced to encapsulate co-dependent sentence representations. In our benchmarks on four different tasks, including ontology classification, sentiment analysis, answer sentence selection, and paraphrase identification, our proposed model, a modified CNN with context-sensitive filters, consistently outperforms the standard CNN and attention-based CNN baselines. By visualizing the learned context-sensitive filters, we further validate and rationalize the effectiveness of proposed framework.","2018-10","2025-09-10 13:17:23","2025-09-10 13:17:23","","1839–1848","","","","","","","","","","","Association for Computational Linguistics","Brussels, Belgium","","","","","","","","","","","","","","Riloff, Ellen; Chiang, David; Hockenmaier, Julia; Tsujii, Jun'ichi","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"YG5PMLGC","conferencePaper","2018","Ren, Liliang; Xie, Kaige; Chen, Lu; Yu, Kai","Towards Universal Dialogue State Tracking","Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing","","","10.18653/v1/D18-1299","https://aclanthology.org/D18-1299/","Dialogue state tracker is the core part of a spoken dialogue system. It estimates the beliefs of possible user's goals at every dialogue turn. However, for most current approaches, it's difficult to scale to large dialogue domains. They have one or more of following limitations: (a) Some models don't work in the situation where slot values in ontology changes dynamically; (b) The number of model parameters is proportional to the number of slots; (c) Some models extract features based on hand-crafted lexicons. To tackle these challenges, we propose StateNet, a universal dialogue state tracker. It is independent of the number of values, shares parameters across all slots, and uses pre-trained word vectors instead of explicit semantic dictionaries. Our experiments on two datasets show that our approach not only overcomes the limitations, but also significantly outperforms the performance of state-of-the-art approaches.","2018-10","2025-09-10 13:17:23","2025-09-10 13:17:23","","2780–2786","","","","","","","","","","","Association for Computational Linguistics","Brussels, Belgium","","","","","","","","","","","","","","Riloff, Ellen; Chiang, David; Hockenmaier, Julia; Tsujii, Jun'ichi","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"IRZF35S3","conferencePaper","2018","Wang, Weikang; Zhang, Jiajun; Zhang, Han; Hwang, Mei-Yuh; Zong, Chengqing; Li, Zhifei","A Teacher-Student Framework for Maintainable Dialog Manager","Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing","","","10.18653/v1/D18-1415","https://aclanthology.org/D18-1415/","Reinforcement learning (RL) is an attractive solution for task-oriented dialog systems. However, extending RL-based systems to handle new intents and slots requires a system redesign. The high maintenance cost makes it difficult to apply RL methods to practical systems on a large scale. To address this issue, we propose a practical teacher-student framework to extend RL-based dialog systems without retraining from scratch. Specifically, the “student” is an extended dialog manager based on a new ontology, and the “teacher” is existing resources used for guiding the learning process of the “student”. By specifying constraints held in the new dialog manager, we transfer knowledge of the “teacher” to the “student” without additional resources. Experiments show that the performance of the extended system is comparable to the system trained from scratch. More importantly, the proposed framework makes no assumption about the unsupported intents and slots, which makes it possible to improve RL-based systems incrementally.","2018-10","2025-09-10 13:17:23","2025-09-10 13:17:23","","3803–3812","","","","","","","","","","","Association for Computational Linguistics","Brussels, Belgium","","","","","","","","","","","","","","Riloff, Ellen; Chiang, David; Hockenmaier, Julia; Tsujii, Jun'ichi","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"Y94CRL8Y","conferencePaper","2018","Tanveer, Md Iftekhar; Ture, Ferhan","SyntaViz: Visualizing Voice Queries through a Syntax-Driven Hierarchical Ontology","Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing: System Demonstrations","","","10.18653/v1/D18-2001","https://aclanthology.org/D18-2001/","This paper describes SyntaViz, a visualization interface specifically designed for analyzing natural-language queries that were created by users of a voice-enabled product. SyntaViz provides a platform for browsing the ontology of user queries from a syntax-driven perspective, providing quick access to high-impact failure points of the existing intent understanding system and evidence for data-driven decisions in the development cycle. A case study on Xfinity X1 (a voice-enabled entertainment platform from Comcast) reveals that SyntaViz helps developers identify multiple action items in a short amount of time without any special training. SyntaViz has been open-sourced for the benefit of the community.","2018-11","2025-09-10 13:17:23","2025-09-10 13:17:23","","1–6","","","","","","","","","","","Association for Computational Linguistics","Brussels, Belgium","","","","","","","","","","","","","","Blanco, Eduardo; Lu, Wei","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"A2NIRF6Z","conferencePaper","2018","Labutov, Igor; Srivastava, Shashank; Mitchell, Tom","LIA: A Natural Language Programmable Personal Assistant","Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing: System Demonstrations","","","10.18653/v1/D18-2025","https://aclanthology.org/D18-2025/","We present LIA, an intelligent personal assistant that can be programmed using natural language. Our system demonstrates multiple competencies towards learning from human-like interactions. These include the ability to be taught reusable conditional procedures, the ability to be taught new knowledge about the world (concepts in an ontology) and the ability to be taught how to ground that knowledge in a set of sensors and effectors. Building such a system highlights design questions regarding the overall architecture that such an agent should have, as well as questions about parsing and grounding language in situational contexts. We outline key properties of this architecture, and demonstrate a prototype that embodies them in the form of a personal assistant on an Android device.","2018-11","2025-09-10 13:17:23","2025-09-10 13:17:23","","145–150","","","","","","","","","","","Association for Computational Linguistics","Brussels, Belgium","","","","","","","","","","","","","","Blanco, Eduardo; Lu, Wei","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RFRJ5KTK","conferencePaper","2019","Gupta, Swapnil; Kenkre, Sreyash; Talukdar, Partha","CaRe: Open Knowledge Graph Embeddings","Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)","","","10.18653/v1/D19-1036","https://aclanthology.org/D19-1036/","Open Information Extraction (OpenIE) methods are effective at extracting (noun phrase, relation phrase, noun phrase) triples from text, e.g., (Barack Obama, took birth in, Honolulu). Organization of such triples in the form of a graph with noun phrases (NPs) as nodes and relation phrases (RPs) as edges results in the construction of Open Knowledge Graphs (OpenKGs). In order to use such OpenKGs in downstream tasks, it is often desirable to learn embeddings of the NPs and RPs present in the graph. Even though several Knowledge Graph (KG) embedding methods have been recently proposed, all of those methods have targeted Ontological KGs, as opposed to OpenKGs. Straightforward application of existing Ontological KG embedding methods to OpenKGs is challenging, as unlike Ontological KGs, OpenKGs are not canonicalized, i.e., a real-world entity may be represented using multiple nodes in the OpenKG, with each node corresponding to a different NP referring to the entity. For example, nodes with labels Barack Obama, Obama, and President Obama may refer to the same real-world entity Barack Obama. Even though canonicalization of OpenKGs has received some attention lately, output of such methods has not been used to improve OpenKG embed- dings. We fill this gap in the paper and propose Canonicalization-infused Representations (CaRe) for OpenKGs. Through extensive experiments, we observe that CaRe enables existing models to adapt to the challenges in OpenKGs and achieve substantial improvements for the link prediction task.","2019-11","2025-09-10 13:17:23","2025-09-10 13:17:23","","378–388","","","","","","","","","","","Association for Computational Linguistics","Hong Kong, China","","","","","","","","","","","","","","Inui, Kentaro; Jiang, Jing; Ng, Vincent; Wan, Xiaojun","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"T9VWF5TB","conferencePaper","2019","Ren, Liliang; Ni, Jianmo; McAuley, Julian","Scalable and Accurate Dialogue State Tracking via Hierarchical Sequence Generation","Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)","","","10.18653/v1/D19-1196","https://aclanthology.org/D19-1196/","Existing approaches to dialogue state tracking rely on pre-defined ontologies consisting of a set of all possible slot types and values. Though such approaches exhibit promising performance on single-domain benchmarks, they suffer from computational complexity that increases proportionally to the number of pre-defined slots that need tracking. This issue becomes more severe when it comes to multi-domain dialogues which include larger numbers of slots. In this paper, we investigate how to approach DST using a generation framework without the pre-defined ontology list. Given each turn of user utterance and system response, we directly generate a sequence of belief states by applying a hierarchical encoder-decoder structure. In this way, the computational complexity of our model will be a constant regardless of the number of pre-defined slots. Experiments on both the multi-domain and the single domain dialogue state tracking dataset show that our model not only scales easily with the increasing number of pre-defined domains and slots but also reaches the state-of-the-art performance.","2019-11","2025-09-10 13:17:23","2025-09-10 13:17:23","","1876–1885","","","","","","","","","","","Association for Computational Linguistics","Hong Kong, China","","","","","","","","","","","","","","Inui, Kentaro; Jiang, Jing; Ng, Vincent; Wan, Xiaojun","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CGM5KJBD","conferencePaper","2019","Henderson, Matthew; Vulić, Ivan; Casanueva, Iñigo; Budzianowski, Paweł; Gerz, Daniela; Coope, Sam; Spithourakis, Georgios; Wen, Tsung-Hsien; Mrkšić, Nikola; Su, Pei-Hao","PolyResponse: A Rank-based Approach to Task-Oriented Dialogue with Application in Restaurant Search and Booking","Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP): System Demonstrations","","","10.18653/v1/D19-3031","https://aclanthology.org/D19-3031/","We present PolyResponse, a conversational search engine that supports task-oriented dialogue. It is a retrieval-based approach that bypasses the complex multi-component design of traditional task-oriented dialogue systems and the use of explicit semantics in the form of task-specific ontologies. The PolyResponse engine is trained on hundreds of millions of examples extracted from real conversations: it learns what responses are appropriate in different conversational contexts. It then ranks a large index of text and visual responses according to their similarity to the given context, and narrows down the list of relevant entities during the multi-turn conversation. We introduce a restaurant search and booking system powered by the PolyResponse engine, currently available in 8 different languages.","2019-11","2025-09-10 13:17:23","2025-09-10 13:17:23","","181–186","","","","","","","","","","","Association for Computational Linguistics","Hong Kong, China","","","","","","","","","","","","","","Padó, Sebastian; Huang, Ruihong","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8LIWLFKU","conferencePaper","2019","Khalife, Sammy; Vazirgiannis, Michalis","Scalable graph-based method for individual named entity identification","Proceedings of the Thirteenth Workshop on Graph-Based Methods for Natural Language Processing (TextGraphs-13)","","","10.18653/v1/D19-5303","https://aclanthology.org/D19-5303/","In this paper, we consider the named entity linking (NEL) problem. We assume a set of queries, named entities, that have to be identified within a knowledge base. This knowledge base is represented by a text database paired with a semantic graph, endowed with a classification of entities (ontology). We present state-of-the-art methods in NEL, and propose a new method for individual identification requiring few annotated data samples. We demonstrate its scalability and performance over standard datasets, for several ontology configurations. Our approach is well-motivated for integration in real systems. Indeed, recent deep learning methods, despite their capacity to improve experimental precision, require lots of parameter tuning along with large volume of annotated data.","2019-11","2025-09-10 13:17:23","2025-09-10 13:17:23","","17–25","","","","","","","","","","","Association for Computational Linguistics","Hong Kong","","","","","","","","","","","","","","Ustalov, Dmitry; Somasundaran, Swapna; Jansen, Peter; Glavaš, Goran; Riedl, Martin; Surdeanu, Mihai; Vazirgiannis, Michalis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EJ63AGWK","conferencePaper","2019","Bossy, Robert; Deléger, Louise; Chaix, Estelle; Ba, Mouhamadou; Nédellec, Claire","Bacteria Biotope at BioNLP Open Shared Tasks 2019","Proceedings of the 5th Workshop on BioNLP Open Shared Tasks","","","10.18653/v1/D19-5719","https://aclanthology.org/D19-5719/","This paper presents the fourth edition of the Bacteria Biotope task at BioNLP Open Shared Tasks 2019. The task focuses on the extraction of the locations and phenotypes of microorganisms from PubMed abstracts and full-text excerpts, and the characterization of these entities with respect to reference knowledge sources (NCBI taxonomy, OntoBiotope ontology). The task is motivated by the importance of the knowledge on biodiversity for fundamental research and applications in microbiology. The paper describes the different proposed subtasks, the corpus characteristics, and the challenge organization. We also provide an analysis of the results obtained by participants, and inspect the evolution of the results since the last edition in 2016.","2019-11","2025-09-10 13:17:23","2025-09-10 13:17:23","","121–131","","","","","","","","","","","Association for Computational Linguistics","Hong Kong, China","","","","","","","","","","","","","","Jin-Dong, Kim; Claire, Nédellec; Robert, Bossy; Louise, Deléger","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UVYNIQ7K","conferencePaper","2019","Baumgartner, William; Bada, Michael; Pyysalo, Sampo; Ciosici, Manuel R.; Hailu, Negacy; Pielke-Lombardo, Harrison; Regan, Michael; Hunter, Lawrence","CRAFT Shared Tasks 2019 Overview — Integrated Structure, Semantics, and Coreference","Proceedings of the 5th Workshop on BioNLP Open Shared Tasks","","","10.18653/v1/D19-5725","https://aclanthology.org/D19-5725/","As part of the BioNLP Open Shared Tasks 2019, the CRAFT Shared Tasks 2019 provides a platform to gauge the state of the art for three fundamental language processing tasks — dependency parse construction, coreference resolution, and ontology concept identification — over full-text biomedical articles. The structural annotation task requires the automatic generation of dependency parses for each sentence of an article given only the article text. The coreference resolution task focuses on linking coreferring base noun phrase mentions into chains using the symmetrical and transitive identity relation. The ontology concept annotation task involves the identification of concept mentions within text using the classes of ten distinct ontologies in the biomedical domain, both unmodified and augmented with extension classes. This paper provides an overview of each task, including descriptions of the data provided to participants and the evaluation metrics used, and discusses participant results relative to baseline performances for each of the three tasks.","2019-11","2025-09-10 13:17:23","2025-09-10 13:17:23","","174–184","","","","","","","","","","","Association for Computational Linguistics","Hong Kong, China","","","","","","","","","","","","","","Jin-Dong, Kim; Claire, Nédellec; Robert, Bossy; Louise, Deléger","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HDGZHME4","conferencePaper","2019","Nooralahzadeh, Farhad; Lønning, Jan Tore; Øvrelid, Lilja","Reinforcement-based denoising of distantly supervised NER with partial annotation","Proceedings of the 2nd Workshop on Deep Learning Approaches for Low-Resource NLP (DeepLo 2019)","","","10.18653/v1/D19-6125","https://aclanthology.org/D19-6125/","Existing named entity recognition (NER) systems rely on large amounts of human-labeled data for supervision. However, obtaining large-scale annotated data is challenging particularly in specific domains like health-care, e-commerce and so on. Given the availability of domain specific knowledge resources, (e.g., ontologies, dictionaries), distant supervision is a solution to generate automatically labeled training data to reduce human effort. The outcome of distant supervision for NER, however, is often noisy. False positive and false negative instances are the main issues that reduce performance on this kind of auto-generated data. In this paper, we explore distant supervision in a supervised setup. We adopt a technique of partial annotation to address false negative cases and implement a reinforcement learning strategy with a neural network policy to identify false positive instances. Our results establish a new state-of-the-art on four benchmark datasets taken from different domains and different languages. We then go on to show that our model reduces the amount of manually annotated data required to perform NER in a new domain.","2019-11","2025-09-10 13:17:23","2025-09-10 13:17:23","","225–233","","","","","","","","","","","Association for Computational Linguistics","Hong Kong, China","","","","","","","","","","","","","","Cherry, Colin; Durrett, Greg; Foster, George; Haffari, Reza; Khadivi, Shahram; Peng, Nanyun; Ren, Xiang; Swayamdipta, Swabha","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"G2UV5C93","conferencePaper","2019","Falis, Matus; Pajak, Maciej; Lisowska, Aneta; Schrempf, Patrick; Deckers, Lucas; Mikhael, Shadia; Tsaftaris, Sotirios; O'Neil, Alison","Ontological attention ensembles for capturing semantic concepts in ICD code prediction from clinical text","Proceedings of the Tenth International Workshop on Health Text Mining and Information Analysis (LOUHI 2019)","","","10.18653/v1/D19-6220","https://aclanthology.org/D19-6220/","We present a semantically interpretable system for automated ICD coding of clinical text documents. Our contribution is an ontological attention mechanism which matches the structure of the ICD ontology, in which shared attention vectors are learned at each level of the hierarchy, and combined into label-dependent ensembles. Analysis of the attention heads shows that shared concepts are learned by the lowest common denominator node. This allows child nodes to focus on the differentiating concepts, leading to efficient learning and memory usage. Visualisation of the multi-level attention on the original text allows explanation of the code predictions according to the semantics of the ICD ontology. On the MIMIC-III dataset we achieve a 2.7% absolute (11% relative) improvement from 0.218 to 0.245 macro-F1 score compared to the previous state of the art across 3,912 codes. Finally, we analyse the labelling inconsistencies arising from different coding practices which limit performance on this task.","2019-11","2025-09-10 13:17:23","2025-09-10 13:17:23","","168–177","","","","","","","","","","","Association for Computational Linguistics","Hong Kong","","","","","","","","","","","","","","Holderness, Eben; Jimeno Yepes, Antonio; Lavelli, Alberto; Minard, Anne-Lyse; Pustejovsky, James; Rinaldi, Fabio","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QUIEVA8A","conferencePaper","2012","Sadoun, Driss","Peuplement d'une ontologie modélisant le fonctionnement d'un environnement intelligent guidée par l'extraction d'instances de relations (Population of an Ontology Modeling the Behavior of an Intelligent Environment Guided by Instance Relation Extractions) [in French]","Proceedings of the Joint Conference JEP-TALN-RECITAL 2012, volume 3: RECITAL","","","","https://aclanthology.org/F12-3022/","","2012-06","2025-09-10 13:17:23","2025-09-10 13:17:23","","281–294","","","","","","","","","","","ATALA/AFCP","Grenoble, France","","","","","","","","","","","","","","Molina Mejia, Jorge Mauricio; Schwab, Didier; Sérasset, Gilles","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KX4MVHEN","conferencePaper","2005","Zheng, Dequan; Zhao, Tiejun; Li, Sheng; Yu, Hao","A Hybrid Chinese Language Model based on a Combination of Ontology with Statistical Method","Companion Volume to the Proceedings of Conference including Posters/Demos and tutorial abstracts","","","","https://aclanthology.org/I05-2003/","","2005","2025-09-10 13:17:23","2025-09-10 13:17:23","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HQ7ZZX9R","conferencePaper","2011","Haralambous, Yannis; Klyuev, Vitaly","A Semantic Relatedness Measure Based on Combined Encyclopedic, Ontological and Collocational Knowledge","Proceedings of 5th International Joint Conference on Natural Language Processing","","","","https://aclanthology.org/I11-1161/","","2011-11","2025-09-10 13:17:23","2025-09-10 13:17:23","","1397–1402","","","","","","","","","","","Asian Federation of Natural Language Processing","Chiang Mai, Thailand","","","","","","","","","","","","","","Wang, Haifeng; Yarowsky, David","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RLRWKRWS","conferencePaper","2019","Mahgoub, Ashraf; Shahin, Youssef; Mansour, Riham; Bagchi, Saurabh","SimVecs: Similarity-Based Vectors for Utterance Representation in Conversational AI Systems","Proceedings of the 23rd Conference on Computational Natural Language Learning (CoNLL)","","","10.18653/v1/K19-1066","https://aclanthology.org/K19-1066/","Conversational AI systems are gaining a lot of attention recently in both industrial and scientific domains, providing a natural way of interaction between customers and adaptive intelligent systems. A key requirement in these systems is the ability to understand the user's intent and provide adequate responses to them. One of the greatest challenges of language understanding (LU) services is efficient utterance (sentence) representation in vector space, which is an essential step for most ML tasks. In this paper, we propose a novel approach for generating vector space representations of utterances using pair-wise similarity metrics. The proposed approach uses only a few corpora to tune the weights of the similarity metric without relying on external general purpose ontologies. Our experiments confirm that the generated vectors can improve the performance of LU services in unsupervised, semi-supervised and supervised learning tasks.","2019-11","2025-09-10 13:17:23","2025-09-10 13:17:23","","708–717","","","","","","","","","","","Association for Computational Linguistics","Hong Kong, China","","","","","","","","","","","","","","Bansal, Mohit; Villavicencio, Aline","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SLC4P4ET","conferencePaper","2006","Kiyota, Yoji; Nakagawa, Hiroshi","A Domain Ontology Production Tool Kit Based on Automatically Constructed Case Frames","Proceedings of the Fifth International Conference on Language Resources and Evaluation (LREC'06)","","","","https://aclanthology.org/L06-1135/","This paper proposes a tool kit to produce a domain ontology for text mining, based on case frames automatically constructed from a raw corpus of a specific domain. Since case frames are strongly related to implicit facts hidden in large domain-specific corpora, we can say that case frames are a promising device for text mining. The aim of the tool kit is to enable automatic analysis of event reports, from which implicit factors of the events are to be extracted. The tool kit enables us to produce a domain ontology by iterating associative retrieval of case frames and manual refinement. In this study, the tool kit is applied to the Japan Airlines pilot report collection, and a domain ontology of contributing factors in the civil aviation domain is experimentally produced. A lot of interesting examples are found in the ontology. In addition, a brief examination of the production process shows the efficiency of the tool kit.","2006-05","2025-09-10 13:17:23","2025-09-10 13:17:23","","","","","","","","","","","","","European Language Resources Association (ELRA)","Genoa, Italy","","","","","","","","","","","","","","Calzolari, Nicoletta; Choukri, Khalid; Gangemi, Aldo; Maegaard, Bente; Mariani, Joseph; Odijk, Jan; Tapias, Daniel","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EHXXI7EZ","conferencePaper","2006","Declerck, Thierry; Vela, Mihaela","Generic NLP Tools for Supporting Shallow Ontology Building","Proceedings of the Fifth International Conference on Language Resources and Evaluation (LREC'06)","","","","https://aclanthology.org/L06-1216/","In this paper we present on-going investigations on how complex syntactic annotation, combined with linguistic semantics, can possibly help in supporting the semi-automatic building of (shallow) ontologies from text by proposing an automated extraction of (possibly underspecified) semantic relations from linguistically annotated text.","2006-05","2025-09-10 13:17:23","2025-09-10 13:17:23","","","","","","","","","","","","","European Language Resources Association (ELRA)","Genoa, Italy","","","","","","","","","","","","","","Calzolari, Nicoletta; Choukri, Khalid; Gangemi, Aldo; Maegaard, Bente; Mariani, Joseph; Odijk, Jan; Tapias, Daniel","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"E38HSNDI","conferencePaper","2006","Tablan, Valentin; Polajnar, Tamara; Cunningham, Hamish; Bontcheva, Kalina","User-friendly ontology authoring using a controlled language","Proceedings of the Fifth International Conference on Language Resources and Evaluation (LREC'06)","","","","https://aclanthology.org/L06-1324/","In recent years, following the rapid development in the Semantic Web and Knowledge Management research, ontologies have become more in demand in Natural Language Processing. An increasing number of systems use ontologies either internally, for modelling the domain of the application, or as data structures that hold the output resulting from the work of the system, in the form of knowledge bases. While there are many ontology editing tools aimed at expert users, there are very few which are accessible to users wishing to create simple structures without delving into the intricacies of knowledge representation languages. The approach described in this paper allows users to create and edit ontologies simply by using a restricted version of the English language. The controlled language described within is based on an open vocabulary and a restricted set of grammatical constructs. Sentences written in this language unambiguously map into a number of knowledge representation formats including OWL and RDF-S to allow round-trip ontology management.","2006-05","2025-09-10 13:17:23","2025-09-10 13:17:23","","","","","","","","","","","","","European Language Resources Association (ELRA)","Genoa, Italy","","","","","","","","","","","","","","Calzolari, Nicoletta; Choukri, Khalid; Gangemi, Aldo; Maegaard, Bente; Mariani, Joseph; Odijk, Jan; Tapias, Daniel","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7ESBDE25","conferencePaper","2008","Suktarachan, Mukda; Thamvijit, Dussadee; Noikongka, Daoyos; Yongyuth, Panita; Mahasarakham, Puwarat Pavaputanont Na; Kawtrakul, Asanee; Kawtrakul, Asanee; Sini, Margherita","Workbench with Authoring Tools for Collaborative Multi-lingual Ontological Knowledge Construction and Maintenance","Proceedings of the Sixth International Conference on Language Resources and Evaluation (LREC'08)","","","","https://aclanthology.org/L08-1271/","An ontological knowledge management system requires dynamic and encapsulating operation in order to share knowledge among communities. The key to success of knowledge sharing in the field of agriculture is using and sharing agreed terminologies such as ontological knowledge especially in multiple languages. This paper proposes a workbench with three authoring tools for collaborative multilingual ontological knowledge construction and maintenance, in order to add value and support communities in the field of food and agriculture. The framework consists of the multilingual ontological knowledge construction and maintenance workbench platform, which composes of ontological knowledge management and user management, and three ontological knowledge authoring tools. The authoring tools used are two ontology extraction tools, ATOM and KULEX, and one ontology integration tool.","2008-05","2025-09-10 13:17:23","2025-09-10 13:17:23","","","","","","","","","","","","","European Language Resources Association (ELRA)","Marrakech, Morocco","","","","","","","","","","","","","","Calzolari, Nicoletta; Choukri, Khalid; Maegaard, Bente; Mariani, Joseph; Odijk, Jan; Piperidis, Stelios; Tapias, Daniel","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PDWEQQXK","conferencePaper","2008","Davis, Brian; Handschuh, Siegfried; Troussov, Alexander; Judge, John; Sogrin, Mikhail","Linguistically Light Lexical Extensions for Ontologies","Proceedings of the Sixth International Conference on Language Resources and Evaluation (LREC'08)","","","","https://aclanthology.org/L08-1558/","The identification of class instances within unstructured text for either the purposes of Ontology population or semantic annotation are usually limited to term mentions of Proper Noun and Personal Noun or fixed Key Phrases within Text Analytics or Ontology based Information Extraction(OBIE) applications. These systems do not generalize to cope with compound nominal classes of multi word expressions. Computational Linguistics approaches involving deep analysis tend to suffer from idiomaticity and overgeneration problems while the shallower words with spaces approach frequently employed in Information Extraction(IE) and Industrial Text Analytics systems lacks flexibility and is prone to lexical proliferation. We outline a representation for encoding light linguistic features of Compound Nominal term mentions of Concepts within an Ontology as well as a lightweight semantic annotator which complies the above linguistic information into efficient Dictionary formats to drive large scale identification and semantic annotation of the aforementioned concepts.","2008-05","2025-09-10 13:17:23","2025-09-10 13:17:23","","","","","","","","","","","","","European Language Resources Association (ELRA)","Marrakech, Morocco","","","","","","","","","","","","","","Calzolari, Nicoletta; Choukri, Khalid; Maegaard, Bente; Mariani, Joseph; Odijk, Jan; Piperidis, Stelios; Tapias, Daniel","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"N323TEC2","conferencePaper","2010","Monachesi, Paola; Markus, Thomas","Socially Driven Ontology Enrichment for eLearning","Proceedings of the Seventh International Conference on Language Resources and Evaluation (LREC'10)","","","","https://aclanthology.org/L10-1570/","One of the objectives of the Language Technologies for Life-Long Learning (LTfLL) project, is to develop a knowledge sharing system that connects learners to resources and learners to other learners. To this end, we complement the formal knowledge represented by existing domain ontologies with the informal knowledge emerging from social tagging. More specifically, we crawl data from social media applications such as Delicious, Slideshare and YouTube. Similarity measures are employed to select possible lexicalizations of concepts that are related to the ones present in the given ontology and which are assumed to be socially relevant with respect to the input lexicalisation. In order to identify the appropriate relationships which exist between the extracted related terms and the existing domain ontology, we employ several heuristics that rely on the use of a large background knowledge base, such as DBpedia. An evaluation of the resulting ontology has been carried out. The methodology proposed allows for an appropriate enrichment process and produces a complementary vocabulary to that of a domain expert.","2010-05","2025-09-10 13:17:23","2025-09-10 13:17:23","","","","","","","","","","","","","European Language Resources Association (ELRA)","Valletta, Malta","","","","","","","","","","","","","","Calzolari, Nicoletta; Choukri, Khalid; Maegaard, Bente; Mariani, Joseph; Odijk, Jan; Piperidis, Stelios; Rosner, Mike; Tapias, Daniel","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EN62UI6D","conferencePaper","2015","Jauhar, Sujay Kumar; Dyer, Chris; Hovy, Eduard","Ontologically Grounded Multi-sense Representation Learning for Semantic Vector Space Models","Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies","","","10.3115/v1/N15-1070","https://aclanthology.org/N15-1070/","","2015-05","2025-09-10 13:17:23","2025-09-10 13:17:23","","683–693","","","","","","","","","","","Association for Computational Linguistics","Denver, Colorado","","","","","","","","","","","","","","Mihalcea, Rada; Chai, Joyce; Sarkar, Anoop","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PD6M4KG4","conferencePaper","2018","Kolyvakis, Prodromos; Kalousis, Alexandros; Kiritsis, Dimitris","DeepAlignment: Unsupervised Ontology Matching with Refined Word Vectors","Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long Papers)","","","10.18653/v1/N18-1072","https://aclanthology.org/N18-1072/","Ontologies compartmentalize types and relations in a target domain and provide the semantic backbone needed for a plethora of practical applications. Very often different ontologies are developed independently for the same domain. Such “parallel” ontologies raise the need for a process that will establish alignments between their entities in order to unify and extend the existing knowledge. In this work, we present a novel entity alignment method which we dub DeepAlignment. DeepAlignment refines pre-trained word vectors aiming at deriving ontological entity descriptions which are tailored to the ontology matching task. The absence of explicit information relevant to the ontology matching task during the refinement process makes DeepAlignment completely unsupervised. We empirically evaluate our method using standard ontology matching benchmarks. We present significant performance improvements over the current state-of-the-art, demonstrating the advantages that representation learning techniques bring to ontology matching.","2018-06","2025-09-10 13:17:23","2025-09-10 13:17:23","","787–798","","","","","","","","","","","Association for Computational Linguistics","New Orleans, Louisiana","","","","","","","","","","","","","","Walker, Marilyn; Ji, Heng; Stent, Amanda","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XHY8QXDB","conferencePaper","2018","Kollar, Thomas; Berry, Danielle; Stuart, Lauren; Owczarzak, Karolina; Chung, Tagyoung; Mathias, Lambert; Kayser, Michael; Snow, Bradford; Matsoukas, Spyros","The Alexa Meaning Representation Language","Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 3 (Industry Papers)","","","10.18653/v1/N18-3022","https://aclanthology.org/N18-3022/","This paper introduces a meaning representation for spoken language understanding. The Alexa meaning representation language (AMRL), unlike previous approaches, which factor spoken utterances into domains, provides a common representation for how people communicate in spoken language. AMRL is a rooted graph, links to a large-scale ontology, supports cross-domain queries, fine-grained types, complex utterances and composition. A spoken language dataset has been collected for Alexa, which contains \ensuremath\sim20k examples across eight domains. A version of this meaning representation was released to developers at a trade show in 2016.","2018-06","2025-09-10 13:17:23","2025-09-10 13:17:23","","177–184","","","","","","","","","","","Association for Computational Linguistics","New Orleans - Louisiana","","","","","","","","","","","","","","Bangalore, Srinivas; Chu-Carroll, Jennifer; Li, Yunyao","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TZBXEDHA","conferencePaper","2019","Li, Diya; Huang, Lifu; Ji, Heng; Han, Jiawei","Biomedical Event Extraction based on Knowledge-driven Tree-LSTM","Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)","","","10.18653/v1/N19-1145","https://aclanthology.org/N19-1145/","Event extraction for the biomedical domain is more challenging than that in the general news domain since it requires broader acquisition of domain-specific knowledge and deeper understanding of complex contexts. To better encode contextual information and external background knowledge, we propose a novel knowledge base (KB)-driven tree-structured long short-term memory networks (Tree-LSTM) framework, incorporating two new types of features: (1) dependency structures to capture wide contexts; (2) entity properties (types and category descriptions) from external ontologies via entity linking. We evaluate our approach on the BioNLP shared task with Genia dataset and achieve a new state-of-the-art result. In addition, both quantitative and qualitative studies demonstrate the advancement of the Tree-LSTM and the external knowledge representation for biomedical event extraction.","2019-06","2025-09-10 13:17:23","2025-09-10 13:17:23","","1421–1430","","","","","","","","","","","Association for Computational Linguistics","Minneapolis, Minnesota","","","","","","","","","","","","","","Burstein, Jill; Doran, Christy; Solorio, Thamar","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2Y57SRKB","conferencePaper","2019","Prokhorov, Victor; Pilehvar, Mohammad Taher; Collier, Nigel","Generating Knowledge Graph Paths from Textual Definitions using Sequence-to-Sequence Models","Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)","","","10.18653/v1/N19-1196","https://aclanthology.org/N19-1196/","We present a novel method for mapping unrestricted text to knowledge graph entities by framing the task as a sequence-to-sequence problem. Specifically, given the encoded state of an input text, our decoder directly predicts paths in the knowledge graph, starting from the root and ending at the the target node following hypernym-hyponym relationships. In this way, and in contrast to other text-to-entity mapping systems, our model outputs hierarchically structured predictions that are fully interpretable in the context of the underlying ontology, in an end-to-end manner. We present a proof-of-concept experiment with encouraging results, comparable to those of state-of-the-art systems.","2019-06","2025-09-10 13:17:23","2025-09-10 13:17:23","","1968–1976","","","","","","","","","","","Association for Computational Linguistics","Minneapolis, Minnesota","","","","","","","","","","","","","","Burstein, Jill; Doran, Christy; Solorio, Thamar","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"SXBNQLUK","conferencePaper","2019","Lockard, Colin; Shiralkar, Prashant; Dong, Xin Luna","OpenCeres: When Open Information Extraction Meets the Semi-Structured Web","Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers)","","","10.18653/v1/N19-1309","https://aclanthology.org/N19-1309/","Open Information Extraction (OpenIE), the problem of harvesting triples from natural language text whose predicate relations are not aligned to any pre-defined ontology, has been a popular subject of research for the last decade. However, this research has largely ignored the vast quantity of facts available in semi-structured webpages. In this paper, we define the problem of OpenIE from semi-structured websites to extract such facts, and present an approach for solving it. We also introduce a labeled evaluation dataset to motivate research in this area. Given a semi-structured website and a set of seed facts for some relations existing on its pages, we employ a semi-supervised label propagation technique to automatically create training data for the relations present on the site. We then use this training data to learn a classifier for relation extraction. Experimental results of this method on our new benchmark dataset obtained a precision of over 70%. A larger scale extraction experiment on 31 websites in the movie vertical resulted in the extraction of over 2 million triples.","2019-06","2025-09-10 13:17:23","2025-09-10 13:17:23","","3047–3056","","","","","","","","","","","Association for Computational Linguistics","Minneapolis, Minnesota","","","","","","","","","","","","","","Burstein, Jill; Doran, Christy; Solorio, Thamar","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"268CI7WZ","conferencePaper","2018","Murty, Shikhar; Verga, Patrick; Vilnis, Luke; Radovanovic, Irena; McCallum, Andrew","Hierarchical Losses and New Resources for Fine-grained Entity Typing and Linking","Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)","","","10.18653/v1/P18-1010","https://aclanthology.org/P18-1010/","Extraction from raw text to a knowledge base of entities and fine-grained types is often cast as prediction into a flat set of entity and type labels, neglecting the rich hierarchies over types and entities contained in curated ontologies. Previous attempts to incorporate hierarchical structure have yielded little benefit and are restricted to shallow ontologies. This paper presents new methods using real and complex bilinear mappings for integrating hierarchical information, yielding substantial improvement over flat predictions in entity linking and fine-grained entity typing, and achieving new state-of-the-art results for end-to-end models on the benchmark FIGER dataset. We also present two new human-annotated datasets containing wide and deep hierarchies which we will release to the community to encourage further research in this direction: <i>MedMentions</i>, a collection of PubMed abstracts in which 246k mentions have been mapped to the massive UMLS ontology; and <i>TypeNet</i>, which aligns Freebase types with the WordNet hierarchy to obtain nearly 2k entity types. In experiments on all three datasets we show substantial gains from hierarchy-aware training.","2018-07","2025-09-10 13:17:23","2025-09-10 13:17:23","","97–109","","","","","","","","","","","Association for Computational Linguistics","Melbourne, Australia","","","","","","","","","","","","","","Gurevych, Iryna; Miyao, Yusuke","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"EA482MSX","conferencePaper","2018","Huang, Lifu; Ji, Heng; Cho, Kyunghyun; Dagan, Ido; Riedel, Sebastian; Voss, Clare","Zero-Shot Transfer Learning for Event Extraction","Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)","","","10.18653/v1/P18-1201","https://aclanthology.org/P18-1201/","Most previous supervised event extraction methods have relied on features derived from manual annotations, and thus cannot be applied to new event types without extra annotation effort. We take a fresh look at event extraction and model it as a generic grounding problem: mapping each event mention to a specific type in a target event ontology. We design a transferable architecture of structural and compositional neural networks to jointly represent and map event mentions and types into a shared semantic space. Based on this new framework, we can select, for each event mention, the event type which is semantically closest in this space as its type. By leveraging manual annotations available for a small set of existing event types, our framework can be applied to new unseen event types without additional manual annotations. When tested on 23 unseen event types, our zero-shot framework, without manual annotations, achieved performance comparable to a supervised model trained from 3,000 sentences annotated with 500 event mentions.","2018-07","2025-09-10 13:17:23","2025-09-10 13:17:23","","2160–2170","","","","","","","","","","","Association for Computational Linguistics","Melbourne, Australia","","","","","","","","","","","","","","Gurevych, Iryna; Miyao, Yusuke","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QJHGMLSC","conferencePaper","2018","Lu, Zhengdong; Liu, Xianggen; Cui, Haotian; Yan, Yukun; Zheng, Daqi","Object-oriented Neural Programming (OONP) for Document Understanding","Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)","","","10.18653/v1/P18-1253","https://aclanthology.org/P18-1253/","We propose Object-oriented Neural Programming (OONP), a framework for semantically parsing documents in specific domains. Basically, OONP reads a document and parses it into a predesigned object-oriented data structure that reflects the domain-specific semantics of the document. An OONP parser models semantic parsing as a decision process: a neural net-based Reader sequentially goes through the document, and builds and updates an intermediate ontology during the process to summarize its partial understanding of the text. OONP supports a big variety of forms (both symbolic and differentiable) for representing the state and the document, and a rich family of operations to compose the representation. An OONP parser can be trained with supervision of different forms and strength, including supervised learning (SL), reinforcement learning (RL) and hybrid of the two. Our experiments on both synthetic and real-world document parsing tasks have shown that OONP can learn to handle fairly complicated ontology with training data of modest sizes.","2018-07","2025-09-10 13:17:23","2025-09-10 13:17:23","","2717–2726","","","","","","","","","","","Association for Computational Linguistics","Melbourne, Australia","","","","","","","","","","","","","","Gurevych, Iryna; Miyao, Yusuke","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"9PAH9HQB","conferencePaper","2018","Ramadan, Osman; Budzianowski, Paweł; Gašić, Milica","Large-Scale Multi-Domain Belief Tracking with Knowledge Sharing","Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)","","","10.18653/v1/P18-2069","https://aclanthology.org/P18-2069/","Robust dialogue belief tracking is a key component in maintaining good quality dialogue systems. The tasks that dialogue systems are trying to solve are becoming increasingly complex, requiring scalability to multi-domain, semantically rich dialogues. However, most current approaches have difficulty scaling up with domains because of the dependency of the model parameters on the dialogue ontology. In this paper, a novel approach is introduced that fully utilizes semantic similarity between dialogue utterances and the ontology terms, allowing the information to be shared across domains. The evaluation is performed on a recently collected multi-domain dialogues dataset, one order of magnitude larger than currently available corpora. Our model demonstrates great capability in handling multi-domain dialogues, simultaneously outperforming existing state-of-the-art models in single-domain dialogue tracking tasks.","2018-07","2025-09-10 13:17:24","2025-09-10 13:17:24","","432–437","","","","","","","","","","","Association for Computational Linguistics","Melbourne, Australia","","","","","","","","","","","","","","Gurevych, Iryna; Miyao, Yusuke","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8NR55JKK","conferencePaper","2018","Hartung, Matthias; ter Horst, Hendrik; Grimm, Frank; Diekmann, Tim; Klinger, Roman; Cimiano, Philipp","SANTO: A Web-based Annotation Tool for Ontology-driven Slot Filling","Proceedings of ACL 2018, System Demonstrations","","","10.18653/v1/P18-4012","https://aclanthology.org/P18-4012/","Supervised machine learning algorithms require training data whose generation for complex relation extraction tasks tends to be difficult. Being optimized for relation extraction at sentence level, many annotation tools lack in facilitating the annotation of relational structures that are widely spread across the text. This leads to non-intuitive and cumbersome visualizations, making the annotation process unnecessarily time-consuming. We propose SANTO, an easy-to-use, domain-adaptive annotation tool specialized for complex slot filling tasks which may involve problems of cardinality and referential grounding. The web-based architecture enables fast and clearly structured annotation for multiple users in parallel. Relational structures are formulated as templates following the conceptualization of an underlying ontology. Further, import and export procedures of standard formats enable interoperability with external sources and tools.","2018-07","2025-09-10 13:17:24","2025-09-10 13:17:24","","68–73","","","","","","","","","","","Association for Computational Linguistics","Melbourne, Australia","","","","","","","","","","","","","","Liu, Fei; Solorio, Thamar","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KXKKDJUP","conferencePaper","2018","Shen, Zhihong; Ma, Hao; Wang, Kuansan","A Web-scale system for scientific knowledge exploration","Proceedings of ACL 2018, System Demonstrations","","","10.18653/v1/P18-4015","https://aclanthology.org/P18-4015/","To enable efficient exploration of Web-scale scientific knowledge, it is necessary to organize scientific publications into a hierarchical concept structure. In this work, we present a large-scale system to (1) identify hundreds of thousands of scientific concepts, (2) tag these identified concepts to hundreds of millions of scientific publications by leveraging both text and graph structure, and (3) build a six-level concept hierarchy with a subsumption-based model. The system builds the most comprehensive cross-domain scientific concept ontology published to date, with more than 200 thousand concepts and over one million relationships.","2018-07","2025-09-10 13:17:24","2025-09-10 13:17:24","","87–92","","","","","","","","","","","Association for Computational Linguistics","Melbourne, Australia","","","","","","","","","","","","","","Liu, Fei; Solorio, Thamar","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"CK2SC4XS","conferencePaper","2019","Wu, Chien-Sheng; Madotto, Andrea; Hosseini-Asl, Ehsan; Xiong, Caiming; Socher, Richard; Fung, Pascale","Transferable Multi-Domain State Generator for Task-Oriented Dialogue Systems","Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics","","","10.18653/v1/P19-1078","https://aclanthology.org/P19-1078/","Over-dependence on domain ontology and lack of sharing knowledge across domains are two practical and yet less studied problems of dialogue state tracking. Existing approaches generally fall short when tracking unknown slot values during inference and often have difficulties in adapting to new domains. In this paper, we propose a Transferable Dialogue State Generator (TRADE) that generates dialogue states from utterances using copy mechanism, facilitating transfer when predicting (domain, slot, value) triplets not encountered during training. Our model is composed of an utterance encoder, a slot gate, and a state generator, which are shared across domains. Empirical results demonstrate that TRADE achieves state-of-the-art 48.62% joint goal accuracy for the five domains of MultiWOZ, a human-human dialogue dataset. In addition, we show the transferring ability by simulating zero-shot and few-shot dialogue state tracking for unseen domains. TRADE achieves 60.58% joint goal accuracy in one of the zero-shot domains, and is able to adapt to few-shot cases without forgetting already trained domains.","2019-07","2025-09-10 13:17:24","2025-09-10 13:17:24","","808–819","","","","","","","","","","","Association for Computational Linguistics","Florence, Italy","","","","","","","","","","","","","","Korhonen, Anna; Traum, David; Màrquez, Lluís","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DRZM3MNY","conferencePaper","2019","Lee, Hwaran; Lee, Jinsik; Kim, Tae-Yoon","SUMBT: Slot-Utterance Matching for Universal and Scalable Belief Tracking","Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics","","","10.18653/v1/P19-1546","https://aclanthology.org/P19-1546/","In goal-oriented dialog systems, belief trackers estimate the probability distribution of slot-values at every dialog turn. Previous neural approaches have modeled domain- and slot-dependent belief trackers, and have difficulty in adding new slot-values, resulting in lack of flexibility of domain ontology configurations. In this paper, we propose a new approach to universal and scalable belief tracker, called slot-utterance matching belief tracker (SUMBT). The model learns the relations between domain-slot-types and slot-values appearing in utterances through attention mechanisms based on contextual semantic vectors. Furthermore, the model predicts slot-value labels in a non-parametric way. From our experiments on two dialog corpora, WOZ 2.0 and MultiWOZ, the proposed model showed performance improvement in comparison with slot-dependent methods and achieved the state-of-the-art joint accuracy.","2019-07","2025-09-10 13:17:24","2025-09-10 13:17:24","","5478–5483","","","","","","","","","","","Association for Computational Linguistics","Florence, Italy","","","","","","","","","","","","","","Korhonen, Anna; Traum, David; Màrquez, Lluís","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"N7PMZZF5","conferencePaper","2019","Bebeshina-Clairet, Nadia; Despres, Sylvie; Lafourcade, Mathieu","Using a Lexical Semantic Network for the Ontology Building","Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2019)","","","10.26615/978-954-452-056-4_012","https://aclanthology.org/R19-1012/","Building multilingual ontologies is a hard task as ontologies are often data-rich resources. We introduce an approach which allows exploiting structured lexical semantic knowledge for the ontology building. Given a multilingual lexical semantic (non ontological) resource and an ontology model, it allows mining relevant semantic knowledge and make the ontology building and enhancement process faster.","2019-09","2025-09-10 13:17:24","2025-09-10 13:17:24","","92–101","","","","","","","","","","","INCOMA Ltd.","Varna, Bulgaria","","","","","","","","","","","","","","Mitkov, Ruslan; Angelova, Galia","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HPP3ZPX6","conferencePaper","2019","Estevez-Velarde, Suilan; Montoyo, Andrés; Almeida-Cruz, Yudivian; Gutiérrez, Yoan; Piad-Morffis, Alejandro; Muñoz, Rafael","Demo Application for LETO: Learning Engine Through Ontologies","Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2019)","","","10.26615/978-954-452-056-4_032","https://aclanthology.org/R19-1032/","The massive amount of multi-formatted information available on the Web necessitates the design of software systems that leverage this information to obtain knowledge that is valid and useful. The main challenge is to discover relevant information and continuously update, enrich and integrate knowledge from various sources of structured and unstructured data. This paper presents the Learning Engine Through Ontologies(LETO) framework, an architecture for the continuous and incremental discovery of knowledge from multiple sources of unstructured and structured data. We justify the main design decision behind LETO's architecture and evaluate the framework's feasibility using the Internet Movie Data Base(IMDB) and Twitter as a practical application.","2019-09","2025-09-10 13:17:24","2025-09-10 13:17:24","","276–284","","","","","","","","","","","INCOMA Ltd.","Varna, Bulgaria","","","","","","","","","","","","","","Mitkov, Ruslan; Angelova, Galia","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"73AL7QAY","conferencePaper","2019","Galitsky, Boris; Ilvovsky, Dmitry","Discourse-Based Approach to Involvement of Background Knowledge for Question Answering","Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2019)","","","10.26615/978-954-452-056-4_044","https://aclanthology.org/R19-1044/","We introduce a concept of a virtual discourse tree to improve question answering (Q/A) recall for complex, multi-sentence questions. Augmenting the discourse tree of an answer with tree fragments obtained from text corpora playing the role of ontology, we obtain on the fly a canonical discourse representation of this answer that is independent of the thought structure of a given author. This mechanism is critical for finding an answer that is not only relevant in terms of questions entities but also in terms of inter-relations between these entities in an answer and its style. We evaluate the Q/A system enabled with virtual discourse trees and observe a substantial increase of performance answering complex questions such as Yahoo! Answers and www.2carpros.com.","2019-09","2025-09-10 13:17:24","2025-09-10 13:17:24","","373–381","","","","","","","","","","","INCOMA Ltd.","Varna, Bulgaria","","","","","","","","","","","","","","Mitkov, Ruslan; Angelova, Galia","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UYMGW9I9","conferencePaper","2019","Nicula, Bogdan; Dascalu, Mihai; Sîrbu, Maria-Dorinela; Trăușan-Matu, Ștefan; Nuță, Alexandru","Building a Comprehensive Romanian Knowledge Base for Drug Administration","Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2019)","","","10.26615/978-954-452-056-4_096","https://aclanthology.org/R19-1096/","Information on drug administration is obtained traditionally from doctors and pharmacists, as well as leaflets which provide in most cases cumbersome and hard-to-follow details. Thus, the need for medical knowledge bases emerges to provide access to concrete and well-structured information which can play an important role in informing patients. This paper introduces a Romanian medical knowledge base focused on drug-drug interactions, on representing relevant drug information, and on symptom-disease relations. The knowledge base was created by extracting and transforming information using Natural Language Processing techniques from both structured and unstructured sources, together with manual annotations. The resulting Romanian ontologies are aligned with larger English medical ontologies. Our knowledge base supports queries regarding drugs (e.g., active ingredients, concentration, expiration date), drug-drug interaction, symptom-disease relations, as well as drug-symptom relations.","2019-09","2025-09-10 13:17:24","2025-09-10 13:17:24","","829–836","","","","","","","","","","","INCOMA Ltd.","Varna, Bulgaria","","","","","","","","","","","","","","Mitkov, Ruslan; Angelova, Galia","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"M5VG56ID","conferencePaper","2018","Poostchi, Hanieh; Piccardi, Massimo","Cluster Labeling by Word Embeddings and WordNet's Hypernymy","Proceedings of the Australasian Language Technology Association Workshop 2018","","","","https://aclanthology.org/U18-1008/","Cluster labeling is the assignment of representative labels to clusters obtained from the organization of a document collection. Once assigned, the labels can play an important role in applications such as navigation, search and document classification. However, finding appropriately descriptive labels is still a challenging task. In this paper, we propose various approaches for assigning labels to word clusters by leveraging word embeddings and the synonymity and hypernymy relations in the WordNet lexical ontology. Experiments carried out using the WebAP document dataset have shown that one of the approaches stand out in the comparison and is capable of selecting labels that are reasonably aligned with those chosen by a pool of four human annotators.","2018-12","2025-09-10 13:17:24","2025-09-10 13:17:24","","66–70","","","","","","","","","","","","Dunedin, New Zealand","","","","","","","","","","","","","","Kim, Sunghwan Mac; Zhang, Xiuzhen (Jenny)","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"KIH59X85","conferencePaper","2003","Wu, Shih-Hung; Tsai, Tzong-Han; Hsu, Wen-Lian","Text Categorization Using Automatically Acquired Domain Ontology","Proceedings of the Sixth International Workshop on Information Retrieval with Asian Languages","","","10.3115/1118935.1118953","https://aclanthology.org/W03-1118/","","2003-07","2025-09-10 13:17:24","2025-09-10 13:17:24","","138–145","","","","","","","","","","","Association for Computational Linguistics","Sapporo, Japan","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"V759WTV3","conferencePaper","2004","Mani, Inderjeet; Samuel, Ken; Concepcion, Kris; Vogel, David","Automatically Inducing Ontologies from Corpora","Proceedings of CompuTerm 2004: 3rd International Workshop on Computational Terminology","","","","https://aclanthology.org/W04-1806/","","2004-08-29","2025-09-10 13:17:24","2025-09-10 13:17:24","","47–54","","","","","","","","","","","COLING","Geneva, Switzerland","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"QN8CBII6","conferencePaper","2006","Fyshe, Alona; Szafron, Duane","Term Generalization and Synonym Resolution for Biological Abstracts: Using the Gene Ontology for Subcellular Localization Prediction","Proceedings of the HLT-NAACL BioNLP Workshop on Linking Natural Language and Biology","","","","https://aclanthology.org/W06-3303/","","2006-06","2025-09-10 13:17:24","2025-09-10 13:17:24","","17–24","","","","","","","","","","","Association for Computational Linguistics","New York, New York","","","","","","","","","","","","","","Verspoor, Karin; Cohen, Kevin Bretonnel; Goertzel, Ben; Mani, Inderjeet","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"JYHBSH47","conferencePaper","2007","Galanis, Dimitrios; Androutsopoulos, Ion","Generating Multilingual Descriptions from Linguistically Annotated OWL Ontologies: the NaturalOWL System","Proceedings of the Eleventh European Workshop on Natural Language Generation (ENLG 07)","","","","https://aclanthology.org/W07-2322/","","2007-06","2025-09-10 13:17:24","2025-09-10 13:17:24","","143–146","","","","","","","","","","","DFKI GmbH","Saarbrücken, Germany","","","","","","","","","","","","","","Busemann, Stephan","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"AI8AIJAA","conferencePaper","2010","Conway, Mike; Dowling, John; Chapman, Wendy","Developing a Biosurveillance Application Ontology for Influenza-Like-Illness","Proceedings of the 6th Workshop on Ontologies and Lexical Resources","","","","https://aclanthology.org/W10-3307/","","2010-08","2025-09-10 13:17:24","2025-09-10 13:17:24","","58–66","","","","","","","","","","","Coling 2010 Organizing Committee","Beijing, China","","","","","","","","","","","","","","Oltramari, Alessandro; Vossen, Piek; Lu, Qin","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"X8PMU62M","conferencePaper","2011","Bouayad-Agha, Nadjet; Casamayor, Gerard; Wanner, Leo","Content selection from an ontology-based knowledge base for the generation of football summaries","Proceedings of the 13th European Workshop on Natural Language Generation","","","","https://aclanthology.org/W11-2810/","","2011-09","2025-09-10 13:17:24","2025-09-10 13:17:24","","72–81","","","","","","","","","","","Association for Computational Linguistics","Nancy, France","","","","","","","","","","","","","","Gardent, Claire; Striegnitz, Kristina","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"PAU4MTXQ","conferencePaper","2012","Movshovitz-Attias, Dana; Cohen, William W.","Bootstrapping Biomedical Ontologies for Scientific Text using NELL","BioNLP: Proceedings of the 2012 Workshop on Biomedical Natural Language Processing","","","","https://aclanthology.org/W12-2402/","","2012-06","2025-09-10 13:17:24","2025-09-10 13:17:24","","11–19","","","","","","","","","","","Association for Computational Linguistics","Montréal, Canada","","","","","","","","","","","","","","Cohen, Kevin B.; Demner-Fushman, Dina; Ananiadou, Sophia; Webber, Bonnie; Tsujii, Jun'ichi; Pestian, John","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6FX7LKU3","conferencePaper","2013","Allen, James; de Beaumont, Will; Galescu, Lucian; Orfan, Jansen; Swift, Mary; Teng, Choh Man","Automatically Deriving Event Ontologies for a CommonSense Knowledge Base","Proceedings of the 10th International Conference on Computational Semantics (IWCS 2013) – Long Papers","","","","https://aclanthology.org/W13-0103/","","2013-03","2025-09-10 13:17:24","2025-09-10 13:17:24","","23–34","","","","","","","","","","","Association for Computational Linguistics","Potsdam, Germany","","","","","","","","","","","","","","Koller, Alexander; Erk, Katrin","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5FZXHX9S","conferencePaper","2013","Genc, Yegin; Lennon, Elizabeth; Mason, Winter; Nickerson, Jeffrey","Building Ontologies from Collaborative Knowledge Bases to Search and Interpret Multilingual Corpora","Proceedings of the Sixth Workshop on Building and Using Comparable Corpora","","","","https://aclanthology.org/W13-2511/","","2013-08","2025-09-10 13:17:24","2025-09-10 13:17:24","","87–94","","","","","","","","","","","Association for Computational Linguistics","Sofia, Bulgaria","","","","","","","","","","","","","","Sharoff, Serge; Zweigenbaum, Pierre; Rapp, Reinhard","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MTM9MQ8X","conferencePaper","2014","McCrae, John P.; Quattri, Francesca; Unger, Christina; Cimiano, Philipp","Modelling the Semantics of Adjectives in the Ontology-Lexicon Interface","Proceedings of the 4th Workshop on Cognitive Aspects of the Lexicon (CogALex)","","","10.3115/v1/W14-4724","https://aclanthology.org/W14-4724/","","2014-08","2025-09-10 13:17:24","2025-09-10 13:17:24","","198–209","","","","","","","","","","","Association for Computational Linguistics and Dublin City University","Dublin, Ireland","","","","","","","","","","","","","","Zock, Michael; Rapp, Reinhard; Huang, Chu-Ren","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"TPAA27BR","conferencePaper","2016","Behera, Pitambar; Muzaffar, Sharmin; Ojha, Atul Ku.; Jha, Girish","The IMAGACT4ALL Ontology of Animated Images: Implications for Theoretical and Machine Translation of Action Verbs from English-Indian Languages","Proceedings of the 6th Workshop on South and Southeast Asian Natural Language Processing (WSSANLP2016)","","","","https://aclanthology.org/W16-3707/","Action verbs are one of the frequently occurring linguistic elements in any given natural language as the speakers use them during every linguistic intercourse. However, each language expresses action verbs in its own inherently unique manner by categorization. One verb can refer to several interpretations of actions and one action can be expressed by more than one verb. The inter-language and intra-language variations create ambiguity for the translation of languages from the source language to target language with respect to action verbs. IMAGACT is a corpus-based ontological platform of action verbs translated from prototypic animated images explained in English and Italian as meta-languages. In this paper, we are presenting the issues and challenges in translating action verbs of Indian languages as target and English as source language by observing the animated images. Among the ten Indian languages which have been annotated so far on the platform are Sanskrit, Hindi, Urdu, Odia (Oriya), Bengali, Manipuri, Tamil, Assamese, Magahi and Marathi. Out of them, Manipuri belongs to the Sino-Tibetan, Tamil comes off the Dravidian and the rest owe their genesis to the Indo-Aryan language family. One of the issues is that the one-word morphological English verbs are translated into most of the Indian languages as verbs having more than one-word form; for instance as in the case of conjunct, compound, serial verbs and so on. We are further presenting a cross-lingual comparison of action verbs among Indian languages. In addition, we are also dealing with the issues in disambiguating animated images by the L1 native speakers using competence-based judgements and the theoretical and machine translation implications they bear.","2016-12","2025-09-10 13:17:24","2025-09-10 13:17:24","","64–73","","","","","","","","","","","The COLING 2016 Organizing Committee","Osaka, Japan","","","","","","","","","","","","","","Wu, Dekai; Bhattacharyya, Pushpak","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"J5I4L3HI","conferencePaper","2017","Bellandi, Andrea; Giovannetti, Emiliano; Piccini, Silvia; Weingart, Anja","Developing LexO: a Collaborative Editor of Multilingual Lexica and Termino-Ontological Resources in the Humanities","Proceedings of Language, Ontology, Terminology and Knowledge Structures Workshop (LOTKS 2017)","","","","https://aclanthology.org/W17-7010/","","2017-09","2025-09-10 13:17:24","2025-09-10 13:17:24","","","","","","","","","","","","","Association for Computational Linguistics","Montpellier, France","","","","","","","","","","","","","","Frontini, Francesca; Grčić Simeunović, Larisa; Vintar, Špela; Khan, Anas Fahad; Parvisi, Artemis","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"M9XZRE4M","conferencePaper","2018","Liang, Chen; Yang, Xiao; Dave, Neisarg; Wham, Drew; Pursel, Bart; Giles, C. Lee","Distractor Generation for Multiple Choice Questions Using Learning to Rank","Proceedings of the Thirteenth Workshop on Innovative Use of NLP for Building Educational Applications","","","10.18653/v1/W18-0533","https://aclanthology.org/W18-0533/","We investigate how machine learning models, specifically ranking models, can be used to select useful distractors for multiple choice questions. Our proposed models can learn to select distractors that resemble those in actual exam questions, which is different from most existing unsupervised ontology-based and similarity-based methods. We empirically study feature-based and neural net (NN) based ranking models with experiments on the recently released SciQ dataset and our MCQL dataset. Experimental results show that feature-based ensemble learning methods (random forest and LambdaMART) outperform both the NN-based method and unsupervised baselines. These two datasets can also be used as benchmarks for distractor generation.","2018-06","2025-09-10 13:17:24","2025-09-10 13:17:24","","284–290","","","","","","","","","","","Association for Computational Linguistics","New Orleans, Louisiana","","","","","","","","","","","","","","Tetreault, Joel; Burstein, Jill; Kochmar, Ekaterina; Leacock, Claudia; Yannakoudakis, Helen","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"HWILGFDP","conferencePaper","2018","Wang, Lucy Lu; Bhagavatula, Chandra; Neumann, Mark; Lo, Kyle; Wilhelm, Chris; Ammar, Waleed","Ontology alignment in the biomedical domain using entity definitions and context","Proceedings of the BioNLP 2018 workshop","","","10.18653/v1/W18-2306","https://aclanthology.org/W18-2306/","Ontology alignment is the task of identifying semantically equivalent entities from two given ontologies. Different ontologies have different representations of the same entity, resulting in a need to de-duplicate entities when merging ontologies. We propose a method for enriching entities in an ontology with external definition and context information, and use this additional information for ontology alignment. We develop a neural architecture capable of encoding the additional information when available, and show that the addition of external data results in an F1-score of 0.69 on the Ontology Alignment Evaluation Initiative (OAEI) largebio SNOMED-NCI subtask, comparable with the entity-level matchers in a SOTA system.","2018-07","2025-09-10 13:17:24","2025-09-10 13:17:24","","47–55","","","","","","","","","","","Association for Computational Linguistics","Melbourne, Australia","","","","","","","","","","","","","","Demner-Fushman, Dina; Cohen, Kevin Bretonnel; Ananiadou, Sophia; Tsujii, Junichi","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"GKBT8947","conferencePaper","2018","Pustejovsky, James; Krishnaswamy, Nikhil","Every Object Tells a Story","Proceedings of the Workshop Events and Stories in the News 2018","","","","https://aclanthology.org/W18-4301/","Most work within the computational event modeling community has tended to focus on the interpretation and ordering of events that are associated with verbs and event nominals in linguistic expressions. What is often overlooked in the construction of a global interpretation of a narrative is the role contributed by the objects participating in these structures, and the latent events and activities conventionally associated with them. Recently, the analysis of visual images has also enriched the scope of how events can be identified, by anchoring both linguistic expressions and ontological labels to segments, subregions, and properties of images. By semantically grounding event descriptions in their visualization, the importance of object-based attributes becomes more apparent. In this position paper, we look at the narrative structure of objects: that is, how objects reference events through their intrinsic attributes, such as affordances, purposes, and functions. We argue that, not only do objects encode conventionalized events, but that when they are composed within specific habitats, the ensemble can be viewed as modeling coherent event sequences, thereby enriching the global interpretation of the evolving narrative being constructed.","2018-08","2025-09-10 13:17:24","2025-09-10 13:17:24","","1–6","","","","","","","","","","","Association for Computational Linguistics","Santa Fe, New Mexico, U.S.A","","","","","","","","","","","","","","Caselli, Tommaso; Miller, Ben; van Erp, Marieke; Vossen, Piek; Palmer, Martha; Hovy, Eduard; Mitamura, Teruko; Caswell, David; Brown, Susan W.; Bonial, Claire","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"5VUEYLFX","conferencePaper","2018","Sharma, Sanjana; Agrawal, Saksham; Shrivastava, Manish","Degree based Classification of Harmful Speech using Twitter Data","Proceedings of the First Workshop on Trolling, Aggression and Cyberbullying (TRAC-2018)","","","","https://aclanthology.org/W18-4413/","Harmful speech has various forms and it has been plaguing the social media in different ways. If we need to crackdown different degrees of hate speech and abusive behavior amongst it, the classification needs to be based on complex ramifications which needs to be defined and hold accountable for, other than racist, sexist or against some particular group and community. This paper primarily describes how we created an ontological classification of harmful speech based on degree of hateful intent and used it to annotate twitter data accordingly. The key contribution of this paper is the new dataset of tweets we created based on ontological classes and degrees of harmful speech found in the text. We also propose supervised classification system for recognizing these respective harmful speech classes in the texts hence. This serves as a preliminary work to lay down foundation on defining different classes of harmful speech and subsequent work will be done in making it's automatic detection more robust and efficient.","2018-08","2025-09-10 13:17:24","2025-09-10 13:17:24","","106–112","","","","","","","","","","","Association for Computational Linguistics","Santa Fe, New Mexico, USA","","","","","","","","","","","","","","Kumar, Ritesh; Ojha, Atul Kr.; Zampieri, Marcos; Malmasi, Shervin","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"6RNZ8VLB","conferencePaper","2018","Naresh Kumar, Ashwin; Kesavamoorthy, Harini; Das, Madhura; Kalwad, Pramati; Chandu, Khyathi; Mitamura, Teruko; Nyberg, Eric","Ontology-Based Retrieval & Neural Approaches for BioASQ Ideal Answer Generation","Proceedings of the 6th BioASQ Workshop A challenge on large-scale biomedical semantic indexing and question answering","","","10.18653/v1/W18-5310","https://aclanthology.org/W18-5310/","The ever-increasing magnitude of biomedical information sources makes it difficult and time-consuming for a human researcher to find the most relevant documents and pinpointed answers for a specific question or topic when using only a traditional search engine. Biomedical Question Answering systems automatically identify the most relevant documents and pinpointed answers, given an information need expressed as a natural language question. Generating a non-redundant, human-readable summary that satisfies the information need of a given biomedical question is the focus of the Ideal Answer Generation task, part of the BioASQ challenge. This paper presents a system for ideal answer generation (using ontology-based retrieval and a neural learning-to-rank approach, combined with extractive and abstractive summarization techniques) which achieved the highest ROUGE score of 0.659 on the BioASQ 5b batch 2 test.","2018-11","2025-09-10 13:17:24","2025-09-10 13:17:24","","79–89","","","","","","","","","","","Association for Computational Linguistics","Brussels, Belgium","","","","","","","","","","","","","","Kakadiaris, Ioannis A.; Paliouras, George; Krithara, Anastasia","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VKUHQVPL","conferencePaper","2018","Rojas-Barahona, Lina M.; Tseng, Bo-Hsiang; Dai, Yinpei; Mansfield, Clare; Ramadan, Osman; Ultes, Stefan; Crawford, Michael; Gašić, Milica","Deep learning for language understanding of mental health concepts derived from Cognitive Behavioural Therapy","Proceedings of the Ninth International Workshop on Health Text Mining and Information Analysis","","","10.18653/v1/W18-5606","https://aclanthology.org/W18-5606/","In recent years, we have seen deep learning and distributed representations of words and sentences make impact on a number of natural language processing tasks, such as similarity, entailment and sentiment analysis. Here we introduce a new task: understanding of mental health concepts derived from Cognitive Behavioural Therapy (CBT). We define a mental health ontology based on the CBT principles, annotate a large corpus where this phenomena is exhibited and perform understanding using deep learning and distributed representations. Our results show that the performance of deep learning models combined with word embeddings or sentence embeddings significantly outperform non-deep-learning models in this difficult task. This understanding module will be an essential component of a statistical dialogue system delivering therapy.","2018-10","2025-09-10 13:17:24","2025-09-10 13:17:24","","44–54","","","","","","","","","","","Association for Computational Linguistics","Brussels, Belgium","","","","","","","","","","","","","","Lavelli, Alberto; Minard, Anne-Lyse; Rinaldi, Fabio","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"XYGR2BLL","conferencePaper","2018","Balachandran, Vidhisha; Rajagopal, Dheeraj; Kanjirathinkal, Rose Catherine; Cohen, William","Learning to Define Terms in the Software Domain","Proceedings of the 2018 EMNLP Workshop W-NUT: The 4th Workshop on Noisy User-generated Text","","","10.18653/v1/W18-6122","https://aclanthology.org/W18-6122/","One way to test a person's knowledge of a domain is to ask them to define domain-specific terms. Here, we investigate the task of automatically generating definitions of technical terms by reading text from the technical domain. Specifically, we learn definitions of software entities from a large corpus built from the user forum Stack Overflow. To model definitions, we train a language model and incorporate additional domain-specific information like word co-occurrence, and ontological category information. Our approach improves previous baselines by 2 BLEU points for the definition generation task. Our experiments also show the additional challenges associated with the task and the short-comings of language-model based architectures for definition generation.","2018-11","2025-09-10 13:17:24","2025-09-10 13:17:24","","164–172","","","","","","","","","","","Association for Computational Linguistics","Brussels, Belgium","","","","","","","","","","","","","","Xu, Wei; Ritter, Alan; Baldwin, Tim; Rahimi, Afshin","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"WE2SNS7J","conferencePaper","2018","Iter, Dan; Halevy, Alon; Tan, Wang-Chiew","FrameIt: Ontology Discovery for Noisy User-Generated Text","Proceedings of the 2018 EMNLP Workshop W-NUT: The 4th Workshop on Noisy User-generated Text","","","10.18653/v1/W18-6123","https://aclanthology.org/W18-6123/","A common need of NLP applications is to extract structured data from text corpora in order to perform analytics or trigger an appropriate action. The ontology defining the structure is typically application dependent and in many cases it is not known a priori. We describe the FrameIt System that provides a workflow for (1) quickly discovering an ontology to model a text corpus and (2) learning an SRL model that extracts the instances of the ontology from sentences in the corpus. FrameIt exploits data that is obtained in the ontology discovery phase as weak supervision data to bootstrap the SRL model and then enables the user to refine the model with active learning. We present empirical results and qualitative analysis of the performance of FrameIt on three corpora of noisy user-generated text.","2018-11","2025-09-10 13:17:24","2025-09-10 13:17:24","","173–183","","","","","","","","","","","Association for Computational Linguistics","Brussels, Belgium","","","","","","","","","","","","","","Xu, Wei; Ritter, Alan; Baldwin, Tim; Rahimi, Afshin","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"2RT3STPS","conferencePaper","2018","Shvets, Alexander; Mille, Simon; Wanner, Leo","Sentence Packaging in Text Generation from Semantic Graphs as a Community Detection Problem","Proceedings of the 11th International Conference on Natural Language Generation","","","10.18653/v1/W18-6542","https://aclanthology.org/W18-6542/","An increasing amount of research tackles the challenge of text generation from abstract ontological or semantic structures, which are in their very nature potentially large connected graphs. These graphs must be “packaged” into sentence-wise subgraphs. We interpret the problem of sentence packaging as a community detection problem with post optimization. Experiments on the texts of the VerbNet/FrameNet structure annotated-Penn Treebank, which have been converted into graphs by a coreference merge using Stanford CoreNLP, show a high F1-score of 0.738.","2018-11","2025-09-10 13:17:24","2025-09-10 13:17:24","","350–359","","","","","","","","","","","Association for Computational Linguistics","Tilburg University, The Netherlands","","","","","","","","","","","","","","Krahmer, Emiel; Gatt, Albert; Goudbeek, Martijn","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FFR3YEGU","conferencePaper","2018","Funke, Isabel; Helaoui, Rim; Härmä, Aki","Interactive health insight miner: an adaptive, semantic-based approach","Proceedings of the 11th International Conference on Natural Language Generation","","","10.18653/v1/W18-6559","https://aclanthology.org/W18-6559/","E-health applications aim to support the user in adopting healthy habits. An important feature is to provide insights into the user's lifestyle. To actively engage the user in the insight mining process, we propose an ontology-based framework with a Controlled Natural Language interface, which enables the user to ask for specific insights and to customize personal information.","2018-11","2025-09-10 13:17:24","2025-09-10 13:17:24","","478–479","","","","","","","","","","","Association for Computational Linguistics","Tilburg University, The Netherlands","","","","","","","","","","","","","","Krahmer, Emiel; Gatt, Albert; Goudbeek, Martijn","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FCCGIMC5","conferencePaper","2018","Pomarlan, Mihai; Porzel, Robert; Bateman, John; Malaka, Rainer","From sensors to sense: Integrated heterogeneous ontologies for Natural Language Generation","Proceedings of the Workshop on NLG for Human–Robot Interaction","","","10.18653/v1/W18-6904","https://aclanthology.org/W18-6904/","We propose the combination of a robotics ontology (KnowRob) with a linguistically motivated one (GUM) under the upper ontology DUL. We use the DUL Event, Situation, Description pattern to formalize reasoning techniques to convert between a robot's beliefstate and its linguistic utterances. We plan to employ these techniques to equip robots with a reason-aloud ability, through which they can explain their actions as they perform them, in natural language, at a level of granularity appropriate to the user, their query and the context at hand.","2018-11","2025-09-10 13:17:24","2025-09-10 13:17:24","","17–21","","","","","","","","","","","Association for Computational Linguistics","Tilburg, The Netherlands","","","","","","","","","","","","","","Foster, Mary Ellen; Buschmeier, Hendrik; Gkatzia, Dimitra","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"88XNQQHT","conferencePaper","2019","Lawley, Lane; Kim, Gene Louis; Schubert, Lenhart","Towards Natural Language Story Understanding with Rich Logical Schemas","Proceedings of the Sixth Workshop on Natural Language and Computer Science","","","10.18653/v1/W19-1102","https://aclanthology.org/W19-1102/","Generating “commonsense” knowledge for intelligent understanding and reasoning is a difficult, long-standing problem, whose scale challenges the capacity of any approach driven primarily by human input. Furthermore, approaches based on mining statistically repetitive patterns fail to produce the rich representations humans acquire, and fall far short of human efficiency in inducing knowledge from text. The idea of our approach to this problem is to provide a learning system with a “head start” consisting of a semantic parser, some basic ontological knowledge, and most importantly, a small set of very general schemas about the kinds of patterns of events (often purposive, causal, or socially conventional) that even a one- or two-year-old could reasonably be presumed to possess. We match these initial schemas to simple children's stories, obtaining concrete instances, and combining and abstracting these into new candidate schemas. Both the initial and generated schemas are specified using a rich, expressive logical form. While modern approaches to schema reasoning often only use slot-and-filler structures, this logical form allows us to specify complex relations and constraints over the slots. Though formal, the representations are language-like, and as such readily relatable to NL text. The agents, objects, and other roles in the schemas are represented by typed variables, and the event variables can be related through partial temporal ordering and causal relations. To match natural language stories with existing schemas, we first parse the stories into an underspecified variant of the logical form used by the schemas, which is suitable for most concrete stories. We include a walkthrough of matching a children's story to these schemas and generating inferences from these matches.","2019-05","2025-09-10 13:17:24","2025-09-10 13:17:24","","11–22","","","","","","","","","","","Association for Computational Linguistics","Gothenburg, Sweden","","","","","","","","","","","","","","Cooper, Robin; de Paiva, Valeria; Moss, Lawrence S.","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"29EIRAN3","conferencePaper","2019","Sarthou, Guillaume; Clodic, Aurélie; Alami, Rachid","Semantic Spatial Representation: a unique representation of an environment based on an ontology for robotic applications","Proceedings of the Combined Workshop on Spatial Language Understanding (SpLU) and Grounded Communication for Robotics (RoboNLP)","","","10.18653/v1/W19-1606","https://aclanthology.org/W19-1606/","It is important, for human-robot interaction, to endow the robot with the knowledge necessary to understand human needs and to be able to respond to them. We present a formalized and unified representation for indoor environments using an ontology devised for a route description task in which a robot must provide explanations to a person. We show that this representation can be used to choose a route to explain to a human as well as to verbalize it using a route perspective. Based on ontology, this representation has a strong possibility of evolution to adapt to many other applications. With it, we get the semantics of the environment elements while keeping a description of the known connectivity of the environment. This representation and the illustration algorithms, to find and verbalize a route, have been tested in two environments of different scales.","2019-06","2025-09-10 13:17:24","2025-09-10 13:17:24","","50–60","","","","","","","","","","","Association for Computational Linguistics","Minneapolis, Minnesota","","","","","","","","","","","","","","Bhatia, Archna; Bisk, Yonatan; Kordjamshidi, Parisa; Thomason, Jesse","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"UEERWPFQ","conferencePaper","2019","Tao, Yifeng; Godefroy, Bruno; Genthial, Guillaume; Potts, Christopher","Effective Feature Representation for Clinical Text Concept Extraction","Proceedings of the 2nd Clinical Natural Language Processing Workshop","","","10.18653/v1/W19-1901","https://aclanthology.org/W19-1901/","Crucial information about the practice of healthcare is recorded only in free-form text, which creates an enormous opportunity for high-impact NLP. However, annotated healthcare datasets tend to be small and expensive to obtain, which raises the question of how to make maximally efficient uses of the available data. To this end, we develop an LSTM-CRF model for combining unsupervised word representations and hand-built feature representations derived from publicly available healthcare ontologies. We show that this combined model yields superior performance on five datasets of diverse kinds of healthcare text (clinical, social, scientific, commercial). Each involves the labeling of complex, multi-word spans that pick out different healthcare concepts. We also introduce a new labeled dataset for identifying the treatment relations between drugs and diseases.","2019-06","2025-09-10 13:17:24","2025-09-10 13:17:24","","1–14","","","","","","","","","","","Association for Computational Linguistics","Minneapolis, Minnesota, USA","","","","","","","","","","","","","","Rumshisky, Anna; Roberts, Kirk; Bethard, Steven; Naumann, Tristan","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"7LY6XBJY","conferencePaper","2019","Mondal, Ishani; Purkayastha, Sukannya; Sarkar, Sudeshna; Goyal, Pawan; Pillai, Jitesh; Bhattacharyya, Amitava; Gattu, Mahanandeeshwar","Medical Entity Linking using Triplet Network","Proceedings of the 2nd Clinical Natural Language Processing Workshop","","","10.18653/v1/W19-1912","https://aclanthology.org/W19-1912/","Entity linking (or Normalization) is an essential task in text mining that maps the entity mentions in the medical text to standard entities in a given Knowledge Base (KB). This task is of great importance in the medical domain. It can also be used for merging different medical and clinical ontologies. In this paper, we center around the problem of disease linking or normalization. This task is executed in two phases: candidate generation and candidate scoring. In this paper, we present an approach to rank the candidate Knowledge Base entries based on their similarity with disease mention. We make use of the Triplet Network for candidate ranking. While the existing methods have used carefully generated sieves and external resources for candidate generation, we introduce a robust and portable candidate generation scheme that does not make use of the hand-crafted rules. Experimental results on the standard benchmark NCBI disease dataset demonstrate that our system outperforms the prior methods by a significant margin.","2019-06","2025-09-10 13:17:24","2025-09-10 13:17:24","","95–100","","","","","","","","","","","Association for Computational Linguistics","Minneapolis, Minnesota, USA","","","","","","","","","","","","","","Rumshisky, Anna; Roberts, Kirk; Bethard, Steven; Naumann, Tristan","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"8VB8MUKA","conferencePaper","2019","Jahan, Labiba; Finlayson, Mark","Character Identification Refined: A Proposal","Proceedings of the First Workshop on Narrative Understanding","","","10.18653/v1/W19-2402","https://aclanthology.org/W19-2402/","Characters are a key element of narrative and so character identification plays an important role in automatic narrative understanding. Unfortunately, most prior work that incorporates character identification is not built upon a clear, theoretically grounded concept of character. They either take character identification for granted (e.g., using simple heuristics on referring expressions), or rely on simplified definitions that do not capture important distinctions between characters and other referents in the story. Prior approaches have also been rather complicated, relying, for example, on predefined case bases or ontologies. In this paper we propose a narratologically grounded definition of character for discussion at the workshop, and also demonstrate a preliminary yet straightforward supervised machine learning model with a small set of features that performs well on two corpora. The most important of the two corpora is a set of 46 Russian folktales, on which the model achieves an F1 of 0.81. Error analysis suggests that features relevant to the plot will be necessary for further improvements in performance.","2019-06","2025-09-10 13:17:24","2025-09-10 13:17:24","","12–18","","","","","","","","","","","Association for Computational Linguistics","Minneapolis, Minnesota","","","","","","","","","","","","","","Bamman, David; Chaturvedi, Snigdha; Clark, Elizabeth; Fiterau, Madalina; Iyyer, Mohit","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"VRHHHEUM","conferencePaper","2019","Manjavacas, Enrique; Long, Brian; Kestemont, Mike","On the Feasibility of Automated Detection of Allusive Text Reuse","Proceedings of the 3rd Joint SIGHUM Workshop on Computational Linguistics for Cultural Heritage, Social Sciences, Humanities and Literature","","","10.18653/v1/W19-2514","https://aclanthology.org/W19-2514/","The detection of allusive text reuse is particularly challenging due to the sparse evidence on which allusive references rely — commonly based on none or very few shared words. Arguably, lexical semantics can be resorted to since uncovering semantic relations between words has the potential to increase the support underlying the allusion and alleviate the lexical sparsity. A further obstacle is the lack of evaluation benchmark corpora, largely due to the highly interpretative character of the annotation process. In the present paper, we aim to elucidate the feasibility of automated allusion detection. We approach the matter from an Information Retrieval perspective in which referencing texts act as queries and referenced texts as relevant documents to be retrieved, and estimate the difficulty of benchmark corpus compilation by a novel inter-annotator agreement study on query segmentation. Furthermore, we investigate to what extent the integration of lexical semantic information derived from distributional models and ontologies can aid retrieving cases of allusive reuse. The results show that (i) despite low agreement scores, using manual queries considerably improves retrieval performance with respect to a windowing approach, and that (ii) retrieval performance can be moderately boosted with distributional semantics.","2019-06","2025-09-10 13:17:24","2025-09-10 13:17:24","","104–114","","","","","","","","","","","Association for Computational Linguistics","Minneapolis, USA","","","","","","","","","","","","","","Alex, Beatrice; Degaetano-Ortlieb, Stefania; Kazantseva, Anna; Reiter, Nils; Szpakowicz, Stan","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"RWVDPEA7","conferencePaper","2019","Prabhumoye, Shrimai; Mayfield, Elijah; Black, Alan W","Principled Frameworks for Evaluating Ethics in NLP Systems","Proceedings of the 2019 Workshop on Widening NLP","","","","https://aclanthology.org/W19-3637/","We critique recent work on ethics in natural language processing. Those discussions have focused on data collection, experimental design, and interventions in modeling. But we argue that we ought to first understand the frameworks of ethics that are being used to evaluate the fairness and justice of algorithmic systems. Here, we begin that discussion by outlining deontological and consequentialist ethics, and make predictions on the research agenda prioritized by each.","2019-08","2025-09-10 13:17:24","2025-09-10 13:17:24","","118–121","","","","","","","","","","","Association for Computational Linguistics","Florence, Italy","","","","","","","","","","","","","","Axelrod, Amittai; Yang, Diyi; Cunha, Rossana; Shaikh, Samira; Waseem, Zeerak","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"J4IMHVEF","conferencePaper","2019","López, Federico; Heinzerling, Benjamin; Strube, Michael","Fine-Grained Entity Typing in Hyperbolic Space","Proceedings of the 4th Workshop on Representation Learning for NLP (RepL4NLP-2019)","","","10.18653/v1/W19-4319","https://aclanthology.org/W19-4319/","How can we represent hierarchical information present in large type inventories for entity typing? We study the suitability of hyperbolic embeddings to capture hierarchical relations between mentions in context and their target types in a shared vector space. We evaluate on two datasets and propose two different techniques to extract hierarchical information from the type inventory: from an expert-generated ontology and by automatically mining the dataset. The hyperbolic model shows improvements in some but not all cases over its Euclidean counterpart. Our analysis suggests that the adequacy of this geometry depends on the granularity of the type inventory and the representation of its distribution.","2019-08","2025-09-10 13:17:24","2025-09-10 13:17:24","","169–180","","","","","","","","","","","Association for Computational Linguistics","Florence, Italy","","","","","","","","","","","","","","Augenstein, Isabelle; Gella, Spandana; Ruder, Sebastian; Kann, Katharina; Can, Burcu; Welbl, Johannes; Conneau, Alexis; Ren, Xiang; Rei, Marek","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"MSFNAZI8","conferencePaper","2019","Joshi, Aditya; Karimi, Sarvnaz; Sparks, Ross; Paris, Cecile; MacIntyre, C Raina","A Comparison of Word-based and Context-based Representations for Classification Problems in Health Informatics","Proceedings of the 18th BioNLP Workshop and Shared Task","","","10.18653/v1/W19-5015","https://aclanthology.org/W19-5015/","Distributed representations of text can be used as features when training a statistical classifier. These representations may be created as a composition of word vectors or as context-based sentence vectors. We compare the two kinds of representations (word versus context) for three classification problems: influenza infection classification, drug usage classification and personal health mention classification. For statistical classifiers trained for each of these problems, context-based representations based on ELMo, Universal Sentence Encoder, Neural-Net Language Model and FLAIR are better than Word2Vec, GloVe and the two adapted using the MESH ontology. There is an improvement of 2-4% in the accuracy when these context-based representations are used instead of word-based representations.","2019-08","2025-09-10 13:17:24","2025-09-10 13:17:24","","135–141","","","","","","","","","","","Association for Computational Linguistics","Florence, Italy","","","","","","","","","","","","","","Demner-Fushman, Dina; Cohen, Kevin Bretonnel; Ananiadou, Sophia; Tsujii, Junichi","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"FM6DPJYY","conferencePaper","2019","Wiegreffe, Sarah; Choi, Edward; Yan, Sherry; Sun, Jimeng; Eisenstein, Jacob","Clinical Concept Extraction for Document-Level Coding","Proceedings of the 18th BioNLP Workshop and Shared Task","","","10.18653/v1/W19-5028","https://aclanthology.org/W19-5028/","The text of clinical notes can be a valuable source of patient information and clinical assessments. Historically, the primary approach for exploiting clinical notes has been information extraction: linking spans of text to concepts in a detailed domain ontology. However, recent work has demonstrated the potential of supervised machine learning to extract document-level codes directly from the raw text of clinical notes. We propose to bridge the gap between the two approaches with two novel syntheses: (1) treating extracted concepts as features, which are used to supplement or replace the text of the note; (2) treating extracted concepts as labels, which are used to learn a better representation of the text. Unfortunately, the resulting concepts do not yield performance gains on the document-level clinical coding task. We explore possible explanations and future research directions.","2019-08","2025-09-10 13:17:24","2025-09-10 13:17:24","","261–272","","","","","","","","","","","Association for Computational Linguistics","Florence, Italy","","","","","","","","","","","","","","Demner-Fushman, Dina; Cohen, Kevin Bretonnel; Ananiadou, Sophia; Tsujii, Junichi","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"F8T6Q4H9","conferencePaper","2019","Gao, Shuyang; Sethi, Abhishek; Agarwal, Sanchit; Chung, Tagyoung; Hakkani-Tur, Dilek","Dialog State Tracking: A Neural Reading Comprehension Approach","Proceedings of the 20th Annual SIGdial Meeting on Discourse and Dialogue","","","10.18653/v1/W19-5932","https://aclanthology.org/W19-5932/","Dialog state tracking is used to estimate the current belief state of a dialog given all the preceding conversation. Machine reading comprehension, on the other hand, focuses on building systems that read passages of text and answer questions that require some understanding of passages. We formulate dialog state tracking as a reading comprehension task to answer the question what is the state of the current dialog? after reading conversational context. In contrast to traditional state tracking methods where the dialog state is often predicted as a distribution over a closed set of all the possible slot values within an ontology, our method uses a simple attention-based neural network to point to the slot values within the conversation. Experiments on MultiWOZ-2.0 cross-domain dialog dataset show that our simple system can obtain similar accuracies compared to the previous more complex methods. By exploiting recent advances in contextual word embeddings, adding a model that explicitly tracks whether a slot value should be carried over to the next turn, and combining our method with a traditional joint state tracking method that relies on closed set vocabulary, we can obtain a joint-goal accuracy of 47.33% on the standard test split, exceeding current state-of-the-art by 11.75%**.","2019-09","2025-09-10 13:17:24","2025-09-10 13:17:24","","264–273","","","","","","","","","","","Association for Computational Linguistics","Stockholm, Sweden","","","","","","","","","","","","","","Nakamura, Satoshi; Gasic, Milica; Zukerman, Ingrid; Skantze, Gabriel; Nakano, Mikio; Papangelis, Alexandros; Ultes, Stefan; Yoshino, Koichiro","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
"DQFUIW88","conferencePaper","2019","Cervone, Alessandra; Khatri, Chandra; Goel, Rahul; Hedayatnia, Behnam; Venkatesh, Anu; Hakkani-Tur, Dilek; Gabriel, Raefer","Natural Language Generation at Scale: A Case Study for Open Domain Question Answering","Proceedings of the 12th International Conference on Natural Language Generation","","","10.18653/v1/W19-8657","https://aclanthology.org/W19-8657/","Current approaches to Natural Language Generation (NLG) for dialog mainly focus on domain-specific, task-oriented applications (e.g. restaurant booking) using limited ontologies (up to 20 slot types), usually without considering the previous conversation context. Furthermore, these approaches require large amounts of data for each domain, and do not benefit from examples that may be available for other domains. This work explores the feasibility of applying statistical NLG to scenarios requiring larger ontologies, such as multi-domain dialog applications or open-domain question answering (QA) based on knowledge graphs. We model NLG through an Encoder-Decoder framework using a large dataset of interactions between real-world users and a conversational agent for open-domain QA. First, we investigate the impact of increasing the number of slot types on the generation quality and experiment with different partitions of the QA data with progressively larger ontologies (up to 369 slot types). Second, we perform multi-task learning experiments between open-domain QA and task-oriented dialog, and benchmark our model on a popular NLG dataset. Moreover, we experiment with using the conversational context as an additional input to improve response generation quality. Our experiments show the feasibility of learning statistical NLG models for open-domain QA with larger ontologies.","2019-10","2025-09-10 13:17:24","2025-09-10 13:17:24","","453–462","","","","","","","","","","","Association for Computational Linguistics","Tokyo, Japan","","","","","","","","","","","","","","van Deemter, Kees; Lin, Chenghua; Takamura, Hiroya","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","","",""
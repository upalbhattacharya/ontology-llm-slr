@article{JYOTISH2022108635,
title = {A state-of-the-art review on performance measurement petri net models for safety critical systems of NPP},
journal = {Annals of Nuclear Energy},
volume = {165},
pages = {108635},
year = {2022},
issn = {0306-4549},
doi = {https://doi.org/10.1016/j.anucene.2021.108635},
url = {https://www.sciencedirect.com/science/article/pii/S0306454921005119},
author = {Nand Kumar Jyotish and Lalit Kumar Singh and Chiranjeev Kumar},
keywords = {Performance Evaluation, Petri nets, Model performance evaluation, Safety Critical System (SCS), Nuclear Power Plant (NPP)},
abstract = {Considering the safety significance, safety critical systems (SCS) of nuclear power plant (NPP) needs to be validated for their performance. Authors are putting their continuous efforts to device new models for performance analysis of the dynamical systems. The results of any model’s performance analysis are critical because they help in identifying any potential bottlenecks by predicting the performance parameters of a system when direct measurement is not possible. A model’s efficiency can be assessed using specific performance parameters or metrics. Depending on the type of system to be built, these metrics can include throughput, waiting time, response time, reliability, system availability, usage rate, resource consumption, and so on. Petri nets, as an analytical model, assist in the performance assessment of any device model. This survey presents various Petri nets-based models for their suitability analysis for use in SCS of NPP. We evaluate the model performance, their benefits, drawbacks, and performance measuring parameters. We consider the papers which are published during the years 2009–2020. These models’ performance can be used to build better systems–this survey paper aids in the identification of appropriate approaches and promising research areas for the future.}
}
@article{LI2021102144,
title = {A semantic-level component-based scheduling method for customized manufacturing},
journal = {Robotics and Computer-Integrated Manufacturing},
volume = {71},
pages = {102144},
year = {2021},
issn = {0736-5845},
doi = {https://doi.org/10.1016/j.rcim.2021.102144},
url = {https://www.sciencedirect.com/science/article/pii/S0736584521000296},
author = {Di Li and Hao Tang},
keywords = {CPPS, Ontology, Markov decision process, Customized manufacturing},
abstract = {To meet the increasingly complex needs of customers, scheduling faces challenges of the high uncertainty of product arrival in customized manufacturing (CM). This paper proposes a semantic-level component-based scheduling method to solve the uncertainty via the integration of the information model and the computation model. In our proposal, we first construct a component-based framework to illustrate the composition and execution mechanism of a component. Then we present a semantic-enriched information model to obtain the state of the shop floor through automatic semantic reasoning. Additionally, we build a computation model to abstract the stochastic scheduling process of CM. Finally, we design an iteration algorithm to solve the computation model through the interaction between the information model and computation model. In experiments, we show that for random arrivals of products, our proposal can ensure the timeliness of the learning and decision-making, and the task assignment performance is the best compared with the other two methods.}
}
@article{DOYLE2025101835,
title = {Creative art-based pedagogies with autistic students: A systematic review on stakeholders' perspectives on its delivery and implementation in secondary mainstream schools},
journal = {Thinking Skills and Creativity},
volume = {57},
pages = {101835},
year = {2025},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2025.101835},
url = {https://www.sciencedirect.com/science/article/pii/S1871187125000847},
author = {Kayleigh Doyle and Lisa E. Kim},
keywords = {Creative art, Education, Pedagogy, Autism, Systematic review, Secondary school},
abstract = {More than 70 % of autistic young people are educated in mainstream schools and some, similarly to their non-autistic peers, experience challenges in mainstream settings. Research suggests that the creative arts offer unique prospects in the education of autistic students. However, such research primarily explores the creative arts in a therapeutic or interventional context; little research has considered creative arts’ use as a pedagogical tool in mainstream secondary school classrooms with autistic students. The current narrative systematic review aims to synthesise empirical evidence concerning: (a) how creative arts-based pedagogy (CABP) is theorised, (b) creative arts-based pedagogies implementation and delivery with autistic secondary school students and (c) research gaps in the field. Identified through thematic analysis, findings indicate that creative arts-based pedagogy was perceived with greater positivity than negativity, yet a greater number of disabling factors were identified than enabling factors. The only paper to explicitly discuss a gap in research within the extracted data was Kehl (2021). However, in the concluding sections not under analysis in line with this study's data extraction approach, further gaps in research were identified. Further research is required to establish enabling factors that can help increase the effectiveness of CABP delivery and implementation in secondary educational settings with autistic students.}
}
@article{XU2021196,
title = {Digital twin-based industrial cloud robotics: Framework, control approach and implementation},
journal = {Journal of Manufacturing Systems},
volume = {58},
pages = {196-209},
year = {2021},
note = {Digital Twin towards Smart Manufacturing and Industry 4.0},
issn = {0278-6125},
doi = {https://doi.org/10.1016/j.jmsy.2020.07.013},
url = {https://www.sciencedirect.com/science/article/pii/S0278612520301230},
author = {Wenjun Xu and Jia Cui and Lan Li and Bitao Yao and Sisi Tian and Zude Zhou},
keywords = {Industrial cloud robotics, Digital twin, Robotic control, Cloud service},
abstract = {Industrial cloud robotics (ICR) integrates cloud computing with industrial robots (IRs). The capabilities of industrial robots can be encapsulated as cloud services and used for ubiquitous manufacturing. Currently, the digital models for process simulation, path simulation, etc. are encapsulated as cloud services. The digital models in the cloud may not reflect the real state of the physical robotic manufacturing systems due to inaccurate or delayed condition update and therefore result in inaccurate simulation and robotic control. Digital twin can be used to realize fine sensing control of the physical manufacturing systems by a combination of high-fidelity digital model and sensory data. In this paper, we propose a framework of digital twin-based industrial cloud robotics (DTICR) for industrial robotic control and its key methodologies. The DTICR is divided into physical IR, digital IR, robotic control services, and digital twin data. First, the robotic control capabilities are encapsulated as Robot Control as-a-Service (RCaaS) based on manufacturing features and feature-level robotic capability model. Then the available RCaaSs are ranked and parsed. After manufacturing process simulation with digital IR models, RCaaSs are mapped to physical robots for robotic control. The digital IR models are connected to the physical robots and updated by sensory data. A case is implemented to demonstrate the workflow of DTICR. The results show that DTICR is capable to synchronize and merge digital IRs and physical IRs effectively. The bidirectional interaction between digital IRs and physical IRs enables fine sensing control of IRs. The proposed DTICR is also flexible and extensible by using ontology models.}
}
@article{PAL2020197,
title = {Semantic Approach to Data Integration for an Internet of Things Supporting Apparel Supply Chain Management},
journal = {Procedia Computer Science},
volume = {175},
pages = {197-204},
year = {2020},
note = {The 17th International Conference on Mobile Systems and Pervasive Computing (MobiSPC),The 15th International Conference on Future Networks and Communications (FNC),The 10th International Conference on Sustainable Energy Information Technology},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2020.07.030},
url = {https://www.sciencedirect.com/science/article/pii/S1877050920317105},
author = {Kamalendu Pal and Ansar-Ul-Haque Yasar},
keywords = {Apparel Business, Description Logics, Internet of Things, Semantic Web Service, Supply Chain Management},
abstract = {The rapid development of the Internet of Things (IoT) and the huge growth of valuable data produced by decentralising information processing along global apparel supply chain have led to a persuasive appeal for a semantic approach to integrating distributed data facilities in the field of self-determining collaborating logistics services. This paper describes a framework, Apparel Business Decentralised Data Integration (ABDDI), which exploits knowledge representation techniques and languages (e.g. Description Logics – DLs) to annotate relevant business activities, movements of products within the manufacturing network to provide value-added services. More specifically the paper discusses the DLs formalisms, which are used for knowledge representation in a decidable fragment of First Order Logic; and ALN (D) (Attributive Language with unqualified Number restrictions and concrete Domains) related issues. The paper presents an algorithm to demonstrate the DLs based entity concept similarity assessment to facilitate semantic web service. Finally, a business scenario is used to present some of the knowledge representation formalisms and concept similarity assessment in ABDDI.}
}
@article{MEIER2021448,
title = {Knowledge Graph for the Visualisation of CRM Objects in a Social Network of Business Objects (SoNBO): Development of the SoNBO Visualiser},
journal = {Procedia Computer Science},
volume = {181},
pages = {448-456},
year = {2021},
note = {CENTERIS 2020 - International Conference on ENTERprise Information Systems / ProjMAN 2020 - International Conference on Project MANagement / HCist 2020 - International Conference on Health and Social Care Information Systems and Technologies 2020, CENTERIS/ProjMAN/HCist 2020},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2021.01.190},
url = {https://www.sciencedirect.com/science/article/pii/S1877050921002325},
author = {Simon Meier and Berit Gebel-Sauer and Petra Schubert},
keywords = {Ontology, Business Object, Knowledge graph, SoNBO, Social Network of Business Objects},
abstract = {This paper investigates possibilities to visually support the collaborative design process of Enterprise Knowledge Graphs for Business Application Systems. Starting with a description of the concept of the Social Network of Business Objects (SoNBO), we show how the SoNBO Visualiser supports the visualisation of a company-specific ontology and the resulting knowledge graph. Our previous research showed that existing visualisation tools from the Semantic Web are unsuited for the human involvement that is required in the design of an ontology for a SoNBO. In order to address the lack of a tool, the SoNBO Visualiser was developed using a Design Science Research approach. This paper aims to provide a methodological as well as a technical contribution: The method provides support for the visualisation of the ontology (on two levels) and facilitates the involvement of domain experts (employees) without technical knowledge in the design process. The complementary technical solution connects heterogeneous source systems in a simple configuration process and allows to visualise the ontology and the resulting knowledge graph.}
}
@article{CAPUANO2022,
title = {A Semantic Framework Supporting Multilayer Networks Analysis for Rare Diseases},
journal = {International Journal on Semantic Web and Information Systems},
volume = {18},
number = {1},
year = {2022},
issn = {1552-6283},
doi = {https://doi.org/10.4018/IJSWIS.297141},
url = {https://www.sciencedirect.com/science/article/pii/S1552628322000102},
author = {Nicola Capuano and Pasquale Foggia and Luca Greco and Pierluigi Ritrovato},
keywords = {Biomedical Ontologies, Human Genome, Linked Data, Multilayer Network Analysis, Neuroen-Docrine Neoplasms, Rare Diseases, Semantic Information Integration},
abstract = {ABSTRACT
Understanding the role played by genetic variations in diseases, exploring genomic variants, and discovering disease-associated loci are among the most pressing challenges of genomic medicine. A huge and ever-increasing amount of information is available to researchers to address these challenges. Unfortunately, it is stored in fragmented ontologies and databases, which use heterogeneous formats and poorly integrated schemas. To overcome these limitations, the authors propose a linked data approach, based on the formalism of multilayer networks, able to integrate and harmonize biomedical information from multiple sources into a single dense network covering different aspects on Neuroendocrine Neoplasms (NENs). The proposed integration schema consists of three interconnected layers representing, respectively, information on the disease, on the affected genes, on the related biological processes and molecular functions. An easy-to-use client-server application was also developed to browse and search for information on the model supporting multilayer network analysis.}
}
@article{MAHIEU2019138,
title = {Semantics-based platform for context-aware and personalized robot interaction in the internet of robotic things},
journal = {Journal of Systems and Software},
volume = {149},
pages = {138-157},
year = {2019},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2018.11.022},
url = {https://www.sciencedirect.com/science/article/pii/S0164121218302553},
author = {Christof Mahieu and Femke Ongenae and Femke {De Backere} and Pieter Bonte and Filip {De Turck} and Pieter Simoens},
keywords = {Internet of things, Personalization, Semantics, Ontology, Context-aware systems, Social robots},
abstract = {Robots are moving from well-controlled lab environments to the real world, where an increasing number of environments has been transformed into smart sensorized IoT spaces. Users will expect these robots to adapt to their preferences and needs, and even more so for social robots that engage in personal interactions. In this paper, we present declarative ontological models and a middleware platform for building services that generate interaction tasks for social robots in smart IoT environments. The platform implements a modular, data-driven workflow that allows developers of interaction services to determine the appropriate time, content and style of human-robot interaction tasks by reasoning on semantically enriched IoT sensor data. The platform also abstracts the complexities of scheduling, planning and execution of these tasks, and can automatically adjust parameters to the personal profile and current context. We present motivational scenarios in three environments: a smart home, a smart office and a smart nursing home, detail the interfaces and executional paths in our platform and present a proof-of-concept implementation.}
}
@article{DING2022100681,
title = {An empirical study of representing adjectives over knowledge bases: Approach, lexicon and application},
journal = {Journal of Web Semantics},
volume = {72},
pages = {100681},
year = {2022},
issn = {1570-8268},
doi = {https://doi.org/10.1016/j.websem.2021.100681},
url = {https://www.sciencedirect.com/science/article/pii/S1570826821000548},
author = {Jiwei Ding and Wei Hu and Xin Yu and Yuzhong Qu},
keywords = {Adjective representation, Question answering, Knowledge base, SPARQL},
abstract = {Adjectives are common in natural language, and their usage and semantics have been studied broadly. In recent years, with the rapid growth of knowledge bases (KBs), many knowledge-based question answering (KBQA) systems are developed to answer users’ natural language questions over KBs. A fundamental task of such systems is to transform natural language questions into structural queries, e.g., SPARQL queries. Thus, such systems require knowledge about how natural language expressions are represented in KBs, including adjectives. In this paper, we specifically address the problem of representing adjectives over KBs. We propose a novel approach, called Adj2SP, to represent adjectives as SPARQL query patterns. Adj2SP contains a statistic-based approach and a neural network-based approach, both of them can effectively reduce the search space for adjective representations and overcome the lexical gap between input adjectives and their target representations. Two adjective representation datasets are built for evaluation, with adjectives used in QALD and Yahoo! Answers, as well as their representations over DBpedia. Experimental results show that Adj2SP can generate representations of high quality and significantly outperform several alternative approaches in F1-score. Furthermore, we publish Lark, a lexicon for adjective representations over KBs. Current KBQA systems show an improvement of over 24% in F1-score by integrating Adj2SP.}
}
@article{SESBOUE20221667,
title = {An Operational Architecture for Knowledge Graph-Based Systems},
journal = {Procedia Computer Science},
volume = {207},
pages = {1667-1676},
year = {2022},
note = {Knowledge-Based and Intelligent Information & Engineering Systems: Proceedings of the 26th International Conference KES2022},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2022.09.224},
url = {https://www.sciencedirect.com/science/article/pii/S1877050922011085},
author = {Matthias Sesboüé and Nicolas Delestre and Jean-Philippe Kotowicz and Ali Khudiyev and Cecilia Zanni-Merk},
keywords = {Knowledge Graph, Ontology, Knowledge-Based System, Semantic},
abstract = {Knowledge Graphs (KG) are gaining in popularity recently, notably since big tech giants announced they are using the technology. While the term is becoming popular, it is not new, and its ideas are even older. The research community has extensively studied knowledge Graphs in their various forms. Furthermore, the approach has been applied and proved valuable in many different applications. However, we found a lack of papers presenting the integration of KGs in a system regardless of the downstream application. We explore how KGs can fit in an overall information system independently from any specific use case, i.e., what we will consider knowledge consumption. We propose an architecture to understand better the KG roles within a system and how they can be integrated and implemented in a business context. We introduce each element of the latter architecture and discuss some candidate technology to implement them. Our work implements Knowledge Graph-Based Systems considering the constraints of a small to medium-sized enterprise.}
}
@article{HOU2025,
title = {Artificial Intelligence in Medicinal Herb Breeding},
journal = {Engineering},
year = {2025},
issn = {2095-8099},
doi = {https://doi.org/10.1016/j.eng.2025.08.021},
url = {https://www.sciencedirect.com/science/article/pii/S2095809925004886},
author = {Biyu Hou and Caiyan Liang and Xiao Sheng and YongGuo Liu and JianDong Ren and Qiang Ma and Tengjiao Wang and Lei Zhang},
keywords = {Medicinal plants, Precision breeding, Artificial intelligence, Multi-omics integration, Genotype–phenotype prediction},
abstract = {Medicinal plant-derived bioactive compounds serve as a crucial foundation for natural pharmaceutical development. Contemporary breeding methodologies can boost both the quality and yield of these medicinally valuable compounds, thereby advancing the development of the pharmaceutical sector. However, conventional breeding encounters substantial challenges when addressing the intricate genetic architectures and polygenic regulatory networks characteristic of medicinal species. These traditional modalities are especially ineffective in optimizing multiple pharmacologically relevant traits while maintaining robust environmental adaptability across diverse cultivation conditions concurrently. Advanced computational tools are emerging for biological research with parallel development of artificial intelligence (AI), which have also been explored for their applications in medicinal plant breeding. In the current comprehensive review, we carried out a systematic examination of the state-of-the-art AI applications across different aspects of the breeding pipeline, encompassing multi-omics data integration, synthetic biology, precision gene editing, trait optimization, and intelligent monitoring systems. Meanwhile, this review elucidated current obstacles of data integration, model generalization, and environmental adaptation when applying AI in medicinal plants, and proposed a concept of constructing a genotype–environment–management (G × E × M) interactive intelligent breeding platform. The integration of AI with biotechnology emphasizes data-driven precision, computational analysis, and potential for trait customization, contributing to shaping new approaches in medicinal plant breeding gradually. Collectively, these developments may facilitate profound improvements in breeding efficiency, compound yield, and environmental sustainability.}
}
@article{GORBAN202117,
title = {Dynamic and thermodynamic models of adaptation},
journal = {Physics of Life Reviews},
volume = {37},
pages = {17-64},
year = {2021},
issn = {1571-0645},
doi = {https://doi.org/10.1016/j.plrev.2021.03.001},
url = {https://www.sciencedirect.com/science/article/pii/S1571064521000129},
author = {A.N. Gorban and T.A. Tyukina and L.I. Pokidysheva and E.V. Smirnova},
keywords = {Correlation graph, Network biology, Adaptation energy, Critical transitions, Training, Limiting factor},
abstract = {The concept of biological adaptation was closely connected to some mathematical, engineering and physical ideas from the very beginning. Cannon in his “The wisdom of the body” (1932) systematically used the engineering vision of regulation. In 1938, Selye enriched this approach by the notion of adaptation energy. This term causes much debate when one takes it literally, as a physical quantity, i.e. a sort of energy. Selye did not use the language of mathematics systematically, but the formalization of his phenomenological theory in the spirit of thermodynamics was simple and led to verifiable predictions. In 1980s, the dynamics of correlation and variance in systems under adaptation to a load of environmental factors were studied and the universal effect in ensembles of systems under a load of similar factors was discovered: in a crisis, as a rule, even before the onset of obvious symptoms of stress, the correlation increases together with variance (and volatility). During 30 years, this effect has been supported by many observations of groups of humans, mice, trees, grassy plants, and on financial time series. In the last ten years, these results were supplemented by many new experiments, from gene networks in cardiology and oncology to dynamics of depression and clinical psychotherapy. Several systems of models were developed: the thermodynamic-like theory of adaptation of ensembles and several families of models of individual adaptation. Historically, the first group of models was based on Selye's concept of adaptation energy and used fitness estimates. Two other groups of models are based on the idea of hidden attractor bifurcation and on the advection–diffusion model for distribution of population in the space of physiological attributes. We explore this world of models and experiments, starting with classic works, with particular attention to the results of the last ten years and open questions.}
}
@article{ANTOSZ2023105802,
title = {What do you want theory for? - A pragmatic analysis of the roles of “theory” in agent-based modelling},
journal = {Environmental Modelling & Software},
volume = {168},
pages = {105802},
year = {2023},
issn = {1364-8152},
doi = {https://doi.org/10.1016/j.envsoft.2023.105802},
url = {https://www.sciencedirect.com/science/article/pii/S1364815223001883},
author = {Patrycja Antosz and Dan Birks and Bruce Edmonds and Alison Heppenstall and Ruth Meyer and J. Gareth Polhill and David O'Sullivan and Nanda Wijermans},
abstract = {There has been some discussion about agent-based modelling (ABM) and theory, particularly how ABM might facilitate theory building. However, there is confusion about the different ways they could relate and some scepticism as to whether theory is needed if one has an ABM. This paper distinguishes some of the different ways that the term “theory” is used in ABM papers in three important ABM journals: Environmental Modelling & Software, Computers, Environment and Urban Systems and the Journal of Artificial Societies and Social Simulation. Apart from the simple-minded identification of theory with mathematics, we distinguish nine different ways that theory and ABM relate. This analysis is situated with respect to some of the expectations and philosophical background behind the idea of “theory”. The paper concludes with some ways in which theory and ABM could work better together, some possible ways forward and suggests that a more cautious approach to generalisation might be more appropriate.}
}
@article{GRISOT2021122,
title = {Experimentally assessing the roles of grammatical aspect, lexical aspect and coreference patterns for the inference of temporal relations in English},
journal = {Journal of Pragmatics},
volume = {184},
pages = {122-139},
year = {2021},
issn = {0378-2166},
doi = {https://doi.org/10.1016/j.pragma.2021.08.007},
url = {https://www.sciencedirect.com/science/article/pii/S0378216621002939},
author = {Cristina Grisot},
keywords = {English, Temporal relations,  assumption, Grammatical aspect, Lexical aspect, Coreference patterns, Expectation-driven model},
abstract = {The question of the roles of grammatical aspect and of lexical aspect for the inference of temporal relations has richly been investigated from a theoretical point of view in various fields of languages sciences. Nevertheless, previous studies do not formulate similar conclusions, and thus they trigger different predictions for experimental testing. In contrast, the role of coreference patterns did not receive as much attention as grammatical and lexical aspect have received. As such, in this study we experimentally assess the roles of grammatical aspect (perfective vs. imperfective), lexical aspect (activities vs. accomplishments) and coreference patterns (same vs. different agents) in English. By means of an annotation study, we establish that fewer chronological relations emerge in passages with the imperfective aspect and coreference of agents (i.e. the actions are performed by the same agent). Then, by means of a temporal evaluation task, we show that synchronous relations are favoured in narrative passages that describe activities and lack of coreference of agents (i.e. the actions are performed by different agents). To interpret the results, we suggest that the comprehenders’ inference of temporal relations is influenced on the one hand by linguistic biases and on the other hand by their expectations of coherence. We discuss the findings from a cross-linguistic perspective.}
}
@article{YEN201952,
title = {Learning English–Chinese bilingual word representations from sentence-aligned parallel corpus},
journal = {Computer Speech & Language},
volume = {56},
pages = {52-72},
year = {2019},
issn = {0885-2308},
doi = {https://doi.org/10.1016/j.csl.2019.01.002},
url = {https://www.sciencedirect.com/science/article/pii/S0885230817302413},
author = {An-Zi Yen and Hen-Hsen Huang and Hsin-Hsi Chen},
keywords = {Cross-lingual applications, Distributed word representation, Word alignment},
abstract = {Representation of words in different languages is fundamental for various cross-lingual applications. In the past researches, there was an argument in using or not using word alignment in learning bilingual word representations. This paper presents a comprehensive empirical study on the uses of parallel corpus to learn the word representations in the embedding space. Various non-alignment and alignment approaches are explored to formulate the contexts for Skip-gram modeling. In the approaches without word alignment, concatenating A and B, concatenating B and A, interleaving A with B, shuffling A and B, and using A and B separately are considered, where A and B denote parallel sentences in two languages. In the approaches with word alignment, three word alignment tools, including GIZA++, TsinghuaAligner, and fast_align, are employed to align words in sentences A and B. The effects of alignment direction from A to B or from B to A are also discussed. To deal with the unaligned words in the word alignment approach, two alternatives, using the words aligned with their immediate neighbors and using the words in the interleaving approach, are explored. We evaluate the performance of the adopted approaches in four tasks, including bilingual dictionary induction, cross-lingual information retrieval, cross-lingual analogy reasoning, and cross-lingual word semantic relatedness. These tasks cover the issues of translation, reasoning, and information access. Experimental results show the word alignment approach with conditional interleaving achieves the best performance in most of the tasks.}
}
@article{NAPOLI2021101854,
title = {Ka Suwe: Culturally sustaining and responsive practices in expressive therapies education},
journal = {The Arts in Psychotherapy},
volume = {76},
pages = {101854},
year = {2021},
issn = {0197-4556},
doi = {https://doi.org/10.1016/j.aip.2021.101854},
url = {https://www.sciencedirect.com/science/article/pii/S019745562100099X},
author = {Michelle Napoli},
keywords = {Culturally sustaining, Cultural responsiveness, Cultural genocide},
abstract = {Indigenous methodology, which includes story, the arts, and Native language, is defined and applied in this article as a response to the appropriation and misrepresentation of Indigenous spirituality and cultural practices, the silencing and erasure of American Indian genocide, and the denigration of Indigenous worldviews experienced by this author in expressive therapies education. Throughout the article, this author identifies and incorporates Indigenous methodology as one route to promoting culturally sustaining and responsive practices in expressive therapies education.}
}
@article{HASSAN2021103479,
title = {Computer-assisted separation of design-build contract requirements to support subcontract drafting},
journal = {Automation in Construction},
volume = {122},
pages = {103479},
year = {2021},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2020.103479},
url = {https://www.sciencedirect.com/science/article/pii/S0926580520310591},
author = {Fahad ul Hassan and Tuyen Le},
keywords = {Contractual requirements, Design-build contracts, Subcontracts, Subcontractors, Natural language processing, Machine learning, Text classification, Text mining},
abstract = {Construction projects delivered using the Design-Build (DB) method include a single contract which defines requirements associated with various disciplines involved in the project. Consequently, DB contractors often need to develop several subcontracts including only a subset of requirements from the main contract. The current manual practices for subcontract drafting are error-prone and time-consuming. The study developed a novel classification model using machine learning for classifying DB requirements into three predefined categories including design, construction, and operation and maintenance. The paper compared various training approaches to perform DB requirement classification including traditional algorithms (i.e., Naïve Bayes, support vector machine, logistic regression, decision tree, and k-nearest neighbor), and two state-of-the-art deep neural networks architectures (i.e., convolutional neural network and recurrent neural network). In addition, it examined the effect of different feature types, feature selection, feature weighting, and ensemble methods on the model training performance. The classification models were trained on a large dataset of over 3000 contractual clauses, and the best model achieved an impressive precision of 93.20%, a recall of 93.08%, and an F-score of 92.98%. The study is expected to assist contract administrators in extracting the precise scope of subcontractors in less time and effort.}
}
@article{WANG2022145,
title = {An improved entity recognition approach to cyber-social knowledge provision of intellectual property using a CRF-LSTM model},
journal = {Pattern Recognition Letters},
volume = {163},
pages = {145-151},
year = {2022},
issn = {0167-8655},
doi = {https://doi.org/10.1016/j.patrec.2022.10.001},
url = {https://www.sciencedirect.com/science/article/pii/S016786552200294X},
author = {Yang Wang and Pandi Vijayakumar and Brij B. Gupta and Wadee Alhalabi and Audithan Sivaraman},
keywords = {Intellectual property, Named-entity recognition, LSTM, CRF, Knowledge graph},
abstract = {With the development of cutting-edge IT technologies, e.g. Big Data, Knowledge Engineering, etc., traditional Intellectual Property (IP) services have depicted high redundancy and low efficiency during management of such large-scale of data. Recent advancement of Artificial Intelligence (AI) and Deep Learning (DL) models has been accelerating relevant research activities being investigated on Knowledge Graph (KG) schemes and applications in different domains, such as medical services, social media, etc. However, when IP services and their cyber-social provision are taken into account, relevant approaches suffer from unbalanced labels against training results, and inappropriate evaluation metrics not well reflecting the impact of the unbalance. In this paper, a deep learning model combining Conditional Random Field and Bidirectional LSTM has been proposed, in order to achieve named entity recognition with unbalanced labels. An adaptive metric, G-Score was introduced to compare the fitting ability of models by evaluating the gap between Precision and Recall. According to the results, the proposed model can effectively recognize the potential named entities with outperformance over other relevant models.}
}
@article{LU202087,
title = {HAPE: A programmable big knowledge graph platform},
journal = {Information Sciences},
volume = {509},
pages = {87-103},
year = {2020},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2019.08.051},
url = {https://www.sciencedirect.com/science/article/pii/S002002551930800X},
author = {Ruqian LU and Chaoqun FEI and Chuanqing WANG and Shunfeng GAO and Han QIU and Songmao ZHANG and Cungen CAO},
keywords = {Big knowledge, Big knowledge system, Big knowledge graph, Knowledge graph browser, Knowledge graph operating system, Knowledge scripting language, Big knowledge security},
abstract = {Heaven Ape (HAPE) is an integrated big knowledge graph platform supporting the construction, management, and operation of large to massive scale knowledge graphs. Its current version described in this paper is a prototype, which consists of three parts: a big knowledge graph knowledge base, a knowledge graph browser on the client side, and a knowledge graph operating system on the server side. The platform is programmed in two high level scripting languages: JavaScript for programming the client side functions and Python for the server side functions. For making the programming more suitable for big knowledge processing and more friendly to knowledge programmers, we have developed two versions of knowledge scripting languages, namely K-script-c and K-script-s, for performing very high level knowledge programming of client resp. server side functions. HAPE borrows ideas from some well-known knowledge graph processing techniques and also invents some new ones as our creation. As an experiment, we transformed a major part of the DBpedia knowledge base and reconstructed it as a big knowledge graph. It works well in some application tests and provides acceptable efficiency.}
}
@article{JAULENT201819,
title = {Semantic interoperability challenges to process large amount of data perspectives in forensic and legal medicine},
journal = {Journal of Forensic and Legal Medicine},
volume = {57},
pages = {19-23},
year = {2018},
note = {Thematic section: Big dataGuest editor: Thomas LefèvreThematic section: Health issues in police custodyGuest editors: Patrick Chariot and Steffen Heide},
issn = {1752-928X},
doi = {https://doi.org/10.1016/j.jflm.2016.10.002},
url = {https://www.sciencedirect.com/science/article/pii/S1752928X1630124X},
author = {Marie-Christine Jaulent and Damien Leprovost and Jean Charlet and Remy Choquet},
keywords = {Variety in big data, Knowledge engineering, Semantic interoperability, Ontology, Forensic science},
abstract = {This article is a position paper dealing with semantic interoperability challenges. It addresses the Variety and Veracity dimensions when integrating, sharing and reusing large amount of heterogeneous data for data analysis and decision making applications in the healthcare domain. Many issues are raised by the necessity to conform Big Data to interoperability standards. We discuss how semantics can contribute to the improvement of information sharing and address the problem of data mediation with domain ontologies. We then introduce the main steps for building domain ontologies as they could be implemented in the context of Forensic and Legal medicine. We conclude with a particular emphasis on the current limitations in standardisation and the importance of knowledge formalization.}
}
@article{KLEINALTENKAMP2025166,
title = {The emergence, stabilization, and destabilization of resources: Gated reverb and the sound of the 80s},
journal = {Industrial Marketing Management},
volume = {129},
pages = {166-181},
year = {2025},
issn = {0019-8501},
doi = {https://doi.org/10.1016/j.indmarman.2025.07.009},
url = {https://www.sciencedirect.com/science/article/pii/S0019850125001099},
author = {Michael Kleinaltenkamp and Moritz J. Kleinaltenkamp and Kieran D. Tierney},
keywords = {Music production, Resources, Resource emergence, Process research},
abstract = {B2B marketing scholarship has begun to question the traditional perspective of resources as stable entities that are ‘out there’ for firms to be acquired, transformed, or leveraged to create value. It has instead begun to adopt a more processual perspective emphasizing resources as situational phenomena that come into existence through their use and may also fade away again. While such a process-relational perspective holds great promise to advance B2B resource thinking, it is still nascent, being marked by lingering conceptual inconsistencies and a relative lack of empirical research. Against this backdrop, our study explores the process of resource emergence, stabilization and destabilization, by drawing on the revelatory case study of the “gated reverb drum sound”, popularly known as “the sound of the 80s”. Using archival and primary data, we develop a process model that shows how resources emerge, gain traction and decline over time by moving through four phases: discovering, prototyping, commodifying, and overusing. We illuminate the material-discursive practices making up these phases, and the resource characteristics they enact at different points in time. Our findings provide a new way of thinking about the lifecycle of resources, and the involvement of humans and non-humans in this process, with significant implications for theory and practice.}
}
@article{XIN201877,
title = {Identification of key microRNAs, transcription factors and genes associated with congenital obstructive nephropathy in a mouse model of megabladder},
journal = {Gene},
volume = {650},
pages = {77-85},
year = {2018},
issn = {0378-1119},
doi = {https://doi.org/10.1016/j.gene.2018.01.063},
url = {https://www.sciencedirect.com/science/article/pii/S0378111918300763},
author = {Guangda Xin and Rui Chen and Xiaofei Zhang},
keywords = {Congenital obstructive nephropathy, Differentially expressed miRNAs, Functional enrichment analysis, Transcription factor, Molecular mechanisms},
abstract = {Objective
The present study aimed to investigate the molecular mechanism underlying congenital obstructive nephropathy (CON).
Methods
The microarray dataset GSE70879 was downloaded from the Gene Expression Omnibus, including 3 kidney samples of megabladder mice and 4 control kidneys. Using this dataset, differentially expressed miRNAs (DEMs) were identified between the kidney samples from megabladder mice and controls, followed by identification of the target genes for these DEMs and construction of a DEM and target gene interaction network. Additionally, the target genes were subjected to Gene Ontology and pathway enrichment analyses, and were used for construction of a protein-protein interaction (PPI) network. Finally, regulatory networks were constructed to analyze transcription factors for the key miRNAs.
Results
From 17 DEMs identified between kidney samples of megabladder mice and controls, 3 key miRNAs were screened, including mmu-miR-150-5p, mmu-miR-374b-5p and mmu-miR-126a-5p. The regulatory networks identified vascular endothelial growth factor A (Vegfa) as the common target gene of mmu-miR-150-5p and five transcription factors, including nuclear receptor subfamily 4, group A, member 2 (Nr4a2), Jun dimerisation protein 2 (Jdp2), Kruppel-like factor 6 (Klf6), Neurexophilin-3 (Nxph3) and RNA binding motif protein 17 (Rbm17). The gene encoding phosphatase and tensin homolog (Pten) was found to be co-regulated by mmu-miR-374b-5p and high mobility group protein A1 (Hmga1), whereas the kirsten rat sarcoma viral oncogene (Kras) was identified as a common target gene of mmu-miR-126a-5p and paired box 6 (Pax6).
Conclusions
In summary, the above-listed key miRNAs, transcription factors and key genes may be involved in the development of CON.}
}
@article{LISLIEN2025154000,
title = {Transcriptomic characterization of 2D and 3D human induced pluripotent stem cell-based in vitro models as New Approach Methodologies for developmental neurotoxicity testing},
journal = {Toxicology},
volume = {510},
pages = {154000},
year = {2025},
issn = {0300-483X},
doi = {https://doi.org/10.1016/j.tox.2024.154000},
url = {https://www.sciencedirect.com/science/article/pii/S0300483X24002816},
author = {Malene Lislien and Eliska Kuchovska and Julia Kapr and Nur Duale and Jill Mari Andersen and Hubert Dirven and Oddvar Myhre and Ellen Fritsche and Katharina Koch and Marcin W. Wojewodzic},
keywords = {Applicability domain, Developing human brain, DNT IVB, Hazard assessment, Human neural progenitor cells},
abstract = {The safety and developmental neurotoxicity (DNT) potential of chemicals remain critically understudied due to limitations of current in vivo testing guidelines, which are low throughput, resource-intensive, and hindered by species differences that limit their relevance to human health. To address these issues, robust New Approach Methodologies (NAMs) using deeply characterized cell models are essential. This study presents the comprehensive transcriptomic characterization of two advanced human-induced pluripotent stem cell (hiPSC)-derived models: a 2D adherent and a 3D neurosphere model of human neural progenitor cells (hiNPCs) differentiated up to 21 days. Using high-throughput RNA sequencing, we compared gene expression profiles of 2D and 3D models at three developmental stages (3, 14, and 21 days of differentiation). Both models exhibit maturation towards post-mitotic neurons, with the 3D model maturing faster and showing a higher prevalence of GABAergic neurons, while the 2D model is enriched with glutamatergic neurons. Both models demonstrate broad applicability domains, including excitatory and inhibitory neurons, astrocytes, and key endocrine and especially the understudied cholinergic receptors. Comparison with human fetal brain samples confirms their physiological relevance. This study provides novel in-depth applicability insights into the temporal and dimensional aspects of hiPSC-derived neural models for DNT testing. The complementary use of these two models is highlighted: the 2D model excels in synaptogenesis assessment, while the 3D model is particularly suited for neural network formation as observed as well in previous functional studies with these models. This research marks a significant advancement in developing human-relevant, high-throughput DNT assays for regulatory purposes.}
}
@article{YANG202030,
title = {Introspection unit in memory network: Learning to generalize inference in OOV scenarios},
journal = {Neurocomputing},
volume = {379},
pages = {30-40},
year = {2020},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2019.07.111},
url = {https://www.sciencedirect.com/science/article/pii/S0925231219314778},
author = {Qichuan Yang and Zhiqiang He and Zhiqiang Zhan and Yang Zhang and Rang Li and Changjian Hu},
keywords = {Memory network, Out of vocabulary, Introspection unit, Language inference},
abstract = {Inference in natural language processing (NLP) is a tough task. Although plenty of models have been proposed in recent years, they are usually restricted to infer within a limited vocabulary or handcrafted training templates. In this paper, we propose the introspection unit (IU), a new neural module which can be incorporated with memory networks to deal with inference tasks in out of vocabulary (OOV) and rare named entities (RNEs) scenarios. Specifically, when encountering a new word, IU compares its part-of-speech context with the training dataset to extract a similar sample, and then embeds the new word into a target position to construct a simulated sample. The target position is located by the result of part-of-speech tagging. Finally, using the simulated sample, IU helps memory networks to learn the context and characteristic of the new word. In experiments, we evaluate the effectiveness of IU with the memory network on four inference datasets: a name OOV dataset, a place OOV dataset, a more challenging synthetical mixture OOV dataset and a realistic dialogue dataset. The experimental results demonstrate that IU effectively generalizes the inference ability of memory networks to OOV scenarios and improves the inference accuracies significantly. Furthermore, we visualize both the introspection process and the effect of IU in word embeddings and memories.}
}
@article{ZHENG2020309,
title = {A Quality-Oriented Digital Twin Modelling Method for Manufacturing Processes Based on A Multi-Agent Architecture},
journal = {Procedia Manufacturing},
volume = {51},
pages = {309-315},
year = {2020},
note = {30th International Conference on Flexible Automation and Intelligent Manufacturing (FAIM2021)},
issn = {2351-9789},
doi = {https://doi.org/10.1016/j.promfg.2020.10.044},
url = {https://www.sciencedirect.com/science/article/pii/S2351978920318990},
author = {Xiaochen Zheng and Foivos Psarommatis and Pierluigi Petrali and Claudio Turrin and Jinzhi Lu and Dimitris Kiritsis},
keywords = {Digital Twin, multi-agent system, quality control, manufacturing processes},
abstract = {The quality of a product is highly dependent on manufacturing processes. The recent development of industrial information technologies, such as Cyber-Physical Production Systems, Industrial Internet of Things, and Big Manufacturing Data Analytics has empowered the digitalization of manufacturing processes and promoted the concept of Digital Twin (DT). As one of the fundamental enabling technologies for Industry 4.0, DT enables the convergence between a physical system and its digital representation. DT modelling is the basis of implementing DT in practice. In this paper, we propose a DT modelling method based on a multi-agent architecture. It focuses on quality control during manufacturing processes and provides solutions to gather relevant information and analyze the corresponding influences on product quality. The MPFQ-model (Material, Production Process, Product Function/Future, Product Quality) is adopted to support the analysis of main influential factors related to the final product quality during the manufacturing phase. The five-dimension architecture is used as the basis for the DT models, including (i) physical entities, (ii) virtual models, (iii) DT data, (iv) services and (v) connections. Based on this architecture a Multi-Agent System (MAS) component and a semantic engineering component are integrated to create a quality-oriented DT framework.}
}
@article{QIU2024106070,
title = {An interoperable software system to store, associate, visualize, and publish global open science data of earth surface system},
journal = {Environmental Modelling & Software},
volume = {178},
pages = {106070},
year = {2024},
issn = {1364-8152},
doi = {https://doi.org/10.1016/j.envsoft.2024.106070},
url = {https://www.sciencedirect.com/science/article/pii/S1364815224001312},
author = {Qinjun Qiu and Jiandong Liu and Mengqi Hao and Weijie Li and Yang Wang and Zhong Xie and Liufeng Tao},
keywords = {Earth surface system, Open science data, Data association network, Open-source software, Scientific data recommendations},
abstract = {Multi-source heterogeneous, multi-modal, and multi-type open scientific data (e.g., thematic sharing sites, metadata, journal articles, etc.) on earth surface systems (EES) provide important data sources for knowledge mining, discovery, and accurate recommendations, and also pose increasing challenges, resulting in the need to develop appropriate tools to address these challenges and support decision-making. This paper constructs an interoperable software system to store, visualize, and publish open science data of ESS. Utilizing an open scientific data catalogue repository encompassing EES information as foundational input and employing an integrated modeling methodology, this system endeavors to synthesize heterogeneous surface data of diverse linguistic, sourced, and typological origins. The objective is to facilitate multidimensional data retrieval and precise data auto-recommendation, thereby fostering the dissemination of scientific data and facilitating value-added services within EES domain. The tool may be used by stakeholders including researchers, data analysts, policymakers and national authorities to support decision-making on questions ranging from locating the location of open data related to the topic, to discovering high-quality data, selecting the data with the better overall evaluation. Along with a description of the system/platform design process, its structure, and the constituent models, key results are presented relating to the user interface, and several application examples. Software systems can help modelers to use the best features of a single software tool to answer open scientific data-related questions that seek to discovery, use, comparison or synthesis within or across topics of ESS.}
}
@article{TOLK20211075,
title = {Hybrid models as transdisciplinary research enablers},
journal = {European Journal of Operational Research},
volume = {291},
number = {3},
pages = {1075-1090},
year = {2021},
issn = {0377-2217},
doi = {https://doi.org/10.1016/j.ejor.2020.10.010},
url = {https://www.sciencedirect.com/science/article/pii/S0377221720308869},
author = {Andreas Tolk and Alison Harper and Navonil Mustafee},
keywords = {Decision processes, Hybrid modelling, Multidisciplinary, Interdisciplinary, Transdisciplinary},
abstract = {Modelling and simulation (M&S) techniques are frequently used in Operations Research (OR) to aid decision-making. With growing complexity of systems to be modelled, an increasing number of studies now apply multiple M&S techniques or hybrid simulation (HS) to represent the underlying system of interest. A parallel but related theme of research is extending the HS approach to include the development of hybrid models (HM). HM extends the M&S discipline by combining theories, methods and tools from across disciplines and applying multidisciplinary, interdisciplinary and transdisciplinary solutions to practice. In the broader OR literature, there are numerous examples of cross-disciplinary approaches in model development. However, within M&S, there is limited evidence of the application of conjoined methods for building HM. Where a stream of such research does exist, the integration of approaches is mostly at a technical level. In this paper, we argue that HM requires cross-disciplinary research engagement and a conceptual framework. The framework will enable the synthesis of discipline-specific methods and techniques, further cross-disciplinary research within the M&S community, and will serve as a transcending framework for the transdisciplinary alignment of M&S research with domain knowledge, hypotheses and theories from diverse disciplines. The framework will support the development of new composable HM methods, tools and applications. Although our framework is built around M&S literature, it is generally applicable to other disciplines, especially those with a computational element. The objective is to motivate a transdisciplinarity-enabling framework that supports the collaboration of research efforts from multiple disciplines, allowing them to grow into transdisciplinary research.}
}
@article{REN2021,
title = {Depression Detection on Reddit With an Emotion-Based Attention Network: Algorithm Development and Validation},
journal = {JMIR Medical Informatics},
volume = {9},
number = {7},
year = {2021},
issn = {2291-9694},
doi = {https://doi.org/10.2196/28754},
url = {https://www.sciencedirect.com/science/article/pii/S2291969421002283},
author = {Lu Ren and Hongfei Lin and Bo Xu and Shaowu Zhang and Liang Yang and Shichang Sun},
keywords = {depression detection, attention network, emotional semantic information, dynamic fusion strategy, natural language processing, social media, emotion, mental health, algorithm, deep learning},
abstract = {Background
As a common mental disease, depression seriously affects people’s physical and mental health. According to the statistics of the World Health Organization, depression is one of the main reasons for suicide and self-harm events in the world. Therefore, strengthening depression detection can effectively reduce the occurrence of suicide or self-harm events so as to save more people and families. With the development of computer technology, some researchers are trying to apply natural language processing techniques to detect people who are depressed automatically. Many existing feature engineering methods for depression detection are based on emotional characteristics, but these methods do not consider high-level emotional semantic information. The current deep learning methods for depression detection cannot accurately extract effective emotional semantic information.
Objective
In this paper, we propose an emotion-based attention network, including a semantic understanding network and an emotion understanding network, which can capture the high-level emotional semantic information effectively to improve the depression detection task.
Methods
The semantic understanding network module is used to capture the contextual semantic information. The emotion understanding network module is used to capture the emotional semantic information. There are two units in the emotion understanding network module, including a positive emotion understanding unit and a negative emotion understanding unit, which are used to capture the positive emotional information and the negative emotional information, respectively. We further proposed a dynamic fusion strategy in the emotion understanding network module to fuse the positive emotional information and the negative emotional information.
Results
We evaluated our method on the Reddit data set. The experimental results showed that the proposed emotion-based attention network model achieved an accuracy, precision, recall, and F-measure of 91.30%, 91.91%, 96.15%, and 93.98%, respectively, which are comparable results compared with state-of-the-art methods.
Conclusions
The experimental results showed that our model is competitive with the state-of-the-art models. The semantic understanding network module, the emotion understanding network module, and the dynamic fusion strategy are effective modules for depression detection. In addition, the experimental results verified that the emotional semantic information was effective in depression detection.}
}
@article{QIAN2025113521,
title = {From local verification to global reasoning: Exploiting slot-accompanying update for improved slot selection},
journal = {Knowledge-Based Systems},
volume = {319},
pages = {113521},
year = {2025},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2025.113521},
url = {https://www.sciencedirect.com/science/article/pii/S0950705125005672},
author = {Bing Qian and Jinyu Guo and Qiwei Wang and Kai Shuang},
keywords = {Dialogue-state tracking, Slot-update selection, Local verification, Global reasoning},
abstract = {The goal of dialogue-state tracking (DST) is to determine the current state of a dialogue by analysing the entire preceding dialogue context. Nonetheless, current approaches frequently fail to account for the significance of concurrent updates, where related slots must be updated simultaneously based on their historical relationships, even in the absence of explicit signals in the current dialogue turn. To address this limitation, we introduce From Local Verification to Global Reasoning (FLV2GR), an innovative method that improves slot-update selection by combining local verification of present dialogue details with global reasoning over historical dialogue data. Our approach utilizes a graph neural network (GNN) to model and infer interdependencies between slots, enabling the identification of accompanying update relationships that are frequently overlooked by other approaches. This comprehensive selection mechanism improves the precision of slot updates, thereby enhancing overall DST performance. The FLV2GR model establishes a new performance benchmark on the MultiWOZ 2.1, 2.2, and 2.4 datasets, showcasing its effectiveness in capturing both local and global dialogue dynamics for more precise and reliable DST.11https://github.com/guojinyu88/FLV2GR.}
}
@article{ZIDOUN2022,
title = {Contextual Conversational Agent to Address Vaccine Hesitancy: Protocol for a Design-Based Research Study},
journal = {JMIR Research Protocols},
volume = {11},
number = {8},
year = {2022},
issn = {1929-0748},
doi = {https://doi.org/10.2196/38043},
url = {https://www.sciencedirect.com/science/article/pii/S1929074822005236},
author = {Youness Zidoun and Sreelekshmi Kaladhara and Leigh Powell and Radwa Nour and Hanan {Al Suwaidi} and Nabil Zary},
keywords = {conversational agent, design-based research, chatbot, Rasa, NLU, COVID-19, vaccine hesitancy, misinformation, vaccination, iterative design, health communication, health information, System Usability Scale},
abstract = {Background
Since the beginning of the COVID-19 pandemic, people have been exposed to misinformation, leading to many myths about SARS-CoV-2 and the vaccines against it. As this situation does not seem to end soon, many authorities and health organizations, including the World Health Organization (WHO), are utilizing conversational agents (CAs) in their fight against it. Although the impact and usage of these novel digital strategies are noticeable, the design of the CAs remains key to their success.
Objective
This study describes the use of design-based research (DBR) for contextual CA design to address vaccine hesitancy. In addition, this protocol will examine the impact of DBR on CA design to understand how this iterative process can enhance accuracy and performance.
Methods
A DBR methodology will be used for this study. Each phase of analysis, design, and evaluation of each design cycle inform the next one via its outcomes. An anticipated generic strategy will be formed after completing the first iteration. Using multiple research studies, frameworks and theoretical approaches are tested and evaluated through the different design cycles. User perception of the CA will be analyzed or collected by implementing a usability assessment during every evaluation phase using the System Usability Scale. The PARADISE (PARAdigm for Dialogue System Evaluation) method will be adopted to calculate the performance of this text-based CA.
Results
Two phases of the first design cycle (design and evaluation) were completed at the time of this writing (April 2022). The research team is currently reviewing the natural-language understanding model as part of the conversation-driven development (CDD) process in preparation for the first pilot intervention, which will conclude the CA’s first design cycle. In addition, conversational data will be analyzed quantitatively and qualitatively as part of the reflection and revision process to inform the subsequent design cycles. This project plans for three rounds of design cycles, resulting in various studies spreading outcomes and conclusions. The results of the first study describing the entire first design cycle are expected to be submitted for publication before the end of 2022.
Conclusions
CAs constitute an innovative way of delivering health communication information. However, they are primarily used to contribute to behavioral change or educate people about health issues. Therefore, health chatbots’ impact should be carefully designed to meet outcomes. DBR can help shape a holistic understanding of the process of CA conception. This protocol describes the design of VWise, a contextual CA that aims to address vaccine hesitancy using the DBR methodology. The results of this study will help identify the strengths and flaws of DBR’s application to such innovative projects.}
}
@article{STRIDSLAND2023139126,
title = {No-one left behind: An open access approach to estimating the carbon footprint of a Danish clothing company},
journal = {Journal of Cleaner Production},
volume = {426},
pages = {139126},
year = {2023},
issn = {0959-6526},
doi = {https://doi.org/10.1016/j.jclepro.2023.139126},
url = {https://www.sciencedirect.com/science/article/pii/S0959652623032845},
author = {Thomas Stridsland and William Biørnstad and Kristina Vigen and Kristian Lange Østergaard and Hans Sanderson},
keywords = {Sustainable transition, Garment and textile sector, Scope 3, Green transition, Transitional risks, GHG accounting},
abstract = {The textile and garment industry has faced ongoing scrutiny for its environmental impacts, prompting pledges like the UN's Fashion Industry Charter for Climate Action (FICCA) targeting net-zero emissions by 2050. Building on FICCA's report on sector limitations, this study introduces an action-oriented case study using a GHG Protocol compliant open-access emissions inventory of MASCOT, a Danish clothing company. We identify most emissions are found in scope 3 (85%), specifically purchased goods and services (76%). Yet, supplier-specific data is limited across global supply chains and often displays methodological inconsistencies. Establishing a common data language between buyer and seller must be achieved for decarbonisation and decision support. Open access databases supplement supplier gaps but often lack the resolution or consistency required for sector specific investigations and decision support. A need for open access standardized data emerges as a crucial first step toward net-zero, filling the sector's data gaps. This study has resulted in greater carbon literacy and data awareness within MASCOT and established a language for supplier-firm dialogue, however, the limitations ultimately prevent these findings from commercial use, as clear and structured methods are still lacking in the sector. For tangible progress, a collaborative sector-specific database is required, alongside structured and verified data exchanges between stakeholders. The CSRD and proposals such as the Digital Product Passport are expected to bring attention to these gaps and expedite progress, however, dedicated sector-specific working groups like FICCA will continue to be essential in driving the necessary focus and informed decarbonisation efforts.}
}
@article{YAN2022112906,
title = {Evaluation of dioxin induced transcriptomic responses in a 3D human liver microtissue model},
journal = {Environmental Research},
volume = {210},
pages = {112906},
year = {2022},
issn = {0013-9351},
doi = {https://doi.org/10.1016/j.envres.2022.112906},
url = {https://www.sciencedirect.com/science/article/pii/S001393512200233X},
author = {Lu Yan and Catherine Jane Messner and Mingming Tian and Xiao Gou and Laura Suter-Dick and Xiaowei Zhang},
keywords = {3D human liver microtissues, Stable system, TCDD, Time-series transcriptomics, Biological processes, Species-specific response},
abstract = {Three-dimensional human liver microtissue model provides a promising method for predicting the human hepatotoxicity of environmental chemicals. However, the dynamics of transcriptional responses of 3D human liver microtissue model to dioxins exposure remain unclear. Herein, time-series transcriptomic analysis was used to characterize modulation of gene expression over 14 days in 3D human liver microtissues exposed to 2,3,7,8-tetra-chlorodibenzo-p-dioxin (TCDD, 31 nM, 10 ng/ml). Changes in gene expression and modulation of biological pathways were evaluated at several time points. The results showed that microtissues stably expressed genes related to toxicological pathways (e.g. highly of genes involved in external stimuli and maintenance of cell homeostasis pathways) during the 14-day culture period. Furthermore, a weekly phenomenon pattern was observed for the number of the differentially expressed genes in microtissues exposed to TCDD at each time point. TCDD led to an induction of genes involved in cell cycle regulation at day three. Metabolic pathways were the main significantly induced pathways during the subsequent days, with the immune/inflammatory response enriched on the fifth day, and the cellular response to DNA damage was identified at the end of the exposure. Finally, relevant transcription patterns identified in microtissues were compared with published data on rodent and human cell-line studies to elucidate potential species-specific responses to TCDD over time. Cell development and cytochrome P450 pathway were mainly affected after a 3-day exposure, with the DNA damage response identified at the end of exposure in the human microtissue system but not in mouse/rat primary hepatocytes models. Overall, the 3D human liver microtissue model is a valuable tool to predict the toxic effects of environmental chemicals with a relatively long exposure.}
}
@article{EFFIONG2025,
title = {Exploring Research Methodology and Research Design:},
journal = {International Journal of Business Analytics},
volume = {12},
number = {1},
year = {2025},
issn = {2334-4547},
doi = {https://doi.org/10.4018/IJBAN.381677},
url = {https://www.sciencedirect.com/science/article/pii/S233445472500005X},
author = {Sokomba Hannah Effiong},
keywords = {Reflexivity Research Philosophy Epistemology Ontology Methodological Flexibility Research Practice Organizational Ethnography Autoethnography Thematic Template Analysis},
abstract = {ABSTRACT
This book review examines Exploring Research Methodology and Research Design: Doing Research Across the Business Disciplines, edited by Peter John Sandiford and Sabine Schührer. The book is a reflective and practice-based resource for researchers navigating the complexities of methodology and design in business disciplines. It is structured in three parts: foundational perspectives on research, considerations in design and planning, and the realities of conducting research. Through diverse voices and case-based insights, the text challenges linear, formulaic approaches to research and instead promotes critical engagement, methodological flexibility, and reflexivity. The book equips doctoral students and early-career researchers with tools for thoughtful and context-sensitive research practice by addressing philosophical, ethical, and social dimensions.}
}
@article{LAMINE201925,
title = {Plas'O'Soins: An Interactive ICT Platform to Support Care Planning and Coordination within Home-Based Care},
journal = {IRBM},
volume = {40},
number = {1},
pages = {25-37},
year = {2019},
issn = {1959-0318},
doi = {https://doi.org/10.1016/j.irbm.2018.10.015},
url = {https://www.sciencedirect.com/science/article/pii/S1959031818302823},
author = {E. Lamine and R. Bastide and M. Bouet and P. Gaborit and D. Gourc and F. Marmier and H. Pingaud and M. Schneider and F. Toumani},
keywords = {Homecare, Coordination, Personalized care plan, Dynamic care planning, Domain specific language},
abstract = {Background
Due to the rising demand in home healthcare services in France as well as in other European countries, homecare organizations are facing challenges in terms of coordination and continuity of care. In both cases, the problem is linked to the efficiency in which care interventions are distributed and managed among the different participants involved in home care processes. Project Plas'O'Soins which was developed within the framework of the French research program TecSan, aims to address these contemporary problems by providing an interactive ICT platform to improve coordination and continuity of care within homecare organizations.
Main achievements
Plas'O'Soins, the software platform we designed, supports care specification as well as planning and monitoring of the care plans. It allows the modeling of care plans using a dedicated Domain Specific Language, the scheduling of care operations taking into account the human resources, the medical constraints and the geographical distribution of patients, and the monitoring of the execution of the operations by the care actors. This software platform enables the coordination of activities and the communication between actors and reacts to unforeseen events and produces dashboards in order to quantify the effectiveness of the processes.
Conclusion
The software platform has been deployed and used in an experimental setting by homecare partner organizations, providing valuable insights on the organizational changes required by the introduction of such an ICT solution in the actual practice of homecare.}
}
@article{XIANG2024108181,
title = {Novel biomarkers associated with oxidative stress and immune infiltration in intervertebral disc degeneration based on bioinformatics approaches},
journal = {Computational Biology and Chemistry},
volume = {112},
pages = {108181},
year = {2024},
issn = {1476-9271},
doi = {https://doi.org/10.1016/j.compbiolchem.2024.108181},
url = {https://www.sciencedirect.com/science/article/pii/S1476927124001695},
author = {Min Xiang and Yue Lai and Jianlin Shen and Bo Wei and Huan Liu and Wenhua Huang},
keywords = {Intervertebral disc degeneration, Oxidative stress, Immune infiltration, PPIA, PXN},
abstract = {Background
The etiology of intervertebral disc degeneration (IVDD), a prevalent degenerative disease in the elderly, remains to be fully elucidated. The objective of this study was to identify immune infiltration and oxidative stress (OS) biomarkers in IVDD, aiming to provide further insights into the intricate pathogenesis of IVDD.
Methods
The Gene Expression microarrays were obtained from the Gene Expression Omnibus (GEO) database. We conducted enrichment analysis of Gene Ontology (GO) and Kyoto Encyclopedia of Genes and Genomes (KEGG) terms. Subsequently, the R language packages CIBERSORT, MCPcounter, and WGCNA were employed to compare immune infiltration levels between IVDD samples and control samples. A protein-protein interaction (PPI) network was constructed using the Search Tools for the Retrieval of Interacting Genes (STRING) database to identify significant gene clusters. To identify hub genes, we employed Cytoscape's Molecular Complex Detection (MCODE) plug-in. The mRNA levels of hub genes in the cell model were validated by qPCR, while Western blotting was used to validate their protein levels.
Results
The GSE70362 dataset from the GEO database identified a total of 1799 genes that were differentially expressed. Among these, 43 genes were found to be differentially expressed and also associated with OS. The differentially expressed genes associated with OS and the immune-related module genes identified through WGCNA were further intersected, resulting in the identification of 10 key genes that were differentially expressed and played crucial roles in both immune response and OS. Subsequently, we validated four diagnostic markers (PPIA, MAP3K5, PXN, and JAK2) using the GSE122429 external dataset. In a cellular model of OS in NP cells, we have identified the upregulation of PPIA and PXN genes, which could serve as novel markers for IVDD.
Conclusion
The study successfully identified and validated differentially expressed genes associated with oxidative stress and immune infiltration in IVDD samples compared to normal ones. Notably, the newly discovered biomarkers PPIA and PXN have not been previously reported in IVDD-related research.}
}
@article{SCHLACHTER2022104258,
title = {Using Linked Building Data for managing temporary construction items},
journal = {Automation in Construction},
volume = {139},
pages = {104258},
year = {2022},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2022.104258},
url = {https://www.sciencedirect.com/science/article/pii/S0926580522001315},
author = {Alexander Schlachter and Mads Holten Rasmussen and Jan Karlshøj},
keywords = {Linked Building Data, Temporary construction items, BIM},
abstract = {For decades, the construction industry has experienced poor productivity due to challenges such as increasing project complexity and a fragmented project environment. Even though some technological innovations around Building Information Modeling (BIM) might have the potential to overcome these challenges, data integration across disciplines, companies and software solutions is yet to be solved entirely. Trending advancements try to enrich existing BIM data using Linked Data technologies to semantically describe the building information and facilitate data integration. By that, project data from different data sources is made available in an accessible format, so project participants can use it for their planning efforts. In this paper we explore the use of Linked Building Data (LBD) on a specific use case to answer the question of how the planning of Temporary Construction Items (TCIs) can be improved by integrating data and automating the demand calculation. A literature review concludes that TCIs only experience little attention in the current planning of construction projects but have a critical impact on the outcome of a project. Thus, the objective of this paper is to develop standard ontologies to provide a semantically rich terminology of the data and to propose a framework for TCI consideration within a BIM based project delivery system. A prototype solution is developed, taking formwork as a TCI representative. The result is a process for automatically creating a TCI utilization plan that quantifies the precise time- and location-based on-site TCI demand by integrating data from BIM, Location-Based Scheduling (LBS) and TCI information. Based on the results of prototyping and findings from expert interviews, this research integrates the solution into the process of construction and finally proposes two implementation scenarios for the solution – one being based on the current industry situation and one exploring the future vision of a more integrated and decentralized project delivery in the construction industry.}
}
@article{LIU2022112935,
title = {Chronic stress induces platinum and Niraparib resistance in mouse models of ovarian cancer},
journal = {Experimental Cell Research},
volume = {410},
number = {2},
pages = {112935},
year = {2022},
issn = {0014-4827},
doi = {https://doi.org/10.1016/j.yexcr.2021.112935},
url = {https://www.sciencedirect.com/science/article/pii/S0014482721004912},
author = {Mu Liu and Xiaofang Zhou and Lijuan Sun and Shanmei Tan and Tingting Liu and Wangli Xiao and Jie Tang},
keywords = {Ovarian cancer, Drug resistance, Chronic stress, Mouse models, Gene expression, Transcriptomics},
abstract = {Resistance to platinum and PARP inhibitors represents a major barrier to the long-term survival of ovarian cancer patients. We aim to explore the potential role of chronic stress in drug resistance in ovarian cancer. Leveraging four ovarian cancer with chronic stress (OCCS) mouse models, we explore the therapeutic efficacy of platinum, Niraparib, and Docetaxel treatment in vivo, and compare the efficacy of these anti-tumor drugs in vitro using cell viability assays. Comparing the transcriptional characteristics in RNA-Seq of OCCS mice with public databases, we analyze the molecular mechanism of chronic stress promoting drug resistance in ovarian cancer. We find that chronic stress is positively correlated with platinum-resistant recurrence in ovarian cancer patients. Chronic stress can induce platinum and Niraparib resistance of ovarian cancer, but it does not affect the therapeutic efficacy of Docetaxel treatment in vivo. And the platinum-resistant cell lines are not sensitive to these anti-tumor drugs, which is different from the result in vivo. Then, we identify several gene networks and their constituent genes that are most significantly associated with chronic stress and drug resistance in ovarian cancer, including the glycolysis pathway and DNA damage. This study develops Niraparib and platinum-resistant in vivo models, reflecting the ability of OCCS mice to reproduce different aspects of human ovarian cancer molecular mechanism, and provides a new theoretical basis for overcoming the double drug resistance of ovarian cancer.}
}
@article{SHARMA2024102805,
title = {A framework for enhancing the replicability of behavioral MIS research using prediction oriented techniques},
journal = {International Journal of Information Management},
volume = {78},
pages = {102805},
year = {2024},
issn = {0268-4012},
doi = {https://doi.org/10.1016/j.ijinfomgt.2024.102805},
url = {https://www.sciencedirect.com/science/article/pii/S0268401224000537},
author = {Pratyush Nidhi Sharma and Marko Sarstedt and Christian M. Ringle and Jun-Hwa Cheah and Anne Herfurth and Joseph F. Hair},
keywords = {Replicability, Exploration, Confirmation, Explanation, Prediction, EP-mixed, Open Science, PLS-SEM},
abstract = {The ongoing scientific discourse surrounding the replication crisis in behavioral research, including management information systems (MIS) research, underscores the importance of innovative and rigorous approaches to theory development and validation. This article proposes the EP-mixed framework, which addresses the necessity of an ontological distinction between explanation and prediction in MIS theories, along with the epistemological challenges associated with conflating exploratory and confirmatory research during the design of robust, replicable theories. EP-mixed refers to theories that explain and predict (i.e., EP theories) developed using a mixed mode that combines the strengths of both exploratory and confirmatory research. The EP-mixed framework guides researchers in selecting appropriate analytical approaches based on their research goals and the type of theory being developed. While it can be applied in conjunction with a broad spectrum of statistical methods to enhance the robustness and replicability of MIS theories, we elaborate on the predictive analytic tools available in partial least squares structural equation modeling (PLS-SEM) as an exemplar for operationalizing the framework.}
}
@article{LIETO2018757,
title = {Higher-level Knowledge, Rational and Social Levels Constraints of the Common Model of the Mind},
journal = {Procedia Computer Science},
volume = {145},
pages = {757-764},
year = {2018},
note = {Postproceedings of the 9th Annual International Conference on Biologically Inspired Cognitive Architectures, BICA 2018 (Ninth Annual Meeting of the BICA Society), held August 22-24, 2018 in Prague, Czech Republic},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2018.11.033},
url = {https://www.sciencedirect.com/science/article/pii/S1877050918323196},
author = {Antonio Lieto and William G. Kennedy and Christian Lebiere and Oscar J. Romero and Niels Taatgen and Robert L. West},
keywords = {Unified Cognitive Architectures, Computational Models of Cognition, Common Model of the Mind, Cognitive Constraints, Knowledge Level, Rational Level, Social Level},
abstract = {We present the input to the discussion about the computational framework known as Common Model of Cognition (CMC) from the working group dealing with the knowledge/rational/social levels. In particular, we present a list of the higher level constraints that should be addressed within such a general framework.}
}
@article{ESCOBAR2020103378,
title = {Adding value to Linked Open Data using a multidimensional model approach based on the RDF Data Cube vocabulary},
journal = {Computer Standards & Interfaces},
volume = {68},
pages = {103378},
year = {2020},
issn = {0920-5489},
doi = {https://doi.org/10.1016/j.csi.2019.103378},
url = {https://www.sciencedirect.com/science/article/pii/S0920548919300480},
author = {Pilar Escobar and Gustavo Candela and Juan Trujillo and Manuel Marco-Such and Jesús Peral},
keywords = {Linked Open Data, Multidimensional modelling, Conceptual modelling, RDF Data Cube vocabulary, Semantic web, Big data},
abstract = {Most organisations using Open Data currently focus on data processing and analysis. However, although Open Data may be available online, these data are generally of poor quality, thus discouraging others from contributing to and reusing them. This paper describes an approach to publish statistical data from public repositories by using Semantic Web standards published by the W3C, such as RDF and SPARQL, in order to facilitate the analysis of multidimensional models. We have defined a framework based on the entire lifecycle of data publication including a novel step of Linked Open Data assessment and the use of external repositories as knowledge base for data enrichment. As a result, users are able to interact with the data generated according to the RDF Data Cube vocabulary, which makes it possible for general users to avoid the complexity of SPARQL when analysing data. The use case was applied to the Barcelona Open Data platform and revealed the benefits of the application of our approach, such as helping in the decision-making process.}
}
@article{SUN2023104482,
title = {A scoping review on multimodal deep learning in biomedical images and texts},
journal = {Journal of Biomedical Informatics},
volume = {146},
pages = {104482},
year = {2023},
issn = {1532-0464},
doi = {https://doi.org/10.1016/j.jbi.2023.104482},
url = {https://www.sciencedirect.com/science/article/pii/S1532046423002034},
author = {Zhaoyi Sun and Mingquan Lin and Qingqing Zhu and Qianqian Xie and Fei Wang and Zhiyong Lu and Yifan Peng},
keywords = {Multimodal learning, Medical images, Clinical notes, Scoping review},
abstract = {Objective
Computer-assisted diagnostic and prognostic systems of the future should be capable of simultaneously processing multimodal data. Multimodal deep learning (MDL), which involves the integration of multiple sources of data, such as images and text, has the potential to revolutionize the analysis and interpretation of biomedical data. However, it only caught researchers’ attention recently. To this end, there is a critical need to conduct a systematic review on this topic, identify the limitations of current work, and explore future directions.
Methods
In this scoping review, we aim to provide a comprehensive overview of the current state of the field and identify key concepts, types of studies, and research gaps with a focus on biomedical images and texts joint learning, mainly because these two were the most commonly available data types in MDL research.
Result
This study reviewed the current uses of multimodal deep learning on five tasks: (1) Report generation, (2) Visual question answering, (3) Cross-modal retrieval, (4) Computer-aided diagnosis, and (5) Semantic segmentation.
Conclusion
Our results highlight the diverse applications and potential of MDL and suggest directions for future research in the field. We hope our review will facilitate the collaboration of natural language processing (NLP) and medical imaging communities and support the next generation of decision-making and computer-assisted diagnostic system development.}
}
@article{IRSHAD2024553,
title = {Context-aware cyber-threat attribution based on hybrid features},
journal = {ICT Express},
volume = {10},
number = {3},
pages = {553-569},
year = {2024},
issn = {2405-9595},
doi = {https://doi.org/10.1016/j.icte.2024.04.005},
url = {https://www.sciencedirect.com/science/article/pii/S2405959524000420},
author = {Ehtsham Irshad and Abdul Basit Siddiqui},
keywords = {Cyber threat intelligence (CTI), Incident of compromise (IOC), Cyber-threat actor (CTA), Tactics techniques and procedures (TTP), Structured threat information expression (STIX), Security operation center (SOC), Convolutional neural network (CNN), Security information and event management (SIEM), Natural language processing (NLP), Decision tree (DT), Random forest (RF)},
abstract = {With the rapid technological development, identifying the attackers behind cyber-attacks is getting more sophisticated. To cope with this phenomenon, the current process of cyber-threat attribution includes features like tactics techniques and procedures (TTP), tools, target country/ company and application. They do not include attacker context and motives; thus, they demand more refined traits. Adding behavioral features to this process is essential to better understand the attacker’s context, motivations and goals. This research study accentuates the impact of adding behavioral features with existing technical features in determining the actual actor. The behavioral features are extracted from Threat actor encyclopedia, a dataset published by Thai CERT. This research investigation also analyzes the impact of hybrid features (technical & and behavioral). For this procedure, the best features are chosen by implementing feature selection techniques. For empirical results, we use the threat actor encyclopedia, a data set published by Thai Cert, for extraction of behavioral attributes. With this augmentation, we achieve elevated results of 97%, 98.8%, 97%, and 97.2% in terms of accuracy, precision, recall and F1-measure using machine/deep learning algorithms.}
}
@article{WEI2025108019,
title = {HPC and AI in bioinformatics},
journal = {Future Generation Computer Systems},
pages = {108019},
year = {2025},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2025.108019},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X25003140},
author = {Yanjie Wei and Weiguo Liu and Bertil Schmidt and Quan Zou and Limin Jiang},
keywords = {HPC, AI, Drug-target interaction, Representation learning, Metagenomics},
abstract = {The unprecedented generation of biological data and the computational intensity of modern biomedical research demand transformative solutions. High-Performance Computing (HPC) and Artificial Intelligence (AI) have emerged as pivotal technologies driving innovation in bioinformatics. The combination of AI and HPC has revolutionized genomics, drug discovery, and precision medicine. This special issue invited review and research articles on the latest trends in HPC and AI technologies for biomedical and biological research. Overall 8 papers were accepted in this issue covering a wide range of research areas, including virtual drug screening, biological sequence analysis, drug-target interaction/drug-disease association, metagenomics etc.}
}
@article{PELTIER2025100059,
title = {Exploring wellness and Wiidooktaadyang (we are helping one another) in Nipissing First Nation11This paper uses the community's name, Nipissing First Nation.},
journal = {First Nations Health and Wellbeing - The Lowitja Journal},
volume = {3},
pages = {100059},
year = {2025},
issn = {2949-8406},
doi = {https://doi.org/10.1016/j.fnhli.2025.100059},
url = {https://www.sciencedirect.com/science/article/pii/S2949840625000178},
author = {Cindy Peltier and Louela Manankil-Rankin and Karey McCullough and Megan Paulin and Phyllis Anderson and Kanessa Hanzlik},
keywords = {Indigenous wellness, Indigenous health, Indigenous self-determination, Conceptual model, Two-Eyed Seeing},
abstract = {Purpose
First Nations peoples have a long history of what it means to be well, but this perspective has not shaped their health and wellness experiences in Canadian healthcare systems. In response to calls for First Nation self-determination in health, this study provided one First Nation community with the opportunity to articulate what it means to be well. Wiidooktaadyang, meaning ‘we are helping each other’, describes a Nipissing First Nation (NFN) philosophy and a relational approach to realising wellness. From this relational approach, this research explored: 1) how NFN debendaagziwaad (NFN members) on reserve, off reserve and staff understood and experienced wellness; 2) what NFN debendaagziwaad perceived as the ‘appropriate kind of help’ to facilitate wellness; and 3) how understandings of wellness and helping can inform a community-owned service delivery model.
Methods
Designed with an NFN advisory committee, this study employed a qualitative design using a Two-Eyed Seeing theoretical and methodological approach, which paired participatory action research with Indigenous research methods. Ninety participants, grouped according to on reserve, off reserve or staff members, engaged in conversational interviews with community-based research assistants. Their stories were analysed using thematic analysis adhering to Indigenous research principles.
Main findings
The story of wellness of NFN debendaagziwaad comprised five themes: 1) Connectedness, 2) Living the Medicine Wheel, 3) Belonging, 4) Experiencing colonialism and 5) Reclaiming NFN ways. Graphic artists facilitated a process of graphical analysis to illustrate themes as conceptual models. This project moved knowledge into meaningful action by meeting with NFN leaders to describe how they could apply the wellness models to their service integration model.
Principal conclusions
This paper contributes to new knowledge by documenting NFN members’ stories of what it means to be well and their recommendations for reclaiming wellness. The knowledge helped to inform community service planning in a First Nations community. Particularly critical is that the models acknowledge First Nation peoples’ power to determine their health and wellness experiences.}
}
@article{LUO2023e21333,
title = {FOXD1 expression-based prognostic model for uveal melanoma},
journal = {Heliyon},
volume = {9},
number = {11},
pages = {e21333},
year = {2023},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2023.e21333},
url = {https://www.sciencedirect.com/science/article/pii/S2405844023085419},
author = {Yang Luo and Renhao Ni and Xiaojun Jin and Peipei Feng and Chenyi Dai and Lingjing Jiang and Pingping Chen and Lu Yang and Yabin Zhu},
keywords = {, Uveal melanoma, Patient survival, Treatment sensitivity, Prognostic model},
abstract = {FOXD1, a new member of the FOX transcription factor family, serves as a mediator and biomarker for cell reprogramming. But its contribution to prognosis of uveal melanoma (UVM) is unclear. This study demonstrated that FOXD1 might promote tumor growth and invasion, because FOXD1 expression was negatively correlated with overall survival, progression-free survival, and disease-specific survival in UVM patients. This conjecture was verified in cell culture with human uveal melanoma cell line (MUM2B) as model cells. Additionally, the biological mechanisms of FOXD1 based on FOXD1-related genomic spectrum, molecular pathways, tumor microenvironment, and drug treatment sensitivity were examined using The Cancer Genome Atlas (TCGA) database, aiming to reasonably explain why FOXD1 leads to poor prognosis of UVM. On these bases, a novel tumor prognostic model was established using the FOXD1-related immunomodulators TMEM173, TNFRSF4, TNFSF13, and ULBP1, which will enable the stratification of disease seriousness and clinical treatment for patients.}
}
@article{TOLKSDORF2019670,
title = {Customized code generation based on user specifications for simulation and optimization},
journal = {Computers & Chemical Engineering},
volume = {121},
pages = {670-684},
year = {2019},
issn = {0098-1354},
doi = {https://doi.org/10.1016/j.compchemeng.2018.12.006},
url = {https://www.sciencedirect.com/science/article/pii/S0098135418306987},
author = {Gregor Tolksdorf and Erik Esche and Günter Wozny and Jens-Uwe Repke},
keywords = {MathML model, Model transformation, Code generation, Customized simulation},
abstract = {Model-driven software engineering is a well-known concept in computer science, but scarcely applied in chemical engineering. This contribution presents a first implementation of model-driven development of customized code for simulation and optimization based on equation-oriented models in process science. Transferring the model-driven approach to chemical engineering allows for transformations or discretizations before automated code generation. The customization of this concept poses additional challenges regarding flexibility and tailoring for the user’s needs. We propose the so-called “User-defined Language Specificators (UDLS)”, based on free standards (MathML, XML), to combine the benefits of automated code generation with the flexibility of customization, therefore still avoiding error-prone manual model implementation. The case studies show the successful application of this approach for equation-based flowsheet simulation (using CAPE-OPEN interfaces) as well as optimization.}
}
@article{VOGEL2022100021,
title = {Attending to and transforming power dynamics in translanguaged research relationships and methodology},
journal = {Research Methods in Applied Linguistics},
volume = {1},
number = {3},
pages = {100021},
year = {2022},
issn = {2772-7661},
doi = {https://doi.org/10.1016/j.rmal.2022.100021},
url = {https://www.sciencedirect.com/science/article/pii/S2772766122000180},
author = {Sara Vogel},
keywords = {Translanguaging methodology, Positionality, Research relationships, Power dynamics},
abstract = {In this response to Lee (2022), I posit that translanguaging has prompted a re-evaluation of applied linguistics and sociolinguistics methodology in part because the theory has implicated issues of power dynamics and coloniality into the study of language. For this, if researchers wish to conduct research from translanguaging perspectives, it becomes necessary to recognize and attend to power dynamics in research design and methodology. This piece suggests some guiding questions for addressing power dynamics in one aspect of translanguaging methodology — forming research relationships. It explores how, in our relationships to our fields, we might promote answerability (Patel, 2014) for the roles our fields have played in the linguistic hierarchization that translanguaging resists. Second, it explores how research relationships with participants might be made more equitable through researcher reflexivity.}
}
@article{DEBNATH2025100325,
title = {CovKG: A Covid-19 Knowledge Graph for enabling multidimensional analytics on Covid-19 epidemiological data considering spatiotemporal, environmental, health, and socioeconomic aspects},
journal = {International Journal of Information Management Data Insights},
volume = {5},
number = {1},
pages = {100325},
year = {2025},
issn = {2667-0968},
doi = {https://doi.org/10.1016/j.jjimei.2025.100325},
url = {https://www.sciencedirect.com/science/article/pii/S2667096825000072},
author = {Rudra Pratap {Deb Nath} and S.M. Shafkat Raihan and Tonmoy Chandro Das and Torben Bach Pedersen and Debasish Ghose},
keywords = {Knowledge Graph, Covid-19, Multidimensional analysis, FAIR principles, Linked data, Semantic technology},
abstract = {The Covid-19 pandemic is influenced by many environmental, health, and socioeconomic aspects such as air pollution, comorbidity, occupation, etc. To better manage future pandemics, decision-makers need comprehensive data on Covid-19 mortality and morbidity. Most Covid-19 data sources focus on spatiotemporal aspects, and existing research often overlook the combined impact of multiple interconnected factors. This study introduces a Covid-19 Knowledge Graph (CovKG) derived from 20 data sources, enabling multidimensional analysis of epidemiological data, including time, location, temperature, comorbidity, occupation, and others. CovKG is modeled using RDF, connected to 10,951 external resources, and semantically enriched with Data Cube (QB) and QB for OLAP (QB4OLAP) vocabularies to adhere to the FAIR principles and ensure OLAP compatibility. Finally, we perform a qualitative and comparative evaluation and extract statistical insights across multiple dimensions of Covid-19 epidemiology. When assessed, CovKG answers 100% of competency queries, outperforming other data stores that only answer 39%. CovKG and its analytical interface are available at https://bike-csecu.com/datasets/CovKG/.}
}
@article{FERTIER2020113260,
title = {A new emergency decision support system: the automatic interpretation and contextualisation of events to model a crisis situation in real-time},
journal = {Decision Support Systems},
volume = {133},
pages = {113260},
year = {2020},
issn = {0167-9236},
doi = {https://doi.org/10.1016/j.dss.2020.113260},
url = {https://www.sciencedirect.com/science/article/pii/S0167923620300154},
author = {Audrey Fertier and Anne-Marie Barthe-Delanoë and Aurélie Montarnal and Sébastien Truptil and Frédérick Bénaben},
keywords = {Information system, Emergency decision support system, Complex event processing, Big Data, Situation awareness, Crisis management},
abstract = {This paper studies, designs and implements a new type of emergency decision support system that aims to improve the decision-making of emergency managers in crisis situations by connecting them to new, multiple data sources. The system combines event-driven and model-driven architectures and is dedicated to crisis cells. After its implementation, the system is evaluated using a realistic crisis scenario, in terms of its user interfaces, its ability to interpret data in real time and its ability to manage the 4Vs of Big Data. The input events correspond to traffic measurements, water levels, water flows, water predictions and flow predictions made available by French official services. The main contributions of this study are: (i) the connection between a complex event processing engine and a graph database containing the model of the crisis situation and (ii) the continuous updating of a common operational picture for the benefit of emergency managers. This study could be used as a framework for future research works on decision support systems facing complex, evolving situations.}
}
@article{ALSHARHAN2019121,
title = {An integrated holistic model for an eHealth system: A national implementation approach and a new cloud-based security model},
journal = {International Journal of Information Management},
volume = {47},
pages = {121-130},
year = {2019},
issn = {0268-4012},
doi = {https://doi.org/10.1016/j.ijinfomgt.2018.12.009},
url = {https://www.sciencedirect.com/science/article/pii/S0268401217305273},
author = {Salah Al-Sharhan and Esraa Omran and Kamran Lari},
keywords = {Holistic eHealth model, EHealth services, eHealth cloud, EHR security, Integrated eHealth framework},
abstract = {Although its structure and strategies are rapidly evolving, the impact of the eHealth on the healthcare services is evident. Implementing eHealth systems on a national level can drastically enhance the health practices and services provided to the patients and community. Hence, the engineering of a new model and a holistic framework for eHealth systems becomes a necessity in order to have an effective implementation of these systems. The vast and rapid development in computers, communication, and Internet technologies has significantly affected the contemporary health systems. However, the complexity of the healthcare environment, the abundance of information, the compatibility and the lack of unified eHealth framework creates real challenges to present efficient and attractive eHealth model that encompasses all these elements. Furthermore, the security of the health records and the secure access to the information add a new dimension of complexity. This work presents a new model and an integrated framework for an efficient implementation of eHealth systems at the national level. The proposed model and framework successfully incorporate all the success factors of efficient eHealth system along with a new security model to access the health records.}
}
@article{NORTHOFF2025173,
title = {Brain dynamics shape cognition–Spatiotemporal Neuroscience},
journal = {Physics of Life Reviews},
volume = {54},
pages = {173-201},
year = {2025},
issn = {1571-0645},
doi = {https://doi.org/10.1016/j.plrev.2025.07.009},
url = {https://www.sciencedirect.com/science/article/pii/S157106452500106X},
author = {Georg Northoff and Angelika Wolman and Jianfeng Zhang},
keywords = {Cognition, Neural dynamics, Intrinsic neural timescales, Variability, Background-foreground},
abstract = {Current neuroscience faces a divide between cognitive function and neural dynamics. Cognitive function is typically studied during task-related activity, while neural dynamics are a key feature of the brain’s spontaneous activity, as measured in the resting state. How are dynamics and cognition connected? Although neural dynamics themselves are well understood, their relationship to—and influence on—cognitive functions remain yet unclear. Addressing this gap is the goal of our paper. For that purpose, we first review recent findings on how dynamic features like neural variability and intrinsic neural timescales (INT) shape various cognitive functions. We then expand our view beyond task-specific foreground activity to the deeper background layers of the brain’s neural activity—its task-unspecific and spontaneous activity. This leads us to propose a Dynamic Layer Model of the Brain (DLB). Drawing on empirical and computational evidence, we demonstrate how neural variability, INT, and other dynamic features (such as scale-free dynamics) connect these three layers of neural activity. Next, we show how these three layers from spontaneous over task-unspecific to task-specific activity mediate four temporal mechanisms through which brain dynamics shape cognition: these range from temporal encoding and integration of input dynamics to temporal scaffolding and segmentation of cognitive output. We conclude that the brain’s neural dynamics operate in the background, shaping the cognitive functions and their contents in the neural foreground in a temporal-dynamic manner. This perspective is at the core of Spatiotemporal Neuroscience, which provides a wider framework than Cognitive Neuroscience by revealing how the brain’s intrinsic dynamics shape our cognition.}
}
@article{RUAN2021121071,
title = {Rethinking the disruption index as a measure of scientific and technological advances},
journal = {Technological Forecasting and Social Change},
volume = {172},
pages = {121071},
year = {2021},
issn = {0040-1625},
doi = {https://doi.org/10.1016/j.techfore.2021.121071},
url = {https://www.sciencedirect.com/science/article/pii/S0040162521005035},
author = {Xuanmin Ruan and Dongqing Lyu and Kaile Gong and Ying Cheng and Jiang Li},
keywords = {Disruption index, Number of references, Regression analysis},
abstract = {Wu et al. (2019) used the disruption(D) index to measure scientific and technological advances in Nature. Their findings spurred extensive discussion in academia on whether we can measure the disruption (i.e., innovation or novelty) of a research paper or a patent based on the number of citations. In this paper, we calculate the D index of ∼0.76 million publications published between 1954 and 2013 in six disciplines including both sciences and social sciences in English and Chinese. We found that the number of references has a negative effect on the D index of a paper with a relatively small number of references, and a positive effect on the D index of a paper with a large number of references. We also found that low coverage of a citation database boosts D values. Specifically, low coverage of non-journal literature in the Web of Science (WOS) boosted D values in social sciences, and the exclusion of non-Chinese language literature in the Chinese Social Sciences Citation Index (CSSCI) resulted in the inflation of D values in Chinese language literature. Limitations of the D index observed in scientific papers also exist in technological patents. This paper sheds light on the use of citation-based measurements of scientific and technological advances and highlights the limitations of this index.}
}
@article{SCHMELING2025102063,
title = {Data collaboration in digital government research: A literature review and research agenda},
journal = {Government Information Quarterly},
volume = {42},
number = {3},
pages = {102063},
year = {2025},
issn = {0740-624X},
doi = {https://doi.org/10.1016/j.giq.2025.102063},
url = {https://www.sciencedirect.com/science/article/pii/S0740624X25000577},
author = {Juliane Schmeling and Sami {al Dakruni} and Ines Mergel},
keywords = {Data collaboration, Data ecosystem, Data space, Computational literature review, Structural topic modelling, Digital government},
abstract = {Sovereign data infrastructures are a central building block of the European Data Strategy, yet little is known about how public administrations share and collaborate on both open and restricted data. This research addresses the gap by systematically analysing the existing literature on data collaboration within the field of digital government research. We thereby make a methodological contribution to digital government research through a rigorous literature review framework that includes Structural Topic Modelling to understand the different themes of the scientific discussion in the field of digital government. We propose an innovative data collaboration framework that includes the ecosystem, the organisational, and the individual levels, enhancing our understanding of the multidimensional nature of data collaboration. Our analysis reveals that while the emphasis is on innovation and participation, critical aspects like standardisation and data management have a declining topic prevalence, despite their importance in developing federated data ecosystems. This comprehensive analysis not only sheds light on the current landscape but also informs a structured research agenda in digital government, aiming to contribute to the advancement of the field.}
}
@article{GYORI2021100362,
title = {From knowledge to models: Automated modeling in systems and synthetic biology},
journal = {Current Opinion in Systems Biology},
volume = {28},
pages = {100362},
year = {2021},
issn = {2452-3100},
doi = {https://doi.org/10.1016/j.coisb.2021.100362},
url = {https://www.sciencedirect.com/science/article/pii/S2452310021000561},
author = {Benjamin M. Gyori and John A. Bachman},
keywords = {Systems biology, Synthetic biology, Modeling, Dynamical modeling, Rule-based modeling, Text mining, Automated modeling},
abstract = {Building computational models of biological mechanisms involves collecting and synthesizing knowledge about the underlying system and encoding it in an appropriate mathematical form. While this process typically requires substantial manual effort from human experts, key aspects of the modeling process are increasingly being automated or augmented by software tools, allowing for the efficient creation of large models or model ensembles. In this review, we introduce a framework for discussing modeling automation by positioning recent work into three ‘levels’, with the human and the machine taking on different responsibilities at each level. We outline the strengths and weaknesses of current modeling approaches at the different levels and discuss the prospect of fully automated fit-to-purpose modeling of biological systems.}
}
@article{HOU2022107621,
title = {Method and dataset entity mining in scientific literature: A CNN + BiLSTM model with self-attention},
journal = {Knowledge-Based Systems},
volume = {235},
pages = {107621},
year = {2022},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2021.107621},
url = {https://www.sciencedirect.com/science/article/pii/S0950705121008832},
author = {Linlin Hou and Ji Zhang and Ou Wu and Ting Yu and Zhen Wang and Zhao Li and Jianliang Gao and Yingchun Ye and Rujing Yao},
keywords = {Literature analysis, Named entity recognition, Methods and datasets mining, CNN+BiLSTM-Attention-CRF structure},
abstract = {The traditional literature analysis mainly focuses on the literature metadata such as topics, authors, keywords, references, and rarely pays attention to the main content of papers. However, in many scientific domains such as science, computing, engineering, the methods and datasets involved in the papers published carry important information and are quite useful for domain analysis and recommendation. Method and dataset entities have various forms, which are more difficult to recognize than common entities. In this paper, we propose a novel Method and Dataset Entity Recognition model (MDER), which is able to effectively extract the method and dataset entities from the main textual content of scientific papers. The model is the first to combine rule embedding, a parallel structure of Convolutional Neural Network (CNN) and a two-layer Bi-directional Long Short-Term Memory (BiLSTM) with the self-attention mechanism. We evaluate the proposed model on datasets constructed from the published papers of different research areas in computer science. Our model performs well in multiple areas and features a good capacity for cross-area learning and recognition. Ablation study indicates that building different modules collectively contributes to the good entity recognition performance as a whole. The data augmentation positively contributes to model training, making our model much more robust. We finally apply the proposed model on PAKDD papers published from 2009–2019 to mine insightful results over a long time span.11PAKDD is the abbreviation of Pacific-Asia Conference on Knowledge Discovery and Data Mining. Our source code and datasets are available at https://github.com/houlinlinvictoria/MDER.}
}
@article{LEE20191952,
title = {An Efficient Design Support System based on Automatic Rule Checking and Case-based Reasoning},
journal = {KSCE Journal of Civil Engineering},
volume = {23},
number = {5},
pages = {1952-1962},
year = {2019},
issn = {1226-7988},
doi = {https://doi.org/10.1007/s12205-019-1750-2},
url = {https://www.sciencedirect.com/science/article/pii/S1226798824033658},
author = {Pin-Chan Lee and Tzu-Ping Lo and Ming-Yang Tian and Danbing Long},
keywords = {automatic rule checking, building information modelling, case-based reasoning, design support system, AHP, TOPSIS},
abstract = {A well building design support system can not only meet the rules but also automatically recommend the appropriate alternatives for designers, but most modifications now are conducted in the manual way. Although the method of automatic rule checking can effectively identify the compliance of rules in Building Information Modeling (BIM) models, recommendation supports are still lacked in applications. This paper aims to propose a design support system, using automatic rule checking to identify the compliance of rules and adopting case-based reasoning to provide recommendations via ontology and semantics. The AHP-TOPSIS (Analytic hierarchy process-Technique for Order Preference by Similarity to an Ideal Solution) method is used to give reliable recommendations rank. A real case is adopted as an illustrative example. Results show that the proposed system can increase the design efficiency in both design checking and modifying. Similar applications can be extended to other fields and rules.}
}
@article{LI2023107370,
title = {Analysis of a new therapeutic target and construction of a prognostic model for breast cancer based on ferroptosis genes},
journal = {Computers in Biology and Medicine},
volume = {165},
pages = {107370},
year = {2023},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2023.107370},
url = {https://www.sciencedirect.com/science/article/pii/S0010482523008351},
author = {Qi Li and Hengchen Liu and Yun Jin and Yuanquan Yu and Yihang Wang and Di Wu and Yinghao Guo and Longfu Xi and Dan Ye and Yanzhi Pan and Xiaoxiao Zhang and Jiangtao Li},
keywords = {Ferroptosis, Prognostic model, Immunotherapy targets, Breast cancer},
abstract = {Breast cancer, which is the most common malignant tumor among women worldwide and an important cause of death in women. The existing prognostic model for patients with breast cancer is not accurate as breast cancer is resistant to commonly used antitumor drugs. Ferroptosis is a novel mechanism of programmed cell death that depends on iron accumulation and lipid peroxidation. Various studies have confirmed the role of ferroptosis in tumor regulation and ferroptosis is now considered to play an important role in breast cancer development. At present, the association between breast cancer prognosis and ferroptosis-related gene expression remains unclear. Further exploration of this research area may optimize the evaluation and prediction of prognosis of patients with breast cancer and finding of new therapeutic targets. In this study, clinical factors and the expression of multiple genes were evaluated in breast cancer samples from the Cancer Genome Atlas (TCGA) database and Gene Expression Omnibus (GEO) database database. Eleven prognostication-related genes (TP63, IFNG, MT3, ANO6, FLT3, PTGS2, SLC1A4, JUN, SLC7A5, CHAC1, and TF) were identified from differentially expressed genes to construct a survival prediction model, which showed a good prediction ability. KEGG pathway analysis revealed that immune-related pathways were the primary pathways. ssGSEA analysis showed significant differences in the distribution of certain immune-related cell subsets, such as CD8+T cells and B cells, and in the expression of multiple immune genes, including type II IFN response and APC coinhibition. In addition, 10 immune targets related to ferroptosis in breast cancer were found: CD276, CD80, HHLA2, LILRA2, NCR3LG1, NECTIN3, PVR, SLAMF9,TNFSF4, and BTN1A1. Using TCGA, new ferroptosis genes related to breast cancer prognosis were identified, a new reliable and accurate prognosis model was developed, and 10 new potential therapeutic targets different from the traditional targeted drugs were identified to provide a reference for improving the poor prognosis of patients with breast cancer.}
}
@article{ARSHAD2022558,
title = {Semantic Attribute-Based Encryption: A framework for combining ABE schemes with semantic technologies},
journal = {Information Sciences},
volume = {616},
pages = {558-576},
year = {2022},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2022.10.132},
url = {https://www.sciencedirect.com/science/article/pii/S0020025522012610},
author = {Hamed Arshad and Christian Johansen and Olaf Owe and Pablo Picazo-Sanchez and Gerardo Schneider},
keywords = {Attribute-based encryption, Semantic technologies, Security, Interoperability, Privacy, Access control, Ontology},
abstract = {Attribute-Based Encryption (ABE) is a cryptographic solution to protect resources in a fine-grained manner based on a set of public attributes. This is similar to attribute-based access control schemes in the sense that both rely on public attributes and access control policies to grant access to resources. However, ABE schemes do not consider the semantics of attributes provided by users or required by access structures. Such semantics not only improve the functionality by making proper access decisions but also enable cross-domain interoperability by making users from one domain able to access and use resources of other domains. This paper proposes a Semantic ABE (SABE) framework by augmenting a classical Ciphertext-Policy ABE (CP-ABE) scheme with semantic technologies using a generic procedure by which any CP-ABE scheme can be extended to an SABE. The proposed SABE framework is implemented in Java and the source code is publicly available. The experiment results confirm that the performance of the proposed framework is promising.}
}
@article{RADIO2019752,
title = {A survey of time based approaches for linked data},
journal = {Library Hi Tech},
volume = {37},
number = {4},
pages = {752-763},
year = {2019},
issn = {0737-8831},
doi = {https://doi.org/10.1108/LHT-04-2019-0084},
url = {https://www.sciencedirect.com/science/article/pii/S0737883119000010},
author = {Erik Radio},
keywords = {Information retrieval, Technology, Metadata, Ontologies, Resource description framework, Bibliographic standards},
abstract = {Purpose
Linked data technologies promise different ways of querying and retrieving information that enable individuals to have search experiences that are broader and more coordinated than those common in current library technologies. It is vital that information technologies be able to incorporate temporal capabilities or reasoning to allow for the more nuanced interactions with resources, particularly as they change over time. The purpose of this paper is to assess methods currently in use that allow for temporal querying of resources serialized as linked data.
Design/methodology/approach
This paper examines philosophical models, experimental approaches and common standards to identify areas of alignment and divergence in their orientations toward serializing time and change as linked data. By framing approaches and standards within the context of philosophical theories, a clear preference for certain models of time emerge.
Findings
While there have been several approaches to serializing time as linked data, none have found their way into a full implementation by standards in common use. Further, approaches to the issue are largely rooted in one model of philosophical thought that is particularly oriented to computational approaches. As such there is a gap between methods and standards, and a large room for further investigation into temporal models that may be applicable for different contexts. A call for investigation into a model that can cascade in to different temporal approaches is provided.
Originality/value
While there are many papers concerning serializing time as linked data, none have tried to thoroughly align these to philosophical theories of time and further to standards currently in use.}
}
@article{EDDAMIRI2020223,
title = {RDF graph mining for cluster-based theme identification},
journal = {International Journal of Web Information Systems},
volume = {16},
number = {2},
pages = {223-247},
year = {2020},
issn = {1744-0084},
doi = {https://doi.org/10.1108/IJWIS-10-2019-0048},
url = {https://www.sciencedirect.com/science/article/pii/S1744008420000233},
author = {Siham Eddamiri and Asmaa Benghabrit and Elmoukhtar Zemmouri},
keywords = {Clustering, Linked data, Machine learning, Word embedding, RDF graph, Theme Identification},
abstract = {Purpose
The purpose of this paper is to present a generic pipeline for Resource Description Framework (RDF) graph mining to provide a comprehensive review of each step in the knowledge discovery from data process. The authors also investigate different approaches and combinations to extract feature vectors from RDF graphs to apply the clustering and theme identification tasks.
Design/methodology/approach
The proposed methodology comprises four steps. First, the authors generate several graph substructures (Walks, Set of Walks, Walks with backward and Set of Walks with backward). Second, the authors build neural language models to extract numerical vectors of the generated sequences by using word embedding techniques (Word2Vec and Doc2Vec) combined with term frequency-inverse document frequency (TF-IDF). Third, the authors use the well-known K-means algorithm to cluster the RDF graph. Finally, the authors extract the most relevant rdf:type from the grouped vertices to describe the semantics of each theme by generating the labels.
Findings
The experimental evaluation on the state of the art data sets (AIFB, BGS and Conference) shows that the combination of Set of Walks-with-backward with TF-IDF and Doc2vec techniques give excellent results. In fact, the clustering results reach more than 97% and 90% in terms of purity and F-measure, respectively. Concerning the theme identification, the results show that by using the same combination, the purity and F-measure criteria reach more than 90% for all the considered data sets.
Originality/value
The originality of this paper lies in two aspects: first, a new machine learning pipeline for RDF data is presented; second, an efficient process to identify and extract relevant graph substructures from an RDF graph is proposed. The proposed techniques were combined with different neural language models to improve the accuracy and relevance of the obtained feature vectors that will be fed to the clustering mechanism.}
}
@article{ZHOU2025106106,
title = {Deep learning for named entity recognition in extracting critical information from struck-by accidents in construction},
journal = {Automation in Construction},
volume = {173},
pages = {106106},
year = {2025},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2025.106106},
url = {https://www.sciencedirect.com/science/article/pii/S0926580525001463},
author = {Zhipeng Zhou and Lixuan Wei and Haiying Luan},
keywords = {Struck-by accident, Named entity recognition, Deep learning, BERT, LSTM},
abstract = {Automatic extraction of critical information from accident reports is helpful for mitigating and controlling hazards. This paper focuses on struck-by accidents in construction and describes the process of extracting information through named entity recognition (NER). Seven entity types were identified, including accident, person, equipment, location, injured area, injured condition, and fatality. Deep learning models were trained involving bidirectional encoder representation from transformers (BERT), integration of BERT with long-short term memory (BERT-LSTM), and BERT-LSTM with conditional random fields (CRF) as a constraint. Compared with other deep learning models, BERT-LSTM achieved a better performance with F1-score of 0.91 across all entity types. It improved efficiency and accuracy of automatic extraction of critical risk factors through constructing an exclusive dictionary for struck-by accidents and developing the BERT-LSTM model. In-depth analysis of accident data provided a reference for identifying accident occurrence patterns, providing a scientific foundation for prevention strategies and safety training of construction workers on site.}
}
@article{GALLEGO2020103568,
title = {An encoder–decoder approach to mine conditions for engineering textual data},
journal = {Engineering Applications of Artificial Intelligence},
volume = {91},
pages = {103568},
year = {2020},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2020.103568},
url = {https://www.sciencedirect.com/science/article/pii/S0952197620300531},
author = {Fernando O. Gallego and Rafael Corchuelo},
keywords = {Condition mining, Natural language processing, Neural networks},
abstract = {Data engineering seeks to support artificial intelligence processes that extract knowledge from raw data. Many such data are rendered in natural language from which entity-relation extractors extract facts and opinion miners extract opinions; the goal of condition mining is to mine the conditions that have an influence on them. In this article, a new condition mining method is proposed. It relies on a deep neural network and attempts to overcome the limitations of existing methods for condition mining that we reviewed. The materials used include readily-available software components for natural language processing and a large multi-lingual, multi-topic dataset. The common information retrieval performance measures were used to assess the results, namely: precision, which is the fraction of correct conditions to the mined ones, recall, which is the fraction of correct conditions that have been mined to the total number of correct conditions, and the F1 score, which is the harmonic mean of precision and recall. The results of the experimental analysis prove that the new proposal can attain an F1 score that is significantly greater than with existing methods. Furthermore, a comprehensive analysis of the dataset was performed, which revealed two key findings: the connectives follows a long-tail distribution and the conditions are quite dissimilar from a semantic point of view.}
}
@article{SOERENSEN2024103914,
title = {“Safety Means Everything”: An ethnographic methodology to explore the formation of professional identity in nursing students},
journal = {Nurse Education in Practice},
volume = {76},
pages = {103914},
year = {2024},
issn = {1471-5953},
doi = {https://doi.org/10.1016/j.nepr.2024.103914},
url = {https://www.sciencedirect.com/science/article/pii/S147159532400043X},
author = {Jette Soerensen and Mari Holen and Ida Skytte Jakobsen and Palle Larsen and Dorthe Susanne Nielsen},
keywords = {Critical psychology, Nursing education, Practice Research, Professional identity, Fieldwork, Qualitative Research},
abstract = {Aim
The aim of this qualitative study is to explore how various conditions within educational contexts impact nursing students’ experiences of becoming professional nurses and how these conditions affect their agency and the formation of their professional identities.
Background
Nursing education is essential to becoming professional and competent in caring for patients. A strong professional identity in nursing contributes to better patient outcomes and improves the well-being, retention, and recruitment of practitioners in the health care system. At the same time, research indicates that development of a professional identity during education is challenging and needs further investigation.
Design
The qualitative research design draws on the theoretical and methodological framework of critical psychology practice research. The practice research design and close collaboration with users ensure the continuous development and implementation of theory and practice.
Methods
The data used in this study originated from ethnographic fieldwork, which involved following two nursing students through their final clinical placement training at the Geriatric Department of a university hospital in Denmark. Additionally, nursing students in two classes were observed as part of their nursing education practice at a university college from April to July 2022. The participant observational design, combined with in-situ interviewing, facilitated a comprehensive understanding of the students’ engagement in social practices and interactions within the context of nursing education.
Results
Our results show how the conditions of nursing students’ everyday lives have a critical impact on their self-understanding and journey to becoming competent and professional nurses. Three main themes emerged from the analysis: (1) Perception of safety, (2) Motivation for learning in different communities of practice, and (3) The meaning of learning culture and role models.
Conclusion
The development of nursing students into professionals is profoundly influenced by factors affecting their ontological safety that are deeply embedded in socio-cultural and educational contexts. The results underscore the need to foster ontological safety in nursing education. Creating safe, participatory, and supportive learning environments is essential to the holistic development of students into caring, competent nurses. Educators and stakeholders must remember their crucial role in this context and focus on establishing these environments to facilitate students’ sense of belonging in the nursing profession.
Tweetable Abstract
The development of professional identity in nursing starts with safety. Ontological Safety in learning environments ensures competent and professional nurses. #NursingEducation#Safety#ProfessionalIdentity}
}
@article{SABATUCCI2025107721,
title = {Personalization goals for run-time adaptation of IoT-based assistance applications for the elderly},
journal = {Information and Software Technology},
volume = {182},
pages = {107721},
year = {2025},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2025.107721},
url = {https://www.sciencedirect.com/science/article/pii/S0950584925000606},
author = {Luca Sabatucci and Claudia {Di Napoli}},
keywords = {Personalized Ambient Assisted Living, Goal modelling, Internet of Things},
abstract = {Context:
the increasing demand for Ambient Assisted Living (AAL) applications has led to the need for personalized assistive tasks that can adapt to individual users’ needs.
Objectives:
we aim to balance design-time personalization with techniques of run-time adaptation for designing and executing assistive AAL applications, personalized to both users’ specific needs and environmental conditions.
Methods:
we propose a personalization process based on: (1) representing assistive tasks as workflows initially defined at a high level of abstraction that specifies their functional components, (2) providing an instrument for specifying how to customize these workflows for individual users, and (3) a supporting architecture that enables the run-time transformation of high-level specifications into executable workflows.
Results:
our empirical evaluation demonstrates that the proposed personalization goals effectively support designers in creating adaptable workflows, showing improved quality scores in personalization compared to traditional BPMN practices, without increasing design effort. Performance analysis also shows the feasibility of our run-time adaptation approach with linear scaling as the number of personalization goals increases.
Conclusion:
a personalization process for modelling personalizable workflows may be a flexible instrument for designers to conceive assistive applications that are automatically adapted to individual users’ needs at run-time, allowing for balancing the benefits of design-time and run-time personalization techniques.}
}
@article{LOVE2023102024,
title = {Explainable artificial intelligence (XAI): Precepts, models, and opportunities for research in construction},
journal = {Advanced Engineering Informatics},
volume = {57},
pages = {102024},
year = {2023},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2023.102024},
url = {https://www.sciencedirect.com/science/article/pii/S1474034623001520},
author = {Peter E.D. Love and Weili Fang and Jane Matthews and Stuart Porter and Hanbin Luo and Lieyun Ding},
keywords = {Construction, Deep learning, Explainability, Interpretability, Machine learning, XAI},
abstract = {Machine learning (ML) and deep learning (DL) are both branches of AI. As a form of AI, ML automatically adapts to changing datasets with minimal human interference. Deep learning is a subset of ML that uses artificial neural networks to imitate the learning process of the human brain. The ‘black box’ nature of ML and DL makes their inner workings difficult to understand and interpret. Deploying explainable artificial intelligence (XAI) can help explain why and how the output of ML and DL models are generated. As a result, understanding a model’s functioning, behavior, and outputs can be garnered, reducing bias and error and improving confidence in decision-making. Despite providing an improved understanding of model outputs, XAI has received limited attention in construction. This paper presents a narrative review of XAI and a taxonomy of precepts and models to raise awareness about its potential opportunities for use in construction. It is envisaged that the opportunities suggested can stimulate new lines of inquiry to help alleviate the prevailing skepticism and hesitancy toward AI adoption and integration in construction.}
}
@article{JIN20241304,
title = {Lightweighting Process of Digital Twin Information Models for Smart City Services},
journal = {KSCE Journal of Civil Engineering},
volume = {28},
number = {4},
pages = {1304-1320},
year = {2024},
issn = {1226-7988},
doi = {https://doi.org/10.1007/s12205-024-2354-z},
url = {https://www.sciencedirect.com/science/article/pii/S1226798824003738},
author = {Chengquan Jin and Yeongchan Lee and Sanghoon Lee and Changtaek Hyun},
keywords = {Lightweight digital twin, Smart city, Building information modeling (BIM), Geographic information system (GIS)},
abstract = {A smart city digital twin refers to a system designed to digitally replicate real-world city objects in a virtual space and implement real-time synchronization with the real world, thus helping to solve urban problems through various service scenario simulations and data analysis processes. In relation to the development of city information models for implementing the smart city digital twin, many efforts have been made to integrate and utilize BIM-GIS data. However, due to problems with the capacity available for storing large amounts of data, there are limitations in practical applications because it is sometimes difficult to provide numerous realtime services in the era of web environments. Therefore, in this study, a lightweighting process for the Lightweight Digital Twin System was presented as a method to provide various services that a smart city offers based on the digital twin, and a lightweighting method was proposed accordingly. The process and method were verified through the development of a case application for the case of 00 city. It is expected that the Digital Twin System lightweighting method proposed in this study will serve as a basis for efficient city information processing and contribute to facilitating the provision of various smart city-related services.}
}
@article{XIONG2019100966,
title = {Onsite video mining for construction hazards identification with visual relationships},
journal = {Advanced Engineering Informatics},
volume = {42},
pages = {100966},
year = {2019},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2019.100966},
url = {https://www.sciencedirect.com/science/article/pii/S1474034619305397},
author = {Ruoxin Xiong and Yuanbin Song and Heng Li and Yuxuan Wang},
keywords = {Scene graph, Hazards identification, Safety regulations, Ontology, Video mining},
abstract = {Widely-used video monitoring systems provide a large corpus of unstructured image data on construction sites. Although previous developed vision-based approaches can be used for hazards recognition in terms of detecting dangerous objects or unsafe operations, such detection capacity is often limited due to lack of semantic representation of visual relationships between/among the components or crews in the workplace. Accordingly, the formal representation of textural criteria for checking improper relationships should also be improved. In this regard, an Automated Hazards Identification System (AHIS) is developed to evaluate the operation descriptions generated from site videos against the safety guidelines extracted from the textual documents with the assistance of the ontology of construction safety. In particular, visual relationships are modeled as a connector between site components/operators. Moreover, both visual descriptions of site operations and semantic representations of safety guidelines are coded in the three-tuple format and then automatically converted into Horn clauses for reasoning out the potential risks. A preliminary implementation of the system was tested on two separate onsite video clips. The results showed that two types of crucial hazards, i.e., failure to wear a helmet and walking beneath the cane, were successfully identified with three rules from Safety Handbook for Construction Site Workers. In addition, the high-performance results of Recall@50 and Recall@100 demonstrated that the proposed visual relationship detection method is promising in enriching the semantic representation of operation facts extracted from site videos, which may lead to better automation in the detection of construction hazards.}
}
@article{CHEN2024105481,
title = {Shifting research from defect detection to defect modeling in computer vision-based structural health monitoring},
journal = {Automation in Construction},
volume = {164},
pages = {105481},
year = {2024},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2024.105481},
url = {https://www.sciencedirect.com/science/article/pii/S0926580524002176},
author = {Junjie Chen and Isabelle Chan and Ioannis Brilakis},
keywords = {Structural health monitoring (SHM), Computer vision (CV), Machine learning, Defect detection, Defect modeling, Damage information modeling},
abstract = {The last decade has witnessed a plethora of studies on the applications of computer vision (CV) in structural health monitoring (SHM). While effort has been primarily focused on defect detection, increasing studies are tapping into a new area called defect modeling. It remains unclear whether the shifting focus constitutes a systematic transition. This article aims to answer the question by conducting a critical review of CV-based SHM. It is found that the turning of limelight to defect modeling coincides with the proliferation of deep learning (DL) in defect detection. The shift to defect modeling does not mean a resolution of defect detection, but poses higher requirements on its performance in realistic settings (e.g., complex background, instance differentiation). A roadmap is proposed to synergize future defect detection/modeling research. The research contributes to understanding the rapidly evolving landscape of CV-based SHM, and laying out an overarching framework to guide future research.}
}
@article{DESAI20232383,
title = {A Model to Identify Redundancy and Relevancy in Question-Answer Systems of Digital Scholarly Platforms},
journal = {Procedia Computer Science},
volume = {218},
pages = {2383-2391},
year = {2023},
note = {International Conference on Machine Learning and Data Engineering},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2023.01.213},
url = {https://www.sciencedirect.com/science/article/pii/S1877050923002132},
author = {Mitali Desai and Rupa G. Mehta and Dipti P. Rana},
keywords = {Contextual Analysis, Question-answer System, Digital Scholarly Platforms, Word2Vec},
abstract = {Many digital scholarly platforms allow researchers to conduct scientific discussions using their question-answer systems. Such discussions are helpful for emerging as well as established researchers in numerous prospects. In order to rely on such discussions, it is essential to effectively validate these questions and answers based on content as well as context. This will help in finding ‘quality’ content, improving user experience for researchers and acquiring efficient results in realistic applications such as influence analysis, topic modeling, expert finding and recommendation systems. In this research, one of the well-known scholarly platforms, ResearchGate (RG) is focused. Questions and answers of 14,000 researchers from RG are rendered. A qualitative analysis is performed to perceive various anomalies in the rendered data. To resolve these anomalies, we propose a Word2Vec based model that identifies redundancy and relevancy in questions and answers using content as well as context analysis. The proposed model is evaluated on the rendered data and the outcome suggests that the model accurately identifies redundant questions and irrelevant answers from scholarly platforms.}
}
@article{ZAREMBA2025111104,
title = {A modular pipeline for evidence-integrated genome annotation across species: A case study on Schmidtea mediterranea},
journal = {Genomics},
pages = {111104},
year = {2025},
issn = {0888-7543},
doi = {https://doi.org/10.1016/j.ygeno.2025.111104},
url = {https://www.sciencedirect.com/science/article/pii/S088875432500120X},
author = {Anastasiia Zaremba and Małgorzata Marszałek-Zeńczak and Annasha Dutta and Anna Samelak-Czajka and Paulina Jackowiak},
keywords = {Genome annotation, Transcriptome assembly, , Non-model organisms, Functional annotation},
abstract = {Despite advancements in genome annotation tools, challenges persist for non-classical model organisms with limited genomic resources, such as Schmidtea mediterranea. To address these challenges, we developed a flexible and scalable genome annotation pipeline that integrates short-read (Illumina) and long-read (PacBio) sequencing technologies. The pipeline combines reference-based and de novo assembly methods, effectively handling genomic variability and alternative splicing events. To improve splice site detection accuracy, DeepSplice deep learning predictions are used. Functional annotation is conducted to filter out low-confidence transcripts and ensure biological relevance. Applying this pipeline to the asexual strain of S. mediterranea revealed thousands of previously undescribed putative genes and transcripts, and improved the existing gene models, highlighting its utility in annotating complex, underexplored genomes. The modularity and comprehensiveness of our pipeline ensure its adaptability for genome annotation across diverse species, making it a valuable tool for annotating genomes of non-model organisms and supporting broader genomic research. The source code and implementation details are available at https://github.com/Norreanea/SmedAnno.}
}
@article{LI2023979,
title = {Construction of risk response scenarios for the emergency material support system},
journal = {Procedia Computer Science},
volume = {221},
pages = {979-983},
year = {2023},
note = {Tenth International Conference on Information Technology and Quantitative Management (ITQM 2023)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2023.08.077},
url = {https://www.sciencedirect.com/science/article/pii/S1877050923008359},
author = {Longfei Li and Xiaolei Sun and Weilan Suo},
keywords = {Emergency material support system (EMSS), Scenario construction, Ontological method},
abstract = {Abstracts
Representing disaster scenarios and evaluating the emergency material support system (EMSS) is crucial to enhance emergency material support capabilities. Current representation methods for EMSS mostly focused on the task response procedure during emergencies, rarely involved the response process analysis for disaster scenarios. This study utilizes an ontological method to construct a representation of risk response scenarios for the EMSS. It can be achieved by representing scenario feature elements, scenario structure elements, scenario constraint elements, and scenario attribute elements through the four dimensions. The scenario representation can generate different setting schemes for EMSS. An example scenario was presented based on the measures implemented by the Chinese government during the COVID-19 epidemic's closure of Wuhan. The findings of this research can provide valuable support for making risk-informed decisions regarding EMSS.}
}
@article{LIBORIUSSEN2021516,
title = {A learning method of trust building: beyond the performance management of artistic events},
journal = {Qualitative Research in Accounting & Management},
volume = {18},
number = {45},
pages = {516-544},
year = {2021},
issn = {1176-6093},
doi = {https://doi.org/10.1108/QRAM-09-2019-0093},
url = {https://www.sciencedirect.com/science/article/pii/S1176609321000036},
author = {Jakob Mathias Liboriussen and Hanne Nørreklit and Mihaela Trenca},
keywords = {Performance management, Creativity, Pragmatic constructivism, Learning method of trust building},
abstract = {Purpose
This paper aims to address a dilemma raised in the accounting literature on how managers of creative practices can produce and use accounting measurements that support employees’ self-determination to create whilst also building trust in them to work for the interests of the organisation.
Design/methodology/approach
Using pragmatic constructivism as a paradigmatic setting, the paper develops a learning method of trust building as a way for organisations to produce and use accounting measurements. Empirical analysis of the European Capital of Culture Aarhus 2017 demonstrates the method in action.
Findings
The study displays a learning method of trust building as an effective way for organisations to account for their creative practices without intruding on the creative process of the people involved. The method involves proactive judgement and pragmatic observation of the trustworthiness of the actors’ language games, construction of quality in the conceptual structures of management narratives and measurement models, and learning that narrows the gap between the actors’ proactive judgement and the pragmatic observation of trustworthiness. Through such processes, including principles of truth, dialogical interactions, ongoing reflections and co-authorship, trust can be built in self-determining, creative actors to drive intentional results.
Research limitations/implications
The learning method of trust building extends the literature on trust building and on knowledge processes of performance measurement of actors in creative practices.
Originality/value
This is the first attempt in the accounting literature to develop a learning method of trust building.}
}
@article{KAUR2024114342,
title = {Neurostrategy: A scientometric analysis of marriage between neuroscience and strategic management},
journal = {Journal of Business Research},
volume = {170},
pages = {114342},
year = {2024},
issn = {0148-2963},
doi = {https://doi.org/10.1016/j.jbusres.2023.114342},
url = {https://www.sciencedirect.com/science/article/pii/S0148296323007014},
author = {Vaneet Kaur},
keywords = {Dynamic capabilities, Managerial ambidexterity, Managerial attention, Neuroscience, Neurostrategy, Strategic management},
abstract = {This study represents one of the earliest attempts at providing a complete scientometric mapping and a systematic review of the nascent field of neurostrategy. Machine-based algorithms and text-mining have been used to – (a) clarify the dominant concepts at the junction of neuroscience and strategic management; (b) identify the ontological and epistemological foundations of neurostrategy; (c) explain how the scholarly discourse around neurostrategy has evolved; (d) reveal the trends that are gaining traction within neurostrategy research; and (e) develop propositions at the confluence of managerial capabilities, knowledge management, dynamic capabilities, and neurostrategy. The study unveils how neurostrategy represents a quintet of disciplines and lays bare the hypes and hopes surrounding neurostrategy. The study explains how the road that leads to competitive success passes through the development of neuronally intelligent strategies that not only resolve the battle between the organization and its people, but also the one within an organizational decision maker.}
}
@article{PENG2023119901,
title = {Building a knowledge graph for operational hazard management of utility tunnels},
journal = {Expert Systems with Applications},
volume = {223},
pages = {119901},
year = {2023},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2023.119901},
url = {https://www.sciencedirect.com/science/article/pii/S0957417423004025},
author = {Fang-Le Peng and Yong-Kang Qiao and Chao Yang},
keywords = {Knowledge graph, Utility tunnels, Operational hazard management, Decision support},
abstract = {The operational hazard management of the utility tunnel infrastructure is crucial for sustainable and resilient urban development. It not only involves various domain expertise such as safety, pipeline, structure, equipment, and electricity, but also requires timely and efficient access to and decision support from the relevant information of critical resources. However, current operational hazard management practices rely mainly on the experience of engineers, rendering it difficult to ensure management quality, thus increasing the risk of utility tunnel accidents. Hence, a knowledge graph-based decision support approach is proposed herein for the operational hazard management of utility tunnels, which illustrates the ontology design and information extraction from structured field inspection data and unstructured normative text files. The experimental case study demonstrates that this approach can improve the hazard management capabilities of utility tunnels by providing decision aids such as query, analysis, and control measure feedback.}
}
@article{WANG2018136,
title = {A Semantic-checking based Model-driven Approach to Serve Multi-organization Collaboration},
journal = {Procedia Computer Science},
volume = {126},
pages = {136-145},
year = {2018},
note = {Knowledge-Based and Intelligent Information & Engineering Systems: Proceedings of the 22nd International Conference, KES-2018, Belgrade, Serbia},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2018.07.217},
url = {https://www.sciencedirect.com/science/article/pii/S1877050918311918},
author = {Tiexin Wang and Aurelie Montarnal and Sebastien Truptil and Frederick Benaben and Matthieu Lauras and Jacques Lamothe},
keywords = {Multi-organization collaboration, Partners selecting, Model-driven approach, Semantic checks},
abstract = {Multi-organization collaboration, which allows partners focus on their core business, is becoming a trend. Besides the interoperability of each partner, the mechanism of selecting qualified and suitable partners is another key issue to guarantee the success of collaboration. Based on our previous work, this paper aims to provide a model-driven approach to solve the partners selecting problem in building collaboration. In this approach, a meta-model is defined to describe the context of collaboration. All the potential partners’ inputs shall be conformed to this meta-model. In order to select the required partners automatically, semantic checks are combined.}
}
@article{HU2025519,
title = {Investigation of brain structures and potential mechanisms associated with ADHD: Insights from Mendelian randomization and genetic analysis},
journal = {Journal of Affective Disorders},
volume = {379},
pages = {519-528},
year = {2025},
issn = {0165-0327},
doi = {https://doi.org/10.1016/j.jad.2025.03.024},
url = {https://www.sciencedirect.com/science/article/pii/S0165032725003623},
author = {Xiaoyun Hu and Liyu Lin and Zilun Wu},
keywords = {Brain structure, ADHD, MRI, Mendelian randomization, Enrichment analysis},
abstract = {Objective
Despite extensive studies linking brain structure with attention deficit hyperactivity disorder (ADHD), the causal relationships remain unclear. This study employs Mendelian randomization (MR) to assess these associations and explores the underlying mechanisms.
Methods
Utilizing genetic instruments from genome - wide association study (GWAS) data of 83 magnetic resonance imaging (MRI) studies sourced from the psychiatric genomics consortium (PGC) and integrative epidemiology unit (IEU), MR analyses were conducted to investigate the link between brain structures and ADHD. The Allen Human Brain Atlas was used to identify genes associated with significant brain structures, followed by gene ontology (GO), Kyoto encyclopedia of genes and genomes (KEGG), and pathway enrichment analyses, and construction of protein - protein interaction (PPI) networks.
Results
Intersection analysis from two MR studies highlighted 17 brain structures, such as the left caudal and rostral middle frontal volumes and right medial orbitofrontal volume, exhibiting strong negative correlations with ADHD symptoms (FDR < 0.05). These structures span the frontal, temporal, and parietal lobes, among others. Differential expression analysis showed these genes predominantly relate to pervasive developmental and autistic disorders, with functions including modulation of synaptic transmission. KEGG pathways identified neuroactive ligand-receptor interaction as significantly involved. PPI analysis pinpointed key proteins like SLC17A7, CAMK2A, and SST as critical hubs.
Conclusion
This research confirms negative correlations between certain brain structures and ADHD and implicates neuroactive ligand-receptor interactions in its pathogenesis, enhancing our understanding of ADHD's anatomical and genetic bases.}
}
@article{KOOLA201887,
title = {Development of an automated phenotyping algorithm for hepatorenal syndrome},
journal = {Journal of Biomedical Informatics},
volume = {80},
pages = {87-95},
year = {2018},
issn = {1532-0464},
doi = {https://doi.org/10.1016/j.jbi.2018.03.001},
url = {https://www.sciencedirect.com/science/article/pii/S153204641830039X},
author = {Jejo D. Koola and Sharon E. Davis and Omar Al-Nimri and Sharidan K. Parr and Daniel Fabbri and Bradley A. Malin and Samuel B. Ho and Michael E. Matheny},
keywords = {Cirrhosis, Phenotyping, Hepatorenal syndrome, Acute kidney injury, Dimension reduction, Natural language processing},
abstract = {Objective
Hepatorenal Syndrome (HRS) is a devastating form of acute kidney injury (AKI) in advanced liver disease patients with high morbidity and mortality, but phenotyping algorithms have not yet been developed using large electronic health record (EHR) databases. We evaluated and compared multiple phenotyping methods to achieve an accurate algorithm for HRS identification.
Materials and methods
A national retrospective cohort of patients with cirrhosis and AKI admitted to 124 Veterans Affairs hospitals was assembled from electronic health record data collected from 2005 to 2013. AKI was defined by the Kidney Disease: Improving Global Outcomes criteria. Five hundred and four hospitalizations were selected for manual chart review and served as the gold standard. Electronic Health Record based predictors were identified using structured and free text clinical data, subjected through NLP from the clinical Text Analysis Knowledge Extraction System. We explored several dimension reduction techniques for the NLP data, including newer high-throughput phenotyping and word embedding methods, and ascertained their effectiveness in identifying the phenotype without structured predictor variables. With the combined structured and NLP variables, we analyzed five phenotyping algorithms: penalized logistic regression, naïve Bayes, support vector machines, random forest, and gradient boosting. Calibration and discrimination metrics were calculated using 100 bootstrap iterations. In the final model, we report odds ratios and 95% confidence intervals.
Results
The area under the receiver operating characteristic curve (AUC) for the different models ranged from 0.73 to 0.93; with penalized logistic regression having the best discriminatory performance. Calibration for logistic regression was modest, but gradient boosting and support vector machines were superior. NLP identified 6985 variables; a priori variable selection performed similarly to dimensionality reduction using high-throughput phenotyping and semantic similarity informed clustering (AUC of 0.81 – 0.82).
Conclusion
This study demonstrated improved phenotyping of a challenging AKI etiology, HRS, over ICD-9 coding. We also compared performance among multiple approaches to EHR-derived phenotyping, and found similar results between methods. Lastly, we showed that automated NLP dimension reduction is viable for acute illness.}
}
@article{XIE2024119115,
title = {Intelligent maritime question-answering and recommendation system based on maritime vessel activity knowledge graph},
journal = {Ocean Engineering},
volume = {312},
pages = {119115},
year = {2024},
issn = {0029-8018},
doi = {https://doi.org/10.1016/j.oceaneng.2024.119115},
url = {https://www.sciencedirect.com/science/article/pii/S0029801824024533},
author = {Cunxiang Xie and Zhaogen Zhong and Limin Zhang},
keywords = {Maritime traffic management, Knowledge graph, Question answering system, Recommendation system, Graph neural networks},
abstract = {Traditional maritime traffic management typically relies on positioning data for data mining without incorporating other multi-source data to analyze the maritime vessel activity, which cannot conduct comprehensive maritime knowledge mining. Thus, this study integrates multi-source data, such as trajectory, maritime accident text, and geographic data, to create a maritime vessel activity knowledge graph. On this basis, a question-answering model is developed based on a bidirectional question-answering attention graph neural network, and a personalized recommendation model is developed based on an attention-enhanced joint knowledge propagation and a user preference graph neural network. The former assists users in extracting valuable information from the maritime vessel activity knowledge graph, while the latter predicts the users' potential interests and automatically recommends vessel entities based on their historical query information. Experimental results show that the proposed question-answering model improved the F1-score by 2.31%–10.09% compared to state-of-the-art baseline models on the MVA question-answering dataset. Similarly, the proposed personalized recommendation model improved the click-through rate prediction accuracy by 2.46%–7.05% compared to state-of-the-art baseline models on the MVA personalized recommendation dataset.}
}
@article{HOGENBOOM2021115568,
title = {The impact of word sense disambiguation on stock price prediction},
journal = {Expert Systems with Applications},
volume = {184},
pages = {115568},
year = {2021},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2021.115568},
url = {https://www.sciencedirect.com/science/article/pii/S0957417421009738},
author = {Alexander Hogenboom and Alex Brojba-Micu and Flavius Frasincar},
keywords = {Stock price prediction, Event detection, Word sense disambiguation, Natural language processing},
abstract = {State-of-the-art decision support systems for stock price prediction incorporate pattern-based event detection in text into their predictions. These systems typically fail to account for word meaning, even though word sense disambiguation is crucial for text understanding. Therefore, we propose an advanced natural language processing pipeline for event-based stock price prediction, that allows for word sense disambiguation to be incorporated in the event detection process. We identify events in natural language news messages and subsequently weight these events for their historical impact on stock prices. We assess the merit of word sense disambiguation in event-based stock price prediction in two evaluation scenarios for NASDAQ-100 companies, based on historical stock prices and news articles retrieved from Dow Jones Newswires over a 2-year period. We evaluate the precision of generated buy and sell signals based on our predicted stock price movements, as well as the excess returns generated by a trading strategy that acts upon these signals. Event-based stock price predictions seem most reliable about 2 days into the future. The number of detected events tends to reduce with over 30% when graph-based word sense disambiguation using a degree centrality measure is applied in the event detection process, thus reducing the noise introduced into the stock price movement predictions by high-impact ambiguous events. As a result, modest improvements in the precision of buy and sell signals generated based on these predictions tend to lead to vast improvements of on average about 70% in the associated excess returns.}
}
@article{BELLOBRAVO2022e09808,
title = {Just participation or just participation? A participatory justice model for more successful theory of change design, implementation, and solution uptake},
journal = {Heliyon},
volume = {8},
number = {7},
pages = {e09808},
year = {2022},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2022.e09808},
url = {https://www.sciencedirect.com/science/article/pii/S2405844022010969},
author = {Julia Bello-Bravo and John William Medendorp and Barry Pittendrigh},
keywords = {Participatory justice, Fairness, Empathy, Cooperation, Recognition, Models, Theory of change},
abstract = {While a wide consensus acknowledges that participation is critical for the successful implementation of change that improves the livelihoods of people and communities around the world, justly securing that participation from stakeholders (at both the design and implementation stages) remains a demanding problem. This paper proposes a heuristic model for increasing participation that not only helps to investigate instances of nonparticipation but also opens up alternative intervention strategies and pathways for designers and implementers to consider toward more justly increasing participation and overcoming nonparticipation. Applied to a successful case of participation in Gurúè District, Mozambique—where an 89% solution adoption of an improved postharvest seed storage method was measured two years after initial training—this paper demonstrates the key importance of designing opportunities and motivations for participation into any solutions or innovations but especially justice as a factor for successful realization of theory of change efforts (all the more so in developing nation contexts). Applied to a second case study, this paper also explores participation despite little to no motivation to do so. Aiming to afford designers and implementers of theory of change interventions a tool for more successfully and exactly matching innovation goals with innovation outcomes, the paper also addresses broader implications for the model within theory of change approaches generally.}
}
@article{LAADHAR2022997,
title = {Web of Things Semantic Interoperability in Smart Buildings},
journal = {Procedia Computer Science},
volume = {207},
pages = {997-1006},
year = {2022},
note = {Knowledge-Based and Intelligent Information & Engineering Systems: Proceedings of the 26th International Conference KES2022},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2022.09.155},
url = {https://www.sciencedirect.com/science/article/pii/S1877050922010377},
author = {Amir Laadhar and Junior Dongo and Søren Enevoldsen and Frédéric Revaz and Dominique Gabioud and Torben Bach Pedersen and Martin Meyer and Brian Nielsen and Christian Thomsen},
keywords = {Web of Things, Internet of Things, Web of Things Discovery, Semantic Interoperability, Semantic Web, Ontology},
abstract = {Buildings are the largest energy consumers in Europe and are responsible for approximately 40% of EU energy consumption and 36% of the greenhouse gas emissions in Europe. Two-thirds of the building consumption is for residential buildings. To achieve energy efficiency, buildings are being integrated with IoT devices through the use of smart IoT services. For instance, a smart space heating service reduces energy consumption by dynamically heating apartments based on indoor and outdoor temperatures. The W3C recommends the use of the Web of Things (WoT) standard to enable IoT interoperability on the Web. However, in the context of a smart building, the ability to search and discover building metadata and IoT devices available in the WoT ecosystems remains a challenge due to the limitation of the current WoT Discovery, which only includes a directory containing only IoT devices metadata without including building metadata. Integrating the IoT device's metadata with building metadata in the same directory can provide better discovery capabilities to the IoT services providers. In this paper, we integrate building metadata into the W3C WoT Discovery through the construction of a Building Description JSON-LD file. This Building Description is integrated into the W3C WoT Discovery and based on the domOS Common Ontology (dCO) to achieve semantic interoperability in smart residential buildings for the WoT IoT ecosystem within the Horizon 2020 domOS project. This integration results in a Thing and Building Description Directory. dCO integrates the SAREF core ontology with the Thing Description ontology, devices, and building metadata. We have implemented and validated the WoT discovery on top of a WoT Thing and Building Description Directory. The WoT Discovery implementation is also made available for the WoT community.}
}
@article{LI2020101857,
title = {An intelligent semantic system for real-time demand response management of a thermal grid},
journal = {Sustainable Cities and Society},
volume = {52},
pages = {101857},
year = {2020},
issn = {2210-6707},
doi = {https://doi.org/10.1016/j.scs.2019.101857},
url = {https://www.sciencedirect.com/science/article/pii/S2210670719316634},
author = {Yu Li and Yacine Rezgui and Sylvain Kubicki},
keywords = {Thermal grid, Demand response, Energy optimization, Operation cost, Data interoperability, Semantic ontology},
abstract = {“Demand Response” energy management of thermal grids requires consideration of a wide range of factors at building and district level, supported by continuously calibrated simulation models that reflect real operation conditions. Moreover, cross-domain data interoperability between concepts used by the numerous hardware and software is essential, in terms of Terminology, Metadata, Meaning and Logic. This paper leverages domain ontology to map and align the semantic resources that underpin building and district energy management, with a focus on the optimization of a thermal grid informed by real-time energy demand. The intelligence of the system is derived from simulation-based optimization, informed by calibrated thermal models that predict the network’s energy demand to inform (near) real-time generation. The paper demonstrates that the use of semantics helps alleviate the endemic energy performance gap, as validated in a real district heating network where 36% reduction on operation cost and 43% reduction on CO2 emission were observed compared to baseline operational data.}
}
@article{HE2025130355,
title = {Text similarity based on two independent channels: Siamese Convolutional Neural Networks and Siamese Recurrent Neural Networks},
journal = {Neurocomputing},
volume = {643},
pages = {130355},
year = {2025},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2025.130355},
url = {https://www.sciencedirect.com/science/article/pii/S0925231225010276},
author = {Zhengfang He},
keywords = {Text similarity, Siamese Convolutional Neural Networks, Siamese Recurrent Neural Networks},
abstract = {In the present-day context, a large amount of information exists in text. It is hard to extract meaningful and potential information from the text. From the current research, text similarity provides a method applied in many practical scenarios. Traditional text similarity algorithms are easy to implement, but more than these algorithms are needed to extract text features. At present, most text similarity algorithms are based on deep learning. However, these algorithms often struggle with adequately extracting both local and context text features, and they typically do not differentiate between the effectiveness of these two types of feature extraction. To address these shortcomings, this paper proposes Two Independent Channels: Siamese Convolutional Neural Networks and Siamese Recurrent Neural Networks (TIC-SCNN-SRNN). This approach is designed for binary classification, where ‘1’ indicates similarity and ‘0’ indicates dissimilarity. In detail, this paper proposes the Siamese Convolutional Neural Networks (SCNN) model to address the issue of insufficient extraction of local text features. Additionally, it introduces the Siamese Recurrent Neural Networks (SRNN) model to tackle the problem of insufficient extraction of context text features. Due to the issue of not distinguishing the effects of local and context text features extractions, this paper conducts independent weight learning on these two models to research which is more effective for text similarity tasks. In order to verify the effectiveness of the model, this paper experiments on SciTail, TwitterPPD, and QQP datasets. The experimental results show that SCNN and SRNN influence the text similarity tasks, but SRNN is more effective than SCNN. Furthermore, to verify the advantages of the TIC-SCNN-SRNN model, this paper tests the performance of the state-of-the-art CNN&RNN models. The test results show that the TIC-SCNN-SRNN model performs the best, indicating that the model proposed in this paper is more effective for the text similarity tasks.}
}
@article{GNOLI20181226,
title = {Mentefacts as a missing level in theory of information science},
journal = {Journal of Documentation},
volume = {74},
number = {6},
pages = {1226-1242},
year = {2018},
issn = {0022-0418},
doi = {https://doi.org/10.1108/JD-04-2018-0054},
url = {https://www.sciencedirect.com/science/article/pii/S0022041818000073},
author = {Claudio Gnoli},
keywords = {Information theory, Information science, Ontology, Knowledge organization, Epistemology, Levels of reality},
abstract = {Purpose
The current debate between two theoretical approaches in library and information science and knowledge organization (KO), the cognitive one and the sociological one, is addressed in view of their possible integration in a more general model. The paper aims to discuss these issues.
Design/methodology/approach
Personal knowledge of individual users, as focused in the cognitive approach, and social production and use of knowledge, as focused in the sociological approach, are reconnected to the theory of levels of reality, particularly in the versions of Nicolai Hartmann and Karl R. Popper (three worlds). The notions of artefact and mentefact, as proposed in anthropological literature and applied in some KO systems, are also examined as further contributions to the generalized framework. Some criticisms to these models are reviewed and discussed.
Findings
Both the cognitive approach and the sociological approach, if taken in isolation, prove to be cases of philosophical monism as they emphasize a single level over the others. On the other hand, each of them can be considered as a component of a pluralist ontology and epistemology, where individual minds and social communities are but two successive levels in knowledge production and use, and are followed by a further level of “objectivated spirit”; this can in turn be analyzed into artefacts and mentefacts. While all these levels are relevant to information science, mentefacts and their properties are its most peculiar objects of study, which make it distinct from such other disciplines as psychology and sociology.
Originality/value
This analysis shows how existing approaches can benefit from additional notions contributed by levels theory, to develop more complete and accurate models of information and knowledge phenomena.}
}
@article{STERCKX2020103544,
title = {Clinical information extraction for preterm birth risk prediction},
journal = {Journal of Biomedical Informatics},
volume = {110},
pages = {103544},
year = {2020},
issn = {1532-0464},
doi = {https://doi.org/10.1016/j.jbi.2020.103544},
url = {https://www.sciencedirect.com/science/article/pii/S1532046420301726},
author = {Lucas Sterckx and Gilles Vandewiele and Isabelle Dehaene and Olivier Janssens and Femke Ongenae and Femke {De Backere} and Filip {De Turck} and Kristien Roelens and Johan Decruyenaere and Sofie {Van Hoecke} and Thomas Demeester},
keywords = {Clinical information extraction, Clinical decision support models, Preterm birth, Text mining},
abstract = {This paper contributes to the pursuit of leveraging unstructured medical notes to structured clinical decision making. In particular, we present a pipeline for clinical information extraction from medical notes related to preterm birth, and discuss the main challenges as well as its potential for clinical practice. A large collection of medical notes, created by staff during hospitalizations of patients who were at risk of delivering preterm, was gathered and analyzed. Based on an annotated collection of notes, we trained and evaluated information extraction components to discover clinical entities such as symptoms, events, anatomical sites and procedures, as well as attributes linked to these clinical entities. In a retrospective study, we show that these are highly informative for clinical decision support models that are trained to predict whether delivery is likely to occur within specific time windows, in combination with structured information from electronic health records.}
}
@article{GEISMANN2020110697,
title = {A systematic literature review of model-driven security engineering for cyber–physical systems},
journal = {Journal of Systems and Software},
volume = {169},
pages = {110697},
year = {2020},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2020.110697},
url = {https://www.sciencedirect.com/science/article/pii/S0164121220301461},
author = {Johannes Geismann and Eric Bodden},
keywords = {Literature survey, Systematic literature review, Model-driven security, Cyber–physical systems, Platform-specific, Security modeling},
abstract = {The last years have elevated the importance of cyber–physical systems like IoT applications, smart cars, or industrial control systems, and, therefore, these systems have also come into the focus of attackers. In contrast to software products running on PCs or smartphones, updating and maintaining cyber–physical systems presents a major challenge. This challenge, combined with the often decades-long lifetime of cyber–physical systems, and with their deployment in often safety-critical contexts, makes it particularly important to consider their security already at design time. When aiming to obtain a provably secure design, model-driven security approaches are key, as they allow to identify and mitigate threats in early phases of the development. As attacks may exploit both code-level as well as physical vulnerabilities, such approaches must consider not just the cyber layer but the physical layer as well. To find out which model-driven security approaches for cyber–physical systems exist considering both layers, we conducted a systematic literature review. From a set of 1160 initial papers, we extracted 69 relevant publications describing 17 candidate approaches. We found seven approaches specifically developed for cyber–physical systems. We provide a comprehensive description of these approaches, discuss them in particular detail, and determine their limitations. We found out that model-driven security is a relevant research area but most approaches focus only on specific security properties and even for CPS-specific approaches the platform is only rarely taken into account.}
}
@article{KIM2025110290,
title = {Modulating vascular smooth muscle cell phenotype via Wnt-Independent FRZB pathways},
journal = {Archives of Biochemistry and Biophysics},
volume = {764},
pages = {110290},
year = {2025},
issn = {0003-9861},
doi = {https://doi.org/10.1016/j.abb.2025.110290},
url = {https://www.sciencedirect.com/science/article/pii/S0003986125000037},
author = {Hyomin Kim and Eun Kyoung Kim and Yeuni Yu and Hye Jin Heo and Dokyoung Kim and Su-Yeon Cho and Yujin Kwon and Won Kyu Kim and Kihun Kim and Dai Sik Ko and Yun Hak Kim},
keywords = {Frizzled-related protein, Vascular smooth muscle cell, Atherosclerosis, Phenotype modulation, Focal adhesion},
abstract = {Background and aims
Vascular smooth muscle cells are pivotal in atherosclerosis, transitioning from a contractile to a synthetic phenotype, which is associated with increased proliferation and inflammation. FRZB, a Wnt signaling modulator, has been implicated in vascular pathology, but its specific role in vascular smooth muscle cell phenotype modulation is not well understood. This study investigates the role of FRZB in regulating vascular smooth muscle cell phenotypes.
Methods
Vascular smooth muscle cell regions were categorized based on FRZB expression levels, and various analyses, including differential gene expression, KEGG pathway analysis, and Disease Ontology analysis, were conducted. FRZB knockdown in human aortic vascular smooth muscle cell was performed using siRNA, followed by assessments of cell migration, proliferation, and phenotype marker expression.
Results
FRZB expression was significantly reduced in synthetic type compared to contractile type in both mouse models and human samples. FRZB knockdown in human vascular smooth muscle cells led to increased cell migration and proliferation, alongside decreased expression of contractile markers and increased synthetic markers. Unexpectedly, FRZB knockdown suppressed Wnt signaling. Pathway analysis revealed associations with the PI3K-Akt signaling pathway, focal adhesion, and ECM interactions.
Conclusions
Our study highlights FRZB's role in Vascular smooth muscle cell phenotype modulation, showing that reduced FRZB expression correlates with a synthetic phenotype and increased disease markers. FRZB does not enhance Wnt signaling but may regulate vascular smooth muscle cell behavior through alternative pathways. These findings suggest FRZB as a potential therapeutic target for stabilizing vascular smooth muscle cells and managing atherosclerosis.}
}
@article{DAURIA2023200161,
title = {Improving graph embeddings via entity linking: A case study on Italian clinical notes},
journal = {Intelligent Systems with Applications},
volume = {17},
pages = {200161},
year = {2023},
issn = {2667-3053},
doi = {https://doi.org/10.1016/j.iswa.2022.200161},
url = {https://www.sciencedirect.com/science/article/pii/S2667305322000989},
author = {Daniela D'Auria and Vincenzo Moscato and Marco Postiglione and Giuseppe Romito and Giancarlo Sperlí},
keywords = {Entity linking, Graph embedding, Link prediction, Health analytics, Healthcare},
abstract = {The ever-increasing availability of Electronic Health Records (EHRs) is the key enabling factor of precision medicine, which aims to provide therapies and diagnoses based not only on medical literature, but also on clinical experience and individual information of patients (e.g. genomics, lifestyle, health history). The unstructured nature of EHRs has posed several challenges on their effective analysis, and heterogeneous graphs are the most suitable solution to handle the heterogeneity of information contained in EHRs. However, while EHRs are an extremely valuable data source, information from current medical literature has yet to be considered in clinical decision support systems. In this work, we build an heterogeneous graph from Italian EHRs provided by the Hospital of Naples Federico II, and we define a methodological workflow allowing us to predict the presence of a link between patients and diagnosed diseases. We empirically demonstrate that linking concepts to biomedical ontologies (e.g. UMLS, DBpedia) — which allow us to extract entities and relationships from medical literature — is significantly beneficial to our link-prediction workflow in terms of Area Under the ROC curve (AUC) and Mean Reciprocal Rank (MRR).}
}
@article{BUDLER2021480,
title = {The development of business model research: A bibliometric review},
journal = {Journal of Business Research},
volume = {135},
pages = {480-495},
year = {2021},
issn = {0148-2963},
doi = {https://doi.org/10.1016/j.jbusres.2021.06.045},
url = {https://www.sciencedirect.com/science/article/pii/S0148296321004574},
author = {Marko Budler and Ivan Župič and Peter Trkman},
keywords = {Business model, Review, Bibliometrics, Bibliographic coupling, Historiography},
abstract = {Recent reviews demonstrate the usefulness of the business model concept as a level of analysis in management, whereas less attention has been devoted to the analysis of the paths of past research to guide its future development. We used bibliometric methods, specifically bibliographic coupling and algorithmic historigraphy, to trace the development of the business model literature from its origins in e-business to its current state. In addition to reviewing the literature as a whole, our study investigated the time-dependent co-evolution of research sub-streams. We examined the relative influence of publications and canonical papers (algorithmic historiography) within and between three separate time spans (bibliographic coupling). We found that business model foundations draw from three major business sub-disciplines—strategy, entrepreneurship, and innovation—whilst new frontiers (e.g., Industry 4.0, sustainability, and networks) offer an opportunity to increase the inter-connectedness of business model research. Finally, we discuss contemporary topics and future avenues for business model research.}
}
@article{VOUGIOUKLIS20181,
title = {Neural Wikipedian: Generating Textual Summaries from Knowledge Base Triples},
journal = {Journal of Web Semantics},
volume = {52-53},
pages = {1-15},
year = {2018},
issn = {1570-8268},
doi = {https://doi.org/10.1016/j.websem.2018.07.002},
url = {https://www.sciencedirect.com/science/article/pii/S1570826818300313},
author = {Pavlos Vougiouklis and Hady Elsahar and Lucie-Aimée Kaffee and Christophe Gravier and Frédérique Laforest and Jonathon Hare and Elena Simperl},
keywords = {Natural language generation, Neural networks, Semantic web triples},
abstract = {Most people need textual or visual interfaces in order to make sense of Semantic Web data. In this paper, we investigate the problem of generating natural language summaries for Semantic Web data using neural networks. Our end-to-end trainable architecture encodes the information from a set of triples into a vector of fixed dimensionality and generates a textual summary by conditioning the output on the encoded vector. We explore a set of different approaches that enable our models to verbalise entities from the input set of triples in the generated text. Our systems are trained and evaluated on two corpora of loosely aligned Wikipedia snippets with triples from DBpedia and Wikidata, with promising results.}
}
@article{WANG2022107639,
title = {Prediction of the disease causal genes based on heterogeneous network and multi-feature combination method},
journal = {Computational Biology and Chemistry},
volume = {97},
pages = {107639},
year = {2022},
issn = {1476-9271},
doi = {https://doi.org/10.1016/j.compbiolchem.2022.107639},
url = {https://www.sciencedirect.com/science/article/pii/S1476927122000196},
author = {Lexiang Wang and Mingxiao Wu and Yulin Wu and Xiaofeng Zhang and Sen Li and Ming He and Fan Zhang and Yadong Wang and Junyi Li},
keywords = {Disease-causative genes, Heterogeneous network, Link prediction, Structure features, Embedding features, Feature combination},
abstract = {At present, the prediction of disease causal genes is mainly based on heterogeneous. Research shows that heterogeneous network contains more information and have better prediction results. In this paper, we constructed a heterogeneous network including four node types of disease, gene, phenotype and gene ontology. On this basis, we use a machine learning algorithm to predict disease-causing genes. The algorithm is divided into three steps: preprocess and training sample extraction, features extraction and combination, model training and prediction. In the process of feature extraction and combination, by using network representation method, the representation vectors of nodes are generated as the embedding features of the nodes. We also extracted the structural features of each node in the network and then the embedding features and structure features are combined. The results of training and prediction show that the prediction algorithm based on all features combined together achieves the best prediction performance. Moreover, the combination of each network representation method’s embedding features and structural features has also achieved performance improvement. In the process of training samples extraction, we propose three improvement directions according to the network structure and data set distribution. Firstly, a positive sample algorithm based on network connectivity is proposed, we try to keep the connectivity of the whole heterogeneous graph in the sampling process to avoid the negative impact of embedding features’ extraction. Moreover, the influence of sample sampling ratio on experimental results was tested in the range of 0–1 with step size of 0.1. The influence of different proportion of positive and negative samples on the results was also tested. These improvements are intended to enhance the balance and robustness of the method. When the positive sample ratio is 0.1 and the proportion of negative and positive samples is 3, the model achieves the optimal result, and its AUC value and accuracy are 0.9887% and 94.55%, respectively, which are significantly higher than other models.}
}
@article{XU2022101265,
title = {Integrative model for discovering linked topics in science and technology},
journal = {Journal of Informetrics},
volume = {16},
number = {2},
pages = {101265},
year = {2022},
issn = {1751-1577},
doi = {https://doi.org/10.1016/j.joi.2022.101265},
url = {https://www.sciencedirect.com/science/article/pii/S1751157722000177},
author = {Haiyun Xu and Zenghui Yue and Hongshen Pang and Ehsan Elahi and Jing Li and Lu Wang},
keywords = {Linked topics in science and technology, Scientific innovation, Science and technology linkage, Link prediction, Topic recognition},
abstract = {Linked topics in science and technology (LTSTs) can provide new avenues for technological innovation and are a key step in the transition from basic to applied research. This paper proposes a science and technology semantic linkage integration model for discovering LTSTs. Particularly, the integrative model fuses the term co-occurrence networks of basic and applied research, which expands the completeness of topic networks by enhancing the semantic characteristics of these networks. It is found that link prediction can further reinforce the semantic association of topic terms in networks between basic and applied topics. Simple fusion explicitly linked the topic terms, which can be used as automatic seed marking for subsequent link prediction to identify implicit linking of topic terms. Furthermore, an application to the gene-engineered vaccines field depicted that newly predicted implicit relations can effectively identify LTSTs. The results also show that implicit semantic recognition of LTSTs can be enhanced through simple fusion, while the recognition of LTST can be improved through link prediction. Therefore, the proposed model can assist experts to identify LTSTs that cannot be recognized through simple fusion.}
}
@article{LEVSHUN2020102151,
title = {Design and verification of a mobile robot based on the integrated model of cyber-Physical systems},
journal = {Simulation Modelling Practice and Theory},
volume = {105},
pages = {102151},
year = {2020},
issn = {1569-190X},
doi = {https://doi.org/10.1016/j.simpat.2020.102151},
url = {https://www.sciencedirect.com/science/article/pii/S1569190X20300903},
author = {Dmitry Levshun and Yannick Chevalier and Igor Kotenko and Andrey Chechulin},
keywords = {Security by design, Cyber-physical system, Integrated model, Attacker model, Attack actions model, Access control system, Mobile robot},
abstract = {The paper describes the new model, which is a key element of the design and verification methodology for secure cyber-physical systems. The proposed model represents cyber-physical systems as a set of building blocks with properties and connections between them, while each building block is the projection of the integrated model. The models of attacker and attack actions are an external models that are connected with an integrated model: attack actions impact is modelled through changes in the properties of the system or its elements while the number of possible attack actions is reduced according to the attacker possibilities. The novelty of the proposed model lies in the strong focus on security and possibilities of direct (from the projections to the integrated model) and reverse (from the integrated model to the projections) transformations. Verification process is an integral part of the proposed solution. Verification provides the formal check of the system creation possibility in accordance with the requirements and limitations as well as that designed system is secured against an attacker of certain level of knowledge which is connected from certain access point and has certain amount of resources. During the experiments SPASS theorem prover, the Maude system and daTac were used. As an example of the proposed model application, firstly, an access control system was considered. This system contains Arduino microcontrollers, software agents, web-servers and different sensors. To provide an additional example an use case about mobile robot for perimeter monitoring was also presented. For the experiments, it was decided to use the LEGO 9797 Mindstorms NXT.}
}
@article{SCHRODER20208276,
title = {Formal Definition of the Term “Semantics” as a Foundation for Semantic Interoperability in the Industrial Internet of Things},
journal = {IFAC-PapersOnLine},
volume = {53},
number = {2},
pages = {8276-8282},
year = {2020},
note = {21st IFAC World Congress},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2020.12.1957},
url = {https://www.sciencedirect.com/science/article/pii/S2405896320325854},
author = {Tizian Schröder and Christian Diedrich},
keywords = {Semantics, Semantic Interoperability, Network of Interacting Systems, Industrial Internet of Things (IIoT), Knowledge Pyramid, Levels of Conceptual Interoperability Model (LCIM), Ontologies},
abstract = {Semantic interoperability is seen as the key to realize the ideas of the Industrial Internet of Things (IIoT). In order to equip technical systems with such a capability, a precise definition of the term “semantics” is needed. Complex IIoT devices can only be developed properly on a formal foundation. Existing approaches that intend to specify the term “semantics” are often more intuitively motivated. These include, for example, the knowledge pyramid or the Levels of Conceptual Interoperability Model (LCIM). The paper provides a formal definition of the term “semantics” and relates these existing approaches critically to the proposed definition.}
}
@article{DAO2024100367,
title = {Interlinking BIM and GIS data for a semantic pedestrian network and applications in high-density cities},
journal = {Developments in the Built Environment},
volume = {17},
pages = {100367},
year = {2024},
issn = {2666-1659},
doi = {https://doi.org/10.1016/j.dibe.2024.100367},
url = {https://www.sciencedirect.com/science/article/pii/S2666165924000486},
author = {Jicao Dao and S. Thomas Ng and Chung Yee Kwok},
keywords = {BIM, GIS, Linked data, Data integration, Pedestrian network},
abstract = {In high-density cities, pedestrians frequently traverse many publicly accessible indoor spaces, such as metro stations and footbridges, which seamlessly connect with outdoor sidewalks, forming indoor-outdoor combined pedestrian networks. However, the information island phenomenon hinders these connections in the digital world because outdoor sidewalks and indoor spaces are modelled using Geographical Information Systems (GIS) and Building Information Modelling (BIM) technologies, respectively, which challenges obtaining integrated information for intelligent pedestrian services. This study presents an approach for interlinking BIM and GIS data for a semantic pedestrian network using semantic web technologies. The proposed approach automatically converts BIM and GIS data into linked data and establishes interlinkages between BIM and GIS data through semantic queries and inferences. The resulting semantic pedestrian network based on integrated linked data graphs forms a knowledge base, including topological and geometrical information and abundant semantic information from BIM and GIS datasets. The application potential of the semantic pedestrian network is demonstrated through information query and semantic route planning. This research contributes to establishing indoor-outdoor combined semantic pedestrian networks ensuring seamless data integration.}
}
@article{PORCEL20181,
title = {Sharing notes: An academic social network based on a personalized fuzzy linguistic recommender system},
journal = {Engineering Applications of Artificial Intelligence},
volume = {75},
pages = {1-10},
year = {2018},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2018.07.007},
url = {https://www.sciencedirect.com/science/article/pii/S0952197618301519},
author = {C. Porcel and A. Ching-López and G. Lefranc and V. Loia and E. Herrera-Viedma},
keywords = {Recommender systems, Educational social networks, Fuzzy linguistic modeling},
abstract = {Social networks are Web systems that enable and encourage a collaborative work, making it possible to exchange information between users, which makes them especially useful in many areas. Specifically, they could be used in an academic environment with the aim of improving the educational processes, not replacing, but complementing the most traditional face-to-face models. But nowadays the increasingly widespread use of new technologies and social networks is causing the information we have available to grow disproportionately, making it more difficult and expensive to access information of interest. To alleviate this problem, automatic tools such as recommender systems, could be used to facilitate the accesses to relevant information, that in an academic environment would help to customize the educational processes. So, in this paper we present SharingNotes, an academic social network that can generate personalized recommendations to improve teaching and learning processes. To achieve this goal, it incorporates a hybrid recommender system that uses an ontology to characterize the degrees of trust among network users, and adopts the fuzzy linguistic modeling to improve the representation of information. Then, the use of this platform allows adapting the educational process to the circumstances of each student. The evaluation developed demonstrates the usefulness of this educational social network, as well as the users’ satisfaction while interacting and working with it.}
}
@article{MUNOZARCENTALES2019590,
title = {An Architecture for Providing Data Usage and Access Control in Data Sharing Ecosystems},
journal = {Procedia Computer Science},
volume = {160},
pages = {590-597},
year = {2019},
note = {The 10th International Conference on Emerging Ubiquitous Systems and Pervasive Networks (EUSPN-2019) / The 9th International Conference on Current and Future Trends of Information and Communication Technologies in Healthcare (ICTH-2019) / Affiliated Workshops},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2019.11.042},
url = {https://www.sciencedirect.com/science/article/pii/S1877050919317429},
author = {Andres Munoz-Arcentales and Sonsoles López-Pernas and Alejandro Pozo and Álvaro Alonso and Joaquín Salvachúa and Gabriel Huecas},
keywords = {Data Usage Control, Data Economy, Usage Policies, International Data Spaces, UCON, XACML},
abstract = {We are experiencing a new digital revolution in which data are becoming a key pillar for business and industry. Promoting data sharing, without compromising data sovereignty and traceability, is fundamental since it provides a heterogeneous ecosystem with the potential to enrich the variety of applications and services that take part in this digital revolution. In this scope, the use of secure and trusted platforms for sharing and processing personal and industrial data is crucial for the creation of a data market and a data economy. Protecting data goes beyond restricting who can access what resource (covered by identity and access control respectively): it becomes necessary to control how data are treated, which is known as data usage control. Data usage control provides a common and trustful security framework to guarantee the sovereignty and the responsible use of organizations’ data by third-party entities, easing and ensuring data sharing in ecosystems such as industry or smart cities. In this article, we present an architecture proposal for achieving access and usage control in shared data ecosystems among multiple organizations. The proposed architecture is based on the UCON (Usage Control) model and an extended XACML (eXtensible Access Control Markup Language) Reference Architecture, relying on key aspects of the IDS (International Data Spaces) Reference Architecture Model. Its modular design and technology-agnostic nature provide an integral solution while maintaining flexibility of implementation.}
}
@article{VASHISHTH2021103880,
title = {Improving broad-coverage medical entity linking with semantic type prediction and large-scale datasets},
journal = {Journal of Biomedical Informatics},
volume = {121},
pages = {103880},
year = {2021},
issn = {1532-0464},
doi = {https://doi.org/10.1016/j.jbi.2021.103880},
url = {https://www.sciencedirect.com/science/article/pii/S1532046421002094},
author = {Shikhar Vashishth and Denis Newman-Griffis and Rishabh Joshi and Ritam Dutt and Carolyn P. Rosé},
keywords = {Natural language processing, Information extraction, Medical concept normalization, Medical entity linking, Distant supervision, Entity typing},
abstract = {Objectives
Biomedical natural language processing tools are increasingly being applied for broad-coverage information extraction—extracting medical information of all types in a scientific document or a clinical note. In such broad-coverage settings, linking mentions of medical concepts to standardized vocabularies requires choosing the best candidate concepts from large inventories covering dozens of types. This study presents a novel semantic type prediction module for biomedical NLP pipelines and two automatically-constructed, large-scale datasets with broad coverage of semantic types.
Methods
We experiment with five off-the-shelf biomedical NLP toolkits on four benchmark datasets for medical information extraction from scientific literature and clinical notes. All toolkits adopt a staged approach of mention detection followed by two stages of medical entity linking: (1) generating a list of candidate concepts, and (2) picking the best concept among them. We introduce a semantic type prediction module to alleviate the problem of overgeneration of candidate concepts by filtering out irrelevant candidate concepts based on the predicted semantic type of a mention. We present MedType, a fully modular semantic type prediction model which we integrate into the existing NLP toolkits. To address the dearth of broad-coverage training data for medical information extraction, we further present WikiMed and PubMedDS, two large-scale datasets for medical entity linking.
Results
Semantic type filtering improves medical entity linking performance across all toolkits and datasets, often by several percentage points of F-1. Further, pretraining MedType on our novel datasets achieves state-of-the-art performance for semantic type prediction in biomedical text.
Conclusions
Semantic type prediction is a key part of building accurate NLP pipelines for broad-coverage information extraction from biomedical text. We make our source code and novel datasets publicly available to foster reproducible research.}
}
@article{REVILLALEON2023276,
title = {Artificial intelligence models for tooth-supported fixed and removable prosthodontics: A systematic review},
journal = {The Journal of Prosthetic Dentistry},
volume = {129},
number = {2},
pages = {276-292},
year = {2023},
issn = {0022-3913},
doi = {https://doi.org/10.1016/j.prosdent.2021.06.001},
url = {https://www.sciencedirect.com/science/article/pii/S0022391321003097},
author = {Marta Revilla-León and Miguel Gómez-Polo and Shantanu Vyas and Abdul Basir Barmak and German O. Gallucci and Wael Att and Mutlu Özcan and Vinayak R. Krishnamurthy},
abstract = {Statement of problem
Artificial intelligence applications are increasing in prosthodontics. Still, the current development and performance of artificial intelligence in prosthodontic applications has not yet been systematically documented and analyzed.
Purpose
The purpose of this systematic review was to assess the performance of the artificial intelligence models in prosthodontics for tooth shade selection, automation of restoration design, mapping the tooth preparation finishing line, optimizing the manufacturing casting, predicting facial changes in patients with removable prostheses, and designing removable partial dentures.
Material and methods
An electronic systematic review was performed in MEDLINE/PubMed, EMBASE, Web of Science, Cochrane, and Scopus. A manual search was also conducted. Studies with artificial intelligence models were selected based on 6 criteria: tooth shade selection, automated fabrication of dental restorations, mapping the finishing line of tooth preparations, optimizing the manufacturing casting process, predicting facial changes in patients with removable prostheses, and designing removable partial dentures. Two investigators independently evaluated the quality assessment of the studies by applying the Joanna Briggs Institute Critical Appraisal Checklist for Quasi-Experimental Studies (nonrandomized experimental studies). A third investigator was consulted to resolve lack of consensus.
Results
A total of 36 articles were reviewed and classified into 6 groups based on the application of the artificial intelligence model. One article reported on the development of an artificial intelligence model for tooth shade selection, reporting better shade matching than with conventional visual selection; 14 articles reported on the feasibility of automated design of dental restorations using different artificial intelligence models; 1 artificial intelligence model was able to mark the margin line without manual interaction with an average accuracy ranging from 90.6% to 97.4%; 2 investigations developed artificial intelligence algorithms for optimizing the manufacturing casting process, reporting an improvement of the design process, minimizing the porosity on the cast metal, and reducing the overall manufacturing time; 1 study proposed an artificial intelligence model that was able to predict facial changes in patients using removable prostheses; and 17 investigations that developed clinical decision support, expert systems for designing removable partial dentures for clinicians and educational purposes, computer-aided learning with video interactive programs for student learning, and automated removable partial denture design.
Conclusions
Artificial intelligence models have shown the potential for providing a reliable diagnostic tool for tooth shade selection, automated restoration design, mapping the preparation finishing line, optimizing the manufacturing casting, predicting facial changes in patients with removable prostheses, and designing removable partial dentures, but they are still in development. Additional studies are needed to further develop and assess their clinical performance.}
}
@incollection{ELLSWORTH2024239,
title = {Acronyms},
editor = {Peggy Wu and Michael Salpukas and Hsin-Fu Wu and Shannon Ellsworth},
booktitle = {Trolley Crash},
publisher = {Academic Press},
pages = {239-241},
year = {2024},
isbn = {978-0-443-15991-6},
doi = {https://doi.org/10.1016/B978-0-44-315991-6.00020-0},
url = {https://www.sciencedirect.com/science/article/pii/B9780443159916000200},
author = {Shannon Ellsworth and Hsin-Fu ‘Sinker’ Wu}
}
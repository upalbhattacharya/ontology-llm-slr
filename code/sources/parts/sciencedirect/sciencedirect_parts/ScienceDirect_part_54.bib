@article{SANTALA2022100026,
title = {Communal sharing within and beyond digital platforms: Prefiguring interdependent sharing cities},
journal = {Digital Geography and Society},
volume = {3},
pages = {100026},
year = {2022},
issn = {2666-3783},
doi = {https://doi.org/10.1016/j.diggeo.2022.100026},
url = {https://www.sciencedirect.com/science/article/pii/S2666378322000010},
author = {Inka Santala and Pauline MGuirk},
keywords = {Communal sharing, Digital platforms, Social innovation, Postcapitalist politics, Sharing cities},
abstract = {While life-as-usual remains disrupted by the COVID-19 pandemic, cities rely increasingly on community-based and often digitally-enabled sharing of knowledge, skills and resources. These emergent forms of ‘communal sharing’ cannot be explained through instrumentally-beneficial economic discourses or structurally-disruptive political narratives alone. Rather, they call for revaluing the interdependent social relations that digital platforms enable and maintain. Drawing from a relational ontology of transformative social innovation, this paper begins to reframe communal sharing as inherently interdependent social relations between citizens and across civic, market and government domains. These interdependencies mean that sharing through digital platforms is not only responding to, or resisting, dominantly neoliberalist urban logics but is both formed by and reforming new understandings of urban agency. To explore these new understandings of being, doing and thinking of the city as shared, the paper adopts a generative epistemology of postcapitalist politics. Reading communal sharing as not merely interdependent but as fundamentally prefigurative of urban structures, norms and behaviours, the paper develops a post-structuralist approach to sharing cities. This approach illustrates practices as co-determined, communities as resourceful, and initiatives as highly adaptive socio-spatial performances taking place within and beyond digital platforms. Recognising and nurturing the enabling role of digital in sharing cities, the paper adopts the hopeful stance of reconceptualising communal sharing to open space for social and sectoral divides to be bridged and reimagined beyond the pandemic accelerations of platform capitalism.}
}
@article{HASSAN2025111242,
title = {Enabling technologies for Web 3.0: A comprehensive survey},
journal = {Computer Networks},
volume = {264},
pages = {111242},
year = {2025},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2025.111242},
url = {https://www.sciencedirect.com/science/article/pii/S1389128625002105},
author = {Md Arif Hassan and Mohammad (Behdad) Jamshidi and Bui Duc Manh and Nam H. Chu and Chi-Hieu Nguyen and Nguyen Quang Hieu and Cong T. Nguyen and Dinh Thai Hoang and Diep N. Nguyen and Nguyen {Van Huynh} and Mohammad Abu Alsheikh and Eryk Dutkiewicz},
keywords = {Web 3.0, Internet of Things, 5G, Blockchain, Semantic Web, Metaverse, Artificial Intelligence, Decentralized networks, Security, Privacy},
abstract = {Web 3.0 represents the next stage of Internet evolution, aiming to empower users with increased autonomy, efficiency, quality, security, and privacy. This evolution has the potential to democratize content access by leveraging advancements in cutting-edge enabling technologies. In this paper, we conduct an in-depth survey of enabling technologies in the context of Web 3.0, such as blockchain, semantic web, 3D interactive web, Metaverse, Virtual Reality (VR) and Augmented Reality (AR), Internet of Things (IoT) technology, and their roles in shaping Web 3.0. We commence by providing a comprehensive background of Web 3.0, including its concept, basic architecture, potential applications, and industry adoption. Subsequently, we examine recent breakthroughs in IoT, 5G, and blockchain technologies that are pivotal to Web 3.0 development. Following that, other enabling technologies, including AI, semantic web, and 3D interactive web, are discussed. Utilizing these technologies can effectively address the critical challenges in realizing Web 3.0, such as ensuring decentralized identity, platform interoperability, data transparency, reducing latency, and enhancing the system’s scalability. Finally, we highlight significant challenges associated with Web 3.0 implementation, emphasizing potential solutions and providing insights into future research directions in this field.}
}
@article{MAVROMATIDIS2025,
title = {A constructal poly-narrative of architectural and urban practices and theories across history},
journal = {Frontiers of Architectural Research},
year = {2025},
issn = {2095-2635},
doi = {https://doi.org/10.1016/j.foar.2025.03.004},
url = {https://www.sciencedirect.com/science/article/pii/S2095263525000391},
author = {Lazaros Mavromatidis},
keywords = {Constructal law, Speculative realism, Architectural philosophy, Irreduction, Complexity, Poly-narrative},
abstract = {The history of architectural and urban practices reflects humanity's enduring quest to comprehend and shape its environment, often through the lens of unifying meta-narratives. This paper critiques the tendency to seek cohesive frameworks, drawing from Graham Harman's speculative realism and Bruno Latour's “Principle of Irreduction,” which challenge hierarchical structures in understanding reality. These perspectives underscore the irreducibility and multiplicity of existence, advocating for a paradigm shift that resists determinism and embraces open-endedness. In this context, Adrian Bejan's constructal law offers a compelling alternative for interpreting architectural and urban forms. Constructal theory conceptualizes form and design as evolutionary responses to flow systems, framing architecture as an active participant in the dynamic interplay of environmental, social, and temporal forces. This perspective encourages a reevaluation of architectural practices not as definitive solutions but as iterative processes that engage with complexity and contingency. By integrating constructal theory with contemporary philosophical critiques, this article proposes a poly-narrative of architecture and urbanism that aligns with the fluidity and multiplicity of modern existence. It argues for a departure from static frameworks toward adaptive methodologies that acknowledge the interconnectedness of actors, scales, and temporalities. Ultimately, this approach reframes design as a dialogic process, fostering resilience and innovation in confronting the uncertainties of a rapidly evolving world.}
}
@article{LEE2018128,
title = {Machine Learning on a Genome-wide Association Study to Predict Late Genitourinary Toxicity After Prostate Radiation Therapy},
journal = {International Journal of Radiation Oncology*Biology*Physics},
volume = {101},
number = {1},
pages = {128-135},
year = {2018},
issn = {0360-3016},
doi = {https://doi.org/10.1016/j.ijrobp.2018.01.054},
url = {https://www.sciencedirect.com/science/article/pii/S0360301618301263},
author = {Sangkyu Lee and Sarah Kerns and Harry Ostrer and Barry Rosenstein and Joseph O. Deasy and Jung Hun Oh},
abstract = {Purpose
Late genitourinary (GU) toxicity after radiation therapy limits the quality of life of prostate cancer survivors; however, efforts to explain GU toxicity using patient and dose information have remained unsuccessful. We identified patients with a greater congenital GU toxicity risk by identifying and integrating patterns in genome-wide single nucleotide polymorphisms (SNPs).
Methods and Materials
We applied a preconditioned random forest regression method for predicting risk from the genome-wide data to combine the effects of multiple SNPs and overcome the statistical power limitations of single-SNP analysis. We studied a cohort of 324 prostate cancer patients who were self-assessed for 4 urinary symptoms at 2 years after radiation therapy using the International Prostate Symptom Score.
Results
The predictive accuracy of the method varied across the symptoms. Only for the weak stream endpoint did it achieve a significant area under the curve of 0.70 (95% confidence interval 0.54-0.86; P = .01) on hold-out validation data that outperformed competing methods. Gene ontology analysis highlighted key biological processes, such as neurogenesis and ion transport, from the genes known to be important for urinary tract functions.
Conclusions
We applied machine learning methods and bioinformatics tools to genome-wide data to predict and explain GU toxicity. Our approach enabled the design of a more powerful predictive model and the determination of plausible biomarkers and biological processes associated with GU toxicity.}
}
@article{GRAY2022,
title = {Associations Between Family Member Involvement and Outcomes of Patients Admitted to the Intensive Care Unit: Retrospective Cohort Study},
journal = {JMIR Medical Informatics},
volume = {10},
number = {6},
year = {2022},
issn = {2291-9694},
doi = {https://doi.org/10.2196/33921},
url = {https://www.sciencedirect.com/science/article/pii/S2291969422001703},
author = {Tamryn F Gray and Anne Kwok and Khuyen M Do and Sandra Zeng and Edward T Moseley and Yasser M Dbeis and Renato Umeton and James A Tulsky and Areej El-Jawahri and Charlotta Lindvall},
keywords = {critical care, natural language processing, family, electronic health records, goals of care, intensive care unit, ICU},
abstract = {Background
Little is known about family member involvement, by relationship status, for patients treated in the intensive care unit (ICU).
Objective
Using documentation of family interactions in clinical notes, we examined associations between child and spousal involvement and ICU patient outcomes, including goals of care conversations (GOCCs), limitations in life-sustaining therapy (LLST), and 3-month mortality.
Methods
Using a retrospective cohort design, the study included a total of 858 adult patients treated between 2008 and 2012 in the medical ICU at a tertiary care center in northeastern United States. Clinical notes generated within the first 48 hours of admission to the ICU were used with standard machine learning methods to predict patient outcomes. We used natural language processing methods to identify family-related documentation and abstracted sociodemographic and clinical characteristics of the patients from the medical record.
Results
Most of the 858 patients were White (n=650, 75.8%); 437 (50.9%) were male, 479 (55.8%) were married, and the median age was 68.4 (IQR 56.5-79.4) years. Most patients had documented GOCC (n=651, 75.9%). In adjusted regression analyses, child involvement (odds ratio [OR] 0.81; 95% CI 0.49-1.34; P=.41) and child plus spouse involvement (OR 1.28; 95% CI 0.8-2.03; P=.3) were not associated with GOCCs compared to spouse involvement. Child involvement was not associated with LLST when compared to spouse involvement (OR 1.49; 95% CI 0.89-2.52; P=.13). However, child plus spouse involvement was associated with LLST (OR 1.6; 95% CI 1.02-2.52; P=.04). Compared to spouse involvement, there were no significant differences in the 3-month mortality by family member type, including child plus spouse involvement (OR 1.38; 95% CI 0.91-2.09; P=.13) and child involvement (OR 1.47; 95% CI 0.9-2.41; P=.12).
Conclusions
Our findings demonstrate that statistical models derived from text analysis in the first 48 hours of ICU admission can predict patient outcomes. Early child plus spouse involvement was associated with LLST, suggesting that decisions about LLST were more likely to occur when the child and spouse were both involved compared to the involvement of only the spouse. More research is needed to further understand the involvement of different family members in ICU care and its association with patient outcomes.}
}
@incollection{MAGHSOUDI2025597,
title = {Chapter 32 - The future of narcolepsy treatment: what role will artificial intelligence play?},
editor = {Ahmed S. BaHammam and Amir Sharafkhaneh and Seithikurippu R. Pandi-Perumal},
booktitle = {Narcolepsy},
publisher = {Academic Press},
pages = {597-620},
year = {2025},
isbn = {978-0-443-30004-2},
doi = {https://doi.org/10.1016/B978-0-443-30004-2.00050-X},
url = {https://www.sciencedirect.com/science/article/pii/B978044330004200050X},
author = {Arash Maghsoudi and Amin Ramezani and Javad Razjouyan and Amir Sharafkhaneh},
keywords = {Computer in society, natural language processing, machine learning, computer science, cognitive process},
abstract = {In a rapidly evolving technological landscape, artificial intelligence (AI) emerges as a catalyst for progress, reshaping human–machine interaction. Branches such as natural language processing (NLP), empowering virtual assistants and language translation, and computer vision, facilitating visual data analysis in various domains, revolutionize communication and industry practices. Robotics further blurs the lines between science fiction and reality, enabling intelligent machines to interact physically with the world, from industrial automation to healthcare assistance. While General AI remains a distant goal, narrow AI dominates, excelling in specific tasks like speech recognition and recommendation algorithms, enhancing efficiency across industries. Machine learning (ML), particularly deep learning, propelled by advanced neural network architectures, drives breakthroughs in image recognition, natural language processing, and decision-making. In healthcare, AI holds promise, including medical note summarization techniques for aiding professionals, with a focus on its potential impact on sleep research, specifically in narcolepsy studies. In this chapter, the diverse applications of AI in the study of narcolepsy will be explored, concentrating on its role in narcolepsy research, diagnosis, and management. Additionally, we will delve into its impact on wearable technology, patient support systems, and the ethical considerations surrounding its implementation in narcolepsy care.}
}
@article{FENG2022117605,
title = {Tailored text augmentation for sentiment analysis},
journal = {Expert Systems with Applications},
volume = {205},
pages = {117605},
year = {2022},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2022.117605},
url = {https://www.sciencedirect.com/science/article/pii/S0957417422009162},
author = {Zijian Feng and Hanzhang Zhou and Zixiao Zhu and Kezhi Mao},
keywords = {Sentiment analysis, Text augmentation},
abstract = {In synonym replacement-based data augmentation techniques for natural language processing tasks, words in a sentence are often sampled randomly with equal probability. In this paper, we propose a novel data augmentation technique named Tailored Text Argumentation (TTA) for sentiment analysis. It has two main operations. The first operation is the probabilistic word sampling for synonym replacement based on the discriminative power and relevance of the word to sentiment. The second operation is the identification of words irrelevant to sentiment but discriminative for the training data, and application of zero masking or contextual replacement to these words. The first operation expands the coverage of discriminative words, while the second operation alleviates the problem of misfitting. Both operations tend to improve the model’s generalization capability. Extensive experiments on simulated low-data regimes demonstrate that TTA yields notable improvements over six strong baselines. Finally, TTA is applied to public sentiment analysis on measures against Covid-19, which again proves the effectiveness of the new data augmentation algorithm.}
}
@article{XU2023e13191,
title = {Hsa_circ_0072309 is a prognostic biomarker and is correlated with immune infiltration in gastric cancer},
journal = {Heliyon},
volume = {9},
number = {2},
pages = {e13191},
year = {2023},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2023.e13191},
url = {https://www.sciencedirect.com/science/article/pii/S2405844023003985},
author = {Bei-Bei Xu and Yi Huang and En-Dian Zheng and Jing-Ya Wang and Chen-Jing Zhang and Xiao-Ge Geng and Ya-Nan Wang and Wen-Sheng Pan},
keywords = {Gastric cancer, Circular RNA, Immune infiltration, Lymph node metastasis, Complement component 7},
abstract = {Background
Hsa_circ_0072309 has been identified as a tumor suppressor in several carcinomas. However, its precise role in gastric cancer (GC) remains largely unknown. This study was aimed to explore the precise role of Hsa_circ_0072309 in GC.
Methods
The transcriptional and clinical data of stomach adenocarcinoma were downloaded using the University of California SantaCruz (UCSC) Xena browser. The circular RNA (circRNA) datasets were obtained from the Gene Expression Omnibus (GEO) database. The expression profile and survival analysis of differentially expressed micro RNAs (DEMIs) and differentially expressed messenger RNAs (DEMs) were performed. Correlations between the expression and immune infiltration of the DEMS were studied. Additionally, the expression of hsa_circ_0072309 in GC tissues and cell lines were validated, and the relationship between its expression and clinical features was investigated. Gain- and loss-of function experiments and molecular interaction experiments were also conducted.
Results
Overall, 7 differentially expressed circRNAs, 13 DEMIs, and 17 DEMs were screened. Two DEMIs (hsa_miR-34a-3p and hsa_miR-326) and five DEMs (C7, MARCKSL1, UBE2T, OLR1, and HOXC11) showed significant differences in the high- and low-risk groups. The most significantly enriched Gene Ontology terms were the circadian regulation of gene expression and protein binding. The most significantly enriched Kyoto Encyclopedia of Genes and Genomes pathways were the PI3K-Akt and Ras signal pathways. Additionally, six genes were significantly correlated with immune infiltration. The real-time quantitative PCR (RT-qPCR) results revealed a significant downregulation of hsa_circ_0072309 in GC tissues related to tumor size, vascular invasion, and lymph node metastasis. A hsa_circ_0072309 overexpression suppressed whereas a hsa_circ_0072309 knockdown promoted GC cells proliferation and migration in vitro; in addition, hsa_circ_0072309 could directly bind to has-miR-34a-3p and has-miR-330-5p.
Conclusions
Hsa_circ_0072309 is a potential diagnostic biomarker for GC, and complement component 7 may be a tumor suppressor. These may potentially predict the prognosis of patients with GC and may become new therapeutic targets.}
}
@article{UNANGST202376,
title = {(De)Colonial historical geography and historical GIS},
journal = {Journal of Historical Geography},
volume = {79},
pages = {76-86},
year = {2023},
issn = {0305-7488},
doi = {https://doi.org/10.1016/j.jhg.2022.12.003},
url = {https://www.sciencedirect.com/science/article/pii/S0305748822000846},
author = {Matthew Unangst},
keywords = {GIS, digital mapping, colonialism, imperialism, Africa, decolonial, Ngugi},
abstract = {This article responds to a recent call from the journal’s editors to diversify the subjects of historical geography. It surveys Historical GIS (HGIS) and colonial cartography scholarship to offer a critique of existing GIS tools for the study of precolonial nonwestern histories. These tools, in the ways in which they turn Indigenous knowledge into computer-processed data, repeat the work of the colonial state. The article applies concepts from decolonial and design theory to address the problem, in particular Ngũgĩ wa Thiong'o’s ideas about the decolonization of knowledge. If we think of cartography as as a language to communicate spatial information, then a decolonial map must be based in Indigenous mapmaking. To articulate what this might look like, the article explores Karl Weule’s work on Indigenous mapmaking in early-20th century mainland Tanzania (then the colony of German East Africa). It demonstrates that the most common means of applying GIS to historical maps distort the mapmakers’ original intentions and proposes an alternative design for a pluralistic decolonial map, based in Indigenous conceptions of space rather than just incorporating Indigenous knowledge.}
}
@article{GHOUL2024772,
title = {Information system of strategic watch to rank innovation article by Machine Learning models},
journal = {Procedia Computer Science},
volume = {234},
pages = {772-779},
year = {2024},
note = {Seventh Information Systems International Conference (ISICO 2023)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.03.063},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924004216},
author = {Dhaou Ghoul and Jérémy Patrix and Ouail Oulmakki and Jérôme Verny},
keywords = {Strategic watch, Information system, Ranking articles, Machine Learning, keywords extraction},
abstract = {Information systems are crucial for companies to enhance strategic decision-making based on strategic watch. Keeping informed about the evolution of the sector is crucial for maintaining a sustainable and resilient supply chain, which is essential for a company's success. To improve competitiveness and anticipate market trends, such as detecting weak signals (early signs of emerging concepts e.g., DDMRP a few years ago), AI can accelerate the monitoring process that typically includes four main phases: defining needs, collecting data, ranking documents, and disseminating results. We present our collective intelligence-based approach of a semi-automatic technological watch information system for the perfumery-cosmetics sector.}
}
@article{NAI2023105887,
title = {Public tenders, complaints, machine learning and recommender systems: a case study in public administration},
journal = {Computer Law & Security Review},
volume = {51},
pages = {105887},
year = {2023},
issn = {2212-473X},
doi = {https://doi.org/10.1016/j.clsr.2023.105887},
url = {https://www.sciencedirect.com/science/article/pii/S0267364923000973},
author = {Roberto Nai and Rosa Meo and Gabriele Morina and Paolo Pasteris},
keywords = {Public procurement, Legal prediction, Complaint detection, Knowledge discovery, Natural language processing, Machine learning, Recommender system},
abstract = {With the proliferation of e-procurement systems in the public sector, valuable and open information sources can be jointly accessed. Our research aims to explore different legal Open Data; in particular, we explored the data set of the National Anti-Corruption Authority in Italy on public procurement and the judges’ sentences related to public procurement, published on the website of the Italian Administrative Justice from 2007 to 2022. Our first goal was to train machine learning models capable of automatically recognizing which procurement has led to disputes and consequently complaints to the Administrative Justice, identifying the relevant features of procurement that correspond to certain anomalies. Our second goal was to develop a recommender system on procurement to return similar procurement to a given one and find companies for bidders, depending on the procurement requirements.}
}
@article{ADAMAKIS2025100269,
title = {A methodological approach towards human-centered visual analytics},
journal = {Visual Informatics},
pages = {100269},
year = {2025},
issn = {2468-502X},
doi = {https://doi.org/10.1016/j.visinf.2025.100269},
url = {https://www.sciencedirect.com/science/article/pii/S2468502X2500052X},
author = {Emmanouil Adamakis and George Margetis and Stavroula Ntoa and Constantine Stephanidis},
keywords = {Visual analytics, Analytical reasoning, Human-centered design},
abstract = {Visual analytics focuses on amplifying users’ reasoning and understanding by enhancing data analysis procedures with the efficient incorporation of information visualization and data processing techniques. In this study, we conduct an overview of this multidisciplinary field, focusing on both the process that formalizes its primary concepts and the affiliated research areas. We identify key developments in each area, as well as the challenges that arise when these areas are interconnected under the visual analytics process. We consider that to address the identified challenges, an appropriate representation of key user needs is essential. Therefore, inspired by human-centered design and its principles, we propose a novel methodological approach comprising a human-centered definition of visual analytics that expands on models of the field and quantifies the intermediate states of a data analysis. In addition to the theoretical aspects of the definition, we also provide a set of directions that align the process with technical aspects of the development cycle. In this respect, our research endeavor aims to transform the visual analytics process into an essential method for both conceptualizing data analysis systems capable of anticipating user needs and for streamlining their technical implementation.}
}
@article{GYRARD2025,
title = {Lessons Learned From European Health Data Projects With Cancer Use Cases: Implementation of Health Standards and Internet of Things Semantic Interoperability},
journal = {Journal of Medical Internet Research},
volume = {27},
year = {2025},
issn = {1438-8871},
doi = {https://doi.org/10.2196/66273},
url = {https://www.sciencedirect.com/science/article/pii/S1438887125004194},
author = {Amelie Gyrard and Somayeh Abedian and Philip Gribbon and George Manias and Rick {van Nuland} and Kurt Zatloukal and Irina Emilia Nicolae and Gabriel Danciu and Septimiu Nechifor and Luis Marti-Bonmati and Pedro Mallol and Stefano Dalmiani and Serge Autexier and Mario Jendrossek and Ioannis Avramidis and Eva {Garcia Alvarez} and Petr Holub and Ignacio Blanquer and Anna Boden and Rada Hussein},
keywords = {artificial intelligence, cancer, European Health Data Space, health care standards, interoperability, AI, health data, cancer use cases, IoT, Internet of Things, primary data, diagnosis, prognosis, decision-making},
abstract = {The adoption of the European Health Data Space (EHDS) regulation has made integrating health data critical for both primary and secondary applications. Primary use cases include patient diagnosis, prognosis, and treatment, while secondary applications support research, innovation, and regulatory decision-making. Additionally, leveraging large datasets improves training quality for artificial intelligence (AI) models, particularly in cancer prevention, prediction, and treatment personalization. The European Union (EU) has recently funded multiple projects under Europe’s Beating Cancer Plan. However, these projects face challenges related to fragmentation and the lack of standardization in metadata, data storage, access, and processing. This paper examines interoperability standards used in six EU-funded cancer-related projects: IDERHA (Integration of Heterogeneous Data and Evidence Towards Regulatory and Health Technology Assessments Acceptance), EUCAIM (European Cancer Imaging Initiative), ASCAPE (Artificial Intelligence Supporting Cancer Patients Across Europe), iHelp, BigPicture, and the HealthData@EU pilot. These initiatives aim to enhance the analysis of heterogeneous health data while aligning with EHDS implementation, specifically for the EHDS for the secondary use of data (EHDS2). Between October 2023 and July 2024, we organized meetings and workshops among these projects to assess how they adopt health standards and apply Internet of Things (IoT) semantic interoperability. The discussions focused on interoperability standards for health data, knowledge graphs, the data quality framework, patient-generated health data, AI reasoning, federated approaches, security, and privacy. Based on our findings, we developed a template for designing the EHDS2 interoperability framework in alignment with the new European Interoperability Framework (EIF) and EHDS governance standards. This template maps EHDS2-recommended standards to the EIF model and principles, linking the proposed EHDS2 data quality framework to relevant International Organization for Standardization (ISO) standards. Using this template, we analyzed and compared how the recommended EHDS2 standards were implemented across the studied projects. During workshops, project teams shared insights on overcoming interoperability challenges and their innovative approaches to bridging gaps in standardization. With support from HSbooster.eu, we facilitated collaboration among these projects to exchange knowledge on standards, legal implementation, project sustainability, and harmonization with EHDS2. The findings from this work, including the created template and lessons learned, will be compiled into an interactive toolkit for the EHDS2 interoperability framework. This toolkit will help existing and future projects align with EHDS2 technical and legal requirements, serving as a foundation for a common EHDS2 interoperability framework. Additionally, standardization efforts include participation in the development of ISO/IEC 21823-3:2021—Semantic Interoperability for IoT Systems. Since no ISO standard currently exists for digital pathology and AI-based image analysis for medical diagnostics, the BigPicture project is contributing to ISO/PWI 24051-2, which focuses on digital pathology and AI-based, whole-slide image analysis. Integrating these efforts with ongoing ISO initiatives can enhance global standardization and facilitate widespread adoption across health care systems.}
}
@article{LIU2025101845,
title = {The Mad-genius controversy: Estimating the creativity of suicide poets via a dual model},
journal = {Thinking Skills and Creativity},
volume = {57},
pages = {101845},
year = {2025},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2025.101845},
url = {https://www.sciencedirect.com/science/article/pii/S187118712500094X},
author = {Yuqing Liu and Ameersing Luximon and Yenan Yang and Xiaoyu Li and Yao Song},
keywords = {Creativity, Suicide, Computational linguistics, Chinese poetry},
abstract = {The "mad genius" controversy concerns the intricate relationship between creativity and psychopathology. Poets, for instance, are often noted for their mental health challenges and elevated suicide rates. This study investigates the link between creativity and suicide among modern and contemporary Chinese poets by employing computational techniques to analyze semantic creativity in their works. Examining 16 poets who died by suicide alongside 21 non-suicidal counterparts, we introduced a dual model that combines flow distance and co-occurrence networks to assess creative cognition. The findings indicate that suicidal poets exhibit significantly higher local and global flow distances, reflecting greater divergent thinking. Furthermore, their co-occurrence networks display more tightly interconnected and efficient structures, suggesting enhanced cognitive flexibility. By demonstrating that heightened creativity, characterized by distinct semantic network properties, is associated with mental health challenges, the study provides empirical support for the "mad genius" hypothesis. These results contribute to the understanding of the creativity-psychopathology nexus, offering novel insights and advancing computational methods for analyzing creative expression.}
}
@article{HOSAMO2023112732,
title = {Digital Twin framework for automated fault source detection and prediction for comfort performance evaluation of existing non-residential Norwegian buildings},
journal = {Energy and Buildings},
volume = {281},
pages = {112732},
year = {2023},
issn = {0378-7788},
doi = {https://doi.org/10.1016/j.enbuild.2022.112732},
url = {https://www.sciencedirect.com/science/article/pii/S0378778822009033},
author = {Haidar Hosamo Hosamo and Henrik Kofoed Nielsen and Dimitrios Kraniotis and Paul Ragnar Svennevig and Kjeld Svidt},
keywords = {Digital twin, Building information modelling (BIM), Fault detection, Predictive maintenance, Facility management, Decision-making},
abstract = {Numerous buildings fall short of expectations regarding occupant satisfaction, sustainability, or energy efficiency. In this paper, the performance of buildings in terms of occupant comfort is evaluated using a probabilistic model based on Bayesian networks (BNs). The BN model is founded on an in-depth analysis of satisfaction survey responses and a thorough study of building performance parameters. This study also presents a user-friendly visualization compatible with BIM to simplify data collecting in two case studies from Norway with data from 2019 to 2022. This paper proposes a novel Digital Twin approach for incorporating building information modeling (BIM) with real-time sensor data, occupants’ feedback, a probabilistic model of occupants’ comfort, and HVAC faults detection and prediction that may affect occupants’ comfort. New methods for using BIM as a visualization platform, as well as a predictive maintenance method to detect and anticipate problems in the HVAC system, are also presented. These methods will help decision-makers improve the occupants’ comfort conditions in buildings. However, due to the intricate interaction between numerous equipment and the absence of data integration among FM systems, CMMS, BMS, and BIM data are integrated in this paper into a framework utilizing ontology graphs to generalize the Digital Twin framework so it can be applied to many buildings. The results of this study can aid decision-makers in the facility management sector by offering insight into the aspects that influence occupant comfort, speeding up the process of identifying equipment malfunctions, and pointing toward possible solutions.}
}
@article{SINGH2025102414,
title = {Evaluating diabetes dataset for knowledge graph embedding based link prediction},
journal = {Data & Knowledge Engineering},
volume = {157},
pages = {102414},
year = {2025},
issn = {0169-023X},
doi = {https://doi.org/10.1016/j.datak.2025.102414},
url = {https://www.sciencedirect.com/science/article/pii/S0169023X25000096},
author = {Sushmita Singh and Manvi Siwach},
keywords = {Link prediction, Knowledge graphs, Knowledge graph embeddings, Knowledge graph completion, Translational embeddings, Diabetes},
abstract = {For doing any accurate analysis or prediction on data, a complete and well-populated dataset is required. Medical based data for any disease like diabetes is highly coupled and heterogeneous in nature, with numerous interconnections. This inherently complex data cannot be analysed by simple relational databases making knowledge graphs an ideal tool for its representation which can efficiently handle intricate relationships. Thus, knowledge graphs can be leveraged to analyse diabetes data, enhancing both the accuracy and efficiency of data-driven decision-making processes. Although substantial data exists on diabetes in various formats, the availability of organized and complete datasets is limited, highlighting the critical need for creation of a well-populated knowledge graph. Moreover while developing the knowledge graph, an inevitable problem of incompleteness is present due to missing links or relationships, necessitating the use of knowledge graph completion tasks to fill in this absent information which involves predicting missing data with various Link Prediction (LP) techniques. Among various link prediction methods, approaches based on knowledge graph embeddings have demonstrated superior performance and effectiveness. These knowledge graphs can support in-depth analysis and enhance the prediction of diabetes-associated risks in this field. This paper introduces a dataset specifically designed for performing link prediction on a diabetes knowledge graph, so that it can be used to fill the information gaps further contributing in the domain of risk analysis in diabetes. The accuracy of the dataset is assessed through validation with state-of-the-art embedding-based link prediction methods.}
}
@article{GETULI2025105897,
title = {Parametric design methodology for developing BIM object libraries in construction site modeling},
journal = {Automation in Construction},
volume = {170},
pages = {105897},
year = {2025},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2024.105897},
url = {https://www.sciencedirect.com/science/article/pii/S0926580524006332},
author = {Vito Getuli and Alessandro Bruttini and Farzad Rahimian},
keywords = {BIM, Object library, Construction site, Parametric design, Modeling, planning, And product information},
abstract = {The adoption of Building Information Modeling (BIM) in construction site layout planning and activity scheduling faces challenges due to the lack of standardized approaches for digitally reproducing and organizing site elements that meet information requirements of diverse regulatory frameworks and stakeholders' use cases. This paper addresses the question of how to streamline the development of BIM objects for construction site modeling by proposing a vendor-neutral parametric design methodology and introduces a dedicated hierarchical structure for BIM object libraries to support users in their implementation. The methodology includes a six-step process for creating informative content, parametric geometries, and documentation, and is demonstrated through the development and implementation of a construction site BIM object library suitable for the Italian context. This approach fills a gap in BIM object development standards and offers a foundation for future research, benefiting practitioners and industry stakeholders involved in BIM-based site layout modeling and activity planning.}
}
@incollection{TAVAST2025,
title = {Aggregate Dictionaries and Portals},
booktitle = {Reference Module in Social Sciences},
publisher = {Elsevier},
year = {2025},
isbn = {978-0-443-15785-1},
doi = {https://doi.org/10.1016/B978-0-323-95504-1.00875-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780323955041008759},
author = {Arvi Tavast and Kristina Koppel},
keywords = {Aggregate dictionaries, Aggregate portals, Aggregated search, Combined dictionary, Dictionary portals, Language portals},
abstract = {In this chapter, we focus on aggregate dictionary portals—online platforms that provide unified and aggregated access to multiple dictionaries, termbases, thesauri and related tools. We place them in the wider context of trends in publishing lexical information, from separate publications to aggregated search to the combined dictionary, each of which is an attempt to better anticipate and meet the information requirements of users. We illustrate these concepts by examining dictionary portals developed in European lexicographic institutions.}
}
@article{RIHM2024100004,
title = {Transforming research laboratories with connected digital twins},
journal = {Nexus},
volume = {1},
number = {1},
pages = {100004},
year = {2024},
issn = {2950-1601},
doi = {https://doi.org/10.1016/j.ynexs.2024.100004},
url = {https://www.sciencedirect.com/science/article/pii/S2950160124000020},
author = {Simon D. Rihm and Jiaru Bai and Aleksandar Kondinski and Sebastian Mosbach and Jethro Akroyd and Markus Kraft},
keywords = {laboratory automation, comprehensive digital twins, connected digital twins, AI scientist, dynamic knowledge graphs, self-driving laboratories, knowledge discovery, smart lab, lab management, research facility},
abstract = {To substantially expedite scientific discovery, research laboratories need to be further automated. In this regard, the scientific community envisions an “artificial intelligence scientist” capable of planning, conducting, and assessing experiments based on higher-order goals and reasoning capabilities. We argue that a paradigm shift is necessary to bridge the gap between the current trajectory of lab automation and this vision. Adopting a systems perspective reveals several key challenges that must be addressed. We argue that achieving holistic lab automation requires a network of comprehensive distributed digital twins grounded in a universal knowledge model. Dynamic knowledge graphs are expected to play an important role, and we introduce a framework encompassing all aspects of experimental research, including infrastructure and peripheries. Our framework considers human-machine interactions from the outset to empower a goal-driven approach that brings automation to autonomy.}
}
@article{BURGUENO201982,
title = {Specifying quantities in software models},
journal = {Information and Software Technology},
volume = {113},
pages = {82-97},
year = {2019},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2019.05.006},
url = {https://www.sciencedirect.com/science/article/pii/S0950584919301156},
author = {Loli Burgueño and Tanja Mayerhofer and Manuel Wimmer and Antonio Vallecillo},
keywords = {Model-based engineering, Modeling physical quantities, Measurement uncertainty, Dimensions, Units},
abstract = {Context
An essential requirement for the design and development of any engineering application that deals with real-world physical systems is the formal representation and processing of physical quantities, comprising both measurement uncertainty and units. Although solutions exist for several programming languages and simulation frameworks, this problem has not yet been fully solved for software models.
Objective
This paper shows how both measurement uncertainty and units can be effectively incorporated into software models, becoming part of their basic type systems.
Method
We introduce the main concepts and mechanisms needed for representing and handling physical quantities in software models. More precisely, we describe an extension of basic type Real, called Quantity, and a set of operations defined for the values of that type, together with a ready-to-use library of dimensions and units, which can be added to any modeling project.
Results
We show how our approach permits modelers to safely represent and operate with physical quantities, statically ensuring type- and unit-safe assignments and operations, prior to any simulation of the system or implementation in any programming language.
Conclusion
Our approach improves the expressiveness and type-safety of software models with respect to measurement uncertainty and units of physical quantities, and its effective use in modeling projects of physical systems.}
}
@article{MONACO2022127,
title = {Linked open data in authoring virtual exhibitions},
journal = {Journal of Cultural Heritage},
volume = {53},
pages = {127-142},
year = {2022},
issn = {1296-2074},
doi = {https://doi.org/10.1016/j.culher.2021.11.002},
url = {https://www.sciencedirect.com/science/article/pii/S1296207421001667},
author = {Daniele Monaco and Maria Angela Pellegrino and Vittorio Scarano and Luca Vicidomini},
keywords = {Virtual exhibitions, Linked open data, Knowledge graph, Virtual reality, Query builder, Natural language interface},
abstract = {In the last years, virtual exhibitions have been widely adopted to enhance traditional museums and enable active interaction with culture without posing any physical constraints. Nevertheless, people interested in cultural heritage still behave as visitors. To fully engage them, we propose to let cultural heritage lovers play the role of exhibition curators. In authoring virtual exhibitions, users have to perform a data selection phase that poses several challenges, including finding data sources and extracting data of interest. We aim to take advantage of data published as Knowledge Graphs in the Linked Open Data format. Users can query geographically distributed artworks thanks to their linking nature, manipulate heterogeneous data, and easily customise their exhibitions by exploiting the wide range of available cultural heritage knowledge graphs. However, the complexity of linked open data query languages (such as SPARQL) threatens their exploitation. Consequently, we need to mask SPARQL technical challenges and guide users in naturally posing questions to unlock the potentialities of linked open data to a broader audience. We propose a virtual exhibition authoring tool that guides users from knowledge graphs querying to the automatic generation of virtual experiences. The Knowledge Graph query phase relies on ELODIE, a natural language interface to scaffold users in retrieving data of interest without asking for technical skills in query languages. We introduce our prototype by describing its operating mechanism and by detailing its components. We present a Van Gogh’s experience as a use case by collecting all the artist’s artworks published on DBpedia (a well-known and general purpose knowledge graph) and organise them in a virtual reality-based virtual exhibition. Finally, we conclude by overviewing advantages and technical challenges posed by linked open data in designing and developing knowledge graph exploitation tools.}
}
@article{GAUDETBLAVIGNAC2021,
title = {A National, Semantic-Driven, Three-Pillar Strategy to Enable Health Data Secondary Usage Interoperability for Research Within the Swiss Personalized Health Network: Methodological Study},
journal = {JMIR Medical Informatics},
volume = {9},
number = {6},
year = {2021},
issn = {2291-9694},
doi = {https://doi.org/10.2196/27591},
url = {https://www.sciencedirect.com/science/article/pii/S2291969421002040},
author = {Christophe Gaudet-Blavignac and Jean Louis Raisaro and Vasundra Touré and Sabine Österle and Katrin Crameri and Christian Lovis},
keywords = {interoperability, clinical data reuse, personalized medicine},
abstract = {Background
Interoperability is a well-known challenge in medical informatics. Current trends in interoperability have moved from a data model technocentric approach to sustainable semantics, formal descriptive languages, and processes. Despite many initiatives and investments for decades, the interoperability challenge remains crucial. The need for data sharing for most purposes ranging from patient care to secondary uses, such as public health, research, and quality assessment, faces unmet problems.
Objective
This work was performed in the context of a large Swiss Federal initiative aiming at building a national infrastructure for reusing consented data acquired in the health care and research system to enable research in the field of personalized medicine in Switzerland. The initiative is the Swiss Personalized Health Network (SPHN). This initiative is providing funding to foster use and exchange of health-related data for research. As part of the initiative, a national strategy to enable a semantically interoperable clinical data landscape was developed and implemented.
Methods
A deep analysis of various approaches to address interoperability was performed at the start, including large frameworks in health care, such as Health Level Seven (HL7) and Integrating Healthcare Enterprise (IHE), and in several domains, such as regulatory agencies (eg, Clinical Data Interchange Standards Consortium [CDISC]) and research communities (eg, Observational Medical Outcome Partnership [OMOP]), to identify bottlenecks and assess sustainability. Based on this research, a strategy composed of three pillars was designed. It has strong multidimensional semantics, descriptive formal language for exchanges, and as many data models as needed to comply with the needs of various communities.
Results
This strategy has been implemented stepwise in Switzerland since the middle of 2019 and has been adopted by all university hospitals and high research organizations. The initiative is coordinated by a central organization, the SPHN Data Coordination Center of the SIB Swiss Institute of Bioinformatics. The semantics is mapped by domain experts on various existing standards, such as Systematized Nomenclature of Medicine Clinical Terms (SNOMED CT), Logical Observation Identifiers Names and Codes (LOINC), and International Classification of Diseases (ICD). The resource description framework (RDF) is used for storing and transporting data, and to integrate information from different sources and standards. Data transformers based on SPARQL query language are implemented to convert RDF representations to the numerous data models required by the research community or bridge with other systems, such as electronic case report forms.
Conclusions
The SPHN strategy successfully implemented existing standards in a pragmatic and applicable way. It did not try to build any new standards but used existing ones in a nondogmatic way. It has now been funded for another 4 years, bringing the Swiss landscape into a new dimension to support research in the field of personalized medicine and large interoperable clinical data.}
}
@article{ZHAO2023102931,
title = {Towards a metrics suite for the complexity analysis of LabVIEW systems models},
journal = {Science of Computer Programming},
volume = {227},
pages = {102931},
year = {2023},
issn = {0167-6423},
doi = {https://doi.org/10.1016/j.scico.2023.102931},
url = {https://www.sciencedirect.com/science/article/pii/S0167642323000138},
author = {Xin Zhao and Jeff Gray},
keywords = {Software metrics, Complexity analysis, Software quality, Systems models, LabVIEW},
abstract = {LabVIEW is a popular commercial modeling tool that is often used in systems engineering. LabVIEW also includes a special programming language developed for engineers to help them support the automation of computer-aided systems. Although LabVIEW is widely used in various fields (e.g., industrial design, academic research, and engineering education), there has not been much attention given to the systems models built in LabVIEW (e.g., support for analyzing the complexity of systems models). Our previous work in surveying engineers who use LabVIEW suggests that systems engineers are deeply concerned about the complexity of the LabVIEW systems models that they create. To address the need for additional support in understanding the complexity of LabVIEW systems models, we introduce in this paper a metrics suite to assist end-users in characterizing the complexities of LabVIEW systems models from different aspects. We theoretically validated the metrics using Weyuker's validation. In addition, our metric suite was applied to 10 LabVIEW models mined from GitHub to empirically evaluate their suitability to support the description of systems model complexities. Our research is one of the first efforts to address the complexity analysis of LabVIEW systems models through a software metrics approach.}
}
@article{LUO2024100465,
title = {Exploring the mechanism of Phyllanthus urinaria L. against ulcerative colitis based on network pharmacology and in vivo experiments},
journal = {Chinese Journal of Analytical Chemistry},
volume = {52},
number = {12},
pages = {100465},
year = {2024},
issn = {1872-2040},
doi = {https://doi.org/10.1016/j.cjac.2024.100465},
url = {https://www.sciencedirect.com/science/article/pii/S1872204024001105},
author = {Qing LUO and Jiaen HUANG and Liu CAO and Ximin WANG and Gengting DONG and Weibo DAI},
keywords = {Ulcerative colitis,  L, Anti-inflammatory, TNF pathway, Network pharmacology},
abstract = {Objective
This study aims to explore the therapeutic effect and molecular mechanism of the aqueous extract of Phyllanthus urinaria L. (PUL) on ulcerative colitis (UC).
Method
PUL was administered to UC mice induced by 2.25 % DSS. The changes of body weight, disease activity index (DAI) score and colon length were recorded during the experiment. Hematoxylin and eosin (HE) staining was conducted for pathology analysis of the mice in each group. The contents of inflammatory cytokines in colon tissues were detected by Elisa. Additionally, ultra performance liquid chromatography quadrupole time-of-flight mass spectrometry (UPLC-TOF-MS/MS) method was employed to identify the main components of PUL. Then, the Traditional Chinese Medicine Systems Pharmacology Database and Analysis Platform (TCMSP) database was utilized to explore the potential active ingredients and drug targets of PUL. The matching of drug targets and disease targets yielded cross targets, which were used to construct a protein-protein interaction (PPI) network in String. Key targets underwent Gene Ontology (GO) and Kyoto Encyclopedia of Genes and Genomes (KEGG) enrichment analysis. Finally, Western blotting was performed to verify the key proteins expressions in the predicted pathway of network pharmacology and the expressions of tight junction proteins in the colon tissue.
Result
PUL has been found to effectively alleviate the symptoms such as weight loss, bloody stools, and colon shortening in mice with UC. Administration of PUL led to an increase in tight junction protein in the colonic tissue of mice, as compared to the model group. Elisa results revealed that PUL reduced the expression of pro-inflammatory factors in mice with UC. HE staining results show that PUL can alleviate colon tissue damage caused by UC. A total of 773 components were detected in the water extract of PUL, among which 26 components, including quercetin, epigallocatechin gallate and kaempferol, may possess anti-UC activity. Network pharmacology analysis suggested that PUL may play an anti-UC role by inhibiting tumor necrosis factor (TNF) pathway. Finally, Western blotting results confirmed that the PUL inhibited the TNF pathway and effectively treated UC.
Conclusion
These preliminary research results indicate that PUL has the potential to exhibit anti-inflammatory activity by inhibiting the TNF pathway, thereby alleviating symptoms associated with UC. Substances such as quercetin, epigallocatechin gallate and kaempferol in PUL are believed to play an important role in this process.}
}
@article{REN2025142075,
title = {Molecular structure and mechanism of protein MSMB, TPPP3, SPI1: Construction of novel 4 pancreatic cancer-related protein signatures model based on machine learning},
journal = {International Journal of Biological Macromolecules},
volume = {307},
pages = {142075},
year = {2025},
issn = {0141-8130},
doi = {https://doi.org/10.1016/j.ijbiomac.2025.142075},
url = {https://www.sciencedirect.com/science/article/pii/S0141813025026273},
author = {Zihan Ren and Wei Gao and Xin Li and Yuchen Jing and Zhe Liu and Xuejie Li and Tao Zhang and Xiangjun Han},
keywords = {Protein MSMB, TPPP3, SPI1, Molecular mechanism, Mechanism of action, Machine learning, Pancreatic cancer, Related proteins, Feature model construction},
abstract = {The high mortality rate of pancreatic cancer is closely related to its inconspicuous early symptoms and difficult diagnosis. In recent years, with the rapid development of proteomics and bioinformatics, the use of machine learning technology to analyze protein characteristics provides a new idea for the early diagnosis and treatment of pancreatic cancer. The main purpose of this study is to deeply analyze the molecular mechanism and action mechanism of MSMB, TPPP3 and SPI1, which are closely related to pancreatic cancer, by constructing a feature model based on machine learning. The study collected a large number of proteomic data from pancreatic cancer patients and screened out candidate proteins associated with pancreatic cancer. Then the molecular characteristics of MSMB, TPPP3 and SPI1 were analyzed by bioinformatics tools. On this basis, machine learning algorithms were used to model the expression patterns and functions of these proteins. The accuracy and generalization ability of the model were verified by cross-validation and independent test sets, and finally a feature model that effectively distinguished pancreatic cancer from normal tissue was determined. Through the construction and verification of the machine learning model, we found that the expression patterns of MSMB, TPPP3 and SPI1 proteins in pancreatic cancer tissues were significantly different. The expression of MSMB protein is down-regulated in pancreatic cancer tissue, while the expression of TPPP3 and SPI1 protein is up-regulated. Further functional analysis indicated that MSMB may be involved in the development of pancreatic cancer through regulation of cell cycle and apoptosis, TPPP3 may be related to cytoskeleton stability and cell migration ability, and SPI1 may play an important role in immune escape of pancreatic cancer. These findings provide new insights into the molecular mechanisms of pancreatic cancer.}
}
@article{DING202479,
title = {Mechanism of Wenyang Shengji Ointment in treating diabetic wounds based on network pharmacology and animal experiments},
journal = {Digital Chinese Medicine},
volume = {7},
number = {1},
pages = {79-89},
year = {2024},
issn = {2589-3777},
doi = {https://doi.org/10.1016/j.dcmed.2024.04.009},
url = {https://www.sciencedirect.com/science/article/pii/S2589377724000284},
author = {Yarong Ding and Chenlei Xie and Shuihua Feng and Zhonghang Yuan and Wei Wang and Mulin Liu and Zhongzhi Zhou and Li Chen},
keywords = {Wenyang Shengji Ointment, Diabetic wound, Wound healing, Network pharmacology, Molecular docking, Hypoxia inducible factor 1A (HIF1A)},
abstract = {Objective
To explore the mechanism of Wenyang Shengji Ointment (温阳生肌膏, WYSJO) in the treatment of diabetic wounds from the perspective of network pharmacology, and to verify it by animal experiments.
Methods
The Traditional Chinese Medicine Systems Pharmacology Database and Analysis Platform (TCMSP) and related literature were used to screen active compounds in WYSJO and their corresponding targets. GeneCards, Online Mendelian Inheritance in Man (OMIM), DrugBank, PharmGkb, and Therapeutic Target Database (TTD) databases were employed to identify the targets associated with diabetic wounds. Cytoscape 3.9.0 was used to map the active ingredients in WYSJO, which was the diabetic wound target network. Search Tool for the Retrieval of Interaction Gene/Proteins (STRING) platform was utilized to construct protein-protein interaction (PPI) network. Kyoto Encyclopedia of Genes and Genomes (KEGG) and Gene Ontology (GO) enrichment analyses were performed to identify signaling pathways between WYSJO and diabetic wounds. AutoDock 1.5.6 was used for molecular docking of core components in WYSJO to their targets. Eighteen rats were randomly divided into control, model, and WYSJO groups (n = 6). The model and WYSJO groups were used to prepare the model of refractory wounds in diabetes rats. The wound healing was observed on day 0, 5, 9, and 14 after treatment, and the wound tissue morphology was observed by hematoxylin-eosin (HE) staining. The expression levels of core genes were detected by quantitative real-time polymerase chain reaction (qPCR).
Results
A total of 76 active compounds in WYSJO, 206 WYSJO drug targets, 3 797 diabetic wound targets, and 167 diabetic wound associated WYSJO targets were screened out through network pharmacology. With the use of WYSJO-diabetic wound target network, core targets of seven active compounds encompassing quercetin, daidzein, kaempferol, rhamnetin, rhamnocitrin, strictosamide, and diisobutyl phthalate (DIBP) in WYSJO were found. GO enrichment analysis showed that the treatment of diabetes wounds with WYSJO may involve lipopolysaccharide, bacteria-derived molecules, metal ions, foreign stimuli, chemical stress, nutrient level, hypoxia, and oxidative stress in the biological processes. KEGG enrichment analysis showed that the treatment of diabetes wounds with WYSJO may involve advanced glycation end products (AGE-RAGE), p53, interleukin (IL)-17, tumor necrosis factor (TNF), hypoxia inducible factor-1 (HIF-1), apoptosis, lipid, atherosclerosis, etc. The results of animal experiments showed that WYSJO could significantly accelerate the healing process of diabetic wounds (P < 0.05), alleviate inflammatory response, promote the growth of granulation tissues, and down-regulate the expression levels of eight core genes [histone crotonyltransferase p300 (EP300), protoc gene-oncogene c-Jun (JUN), myelocytomatosis (MYC), hypoxia inducible factor 1A (HIF1A), mitogen-activated protein kinase 14 (MAPK14), specificity protein 1 (SP1), tumor protein p53 (TP53), and estrogen receptor 1 (ESR1)] predicted by the network pharmacology (P < 0.05).
Conclusion
The mechanism of WYSJO in treating diabetes wounds may be closely related to AGE-RAGE, p53, HIF-1, and other pathways. This study can provide new ideas for the pharmacological research of WYSJO, and provide a basis for its further transformation and application.}
}
@article{VIALE2023100667,
title = {Conserving traditional wisdom in a commodified landscape: Unpacking brand Ayurveda},
journal = {Journal of Ayurveda and Integrative Medicine},
volume = {14},
number = {1},
pages = {100667},
year = {2023},
issn = {0975-9476},
doi = {https://doi.org/10.1016/j.jaim.2022.100667},
url = {https://www.sciencedirect.com/science/article/pii/S0975947622001267},
author = {Marine Viale and Mark Vicol},
keywords = {Commodification, Ayurveda, Cultural appropriation, New Age Orientalism},
abstract = {As Ayurveda continues to gain global recognition as a sanctioned system of health care, the essence of Ayurveda's identity has become prey to commoditization and commodification for commercial undertakings in the holistic health milieu of India, but also in emerging markets such as Europe. This paper critically assesses the commodification of Ayurveda as a cultural signifier within Europe that separates the indigenous artefact from its Vedic origins. Often presented as an elite commodity in Western settings, Ayurveda has become embedded as a cultural artifact within consumer society as the epitome of holistic care with an emphasis on its spiritual attributes, yet simultaneously isolating it from the customary elements that motivated its inception. The paper argues that Ayurveda's discursive detachment from its ontological tenets facilitates its rearticulation as a malleable experience as it crosses national boundaries, and in this process fosters the misinterpretation of the ancient healing tradition. This process may provide Ayurvedic treatments and principles with increased visibility in Europe's health sector. However, brands are exploiting this niche with push-marketing strategies to capitalize on the budding Ayurveda industry, turning traditional medicines into emblematic commodities. To advance this argument, we examine product diversions in the commodification of classical Ayurvedic medicines in the Netherlands and Germany, focusing on the over-the-counter (OTC) segment. We present an interpretive analysis of the processes that are (de)constructing traditional practices and principles as Ayurveda travels beyond India, and how this complicates issues of authenticity and expertise as herbal medicines diverge from the indications ratified in Ayurveda's classical compendiums.}
}
@article{WOLF2024100168,
title = {Towards robotic laboratory automation plug & play: Reference architecture model for robot integration},
journal = {SLAS Technology},
volume = {29},
number = {4},
pages = {100168},
year = {2024},
issn = {2472-6303},
doi = {https://doi.org/10.1016/j.slast.2024.100168},
url = {https://www.sciencedirect.com/science/article/pii/S2472630324000505},
author = {Ádám Wolf and Panna Zsoldos and Károly Széll and Péter Galambos},
keywords = {Laboratory automation, Mobile robotics, Autonomous manipulation, System integration, Plug and play, Digital twin},
abstract = {Supportive robotic solutions take over mundane, but essential tasks from human workforce in biomedical research and development laboratories. The newest technologies in collaborative and mobile robotics enable the utilization in the human-centered and low-structured environment. Their adaptability, however, is hindered by the additional complexity that they introduce. In our paper we aim to entangle the convoluted laboratory robot integration architectures. We begin by hierarchically decomposing the laboratory workflows, and mapping the activity representations to layers and components of the automation control architecture. We elaborate the framework in detail on the example of pick-and-place labware transportation - a crucial supportive step, which we identified as the number one area of interest among experts of the field. Our concept proposal serves as a reference architecture model, the key principles of which were used in reference implementations, and are in line with international standardization efforts.}
}
@article{SINCLAIR2022100983,
title = {A cumulative, coherent and convincing theory that is also seductive, singular and selective},
journal = {The Journal of Mathematical Behavior},
volume = {67},
pages = {100983},
year = {2022},
issn = {0732-3123},
doi = {https://doi.org/10.1016/j.jmathb.2022.100983},
url = {https://www.sciencedirect.com/science/article/pii/S0732312322000517},
author = {Nathalie Sinclair},
keywords = {Commognition, Sociopolitical, Language, Method, Pluralism, Vocabulary},
abstract = {This article offers a commentary on the articles contributed to the special issue on Advances in Commognition.}
}
@article{JOHANSEN2024105849,
title = {Automated rule-based safety inspection and compliance checking of temporary guardrail systems in construction},
journal = {Automation in Construction},
volume = {168},
pages = {105849},
year = {2024},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2024.105849},
url = {https://www.sciencedirect.com/science/article/pii/S0926580524005855},
author = {K.W. Johansen and J. Teizer and C. Schultz},
keywords = {Automated construction safety inspection, Construction safety ontology, Continuous inspection, Digital safety rule-checking and reasoning, Fall protection systems, Rule-based inference, Photogrammetry, Point cloud data, Human-assisted decision-making software tools},
abstract = {The construction industry records more hazards compared to any other sector. Protective equipment, such as guardrail systems, is essential for protecting workers from deadly falls but may quickly become incompliant after installation. Yet, many construction projects do not have the resources to dedicate personnel to perform the inspection as frequently as needed. Therefore, this paper proposes an automated rule-based inspection and compliance-checking system that can assist the responsible personnel in detecting faulty guardrails in live work environments. The classification approach utilizes safety design and mimics the steps of human guardrailing compliance assessment, which enforces simplicity and transparency, allowing the human domain expert to remain in control. Even under scarce data availability, this first-of-a-kind classification approach is reliable and scalable and successfully classifies 21 predefined and 9 validation scenarios of guardrail systems for fall protection.}
}
@article{LIAO2023101273,
title = {Deep learning approaches to automatic radiology report generation: A systematic review},
journal = {Informatics in Medicine Unlocked},
volume = {39},
pages = {101273},
year = {2023},
issn = {2352-9148},
doi = {https://doi.org/10.1016/j.imu.2023.101273},
url = {https://www.sciencedirect.com/science/article/pii/S235291482300117X},
author = {Yuxiang Liao and Hantao Liu and Irena Spasić},
keywords = {Image processing, Natural language generation, Natural language processing, Deep learning, Neural network},
abstract = {Background
A radiology report communicates the imaging findings to the referring clinicians. The rising number of referrals has created a bottleneck in healthcare. Writing a report takes disproportionally more time than the imaging itself. Therefore, Automatic Radiology Report Generation (ARRG) has a great potential to unclog this bottleneck.
Objectives
This study aims to provide a systematic review of Deep Learning (DL) approaches to ARRG. Specifically, it aims to answer the following research questions. What data have been used to train and evaluate DL approaches to ARRG? How are DL approaches to ARRG evaluated? How is DL used to generate the reports from radiology images?
Materials and methods
We followed the PRISMA guidelines. We retrieved 1443 records from PubMed and Web of Science on November 3, 2021. Relevant studies were categorized and compared from multiple perspectives. The corresponding findings were reported narratively.
Results
A total of 41 studies were included. We identified 14 radiology datasets. In terms of evaluation, we identified four commonly used natural language generation metrics, six clinical efficacy metrics, and other qualitative methods. We compared DL approaches with respect to the underlying neural network architecture, the method of text generation, problem representation, training strategy, interpretability, and intermediate processing.
Discussion and conclusion
Data imbalance (normal versus abnormal cases) and the inner complexity of reports pose major difficulties in ARRG. More appropriate evaluation metrics are required as well as datasets on a much larger scale. Leveraging structured representation of radiology reports and pre-trained language models warrant further research.}
}
@article{HU2024,
title = {Semantic Web–assisted progress monitoring of crane operations in construction projects},
journal = {Proceedings of the Institution of Civil Engineers - Smart Infrastructure and Construction},
year = {2024},
issn = {2397-8759},
doi = {https://doi.org/10.1680/jsmic.24.00011},
url = {https://www.sciencedirect.com/science/article/pii/S2397875924000152},
author = {Songbo Hu and Junlin Wang and Yihai Fang},
keywords = {construction, cranes, conveyors & material handling, monitoring, planning & scheduling construction management, sensors, UN SDG 9: industry, innovation and infrastructure},
abstract = {The rising importance of cranes in modern construction has led to the need for more efficient crane monitoring and operational management. Previous studies have focused on acquiring crane monitoring data through Internet of Things (IoT) devices. However, they offer limited data reasoning capacity and only understand a few particular construction activities with distinct patterns. These limitations restrict the applicability and generalisability of crane monitoring systems in real-world projects. This study proposes a Semantic Web-based method to enhance the reasoning of crane monitoring data by correlating as-is and as-planned information of crane operations from different IoT devices and information systems. The proposed method was validated through laboratory experiments, where the transient crane behaviours during a 242.7-second lift operation were accurately detected with an average error of 0.32 seconds, and all recognised lifts were successfully matched to the six lift orders. The outcome of this study is expected to advance crane lift monitoring and management practices, leading to increased crane utilisation and project performance.}
}
@article{STEGER2021100772,
title = {Emotional cartography as a window into children's well-being: Visualizing the felt geographies of place},
journal = {Emotion, Space and Society},
volume = {39},
pages = {100772},
year = {2021},
issn = {1755-4586},
doi = {https://doi.org/10.1016/j.emospa.2021.100772},
url = {https://www.sciencedirect.com/science/article/pii/S1755458621000104},
author = {Andrew Steger and Elly Evans and Bryan Wee},
keywords = {Emotion, Emotional cartography, Qualitative GIS, Embodiment, Felt geography, Children, Geovisualization},
abstract = {More often than not, Geographic Information Systems (GIS) excludes emotion and qualitative analysis from studies of people-place relationships in favor of quantitative approaches. We employ emotional cartography as a form of qualitative GIS (qualGIS) to elevate emotions from the periphery to the center of dialogue about children's well-being. We highlight the ontological parallels between qualGIS, emotional cartography and children in society, and advance emotion maps as a way to visualize different spatial and emotional realities. In reflecting upon the felt geography of our own childhood places, we affirm the importance of children's emotional attachments to places as well as the centrality of ‘messy’ human experiences in GIS. To conclude, we discuss the implications of emotional cartography for researchers, planners and GIS, paying special attention to children's well-being amidst the current COVID-19 pandemic. In particular, this includes a call to ‘witness’ and to foster spatial empathy among those advocating for children.}
}
@article{GOMEZPROTO2025101565,
title = {Exploring genetic diversity and genomic inbreeding across local beef cattle breeds},
journal = {animal},
volume = {19},
number = {7},
pages = {101565},
year = {2025},
issn = {1751-7311},
doi = {https://doi.org/10.1016/j.animal.2025.101565},
url = {https://www.sciencedirect.com/science/article/pii/S175173112500148X},
author = {G. {Gomez Proto} and E. Mancin and A. Quaglia and F. Sbarra and R. Mantovani and C. Sartori},
keywords = {Adaptation, Autochthonous cattle, Podolian cattle, Runs of homozygosity, Rusticity},
abstract = {Beef cattle breeds from Central and Southern Italy, such as Marchigiana, Chianina, Romagnola, Maremmana, and Podolica, represent a unique genetic resource shaped by centuries of natural and artificial selection. Their origin, partly linked to the Podolian group, remains debated, while their adaptation to diverse environments and close association with regional economies enhance their zootechnical and cultural value. Despite their importance, comprehensive assessments of their genomic diversity are still limited, especially in an international context where preserving local breeds is crucial to maintain global biodiversity and resilience in livestock systems. This study investigates population structure, inbreeding, selection signatures, and effective population size using medium-density single-nucleotide polymorphism genotypes. Multivariate and clustering approaches confirmed clear genetic differentiation among breeds, with Chianina and Romagnola being the most divergent, in line with their intensive selection history. In contrast, Maremmana and Podolica displayed shared ancestral components, reflecting their adaptation to extensive and marginal environments. Pairwise Fst values supported these patterns of divergence, while the phylogenetic tree grouped specialised beef breeds (Marchigiana, Chianina, Romagnola) separately from the more rustic ones (Maremmana and Podolica). Historical Ne trajectories revealed long-term contraction in Chianina and Romagnola, whereas Podolica maintained higher Ne over time. Runs of homozygosity (ROH) were used to estimate inbreeding coefficients (FROH) and to distinguish ancient (ROH ≤ 4 Mb) from recent inbreeding (ROH ≥ 8 Mb). Chianina exhibited the highest FROH values, mainly composed of shorter ROH, suggesting older inbreeding episodes. ROH islands were detected on BTA5 and BTA6 and included genes such as FGF5, RAB21, KRT71, and DCAF16, which are linked to coat characteristics, growth, and environmental adaptation. Gene Ontology enrichment analyses indicated their involvement in relevant biological functions. Overall, this study provides a comprehensive genomic characterisation of five Italian beef cattle breeds, emphasising their differentiation, demographic history, and signatures of selection. These findings enhance the understanding of local genetic resources and contribute to broader strategies for the conservation and sustainable use of animal biodiversity in the face of global challenges.}
}
@article{WANG2025333,
title = {Multi-robot collaborative manufacturing driven by digital twins: Advancements, challenges, and future directions},
journal = {Journal of Manufacturing Systems},
volume = {82},
pages = {333-361},
year = {2025},
issn = {0278-6125},
doi = {https://doi.org/10.1016/j.jmsy.2025.06.014},
url = {https://www.sciencedirect.com/science/article/pii/S0278612525001657},
author = {Gang Wang and Cheng Zhang and Sichao Liu and Yongxuan Zhao and Yingfeng Zhang and Lihui Wang},
keywords = {Multi-robot system, Digital twin, Collaborative manufacturing, Robot},
abstract = {Multi-robot systems envisioned for future factories will promote advancements and capabilities of handling complex tasks and realising optimal robotic operations. However, existing multi-robot systems face challenges such as integration complexity, difficult coordination and control, low scalability, and flexibility, and thus are far from realising adaptive and efficient multi-robot collaborative manufacturing (MRCM). Digital twin technology improves visualisation, consistency, and spatial–temporal collaboration in MRCM through real-time interaction and iterative optimisation in physical and virtual spaces. Despite these improvements, barriers such as undeveloped modelling capabilities, indeterminate collaborative strategies, and limited applicability impede widespread integration of MRCM. In response to these needs, this study provides a comprehensive review of the foundational concepts, systematic architecture, and enabling technologies of digital twin-driven MRCM, serving as a prospective vision for future work in collaborative intelligent manufacturing. With the development of sensors and computational capabilities, robot intelligence is evolving towards multi-robot collaboration, including perceptual, cognitive, and behavioural collaboration. Digital twins play a critical supporting role in multi-robot collaboration, and the architecture, methodologies, and applications are elaborated across diverse stages of MRCM processes. This paper also identifies current challenges and future research directions. It encourages academic and industrial stakeholders to integrate state-of-the-art AI technologies more thoroughly into multi-robot digital twin systems for enhanced efficiency and reliability in production.}
}
@article{PAKKALA2025104263,
title = {On design of cognitive situation-adaptive autonomous mobile robotic applications},
journal = {Computers in Industry},
volume = {167},
pages = {104263},
year = {2025},
issn = {0166-3615},
doi = {https://doi.org/10.1016/j.compind.2025.104263},
url = {https://www.sciencedirect.com/science/article/pii/S0166361525000284},
author = {Daniel Pakkala and Niko Känsäkoski and Tapio Heikkilä and Jere Backman and Pekka Pääkkönen},
keywords = {Design, Cognitive robotics, Autonomous adaptation, Neurosymbolic AI},
abstract = {Fostered by the recent development in artificial intelligence technologies, digitalization in industries is proceeding towards intelligent automation of various physical work processes with autonomous robotic applications, in dynamic and non-deterministic environments, and in collaboration with human workers. The article presents an explorative case study on designing a cognitive situation-adaptive Autonomous Mobile Robotics (AMR) application for material hauling, in a simulated underground mining context. The goal of the research is to synthesize and present new design knowledge for improving situation-adaptation capabilities of AMR applications, which are increasingly required as the operational environments for the AMRs become dynamic, non-deterministic, and include people working on the same area with the robots. The research applies design science research methodology, and evaluates the results empirically via a prototype system, which is demonstrated in laboratory setting simulating an underground tunnel network. As an outstanding contribution, the results contribute a novel, nascent, and empirically evaluated design approach, which proposes three design aspects combining design and engineering activities across the systems engineering, knowledge engineering, computer science and robotics disciplines. Empirical evaluation is made via design, development, and demonstration of a system architecture and prototype system of a cognitive situation-adaptive AMR application, which is used in synthesis and evaluation of the design approach. The three design aspects proposed by the approach are 1) Context of operation, 2) Knowledge-driven behaviour, and 3) Knowledge driven operation. Also design challenges, future research and development needs, and innovation potential on designing of cognitive situation-adaptive AMR applications for industrial use are identified and discussed.}
}
@article{JAMIL2023120640,
title = {Toward intelligent open-ended questions evaluation based on predictive optimization},
journal = {Expert Systems with Applications},
volume = {231},
pages = {120640},
year = {2023},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2023.120640},
url = {https://www.sciencedirect.com/science/article/pii/S0957417423011429},
author = {Faisal Jamil and Ibrahim A. Hameed},
keywords = {NLP, Deep learning, Text mining, Semantic similarity, Open-ended question evaluation},
abstract = {An evaluation is administered to measure students’ learning outcomes, which nowadays become challenging for instructors as student growth increases exponentially. Several models are proposed in the literature based on selected artificial intelligence algorithms that are once trained and then deployed. The problem with these kinds of systems is that the trained models are locked and cannot adjust to dynamically changing circumstances, leading to a drop in performance. Moreover, these systems only considered basic parameters for computing the semantic similarity, resulting in less accuracy. This paper develops an intelligent student evaluation model based on a predictive optimization approach, which considers question type, structure, necessary keywords, language, and conceptual aspects to evaluate the student’s answer. In order to enhance the performance of the proposed evaluation system, we have proposed a predictive optimization approach where a deep neural network is used as a learning module to learn from training data, and particle swarm optimization and gradient descent are used as an optimization scheme to optimize weighting parameters for the deep neural network. The proposed work uses and analyzes the real dataset of NTNU students’ exams to validate the proposed platform’s practicability. Initially, we will employ the natural language processing technique of deep learning in which semantic similarity score and other features will be used to compute the degree of relevance between actual answers and students’ provided answers. The proposed semantic similarity score algorithm is based on the WordNet library and Growbag dataset to check the solution’s semantics, conceptual aspects, and creativity. The resulting score will be used as a supervised machine-learning classification system feature. Performance of the classification model will be ensured using standard evaluation measures, including Precision, recall, and f-measure. The end goal of this platform is to acquire the grade against the student’s answer given as input in the developed platform.}
}
@article{YANG2023103188,
title = {Business ecosystem model innovation based on Internet of Things big data},
journal = {Sustainable Energy Technologies and Assessments},
volume = {57},
pages = {103188},
year = {2023},
issn = {2213-1388},
doi = {https://doi.org/10.1016/j.seta.2023.103188},
url = {https://www.sciencedirect.com/science/article/pii/S2213138823001819},
author = {Yang Yang},
keywords = {Big data, Business model innovation, Internet of things, Structured output from input},
abstract = {The research paper presents a novel big data technique for conceptual modelling of Internet of Things (IoT) networks. This method enables the development of models that incorporate IoT based devices into its activities to give a business for the company while taking into account the business operational activities. This study's major goal is to assist management in making quicker effective options that depend on the structured output from their input to develop IoT networks and resources. In the big data business ecological model based on the Internet of Things, 47.5% of the integrated enterprises started to innovate the enterprise ecological model, which can better help enterprises make decisions and plan. In order to include IoT into business model innovation programs to ensure that IoT is taken into account in the overall strategy business planning and decision-making at all levels, such that the modelling and formal descriptions must be used. A number of interviews with workers from various companies and with their experts, throughout such platform were done to further illuminate this research area. Future challenges will create a constant challenge to create and adopt fresh IoT-related business models for large manufacturing organisations. The high-level strategic steps of business model innovation (BMI) are an intriguing topic for current research. These results represent a first step in the exploration of IoT adoption and serve as a springboard for promising new research directions.}
}
@article{MAHMOUD20212711,
title = {Using Semantic Web Technologies to Improve the Extract Transform Load Model},
journal = {Computers, Materials and Continua},
volume = {68},
number = {2},
pages = {2711-2726},
year = {2021},
issn = {1546-2218},
doi = {https://doi.org/10.32604/cmc.2021.015293},
url = {https://www.sciencedirect.com/science/article/pii/S1546221821009851},
author = {Amena Mahmoud and Mahmoud Y. Shams and O. M. Elzeki and Nancy Awadallah Awad},
keywords = {Semantic web, big data, ETL model, linked data, geospatial data},
abstract = {Semantic Web (SW) provides new opportunities for the study and application of big data, massive ranges of data sets in varied formats from multiple sources. Related studies focus on potential SW technologies for resolving big data problems, such as structurally and semantically heterogeneous data that result from the variety of data formats (structured, semi-structured, numeric, unstructured text data, email, video, audio, stock ticker). SW offers information semantically both for people and machines to retain the vast volume of data and provide a meaningful output of unstructured data. In the current research, we implement a new semantic Extract Transform Load (ETL) model that uses SW technologies for aggregating, integrating, and representing data as linked data. First, geospatial data resources are aggregated from the internet, and then a semantic ETL model is used to store the aggregated data in a semantic model after converting it to Resource Description Framework (RDF) format for successful integration and representation. The principal contribution of this research is the synthesis, aggregation, and semantic representation of geospatial data to solve problems. A case study of city data is used to illustrate the semantic ETL model’s functionalities. The results show that the proposed model solves the structural and semantic heterogeneity problems in diverse data sources for successful data aggregation, integration, and representation.}
}
@article{LIFE2023106138,
title = {FTD-associated behavioural and transcriptomic abnormalities in ‘humanized’ progranulin-deficient mice: A novel model for progranulin-associated FTD},
journal = {Neurobiology of Disease},
volume = {182},
pages = {106138},
year = {2023},
issn = {0969-9961},
doi = {https://doi.org/10.1016/j.nbd.2023.106138},
url = {https://www.sciencedirect.com/science/article/pii/S0969996123001523},
author = {Benjamin Life and Terri L. Petkau and Giuliano N.F. Cruz and Erick I. Navarro-Delgado and Ning Shen and Keegan Korthauer and Blair R. Leavitt},
keywords = {Progranulin, Frontotemporal dementia, Humanized mice, Preclinical model, RNAseq},
abstract = {Frontotemporal dementia (FTD) is an early onset dementia characterized by neuropathology and behavioural changes. A common genetic cause of FTD is haploinsufficiency of the gene progranulin (GRN). Mouse models of progranulin deficiency have provided insight into progranulin neurobiology, but the description of phenotypes with preclinical relevance has been limited in the currently available heterozygous progranulin-null mice. The identification of robust and reproducible FTD-associated behavioural, neuropathological, and biochemical phenotypes in progranulin deficient mice is a critical step in the preclinical development of therapies for FTD. In this work, we report the generation of a novel, ‘humanized’ mouse model of progranulin deficiency that expresses a single, targeted copy of human GRN in the absence of mouse progranulin. We also report the in-depth, longitudinal characterization of humanized progranulin-deficient mice and heterozygous progranulin-null mice over 18 months. Our analysis yielded several novel progranulin-dependent physiological and behavioural phenotypes, including increased marble burying, open field hyperactivity, and thalamic microgliosis in both models. RNAseq analysis of cortical tissue revealed an overlapping profile of transcriptomic dysfunction. Further transcriptomic analysis offers new insights into progranulin neurobiology. In sum, we have identified several consistent phenotypes in two independent mouse models of progranulin deficiency that are expected to be useful endpoints in the development of therapies for progranulin-deficient FTD. Furthermore, the presence of the human progranulin gene in the humanized progranulin-deficient mice will expedite the development of clinically translatable gene therapy strategies.}
}
@article{ALTHOBAITI2024167353,
title = {Gadd45A-mediated autophagy regulation and its impact on Alzheimer's disease pathogenesis: Deciphering the molecular Nexus},
journal = {Biochimica et Biophysica Acta (BBA) - Molecular Basis of Disease},
volume = {1870},
number = {7},
pages = {167353},
year = {2024},
issn = {0925-4439},
doi = {https://doi.org/10.1016/j.bbadis.2024.167353},
url = {https://www.sciencedirect.com/science/article/pii/S0925443924003466},
author = {Norah A. Althobaiti and Nouf S. Al-Abbas and Ifat Alsharif and Aishah E. Albalawi and Amany I. Almars and Ammar A. Basabrain and Ayman Jafer and Sawsan Abd Ellatif and Nuha M. Bauthman and Hailah M. Almohaimeed and Mona H. Soliman},
keywords = {Gadd45A, Alzheimer's disease, Neurodegeneration, Cognitive impairment, Autophagy, Synaptic plasticity},
abstract = {Background
The growth arrest and DNA damage-inducible 45 (Gadd45) gene has been implicated in various central nervous system (CNS) functions, both normal and pathological, including aging, memory, and neurodegenerative diseases. In this study, we examined whether Gadd45A deletion triggers pathways associated with neurodegenerative diseases including Alzheimer's disease (AD).
Methods
Utilizing transcriptome data from AD-associated hippocampus samples, we identified Gadd45A as a pivotal regulator of autophagy. Comprehensive analyses, including Gene Ontology enrichment and protein-protein interaction network assessments, highlighted Cdkn1A as a significant downstream target of Gadd45A. Experimental validation confirmed Gadd45A's role in modulating Cdkn1A expression and autophagy levels in hippocampal cells. We also examined the effects of autophagy on hippocampal functions and proinflammatory cytokine secretion. Additionally, a murine model was employed to validate the importance of Gadd45A in neuroinflammation and AD pathology.
Results
Our study identified 20 autophagy regulatory factors associated with AD, with Gadd45A emerging as a critical regulator. Experimental findings demonstrated that Gadd45A influences hippocampal cell fate by reducing Cdkn1A expression and suppressing autophagic activity. Comparisons between wild-type (WT) and Gadd45A knockout (Gadd45A−/−) mice revealed that Gadd45A−/− mice exhibited significant cognitive impairments, including deficits in working and spatial memory, increased Tau hyperphosphorylation, and elevated levels of kinases involved in Tau phosphorylation in the hippocampus. Additionally, Gadd45A−/− mice showed significant increases in pro-inflammatory cytokines and decreases autophagy markers in the brain. Neurotrophin levels and dendritic spine length were also reduced in Gadd45A−/− mice, likely contributing to the observed cognitive deficits.
Conclusions
These findings support the direct involvement of the Gadd45A gene in AD pathogenesis, and enhancing the expression of Gadd45A may represent a promising therapeutic strategy for the treatment of AD.}
}
@article{SHARMA2022388,
title = {Fake news detection on Twitter},
journal = {International Journal of Web Information Systems},
volume = {18},
number = {56},
pages = {388-412},
year = {2022},
issn = {1744-0084},
doi = {https://doi.org/10.1108/IJWIS-02-2022-0044},
url = {https://www.sciencedirect.com/science/article/pii/S1744008422000027},
author = {Srishti Sharma and Mala Saraswat and Anil Kumar Dubey},
keywords = {Fake news, Transfer learning, Classification, Transformers, Gradient boosting, Text classification, Twitter},
abstract = {Purpose
Owing to the increased accessibility of internet and related technologies, more and more individuals across the globe now turn to social media for their daily dose of news rather than traditional news outlets. With the global nature of social media and hardly any checks in place on posting of content, exponential increase in spread of fake news is easy. Businesses propagate fake news to improve their economic standing and influencing consumers and demand, and individuals spread fake news for personal gains like popularity and life goals. The content of fake news is diverse in terms of topics, styles and media platforms, and fake news attempts to distort truth with diverse linguistic styles while simultaneously mocking true news. All these factors together make fake news detection an arduous task. This work tried to check the spread of disinformation on Twitter.
Design/methodology/approach
This study carries out fake news detection using user characteristics and tweet textual content as features. For categorizing user characteristics, this study uses the XGBoost algorithm. To classify the tweet text, this study uses various natural language processing techniques to pre-process the tweets and then apply a hybrid convolutional neural network–recurrent neural network (CNN-RNN) and state-of-the-art Bidirectional Encoder Representations from Transformers (BERT) transformer.
Findings
This study uses a combination of machine learning and deep learning approaches for fake news detection, namely, XGBoost, hybrid CNN-RNN and BERT. The models have also been evaluated and compared with various baseline models to show that this approach effectively tackles this problem.
Originality/value
This study proposes a novel framework that exploits news content and social contexts to learn useful representations for predicting fake news. This model is based on a transformer architecture, which facilitates representation learning from fake news data and helps detect fake news easily. This study also carries out an investigative study on the relative importance of content and social context features for the task of detecting false news and whether absence of one of these categories of features hampers the effectiveness of the resultant system. This investigation can go a long way in aiding further research on the subject and for fake news detection in the presence of extremely noisy or unusable data.}
}
@article{ZHAO2024101600,
title = {PANoptosis-related long non-coding RNA signature to predict the prognosis and immune landscapes of pancreatic adenocarcinoma},
journal = {Biochemistry and Biophysics Reports},
volume = {37},
pages = {101600},
year = {2024},
issn = {2405-5808},
doi = {https://doi.org/10.1016/j.bbrep.2023.101600},
url = {https://www.sciencedirect.com/science/article/pii/S2405580823001814},
author = {Qinying Zhao and Yingquan Ye and Quan Zhang and Yue Wu and Gaoxiang Wang and Zhongxuan Gui and Mei Zhang},
keywords = {Pancreatic adenocarcinoma, PANoptosis, Long non-coding RNAs, Prognostic signature, Immunotherapy},
abstract = {Background
Cancer growth is significantly influenced by processes such as pyroptosis, apoptosis, and necroptosis that underlie PANoptosis, a proinflammatory programmed cell death. Several studies have examined the long non-coding RNAs (lncRNAs) associated with pancreatic adenocarcinoma (PAAD). However, the predictive value of lncRNAs related to PANoptosis for PAAD has not been established.
Methods
The Clinical Genome Atlas database was used to obtain the transcriptome 、clinical data and the corresponding mutation data of the patients with PAAD in this study. The least absolute shrinkage and selection operator regression analysis was employed to obtain prognosis-related lncRNAs for constructing a risk signature. According to the median risk score of the signature, patients with PAAD were grouped into low- and high-risk groups to further compare the survival prognosis of different risk groups. Time-dependent receiver operating characteristic curves, c-index analysis, nomograms, principal component analysis and univariate Cox and multivariate Cox regression were performed for the internal validation of the signature. In addition, enrichment analysis of different genes was performed using gene ontology (GO) and Kyoto Encyclopedia of Genes and Genomes (KEGG) analysis. Lastly, differences in tumor mutation burden (TMB), immune function, tumor immune dysfunction and rejection (TIDE), and drug response were determined for the two risk groups.
Results
The signature was constructed with six PANoptosis-related lncRNAs (AC067817.2、LINC02004、AC243829.1、AC092171.5、AP005233.2、AC004687.1) that predicted the prognosis of the patients with PAAD. Survival curves showed that patients in the two risk groups had statistically significant differences in prognosis (P < 0.05), and multi-cox regression analysis identified risk score as an independent risk factor for PAAD prognosis, and internal validation of nomograms showed high confidence in the signature. GO and KEGG enrichment analysis showed functional and pathway differences between the high- and low-risk groups. TMB evaluation demonstrated that patients in the high-risk group had a higher frequency of mutations. The TIDE score indicated that the high-risk group had a lower risk of immunotherapy escape and better immunotherapy outcomes. Additionally, the two risk groups revealed significantly different responses to 11 anticancer drugs.
Conclusion
We identified a novel risk signature for PANoptosis-related lncRNAs, which is a standalone prognostic indicator for PAAD. The PANoptosis-related lncRNA risk signature may be relevant for immunotherapy and a therapeutic target for PAAD.}
}
@article{PAWAR2023,
title = {Study and Analysis of Various Cloud Security, Authentication, and Data Storage Models:},
journal = {International Journal of Decision Support System Technology},
volume = {15},
number = {1},
year = {2023},
issn = {1941-6296},
doi = {https://doi.org/10.4018/IJDSST.315760},
url = {https://www.sciencedirect.com/science/article/pii/S1941629623000022},
author = {Ankush Balaram Pawar and Shashikant U. Ghumbre and Rashmi M. Jogdand},
keywords = {Authentication, Cloud Storage, Data Security, Data Storage, Privacy Preservation},
abstract = {ABSTRACT
In recent days, widespread acceptance of cloud data storage applications increases various privacy problems and security problems. Outsourced data security is considered the main confrontation for cloud clients because of data control loss. This review presents a detailed survey of 50 research papers presenting privacy preservation approaches, namely authentication-based, cloud security-based, data storage-based, data security-based, and encryption-based techniques. The analysis is considered based on the categorization of approaches, dataset employed, utilized software tools, published year, and the performance metrics are discussed. Furthermore, problems raised in existing privacy preservation techniques are elucidated in the research gaps and problems section. The future work of this study is based on the research gaps and problems recognized from present research schemes. Additionally, JAVA software language is widely utilized for implementing privacy preservation models, and the Amazon access sample database is a commonly employed dataset for the privacy preservation approach.}
}
@article{BELLINI2018142,
title = {Managing cloud via Smart Cloud Engine and Knowledge Base},
journal = {Future Generation Computer Systems},
volume = {78},
pages = {142-154},
year = {2018},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2016.10.006},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X16303867},
author = {Pierfrancesco Bellini and Ivan Bruno and Daniele Cenni and Paolo Nesi},
keywords = {Knwoledge base, Smart cloud, Cloud computing, Service level agreement},
abstract = {Complexity of cloud infrastructures needs models and tools for process management, configuration, scaling, elastic computing and cloud resource health control. This paper presents a Smart Cloud Engine and solution based on a Knowledge Base, KB, with the aim of modeling cloud resources, Service Level Agreements and their evolutions, and enabling the reasoning on structures by implementing strategies of efficient smart cloud management and intelligence. The solution proposed provides formal verification and intelligence tools for cloud control. It can be easily integrated with a large range of cloud configuration manager, cloud orchestrator, and monitoring tools, since the connections with these tools are performed by using REST calls and XML files. The proposed solution has been validated in the context of large ICARO Cloud project and in the cloud facility of a national cloud service provider. Some data resulting from the validation phases have been reported and are referring to the dynamic management of real ECLAP social network http://www.eclap.eu.}
}
@article{FORTH2023112837,
title = {Calculation of embodied GHG emissions in early building design stages using BIM and NLP-based semantic model healing},
journal = {Energy and Buildings},
volume = {284},
pages = {112837},
year = {2023},
issn = {0378-7788},
doi = {https://doi.org/10.1016/j.enbuild.2023.112837},
url = {https://www.sciencedirect.com/science/article/pii/S0378778823000671},
author = {Kasimir Forth and Jimmy Abualdenien and André Borrmann},
keywords = {BIM, NLP, Model healing, Early design stage, LCA},
abstract = {To reach the goals of limiting global warming, the embodied greenhouse gas (GHG) emissions of new buildings need to be quantified and optimized in the very early design stages, during which design decisions significantly influence the success of projects in achieving their performance goals. Semantically rich building information models (BIM) enable to perform an automated quantity take-off of the relevant elements for calculating a whole building life cycle assessment (LCA). However, imprecise type and property information often found in today’s BIM practice hinders a seamless processing for downstream applications. At the same time, the early design stages are characterized by high uncertainty due to the lack of information and knowledge, making a holistic and consistent LCA for supporting design decisions and optimizing performance challenging. In assessing this often vague information, it is essential to consider different levels of element and material information for matching BIM to LCA data. For example, the structural properties of concrete are not yet defined in early design stages and should instead be considered as a range of material options due to different compressive strength classes. This paper presents a novel methodology for automatically matching the coarse information available in BIM models of the early design stages to the respective entries in LCA databases as a basis for a fully automated calculation process of the embodied GHG emissions of new buildings. This approach solves the existing gap in the automation process of manually enriching BIM models and adding information of LCA data and missing layers of vague models. In more detail, the proposed method is based on Natural Language Processing (NLP), using different strategies to increase performance in matching elements and materials from a BIM model to a knowledge database to enrich environmental indicators of commonly used elements’ materials. The knowledge database contains all missing information for LCAs and has different levels of information for a range of several potential design options of elements and materials, including their dependencies. Accordingly, this paper investigates multiple NLP techniques and evaluates the performance of state-of-the-art deep learning models such as GermaNet, SpaCy, or BERT. Following this, the most performant NLP approach is used to provide an automatic workflow for matching Industry Foundation Classes (IFC) elements to the knowledge database, facilitating a seamless LCA in the early stages of design. For five different case studies, the performances of the proposed matching method are analyzed. Finally, one case study is selected to compare the embodied emissions results to those of the conventional process.}
}
@article{REINIER2025101614,
title = {Observational study of sudden cardiac arrest risk (OSCAR): Rationale and design of an electronic health records cohort},
journal = {IJC Heart & Vasculature},
volume = {56},
pages = {101614},
year = {2025},
issn = {2352-9067},
doi = {https://doi.org/10.1016/j.ijcha.2025.101614},
url = {https://www.sciencedirect.com/science/article/pii/S235290672500017X},
author = {Kyndaron Reinier and Harpriya S. Chugh and Audrey Uy-Evanado and Elizabeth Heckard and Marco Mathias and Nichole Bosson and Vinicius F. Calsavara and Piotr J. Slomka and David A. Elashoff and Alex A.T. Bui and Sumeet S Chugh},
keywords = {Sudden cardiac death, Out-of-hospital cardiac arrest, Electronic health records cohort, Prediction},
abstract = {Background
Out-of-hospital sudden cardiac arrest (SCA) is a major cause of mortality and improved risk prediction is needed. The Observational Study of Sudden Cardiac Arrest Risk (OSCAR) is an electronic health records (EHR)-based cohort study of patients receiving routine medical care in the Cedars-Sinai Health System (CSHS) in Los Angeles County, CA designed to evaluate predictors of SCA. This paper describes the rationale, objectives, and study design for the OSCAR cohort.
Methods and Results
The OSCAR cohort includes 379,833 Los Angeles County residents with at least one patient encounter at CSHS in each of two consecutive calendar years from 2016 to 2020. We obtained baseline cohort characteristics from the EHR from 2012 until the start of follow-up, including demographics, vital signs, clinical diagnoses, cardiac tests and imaging, procedures, laboratory results, and medications. Follow-up will continue until Dec. 31, 2025, with an expected median follow-up time of ∼ 7 years. The primary outcome is out-of-hospital SCA of likely cardiac etiology attended by Los Angeles County Emergency Medical Services (LAC-EMS). The secondary outcome is total mortality identified using California Department of Public Health – Vital Records death certificates. We will use conventional approaches (diagnosis code algorithms) and artificial intelligence (natural language processing, deep learning) to define patient phenotypes and biostatistical and machine learning approaches for analysis.
Conclusions
The OSCAR cohort will provide a large, diverse dataset and adjudicated SCA outcomes to facilitate the derivation and testing of risk prediction models for incident SCA.}
}
@article{LI2022109889,
title = {A knowledge graph completion model based on contrastive learning and relation enhancement method},
journal = {Knowledge-Based Systems},
volume = {256},
pages = {109889},
year = {2022},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2022.109889},
url = {https://www.sciencedirect.com/science/article/pii/S0950705122009820},
author = {LinYu Li and Xuan Zhang and YuBin Ma and Chen Gao and Jishu Wang and Yong Yu and Zihao Yuan and Qiuying Ma},
keywords = {Knowledge graph, Knowledge graph completion, Contrastive learning, Graph attention network, Link prediction},
abstract = {The rapid development in knowledge graph (KG) technology and its popularity in the field of artificial intelligence (AI) have significantly increased the support for similar KG-based applications. However, there is a concerning problem regarding KGs; most of them are often incomplete. This motivated us to study knowledge graph completion (KGC). Some recent studies have used graph neural networks (GNN) such as graph convolutional networks (GCN) to model graph-structured data, providing good results on KGC tasks. However, the edge weights in GCN models are controlled by degree, a measure that moderately ignores the differences among relation information. To address the above limitations and obtain better KGC, we propose a model based on graph attention networks (GATs) and contrastive learning (CL), called the CLGAT-KGC model. This model introduces the graph attention mechanism and adds different representations of entities under the same entity corresponding to different relations to enhance the entity-relation message function. Additionally, a new CL method is proposed under the CLGAT-KGC model to better learn the embedding of entities and relations in the KG domain. We have completely verified the effectiveness of this model through extensive experiments.}
}
@article{DEBNATH2025100325,
title = {CovKG: A Covid-19 Knowledge Graph for enabling multidimensional analytics on Covid-19 epidemiological data considering spatiotemporal, environmental, health, and socioeconomic aspects},
journal = {International Journal of Information Management Data Insights},
volume = {5},
number = {1},
pages = {100325},
year = {2025},
issn = {2667-0968},
doi = {https://doi.org/10.1016/j.jjimei.2025.100325},
url = {https://www.sciencedirect.com/science/article/pii/S2667096825000072},
author = {Rudra Pratap {Deb Nath} and S.M. Shafkat Raihan and Tonmoy Chandro Das and Torben Bach Pedersen and Debasish Ghose},
keywords = {Knowledge Graph, Covid-19, Multidimensional analysis, FAIR principles, Linked data, Semantic technology},
abstract = {The Covid-19 pandemic is influenced by many environmental, health, and socioeconomic aspects such as air pollution, comorbidity, occupation, etc. To better manage future pandemics, decision-makers need comprehensive data on Covid-19 mortality and morbidity. Most Covid-19 data sources focus on spatiotemporal aspects, and existing research often overlook the combined impact of multiple interconnected factors. This study introduces a Covid-19 Knowledge Graph (CovKG) derived from 20 data sources, enabling multidimensional analysis of epidemiological data, including time, location, temperature, comorbidity, occupation, and others. CovKG is modeled using RDF, connected to 10,951 external resources, and semantically enriched with Data Cube (QB) and QB for OLAP (QB4OLAP) vocabularies to adhere to the FAIR principles and ensure OLAP compatibility. Finally, we perform a qualitative and comparative evaluation and extract statistical insights across multiple dimensions of Covid-19 epidemiology. When assessed, CovKG answers 100% of competency queries, outperforming other data stores that only answer 39%. CovKG and its analytical interface are available at https://bike-csecu.com/datasets/CovKG/.}
}
@article{GUPTA2023102141,
title = {Generating multiple conceptual models from behavior-driven development scenarios},
journal = {Data & Knowledge Engineering},
volume = {145},
pages = {102141},
year = {2023},
issn = {0169-023X},
doi = {https://doi.org/10.1016/j.datak.2023.102141},
url = {https://www.sciencedirect.com/science/article/pii/S0169023X23000010},
author = {Abhimanyu Gupta and Geert Poels and Palash Bera},
keywords = {Conceptual modeling, User stories, Agile software development, Behavior-driven development, Automated model generation},
abstract = {Researchers have proposed that generating conceptual models automatically from user stories might be useful for agile software development. It is, however, unclear from the state-of-the-art what a consistent and complementary set of models to generate is, how these models can be generated such that relationships and dependencies in a set of related user stories are unveiled, and why these models are useful in agile software development projects. In this paper, we address these questions through a Design Science research study. First, we define four stylized versions of Unified Modeling Language (UML) diagrams (i.e., use case diagram, class diagram, activity diagram, state machine diagram) that will be the target of the model generation. Although these stylized UML diagrams have a reduced abstract syntax, they offer different perspectives on the software system in focus with potential usefulness for requirements and software engineering. Second, we develop an automated model generation approach based on different design artifacts including a Natural Language Processing (NLP) tool that implements our approach. Key to our solution is the use of the Behavior-Driven Development (BDD) scenario template to document user stories. Using an example set of BDD scenarios as source of the model generation, we demonstrate the feasibility of our approach via the NLP tool that implements our approach. Third, we conduct an empirical study with experts in agile software development involving the researcher-guided interactive use of our tool to explore the use of the generated models. This study shows the perceived usefulness of the models that our tool can generate and identifies different uses and benefits of the models for requirements analysis, system design, software implementation, and testing in projects that employ agile methods.}
}
@article{OSUNA202357,
title = {Towards the construction of computational models of emotions from the perspective of a software system},
journal = {Cognitive Systems Research},
volume = {78},
pages = {57-70},
year = {2023},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2022.12.003},
url = {https://www.sciencedirect.com/science/article/pii/S138904172200105X},
author = {Enrique Osuna and Elsa L. Padilla and Luis-Felipe Rodríguez},
keywords = {Computational model of emotion, Software engineering, Cognitive agent architecture, Software design pattern},
abstract = {Computational models of emotion (CMEs) are software systems designed to emulate the diverse aspects of the human emotion process. This type of model is commonly incorporated into cognitive agent architectures to provide mechanisms underlying affective behavior. The construction of CMEs involve theories that explain human emotion as well as computational artifacts related to the design and implementation of software systems. Although most CMEs reported in the literature provide details on their theoretical foundations, it is uncommon to find details about the computational practices and artifacts utilized during their design and implementation phases. This paper presents and discusses some challenges associated with the computational nature of this type of model: (i) Software quality attributes in CMEs, (ii) Interoperability between CMEs and cognitive components, (iii) Formal procedures for the design of CMEs, and (iv) Reference schemes to validate CMEs. Software engineering is used as a reference to propose and discuss these challenges. In addition, a reference architecture designed by following software engineering practices and artifacts is proposed to discuss the implications of addressing these challenges. The present research is at the intersection of human emotion modeling and software engineering to contribute to the software development process of affective systems.}
}
@article{FORBES2025101796,
title = {Preserving model structure and constraints in scientific computing},
journal = {Measurement: Sensors},
volume = {38},
pages = {101796},
year = {2025},
note = {Proceedings of the XXIV IMEKO World Congress},
issn = {2665-9174},
doi = {https://doi.org/10.1016/j.measen.2024.101796},
url = {https://www.sciencedirect.com/science/article/pii/S2665917424007724},
author = {Alistair Forbes and Keith Lines and Fredrik Nordvall Forsberg and Conor McBride and Andre Videla},
keywords = {Dimensioned variable, Functional programming, Numerical computation, Units of measurement},
abstract = {In this paper, we look at how model structure and constraints can be incorporated into scientific computing using functional programming and, implicitly, category theory, in a way that constraints are automatically satisfied. Category theory is the study of different types of objects (e.g., sets, groups, vector spaces) and mappings between them (e.g., functions, homomorphisms, matrices) and is used in mathematics to model the underlying structure associated with systems we wish to describe and how this underlying structure is preserved under transformations. In this paper, we look at the structure associated with the representation of, and calculations using, quantitative data. In particular, we describe how measurement data can be represented in terms of the product C × D of two groups: the first, C, the counting algebra, and the second, D, the dimension algebra. Different but equivalent unit systems are related through group isomorphisms. The structure associated with this representation can be embedded in software using functional programming.}
}
@article{ATTWELL2023101465,
title = {Reference architecture design for computer-based speech therapy systems},
journal = {Computer Speech & Language},
volume = {78},
pages = {101465},
year = {2023},
issn = {0885-2308},
doi = {https://doi.org/10.1016/j.csl.2022.101465},
url = {https://www.sciencedirect.com/science/article/pii/S0885230822000882},
author = {Geertruida Aline Attwell and Kwabena Ebo Bennin and Bedir Tekinerdogan},
keywords = {Online speech therapy system, Reference architecture, Architecture design, Communication disorder},
abstract = {With the current international shortage of speech-language pathologists (SLPs), there is a demand for online tools to support SLPs with their daily tasks. For this purpose, several online speech therapy systems (OSTSs) have been proposed and discussed in the literature. However, developing these OSTSs is not trivial since it involves the consideration of various functional and quality concerns. Hence, for communicating the design decisions and guiding the development and analysis of these systems, a proper architecture design is important. Unfortunately, the architecture design of OSTSs has not been explicitly addressed in the literature. To this end, we present a reference architecture for OSTSs which has been designed following well-established architecture design methods. The reference architecture captures the reusable design elements of OSTSs and can be used to derive various different application architectures. A case study approach is used to illustrate and validate the use of the presented reference architecture.}
}
@article{KOMI2025104238,
title = {“The real truth about wolves”: Political ecology of wildlife conservation in the post-truth era},
journal = {Geoforum},
volume = {160},
pages = {104238},
year = {2025},
issn = {0016-7185},
doi = {https://doi.org/10.1016/j.geoforum.2025.104238},
url = {https://www.sciencedirect.com/science/article/pii/S0016718525000387},
author = {Sanna Komi},
keywords = {Conservation, Finland, Political ecology, Post-truth, Wolf},
abstract = {Using a political ecology lens, this paper examines the impact of the post-truth era on wolf conservation debates in Finland. Based on ethnographic fieldwork in Lieksa, and analysis of discussions in two Facebook groups focused on large carnivores from 2018 to 2023, it reveals a fundamental concern for the future of rural life and traditions. Critics of wolf conservation, while distrusting of conservation scientists, mimic scientific language and official data to convey their perceptions of the “real truth about wolves”. Such post-truth strategies, along with rumours and conspiracy theories, provide means to criticize conservation practices, but also exemplify power struggles over wildlife management. In essence, this paper posits that post-truth can be seen as a response to a post-political society where environmental governance is based on “objective” science, bypassing diverse value-laden nature relations. The study underscores the need for political dialogue to address the post-truth era’s challenges.}
}
@article{CLARK2021106567,
title = {Test case generation for agent-based models: A systematic literature review},
journal = {Information and Software Technology},
volume = {135},
pages = {106567},
year = {2021},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2021.106567},
url = {https://www.sciencedirect.com/science/article/pii/S0950584921000501},
author = {Andrew G. Clark and Neil Walkinshaw and Robert M. Hierons},
keywords = {Agent-based modelling, Multi-agent systems, Software testing, Test case generation, Systematic literature review},
abstract = {Context:
Agent-based models play an important role in simulating complex emergent phenomena and supporting critical decisions. In this context, a software fault may result in poorly informed decisions that lead to disastrous consequences. The ability to rigorously test these models is therefore essential.
Objective:
Our objective is to summarise the state-of-the-art techniques for test case generation in agent-based models and identify future research directions.
Method:
We have conducted a systematic literature review in which we pose five research questions related to the key aspects of test case generation in agent-based models: What are the information artifacts used to generate tests? How are these tests generated? How is a verdict assigned to a generated test? How is the adequacy of a generated test suite measured? What level of abstraction of an agent-based model is targeted by a generated test?
Results:
Out of the 464 initial search results, we identified 24 primary publications. Based on these primary publications, we formed a taxonomy to summarise the state-of-the-art techniques for test case generation in agent-based models. Our results show that whilst the majority of techniques are effective for testing functional requirements at the agent and integration levels of abstraction, there are comparatively few techniques capable of testing society-level behaviour. Furthermore, the majority of techniques cannot test non-functional requirements or “soft goals”.
Conclusions:
This paper reports insights into the key developments and open challenges concerning test case generation in agent-based models that may be of interest to both researchers and practitioners. In particular, we identify the need for test case generation techniques that focus on societal and non-functional behaviour, and a more thorough evaluation using realistic case studies that feature challenging properties associated with a typical agent-based model.}
}
@article{FILICE20191279,
title = {Radiology-Pathology Correlation to Facilitate Peer Learning: An Overview Including Recent Artificial Intelligence Methods},
journal = {Journal of the American College of Radiology},
volume = {16},
number = {9, Part B},
pages = {1279-1285},
year = {2019},
note = {Special Issue: Quality and Data Science},
issn = {1546-1440},
doi = {https://doi.org/10.1016/j.jacr.2019.05.010},
url = {https://www.sciencedirect.com/science/article/pii/S1546144019305940},
author = {Ross W. Filice},
keywords = {Artificial intelligence, deep learning, peer learning, pathology, quality},
abstract = {Correlation of pathology reports with radiology examinations has long been of interest to radiologists and helps to facilitate peer learning. Such correlation also helps meet regulatory requirements, ensures quality, and supports multidisciplinary conferences and patient care. Additional offshoots of such correlation include evaluating for and ensuring concordance of pathology results with radiology interpretation and procedures as well as ensuring specimen adequacy after biopsy. For much of the history of radiology, this correlation has been done manually, which is time consuming and cumbersome and provides coverage of only a fraction of radiology examinations performed. Electronic storage and indexing of radiology and pathology information laid the foundation for easier access and for the development of automated artificial intelligence methods to match pathology information with radiology reports. More recent techniques have resulted in near comprehensive coverage of radiology examinations with methods to present results and solicit feedback from end users. Newer deep learning language modeling techniques will advance these methods by providing more robust automated and comprehensive radiology-pathology correlation with the ability to rapidly, flexibly, and iteratively tune models to site and user preference.}
}
@article{ZHONG2020101195,
title = {A building regulation question answering system: A deep learning methodology},
journal = {Advanced Engineering Informatics},
volume = {46},
pages = {101195},
year = {2020},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2020.101195},
url = {https://www.sciencedirect.com/science/article/pii/S1474034620301658},
author = {Botao Zhong and Wanlei He and Ziwei Huang and Peter E.D. Love and Junqing Tang and Hanbin Luo},
keywords = {Building regulation, Deep learning, Question answering, Natural language processing},
abstract = {Regulations play an important role in assuring the quality of a building’s construction and minimizing its adverse environmental impacts. Engineers and the like need to retrieve regulatory information to ensure a building conforms to specified standards. Despite the availability of search engines and digital databases that can be used to store regulations, engineers, for example, are unable to retrieve information for domain-specific needs in a timely manner. As a consequence, users often have to deal with the burden of browsing and filtering information, which can be a time-consuming process. This research develops a robust end-to-end methodology to improve the efficiency and effectiveness of retrieving queries pertaining to building regulations. The developed methodology integrates information retrieval with a deep learning model of Natural Language Processing (NLP) to provide precise and rapid answers to user’s questions from a collection of building regulations. The methodology is evaluated and a prototype system to retrieve queries is developed. The paper’s contribution is therefore twofold as it develops a: (1) methodology that combines NLP and deep learning to be able to address queries raised about the building regulations; and (2) chatbot of question answering system, which we refer to as QAS4CQAR. Our proposed methodology has powerful feature representation and learning capability and therefore can potentially be adopted to building regulations in other jurisdictions.}
}
@article{SLUSNA2024423,
title = {Functional dysregulation of the auditory cortex in bilateral perisylvian polymicrogyria: Multiparametric case analysis of the absent speech phenotype},
journal = {Cortex},
volume = {171},
pages = {423-434},
year = {2024},
issn = {0010-9452},
doi = {https://doi.org/10.1016/j.cortex.2023.11.006},
url = {https://www.sciencedirect.com/science/article/pii/S0010945223002927},
author = {Dominika Slušná and Jiwandeep S. Kohli and Janice Hau and Juan {Álvarez-Linera Prado} and Annika C. Linke and Wolfram Hinzen},
keywords = {Cortical development, fMRI, Nonverbal, Polymicrogyria, White matter connectivity},
abstract = {The absence of speech is a clinical phenotype seen across neurodevelopmental syndromes, offering insights for neural language models. We present a case of bilateral perisylvian polymicrogyria (BPP) and complete absence of speech with considerable language comprehension and production difficulties. We extensively characterized the auditory speech perception and production circuitry by employing a multimodal neuroimaging approach. Results showed extensive cortical thickening in motor and auditory-language regions. The auditory cortex lacked sensitivity to speech stimuli despite relatively preserved thalamic projections yet had no intrinsic functional organization. Subcortical structures implicated in early stages of processing exhibited heightened sensitivity to speech. The arcuate fasciculus, a suggested marker of language in BPP, showed similar volume and integrity to a healthy control. The frontal aslant tract, linked to oromotor function, was partially reconstructed. These findings highlight the importance of assessing the auditory cortex beyond speech production structures to understand absent speech in BPP. Despite profound cortical alterations, the intrinsic motor network and motor-speech pathways remained largely intact. This case underscores the need for comprehensive phenotyping using multiple MRI modalities to uncover causes of severe disruption in language development.}
}
@article{SIK2021203,
title = {Assessing the readiness of Turkish health information systems for integrating genetic/genomic patient data: System architecture and available terminologies, legislative, and protection of personal data},
journal = {Health Policy},
volume = {125},
number = {2},
pages = {203-212},
year = {2021},
issn = {0168-8510},
doi = {https://doi.org/10.1016/j.healthpol.2020.12.004},
url = {https://www.sciencedirect.com/science/article/pii/S0168851020303031},
author = {Ayhan Serkan Şık and Arsev Umur Aydınoğlu and Yeşim {Aydın Son}},
keywords = {Genetic test data representation in Turkey’s EHR, Rules and Regulations about Genetic Testing in Turkey, Genomic data management, Turkish EHR},
abstract = {Advances in genetic/genomic research and translational studies drive the progress on molecular diagnosis, personalised treatment, and monitoring. Healthcare professionals and governments are encouraged to set administrative regulations and implement structured and interoperable representation to utilise the genetic/genomic data, which will support precision medicine approaches through Health Information Systems (HIS). Clear regulations and careful legislation are also crucial for the security and privacy of genetic/genomic test data. In this article, we present a review of the National Health Information System of Turkey (NHIS-T) about interoperable health data representation for genetic tests. We discuss the content of rules and regulations related to genetic/genomic testing and structured data representation in Turkey. A brief comparison of the Turkish “Law on the Protection of Personal Data” (LPPD) in genetic/genomic data privacy with its counterparts is presented. The final discussion about the shortcomings of Turkey is transferable to health information systems worldwide. Constructing a national reference database and IT infrastructure to enable data integration and exchange between genomic data, metadata, and health records will improve genetics studies’ utility and outcomes. The critical success factors behind integration are establishing broadly accepted terminologies and government guidance. The governments should set clear a transparent policy defining the legal and ethical framework, workforce training, clinical decision-support tools, public engagement, and education concurrently.}
}
@article{BCHETNIA2022100847,
title = {Expression signature of the Leigh syndrome French-Canadian type},
journal = {Molecular Genetics and Metabolism Reports},
volume = {30},
pages = {100847},
year = {2022},
issn = {2214-4269},
doi = {https://doi.org/10.1016/j.ymgmr.2022.100847},
url = {https://www.sciencedirect.com/science/article/pii/S2214426922000076},
author = {Mbarka Bchetnia and Jessica Tardif and Charles Morin and Catherine Laprise},
keywords = {Leigh syndrome French-Canadian type (LSFC), Gene expression, Microarrays, , , Mitochondrial chain respiration, Cytochrome  oxidase, rare diseases, Leigh syndrome},
abstract = {As a result of a founder effect, a Leigh syndrome variant called Leigh syndrome, French-Canadian type (LSFC, MIM / 220,111) is more frequent in Saguenay–Lac-Saint-Jean (SLSJ), a geographically isolated region on northeastern Quebec, Canada. LSFC is a rare autosomal recessive mitochondrial neurodegenerative disorder due to damage in mitochondrial energy production. LSFC is caused by pathogenic variants in the nuclear gene leucine-rich pentatricopeptide repeat-containing (LRPPRC). Despite progress understanding the molecular mode of action of LRPPRC gene, there is no treatment for this disease. The present study aims to identify the biological pathways altered in the LSFC disorder through microarray-based transcriptomic profile analysis of twelve LSFC cell lines compared to twelve healthy ones, followed by gene ontology (GO) and pathway analyses. A set of 84 significantly differentially expressed genes were obtained (p ≥ 0.05; Fold change (Flc) ≥ 1.5). 45 genes were more expressed (53.57%) in LSFC cell lines compared to controls and 39 (46.43%) had lower expression levels. Gene ontology analysis highlighted altered expression of genes involved in the mitochondrial respiratory chain and energy production, glucose and lipids metabolism, oncogenesis, inflammation and immune response, cell growth and apoptosis, transcription, and signal transduction. Considering the metabolic nature of LSFC disease, genes included in the mitochondrial respiratory chain and energy production cluster stood out as the most important ones to be involved in LSFC mitochondrial disorder. In addition, the protein-protein interaction network indicated a strong interaction between the genes included in this cluster. The mitochondrial gene NDUFA4L2 (NADH dehydrogenase [ubiquinone] 1 alpha subcomplex, 4-like 2), with higher expression in LSFC cells, represents a target for functional studies to explain the role of this gene in LSFC disease. This work provides, for the first time, the LSFC gene expression profile in fibroblasts isolated from affected individuals. This represents a valuable resource to understand the pathogenic basis and consequences of LRPPRC dysfunction.}
}
@article{GACITUA2025105115,
title = {Structured insights: Enhancing disaster preparedness through survivor testimonies and interoperable data systems},
journal = {International Journal of Disaster Risk Reduction},
volume = {116},
pages = {105115},
year = {2025},
issn = {2212-4209},
doi = {https://doi.org/10.1016/j.ijdrr.2024.105115},
url = {https://www.sciencedirect.com/science/article/pii/S221242092400877X},
author = {Ricardo Gacitua and Michael Klafft and Ivana Harari and Solhanlle Bonilla Duarte and Agnieszka Dudzinska-Jarmolinska},
keywords = {Natural hazard, Survivor testimonies, Interoperable data systems},
abstract = {Capturing qualitative data from disaster survivors is essential for understanding their experiences and improving disaster response strategies. This data is vital for informed decision-making and enhancing disaster preparedness. Despite the critical importance of these narratives, a significant gap exists in systematically collecting, preserving, and utilizing these experiences. Most survivors’ testimonies remain undocumented, leading to a loss of valuable insights over time. This paper presents an innovative international effort to bridge these gaps through a collaborative framework. We have developed a structured schema and a web-based platform that enhance the interoperability of qualitative disaster data across different linguistic and cultural contexts. Our approach involves standardized guidelines for conducting and transcribing interviews with disaster survivors, ensuring consistent data capture and facilitating computational analysis and sharing. Our model supports the effective registration and interoperability of disaster narratives, making them accessible for global disaster management communities. This integrated, cross-cultural approach significantly advances the interoperability of disaster-related data, promoting a more profound understanding of disasters and supporting evidence-based strategies for risk reduction and management.}
}
@incollection{CAMPOS2019349,
title = {Chapter 16 - Sentiment concept embedding for visual affect recognition},
editor = {Xavier Alameda-Pineda and Elisa Ricci and Nicu Sebe},
booktitle = {Multimodal Behavior Analysis in the Wild},
publisher = {Academic Press},
pages = {349-367},
year = {2019},
series = {Computer Vision and Pattern Recognition},
isbn = {978-0-12-814601-9},
doi = {https://doi.org/10.1016/B978-0-12-814601-9.00018-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780128146019000183},
author = {Victor Campos and Xavier Giro-i-Nieto and Brendan Jou and Jordi Torres and Shih-Fu Chang},
keywords = {Computer vision, Sentiment analysis, Affective computing, Word embeddings},
abstract = {Automatic sentiment and emotion understanding of general visual content has recently garnered much research attention. However, the large visual variance associated with high-level affective concepts presents a challenge when designing systems with high-performance requirements. One popular approach to bridge the “affective gap” between low-level visual features and affective semantics consists of using Adjective Noun Pair (ANP) semantic constructs for concepts, e.g. “beautiful landscape” or “scary face,” which act as a mid-level representation that can be recognized by visual classifiers while still carrying an affective bias. In this work, we formulate the ANP detection task in images over a continuous space defined over an embedding that captures the inter-concept relationships between ANPs. We show how the compact representations obtained from the embedding extend the discrete concepts in the ontology and can be used for improved visual sentiment and emotion prediction, as well as new applications such as zero-shot ANP detection.}
}
@article{HAIN2022121559,
title = {A text-embedding-based approach to measuring patent-to-patent technological similarity},
journal = {Technological Forecasting and Social Change},
volume = {177},
pages = {121559},
year = {2022},
issn = {0040-1625},
doi = {https://doi.org/10.1016/j.techfore.2022.121559},
url = {https://www.sciencedirect.com/science/article/pii/S0040162522000919},
author = {Daniel S. Hain and Roman Jurowetzki and Tobias Buchmann and Patrick Wolf},
keywords = {Technological similarity, Patent data, Natural-language processing, Technology network, Patent landscaping, Patent quality},
abstract = {This paper describes an efficiently scaleable approach to measuring technological similarity between patents by combining embedding techniques from natural language processing with nearest-neighbor approximation. Using this methodology, we are able to compute similarities between all existing patents, which in turn enables us to represent the whole patent universe as a technological network. We validate both technological signature and similarity in various ways and, using the case of electric vehicle technologies, demonstrate their usefulness in measuring knowledge flows, mapping technological change, and creating patent quality indicators. This paper contributes to the growing literature on text-based indicators for patent analysis. We provide thorough documentation of our methods, including all code, and indicators at https://github.com/AI-Growth-Lab/patent_p2p_similarity_w2v).}
}
@article{NISHI2022314,
title = {Health and landscape approaches: A comparative review of integrated approaches to health and landscape management},
journal = {Environmental Science & Policy},
volume = {136},
pages = {314-325},
year = {2022},
issn = {1462-9011},
doi = {https://doi.org/10.1016/j.envsci.2022.06.015},
url = {https://www.sciencedirect.com/science/article/pii/S1462901122002027},
author = {Maiko Nishi and Shizuka Hashimoto},
keywords = {Landscape approaches, One Health, Ecohealth, Planetary Health, Social-ecological systems, Sustainability transformation},
abstract = {Landscape approaches are integrated place-based approaches and provide cross-sectoral opportunities to facilitate sustainability transformations. The COVID-19 outbreak has profound ramifications for multiple dimensions of landscapes, ranging from mobility and lifestyle to value to environment and society. Therefore, integrated approaches to “health” have been more vigorously promoted in the policy arena dealing with human–nature interactions. The ecosystem principles of the Convention on Biological Diversity, which resonate with landscape approaches, are generally aligned with integrated approaches to health. However, commonalities and distinctions between these integrated approaches in both political and scientific domains have not been clarified. Drawing on a narrative review of the literature on “One Health,” “Ecohealth,” and “Planetary Health” as major health-oriented approaches in comparison with landscape approaches, the aspects of landscape approaches to be complemented in addressing health-related challenges were examined in this study. In addition to the review on the intellectual roots and evolutionary pathways, a comparative analysis of these relevant approaches was conducted in terms of three realms including theoretical assumptions, knowledge bases, and research paradigms. The results of the comparative review show that all approaches share systems thinking, interdisciplinarity, cross-sectoral collaboration, and holistic paradigm but differ with respect to their focused management problems, disciplines, and sectors as well as ontological and epistemological underpinnings. Pointing to the recent theoretical and methodological development in integrating health in placemaking, the results of this study suggest that pragmatic landscape approaches could be strengthened by using health-related research paradigms to achieve better constructivism–positivism meeting grounds regarding health–landscape intersections.}
}
@article{YANG2024e29169,
title = {Exosomal miR-151-3p in saliva: A potential non-invasive marker for gastric cancer diagnosis and prognosis modulated by Sijunzi decoction (SJZD) in mice},
journal = {Heliyon},
volume = {10},
number = {7},
pages = {e29169},
year = {2024},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2024.e29169},
url = {https://www.sciencedirect.com/science/article/pii/S2405844024052009},
author = {Ping Yang and Huijun Lei and Yue Fu and Cheng Chen and Li Tang and Shuaishuai Xia and Yan Guo and Guangyu Chen and Mengzhou Xie and Jingjing Yang and Feng Li and Liang Li},
keywords = {Gastric cancer, Exosomal miRNAs, Sijunzi decoction (SJZD), Spleen deficiency syndrome, Exosomal miR-151-3p},
abstract = {Gastric cancer (GC) is one of the most prominent malignancies that originate in the epithelial cells of the gastric mucosa and is one of the main causes of cancer-related mortality worldwide. New circulating biomarkers of exosomal RNA might have great potential for non-invasive early prognosis of GC. Sijunzi Decoction (SJZD) is a typical representative formula of the method of benefiting Qi and strengthening the spleen in Traditional Chinese Medicine (TCM). However, the effects and mechanism of SJZD in treating GC remain unclear. This study looked for biomarkers of exosomal RNA for early prognosis of GC, and explored the mechanism of SJZD in treating GC. A gastric cancer model with spleen deficiency syndrome was established in nude mice, and the curative effects of SJZD were investigated. Differentially expressed miRNAs in plasma and saliva exosomes were sequenced and analyzed. Potential target genes of these miRNAs were predicted and applied for Gene Ontology (GO) and Kyoto Encyclopedia of Genes and Genomes (KEGG) signaling pathway enrichment annotation. Overlapping miRNAs in saliva and plasma samples were analyzed, and qRT-PCR was performed for verification. miR-151a-3p was selected, and qRT-PCR further determined that miR-151a-3p was downregulated in saliva and plasma exosomes from the SJZD group. The intersected miR-151a-3p target genes were predicted and enriched in the extrinsic apoptotic signaling pathways. SJZD significantly ameliorates gastric cancer with spleen deficiency syndrome in mouse models, and exosomal miRNAs, particularly miR-151-3p, might be modulated by SJZD in plasma and saliva. The exosomal miR-151-3p in saliva may serve as a non-invasive potential marker for gastric cancer diagnosis and prognosis.}
}
@article{ZHANG2018782,
title = {Analysing the features of negative sentiment tweets},
journal = {The Electronic Library},
volume = {36},
number = {5},
pages = {782-799},
year = {2018},
issn = {0264-0473},
doi = {https://doi.org/10.1108/EL-05-2017-0120},
url = {https://www.sciencedirect.com/science/article/pii/S0264047318000358},
author = {Ling Zhang and Wei Dong and Xiangming Mu},
keywords = {Sentiment analysis, Twitter, Features, Negative sentiment tweets, Topic classification},
abstract = {Purpose
This paper aims to address the challenge of analysing the features of negative sentiment tweets. The method adopted in this paper elucidates the classification of social network documents and paves the way for sentiment analysis of tweets in further research.
Design/methodology/approach
This study classifies negative tweets and analyses their features.
Findings
Through negative tweet content analysis, tweets are divided into ten topics. Many related words and negative words were found. Some indicators of negative word use could reflect the degree to which users release negative emotions: part of speech, the density and frequency of negative words and negative word distribution. Furthermore, the distribution of negative words obeys Zipf’s law.
Research limitations/implications
This study manually analysed only a small sample of negative tweets.
Practical implications
The research explored how many categories of negative sentiment tweets there are on Twitter. Related words are helpful to construct an ontology of tweets, which helps people with information retrieval in a fixed research area. The analysis of extracted negative words determined the features of negative tweets, which is useful to detect the polarity of tweets by machine learning method.
Originality/value
The research provides an initial exploration of a negative document classification method and classifies the negative tweets into ten topics. By analysing the features of negative tweets, related words, negative words, the density of negative words, etc. are presented. This work is the first step to extend Plutchik’s emotion wheel theory into social media data analysis by constructing filed specific thesauri, referred to as local sentimental thesauri.}
}
@article{ZHAO2023101940,
title = {Screening protective miRNAs and constructing novel lncRNAs/miRNAs/mRNAs networks and prognostic models for triple-negative breast cancer},
journal = {Molecular and Cellular Probes},
volume = {72},
pages = {101940},
year = {2023},
issn = {0890-8508},
doi = {https://doi.org/10.1016/j.mcp.2023.101940},
url = {https://www.sciencedirect.com/science/article/pii/S089085082300049X},
author = {Yuelei Zhao and Yichen Song and Yan Zhang and Meiju Ji and Peng Hou and Fang Sui},
keywords = {Breast cancer, miRNAs, lncRNAs/miRNAs/mRNAs networks, Prognostic model, TCGA},
abstract = {Triple-negative breast cancer (TNBC) represents 10–20 % of all breast cancer (BC) cases and is characterized by poor prognosis. Given the urgent need to improve prognostication and develop specific therapies for TNBC, the identification of new molecular targets is of great importance. MicroRNA (miRNA) has been reported as a valuable and novel molecular target in the progression of TNBC. However, the expression and function of miRNAs in different tumors are heterogeneous. Herein, we first analyzed miRNA data from The Cancer Genome Atlas (TCGA) and surprisedly found that overexpressed miRNAs were associated with poor survival in all breast cancer patients, but the overexpressed miRNAs were associated with better survival in TNBC patients. Based on the heterogeneity of miRNA expression in TNBC, we conducted further analysis using univariate Cox proportional hazard regression models and identified 17 miRNAs with prognostic potential. Subsequently, a multivariate Cox model was employed to create a 3-miRNA prognostic model for predicting overall survival in TNBC patients. The diagnostic model exhibited an area under the curve (AUC) of 0.727, and multivariable Cox regression indicated that each covariate was associated with survival. These data indicate that this model is relatively accurate and robust for risk assessment, which have a certain value for clinical application. In order to explore the network behind the overexpressed miRNAs in TNBC, we established a novel network consisting of lncRNAs, miRNAs, and mRNAs through complete transcriptome data from matched samples in the TCGA database. In this network, IRS-1 appeared to be the top hub gene. Experimental results demonstrated that miR-15b-5p and miR-148a-3p effectively target IRS-1 in vitro, shedding light on the intricate regulatory mechanisms in TNBC mediated by the heterogeneous miRNAs. Besides, miR-148a-3p significantly inhibited cell migration and viability. Overall, this study may add valuable insights into the molecular landscape of TNBC based on miRNAs and have the potential to contribute to the development of targeted therapies and improved prognostic strategies of TNBC.}
}
@article{YU2024105901,
title = {Future considerations for the Human Affectome: Reply to commentaries},
journal = {Neuroscience & Biobehavioral Reviews},
volume = {167},
pages = {105901},
year = {2024},
issn = {0149-7634},
doi = {https://doi.org/10.1016/j.neubiorev.2024.105901},
url = {https://www.sciencedirect.com/science/article/pii/S0149763424003701},
author = {Alessandra N.C. Yu and Leroy Lowe and Daniela Schiller}
}
@article{ZHAO2024102491,
title = {Integrating MBD with BOM for consistent data transformation during lifecycle synergetic decision-making of complex products},
journal = {Advanced Engineering Informatics},
volume = {61},
pages = {102491},
year = {2024},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2024.102491},
url = {https://www.sciencedirect.com/science/article/pii/S1474034624001393},
author = {Xin Zhao and Shuangshuang Wei and Shan Ren and Weihua Cai and Yingfeng Zhang},
keywords = {Model-based definition, Bill of material, Lifecycle data, Consistent data transformation, Synergetic decision-making},
abstract = {Model-based definition (MBD) can be applied to normalized define and associate the whole lifecycle data of complex products by a three-dimensional (3D) digital model, which can further provide single data source for bill of material (BOM) transforming of different lifecycle stages. Therefore, a promising application combining MBD and BOM is to ensure the accuracy and completeness of information during various BOM transformation, and to provide consistent and reliable data support for lifecycle synergetic decision-making. However, the studies in the above field are facing many challenges. For example, the research and application of MBD in the whole lifecycle is still in its infancy. MBD and BOM are studied separately, and the overall solution that integrates these two pillars for lifecycle synergetic decision-making is almost vacant. A novel approach for consistent lifecycle data transformation is proposed to address these challenges. First, an overall conceptual framework is developed to show how the approach can be implemented. Second, a unified lifecycle data representation method with the MBD main-domain dataset is proposed. Third, based on the single data source from MBD dataset, xBOM multi-view transforming are realised by designing a set of mapping models and rules. Finally, an applicable scenario for an electric multiple units (EMU) bogie is presented to illustrate the effectiveness of the proposed approach. The result shows that the proposed approach can provide significant potential for industrial practitioners to carry out synergetic and optimal decision-making in the whole lifecycle management processes.}
}
@article{JIANG2024107892,
title = {Tissue-specific RNA methylation prediction from gene expression data using sparse regression models},
journal = {Computers in Biology and Medicine},
volume = {169},
pages = {107892},
year = {2024},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2023.107892},
url = {https://www.sciencedirect.com/science/article/pii/S0010482523013574},
author = {Jie Jiang and Bowen Song and Jia Meng and Jingxian Zhou},
keywords = {Epitranscriptome, Tissue-specific methylation status, Human methylome distribution, Methylation level prediction, Elastic net regression},
abstract = {N6-methyladenosine (m6A) is a highly prevalent and conserved post-transcriptional modification observed in mRNA and long non-coding RNA (lncRNA). Identifying potential m6A sites within RNA sequences is crucial for unraveling the potential influence of the epitranscriptome on biological processes. In this study, we introduce Exp2RM, a novel approach that formulates single-site-based tissue-specific elastic net models for predicting tissue-specific methylation levels utilizing gene expression data. The resulting ensemble model demonstrates robust predictive performance for tissue-specific methylation levels, with an average R-squared value of 0.496 and a median R-squared value of 0.482 across all 22 human tissues. Since methylation distribution varies among tissues, we trained the model to incorporate similar patterns, significantly improves accuracy with the median R-squared value increasing to 0.728. Additonally, functional analysis reveals Exp2RM's ability to capture coefficient genes in relevant biological processes. This study emphasizes the importance of tissue-specific methylation distribution in enhancing prediction accuracy and provides insights into the functional implications of methylation sites.}
}
@article{WANG2024111950,
title = {A comprehensive survey on interactive evolutionary computation in the first two decades of the 21st century},
journal = {Applied Soft Computing},
volume = {164},
pages = {111950},
year = {2024},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2024.111950},
url = {https://www.sciencedirect.com/science/article/pii/S1568494624007245},
author = {Yanan Wang and Yan Pei},
keywords = {Interactive evolutionary computation, Evolutionary computation, Computational intelligence, Humanized computational intelligence, Human-machine interaction},
abstract = {Interactive evolutionary computation (IEC) has demonstrated significant success in addressing numerous real-world problems that are challenging to quantify mathematically or are inadequately evaluated using conventional computational models. This success arises from IEC’s ability to effectively amalgamate evolutionary computation (EC) algorithms with expert knowledge and user preferences. These problems encompass the creative and personalized generation of products, art, and sound; the design optimization of communication systems, environments, and pharmaceuticals; and expert support in areas such as portfolio selection and hearing aid fitting, among others. Despite significant advancements in IEC over the past two decades, no major comprehensive survey encompassing all aspects of IEC research has been conducted since 2001. This article aims to address this gap by providing a comprehensive survey and an enriched definition and scope of IEC, along with innovative ideas for future research in this field. The proposed IEC definition more clearly reflects the mechanism and current research status of the IEC. Additionally, the survey categorizes IEC research into five distinct directions from a problem-oriented perspective: interactive evolutionary computation algorithms, IEC algorithm improvements, evolutionary multi-objective optimization (EMO) with IEC, human perception studies with IEC, and IEC applications. Each direction is meticulously explored, elucidating its contents and key features, while providing a concise summary of pertinent IEC studies. Finally, the survey investigates several promising future trends in IEC, analyzing them through the lens of these five directions and considering the current perspective of computational intelligence, artificial intelligence, and human-machine interaction.}
}
@article{XIAOJUAN2023113933,
title = {A Data integration tool for the integrated modeling and analysis for EAST},
journal = {Fusion Engineering and Design},
volume = {195},
pages = {113933},
year = {2023},
issn = {0920-3796},
doi = {https://doi.org/10.1016/j.fusengdes.2023.113933},
url = {https://www.sciencedirect.com/science/article/pii/S092037962300515X},
author = {Liu Xiaojuan and Zhi Yu},
keywords = {Integrated modeling, Data integration, Data mapping, Date model},
abstract = {A large amount of heterogeneous data is generated during the experiments, operations, and simulations of the Experimental Advanced Superconducting Tokamak (EAST). The semantic and formatting inconsistencies of these heterogeneous data barrier the automation of data processes in integrated modeling and analysis. Data integration approaches based on a unified data model are an effective way to address this problem. A data integration tool, SpDB, was developed to unify data access for EAST’s integrated modeling process. SpDB unifies access to heterogeneous data sources under a single entry point in a namespace compatible with Integrated Modeling and Analysis Suite (IMAS). Users can access abstract tree data structures through a unified path without worrying about the format of specific data sources. SpDB enables automating integrated modeling workflows by combining multiple data sources into a single data structure that acts as a unified IO interface to the module.}
}
@article{COLLINGE20244611,
title = {Advancing social practice understandings of digital innovation delivery in construction project management},
journal = {Engineering, Construction and Architectural Management},
volume = {32},
number = {7},
pages = {4611-4630},
year = {2024},
issn = {0969-9988},
doi = {https://doi.org/10.1108/ECAM-12-2023-1290},
url = {https://www.sciencedirect.com/science/article/pii/S0969998824000018},
author = {William Henry Collinge},
keywords = {Innovation studies, BIM, Building information modelling, Digitalisation, Projects-as-practice, Social practices, Health and safety, Data engineering},
abstract = {Purpose
The paper aims to apply social practice theory to clarify the process of innovation design and delivery from one successful digital innovation: the building information modelling (BIM) risk library. The paper clarifies the practices surrounding construction innovation and provides a schema useful for practitioners and technology designers through a social practice analysis.
Design/methodology/approach
The paper applies Schatzki's “organisation of practice” concepts to a construction project innovation to clarify how the practice of innovation revolves around understandings, rules and teleoaffectivities (emotive behaviours). Sources for the study include notes from meetings, workshops with experts and the shared artefacts of innovation.
Findings
The practice of innovation design and delivery are clarified through a social practice analysis: a distinct “field of practice” and a “schema” of generalisable prescriptions and preferences for innovation delivery being presented.
Practical implications
The paper informs the practice and process of innovation design and delivery; the insights clarify how collective understandings and rules of use evolve over time, becoming formalised into contracts, agreements and workplans. Practically, processes whereby innovation “sayings” evolve into innovation “doings” are clarified: a schema detailing prescriptions and preferences of practitioners and developers being presented.
Originality/value
The social practice analysis of one successful construction innovation is an original contribution to the body of knowledge, adding a level of detail regarding innovation design and delivery often missing from reported research.}
}
@article{HAN2019159,
title = {Immune checkpoint molecule herpes virus entry mediator is overexpressed and associated with poor prognosis in human glioblastoma},
journal = {EBioMedicine},
volume = {43},
pages = {159-170},
year = {2019},
issn = {2352-3964},
doi = {https://doi.org/10.1016/j.ebiom.2019.04.002},
url = {https://www.sciencedirect.com/science/article/pii/S2352396419302361},
author = {Ming-Zhi Han and Shuai Wang and Wen-Bo Zhao and Shi-Lei Ni and Ning Yang and Yang Kong and Bin Huang and An-Jing Chen and Xin-Gang Li and Jian Wang and Dong-Hai Wang},
keywords = {Glioma, HVEM, Immune response, Prognosis, Tumour microenvironment},
abstract = {Background
Dysregulation of immune checkpoint molecules leads to immune evasion in human tumours but has become a viable target for tumour therapy. Here, we examined expression of Herpes virus entry mediator (HVEM), an immune checkpoint molecule, in human glioblastoma (GBM) to assess its potential as a molecular target for treatment.
Methods
Molecular and clinical data from publicly available genomic databases containing WHO grade II-IV human glioma cases (n = 1866) were analyzed. Immunohistochemistry was applied to assess HVEM protein levels in primary tumour sections. Statistical analysis was performed using Matlab and R language.
Findings
HVEM was found to be elevated in aggressive gliomas, particularly in the mesenchymal and isocitrate dehydrogenase (IDH) wild-type molecular subtypes of GBM. HVEMhigh tumours tended to be associated with amplification of EGFR and loss of PTEN, while HVEMlow tumours harbored mutations in IDH1 (93%). HVEM exhibited potential as a prognostic marker based on Cox regression and nomogram models. HVEM displayed intra-tumour heterogeneity and was more highly expressed in peri-necrotic and microvascular regions. Gene ontology and pathway analysis revealed enrichment of HVEM in multiple immune regulatory processes, such as suppression of T cell mediated immunity in GBM. Finally, in cell lineage analysis, HVEM was found to be tightly associated with several infiltrating immune and stromal cell types which localized to the tumour microenvironment.
Interpretation
Our data highlights the importance of HVEM in the development of GBM and as a potential molecular target in combination with current immune checkpoint blockades for treatment of GBM.}
}
@article{JONES2019153,
title = {What does it mean to be poor? Investigating the qualitative-quantitative divide in Mozambique},
journal = {World Development},
volume = {117},
pages = {153-166},
year = {2019},
issn = {0305-750X},
doi = {https://doi.org/10.1016/j.worlddev.2019.01.005},
url = {https://www.sciencedirect.com/science/article/pii/S0305750X19300117},
author = {Sam Jones and Inge Tvedten},
keywords = {Poverty, Qualitative, Anthropology, Quantitative, Q-squared, Mozambique},
abstract = {Motivated by the siloed nature of much poverty research, as well as the challenge of finding inclusive operational definitions of poverty, this study reflects on the merits of seeking to reconcile economic (quantitative) and anthropological (qualitative) analytical approaches. Drawing on detailed evidence from Mozambique, we highlight fundamental philosophical tensions in poverty research along three main axes: social ontology (what is the form of social reality?); (b) epistemology (what can be known about poverty?); and (c) aetiology (how is poverty produced?). We argue the quantitative tradition is rooted in an atomistic view of the social world, which is allied to an etic epistemology in which causes and effects are treated as analytically separable. Anthropological work in Mozambique is anchored in an emic perspective, where the diverse forms of poverty are revealed through investigation of their generative mechanisms. This provides a view of poverty as a relational process of social marginalization and directs attention to the diversity of lived-experiences, as well as structural factors that limit individuals’ agency. In clarifying their distinct philosophical commitments, we contend that a forced empirical marriage of the two approaches may be unhelpful. Instead, we recommend the virtues of each approach are leveraged toward genuine mutual dialogue.}
}
@article{LUO2025101344,
title = {Decoding virtual chats: NLP insights into academic library services.},
journal = {Library & Information Science Research},
volume = {47},
number = {1},
pages = {101344},
year = {2025},
issn = {0740-8188},
doi = {https://doi.org/10.1016/j.lisr.2025.101344},
url = {https://www.sciencedirect.com/science/article/pii/S0740818825000052},
author = {Jiebei Luo and Alyssa Brissett},
keywords = {Machine learning (ML), Natural language processing (NLP), Text classification, Topic modeling, Supervised learning, Virtual reference services (VRS), COVID-19, Prodigy, spaCy},
abstract = {Assessing unstructured data from virtual reference chats is complex. Full-text reveals nuances but is time-consuming, while transcript metadata gives an overview but may miss important details in the conversation. This research applies a machine learning (ML) tool to the complete set of transcripts from a research university's chat reference service (2017–2022) to examine evolving trends and patron needs in the library reference service. The study has two key objectives: 1) demonstrating ML's effectiveness in the academic library setting, and 2) assessing the impact of COVID-19 on chat reference needs. A text classification model, trained on 1.5 % of the sample, achieves a 75 % accuracy match with human annotations. Findings indicate a marked rise in circulation-related inquiries as libraries transitioned to fully online services during the pandemic. Notably, user behaviors remain consistent even after the pandemic. This study highlights ML's potential to analyze large-scale unstructured data effectively in the academic library setting.}
}
@article{LU2025102701,
title = {Transcriptomic analysis of defense genes associated with Botrytis cinerea resistance in chicory},
journal = {Physiological and Molecular Plant Pathology},
volume = {138},
pages = {102701},
year = {2025},
issn = {0885-5765},
doi = {https://doi.org/10.1016/j.pmpp.2025.102701},
url = {https://www.sciencedirect.com/science/article/pii/S0885576525001407},
author = {Hao Lu and Fengqi Zhang and Fang Zhang and Zhen Tang and Shiyu Chu and Yanan Gai and Xiuhua Meng and Han Lv and Jian Chen and Guanting Niu},
keywords = { L, , Transcriptomic profiling, Abscisic acid, Stomatal closure},
abstract = {Chicory (Cichorium intybus L.) is a plant of significant ecological and economic value, exhibiting notably high resistance to fungal pathogens. However, the mechanisms underlying its antifungal properties remain poorly understood. In this study, Botrytis cinerea, a representative fungal pathogen, was applied to investigate the transcriptomic responses of chicory before and after infection. Gene Ontology (GO) enrichment analysis identified the activation of multiple stress response pathways, with light signaling being particularly prominent. KEGG enrichment analysis further revealed that differentially expressed genes (DEGs) were primarily associated with carotenoid biosynthesis, phenylpropanoid biosynthesis, and amino acid metabolism. Compared to the control, infected plants exhibited upregulation of DEGs involved in abscisic acid, lignin, and coumarin biosynthesis. Abscisic acid, a key regulator of stomatal closure, was linked to increased stomatal closure in infected chicory leaves, as observed via confocal microscopy. Additionally, lignin and coumarin accumulation likely reinforced the epidermal cell wall, enhancing pathogen resistance. These findings elucidate the molecular mechanisms underlying chicory's defense against B. cinerea and provide a foundation for identifying candidate genes to improve fungal resistance in susceptible crop varieties.}
}
@article{HUSSAIN2023103202,
title = {Wikipedia bi-linear link (WBLM) model: A new approach for measuring semantic similarity and relatedness between linguistic concepts using Wikipedia link structure},
journal = {Information Processing & Management},
volume = {60},
number = {2},
pages = {103202},
year = {2023},
issn = {0306-4573},
doi = {https://doi.org/10.1016/j.ipm.2022.103202},
url = {https://www.sciencedirect.com/science/article/pii/S030645732200303X},
author = {Muhammad Jawad Hussain and Heming Bai and Yuncheng Jiang},
keywords = {Graph theory, Information content, Semantic similarity, Semantic relatedness, Vector space},
abstract = {Wikipedia links its articles by manually defined semantic relations called the Wikipedia hyperlink (link) structure. The existing Wikipedia link-based semantic similarity (SS) and semantic relatedness (SR) computation models, such as Wikipedia one-way link (WOLM) model and Wikipedia two-way link (WTLM) model, do not assess the strengths of the relationships between a candidate concept and its links (out-links or in-links). These models treat all the links as equally important even though some links are semantically more influential than others and should be given more importance. This phenomenon reduces the accuracy of these models. This paper presents the Wikipedia bi-linear link (WBLM) model that extends the previously proposed WOLM and WTLM models. The WBLM model explores the Wikipedia link structure as a semantic graph and discovers the strongly (bi-linear links) and weakly (out-links or in-links) connected links of a candidate concept. It improves the link-based vector representations of concepts by assigning weights to their connected links according to the strengths of their semantic associations. The experimental results demonstrate that the proposed WBLM model significantly improves the SS and SR computation accuracy of the WOLM model (6.9%, 8%, 24%, 17.3%, 31.2%, 30.6%, 26.5%, and 35.4%) and WTLM model (1.2%, 3.9%, 7.1%, 9.9%, 11%, 6.3%, 12.7%, and 13%), in terms of linear correlations with human judgments on gold standard benchmarks, including MC30, RG65, WS203, SimLex, 353All, MTurk287, MTurk771, and MEN3000, respectively. Moreover, this research offers a deep insight into the Wikipedia link structure and provides an adequate base for understanding it as a semantic graph.}
}
@article{WANG2024113099,
title = {A multi-task deep learning model based on comprehensive feature integration and self-attention mechanism for predicting response to anti-PD1/PD-L1},
journal = {International Immunopharmacology},
volume = {142},
pages = {113099},
year = {2024},
issn = {1567-5769},
doi = {https://doi.org/10.1016/j.intimp.2024.113099},
url = {https://www.sciencedirect.com/science/article/pii/S1567576924016205},
author = {Ren Wang and Qiumei Liu and Wenhua You and Yun Chen},
keywords = {Immune checkpoint inhibitor, Feature selection, Feature integration, Deep learning, Self-attention mechanism},
abstract = {Background
Immune checkpoint inhibitor (ICI) has been widely used in the treatment of advanced cancers, but predicting their efficacy remains challenging. Traditional biomarkers are numerous but exhibit heterogeneity within populations. For comprehensively utilizing the ICI-related biomarkers, we aim to conduct multidimensional feature selection and deep learning model construction.
Methods
We used statistical and machine learning methods to map features of different levels to next-generation sequencing gene expression. We integrated genes from different sources into the feature input of a deep learning model, by means of self-attention mechanism.
Results
We performed feature selection at the single-cell sequencing level, PD-L1 (CD274) analysis level, tumor mutational burden (TMB)/mismatch repair (MMR) level, and somatic copy number alteration (SCNA) level, obtaining 96 feature genes. Based on the pan-cancer dataset, we trained a multi-task deep learning model. We tested the model in the bladder urothelial carcinoma testing set 1 (AUC = 0.62, n = 298), bladder urothelial carcinoma testing set 2 (AUC = 0.66, n = 89), non-small cell lung cancer testing set (AUC = 0.85, n = 27), and skin cutaneous melanoma testing set (AUC = 0.71, n = 27).
Conclusion
Our study demonstrates the potential of the deep learning model for integrating multidimensional features in predicting the outcome of ICI. Our study also provides a potential methodological case for medical scenarios requiring the integration of multiple levels of features.}
}
@article{YAN2025106131,
title = {Common data environment for digital twins from building to city levels},
journal = {Automation in Construction},
volume = {174},
pages = {106131},
year = {2025},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2025.106131},
url = {https://www.sciencedirect.com/science/article/pii/S0926580525001712},
author = {Jiayi Yan and Qiuchen Lu and Nan Li and Long Chen and Michael Pitt},
keywords = {Digital twin (DT), City-level digital twin (CDT), Common data environment (CDE), Data sources, Data management, Stakeholder, Data ecosystem},
abstract = {Digital twin (DT) technology is pivotal for advancing sustainable, liveable, and resilient smart cities. As DTs scale from building to infrastructure and city levels, data management remains a key challenge due to increasing data heterogeneity. This paper addresses this gap by defining a common data environment (CDE) that connects physical and virtual spaces with three enablers: data sources, data management with functional components (FCs), and data consumers. A systematic literature review (SLR) of 264 papers (from 14,532) analyses these enablers, identifying knowledge gaps and future directions. A prospective DT data ecosystem model is proposed to support city-level DTs (CDT) and federated sub-DTs, integrating informational, technological, functional, organisational, and user-centred features. The paper highlights the immaturity of current data environments in managing heterogeneous data for comprehensive DT applications. It provides state-of-the-art insights and practical recommendations to researchers, practitioners, and policymakers to enhance data management in diverse smart city scenarios.}
}
@article{DOUNGPHUMMES2020205,
title = {Implementing PAR in a Thai community development context},
journal = {Qualitative Research Journal},
volume = {20},
number = {2},
pages = {205-215},
year = {2020},
issn = {1443-9883},
doi = {https://doi.org/10.1108/QRJ-12-2019-0101},
url = {https://www.sciencedirect.com/science/article/pii/S1443988320000508},
author = {Nuntiya Doungphummes and Mark Vicars},
keywords = {Participatory action research, Insider research, Positionality, Culturally responsive, Situated methodology, Community development, Critical praxis, Gatekeepers},
abstract = {Purpose
The purpose of this paper is to present an account of a PAR project in a Thai community and to discuss the methodological implications of implementing a culturally responsive approach.
Design/methodology/approach
The paper draws on the frameworks for PAR conducted as a community development project with rural Thai communities.
Findings
The paper reviews the use of a PAR approach as a culturally responsive approach and presents an experience of culturally situated research practice.
Originality/value
This paper encourages researchers conducting participatory inquiry to engage in deeper critical reflection on the implications of these methods in keeping with PAR's critical ontological, epistemological and axiological orientation.}
}
@article{MAASS2021101909,
title = {Pairing conceptual modeling with machine learning},
journal = {Data & Knowledge Engineering},
volume = {134},
pages = {101909},
year = {2021},
issn = {0169-023X},
doi = {https://doi.org/10.1016/j.datak.2021.101909},
url = {https://www.sciencedirect.com/science/article/pii/S0169023X21000367},
author = {Wolfgang Maass and Veda C. Storey},
keywords = {Conceptual modeling, Machine learning, Methodologies and tools, Models, Database management, Framework for incorporating conceptual modeling into data science projects, Artificial intelligence},
abstract = {Both conceptual modeling and machine learning have long been recognized as important areas of research. With the increasing emphasis on digitizing and processing large amounts of data for business and other applications, it would be helpful to consider how these areas of research can complement each other. To understand how they can be paired, we provide an overview of machine learning foundations and development cycle. We then examine how conceptual modeling can be applied to machine learning and propose a framework for incorporating conceptual modeling into data science projects. The framework is illustrated by applying it to a healthcare application. For the inverse pairing, machine learning can impact conceptual modeling through text and rule mining, as well as knowledge graphs. The pairing of conceptual modeling and machine learning in this way should help lay the foundations for future research.}
}
@article{YUSTIANTO2019134,
title = {A unifying structure of metamodel landscape},
journal = {Journal of Modelling in Management},
volume = {14},
number = {1},
pages = {134-152},
year = {2019},
issn = {1746-5664},
doi = {https://doi.org/10.1108/JM2-11-2017-0127},
url = {https://www.sciencedirect.com/science/article/pii/S174656641900012X},
author = {Purnomo Yustianto and Robin Doss and  Suhardi},
keywords = {Modelling, Computing, Business analytics},
abstract = {Purpose
The modelling landscape experiences a rich proliferation of modelling language, or metamodel. The emergence of cross-disciplinary disciplines, such as enterprise engineering and service engineering, necessitates a multi-perspective approach to traverse the component from strategic level to technological aspect. This paper aims to find a unifying structure of metamodels introduced by academics and industries.
Design/methodology/approach
A grounded approach is taken to define the structure by collating the metamodels to form an emerging structure. Metamodels were collected from a literature survey from several interrelated disciplines: software engineering, system engineering, enterprise architecture, service engineering, business process management and financial accounting.
Findings
The result suggests seven stereotypes of metamodel, characterized by its label: goal, enterprise, business model, service, process, software and system. The aspect of “process” holds a central role in connecting all other aspect in the modelling continuum. Service engineering can be viewed as an alternative abstraction of enterprise engineering in containing the concepts of “business model”, “capability”, “value”, “interaction”, “process” and “software”.
Research limitations/implications
Metamodel collection was performed to emphasize on representativeness rather than comprehensiveness, in which old and unpopular metamodel were disregarded unless it offer unique characteristic not yet represented in the collection. Owing to its bottom-up approach, the paper is not intended to identify a gap in metamodel offering.
Originality/value
This paper produces a structure of metamodel landscape in a graphical format to illustrate correlation between metamodels in which evolutive patterns of metamodel proliferation can be observed. The produced structure can serve as map in metamodel continuum.}
}
@article{BREITINGER2025301932,
title = {SoK: Timeline based event reconstruction for digital forensics: Terminology, methodology, and current challenges},
journal = {Forensic Science International: Digital Investigation},
volume = {53},
pages = {301932},
year = {2025},
note = {DFRWS USA 2025 - Selected Papers from the 25th Annual Digital Forensics Research Conference USA},
issn = {2666-2817},
doi = {https://doi.org/10.1016/j.fsidi.2025.301932},
url = {https://www.sciencedirect.com/science/article/pii/S266628172500071X},
author = {Frank Breitinger and Hudan Studiawan and Chris Hargreaves},
keywords = {Event reconstruction, Timeline, Digital investigation, Methodology, Artifacts, Terminology, Framework, Challenges},
abstract = {Event reconstruction is a technique that examiners can use to attempt to infer past activities by analyzing digital artifacts. Despite its significance, the field suffers from fragmented research, with studies often focusing narrowly on aspects like timeline creation or tampering detection. This paper addresses the lack of a unified perspective by proposing a comprehensive framework for timeline-based event reconstruction, adapted from traditional forensic science models. We begin by harmonizing existing terminology and presenting a cohesive diagram that clarifies the relationships between key elements of the reconstruction process. Through a comprehensive literature survey, we classify and organize the main challenges, extending the discussion beyond common issues like data volume. Lastly, we highlight recent advancements and propose directions for future research, including specific research gaps. By providing a structured approach, key findings, and a clearer understanding of the underlying challenges, this work aims to strengthen the foundation of digital forensics.}
}
@article{CAJKA2022107416,
title = {Let us expand this Western project by admitting diversity and enhancing rigor: A systematic review of empirical research on alternative economies},
journal = {Ecological Economics},
volume = {196},
pages = {107416},
year = {2022},
issn = {0921-8009},
doi = {https://doi.org/10.1016/j.ecolecon.2022.107416},
url = {https://www.sciencedirect.com/science/article/pii/S0921800922000787},
author = {Adam Čajka and Josef Novotný},
keywords = {Alternative economy, Alternative food networks, Global South, Knowledge production, Systematic review},
abstract = {Research of alternative economies (AEs) has been portrayed as a mission of spreading visionary hopes for progressive change toward more sustainable and equitable economic systems. Despite its increasing popularity, it is less clear how it has been supported by empirical evidence. Therefore, we systematically searched for primary research studies on AEs (comprising alternative, diverse, community, or heterodox economies, and alternative food networks) published in recognized journals. We analyzed the patterns of the literature and characterized the examined AEs. We also overviewed methods and theories, and how the literature on AEs in the Global South conceptualizes both AEs and mainstream economic practices. We found that research of AEs has increased rapidly driven by an explosion of interest in alternative food networks. The published research of AEs has largely been a Western project signifying another example of the hierarchy of knowledge production. We argue that two general directions are worth to follow. First, the cultivation of empathy toward ontological diversity can make the research on AEs more pertinent to non-Western audience. Second, increased scope and epistemological rigor can make this research project more credible. We believe that these two directions can be followed without compromising the normative appeal of this scholarly programme.}
}
@article{SULIS2024105949,
title = {Introduction for computer law and security review: special issue “knowledge management for law”},
journal = {Computer Law & Security Review},
volume = {52},
pages = {105949},
year = {2024},
issn = {2212-473X},
doi = {https://doi.org/10.1016/j.clsr.2024.105949},
url = {https://www.sciencedirect.com/science/article/pii/S0267364924000165},
author = {Emilio Sulis and Luigi Di Caro and Rohan Nanda}
}
@article{VARTIAINEN2025101742,
title = {Emerging human-technology relationships in a co-design process with generative AI},
journal = {Thinking Skills and Creativity},
volume = {56},
pages = {101742},
year = {2025},
issn = {1871-1871},
doi = {https://doi.org/10.1016/j.tsc.2024.101742},
url = {https://www.sciencedirect.com/science/article/pii/S1871187124002803},
author = {Henriikka Vartiainen and Päivikki Liukkonen and Matti Tedre},
keywords = {Artificial intelligence, Text-to-image generative models, Generative AI, Prompt crafting, Prompting, Human-technology relationships, Teacher education, AI education},
abstract = {This study explored how pre-service teachers (N = 33) perceived human-technology relationships with generative AI (genAI). The study employed a research-creation approach and implemented a hands-on workshop, in which the participants engaged in a speculative design process using generative AI. The study focused on how participants, armed with their new tool, approached their designs, made design decisions, and interacted with the responsive tool. The qualitative analysis of the video data from students' project presentations employed thematic analysis, interpreting the students' responses in relational terms. The results revealed that the emerging human-technology relationships were primarily expressed through distributed decision-making, with the AI actively contributing both to the object of activity and to the emerging design process. The findings highlight that genAI is neither passive nor neutral tool but actively transforms both the design process and its outcomes, shaping how people experience new forms of agency in relation to such technology.}
}
@article{GAO2024,
title = {AI Ethics:},
journal = {International Journal of Business Analytics},
volume = {11},
number = {1},
year = {2024},
issn = {2334-4547},
doi = {https://doi.org/10.4018/IJBAN.338367},
url = {https://www.sciencedirect.com/science/article/pii/S2334454724000017},
author = {Di Kevin Gao and Andrew Haverly and Sudip Mittal and Jiming Wu and Jingdao Chen},
keywords = {AI Ethics, AI Identification, Artificial Intelligence Ethics, Bibliometric Analysis, Human-Like Machine, Large Ethics Model (LEM), Literature Review, Machine-Like Human},
abstract = {ABSTRACT
Artificial intelligence (AI) ethics has emerged as a burgeoning yet pivotal area of scholarly research. This study conducts a comprehensive bibliometric analysis of the AI ethics literature over the past two decades. The analysis reveals a discernible tripartite progression, characterized by an incubation phase, followed by a subsequent phase focused on imbuing AI with human-like attributes, culminating in a third phase emphasizing the development of human-centric AI systems. After that, they present seven key AI ethics issues, encompassing the Collingridge dilemma, the AI status debate, challenges associated with AI transparency and explainability, privacy protection complications, considerations of justice and fairness, concerns about algocracy and human enfeeblement, and the issue of superintelligence. Finally, they identify two notable research gaps in AI ethics regarding the large ethics model (LEM) and AI identification and extend an invitation for further scholarly research.}
}
@article{GONI2024103324,
title = {Analytical categories to describe imaginations about the collective futures: From theory to linguistics to computational analysis},
journal = {Futures},
volume = {156},
pages = {103324},
year = {2024},
issn = {0016-3287},
doi = {https://doi.org/10.1016/j.futures.2024.103324},
url = {https://www.sciencedirect.com/science/article/pii/S0016328724000077},
author = {Julian “Iñaki” Goñi and Maria Paz Raveau and Claudio {Fuentes Bravo}},
keywords = {Imaginations about the collective futures, Images of the future, Linguistic markers, Natural language processing},
abstract = {Anticipation of collective futures has been described as one of the most critical challenges of contemporary societies. Imaginations or images of the collective future are a form of narrative and social activity that involves many complex political, psychological and cultural nuances that pose significant challenges in terms of assessment. In this article, we propose six analytical categories to describe qualitative information regarding imaginations about the collective futures. These categories reflect a conceptual integration of normative stances in Science, Technology and Society and capacity approaches to Futures Studies. We translated those analytical categories into grammatical markers that allow for their operationalisation. Using a large-scale participatory process in Chile aimed at systematising images of the future, we utilised Natural Language Process to transform the grammatical markers into computational codes that allowed us to automatically assess large amounts of qualitative data. Ultimately, our main argument is that analytical categories to describe imaginations about collective futures can be generated with reasonable foundations in the humanities and social sciences.}
}
@article{POYNTER2019e210,
title = {Network Mapping of Molecular Biomarkers Influencing Radiation Response in Rectal Cancer},
journal = {Clinical Colorectal Cancer},
volume = {18},
number = {2},
pages = {e210-e222},
year = {2019},
issn = {1533-0028},
doi = {https://doi.org/10.1016/j.clcc.2019.01.004},
url = {https://www.sciencedirect.com/science/article/pii/S1533002818302913},
author = {Liam Poynter and Dieter Galea and Kirill Veselkov and Alexander Mirnezami and James Kinross and Jeremy Nicholson and Zoltán Takáts and Ara Darzi and Reza Mirnezami},
keywords = {Neoadjuvant therapy, Radiation tolerance, Radiotherapy, Rectal neoplasms},
abstract = {Preoperative radiotherapy (RT) plays an important role in the management of locally advanced rectal cancer (RC). Tumor regression after RT shows marked variability, and robust molecular methods are needed to help predict likely response. The aim of this study was to review the current published literature and use Gene Ontology (GO) analysis to define key molecular biomarkers governing radiation response in RC. A systematic review of electronic bibliographic databases (Medline, Embase) was performed for original articles published between 2000 and 2015. Biomarkers were then classified according to biological function and incorporated into a hierarchical GO tree. Both significant and nonsignificant results were included in the analysis. Significance was binarized on the basis of univariate and multivariate statistics. Significance scores were calculated for each biological domain (or node), and a direct acyclic graph was generated for intuitive mapping of biological pathways and markers involved in RC radiation response. Seventy-two individual biomarkers across 74 studies were identified. On highest-order classification, molecular biomarkers falling within the domains of response to stress, cellular metabolism, and pathways inhibiting apoptosis were found to be the most influential in predicting radiosensitivity. Homogenizing biomarker data from original articles using controlled GO terminology demonstrated that cellular mechanisms of response to RT in RC—in particular the metabolic response to RT—may hold promise in developing radiotherapeutic biomarkers to help predict, and in the future modulate, radiation response.}
}
@article{MENASSEL2025112553,
title = {Operational profile-based test case generation for normative MAS},
journal = {Journal of Systems and Software},
volume = {230},
pages = {112553},
year = {2025},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2025.112553},
url = {https://www.sciencedirect.com/science/article/pii/S0164121225002225},
author = {Yahia Menassel and Toufik Marir and Farid Mokhati and Varun Gupta},
keywords = {Normative multiagent system (NorMAS), Test case generation (TCG), Normative operational profile (OP4NorMAS), Testing},
abstract = {Agent-based models are widely used to simulate complex systems and support decision-making processes. The reliability of multiagent systems (MAS) depends on their alignment with design specifications, necessitating rigorous verification against these specifications. In MAS, agents collaborate to achieve shared goals, but their autonomous and proactive nature poses significant testing challenges. Despite these challenges, testing is crucial for ensuring operational integrity. This paper introduces a novel test case generation (TCG) methodology specifically designed for normative multiagent systems (NorMAS). The methodology leverages a normative operational profile (OP4NorMAS) to generate test cases that align with the behavioral constraints of NorMAS agents. A comprehensive case study demonstrates the effectiveness of this approach in ensuring normative compliance and operational reliability.}
}
@article{SANTOS2025106128,
title = {Automating inspection data from bridge management system into bridge information model},
journal = {Automation in Construction},
volume = {174},
pages = {106128},
year = {2025},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2025.106128},
url = {https://www.sciencedirect.com/science/article/pii/S0926580525001682},
author = {Carlos Santos and Furkan Luleci and João Amado and José C. Matos and F. Necati Catbas},
keywords = {Bridge Information Modeling (BrIM), Bridge Management System (BMS), Relational data model, Industry Foundation Classes (IFC), Object-oriented data model},
abstract = {This paper presents an approach to enhance the implementation of the Bridge Information Modeling (BrIM) methodology during the operational stage by automating the integration of inspection data from Bridge Management Systems (BMS) into BrIM models. While the data from BMS is available and retrievable from spreadsheets, the 3D bridge model is represented according to the Industry Foundation Classes (IFC) data model. Then, this paper introduces an algorithm that ensures seamless interoperability between the spreadsheets and the IFC data model. The semantically enriched BrIM models are achieved through a set of rules and procedures that are established to simplify the matching of the modeled objects with the components that characterize the bridge in the BMS. The openness of the IFC data model allows the identification of appropriate entities to store the corresponding information that comes from the BMS. This automated process removes the need for manual attachment of inspection data into IFC files, which is prone to errors, reduces the complexity of moving towards BrIM-based bridge management practices, and increases the efficiency of creating BrIM models for existing bridges. Finally, the proposed approach is a scalable and transferable solution that transportation agencies worldwide can adopt to manage bridge assets.}
}
@article{ZHU2025111087,
title = {Exploring the mechanism of action of trastuzumab-induced cardiomyocyte atrophy based on the FN1/PI3K/AKT-mediated mTOR-independent signaling pathway},
journal = {Genomics},
volume = {117},
number = {5},
pages = {111087},
year = {2025},
issn = {0888-7543},
doi = {https://doi.org/10.1016/j.ygeno.2025.111087},
url = {https://www.sciencedirect.com/science/article/pii/S088875432500103X},
author = {Minyan Zhu and Yaping Yang and Hongjie Fang and Rong Chen},
keywords = {Trastuzumab, Cardiomyocyte atrophy, Single-cell transcriptome sequencing, Bioinformatics analysis, FN1/PI3K/AKT-mediated mTOR-independent signaling pathways},
abstract = {Trastuzumab (TRZ) is a standard drug for the treatment of HER-2-positive breast cancer, but its cardiotoxicity seriously affects the prognosis of patients, and the potential mechanism of TRZ-induced cardiomyocyte atrophy leading to cardiotoxicity remains unclear. This study aimed to investigate the potential targets and signaling pathways of TRZ-induced cardiotoxicity using single-cell transcriptome sequencing (scRNA-seq) and bioinformatics methods. A total of 618 differentially expressed genes (DEGs) were identified through scRNA-seq and bioinformatics analysis. Gene Ontology (GO) analysis, Kyoto Encyclopedia of Genes and Genomes (KEGG) pathway analysis, Reactome analysis, Wiki pathway analysis, Protein-Protein Interaction (PPI) network analysis, and Reverse Transcription-Polymerase Chain Reaction (RT-PCR) results indicated that immune cell-derived FN1 may play a pivotal role in TRZ-induced cardiotoxicity by activating PI3K/AKT-mediated mTOR-independent signaling pathways in cardiomyocytes through extracellular matrix (ECM) mechanisms. Western blot analysis revealed that the expression of FN1, p-PI3K/PI3K, and p-AKT/AKT proteins was elevated in the TRZ group, no elevation of p-mTOR/mTOR and the autophagy level of cardiomyocytes was elevated, as well as the levels of myocardial atrophy and apoptosis were enhanced after treatment with TRZ. TEM revealed increased autolysosomes in TRZ-treated samples, while immunofluorescence analysis demonstrated exacerbated myocardial injury and significant cardiomyocyte atrophy in the TRZ group compared to CON. Our results demonstrate that TRZ-primed immune cells release FN1 which, through ECM triggers non-canonical (mTOR-independent) PI3K/AKT signaling in cardiomyocytes. This aberrant pathway drives excessive autophagy, initiating a pathological cascade from cellular atrophy to apoptotic death and ultimately manifesting as clinical cardiotoxicity.}
}
@article{DJEDDI2025126755,
title = {A degree centrality-enhanced computational approach for local network alignment leveraging knowledge graph embeddings},
journal = {Expert Systems with Applications},
volume = {275},
pages = {126755},
year = {2025},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2025.126755},
url = {https://www.sciencedirect.com/science/article/pii/S095741742500377X},
author = {Warith Eddine Djeddi and Sadok {Ben Yahia} and Engelbert {Mephu Nguifo}},
keywords = {Protein networks, Degree centrality, Knowledge graph embedding, Local network alignment, Protein complex},
abstract = {Biological network alignment serves various goals, including identifying similar regions between networks of different species, transferring biological knowledge, and predicting protein complexes and functions. This paper presents KOGAL (KnOwledge Graph ALignment), a scalable multiprocessing algorithm for local protein–protein interaction (PPI) network alignment. KOGAL aims to predict conserved protein complexes across species’ PPI networks. It employs two strategies for seed discovery and initial alignment: the first computes the cosine similarity between embedding vectors derived from knowledge graph models like TransE or DistMult to generate an alignment matrix. The second strategy begins the alignment process by calculating the centrality degree of nodes within each network, highlighting the importance of each protein in the network structure. Protein similarities are quantified by combining protein sequence similarities with knowledge graph embeddings, ensuring biologically meaningful structural alignments. KOGAL depicts strong results compared to other state-of-the-art approaches. When evaluated on real PPI networks, KOGAL demonstrates high accuracy across multiple metrics, including coverage, sensitivity, the number of matched reference conserved complexes (Frac), complex-wise sensitivity (Sn), positive predictive value (PPV), geometric accuracy (ACC), and maximum matching ratio (MMR).}
}
@article{SAHA202121,
title = {Application of tools to support Linked Open Data},
journal = {Library Hi Tech News},
volume = {38},
number = {6},
pages = {21-24},
year = {2021},
issn = {0741-9058},
doi = {https://doi.org/10.1108/LHTN-09-2021-0060},
url = {https://www.sciencedirect.com/science/article/pii/S0741905821000364},
author = {Sujan Saha and Sukumar Mandal},
keywords = {Library services, Linked open data, Semantic Web, Ontologies, RDF, Data visualization, BIBFRAME},
abstract = {Purpose
These projects aim to improve library services for users in the future by combining Link Open Data (LOD) technology with data visualization. It displays and analyses search results in an intuitive manner. These services are enhanced by integrating various LOD technologies into the authority control system.
Design/methodology/approach
The technology known as LOD is used to access, recycle, share, exchange and disseminate information, among other things. The applicability of Linked Data technologies for the development of library information services is evaluated in this study.
Findings
Apache Hadoop is used for rapidly storing and processing massive Linked Data data sets. Apache Spark is a free and open-source data processing tool. Hive is a SQL-based data warehouse that enables data scientists to write, read and manage petabytes of data.
Originality/value
The distributed large data storage system Apache HBase does not use SQL. This study’s goal is to search the geographic, authority and bibliographic databases for relevant links found on various websites. When data items are linked together, all of the data bits are linked together as well. The study observed and evaluated the tools and processes and recorded each data item’s URL. As a result, data can be combined across silos, enhanced by third-party data sources and contextualized.}
}
@article{MINUTOLO2022105004,
title = {A conversational agent for querying Italian Patient Information Leaflets and improving health literacy},
journal = {Computers in Biology and Medicine},
volume = {141},
pages = {105004},
year = {2022},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2021.105004},
url = {https://www.sciencedirect.com/science/article/pii/S0010482521007988},
author = {Aniello Minutolo and Emanuele Damiano and Giuseppe {De Pietro} and Hamido Fujita and Massimo Esposito},
keywords = {Conversational agent, Chatbots, Natural language interaction, Medical information, Health literacy},
abstract = {In the last years, the rise of digital technologies has enormously augmented the possibility for people to access health information and consult online versions of Patient Information Leaflets (PILs), enabling them to improve their knowledge about medication and adherence to therapies. However, health information may often be difficult to consult and comprehend due to an excessively lengthy and undersized text, coupled with the presence of many incomprehensible medical terms. To face these issues, this paper proposes a conversational agent as a valuable solution to simplify health information retrieval and improve health literacy in Italian by codifying PILs and making them query-able in natural language. In particular, the system has been devised to: i) comprehend natural language questions on medicines of interest; ii) proactively ask the user or automatically infer from the dialog state all the missing information necessary to generate an answer; iii) extract the answer from a structured knowledge base built from PILs of registered drugs. An experimental study has been carried out to evaluate both the performance and usability of the proposed system. Results showed an adequate ability of the system to handle most of the dialogues started by participants correctly, good users satisfaction, and, thus, proved its feasibility and usefulness.}
}
@article{YU2025503,
title = {Exploring the active components and mechanism of Ziziphi Spinosae Semen in treating insomnia by network pharmacology and metabonomics},
journal = {Journal of Future Foods},
volume = {5},
number = {5},
pages = {503-512},
year = {2025},
issn = {2772-5669},
doi = {https://doi.org/10.1016/j.jfutfo.2024.08.008},
url = {https://www.sciencedirect.com/science/article/pii/S2772566924000624},
author = {Xia Yu and Ziheng Jin and Linzheng Li and Jinmei Wang and Changyang Ma and Xuqiang Liu},
keywords = {, Insomnia, Network pharmacology, Metabonomics},
abstract = {Insomnia, a sleep-disordered disease, is characterized by difficulty in falling asleep, decrease of sleep quality and sleep time, decline of memory and attention. Ziziphi Spinosae Semen (ZSS) is one of the important “medicine-food” herbs for insomnia and anxiety. In this research, the sedative and hypnotic effects of ZSS extract (ZSSE) was evaluated by animal experiment, and the potential active components and related mechanism were further analyzed by using metabonomics and network pharmacology techniques. The results showed that ZSSE could cooperate with the subthreshold dose of barbital sodium in the hypnotic effect of mice, and the high-dose group (1 g/kg) significantly prolonged the sleep time of mice induced by barbital sodium (P < 0.01). A total of 200 compounds were obtained from ZSSE by liquid chromatography-mass spectrometry (LC-MS/MS), including triterpenoids, flavonoids, alkaloids, organic acids, fatty acyls, and among them 113 active components were screened. Network pharmacological analysis indicated that kaempferol, boldine, apigenin and ursolic acid may be the potential active ingredients of ZSSE in the treatment of insomnia. Protein-protein interaction (PPI) networks analysis showed that AKT serine/threonine kinase 1 (AKT1), catalase (CAT), prostaglandin-endoperoxide synthase 2 (PTGS2) and heme oxygenase 1 (HMOX1) were the main key targets. Gene Ontology (GO) enrichment analysis showed that these targets were mainly involved in steroid metabolic process, hormone level regulation and metabolism, synaptic membrane, neuronal cell body, heme binding, postsynaptic neurotransmitter receptor activity and neurotransmitter receptor activity. The enrichment analysis of Kyoto Encyclopedia of Genes and Genomes (KEGG) pathway showed that the sedative and hypnotic effects of ZSSE might be closely related to signaling pathways such as steroid hormone biosynthesis, neuroactive ligand-receptor interaction, HIF-1 signaling pathway, calcium signaling pathway, dopaminergic synapse, cAMP signaling pathway and cholinergic synapse. This study revealed the potential active components and mechanism of ZSSE in the treatment of insomnia, and provided a theoretical basis for the development and utilization of ZSS.}
}
@article{KUHLE201872,
title = {Clues to the puzzle: The significance of material cultures in nonhuman primates for the study of language},
journal = {Language Sciences},
volume = {67},
pages = {72-88},
year = {2018},
issn = {0388-0001},
doi = {https://doi.org/10.1016/j.langsci.2018.04.002},
url = {https://www.sciencedirect.com/science/article/pii/S0388000117301547},
author = {Anneliese Kuhle},
keywords = {Tools, Culture, General intelligence, Intentionality, Reasoning, Means–ends dissociation, Pragmatic inferencing, Linguistic diversity, Language grammar, Communication},
abstract = {This article argues in favor of a significant continuity, i.e., a homology, in underlying cognition between prelinguistic tool use in nonhuman primates and linguistic behavior in humans. In terms of theory, the evidence for such a cognitive homology is based on the distinct criteria for intentional behavior and cross-group cultural variation. I argue that these criteria are equally valid in primatological and human linguistic research. In past decades, tool use and natural language use have indeed been considered analogous with one another. However, this analogy has never been applied outside of the human domain. In fact, the discussion of intelligent behavior in animals has grown so controversial that even where the issue of concern is not language, much opposition emerges against the idea that the human capacity for culture is based on inherited cognitive capacities that we share with our closest living relatives. My argument challenges such extreme skepticism and supports the continuity hypothesis. The empirical evidence is based on data from ethnographic fieldwork on ape tool practices and natural languages.}
}
@article{BRABRA201965,
title = {On semantic detection of cloud API (anti)patterns},
journal = {Information and Software Technology},
volume = {107},
pages = {65-82},
year = {2019},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2018.10.012},
url = {https://www.sciencedirect.com/science/article/pii/S095058491830226X},
author = {Hayet Brabra and Achraf Mtibaa and Fabio Petrillo and Philippe Merle and Layth Sliman and Naouel Moha and Walid Gaaloul and Yann-Gaël Guéhéneuc and Boualem Benatallah and Faïez Gargouri},
keywords = {Cloud computing, REST, OCCI, Pattern, Anti-pattern, Analysis, Specification, Detection, Ontology},
abstract = {Context
Open standards are urgently needed for enabling software interoperability in Cloud Computing. Open Cloud Computing Interface (OCCI) provides a set of best design principles to create interoperable REST management APIs. Although OCCI is the only standard addressing the management of any kind of cloud resources, it does not support a range of best principles related to REST design. This often worsens REST API quality by decreasing their understandability and reusability.
Objective
We aim at assisting cloud developers to enhance their REST management APIs by providing a compliance evaluation of OCCI and REST best principles and a recommendation support to comply with these principles.
Method
First, we leverage patterns and anti-patterns to drive respectively the good and poor practices of OCCI and REST best principles. Then, we propose a semantic-based approach for defining and detecting REST and OCCI (anti)patterns and providing a set of correction recommendations to comply with both REST and OCCI best principles. We validated this approach by applying it on cloud REST APIs and evaluating its accuracy, usefulness and extensibility.
Results
We found that our approach accurately detects OCCI and REST(anti)patterns and provides useful recommendations. According to the compliance results, we reveal that there is no widespread adoption of OCCI principles in existing APIs. In contrast, these APIs have reached an acceptable level of maturity regarding REST principles.
Conclusion
Our approach provides an effective and extensible technique for defining and detecting OCCI and REST (anti)patterns in Cloud REST APIs. Cloud software developers can benefit from our approach and defined principles to accurately evaluate their APIs from OCCI and REST perspectives. This contributes in designing interoperable, understandable, and reusable Cloud management APIs. Thank to the compliance analysis and the recommendation support, we also contribute to improving these APIs, which make them more straightforward.}
}
@article{AHMAD202258,
title = {A novel hybrid methodology for computing semantic similarity between sentences through various word senses},
journal = {International Journal of Cognitive Computing in Engineering},
volume = {3},
pages = {58-77},
year = {2022},
issn = {2666-3074},
doi = {https://doi.org/10.1016/j.ijcce.2022.02.001},
url = {https://www.sciencedirect.com/science/article/pii/S2666307422000055},
author = {Farooq Ahmad and Dr. Mohammad Faisal},
keywords = {Natural language processing, WordNet, Word embedding, Word overlap, Semantic search, Semantic similarity, Lexical database, Corpus},
abstract = {In the area of natural language processing, measuring sentence similarity is an essential problem. Searching for semantic meaning in natural language is a related issue. The task of measuring sentence similarity is to find semantic symmetry in two sentences, not matter how they are arranged. It is important to measure the similarity of sentences accurately. To compute the similarity between sentences, existing methods have been constructed from approaches for large texts. Since these methods work in very high-dimensional spaces, they are inefficient, require human input, and are not flexible enough for some applications. In this study, we propose a hybrid method (HydMethod) which considers not only semantic information including lexical databases, word embeddings, and corpus statistics, but also implied word order information. With lexical databases, our method models human common sense knowledge, and that knowledge can then be adapted to be used in different domains with the incorporation of corpus statistics. Therefore, the methodology is applicable across several domains. As part of our experiments, we used two standard datasets - Pilot Short Text Semantic Similarity Benchmark and MS paraphrase - in order to demonstrate the efficacy of our proposed method. As a result, the proposed method outperforms the existing approaches when tested on these two datasets, giving the highest correlation value for both word and sentence similarity. Moreover, it achieves a maximum of 32% higher increase than only using word vector or WorldNet based methodology. With Rubenstein and Goodenough word & sentence pairs, our algorithm's similarity measure shows a high Pearson correlation coefficient of 0.8953.}
}
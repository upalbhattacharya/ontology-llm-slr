@article{SINGLE2020104321,
title = {Ontology-based computer aid for the automation of HAZOP studies},
journal = {Journal of Loss Prevention in the Process Industries},
volume = {68},
pages = {104321},
year = {2020},
issn = {0950-4230},
doi = {https://doi.org/10.1016/j.jlp.2020.104321},
url = {https://www.sciencedirect.com/science/article/pii/S0950423020306082},
author = {Johannes I. Single and Jürgen Schmidt and Jens Denecke},
keywords = {Computer-aided HAZOP, Ontologies and reasoning, Ontology-based hazard identification, Reasoning strategy, Next-generation HAZOP},
abstract = {Hazard and Operability (HAZOP) studies are conducted to identify and assess potential hazards which originate from processes, equipment, and process plants. These studies are human-centered processes that are time and labor-intensive. Also, extensive expertise and experience in the field of process safety engineering are required. There have been several attempts by different research groups to (semi-)automate HAZOP studies in the past. Within this research, a knowledge-based framework for the automatic generation of HAZOP worksheets was developed. Compared to other approaches, the focus is on representing semantic relationships between HAZOP relevant concepts under consideration of the degree of abstraction. In the course of this, expert knowledge from the process and plant safety (PPS) domain is embedded within the ontological model. Based on that, a reasoning algorithm based on semantic reasoners is developed to identify hazards and operability issues in a HAZOP similar manner. An advantage of the proposed method is that by modeling causal relationships between HAZOP concepts, automatically generated but meaningless scenarios can be avoided. The results of the enhanced causation model are high quality extended HAZOP worksheets. The developed methodology is applied within a case study that involves a hexane storage tank. The quality and quantity of the automatically generated results agree with the original worksheets. Thus the ontology-based reasoning algorithm is well-suited to identify hazardous scenarios and operability issues. Node-based analyses involving multiple process units can also be carried out by a slight adjustment of the method. The presented method can help to support HAZOP study participants and non-experts in conducting HAZOP studies.}
}
@article{ARBABI2019,
title = {Identifying Clinical Terms in Medical Text Using Ontology-Guided Machine Learning},
journal = {JMIR Medical Informatics},
volume = {7},
number = {2},
year = {2019},
issn = {2291-9694},
doi = {https://doi.org/10.2196/12596},
url = {https://www.sciencedirect.com/science/article/pii/S2291969419000371},
author = {Aryan Arbabi and David R Adams and Sanja Fidler and Michael Brudno},
keywords = {concept recognition, medical text mining, biomedical ontologies, machine learning, phenotyping, human phenotype ontology},
abstract = {Background
Automatic recognition of medical concepts in unstructured text is an important component of many clinical and research applications, and its accuracy has a large impact on electronic health record analysis. The mining of medical concepts is complicated by the broad use of synonyms and nonstandard terms in medical documents.
Objective
We present a machine learning model for concept recognition in large unstructured text, which optimizes the use of ontological structures and can identify previously unobserved synonyms for concepts in the ontology.
Methods
We present a neural dictionary model that can be used to predict if a phrase is synonymous to a concept in a reference ontology. Our model, called the Neural Concept Recognizer (NCR), uses a convolutional neural network to encode input phrases and then rank medical concepts based on the similarity in that space. It uses the hierarchical structure provided by the biomedical ontology as an implicit prior embedding to better learn embedding of various terms. We trained our model on two biomedical ontologies—the Human Phenotype Ontology (HPO) and Systematized Nomenclature of Medicine - Clinical Terms (SNOMED-CT).
Results
We tested our model trained on HPO by using two different data sets: 288 annotated PubMed abstracts and 39 clinical reports. We achieved 1.7%-3% higher F1-scores than those for our strongest manually engineered rule-based baselines (P=.003). We also tested our model trained on the SNOMED-CT by using 2000 Intensive Care Unit discharge summaries from MIMIC (Multiparameter Intelligent Monitoring in Intensive Care) and achieved 0.9%-1.3% higher F1-scores than those of our baseline. The results of our experiments show high accuracy of our model as well as the value of using the taxonomy structure of the ontology in concept recognition.
Conclusion
Most popular medical concept recognizers rely on rule-based models, which cannot generalize well to unseen synonyms. In addition, most machine learning methods typically require large corpora of annotated text that cover all classes of concepts, which can be extremely difficult to obtain for biomedical ontologies. Without relying on large-scale labeled training data or requiring any custom training, our model can be efficiently generalized to new synonyms and performs as well or better than state-of-the-art methods custom built for specific ontologies.}
}
@article{KANG2020101412,
title = {Understanding and improving ontology reasoning efficiency through learning and ranking},
journal = {Information Systems},
volume = {87},
pages = {101412},
year = {2020},
issn = {0306-4379},
doi = {https://doi.org/10.1016/j.is.2019.07.002},
url = {https://www.sciencedirect.com/science/article/pii/S0306437917306476},
author = {Yong-Bin Kang and Shonali Krishnaswamy and Wudhichart Sawangphol and Lianli Gao and Yuan-Fang Li},
keywords = {OWL, Reasoning, Performance prediction, Ontology, Metrics, Learning, Meta-reasoning, Semantic web},
abstract = {Ontologies are the fundamental building blocks of the Semantic Web and Linked Data. Reasoning is critical to ensure the logical consistency of ontologies, and to compute inferred knowledge from an ontology. It has been shown both theoretically and empirically that, despite decades of intensive work on optimising ontology reasoning algorithms, performing core reasoning tasks on large and expressive ontologies is time-consuming and resource-intensive. In this paper, we present the meta-reasoning framework R2O2* to tackle the important problems of understanding the source of TBox reasoning hardness and predicting and optimising TBox reasoning efficiency by exploiting machine learning techniques. R2O2* combines state-of-the-art OWL 2 DL reasoners as well as an efficient OWL 2 EL reasoner as components, and predicts the most efficient one by using an ensemble of robust learning algorithms including XGBoost and Random Forests. A comprehensive evaluation on a large and carefully curated ontology corpus shows that R2O2* outperforms all six component reasoners as well as AutoFolio, a robust and strong algorithm selection system.}
}
@article{LUO2020,
title = {Automatic Structuring of Ontology Terms Based on Lexical Granularity and Machine Learning: Algorithm Development and Validation},
journal = {JMIR Medical Informatics},
volume = {8},
number = {11},
year = {2020},
issn = {2291-9694},
doi = {https://doi.org/10.2196/22333},
url = {https://www.sciencedirect.com/science/article/pii/S2291969420000708},
author = {Lingyun Luo and Jingtao Feng and Huijun Yu and Jiaolong Wang},
keywords = {ontology, automatic structuring, Foundational Model of Anatomy, lexical granularity, machine learning},
abstract = {Background
As the manual creation and maintenance of biomedical ontologies are labor-intensive, automatic aids are desirable in the lifecycle of ontology development.
Objective
Provided with a set of concept names in the Foundational Model of Anatomy (FMA), we propose an innovative method for automatically generating the taxonomy and the partonomy structures among them, respectively.
Methods
Our approach comprises 2 main tasks: The first task is predicting the direct relation between 2 given concept names by utilizing word embedding methods and training 2 machine learning models, Convolutional Neural Networks (CNN) and Bidirectional Long Short-term Memory Networks (Bi-LSTM). The second task is the introduction of an original granularity-based method to identify the semantic structures among a group of given concept names by leveraging these trained models.
Results
Results show that both CNN and Bi-LSTM perform well on the first task, with F1 measures above 0.91. For the second task, our approach achieves an average F1 measure of 0.79 on 100 case studies in the FMA using Bi-LSTM, which outperforms the primitive pairwise-based method.
Conclusions
We have investigated an automatic way of predicting a hierarchical relationship between 2 concept names; based on this, we have further invented a methodology to structure a group of concept names automatically. This study is an initial investigation that will shed light on further work on the automatic creation and enrichment of biomedical ontologies.}
}
@article{CAO2021102942,
title = {An Automated Approach for Execution Sequence-Driven Software and Physical Co-Design of Mechatronic Systems Based on Hybrid Functional Ontology},
journal = {Computer-Aided Design},
volume = {131},
pages = {102942},
year = {2021},
issn = {0010-4485},
doi = {https://doi.org/10.1016/j.cad.2020.102942},
url = {https://www.sciencedirect.com/science/article/pii/S0010448520301354},
author = {Yue Cao and Yusheng Liu and Xiaoping Ye and Jianjun Zhao},
keywords = {Software-intensive mechatronic system, Software-physical co-design, Functional modeling, Design automation, Ontologies},
abstract = {Most mechatronic systems have becoming software-intensive. Even in their early design, the software and physical domains intersect with each other deeply. It is significant to capture and process the cross-domain influences automatically to avoid design defects in late stages. Semantic web technologies have been recognized as effective enabling technologies to support cross-domain knowledge representation and inference. However, how to correlate the knowledge of software and physical designs, which have divergent characteristics in an ontological knowledge is the difficulty. In this study, with the help of semantic web technologies, an automated software-physical co-design approach is proposed based on a hybrid function ontology, which unifies the physical-centric flow-based functional representation and software-centric data/control flow diagram. Software and physical designs are linked to this unified functional ontology such that the execution sequences controlled by software can constrain the physical design and the updates on the execution sequences introduced by physical design can be reflected on software behaviors. An ontology-based framework is implemented to support this approach. Two case studies from different application areas are illustrated to show its effectiveness.}
}
@article{DEVENDRAKUMAR2021104313,
title = {Extraction of the molecular level biomedical event trigger based on gene ontology using radial belief neural network techniques},
journal = {Biosystems},
volume = {199},
pages = {104313},
year = {2021},
issn = {0303-2647},
doi = {https://doi.org/10.1016/j.biosystems.2020.104313},
url = {https://www.sciencedirect.com/science/article/pii/S0303264720301878},
author = {R.N. {Devendra Kumar} and Arvind C and K. Srihari},
keywords = {Biomedical, Artificial intelligence, Cystic fibrosis, Machine learning, Neural network, Gene ontology biosystems, Radial belief neural network (RBNN)},
abstract = {Detection of molecular level biomedical event extraction plays a vital role in creating and visualizing the applications related to natural language processing. Cystic Fibrosis is an inherited genetic and debilitating pathology involving the respiratory and digestive systems. The excessive production of thick sticky mucus on the outside of the cells is the main consequence of such disease. This includes disease prevention and medical search to signify the occurrence and detection of event triggers, which is regarded as a proper step in an event extraction of molecular level in biomedical applications. In this model, use a rich set of extracted features to feed the machine learning classifier that helps in better extraction of events. The study uses an automatic feature selection and a classification model using Radial Belief Neural Network (RBNN) for the optimal detection of molecular biomedical event detection. The Radial Belief Neural Network (RBNN) is the proposed system is implemented and it is the classifier to give accurate result of the disease detection. These three algorithms are used to enhance the generalization performance and scalability of detecting the molecular event triggers. The validation is conducted on the cystic fibrosis event trigger based on the gene ontology bio system using the RBNN model with a lung molecular event-level extraction dataset. The extensive computation shows that the Radial Belief Neural Network (RBNN) is proposed to given the better performance results like Accuracy, Sensitivity, Specificity, F-measure and Execution time.}
}
@article{WALOSZEK2020723,
title = {Contextual ontology for tonality assessment},
journal = {Procedia Computer Science},
volume = {176},
pages = {723-732},
year = {2020},
note = {Knowledge-Based and Intelligent Information & Engineering Systems: Proceedings of the 24th International Conference KES2020},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2020.09.045},
url = {https://www.sciencedirect.com/science/article/pii/S1877050920319402},
author = {Wojciech Waloszek and Nina Rizun},
keywords = {knowledge bases, contexts, sentiment classification, topic modelling, hierarchical sentiment dictionary},
abstract = {In the paper we discuss the possibilities of using hierarchical contextual ontologies for supporting sentiment classification tasks. The discussion focuses on two important research hypotheses: (1) whether it is possible to construct such an ontology from a corpus of textual document, and (2) whether it is possible and beneficial to use inferencing from this ontology to support the process of sentiment classification. To support the first hypothesis we present a method of extraction of hierarchy of contexts from a set of textual documents and encoding this hierarchy into a multi-level contextual ontology. To support the second hypothesis, we present a method of reasoning from the ontology, and results of experimental verification, which show that use of this reasoning method can increase the accuracy of sentiment classification for longer text documents.}
}
@article{SORMAZ2019183,
title = {SIMPM – Upper-level ontology for manufacturing process plan network generation},
journal = {Robotics and Computer-Integrated Manufacturing},
volume = {55},
pages = {183-198},
year = {2019},
note = {Extended Papers Selected from FAIM2016},
issn = {0736-5845},
doi = {https://doi.org/10.1016/j.rcim.2018.04.002},
url = {https://www.sciencedirect.com/science/article/pii/S0736584517302119},
author = {Dušan Šormaz and Arkopaul Sarkar},
abstract = {Distributed computer integrated manufacturing is increasingly adopting cloud computing, software-as-a-service (SaaS) and multi-agent systems as steps towards “design anywhere, build anywhere” strategy. In this scenario, ontologies not only serve as common message exchange structure among distributed agents but also provide reasoning capability to extract implicit knowledge from explicit information already stored in the knowledge base. Foundation ontologies (upper-level), comprised of most general concepts of a domain, provide a common semantic structure to the domain-level ontologies, which capture details of multi-disciplinary manufacturing knowledge. In this paper, novel upper-level ontology, called SIMPM (Semantically Integrated Manufacturing Planning Model), is proposed in order to model three fundamental constraints of manufacturing process planning: variety, time, and aggregation. The philosophical underpinning of the proposed ontology – presented as OWL-DL axioms – is derived from a three dimensional planning model, developed during our past research on computer-aided process planning. As part of the evaluation of SIMPM ontology, we first expound on the interoperability issues with other upper-level manufacturing ontologies. Next, we present a case study on process planning for prismatic part design. In this way, we demonstrate how the generic set of proposed axioms may be used to address various manufacturing process planning concerns, such as alternative manufacturing resources, the temporal order among operations and granularity in the details of a process plan.}
}
@article{CAO2020104119,
title = {Maximal structure generation of superstructure for semantic triple generated by DEVS ontology in the process industry},
journal = {Chemometrics and Intelligent Laboratory Systems},
volume = {205},
pages = {104119},
year = {2020},
issn = {0169-7439},
doi = {https://doi.org/10.1016/j.chemolab.2020.104119},
url = {https://www.sciencedirect.com/science/article/pii/S016974392030349X},
author = {Jian Cao and Yan-Lin He and Qun-Xiong Zhu},
keywords = {Superstructure, P-Graph, DEVS Ontology, Process industry},
abstract = {In the process industry, a large number of multi-source heterogeneous data are generated. Ontology combined with resource description framework (RDF) is a great way to describe multi-source heterogeneous data. Due to the characteristics of free extension, no model limitations and few constraints in the calculation process, semantic data have been increasingly used in industrial systems. However, semantic data have not been fully utilized to realize automatic modeling. Lots of time and experience from knowledge workers is still required in the feedstock scheduling. Therefore, this article presents a method of constructing the RDF triple graph data based on the discrete event system specification ontology. Based on the advantage of graph data, the procedure of superstructure generation is greatly simplified by the proposed RDFMSG (maximal structure generation based on resource description framework data) algorithm. In the RDFMSG algorithm, the original structure is no longer pruned and then reorganized; the superstructure can be generated by the traversing RDF data set only once. The effectiveness and efficiency of the proposed methodology are verified through three cases. In addition, the representation of the discrete event system specification ontology can achieve good performance. Furthermore, the combination explosion caused by set operation can be greatly reduced, indicating that the strategy of the RDFMSG plays an important role in the solution structure generation algorithm and the accelerated branch and bound algorithm.}
}
@article{KUSTER2020102731,
title = {The UDSA ontology: An ontology to support real time urban sustainability assessment},
journal = {Advances in Engineering Software},
volume = {140},
pages = {102731},
year = {2020},
issn = {0965-9978},
doi = {https://doi.org/10.1016/j.advengsoft.2019.102731},
url = {https://www.sciencedirect.com/science/article/pii/S0965997818311773},
author = {Corentin Kuster and Jean-Laurent Hippolyte and Yacine Rezgui},
abstract = {Urban sustainability assessment frameworks have emerged during the past decade to address holistically the complexity of the urban landscape through a systems approach, factoring in environmental, social and economic requirements. However, the current assessment schemes are (a) static in nature, and as such don't reflect the dynamic and real-time nature of urban artefacts, (b) are not grounded in semantics (e.g. BIM and GIS), and (c) are at best used to assist in regulatory compliance, for instance in energy design, to meet increasingly stringent regulatory requirements. Information and communication technologies provide a new value proposition capitalizing on the Internet of Things (IoT) and semantics to provide real-time insights and inform decision making. Consequently, there is a real need in the field for data models that could facilitate data exchange and handle data heterogeneity. In this study, a semantic data model is considered to support near real-time urban sustainability assessment and enhance the semantics of sensor network data. Based on an extensive review of urban sustainability assessment frameworks and ontology development methodologies, the Urban District Sustainability Assessment (UDSA) ontology has been developed and validated using real data from the site of “The Works”, a newly refurbished neighbourhood in Ebbw Vale, Wales. This novel approach reconciles several domain-specific ontologies within one high-level ontology that can support the creation of real-time urban sustainability assessment software. In addition, this information model is aligned with 29 authoritative urban sustainability assessment frameworks, thus providing a useful resource not only in urban sustainability assessment, but also in the wider smart cities context.}
}
@article{ZOU2018262,
title = {Linking historical collections in an event-based ontology},
journal = {Digital Library Perspectives},
volume = {34},
number = {4},
pages = {262-275},
year = {2018},
issn = {2059-5816},
doi = {https://doi.org/10.1108/DLP-02-2018-0005},
url = {https://www.sciencedirect.com/science/article/pii/S2059581618000168},
author = {Qing Zou and Eun G. Park},
keywords = {Event, Basic Formal Ontology, BFO, Creator history, Event Ontology for Historical Description (EOHD), Historical collections},
abstract = {Purpose
This study aims to explore a way of representing historical collections by examining the features of an event in historical documents and building an event-based ontology model.
Design/methodology/approach
To align with a domain-specific and upper ontology, the Basic Formal Ontology (BFO) model is adopted. Based on BFO, an event-based ontology for historical description (EOHD) is designed. To define events, event-related vocabularies are taken from the Library of Congress’ event types (2012). The three types of history and six kinds of changes are defined.
Findings
The EOHD model demonstrates how to apply the event ontology to biographical sketches of a creator history to link event types.
Research limitations/implications
The EOHD model has great potential to be further expanded to specific events and entities through different types of history in a full set of historical documents.
Originality/value
The EOHD provides a framework for modeling and semantically reforming the relationships of historical documents, which can make historical collections more explicitly connected in Web environments.}
}
@article{BOUAUD2020101922,
title = {Implementation of an ontological reasoning to support the guideline-based management of primary breast cancer patients in the DESIREE project},
journal = {Artificial Intelligence in Medicine},
volume = {108},
pages = {101922},
year = {2020},
issn = {0933-3657},
doi = {https://doi.org/10.1016/j.artmed.2020.101922},
url = {https://www.sciencedirect.com/science/article/pii/S0933365719306736},
author = {Jacques Bouaud and Sylvia Pelayo and Jean-Baptiste Lamy and Coralie Prebet and Charlotte Ngo and Luis Teixeira and Gilles Guézennec and Brigitte Séroussi},
keywords = {Clinical decision support systems, Ontology, Clinical practice guidelines, Breast cancer},
abstract = {The DESIREE project has developed a platform offering several complementary therapeutic decision support modules to improve the quality of care for breast cancer patients. All modules are operating consistently with a common breast cancer knowledge model (BCKM) following the generic entity-attribute-value model. The BCKM is formalized as an ontology including both the data model to represent clinical patient information and the termino-ontological model to represent the application domain concepts. This ontological model is used to describe data semantics and to allow for reasoning at different levels of abstraction. We present the guideline-based decision support module (GL-DSS). Three breast cancer clinical practice guidelines have been formalized as decision rules including evidence levels, conformance levels, and two types of dependency, “refinement” and “complement”, used to build complete care plans from the reconciliation of atomic recommendations. The system has been assessed on 138 decisions previously made without the system and re-played with the system after a washout period on simulated tumor boards (TBs) in three pilot sites. When TB clinicians changed their decision after using the GL-DSS, it was for a better decision than the decision made without the system in 75 % of the cases.}
}
@article{QUINN2021101233,
title = {A case study comparing the completeness and expressiveness of two industry recognized ontologies},
journal = {Advanced Engineering Informatics},
volume = {47},
pages = {101233},
year = {2021},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2020.101233},
url = {https://www.sciencedirect.com/science/article/pii/S1474034620302020},
author = {Caroline Quinn and J.J. McArthur},
keywords = {Brick, Haystack, Smart building, Ontology},
abstract = {Enabling Smart Building applications will help to achieve the ongoing efficient commissioning of buildings, ultimately attaining peak performance in energyuse and improved occupant health and comfort, at minimum cost. For these technologies to be scalable, ontology must be adopted to semantically represent data generated by building mechanical systems, acting as conduit for connection to Smart Building applications. As the Building Automation System (BAS) industry considers Brick and Project Haystack ontologies for such applications, this paper provides a quantitative comparison of their completeness and expressiveness using a case study. This is contextualized within the broader set of ontological approaches developed for Smart Buildings, and critically evaluated using key ontology qualities outlined in literature. Brick achieved higher assessment values in completeness and expressiveness achieving 59% and 100% respectively, as compared to Haystacks 43% and 96%. Additionally, Brick exhibited five of six desirable qualities, where Haystack exhibited only three. Overall, this critical analysis has found Brick to be preferable to Haystack but still lacking in completeness; to overcome this, it should be integrated with other existing ontologies to serve as a holistic ontology for the longer- term development of Smart Building applications. These will support innovative approachesto sustainability in building operations across scales and as next- generation building controls and automation strategies.}
}
@article{SHAHZAD2021106146,
title = {Ontology Driven Smart Health Service Integration},
journal = {Computer Methods and Programs in Biomedicine},
volume = {207},
pages = {106146},
year = {2021},
issn = {0169-2607},
doi = {https://doi.org/10.1016/j.cmpb.2021.106146},
url = {https://www.sciencedirect.com/science/article/pii/S0169260721002200},
author = {Syed Khuram Shahzad and Daniyal Ahmed and Muhammad Raza Naqvi and Muhammad Tahir Mushtaq and Muhammad Waseem Iqbal and Farrukh Munir},
keywords = {Internet of things, Integrated platform, Smart healthcare, Health service facilitation, Ontological framework},
abstract = {Background and objective
The massive increase, in the Internet of Things applications, has greatly evolved technological aspects of human life. The drastic development of IoT based smart healthcare services have layout the smart process models to facilitate all stakeholders (e.g. patients, doctors, hospitals etc.) and made it an important social-economic concern. There are variety of smart healthcare services like remote patient monitoring, diagnostic, disease specific remote treatments and telemedicine. Many trending Internet of Health Things research and development are done in a very disjoint and independent fashion providing solutions and guidelines for variant diseases, medical resources and remote services management. These expositions work over many shared resources such as health facilities for patient and human in healthcare system.
Methods
This research discusses the ontology for merging methods to form an integrated platform with shared knowledge of smart healthcare services. The proposed process model creates an ontological framework of integrated healthcare services, which are firstly defined using ontologies and lately integrated over similarities, differences, dependencies and other semantic relations. The data and process requirements for service integration facility is derived from various smart healthcare services.
Results
The proposed model is evaluated using two-step ontological modeling testing method, applied at the ontological framework of integrated smart health services. First evaluation step has targeted the model consistency validation using reasoning tool while querying tools are used to validate the retrieved data entities and relations among them for predefined use-cases.
Conclusions
The research concluded with a novel approach for smart health service integration using ontological modeling and merging techniques. The model efficiency enhancement and query optimization methods are listed in future tasks of the research.}
}
@article{AN202010929,
title = {A multi-facets ontology matching approach for generating PLC domain knowledge graphs},
journal = {IFAC-PapersOnLine},
volume = {53},
number = {2},
pages = {10929-10934},
year = {2020},
note = {21st IFAC World Congress},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2020.12.2834},
url = {https://www.sciencedirect.com/science/article/pii/S2405896320335990},
author = {Yameng An and Feiwei Qin and Danfeng Sun and Huifeng Wu},
keywords = {Software reuse, Semantic representation, Ontology matching, Knowledge graph},
abstract = {Programmable Logic Controller (PLC) has been playing an important role in industrial automation. Users want to improve programming efficiency by implementing code reuse and more intelligent code retrieval. Due to the heterogeneity of different PLC development environments, it is then necessary to design a computable knowledge model to semantically represent, organize, and utilize these diversified resources. Using the ontology technique is a common way to achieve the interoperability of heterogeneous systems. Aiming at this, we propose an ontology matching approach in this paper. Knowledge extraction and alignment are difficult for most of the knowledge graphs construction tasks, however, we are able to build the PLC domain knowledge graph with high accuracy and completeness by considering PLC domain characteristics, designing layered ontology, and implementing the matching process primarily on schema level instead of instance level.}
}
@incollection{GUERRERO202425,
title = {1.03 - Ontology anchored decision support tools: A focus on pharmacogenomics},
editor = {Kenneth S. Ramos},
booktitle = {Comprehensive Precision Medicine (First Edition)},
publisher = {Elsevier},
edition = {First Edition},
address = {Oxford},
pages = {25-40},
year = {2024},
isbn = {978-0-12-824256-8},
doi = {https://doi.org/10.1016/B978-0-12-824010-6.00069-1},
url = {https://www.sciencedirect.com/science/article/pii/B9780128240106000691},
author = {Ruben Bonilla Guerrero and Kaitlyn Marshall and Sara Rogers and Mary Weissman},
keywords = {Clinical decision support, Clinical rules, Computer-interpretable guidelines, Data science, Decision support algorithms, Electronic health record, Informatics, Ontology, Pharmacogenetics, Pharmacogenomics},
abstract = {Increasingly, institutions have implemented clinical decision support (CDS) tools in the clinical setting to bring pharmacogenomics data into patient care. Principles of ontology are often leveraged to create CDS tools to fit customized pharmacogenomics interfaces. The purpose of this chapter is to review the concept of pharmacogenomics and the type of data generated. Then we provide a summary of the types, functions, and limitations of the underlying ontological features to support CDS. Finally, we conclude with a discussion of opportunities and areas of growth for pharmacogenomics CDS.}
}
@article{BENAVIDES2018107,
title = {An ontology-based approach to knowledge representation for Computer-Aided Control System Design},
journal = {Data & Knowledge Engineering},
volume = {118},
pages = {107-125},
year = {2018},
issn = {0169-023X},
doi = {https://doi.org/10.1016/j.datak.2018.10.002},
url = {https://www.sciencedirect.com/science/article/pii/S0169023X17305189},
author = {Carmen Benavides and Isaías García and Héctor Alaiz and Luis Quesada},
keywords = {Conceptual modeling, Data and knowledge visualization, Ontologies, Computer-Aided Control System Design},
abstract = {Different approaches have been used in order to represent and build control engineering concepts for the computer. Software applications for these fields are becoming more and more demanding each day, and new representation schemas are continuously being developed. This paper describes a study of the use of knowledge models represented in ontologies for building Computer Aided Control Systems Design (CACSD) tools. The use of this approach allows the construction of formal conceptual structures that can be stated independently of any software application and be used in many different ones. In order to show the advantages of this approach, an ontology and an application have been built for the domain of design of lead/lag controllers with the root locus method, presenting the results and benefits found.}
}
@article{BAYOUDHI2018138,
title = {How to Repair Inconsistency in OWL 2 DL Ontology Versions?},
journal = {Data & Knowledge Engineering},
volume = {116},
pages = {138-158},
year = {2018},
issn = {0169-023X},
doi = {https://doi.org/10.1016/j.datak.2018.05.010},
url = {https://www.sciencedirect.com/science/article/pii/S0169023X16303172},
author = {Leila Bayoudhi and Najla Sassi and Wassim Jaziri},
keywords = {OWL 2 DL ontology, Evolution, Inconsistency, A priori approach},
abstract = {Semantic modeling knowledge formalisms, such as ontologies, have to follow the continuous evolution and changes of knowledge. However, ontology changes should never affect its consistency. Ontology needs to remain in a consistent state along its whole engineering process. In the literature, most of approaches check/repair ontology inconsistencies in an a posteriori way. In this paper, an a priori inconsistency approach was proposed to generate consistent OWL 2 DL ontology versions. It relies on the OWL 2 DL change kits, which anticipate inconsistencies upon each change request on an ontology version. The proposed approach predicts potential inconsistencies, provides an a priori repair action and applies the required changes. Consistency rules were defined and used to check logical inconsistencies, but also syntactical invalidities and style issues. A protégé plugin was implemented to validate our approach.}
}
@article{LOUGE2025126641,
title = {Events-based semantic services composition in Industry 4.0 using Asset Administration Shell meta-model for digital twins},
journal = {Expert Systems with Applications},
volume = {271},
pages = {126641},
year = {2025},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2025.126641},
url = {https://www.sciencedirect.com/science/article/pii/S0957417425002635},
author = {Thierry Louge and Sina Namaki Araghi and Mohamed Hedi Karray and Arkopaul Sarkar},
keywords = {Ontologies, Semantic services, Asset Administration Shell, Industry 4.0, Digital twins},
abstract = {Since the emergence of the Semantic Web concept, considerable work has focused on service composition using ontology-based approaches. Meanwhile, the concept of Industry 4.0 has emerged, emphasizing the benefits of utilizing data and computing devices in close proximity to production lines, exemplified by concepts like digital twins. However, these two fields rarely intersect, and the requirements for integrating domain-specific knowledge into business processes with event feedback during processes execution differ between these contexts. With the recent advancements in the semantization of industrial standards, such as the Asset Administration Shell, this work explores the elements of a semantic model for describing equipment, enabling the semantic composition of equipment as services. We propose an ontology, COMPAAS, designed to facilitate the composition of production lines that can react to events reported by their components, allowing the system to adjust its behavior accordingly. This approach also addresses the removal and addition of hardware or software elements within the chain, and the entire concept is validated through a minimal use case that demonstrates the improved flexibility of the production line in response to potential disturbances.}
}
@article{WANG2018359,
title = {Citrus ontology development based on the eight-point charter of agriculture},
journal = {Computers and Electronics in Agriculture},
volume = {155},
pages = {359-370},
year = {2018},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2018.10.034},
url = {https://www.sciencedirect.com/science/article/pii/S0168169917312012},
author = {Yi Wang and Ying Wang},
keywords = {Ontology, Knowledge modeling, Semantic web, Agriculture},
abstract = {Developing large-scale agricultural ontologies is a challenging and error-prone task that requires substantial effort and collaboration between domain experts and ontology developers due to the complexity of agricultural knowledge. Inspired by the Chinese Eight-Point Charter of Agriculture, i.e., Soil, Fertilization, Water, Variety, Density, Protection, Management and Tool, this paper presents an approach to modeling and integrating citrus production knowledge. Citrus domain knowledge is classified into eight categories based on the Eight-Point Charter of Agriculture, and the relationships in each category and among categories are established. The eight categories and the relationships are defined as the citrus production knowledge framework. Then, we propose mechanisms to develop citrus ontology based on the citrus production knowledge framework. The Fertilization ontology is created as an illustration of our approach, which contains 866 ontology entities and 12,583 Resource Description Framework triples. The structural evaluation results of the eight metrics for the Fertilization ontology are considerably better than the average and median values of 1413 Web ontologies. In addition, four antipatterns were used to evaluate the ontology, and no occurrence of the antipatterns was detected for the 866 ontology entities. The accuracy of the ontology is ensured by the competency evaluation of the 110 questions with 88% accuracy. Our approach provides an effective solution for modeling complex agricultural knowledge and transforming the agriculture domain knowledge into computable resources.}
}
@article{WATROBSKI20203345,
title = {Towards standardization in frameworks, tools and approaches dedicated to ontology building and management},
journal = {Procedia Computer Science},
volume = {176},
pages = {3345-3355},
year = {2020},
note = {Knowledge-Based and Intelligent Information & Engineering Systems: Proceedings of the 24th International Conference KES2020},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2020.09.063},
url = {https://www.sciencedirect.com/science/article/pii/S187705092031958X},
author = {Jarosław Wątróbski},
keywords = {Ontology integration, Ontology merging, alignement, Knowledge repository, Ontology},
abstract = {The widespread popularity and spread of ontologies in many areas increasingly requires the successful integration of multiple such ontologies. The ontology integration problem has been investigated during last years and it is still a challenging task. Aligning and merging existing ontologies, which are usually handled manually, is often a big and tedious part of the sharing process. Due to the fact that there are different approaches, tools and strategies that help to avoid mistakes during modeling especially large domains and creating a new single coherent ontology, this article attempts to build a common knowledge repository in the form of an open and publicly available tool. The overall goal of the proposed open knowledge repository is to provide free access to basic data and to compare the features offered. It is worth mentioning that this form of knowledge representation is publicly available and focuses on the possibility of updating and reusing. It is an attempt to structure knowledge that can be successfully extended with additional groups of solutions and parameters. The proposed approach can be easily implemented as a light library and used in any type of OWL/RDF or OWL/XML management application or adapted in a given management information system.}
}
@article{NATH2021104433,
title = {The quest for better clinical word vectors: Ontology based and lexical vector augmentation versus clinical contextual embeddings},
journal = {Computers in Biology and Medicine},
volume = {134},
pages = {104433},
year = {2021},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2021.104433},
url = {https://www.sciencedirect.com/science/article/pii/S0010482521002274},
author = {Namrata Nath and Sang-Heon Lee and Mark D. McDonnell and Ivan Lee},
keywords = {Clinical word vectors, Antonymy, Word embedding, Augmentation},
abstract = {Background
Word vectors or word embeddings are n-dimensional representations of words and form the backbone of Natural Language Processing of textual data. This research experiments with algorithms that augment word vectors with lexical constraints that are popular in NLP research and clinical domain constraints derived from the Unified Medical Language System (UMLS). It also compares the performance of the augmented vectors with Bio + Clinical BERT vectors which have been trained and fine-tuned on clinical datasets.
Methods
Word2vec vectors are generated for words in a publicly available de-identified Electronic Health Records (EHR) dataset and augmented by ontologies using three algorithms that have fundamentally different approaches to vector augmentation. The augmented vectors are then evaluated alongside publicly available Bio + Clinical BERT on their correlation with human-annotated lists using Spearman's correlation coefficient. They are also evaluated on the downstream task of Named Entity Recognition (NER). Quantitative and empirical evaluations are used to highlight the strengths and weaknesses of the different approaches.
Results
The counter-fitted word2vec vectors augmented with information from the UMLS ontology produced the best correlation overall with human-annotated evaluation lists (Spearman's correlation of 0.733 with mini mayo-doctors’ annotation) while Bio + Clinical BERT produces the best results in the NER task (F1 of 0.87 and 0.811 on the i2b2 2010 and i2b2 2012 datasets respectively) in our experiments.
Conclusion
Clinically adapted word2vec vectors successfully encapsulate concepts of lexical and clinical synonymy and antonymy and to a smaller extent, hyponymy and hypernymy. Bio + Clinical BERT vectors perform better at NER and avoid out-of-vocabulary words.}
}
@article{HAQUE20191085,
title = {Restoring Consistency in Ontological Multidimensional Data Models via Weighted Repairs},
journal = {Procedia Computer Science},
volume = {159},
pages = {1085-1094},
year = {2019},
note = {Knowledge-Based and Intelligent Information & Engineering Systems: Proceedings of the 23rd International Conference KES2019},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2019.09.277},
url = {https://www.sciencedirect.com/science/article/pii/S1877050919314735},
author = {Enamul Haque and Fei Chiang},
keywords = {multidimensional data model, ontology, data quality, weight repairs, CRITIC},
abstract = {High data quality is a prerequisite for accurate data analysis. However, data inconsistencies often arise in real data, leading to untrusted decision making downstream in the data analysis pipeline. In this paper, we study the problem of inconsistency detection and repair of the Ontology Multi-dimensional Data Model (OMD). We propose a framework of data quality assessment, and repair for the OMD. We formally define a weight-based repair-by-deletion semantics, and present an automatic weight generation mechanism that considers multiple input criteria. Our methods are rooted in multi-criteria decision making that consider the correlation, contrast, and conflict that may exist among multiple criteria, and is often needed in the data cleaning domain.}
}
@article{SYED2020103334,
title = {Cybersecurity vulnerability management: A conceptual ontology and cyber intelligence alert system},
journal = {Information & Management},
volume = {57},
number = {6},
pages = {103334},
year = {2020},
issn = {0378-7206},
doi = {https://doi.org/10.1016/j.im.2020.103334},
url = {https://www.sciencedirect.com/science/article/pii/S0378720620302718},
author = {Romilla Syed},
keywords = {Cybersecurity vulnerability, Vulnerability management, Social media intelligence, Ontology, Conceptual modeling, Cyberalerts},
abstract = {Effective vulnerability management requires the integration of vulnerability information available on multiple sources, including social media. The information could be used to inform common users about impending vulnerabilities and countermeasures. First, we present the Cybersecurity Vulnerability Ontology (CVO), a conceptual model for formal knowledge representation of the vulnerability management domain. Second, we utilize the CVO to design a Cyber Intelligence Alert (CIA) system that issues cyber alerts about vulnerabilities and countermeasures. We rigorously evaluated the CVO as well as the accuracy, performance, and usefulness of the CIA system. Key contributions of this study to research and practice are discussed.}
}
@article{EIBECK2019106586,
title = {J-Park Simulator: An ontology-based platform for cross-domain scenarios in process industry},
journal = {Computers & Chemical Engineering},
volume = {131},
pages = {106586},
year = {2019},
issn = {0098-1354},
doi = {https://doi.org/10.1016/j.compchemeng.2019.106586},
url = {https://www.sciencedirect.com/science/article/pii/S0098135419301589},
author = {Andreas Eibeck and Mei Qi Lim and Markus Kraft},
keywords = {Industry 4.0, Ontology, Linked data, Knowledge graph, Interoperability, Agent},
abstract = {The J-Park Simulator (JPS) acts as a continuously growing platform for integrating real-time data, knowledge, models, and tools related to process industry. It aims at simulation and optimization in cross-domain and multi-level scenarios and relies heavily on ontologies and semantic technologies. In this paper, we demonstrate the interoperability between different applications in JPS, introduce new domain ontologies into the JPS, and integrate live data. For this, we utilize a knowledge graph to store and link semantically described data and models and create agents wrapping the applications and updating the data in the knowledge graph dynamically. We present a comprehensive industrial air pollution scenario, which has been implemented as part of the JPS, to show how knowledge graphs and modular domain ontologies support the interoperability between agents. We show that the architecture of JPS increases the interoperability and flexibility in cross-domain scenarios and conclude that the potential of ontologies outweighs additional wrapping efforts.}
}
@article{SOUZA2020151,
title = {A framework to aggregate multiple ontology matchers},
journal = {International Journal of Web Information Systems},
volume = {16},
number = {2},
pages = {151-169},
year = {2020},
issn = {1744-0084},
doi = {https://doi.org/10.1108/IJWIS-05-2019-0023},
url = {https://www.sciencedirect.com/science/article/pii/S174400842000021X},
author = {Jairo Francisco de Souza and Sean Wolfgand Matsui Siqueira and Bernardo Nunes},
keywords = {Metadata and ontologies, Semantic interoperability, Schema matching},
abstract = {Purpose
Although ontology matchers are annually proposed to address different aspects of the semantic heterogeneity problem, finding the most suitable alignment approach is still an issue. This study aims to propose a computational solution for ontology meta-matching (OMM) and a framework designed for developers to make use of alignment techniques in their applications.
Design/methodology/approach
The framework includes some similarity functions that can be chosen by developers and then, automatically, set weights for each function to obtain better alignments. To evaluate the framework, several simulations were performed with a data set from the Ontology Alignment Evaluation Initiative. Simple similarity functions were used, rather than aligners known in the literature, to demonstrate that the results would be more influenced by the proposed meta-alignment approach than the functions used.
Findings
The results showed that the framework is able to adapt to different test cases. The approach achieved better results when compared with existing ontology meta-matchers.
Originality/value
Although approaches for OMM have been proposed, it is not easy to use them during software development. On the other hand, this work presents a framework that can be used by developers to align ontologies. New ontology matchers can be added and the framework is extensible to new methods. Moreover, this work presents a novel OMM approach modeled as a linear equation system which can be easily computed.}
}
@article{CAO20191691,
title = {An Ontology-based Bayesian network modelling for supply chain risk propagation},
journal = {Industrial Management & Data Systems},
volume = {119},
number = {8},
pages = {1691-1711},
year = {2019},
issn = {0263-5577},
doi = {https://doi.org/10.1108/IMDS-01-2019-0032},
url = {https://www.sciencedirect.com/science/article/pii/S026355771900085X},
author = {Shoufeng Cao and Kim Bryceson and Damian Hine},
keywords = {Supply chain risk management, Global supply chain management, Risk performance, Fresh produce, Ontology-based Bayesian network, Risk propagation},
abstract = {Purpose
Supply chain risks (SCRs) do not work in isolation and have impact both on each member of a chain and the performance of the entire supply chain. The purpose of this paper is to quantitatively assess the impact of dynamic risk propagation within and between integrated firms in global fresh produce supply chains.
Design/methodology/approach
A risk propagation ontology-based Bayesian network (BN) model was developed to measure dynamic SCR propagation. The proposed model was applied to a two-tier Australia-China table grape supply chain (ACTGSC) featured with an upstream Australian integrated grower and exporter and a downstream Chinese integrated importer and online retailer.
Findings
An ontology-based BN can be generated to accurately represent the risk domain of interest using the knowledge and inference capabilities inherent in a risk propagation ontology. In addition, the analyses revealed that supply discontinuity, product inconsistency and/or delivery delay originating in the upstream firm can propagate to increase the downstream firm’s customer value risk and business performance risk.
Research limitations/implications
The work was conducted in an Australian-China table grape supply chain, so results are only product chain-specific in nature. Additionally, only two state values were considered for all nodes in the model, and finally, while the proposed methodology does provide a large-scale risk network map, it may not be appropriate for a large supply chain network as it only follows the process flow of a single supply chain.
Practical implications
This study supports the backward-looking traceability of risk root causes through the ACTGSC and the forward-looking prediction of risk propagation to key risk performance measures.
Social implications
The methodology used in this paper provides an evidence-based decision-making capability as part of a system-wide risk management approach and fosters collaborative SCR management, which can yield numerous societal benefits.
Originality/value
The proposed methodology addresses the challenges in using a knowledge-based approach to develop a BN model, particularly with a large-scale model and integrates risk and performance for a holistic risk propagation assessment. The combination of modelling approaches to address the issue is unique.}
}
@article{HIPPOLYTE2018210,
title = {Ontology-driven development of web services to support district energy applications},
journal = {Automation in Construction},
volume = {86},
pages = {210-225},
year = {2018},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2017.10.004},
url = {https://www.sciencedirect.com/science/article/pii/S0926580517308907},
author = {J.-L. Hippolyte and Y. Rezgui and H. Li and B. Jayan and S. Howell},
keywords = {Ontology design, Domain engineering, Software development, Intelligent web services, Semantic web},
abstract = {Current urban and district energy management systems lack a common semantic referential for effectively interrelating intelligent sensing, data models and energy models with visualization, analysis and decision support tools. This paper describes the structure, as well as the rationale that led to this structure, of an ontology that captures the real-world concepts of a district energy system, such as a district heating and cooling system. This ontology (called ee-district ontology) is intended to support knowledge provision that can play the role of an intermediate layer between high-level energy management software applications and local monitoring and control software components. In order to achieve that goal, the authors propose to encapsulate queries to the ontology in a scalable web service, which will facilitate the development of interfaces for third-party applications. Considering the size of the ee-district ontology once populated with data from a specific district case study, this could prove to be a repetitive and time-consuming task for the software developer. This paper therefore assesses the feasibility of ontology-driven automation of web service development that is to be a core element in the deployment of heterogeneous district-wide energy management software.}
}
@article{ZHONG201917,
title = {A scientometric analysis and critical review of construction related ontology research},
journal = {Automation in Construction},
volume = {101},
pages = {17-31},
year = {2019},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2018.12.013},
url = {https://www.sciencedirect.com/science/article/pii/S0926580518305648},
author = {Botao Zhong and Haitao Wu and Heng Li and Samad Sepasgozar and Hanbin Luo and Ling He},
keywords = {Ontology, Research trends, Scientometrics, CiteSpace, Construction industry},
abstract = {There is a wide range of literature on adopting ontology to solve construction problems, but no review of existing studies has systematically analyzed and visualized the trends in ontology research. This study reviews ontology research mainly published in the Scopus database from 2007 to 2017 with the combination of scientometric analysis and critical review. Scientometric analysis (e.g. co-author, co-word, co-citation, and clusters) objectively visualized the research status quo while a critical review was used to identify the research themes and challenges of ontology research in the construction industry. The results identified a large network of co-authors in this field to understand collaboration relationships. Over half the papers (53%) were published by the following three countries: the United States, the United Kingdom, and Canada. The top co-occurring keywords were “project management” at which ontology facilitates knowledge management and information retrieval. When the time factor was taken into consideration, keywords naturally evolved from “project management”, and “knowledge management” to “building information modeling”, and “compliance control” with the successful adoption of information techniques in the construction industry. Four research themes were identified with the combination of cluster analysis and critical review: “Domain ontology”, “Industry foundation classes”, “Automated compliance checking”, and “Building information modeling”. This review provides an in-depth understanding of existing ontology research and indicates the emerging trends in this research domain.}
}
@article{TURCHET2020100548,
title = {The Internet of Musical Things Ontology},
journal = {Journal of Web Semantics},
volume = {60},
pages = {100548},
year = {2020},
issn = {1570-8268},
doi = {https://doi.org/10.1016/j.websem.2020.100548},
url = {https://www.sciencedirect.com/science/article/pii/S1570826820300019},
author = {Luca Turchet and Francesco Antoniazzi and Fabio Viola and Fausto Giunchiglia and György Fazekas},
keywords = {Internet of Musical Things, Smart musical instruments, Semantic audio},
abstract = {The Internet of Musical Things (IoMusT) is an emerging research area consisting of the extension of the Internet of Things paradigm to the music domain. Interoperability represents a central issue within this domain, where heterogeneous objects dedicated to the production and/or reception of musical content (Musical Things) are envisioned to communicate between each other. This paper proposes an ontology for the representation of the knowledge related to IoMusT ecosystems to facilitate interoperability between Musical Things. There was no previous comprehensive data model for the IoMusT domain, however the new ontology relates to existing ontologies, including the SOSA Ontology for the representation of sensors and actuators and the Music Ontology focusing on the production and consumption of music. This paper documents the design of the ontology and its evaluation with respect to specific requirements gathered from an extensive literature review, which was based on scenarios involving IoMusT stakeholders, such as performers and audience members. The IoMusT Ontology can be accessed at: https://w3id.org/iomust#.}
}
@article{BUREK2019784,
title = {A pattern-based approach to a cell tracking ontology.},
journal = {Procedia Computer Science},
volume = {159},
pages = {784-793},
year = {2019},
note = {Knowledge-Based and Intelligent Information & Engineering Systems: Proceedings of the 23rd International Conference KES2019},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2019.09.237},
url = {https://www.sciencedirect.com/science/article/pii/S1877050919314243},
author = {Patryk Burek and Nico Scherf and Heinrich Herre},
keywords = {Semantic-Based Systems, Knowledge Representation, Management, Semantic annotation of images, videos, Ontologies},
abstract = {Time-lapse microscopy has thoroughly transformed our understanding of biological motion and developmental dynamics from single cells to entire organisms. The increasing amount of cell tracking data demands the creation of tools to make extracted data searchable and interoperable between experiment and data types. In order to address that problem, the current paper reports on the progress in building the Cell Tracking Ontology (CTO): An ontology framework for describing, querying and integrating data from complementary experimental techniques in the domain of cell tracking experiments. CTO is based on a basic knowledge structure: the cellular genealogy serving as a backbone model to integrate specific biological ontologies into tracking data. As a first step we integrate the Phenotype and Trait Ontology (PATO) as one of the most relevant ontologies to annotate cell tracking experiments. The CTO requires both the integration of data on various levels of generality as well as the proper structuring of collected information. Therefore, in order to provide a sound foundation of the ontology, we have built on the rich body of work on top-level ontologies and established three generic ontology design patterns addressing three modeling challenges for properly representing cellular genealogies, i.e. representing entities existing in time, undergoing changes over time and their organization into more complex structures such as situations.}
}
@article{KURFALI2025106243,
title = {Representations of smells: The next frontier for language models?},
journal = {Cognition},
volume = {264},
pages = {106243},
year = {2025},
issn = {0010-0277},
doi = {https://doi.org/10.1016/j.cognition.2025.106243},
url = {https://www.sciencedirect.com/science/article/pii/S0010027725001830},
author = {Murathan Kurfalı and Pawel Herman and Stephen Pierzchajlo and Jonas Olofsson and Thomas Hörberg},
keywords = {Large language models, Olfaction, Human perception, Chemical senses, Human perception modeling},
abstract = {Whereas human cognition develops through perceptually driven interactions with the environment, language models (LMs) are “disembodied learners” which might limit their usefulness as model systems. We evaluate the ability of LMs to recover sensory information from natural language, addressing a significant gap in cognitive science research literature. Our investigation is carried out through the sense of smell — olfaction — because it is severely underrepresented in natural language and thus poses a unique challenge for linguistic and cognitive modeling. By systematically evaluating the ability of three generations of LMs, including static word embedding models (Word2Vec, FastText), encoder-based models (BERT), and the decoder-based large LMs (LLMs; GPT-4o, Llama 3.1 among others), under nearly 200 training configurations, we investigate their proficiency in acquiring information to approximate human odor perception from textual data. As benchmarks for the performance of the LMs, we use three diverse experimental odor datasets including odor similarity ratings, imagined similarities of odor pairings from word labels, and odor-to-label ratings. The results reveal the possibility for LMs to accurately represent olfactory information, and describe the conditions under which this possibility is realized. Static, simpler models perform best in capturing odor-perceptual similarities under certain training configurations, while GPT-4o excels in simulating olfactory-semantic relationships, as suggested by its superior performance on datasets where the collected odor similarities are derived from word-based assessments. Our findings show that natural language encodes latent information regarding human olfactory information that is retrievable through text-based LMs to varying degrees. Our research shows promise for LMs to be useful tools in investigating the long debated relation between symbolic representations and perceptual experience in cognitive science.}
}
@article{DING2025112663,
title = {Large language models for cyber resilience: A comprehensive review, challenges, and future perspectives},
journal = {Applied Soft Computing},
volume = {170},
pages = {112663},
year = {2025},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2024.112663},
url = {https://www.sciencedirect.com/science/article/pii/S1568494624014376},
author = {Weiping Ding and Mohamed Abdel-Basset and Ahmed M. Ali and Nour Moustafa},
keywords = {Large Language Model, Cyber Resilience, Cyber Security, Data Privacy and Protection, Network and Endpoint Security},
abstract = {Interconnect cyber system is used by various users and organizations worldwide to perform different activities. These activities are combined with digital information and systems around the organizations to obtain higher accuracy and performance. However, these combinations of activities have faced cyber threats and attacks by single or multiple attackers. So, protecting and saving users' and organizations' sensitive data is a big challenge. So, the cyber resilience concept refers to the ability to prepare, absorb, recover, and adapt against cyberattacks and threats. It is used to mitigate cyberattacks and risks by the ability of the system to recover from threats. Artificial intelligence models enhance cyber resilience using machine learning and deep learning models. One of the most common components of artificial intelligence is large language models (LLM). It is used to understand language from text data and extract features to predict future words or missing in text datasets. LLM can enhance cyber resilience by providing various benefits for users and organizations. We divide the cyber resilience strategies into five parts. We review the LLM in each part, including security posture, data privacy and protection, security awareness, network security, and security automation. The fundamentals of LLMs are introduced as pre-trained models, transformers, encoders, and decoders. Then, we review the challenges of LLM in cyber resilience and cyber defense methods to overcome these challenges. We applied the LLM into three case studies including two for email spam text classifications and one for cyber threat detection. We obtained higher accuracy including 96.67 %, 90.70 %, and 89.94 % from three case studies respectively. Then we compared our LLM with other traditional machine learning models. The results show the LLM has higher accuracy, precision, recall, and f1 score compared with other models. Finally, the future directions of LLM in cyber resilience are provided.}
}
@article{ALSAYED2020143,
title = {CloudFNF: An ontology structure for functional and non-functional features of cloud services},
journal = {Journal of Parallel and Distributed Computing},
volume = {141},
pages = {143-173},
year = {2020},
issn = {0743-7315},
doi = {https://doi.org/10.1016/j.jpdc.2020.03.019},
url = {https://www.sciencedirect.com/science/article/pii/S0743731519300437},
author = {Mustafa M. Al-Sayed and Hesham A. Hassan and Fatma A. Omara},
keywords = {Cloud computing, Cloud ontology, Cloud taxonomy, QoS, Cloud service recommendation},
abstract = {Recently, cloud computing becomes one of the main orientations of many researchers and companies in the IT area. Therefore, a huge number of cloud services have been developed. Because of the diversity and heterogeneity in providing these services, it is urgently needed to develop a unified cloud ontology. Such ontology can classify these services appropriately and participate as a mapping layer to present such services in a unified description format. Although many studies have been conducted to build cloud ontologies, they have adopted the cloud service layers-based structure. On the other hand, the existing cloud services may involve functionalities from different layers due to the continual increase in the complexity of customer demands. Unfortunately, there are no clear relations to organize the interventions among these layers. Therefore, such services may be difficult to be classified into a specific cloud service layer. Additionally, the layers-based structure of ontologies represents an obstacle to address important issues, such as cloud service recommendation. Despite there are few cloud service functionality-based cloud ontologies, they suffer from many overlaps, lack of semantic relations, or poor granularity of concepts. Also, all the existing cloud ontologies (i.e., layers-based and functionality-based) lack important criteria, such as completeness, consistency, conciseness, clarity, preciseness, and granularity. In this paper, a comprehensive cloud ontology called CloudFNF has been proposed to overcome such drawbacks. According to the structure of the proposed ontology, cloud services are classified as functionality-based instead of layers-based. Also, non-functional features of cloud services (i.e., configuration and QoS features) are considered to enable services of the same functionalities to be ranked efficiently. Based on our previously suggested cloud ontology evaluation framework, our proposed cloud ontology has been evaluated compared to the most related cloud ontologies. The evaluation results show that the proposed CloudFNF ontology outperforms the other ontologies.}
}
@article{NGUYEN2022,
title = {Toward Human Digital Twins for Cybersecurity Simulations on the Metaverse: Ontological and Network Science Approach},
journal = {JMIRx Med},
volume = {3},
number = {2},
year = {2022},
issn = {2563-6316},
doi = {https://doi.org/10.2196/33502},
url = {https://www.sciencedirect.com/science/article/pii/S2563631622000383},
author = {Tam N Nguyen},
keywords = {human behavior modeling, cognitive twins, human digital twins, cybersecurity, cognitive systems, digital twins, Metaverse, artificial intelligence},
abstract = {Background
Cyber defense is reactive and slow. On average, the time-to-remedy is hundreds of times larger than the time-to-compromise. In response, Human Digital Twins (HDTs) offer the capability of running massive simulations across multiple domains on the Metaverse. Simulated results may predict adversaries' behaviors and tactics, leading to more proactive cyber defense strategies. However, current HDTs’ cognitive architectures are underdeveloped for such use.
Objective
This paper aims to make a case for extending the current digital cognitive architectures as the first step toward more robust HDTs that are suitable for realistic Metaverse cybersecurity simulations.
Methods
This study formally documented 108 psychology constructs and thousands of related paths based on 20 time-tested psychology theories, all of which were packaged as Cybonto—a novel ontology. Then, this study applied 20 network science centrality algorithms in ranking the Cybonto psychology constructs by their influences.
Results
Out of 108 psychology constructs, the top 10 are Behavior, Arousal, Goals, Perception, Self-efficacy, Circumstances, Evaluating, Behavior-Controllability, Knowledge, and Intentional Modality. In this list, only Behaviors, Goals, Perception, Evaluating, and Knowledge are parts of existing digital cognitive architectures. Notably, some of the constructs are not explicitly implemented. Early usability tests demonstrate that Cybonto can also be useful for immediate uses such as manual analysis of hackers’ behaviors and automatic analysis of behavioral cybersecurity knowledge texts.
Conclusions
The results call for specific extensions of current digital cognitive architectures such as explicitly implementing more refined structures of Long-term Memory and Perception, placing a stronger focus on noncognitive yet influential constructs such as Arousal, and creating new capabilities for simulating, reasoning about, and selecting circumstances.}
}
@article{CAO2019177,
title = {Towards a Core Ontology for Condition Monitoring},
journal = {Procedia Manufacturing},
volume = {28},
pages = {177-182},
year = {2019},
note = {7th International conference on Changeable, Agile, Reconfigurable and Virtual Production (CARV2018)},
issn = {2351-9789},
doi = {https://doi.org/10.1016/j.promfg.2018.12.029},
url = {https://www.sciencedirect.com/science/article/pii/S2351978918313714},
author = {Qiushi Cao and Cecilia Zanni-Merk and Christoph Reich},
keywords = {condition monitoring, state of the system or machine, ontology engineering, core ontology, conceptual model},
abstract = {Condition monitoring is performed to identify the functioning state of a machine or a mechanical system. It is an important task by which the machine or mechanical system deterioration tendency and the location of a failure can be detected. In recent years, ontologies have shown promising results to enhance knowledge sharing in condition monitoring tasks, while offering a logically defined and controlled vocabulary of domain entities. Motivated by the growing demand for unification and formal representation of useful concepts in condition monitoring, in this paper we present CM-core, an ontology of core condition monitoring entities. It incorporates several ISO standards as sources and also extracts general concepts from a series of domain ontologies. The ontology contains taxonomies of core condition monitoring concepts such as system, function, behavior, structure, state, failure and fault, with their interrelationships. The CM-core ontology has a broader domain coverage than the existing ontologies, and its generality ensures further specification into more specific domain ontologies.}
}
@article{TAO20181040,
title = {Multi-layer cloud architectural model and ontology-based security service framework for IoT-based smart homes},
journal = {Future Generation Computer Systems},
volume = {78},
pages = {1040-1051},
year = {2018},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2016.11.011},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X16305775},
author = {Ming Tao and Jinglong Zuo and Zhusong Liu and Aniello Castiglione and Francesco Palmieri},
keywords = {Smart home, Heterogeneity, IoT, Cloud, Ontology, Security},
abstract = {The Smart Home concept, associated with the pervasiveness of network coverage and embedded computing technologies is assuming an ever-growing significance for people living in the highly developed areas. However, the heterogeneity of devices, services, communication protocols, standards and data formats involved in most of the available solutions developed by different vendors, is adversely affecting its widespread application. In this paper, promoted by several promising opportunities provided by the advances in Internet of Things (IoT) and Cloud Computing technologies for facing these challenges, a novel multi-layer cloud architectural model is developed to enable effective and seamless interactions/interoperations on heterogeneous devices/services provided by different vendors in IoT-based smart home. In addition, to better solve the heterogeneity issues in the presented layered cloud platform, ontology has been used as a promising way to address data representation, knowledge, and application heterogeneity, and an ontology-based security service framework is designed for supporting security and privacy preservation in the process of interactions/interoperations. Challenges and directions for future work on smart home management have been also discussed at the end of this paper.}
}
@article{KOOHIHABIBIDEHKORDI2025,
title = {Improving Large Language Models’ Summarization Accuracy by Adding Highlights to Discharge Notes: Comparative Evaluation},
journal = {JMIR Medical Informatics},
volume = {13},
year = {2025},
issn = {2291-9694},
doi = {https://doi.org/10.2196/66476},
url = {https://www.sciencedirect.com/science/article/pii/S2291969425001395},
author = {Mahshad {Koohi Habibi Dehkordi} and Yehoshua Perl and Fadi P Deek and Zhe He and Vipina K Keloth and Hao Liu and Gai Elhanan and Andrew J Einstein},
keywords = {electronic health record, EHR, EHR summaries, clinical notes summarization, discharge notes summarization, LLM summaries, ChatGPT summaries, highlighted EHR notes, accuracy of summaries, discharge notes, large language model, LLM, ChatGPT, artificial intelligence, AI},
abstract = {Background
The American Medical Association recommends that electronic health record (EHR) notes, often dense and written in nuanced language, be made readable for patients and laypeople, a practice we refer to as the simplification of discharge notes. Our approach to achieving the simplification of discharge notes involves a process of incremental simplification steps to achieve the ideal note. In this paper, we present the first step of this process. Large language models (LLMs) have demonstrated considerable success in text summarization. Such LLM summaries represent the content of EHR notes in an easier-to-read language. However, LLM summaries can also introduce inaccuracies.
Objective
This study aims to test the hypothesis that summaries generated by LLMs from highlighted discharge notes will achieve increased accuracy compared to those generated from the original notes. For this purpose, we aim to prove a hypothesis that summaries generated by LLMs of discharge notes in which detailed information is highlighted are likely to be more accurate than summaries of the original notes.
Methods
To test our hypothesis, we randomly sampled 15 discharge notes from the MIMIC III database and highlighted their detailed information using an interface terminology we previously developed with machine learning. This interface terminology was curated to encompass detailed information from the discharge notes. The highlighted discharge notes distinguished detailed information, specifically the concepts present in the aforementioned interface terminology, by applying a blue background. To calibrate the LLMs’ summaries for our simplification goal, we chose GPT-4o and used prompt engineering to ensure high-quality prompts and address issues of output inconsistency and prompt sensitivity. We provided both highlighted and unhighlighted versions of each EHR note along with their corresponding prompts to GPT-4o. Each generated summary was manually evaluated to assess its quality using the following evaluation metrics: completeness, correctness, and structural integrity.
Results
We used the study sample of 15 discharge notes. On average, summaries from highlighted notes (H-summaries) achieved 96% completeness, 8% higher than the summaries from unhighlighted notes (U-summaries). H-summaries had higher completeness in 13 notes, and U-summaries had higher or equal completeness in 2 notes, resulting in P=.01, which implied statistical significance. Moreover, H-summaries demonstrated better correctness than U-summaries, with fewer instances of erroneous information (2 vs 3 errors, respectively). The number of improper headers was smaller for H-summaries for 11 notes and U-summaries for 4 notes (P=.03; implying statistical significance). Moreover, we identified 8 instances of misplaced information in the U-summaries and only 2 in the H-summaries. We showed that our findings supported the hypothesis that summarizing highlighted discharge notes improves the accuracy of the summaries.
Conclusions
Feeding LLMs with highlighted discharge notes, combined with prompt engineering, results in higher-quality summaries in terms of correctness, completeness, and structural integrity compared to unhighlighted discharge notes.}
}
@article{SOBRAL2020113260,
title = {An Ontology-based approach to Knowledge-assisted Integration and Visualization of Urban Mobility Data},
journal = {Expert Systems with Applications},
volume = {150},
pages = {113260},
year = {2020},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2020.113260},
url = {https://www.sciencedirect.com/science/article/pii/S0957417420300853},
author = {Thiago Sobral and Teresa Galvão and José Borges},
keywords = {Data integration, Data visualization, Urban mobility, Semantic web, ontology},
abstract = {This paper proposes an ontology-based framework to support integration and visualization of data from Intelligent Transportation Systems. These activities may be technically demanding for transportation stakeholders, due to technical and human factors, and may hinder the use of visualization tools in practice. The existing ontologies do not provide the necessary semantics for integration of spatio-temporal data from such systems. Moreover, a formal representation of the components of visualization techniques and expert knowledge can leverage the development of visualization tools that facilitate data analysis. The proposed Visualization-oriented Urban Mobility Ontology (VUMO) provides a semantic foundation to knowledge-assisted visualization tools (KVTs). VUMO contains three facets that interrelate the characteristics of spatio-temporal mobility data, visualization techniques and expert knowledge. A built-in rule set leverages semantic technologies standards to infer which visualization techniques are compatible with analytical tasks, and to discover implicit relationships within integrated data. The annotation of expert knowledge encodes qualitative and quantitative feedback from domain experts that can be exploited by recommendation methods to automate part of the visualization workflow. Data from the city of Porto, Portugal were used to demonstrate practical applications of the ontology for each facet. As a foundational domain ontology, VUMO can be extended to meet the distinctiveness of a KVT.}
}
@article{MANI2022,
title = {An Improved Structural-Based Ontology Matching Approach Using Similarity Spreading},
journal = {International Journal on Semantic Web and Information Systems},
volume = {18},
number = {1},
year = {2022},
issn = {1552-6283},
doi = {https://doi.org/10.4018/IJSWIS.300825},
url = {https://www.sciencedirect.com/science/article/pii/S1552628322000163},
author = {Sengodan Mani and Samukutty Annadurai},
keywords = {Coefficient Similarity Propagation, Graph Matching, Graph Similarity, Ontology Alignment, Ontology Mapping, Semantic Web, Similarity Flooding, Similarity Matching},
abstract = {ABSTRACT
An increasing number of ontologies demand the interoperability between them in order to gain accurate information. The ontology heterogeneity also makes the interoperability process even more difficult. The existing ontology matching systems are mainly focusing on subject derivatives of the concern domain. Since ontologies are represented as data models in a structured format, in this paper, a new modified model of similarity spreading for ontology mapping is proposed. In this approach, the mapping mainly involves with node clustering based on edge affinity, and then the graph matching is achieved by applying coefficient similarity propagation. This process is carried out by iterative manner, and at the end, the similarity score is calculated for iteration. This model is evaluated in terms of precision, recall, and f-measure parameters, and it is found that it outperforms similar systems.}
}
@article{ORELLANA2019268,
title = {The Ontology of Systems Engineering: Towards a Computational Digital Engineering Semantic Framework},
journal = {Procedia Computer Science},
volume = {153},
pages = {268-276},
year = {2019},
note = {17th Annual Conference on Systems Engineering Research (CSER)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2019.05.079},
url = {https://www.sciencedirect.com/science/article/pii/S1877050919307380},
author = {Douglas Orellana and William Mandrick},
keywords = {Systems Engineering, Ontology, Digital Engineering, Model Based Systems Engineering, MBSE, Digital Thread, Systems Modeling, Knowledge Management, Basic Formal Ontology, Information Content Entity},
abstract = {The goal of implementing an enterprise digital engineering strategy is to improve data sharing throughout system conceptualization, development, manufacturing, operations, sustainment and their supporting organizations. Data sharing is a critical element of interoperability of models and other digital artifacts supporting the systems engineering process. Achieving interoperability within systems engineering requires eliminating differences of syntax and semantics to take advantage of automation, augmentation, and artificial intelligence capabilities that will increase process efficiency and artifact quality. This paper describes the development of a process-centric Systems Engineering (SE) reference ontology, based upon ISO/IEC/IEEE 15288 Systems and Software Engineering – Life Cycle Processes [1]. The proposed SE reference ontology extends from the Basic Formal Ontology (BFO), which is a very small top-level ontology (TLO) designed specifically to support the integration of more specific ontologies that extend from it [2]. A reference ontology is intended to provide a comprehensive representation of the entities in a given domain encapsulating the terminological content of established knowledge. Unlike other systems ontologies, which focus on the target systems, this reference ontology is focused on the systems engineering process, providing context and purpose for the digital artifacts being built and linking the content of artifacts together into one lexicon.}
}
@article{BUREK20211021,
title = {Overview of GFO 2.0 Functions: An ontology module for representing teleological knowledge},
journal = {Procedia Computer Science},
volume = {192},
pages = {1021-1030},
year = {2021},
note = {Knowledge-Based and Intelligent Information & Engineering Systems: Proceedings of the 25th International Conference KES2021},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2021.08.105},
url = {https://www.sciencedirect.com/science/article/pii/S1877050921015933},
author = {Patryk Burek and Frank Loebe and Heinrich Herre},
keywords = {Ontology, Knowledge Representation, Functional Modeling},
abstract = {Teleological knowledge and functional representation are present in numerous scientific and engineering disciplines and are key aspects addressed by a broad spectrum of design and modeling frameworks. The current paper summarizes the results obtained in the area of functional modeling achieved under the umbrella of the second release of the General Formal Ontology (GFO 2.0), which is a modular top-level ontological framework actively developed by the Onto-Med Research Group. This paper presents and discusses the Function Module of GFO 2.0, which serves three objectives. (1) It supports the representation of teleological components, let it be a function or a goal-oriented process, by a blueprint of structured specifications. (2) It provides a classification of relationships enabling the construction of functional decomposition models. (3) The module enables the description of the elements of a domain in functional terms by means of a family of function ascription constructs, which handle the modeling of not only function-to-object assignments, but also of malfunctions.}
}
@article{NING2019101,
title = {A novel ontology consistent with acknowledged standards in smart homes},
journal = {Computer Networks},
volume = {148},
pages = {101-107},
year = {2019},
issn = {1389-1286},
doi = {https://doi.org/10.1016/j.comnet.2018.11.004},
url = {https://www.sciencedirect.com/science/article/pii/S1389128618311964},
author = {Huansheng Ning and Feifei Shi and Tao Zhu and Qingjuan Li and Liming Chen},
keywords = {Semantic, Ontology, Standards, Smart homes, Internet of Things},
abstract = {With the development of Internet of Things, the Smart Home equipped with various sensors and devices has become a hot area attracting global attention and concern. In order to get a better understanding of ambient environments, adding semantics to sensor data plays a significant role. Researchers are attempting to build semantic models in order to satisfy their own requirements, which leads to little reusability between different models. This paper aims to provide a novel ontology which follows publicly acknowledged standards for achieving sensor data semantization in smart homes, including modeling sensors, context and activities with semantics. For keeping consistent with current accepted standards, the proposed ontology is based on the Semantic Sensor Network Ontology. In addition, we enrich the ontologies by incorporating spatiotemporal information and user profiles. The ontology is designed using Protégé and a use case is demonstrated to show the great potentiality in daily activity recognition in smart homes.}
}
@article{AKRAM2025102607,
title = {AquaChat: An LLM-guided ROV framework for adaptive inspection of aquaculture net pens},
journal = {Aquacultural Engineering},
volume = {111},
pages = {102607},
year = {2025},
issn = {0144-8609},
doi = {https://doi.org/10.1016/j.aquaeng.2025.102607},
url = {https://www.sciencedirect.com/science/article/pii/S0144860925000962},
author = {Waseem Akram and Muhayy Ud Din and Abdelhaleem Saad and Irfan Hussain},
keywords = {Aquaculture, Marine robots, ROVs, Autonomous navigation, Large language models},
abstract = {Inspection of aquaculture net pens is essential for maintaining the structural integrity, biosecurity, and operational efficiency of fish farming systems. Traditional inspection approaches rely on pre-programmed missions or manual control, offering limited adaptability to dynamic underwater conditions and user-specific demands. In this study, we propose AquaChat, a novel Remotely Operated Vehicle (ROV) framework that integrates Large Language Models (LLMs) for instruction-driven, intelligent and adaptive net pen inspection. The system features a multi-layered architecture: (1) a high-level planning layer that interprets natural language user commands using an LLM to generate symbolic task plans; (2) a mid-level task manager that translates plans into ROV control sequences; and (3) a low-level motion control layer that executes navigation and inspection tasks with precision. Real-time feedback and event-triggered replanning enhance robustness in challenging aquaculture environments. The framework is validated through experiments in both simulated and controlled aquatic environments representative of aquaculture net pens. Results demonstrate improved task flexibility, inspection accuracy, and operational efficiency. AquaChat illustrates the potential of integrating language-based AI with marine robotics to enable intelligent, user-interactive inspection systems for sustainable aquaculture operations.}
}
@article{SHA2025,
title = {Leveraging Retrieval-Augmented Large Language Models for Dietary Recommendations With Traditional Chinese Medicine’s Medicine Food Homology: Algorithm Development and Validation},
journal = {JMIR Medical Informatics},
volume = {13},
year = {2025},
issn = {2291-9694},
doi = {https://doi.org/10.2196/75279},
url = {https://www.sciencedirect.com/science/article/pii/S2291969425001711},
author = {Hangyu Sha and Fan Gong and Bo Liu and Runfeng Liu and Haofen Wang and Tianxing Wu},
keywords = {Traditional Chinese Medicine, medicine food homology, large language model, retrieval-augmented generation, uncertain knowledge graph, dietary recommendation},
abstract = {Background
Traditional Chinese Medicine (TCM) emphasizes the concept of medicine food homology (MFH), which integrates dietary therapy into health care. However, the practical application of MFH principles relies heavily on expert knowledge and manual interpretation, posing challenges for automating MFH-based dietary recommendations. Although large language models (LLMs) have shown potential in health care decision support, their performance in specialized domains such as TCM is often hindered by hallucinations and a lack of domain knowledge. The integration of uncertain knowledge graphs (UKGs) with LLMs via retrieval-augmented generation (RAG) offers a promising solution to overcome these limitations by enabling a structured and faithful representation of MFH principles while enhancing LLMs’ ability to understand the inherent uncertainty and heterogeneity of TCM knowledge. Consequently, it holds potential to improve the reliability and accuracy of MFH-based dietary recommendations generated by LLMs.
Objective
This study aimed to introduce Yaoshi-RAG, a framework that leverages UKGs to enhance LLMs' capabilities in generating accurate and personalized MFH-based dietary recommendations.
Methods
The proposed framework began by constructing a comprehensive MFH knowledge graph (KG) through LLM-driven open information extraction, which extracted structured knowledge from multiple sources. To address the incompleteness and uncertainty within the MFH KG, UKG reasoning was used to measure the confidence of existing triples and to complete missing triples. When processing user queries, query entities were identified and linked to the MFH KG, enabling retrieval of relevant reasoning paths. These reasoning paths were then ranked based on triple confidence scores and entity importance. Finally, the most informative reasoning paths were encoded into prompts using prompt engineering, enabling the LLM to generate personalized dietary recommendations that aligned with both individual health needs and MFH principles. The effectiveness of Yaoshi-RAG was evaluated through both automated metrics and human evaluation.
Results
The constructed MFH KG comprised 24,984 entities, 22 relations, and 29,292 triples. Extensive experiments demonstrate the superiority of Yaoshi-RAG in different evaluation metrics. Integrating the MFH KG significantly improved the performance of LLMs, yielding an average increase of 14.5% in Hits@1 and 8.7% in F1-score, respectively. Among the evaluated LLMs, DeepSeek-R1 achieved the best performance, with 84.2% in Hits@1 and 71.5% in F1-score, respectively. Human evaluation further validated these results, confirming that Yaoshi-RAG consistently outperformed baseline models across all assessed quality dimensions.
Conclusions
This study shows Yaoshi-RAG, a new framework that enhances LLMs’ capabilities in generating MFH-based dietary recommendations through the knowledge retrieved from a UKG. By constructing a comprehensive TCM knowledge representation, our framework effectively extracts and uses MFH principles. Experimental results demonstrate the effectiveness of our framework in synthesizing traditional wisdom with advanced language models, facilitating personalized dietary recommendations that address individual health conditions while providing evidence-based explanations.}
}
@article{LASTRADIAZ2019104432,
title = {Reproducibility dataset for a large experimental survey on word embeddings and ontology-based methods for word similarity},
journal = {Data in Brief},
volume = {26},
pages = {104432},
year = {2019},
issn = {2352-3409},
doi = {https://doi.org/10.1016/j.dib.2019.104432},
url = {https://www.sciencedirect.com/science/article/pii/S2352340919307875},
author = {Juan J. Lastra-Díaz and Josu Goikoetxea and Mohamed Ali {Hadj Taieb} and Ana García-Serrano and Mohamed Ben Aouicha and Eneko Agirre},
keywords = {Ontology-based semantic similarity measures, Word embedding models, Information content models, WordNet, Experimental survey, HESML, Reprozip},
abstract = {This data article introduces a reproducibility dataset with the aim of allowing the exact replication of all experiments, results and data tables introduced in our companion paper (Lastra-Díaz et al., 2019), which introduces the largest experimental survey on ontology-based semantic similarity methods and Word Embeddings (WE) for word similarity reported in the literature. The implementation of all our experiments, as well as the gathering of all raw data derived from them, was based on the software implementation and evaluation of all methods in HESML library (Lastra-Díaz et al., 2017), and their subsequent recording with Reprozip (Chirigati et al., 2016). Raw data is made up by a collection of data files gathering the raw word-similarity values returned by each method for each word pair evaluated in any benchmark. Raw data files were processed by running a R-language script with the aim of computing all evaluation metrics reported in (Lastra-Díaz et al., 2019), such as Pearson and Spearman correlation, harmonic score and statistical significance p-values, as well as to generate automatically all data tables shown in our companion paper. Our dataset provides all input data files, resources and complementary software tools to reproduce from scratch all our experimental data, statistical analysis and reported data. Finally, our reproducibility dataset provides a self-contained experimentation platform which allows to run new word similarity benchmarks by setting up new experiments including other unconsidered methods or word similarity benchmarks.}
}
@article{MANDORLI2020101088,
title = {From form features to semantic features in existing MCAD: An ontological approach},
journal = {Advanced Engineering Informatics},
volume = {44},
pages = {101088},
year = {2020},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2020.101088},
url = {https://www.sciencedirect.com/science/article/pii/S1474034620300574},
author = {Ferruccio Mandorli and Stefano Borgo and Paulina Wiejak},
keywords = {Feature, MCAD, Ontological analysis, Semantic representation, Design rational, Functional feature},
abstract = {Today’s product development processes rely on Mechanical Computer-Aided Design (MCAD) systems that implement a geometric-centered perspective in design. The development of long discussed feature-based MCAD has not yet led to systems that truly support semantic and functional representation of features, which hampers also the use of these models for functional reasoning. This paper investigates the present feature-based MCAD limitations. It illustrates, through simple examples, how to use ontological analysis and feature re-classification to introduce software extensions in existing MCAD that achieve a newer level of semantic representation of features, and enhance the cognitive understanding of the final model. The proposal also shows how to automatically validate these features from the functional viewpoint.}
}
@article{OSMAN202138,
title = {Ontology Integration: Approaches and Challenging Issues},
journal = {Information Fusion},
volume = {71},
pages = {38-63},
year = {2021},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2021.01.007},
url = {https://www.sciencedirect.com/science/article/pii/S1566253521000130},
author = {Inès Osman and Sadok {Ben Yahia} and Gayo Diallo},
keywords = {Ontology integration, Ontology merging, Ontology matching, Alignment repair, Coherence principle, Conservativity principle},
abstract = {In recent years, the decentralized development of ontologies has led to the generation of multiple ontologies of overlapping knowledge. This heterogeneity problem can be tackled by integrating existing ontologies to build a single coherent one. Ontology integration has been investigated during the last two decades, but it is still a challenging task. In this article, we provide a comprehensive survey of all ontology integration aspects. We discuss related notions and scrutinize existing techniques and literature approaches. We also detail the role of ontology matching in the ontology integration process. Indeed, the ontology community has adopted the splitting of the ontology integration problem into matching, merging and repairing sub-tasks, where matching is a necessary preceding step for merging, and repairing can be included in the matching process or performed separately. Ontology matching and merging systems have become quite proficient, however the trickiest part lies in the repairing step. We also focus on the case of a holistic integration of multiple heterogeneous ontologies, which needs further exploration. Finally, we investigate challenges, open issues, and future directions of the ontology integration and matching areas.}
}
@article{KHADIR2021100339,
title = {Ontology learning: Grand tour and challenges},
journal = {Computer Science Review},
volume = {39},
pages = {100339},
year = {2021},
issn = {1574-0137},
doi = {https://doi.org/10.1016/j.cosrev.2020.100339},
url = {https://www.sciencedirect.com/science/article/pii/S1574013720304391},
author = {Ahlem Chérifa Khadir and Hassina Aliane and Ahmed Guessoum},
keywords = {Ontologies, Ontology learning, Linguistic and statistical approaches, Machine learning, Deep learning},
abstract = {Ontologies are at the core of the semantic web. As knowledge bases, they are very useful resources for many artificial intelligence applications. Ontology learning, as a research area, proposes techniques to automate several tasks of the ontology construction process to simplify the tedious work of manually building ontologies. In this paper we present the state of the art of this field. Different classes of approaches are covered (linguistic, statistical, and machine learning), including some recent ones (deep-learning-based approaches). In addition, some relevant solutions (frameworks), which offer strategies and built-in methods for ontology learning, are presented. A descriptive summary is made to point out the capabilities of the different contributions based on criteria that have to do with the produced ontology components and the degree of automation. We also highlight the challenge of evaluating ontologies to make them reliable, since it is not a trivial task in this field; it actually represents a research area on its own. Finally, we identify some unresolved issues and open questions.}
}
@article{OUALI2019774,
title = {MBOPS: Towards A Multidimensional Business Ontology based-Premodeling System},
journal = {Procedia Computer Science},
volume = {159},
pages = {774-783},
year = {2019},
note = {Knowledge-Based and Intelligent Information & Engineering Systems: Proceedings of the 23rd International Conference KES2019},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2019.09.236},
url = {https://www.sciencedirect.com/science/article/pii/S1877050919314231},
author = {Sonya Ouali and Mohamed Mhiri and Faiez Gargouri},
keywords = {Framework, Business ontology, Knowledge Dimension, Business rules, Semantic relationships, Protege, Breast cancer},
abstract = {In this paper, we propose a Multidimensional Business Ontology based-Premodeling System (MBOPS). Its knowledge-oriented core ensures an easier use and share for unambiguous business process modeling. Furthermore, the proposed (MBOPS) guarantees a good understanding level for the modelled-domain familiar designers as well as the modelled-domain non-familiar designers thanks to a Multidimensional business ontology. In order to evaluate the proposed (MBPS) and demonstrate its effectiveness, we choice the breast cancer treatment protocols as an applicative field.}
}
@article{LEWIS2021623,
title = {Elinor's Ostrom's ‘realist orientation’: An investigation of the ontological commitments of her analysis of the possibility of self-governance},
journal = {Journal of Economic Behavior & Organization},
volume = {189},
pages = {623-636},
year = {2021},
issn = {0167-2681},
doi = {https://doi.org/10.1016/j.jebo.2021.07.021},
url = {https://www.sciencedirect.com/science/article/pii/S0167268121003097},
author = {Paul Lewis},
keywords = {Elinor Ostrom, Self-governance, Social ontology, Realism, Complexity},
abstract = {This paper examines an important, but hitherto relatively neglected, aspect of the work of Nobel Laureate Elinor Ostrom, namely her ontological commitments (that is, her views about the nature of social reality and their implications). While they are rarely described as such, Ostrom's writings contain discussions of many important ontological issues (including the openness of the social world, the nature of human agency, the configural nature of social rules; the relationship between social structure and human agency; and the complexity of the social world, viewed as a nested hierarchy of emergent systems). This article is the first to draw together systematically Ostrom's reflections about ontological issues and to identify what Ostrom saw as their implications for the appropriate methods for analysing and explaining the possibility of self-governance. In doing so, the paper also contributes to the growing literature on ontology and the history of economic thought.}
}
@article{IATRELLIS2018,
title = {A Review on Software Project Management Ontologies},
journal = {International Journal of Information Technology Project Management},
volume = {9},
number = {4},
year = {2018},
issn = {1938-0232},
doi = {https://doi.org/10.4018/IJITPM.2018100104},
url = {https://www.sciencedirect.com/science/article/pii/S1938023218000044},
author = {Omiros Iatrellis and Panos Fitsilis},
keywords = {Ontologies, Project Management, Software Project Management},
abstract = {This article aims to provide the reader with a comprehensive background for understanding current knowledge and research works on ontologies for software project management (SPM). It constitutes a systematic literature review behind key objectives of the potential adoption of ontologies in PM. Ontology development and engineering could facilitate substantially the software development process and improve knowledge management, software and artifacts reusability, internal consistency within project management processes of various phases of software life cycle. The authors examined the literature focusing on software project management ontologies and analyzed the findings of these published papers and categorized them accordingly. They used qualitative methods to evaluate and interpret findings of the collected studies. The literature review, among others, has highlighted lack of standardization in terminology and concepts, lack of systematic domain modeling and use of ontologies mainly in prototype ontology systems that address rather limited aspects of software project management processes.}
}
@article{WU2025122539,
title = {Optimizing prompt efficacy in large language models for fake news detection via evolutionary algorithm-based feature selection},
journal = {Information Sciences},
volume = {720},
pages = {122539},
year = {2025},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2025.122539},
url = {https://www.sciencedirect.com/science/article/pii/S0020025525006723},
author = {Lei Wu and Xinran Yang and Xiaochuan Shi and Chao Ma},
keywords = {Artificial intelligence, LLM, Evolutionary learning, Fake news detection, Explainable AI},
abstract = {This article introduces an optimization framework based on a large language model, designed for detecting fake news and using an evolutionary algorithm to optimize prompt design. Our methodology systematically incorporates a broad array of features, including linguistic style, text complexity, and psychological factors, to facilitate a comprehensive and transparent analysis of news content, thereby enabling more explainable detection outcomes. Initially, the framework augments the training phase with a preprocessing component that utilizes robust estimation techniques to refine data evaluation and enhance outcome quality. Subsequently, an evolutionary algorithm refines the original feature set, significantly enhancing the accuracy of fake news detection models. In the final stage, this optimized subset of features is integrated with a large language model, facilitating precise authenticity assessments of news articles. Empirical evaluations on benchmark datasets confirm that our approach outperforms existing models by filtering out suitable feature sets that generate effective prompts.}
}
@article{LAKZAEI2021280,
title = {Ontology learning from relational databases},
journal = {Information Sciences},
volume = {577},
pages = {280-297},
year = {2021},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2021.06.074},
url = {https://www.sciencedirect.com/science/article/pii/S0020025521006654},
author = {Batool Lakzaei and Mehrnoush Shamsfard},
keywords = {Ontology, Ontology learning, Relational database, OWL, RDB},
abstract = {An ontology is a formal, explicit specification of a shared conceptualization. Ontologies are used in many fields, such as software engineering, information extraction, semantic search, knowledge management, recommender systems, etcetera. Since manual ontology building is a very costly, time-consuming, and error-prone task, automating the process of ontology building, or in other words, learning ontology from existing resources, is a good option. Nowadays, a large amount of data on the web is stored in relational databases, but databases cannot be used directly in the semantic web. Hence, in this paper, we have proposed a new approach to automatically creating an OWL ontology from a relational database. We have defined a set of rules to analyze all database components and convert them to corresponding ontology components. The core contribution of our work is the set of rules which can analyze and extract ontology elements from stored procedures, user-defined functions, views, multiple inheritance, the specific representation of single inheritance, common attributes, and the constraints on tables and their columns. The proposed approach has been compared with existing approaches using three frameworks.}
}
@article{LIU2021101191,
title = {Photovoltaic generation power prediction research based on high quality context ontology and gated recurrent neural network},
journal = {Sustainable Energy Technologies and Assessments},
volume = {45},
pages = {101191},
year = {2021},
issn = {2213-1388},
doi = {https://doi.org/10.1016/j.seta.2021.101191},
url = {https://www.sciencedirect.com/science/article/pii/S2213138821002010},
author = {Hongfei Liu and Qian Gao and Pengcheng Ma},
keywords = {Photovoltaic power systems, Forecasting, Context information, Ontology, Recurrent neural network},
abstract = {This paper proposes a new method to improve the prediction accuracy of photovoltaic power generation. By improving the accuracy of photovoltaic generation prediction, the grid can reduce the restriction on photovoltaic power and thus improve the return on investment of the photovoltaic industry. This paper innovatively obtains high-quality contextual information through high-quality ontology and improves the accuracy of final prediction from the perspective of improving the quality of input data. By building a high quality context ontology model, the context is classified according to its different sources. Then the quality of the classified context is scored. Finally, the high quality context is selected to replace the low quality context. Simulation results show that this method can represent the context quality more flexibly while increasing the ontology in a small scale. Besides, this paper also used the gated recurrent neural network as the prediction model. Experimental results show that the prediction accuracy of photovoltaic power generation based on high quality context ontology and Gated Recursive Neural Network is about 5% higher than that of Long Short Term Memory model. When the number of hidden layers of the prediction network is set to 4 and the number of iterations is set to 100, the accuracy is the highest and the mean square error is 0.0037. In conclusion, this method can effectively improve the prediction accuracy and has a high application prospect in the industry.}
}
@article{ZHOU201849,
title = {An ontology framework towards decentralized information management for eco-industrial parks},
journal = {Computers & Chemical Engineering},
volume = {118},
pages = {49-63},
year = {2018},
issn = {0098-1354},
doi = {https://doi.org/10.1016/j.compchemeng.2018.07.010},
url = {https://www.sciencedirect.com/science/article/pii/S0098135418300929},
author = {Li Zhou and Chuan Zhang and Iftekhar A. Karimi and Markus Kraft},
keywords = {Eco-industrial park, Knowledge base, Ontology, Process modelling},
abstract = {In this paper, we develop a skeletal ontology for eco-industrial parks. A top-down conceptual framework including five operating levels (unit operations, processes, plants, industrial resource networks and eco-industrial parks) is employed to guide the design of the ontology structure. The detailed ontological representation of each level is realized through adapting and extending OntoCAPE, an ontology of the chemical engineering domain. Based on the proposed ontology, a framework for distributed information management is proposed for eco-industrial parks. As an example, this ontology is used to create a knowledge base for Jurong Island, an industrial park in Singapore. Its potential uses in supporting process modeling and optimization and facilitating industrial symbiosis are also discussed in the paper.}
}
@article{RODRIGUES201912,
title = {Legal ontologies over time: A systematic mapping study},
journal = {Expert Systems with Applications},
volume = {130},
pages = {12-30},
year = {2019},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2019.04.009},
url = {https://www.sciencedirect.com/science/article/pii/S0957417419302398},
author = {Cleyton Mário de Oliveira Rodrigues and Frederico Luiz Gonçalves de Freitas and Emanoel Francisco Spósito Barreiros and Ryan Ribeiro de Azevedo and Adauto Trigueiro de Almeida Filho},
keywords = {Legal ontology, Systematic mapping study, Legal expert system, Legal theory, Semantic web},
abstract = {Over the last 30 years, AI & Law has provided breakthroughs in studies involving case-based reasoning, rule-based reasoning, information retrieval and, most recently, conceptual models for knowledge representation and reasoning, known as Legal Ontologies. Ontologies have been widely used by legal practitioners, scholars, and lay people in a variety of situations, such as simulating legal actions, semantic search and indexing, and to keep up-to-date with the continual change of laws and regulations. Given the high number of legal ontologies produced, the need to summarize this research realm through a well-defined methodological procedure is urgent need. This study presents the results of a systematic mapping of the literature, aiming at categorizing legal ontologies along certain dimensions, such as purpose, level of generality, underlying legal theories, among other aspects. The reasons to carry out a systematic mapping are twofold: in addition to explaining the maturation of the area over recent decades, it helps to avoid the old problem of reinventing the wheel. Through organizing and classifying what has already been produced, it is possible to realize that the development of legal ontologies can rise to the level of reusability where prefabricated models might be coupled with new and more complex ontologies for practical law.}
}
@article{HUSSIEN2025125914,
title = {RAG-based explainable prediction of road users behaviors for automated driving using knowledge graphs and large language models},
journal = {Expert Systems with Applications},
volume = {265},
pages = {125914},
year = {2025},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2024.125914},
url = {https://www.sciencedirect.com/science/article/pii/S0957417424027817},
author = {Mohamed Manzour Hussien and Angie Nataly Melo and Augusto Luis Ballardini and Carlota Salinas Maldonado and Rubén Izquierdo and Miguel Ángel Sotelo},
keywords = {Road users’ behaviors, Explainable predictions, Pedestrian crossing actions, Lane change maneuvers, Autonomous driving},
abstract = {The prediction of road user behaviors in the context of autonomous driving has attracted considerable attention from the scientific community in recent years. Most works focus on predicting behaviors based on kinematic information alone, a simplification of reality since road users are humans, and as such they are highly influenced by their surrounding context. In addition, a large plethora of research works rely on powerful Deep Learning techniques, which exhibit high-performance metrics in prediction tasks but may lack the ability to fully understand and exploit the contextual semantic information contained in the road scene, not to mention their inability to provide explainable predictions that can be understood by humans. In this work, we propose an explainable road users’ behavior prediction system that integrates the reasoning abilities of Knowledge Graphs (KG) and the expressiveness capabilities of Large Language Models (LLM) by using Retrieval Augmented Generation (RAG) techniques. For that purpose, Knowledge Graph Embeddings (KGE) and Bayesian inference are combined to allow the deployment of a fully inductive reasoning system that enables the issuing of predictions that rely on legacy information contained in the graph, as well as on current evidence gathered in real-time by onboard sensors. Two use cases have been implemented following the proposed approach: 1) Prediction of pedestrians’ crossing actions; and 2) Prediction of lane change maneuvers. In both cases, the performance attained exceeds the current state-of-the-art in terms of anticipation and F1 score, showing a promising avenue for future research in this field.}
}
@article{LIU202097,
title = {An ontology constructing technology oriented on massive social security policy documents},
journal = {Cognitive Systems Research},
volume = {60},
pages = {97-105},
year = {2020},
issn = {1389-0417},
doi = {https://doi.org/10.1016/j.cogsys.2019.09.005},
url = {https://www.sciencedirect.com/science/article/pii/S1389041719304711},
author = {Gang Liu and Hanwen Zhang},
keywords = {Ontology expansion, Text fragment extraction, Semi-automatic construction},
abstract = {To solve the problem brought from enormous policy documents and complex management in the social security domain, the article uses ontology as the way of representing and storing knowledge. The article first constructs the framework of ontology through manual work so that it can ensure the relative accuracy of the ontology structure. Then it achieves the automatic ontology expansion based on the inclusion relationship of property sets or operational object sets. The article uses a semi-automatic method that extracts hierarchical concepts and non-hierarchical concepts from domain thesaurus by using the method combining statistics with rules to construct the ontology. Besides constructing the ontology, the article proposes the concepts of concept phrase vector model and high frequency characteristics phrase vector model. The experiment result indicates that ontology semi-automatic construction process can help experts to construct the social security ontology effectively oriented on massive policy documents and is a considerable reference for the construction of ontology in other domains.}
}
@article{RAJPATHAK2020103338,
title = {An integrated framework for automatic ontology learning from unstructured repair text data for effective fault detection and isolation in automotive domain},
journal = {Computers in Industry},
volume = {123},
pages = {103338},
year = {2020},
issn = {0166-3615},
doi = {https://doi.org/10.1016/j.compind.2020.103338},
url = {https://www.sciencedirect.com/science/article/pii/S0166361520305728},
author = {Dnyanesh Rajpathak and Yiming Xu and Ian Gibbs},
keywords = {Ontology learning, Automotive, Supervised machine learning, Decision support},
abstract = {A real-life hierarchical classification system is developed to automatically extract a domain ontology from repair data collected during the warranty period of an original equipment manufacturer (OEM), e.g. automotive. Given the complex nature of products, failures may occur impacting consumers and to limit their adverse effect it is critical to react through effective fault detection and isolation. The key fault signals, such as failed parts, their associated symptoms, and the repair actions are latent in repair data. The overwhelming size of real-life data makes it impossible to read and curate a domain ontology manually in a reasonable time. In our work, a hierarchical classification system firstly classifies key phrases into technical and non-technical classes. Secondly, the technical phrases are classified into part, symptom, or action classes. Our system is deployed as a prototype and its performance is validated using real-life data. The system achieved the average F1 score of 0.82 and the new ontology is used in fault detection and isolation in seven different fault models.}
}
@article{PAN2024111224,
title = {A semantic augmented approach to FEMA P-58 based dynamic regional seismic loss estimation application},
journal = {Journal of Building Engineering},
volume = {98},
pages = {111224},
year = {2024},
issn = {2352-7102},
doi = {https://doi.org/10.1016/j.jobe.2024.111224},
url = {https://www.sciencedirect.com/science/article/pii/S235271022402792X},
author = {Zeyu Pan and Jianyong Shi and Liu Jiang},
keywords = {Dynamic regional seismic loss estimation, Mainshock-aftershock sequence, FEMA P-58, Semantic web, Large language model},
abstract = {Regional seismic loss estimation (RSLE) is a crucial process in both immediate post-earthquake emergency response and long-term reconstruction endeavors. Over the years, significant progress has been made in RSLE: sensing approaches such as field investigation and remote sensing offers a comprehensive overview necessary for real-time disaster response, while simulation techniques such as the methodology proposed in Federal Emergency Management Agency (FEMA) P-58 series provide insights into the mechanism of disaster development and its potential long-term impacts on urban assets. Nonetheless, challenges persist in the realm of practical RSLE applications. Firstly, a dynamic understanding of a disaster event and its influence is deemed important for effective emergency responses while challenging to achieve in current approaches. Secondly, stakeholders with varying roles, including administrators, rescue teams and ordinary citizens have distinct information requirements for RSLE. Thirdly, the complexity of seismic loss estimation, involving diverse data sources such as building information models, performance models, fragility data and sensor observations, poses interoperability issue. To tackle these issues, this article introduces a dynamic, multi-granularity, ontological representation scheme tailored for RSLE decision-supporting systems. This scheme operates across various scales, from individual building components to broader regional scales by synergistically employing FEMA P-58 guidelines and Semantic Web technologies. Upon the corresponding semantics, a question-and-answer agent powered by large language model is further developed to facilitate interaction requirements within the RSLE process via FEMA P-58 pipeline. The practical efficacy of this approach is validated through a prototype deployed under a real earthquake event, demonstrating its value in real-world scenarios.}
}
@article{CHEN2024104804,
title = {Enhancing emergency decision-making with knowledge graphs and large language models},
journal = {International Journal of Disaster Risk Reduction},
volume = {113},
pages = {104804},
year = {2024},
issn = {2212-4209},
doi = {https://doi.org/10.1016/j.ijdrr.2024.104804},
url = {https://www.sciencedirect.com/science/article/pii/S2212420924005661},
author = {Minze Chen and Zhenxiang Tao and Weitong Tang and Tingxin Qin and Rui Yang and Chunli Zhu},
keywords = {Emergency decision support, Large language model, Knowledge graph, Decision support system},
abstract = {Emergency management urgently requires comprehensive knowledge while having a high possibility to go beyond individuals’ cognitive scope. Therefore, artificial intelligence(AI) supported decision-making under that circumstance is of vital importance. Recent emerging large language models (LLM) provide a new direction for enhancing targeted machine intelligence. However, the utilization of LLM directly would inevitably introduce unreliable output for its inherent issue of hallucination and poor reasoning skills. In this work, we develop a system called Enhancing Emergency decision-making with Knowledge Graph and LLM (E-KELL), which provides evidence-based decision-making in various emergency stages. The study constructs a structured emergency knowledge graph and guides LLMs to reason over it via a prompt chain. In real-world evaluations, E-KELL demonstrates significant improvement over baseline models in various emergency response scenarios, as rated by emergency commanders and firefighters. This work introduces a novel approach to applying LLMs to enhance emergency decision-making.}
}
@article{SAYEED20252930,
title = {Engineering Text-to-text Generation Language Models as Discriminative Classifiers for Accurate Answer Detection},
journal = {Procedia Computer Science},
volume = {258},
pages = {2930-2947},
year = {2025},
note = {International Conference on Machine Learning and Data Engineering},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2025.04.553},
url = {https://www.sciencedirect.com/science/article/pii/S1877050925016576},
author = {Mohammed Azam Sayeed and Deepa Gupta and Vani Kanjirangat},
keywords = {Education, Semi automized peer grading, Smaller scale language models, Text-to-text generation, Discriminative classifier},
abstract = {Online peer grading is gaining wide adoption to manage open-ended questions involving students in the grading process. Evaluators could save a lot of grading time by using semi-automating peer grading to identify the most accurate/highest-scored and use them as anonymous graders promoting competency and fairness, thereby empowering students in the grading process. Leveraging language models (LMs) of smaller-scale large language models (LLMs), medium language models (MLMs) and small language models (SLMs) can offer greener, affordable AI (Artificial Intelligence) inferences for domain adaption suitable for limited educational settings. This study utilizes a university-sourced dataset compiled from advanced university courses like AI and ML (Machine learning), which are typically scarce in volume as seen in most education settings. We explore the efficacy of domain-adapting text-to-text generation language models (such as mT5, blenderbot, Flan-T5, byT5, and switch-base collections) with greener parameters to behave as discriminative classifier models via full finetuning, without changing the base model architecture having all base parameters as trainable, unlike partial base model finetuning with adapters. Our research establishes the flan-T5-large model to achieve about 83% for both accuracy and f1 score. These experimental models are analyzed from various perspectives such as topics, questions, and marking schemes on the standard evaluation metrics.}
}
@article{ARSLAN2025116276,
title = {Monitoring indoor environmental conditions in office buildings using a sustainable Agentic RAG-LLM system},
journal = {Energy and Buildings},
volume = {347},
pages = {116276},
year = {2025},
issn = {0378-7788},
doi = {https://doi.org/10.1016/j.enbuild.2025.116276},
url = {https://www.sciencedirect.com/science/article/pii/S0378778825010060},
author = {Muhammad Arslan and Saba Munawar and Lamine Mahdjoubi and Patrick Manu},
keywords = {Thermal Comfort Monitoring (TCM), Building Information Modeling (BIM), Sensors, Large Language Models (LLMs), Sustainable Building Management},
abstract = {Indoor Environmental Conditions (IEC) play a crucial role in determining the health, productivity, and overall building performance of employees, as well as their energy consumption. Key parameters, such as temperature and humidity, are not only vital for thermal comfort but also offer opportunities to enhance energy efficiency when effectively monitored and managed. Accurate Thermal Comfort Monitoring (TCM) remains challenging to achieve because it requires the integration of diverse data sources and intelligent analysis, particularly in light of evolving global energy and sustainability standards. Although Building Information Modeling (BIM) is increasingly being adopted to manage complex building data, its integration with real-time sensor inputs remains vastly underutilized. Existing thermal monitoring systems are often development-intensive, require significant domain expertise, lack Natural Language (NL) interaction capabilities, and are not inherently adaptable, necessitating frequent technical upgrades. These limitations give rise to pressing concerns about long-term scalability, usability, and sustainability. To address these limitations, this study introduces ThermalComfortBot, an integrated Information System (IS) powered by Generative Artificial Intelligence (GenAI). ThermalComfortBot utilizes open-source technologies, including Large Language Models (LLMs) and Agentic Retrieval-Augmented Generation (RAG), to enhance thermal comfort and support energy optimization in buildings. The system integrates Building Information Modeling (BIM), sensor data, and external datasets to generate actionable insights, delivered through both textual explanations and graphical visualizations. This system utilizes flexible and adjustable LLMs that are guided by principles of sustainability, thereby making them cost-efficient, scalable, and practical for a diverse range of organizational environments. In a real-world case study, ThermalComfortBot outperforms traditional RAG-LLM, achieving 94% accuracy, 92% precision, and 89% recall, enhancing comfort and efficiency.}
}
@article{ZHUANG2020100544,
title = {SOBA: Semi-automated Ontology Builder for Aspect-based sentiment analysis},
journal = {Journal of Web Semantics},
volume = {60},
pages = {100544},
year = {2020},
issn = {1570-8268},
doi = {https://doi.org/10.1016/j.websem.2019.100544},
url = {https://www.sciencedirect.com/science/article/pii/S1570826819300770},
author = {Lisa Zhuang and Kim Schouten and Flavius Frasincar},
keywords = {Domain ontology, Aspect-based sentiment analysis, Ontology learning, Reviews, Semi-automatization},
abstract = {This research explores the possibility of improving knowledge-driven aspect-based sentiment analysis (ABSA) in terms of efficiency and effectiveness. This is done by implementing a Semi-automated Ontology Builder for Aspect-based sentiment analysis (SOBA). Semi-automatization of the ontology building process could produce more extensive ontologies, whilst shortening the building time. Furthermore, SOBA aims to improve the effectiveness of its ontologies in ABSA by attaching to concepts the semantics provided by a semantic lexicon. To evaluate the performance of SOBA, ontologies are created using the ontology builder for the restaurant and laptop domains. The use of these ontologies is then compared with the use of manually constructed ontologies in a state-of-the-art knowledge-driven ABSA model, the Two-Stage Hybrid Model (TSHM). The results show that it is difficult for a machine to beat the quality of a human made ontology, as SOBA does not improve the effectiveness of TSHM, achieving similar results. Including the semantics provided by a semantic lexicon in general increases the performance of TSHM, albeit not significantly. However, SOBA decreases by 50% or more the human time needed to build ontologies, so that it is recommended to use SOBA for knowledge-driven ABSA frameworks, as it leads to greater efficiency.}
}
@article{KHARLAMOV201930,
title = {An ontology-mediated analytics-aware approach to support monitoring and diagnostics of static and streaming data},
journal = {Journal of Web Semantics},
volume = {56},
pages = {30-55},
year = {2019},
issn = {1570-8268},
doi = {https://doi.org/10.1016/j.websem.2019.01.001},
url = {https://www.sciencedirect.com/science/article/pii/S1570826819300010},
author = {Evgeny Kharlamov and Yannis Kotidis and Theofilos Mailis and Christian Neuenstadt and Charalampos Nikolaou and Özgür Özçep and Christoforos Svingos and Dmitriy Zheleznyakov and Yannis Ioannidis and Steffen Lamparter and Ralf Möller and Arild Waaler},
keywords = {Ontology Based Data Access, Data integration, IoT, Streaming data, Static data, Optimisations, Siemens},
abstract = {Streaming analytics that requires integration and aggregation of heterogeneous and distributed streaming and static data is a typical task in many industrial scenarios including the case of industrial IoT where several pieces of industrial equipment such as turbines in Siemens are integrated into an IoT. The OBDA approach has a great potential to facilitate such tasks; however, it has a number of limitations in dealing with analytics that restrict its use in important industrial applications. We argue that a way to overcome those limitations is to extend OBDA to become analytics, source, and cost aware. In this work we propose such an extension. In particular, we propose an ontology, mapping, and query language for OBDA, where aggregate and other analytical functions are first class citizens. Moreover, we develop query optimisation techniques that allow to efficiently process analytical tasks over static and streaming data. We implement our approach in a system and evaluate our system with Siemens turbine data.}
}
@article{YANG2019148,
title = {Ontology-based systems engineering: A state-of-the-art review},
journal = {Computers in Industry},
volume = {111},
pages = {148-171},
year = {2019},
issn = {0166-3615},
doi = {https://doi.org/10.1016/j.compind.2019.05.003},
url = {https://www.sciencedirect.com/science/article/pii/S0166361518307887},
author = {Lan Yang and Kathryn Cormican and Ming Yu},
keywords = {systems engineering, ontology, state of the art, systematic literature review},
abstract = {In recent years ontology-based systems engineering has grown significantly. Its raison d’etre is to use ontologies to improve the systems engineering body of knowledge. Specifically, ontologies act as an enabler of good knowledge management as they focus on establishing well-defined domain concepts in terms of terminologies, definitions, and relationships. In addition, the use of formal semantics is essential for explicit, sharable, and reusable knowledge representation. However, little research exists that evaluates the impact and real benefits of ontologies for systems engineering. A thorough review of the state of the art of ontology-based systems engineering will contribute to the future development of the discipline. Therefore, the primary objective of this paper is to draw a clear roadmap of how ontologies support systems engineering and to determine what extent they have been applied in this domain. This review contributes to a holistic examination of the primary studies relevant to the topic of ontology-based systems engineering, spanning nearly two decades. The findings provide an integrated and comprehensive understanding of and shed new light on (1) the systems engineering knowledge areas supported by ontologies; (2) the contribution that ontologies make to systems engineering problems; (3) the existing ontologies that are created to support systems engineering; and (4) the techniques adopted from an ontology engineering perspective. It assesses the influence of ontologies in systems engineering knowledge areas, expounding and highlighting the effects of ontologies. All in all, it presents a comprehensive summary of the state of the art of ontology-based systems engineering, as well as illuminating a roadmap for future directions.}
}
@incollection{DEAZEVEDOJACYNTHO2021195,
title = {Chapter 14 - Ontology-based decision-making},
editor = {Sarika Jain and Vishal Jain and Valentina Emilia Balas},
booktitle = {Web Semantics},
publisher = {Academic Press},
pages = {195-209},
year = {2021},
isbn = {978-0-12-822468-7},
doi = {https://doi.org/10.1016/B978-0-12-822468-7.00016-X},
url = {https://www.sciencedirect.com/science/article/pii/B978012822468700016X},
author = {Mark Douglas {de Azevedo Jacyntho} and Matheus {D. Morais}},
keywords = {Problem solving, decision-making, decision support, ontology, Web Ontology Language (OWL)},
abstract = {A knowledge-based system is a kind of decision support system with specialized problem-solving expertise. The expertise consists of knowledge about a particular domain, understanding symptoms, problems, and solutions within that domain. These systems can essentially suggest or recommend actions. We can say that a person–machine team processes knowledge to accomplish a task. In this context, ontologies emerge as a powerful tool to formally representing such a domain of knowledge, allowing the machine to comprehend it and therefore assist us. This chapter presents the benefits of using ontologies in decision-making and how to achieve them. An actual problem-solving Web Ontology Language ontology, namely Issue-Procedure Ontology, and a corresponding fictitious, but with real-world challenges, health care case study are introduced.}
}
@article{GU2025101094,
title = {Construction of Q&A methods based on knowledge graphs and large language models-improving the accuracy of landscape pest and disease Q&A},
journal = {Smart Agricultural Technology},
volume = {12},
pages = {101094},
year = {2025},
issn = {2772-3755},
doi = {https://doi.org/10.1016/j.atech.2025.101094},
url = {https://www.sciencedirect.com/science/article/pii/S2772375525003272},
author = {Zhixin Gu and Ting Long and Shuairan Wang and Xiaowei Shang and Weizheng Shen and Xiaoli Wei and Kaihong Xu},
keywords = {Knowledge graph, Large language model, ERNIE, Garden diseases and pests},
abstract = {With the development of urban landscaping, the problem of garden diseases and pests is becoming increasingly severe. Large language models have garnered significant attention for their ability to understand user intent and provide answers. The introduction of knowledge graphs has provided a high quality knowledge base for large language models. This study combines knowledge graphs (KGs), large language models (LLMs) and other technologies to design an intelligent question-answering (Q&A) model for garden pests and diseases. The main work carried out is as follows: Build a knowledge graph for garden diseases and pests by collecting high-quality data through web crawling and literature analysis. Identify key entities and relationships to construct a conceptual pattern layer. Applying the ERNIE-BiLSTM-CRF model to extract knowledge from unstructured data. Through experiments, it is found that the accuracy, recall and F1 value of the knowledge extraction model proposed in this study are all more than 92%, superior to other models. Propose a Q&A method that integrates the garden pest and disease KG with the ERNIE-Bot-turbo model. By vectorizing the knowledge and using similarity matching, the most relevant data is retrieved, combined with the question to form prompts, and input into the language model to generate natural language answers. Experiments comparing our method with ERNIE-Bot-turbo and ChatGLM-6B showed that our approach performs well on simple, moderate, and complex problems, avoiding misleading answers for irrelevant questions. It outperforms both models in accuracy, achieving a 90% accuracy rate for simple questions.}
}
@article{GHEISARI20211,
title = {OBPP: An ontology-based framework for privacy-preserving in IoT-based smart city},
journal = {Future Generation Computer Systems},
volume = {123},
pages = {1-13},
year = {2021},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2021.01.028},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X21000388},
author = {Mehdi Gheisari and Hamid Esmaeili Najafabadi and Jafar A. Alzubi and Jiechao Gao and Guojun Wang and Aaqif Afzaal Abbasi and Aniello Castiglione},
keywords = {Privacy-preserving, Internet of Things (IoT), Ontology, Smart city, Penetration rate, Heterogeneity},
abstract = {IoT devices generate data over time, which is going to be shared with other parties to provide high-level services. Smart City is one of its applications which aims to manage cities automatically. Because of the large number of devices, three critical challenges come up: heterogeneity, privacy-preserving of generated data, and providing high-level services. The existing solutions cannot even solve two of the mentioned challenges simultaneously. In this paper, we propose a three-module framework, named “Ontology-Based Privacy-Preserving” (OBPP) to address these issues. The first module includes an ontology, a data storage model, to address the heterogeneity issue while keeping the privacy information of IoT devices. The second one contains semantic reasoning rules to find abnormal patterns while addressing the quality of provided services. The third module provides a privacy rules manager to address the privacy-preserving challenges of IoT devices achieved by dynamically changing privacy behaviors of the devices. Extensive simulations on a synthetic smart city dataset demonstrate the superior performance of our approach compared to the existing solutions while providing affordability and robustness against information leakages. Thus, it can be widely applied to smart cities.}
}
@article{SCHROEREN2021235,
title = {Quantum metaphysical indeterminacy and the ontological foundations of orthodoxy},
journal = {Studies in History and Philosophy of Science Part A},
volume = {90},
pages = {235-246},
year = {2021},
issn = {0039-3681},
doi = {https://doi.org/10.1016/j.shpsa.2021.09.008},
url = {https://www.sciencedirect.com/science/article/pii/S0039368121001424},
author = {David Schroeren},
abstract = {This paper develops quantum state individualism, a fundamental ontology for what is usually known as ‘orthodox quantum mechanics.’ The central import of this ontology is that allows for a systematic evaluation of some of the main conclusions of the recent literature on quantum metaphysical indeterminacy. In particular, quantum state individualism supports the ‘gappy’ version of Jessica Wilson's determinable-based account of metaphysical indeterminacy; it implies that fundamental reality is perfectly precise; and third, it provides a non-disjunctive definition of determinables and thereby shields Wilson's account against the charge that it requires either a departure from classical logic or a revision of the quantum formalism.}
}
@article{FERRANTI2021114578,
title = {Metaheuristics-based ontology meta-matching approaches},
journal = {Expert Systems with Applications},
volume = {173},
pages = {114578},
year = {2021},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2021.114578},
url = {https://www.sciencedirect.com/science/article/pii/S0957417421000191},
author = {Nicolas Ferranti and Stênio Sã {Rosário Furtado Soares} and Jairo Francisco {de Souza}},
keywords = {Ontology meta-matching, Metaheuristic-based ontology matching, Systematic mapping, Evolutionary ontology matching},
abstract = {Ontologies have emerged to establish a well-defined meaning for information, solving problems of heterogeneity in data semantics and facilitating the process of information exchange. However, ontologies have generated a new semantic problem, since using more than one ontology can generate ambiguity in the meaning of a given data. The problem of ontology matching is to search for relationships between entities of distinct ontologies, solving the problem of semantic heterogeneity of the data. The problem is a relevant issue in the area of knowledge representation and several approaches have been proposed to solve it. This work presents a systematic mapping of the main works published in the area with an emphasis on metaheuristics-based meta-matching approaches.}
}
@article{PAL2018985,
title = {Ontology-Based Web Service Architecture for Retail Supply Chain Management},
journal = {Procedia Computer Science},
volume = {130},
pages = {985-990},
year = {2018},
note = {The 9th International Conference on Ambient Systems, Networks and Technologies (ANT 2018) / The 8th International Conference on Sustainable Energy Information Technology (SEIT-2018) / Affiliated Workshops},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2018.04.101},
url = {https://www.sciencedirect.com/science/article/pii/S1877050918304630},
author = {Kamalendu Pal},
keywords = {Retail Supply Chain, Service Oriented Computing, Semantic Web Services, Case-Based Reasoning, Rule-Based Reasoning, Ontology Matchmaking Algorithm},
abstract = {Service-oriented computing (SOC) technologies provide numerous opportunities and value-added service capabilities that global retail business requires to remain competitive in the market. Initiative to semantic web service provision is playing a crucial role to realize the possibility of heterogenous information systems integration in supply chain. The ability to dynamically discover and invoke a web service is an important aspects of semantic web service-based architecture. An essential part of the service discovery process is the ontology-based semantic web service matchmaking algorithm. This paper presents the key features of an improved matchmaking algorithm to calculate the similarity between concepts on ontology for semantic web service. The matchmaking is taking place in the context of OWL-S (Ontology Web Language for Services) based retail sales management. The paper describes the Semantic Web Service Architecture-II (SWSA-II), which uses a hybrid knowledge-based system; and it consists of Structural Case-Based Reasoning (S-CBR), Rule-Based Reasoning (RBR), and an ontological concept similarity assessment algorithm. Finally, a business scenario is used to demonstrate the functionality of the algorithm.}
}
@article{SIEPMANN2025100378,
title = {An automated information extraction model for unstructured discharge letters using large language models and GPT-4},
journal = {Healthcare Analytics},
volume = {7},
pages = {100378},
year = {2025},
issn = {2772-4425},
doi = {https://doi.org/10.1016/j.health.2024.100378},
url = {https://www.sciencedirect.com/science/article/pii/S2772442524000807},
author = {Robert M. Siepmann and Giulia Baldini and Cynthia S. Schmidt and Daniel Truhn and Gustav Anton Müller-Franzes and Amin Dada and Jens Kleesiek and Felix Nensa and René Hosch},
keywords = {Large language models, Automated information extraction, Artificial intelligence, Generative pre-trained transformer (GPT), ChatGPT, Discharge letters},
abstract = {The administrative burden of manually extracting clinical information from discharge letters is a common challenge in healthcare. This study aims to explore the use of Large Language Models (LLMs), specifically Generative Pretrained Transformer 4 (GPT-4) by OpenAI, for automated extraction of diagnoses, medications, and allergies from discharge letters. Data for this study were sourced from two healthcare institutions in Germany, comprising discharge letters for ten patients from each institution. The first experiment is conducted using a standardized prompt for information extraction. However, challenges were encountered, and the prompt was fine-tuned in a second experiment to improve the results. We further tested whether open-source LLMs can achieve similar results. In the first experiment, primary diagnoses were identified with 85% accuracy and secondary diagnoses with 55.8%. Medications and allergies were extracted with 85.9% and 100% accuracy, respectively. The International Classification of Diseases, 10th revision (ICD-10) codes for the identified diagnoses achieved an accuracy of 85% for primary diagnoses and 60.7% for secondary diagnoses. Anatomical Therapeutic Chemical (ATC) codes were identified with an accuracy of 78.8%. On the other hand, open-source LLMs did not provide similar levels of accuracy and could not consistently fill the template. With prompt fine-tuning in the second experiment, the primary diagnoses, secondary diagnoses, and medications could be predicted with 95%, 88.9%, and 92.2% accuracy, respectively. GPT-4 shows excellent potential for automated extraction of crucial diagnostic and medication information from discharge letters, presumably lowering the administrative burden for healthcare professionals and improving patient outcomes.}
}
@article{MING2020103145,
title = {An Ontology for Representing Knowledge of Decision Interactions in Decision-Based Design},
journal = {Computers in Industry},
volume = {114},
pages = {103145},
year = {2020},
issn = {0166-3615},
doi = {https://doi.org/10.1016/j.compind.2019.103145},
url = {https://www.sciencedirect.com/science/article/pii/S0166361519304191},
author = {Zhenjun Ming and Gehendra Sharma and Janet K. Allen and Farrokh Mistree},
keywords = {Decision Interaction, Decision-Based Design, Decision Workflow, Ontology, Knowledge Representation},
abstract = {Design processes for complex engineered systems are inherently complex due to the dependencies among subsystems at the same level and between levels of a partitioned hierarchy. In decision-based design, this results in interactions among sets of design decisions. Representing and capturing the knowledge related to the decision interactions is critical for designing decision-based design processes. Two key challenges in modeling the interactions are: •there are different types of decisions, and•these decisions are made at different levels. To address these challenges, in this paper we identify nine basic interaction patterns among decisions and propose an ontology to define the knowledge associated with these interaction patterns. Key advantages of the ontology include that we can capture both the vertical and horizontal interactions between decisions in a decision-based design process, and we can design flexible, reusable, and executable decision workflows for designing complex systems using the ontology. The utility of the ontology is illustrated via a one[HYPHEN]stage reduction gearbox design example, a hot rod rolling process design example and a composite structure design example.}
}
@article{HOU2025,
title = {Improving Dietary Supplement Information Retrieval: Development of a Retrieval-Augmented Generation System With Large Language Models},
journal = {Journal of Medical Internet Research},
volume = {27},
year = {2025},
issn = {1438-8871},
doi = {https://doi.org/10.2196/67677},
url = {https://www.sciencedirect.com/science/article/pii/S1438887125004030},
author = {Yu Hou and Jeffrey R Bishop and Hongfang Liu and Rui Zhang},
keywords = {dietary supplements, knowledge representation, knowledge graph, retrieval-augmented generation, large language model, user interface},
abstract = {Background
Dietary supplements (DSs) are widely used to improve health and nutrition, but challenges related to misinformation, safety, and efficacy persist due to less stringent regulations compared with pharmaceuticals. Accurate and reliable DS information is critical for both consumers and health care providers to make informed decisions.
Objective
This study aimed to enhance DS-related question answering by integrating an advanced retrieval-augmented generation (RAG) system with the integrated Dietary Supplement Knowledgebase 2.0 (iDISK2.0), a dietary supplement knowledge base, to improve accuracy and reliability.
Methods
We developed iDISK2.0 by integrating updated data from authoritative sources, including the Natural Medicines Comprehensive Database, the Memorial Sloan Kettering Cancer Center database, Dietary Supplement Label Database, and Licensed Natural Health Products Database, and applied advanced data cleaning and standardization techniques to reduce noise. The RAG system combined the retrieval power of a biomedical knowledge graph with the generative capabilities of large language models (LLMs) to address limitations of stand-alone LLMs, such as hallucination. The system retrieves contextually relevant subgraphs from iDISK2.0 based on user queries, enabling accurate and evidence-based responses through a user-friendly interface. We evaluated the system using true-or-false and multiple-choice questions derived from the Memorial Sloan Kettering Cancer Center database and compared its performance with stand-alone LLMs.
Results
iDISK2.0 integrates 174,317 entities across 7 categories, including 8091 dietary supplement ingredients; 163,806 dietary supplement products; 786 diseases; and 625 drugs, along with 6 types of relationships. The RAG system achieved an accuracy of 99% (990/1000) for true-or-false questions on DS effectiveness and 95% (948/100) for multiple-choice questions on DS-drug interactions, substantially outperforming stand-alone LLMs like GPT-4o (OpenAI), which scored 62% (618/1000) and 52% (517/1000) on these respective tasks. The user interface enabled efficient interaction, supporting free-form text input and providing accurate responses. Integration strategies minimized data noise, ensuring access to up-to-date, DS-related information.
Conclusions
By integrating a robust knowledge graph with RAG and LLM technologies, iDISK2.0 addresses the critical limitations of stand-alone LLMs in DS information retrieval. This study highlights the importance of combining structured data with advanced artificial intelligence methods to improve accuracy and reduce misinformation in health care applications. Future work includes extending the framework to broader biomedical domains and improving evaluation with real-world, open-ended queries.}
}
@article{LULA20202425,
title = {An Advanced Analysis of Cloud Computing Concepts Based on the Computer Science Ontology},
journal = {Computers, Materials and Continua},
volume = {66},
number = {3},
pages = {2425-2443},
year = {2020},
issn = {1546-2218},
doi = {https://doi.org/10.32604/cmc.2021.013771},
url = {https://www.sciencedirect.com/science/article/pii/S1546221820000223},
author = {Paweł Lula and Octavian Dospinescu and Daniel Homocianu and Napoleon-Alexandru Sireteanu},
keywords = {Cloud computing scientific literature, cloud related concepts, CSO ontology},
abstract = {Our primary research hypothesis stands on a simple idea: The evolution of top-rated publications on a particular theme depends heavily on the progress and maturity of related topics. And this even when there are no clear relations or some concepts appear to cease to exist and leave place for newer ones starting many years ago. We implemented our model based on Computer Science Ontology (CSO) and analyzed 44 years of publications. Then we derived the most important concepts related to Cloud Computing (CC) from the scientific collection offered by Clarivate Analytics. Our methodology includes data extraction using advanced web crawling techniques, data preparation, statistical data analysis, and graphical representations. We obtained related concepts after aggregating the scores using the Jaccard coefficient and CSO Ontology. Our article reveals the contribution of Cloud Computing topics in research papers in leading scientific journals and the relationships between the field of Cloud Computing and the interdependent subdivisions identified in the broader framework of Computer Science.}
}
@article{ARTALE2021103536,
title = {First-order rewritability of ontology-mediated queries in linear temporal logic},
journal = {Artificial Intelligence},
volume = {299},
pages = {103536},
year = {2021},
issn = {0004-3702},
doi = {https://doi.org/10.1016/j.artint.2021.103536},
url = {https://www.sciencedirect.com/science/article/pii/S0004370221000874},
author = {Alessandro Artale and Roman Kontchakov and Alisa Kovtunova and Vladislav Ryzhikov and Frank Wolter and Michael Zakharyaschev},
keywords = {Linear temporal logic, Description logic, Ontology-based data access, First-order rewritability, Data complexity},
abstract = {We investigate ontology-based data access to temporal data. We consider temporal ontologies given in linear temporal logic LTL interpreted over discrete time (Z,<). Queries are given in LTL or MFO(<), monadic first-order logic with a built-in linear order. Our concern is first-order rewritability of ontology-mediated queries (OMQs) consisting of a temporal ontology and a query. By taking account of the temporal operators used in the ontology and distinguishing between ontologies given in full LTL and its core, Krom and Horn fragments, we identify a hierarchy of OMQs with atomic queries by proving rewritability into either FO(<), first-order logic with the built-in linear order, or FO(<,≡), which extends FO(<) with the standard arithmetic predicates x≡0(modn), for any fixed n>1, or FO(RPR), which extends FO(<) with relational primitive recursion. In terms of circuit complexity, FO(<,≡)- and FO(RPR)-rewritability guarantee OMQ answering in uniform Image 1 and, respectively, Image 2. We obtain similar hierarchies for more expressive types of queries: positive LTL-formulas, monotone MFO(<)- and arbitrary MFO(<)-formulas. Our results are directly applicable if the temporal data to be accessed is one-dimensional; moreover, they lay foundations for investigating ontology-based access using combinations of temporal and description logics over two-dimensional temporal data.}
}
@article{WANG2023107589,
title = {Prediction of submitochondrial proteins localization based on Gene Ontology},
journal = {Computers in Biology and Medicine},
volume = {167},
pages = {107589},
year = {2023},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2023.107589},
url = {https://www.sciencedirect.com/science/article/pii/S0010482523010545},
author = {Jingyu Wang and Haihang Zhou and Yuxiang Wang and Mengdie Xu and Yun Yu and Junjie Wang and Yun Liu},
keywords = {Submitochondrial proteins localization, Gene Ontology, Pre-trained model, Fine-tune, Multi-head attention mechanism},
abstract = {Mitochondria, which are double-membrane bound organelles commonly found in eukaryotic cells, play a fundamental role as sites for cellular energy production. Within the mitochondria, there exist substructures called submitochondria, and specific proteins associated with submitochondria have been implicated in various human diseases. Therefore, comprehending the precise localization of these submitochondrial proteins is of utmost importance. Such knowledge not only aids in unraveling their role in the pathogenesis of diseases but also facilitates the development of therapeutic drugs and diagnostic methods. In this study, we proposed a novel method based on Gene Ontology (GO) to predict the localization of the submitochondrial proteins, called GO-Submito. More specifically, the GO-Submito fine-tuned pre-training Bidirectional Encoder Representations from Transformers models to encode GO annotations into vectors. Subsequently, the Multi-head Attention Mechanism was employed to fuse these encoded vectors of GO annotations, enabling precise localization prediction. Through comprehensive evaluation, our results demonstrated that GO-Submito outperforms existing methods, offering a reliable and efficient tool for precisely localizing submitochondrial proteins.}
}
@article{QORICH2025128405,
title = {Detection of artificial intelligence-generated essays for academic assessment integrity using large language models},
journal = {Expert Systems with Applications},
volume = {291},
pages = {128405},
year = {2025},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2025.128405},
url = {https://www.sciencedirect.com/science/article/pii/S095741742502024X},
author = {Mohammed Qorich and Rajae {El Ouazzani}},
keywords = {Artificial intelligence (AI), AI-Generated essays detection, Automatic optimization, ChatGPT, Education, Large language models (LLMs), Plagiarism detection},
abstract = {Across various fields of human life, the lightning adoption of generative artificial intelligence (AI) tools is driven by their ease of use and ability to produce high-quality outputs, transforming communication and productivity. However, the growing popularity and influence of models such as ChatGPT have raised concerns in education regarding academic integrity, as AI-generated content challenges the authenticity of student work and complicates traditional assessment practices. Existing plagiarism detection tools, such as Turnitin and GPTZero, attempt to identify AI-generated content; however, their reliability remains limited, as most struggle to accurately differentiate between human and AI essays. To address existing tools limitations, we propose a novel detection model leveraging three large language models (LLMs): Generative Pre-trained Transformer 2 (GPT-2), Robustly Optimized BERT Pretraining Approach (RoBERTa), and Bidirectional and Auto-Regressive Transformers (BART). We first fine-tuned each model on two large-scale datasets to evaluate their effectiveness in distinguishing between human and AI-generated essays. To further enhance the performance, we applied both manual and automated hyperparameter optimization techniques, including Random Search, Grid Search, and Bayesian Optimization. Building on these experiments, we developed our BART-CNN model, which incorporates the best-performing BART configuration with an additional convolutional head classifier. Our BART-CNN model achieved impressive Macro F1-scores of 99.78 % and 98.10 % on the Kaggle and Hugging Face datasets, respectively, and demonstrated significant performance gains over baseline methods in cross-domain validation. Our study offers a critical advancement in AI plagiarism detection, helping to uphold academic standards and the assessment quality in an evolving AI landscape.}
}
@article{DE2020813,
title = {Semantic Mapping of Component Framework Interface Ontologies for Interoperability of Vehicle Applications},
journal = {Procedia Computer Science},
volume = {170},
pages = {813-818},
year = {2020},
note = {The 11th International Conference on Ambient Systems, Networks and Technologies (ANT) / The 3rd International Conference on Emerging Data and Industry 4.0 (EDI40) / Affiliated Workshops},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2020.03.151},
url = {https://www.sciencedirect.com/science/article/pii/S1877050920306074},
author = {Sangita De and Michael Niklas and Rooney Brian and Juergen Mottok and Premek Brada},
keywords = {ontology, xml, xsd, rdf, model, mapping, semantic, component, interface},
abstract = {Over the past few years, ontology merging, and ontology semantic alignment has gained significant interest as research topics in automotive application domain for finding solutions to semantic data heterogeneity. To accomplish the complex and novel vehicle service requirements such as autonomous driving, V2X (Vehicle-to-Vehicle communication), etc. the automotive applications involve collaborations of several platform-specific data from heterogeneous enterprises component frameworks and consequently there has been increase in data interoperability issues. At the application component level, data interoperability relies on the semantic alignment or mapping between the various component framework interfaces data models represented as XML schemas (XSD). With the XML schemas being the preferred standard for the interface description exchange between most of the automotive application domain components, however, the data interoperability between the semantically equivalent but structurally different data constructs of multiple heterogeneous XSDs stands as a challenge in the absence of an ontology-based approach. To confront this crucial requirement for data interoperability and to increase in effect the reuse of existing components through their interfaces, we propose an approach to semantically map the various component framework interface data models when expressed as ontology schemas, based on the exploration of semantic synergies. The transformation between XSD and RDF (Resource Description Framework) schema representations and the use of queries over the ontology schemas for semantic mapping are demonstrated including a real-world case study.}
}
@article{LIU2025103460,
title = {Probing a novel machine tool fault reasoning and maintenance service recommendation approach through data-knowledge empowered LLMs integrated with AR-assisted maintenance guidance},
journal = {Advanced Engineering Informatics},
volume = {66},
pages = {103460},
year = {2025},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2025.103460},
url = {https://www.sciencedirect.com/science/article/pii/S1474034625003532},
author = {Changchun Liu and Jiaye Song and Dunbing Tang and Liping Wang and Haihua Zhu and Qixiang Cai},
keywords = {Machine tools, Fault reasoning, Maintenance service recommendation, data-knowledge empowered LLMs, Augmented reality},
abstract = {With the growing complexity and quantity of machine tools, the emergence of various faults threatens manufacturing process stability. Existing methods often fail to effectively utilize knowledge for fault causality reasoning and maintenance service provision, while the absence of intuitive visual guidance results in low maintenance efficiency and potential misoperations. To address this issue, a novel machine tool fault reasoning and maintenance service recommendation approach through data-knowledge empowered LLMs (Large Language Models) integrated with AR (Augmented Reality)-assisted visible guidance. Firstly, a scene graph is established to analyze fault correlations through semantic associations, enabling comprehensive fault-root cause analysis. Based on this, an industrial LLM is constructed by integrating fault-maintenance scene graphs with foundational Llama 3, employing prompt-based fine-tuning and multi-agent collaborative fault detection. On the one hand, multi-agent collaborative fault detection leverages a network of agents working in tandem to enhance fault identification efficiency. On the other hand, the integration of AR-assisted visual guidance facilitates accurate fault localization and provides maintenance personnel with enhanced operational support, significantly improving maintenance efficiency and accuracy. The comparative experimental results indicate that the proposed industrial LLM demonstrates superior capability in modeling complex node relationships and identifying intricate patterns within large-scale graph datasets, enabling precise maintenance service recommendations. Based on this, a significant advancement in predictive maintenance can be offered for complex machine tools by the proposed comprehensive approach.}
}
@article{GORIDKOV2024964,
title = {What's in this LCA Report? A Case Study on Harnessing Large Language Models to Support Designers in Understanding Life Cycle Reports},
journal = {Procedia CIRP},
volume = {122},
pages = {964-969},
year = {2024},
note = {31st CIRP Conference on Life Cycle Engineering},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2024.01.131},
url = {https://www.sciencedirect.com/science/article/pii/S2212827124001756},
author = {Nicole Goridkov and Ye Wang and Kosa Goucher-Lambert},
keywords = {sustainable design, life cycle reports, document understanding, knowledge management, large language models},
abstract = {Life cycle assessment (LCA) is a well-established approach and benchmark for design for sustainability efforts, in which detailed reports are produced that can serve as decision-making guides for developing new products. However, LCA reports are typically dense and technically complex, making it difficult for many engineering design project stakeholders to appropriately leverage the information found within them. Our work seeks to understand and improve the transfer of knowledge from LCA reports during the early stages of the design process, specifically leveraging the natural language capabilities of large language models (LLMs). In this paper, we investigate how four LCA-and sustainability-centric prompting frameworks can extract relevant design knowledge from LCA reports, demonstrated through a case study where an LLM (ChatGPT) is prompted on a provided electric toothbrush LCA report. Key findings illustrate the prompting frameworks can establish high-level summaries and identify life-cycle specific information, but the development of specific and design-focused sub-prompts will allow for richer understanding. We envision designers can use these proposed frameworks to query an LLM to gain context and insights from relevant LCA reports. The proposed techniques serve as a basis for automatic knowledge extraction from life cycle documents, creating accessible information in a user-friendly manner for designers who look to develop life-cycle-informed products.}
}
@incollection{BEDI2021233,
title = {Chapter 17 - Classification of genetic mutations using ontologies from clinical documents and deep learning},
editor = {Sarika Jain and Vishal Jain and Valentina Emilia Balas},
booktitle = {Web Semantics},
publisher = {Academic Press},
pages = {233-250},
year = {2021},
isbn = {978-0-12-822468-7},
doi = {https://doi.org/10.1016/B978-0-12-822468-7.00007-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780128224687000079},
author = {Punam Bedi and  Shivani and Neha Gupta and Priti Jagwani and Veenu Bhasin},
keywords = {Clinical natural language processing, semantic web, ontology, classification, deep learning, electronic health records, cancer, genetic mutation},
abstract = {Health care is an important aspect of human life in which medical data plays an important role. The medical data present in pathology reports, diagnosis, prescription, and clinical articles however is normally available in an unstructured textual format. Such data can be processed using Clinical Natural Language Processing (NLP) to unearth the important information. This information can be represented using ontology, a building block of the semantic web. Clinical NLP and ontology are used in the medical domain for text summarization and knowledge representation. This knowledge can be utilized for disease identification using machine learning and deep learning (DL) techniques. A framework for classifying cancerous genetic mutation reported in electronic health records has been proposed using ontologies and DL. In addition, a case study for the same is presented using clinical NLP, ontologies, and convolution neural network using catalog of somatic mutations in cancer mutation data and Kaggle’s cancer-diagnosis dataset.}
}
@article{WALOSZEK2021786,
title = {Towards Use of OntoClean for Ontology Contextualization},
journal = {Procedia Computer Science},
volume = {192},
pages = {786-795},
year = {2021},
note = {Knowledge-Based and Intelligent Information & Engineering Systems: Proceedings of the 25th International Conference KES2021},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2021.08.081},
url = {https://www.sciencedirect.com/science/article/pii/S1877050921015696},
author = {Wojciech Waloszek},
keywords = {knowledge bases, contexts, reasoning, systematic literature review, interviews},
abstract = {Ontologies are formal systems of concepts used to describe numerous domains of interest. Ontologies are usually very expressive, but it comes at a price of computationally expensive reasoning over them. In our previous work we discussed the possible performance benefits that can be obtained by decomposing an ontology into contexts. While the benefits are appealing, we discovered that, in our case, the main obstacle against using contextual versions of ontologies was the necessity of performing the costly process of their decomposition with the participation of human experts. In this paper we discuss the possibility of using OntoClean method for streamlining and at least partial automation of suggesting a decomposition of an ontology into contexts. We present a hypothesis about how to build a structure of contexts, and verify this hypothesis against several ontologies used in state-of-the-art research. The ontologies have been obtained by us in the process that uses elements of Systematic Literature Review. The final assessment of the method has been performed by human experts, during interviews, and we present the details of their evaluation in the paper.}
}
@article{XU2025126585,
title = {Towards normalized clinical information extraction in Chinese radiology report with large language models},
journal = {Expert Systems with Applications},
volume = {271},
pages = {126585},
year = {2025},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2025.126585},
url = {https://www.sciencedirect.com/science/article/pii/S0957417425002076},
author = {Qinwei Xu and Xingkun Xu and Chenyi Zhou and Zuozhu Liu and Feiyue Huang and Shaoxin Li and Lifeng Zhu and Zhian Bai and Yuchen Xu and Weiguo Hu},
keywords = {Clinical information extraction, Large language models, Instruction tuning, Data-efficient learning, Chinese radiology reports},
abstract = {Radiology reports serve as a fundamental component within electronic medical records. Converting unstructured free-text reports into structured formats holds paramount importance for the management and utilization of radiology reports. In this paper, we propose a novel information extraction paradigm named normalized clinical information extraction (NCIE) for Chinese radiology reports. Specifically, NCIE operates in an end-to-end fashion to extract normalized and structured clinical information without decomposing the information extraction process into multiple intermediate tasks. Motivated by recent progress in Large Language Models (LLMs), we address the NCIE problem based on the instruction tuning of LLMs. The proposed approach, termed Radiological Information End-to-end Extraction with LLM (RIEEL), excels at extracting structural information comprising radiological observations alongside their corresponding anatomical locations and status. To ensure the model in learning the normalized medical concepts correctly, we establish a radiology knowledge base with expert knowledge and further curate a high-quality instruction tuning dataset. Moreover, we incorporate two data-efficient learning strategies based on data augmentation and self-training to enhance the model’s NCIE capabilities during instruction tuning. Through extensive experiments, we demonstrate that the proposed RIEEL achieves superior performances with different state-of-the-arts backbone LLMs, including Qwen1.5, Baichuan2 and LLaMA3. Remarkably, the best version of RIEEL surpasses GPT-4 in NCIE by a substantial margin of 30.61% in terms of the F1 score.}
}
@article{ZHU2025128677,
title = {LEGN: A large language model-guided event graph network for intraoperative hypotension prediction},
journal = {Expert Systems with Applications},
volume = {294},
pages = {128677},
year = {2025},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2025.128677},
url = {https://www.sciencedirect.com/science/article/pii/S095741742502295X},
author = {Zhichao Zhu and Qing Zhao and Yanhu Ge and Jianjiang Li and Sheng Wang and Ji-Jiang Yang},
keywords = {Intraoperative hypotension, Large language model, Domain knowledge},
abstract = {Intraoperative Hypotension (IOH) real-time monitoring is crucial for maintaining patient stability and preventing postoperative complications. Existing IOH prediction methods primarily rely on preoperative and intraoperative data modeling and have achieved certain breakthroughs, but they generally overlook the correlations among preoperative features. The modeling mehods For other disease prediction tasks, have proposed effective solutions to this issue, particularly the “graph-structured representation & domain knowledge” fusion strategy, which has demonstrated highly competitive performance. This provides important references for constructing more accurate IOH prediction models. However, clinical realities reveal some limitations of these methods: 1) These methods construct graph-structured representations at the conceptual level, yet clinical practice shows that some medical concepts inherently lack temporal or causal relations. This leads to distorted representations of patients’ physiological states and their dynamic trends, thus introducing noise into the model’s predictions. 2) The domain knowledge introduced by these methods typically originates from static knowledge bases, making it difficult to dynamically expand. This results in insufficient generalization ability when the model encounters new data or rare cases. To address these issues, we propose a Large Language Model-guided Event Graph Network (LEGN): First, we design an event graph representation method that accurately characterizes the patient’s physiological state and its evolution trends through higher-order event granularity abstraction. Second, we realize the dynamic provision of domain knowledge based on a Large Language Model (LLM), leveraging its powerful knowledge reasoning capabilities to expand the boundaries of knowledge and enhance the model’s adaptability. Extensive experimental validation demonstrates that our proposed method achieves F1 value improvements of 1.89% and 2.63% over the best baseline on real-world and public datasets, respectively.}
}
@article{CHEN2025103068,
title = {Meet2Mitigate: An LLM-powered framework for real-time issue identification and mitigation from construction meeting discourse},
journal = {Advanced Engineering Informatics},
volume = {64},
pages = {103068},
year = {2025},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2024.103068},
url = {https://www.sciencedirect.com/science/article/pii/S1474034624007195},
author = {Gongfan Chen and Abdullah Alsharef and Anto Ovid and Alex Albert and Edward Jaselskis},
keywords = {Construction meeting, Speaker diarization, Automatic speech recognition, Large language model, Retrieval augmented generation, Human-AI interaction},
abstract = {Construction meetings are essential for bringing together project participants to coordinate efforts, identify problems, and make decisions. Previous studies on meeting analysis relied on manual approaches to identify isolated pieces of information but struggled with providing a high-level overview that targeted real-time problem identification and resolution. Despite the rich discussions that occur, the sheer volume of information exchanged can make it difficult to discern key issues, decisions, and action items. Recent advancements in large language models (LLMs) provide sophisticated natural language processing capabilities that can effectively distill essential information and highlight actionable insights from meeting transcripts. However, these technologies are often underutilized in practice, despite their potential to significantly enhance the analysis and management of meeting data. This study introduced the Meet2Mitigate (M2M) framework, which integrates cutting-edge technologies, including speaker diarization, automatic speech recognition (ASR), LLMs, and retrieval-augmented generation (RAG) to revolutionize how construction meetings are captured and analyzed. In this framework, construction meeting recordings can be converted into a structured format, differentiated by timestamps, speakers, and corresponding contents. Different speakers’ dialogues are then summarized to extract the main project-related issues. For quick mitigation responses, this framework combines LLMs with a retrieval mechanism to access the Construction Industry Institute (CII) Best Practices (BPs) knowledge pool, generating detailed action items to drive problem-solving. The validation results demonstrated that the M2M prototype can automatically generate a tailored end-to-end problem-to-solution report in real time by only using a meeting recording file.}
}
@article{PERNISCH2021100658,
title = {Beware of the hierarchy — An analysis of ontology evolution and the materialisation impact for biomedical ontologies},
journal = {Journal of Web Semantics},
volume = {70},
pages = {100658},
year = {2021},
issn = {1570-8268},
doi = {https://doi.org/10.1016/j.websem.2021.100658},
url = {https://www.sciencedirect.com/science/article/pii/S1570826821000330},
author = {Romana Pernisch and Daniele Dell’Aglio and Abraham Bernstein},
keywords = {Ontology evolution, Materialisation, Evolution impact, Ontology change},
abstract = {Ontologies are becoming a key component of numerous applications and research fields. But knowledge captured within ontologies is not static. Some ontology updates potentially have a wide ranging impact; others only affect very localised parts of the ontology and their applications. Investigating the impact of the evolution gives us insight into the editing behaviour but also signals ontology engineers and users how the ontology evolution is affecting other applications. However, such research is in its infancy. Hence, we need to investigate the evolution itself and its impact on the simplest of applications: the materialisation. In this work, we define impact measures that capture the effect of changes on the materialisation. In the future, the impact measures introduced in this work can be used to investigate how aware the ontology editors are about consequences of changes. By introducing five different measures, which focus either on the change in the materialisation with respect to the size or on the number of changes applied, we are able to quantify the consequences of ontology changes. To see these measures in action, we investigate the evolution and its impact on materialisation for nine open biomedical ontologies, most of which adhere to the EL++ description logic. Our results show that these ontologies evolve at varying paces but no statistically significant difference between the ontologies with respect to their evolution could be identified. We identify three types of ontologies based on the types of complex changes which are applied to them throughout their evolution. The impact on the materialisation is the same for the investigated ontologies, bringing us to the conclusion that the effect of changes on the materialisation can be generalised to other similar ontologies. Further, we found that the materialised concept inclusion axioms experience most of the impact induced by changes to the class inheritance of the ontology and other changes only marginally touch the materialisation.}
}
@article{AMADORDOMINGUEZ202185,
title = {An ontology-based deep learning approach for triple classification with out-of-knowledge-base entities},
journal = {Information Sciences},
volume = {564},
pages = {85-102},
year = {2021},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2021.02.018},
url = {https://www.sciencedirect.com/science/article/pii/S0020025521001602},
author = {Elvira Amador-Domínguez and Emilio Serrano and Daniel Manrique and Patrick Hohenecker and Thomas Lukasiewicz},
keywords = {Knowledge graph embeddings, Entity initialization, Knowledge graph completion, Word embeddings, Ontological information},
abstract = {Knowledge graphs (KGs) are one of the most common frameworks for knowledge representation. However, they suffer from a severe scalability problem that hinders their usage. KG embedding aims to provide a solution to this issue. Nonetheless, general approaches are incapable of representing and reasoning about information not previously contained in the graph. This paper proposes to leverage semantic and ontological information for a significant benefit of knowledge graph completion, focusing on triple classification. The goal of this task is to determine whether a given fact holds. Furthermore, this paper also considers the classification of facts that include entities that have not been seen during training, denoted out-of-knowledge-base or OOKB entities. An incremental method is presented, composed of six stages. Although the proposal can be applied to any KG embedding model, this work focuses on its application for semantic matching models, such as ComplEx and DistMult. Compared to other approaches, our proposal is model-agnostic, computationally inexpensive, and does not require retraining. The results show that triple classification accuracy scales up to 15% with the proposed approach, as well as accelerating the convergence of the model to its optimal solution. Furthermore, facts containing OOKB entities can be classified with a reasonable accuracy.}
}
@article{GHIABI2021103116,
title = {Ontological journeys: The lifeworld of opium across the Afghan-Iranian border in/out of the pharmacy},
journal = {International Journal of Drug Policy},
volume = {89},
pages = {103116},
year = {2021},
note = {Special Issue: Drugs, Conflict and Development},
issn = {0955-3959},
doi = {https://doi.org/10.1016/j.drugpo.2021.103116},
url = {https://www.sciencedirect.com/science/article/pii/S0955395921000153},
author = {Maziyar Ghiabi},
keywords = {Ontology, Giorgio Agamben, Opium, Maintenance policy, Social theory, Iran, Afghanistan},
abstract = {How can we conceive alternative policy models that embrace the empirical potentialities emerging from the lifeworld of drugs? The article reflects on this question, concluding that to reassess and to reinvent current policies on drugs, we need to think with a political ontology. Incidentally, the article also responds to the critique dismissing ontological inquiries as obstructing – or, at best, not informing – alternative drug policies. In an archaeological approach inspired by the work of Giorgio Agamben, the article unearths the case study of opium maintenance programme in Iran (1969–79), a forgotten policy experiment in an understudied and yet crucial geo-cultural environment for the global study of drugs. Mobilising the conceptual framework of ontological journeys, the article recomposes the lifeworld of opium within the horizons of transformative cultural practices, international borders, policy regimes and public ethics. Here, the materiality of drug consumption under the maintenance policy links with the changes in opium's transnational political economy and with shifting regimes of health and bioethical orthodoxy. Ontological journeys, hence, develop in a fluid space and time, making it possible to illuminate the lifeworld of drugs in places and times hitherto deserted by global policy studies. In building theoretical reflections upon a non-Western case, the article also incites the possibility of theory beyond Eurocentric knowledge and Euromerican cases. In this way, the article's purpose is to analyse the be-coming of opium beyond ‘good’ or ‘evil’, as a ‘medicine’ or a ‘drug’ and its real or perceived classification as ‘licit’ or ‘illicit’ across the Afghan-Iranian border. In conclusion, the article reflects upon the significance of this forgotten policy experiment, understood as an ontological journey, for contemporary drug policy and drug studies, but also for reinventing notions of care, welfare and health.}
}
@article{AFSHAR2024104707,
title = {On the role of the UMLS in supporting diagnosis generation proposed by Large Language Models},
journal = {Journal of Biomedical Informatics},
volume = {157},
pages = {104707},
year = {2024},
issn = {1532-0464},
doi = {https://doi.org/10.1016/j.jbi.2024.104707},
url = {https://www.sciencedirect.com/science/article/pii/S1532046424001254},
author = {Majid Afshar and Yanjun Gao and Deepak Gupta and Emma Croxford and Dina Demner-Fushman},
keywords = {Artificial intelligence, Knowledge representation (computer), Natural language processing, Unified medical language system, Evaluation methodology, Differential diagnoses},
abstract = {Objective:
Traditional knowledge-based and machine learning diagnostic decision support systems have benefited from integrating the medical domain knowledge encoded in the Unified Medical Language System (UMLS). The emergence of Large Language Models (LLMs) to supplant traditional systems poses questions of the quality and extent of the medical knowledge in the models’ internal knowledge representations and the need for external knowledge sources. The objective of this study is three-fold: to probe the diagnosis-related medical knowledge of popular LLMs, to examine the benefit of providing the UMLS knowledge to LLMs (grounding the diagnosis predictions), and to evaluate the correlations between human judgments and the UMLS-based metrics for generations by LLMs.
Methods:
We evaluated diagnoses generated by LLMs from consumer health questions and daily care notes in the electronic health records using the ConsumerQA and Problem Summarization datasets. Probing LLMs for the UMLS knowledge was performed by prompting the LLM to complete the diagnosis-related UMLS knowledge paths. Grounding the predictions was examined in an approach that integrated the UMLS graph paths and clinical notes in prompting the LLMs. The results were compared to prompting without the UMLS paths. The final experiments examined the alignment of different evaluation metrics, UMLS-based and non-UMLS, with human expert evaluation.
Results:
In probing the UMLS knowledge, GPT-3.5 significantly outperformed Llama2 and a simple baseline yielding an F1 score of 10.9% in completing one-hop UMLS paths for a given concept. Grounding diagnosis predictions with the UMLS paths improved the results for both models on both tasks, with the highest improvement (4%) in SapBERT score. There was a weak correlation between the widely used evaluation metrics (ROUGE and SapBERT) and human judgments.
Conclusion:
We found that while popular LLMs contain some medical knowledge in their internal representations, augmentation with the UMLS knowledge provides performance gains around diagnosis generation. The UMLS needs to be tailored for the task to improve the LLMs predictions. Finding evaluation metrics that are aligned with human judgments better than the traditional ROUGE and BERT-based scores remains an open research question.}
}
@article{LI2025103375,
title = {An interactive system for 3D spatial relationship query by integrating tree-based element indexing and LLM-based agent},
journal = {Advanced Engineering Informatics},
volume = {66},
pages = {103375},
year = {2025},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2025.103375},
url = {https://www.sciencedirect.com/science/article/pii/S147403462500268X},
author = {Ang Li and Peter Kok-Yiu Wong and Xingyu Tao and Jun Ma and Jack C.P. Cheng},
keywords = {Large Language Model (LLM), openBIM Standards, Prompt Engineering, 3D Spatial Relationship Query, Tree-based Geometric Information Indexing},
abstract = {The spatial relationships of building information modeling (BIM) elements are essential to support various applications (e.g., compliance checking, path planning). While the large language models (LLMs) have shown promise in querying the BIM spatial relationship in an efficient and user-friendly manner, three critical challenges persist: extracting the complex spatial geometric information is error-prone, processing large number of elements is low efficient, and the exploitation integrating LLM and BIM spatial query task is still inadequate. Addressing these challenges, this paper develops an interactive natural language spatial query system based on the LLM-based agent system, with three major contributions: (1) an openBIM standards-based algorithm to extract complex geometric information; (2) a two-level spatial index to improve search efficiency; (3) an LLM-based multi-agent collaboration framework to deeply integrate LLM and spatial query task. Our proposed query system is verified in the case study with three BIM models. In our case study, our query can successfully extract geometric information from BIM models with complex layout to facilitate answering spatial query. The spatial index in our query system can significantly improve the efficiency of element search, which reduce 70% of average total query time. Furthermore, our query system shows 92.1% correctness rate in query understanding test. With such high understanding performance, the multi-agent system can decompose the spatial query task and assign it to LLM agents with different functionalities to cooperatively complete the spatial query task, which enhances the applicability of the query system.}
}
@article{AYADI2019100495,
title = {BNO—An ontology for understanding the transittability of complex biomolecular networks},
journal = {Journal of Web Semantics},
volume = {57},
pages = {100495},
year = {2019},
issn = {1570-8268},
doi = {https://doi.org/10.1016/j.websem.2019.01.002},
url = {https://www.sciencedirect.com/science/article/pii/S1570826819300022},
author = {Ali Ayadi and Cecilia Zanni-Merk and François de Bertrand {de Beuvron} and Julie Thompson and Saoussen Krichen},
keywords = {Systems biology, Complex biomolecular networks, Transittability, Ontology engineering, Qualitative reasoning, SWRL rules},
abstract = {Analysis of biological systems is being progressively facilitated by computational tools. Most of these tools are based on qualitative and numerical methods. However, they are not always evident, and there is an increasing need to provide an additional semantic layer. Semantic technologies, especially ontologies, are one of the tools frequently used for this purpose. Indeed, they are indispensable for understanding the semantic knowledge about the operation of cells at a molecular level. We describe here the biomolecular network ontology (BNO) created specially to address the needs of analysing the complex biomolecular network’s behaviour. A biomolecular network consists of nodes, denoting cellular entities, and edges, representing interactions among cellular components. The BNO ontology provides a foundation for qualitative simulation of complex biomolecular networks. We test the performance of the proposed BNO ontology by using a real example of a biomolecular network, the bacteriophage T4 gene 32. We illustrate the proposed BNO ontology for reasoning and inferring new knowledge with sets of rules expressed in SWRL. Results demonstrate that the BNO ontology allows to precisely interpret the corresponding semantic context and intelligently model biomolecular networks and their state changes. The Biomolecular Network Ontology (BNO) is freely available at https://github.com/AliAyadi/BNO-ontology-version-1.0.}
}
@article{ULITIN20191138,
title = {Ontology-based reconfigurable DSL for planning technical services},
journal = {IFAC-PapersOnLine},
volume = {52},
number = {13},
pages = {1138-1144},
year = {2019},
note = {9th IFAC Conference on Manufacturing Modelling, Management and Control MIM 2019},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2019.11.349},
url = {https://www.sciencedirect.com/science/article/pii/S2405896319313278},
author = {Boris Ulitin and Eduard Babkin},
keywords = {enterprise knowledge management, domain-specific language, planning technical service, resource allocation problem, ontology, evolution},
abstract = {The article is related to the problem of decision support in dynamic business contexts where multiple facts of domain knowledge (conditions, values and goals) frequently change over time, and users should participate continuously in the problem definition. In our research we explore an opportunity to use reconfigurable domain specific languages (DSL) as the most convenient and user-oriented way to implementation of decision support systems in the context of modern digital enterprises. What is the most important, the DSL proposed can be evolved in real time using the framework according to the changes in the target domain and competences of end-users. Applicability of the framework is demonstrated using a real-life example of resource allocation process in the railway transportation.}
}
@article{KUMAR2024100308,
title = {AOPWIKI-EXPLORER: An interactive graph-based query engine leveraging large language models},
journal = {Computational Toxicology},
volume = {30},
pages = {100308},
year = {2024},
issn = {2468-1113},
doi = {https://doi.org/10.1016/j.comtox.2024.100308},
url = {https://www.sciencedirect.com/science/article/pii/S2468111324000100},
author = {Saurav Kumar and Deepika Deepika and Karin Slater and Vikas Kumar},
keywords = {Adverse outcome pathway, Large language model, Graph database, Risk assessment, Artificial intelligence, Data integration, Information retrieval, Information extraction},
abstract = {Adverse Outcome Pathways (AOPs) provide a basis for non-animal testing, by outlining the cascade of molecular and cellular events initiated upon stressor exposure, leading to adverse effects. In recent years, the scientific community has shown interest in developing AOPs through crowdsourcing, with the results archived in the AOP-Wiki: a centralized repository coordinated by the OECD, hosting nearly 512 AOPs (April, 2023). However, the AOP-Wiki platform currently lacks a versatile querying system, which hinders developers' exploration of the AOP network and impedes its practical use in risk assessment. This work proposes to unleash the full potential of the AOP-Wiki archive by adapting its data into a Labelled Property Graph (LPG) schema. Additionally, the tool offers a visual network query interface for both database-specific and natural language queries, facilitating the retrieval and analysis of graph data. The multi-query interface allows non-technical users to construct flexible queries, thereby enhancing the potential for AOP exploration. By reducing the time and technical requirements, the present query engine enhances the practical utilization of the valuable data within AOP-Wiki. To evaluate the platform, a case study is presented with three levels of use-case scenarios (simple, moderate, and complex queries). AOPWIKI-EXPLORER is freely available on GitHub (https://github.com/Crispae/AOPWiki_Explorer) for wider community reach and further enhancement.}
}
@incollection{YORDANOVA2021396,
title = {Ontologies to Support Patients with Dementia},
editor = {Olaf Wolkenhauer},
booktitle = {Systems Medicine},
publisher = {Academic Press},
address = {Oxford},
pages = {396-405},
year = {2021},
isbn = {978-0-12-816078-7},
doi = {https://doi.org/10.1016/B978-0-12-801238-3.11473-4},
url = {https://www.sciencedirect.com/science/article/pii/B9780128012383114734},
author = {Kristina Y. Yordanova},
keywords = {Alzheimer׳s disease, Assistance, Automatic patient support, Behavior recognition, Dementia, Intelligent systems, Intervention generation, Knowledge base, Ontology, Situation-awareness},
abstract = {With the changing demographics toward aging population, also the number of people suffering from dementia increases. To allow the prolonged independent and socially active life of patients with dementia (PwD), some works propose the development of intelligent assistive systems that aim to support the PwD during their everyday activities. With the help of a structured knowledge base such systems are able to reason about the person׳s behavior, causes of deviations from normal behavior, and the appropriate intervention strategies. The knowledge base is usually modeled in the form of an ontology, allowing its reuse in other applications aiming to support the independent life of PwD. In this article, we describe how assistive systems use ontologies in order to support the PwD, and we present ontologies that contain domain-specific knowledge used by healthcare and monitoring systems for PwD. Furthermore, we discuss how these ontologies can be linked to other ontologies in order to extend functionality and applicability to different problems from the domain of dementia.}
}
@article{PARK2019103182,
title = {Concept embedding to measure semantic relatedness for biomedical information ontologies},
journal = {Journal of Biomedical Informatics},
volume = {94},
pages = {103182},
year = {2019},
issn = {1532-0464},
doi = {https://doi.org/10.1016/j.jbi.2019.103182},
url = {https://www.sciencedirect.com/science/article/pii/S1532046419301005},
author = {Junseok Park and Kwangmin Kim and Woochang Hwang and Doheon Lee},
keywords = {UMLS, Similarity, Paragraph vector, Embedding, NLP, Wikipedia},
abstract = {There have been many attempts to identify relationships among concepts corresponding to terms from biomedical information ontologies such as the Unified Medical Language System (UMLS). In particular, vector representation of such concepts using information from UMLS definition texts is widely used to measure the relatedness between two biological concepts. However, conventional relatedness measures have a limited range of applicable word coverage, which limits the performance of these models. In this paper, we propose a concept-embedding model of a UMLS semantic relatedness measure to overcome the limitations of earlier models. We obtained context texts of biological concepts that are not defined in UMLS by utilizing Wikipedia as an external knowledgebase. Concept vector representations were then derived from the context texts of the biological concepts. The degree of relatedness between two concepts was defined as the cosine similarity between corresponding concept vectors. As a result, we validated that our method provides higher coverage and better performance than the conventional method.}
}
@article{LALIS202037,
title = {Ontology-based reliability analysis of aircraft engine lubrication system},
journal = {Transportation Research Procedia},
volume = {51},
pages = {37-45},
year = {2020},
note = {INAIR 2020 - CHALLENGES OF AVIATION DEVELOPMENT},
issn = {2352-1465},
doi = {https://doi.org/10.1016/j.trpro.2020.11.006},
url = {https://www.sciencedirect.com/science/article/pii/S2352146520308565},
author = {Andrej Lališ and Simona Bolčeková and Oldřich Štumbauer},
keywords = {aircraft engine, failure mode, effects analysis, ontology, ontology engineering, reliability analysis},
abstract = {This article focuses on identifying limitations and deficiencies of reliability methods that are currently used in the aviation industry. The goal is to propose a solution to address these issues and, consequently, improve the way reliability analyses are carried in the industry. In collaboration with an aircraft engine manufacturer, Failure Mode and Effects Analysis (FMEA) of an aircraft engine lubrication system was carried the traditional way and with current tools used by the company. Reliability ontology suitable to carry the analysis in semi-automatic way was then proposed, implemented, and used with the same FMEA analysis. The results show that the ontology-based approach has significant potential for improving the consistency and overall quality of the reliability analyses in the aviation. This article details the process of development of an FMEA ontology model, case study of its application and the comparison of the traditional and the ontology-based approach.}
}
@article{NOWROOZI2018665,
title = {The comparison of thesaurus and ontology},
journal = {Library Hi Tech},
volume = {36},
number = {4},
pages = {665-684},
year = {2018},
issn = {0737-8831},
doi = {https://doi.org/10.1108/LHT-03-2017-0060},
url = {https://www.sciencedirect.com/science/article/pii/S0737883118000453},
author = {Maryam Nowroozi and Mahdieh Mirzabeigi and Hajar Sotudeh},
keywords = {Usability, Ontology, Representation of concepts, Representation of relations, Semantic tools, Thesaurus},
abstract = {Purpose
The purpose of this paper is to investigate indexers’ evaluation on the usability of ontology vs thesaurus in representation of concepts and semantic relations. To do so, “searching” category of ASIS&T thesaurus was selected and ASIS&TOnto was built based on it.
Design/methodology/approach
The usability examination method is used in order to compare the two semantic tools. Nine indexers were recruited as participants, who were proficient in English language, had experience in using the thesaurus and all had successfully passed the course of “information representation.” They were asked to think aloud while working with the tools and to answer a semi-structured interview. The data gathering was continued until it reached its saturation point.
Findings
The results of this study revealed that the definitions and scope notes represented in indexing tools such as thesauri and ontologies have an important role in improvement of indexers’ understanding. On comparing the hierarchical relations, results show that converting the structure of hierarchical relationships of ASIS&T thesaurus can enhance the indexers understanding of them, and also enriching the associative relations of ASIS&T thesaurus can cause indexers to have a better understanding and evaluation of the presented concepts and relations.
Originality/value
This study shares our findings on the usability of ASIS&T thesaurus as a core set of vocabulary for building a “searching” domain as a prototype ontology in the area of library and information science and provides the indexers viewpoints of the two semantic tools in this area.}
}
@article{GIRMAY2023102853,
title = {Functional genomics analysis of Leptin-Melanocortin system genes reveals candidate genes associated rapid growth and high carcass yield in sheep},
journal = {Journal of King Saud University - Science},
volume = {35},
number = {8},
pages = {102853},
year = {2023},
issn = {1018-3647},
doi = {https://doi.org/10.1016/j.jksus.2023.102853},
url = {https://www.sciencedirect.com/science/article/pii/S1018364723003154},
author = {Shishay Girmay and Nabeel Ijaz and Nighat Hashmi and Muhammad Irfan Ullah and Gulnaz Afzal and Amar Nasir and Shazia Perween and Amtul Sami and Nain Tara and Shaista Abbas and Sayyed Aun Muhammad and Uzma hussain and Shakeel Ahmed and Jilong Han and Huma Ali and Saud Alarifi and Hafiz Ishfaq Ahmad},
keywords = {Body weight, Evolution, Gene ontology, Growth, Positive selection, Sheep},
abstract = {The Leptin-Melanocortin System (LMS) is an important regulatory system involved in appetite and energy balance in many organisms, including sheep. Functional genomics analysis of LMS genes can provide insights into the genetic factors that influence rapid growth and high carcass yield in sheep. However, the genetic potential of sheep growth and reproduction has not been fully exploited. Therefore, identifying genes that regulate growth and reproduction would offer strategies for improving the yield and quality of sheep meat. In this study, to explore the possible molecular mechanisms underlying rapid growth and muscular high-yield carcass in sheep, we screened 14 genes, which were previously claimed to be associated with such traits in humans and rodents. The FST outlier approach implemented in LOSITAN detected the loci under selection. These candidate genes were connected to complicated biological processes, including the regulation of eating behavior, energy balance, and the positive regulation of the cAMP biosynthetic process, according to the gene ontology (GO) study. In addition, the 14 genes' re-sequence data revealed 7,226 SNPs. The MC4R, STAT3, BDNF, and TUB genes were discovered to be an outlier and significantly under positive selection using the fixation index (FST) based technique with the tentative combined allocation of mean heterozygosity and FST. Differentially expressed genes were found, and their functions were assigned using a functional genomics approach. Results showed that these genes are crucial in determining sheep features including size and meat quality. Insights are gained into the molecular mechanisms behind these phenotypic variations, and possible genes for future sheep breeding initiatives are provided. This research proves the value of functional genomics analysis in identifying the heritable components of valuable sheep agriculture traits.}
}
@article{ZHELEZNYAKOV2019100484,
title = {On expansion and contraction of DL-Lite knowledge bases},
journal = {Journal of Web Semantics},
volume = {57},
pages = {100484},
year = {2019},
issn = {1570-8268},
doi = {https://doi.org/10.1016/j.websem.2018.12.002},
url = {https://www.sciencedirect.com/science/article/pii/S1570826818300647},
author = {Dmitriy Zheleznyakov and Evgeny Kharlamov and Werner Nutt and Diego Calvanese},
keywords = {Knowledge evolution, Knowledge expansion, Knowledge contraction, DL-Lite, Semantics, Complexity, Algorithms},
abstract = {Knowledge bases (KBs) are not static entities: new information constantly appears and some of the previous knowledge becomes obsolete. In order to reflect this evolution of knowledge, KBs should be expanded with the new knowledge and contracted from the obsolete one. This problem is well-studied for propositional but much less for first-order KBs. In this work we investigate knowledge expansion and contraction for KBs expressed in DL-Lite, a family of description logics (DLs) that underlie the tractable fragment OWL2QL of the Web Ontology Language OWL2. We start with a novel knowledge evolution framework and natural postulates that evolution should respect, and compare our postulates to the well-established AGM postulates. We then review well-known model and formula-based approaches for expansion and contraction for propositional theories and show how they can be adapted to the case of DL-Lite. In particular, we show intrinsic limitations of model-based approaches: besides the fact that some of them do not respect the postulates we have established, they ignore the structural properties of KBs. This leads to undesired properties of evolution results: evolution of DL-Lite KBs cannot be captured in DL-Lite. Moreover, we show that well-known formula-based approaches are also not appropriate for DL-Lite expansion and contraction: they either have a high complexity of computation, or they produce logical theories that cannot be expressed in DL-Lite. Thus, we propose a novel formula-based approach that respects our principles and for which evolution is expressible in DL-Lite. For this approach we also propose polynomial time deterministic algorithms to compute evolution of DL-Lite KBs when evolution affects only factual data.}
}
@incollection{RAHLARABIA2022319,
title = {17 - Applications of Building Information Modeling for COVID-19 spread assessment due to the organization of building artifacts},
editor = {Utku Kose and Deepak Gupta and Victor Hugo C. {de Albuquerque} and Ashish Khanna},
booktitle = {Data Science for COVID-19},
publisher = {Academic Press},
pages = {319-333},
year = {2022},
isbn = {978-0-323-90769-9},
doi = {https://doi.org/10.1016/B978-0-323-90769-9.00009-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780323907699000098},
author = {M.P. {Rahla Rabia} and D. {Sathish Kumar} and Jasim Farooq and Rupendra Kumar Pachauri},
keywords = {BIM, C#, COVID-19, Disease spread, GIS, Revit},
abstract = {Quick and accurate building-level infectious disease transmission evaluation is a key concern that gains traction nowadays. This chapter summarizes Building Information Modeling (BIM) applications for COVID-19 Spread Assessment due to the Organization of Building Artifacts (CSAOBA). Development of BIM-based inbuilt and add-in tools for CSAOBA offer a faster approach for data gathering and sharing. A Geographic Information System (GIS) and BIM-integrated CSAOBA at the provincial level information system is a suitable platform for retrieving and processing huge data automatically and accurately. BIM delivers project-level information and GIS stores and manipulates the regional-level information for district-level assessments. Future BIM standards are to incorporate CSAOBA-related modeling rules and regulations, which may ease handling emergency situations. BIM-based reliable CSAOBA tools require efficient ontologies and related algorithms to increase the accuracy and industrial deployment.}
}
@article{ALOMARI2022103637,
title = {Online perceptual learning and natural language acquisition for autonomous robots},
journal = {Artificial Intelligence},
volume = {303},
pages = {103637},
year = {2022},
issn = {0004-3702},
doi = {https://doi.org/10.1016/j.artint.2021.103637},
url = {https://www.sciencedirect.com/science/article/pii/S0004370221001880},
author = {Muhannad Alomari and Fangjun Li and David C. Hogg and Anthony G. Cohn},
keywords = {Language and vision, Language acquisition, Language grounding, Grammar induction},
abstract = {In this work, the problem of bootstrapping knowledge in language and vision for autonomous robots is addressed through novel techniques in grammar induction and word grounding to the perceptual world. In particular, we demonstrate a system, called OLAV, which is able, for the first time, to (1) learn to form discrete concepts from sensory data; (2) ground language (n-grams) to these concepts; (3) induce a grammar for the language being used to describe the perceptual world; and moreover to do all this incrementally, without storing all previous data. The learning is achieved in a loosely-supervised manner from raw linguistic and visual data. Moreover, the learnt model is transparent, rather than a black-box model and is thus open to human inspection. The visual data is collected using three different robotic platforms deployed in real-world and simulated environments and equipped with different sensing modalities, while the linguistic data is collected using online crowdsourcing tools and volunteers. The analysis performed on these robots demonstrates the effectiveness of the framework in learning visual concepts, language groundings and grammatical structure in these three online settings.}
}
@article{DELHOMME2022113694,
title = {An interface between natural language and abstract argumentation frameworks for real-time debate analysis},
journal = {Decision Support Systems},
volume = {154},
pages = {113694},
year = {2022},
issn = {0167-9236},
doi = {https://doi.org/10.1016/j.dss.2021.113694},
url = {https://www.sciencedirect.com/science/article/pii/S0167923621002049},
author = {Benjamin Delhomme and Franck Taillandier and Irène Abi-Zeid and Rallou Thomopoulos and Cédric Baudrit and Laurent Mora},
keywords = {Argumentation framework, Conflict resolution, Real-time debate modeling, Participatory debate, Computational argumentation tool},
abstract = {Participatory approaches are increasingly being used to plan policies, usually involving stakeholders with conflicting interests, visions and objectives. Participants are often passionate about their cause, especially in sensitive contexts such as their health or the environment for example. Whether involved in, or observing a debate, more often than not, it is hard to follow its progress; positions are unclear and arguments are unstructured often resulting in circular discussions. This is true both for participants in an ongoing debate hoping to reach a consensus as well as for those who, a posteriori, wish to understand what was discussed and how. However, at the current time, there are to our knowledge no tools to support real-time debates by allowing participants to visualize arguments and identifying opposing points of view in order to resolve conflicts. In order to fill this gap, we developed a model based on Dung's argumentation framework that we implemented in a tool called AIPA, along with a web-application to facilitate user interaction. AIPA allows one to formalize and visualize, in real-time, the arguments of the participants, to conduct inferences in order to identify acceptable arguments and to highlight conflicting ones. Furthermore, AIPA can be used a posteriori to summarize a debate in an easy to follow argument representation. The main contribution of AIPA is its ability to structure the debate by making the arguments chain traceable and transparent, in real-time and a posteriori, and this, with users with no expertise in argumentation. In this paper, we present AIPA along with two applications to illustrate its workings and benefits.}
}
@article{EKE2023100060,
title = {ChatGPT and the rise of generative AI: Threat to academic integrity?},
journal = {Journal of Responsible Technology},
volume = {13},
pages = {100060},
year = {2023},
issn = {2666-6596},
doi = {https://doi.org/10.1016/j.jrt.2023.100060},
url = {https://www.sciencedirect.com/science/article/pii/S2666659623000033},
author = {Damian Okaibedi Eke},
keywords = {ChatGPT, Large language models, OpenAI, Academic integrity, Generative AI},
abstract = {The emergence of OpenAI's ChatGPT has put intense spotlight on Generative AI (Gen-AI) systems and their possible impacts on Academic integrity. This paper provides an overview of the current arguments around ChatGPT and Academic integrity and concludes that although these technologies are capable of revolutionising academia, the way ChatGPT and other generative AI systems are used could surely undermine academic integrity. However, to ensure that the risks to academic integrity are mitigated for greater maximisation, institutional and multi-stakeholder efforts are required.}
}
@article{FERNANDEZCHAVES2021107440,
title = {ViMantic, a distributed robotic architecture for semantic mapping in indoor environments},
journal = {Knowledge-Based Systems},
volume = {232},
pages = {107440},
year = {2021},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2021.107440},
url = {https://www.sciencedirect.com/science/article/pii/S0950705121007024},
author = {D. Fernandez-Chaves and J.R. Ruiz-Sarmiento and N. Petkov and J. Gonzalez-Jimenez},
keywords = {Semantic maps, Robotic architecture, Mobile robots, Unity 3D, ROS, Object detection, Detectron2, Robot@Home},
abstract = {Semantic maps augment traditional representations of robot workspaces, typically based on their geometry and/or topology, with meta-information about the properties, relations and functionalities of their composing elements. A piece of such information could be: fridges are appliances typically found in kitchens and employed to keep food in good condition. Thereby, semantic maps allow for the execution of high-level robotic tasks in an efficient way, e.g. “Hey robot, Store the leftover salad”. This paper presents ViMantic, a novel semantic mapping architecture for the building and maintenance of such maps, which brings together a number of features as demanded by modern mobile robotic systems, including: (i) a formal model, based on ontologies, which defines the semantics of the problem at hand and establishes mechanisms for its manipulation; (ii) techniques for processing sensory information and automatically populating maps with, for example, objects detected by cutting-edge CNNs; (iii) distributed execution capabilities through a client–server design, making the knowledge in the maps accessible and extendable to other robots/agents; (iv) a user interface that allows for the visualization and interaction with relevant parts of the maps through a virtual environment; (v) public availability, hence being ready to use in robotic platforms. The suitability of ViMantic has been assessed using Robot@Home, a vast repository of data collected by a robot in different houses. The experiments carried out consider different scenarios with one or multiple robots, from where we have extracted satisfactory results regarding automatic population, execution times, and required size in memory of the resultant semantic maps.}
}
@article{DANENAS2020101822,
title = {Natural language processing-enhanced extraction of SBVR business vocabularies and business rules from UML use case diagrams},
journal = {Data & Knowledge Engineering},
volume = {128},
pages = {101822},
year = {2020},
issn = {0169-023X},
doi = {https://doi.org/10.1016/j.datak.2020.101822},
url = {https://www.sciencedirect.com/science/article/pii/S0169023X1930299X},
author = {Paulius Danenas and Tomas Skersys and Rimantas Butleris},
keywords = {SBVR business vocabulary and rules, UML use case diagram, Model-to-model transformation, Controlled natural language, Natural language processing, Information extraction},
abstract = {Discovery, specification and proper representation of various aspects of business knowledge plays crucial part in model-driven information systems engineering, especially when it comes to the early stages of systems development. Being among the most applicable and advanced features of model-driven development, model transformation could help improving one of the most time- and resource-consuming efforts in this process, namely, discovery and specification of business vocabularies and business rules within the problem domain. One of our latest developments in this area was the solution for the automatic extraction of SBVR business vocabularies and business rules from UML use case diagrams, which was arguably one of the most comprehensive developments of this kind currently available in public. In this paper, we present an enhancement to our previous development by introducing a novel natural language processing component to it. This enhancement provides more advanced extraction capabilities (such as recognition of entities, entire noun and verb phrases, multinary associations) and better quality of the extraction results compared to our previous solution. The main contributions presented in this paper are pre- and post-processing algorithms, and two extraction algorithms using custom-trained POS tagger. Based on the related work findings, it is safe to state that the presented solution is novel and original in its approach of combining together M2M transformation of UML and SBVR models with natural language processing techniques in the field of model-driven information systems engineering.}
}
@article{XU2021196,
title = {Digital twin-based industrial cloud robotics: Framework, control approach and implementation},
journal = {Journal of Manufacturing Systems},
volume = {58},
pages = {196-209},
year = {2021},
note = {Digital Twin towards Smart Manufacturing and Industry 4.0},
issn = {0278-6125},
doi = {https://doi.org/10.1016/j.jmsy.2020.07.013},
url = {https://www.sciencedirect.com/science/article/pii/S0278612520301230},
author = {Wenjun Xu and Jia Cui and Lan Li and Bitao Yao and Sisi Tian and Zude Zhou},
keywords = {Industrial cloud robotics, Digital twin, Robotic control, Cloud service},
abstract = {Industrial cloud robotics (ICR) integrates cloud computing with industrial robots (IRs). The capabilities of industrial robots can be encapsulated as cloud services and used for ubiquitous manufacturing. Currently, the digital models for process simulation, path simulation, etc. are encapsulated as cloud services. The digital models in the cloud may not reflect the real state of the physical robotic manufacturing systems due to inaccurate or delayed condition update and therefore result in inaccurate simulation and robotic control. Digital twin can be used to realize fine sensing control of the physical manufacturing systems by a combination of high-fidelity digital model and sensory data. In this paper, we propose a framework of digital twin-based industrial cloud robotics (DTICR) for industrial robotic control and its key methodologies. The DTICR is divided into physical IR, digital IR, robotic control services, and digital twin data. First, the robotic control capabilities are encapsulated as Robot Control as-a-Service (RCaaS) based on manufacturing features and feature-level robotic capability model. Then the available RCaaSs are ranked and parsed. After manufacturing process simulation with digital IR models, RCaaSs are mapped to physical robots for robotic control. The digital IR models are connected to the physical robots and updated by sensory data. A case is implemented to demonstrate the workflow of DTICR. The results show that DTICR is capable to synchronize and merge digital IRs and physical IRs effectively. The bidirectional interaction between digital IRs and physical IRs enables fine sensing control of IRs. The proposed DTICR is also flexible and extensible by using ontology models.}
}
@article{ZHANG2025111368,
title = {A flexible manufacturing mechanism presentation model for process simulation and execution},
journal = {Computers & Industrial Engineering},
volume = {208},
pages = {111368},
year = {2025},
issn = {0360-8352},
doi = {https://doi.org/10.1016/j.cie.2025.111368},
url = {https://www.sciencedirect.com/science/article/pii/S0360835225005145},
author = {Kai Zhang and Meqi Lu and Lucheng Chen and Dianhui Chu and Zhiying Tu and Xiaoping Lu and Liyang Dong and Qingran Ji},
keywords = {Flexible manufacturing, Multi-view, Knowledge graph, Process execution, Process simulation},
abstract = {The flexible manufacturing capability of unmanned factories and robotic intelligence is reflected in the autonomous collaboration of multiple machines based on manufacturing tasks. This requires intelligent machines to be able to understand manufacturing process requirements and collaborate in production according to specific procedures. Currently, some machines are limited to embedded processes and fixed parameters, which not only restricts their ability to switch manufacturing tasks on demand but also hinder autonomous collaboration among multiple machines. To this end, we proposed the Process Mechanism Presentation (PMP) model that performs multi-view knowledge modeling for manufacturing processes and machine capabilities, and achieves matching through knowledge reasoning. In this model, the process view selects candidate process templates based on manufacturing tasks. Furthermore, by matching the capabilities with the available manufacturing resources, the optimal production process path and step parameters can be determined. The above path and its parameters can be dynamically loaded to selected machines through our constructed process execution middleware, enabling task customization and autonomous collaboration among multiple machines. Finally, we conducted simulation verification and real-case validation of the refrigerator assembly line. The results show that the success rate of process execution guided by the model can reach 99%, demonstrating excellent results.}
}
@article{VISHWAKARMA2025102468,
title = {Automatic query expansion for enhancing document retrieval system in healthcare application using GAN based embedding and hyper-tuned DAEBERT algorithm},
journal = {Data & Knowledge Engineering},
volume = {160},
pages = {102468},
year = {2025},
issn = {0169-023X},
doi = {https://doi.org/10.1016/j.datak.2025.102468},
url = {https://www.sciencedirect.com/science/article/pii/S0169023X25000631},
author = {Deepak Vishwakarma and Suresh Kumar},
keywords = {Automatic query expansion, Information retrieval, Generative Adversial Network, Modified Page Ranking Algorithm, Proximity based Keyword Extraction},
abstract = {Query expansion is a useful technique for improving document retrieval systems' dependability and performance. Search engines frequently employ query expansion strategies to improve Information Retrieval (IR) performance and elucidate users' information requirements. Although there are several methods for automatically expanding queries, the list of documents that are returned can occasionally be lengthy and contain a lot of useless information, particularly when searching the Web. As the size of medical document grows, Automatic Query Expansion might struggle with efficiency and real-time application. Thus, Hyper-Tuned Dual Attention Enhanced Bi-directional Encoder Representation from Transformers (HT-DAEBERT) with automatic ranking based query expansion system is created for enhancing medical document retrieval system. Initially, the user's query from the medical corpus document was collected, and it was augmented using the Generative Adversarial Network (GAN) approach. Then augmented text is pre-processed to improve the original text's quality through tokenization, acronym expansion, stemming, stop word removal, hyperlink removal, and spell correction. After that, Keywords are extracted using the Proximity-based Keyword Extraction (PKE) technique from the pre-processed text. Afterwards, the words are converted into vector form by utilizing the Hyper-Tuned Dual Attention Enhanced Bi-directional Encoder Representation from Transformers (HT-DAEBERT) model. In DAEBERT, key parameters such as dropout rate and weight decay were optimally selected by using the Election Optimization Algorithm (EOA). After that, a ranking-based query expansion approach was employed to enhance the document retrieval system. The proposed method achieves an accuracy of 97.60 %, a Hit Rate of 98.30 %, a PPV of 93.40 %, an F1-Score of 95.79 %, and an NPV of 97.50 %. This approach improves the accuracy and relevance of document retrieval in healthcare, potentially leading to better patient care and enhanced clinical outcomes.}
}
@article{HOPPNER2023101185,
title = {Distributed age(ing): Features of a material gerontology},
journal = {Journal of Aging Studies},
volume = {67},
pages = {101185},
year = {2023},
issn = {0890-4065},
doi = {https://doi.org/10.1016/j.jaging.2023.101185},
url = {https://www.sciencedirect.com/science/article/pii/S0890406523000865},
author = {Grit Höppner},
keywords = {Distributed age(ing), Material gerontology, Actor-network theory, Breathing},
abstract = {In this paper, I develop features of a material gerontology which are summarised in the concept of “distributed age(ing);” that is, age(ing) that is distributed across and co-constituted through meanings, roles, and identities, as well as human and non-human forms of materiality, their productive dimensions and their relations to each other. The starting point is the critique of the human-centredness of gerontological approaches and, thus, the lack of a systematic conceptual consideration of non-human forms of materiality and agency in the context of age(ing). To overcome this problem, I propose the following shifts in perspective that are inspired by actor-network theory: from human-centredness to the recognition and consideration of the material diversity of age(ing); from the critique of subject/object dualism to the symmetrisation of materialities; from the seemingly given ontology of the ageing body to the re-ontologisation of age(ing); from the critique of intentional and causal determinants to embodiment and relationality; from linearity and chronology to the plural temporalities of age(ing). I will explain these features in more detail by using breathing as an example. I will show that the concept of distributed age(ing) allows for both the generation of new insights on age(ing) by asking how, where and when age(ing) takes place and reflection on presumptions, determinants and reductions of approaches belonging to social and cultural gerontology.}
}
@article{JAWAD2023102124,
title = {Adoption of knowledge-graph best development practices for scalable and optimized manufacturing processes},
journal = {MethodsX},
volume = {10},
pages = {102124},
year = {2023},
issn = {2215-0161},
doi = {https://doi.org/10.1016/j.mex.2023.102124},
url = {https://www.sciencedirect.com/science/article/pii/S2215016123001255},
author = {M.S. Jawad and Chitra Dhawale and Azizul Azhar Bin Ramli and Hairulnizam Mahdin},
keywords = {Enterprise knowledge graph, Smart manufacturing, Ontology, Machine learning, Data Analytics, Data Fabric},
abstract = {Using data analytics to properly extracting insights that are in-line to the enterprises strategic goals is crucial for the business sustainability. Developing the most fitting context as a knowledge graph that answer related businesses questions and queries at scale. Data analytics is an integral main part of smart manufacturing for monitoring the production processes and identifying the potentials for automated operations for improved manufacturing performance. This paper reviews and investigates the best development practices to be followed for industrial enterprise knowledge-graph development that support smart manufacturing in the following aspects:•Decision for intelligent business processes, data collection from multiple sources, competitive advantage graph ontology, ensuring data quality, improved data analytics, human-friendly interaction, rapid and scalable enterprise's architectures.•Successful digital-transformation adoption for smart manufacturing as an enterprise knowledge-graph development with the capability to be transformed to data fabric supporting scalability of smart manufacturing processes in industrial enterprises.}
}
@article{ZHENG2022,
title = {Identifying Cases of Shoulder Injury Related to Vaccine Administration (SIRVA) in the United States: Development and Validation of a Natural Language Processing Method},
journal = {JMIR Public Health and Surveillance},
volume = {8},
number = {5},
year = {2022},
issn = {2369-2960},
doi = {https://doi.org/10.2196/30426},
url = {https://www.sciencedirect.com/science/article/pii/S2369296022001351},
author = {Chengyi Zheng and Jonathan Duffy and In-Lu Amy Liu and Lina S Sy and Ronald A Navarro and Sunhea S Kim and Denison S Ryan and Wansu Chen and Lei Qian and Cheryl Mercado and Steven J Jacobsen},
keywords = {health, informatics, shoulder injury related to vaccine administration, SIRVA, natural language processing, NLP, causal relation, temporal relation, pharmacovigilance, electronic health records, EHR, vaccine safety, artificial intelligence, big data, population health, real-world data, vaccines},
abstract = {Background
Shoulder injury related to vaccine administration (SIRVA) accounts for more than half of all claims received by the National Vaccine Injury Compensation Program. However, due to the difficulty of finding SIRVA cases in large health care databases, population-based studies are scarce.
Objective
The goal of the research was to develop a natural language processing (NLP) method to identify SIRVA cases from clinical notes.
Methods
We conducted the study among members of a large integrated health care organization who were vaccinated between April 1, 2016, and December 31, 2017, and had subsequent diagnosis codes indicative of shoulder injury. Based on a training data set with a chart review reference standard of 164 cases, we developed an NLP algorithm to extract shoulder disorder information, including prior vaccination, anatomic location, temporality and causality. The algorithm identified 3 groups of positive SIRVA cases (definite, probable, and possible) based on the strength of evidence. We compared NLP results to a chart review reference standard of 100 vaccinated cases. We then applied the final automated NLP algorithm to a broader cohort of vaccinated persons with a shoulder injury diagnosis code and performed manual chart confirmation on a random sample of NLP-identified definite cases and all NLP-identified probable and possible cases.
Results
In the validation sample, the NLP algorithm had 100% accuracy for identifying 4 SIRVA cases and 96 cases without SIRVA. In the broader cohort of 53,585 vaccinations, the NLP algorithm identified 291 definite, 124 probable, and 52 possible SIRVA cases. The chart-confirmation rates for these groups were 95.5% (278/291), 67.7% (84/124), and 17.3% (9/52), respectively.
Conclusions
The algorithm performed with high sensitivity and reasonable specificity in identifying positive SIRVA cases. The NLP algorithm can potentially be used in future population-based studies to identify this rare adverse event, avoiding labor-intensive chart review validation.}
}
@article{BERETTA2018298,
title = {Truth selection for truth discovery models exploiting ordering relationship among values},
journal = {Knowledge-Based Systems},
volume = {159},
pages = {298-308},
year = {2018},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2018.06.023},
url = {https://www.sciencedirect.com/science/article/pii/S0950705118303320},
author = {Valentina Beretta and Sébastien Harispe and Sylvie Ranwez and Isabelle Mougenot},
keywords = {Truth identification, Truth discovery, Conflicting values, Value relationships, Ontology},
abstract = {Data veracity is one of the main issues regarding Web data. Truth Discovery models can be used to assess it by estimating value confidence and source trustworthiness through analysis of claims on the same real-world entities provided by different sources. Many studies have been conducted in this domain. True values selected by most models have the highest confidence estimation. This naive strategy cannot be applied to identify true values when there is a partial order among values that is considered to enhance the final performance. Indeed, in this case, the resulting estimations monotonically increase with respect to the partial order of values. The highest confidence is always assigned to the most general value that is implicitly supported by all the others. Thus, using the highest confidence as criterion to select the true values is not appropriate because it will always return the most general values. To address this problem, we propose a post-processing procedure that, leveraging the partial order among values and their monotonic confidence estimations, is able to identify the expected true value. Experimental results on synthetic datasets show the effectiveness of our approach.}
}
@article{LI2025113534,
title = {An interpretable reasoning schema for fuzzy knowledge graph under interval Type-2 fuzzy model},
journal = {Applied Soft Computing},
volume = {182},
pages = {113534},
year = {2025},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2025.113534},
url = {https://www.sciencedirect.com/science/article/pii/S1568494625008452},
author = {Pu Li and Guopeng Cheng and Yongqi Zhao and Luyang Liu and Meifang Chen and Zhengang Ma and Xiaoyu Chen},
keywords = {Interpretable reasoning, Fuzzy semantic, Interval Type-2 fuzzy model, Knowledge graph},
abstract = {Knowledge graphs (KGs) require the ability to model the prevalent fuzzy semantics of the real world to better align with human cognition and maximize their value. However, the standard RDF model inadequately expresses deep fuzzy semantics between entities and lacks interpretability, especially for deep learning-based reasoning. To address these limitations, this work proposes an interpretable reasoning schema by introducing the Interval Type-2 fuzzy (IT2_F) model. Specifically, we employ IT2_F theory to describe predicate fuzzy semantics, propose new fuzzy semantic extension principles, and design a corresponding interpretation mechanism for credible fuzzy semantic discovery. Evaluations demonstrate that our approach uncovers richer deep fuzzy semantic information and provides users with more effective and reasonable traceability services.}
}
@article{ZHOU2022116560,
title = {Semantic Relatedness Enhanced Graph Network for aspect category sentiment analysis},
journal = {Expert Systems with Applications},
volume = {195},
pages = {116560},
year = {2022},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2022.116560},
url = {https://www.sciencedirect.com/science/article/pii/S0957417422000586},
author = {Tao Zhou and Kris M.Y. Law},
keywords = {Aspect category sentiment analysis, Semantic relatedness, Edge-Gated Graph Convolutional Network, Aspect–context attention},
abstract = {As a variant problem of aspect-based sentiment analysis (ABSA), aspect category sentiment analysis (ACSA) aims to identify the aspect categories discussed in sentences and predict their sentiment polarities. However, most aspect-based sentiment analysis (ABSA) research focuses on predicting the sentiment polarities of given aspect categories or aspect terms explicitly discussed in sentences. In contrast, aspect categories are often discussed implicitly. Additionally, most of the research does not consider the relations between contextual words and aspect categories. This paper proposes a novel Semantic Relatedness-enhanced Graph Network (SRGN) model which integrates the semantic relatedness information through an Edge-gated Graph Convolutional Network (EGCN). We introduce an ontology-based approach and a distributional approach to calculate the semantic relatedness values between contextual words and aspect categories. EGCN with the capability to aggregate multi-channel edge features, is then applied to model the semantic relatedness values in a graphical structure. We also employ an aspect–context attention module to generate aspect-specific representations. The proposed SRGN is evaluated on five datasets constructed based on SemEval 2015, SemEval 2016 and MAMC-ACSA datasets. Experimental results indicate that our proposed model outperforms the baseline models in both accuracy and F1 score.}
}
@article{ALOULOU2023100567,
title = {Personalized, context-aware, and adaptable persuasive approach for encouraging physical activity among older adults},
journal = {Entertainment Computing},
volume = {46},
pages = {100567},
year = {2023},
issn = {1875-9521},
doi = {https://doi.org/10.1016/j.entcom.2023.100567},
url = {https://www.sciencedirect.com/science/article/pii/S1875952123000228},
author = {Houssem Aloulou and Hamdi Aloulou and Bessam Abdulrazak and Ahmed Hadj Kacem},
keywords = {Elderlies care, Physical activity, Persuasion strategy, Ontology, Semantic reasoning, Context-aware},
abstract = {Seclusion and sedentary lifestyle are the main causes of many psychological and physical health problems. They may be among the top 10 causes of death and disability in the world. The pandemic crisis context of COVID has deepened these problems, especially for older adults who have been isolated, deprived of their relatives and of doing physical activities. In this paper, we introduce an adaptive, personalized, and context-aware persuasive platform to stimulate physical activities of older adults without deception or coercion. Our persuasion approach is customizable, in the sense that every older adult has its personal profile. It is also adaptive because it can use a persuasion loop to change the persuasion strategy when the older adult does not adhere to the proposed persuasion strategy. Furthermore, our persuasion approach is context-aware as it takes account of contextual location and weather information in the provision of the persuasion strategy. To validate our approach, we implemented “ActiveSenior”. Then, we carried out a large-scale challenge for one month to approve the results of our persuasive approach. The evaluation of the acceptance of our ActiveSenior system was encouraging as most of the interviewed participants were satisfied. In addition, the obtained results showed a marked improvement in the physical activity of older adults, quantified by the number of steps taken per day.}
}
@article{SEIDEL2024615,
title = {Multilayer concept of autoimmune mechanisms and manifestations in inborn errors of immunity: Relevance for precision therapy},
journal = {Journal of Allergy and Clinical Immunology},
volume = {153},
number = {3},
pages = {615-628.e4},
year = {2024},
issn = {0091-6749},
doi = {https://doi.org/10.1016/j.jaci.2023.12.022},
url = {https://www.sciencedirect.com/science/article/pii/S0091674924000071},
author = {Markus G. Seidel and Fabian Hauck},
keywords = {Inborn error of immunity, autoimmunity, next-generation sequencing, genetics, pathophysiology, human phenotype ontology, precision therapy, European Society for Immunodeficiency},
abstract = {Autoimmunity in inborn errors of immunity (IEIs) has a multifactorial pathogenesis and develops subsequent to a genetic predisposition in conjunction with gene regulation, environmental modifiers, and infectious triggers. On the basis of incremental data availability owing to upfront application of omics technologies, a more granular and dynamic view of mechanisms and manifestations is warranted. Here, we present a comprehensive novel concept of autoimmunity in IEIs that considers multiple layers of interdependent elements and connects 101 causative genes or deletions according to the quality of the allelic variants with 47 molecular pathways and 22 immune effector mechanisms. Furthermore, we list 50 resulting manifestations together with the corresponding Human Phenotype Ontology terms and review the types and frequencies of the most relevant clinical presentations. When all of its elements are taken together, this concept (1) extends the historical anatomic view of central versus peripheral tolerance toward multiple interdependent mechanisms of immune tolerance, (2) delineates the mechanisms underlying the protean clinical manifestations, and thereby, (3) points toward the most suitable precision therapy for autoimmunity in IEIs. The multilayer concept of autoimmune mechanisms and manifestations in IEIs will facilitate research design and provide clinical guidance on the use of precision medicine irrespective of the data depth available in each health care scenario.}
}
@article{CHENAIS2023,
title = {Deep Learning Transformer Models for Building a Comprehensive and Real-time Trauma Observatory: Development and Validation Study},
journal = {JMIR AI},
volume = {2},
year = {2023},
issn = {2817-1705},
doi = {https://doi.org/10.2196/40843},
url = {https://www.sciencedirect.com/science/article/pii/S2817170523000017},
author = {Gabrielle Chenais and Cédric Gil-Jardiné and Hélène Touchais and Marta {Avalos Fernandez} and Benjamin Contrand and Eric Tellier and Xavier Combes and Loick Bourdois and Philippe Revel and Emmanuel Lagarde},
keywords = {deep learning, public health, trauma, emergencies, natural language processing, transformers},
abstract = {Background
Public health surveillance relies on the collection of data, often in near-real time. Recent advances in natural language processing make it possible to envisage an automated system for extracting information from electronic health records.
Objective
To study the feasibility of setting up a national trauma observatory in France, we compared the performance of several automatic language processing methods in a multiclass classification task of unstructured clinical notes.
Methods
A total of 69,110 free-text clinical notes related to visits to the emergency departments of the University Hospital of Bordeaux, France, between 2012 and 2019 were manually annotated. Among these clinical notes, 32.5% (22,481/69,110) were traumas. We trained 4 transformer models (deep learning models that encompass attention mechanism) and compared them with the term frequency–inverse document frequency associated with the support vector machine method.
Results
The transformer models consistently performed better than the term frequency–inverse document frequency and a support vector machine. Among the transformers, the GPTanam model pretrained with a French corpus with an additional autosupervised learning step on 306,368 unlabeled clinical notes showed the best performance with a micro F1-score of 0.969.
Conclusions
The transformers proved efficient at the multiclass classification of narrative and medical data. Further steps for improvement should focus on the expansion of abbreviations and multioutput multiclass classification.}
}
@article{JARVENPAA2021435,
title = {Capability matchmaking software for rapid production system design and reconfiguration planning},
journal = {Procedia CIRP},
volume = {97},
pages = {435-440},
year = {2021},
note = {8th CIRP Conference of Assembly Technology and Systems},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2020.05.264},
url = {https://www.sciencedirect.com/science/article/pii/S2212827120314864},
author = {Eeva Järvenpää and Niko Siltala and Otto Hylli and Minna Lanz},
keywords = {Production system design, Production system reconfiguration, Capability matchmaking, Matchmaking software, Resource modelling, Ontology},
abstract = {Traditionally, the production system design and reconfiguration planning are manual processes, which rely heavily on the designers’ expertise and tacit knowledge to find feasible system configuration solutions. Rapid responsiveness of future production systems calls for new computer-aided intelligent design and planning solutions, that would reduce the time and effort put into system design, both in brownfield and greenfield scenarios. This paper describes the implementation of a capability matchmaking software, which automatizes the matchmaking between product requirements and resource capabilities. The interaction of the matchmaking system with external design and planning tools is explained and illustrated with a case example. The matchmaking approach supports production system design and reconfiguration planning by providing automatic means for checking if the existing system already fulfills the new product requirements, and for finding alternative resources and resource combinations to specific product requirements from large search spaces, e.g. from global resource catalogues.}
}
@article{AMBROSO2022101030,
title = {Teaching students from refugee backgrounds: The link between language ideologies and policy appropriation},
journal = {Linguistics and Education},
volume = {70},
pages = {101030},
year = {2022},
note = {Researching the Role of Language Teachers in Refugee Resettlement Contexts},
issn = {0898-5898},
doi = {https://doi.org/10.1016/j.linged.2022.101030},
url = {https://www.sciencedirect.com/science/article/pii/S0898589822000195},
author = {Eric Patrick Ambroso},
keywords = {Refugee education, Language ideologies, Language policy, Structured English immersion, Education in resettlement contexts},
abstract = {In the United States, where the instruction of students from refugee backgrounds (SRBs) is generally guided by each state's language policy, English as a second language (ESL) teachers play an especially important role in SRBs’ educational experiences (Mthethwa-Sommers & Kisiara, 2015). Yet, while there is a scarcity of research on SRBs’ academic experiences (Koyama & Bakuza, 2017), even less has been written about teachers working with this student population (Roxas, 2011). In this year-long, ethnographic case study, I examine how teachers’ language ideologies shape their implementation of Structured English Immersion (SEI), the official language policy in the state of Arizona. I consider the experiences of teachers (n = 3) and SRBs (n = 32) in three different classrooms, which serve as the units of analysis. The participating SRBs, who made up at least 60% of the selected classrooms, came from a wide variety of home countries and spoke a combined 15 different home languages. Findings highlight the link between language ideologies and the implementation (or appropriation) of authorized language policy.}
}
@article{WEYNS2025103242,
title = {Explainable knowledge graph embeddings for industrial process monitoring & control},
journal = {Information Fusion},
volume = {123},
pages = {103242},
year = {2025},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2025.103242},
url = {https://www.sciencedirect.com/science/article/pii/S156625352500315X},
author = {Michael Weyns and Thibault Blyau and Bram Steenwinckel and Filip {De Turck} and Sofie {Van Hoecke} and Femke Ongenae},
keywords = {Knowledge graph, Knowledge graph embedding, Process monitoring, Process control, Industry 4.0, Hybrid AI, XAI},
abstract = {AI-driven solutions are being employed in process monitoring and control to learn typical system behaviours under various conditions based on historical data. However, they are unable to take advantage of the rich, tacit domain expertise of experienced process engineers pertaining to these behaviours. Hybrid AI solutions are designed to fuse domain knowledge into machine learning models, but have so far been limited to specific industrial subdomains or applications and support only domain expertise in the form of equations. We propose an explainable hybrid AI methodology that can integrate any kind of tacit knowledge in an interpretable manner. First, we introduce a method to consolidate process data and domain-specific expertise in a generic fashion using Knowledge Graphs. Second, we propose a Knowledge Graph transformation technique to better capture the sequential aspects of a process and an accompanying white-box Knowledge Graph embedding technique that allows us to integrate domain knowledge directly into the feature space of a data-driven model. Third, we show how our methodology can be combined with explainability techniques, such as SHAP, to highlight directly in the graph which paths contributed most to the AI-driven decision. Our methodology has been evaluated on two real-world chemical engineering use cases. It outperforms data-driven baselines on all performance metrics, with average improvements of up to 8.57% and 10.21%.}
}
@article{LI2018317,
title = {Integrating geometric models, site images and GIS based on Google Earth and Keyhole Markup Language},
journal = {Automation in Construction},
volume = {89},
pages = {317-331},
year = {2018},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2018.02.002},
url = {https://www.sciencedirect.com/science/article/pii/S0926580517303333},
author = {Duanshun Li and Ming Lu},
keywords = {Information, Integration, Visualization, Augmented reality, Google earth, KML},
abstract = {Technologies for information management and visualization are instrumental in enhancing human perceptions and interpretations of complicated project information. 3D/4D modeling, Virtual Reality (VR), Building Information Models (BIM) and Geographical Information Systems (GIS) have been increasingly used for data management and analytics in construction. Apart from virtual models, it is essential to represent the ever-changing site reality by integrating images captured with drones, mobile devices, and digital cameras. To improve the cognitive perception of the site environment from fragmented datasets, this paper proposes a framework to integrate unordered images, geometric models and surrounding environment in Google Earth using Keyhole Markup Language (KML). A ground-control-free methodology to geo-reference sequential aerial imageries and ground imageries is proposed in order to place unordered images into the physical coordinate system of Google Earth. To combine geometric models, site images and panoramic images with the site surrounding environment in 3D GIS, a KML and cloud storage based data management system is conceptualized to handle large scale datasets. The research provides construction engineers with a low-cost and low-technology-barrier solution to represent a dynamic construction site through information management, integration and visualization.}
}
@article{RATHORE2024108926,
title = {ToxinPred 3.0: An improved method for predicting the toxicity of peptides},
journal = {Computers in Biology and Medicine},
volume = {179},
pages = {108926},
year = {2024},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2024.108926},
url = {https://www.sciencedirect.com/science/article/pii/S0010482524010114},
author = {Anand Singh Rathore and Shubham Choudhury and Akanksha Arora and Purva Tijare and Gajendra P.S. Raghava},
keywords = {Toxic motifs, Virtual screening, Machine learning, Deep learning, Large language models, Ensemble/hybrid method},
abstract = {Toxicity emerges as a prominent challenge in the design of therapeutic peptides, causing the failure of numerous peptides during clinical trials. In 2013, our group developed ToxinPred, a computational method that has been extensively adopted by the scientific community for predicting peptide toxicity. In this paper, we propose a refined variant of ToxinPred that showcases improved reliability and accuracy in predicting peptide toxicity. Initially, we utilized a similarity/alignment-based approach employing BLAST to predict toxic peptides, which yielded satisfactory accuracy; however, the method suffered from inadequate coverage. Subsequently, we employed a motif-based approach using MERCI software to uncover specific patterns or motifs that are exclusively observed in toxic peptides. The search for these motifs in peptides allowed us to predict toxic peptides with a high level of specificity with poor sensitivity. To overcome the coverage limitations, we developed alignment-free methods using machine/deep learning techniques to balance sensitivity and specificity of prediction. Deep learning model (ANN - LSTM with fixed sequence length) developed using one-hot encoding achieved a maximum AUROC of 0.93 with MCC of 0.71 on an independent dataset. Machine learning model (extra tree) developed using compositional features of peptides achieved a maximum AUROC of 0.95 with MCC of 0.78. We also developed large language models and achieved maximum AUC of 0.93 using ESM2-t33. Finally, we developed hybrid or ensemble methods combining two or more methods to enhance performance. Our specific hybrid method, which combines a motif-based approach with a machine learning-based model, achieved a maximum AUROC of 0.98 with MCC 0.81 on an independent dataset. In this study, all models were trained and tested on 80 % of data using five-fold cross-validation and evaluated on the remaining 20 % of data called independent dataset. The evaluation of all methods on an independent dataset revealed that the method proposed in this study exhibited better performance than existing methods. To cater to the needs of the scientific community, we have developed a standalone software, pip package and web-based server ToxinPred3 (https://github.com/raghavagps/toxinpred3 and https://webs.iiitd.edu.in/raghava/toxinpred3/).}
}
@article{RIVEIRO2025103767,
title = {Editorial: EG-ICE workshop 2024: data and intelligent methods for engineering the built environment},
journal = {Advanced Engineering Informatics},
pages = {103767},
year = {2025},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2025.103767},
url = {https://www.sciencedirect.com/science/article/pii/S1474034625006603},
author = {Belén Riveiro and Pedro Arias-Sánchez}
}
@incollection{DENICOLA2022129,
title = {Chapter 7 - Toward a knowledge graph for medical diagnosis: issues and usage scenarios},
editor = {Sanju Tiwari and Fernando {Ortiz Rodriguez} and M.A. Jabbar},
booktitle = {Semantic Models in IoT and eHealth Applications},
publisher = {Academic Press},
pages = {129-142},
year = {2022},
series = {Intelligent Data-Centric Systems},
isbn = {978-0-323-91773-5},
doi = {https://doi.org/10.1016/B978-0-32-391773-5.00013-3},
url = {https://www.sciencedirect.com/science/article/pii/B9780323917735000133},
author = {Antonio {De Nicola} and Rita Zgheib and Francesco Taglino},
keywords = {Knowledge graph, Ontology, Medical diagnosis, Healthcare},
abstract = {The healthcare industry faces many challenges like demand for high-quality remote services, especially when pandemics like COVID-19 spread across a region or even all over the world. Due to these challenges, healthcare providers are adopting innovative technologies to build new systems with enhanced automation for disease detection and assistance. For instance, a system able to support medical doctors to detect potential diseases when analyzing symptoms of a patient can help to treat the patient in a quicker and more effective manner, e.g., by routing her/him to the right specialist. Diagnostic systems need a significant amount of background knowledge in the medical sector, which can be enhanced by using semantics for knowledge representation, sharing, information integration and extraction, and reasoning. To this purpose, we propose a knowledge graph for medical diagnosis leveraging existing largely used standards and ontologies and we present the main issues in aligning them. Then we describe some usage scenarios for the knowledge graph. In detail, the knowledge graph for medical diagnosis encompasses SNOMED CT, ICD-10-CM, and DOID ontology.}
}
@article{ZHANG2022333,
title = {Screening of genes related to breast cancer prognosis based on the DO-UniBIC method},
journal = {The American Journal of the Medical Sciences},
volume = {364},
number = {3},
pages = {333-342},
year = {2022},
issn = {0002-9629},
doi = {https://doi.org/10.1016/j.amjms.2022.04.022},
url = {https://www.sciencedirect.com/science/article/pii/S0002962922001872},
author = {Fan Zhang and Yawei Zhang and Tingting Hou and Fangtao Ren and Xi Liu and Runan Zhao and Xinhong Zhang},
keywords = {Breast cancer, Prognosis, Differentially expressed gene, DO-UniBIC},
abstract = {Background
Early screening is the most effective way to control breast cancer. Due to the lack of accurate biomarkers, early diagnosis of breast cancer is still very difficult. Therefore, it is necessary to discover new candidate genes of breast cancer and improve the early diagnosis and prognosis.
Methods
A DO-UniBIC gene screening method was proposed. First, Disease Ontology (DO) analysis was used to screen out breast cancer related genes from differentially expressed genes, and then the UniBIC algorithm was used to find all gene clusters with the same changing trend based on the longest common subsequence. In addition, an eight-gene prognostic model was constructed to assess the prognostic risk of breast cancer patients.
Results
The prognostic analysis of the candidate genomes based on multivariate Cox proportional regression model revealed eight genes that were significantly related to prognosis. The eight genes were ACSL1, CD24, EMP1, JPH3, CAMK4, JUN, S100B and TP53AIP1. Among them, ACSL1 was a new potential breast cancer related gene screened by the DO-UniBIC method.
Conclusions
More comprehensive cancer-related genes can be screened based on the DO-UniBIC method, which can be used as the candidate gene set for prognostic analysis.}
}
@article{TAMBORINI2025100116,
title = {The ethics of bioinspired animal-robot interaction: A relational meta-ethical approach},
journal = {Journal of Responsible Technology},
volume = {22},
pages = {100116},
year = {2025},
issn = {2666-6596},
doi = {https://doi.org/10.1016/j.jrt.2025.100116},
url = {https://www.sciencedirect.com/science/article/pii/S2666659625000125},
author = {Marco Tamborini},
keywords = {Biorobotics, Bio-hybrid, Robot-animal, Metaethics, Technological deception, Philosophy of technology},
abstract = {In this article, I focus on a specific aspect of biorobotics: biohybrid interaction between bioinspired robots and animals. My goal is to analyze the ethical and epistemic implications of this practice, starting with a central question: Is it ethically permissible to have a bioinspired robot that mimics and reproduces the behaviors and/or morphology of an animal interact with a particular population, even if the animals do not know that the object they are interacting with is a robot and not a conspecific? My answer to the ethical question is that the interaction between animals and bioinspired robots is ethically acceptable if the animal actively participates in the language game (sense Coeckelbergh) established with the robot. I proceed as follows: First, I define the field of biorobotics and describe its four macro-categories. Second, I present concrete examples of interactive biorobotics, showing two emblematic cases in which the relationship between bioinspired robots and animals plays a central role. Third, I address one key issue—among many—in applied ethics regarding my ethical question. Fourth, I explore the ethical question on a metaethical level, making use of the theories of David Gunkel and Mark Coeckelbergh, as well as the linguistic approach and ethics of the late Ludwig Wittgenstein. Last, I argue that from a meta-ethical approach the original ethical question turns out to be misplaced. The ethical boundary lies not in the distinction between a real or fake relationship between the robot and the organism, but in the degree of mutual participation and understanding between the entities involved.}
}
@article{JO2025105283,
title = {Application of artificial intelligence in the advancement of sensory evaluation of food products},
journal = {Trends in Food Science & Technology},
pages = {105283},
year = {2025},
issn = {0924-2244},
doi = {https://doi.org/10.1016/j.tifs.2025.105283},
url = {https://www.sciencedirect.com/science/article/pii/S0924224425004194},
author = {Du-Min Jo and Seo-Jin Han and Seok-Chun Ko and Kyung Woo Kim and Dongwoo Yang and Ji-Yul Kim and Gun-Woo Oh and Grace Choi and Dae-Sung Lee and Nazia Tabassum and Young-Mog Kim and Fazlurrahman Khan},
keywords = {Artificial Intelligence, Sensory analysis, Food products, Machine and Deep Learning, Flavor and Texture Analysis},
abstract = {Background
Artificial intelligence (AI) is increasingly being integrated into sensory evaluation in food science to overcome limitations of traditional methods such as subjectivity, variability, and dependence on human panels. By incorporating data from chemical analysis, imaging, and consumer feedback, AI enables more objective, reproducible, and scalable assessments of sensory attributes, including taste, aroma, texture, and appearance.
Scope and approach
This review provides a comprehensive overview of AI applications in the sensory evaluation of food products. It includes key AI technologies, such as machine learning, computer vision, natural language processing, and intelligent sensors, and their roles in predicting, simulating, and personalizing sensory attributes. AI transformations of sensory analysis through data-driven modeling, multimodal integration, and digital simulation are highlighted. Additionally, ethical and technical challenges associated with the adoption of AI in sensory science are addressed.
Key findings and conclusions
AI enables advanced modeling of human sensory perception by linking analytical data with consumer sensory responses. Machine learning and deep learning facilitate predictive analysis of sensory traits; computer vision and e-sensing technologies replicate human visual and chemical perception; and natural language processing provides insights from consumer-generated content. These technologies also support real-time, personalized sensory experiences. While AI presents powerful tools for innovation in food design and evaluation, issues such as data quality, model transparency, and ethical use must be addressed. This review emphasizes the need for interdisciplinary collaboration to ensure inclusive, explainable, and human-centered development of AI-based sensory systems.}
}
@article{IOANNOU201885,
title = {Constructions and image-schema preservation. A historical-comparative analysis of PAY in Greek and English},
journal = {Lingua},
volume = {206},
pages = {85-111},
year = {2018},
issn = {0024-3841},
doi = {https://doi.org/10.1016/j.lingua.2018.02.001},
url = {https://www.sciencedirect.com/science/article/pii/S0024384117304631},
author = {Georgios Ioannou},
keywords = {Image-schemas, Semantic frames, Constructions, Invariance hypothesis, Semantic change},
abstract = {This is a corpus-based comparative analysis of aspects of the evolution of the terms plirono and pay in Greek and English, respectively, both meaning PAY. It is based on a manual coding of the extant instances of the Greek verb from 6th c. BCE to 3rd c. CE, and 340 instances of the English verb from 13th c. to 15th c. CE. It is grounded on the hypothesis that the image-schematic gestalts immanent to the conceptualisations of linguistically coded terms are preserved through semantic extension, otherwise known as invariance principle. It identifies and compares some constraints that the distinct image-schematic origins of plirono and pay have imposed onto the semantic evolution of the terms. It is argued that the image-schemas underlying the conceptual constitution of them are these of CONTAINER and BALANCE, respectively. Consequently, a comparison follows between the terms, regarding two aspects: the semantic listing of elements within their frame-semantic structure, on the one hand, and the grammatically expressed constructional encoding of these elements, on the other. Subsequently, some asymmetries found between the terms’ constructional paradigms are related to the constraints imposed on their evolutionary paths by the underlying image-schematic structure. Conclusively, it is shown that, although the situational ontologies may appear identical in terms of the semantic listing of their frame-semantic elements, the perspectival construal over these ontologies is distinct. Entrenched grammatical realisation constitutes a second level of perspectivisation over the conceptual make-up of a frame.}
}
@article{NYAMATHI2024,
title = {Establishing the Foundations of Emotional Intelligence in Care Companion Robots to Mitigate Agitation Among High-Risk Patients With Dementia: Protocol for an Empathetic Patient-Robot Interaction Study},
journal = {JMIR Research Protocols},
volume = {13},
year = {2024},
issn = {1929-0748},
doi = {https://doi.org/10.2196/55761},
url = {https://www.sciencedirect.com/science/article/pii/S1929074824004803},
author = {Adeline Nyamathi and Nikil Dutt and Jung-Ah Lee and Amir M Rahmani and Mahkameh Rasouli and Donna Krogh and Erik Krogh and David Sultzer and Humayun Rashid and Hamza Liaqat and Riyam Jawad and Farhan Azhar and Ali Ahmad and Bilal Qamar and Taha Yasin Bhatti and Chet Khay and Jocelyn Ludlow and Lisa Gibbs and Julie Rousseau and Mahyar Abbasian and Yutong Song and Cheonkam Jeong and Sabine Brunswicker},
keywords = {persons with dementia, empathy-based care companion robot, agitation, fall risk, artificial intelligence, AI},
abstract = {Background
An estimated 6.7 million persons are living with dementia in the United States, a number expected to double by 2060. Persons experiencing moderate to severe dementia are 4 to 5 times more likely to fall than those without dementia, due to agitation and unsteady gait. Socially assistive robots fail to address the changing emotional states associated with agitation, and it is unclear how emotional states change, how they impact agitation and gait over time, and how social robots can best respond by showing empathy.
Objective
This study aims to design and validate a foundational model of emotional intelligence for empathetic patient-robot interaction that mitigates agitation among those at the highest risk: persons experiencing moderate to severe dementia.
Methods
A design science approach will be adopted to (1) collect and store granular, personal, and chronological data using Personicle (an open-source software platform developed to automatically collect data from phones and other devices), incorporating real-time visual, audio, and physiological sensing technologies in a simulation laboratory and at board and care facilities; (2) develop statistical models to understand and forecast the emotional state, agitation level, and gait pattern of persons experiencing moderate to severe dementia in real time using machine learning and artificial intelligence and Personicle; (3) design and test an empathy-focused conversation model, focused on storytelling; and (4) test and evaluate this model for a care companion robot (CCR) in the community.
Results
The study was funded in October 2023. For aim 1, architecture development for Personicle data collection began with a search for existing open-source data in January 2024. A community advisory board was formed and met in December 2023 to provide feedback on the use of CCRs and provide personal stories. Full institutional review board approval was received in March 2024 to place cameras and CCRs at the sites. In March 2024, atomic marker development was begun. For aim 2, after a review of open-source data on patients with dementia, the development of an emotional classifier was begun. Data labeling was started in April 2024 and completed in June 2024 with ongoing validation. Moreover, the team established a baseline multimodal model trained and validated on healthy-person data sets, using transformer architecture in a semisupervised manner, and later retrained on the labeled data set of patients experiencing moderate to severe dementia. In April 2024, empathy alignment of large language models was initiated using prompt engineering and reinforcement learning.
Conclusions
This innovative caregiving approach is designed to recognize the signs of agitation and, upon recognition, intervene with empathetic verbal communication. This proposal has the potential to have a significant impact on an emerging field of computational dementia science by reducing unnecessary agitation and falls of persons experiencing moderate to severe dementia, while reducing caregiver burden.
International Registered Report Identifier (IRRID)
PRR1-10.2196/55761}
}
@article{PARENT2023103014,
title = {Imagining an agrarian future in rural Rwanda: Evidence from Congolese refugees at Mahama camp},
journal = {Journal of Rural Studies},
volume = {100},
pages = {103014},
year = {2023},
issn = {0743-0167},
doi = {https://doi.org/10.1016/j.jrurstud.2023.103014},
url = {https://www.sciencedirect.com/science/article/pii/S0743016723000803},
author = {Nicolas Parent},
keywords = {Refugees, Land and peace, Rural futurity, Utopia, Critical agrarian studies, Rwanda},
abstract = {Congolese refugees in Rwanda constitute one of the most protracted displaced populations in the world. As durable solutions remain evasive, this article presents Congolese’ own vision for life beyond the camp. Wanting to return to peasantry, their utopian agrarian landscape is articulated as an intentional community where subsistence and autonomy exist within a common property space shared peacefully with now-landless Rwandans. By exploring the archaeologies and ontologies that lay the architectural foundations of this utopia, key assumptions are subverted – notably, that refugees in protracted exile have a limited sense of futurity, and that their return to land within rural Rwanda would necessarily lead to conflict.}
}
@article{YU202520,
title = {Rescheduling human-robot collaboration tasks under dynamic disassembly scenarios: An MLLM-KG collaboratively enabled approach},
journal = {Journal of Manufacturing Systems},
volume = {80},
pages = {20-37},
year = {2025},
issn = {0278-6125},
doi = {https://doi.org/10.1016/j.jmsy.2025.02.015},
url = {https://www.sciencedirect.com/science/article/pii/S0278612525000445},
author = {Weigang Yu and Jianhao Lv and Weibin Zhuang and Xinyu Pan and Sijie Wen and Jinsong Bao and Xinyu Li},
keywords = {Human–robot collaboration disassembly, Multimodal large language model, Knowledge Graph, Task rescheduling, Scenario perception},
abstract = {During product recycling, the uncertainty of the degradation level of end-of-life products leads to dynamic conditions such as component corrosion and damage during the disassembly process. Therefore, enhancing the robot's perception of disassembly scenarios and matching historical disassembly experiences is crucial for task rescheduling in human-robot collaborative disassembly (HRCD) under dynamic conditions. To address this, this paper proposes a dynamic task rescheduling method for human-robot collaborative disassembly, empowered by the synergy of Knowledge Graph (KG) and Multimodal Large Language Model (MLLM). Leveraging a Mark-Aware image preprocessing module and prompt-based scene understanding, the physical characteristics and occlusion relationships of disassembly targets are extracted. The concept of affordance is introduced, and an Affordance KG is constructed to recommend disassembly actions based on the physical features of objects in the scene. A task allocation standard for human-robot collaboration is designed, which, combined with depth and human factor information from mixed reality scenarios, enables dynamic task rescheduling and reconstruction of the entire human-robot collaborative disassembly process. The proposed method is validated through a case study on human-robot collaborative disassembly of end-of-life automotive lithium-ion batteries. Experimental results demonstrate that the method exhibits strong robustness and generalizability in dynamic disassembly scenarios, accurately identifying the physical features of components and recommending appropriate disassembly actions under conditions such as component corrosion, damage, and tool unavailability, thus achieving effective task rescheduling.}
}
@article{DENICOLA201921,
title = {Creative design of emergency management scenarios driven by semantics: An application to smart cities},
journal = {Information Systems},
volume = {81},
pages = {21-48},
year = {2019},
issn = {0306-4379},
doi = {https://doi.org/10.1016/j.is.2018.10.005},
url = {https://www.sciencedirect.com/science/article/pii/S0306437918304277},
author = {Antonio {De Nicola} and Michele Melchiori and Maria Luisa Villani},
keywords = {Computational creativity, Conceptual modeling, Design pattern, Emergency management, Ontology, Smart city},
abstract = {We present a framework to support creative design of emergency management scenarios. By creative design of scenarios we mean the process of imagining situations and describing them through models and stories. The framework supports the tasks of gathering and organizing knowledge about emergency management situations by automatically generating conceptual models, related to fragments of emergency scenarios. It leverages semantics-based techniques to enable a computational creativity approach. A software application was defined to support the activities of modeling scenarios by permitting to generate, organize, and query sets of these conceptual models, which we name mini-stories, and that can be adopted to inspire the activity of creative design. Selected mini-stories are blueprints for more detailed user scenario descriptions and models that can be used, for instance, for analysis or simulation. As a case study, we consider emergency management in smart cities. This is a challenging domain because smart cities are characterized by interconnected physical and virtual services forming complex ecosystems, which provide sophisticated services to the population and to institutions, manage public resources in a optimal way, and involve citizens in decisional processes. As a consequence, smart city ecosystems can be threatened by several hazards spanning from natural disasters, as tsunami and earthquakes, to anthropic events, as terrorist attacks. Ability of service providers and institutional operators to face and manage emergency situations is therefore a relevant issue. Simulation and analysis of both crisis events and executions of management plans are a promising approach to deal with these articulated problems. However, manual definition of models to base the analysis is a demanding activity due to the huge number of different situations to consider. It requires knowledge related to the crisis and emergency domains, to the context (e.g., a specific city and its current regulations) and ability in modeling tasks. All these aspects demand for tools to support modeling activities, and our proposal aims at fulfilling this need. In particular, the discussed framework uses in a integrated way three types of knowledge: structural knowledge, to support the construction of models based on design patterns; domain knowledge, here related to smart cities and emergency management and represented by means of ontologies; and contextual knowledge, related to specific aspects (e.g., localization) of the considered scenario and represented as rules. We validated the presented approach by means of experiments performed by real city planners.}
}
@article{LI2024101038,
title = {One-stop multi-sensor fusion and multimodal precise quantified traditional Chinese medicine imaging health examination technology},
journal = {Journal of Radiation Research and Applied Sciences},
volume = {17},
number = {4},
pages = {101038},
year = {2024},
issn = {1687-8507},
doi = {https://doi.org/10.1016/j.jrras.2024.101038},
url = {https://www.sciencedirect.com/science/article/pii/S168785072400222X},
author = {Chuanxue Li and Ping Wang and Meifang Zheng and Wenxiang Li and Jun Zhou and Lin Fu},
keywords = {Traditional Chinese medicine imaging, Large language model, Knowledge graphs, Multimodal imaging, Health examination technology, Image fusion, Imaging agent, Deep learning},
abstract = {Except for single-mode traditional Chinese medicine imaging techniques such as infrared thermal imaging, the one-stop multimodal whole-body imaging health examination technology and device is still blank. We focus on infrared thermal imaging as the main modality, integrated various modalities of medical imaging intelligent sensing agents such as terahertz imaging. The upper and lower computer and virtual instrument architecture are used, and the imaging data are collected by the lower computers that each is an intelligent sensing agent. The upper computer is used for image reconstruction with intelligent algorithms. Based on the core theory of traditional Chinese medicine, intelligent fusion imaging is achieved through various modalities to achieve the ‘observation, hearing, questioning, and palpation’ four diagnostic integration. We use fractional Fourier transform to filter imaging data, Laplacian pyramid for image fusion. We have proposed an implementation method and process for combining traditional Chinese medicine imaging large language model with knowledge graph, and based on deep learning, we have studied the image and report generation algorithm that combines traditional Chinese medicine pathology and four diagnostic methods with knowledge graph fusion, as well as the traditional Chinese medicine human physiological and pathological interpretation and evaluation system. We have achieved some results, and through further research and development, we can achieve commercial applications.}
}
@article{RANATHUNGA2024100733,
title = {Enabling secure and self-sovereign machine learning model exchange in manufacturing data spaces},
journal = {Journal of Industrial Information Integration},
volume = {42},
pages = {100733},
year = {2024},
issn = {2452-414X},
doi = {https://doi.org/10.1016/j.jii.2024.100733},
url = {https://www.sciencedirect.com/science/article/pii/S2452414X24001766},
author = {Tharindu Ranathunga and Alan McGibney and Sourabh Bharti},
keywords = {Data spaces, Transfer learning, Self sovereignty, Energy efficiency, Semantic interoperability},
abstract = {With the rapid digital transformation of manufacturing, vast amounts of data are being generated and analyzed to uncover valuable patterns in areas such as energy efficiency, predictive maintenance, production scheduling etc. However, much of this data and the intelligence derived from it remain isolated within individual companies. This is strongly influenced by companies reluctance to share data due to concerns over privacy and security associated with the commercially sensitive information. As a result, the potential shared value that can be derived from a richer, larger pool of data and intelligence across multiple companies remains untapped. While solutions such as federated learning exist to address privacy and security issues, strong governance so that the privacy is preserved is crucial to its successful implementation. Currently, there is a lack of software infrastructure that guarantees data sovereignty and governance for data owners in this space. This paper introduces COllaboRative Data Space (CORDS), a framework that enables companies to engage in a machine learning model-sharing ecosystem, providing full control over the access and usage of their data. Aligned with the European Data Space initiative, CORDS aims to foster trusted collaboration by providing a software infrastructure constituting a set of tools for both intra and inter-organization data asset management and ML model exchange. To the best of our knowledge, CORDS is the first minimum viable data space (MVDS) designed to address the broader challenges of sovereignty, interoperability, compliance & governance in cross-party ML model sharing. This paper also highlights the value of data sharing by applying CORDS to a use-case focused on improving energy efficiency in manufacturing. Extensive performance evaluation showcases CORDS’ utility in securely managing data assets and facilitating machine learning model exchanges. CORDS is available as open-source software, supporting further research and practical applications of trusted data spaces in both academia and industry.}
}
@article{BUCHE2021,
title = {How to Manage Incompleteness of Nutritional Food Sources?},
journal = {International Journal of Agricultural and Environmental Information Systems},
volume = {12},
number = {4},
year = {2021},
issn = {1947-3192},
doi = {https://doi.org/10.4018/IJAEIS.20211001.oa4},
url = {https://www.sciencedirect.com/science/article/pii/S1947319221000046},
author = {Patrice Buche and Julien Cufi and Stéphane Dervaux and Juliette Dibie and Liliana Ibanescu and Alrick Oudot and Magalie Weber},
keywords = {ANSES, Background Knowledge, Food Composition Databases, FoodOn, Incompleteness Management, LanguaL, Ontology Alignment, Ontology Building, USDA},
abstract = {ABSTRACT
In order to correctly assess the nutritional quality of a raw or manufactured food product, the first step is to obtain the associated nutritional values. Food composition databases (FCDBs) managed at national level provide values for nutrients of foods. Unfortunately, values associated with some nutrients of interest may be lacking in the FCDB of the country in which the nutritional quality must be assessed, and finding values associated with nutrients for similar foods in other FCDBs is a way to deal with incompleteness. An additional issue arises because the vocabulary used to denote a given food in a given FCDB is usually different from the one used in others. In this paper, the authors address the problem of retrieving the nutritional value of foods by querying different FCDBs through FoodOn used as pivot ontology. The article presents a new food source alignment method between two FCDBs. The method has been evaluated on the French and United States food nutritional evaluation. The proposed solution for the incompleteness management task has been assessed with a real use case.}
}
@article{NUYTS2024102443,
title = {Comparative analysis of approaches for automated compliance checking of construction data},
journal = {Advanced Engineering Informatics},
volume = {60},
pages = {102443},
year = {2024},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2024.102443},
url = {https://www.sciencedirect.com/science/article/pii/S1474034624000910},
author = {Emma Nuyts and Mathias Bonduel and Ruben Verstraeten},
keywords = {Automated compliance checking, Building information management, Comparative analysis},
abstract = {While the domain of Automated Compliance Checking (ACC) has gained track, the construction industry has been flooded with different approaches. This paper studies these different approaches for use in compliance checking of construction data. The approaches are compared by defining constraints for the same set of five requirements, each of a different category, stemming from the Flemish building regulation on accessibility. Eight approaches have been selected for comparison: two IFC-based approaches (Solibri Model Checker and the upcoming buildingSMART standard IDS), two general data standards and their accompanying schema definition languages (JSON Schema and XSD), and four Linked Data approaches (OWL, SWRL, SPARQL, and SHACL). Besides the pure functional analysis, the relative uptake and support in tooling are also considered. While XML/XSD and JSON/JSON Schema and the Linked Data approaches are in essence domain-independent, only the latter has an extra layer for agreeing on high-level data modeling (and thus data validation) patterns in the construction domain with the EN17632-1:2022 standard. SHACL is considered the most adept method from the Linked Data approaches since it is fully standardized for both inputs and outputs and was developed for validation use cases.}
}
@article{GULATI2019101869,
title = {Towards socially enabled internet of industrial things: Architecture, semantic model and relationship management},
journal = {Ad Hoc Networks},
volume = {91},
pages = {101869},
year = {2019},
issn = {1570-8705},
doi = {https://doi.org/10.1016/j.adhoc.2019.101869},
url = {https://www.sciencedirect.com/science/article/pii/S157087051830194X},
author = {Nancy Gulati and Pankaj Deep Kaur},
keywords = {Internet of things, Social internet of things, Industrial internet of things, Social asset, Relationship management, Asset performance management},
abstract = {The progression of Internet of Things (IoT) has culminated from merely communicating objects towards smart objects. Furthermore, the widespread adoption of social networking is leading us into a new era of social objects. Under this vision, the idea of Social Internet of Things (SIoT) involving integration of social networking concepts into IoT was carved. Also, in the past few years application of IoT technologies into industry termed as Industrial Internet of Things (IIoT) has gained significant attention worldwide. This paper examines the major opportunities emerging from the introduction of novel concept of SIoT into manufacturing industry along with proposing reference architecture for the same. The proposed architecture is explored from a semantic point of view and an ontological model is designed. In addition, a novel approach for relationship management among manufacturing resources (assets) has been introduced. Further, to support the theoretical framework, a use case scenario and a simulation model for the performance management of an automated bottle filling industrial plant has been designed. The proposed model is certain to serve as a solid foundation for the future development of industrial IoT applications by researchers and developers.}
}
@article{KARTHIKA2024,
title = {Semantic-Rich Recommendation System for Medical Emergency Response System},
journal = {International Journal on Semantic Web and Information Systems},
volume = {20},
number = {1},
year = {2024},
issn = {1552-6283},
doi = {https://doi.org/10.4018/IJSWIS.341231},
url = {https://www.sciencedirect.com/science/article/pii/S1552628324001194},
author = {R. Karthika and L. Jegatha Deborah and Wenying Zheng and Fayez Alqahtani and Amr Tolba and B. Gokula Krishnan and Ritika Bansal},
keywords = {Business Process Composition, Emergency Response Processes, Emergency Management Ontology, Knowledge-Centric Business Processes, Process Evolution},
abstract = {ABSTRACT
The emergency response process consists of methodical and coordinated series of actions and protocols executed by individuals and organizations to proficiently address crises. When planning for medical emergencies, it is vital to work with responsive medical organizations to ensure good communication and coordination. Unlike e-government processes, emergency response processes are focused on knowledge and may frequently change as the emergency situation develops. It is important to change the emergency response plan for dynamic situations and the proposed method helps to create a flexible plan for emergency responses. The proposed approach uses a system for organizing knowledge to figure out the needs and the resources essential for an emergency. It helps to identify the organizations to be involved based on their rules for mutual aid and jurisdiction. Experimental analysis shows that the proposed method outperforms Smart-c and DCERP in suggesting a greater number of hospitals during medical emergency and achieves 0.8, 0.9 and 0.9 precision, recall, and f-measure approximately.}
}
@article{BABAIAN2024114172,
title = {Entity recognition from colloquial text},
journal = {Decision Support Systems},
volume = {179},
pages = {114172},
year = {2024},
issn = {0167-9236},
doi = {https://doi.org/10.1016/j.dss.2024.114172},
url = {https://www.sciencedirect.com/science/article/pii/S0167923624000058},
author = {Tamara Babaian and Jennifer Xu},
keywords = {Entity recognition, Symptom recognition, Natural language processing, Training strategies, Design science},
abstract = {Extraction of concepts and entities of interest from non-formal texts such as social media posts and informal communication is an important capability for decision support systems in many domains, including healthcare, customer relationship management, and others. Despite the recent advances in training large language models for a variety of natural language processing tasks, the developed models and techniques have mainly focused on formal texts and do not perform as well on colloquial data, which is characterized by a number of distinct challenges. In our research, we focus on the healthcare domain and investigate the problem of symptom recognition from colloquial texts by designing and evaluating several training strategies for BERT-based model fine-tuning. These strategies are distinguished by the choice of the base model, the training corpora, and application of term perturbations in the training data. The best-performing models trained using these strategies outperform the state-of-the-art specialized symptom recognizer by a large margin. Through a series of experiments, we have found specific patterns of model behavior associated with the training strategies we designed. We present design principles for training strategies for effective entity recognition in colloquial texts based on our findings.}
}
@article{LATIF2023111825,
title = {Pragmatic evidence of cross-language link detection: A systematic literature review},
journal = {Journal of Systems and Software},
volume = {206},
pages = {111825},
year = {2023},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2023.111825},
url = {https://www.sciencedirect.com/science/article/pii/S0164121223002200},
author = {Saira Latif and Zaigham Mushtaq and Ghulam Rasool and Furqan Rustam and Naila Aslam and Imran Ashraf},
keywords = {Software development, Reverse engineering, Multilingual source code, Cross-language link detection, Source code analysis, Cross-language dependencies, Multilingual software applications, Graph databases, Machine learning in software engineering, Software maintenance, Systematic literature review},
abstract = {There is a rising trend for heterogeneous software applications involving multilingual source code. The key focus of reverse engineers is to unravel the cross-language links (XLLs) and their dependencies. This study aims to perform a systematic literature review (SLR) to compile different approaches, tools, techniques, and shortcomings of such techniques and understand the XLLs and their dependencies while performing reverse engineering on state-of-the-art software applications. This SLR selects 76 primary studies and uses them to create a ’go-to’ literature database, where professionals from software engineering could find all the content pertinent to the analysis and XLL detection for major multilingual applications like Java enterprise applications, Android applications, etc. It has been observed that traditional source code analysis mechanisms to reverse engineer contemporary software applications face scores of problems and limitations that need to be addressed. To assist the community in the above-mentioned goal, a general schema with definitions of XLLs and associated concepts is furnished. This study provides an SLR on XLLs, comprehensive taxonomy called cross-language analysis, which incorporates all the methods for XLL detection in multilingual source code. By pursuing future directions suggested in the end, researchers and practitioners can advance the field of multilingual applications; such as Enterprise resource planning (ERP) solutions, and cross-language software corpora, leading to improved software development practices and better understanding of language interactions in multilingual environments. The research data provided in the survey presents a comprehensive analysis of the complexities involved in working with diverse programming languages and frameworks, offering valuable insights for language technology researchers, software developers, academics, and decision-makers. This integration will enable them to identify and manage dependencies across diverse languages, leading to more efficient and reliable multilingual software systems.}
}
@article{HU2022,
title = {Evaluation and Comparative Analysis of Semantic Web-Based Strategies for Enhancing Educational System Development},
journal = {International Journal on Semantic Web and Information Systems},
volume = {18},
number = {1},
year = {2022},
issn = {1552-6283},
doi = {https://doi.org/10.4018/IJSWIS.302895},
url = {https://www.sciencedirect.com/science/article/pii/S1552628322000333},
author = {Bin Hu and Akshat Gaurav and Chang Choi and Ammar Almomani},
keywords = {Artificial Intelligence, Big Data, E-Learning, Machine Learning, Ontology},
abstract = {ABSTRACT
Educators have been calling for reform for a decade. Recent technical breakthroughs have led to various improvements in the semantic web-based education system. After last year's COVID-19 outbreak, development quickened. Many countries and educational systems now concentrate on providing students with online education, which differs greatly from traditional classroom education. Online education allows students to learn at their own pace. As a consequence, education has become more dynamic. In the educational system, this changing nature makes user demands difficult to identify. Many instructors suggest using machine learning, artificial intelligence, or ontology to improve traditional teaching methods. Due to the lack of survey studies examining and comparing all of the researcher's semantic web-based teaching methodologies, the authors decided to conduct this survey. This paper's goal is to analyse all available possibilities for semantic web-based education systems that enable new researchers to develop their knowledge.}
}
@article{XU20221,
title = {Understanding language, intercultural competence and harmony from the Taoist philosophy: An investigation of an EU-exchange sail-training voyage},
journal = {International Journal of Intercultural Relations},
volume = {91},
pages = {1-12},
year = {2022},
issn = {0147-1767},
doi = {https://doi.org/10.1016/j.ijintrel.2022.08.007},
url = {https://www.sciencedirect.com/science/article/pii/S0147176722000980},
author = {Yujun Xu},
keywords = {Taoist philosophy, Intercultural competence, Dual Harmony of Intercultural Cultivation (DHIC), Sail-training},
abstract = {This paper presents a philosophical exploration for understanding language and intercultural competence from the Taoist philosophy, focusing on three Taoist concepts of Yin-Yang, He (harmony) and Sanbao (three-treasures). The philosophical insights were applied to an ethnographic study that was conducted to investigate the participants’ intercultural learning outcomes during an EU-exchange sail-training voyage across the North Sea. The sailing space enables convergence and interaction, minimises boundaries and fosters the co-construction of a sense of community. This paper acknowledges the complexity of dynamic and relation-oriented intercultural learning and communication, and proposes the concept of Dual Harmony of Intercultural Cultivation (DHIC), including the dual dimensions of personal harmony and relational harmony, based on the critical analysis of the interculturality in the sail-training context.}
}
@article{MALIK2020113120,
title = {Automated domain-specific healthcare knowledge graph curation framework: Subarachnoid hemorrhage as phenotype},
journal = {Expert Systems with Applications},
volume = {145},
pages = {113120},
year = {2020},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2019.113120},
url = {https://www.sciencedirect.com/science/article/pii/S0957417419308371},
author = {Khalid Mahmood Malik and Madan Krishnamurthy and Mazen Alobaidi and Maqbool Hussain and Fakhare Alam and Ghaus Malik},
keywords = {Knowledge Graph, Ontology, Electronic Health Records, Intracranial Aneurysm, Association Rules, Ensemble Learning, Subarachnoid Hemorrhage Stroke},
abstract = {To derive meaningful insights from voluminous healthcare data, it is essential to convert it into machine understandable knowledge. Currently, machine understandable domain specific healthcare knowledge curation framework does not exist for complex neurological diseases such as subarachnoid hemorrhage stroke. We envisage futuristic clinical decision support systems and tools backed with such knowledge will aide in complex neurological disease prognosis, diagnosis, and treatment. Existing knowledge graphs (KGs) only contain concepts and relationships between them and offer this knowledge to information extraction and knowledge management applications. However, the proposed domain-specific automated KG curation framework enables extraction of concepts, relationships, individual and cohort graphs, and predictive knowledge. By employing ontology-based information extraction, ensemble learning and word embedding based on skip-gram techniques on structured and unstructured data from electronic health records of 1025 patients with an intracranial aneurysm, this paper proposes a novel fully automated framework to curate knowledge graph, consisting of concepts, different hierarchical and non-hierarchical relationships, and predictive rules for prediction of subarachnoid hemorrhage. The evaluation shows that proposed framework achieves 78% precision and 71% recall respectively, for concept extraction from clinical text. Taxonomic relationships evaluation had precision and recall of 68%, and 95%, respectively. Evaluation of knowledge to predict unruptured status using validation dataset shows accuracy, precision, recall, of 73%, 76%, and 90% respectively.}
}
@article{CALABRO2025101557,
title = {CONCERN: A model-based monitoring infrastructure},
journal = {Internet of Things},
volume = {31},
pages = {101557},
year = {2025},
issn = {2542-6605},
doi = {https://doi.org/10.1016/j.iot.2025.101557},
url = {https://www.sciencedirect.com/science/article/pii/S2542660525000708},
author = {Antonello Calabrò and Eda Marchetti and Paweł Skrzypek and Jan Marchel},
keywords = {Monitoring, System engineering, Anomaly detection, Predictive maintenance},
abstract = {Characteristics such as quality, trustworthiness, and cybersecurity are becoming essential in the ecosystems of Internet of Things (IoT) systems. Although significant efforts in industry and academia have been made to create solutions that ensure, monitor, and evaluate these attributes throughout the development process, time-to-market urgency, demands for higher productivity, and competitive pressures often result in faster release schedules. This situation calls for methods and means to quickly and accurately identify and avert anomalies and hazardous circumstances. Among them, a monitoring system is an effective solution for evaluating functional and non-functional attributes during the online execution. This paper proposes an integrated Runtime Monitoring solution called CONCERN (COmplex eveNt proCEssing monitoR iNfrastructure) for guaranteeing a consistent quality of services, managing the possible execution exceptions and interruptions, and providing a high system availability. The paper describes the CONCERN supporting architecture and proof-of-concept implementation of its components, validation of the CONCERN usability, and its performance in a real scenario taken from the financial domain. Finally, the paper reports the discussion, lessons learned, and the future work suggested by the showcase.}
}
@article{RAMIREZDURAN2021103403,
title = {Towards the implementation of Industry 4.0: A methodology-based approach oriented to the customer life cycle},
journal = {Computers in Industry},
volume = {126},
pages = {103403},
year = {2021},
issn = {0166-3615},
doi = {https://doi.org/10.1016/j.compind.2021.103403},
url = {https://www.sciencedirect.com/science/article/pii/S0166361521000105},
author = {Víctor Julio Ramírez-Durán and Idoia Berges and Arantza Illarramendi},
keywords = {Industry 4.0, Customer life cycle, CAD, Ontology},
abstract = {Many different worldwide initiatives are promoting the transformation from machine dominant manufacturing to digital manufacturing. Thus, to achieve a successful transformation to Industry 4.0 standard, manufacturing enterprises are required to implement a clear roadmap. However, Small and Medium Manufacturing Enterprises (SMEs) encounter many barriers and difficulties (economical, technical, cultural, etc.) in the implementation of Industry 4.0. Although several works deal with the incorporation of Industry 4.0 technologies in the area of the product and supply chain life cycles, which SMEs could use as reference, this is not the case for the customer life cycle. Thus, we present two contributions that can help the software engineers of those SMEs to incorporate Industry 4.0 technologies in the context of the customer life cycle. The first contribution is a methodology that can help those software engineers in the task of creating new software services, aligned with Industry 4.0, that allow to change how customers interact with enterprises and the experiences they have while interacting with them. The methodology details a set of stages that are divided into phases which in turn are made up of activities. It places special emphasis on the incorporation of semantics descriptions and 3D visualization in the implementation of those new services. The second contribution is a system developed for a real manufacturing scenario, using the proposed methodology, which allows to observe the possibilities that this kind of systems can offer to SMEs in two phases of the customer life cycle: Discover & Shop, and Use & Service.}
}
@article{HU2025104640,
title = {Shades of zero: Distinguishing impossibility from inconceivability},
journal = {Journal of Memory and Language},
volume = {143},
pages = {104640},
year = {2025},
issn = {0749-596X},
doi = {https://doi.org/10.1016/j.jml.2025.104640},
url = {https://www.sciencedirect.com/science/article/pii/S0749596X25000336},
author = {Jennifer Hu and Felix Sosa and Tomer Ullman},
keywords = {Impossibility, Inconceivability, Modal reasoning, Language models, Event knowledge},
abstract = {Some things are impossible, but some things may be even more impossible than impossible. Levitating a feather using one’s mind is impossible in our world, but fits into our intuitive theories of possible worlds, whereas levitating a feather using the number five cannot be conceived in any possible world (“inconceivable”). While prior work has examined the distinction between improbable and impossible events, there has been little empirical research on inconceivability. Here, we investigate whether people maintain a distinction between impossibility and inconceivability, and how such distinctions might be made. We find that people can readily distinguish the impossible from the inconceivable, using categorization studies similar to those used to investigate the differences between impossible and improbable (Experiment 1). However, this distinction is not explained by people’s subjective ratings of event likelihood, which are near zero and indistinguishable between impossible and inconceivable event descriptions (Experiment 2). Finally, we ask whether the probabilities assigned to event descriptions by statistical language models (LMs) can be used to separate modal categories, and whether these probabilities align with people’s ratings (Experiment 3). We find high-level similarities between people and LMs: both distinguish among impossible and inconceivable event descriptions, and LM-derived string probabilities predict people’s ratings of event likelihood across modal categories. Our findings suggest that fine-grained knowledge about exceedingly rare events (i.e., the impossible and inconceivable) may be learned via statistical learning over linguistic forms, yet leave open the question of whether people represent the distinction between impossible and inconceivable as a difference not of degree, but of kind.}
}
@article{ZHANG2025103812,
title = {Multi-task hierarchical network for semantic understanding of air traffic controller-pilot communication},
journal = {Chinese Journal of Aeronautics},
pages = {103812},
year = {2025},
issn = {1000-9361},
doi = {https://doi.org/10.1016/j.cja.2025.103812},
url = {https://www.sciencedirect.com/science/article/pii/S1000936125004182},
author = {Xiaoxiao ZHANG and Qihan DENG and Yang YANG and Shengsheng QIAN and Yi HUI and Yanbo ZHU and Kaiquan CAI},
keywords = {Air traffic control, Semantic understanding, Multi-task learning, Hierarchical modeling, Attention mechanism},
abstract = {Flight situational awareness in civil aviation relies on the semantic understanding of both the key details and the full picture from the Air Traffic Controller (ATCo) and pilot communication. This paper proposes a novel end-to-end Multi-Task Hierarchical Network (MTHN) for automatically understanding ATCo-pilot communication, handling slot filling, role detection, and intent recognition at different levels while adaptively integrating them. Specifically, we introduce a word-based knowledge-masked slot distillation module that constructs an ATC knowledge base to dynamically mask keywords during teacher-student distillation. Considering the distinct intent differences between ATCos and pilots, we design a sentence-based role-aware intent attention module that extracts role label space vectors as context to enrich intent representations. To exploit the complementarity across different semantic levels in ATCo-pilot communication, we explicitly develop an adaptive bi-interaction flow module that dynamically explores semantic dependencies among tasks. Extensive experiments on real-world datasets collected in China show the superior performance of MTHN, compared to state-of-the-art baselines in both general natural language understanding and ATC-specific text processing. Our results highlight that MTHN achieves 99.26%, 97.25%, and 96.22% accuracy across key slots, as well as 96.59% accuracy in speaker role classification. Moreover, it can perceive multi-label deep intents behind sentences. These analytical findings demonstrate the potential to reduce human errors in high-concurrency ATCo-pilot interactions under dense operational conditions.}
}
@article{AZAM2025127140,
title = {A practical solution for modelling GDPR-compliance based on defeasible logic reasoning},
journal = {Expert Systems with Applications},
volume = {277},
pages = {127140},
year = {2025},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2025.127140},
url = {https://www.sciencedirect.com/science/article/pii/S0957417425007626},
author = {Naila Azam and Alex Chak and Annalito Michala and Shuja Ansari and Nguyen Binh Truong},
keywords = {Data privacy, Data protection, Defeasible logic programming (DeLP), General data protection regulation (GDPR), GDPR compliance, Threat modelling},
abstract = {The General Data Protection Regulation (GDPR), the EU/UK data protection legislation, has necessitated a critical need for compliance modelling to meet its strict and sophisticated requirements. Traditional techniques for modelling security and privacy-related threats fall short of addressing and mitigating the threats of non-compliance. This paper introduces a practical solution to modelling GDPR-compliance based on Defeasible Logic Programming (DeLP), which enhances the robustness and reasoning capabilities of compliance models in real-world scenarios. Furthermore, to overcome the challenges of UNDECIDED query outputs in logical reasoning, we incorporate explicit priorities for conflicting rules and suggest related knowledge for a query in an incomplete knowledge base. To finalize the compliance modelling system, we develop the threat mitigation mechanism that specifies the reasons in case there is a non-compliance threat, along with the suggested actions to mitigate the threats. The application of our approach is demonstrated through a case study on Fitbit, health tracking devices, focusing on non-compliance threats and resolving ”UNDECIDED” query results. Our findings show that the inference engine efficiently identifies non-compliance threats, handles UNDECIDED query results, and suggests appropriate threat mitigation measures.}
}
@article{BURGUN2019913,
title = {Intelligence artificielle et radiothérapie : quelles bases et quelles perspectives ?},
journal = {Cancer/Radiothérapie},
volume = {23},
number = {8},
pages = {913-916},
year = {2019},
issn = {1278-3218},
doi = {https://doi.org/10.1016/j.canrad.2019.08.005},
url = {https://www.sciencedirect.com/science/article/pii/S1278321819303865},
author = {A. Burgun},
keywords = {Intelligence artificielle, Oncologie, Radiothérapie, Médecine de précision, Algorithme, Artificial intelligence, Precision oncology, Radiation therapy, Algorithm},
abstract = {Résumé
L’intelligence artificielle est une notion hautement polysémique. Pour réaliser un raisonnement complexe dans la vie réelle, et s’adapter à des connaissances et des situations nouvelles, deux grandes approches sont développées en informatique : les réseaux de neurones basés sur le modèle connexionniste (deep learning) pour l’apprentissage, et les méthodes symboliques et logiques capables de travailler à un niveau abstrait de description et de raisonnement. Les algorithmes d’intelligence artificielle reproduisant les processus de déduction, induction et abduction ont des applications en radiothérapie. Combinés à la radiomique, les réseaux de neurones ont obtenu de bons résultats en classification d’images, traitement du langage naturel, phénotypage à partir des dossiers patients, adaptation des traitements. Les approches logiques ont produit des ontologies formelles, des algorithmes déterministes pour la décision et des méthodes de vérification de cohérence des systèmes complexes. Une intelligence artificielle hybride conjuguant apprentissage et logique est nécessaire pour réaliser des tâches complexes allant au delà de l’intelligence artificielle qui réalise des tâches restreintes et spécialisées. Combinée à des modèles formalisant les connaissances physicobiologiques, l’intelligence artificielle est au cœur de nouveaux outils comme les jumeaux numériques (digital twins) nécessaires à la médecine de précision en oncologie.
Artificial intelligence is a highly polysemic term. In computer science, with the objective of being able to solve totally new problems in new contexts, artificial intelligence includes connectionism (neural networks) for learning and logics for reasoning. Artificial intelligence algorithms mimic tasks normally requiring human intelligence, like deduction, induction, and abduction. All apply to radiation oncology. Combined with radiomics, neural networks have obtained good results in image classification, natural language processing, phenotyping based on electronic health records, and adaptive radiation therapy. General adversial networks have been tested to generate synthetic data. Logics based systems have been developed for providing formal domain ontologies, supporting clinical decision and checking consistency of the systems. Artificial intelligence must integrate both deep learning and logic approaches to perform complex tasks and go beyond the so-called narrow artificial intelligence that is tailored to perform some highly specialized task. Combined together with mechanistic models, artificial intelligence has the potential to provide new tools such as digital twins for precision oncology.}
}
@article{BERTHON2024461,
title = {Trajectories of AI technologies: Insights for managers},
journal = {Business Horizons},
volume = {67},
number = {5},
pages = {461-470},
year = {2024},
note = {SPECIAL ISSUE: WRITTEN BY CHATGPT},
issn = {0007-6813},
doi = {https://doi.org/10.1016/j.bushor.2024.03.002},
url = {https://www.sciencedirect.com/science/article/pii/S0007681324000284},
author = {Pierre Berthon and Taylan Yalcin and Ekin Pehlivan and Tamara Rabinovich},
keywords = {Trajectories of technology, Generative AI, Chatbots, ChatGPT, Large language models, Social media},
abstract = {Generative artificial intelligence (GenAI) has long been considered a technology for the future. With the release of the chatbot ChatGPT 4, many now feel the future has arrived. Long in gestation, this new technology promises many benefits to humankind, but worries persist that as AI technology scales and comes to rival or exceed human intelligence, the servant may become the master. Amid such hyperbole, the more nuanced trajectories of this technology have been neglected. In this article, we use the Trajectories of Technology (ToT) framework developed by Berthon and colleagues to explore the disparate paths that AI has taken and will take in the coming years, especially in the form of chatbots. This framework provides managers with a conceptual tool to strategically plan for the enormous promises and perils of AI in general and of chatbots specifically.}
}
@article{FICKO2025100257,
title = {Reflective thinking meets artificial intelligence: Synthesizing sustainability transition knowledge in left-behind mountain regions},
journal = {Geography and Sustainability},
volume = {6},
number = {1},
pages = {100257},
year = {2025},
issn = {2666-6839},
doi = {https://doi.org/10.1016/j.geosus.2024.100257},
url = {https://www.sciencedirect.com/science/article/pii/S2666683924001202},
author = {Andrej Ficko and Simo Sarkki and Yasar Selman Gultekin and Antonia Egli and Juha Hiedanpää},
keywords = {Artificial intelligence, Innovation, Reflective thinking, Scientific imagination, Text mining, Text summarization},
abstract = {We demonstrate a multi-method approach towards discovering and structuring sustainability transition knowledge in marginalized mountain regions. By employing reflective thinking, artificial intelligence (AI)-powered text summarization and text mining, we synthesize experts’ narratives on sustainable development challenges and solutions in Kardüz Upland, Türkiye. We then analyze their alignment with the UN Sustainable Development Goals (SDGs) using document embedding. Investment in infrastructure, education, and resilient socio-ecological systems emerged as priority sectors to combat poor infrastructure, geographic isolation, climate change, poverty, depopulation, unemployment, low education levels, and inadequate social services. The narratives were closest in substance to SDG 1, 3, and 11. Social dimensions of sustainability were more pronounced than environmental dimensions. The presented approach supports policymakers in organizing loosely structured sustainability transition knowledge and fragmented data corpora, while also advancing AI applications for designing and planning sustainable development policies at the regional level.}
}
@article{BARUA2018102,
title = {Ratzel's biogeography: a more-than-human encounter},
journal = {Journal of Historical Geography},
volume = {61},
pages = {102-108},
year = {2018},
issn = {0305-7488},
doi = {https://doi.org/10.1016/j.jhg.2018.05.015},
url = {https://www.sciencedirect.com/science/article/pii/S0305748817302487},
author = {Maan Barua},
keywords = {Friedrich Ratzel, Biogeography, More-than-human geography, Oecumene, Animals, Space, Mobility},
abstract = {Understanding the social and political in relation to fabrications of earth/life has been one of geography's most enduring concerns. Friedrich Ratzel's Lebensraum essay, subtitled ‘a biogeographical study’, is an early exposition of how relations between the bio and the geo are politically molten. Yet his oeuvre, whilst of interest to political geographers, has been overlooked in the recent proliferation of work on the earth/life nexus in more-than-human geography. To this end, this commentary asks what it might mean to read Ratzel's essay in light of attempts to articulate and specify the cartographies of life. Three key themes are highlighted that resonate with contemporary more-than-human approaches: the spatial ontologies of animal life, animals' mobilities and cartographies of the living world. More specifically, this commentary expands upon Ratzel's notion of the oecumene and argues that it offers up critical purchase for diagramming animals' ontologies in ways sensitive to geographical concerns with nonhuman difference, lifeworlds and movement. A brief conclusion identifies avenues for future research and engagement.}
}
@article{KLOCKERLARSEN2025100270,
title = {Finding the cracks: How do frontline officials maneuver state institutions to advance Indigenous rights to land and environment?},
journal = {Earth System Governance},
volume = {25},
pages = {100270},
year = {2025},
issn = {2589-8116},
doi = {https://doi.org/10.1016/j.esg.2025.100270},
url = {https://www.sciencedirect.com/science/article/pii/S2589811625000369},
author = {Rasmus {Kløcker Larsen} and Mikkel Funder and Cortney Golkar-Dakin and Maria-Therese Gustafsson and Carol Hunsberger and Martin Marani and Almut Schilling-Vacaflor},
keywords = {State, Institutions, Agency, Indigenous peoples, Environment, Rights},
abstract = {This paper challenges the monolithic portrayal of the state as inherently ‘bad’ when it comes to implementation of Indigenous rights. Offering a comparative analysis of case studies from four continents we demonstrate examples of frontline state officials proactively advancing Indigenous rights to land and environment. Combining distinct literatures on institutional theory, we develop an analytical framework that sheds light on bureaucratic agency within state-Indigenous relations. The findings show how government organizations maintain a broadly colonial agenda, but that officials on the inside sometimes manage to advance decolonizing or otherwise supportive actions. We propose the concept of institutional braiding to describe this agency exerted by state officials in collaboration with Indigenous representatives when navigating co-existing normative orders. By examining the fraught institutional constraints faced by frontline actors, we contribute to debates on Indigenous-state relations and the prospects of reaching common ground in the contact zone between divergent ontologies.}
}
@incollection{GURALNICK2024308,
title = {Biodiversity Informatics},
editor = {Samuel M. Scheiner},
booktitle = {Encyclopedia of Biodiversity (Third Edition)},
publisher = {Academic Press},
edition = {Third Edition},
address = {Oxford},
pages = {308-313},
year = {2024},
isbn = {978-0-323-98434-8},
doi = {https://doi.org/10.1016/B978-0-12-822562-2.00329-7},
url = {https://www.sciencedirect.com/science/article/pii/B9780128225622003297},
author = {Robert Guralnick and Robert A. Morris},
keywords = {Darwin Core, Data discovery, Data integration, Data management, Data publishing, FAIR data, Globally unique identifiers, Machine learning, Metadata, Natural History Collections, Natural Language Processing, Observations, Ontology, Species, Specimens},
abstract = {Biodiversity informatics in an interdisciplinary field with a focus on organizing, accessing, provisioning and integrating a variety of sources of primary biodiversity data. What biodiversity informatics is not is a field devoted to developing statistical methodologies for analyzing biodiversity, but software development supporting ecological modeling is within it׳s purvey. Key topic areas in biodiversity informatics include: Community development of data and metadata standards to support provisioning of data and information conforming to FAIR data principles; Development of data publishing systems built on standards to assure interoperability; Development of data integration approaches to support integrating diverse data types ranging from co-locating resources to more sophisticated knowledge systems development and; methods and mechanisms to automate and enhance biodiversity data; and development of new means to extract data and information using tools such as natural language processing or other machine learning techniques. Together these approaches are meant to support community efforts to understand biodiversity and its change across the broadest phylogenetic, spatial and temporal scales.}
}
@article{ZHU202311,
title = {Investigation of the mechanisms leading to human sperm DNA damage based on transcriptome analysis by RNA-seq techniques},
journal = {Reproductive BioMedicine Online},
volume = {46},
number = {1},
pages = {11-19},
year = {2023},
issn = {1472-6483},
doi = {https://doi.org/10.1016/j.rbmo.2022.08.108},
url = {https://www.sciencedirect.com/science/article/pii/S1472648322006836},
author = {Chun-Hui Zhu and Ye Wei and Sheng-Min Zhang and Fang Chen and Feng Li and Nai-Jun Dong and Tong-Min Xue and Kai-Feng Liu and Jin-Chun Lu and Heng-Mi Cui},
keywords = {Male infertility, mRNA, RNA-seq, Sperm DNA damage, Transcriptome},
abstract = {Research question
What are the molecular mechanisms leading to human sperm DNA damage?
Design
Semen samples were collected and the sperm DNA fragmentation index (DFI) was assessed. Differentially expressed RNA in spermatozoa with a high (DFI ≥30%, experimental group) or normal (DFI <30%, control group) DFI were identified by RNA-sequencing (RNA-seq) technology, and Gene Ontology and Kyoto Encyclopedia of Genes and Genomes (KEGG) analysis was performed. Three differentially expressed RNA related to sperm DNA damage and repair, namely PMS1, TP53BP1 and TLK2, were validated using real-time quantitative (RT-qPCR).
Results
A total of 19,970 expressed RNA were detected in the two groups. Compared with the control group, the expression levels of 189 RNA in the experimental group were significantly increased and those of 163 genes decreased. Gene Ontology enrichment analysis showed that these RNA were mainly concentrated in the ATPase-dependent transmembrane transport complex, extracellular exosome, somatic cell DNA recombination, protein binding, cytoplasm and regulation of localization. KEGG pathway analysis showed that these RNA were mainly related to the PI3K-Akt signalling pathway, endocytosis, p53 signalling pathway and cGMP-PKG signalling pathway. The RT-qPCR results showed that the expression levels of PMS1, TP53BP1 and TLK2 in the experimental group were significantly lower than in the control group (P = 0.01, 0.015 and 0.004, respectively), which was identical to the results of RNA sequencing.
Conclusions
Differentially expressed RNA related to sperm DNA damage and repair may be identified by RNA-seq technology, which provides new insights into the understanding of sperm DNA damage and repair, and will help to discover new biomarkers related to sperm DNA damage.}
}
@article{SUNDMAN2025102849,
title = {XTDB, an XML based format for Calphad databases},
journal = {Calphad},
volume = {90},
pages = {102849},
year = {2025},
issn = {0364-5916},
doi = {https://doi.org/10.1016/j.calphad.2025.102849},
url = {https://www.sciencedirect.com/science/article/pii/S0364591625000525},
author = {Bo Sundman and Fabio Miani and Axel {van de Walle} and Bengt Hallstedt and Ursula R. Kattner and Florian Tang and Taichi Abe and Reza Naraghi and Erwin Povoden-Karadeniz and Aurelie Jacob and Shuanglin Chen and Richard Otis and Kazuhisa Shobu and Malin Selleby and Alexander Pisch},
keywords = {Computational thermodynamics, Calphad, Models, Model parameters, Databases, XML},
abstract = {The calculation of phase diagram (Calphad) method uses models that depend on assessed parameters to describe the thermodynamic properties of materials. These model parameters are assessed by researchers and students using experimental and theoretical data on binary and ternary systems that can be merged to multicomponent databases and used to calculate properties and simulate processes for a wide range of materials. There are several different software using the Calphad method for calculations and they may use slightly different models and database formats. This paper will provide a short background on the current state of database development and proposes a new format based on the eXtensive Markup Language (XML) as a unified database format. This change is particularly important as several new models for the pure elements are currently being introduced in the Calphad databases.}
}
@article{MAYAMPURATH2025108376,
title = {Identification of neurological text markers associated with risk of stroke},
journal = {Journal of Stroke and Cerebrovascular Diseases},
volume = {34},
number = {8},
pages = {108376},
year = {2025},
issn = {1052-3057},
doi = {https://doi.org/10.1016/j.jstrokecerebrovasdis.2025.108376},
url = {https://www.sciencedirect.com/science/article/pii/S1052305725001545},
author = {Anoop Mayampurath and Avery Rosado and Elida Romo and Philip Silberman and Jay Patel and Samantha Jankowski and Matthew Maas and Jane L. Holl and Ava L. Liberman and Shyam Prabhakaran},
keywords = {Stroke, Diagnosis, Natural language processing, Neurological signs and symptoms},
abstract = {Background
Delayed or missed stroke diagnosis is associated with poor outcomes. We utilized natural language processing of notes from non-neurological emergency department (ED) encounters to identify text phrases indicating stroke presentations that are associated with stroke hospitalization 30 days after ED discharge.
Methods
We conducted a retrospective analysis of stroke (case) and gastroenteritis (matched-control) patients at two academic medical centers who had an ED encounter 30 days before index admission diagnosis. Medical concepts were extracted from the ED encounter notes. Statistical analysis was used to detect neurological text markers indicating stroke signs and symptoms using data from one hospital (discovery cohort) and validated in the second (validation cohort). We further compared the coefficients and the predictive performance of an elastic net model of both cohorts.
Results
We detected 58 medical concepts with a statistically significant positive association with stroke cases in the discovery cohort of 987 patients (51 % stroke). Expert review was used to combine these medical concepts into 11 text markers indicative of stroke presentations (e.g., coordination, language). Markers demonstrated external validity in terms of positive association when analyzed in the validation cohort of 433 patients (24 % stroke). Elastic net models derived at each center demonstrated equivalence in coefficient magnitudes and predictive performance, demonstrating generalizability.
Conclusion
We detected and validated neurologic text markers characteristic of stroke signs and symptoms at an ED encounter 30 days before the stroke diagnosis. The presence of these markers could be used to prompt additional neurologic evaluation to prevent delayed stroke diagnosis.}
}
@article{HAHNEL2023,
title = {A Semantic Relatedness Model for the Automatic Cluster Analysis of Phonematic and Semantic Verbal Fluency Tasks Performed by People With Parkinson Disease: Prospective Multicenter Study},
journal = {JMIR Neurotechnology},
volume = {2},
year = {2023},
issn = {2817-092X},
doi = {https://doi.org/10.2196/46021},
url = {https://www.sciencedirect.com/science/article/pii/S2817092X2300008X},
author = {Tom Hähnel and Tim Feige and Julia Kunze and Andrea Epler and Anika Frank and Jonas Bendig and Nils Schnalke and Martin Wolz and Peter Themann and Björn Falkenburger},
keywords = {cognition, executive function, language function, mild cognitive impairment, Parkinson disease, Parkinson disease dementia, semantic clusters, semantic relatedness, verbal fluency tasks},
abstract = {Background
Phonematic and semantic verbal fluency tasks (VFTs) are widely used to capture cognitive deficits in people with neurodegenerative diseases. Counting the total number of words produced within a given time frame constitutes the most commonly used analysis for VFTs. The analysis of semantic and phonematic word clusters can provide additional information about frontal and temporal cognitive functions. Traditionally, clusters in the semantic VFT are identified using fixed word lists, which need to be created manually, lack standardization, and are language specific. Furthermore, it is not possible to identify semantic clusters in the phonematic VFT using this technique.
Objective
The objective of this study was to develop a method for the automated analysis of semantically related word clusters for semantic and phonematic VFTs. Furthermore, we aimed to explore the cognitive domains captured by this analysis for people with Parkinson disease (PD).
Methods
People with PD performed tablet-based semantic (51/85, 60%) and phonematic (69/85, 81%) VFTs. For both tasks, semantic word clusters were determined using a semantic relatedness model based on a neural network trained on the Wikipedia (Wikimedia Foundation) text corpus. The cluster characteristics derived from this model were compared with those derived from traditional evaluation methods of VFTs and a set of neuropsychological parameters.
Results
For the semantic VFT, the cluster characteristics obtained through automated analyses showed good correlations with the cluster characteristics obtained through the traditional method. Cluster characteristics from automated analyses of phonematic and semantic VFTs correlated with the overall cognitive function reported by the Montreal Cognitive Assessment, executive function reported by the Frontal Assessment Battery and the Trail Making Test, and language function reported by the Boston Naming Test.
Conclusions
Our study demonstrated the feasibility of standardized automated cluster analyses of VFTs using semantic relatedness models. These models do not require manually creating and updating categorized word lists and, therefore, can be easily and objectively implemented in different languages, potentially allowing comparison of results across different languages. Furthermore, this method provides information about semantic clusters in phonematic VFTs, which cannot be obtained from traditional methods. Hence, this method could provide easily accessible digital biomarkers for executive and language functions in people with PD.}
}
@article{ITO2024109309,
title = {Predicting potential target genes in molecular biology experiments using machine learning and multifaceted data sources},
journal = {iScience},
volume = {27},
number = {3},
pages = {109309},
year = {2024},
issn = {2589-0042},
doi = {https://doi.org/10.1016/j.isci.2024.109309},
url = {https://www.sciencedirect.com/science/article/pii/S2589004224005303},
author = {Kei K. Ito and Yoshimasa Tsuruoka and Daiju Kitagawa},
keywords = {Molecular biology, Natural language processing},
abstract = {Summary
Experimental analysis of functionally related genes is key to understanding biological phenomena. The selection of genes to study is a crucial and challenging step, as it requires extensive knowledge of the literature and diverse biomedical data resources. Although software tools that predict relationships between genes are available to accelerate this process, they do not directly incorporate experiment information derived from the literature. Here, we develop LEXAS, a target gene suggestion system for molecular biology experiments. LEXAS is based on machine learning models trained with diverse information sources, including 24 million experiment descriptions extracted from full-text articles in PubMed Central by using a deep-learning-based natural language processing model. By integrating the extracted experiment contexts with biomedical data sources, LEXAS suggests potential target genes for upcoming experiments, complementing existing tools like STRING, FunCoup, and GOSemSim. A simple web interface enables biologists to consider newly derived gene information while planning experiments.}
}
@article{LIAN2024317,
title = {Hub genes, a diagnostic model, and immune infiltration based on ferroptosis-linked genes in schizophrenia},
journal = {IBRO Neuroscience Reports},
volume = {16},
pages = {317-328},
year = {2024},
issn = {2667-2421},
doi = {https://doi.org/10.1016/j.ibneur.2024.01.007},
url = {https://www.sciencedirect.com/science/article/pii/S2667242124000071},
author = {Kun Lian and Yongmei Li and Wei Yang and Jing Ye and Hongbing Liu and Tianlan Wang and Guangya Yang and Yuqi Cheng and Xiufeng Xu},
keywords = {Schizophrenia, Ferroptosis, WGCNA, Hub gene, Diagnostic model, Immune infiltration},
abstract = {Background
Schizophrenia (SCZ) is a prevalent and serious mental disorder, and the exact pathophysiology of this condition is not fully understood. In previous studies, it has been proven that ferroprotein levels are high in SCZ. It has also been shown that this inflammatory response may modify fibromodulin. Accumulating evidence indicates a strong link between metabolism and ferroptosis. Therefore, the present study aims to identify ferroptosis‐linked hub genes to further investigate the role that ferroptosis plays in the development of SCZ.
Material and methods
From the GEO database, four microarray data sets on SCZ (GSE53987, GSE38481, GSE18312, and GSE38484) and ferroptosis‐linked genes were extracted. Using the prefrontal cortex expression matrix of SCZ patients and healthy individuals as the control group from GSE53987, weighted gene co‐expression network analysis (WGCNA) was performed to discover SCZ‐linked module genes. From the feed, genes associated with ferroptosis were retrieved. The intersection of the module and ferroptosis-linked genes was done to obtain the hub genes. Then, Gene Ontology (GO), Kyoto Encyclopedia of Genes and Genomes (KEGG) pathway enrichment analyses, and Gene Set Enrichment Analysis (GSEA) were conducted. The SCZ diagnostic model was established using logistic regression, and the GSE38481, GSE18312, and GSE38484 data sets were used to validate the model. Finally, hub genes linked to immune infiltration were examined.
Results
A total of 13 SCZ module genes and 7 hub genes linked to ferroptosis were obtained: DECR1, GJA1, EFN2L2, PSAT1, SLC7A11, SOX2, and YAP1. The GO/KEGG/GSEA study indicated that these hub genes were predominantly enriched in mitochondria and lipid metabolism, oxidative stress, immunological inflammation, ferroptosis, Hippo signaling pathway, AMP‐activated protein kinase pathway, and other associated biological processes. The diagnostic model created using these hub genes was further confirmed using the data sets of three blood samples from patients with SCZ. The immune infiltration data showed that immune cell dysfunction enhanced ferroptosis and triggered SCZ.
Conclusion
In this study, seven critical genes that are strongly associated with ferroptosis in patients with SCZ were discovered, a valid clinical diagnostic model was built, and a novel therapeutic target for the treatment of SCZ was identified by the investigation of immune infiltration.}
}
@article{SHAHANDASHTI2024107526,
title = {A PRISMA-driven systematic mapping study on system assurance weakeners},
journal = {Information and Software Technology},
volume = {175},
pages = {107526},
year = {2024},
issn = {0950-5849},
doi = {https://doi.org/10.1016/j.infsof.2024.107526},
url = {https://www.sciencedirect.com/science/article/pii/S0950584924001319},
author = {Kimya Khakzad Shahandashti and Alvine B. Belle and Timothy C. Lethbridge and Oluwafemi Odu and Mithila Sivakumar},
keywords = {Assurance cases, Assurance deficits, Uncertainty, Logical fallacies, PRISMA, GSN, SACM, Systematic mapping study, Cyber–physical systems, Safety, Reliability, Defeaters},
abstract = {Context:
An assurance case is a structured hierarchy of claims aiming at demonstrating that a mission-critical system supports specific requirements (e.g., safety, security, privacy). The presence of assurance weakeners (i.e., assurance deficits, logical fallacies) in assurance cases reflects insufficient evidence, knowledge, or gaps in reasoning. These weakeners can undermine confidence in assurance arguments, potentially hindering the verification of mission-critical system capabilities which could result in catastrophic outcomes (e.g., loss of lives). Given the growing interest in employing assurance cases to ensure that systems are developed to meet their requirements, exploring the management of assurance weakeners becomes beneficial.
Objective:
As a stepping stone for future research on assurance weakeners, we aim to initiate the first comprehensive systematic mapping study on this subject.
Methods:
We followed the well-established PRISMA 2020 and SEGRESS guidelines to conduct our systematic mapping study. We searched for primary studies in five digital libraries and focused on the 2012–2023 publication year range. Our selection criteria focused on studies addressing assurance weakeners from a qualitative standpoint, resulting in the inclusion of 39 primary studies in our systematic review.
Results:
Our systematic mapping study reports a taxonomy (map) that provides a uniform categorization of assurance weakeners and approaches proposed to manage them from a qualitative perspective. The taxonomy classifies weakeners in four categories: aleatory, epistemic, ontological, and argument uncertainty. Additionally, it classifies approaches supporting the management of weakeners in three main categories: representation, identification and mitigation approaches.
Conclusion:
Our study findings suggest that the SACM (Structured Assurance Case Metamodel) – a standard specified by the OMG (Object Management Group) – offers a comprehensive range of capabilities to capture structured arguments and reason about their potential assurance weakeners. Our findings also suggest novel assurance weakener management approaches should be proposed to better assure mission-critical systems.}
}
@article{JACKSON2020209,
title = {Understanding understanding and ambiguity in natural language},
journal = {Procedia Computer Science},
volume = {169},
pages = {209-225},
year = {2020},
note = {Postproceedings of the 10th Annual International Conference on Biologically Inspired Cognitive Architectures, BICA 2019 (Tenth Annual Meeting of the BICA Society), held August 15-19, 2019 in Seattle, Washington, USA},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2020.02.138},
url = {https://www.sciencedirect.com/science/article/pii/S1877050920302611},
author = {Philip Jackson},
keywords = {understanding, ambiguity, natural language, language of thought, mentalese, TalaMind},
abstract = {How can we define and understand the nature of understanding itself? This paper discusses cognitive processes for understanding the world in general and for understanding natural language. The discussion considers whether and how an artificial cognitive system could use a ‘natural language of thought’, and whether the ambiguities of natural language would be a theoretical barrier or could be a theoretical advantage for such a system, in a research approach toward human-level artificial intelligence.}
}
@article{LIU2022200,
title = {Facial expressions elicit multiplexed perceptions of emotion categories and dimensions},
journal = {Current Biology},
volume = {32},
number = {1},
pages = {200-209.e6},
year = {2022},
issn = {0960-9822},
doi = {https://doi.org/10.1016/j.cub.2021.10.035},
url = {https://www.sciencedirect.com/science/article/pii/S096098222101424X},
author = {Meng Liu and Yaocong Duan and Robin A.A. Ince and Chaona Chen and Oliver G.B. Garrod and Philippe G. Schyns and Rachael E. Jack},
keywords = {facial expressions, emotion categories, affective dimensions, communication, perception, data-driven methods, information theory, reverse correlation},
abstract = {Summary
Human facial expressions are complex, multi-component signals that can communicate rich information about emotions,1, 2, 3, 4, 5 including specific categories, such as “anger,” and broader dimensions, such as “negative valence, high arousal.”6, 7, 8 An enduring question is how this complex signaling is achieved. Communication theory predicts that multi-component signals could transmit each type of emotion information—i.e., specific categories and broader dimensions—via the same or different facial signal components, with implications for elucidating the system and ontology of facial expression communication.9 We addressed this question using a communication-systems-based method that agnostically generates facial expressions and uses the receiver’s perceptions to model the specific facial signal components that represent emotion category and dimensional information to them.10, 11, 12 First, we derived the facial expressions that elicit the perception of emotion categories (i.e., the six classic emotions13 plus 19 complex emotions3) and dimensions (i.e., valence and arousal) separately, in 60 individual participants. Comparison of these facial signals showed that they share subsets of components, suggesting that specific latent signals jointly represent—i.e., multiplex—categorical and dimensional information. Further examination revealed these specific latent signals and the joint information they represent. Our results—based on white Western participants, same-ethnicity face stimuli, and commonly used English emotion terms—show that facial expressions can jointly represent specific emotion categories and broad dimensions to perceivers via multiplexed facial signal components. Our results provide insights into the ontology and system of facial expression communication and a new information-theoretic framework that can characterize its complexities.}
}
@article{LI2023126583,
title = {Embracing ambiguity: Improving similarity-oriented tasks with contextual synonym knowledge},
journal = {Neurocomputing},
volume = {555},
pages = {126583},
year = {2023},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2023.126583},
url = {https://www.sciencedirect.com/science/article/pii/S0925231223007063},
author = {Yangning Li and Jiaoyan Chen and Yinghui Li and Tianyu Yu and Xi Chen and Hai-Tao Zheng},
keywords = {Natural language processing, Pre-trained language model, Similarity-oriented tasks, Synonym knowledge enhancement},
abstract = {Contextual synonym knowledge is crucial for those similarity-oriented tasks whose core challenge lies in capturing semantic similarity between entities in their contexts, such as entity linking and entity matching. However, most Pre-trained Language Models (PLMs) lack synonym knowledge due to inherent limitations of their pre-training objectives such as masked language modeling (MLM). Existing works which inject synonym knowledge into PLMs often suffer from two severe problems: (i) Neglecting the ambiguity of synonyms, and (ii) Undermining semantic understanding of original PLMs, which is caused by inconsistency between the exact semantic similarity of the synonyms and the broad conceptual relevance learned from the original corpus. To address these issues, we propose PICSO, a flexible framework that supports the injection of contextual synonym knowledge from multiple domains into PLMs via a novel entity-aware Adapter which focuses on the semantics of the entities (synonyms) in the contexts. Meanwhile, PICSO stores the synonym knowledge in additional parameters of the Adapter structure, which prevents it from corrupting the semantic understanding of the original PLM. Extensive experiments demonstrate that PICSO can dramatically outperform the original PLMs and the other knowledge and synonym injection models on four different similarity-oriented tasks. In addition, experiments on GLUE prove that PICSO also benefits general natural language understanding tasks. Codes and data will be public.}
}
@incollection{HAMILTON2023371,
title = {Chapter 16 - Natural Language Processing},
editor = {Julien Delarue and J. Ben Lawlor},
booktitle = {Rapid Sensory Profiling Techniques (Second Edition)},
publisher = {Woodhead Publishing},
edition = {Second Edition},
pages = {371-410},
year = {2023},
series = {Woodhead Publishing Series in Food Science, Technology and Nutrition},
isbn = {978-0-12-821936-2},
doi = {https://doi.org/10.1016/B978-0-12-821936-2.00004-2},
url = {https://www.sciencedirect.com/science/article/pii/B9780128219362000042},
author = {Leah Marie Hamilton and Jacob Lahne},
keywords = {Natural Language Processing, Machine learning, Deep learning, Text analysis, Computational linguistics, Sensory evaluation, Descriptive analysis},
abstract = {Sensory evaluation is predicated on the use and interpretation of human language. We ask our subjects to describe their sensory experiences and affective responses, which we cannot directly observe. This formulation of sensory science encourages direct engagement with linguistics and in particular, a recent subfield of linguistics, computer science, and artificial intelligence called “Natural Language Processing” (NLP, sometimes “computational linguistics”). In this chapter we will provide an introduction to Natural Language Processing (NLP) for sensory scientists who wish to employ NLP as a rapid method for sensory evaluation. Because NLP is a large, diverse, and rapidly evolving field, we will begin with a brief, pragmatic overview of the discipline, with an emphasis on key historical and current methods and applications. We will then briefly discuss the linguistic perspective and its application to sensory evaluation, with an aim to motivating the remaining chapter. Following that, we will discuss key areas of NLP, from data collection to processing to analysis to advanced applications. Throughout the chapter, we will use a consistent case study of natural-language descriptions for a food product to provide examples and illustrate NLP methods.}
}
@article{BEIGHLEY2020123,
title = {Clinical Phenotypes of Carriers of Mutations in CHD8 or Its Conserved Target Genes},
journal = {Biological Psychiatry},
volume = {87},
number = {2},
pages = {123-131},
year = {2020},
note = {Molecular Mechanisms of Neurodevelopmental Disorders},
issn = {0006-3223},
doi = {https://doi.org/10.1016/j.biopsych.2019.07.020},
url = {https://www.sciencedirect.com/science/article/pii/S0006322319315537},
author = {Jennifer S. Beighley and Caitlin M. Hudac and Anne B. Arnett and Jessica L. Peterson and Jennifer Gerdts and Arianne S. Wallace and Heather C. Mefford and Kendra Hoekzema and Tychele N. Turner and Brian J. O’Roak and Evan E. Eichler and Raphael A. Bernier},
keywords = {Autism spectrum disorder, , Gene regulation, Genetic subtypes, Neurodevelopmental disorder, Precision medicine},
abstract = {Background
Variants disruptive to CHD8 (which codes for the protein CHD8 [chromodomain-helicase-DNA-binding protein 8]) are among the most common mutations revealed by exome sequencing in autism spectrum disorder (ASD). Recent work has indicated that CHD8 plays a role in the regulation of other ASD-risk genes. However, it is unclear whether a possible shared genetic ontology extends to the phenotype.
Methods
This study (N = 143; 42.7% female participants) investigated clinical and behavioral features of individuals ascertained for the presence of a known disruptive ASD-risk mutation that is 1) CHD8 (CHD8 group) (n = 15), 2) a gene targeted by CHD8 (target group) (n = 22), or 3) a gene without confirmed evidence of being targeted by CHD8 (other gene group) (n = 106).
Results
Results indicated shared features between the CHD8 and target groups that included less severe adaptive deficits in communication skills, similar functional language, more social motivation challenges in those with ASD, larger head circumference, higher weight, and lower seizure prevalence relative to the other gene group.
Conclusions
These similarities suggest broader genetic ontology accounts for aspects of phenotypic heterogeneity. Improved understanding of the relationships between related disruptive gene events may lead us to improved understanding of shared mechanisms and lead to more focused treatments for individuals with known genetic mutations.}
}
@article{ALAM2024100431,
title = {Identification of key signaling pathways and novel computational drug target for oral cancer, metabolic disorders and periodontal disease},
journal = {Journal of Genetic Engineering and Biotechnology},
volume = {22},
number = {4},
pages = {100431},
year = {2024},
issn = {1687-157X},
doi = {https://doi.org/10.1016/j.jgeb.2024.100431},
url = {https://www.sciencedirect.com/science/article/pii/S1687157X24001343},
author = {Mohammad Khursheed Alam and Md. {Faruk Hosen} and Kiran Kumar Ganji and Kawsar Ahmed and Francis M. Bui},
keywords = {Oral cancer, Periodontal disease, Metabolic Disorder, Biomarker Identification, Molecular pathway, Drug compound, Signaling pathway},
abstract = {Aim
Due to conventional endocrinological methods, there is presently no shared work available, and no therapeutic options have been demonstrated in oral cancer (OC) and periodontal disease (PD), type 2 diabetes (T2D), and obese patients. The aim of this study is to determine the similar molecular pathways and potential therapeutic targets in PD, OC, T2D, and obesity that may be used to anticipate the progression of the disease.
Methods
Four Gene Expression Omnibus (GEO) microarray datasets (GSE29221, GSE15773, GSE16134, and GSE13601) are used for finding differentially expressed genes (DEGs) for T2D, obese, and PD patients with OC in order to explore comparable pathways and therapeutic medications. Gene ontology (GO) and pathway analysis were used to investigate the functional annotations of the genes. The hub genes were then identified using protein-protein interaction (PPI) networks, and the most significant PPI components were evaluated using a clustering approach.
Results
These three gene expression-based datasets yielded a total of seven common DEGs. According to the GO annotation, the majority of the DEGs were connected with the microtubule cytoskeleton structure involved in mitosis. The KEGG pathways revealed that the concordant DEGs are connected to the cell cycle and progesterone-mediated oocyte maturation. Based on topological analysis of the PPI network, major hub genes (CCNB1, BUB1, TTK, PLAT, and AHNAK) and notable modules were revealed. This work additionally identified the connection of TF genes and miRNAs with common DEGs, as well as TF activity.
Conclusion
Predictive drug analysis yielded concordant drug compounds involved with T2D, OC, PD, and obesity disorder, which might be beneficial for examining the diagnosis, treatment, and prognosis of metabolic disorders and Oral cancer.}
}
@article{WANG2025125407,
title = {Exploring multi-granularity contextual semantics for fully inductive knowledge graph completion},
journal = {Expert Systems with Applications},
volume = {260},
pages = {125407},
year = {2025},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2024.125407},
url = {https://www.sciencedirect.com/science/article/pii/S0957417424022747},
author = {Jingchao Wang and Weimin Li and Alex Munyole Luvembe and Xiao Yu and Xinyi Zhang and Fangyu Liu and Fangfang Liu and Hao Wang and Zhenhai Wang and Qun Jin},
keywords = {Knowledge graph, Knowledge reasoning, Graph neural network, Graph embedding},
abstract = {Fully inductive knowledge graph completion (KGC) aims to predict triplets involving both unseen entities and relations. Recent several approaches transform paths between entities into descriptions and modeling semantic correlations between paths using pre-trained language models (PLMs), have emerged as a promising solution for fully inductive reasoning. However, these methods often adopt a simplistic concatenation strategy for path-to-sentence transformation, which impedes PLMs’ ability to capture subtle nuances in context, resulting in sub-optimal path context embeddings. Furthermore, they ignore the high-order semantics underlying the complete context, which can provide richer information for inductive reasoning. To address these issues, we propose a Multi-Granularity Contextual Semantic (MGCS) modeling framework, utilizing a Path Modeling Network (PMN) and a Subgraph Modeling Network (SMN) to extract two granularity levels of contextual semantics from single paths and complete subgraphs, for fully inductive KGC. The PMN extracts paths between head and tail entities and employs reasoning patterns from similar cases to filter out unreliable paths. Then two innovative path conversion strategies are designed to significantly enhance the pre-trained language model’s understanding of specific path contexts. The SMN employs a neighbor interactive graph neural network to extract high-order semantics from the complete subgraph context with a concept-enhanced relation encoding, and optimizes it through a contrastive learning method. Finally, the confidence of the triples is evaluated from the perspective of global complete context by comparing the semantics between the subgraphs surrounding the target triplet and the subgraphs surrounding similar cases. Experimental results on benchmark datasets demonstrate the effectiveness of MGCS.}
}
@article{LI2025100894,
title = {A concise review of intelligent game agent},
journal = {Entertainment Computing},
volume = {52},
pages = {100894},
year = {2025},
issn = {1875-9521},
doi = {https://doi.org/10.1016/j.entcom.2024.100894},
url = {https://www.sciencedirect.com/science/article/pii/S1875952124002623},
author = {Hui Li and Xinyi Pang and Bixia Sun and Kexin Liu},
keywords = {Intelligent agent, Artificial intelligence, Monte Carlo tree, Reinforcement learning, Large language models},
abstract = {Intelligent game agents are crafted using AI technologies to mimic player behavior and make decisions autonomously. Over the past decades, the scope of intelligent agents has broadened from chess to encompass content generation, player modeling, and result prediction, reflecting the field’s evolving and multifaceted nature. In this paper, we conduct a systematic review of recent literature on intelligent methods and applications of game agents, along with general game agent frameworks. Our findings suggest that creating general intelligent agents remains a significant challenge, yet it is worthwhile to explore methods that better integrate the strengths of different techniques to build more robust and adaptable intelligent game agents.}
}
@article{TIYYAGURA2022981,
title = {Development and Validation of a Natural Language Processing Tool to Identify Injuries in Infants Associated With Abuse},
journal = {Academic Pediatrics},
volume = {22},
number = {6},
pages = {981-988},
year = {2022},
issn = {1876-2859},
doi = {https://doi.org/10.1016/j.acap.2021.11.004},
url = {https://www.sciencedirect.com/science/article/pii/S1876285921005404},
author = {Gunjan Tiyyagura and Andrea G. Asnes and John M. Leventhal and Eugene D. Shapiro and Marc Auerbach and Wei Teng and Emily Powers and Amy Thomas and Daniel M. Lindberg and Justin McClelland and Carol Kutryb and Thomas Polzin and Karen Daughtridge and Virginia Sevin and Allen L. Hsiao},
keywords = {child abuse, emergency department, natural language processing, test characteristics},
abstract = {Objectives
Medically minor but clinically important findings associated with physical child abuse, such as bruises in pre-mobile infants, may be identified by frontline clinicians yet the association of these injuries with child abuse is often not recognized, potentially allowing the abuse to continue and even to escalate. An accurate natural language processing (NLP) algorithm to identify high-risk injuries in electronic health record notes could improve detection and awareness of abuse. The objectives were to: 1) develop an NLP algorithm that accurately identifies injuries in infants associated with abuse and 2) determine the accuracy of this algorithm.
Methods
An NLP algorithm was designed to identify ten specific injuries known to be associated with physical abuse in infants. Iterative cycles of review identified inaccurate triggers, and coding of the algorithm was adjusted. The optimized NLP algorithm was applied to emergency department (ED) providers’ notes on 1344 consecutive sample of infants seen in 9 EDs over 3.5 months. Results were compared with review of the same notes conducted by a trained reviewer blind to the NLP results with discrepancies adjudicated by a child abuse expert.
Results
Among the 1344 encounters, 41 (3.1%) had one of the high-risk injuries. The NLP algorithm had a sensitivity and specificity of 92.7% (95% confidence interval [CI]: 79.0%–98.1%) and 98.1% (95% CI: 97.1%–98.7%), respectively, and positive and negative predictive values were 60.3% and 99.8%, respectively, for identifying high-risk injuries.
Conclusions
An NLP algorithm to identify infants with high-risk injuries in EDs has good accuracy and may be useful to aid clinicians in the identification of infants with injuries associated with child abuse.}
}
@article{MEREDITH202215,
title = {HOLEY MOLEY, the poppycock syndrome, and academic drift},
journal = {International Journal of Project Management},
volume = {40},
number = {1},
pages = {15-18},
year = {2022},
issn = {0263-7863},
doi = {https://doi.org/10.1016/j.ijproman.2021.08.005},
url = {https://www.sciencedirect.com/science/article/pii/S0263786321001010},
author = {Jack R. Meredith},
keywords = {Academic drift, Theory, Journal articles, Ontology}
}
@article{WANG2025103085,
title = {Implementation path and reference model for Multilateral Data Circulation System (MDCS) in Datacentric Product-Service System (DPSS): from an industrial practice survey},
journal = {Advanced Engineering Informatics},
volume = {64},
pages = {103085},
year = {2025},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2024.103085},
url = {https://www.sciencedirect.com/science/article/pii/S1474034624007365},
author = {Chengjun Wang and Xinguo Ming and Xinming Gao and Xianyu Zhang},
keywords = {Datacentric product-service systems, Data circulation, Data sovereignty, Data privacy},
abstract = {With the digital transformation of enterprises and the development of digital infrastructure (smart sensors, 5G/6G, IoT, Industrial Internet, etc.), large amounts of data are generated in various stages of the product life cycle. The value of data in the Product-Service System is becoming prominent. However, through literature review and industrial practice survey, it has been observed that there is a lack of systematic investigation into the processes of data circulation and utilization within PSS. Additionally, within the existing research on data circulation, scholars focus on partial points such as data privacy computing, data sharing and data transaction, lacking an overall reference model for the data circulation in the Product-Service System and the path of implementing a multilateral data circulation platform in the industry. This paper aims to use the industrial practice survey method, based on the literature review, to propose the Datacentric Product-Service System (DPSS) for the first time, and study the main processes of data circulation in the DPSS. The study of the reference model and industrial implementation path of the multilateral data circulation system that meets the industry’s needs in the Datacentric Product-Service System. It provides a reference for the government and industry to design, implement and regulate the domain data circulation platform. In addition, the proposed data circulation system reference model and implementation path can enhance the value symbiosis among enterprises and increase industry benefits.}
}
@article{YOHANNES2025e02657,
title = {Amharic document clustering using semantic information from neural word embedding and encyclopedic knowledge},
journal = {Scientific African},
volume = {28},
pages = {e02657},
year = {2025},
issn = {2468-2276},
doi = {https://doi.org/10.1016/j.sciaf.2025.e02657},
url = {https://www.sciencedirect.com/science/article/pii/S2468227625001279},
author = {Dessalew Yohannes and Yenewondim Biadgie Sinshaw and Surafiel Habib Asefa and Yaregal Assabie},
keywords = {Amharic document clustering, Hierarchical concept-based text clustering, Document feature expansion, Semantic information extraction, Neural word embedding, Encyclopedic knowledge},
abstract = {Amharic is the working language of Ethiopia, and its complex morphology, coupled with limited usable resources, makes the development of text processing applications for the language a challenging task. In this paper, we introduce Amharic document clustering system using an integration of the semantic information extracted from the word embedding model and encyclopedic knowledge. The encyclopedic knowledge is stored as a database with tree-like structures, enabling the construction of structured concepts, whereas the word embedding is used to capture the contextual relatedness between two concepts. Text features are extracted and further expanded with semantically similar concepts by mapping document words to the structured concepts constructed from the encyclopedic knowledge. The expanded text features are subsequently weighted using the TF-IDF method, resulting in a weighted document-by-term matrix. Finally, documents are clustered based on this matrix using the spherical k-means algorithm. The proposed system is tested using an Amharic text corpus and the Amharic Wikipedia which is utilized as encyclopedic knowledge. The implementation is carried out in low-resource setting and we use word embedding to capture the semantic information of terms. Various experiments are conducted, and test results show that the use of encyclopedic knowledge with semantic information shows better performance in comparison to other conventional clustering techniques, providing new insights for advancing text clustering, especially for low-resourced languages where computational and linguistic resources are limited.}
}
@article{HUANG2025103266,
title = {mKGMPP: A multi-layer knowledge graph integration framework and its inference method for manufacturing process planning},
journal = {Advanced Engineering Informatics},
volume = {65},
pages = {103266},
year = {2025},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2025.103266},
url = {https://www.sciencedirect.com/science/article/pii/S1474034625001594},
author = {Zechuan Huang and Xin Guo and Chong Jiang and Mingyue Yang and Hao Xue and Wu Zhao and Jie Wang},
keywords = {Knowledge graph, Manufacturing process planning, Interactive inference},
abstract = {Manufacturing process planning is the process of organizing the production steps based on product design. It aimed at determining the process routes and formulating resource allocation strategies in response to digital model. In the process of connecting product design and manufacturing, designers and manufacturing technicians focus on different aspects of the digital model. This leads to a distortion when manufacturing technicians transform the digital model information into process information. As a result, this results in a deviation in the mapping between design intent and process intent. Such deviations can lead to disconnections in the association of process knowledge, undermine the consistency and traceability between process documents and digital models. Therefore, this study proposes a multi-layer knowledge graph for manufacturing process planning(mKGMPP) and an interactive manufacturing process planning system (IMPP system) driven by digital model and the proposed knowledge framework. The historical process schemes are analyzed using a dual-dimensional approach based on text and digital model. An extraction strategy based on structured data parsing and intelligent agent processing is employed for textual knowledge extraction. For geometric feature knowledge, the OpenCV library is employed, along with Gaussian blur, morphological operations, and the Canny detection algorithm. The intra knowledge of process schemes is integrated using the 4M1E elements, and multi-dimensional relationships between process schemes are established based on TQCSE. The geometric similarity inference module, process scheme inference module, and processing content modification module have been developed, and an interactive interface has been built based on Gradio. A manufacturing process planning of a slender shaft in the aerospace domain validates the rationality of the proposed knowledge organization framework and knowledge inference method.}
}
@article{CHEN2023101900,
title = {Reinforcement learning-based distant supervision relation extraction for fault diagnosis knowledge graph construction under industry 4.0},
journal = {Advanced Engineering Informatics},
volume = {55},
pages = {101900},
year = {2023},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2023.101900},
url = {https://www.sciencedirect.com/science/article/pii/S1474034623000289},
author = {Chong Chen and Tao Wang and Yu Zheng and Ying Liu and Haojia Xie and Jianfeng Deng and Lianglun Cheng},
keywords = {Distant supervision relation extraction, Knowledge graph, Fault diagnosis, Reinforcement Learning},
abstract = {Fault diagnosis is the key concern in the operation and maintenance of industrial assets. A fault diagnosis knowledge graph (KG) can provide decision support to the engineers to efficiently conduct maintenance tasks. However, as a type of domain KG, it would be time-consuming to manually label the corpus collected from the multi-source including the maintenance log, handbook and article. Meanwhile, the existence of the noisy sentence in the multi-source corpus jeopardises the performance of relation extraction modelling. In order to address this issue, this paper proposes a distant supervision relation extraction (DSRE)-based approach to construct a fault diagnosis KG. In this approach, the ontology of the fault diagnosis KG is firstly designed. Subsequently, a DSRE algorithm named relation-aware-based sentence-level attention enhanced piecewise convolutional neural network with reinforcement learning strategy (PCNN-ATTRA-RL) is proposed. The algorithm can effectively lower the impact of noisy sentences and accurately label the relation of different entities when the labelled data is insufficient. In this algorithm, PCNN-ATTRA is designed as the DSRE classifier to effectively extract the relation between entity pairs. RL is conducted to remove the noisy sentence so as to further improve the performance. An experimental study based on the multi-source corpus collected from the real world reveals that the proposed approach shows merits in comparison with the state-of-the-art algorithms. Meanwhile, a fault diagnosis KG, which can greatly support the decision-making of the engineers in the fault diagnosis, is established via the proposed approach.}
}
@article{KULUS202076,
title = {The processes of cellular growth, aging, and programmed cell death are involved in lifespan of ovarian granulosa cells during short-term IVC – Study based on animal model},
journal = {Theriogenology},
volume = {148},
pages = {76-88},
year = {2020},
issn = {0093-691X},
doi = {https://doi.org/10.1016/j.theriogenology.2020.02.044},
url = {https://www.sciencedirect.com/science/article/pii/S0093691X20301564},
author = {Magdalena Kulus and Wiesława Kranc and Patrycja Sujka-Kordowska and Paul Mozdziak and Maurycy Jankowski and Aneta Konwerska and Jakub Kulus and Dorota Bukowska and Mariusz Skowroński and Hanna Piotrowska-Kempisty and Michał Nowicki and Bartosz Kempisty and Paweł Antosik},
keywords = {Pig, Ovarian follicle, Granulosa cells, Primary culture, Microarray},
abstract = {The oogenesis and folliculogenesis are closely linked and occur simultaneously in the growing ovarian follicles. Biochemical and morphological changes in oocytes (OC) and surrounding granulosa cells (GCs) are highly complex and depend on many factors, including intercellular communication. GCs are cells with many functions, often crucial for the proper viability of the oocyte and subsequent positive fertilization. The purpose of this study was to analyze gene expression in porcine GCs, to define differentially expressed genes belongs to the “cell growth”, “aging”, “positive regulation of cell death”, “apoptotic process”, “regulation of cell death”, "cell death" and "negative regulation of cell death" ontology groups during the short – term primary in vitro culture. Microarrays were employed to study the transcriptome contained in the total RNA of the cultured GCs. Ovaries were obtained after slaughter, from 40 gilts of swine aged 170 days. The cells were obtained through puncture of the ovaries, collection of follicular fluid, removal of the cumulus - oocyte complexes and centrifugation. The cells were then cultured in vitro. The RNA material was obtained before the culture was established (0h) and then after 48h, 96h and 144h of its course. From 182 differently expressed genes belonging to the these ontology groups, we have selected POSTN, FN1, FMOD, ITGB3, DCN, SERPINB2, SFRP2, IGFBP5, EMP1, and CCL2 which were upregulated, as well as DAPL1, ESR1, IHH, TGFBR3, PPARD, PDK4, TXNIP, IFIT3, CSRNP3, and TNFSF10 genes whose expression was downregulated during the time of in vitro culture of the GCs. The significance of the differential gene expression is to provide new information on the molecular aspects of in vitro granulosa cell culture.}
}
@article{GNOLI20181226,
title = {Mentefacts as a missing level in theory of information science},
journal = {Journal of Documentation},
volume = {74},
number = {6},
pages = {1226-1242},
year = {2018},
issn = {0022-0418},
doi = {https://doi.org/10.1108/JD-04-2018-0054},
url = {https://www.sciencedirect.com/science/article/pii/S0022041818000073},
author = {Claudio Gnoli},
keywords = {Information theory, Information science, Ontology, Knowledge organization, Epistemology, Levels of reality},
abstract = {Purpose
The current debate between two theoretical approaches in library and information science and knowledge organization (KO), the cognitive one and the sociological one, is addressed in view of their possible integration in a more general model. The paper aims to discuss these issues.
Design/methodology/approach
Personal knowledge of individual users, as focused in the cognitive approach, and social production and use of knowledge, as focused in the sociological approach, are reconnected to the theory of levels of reality, particularly in the versions of Nicolai Hartmann and Karl R. Popper (three worlds). The notions of artefact and mentefact, as proposed in anthropological literature and applied in some KO systems, are also examined as further contributions to the generalized framework. Some criticisms to these models are reviewed and discussed.
Findings
Both the cognitive approach and the sociological approach, if taken in isolation, prove to be cases of philosophical monism as they emphasize a single level over the others. On the other hand, each of them can be considered as a component of a pluralist ontology and epistemology, where individual minds and social communities are but two successive levels in knowledge production and use, and are followed by a further level of “objectivated spirit”; this can in turn be analyzed into artefacts and mentefacts. While all these levels are relevant to information science, mentefacts and their properties are its most peculiar objects of study, which make it distinct from such other disciplines as psychology and sociology.
Originality/value
This analysis shows how existing approaches can benefit from additional notions contributed by levels theory, to develop more complete and accurate models of information and knowledge phenomena.}
}
@article{DIB20226125,
title = {A multi-layered bigraphical modelling approach for context-aware systems},
journal = {Journal of King Saud University - Computer and Information Sciences},
volume = {34},
number = {8, Part B},
pages = {6125-6139},
year = {2022},
issn = {1319-1578},
doi = {https://doi.org/10.1016/j.jksuci.2021.08.008},
url = {https://www.sciencedirect.com/science/article/pii/S1319157821002111},
author = {Ahmed Taki Eddine DIB and Ramdane Maamri},
keywords = {Context-aware systems, Computing methodologies, Formal modelling, Multi-agent systems},
abstract = {There exist several approaches proposed for building Context-Aware Systems (CAS). However, due to the continually changing environment, the large number of interrelated components, complexity and diversity of application domains make the modelling of context-aware systems a particularly challenging task. To address the increasing complexity of the modelling: i) It is critical to take into account the importance of the environment (operational context); and ii) rely on software engineering concepts such as abstraction and modularity in order to reduce the level of complexity. Also, a context-aware system may require intelligence and autonomy. These naturally lead us to apply intelligent agent-based engineering. This work introduces a formal layered design approach that combines intelligent control of multi-agent systems and bigraph's rigor to model context-aware systems. Bigraphical reactive systems are particularly compelling for their capacity to specify, simultaneously, the physical and logical distribution of system components and their interconnections using two distinct structures; that is: place graph and link graph. While the behaviour and dynamic evolution are expressed using defined reaction rules, and as a last step, the bigraph specifications are coded in the Maude language to allow their execution and the verification of their validity.}
}
@article{ODIGIE2019,
title = {Fast Healthcare Interoperability Resources, Clinical Quality Language, and Systematized Nomenclature of Medicine—Clinical Terms in Representing Clinical Evidence Logic Statements for the Use of Imaging Procedures: Descriptive Study},
journal = {JMIR Medical Informatics},
volume = {7},
number = {2},
year = {2019},
issn = {2291-9694},
doi = {https://doi.org/10.2196/13590},
url = {https://www.sciencedirect.com/science/article/pii/S2291969419000437},
author = {Eseosa Odigie and Ronilda Lacson and Ali Raja and David Osterbur and Ivan Ip and Louise Schneider and Ramin Khorasani},
keywords = {knowledge representation, guidelines, evidence-based medicine, clinical decision support},
abstract = {Background
Evidence-based guidelines and recommendations can be transformed into “If-Then” Clinical Evidence Logic Statements (CELS). Imaging-related CELS were represented in standardized formats in the Harvard Medical School Library of Evidence (HLE).
Objective
We aimed to (1) describe the representation of CELS using established Systematized Nomenclature of Medicine—Clinical Terms (SNOMED CT), Clinical Quality Language (CQL), and Fast Healthcare Interoperability Resources (FHIR) standards and (2) assess the limitations of using these standards to represent imaging-related CELS.
Methods
This study was exempt from review by the Institutional Review Board as it involved no human subjects. Imaging-related clinical recommendations were extracted from evidence sources and translated into CELS. The clinical terminologies of CELS were represented using SNOMED CT and the condition-action logic was represented in CQL and FHIR. Numbers of fully and partially represented CELS were tallied.
Results
A total of 765 CELS were represented in the HLE as of December 2018. We were able to fully represent 137 of 765 (17.9%) CELS using SNOMED CT, CQL, and FHIR. We were able to represent terms using SNOMED CT in the temporal component for action (“Then”) statements in CQL and FHIR in 755 of 765 (98.7%) CELS.
Conclusions
CELS were represented as shareable clinical decision support (CDS) knowledge artifacts using existing standards—SNOMED CT, FHIR, and CQL—to promote and accelerate adoption of evidence-based practice. Limitations to standardization persist, which could be minimized with an add-on set of standard terms and value sets and by adding time frames to the CQL framework.}
}
@article{MOLLAHASSANI2023662,
title = {Knowledge Collaboration Approach in Smart Product Innovation Networks},
journal = {Procedia CIRP},
volume = {119},
pages = {662-668},
year = {2023},
note = {The 33rd CIRP Design Conference},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2023.02.158},
url = {https://www.sciencedirect.com/science/article/pii/S2212827123005450},
author = {Damun Mollahassani and Thomas Eickhoff and Yannick Juresa and Jens C. Göbel},
keywords = {Knowledge Base, Knowledge Collaboration, Value Creation Networks, Smart Products, Innovation Networks, Innovation Processes},
abstract = {Due to the transformation of traditional domain specific products to smart, connected and interdisciplinary products that are increasingly developed within value creation networks, an exchange of innovation-relevant knowledge in early engineering phases is required, covering interdependencies of several technical systems. Knowledge-based collaboration within a value creation network could enable an acceleration during the innovation development of smart products. Discipline- and stakeholder-specific knowledge, e.g. semiconductor research and production knowledge along the product lifecycle must be prepared for the usage within innovation development. This paper introduces a conceptual approach of a knowledge base to support the collaboration during innovation processes within value creation networks for smart products. The main focus is the sharing of relevant knowledge from different stakeholders within the innovation value creation network. Through knowledge networking, decentrally collected initial knowledge is centralized, made explorable and realized through a three-stage tagging architecture similar to an ontology. The collaboration of different stakeholders is enabled through mutual knowledge interests and automated suggestions independent from their respective IT ecosystems. The presented approach is instantiated and validated by considering the function to charge mobile phones wirelessly while car driving. Prerequisites for the presented approach are discussed.}
}
@article{XIA2023109068,
title = {Maintenance planning recommendation of complex industrial equipment based on knowledge graph and graph neural network},
journal = {Reliability Engineering & System Safety},
volume = {232},
pages = {109068},
year = {2023},
issn = {0951-8320},
doi = {https://doi.org/10.1016/j.ress.2022.109068},
url = {https://www.sciencedirect.com/science/article/pii/S0951832022006834},
author = {Liqiao Xia and Yongshi Liang and Jiewu Leng and Pai Zheng},
keywords = {Graph neural network, Knowledge graph, Link prediction, Maintenance management, Predictive maintenance},
abstract = {Maintenance planning is a significant part of predictive maintenance, which involves task planning, resource scheduling, and prevention. With large-scale sensor systems in modern factories, much data will be captured during monitoring and maintenance of complex industrial equipment. Accumulated data facilitates maintenance planning becomes more thorough and timely. Recently, a knowledge graph (KG) was offered to handle large-scale, unorganized maintenance data semantically, resulting in better data usage. Some prior studies have utilized KG for maintenance planning with semantic searching or graph structure-based algorithms, nevertheless neglecting the prediction of potential linkage. To fill this gap, a maintenance-oriented KG is established firstly based on a well-defined domain-specific ontology schema and accumulated maintenance data. Then, an Attention-Based Compressed Relational Graph Convolutional Network is proposed to predict potential solutions and explain fault in maintenance tasks. Lastly, a maintenance case of oil drilling equipment is carried out, where the proposed model is compared with other cutting-edge models to demonstrate its effectiveness in link prediction. This research is anticipated to shed light on future adoption of KG in maintenance planning recommendations.}
}
@article{ZHENG201845,
title = {An ecological community becoming: Language learning as first-order experiencing with place and mobile technologies},
journal = {Linguistics and Education},
volume = {44},
pages = {45-57},
year = {2018},
note = {Studying the visual and material dimensions of education and learning},
issn = {0898-5898},
doi = {https://doi.org/10.1016/j.linged.2017.10.004},
url = {https://www.sciencedirect.com/science/article/pii/S0898589817300967},
author = {Dongping Zheng and Yang Liu and Andrew Lambert and Aitao Lu and Jared Tomei and Daniel Holden},
keywords = {Space-place-time, Mobile devices, Events, Experiencing, (Trans)languaging, Affordances, Community becoming},
abstract = {This work looks at how language learners’ experiential engagement with place is achieved through design. It proposes a new language learning model, one that emerges through the availability and support of mobile technologies, and in which semiotic resources and learners’ participation in and experience of events are central. In this model, language learning is languaging in place, where place is a 3D holographic experience. Within such place and through such experience, knowing co-arises with design, place-based interactive experiences with others, and through mobile game narrative. The findings also suggest experiencing events together creates community, one that is emergent, dynamic, place-making and ecological in nature. Drawing on the constraints and affordances of community gives rise to linguistic choices and skilled linguistic action. By employing an eclectic toolkit from multimodal analysis, cognitive event analysis, and communicative project, we describe our mobile game design and describe our analysis of the game playing process to explain how we conceptualize the relationship between language learning, place, events and mobile technologies.}
}
@article{ERONEN2022102981,
title = {Transfer language selection for zero-shot cross-lingual abusive language detection},
journal = {Information Processing & Management},
volume = {59},
number = {4},
pages = {102981},
year = {2022},
issn = {0306-4573},
doi = {https://doi.org/10.1016/j.ipm.2022.102981},
url = {https://www.sciencedirect.com/science/article/pii/S0306457322000978},
author = {Juuso Eronen and Michal Ptaszynski and Fumito Masui and Masaki Arata and Gniewosz Leliwa and Michal Wroczynski},
keywords = {Abusive language detection, Zero-shot learning, Transfer learning, Linguistics},
abstract = {We study the selection of transfer languages for automatic abusive language detection. Instead of preparing a dataset for every language, we demonstrate the effectiveness of cross-lingual transfer learning for zero-shot abusive language detection. This way we can use existing data from higher-resource languages to build better detection systems for low-resource languages. Our datasets are from seven different languages from three language families. We measure the distance between the languages using several language similarity measures, especially by quantifying the World Atlas of Language Structures. We show that there is a correlation between linguistic similarity and classifier performance. This discovery allows us to choose an optimal transfer language for zero shot abusive language detection.}
}
@article{ZHANG20181135,
title = {A Chinese legal intelligent auxiliary discretionary adviser based on GA-BP NNs},
journal = {The Electronic Library},
volume = {36},
number = {6},
pages = {1135-1153},
year = {2018},
issn = {0264-0473},
doi = {https://doi.org/10.1108/EL-03-2017-0056},
url = {https://www.sciencedirect.com/science/article/pii/S0264047318000103},
author = {Ni Zhang and Yi-fei Pu and Suiquan Yang and Jinkang Gao and Zhu Wang and Ji-liu Zhou},
keywords = {Artificial intelligence, Information studies, Models, Knowledge-based systems},
abstract = {Purpose
This paper aims to build a legal intelligent auxiliary discretionary system for predicting the penalty and damage compensation values. After extensively considering current the characteristics of the current Chinese legal system, a practical legal intelligent auxiliary discretionary system based on genetic algorithm-backpropagation (GA-BP) neural network (NN) is proposed herein.
Design/methodology/approach
An experiment is designed to analyze cases involving mental anguish compensation in medical disputes, and a Chinese legal intelligent auxiliary discretionary adviser system is built based on a GA-BP NN. Because BP neural networks perform well for nonlinear problems and GAs can improve their ability to find optimal values, and accelerate their convergence, a combined GA–BP algorithm is used. In addition, an ontology is used to reduce the semantic ambiguities and extract the implied semantic information.
Findings
We confirm that a case-based legal intelligent auxiliary discretionary adviser system based on a GA-BP NN and ontology techniques has good performance in prediction. By predicting the mental anguish compensation values, the legal intelligent auxiliary discretionary adviser system can help judges to handle cases more quickly and ordinary people to discover the suggested compensation or penalty. In contrast to BP NN or SVM, the result seems more close to the actual compensation rate.
Practical implications
Recently, smart court has been developed in China; the purpose of which is to build the legal advice system for improving judicial justice and reducing differences in sentencing. A practical legal advice system is an urgent requirement for the judiciary.
Originality/value
This paper presents a study of a case-based legal intelligent auxiliary discretionary adviser system based on a GA-BP NN and ontology techniques. The findings offer advice to optimize legal intelligent auxiliary discretionary adviser systems for mental anguish compensation in medical disputes.}
}
@article{MENON201933,
title = {From database to knowledge graph — using data in chemistry},
journal = {Current Opinion in Chemical Engineering},
volume = {26},
pages = {33-37},
year = {2019},
note = {Energy, Environment & Sustainability: Sustainability Modeling ● Reaction engineering and catalysis: Green Reaction Engineering},
issn = {2211-3398},
doi = {https://doi.org/10.1016/j.coche.2019.08.004},
url = {https://www.sciencedirect.com/science/article/pii/S2211339819300322},
author = {Angiras Menon and Nenad B Krdzavac and Markus Kraft},
abstract = {Over the last couple of decades, the scientific community has made large efforts to process and store experimental and computational chemical data and information on the world wide web. This review summarizes several databases and ontologies available on the web for researchers to use. We also discuss briefly the categories of chemistry data that are stored, its main usage and how it can be accessed and understood in the framework of the Semantic Web.}
}
@article{REALENOSEI2024103264,
title = {From vision to text: A comprehensive review of natural image captioning in medical diagnosis and radiology report generation},
journal = {Medical Image Analysis},
volume = {97},
pages = {103264},
year = {2024},
issn = {1361-8415},
doi = {https://doi.org/10.1016/j.media.2024.103264},
url = {https://www.sciencedirect.com/science/article/pii/S1361841524001890},
author = {Gabriel Reale-Nosei and Elvira Amador-Domínguez and Emilio Serrano},
keywords = {Medical image captioning, Natural image captioning, Diagnostic captioning, Radiology report generation, Survey, State-of-the-art review},
abstract = {Natural Image Captioning (NIC) is an interdisciplinary research area that lies within the intersection of Computer Vision (CV) and Natural Language Processing (NLP). Several works have been presented on the subject, ranging from the early template-based approaches to the more recent deep learning-based methods. This paper conducts a survey in the area of NIC, especially focusing on its applications for Medical Image Captioning (MIC) and Diagnostic Captioning (DC) in the field of radiology. A review of the state-of-the-art is conducted summarizing key research works in NIC and DC to provide a wide overview on the subject. These works include existing NIC and MIC models, datasets, evaluation metrics, and previous reviews in the specialized literature. The revised work is thoroughly analyzed and discussed, highlighting the limitations of existing approaches and their potential implications in real clinical practice. Similarly, future potential research lines are outlined on the basis of the detected limitations.}
}
@article{DADKHAH2020110485,
title = {A systematic literature review on semantic web enabled software testing},
journal = {Journal of Systems and Software},
volume = {162},
pages = {110485},
year = {2020},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2019.110485},
url = {https://www.sciencedirect.com/science/article/pii/S0164121219302596},
author = {Mahboubeh Dadkhah and Saeed Araban and Samad Paydar},
keywords = {Software testing, Test generation, Semantic web, Ontology, Systematic literature review},
abstract = {Software testing, as a major verification and validation activity which revolves around quality tests, is a knowledge-intensive activity. Hence, it is reasonable to expect that it can be improved by effective application of semantic web technologies, e.g., ontologies, which have been frequently used in knowledge engineering activities. The objective of this work is to investigate and provide a better understanding of how semantic web enabled techniques, i.e., the techniques that are based on the effective application of the semantic web technologies, have been used to support software testing activities. For this purpose, a Systematic Literature Review based on a predefined procedure is conducted. A total of 52 primary studies were identified as relevant, which have undergone a thorough meta-analysis with regards to our posed research questions. This study indicates the benefits of semantic web enabled software testing in both industry and academia. It also identifies main software testing activities that can benefit from the semantic web enabled techniques. Furthermore, contributions of such techniques to the testing process are thoroughly examined. Finally, potentials and difficulties of applying these techniques to software testing, along with the promising research directions are discussed.}
}
@article{CALBIMONTE2023100774,
title = {Decentralized semantic provision of personal health streams},
journal = {Journal of Web Semantics},
volume = {76},
pages = {100774},
year = {2023},
issn = {1570-8268},
doi = {https://doi.org/10.1016/j.websem.2023.100774},
url = {https://www.sciencedirect.com/science/article/pii/S1570826823000033},
author = {Jean-Paul Calbimonte and Orfeas Aidonopoulos and Fabien Dubosson and Benjamin Pocklington and Ilia Kebets and Pierre-Mikael Legris and Michael Schumacher},
keywords = {Semantic streams, Personal data streams, Machine learning, Decentralized healthcare data, Open source},
abstract = {Personalized healthcare is nowadays driven by the increasing volumes of patient data, observed and produced continuously thanks to medical devices, mobile sensors, patient-reported outcomes, among other data sources. This data is made available as streams, due to their dynamic nature, which represents an important challenge for processing, querying and interpreting the incoming information. In addition, the sensitive nature of healthcare data poses significant restrictions regarding privacy, which has led to the emergence of decentralized personal data management systems. Data semantics play a key role in order to enable both decentralization and integration of personal health data, as they introduce the capability to represent knowledge and information using ontologies and semantic vocabularies. In this paper we describe the SemPryv system, which provides the means to manage personal health data streams enriched with semantic information. SemPryv is designed as a decentralized system, so that users have the possibility of hosting their personal data at different sites, while keeping control of access rights. The semantization of data in SemPryv is implemented through different strategies, ranging from rule-based annotation to machine learning-based suggestions, fed from third-party specialized healthcare metadata providers. The system has been made available as Open Source, and is integrated as part of the Pryv.io platform used and commercialized in the healthcare and personal data management industry.}
}
@article{SCHRODER20208276,
title = {Formal Definition of the Term “Semantics” as a Foundation for Semantic Interoperability in the Industrial Internet of Things},
journal = {IFAC-PapersOnLine},
volume = {53},
number = {2},
pages = {8276-8282},
year = {2020},
note = {21st IFAC World Congress},
issn = {2405-8963},
doi = {https://doi.org/10.1016/j.ifacol.2020.12.1957},
url = {https://www.sciencedirect.com/science/article/pii/S2405896320325854},
author = {Tizian Schröder and Christian Diedrich},
keywords = {Semantics, Semantic Interoperability, Network of Interacting Systems, Industrial Internet of Things (IIoT), Knowledge Pyramid, Levels of Conceptual Interoperability Model (LCIM), Ontologies},
abstract = {Semantic interoperability is seen as the key to realize the ideas of the Industrial Internet of Things (IIoT). In order to equip technical systems with such a capability, a precise definition of the term “semantics” is needed. Complex IIoT devices can only be developed properly on a formal foundation. Existing approaches that intend to specify the term “semantics” are often more intuitively motivated. These include, for example, the knowledge pyramid or the Levels of Conceptual Interoperability Model (LCIM). The paper provides a formal definition of the term “semantics” and relates these existing approaches critically to the proposed definition.}
}
@article{DAPICA20211208,
title = {Towards a Semantic Knowledge Base for Competency-Based Training of Airline Pilots},
journal = {Procedia Computer Science},
volume = {192},
pages = {1208-1217},
year = {2021},
note = {Knowledge-Based and Intelligent Information & Engineering Systems: Proceedings of the 25th International Conference KES2021},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2021.08.124},
url = {https://www.sciencedirect.com/science/article/pii/S1877050921016136},
author = {Rubén Dapica and Federico Peinado},
keywords = {Pilot Training, Aviation Data Management, Data Interoperability, Ontology Engineering, Semantic Web},
abstract = {The acquisition and maintenance of non-technical skills by the pilots are fundamental factors for the prevention of aviation accidents. The aviation authorities are promoting that air crew training be carried out through simulator sessions using scenarios specifically designed to develop and assess the global performance of pilots in such skills. When designing custom flight training scenarios, choosing the correct events and conditions from the myriad of possible combinations with respect to their potential utility in training specific competencies is a costly task that depends entirely on highly specialized expert knowledge. In this paper, we present EBTOnto, an OWL DL ontology that allows to formalize this knowledge and other useful data from real cases, laying the foundations for a semantic knowledge base of scenarios for airline pilots training. Previous advances in this matter and possible applications of this system are reviewed. EBTOnto is built on top of a source validated by experts, the Evidence-Based Training Implementation Guide by the International Air Transport Association, and then checked using an automatic reasoner and a database of 37,568 aviation safety incidents, extracted from the widely regarded Aviation Safety Reporting System by the U.S. National Aeronautics and Space Administration. The results suggest that it is possible to classify real aviation scenarios in terms of non-technical competencies and filter useful incident reports for design and enrichment of these training scenarios. EBTOnto opens up new possibilities for interoperability between incident databases and training organizations, and smoothes the path to represent, share and generate custom simulation training scenarios for pilots based on real data.}
}
@article{LIU20251443,
title = {Exploring the Mechanism of Acupuncture in Improving Ovarian Function in Rats with Poor Ovarian Response Using High-Throughput Sequencing},
journal = {Combinatorial Chemistry & High Throughput Screening},
volume = {28},
number = {8},
pages = {1443-1457},
year = {2025},
issn = {1386-2073},
doi = {https://doi.org/10.2174/0113862073365843241223093834},
url = {https://www.sciencedirect.com/science/article/pii/S1386207325000266},
author = {Yunzhu Liu and Wanqiu Yang and Rongli Yuan and Zimeng Li and Tianyu Wang and Bin Yang and Zhi Li and Mengjing Wang and Jie Wu},
keywords = {Acupuncture, poor ovarian response, miRNA, MAPK signal path, ovarian function, granulosa cell structure},
abstract = {Objective
This study aimed to investigate the possible mechanism through which acupuncture protects ovaries with Poor Ovarian Response (POR) in rats based on microRNA (miRNA).
Methods
Thirty-six SPF SD female non-pregnant rats aged 8 weeks were randomly divided into the blank group, model group, and acupuncture group, with 12 rats in each group. According to the group, the rats were given gavage of Tripterygium wilfordii polyglycosides suspension for 14 days to establish the model of POR, and then the rats were treated with acupuncture for 2 weeks, once a day, for 20 minutes. Afterward, their hormone levels were measured, and HE staining was performed on the ovaries after the intervention. Three rats from each group were randomly selected for ovarian tissue miRNA sequencing, and differential miRNAs were subjected to Gene Ontology (GO) enrichment analysis, Kyoto Encyclopedia of Genes and Genomes (KEGG) signaling pathway analysis, and Quantitative Polymerase Chain Reaction (Q-PCR) verification. By using TargetScan to predict the target genes of differential miRNAs, we validated the results with a dual luciferase reporter gene assay.
Results
Compared with the blank group, the estrus cycle of the model group was significantly prolonged (P<0.01). Anti-Müllerian Hormone (AMH) (P<0.01) and Estrogen (E2) were significantly decreased (P<0.05). Follicle-Stimulating Hormone (FSH) (P<0.05) and Luteinizing Hormone (LH) increased sharply (P<0.01). Compared with the model group, the estrus cycle was significantly shortened in the acupuncture group (P<0.01). AMH and E2 were markedly raised (P<0.05). FSH (P<0.05) and LH (P<0.01) were significantly declined. miRNA sequencing showed that there were 23 miRNAs significantly different between the model group and the blank group (P<0.05), and 30 miRNAs significantly different between the acupuncture group and the model group (P<0.05). GO demonstrated that the network was mainly involved in cellular components, cells, cellular metabolic processes, binding, and single biological processes; KEGG signaling pathway enrichment showed that it was mainly related to MAPK, adhesion junction, calcium signaling pathways, etc. Q-PCR results showed that after modeling, the expression rose, and after acupuncture, the expression of the following miRNA decreased:miR-154-5p (P<0.01), miR-300-5p (P < 0.05), miR-376c-5p (P<0.05). The dual luciferase reporter assay showed that the relative luciferase activity of the miR-300-5p mimics+MAP3K1-WT group was significantly lower than that of the NC+MAP3K1-WT group (P<0.01). HE results demonstrated that the number of primordial follicles and primary follicles in the model group was significantly lower than that in the blank group (P<0.05). Moreover, the morphology was poorer, and the granulosa cell layer was thinner. Compared with the model group, the number of primary follicles in the acupuncture group increased (P<0.05); the morphology and granulosa cell structure of the ovary were improved to different degrees, and mature follicles could be seen.
Conclusion
Acupuncture may improve the ovarian responsiveness of POR rats by regulating miR-154-5p,miR-300-5p, and miR-376c-5p. Furthermore, miR-300-5p can specifically bind to the 3'-UTR of MAP3K1, and MAP3K1 may be the target of miR-300-5p.}
}
@article{PORCEL20181,
title = {Sharing notes: An academic social network based on a personalized fuzzy linguistic recommender system},
journal = {Engineering Applications of Artificial Intelligence},
volume = {75},
pages = {1-10},
year = {2018},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2018.07.007},
url = {https://www.sciencedirect.com/science/article/pii/S0952197618301519},
author = {C. Porcel and A. Ching-López and G. Lefranc and V. Loia and E. Herrera-Viedma},
keywords = {Recommender systems, Educational social networks, Fuzzy linguistic modeling},
abstract = {Social networks are Web systems that enable and encourage a collaborative work, making it possible to exchange information between users, which makes them especially useful in many areas. Specifically, they could be used in an academic environment with the aim of improving the educational processes, not replacing, but complementing the most traditional face-to-face models. But nowadays the increasingly widespread use of new technologies and social networks is causing the information we have available to grow disproportionately, making it more difficult and expensive to access information of interest. To alleviate this problem, automatic tools such as recommender systems, could be used to facilitate the accesses to relevant information, that in an academic environment would help to customize the educational processes. So, in this paper we present SharingNotes, an academic social network that can generate personalized recommendations to improve teaching and learning processes. To achieve this goal, it incorporates a hybrid recommender system that uses an ontology to characterize the degrees of trust among network users, and adopts the fuzzy linguistic modeling to improve the representation of information. Then, the use of this platform allows adapting the educational process to the circumstances of each student. The evaluation developed demonstrates the usefulness of this educational social network, as well as the users’ satisfaction while interacting and working with it.}
}
@article{MIN2021100963,
title = {A systematic review of item response theory in language assessment: Implications for the dimensionality of language ability},
journal = {Studies in Educational Evaluation},
volume = {68},
pages = {100963},
year = {2021},
issn = {0191-491X},
doi = {https://doi.org/10.1016/j.stueduc.2020.100963},
url = {https://www.sciencedirect.com/science/article/pii/S0191491X2030211X},
author = {Shangchao Min and Vahid Aryadoust},
keywords = {Dimensionality, Item response theory (IRT), Language ability, Systematic review, Language assessment},
abstract = {The present study conducted a systematic review of the item response theory (IRT) literature in language assessment to investigate the conceptualization and operationalization of the dimensionality of language ability. Sixty-two IRT-based studies published between 1985 and 2020 in language assessment and educational measurement journals were first classified into two categories based on a unidimensional and multidimensional research framework, and then reviewed to examine language dimensionality from technical and substantive perspectives. It was found that 12 quantitative techniques were adopted to assess language dimensionality. Exploratory factor analysis was the primary method of dimensionality analysis in papers that had applied unidimensional IRT models, whereas the comparison modeling approach was dominant in the multidimensional framework. In addition, there was converging evidence within the two streams of research supporting the role of a number of factors such as testlets, language skills, subskills, and linguistic elements as sources of multidimensionality, while mixed findings were reported for the role of item formats across research streams. The assessment of reading, listening, speaking, and writing skills was grounded within both unidimensional and multidimensional framework. By contrast, vocabulary and grammar knowledge was mainly conceptualized as unidimensional. Directions for continued inquiry and application of IRT in language assessment are provided.}
}
@article{GUZMAN2020145036,
title = {Analysis of hepatic transcriptome modulation exerted by γ-conglutin from lupins in a streptozotocin-induced diabetes model},
journal = {Gene},
volume = {761},
pages = {145036},
year = {2020},
issn = {0378-1119},
doi = {https://doi.org/10.1016/j.gene.2020.145036},
url = {https://www.sciencedirect.com/science/article/pii/S0378111920307058},
author = {Tereso Jovany Guzmán and Belinda Vargas-Guerrero and Pedro Macedonio García-López and Carmen Magdalena Gurrola-Díaz},
keywords = {, Legumes, Nutraceuticals, Streptozotocin-induced diabetes, Gene expression profiling, DNA microarray, Plant proteins},
abstract = {Lupinus albus γ-conglutin is proposed to positively affect glucose metabolism through inhibition of hepatic glucose production and insulin-mimetic activity; however, the action mechanism is not entirely known. Besides, most studies had focused on its effect on molecular targets directly related to glucose metabolism, and few studies have investigated how γ-conglutin may affect the liver gene expression or if it plays a role in other metabolic processes. Therefore, we investigated the influence of γ-conglutin on the liver transcriptome of streptozotocin-induced diabetic rats using DNA microarrays, ontological analyses, and quantitative PCR. Of the 22,000 genes evaluated, 803 and 173 were downregulated and upregulated, respectively. The ontological analyses of the differentially expressed genes revealed that among others, the mitochondria, microtubules, cytoskeleton, and oxidoreductase activity terms were enriched, implying a possible role of γ-conglutin on autophagy. To corroborate the microarray results, we selected and quantified, by PCR, the expression of two genes associated with autophagy (Atg7 and Snx18) and found their expression augmented two and threefold, respectively; indicating a higher autophagy activity in animals treated with γ-conglutin. Although complementary studies are required, our findings indicate for the first time that the hypoglycaemic effects of γ-conglutin may involve an autophagy induction mechanism, a pivotal process for the preservation of cell physiology and glucose homeostasis.}
}
@article{TRIPODI2020104877,
title = {Applying knowledge-driven mechanistic inference to toxicogenomics},
journal = {Toxicology in Vitro},
volume = {66},
pages = {104877},
year = {2020},
issn = {0887-2333},
doi = {https://doi.org/10.1016/j.tiv.2020.104877},
url = {https://www.sciencedirect.com/science/article/pii/S0887233320300576},
author = {Ignacio J. Tripodi and Tiffany J. Callahan and Jessica T. Westfall and Nayland S. Meitzer and Robin D. Dowell and Lawrence E. Hunter},
keywords = {Computational toxicology, Mechanistic inference, Artificial intelligence, Mechanistic toxicology, Adverse outcome pathways},
abstract = {When considering toxic chemicals in the environment, a mechanistic, causal explanation of toxicity may be preferred over a statistical or machine learning-based prediction by itself. Elucidating a mechanism of toxicity is, however, a costly and time-consuming process that requires the participation of specialists from a variety of fields, often relying on animal models. We present an innovative mechanistic inference framework (MechSpy), which can be used as a hypothesis generation aid to narrow the scope of mechanistic toxicology analysis. MechSpy generates hypotheses of the most likely mechanisms of toxicity, by combining a semantically-interconnected knowledge representation of human biology, toxicology and biochemistry with gene expression time series on human tissue. Using vector representations of biological entities, MechSpy seeks enrichment in a manually curated list of high-level mechanisms of toxicity, represented as biochemically- and causally-linked ontology concepts. Besides predicting the canonical mechanism of toxicity for many well-studied compounds, we experimentally validated some of our predictions for other chemicals without an established mechanism of toxicity. This mechanistic inference framework is an advantageous tool for predictive toxicology, and the first of its kind to produce a mechanistic explanation for each prediction. MechSpy can be modified to include additional mechanisms of toxicity, and is generalizable to other types of mechanisms of human biology.}
}
@article{OZEGOWSKA2018122,
title = {Expression pattern of new genes regulating female sex differentiation and in vitro maturational status of oocytes in pigs},
journal = {Theriogenology},
volume = {121},
pages = {122-133},
year = {2018},
issn = {0093-691X},
doi = {https://doi.org/10.1016/j.theriogenology.2018.08.019},
url = {https://www.sciencedirect.com/science/article/pii/S0093691X18306800},
author = {Katarzyna Ożegowska and Marta Dyszkiewicz-Konwińska and Piotr Celichowski and Mariusz J. Nawrocki and Artur Bryja and Maurycy Jankowski and Wiesława Kranc and Maciej Brązert and Sandra Knap and Michal Jeseta and Mariusz T. Skowroński and Dorota Bukowska and Paweł Antosik and Klaus P. Brüssow and Andrzej Bręborowicz and Małgorzata Bruska and Michał Nowicki and Leszek Pawelczyk and Maciej Zabel and Bartosz Kempisty},
keywords = {Porcine oocyte,  maturation, Sex differentiation, Microarrays},
abstract = {The processes underlying maturation of mammalian oocytes are considered crucial for the oocytes ability to undergo monospermic fertilization. The same factors of influence are suggested to impact the development of sex associated characteristics, allowing sex differentiation to progress during embryonic growth. The primary aim of the study was to analyze the gene ontology groups involved in regulation of porcine oocytes' response to endogenous stimuli. The results obtained would indicate potential genes influencing sex differentiation. Additionally, they could help to determine new genetic markers, expression profile of which is substantially regulated during porcine oocytes’ in vitro maturation. To achieve that, porcine oocytes were collected for analysis before and after in vitro maturation. Pigs were used as they are a readily available model that presents significant similarity to humans in terms of physiology and anatomy. Microarray analysis of oocytes, before and after in vitro maturation was performed and later validated by RT-qPCR. We have particularly detected and analyzed genes belonging to gene ontology groups associated with hormonal stimulation during maturation of the oocytes, that exhibited significant change in expression (fold change ≥ |2|; p < 0.05) namely “Female sex differentiation” (CCND2, MMP14, VEGFA, FST, INHBA, NR5A1), “Response to endogenous stimulus” (INSR, ESR1, CCND2, TXNIP, TACR3, MMP14, FOS, AR, EGR2, IGFBP7, TGFBR3, BTG2, PLD1, PHIP, UBE2B) and “Response to estrogen stimulus” (INSR, ESR1, CCND2, IHH, TXNIP, TACR3, MMP14). Some of them were characteristic for just one of the described ontologies, while some belonged into multiple ontological terms. The genes were analyzed, with their relation to the processes of interest explained. Overall, the study provides us with a range of genes that might serve as molecular markers of in vitro maturation associated processes of the oocytes. This knowledge might serve as a reference for further studies and, after further validation, as a potentially useful knowledge in assessment of the oocytes during assisted reproduction processes.}
}
@article{KELOTH2019103193,
title = {Alternative classification of identical concepts in different terminologies: Different ways to view the world},
journal = {Journal of Biomedical Informatics},
volume = {94},
pages = {103193},
year = {2019},
issn = {1532-0464},
doi = {https://doi.org/10.1016/j.jbi.2019.103193},
url = {https://www.sciencedirect.com/science/article/pii/S153204641930111X},
author = {Vipina K. Keloth and Zhe He and Gai Elhanan and James Geller},
keywords = {Ontologies and terminologies, UMLS, NCIt, MEDCIN, Concept import, Alternative classification},
abstract = {In previous research, we have studied concepts that occur in pairs of medical terminologies and are known to be identical, because they have the same ID number in the Unified Medical Language System (UMLS). We observed that such concepts rarely have exactly the same sets of children (=subconcepts) in the two terminologies. The number of common children was found to vary widely. A special situation was identified where the children in one terminology relate to the common parent in a very different way than the children in the other terminology. For example, children in one terminology might subdivide a parent concept by anatomical location in one terminology and by disease kind in the other terminology. We coined the term “alternative classification” (of the same parent concept) for such situations. In previous work, only human experts could recognize alternative classifications. In this paper, we present a mathematically expressed criterion for likely cases of alternative classifications. We compare the recommendations of this criterion, expressed by a mathematical quantity called “EFI” becoming zero, with the decisions of a human expert. It is found that the human expert agreed with the criterion in 72% of all cases, which is a big improvement over having no computable criterion at all. Besides alternative classifications, common parent concepts in a pair of terminologies might also indicate a possible import of a child concept missing in one terminology, different granularities, or errors in either one of the two terminologies. In this paper, we further investigate different kinds of alternative classifications.}
}

@InProceedings{zeginis2024ApplyingOntologyAware,
	keywords = {Prompt Format},
	file = {References/pdf/zeginis2024ApplyingOntologyAware.pdf},
	author = {Dimitris Zeginis and Evangelos Kalampokis and Konstantinos
		  A. Tarabanis},
	title = {Applying an ontology-aware zero-shot {LLM} prompting
		  approach for information extraction in Greek: the case of
		  {DIAVGEIA} gov gr},
	year = 2024,
	booktitle = {Proceedings of the 28th Pan-Hellenic Conference on
		  Progress in Computing and Informatics, {PCI} 2024,
		  AthensGreece, December 13-15, 2024},
	pages = {324-330},
	doi = {10.1145/3716554.3716603},
	url = {https://doi.org/10.1145/3716554.3716603},
	crossref = {DBLP:conf/pci/2024},
	timestamp = {Wed, 11 Jun 2025 21:00:16 +0200},
	biburl = {https://dblp.org/rec/conf/pci/ZeginisKT24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@InProceedings{tsaneva2024LlmDrivenOntology,
	file = {References/pdf/tsaneva2024LlmDrivenOntology.pdf},
	author = {Stefani Tsaneva and Stefan Vasic and Marta Sabou},
	title = {LLM-driven Ontology Evaluation: Verifying Ontology
		  Restrictions with ChatGPT},
	year = 2024,
	booktitle = {Joint proceedings of the 3rd International workshop on
		  knowledge graph generation from text {(TEXT2KG)} and Data
		  Quality meets Machine Learning and Knowledge Graphs
		  {(DQMLKG)} co-located with the Extended Semantic Web
		  Conference {(} {ESWC} 2024), Hersonissos, Greece, May
		  26-30, 2024},
	pages = 15,
	url = {https://ceur-ws.org/Vol-3747/dqmlkg\_paper3.pdf},
	crossref = {DBLP:conf/text2kg/2024},
	timestamp = {Thu, 31 Oct 2024 17:18:55 +0100},
	biburl = {https://dblp.org/rec/conf/text2kg/TsanevaVS24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@InProceedings{jain2022DistillingHypernymyRelations,
	keywords = {taxonomy discovery},
	file = {References/pdf/jain2022DistillingHypernymyRelations.pdf},
	author = {Devansh Jain and Luis Espinosa Anke},
	title = {Distilling Hypernymy Relations from Language Models: On
		  the Effectiveness of Zero-Shot Taxonomy Induction},
	year = 2022,
	booktitle = {Proceedings of the 11th Joint Conference on Lexical and
		  Computational Semantics, *SEM@NAACL-HLT 2022, Seattle, WA,
		  USA, July 14-15, 2022},
	pages = {151-156},
	doi = {10.18653/V1/2022.STARSEM-1.13},
	url = {https://doi.org/10.18653/v1/2022.starsem-1.13},
	crossref = {DBLP:conf/starsem/2022},
	timestamp = {Thu, 22 Aug 2024 07:28:05 +0200},
	biburl = {https://dblp.org/rec/conf/starsem/JainA22.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@InProceedings{garijo2024LlmsOntologyEngineering,
	keywords = {review, ontology enrichment},
	file = {References/pdf/garijo2024LlmsOntologyEngineering.pdf},
	author = {Daniel Garijo and Mar{\'{\i}}a Poveda{-}Villal{\'{o}}n and
		  Elvira Amador{-}Dom{\'{\i}}nguez and Ziyuan Wang and
		  Ra{\'{u}}l Garc{\'{\i}}a{-}Castro and {\'{O}}scar Corcho},
	title = {LLMs for Ontology Engineering: {A} landscape of Tasks and
		  Benchmarking challenges},
	year = 2024,
	booktitle = {Proceedings of the Special Session on Harmonising
		  Generative {AI} and Semantic Web Technologies {(HGAIS}
		  2024) co-located with the 23rd International Semantic Web
		  Conference {(ISWC} 2024), Baltimore, Maryland, November 13,
		  2024},
	url = {https://ceur-ws.org/Vol-3953/364.pdf},
	crossref = {DBLP:conf/semweb/2024hgais},
	timestamp = {Thu, 12 Jun 2025 16:38:15 +0200},
	biburl = {https://dblp.org/rec/conf/semweb/GarijoPAWGC24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@InProceedings{fathallah2024NeonGptLarge,
	file = {References/pdf/fathallah2024NeonGptLarge.pdf},
	author = {Nadeen Fathallah and Arunav Das and Stefano De Giorgis and
		  Andrea Poltronieri and Peter Haase and Liubov Kovriguina},
	title = {NeOn-GPT: {A} Large Language Model-Powered Pipeline for
		  Ontology Learning},
	year = 2024,
	booktitle = {The Semantic Web: {ESWC} 2024 Satellite Events -
		  Hersonissos, Crete, Greece, May 26-30, 2024, Proceedings,
		  Part {I}},
	pages = {36-50},
	doi = {10.1007/978-3-031-78952-6\_4},
	url = {https://doi.org/10.1007/978-3-031-78952-6\_4},
	crossref = {DBLP:conf/esws/2024s-1},
	timestamp = {Wed, 19 Feb 2025 12:54:38 +0100},
	biburl = {https://dblp.org/rec/conf/esws/FathallahDGPHK24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@InProceedings{bakker2024OntologyLearningText,
	file = {References/pdf/bakker2024OntologyLearningText.pdf},
	author = {Roos M. Bakker and Daan L. Di Scala and Maaike H. T. de
		  Boer},
	title = {Ontology Learning from Text: an Analysis on {LLM}
		  Performance},
	year = 2024,
	booktitle = {Proceedings of the 3rd International Workshop on Natural
		  Language Processing for Knowledge Graph Creation co-located
		  with 20th International Conference on Semantic Systems
		  (SEMANTiCS 2024), Amsterdam, The Netherlands, September 17,
		  2024},
	pages = {70-87},
	url = {https://ceur-ws.org/Vol-3874/paper5.pdf},
	crossref = {DBLP:conf/nlp4kgc/2024},
	timestamp = {Mon, 06 Jan 2025 16:59:41 +0100},
	biburl = {https://dblp.org/rec/conf/nlp4kgc/BakkerSB24.bib},
	bibsource = {dblp computer science bibliography, https://dblp.org}
}

@InProceedings{a2024StructuringSustainabilityReports,
	author = {A, Usmanova and R, Usbeck},
	date = {2024},
	title = {Structuring sustainability reports for environmental
		  standards with LLMs guided by ontology},
	pages = {168–177},
	booktitle = {Proceedings of the 1st Workshop on Natural Language
		  Processing Meets Climate Change}
}

@Misc{ahuja2024SampleEfficientMultilingual,
	title = {Sample efficient multilingual instruction fine-tuning
		  through n-shot guided prompting},
	author = {Ahuja, S. and Tanmay, K. and Chauhan, H.H. and Patra, B.
		  and Aggarwal, K. and Del Corro, L. and Mitra, A. and
		  Dhamecha, T.I. and Awadallah, A. and M, Choudhary},
	date = {2024},
	note = {sphinx: Sample efficient multilingual instruction
		  fine-tuning through n-shot guided prompting. arXiv preprint
		  arXiv:2407.09879 .},
	arxiv = {2407.09879}
}

@InProceedings{alharbi2024ExperimentInRetrofitting,
	author = {Alharbi, R. and Tamma, V. and F, Grasso and Payne, T.},
	date = {2024},
	title = {An experiment in retrofitting competency questions for
		  existing ontologies},
	pages = {1650–1658},
	doi = {10.1145/3605098.3636053.},
	booktitle = {Proceedings of the 39th ACM/SIGAPP Symposium on Applied
		  Computing}
}

@InProceedings{alharbi2024InvestigatingOpenSource,
	author = {Alharbi, R. and Tamma, V. and F, Grasso and Payne, T.R.},
	date = {2024},
	title = {Investigating open source llms to retrofit competency
		  questions in ontology engineering},
	volume = {4},
	pages = {188–198},
	booktitle = {Proceedings of the AAAI Symposium Series}
}

@InProceedings{babaei2023Llms4olLargeLanguage,
	title = {{{LLMs4OL}}: {{Large Language Models}} for {{Ontology
		  Learning}}},
	shorttitle = {{{LLMs4OL}}},
	booktitle = {The {{Semantic Web}} – {{ISWC}} 2023},
	author = {Babaei Giglou, Hamed and D'Souza, Jennifer and Auer,
		  Sören},
	editor = {Payne, Terry R. and Presutti, Valentina and Qi, Guilin and
		  Poveda-Villalón, María and Stoilos, Giorgos and Hollink,
		  Laura and Kaoudi, Zoi and Cheng, Gong and Li, Juanzi},
	date = {2023},
	pages = {408--427},
	publisher = {Springer Nature Switzerland},
	location = {Cham},
	doi = {10.1007/978-3-031-47240-4_22},
	abstract = {We propose the LLMs4OL approach, which utilizes Large
		  Language Models (LLMs) for Ontology Learning (OL). LLMs
		  have shown significant advancements in natural language
		  processing, demonstrating their ability to capture complex
		  language patterns in different knowledge domains. Our
		  LLMs4OL paradigm investigates the following hypothesis: Can
		  LLMs effectively apply their language pattern capturing
		  capability to OL, which involves automatically extracting
		  and structuring knowledge from natural language text? To
		  test this hypothesis, we conduct a comprehensive evaluation
		  using the zero-shot prompting method. We evaluate nine
		  different LLM model families for three main OL tasks: term
		  typing, taxonomy discovery, and extraction of non-taxonomic
		  relations. Additionally, the evaluations encompass diverse
		  genres of ontological knowledge, including lexicosemantic
		  knowledge in WordNet, geographical knowledge in GeoNames,
		  and medical knowledge in UMLS.},
	isbn = {978-3-031-47240-4},
	langid = {english},
	keywords = {Important,Large Language Models,LLMs,Ontologies,Ontology
		  Learning,Prompt-based Learning,Prompting, taxonomy
		  discovery},
	timestamp = {2024-09-12T12:01:26Z},
	file = {References/pdf/babaei2023Llms4olLargeLanguage.pdf}
}

@InBook{babaei2025Llms4omMatchingOntologies,
	file = {References/pdf/babaei2025Llms4omMatchingOntologies.pdf},
	title = {LLMs4OM: Matching Ontologies with Large Language Models},
	year = 2025,
	author = {Babaei Giglou, Hamed and D’Souza, Jennifer and Engel,
		  Felix and Auer, Sören},
	booktitle = {The Semantic Web: ESWC 2024 Satellite Events},
	publisher = {Springer Nature Switzerland},
	isbn = 9783031789526,
	pages = {25–35},
	doi = {10.1007/978-3-031-78952-6_3},
	url = {http://dx.doi.org/10.1007/978-3-031-78952-6_3},
	issn = {1611-3349}
}

@InProceedings{bischof2024LlmBasedGuided,
	author = {Bischof, S. and Filtz, E. and JX, Parreira and Steyskal,
		  S.},
	date = {2024},
	title = {Llm-based guided generation of ontology term definitions},
	publisher = {Springer},
	pages = {133–137},
	booktitle = {European Semantic Web Conference}
}

@Article{chen2023ContextualSemanticEmbeddings,
	file = {References/pdf/chen2023ContextualSemanticEmbeddings.pdf},
	title = {Contextual Semantic Embeddings for Ontology Subsumption
		  Prediction},
	author = {Chen, Jiaoyan and He, Yuan and Geng, Yuxia and
		  Jiménez-Ruiz, Ernesto and Dong, Hang and Horrocks, Ian},
	date = {2023-09},
	journaltitle = {World Wide Web-internet and Web Information Systems},
	shortjournal = {World Wide Web},
	volume = {26},
	number = {5},
	pages = {2569--2591},
	issn = {1573-1413},
	doi = {10.1007/s11280-023-01169-9},
	abstract = {Automating ontology construction and curation is an
		  important but challenging task in knowledge engineering and
		  artificial intelligence. Prediction by machine learning
		  techniques such as contextual semantic embedding is a
		  promising direction, but the relevant research is still
		  preliminary especially for expressive ontologies in Web
		  Ontology Language (OWL). In this paper, we present a new
		  subsumption prediction method named BERTSubs for classes of
		  OWL ontology. It exploits the pre-trained language model
		  BERT to compute contextual embeddings of a class, where
		  customized templates are proposed to incorporate the class
		  context (e.g., neighbouring classes) and the logical
		  existential restriction. BERTSubs is able to predict
		  multiple kinds of subsumers including named classes from
		  the same ontology or another ontology, and existential
		  restrictions from the same ontology. Extensive evaluation
		  on five real-world ontologies for three different
		  subsumption tasks has shown the effectiveness of the
		  templates and that BERTSubs can dramatically outperform the
		  baselines that use (literal-aware) knowledge graph
		  embeddings, non-contextual word embeddings and the
		  state-of-the-art OWL ontology embeddings.},
	langid = {english},
	keywords = {Artificial Intelligence,BERT,Ontology alignment,Ontology
		  embedding,OWL,Pre-trained language model,Subsumption
		  prediction},
	timestamp = {2024-08-15T09:49:42Z}
}

@Misc{coutinho2024LeveragingLlmsIn,
	author = {Coutinho, M.L.},
	date = {2024},
	title = {Leveraging llms in text-based ontology-driven conceptual
		  modeling}
}

@InProceedings{dong2023OntologyEnrichmentTexts,
	author = {Dong, H. and Chen, J. and Y, He and Horrocks, I.},
	date = {2023},
	title = {Ontology enrichment from texts: A biomedical dataset for
		  concept discovery and placement},
	pages = {5316–5320},
	booktitle = {Proceedings of the 32nd ACM International Conference on
		  Information and Knowledge Management}
}

@InProceedings{dong2024LanguageModelBased,
	file = {References/pdf/dong2024LanguageModelBased.pdf},
	title = {A {{Language Model Based Framework}} for {{New Concept
		  Placement}} in {{Ontologies}}},
	booktitle = {The {{Semantic Web}}},
	author = {Dong, Hang and Chen, Jiaoyan and He, Yuan and Gao,
		  Yongsheng and Horrocks, Ian},
	editor = {Meroño Peñuela, Albert and Dimou, Anastasia and Troncy,
		  Raphaël and Hartig, Olaf and Acosta, Maribel and Alam,
		  Mehwish and Paulheim, Heiko and Lisena, Pasquale},
	date = {2024},
	pages = {79--99},
	publisher = {Springer Nature Switzerland},
	location = {Cham},
	doi = {10.1007/978-3-031-60626-7_5},
	abstract = {We investigate the task of inserting new concepts
		  extracted from texts into an ontology using language
		  models. We explore an approach with three steps: edge
		  search which is to find a set of candidate locations to
		  insert (i.e., subsumptions between concepts), edge
		  formation and enrichment which leverages the ontological
		  structure to produce and enhance the edge candidates, and
		  edge selection which eventually locates the edge to be
		  placed into. In all steps, we propose to leverage neural
		  methods, where we apply embedding-based methods and
		  contrastive learning with Pre-trained Language Models
		  (PLMs) such as BERT for edge search, and adapt a BERT
		  fine-tuning-based multi-label Edge-Cross-encoder, and Large
		  Language Models (LLMs) such as GPT series, FLAN-T5, and
		  Llama 2, for edge selection. We evaluate the methods on
		  recent datasets created using the SNOMED CT ontology and
		  the MedMentions entity linking benchmark. The best settings
		  in our framework use fine-tuned PLM for search and a
		  multi-label Cross-encoder for selection. Zero-shot
		  prompting of LLMs is still not adequate for the task, and
		  we propose explainable instruction tuning of LLMs for
		  improved performance. Our study shows the advantages of
		  PLMs and highlights the encouraging performance of LLMs
		  that motivates future studies.},
	isbn = {978-3-031-60626-7},
	langid = {english},
	keywords = {Concept Placement,Large Language Models,Ontology
		  Enrichment,Pre-trained Language Models,SNOMED CT},
	timestamp = {2024-08-15T09:20:01Z}
}

@InProceedings{doumanas2024IntegratingLlmsIn,
	file = {References/pdf/doumanas2024IntegratingLlmsIn.pdf},
	title = {Integrating {{LLMs}} in the {{Engineering}} of a {{SAR
		  Ontology}}},
	booktitle = {Artificial {{Intelligence Applications}} and
		  {{Innovations}}},
	author = {Doumanas, Dimitrios and Soularidis, Andreas and Kotis,
		  Konstantinos and Vouros, George},
	editor = {Maglogiannis, Ilias and Iliadis, Lazaros and Macintyre,
		  John and Avlonitis, Markos and Papaleonidas, Antonios},
	date = {2024},
	pages = {360--374},
	publisher = {Springer Nature Switzerland},
	location = {Cham},
	doi = {10.1007/978-3-031-63223-5_27},
	abstract = {In Search and Rescue (SAR) missions, the integration of
		  multiple sources of information may enhance operational
		  efficiency and increase responsiveness significantly,
		  improving situation awareness and aiding decision-making to
		  save lives and mitigate incident impact. Ontologies are
		  crucial for integrating and reasoning with data from
		  diverse sources. Engineering a domain ontology for SAR can
		  be better supported from an agile, collaborative, and
		  iterative ontology engineering methodology (OEM),
		  incorporating the interests of several stakeholders. Large
		  Language Models (LLMs) can play a significant role in
		  completing OEM processes. The goal of this work is to
		  identify how ontology engineering (OE) tasks can be
		  completed with the collaboration of LLMs and humans. The
		  objectives of this paper are, a) to present preliminary
		  exploration of LLMs to generate domain ontologies for the
		  modeling of SAR missions in wildfire incidents b) to
		  propose and evaluate an LLM-enhanced OE approach. In
		  overall, the main contribution of the work presented in
		  this paper is the analysis of LLMs capabilities to ontology
		  engineering, and the evaluation of the synergy between
		  humans and machines to efficiently represent knowledge,
		  with specific focus in the SAR domain.},
	isbn = {978-3-031-63223-5},
	langid = {english},
	keywords = {Large Language Models,Ontology Engineering,Search and
		  Rescue},
	timestamp = {2024-09-12T09:47:07Z}
}

@InProceedings{eells2024CommonsenseOntologyMicropatterns,
	author = {Eells, A. and Dave, B. and P, Hitzler and Shimizu, C.},
	date = {2024},
	title = {Commonsense ontology micropatterns},
	publisher = {Springer},
	pages = {51–59},
	booktitle = {International Conference on Neural-Symbolic Learning and
		  Reasoning}
}

@Misc{fathallah2024Llms4lifeLargeLanguage,
	author = {Fathallah, N. and S, Staab and Algergawy, A.},
	date = {2024},
	title = {Llms4life: Large language models for ontology learning in
		  life sciences},
	note = {arXiv preprint arXiv:2412.02035 .},
	arxiv = {2412.02035}
}

@InProceedings{funk2023TowardsOntologyConstruction,
	file = {References/pdf/funk2023TowardsOntologyConstruction.pdf},
	title = {Towards {{Ontology Construction}} with {{Language
		  Models}}},
	booktitle = {{{KBC-LM}} @ {{ISWC}} 2023},
	author = {Funk, Maurice and Hosemann, Simon and Jung, Jean Christoph
		  and Lutz, Carsten},
	date = {2023},
	doi = {10.48550/arXiv.2309.09898},
	abstract = {An academic search engine that utilizes artificial
		  intelligence methods to provide highly relevant results and
		  novel tools to filter them with ease.},
	langid = {english},
	timestamp = {2024-07-25T09:10:54Z}
}

@InProceedings{giglou2024Llms4ol2024Datasets,
	author = {Giglou, H.B. and D’Souza, J. and S, Sadruddin and Auer,
		  S.},
	date = {2024},
	title = {Llms4ol 2024 datasets: Toward ontology learning with large
		  language models},
	volume = {4},
	pages = {17–30},
	booktitle = {Open Conference Proceedings}
}

@Article{giri2024Go2sumGeneratingHuman,
	author = {Giri, S.J. and N, Ibtehaz and Kihara, D.},
	date = {2024},
	title = {Go2sum: generating human-readable functional summary of
		  proteins from go terms},
	volume = {10},
	pages = {29},
	journal = {npj Systems Biology and Applications},
	number = {1}
}

@Article{glauer2024InterpretableOntologyExtension,
	author = {Glauer, M. and Memariani, A. and Neuhaus, F. and T,
		  Mossakowski and Hastings, J.},
	date = {2024},
	title = {Interpretable ontology extension in chemistry},
	volume = {15},
	pages = {937–958},
	journal = {Semantic Web},
	number = {4}
}

@InProceedings{goyal2024SilpNlpAt,
	author = {Goyal, P.K. and S, Singh and Tiwary, U.S.},
	date = {2024},
	title = {silp_nlp at llms4ol 2024 tasks a, b, and c: Ontology
		  learning through prompts with llms},
	volume = {4},
	pages = {31–38},
	booktitle = {Open Conference Proceedings}
}

@InProceedings{h2023Llms4olLargeLanguage,
	author = {H, Babaei Giglou and J, D.’Souza and S, Auer},
	date = {2023},
	title = {Llms4ol: Large language models for ontology learning},
	publisher = {Springer},
	pages = {408–427},
	booktitle = {International Semantic Web Conference}
}

@InProceedings{he2023ExploringLargeLanguage,
	file = {References/pdf/he2023ExploringLargeLanguage.pdf},
	title = {Exploring Large Language Models for Ontology Alignment},
	booktitle = {Proceedings of the {{ISWC}} 2023 Posters, Demos and
		  Industry Tracks: {{From}} Novel Ideas to Industrial
		  Practice Co-Located with 22nd International Semantic Web
		  Conference ({{ISWC}} 2023), Athens, Greece, November 6-10,
		  2023},
	author = {He, Yuan and Chen, Jiaoyan and Dong, Hang and Horrocks,
		  Ian},
	editor = {Fundulaki, Irini and Kozaki, Kouji and Garijo, Daniel and
		  Gómez-Pérez, José Manuél},
	date = {2023},
	series = {{{CEUR}} Workshop Proceedings},
	volume = {3632},
	publisher = {CEUR-WS.org},
	bibsource = {dblp computer science bibliography, https://dblp.org},
	timestamp = {Mon, 03 Jun 2024 15:23:14 +0200}
}

@InProceedings{he2023LanguageModelAnalysis,
	file = {References/pdf/he2023LanguageModelAnalysis.pdf},
	title = {Language {{Model Analysis}} for {{Ontology Subsumption
		  Inference}}},
	booktitle = {Findings of the {{Association}} for {{Computational
		  Linguistics}}: {{ACL}} 2023},
	author = {He, Yuan and Chen, Jiaoyan and Jimenez-Ruiz, Ernesto and
		  Dong, Hang and Horrocks, Ian},
	editor = {Rogers, Anna and Boyd-Graber, Jordan and Okazaki, Naoaki},
	date = {2023-07},
	pages = {3439--3453},
	publisher = {Association for Computational Linguistics},
	location = {Toronto, Canada},
	doi = {10.18653/v1/2023.findings-acl.213},
	abstract = {Investigating whether pre-trained language models (LMs)
		  can function as knowledge bases (KBs) has raised wide
		  research interests recently. However, existing works focus
		  on simple, triple-based, relational KBs, but omit more
		  sophisticated, logic-based, conceptualised KBs such as OWL
		  ontologies. To investigate an LM's knowledge of ontologies,
		  we propose OntoLAMA, a set of inference-based probing tasks
		  and datasets from ontology subsumption axioms involving
		  both atomic and complex concepts. We conduct extensive
		  experiments on ontologies of different domains and scales,
		  and our results demonstrate that LMs encode relatively less
		  background knowledge of Subsumption Inference (SI) than
		  traditional Natural Language Inference (NLI) but can
		  improve on SI significantly when a small number of samples
		  are given. We will open-source our code and datasets.},
	timestamp = {2024-08-15T09:50:24Z}
}

@Article{joachimiak2024ArtificialIntelligenceOntology,
	author = {Joachimiak, M.P. and Miller, M.A. and Caufield, J.H. and
		  Ly, R. and Harris, N.L. and Tritt, A. and CJ, Mungall and
		  Bouchard, K.E.},
	date = {2024},
	title = {The artificial intelligence ontology: LLM-assisted
		  construction of ai concept hierarchies},
	volume = {},
	pages = {15705838241304103},
	journal = {Applied Ontology}
}

@InProceedings{kholmska2024EnhancingOntologyEngineering,
	author = {Kholmska, G. and K, Kenda and Rozanec, J.},
	date = {2024},
	title = {Enhancing ontology engineering with LLMs: From search to
		  active learning extensions},
	booktitle = {Proceedings of Data Mining and Data Warehauses – Sikdd
		  2024}
}

@InProceedings{lippolis2024OntogeniaOntologyGeneration,
	author = {Lippolis, A.S. and Ceriani, M. and S, Zuppiroli and
		  Nuzzolese, A.G.},
	date = {2024},
	title = {Ontogenia: Ontology generation with metacognitive
		  prompting in large language models},
	publisher = {Springer},
	pages = {259–265},
	booktitle = {European Semantic Web Conference}
}

@Misc{lippolis2025OntologyGenerationUsing,
	author = {Lippolis, A.S. and Saeedizade, M.J. and Keskisärkkä, R.
		  and Zuppiroli, S. and Ceriani, M. and Gangemi, A. and E,
		  Blomqvist and Nuzzolese, A.G.},
	date = {2025},
	title = {Ontology generation using large language models},
	note = {arXiv preprint arXiv:2503.05388 .},
	arxiv = {2503.05388}
}

@InProceedings{liu2025OntotuneOntologyDriven,
	author = {Liu, Z. and Gan, C. and Wang, J. and Zhang, Y. and Bo, Z.
		  and Sun, M. and H, Chen and Zhang, W.},
	date = {2025},
	title = {OntoTune: Ontology-driven self-training for aligning large
		  language models},
	pages = {119–133},
	booktitle = {Proceedings of the ACM on Web Conference}
}

@InProceedings{lmv2024UseLargeLanguage,
	author = {LMV, Silva and A, Kocher and F, Gehlhoff and A, Fay},
	date = {2024},
	title = {On the use of large language models to generate capability
		  ontologies},
	pages = {1–8},
	booktitle = {2024 IEEE 29th International Conference on Emerging
		  Technologies and Factory Automation (ETFA). IEEE}
}

@Misc{lo2024EndEndOntology,
	author = {Lo, A. and Jiang, A.Q. and W, Li and Jamnik, M.},
	date = {2024},
	title = {End-to-end ontology learning with large language models},
	note = {arXiv preprint arXiv:2410.23584 .},
	arxiv = {2410.23584}
}

@InBook{mai2024DoLlmsReally,
	file = {References/pdf/mai2024DoLlmsReally.pdf},
	title = {Do LLMs Really Adapt to Domains? An Ontology Learning
		  Perspective},
	year = 2024,
	author = {Mai, Huu Tan and Chu, Cuong Xuan and Paulheim, Heiko},
	booktitle = {The Semantic Web – ISWC 2024},
	publisher = {Springer Nature Switzerland},
	isbn = 9783031778445,
	pages = {126–143},
	doi = {10.1007/978-3-031-77844-5_7},
	url = {http://dx.doi.org/10.1007/978-3-031-77844-5_7},
	issn = {1611-3349},
	month = nov
}

@Article{mateiu2023OntologyEngineeringWith,
	file = {References/pdf/mateiu2023OntologyEngineeringWith.pdf},
	title = {Ontology Engineering with {{Large Language Models}}},
	author = {Mateiu, Patricia and Groza, Adrian},
	date = {2023-09},
	journaltitle = {2023 25th International Symposium on Symbolic and Numeric
		  Algorithms for Scientific Computing (SYNASC)},
	pages = {226--229},
	publisher = {IEEE},
	location = {Nancy, France},
	doi = {10.1109/SYNASC61333.2023.00038},
	abstract = {We tackle the task of enriching ontologies by
		  automatically translating natural language (NL) into
		  Description Logic (DL). Since Large Language Models (LLMs)
		  are the best tools for translations, we fine-tuned a GPT-3
		  model to convert NL into OWL Functional Syntax. For
		  fine-tuning, we designed pairs of sentences in NL and the
		  corresponding translations. This training pairs cover
		  various aspects from ontology engineering: instances, class
		  subsumption, domain and range of relations, object
		  properties relationships, disjoint classes, complements, or
		  cardinality restrictions. The resulted axioms are used to
		  enrich an ontology, in a human supervised manner. The
		  developed tool is publicly provided as a Protégé
		  plugin.},
	isbn = {9798350394122},
	timestamp = {2024-08-15T09:04:33Z}
}

@InProceedings{mj2023AutomatingGenerationCompetency,
	author = {MJ, Antia and CM, Keet},
	date = {2023},
	title = {Automating the generation of competency questions for
		  ontologies with agocqs},
	publisher = {Springer},
	pages = {213–227},
	booktitle = {Iberoamerican Knowledge Graphs and Semantic Web
		  Conference}
}

@InProceedings{mj2024NavigatingOntologyDevelopment,
	author = {MJ, Saeedizade and E, Blomqvist},
	date = {2024},
	title = {Navigating ontology development with large language
		  models},
	publisher = {Springer},
	pages = {143–161},
	doi = {10.1007/978-3-031-60626-7_8.},
	booktitle = {European Semantic Web Conference}
}

@Article{mukanova2024LlmPoweredNatural,
	author = {Mukanova, A. and Milosz, M. and Dauletkaliyeva, A. and
		  Nazyrova, A. and Yelibayeva, G. and D, Kuzin and Kussepova,
		  L.},
	date = {2024},
	title = {LLM-powered natural language text processing for ontology
		  enrichment},
	volume = {14},
	doi = {10.3390/app14135860.},
	url = {https://www.mdpi.com/2076-3417/14/13/5860.},
	journal = {Applied Sciences},
	number = {13}
}

@Misc{nakano2021WebgptBrowserAssisted,
	title = {Webgpt: Browser-assisted question-answerign with human
		  feedback},
	author = {Nakano, R. and Hilton, J. and Balaji, S. and Wu, J. and
		  Ouyang, L. and Kim, C. and Hesse, C. and Jain, S. and
		  Kosaraju, V. and W, Saunders},
	date = {2021},
	note = {Webgpt: Browser-assisted question-answering with human
		  feedback. arXiv preprint arXiv:2112.09332 .},
	arxiv = {2112.09332}
}

@Misc{norouzi2023ConversationalOntologyAlignment,
	author = {Norouzi, S.S. and MS, Mahdavinejad and Hitzler, P.},
	date = {2023},
	title = {Conversational ontology alignment with chatgpt},
	note = {arXiv preprint arXiv:2308.09217 .},
	arxiv = {2308.09217}
}

@Misc{o2024ExploringLargeLanguage,
	author = {O, Perera and J, Liu},
	date = {2024},
	title = {Exploring large language models for ontology learning}
}

@InProceedings{p2023OntologyEngineeringWith,
	author = {P, Mateiu and A, Groza},
	date = {2023},
	title = {Ontology engineering with large language models},
	pages = {226–229},
	booktitle = {2023 25th International Symposium on Symbolic and Numeric
		  Algorithms for Scientific Computing (SYNASC). IEEE}
}

@InCollection{pisu2024LeveragingLanguageModels,
	author = {Pisu, A. and Pompianu, L. and Salatino, A. and Osborne, F.
		  and Riboni, D. and E, Motta and Recupero, D.R.},
	date = {2024},
	title = {Leveraging language models for generating ontologies of
		  research topics},
	url = {https://ceur-ws.org/Vol-3747/text2kg%5fpaper6.pdf.},
	booktitle = {Text2KG 2024: International Workshop on Knowledge Graph
		  Generation from Text URL}
}

@Misc{r2025EnhancingLargeLanguage,
	author = {R, Idelfonso Magana Vsevolodovna and M, Monti},
	date = {2025},
	title = {Enhancing large language models through neuro-symbolic
		  integration and ontological reasoning},
	note = {arXiv e-prints : arXiv–2504.}
}

@InProceedings{rebboud2024BenchmarkingLlmBased,
	author = {Rebboud, Y. and Lisena, P. and L, Tailhardat and Troncy,
		  R.},
	date = {2024},
	title = {Benchmarking llm-based ontology conceptualization: A
		  proposal},
	booktitle = {ISWC 2024, 23rd International Semantic Web Conference}
}

@InProceedings{rebboud2024CanLlmsGenerate,
	author = {Rebboud, Y. and Tailhardat, L. and P, Lisena and Troncy,
		  R.},
	date = {2024},
	title = {Can llms generate competency questions?},
	booktitle = {ESWC 2024, Extended Semantic Web Conference}
}

@InProceedings{s2023OlalaOntologyMatching,
	author = {S, Hertling and H, Paulheim},
	date = {2023},
	title = {Olala: Ontology matching with large language models},
	pages = {131–139},
	booktitle = {Proceedings of the 12th Knowledge Capture Conference}
}

@Article{sahbi2024AutomaticOntologyPopulation,
	author = {Sahbi, A. and C, Alec and Beust, P.},
	date = {2024},
	title = {Automatic ontology population from textual advertisements:
		  LLM vs. semantic approach},
	volume = {246},
	pages = {3083–3092},
	journal = {Procedia Computer Science}
}

@Misc{singh2023AssessingGpt4V,
	title = {Assessing GPT4-v on structure reasoning tasks},
	author = {Singh, M. and Cambronero, J. and Gulwani, S. and V, Le and
		  Verbruggen, G.},
	date = {2023},
	note = {Assessing gpt4-v on structured reasoning tasks. arXiv
		  preprint arXiv:2312.11524 .},
	arxiv = {2312.11524}
}

@Article{snijder2024AdvancingOntologyAlignment,
	file = {References/pdf/snijder2024AdvancingOntologyAlignment.pdf},
	title = {Advancing {{Ontology Alignment}} in the {{Labor Market}}:
		  {{Combining Large Language Models}} with {{Domain
		  Knowledge}}},
	shorttitle = {Advancing {{Ontology Alignment}} in the {{Labor Market}}},
	author = {Snijder, Lucas L. and Smit, Quirine T. S. and family=Boer,
		  given=Maaike H. T., prefix=de, useprefix=true},
	date = {2024-05},
	journaltitle = {Proceedings of the AAAI Symposium Series},
	volume = {3},
	number = {1},
	pages = {253--262},
	issn = {2994-4317},
	doi = {10.1609/aaaiss.v3i1.31208},
	abstract = {One of the approaches to help the demand and supply
		  problem in the labor market domain is to change from
		  degree-based hiring to skill-based hiring. The link between
		  occupations, degrees and skills is captured in domain
		  ontologies such as ESCO in Europe and O*NET in the US.
		  Several countries are also building or extending these
		  ontologies. The alignment of the ontologies is important,
		  as it should be clear how they all relate. Aligning two
		  ontologies by creating a mapping between them is a tedious
		  task to do manually, and with the rise of generative large
		  language models like GPT-4, we explore how language models
		  and domain knowledge can be combined in the matching of the
		  instances in the ontologies and in finding the specific
		  relation between the instances (mapping refinement). We
		  specifically focus on the process of updating a mapping,
		  but the methods could also be used to create a first-time
		  mapping. We compare the performance of several
		  state-of-the-art methods such as GPT-4 and fine-tuned BERT
		  models on the mapping between ESCO and O*NET and ESCO and
		  CompetentNL (the Dutch variant) for both ontology matching
		  and mapping refinement. Our findings indicate that: 1)
		  Match-BERT-GPT, an integration of BERT and GPT, performs
		  best in ontology matching, while 2) TaSeR outperforms
		  GPT-4, albeit marginally, in the task of mapping
		  refinement. These results show that domain knowledge is
		  still important in ontology alignment, especially in the
		  updating of a mapping in our use cases in the labor
		  domain.},
	copyright = {Copyright (c) 2024 Association for the Advancement of
		  Artificial Intelligence},
	langid = {english},
	keywords = {O*NET},
	timestamp = {2024-09-16T11:59:33Z}
}

@InProceedings{tang2023DomainKnowledgeDistillation,
	author = {Tang, Y. and Costa, A.A.B. and Zhang, X. and Patrick, I.
		  and S, Khastgir and Jennings, P.},
	date = {2023},
	title = {Domain knowledge distillation from large language model:
		  An empirical study in the autonomous driving domain},
	pages = {3893–3900},
	booktitle = {2023 IEEE 26th International Conference on Intelligent
		  Transportation Systems (ITSC). IEEE}
}

@InProceedings{tian2023EnhancingOntologyTranslation,
	author = {Tian, M. and Giunchiglia, F. and Song, R. and X, Chen and
		  Xu, H.},
	date = {2023},
	title = {Enhancing ontology translation through cross-lingual
		  agreement},
	pages = {1–5},
	booktitle = {ICASSP 2023-2023 IEEE International Conference on
		  Acoustics, Speech and Signal Processing (ICASSP). IEEE}
}

@Article{toro2024DynamicRetrievalAugmented,
	author = {Toro, S. and Anagnostopoulos, A.V. and Bello, S.M. and
		  Blumberg, K. and Cameron, R. and Carmody, L. and Diehl,
		  A.D. and Dooley, D.M. and Duncan, W.D. and P, Fey},
	date = {2024},
	title = {Dynamic retrieval augmented generation of ontologies using
		  artificial intelligence (dragon-ai},
	volume = {15},
	pages = {19},
	journal = {Journal of Biomedical Semantics},
	number = {1}
}

@InProceedings{tufek2024ValidatingSemanticArtifacts,
	author = {Tufek, N. and A, Saissre and Hanbury, A.},
	date = {2024},
	title = {Validating semantic artifacts with large language models},
	publisher = {Krete},
	pages = {24–30},
	booktitle = {Proceedings of the 21th European Semantic Web Conference
		  (ESWC},
	address = {Greece}
}

@Misc{west2021SymbolicKnowledgeDistillation,
	author = {West, P. and Bhagavatula, C. and Hessel, J. and Hwang,
		  J.D. and Jiang, L. and Bras, R.L. and Lu, X. and S, Welleck
		  and Choi, Y.},
	date = {2021},
	title = {Symbolic knowledge distillation: from general language
		  models to commonsense models},
	note = {arXiv preprint arXiv:2110.07178 .},
	arxiv = {2110.07178}
}

@InProceedings{yang2024LlmSupportedApproach,
	file = {References/pdf/yang2024LlmSupportedApproach.pdf},
	author = {Yang, Hang and Xiao, Liang and Zhu, Rujun and Liu, Ziji
		  and Chen, Jianxia},
	title = {An LLM supported approach to ontology and knowledge graph
		  construction},
	year = 2024,
	booktitle = {2024 IEEE International Conference on Bioinformatics and
		  Biomedicine (BIBM)},
	publisher = {IEEE},
	month = dec,
	pages = {5240–5246},
	doi = {10.1109/bibm62325.2024.10822222},
	url = {http://dx.doi.org/10.1109/BIBM62325.2024.10822222}
}

@InProceedings{zamazal2024TowardsPatternBased,
	author = {Zamazal, O.},
	date = {2024},
	title = {Towards pattern-based complex ontology matching using
		  sparql and llm},
	booktitle = {Proceedings of the 20th International Conference on
		  Semantic Systems (SEMANTiCS 2024), SEMANTiCS},
	address = {Amsterdam, Netherlands}
}

@Article{zhang2025OntochatFrameworkConversational,
	author = {Zhang, B. and Carriero, V.A. and Schreiberhuber, K. and
		  Tsaneva, S. and González, L.S. and J, Kim and Berardinis,
		  J. and A, Meroño Peñuela and O, Corcho and P, Groth and
		  E, Simperl and V, Tamma and AG, Nuzzolese and M,
		  Poveda-Villalón and M, Sabou and Presutti},
	date = {2025},
	title = {Ontochat: A framework for conversational ontology
		  engineering using language models},
	editor = {V, Celino I. and A, Revenko and J, Raad and B, Sartini and
		  P, Lisena},
	publisher = {Springer Nature Switzerland},
	pages = {102–121},
	journal = {The Semantic Web: ESWC 2024 Satellite Events},
	address = {Cham}
}


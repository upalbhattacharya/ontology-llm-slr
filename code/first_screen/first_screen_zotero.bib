
@article{abdelmageed2023BiodivbertPreTrained,
	file = {References/pdf/abdelmageed2023BiodivbertPreTrained.pdf},
	title = {{BiodivBERT}: a {Pre}-{Trained} {Language} {Model} for the {Biodiversity} {Domain}},
	volume = {3415},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165793172&partnerID=40&md5=8cca4477cb76fca65e4b133871920cbf},
	abstract = {Information Extraction in the Life Sciences is getting increasing attention due to the constantly growing amount of data and text. The advancements of deep learning models further accelerate this development. However, applying these models to domain-specific data is crucial as applied domains often require different entity type extractions than general ones. This paper introduces BiodivBERT, the first pre-trained language model for the biodiversity domain. We constructed two pre-training corpora (abstracts and abstracts + full text) based on a keyword search strategy from two leading publishers in the Life Sciences. In addition, we fine-tuned BiodivBERT on two downstream tasks, i.e., Named Entity Recognition (NER) and Relation Extraction (RE), using various state-of-the-art benchmarks. The results show that BiodivBERT outperforms the state-of-the-art approaches. Moreover, we discuss a potential application of BiodivBERT for ontology auto-population. We publicly release data and code for both pre-training and fine-tuning. © 2023 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Abdelmageed, Nora and Löffler, Felicitas and König-Ries, Birgitta},
	year = {2023},
	note = {Section: 0},
	keywords = {Language model, Biodiversity, BERT, Deep learning, Search engines, Pre-training, Computational linguistics, Abstracting, Domain specific, Learning models, Fine tuning, Life-sciences, Entity-types, Training corpus, Keyword search},
	pages = {62 -- 71},
	annote = {Type: Conference paper}
}

@article{abolhasani2025OntokgenGenuineOntology,
	title = {{OntoKGen}: {A} {Genuine} {Ontology} and {Knowledge} {Graph} {Generator} {Using} {Large} {Language} {Model}},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105002271575&doi=10.1109%2FRAMS48127.2025.10935139&partnerID=40&md5=a1dda94eab8edc38426e8bfe96221f84},
	doi = {10.1109/RAMS48127.2025.10935139},
	abstract = {Extracting relevant and structured knowledge from large, complex technical documents within the Reliability and Maintainability (RAM) domain is labor-intensive and prone to errors. Our work addresses this challenge by presenting OntoKGen, a Genuine pipeline for Ontology extraction and Knowledge Graph (KG) generation. OntoKGen leverages Large Language Models (LLMs) through an interactive user interface guided by our adaptive iterative Chain of Thought (CoT) algorithm to ensure that the ontology extraction process and, thus, KG generation align with user-specific requirements. Although KG generation follows a clear, structured path based on the confirmed ontology, there is no universally correct ontology as it is inherently based on the user's preferences. OntoKGen recommends an ontology grounded in best practices, minimizing user effort and providing valuable insights that may have been overlooked, all while giving the user complete control over the final ontology. Having generated the KG based on the confirmed ontology, OntoKGen enables seamless integration into schemeless, non-relational databases like Neo4j. This integration allows for flexible storage and retrieval of knowledge from diverse, unstructured sources, facilitating advanced querying, analysis, and decision-making. Moreover, the generated KG serves as a robust foundation for future integration into Retrieval-Augmented Generation (RAG) systems, offering enhanced capabilities for developing domain-specific intelligent applications.},
	journal = {2025 Annual Reliability and Maintainability Symposium (RAMS)},
	author = {Abolhasani, Mohammad Sadeq and Pan, Rong},
	month = jan,
	year = {2025},
	note = {Section: 0},
	keywords = {Ontologies, Knowledge graphs, Knowledge graph, Large language model, Ontology, Language model, Large language models, Retrieval augmented generation, Prompt Engineering, Large Language Model, Neo4j, Prompt engineering, Ontology Extraction, Pipelines, Generators, Neo4J, Ontology and Knowledge Graph Generator, Random access memory, Reliability engineering, User interfaces, Structured Query Language, Ontology's, Ontology graphs, Query languages, Relational database systems, Graph generation, Ontology and knowledge graph generator, Cannot download},
	pages = {1--6},
	annote = {ISSN: 2577-0993}
}

@article{aggarwal2024IdentifyingSemanticRelationships,
	file = {References/pdf/aggarwal2024IdentifyingSemanticRelationships.pdf},
	title = {Identifying {Semantic} {Relationships} {Between} {Research} {Topics} {Using} {Large} {Language} {Models} in a {Zero}-{Shot} {Learning} {Setting}},
	volume = {3780},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207042155&partnerID=40&md5=595559c5582ddfa5a9fb95c64b924450},
	abstract = {Knowledge Organization Systems (KOS), such as ontologies, taxonomies, and thesauri, play a crucial role in organising scientific knowledge. They help scientists navigate the vast landscape of research literature and are essential for building intelligent systems such as smart search engines, recommendation systems, conversational agents, and advanced analytics tools. However, the manual creation of these KOSs is costly, time-consuming, and often leads to outdated and overly broad representations. As a result, researchers have been exploring automated or semi-automated methods for generating ontologies of research topics. This paper analyses the use of large language models (LLMs) to identify semantic relationships between research topics. We specifically focus on six open and lightweight LLMs (up to 10.7 billion parameters) and use two zero-shot reasoning strategies to identify four types of relationships: broader, narrower, same-as, and other. Our preliminary analysis indicates that Dolphin2.1-OpenOrca-7B performs strongly in this task, achieving a 0.853 F1-score against a gold standard of 1,000 relationships derived from the IEEE Thesaurus. These promising results bring us one step closer to the next generation of tools for automatically curating KOSs, ultimately making the scientific literature easier to explore. © 2024 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Aggarwal, Tanay and Salatino, Angelo Antonio and Osborne, Francesco and Motta, Enrico},
	year = {2024},
	note = {Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Large language model, Ontology, Language model, Semantics, Taxonomies, Ontology generation, Semantic relationships, Federated learning, Recommender systems, Latent semantic analysis, Zero-shot learning, Adversarial machine learning, Ontology's, Contrastive Learning, Knowledge organization system (KOS), Scientific knowledge, Scientific knowledge graph, Research topics, Scholarly knowledge},
	annote = {Type: Conference paper}
}

@article{agrawal2024BoostingEntityRecognition,
	file = {References/pdf/agrawal2024BoostingEntityRecognition.pdf},
	series = {{CIKM} '24},
	title = {Boosting {Entity} {Recognition} by leveraging {Cross}-task {Domain} {Models} for {Weak} {Supervision}},
	url = {https://doi.org/10.1145/3627673.3680009},
	doi = {10.1145/3627673.3680009},
	abstract = {Entity Recognition (ER) is a common natural language processing task encountered in a number of real-world applications. For common domains and named entities such as places and organisations, there exists sufficient high quality annotated data and foundational models such as T5 and GPT-3.5 also provide highly accurate predictions. However, for niche domains such as e-commerce and medicine with specialized entity types, there is a paucity of labeled data since manual labeling of tokens is often time-consuming and expensive, which makes entity recognition challenging for such domains. Recent works such as NEEDLE [48] propose hybrid solutions to efficiently combine a small amount of strongly labeled (human-annotated) with a large amount of weakly labeled (distant supervision) data to yield superior performance relative to supervised training. The extensive noise in the weakly labeled data, however, remains a challenge. In this paper, we propose WeSDoM (Weak Supervision with Domain Models), which leverages pretrained encoder models from the same domain but different tasks to create domain ontologies that can enable the creation of less noisy weakly labeled data. Experiments on internal e-commerce and public biomedical NER datasets demonstrate that WeSDoM outperforms existing SOTA baselines by a significant margin. We achieve new SOTA F1 scores on two popular Biomedical NER datasets, BC5CDR-chem 94.27, BC5CDR-disease 91.23.},
	journal = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
	author = {Agrawal, Sanjay and Merugu, Srujana and Sembium, Vivek},
	year = {2024},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery
Section: 0},
	keywords = {ontologies, entity recognition, weak supervision, cross-task domain encoder},
	pages = {4324--4331},
	annote = {event-place: Boise, ID, USA}
}

@article{alharbi2024ExperimentInRetrofitting,
	file = {References/pdf/alharbi2024ExperimentInRetrofitting.pdf},
	series = {{SAC} '24},
	title = {An {Experiment} in {Retrofitting} {Competency} {Questions} for {Existing} {Ontologies}},
	url = {https://doi.org/10.1145/3605098.3636053},
	doi = {10.1145/3605098.3636053},
	abstract = {Competency Questions (CQs) are a form of ontology functional requirements expressed as natural language questions. Inspecting CQs together with the axioms in an ontology provides critical insights into the intended scope and applicability of the ontology. CQs also underpin a number of tasks in the development of ontologies e.g. ontology reuse, ontology testing, requirement specification, and the definition of patterns that implement such requirements. Although CQs are integral to the majority of ontology engineering methodologies, the practice of publishing CQs alongside the ontological artefacts is not widely observed by the community.In this context, we present an experiment in retrofitting CQs from existing ontologies. We propose RETROFIT-CQs, a method to extract candidate CQs directly from ontologies using Generative AI. In the paper we present the pipeline that facilitates the extraction of CQs by leveraging Large Language Models (LLMs) and we discuss its application to a number of existing ontologies.},
	journal = {Proceedings of the 39th ACM/SIGAPP Symposium on Applied Computing},
	author = {Alharbi, Reham and Tamma, Valentina and Grasso, Floriana and Payne, Terry},
	year = {2024},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery
Section: 0},
	keywords = {Ontology engineering, Large language model, Ontology, Language model, large language models, Ontology reuse, Competency question, ontology engineering, Computational linguistics, competency questions, Ontology's, Natural language processing systems, Functional requirement, Natural language questions, Retrofitting, Testing requirements, Requirements specifications},
	pages = {1650--1658},
	annote = {event-place: Avila, Spain}
}

@article{alharbi2025RoleGenerativeAi,
	file = {References/pdf/alharbi2025RoleGenerativeAi.pdf},
	title = {The {Role} of {Generative} {AI} in {Competency} {Question} {Retrofitting}},
	volume = {15344},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218447447&doi=10.1007%2F978-3-031-78952-6_1&partnerID=40&md5=de488f84c86cb908b9bf333e648ed84e},
	doi = {10.1007/978-3-031-78952-6_1},
	abstract = {Competency Questions (CQs) are essential in ontology engineering; they express an ontology’s functional requirements as natural language questions, offer crucial insights into an ontology’s scope and are pivotal for various tasks, e.g. ontology reuse, testing, requirement specification, and pattern definition. Despite their importance, the practice of publishing CQs alongside ontological artefacts is not commonly adopted. We propose an approach based on Generative AI, specifically Large Language Models (LLMs) for retrofitting CQs from existing ontologies and we study how the control parameters in two LLMs (i.e. gpt-3.5-turbo and gpt-4) affect their performance and investigate the interplay between prompts and configuration for retrofitting viable CQs. © 2025 Elsevier B.V., All rights reserved.},
	journal = {Lecture Notes in Computer Science},
	author = {Alharbi, Reham and Tamma, Valentina A.M. and Grasso, Floriana and Payne, Terry R.},
	year = {2025},
	note = {Section: 0},
	keywords = {Ontology engineering, Large language model, Ontology, Language model, Ontology reuse, Competency question, Requirements engineering, Ontology's, C (programming language), Functional requirement, Generative adversarial networks, Natural language questions, Ontology Engineering Methodologies, Retrofitting, Testing requirements, Incorrect information},
	pages = {3 -- 13},
	annote = {Type: Conference paper}
}

@article{amini2025TowardsComplexOntology,
	file = {References/pdf/amini2025TowardsComplexOntology.pdf},
	title = {Towards {Complex} {Ontology} {Alignment} {Using} {Large} {Language} {Models}},
	volume = {15459},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218934218&doi=10.1007%2F978-3-031-81221-7_2&partnerID=40&md5=0ceb4a7e31a8a179e3d1efda57c8567e},
	doi = {10.1007/978-3-031-81221-7_2},
	abstract = {Ontology alignment, a critical process in the Semantic Web for detecting relationships between different ontologies, has traditionally focused on identifying so-called “simple” 1-to-1 relationships through class labels and properties comparison. The more practically useful exploration of more complex alignments remains a hard problem to automate, and as such is largely underexplored, i.e. in application practice it is usually done manually by ontology and domain experts. Recently, the surge in Natural Language Processing (NLP) capabilities, driven by advancements in Large Language Models (LLMs), presents new opportunities for enhancing ontology engineering practices, including ontology alignment tasks. This paper investigates the application of LLM technologies to tackle the complex ontology alignment challenge. Leveraging a prompt-based approach and integrating rich ontology content – so-called modules – our work constitutes a significant advance towards automating the complex alignment task. © 2025 Elsevier B.V., All rights reserved.},
	journal = {Lecture Notes in Computer Science},
	author = {Amini, Reihaneh and Norouzi, Sanaz Saki and Hitzler, Pascal Al and Amini, Reza},
	year = {2025},
	note = {Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Large language model, Ontology, Ontology model, Language model, Semantics, Modular ontologies, Ontology alignment, Modular ontology modeling, Modeling languages, Ontology's, Natural language processing systems, Semantic-Web, Complex ontology alignment},
	pages = {17 -- 31},
	annote = {Type: Conference paper}
}

@article{arevalo2025AutontoTowardsSemi,
	file = {References/pdf/arevalo2025AutontoTowardsSemi.pdf},
	title = {{AutOnto}: {Towards} {A} {Semi}-{Automated} {Ontology} {Engineering} {Methodology}},
	volume = {15459},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218935432&doi=10.1007%2F978-3-031-81221-7_16&partnerID=40&md5=ca4a284fddf4e697c1b7573d812ac843},
	doi = {10.1007/978-3-031-81221-7_16},
	abstract = {This paper addresses the challenge of efficiently constructing domain ontologies for large, rapidly evolving domains, where manual approaches often struggle to overcome knowledge acquisition bottlenecks. To overcome these limitations, we developed an automated framework, AutOnto, for knowledge extraction and ontology conceptualization that leverages Large Language Models (LLMs) and natural language processing (NLP) techniques. AutOnto integrates BERT-based topic modeling with LLMs to automate the extraction of concepts and relationships from text corpora, facilitating the construction of taxonomies and the generation of domain ontologies. We applied AutOnto to a dataset of NLP-specific articles from OpenAlex and compared the resulting ontology generated by our automated process against a well-established gold-standard ontology. The results indicate that AutOnto achieves comparable levels of quality and correctness while significantly reducing the amount of data required and the dependence on domain-specific expertise. These findings highlight AutOnto’s efficiency and effectiveness in knowledge extraction and ontology generation. This work has significant implications for rapid ontology development in large, evolving domains, potentially mitigating the knowledge acquisition bottleneck in ontology engineering. © 2025 Elsevier B.V., All rights reserved.},
	journal = {Lecture Notes in Computer Science},
	author = {Arevalo, Kiara Marnitt Ascencion and Ambre, Shruti and Dorsch, Rene},
	year = {2025},
	note = {Section: 0},
	keywords = {Knowledge acquisition, Ontology engineering, Large language model, Ontology, Natural language processing, Language model, Domain ontologies, Knowledge extraction, Modeling languages, Knowledge ontology, Taxonomies, Language processing, Natural languages, Domain Knowledge, Natural language processing systems, Knowledge acquisition bottlenecks},
	pages = {225 -- 241},
	annote = {Type: Conference paper}
}

@article{armary2024IdentifyingLogicalPatterns,
	file = {References/pdf/armary2024IdentifyingLogicalPatterns.pdf},
	title = {Identifying {Logical} {Patterns} in {Text} for {Reasoning}},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217432359&doi=10.1109%2FICTAI62512.2024.00122&partnerID=40&md5=57088e55fc285fbc3412ea1f7c228efb},
	doi = {10.1109/ICTAI62512.2024.00122},
	abstract = {Translating unstructured text into logical format is a key challenge for building ontologies automatically and addressing deductive inference. Most of the approaches have tackled the identification of concepts and relations in text, but few of them have addressed the most complex axioms like class expression subsumption. This work proposes DeLIR, a neuro-symbolic approach to identify complex logical patterns in text by combining a grammatical translation of dependency parsing trees and a fine-tuned Large language Model (LLM). DeLIR combines the strength of the parsing accuracy provided by a grammatical approach and pattern flexibility provided by a finetuned LLM. We evaluated our approach on FOLIO dataset for both translation capacity and inference capability. Our grammatical approach has a perfect parsing accuracy and combining the grammatical approach with LLMs improves the LLMS translation capacity: tinyLlama, T5-small-text2logic, Llama-7B and Mistral-7B. We also evaluate the inference capacity of the different LLMs. Mistral-7B, while being smaller than the state-of-the-art approach using GPT-4, presents similar results to predict the correct inference labels.},
	journal = {2024 IEEE 36th International Conference on Tools with Artificial Intelligence (ICTAI)},
	author = {Armary, Pauline and El-Vaigh, Cheikh-Brahim and Spicher, Antoine and Narsis, Ouassila Labbani and Nicolle, Christophe},
	month = oct,
	year = {2024},
	note = {Section: 0},
	keywords = {Ontologies, Ontology, Language model, Ontology learning, Large language models, Cognition, Ontology Learning, Natural language inference, Translation, Natural Language Inference, Accuracy, Language inference, Natural languages, Syntactics, Buildings, Zero shot learning, Hands, Translation to Logic, Ontology's, Contrastive Learning, Computer aided language translation, Unstructured texts, Computer circuits, Dependency parsing, State-of-the-art approach, Translation to logic},
	pages = {837--844},
	annote = {ISSN: 2375-0197}
}

@article{ayad2025OntologyPopulationWith,
	title = {Ontology {Population} {With} {Large} {Language} {Models} ({LLMs}): {A} {Case} {Study} on {Asbestos} {Ontology}},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009643870&doi=10.1177%2F15705838251334528&partnerID=40&md5=99260599b40b559e791145cd4b880519},
	doi = {10.1177/15705838251334528},
	abstract = {The Asbestos Ontology is a domain application ontology designed for use in an ontology-based approach that estimates the probability of the existence of asbestos products in a building. However, new issues in the building domain, such as predicting the presence of lead in buildings, renovating asbestos floors, or the reuse and recycling of components or parts of buildings as part of the circular economy, require a generalization of this ontology to a building ontology. The lack of relevant data tends to make decision-making difficult. The purpose of our approach is to show how instance-level knowledge graphs can be populated without having to manually create hundreds of instances using large language models (LLMs) and prompt engineering. This paper introduces a novel method for populating ontologies using the latest generative LLMs, such as GPT-3.5. Our method is characterized by an innovative recursive zero-shot prompting technique. The key contributions of this study are: (i) a new strategy for recursively prompting LLMs to elicit pertinent knowledge from the asbestos application domain; (ii) ontology population informed by the ontology metamodel; and (iii) formalization of the results into OWL axioms for the automatic integration of new instances. To evaluate the efficacy of our approach, we employed two main methodologies: (1) querying for instances linked to each entity; and (2) recursively querying for instances to leverage our recursive prompting strategy. Our initial strategy focused on evaluating the effectiveness of zero-shot prompting in retrieving relevant values for entities and data properties. This was facilitated through the development of the PromptGeneration function, which adjusted the input C{\textbackslash}textlessinf{\textbackslash}textgreateri{\textbackslash}textless/inf{\textbackslash}textgreater across various contexts. © 2025 Elsevier B.V., All rights reserved.},
	journal = {Applied Ontology},
	author = {Ayad, Sarah and Khelifa Chibout, Lydia},
	year = {2025},
	note = {Section: 0},
	keywords = {ChatGPT, Large language model, Ontology, Ontology Population, Language model, Knowledge management, Prompt engineering, Decision making, Ontology-based, Buildings, Ontology's, In-buildings, Case-studies, Asbestos, Reuse and recycling, Cannot download},
	annote = {Type: Article}
}

@article{baidya2024TowardFineTuning,
	file = {References/pdf/baidya2024TowardFineTuning.pdf},
	title = {Toward {Fine}-{Tuning} {Large} {Language} {Models} in {Ontology} of {Microbial} {Phenotypes} {Construction}},
	doi = {10.1109/BIBM62325.2024.10947604},
	abstract = {Ontologies are crucial for organizing domainspecific knowledge in biomedical fields, but their manual construction is time-consuming. This study explores the automation of ontology learning using large language models (LLMs) like BERT, RoBERTa, and DistilBERT, focusing on the Ontology of Microbial Phenotypes (OMP). We investigate three key tasks: (1) entity extraction, (2) relation extraction between entities, and (3) ontology verification. These tasks align with broader applications in biomedical annotation and named entity recognition (NER) by enabling the identification and structuring of key terms and relationships within microbial phenotypes. We evaluate LLMs in two scenarios: baseline performance using pre-trained models and fine-tuned performance after training on OMP-specific data. Our approach integrates spaCy for entity extraction, Llama 2 for relation identification, and LLMs for ontology verification. Experiments reveal that fine-tuned models significantly improve accuracy, precision, recall, and F1 scores, particularly for ontology verification. This research highlights the potential of LLMs to enhance ontology learning and support related biomedical applications like biofilm analysis, annotation, and NER, while emphasizing the value of expert curation.},
	journal = {2024 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)},
	author = {Baidya, Anushuya and Do, Tuyen and Gnimpieba, Etienne Z.},
	month = dec,
	year = {2024},
	note = {Section: 0},
	keywords = {Ontologies, Large Language Models, Named entity recognition, Large language models, Annotations, Fine-tuning, Ontology Learning, Data models, Training, Phenotypes, Manuals, Focusing, Biological system modeling, Microbial Phenotypes, Ontology Verification},
	pages = {6913--6920},
	annote = {ISSN: 2156-1133}
}

@article{bakker2024OntologyLearningText,
	file = {References/pdf/bakker2024OntologyLearningText.pdf},
	title = {Ontology {Learning} from {Text}: an {Analysis} on {LLM} {Performance}},
	volume = {3874},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214243423&partnerID=40&md5=8356243bab75422799ef66c7e3d26eff},
	abstract = {Ontologies provide a structured framework to represent and integrate domain knowledge. Developing them is a complex and time-consuming task, requiring domain expertise to ensure accuracy and consistency. Ontology learning aims to automate this process by learning full ontologies, or parts of them, from sources such as textual data. In this paper, we research the potential of Large Language Models (LLMs), specifically GPT-4o, in ontology learning, using a real-world use case. We introduce a manually constructed ontology based on knowledge in a news article, and compare it to ontologies extracted using three different prompting approaches over multiple runs. The resulting ontologies are evaluated both quantitatively and qualitatively, to ensure that differences in performance due to modelling choices are also considered. The results show that, while the LLM effectively identifies important classes and individuals, it often does not include properties between classes, and adds inconsistent and incorrect properties between individuals. Prompting on a sentence level leads to more correct individuals and properties, however, quantitative evaluation shows more hallucinations and incorrect triples. Despite these issues, LLMs advance previous ontology learning methods by considering classes, individuals, and properties as a whole, creating a more complete ontology rather than isolated elements. This provides a new perspective on ontology learning and highlights the potential of LLMs to offer a first version of an ontology or an extension to an existing one based on new information. © 2025 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Bakker, Roos M. and Di Scala, Daan L. and de Boer, Maaike H.T.},
	year = {2024},
	note = {Section: 0},
	keywords = {Knowledge graphs, Information extraction, Knowledge graph, Large language model, Language model, Ontology learning, Federated learning, Adversarial machine learning, Ontology's, Contrastive Learning, Property, Graph extractions, Learning from texts, Knowledge graph extraction},
	pages = {70 -- 87},
	annote = {Type: Conference paper}
}

@article{banerjee2024CrossLingualOntology,
	file = {References/pdf/banerjee2024CrossLingualOntology.pdf},
	title = {Cross-{Lingual} {Ontology} {Matching} using {Structural} and {Semantic} {Similarity}},
	url = {https://aclanthology.org/2024.ldl-1.2/},
	abstract = {The development of ontologies in various languages is attracting attention as the amount of multilingual data available on the web increases. Cross-lingual ontology matching facilitates interoperability amongst ontologies in different languages. Although supervised machine learning-based methods have shown good performance on ontology matching, their application to the cross-lingual setting is limited by the availability of training data. Current state-of-the-art unsupervised methods for cross-lingual ontology matching focus on lexical similarity between entities. These approaches follow a two-stage pipeline where the entities are translated into a common language using a translation service in the first step followed by computation of lexical similarity between the translations to match the entities in the second step. In this paper we introduce a novel ontology matching method based on the fusion of structural similarity and cross-lingual semantic similarity. We carry out experiments using 3 language pairs and report substantial improvements on the performance of the lexical methods thus showing the effectiveness of our proposed approach. To the best of our knowledge this is the first work which tackles the problem of unsupervised ontology matching in the cross-lingual setting by leveraging both structural and semantic embeddings.},
	journal = {Proceedings of the 9th Workshop on Linked Data in Linguistics @ LREC-COLING 2024},
	author = {Banerjee, Shubhanker and Chakravarthi, Bharathi Raja and McCrae, John Philip},
	editor = {Chiarcos, Christian and Gkirtzou, Katerina and Ionov, Maxim and Khan, Fahad and McCrae, John P. and Ponsoda, Elena Montiel and Chozas, Patricia Martín},
	month = may,
	year = {2024},
	note = {Place: Torino, Italia
Publisher: ELRA and ICCL
Section: 0},
	pages = {11--21},
	annote = {RAYYAN-LABELS: Good for referencing}
}

@article{banerjee2024LargeLanguageModels,
	file = {References/pdf/banerjee2024LargeLanguageModels.pdf},
	title = {Large {Language} {Models} for {Few}-{Shot} {Automatic} {Term} {Extraction}},
	volume = {14762},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205377483&doi=10.1007%2F978-3-031-70239-6_10&partnerID=40&md5=1d8b90d62ef32b8cf5241528fc134779},
	doi = {10.1007/978-3-031-70239-6_10},
	abstract = {Automatic term extraction is the process of identifying domain-specific terms in a text using automated algorithms and is a key first step in ontology learning and knowledge graph creation. Large language models have shown good few-shot capabilities, thus, in this paper, we present a study to evaluate the few-shot in-context learning performance of GPT-3.5-Turbo on automatic term extraction. To benchmark the performance we compare the results with fine-tuning of a BERT-sized model. We also carry out experiments with count-based term extractors to assess their applicability to few-shot scenarios. We quantify prompt sensitivity with experiments to analyze the variation in performance of large language models across different prompt templates. Our results show that in-context learning with GPT-3.5-Turbo outperforms the BERT-based model and unsupervised count-based methods in few-shot scenarios. © 2024 Elsevier B.V., All rights reserved.},
	journal = {Lecture Notes in Computer Science},
	author = {Banerjee, Shubhanker and Chakravarthi, Bharathi Raja and Mccrae, John Philip},
	year = {2024},
	note = {Section: 0},
	keywords = {Knowledge graph, Large language model, Ontology, Language model, Ontology learning, Performance, Automatic term extraction, Zero-shot learning, Few-shot, Context learning, In contexts, Contrastive Learning, Domain specific, Automated algorithms},
	pages = {137 -- 150},
	annote = {Type: Conference paper}
}

@article{barros2025LlmBasedApproaches,
	file = {References/pdf/barros2025LlmBasedApproaches.pdf},
	title = {{LLM}-based approaches for automated vocabulary mapping between {SIGTAP} and {OMOP} {CDM} concepts},
	volume = {168},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105011174963&doi=10.1016%2Fj.artmed.2025.103204&partnerID=40&md5=1b775df6ed0d57e4182e5af0d7b58848},
	doi = {10.1016/j.artmed.2025.103204},
	abstract = {In the context of global healthcare systems, integrating diverse medical terminologies and classification systems has become a priority due to the adoption of Electronic Health Record (EHR) systems and the imperative for information exchange between healthcare systems. This study addresses the necessity for mapping between the SIGTAP vocabulary used in Brazilian healthcare systems and the broader medical terms of the OMOP CDM terminologies. Two distinct pipelines are evaluated for the vocabulary mapping process, focusing on two subsets of the SIGTAP vocabulary: medicines and medical procedures. The first pipeline utilizes textual embeddings for semantic similarity evaluation, followed by Large Language Models (LLMs) for correspondences selection through a retrieval-augmented generation (RAG) approach. In the second pipeline, LLM agents employ predefined protocols for vocabulary mapping and query refinement. Our results show comparable performance between pipelines in both the Procedures subset (F{\textbackslash}textlessinf{\textbackslash}textgreater1{\textbackslash}textless/inf{\textbackslash}textgreater of 0.684 versus 0.678), and the Medicines subset (F{\textbackslash}textlessinf{\textbackslash}textgreater1{\textbackslash}textless/inf{\textbackslash}textgreater of 0.846 versus 0.839), indicating the viability of the multi-stage filtering approach. The second pipeline demonstrates an advantage over the first in terms of recall, highlighting the efficacy of dynamic query refinement by the agent. These findings provide evidence that LLM-based methods significantly reduce manual effort required by experts, enabling domain specialists to focus on more challenging cases. © 2025 Elsevier B.V., All rights reserved.},
	journal = {Artificial Intelligence in Medicine},
	author = {de Barros Vanzin, Vinícius João and Moreira, Dilvan De Abreu and Marcondes Marcacini, Ricardo},
	year = {2025},
	note = {Section: 0},
	keywords = {large language model, Ontology, Terminology, Language model, Ontology mapping, Semantics, natural language processing, ontology, vocabulary, Natural Language Processing, semantics, Retrieval-augmented generation, Health care, Brazil, Electronic health record, Controlled, Vocabulary, Query processing, electronic health record, Medicine, Thesauri, Mapping, Electronic Health Records, retrieval augmented generation, protocol, human, health care system, Pipelines, article, Humans, female, male, Classification (of information), Medical computing, controlled vocabulary, Electronic document exchange, filtration, Healthcare systems, Large language model agent, Medical classification, Medical information systems, medical specialist, Medical terminologies, medical terminology, Model agents, Model based approach, Query refinement, Vocabulary control},
	annote = {Type: Article}
}

@article{barua2024ConceptInductionUsing,
	file = {References/pdf/barua2024ConceptInductionUsing.pdf},
	title = {Concept {Induction} {Using} {LLMs}},
	volume = {3884},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214839760&partnerID=40&md5=a4f4be096d70304877c43b60b93d8ecf},
	abstract = {In this study, the capability of Large Language Models (LLMs) is explored to automate Concept Induction, a process traditionally reliant on formal logical reasoning using description logic ontologies, within the context of explainable AI (XAI). Initially, a pre-trained LLM like GPT-4 is employed to assess its ability to generate high-level concepts describing data differentials for a scene classification task via prompting. A human assessment study was conducted which revealed that concepts produced by GPT-4 are preferred over those from logical concept induction systems in terms of human understandability, despite some limitations in neuron activation analysis. Building on these insights, further research aims to automate the concept induction system using LLMs, potentially addressing the shortcomings of traditional logical reasoners. This approach has the potential to scale and provide a significant avenue for concept discovery in complex AI models. © 2025 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Barua, Adrita},
	year = {2024},
	note = {Section: 0},
	keywords = {Large language model, Ontology, Language model, Modeling languages, Description logic, Formal languages, Explainable AI, GPT-4, Concept induction, Logical reasoning, Ontology's, Problem oriented languages, Induction system, Scene classification},
	annote = {Type: Conference paper}
}

@article{bernardini2025AdvancingInternetConnected,
	file = {References/pdf/bernardini2025AdvancingInternetConnected.pdf},
	title = {Advancing {Internet}-{Connected} {Devices} {Posture} {Analysis} with a {Meta}-{Search} {Engine}: {A} {Case} {Study} in {Energy} {Systems}},
	volume = {3962},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105005824204&partnerID=40&md5=df494d58a3cac4f953de4dc4f32a9bc7},
	abstract = {In the contemporary digital ecosystem, Internet of Things Search Engines can be used for passive reconnaissance of Internet-connected devices, mapping possible attack surfaces without a direct interaction with the target devices or infrastructures. Each IoT search engine utilizes diverse scanning techniques and analytical methodologies, resulting in metadata with varying levels of coverage, accuracy, and relevance. This research introduces an IoT meta-search engine prototype designed to aggregate and merge metadata from commercial IoT search engines (Shodan, Censys, Netlas, Zoomeye, Binaryedge, Fofa) complemented by Common Vulnerabilities and Exposures (CVE) and Common Weakness Enumeration (CWE) sources. By merging those data, a more comprehensive and detailed perspective of the interconnected device landscape can be provided. Our methodology leverages an ontological framework using Stanford’s Protégé and Python, implementing zero-shot learning with a panel of three Large Language Models (LLMs) under human supervision to map IoT search engine taxonomic structures and quantitatively validate the generated Knowledge Base. The IoT meta-search engine is tested on photovoltaic (PV) energy production and monitoring systems, a domain essential to renewable energy grids. Vulnerabilities in PV systems can be exploited by hackers, causing energy disruptions, data breaches, or manipulation of grid operations. Although the findings are preliminary, they serve as a proof of concept to demonstrate the feasibility of the methodology to provide various types of overviews and insights associated with individual and multiple hosts for security posture evaluation. © 2025 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Bernardini, Andrea and Lezoche, Mario and Angelini, Simone and Dondossola, Giovanna and Terruggia, Roberta},
	year = {2025},
	note = {Section: 0},
	keywords = {Knowledge acquisition, Large language model, Ontology, Language model, Knowledge representation, Taxonomies, Security, Vulnerability, Ontology's, Online searching, Inference engines, Case-studies, Energy systems, Internet connected device, Meta search engines, Posture analysis, Sensitive data},
	annote = {Type: Conference paper}
}

@article{bertini2024Concept2textExplainableMultilingual,
	file = {References/pdf/bertini2024Concept2textExplainableMultilingual.pdf},
	title = {{Concept2Text}: an explainable multilingual rewriting of concepts into natural language},
	volume = {3733},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200126703&partnerID=40&md5=e09884c42ba89e9a77cf5bd1e91aab98},
	abstract = {Automated and explainable data interpretation hinges on two critical steps: (i) identifying emerging properties from data and representing them into abstract concepts, and (ii) translating such concepts into natural language. While Large Language Models have recently demonstrated impressive capabilities in generating natural language, their trustworthiness remains difficult to ascertain. The deployment of an explainable pipeline enables its application in high-risk activities, such as decision making. Addressing this demanding requirement is facilitated by the fertile ground of knowledge representation and automated reasoning research. Building upon previous work that explored the first step, we focus on the second step, named Concept2Text. The design of an explainable translation naturally lends itself to a logic-based model, once again highlighting the contribution of declarative programming to achieving explainability in AI. This paper explores a Prolog/CLP-based rewriting system designed to interpret concepts expressed in terms of classes and relations derived from a generic ontology, generating text in natural language. Its key features encompass hierarchical tree rewritings, modular multilingual generation, support for equivalent variants across semantic, grammar, and lexical levels, and a transparent rule-based system. We present the architecture and illustrate a simple working example that allows the generation of hundreds of different and equivalent rewritings relative to the input concept. © 2024 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Bertini, Flavio and Dal Palú, Alessandro and Fabiano, Francesco and Formisano, Andrea and Zaglio, Federica},
	year = {2024},
	note = {Section: 0},
	keywords = {Language model, Semantics, Knowledge representation, Decision making, Prolog, Explainable AI, Logic programming, Data interpretation, Natural languages, Abstracting, Property, Abstract concept, PROLOG (programming language), Translation (languages), Concept-to-text, Critical steps, ITS applications, Program translators},
	annote = {Type: Conference paper}
}

@article{bhattacharya2024AutomaticOntologyTerm,
	file = {References/pdf/bhattacharya2024AutomaticOntologyTerm.pdf},
	title = {Automatic {Ontology} {Term} {Typing} by {LLMs}: {The} {Impact} of {Prompt} and {Ontology} {Variation}},
	volume = {3967},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105006903401&partnerID=40&md5=ed7b3771dc19477cc1c99014f80d8788},
	abstract = {Large Language Models (LLMs) have been applied to a wide variety of ontology engineering tasks. Building on initial progress, further research is needed to explore potential effects of variation over model-specific and ontology-specific factors. We perform a preliminary study on the ability of an LLM to perform term typing using only its own knowledge through concept retrieval and analyse the effect of domain contextualisation, ontology structure and popularity of ontologies on performance. Our findings suggest that LLMs are reasonably adept at identifying correct individual to concept assertions but are less capable of inferring concept hierarchies when used in a zero-shot setting. Domain contextualisation can enhance performance for structurally complex and less-popular ontologies. Our analysis furthers hints at ontology popularity improving concept retrievability while complexity in terms of structural depth and dispersion makes it difficult for LLMs to identify assertions. © 2025 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Bhattacharya, Upal and de Boer, Maaike H.T. and Sosnovsky, Sergey A.},
	year = {2024},
	note = {Section: 0},
	keywords = {Large language model, Ontology, Language model, Ontology learning, Performance, Contextualization, Ontology's, Ontology evaluations, Automatic ontology, Individual assertion, Term typing},
	annote = {Type: Conference paper}
}

@article{bischof2025LlmBasedGuided,
	file = {References/pdf/bischof2025LlmBasedGuided.pdf},
	title = {{LLM}-{Based} {Guided} {Generation} of {Ontology} {Term} {Definitions}},
	volume = {15344},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218454539&doi=10.1007%2F978-3-031-78952-6_13&partnerID=40&md5=1bb87d01dc10ca28ae22f25a611815f1},
	doi = {10.1007/978-3-031-78952-6_13},
	abstract = {This paper describes our approach for leveraging LLMs to generate definitions and descriptions for ontology terms. Our approach is grounded in the need for detailed and accurate representation of (domain-specific) Knowledge Graphs, and it aims at speeding up the process of generating such text. We outline our approach, including the problems that we encountered, and the solution we propose to overcome them. Our approach is currently in use in an industrial setting. © 2025 Elsevier B.V., All rights reserved.},
	journal = {Lecture Notes in Computer Science},
	author = {Bischof, Stefan and Filtz, Erwin and Parreira, Josiane Xavier and Steyskal, Simon},
	year = {2025},
	note = {Section: 0},
	keywords = {Knowledge graphs, Ontology engineering, Knowledge graph, Large language model, Ontology, Language model, Domain-specific knowledge, Ontology terms, Industrial settings, Knowledge IT, Text generations, Incorrect information},
	pages = {133 -- 137},
	annote = {Type: Conference paper}
}

@article{bombieri2025DoLlmsDream,
	file = {References/pdf/bombieri2025DoLlmsDream.pdf},
	title = {Do {LLMs} {Dream} of {Ontologies}?},
	issn = {2157-6904},
	url = {https://doi.org/10.1145/3725852},
	doi = {10.1145/3725852},
	abstract = {Large Language Models (LLMs) have demonstrated remarkable performance across diverse natural language processing tasks, yet their ability to memorize structured knowledge remains underexplored. In this paper, we investigate the extent to which general-purpose pre-trained LLMs retain and correctly reproduce concept identifier (ID)–label associations from publicly available ontologies. We conduct a systematic evaluation across multiple ontological resources, including the Gene Ontology, Uberon, Wikidata, and ICD-10, using LLMs such as Pythia-12B, Gemini-1.5-Flash, GPT-3.5, and GPT-4. Our findings reveal that only a small fraction of ontological concepts is accurately memorized, with GPT-4 demonstrating the highest performance. To understand why certain concepts are memorized more effectively than others, we analyze the relationship between memorization accuracy and concept popularity on the Web. Our results indicate a strong correlation between the frequency of a concept’s occurrence online and the likelihood of accurately retrieving its ID from the label. This suggests that LLMs primarily acquire such knowledge through indirect textual exposure rather than directly from structured ontological resources. Furthermore, we introduce new metrics to quantify prediction invariance, demonstrating that the stability of model responses across variations in prompt language and temperature settings can serve as a proxy for estimating memorization robustness.},
	journal = {ACM Trans. Intell. Syst. Technol.},
	author = {Bombieri, Marco and Fiorini, Paolo and Ponzetto, Simone Paolo and Rospocher, Marco},
	month = mar,
	year = {2025},
	note = {Section: 0},
	keywords = {Ontologies, Large Language Models, Memorization},
	annote = {Place: New York, NY, USA Publisher: Association for Computing Machinery}
}

@article{bora2025VrsilFrameworkVideo,
	file = {References/pdf/bora2025VrsilFrameworkVideo.pdf},
	title = {{VRSIL}: {A} {Framework} for {Video} {Recommendation} {Integrating} {Semantic} {Intelligence} with a {Large} {Language} {Model}},
	volume = {2461},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010813395&doi=10.1007%2F978-3-031-96473-2_2&partnerID=40&md5=e89825e27bd426a69a8c41847958678c},
	doi = {10.1007/978-3-031-96473-2_2},
	abstract = {This framework presents a strategic model for video recommendation in the Web 3.0 era, integrating hybrid machine intelligence, generative AI, and semantic artificial intelligence through advanced semantic reasoning and quantitative semantic measures. The model dynamically generates ontologies from preprocessed query words, which are then used to select features based on linked similarity. These features are employed to classify the dataset from the perspective of the query using a logistic regression classifier. Semantics-oriented reasoning is achieved by computing the Normalized Pointwise Mutual Information (NPMI) to determine quantitative thresholds, and the Jian-Konrad Index is utilized as a criterion function for optimization. This optimization is carried out using the Elephant Optimization algorithm, which is executed only once to maintain the diversity and number of recommended entities. This approach ensures that the recommendations are both relevant and varied, aligning with the dynamic nature of Web 3.0. © 2025 Elsevier B.V., All rights reserved.},
	journal = {Communications in Computer and Information Science},
	author = {Bora, Anubrat and Deepak, Gerard},
	year = {2025},
	note = {Section: 0},
	keywords = {Ontology, Language model, Artificial intelligence, Semantic Web, Semantics, Web 3.0, Semantic similarity, Ontology generation, Semantic reasoning, Optimisations, Hybrid machine, Logistic regression, Machine intelligence, Semantic intelligence, Strategic modeling},
	pages = {15 -- 24},
	annote = {Type: Conference paper}
}

@article{bouas2025KnowledgeExtractionOntology,
	file = {References/pdf/bouas2025KnowledgeExtractionOntology.pdf},
	title = {Knowledge {Extraction} and {Ontology} {Modeling} in the {SALLY} {Chatbot}},
	volume = {754},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010208274&doi=10.1007%2F978-3-031-97313-0_8&partnerID=40&md5=f8721ca170bf3fe1df83fa69419470c1},
	doi = {10.1007/978-3-031-97313-0_8},
	abstract = {Reception and social integration of Third Country Nationals (TCNs) remains a pressing challenge in contemporary societies shaped by migration. The SALLY project supports the integration of migrants in Greece through a multilingual conversational agent designed to assist users in accessing information related to legal, healthcare, employment, and social services. This paper presents preliminary work on a knowledge extraction framework that captures key elements from natural language conversations—such as topics, entities, and relationships—using Large Language Models (LLMs). These are structured as RDF Knowledge Graphs guided by an ontology that reflects the dynamics of user-agent interaction. By translating informal dialogue into semantically meaningful representations, the system offers a foundation for better understanding user needs and behavior, while enhancing the transparency and responsiveness of the SALLY conversational agent. © 2025 Elsevier B.V., All rights reserved.},
	journal = {IFIP Advances in Information and Communication Technology},
	author = {Bouas, Christos and Papoutsoglou, Maria C. and Tassios, Alexandros and Tegos, Stergios D. and Manousaridis, Konstantinos and Mavropoulos, Thanassis and Vrochidis, Stefanos and Meditskos, Georgios},
	year = {2025},
	note = {Section: 0},
	keywords = {Knowledge graphs, Large language model, Ontology, Ontology model, Language model, Knowledge extraction, Knowledge management, Modeling languages, Integration, Knowledge ontology, Information systems, Human computer interaction, Extraction, Conversational agents, Chatbots, Information use, Multi agent systems, User interfaces, Natural language processing systems, Behavioral research, Human engineering, Extraction modeling, Migrant integration},
	pages = {95 -- 103},
	annote = {Type: Conference paper {\textbar} RAYYAN-LABELS: ontology-supported application}
}

@article{bouchouras2024LlmsEngineeringParkinson,
	file = {References/pdf/bouchouras2024LlmsEngineeringParkinson.pdf},
	title = {{LLMs} for the {Engineering} of a {Parkinson} {Disease} {Monitoring} and {Alerting} {Ontology}},
	volume = {3749},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203587310&partnerID=40&md5=6cf0a5bc51abfa68aafd9a5fe1f9d3ea},
	abstract = {This paper investigates the integration of Large Language Models (LLMs) in the engineering of a Parkinson's Disease (PD) monitoring and alerting ontology. The focus is on the ontology engineering methodology which combines the capabilities of LLMs and human expertise to develop more robust and comprehensive domain ontologies, faster than humans do alone. Evaluating models like ChatGPT-3.5, ChatGPT4, Gemini, and Llama2, this study explores various LLM based ontology engineering methods. The findings reveal that the proposed hybrid approach (both LLM and human involvement), namely X-HCOME, consistently excelled in class generation and F-1 score, indicating its efficiency in creating valid and comprehensive ontologies faster than humans do alone. The study underscores the potential of the combined LLMs and human intelligence to enrich PD domain knowledge and enhance expert-generated PD ontologies. In overall, the presented approach exemplifies a promising collaboration between machine capabilities and human expertise in developing ontologies for complex domains. © 2024 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Bouchouras, Georgios and Bitilis, Pavlos and Kotis, Konstantinos I. and Vouros, George A.},
	year = {2024},
	note = {Section: 0},
	keywords = {Ontology engineering, Large language model, Ontology, Language model, Neurodegenerative diseases, Parkinson's disease, Ontology's, Human engineering, Ontology Engineering Methodologies, Disease control, Disease monitoring, Human expertise, Human-large language model teaming},
	annote = {Type: Conference paper}
}

@article{bowles2025ComparativeAnalysisNlp,
	file = {References/pdf/bowles2025ComparativeAnalysisNlp.pdf},
	title = {Comparative {Analysis} of {NLP} {Models} for {Automatic} {LOINC} {Document} {Ontology} {Named} {Entity} {Recognition} in {Clinical} {Note} {Titles}},
	volume = {329},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105013326994&doi=10.3233%2FSHTI250944&partnerID=40&md5=1f8db405df3dc83d8eef1b9e31cbf3a0},
	doi = {10.3233/SHTI250944},
	abstract = {In order to utilize clinical notes for research studies, it is necessary to identify the most relevant notes. Mapping to the LOINC Document Ontology makes this process easier by reducing the variability of note types. We experimented with three models to automatically identify LOINC DO entities in VA note titles. The supervised BERT model performed best, but the open-source large language models (LLMs) performed well despite a lack of fine-tuning. Future work will aim to improve note classification by including additional note metadata and contents, hybridizing with rule-based approaches, testing fine-tuned LLMs, and mapping to exact LOINC codes. This record is sourced from MEDLINE/PubMed, a database of the U.S. National Library of Medicine},
	journal = {Studies in Health Technology and Informatics},
	author = {Bowles, Annie E. and Gan, Qiwei and Hanchrow, Elizabeth E. and DuVall, Scott L. and Alba, Patrick R. and Shi, Jianlin},
	year = {2025},
	note = {Section: 0},
	keywords = {natural language processing, Natural Language Processing, classification, electronic health record, Electronic Health Records, procedures, comparative study, Automated, automated pattern recognition, Logical Observation Identifiers Names and Codes, Pattern Recognition},
	pages = {769 -- 773},
	annote = {Type: Article}
}

@article{buehler2024AcceleratingScientificDiscovery,
	file = {References/pdf/buehler2024AcceleratingScientificDiscovery.pdf},
	title = {Accelerating scientific discovery with generative knowledge extraction, graph-based representation, and multimodal intelligent graph reasoning},
	volume = {5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206499137&doi=10.1088%2F2632-2153%2Fad7228&partnerID=40&md5=21a0937dc10d125ed87c7888c5c0d635},
	doi = {10.1088/2632-2153/ad7228},
	abstract = {Leveraging generative Artificial Intelligence (AI), we have transformed a dataset comprising 1000 scientific papers focused on biological materials into a comprehensive ontological knowledge graph. Through an in-depth structural analysis of this graph, we have calculated node degrees, identified communities along with their connectivities, and evaluated clustering coefficients and betweenness centrality of pivotal nodes, uncovering fascinating knowledge architectures. We find that the graph has an inherently scale-free nature, shows a high level of connectedness, and can be used as a rich source for downstream graph reasoning by taking advantage of transitive and isomorphic properties to reveal insights into unprecedented interdisciplinary relationships that can be used to answer queries, identify gaps in knowledge, propose never-before-seen material designs, and predict material behaviors. Using a large language embedding model we compute deep node representations and use combinatorial node similarity ranking to develop a path sampling strategy that allows us to link dissimilar concepts that have previously not been related. One comparison revealed detailed structural parallels between biological materials and Beethoven’s 9th Symphony, highlighting shared patterns of complexity through isomorphic mapping. In another example, the algorithm proposed an innovative hierarchical mycelium-based composite based on integrating path sampling with principles extracted from Kandinsky’s ‘Composition VII’ painting. The resulting material integrates an innovative set of concepts that include a balance of chaos and order, adjustable porosity, mechanical strength, and complex patterned chemical functionalization. We uncover other isomorphisms across science, technology and art, revealing a nuanced ontology of immanence that reveal a context-dependent heterarchical interplay of constituents. Because our method transcends established disciplinary boundaries through diverse data modalities (graphs, images, text, numerical data, etc), graph-based generative AI achieves a far higher degree of novelty, explorative capacity, and technical detail, than conventional approaches and establishes a widely useful framework for innovation by revealing hidden connections. © 2024 Elsevier B.V., All rights reserved.},
	number = {3},
	journal = {Machine Learning: Science and Technology},
	author = {Buehler, Markus J.},
	year = {2024},
	note = {Section: 0},
	keywords = {Knowledge graph, Ontology, Natural language processing, Language model, Knowledge extraction, Generative artificial intelligence, Scientific discovery, Language processing, Biomaterials, Natural languages, Generative adversarial networks, Biological materials, Chaos theory, Crystalline materials, Material Informatics, Material science, Path sampling},
	annote = {Type: Article}
}

@article{cappelli2025MethodologicalExplorationOntology,
	file = {References/pdf/cappelli2025MethodologicalExplorationOntology.pdf},
	title = {Methodological {Exploration} of {Ontology} {Generation} with a {Dedicated} {Large} {Language} {Model}},
	volume = {14},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105011611837&doi=10.3390%2Felectronics14142863&partnerID=40&md5=bba003bc82fccbcb202e71d79931bc06},
	doi = {10.3390/electronics14142863},
	abstract = {Ontologies are essential tools for representing, organizing, and sharing knowledge across various domains. This study presents a methodology for ontology construction supported by large language models (LLMs), with an initial application in the automotive sector. Specifically, a user preference ontology for adaptive interfaces in autonomous machines was developed using ChatGPT-4o. Based on this case study, the results were generalized into a reusable methodology. The proposed workflow integrates classical ontology engineering methodologies with the generative and analytical capabilities of LLMs. Each phase follows well-established steps: domain definition, term elicitation, class hierarchy construction, property specification, formalization, population, and validation. A key innovation of this approach is the use of a guiding table that translates domain knowledge into structured prompts, ensuring consistency across iterative interactions with the LLM. Human experts play a continuous role throughout the process, refining definitions, resolving ambiguities, and validating outputs. The ontology was evaluated in terms of logical consistency, structural properties, semantic accuracy, and inferential completeness, confirming its correctness and coherence. Additional validation through SPARQL queries demonstrated its reasoning capabilities. This methodology is generalizable to other domains, if domain experts adapt the guiding table to the specific context. Despite the support provided by LLMs, domain expertise remains essential to guarantee conceptual rigor and practical relevance. © 2025 Elsevier B.V., All rights reserved.},
	number = {14},
	journal = {Electronics (Switzerland)},
	author = {Cappelli, Maria Assunta and Di Marzo Serugendo, Giovanna},
	year = {2025},
	note = {Section: 0},
	keywords = {Large language model, Ontology, Language model, Semantics, Generative AI, Knowledge representation, Knowledge management, Ontology development, Automotive industry, Query processing, Autonomous vehicles, Human-in-the-loop, Evaluation metrics, Iterative methods, Domain Knowledge, Ontology's, Knowledge-representation, Ontology evaluations, Adaptive interface, Automotive domains, Autonomous car, Computer software reusability, Ontology evaluation metric},
	annote = {Type: Article}
}

@article{capshaw2024LintextVisualTool,
	file = {References/pdf/capshaw2024LintextVisualTool.pdf},
	title = {{LINTEXT}: {A} {Visual} {Tool} for {Exploring} and {Modeling} {Knowledge} in {Text} {Documents}},
	volume = {3967},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105006925553&partnerID=40&md5=8445ff346393a09f7d1bd79907c48606},
	abstract = {A large part of knowledge is commonly encoded into text documents. While extracting this information into a Knowledge Graph (KG) is a common approach, it suffers from challenges when texts are added, removed, or changed, or when the schema of the intended KG changes. Instead we advocate an approach where text and models evolve together in an interactive manner. We present LINTEXT, a system accompanying a published method which allows users to jointly explore and model the information held within text documents. The modeling is accomplished by specifying fill-in-the-blank prompts along with some metadata which are then recorded as specifications for simple relations that can be used to generate an ontology. The exploration aspect is accomplished by having the system complete each prompt with entities identified from the text and presenting the completions as a ranked list to the user, allowing users to verify the quality of the extracted triples. By elevating the development of the ontology to a visual and interactive level, it has an immediate text connection and users can be more certain that the documents they wish to model contain the information they wish to extract or query. Additionally, our system is designed to support the development of relation extraction (RE) pipelines underlying the document analysis, with a particular focus on supporting methods for improving vector representations of the extracted entities. To this end, users can choose to analyze documents from pre-annotated RE data sets to understand how changes in different elements of the pipeline affect the results. © 2025 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Capshaw, Riley and Blomqvist, Eva},
	year = {2024},
	note = {Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Language model, Relation extraction, Embeddings, Knowledge model, Entity embedding, Masked language model, Document-level relation extraction, Machine reading, Interactive knowledge modeling},
	annote = {Type: Conference paper}
}

@article{capshaw2025ContextualizingEntityRepresentations,
	file = {References/pdf/capshaw2025ContextualizingEntityRepresentations.pdf},
	title = {Contextualizing {Entity} {Representations} for {Zero}-{Shot} {Relation} {Extraction} with {Masked} {Language} {Models}},
	volume = {15370},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210848015&doi=10.1007%2F978-3-031-77792-9_24&partnerID=40&md5=45282001afe6225ccaee18bde89df536},
	doi = {10.1007/978-3-031-77792-9_24},
	abstract = {Knowledge graphs (KGs) and their related ontologies constitute a key component in modern knowledge-based systems. However, hand-crafting these is not scalable, particularly due to the rate at which knowledge changes in many real-world applications. Partially automating the process of extracting and even modelling knowledge has therefore been a subject of research for many years. Nevertheless, accurate and reliable KG construction from natural language documents still remains a difficult task with many challenges, even in light of the impressive recent advances in language modelling. This paper focuses on one of those challenges, namely the extraction of accurate entity representations from text documents in order to facilitate relation extraction (RE). We present a novel method for generating document-contextualized input representations for entities using a masked language model (MLM) without the need for any sort of fine-tuning. These representations are then used as inputs to the same MLM that generated them, alleviating the need to include entire documents when prompting. Our results show that these representations 1) improve the ability of the MLMs BERT and RoBERTa to identify statements that represent correct relations between two entities; and 2) allow BERT to perform on par with the fine-tuned MLMs BioBERT and PubMedBERT. © 2024 Elsevier B.V., All rights reserved.},
	journal = {Lecture Notes in Computer Science},
	author = {Capshaw, Riley and Blomqvist, Eva},
	year = {2025},
	note = {Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Ontology, Language model, Relation extraction, Modeling languages, Knowledge-based systems, Embeddings, Graph embeddings, Entity embedding, Ontology's, Natural language processing systems, Masked language model, Document-level relation extraction, Machine reading},
	pages = {399 -- 415},
	annote = {Type: Conference paper}
}

@article{carta2024TowardsZeroShot,
	file = {References/pdf/carta2024TowardsZeroShot.pdf},
	series = {{UMAP} {Adjunct} '24},
	title = {Towards {Zero}-shot {Knowledge} {Graph} building: {Automated} {Schema} {Inference}},
	url = {https://doi.org/10.1145/3631700.3665234},
	doi = {10.1145/3631700.3665234},
	abstract = {In the current Digital Transformation scenario, Knowledge Graphs are essential for comprehending, representing, and exploiting complex information in a structured form. The main paradigm in automatically generating proper Knowledge Graphs relies on predefined schemas or ontologies. Such schemas are typically manually constructed, requiring an intensive human effort, and are often sensitive to information loss due to negligence, incomplete analysis, or human subjectivity or inclination. Limiting human bias and the resulting information loss in creating proper Knowledge Graphs is paramount, particularly for user modeling in various sectors, such as education or healthcare. To this end, we propose a novel approach to automatically generating a proper entity schema. The devised methodology combines the language understanding capabilities of LLM with classical machine learning methods such as clustering to properly build an entity schema from a set of documents. This solution eliminates the need for human intervention and fosters a more efficient and comprehensive knowledge representation. The assessment of our proposal concerns adopting a state-of-the-art entity extraction model (UniNER) to estimate the relevance of the extracted entities based on the generated schema. Results confirm the potential of our approach, as we observed a negligible difference between the topic similarity score obtained with the ground truth and with the automatically generated schema (less than 1\% on average on three different datasets). Such an outcome confirms that the proposed approach may be valuable in automatically creating an entity schema from a set of documents.},
	journal = {Adjunct Proceedings of the 32nd ACM Conference on User Modeling, Adaptation and Personalization},
	author = {Carta, Salvatore and Giuliani, Alessandro and Manca, Marco Manolo and Piano, Leonardo and Tiddia, Sandro Gabriele},
	year = {2024},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery
Section: 0},
	keywords = {Knowledge graphs, Large Language Models, Knowledge graph, Large language model, Ontology, Language model, Ontology learning, Named entity recognition, Semantics, User profile, Digital transformation, Ontology Learning, Named Entity Recognition, Zero-shot learning, Learning systems, 'current, Complex information, Schema inference, Information loss},
	pages = {467--473},
	annote = {event-place: Cagliari, Italy}
}

@article{caufield2024StructuredPromptInterrogation,
	file = {References/pdf/caufield2024StructuredPromptInterrogation.pdf},
	title = {Structured {Prompt} {Interrogation} and {Recursive} {Extraction} of {Semantics} ({SPIRES}): a method for populating knowledge bases using zero-shot learning},
	volume = {40},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187509853&doi=10.1093%2Fbioinformatics%2Fbtae104&partnerID=40&md5=c8ab6d67018f4989386c6cc3a12eb9dc},
	doi = {10.1093/bioinformatics/btae104},
	abstract = {Motivation: Creating knowledge bases and ontologies is a time consuming task that relies on manual curation. AI/NLP approaches can assist expert curators in populating these knowledge bases, but current approaches rely on extensive training data, and are not able to populate arbitrarily complex nested knowledge schemas. Results: Here we present Structured Prompt Interrogation and Recursive Extraction of Semantics (SPIRES), a Knowledge Extraction approach that relies on the ability of Large Language Models (LLMs) to perform zero-shot learning and general-purpose query answering from flexible prompts and return information conforming to a specified schema. Given a detailed, user-defined knowledge schema and an input text, SPIRES recursively performs prompt interrogation against an LLM to obtain a set of responses matching the provided schema. SPIRES uses existing ontologies and vocabularies to provide identifiers for matched elements. We present examples of applying SPIRES in different domains, including extraction of food recipes, multispecies cellular signaling pathways, disease treatments, multi-step drug mechanisms, and chemical to disease relationships. Current SPIRES accuracy is comparable to the mid-range of existing Relation Extraction methods, but greatly surpasses an LLM’s native capability of grounding entities with unique identifiers. SPIRES has the advantage of easy customization, flexibility, and, crucially, the ability to perform new tasks in the absence of any new training data. This method supports a general strategy of leveraging the language interpreting capabilities of LLMs to assemble knowledge bases, assisting manual knowledge curation and acquisition while supporting validation with publicly-available databases and ontologies external to the LLM. Availability and implementation: SPIRES is available as part of the open source OntoGPT package: https://github.com/monarch-initiative/ontogpt. © 2024 Elsevier B.V., All rights reserved.},
	number = {3},
	journal = {Bioinformatics},
	author = {Caufield, John Harry and Hegde, Harshad B. and Emonet, Vincent and Harris, Nomi L. and Joachimiak, Marcin Pawel and Matentzoglu, Nicolas A. and Kim, Hyeongsik and Moxon, Sierra A.Taylor and Reese, Justin T. and Haendel, Melissa Anne},
	year = {2024},
	note = {Section: 0},
	keywords = {Semantics, semantics, Databases, knowledge base, Knowledge Bases, Factual, factual database},
	annote = {Type: Article}
}

@article{cauter2024OntologyGuidedKnowledge,
	file = {References/pdf/cauter2024OntologyGuidedKnowledge.pdf},
	title = {Ontology-guided {Knowledge} {Graph} {Construction} from {Maintenance} {Short} {Texts}},
	url = {https://aclanthology.org/2024.kallm-1.8/},
	doi = {10.18653/v1/2024.kallm-1.8},
	abstract = {Large-scale knowledge graph construction remains infeasible since it requires significant human-expert involvement. Further complications arise when building graphs from domain-specific data due to their unique vocabularies and associated contexts. In this work, we demonstrate the ability of open-source large language models (LLMs), such as Llama-2 and Llama-3, to extract facts from domain-specific Maintenance Short Texts (MSTs). We employ an approach which combines ontology-guided triplet extraction and in-context learning. By using only 20 semantically similar examples with the Llama-3-70B-Instruct model, we achieve performance comparable to previous methods that relied on fine-tuning techniques like SpERT and REBEL. This indicates that domain-specific fact extraction can be accomplished through inference alone, requiring minimal labeled data. This opens up possibilities for effective and efficient semi-automated knowledge graph construction for domain-specific data.},
	journal = {Proceedings of the 1st Workshop on Knowledge Graphs and Large Language Models (KaLLM 2024)},
	author = {van Cauter, Zeno and Yakovets, Nikolay},
	editor = {Biswas, Russa and Kaffee, Lucie-Aimée and Agarwal, Oshin and Minervini, Pasquale and Singh, Sameer and de Melo, Gerard},
	month = aug,
	year = {2024},
	note = {Place: Bangkok, Thailand
Publisher: Association for Computational Linguistics
Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Ontology, Language model, Semantics, Computational linguistics, Adversarial machine learning, Graph construction, Domain Knowledge, Ontology's, In contexts, Contrastive Learning, Large-scales, Domain specific, Human expert, Open-source, Short texts},
	pages = {75--84},
	annote = {Type: Conference paper}
}

@article{cavalleri2024InitialAchievementsIn,
	file = {References/pdf/cavalleri2024InitialAchievementsIn.pdf},
	title = {Initial achievements in relation extraction from {RNA}-focused scientific papers},
	volume = {3741},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202018471&partnerID=40&md5=903a15b130d3508fdc1210b503158de3},
	abstract = {Relation extraction from the scientific literature to comply with a domain ontology is a well-known problem in natural language processing and is particularly critical in precision medicine. The advent of large language models (LLMs) has paved the way for the development of new effective approaches to this problem, but the extracted relations can be affected by issues such as hallucination, which must be minimized. In this paper, we present the initial design and preliminary experimental validation of SPIREX, an extension of the SPIRES-based system for the extraction of RDF triples from scientific literature involving RNA molecules. Our system exploits schema constraints in the formulations of LLM prompts along with our RNA-based KG, RNA-KG, for evaluating the plausibility of the extracted triples. RNA-KG contains more than 9M edges representing different kinds of relationships in which RNA molecules can be involved. Initial experimental results on a controlled data set are quite encouraging. © 2024 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Cavalleri, Emanuele and Soto Gomez, Mauricio A. and Pashaeibarough, Ali and Malchiodi, Dario and Caufield, John Harry and Reese, Justin T. and Mungall, Christopher John and Robinson, Peter Nicholas and Casiraghi, Elena and Valentini, Giorgio},
	year = {2024},
	note = {Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Large language model, Ontology, Language model, Relation extraction, Link prediction, Prompt engineering, Natural language processing systems, Scientific literature, Relation discovery, RNA molecules, RNA-based knowledge graph},
	pages = {61 -- 69},
	annote = {Type: Conference paper}
}

@article{chen2021ConstructingTaxonomiesPretrained,
	file = {References/pdf/chen2021ConstructingTaxonomiesPretrained.pdf},
	title = {Constructing {Taxonomies} from {Pretrained} {Language} {Models}},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85125028771&doi=10.18653%2Fv1%2F2021.naacl-main.373&partnerID=40&md5=98e416eedc7b0ab3e8fd89bb10a055d8},
	doi = {10.18653/v1/2021.naacl-main.373},
	abstract = {We present a method for constructing taxonomic trees (e.g., WORDNET) using pretrained language models. Our approach is composed of two modules, one that predicts parenthood relations and another that reconciles those predictions into trees. The parenthood prediction module produces likelihood scores for each potential parent-child pair, creating a graph of parent-child relation scores. The tree reconciliation module treats the task as a graph optimization problem and outputs the maximum spanning tree of this graph. We train our model on subtrees sampled from WORDNET, and test on non-overlapping WORDNET subtrees. We show that incorporating web-retrieved glosses can further improve performance. On the task of constructing subtrees of English WORDNET, the model achieves 66.7 ancestor F{\textbackslash}textlessinf{\textbackslash}textgreater1{\textbackslash}textless/inf{\textbackslash}textgreater, a 20.0\% relative increase over the previous best published result on this task. In addition, we convert the original English dataset into nine other languages using OPEN MULTILINGUAL WORDNET and extend our results across these languages. © 2025 Elsevier B.V., All rights reserved.},
	author = {Chen, Catherine and Lin, Kevin Qinhong and Klein, Dan},
	year = {2021},
	note = {Section: 0},
	keywords = {Ontology, Language model, Computational linguistics, Trees (mathematics), Improve performance, Graph optimization problems, Likelihood score, Maximum spanning-tree, Sub trees, Taxonomic trees},
	pages = {4687 -- 4700},
	annote = {Type: Conference paper}
}

@article{chen2022EnhancingCrossLingual,
	file = {References/pdf/chen2022EnhancingCrossLingual.pdf},
	title = {Enhancing {Cross}-lingual {Medical} {Concept} {Alignment} by {Leveraging} {Synonyms} and {Translations} of the {Unified} {Medical} {Language} {System}},
	doi = {10.1109/HPCC-DSS-SmartCity-DependSys57074.2022.00309},
	abstract = {Well-developed medical terminology systems like the Unified Medical Language System (UMLS) improve the ability of language models to handle medical entity linking tasks. However, such magnificent terminology systems are only available for few languages, such as English. For Chinese, both simplified and traditional, the lack of well-developed terminology systems remains a big challenge to unify Chinese medical terminologies by linking medical entities as concepts. In this study, we purpose a translation enhanced contrastive learning scheme which leverages translations and synonyms of UMLS to infuse knowledge into the language model, and present a cross-lingual pre-trained language model called TeaBERT that aligns cross-lingual Chinese and English medical synonyms well at semantic level. Comparing with former cross-lingual language models, TeaBERT significantly outperforms on evaluation datasets, with 93.21\%, 89.89\% and 76.45\% of Top 5 accuracy on ICDI0-CN, CHPO and RealWorld dataset respectively, and achieves new state-of-theart performance without task specific fine-tuning. Our contrastive learning scheme can not only be used for enhancing Chinese-English medical concepts alignment, but also be applied to other languages facing the same challenges.},
	journal = {2022 IEEE 24th Int Conf on High Performance Computing \& Communications; 8th Int Conf on Data Science \& Systems; 20th Int Conf on Smart City; 8th Int Conf on Dependability in Sensor, Cloud \& Big Data Systems \& Application (HPCC/DSS/SmartCity/DependSys)},
	author = {Chen, Luming and Qi, Yifan and Wu, Aiping and Deng, Lizong and Jiang, Taijiao},
	month = dec,
	year = {2022},
	note = {Section: 0},
	keywords = {Terminology, Semantics, Knowledge representation, NLP, Unified modeling language, UMLS, pre-trained language model, Biological system modeling, Task analysis, cross-lingual medical entity linking},
	pages = {2078--2083}
}

@article{chen2023ContextualSemanticEmbeddings,
	file = {References/pdf/chen2023ContextualSemanticEmbeddings.pdf},
	title = {Contextual semantic embeddings for ontology subsumption prediction},
	volume = {26},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85156109122&doi=10.1007%2Fs11280-023-01169-9&partnerID=40&md5=a100ea0dbca26b847c8cf4881ae388de},
	doi = {10.1007/s11280-023-01169-9},
	abstract = {Automating ontology construction and curation is an important but challenging task in knowledge engineering and artificial intelligence. Prediction by machine learning techniques such as contextual semantic embedding is a promising direction, but the relevant research is still preliminary especially for expressive ontologies in Web Ontology Language (OWL). In this paper, we present a new subsumption prediction method named BERTSubs for classes of OWL ontology. It exploits the pre-trained language model BERT to compute contextual embeddings of a class, where customized templates are proposed to incorporate the class context (e.g., neighbouring classes) and the logical existential restriction. BERTSubs is able to predict multiple kinds of subsumers including named classes from the same ontology or another ontology, and existential restrictions from the same ontology. Extensive evaluation on five real-world ontologies for three different subsumption tasks has shown the effectiveness of the templates and that BERTSubs can dramatically outperform the baselines that use (literal-aware) knowledge graph embeddings, non-contextual word embeddings and the state-of-the-art OWL ontology embeddings. © 2023 Elsevier B.V., All rights reserved.},
	number = {5},
	journal = {World Wide Web},
	author = {Chen, Jiaoyan and He, Yuan and Geng, Yuxia and Jimeńez-Ruiz, Ernesto and Dong, Hang and Horrocks, Ian},
	year = {2023},
	note = {Section: 0},
	keywords = {Ontology, Language model, Pre-trained language model, Artificial intelligence, Semantics, Web ontology language (OWL), BERT, Ontology embedding, Ontology alignment, Embeddings, Forecasting, Computational linguistics, Ontology's, Birds, Ontology in web ontology language, Subsumption prediction},
	pages = {2569 -- 2591},
	annote = {Type: Article}
}

@article{chen2023OpalOntologyAware,
	file = {References/pdf/chen2023OpalOntologyAware.pdf},
	title = {{OPAL}: {Ontology}-{Aware} {Pretrained} {Language} {Model} for {End}-to-{End} {Task}-{Oriented} {Dialogue}},
	volume = {11},
	url = {https://aclanthology.org/2023.tacl-1.5/},
	doi = {10.1162/tacl_a_00534},
	abstract = {This paper presents an ontology-aware pretrained language model (OPAL) for end-to-end task-oriented dialogue (TOD). Unlike chit-chat dialogue models, task-oriented dialogue models fulfill at least two task-specific modules: Dialogue state tracker (DST) and response generator (RG). The dialogue state consists of the domain-slot-value triples, which are regarded as the user's constraints to search the domain-related databases. The large-scale task-oriented dialogue data with the annotated structured dialogue state usually are inaccessible. It prevents the development of the pretrained language model for the task-oriented dialogue. We propose a simple yet effective pretraining method to alleviate this problem, which consists of two pretraining phases. The first phase is to pretrain on large-scale contextual text data, where the structured information of the text is extracted by the information extracting tool. To bridge the gap between the pretraining method and downstream tasks, we design two pretraining tasks: ontology-like triple recovery and next-text generation, which simulates the DST and RG, respectively. The second phase is to fine-tune the pretrained model on the TOD data. The experimental results show that our proposed method achieves an exciting boost and obtains competitive performance even without any TOD data on CamRest676 and MultiWOZ benchmarks.},
	journal = {Transactions of the Association for Computational Linguistics},
	author = {Chen, Zhi and Liu, Yuncong and Chen, Lu and Zhu, Su and Wu, Mengyue and Yu, Kai},
	year = {2023},
	note = {Section: 0},
	keywords = {Ontology, Language model, Pre-training, Benchmarking, Computational linguistics, Bridges, Ontology's, Large-scales, Simple++, Task-oriented, Dialogue models, End-to-end task, Modeling task, Task-specific modules},
	pages = {68--84},
	annote = {Place: Cambridge, MA Publisher: MIT Press}
}

@article{chen2023PromptingOrFine,
	file = {References/pdf/chen2023PromptingOrFine.pdf},
	title = {Prompting or {Fine}-tuning? {A} {Comparative} {Study} of {Large} {Language} {Models} for {Taxonomy} {Construction}},
	doi = {10.1109/MODELS-C59198.2023.00097},
	abstract = {Taxonomies represent hierarchical relations between entities, frequently applied in various software modeling and natural language processing (NLP) activities. They are typically subject to a set of structural constraints restricting their content. However, manual taxonomy construction can be time-consuming, incomplete, and costly to maintain. Recent studies of large language models (LLMs) have demonstrated that appropriate user inputs (called prompting) can effectively guide LLMs, such as GPT-3, in diverse NLP tasks without explicit (re-)training. However, existing approaches for automated taxonomy construction typically involve fine-tuning a language model by adjusting model parameters. In this paper, we present a general framework for taxonomy construction that takes into account structural constraints. We subsequently conduct a systematic comparison between the prompting and fine-tuning approaches performed on a hypernym taxonomy and a novel computer science taxonomy dataset. Our result reveals the following: (1) Even without explicit training on the dataset, the prompting approach outperforms fine-tuning-based approaches. Moreover, the performance gap between prompting and fine-tuning widens when the training dataset is small. However, (2) taxonomies generated by the fine-tuning approach can be easily post-processed to satisfy all the constraints, whereas handling violations of the taxonomies produced by the prompting approach can be challenging. These evaluation findings provide guidance on selecting the appropriate method for taxonomy construction and highlight potential enhancements for both approaches.},
	journal = {2023 ACM/IEEE International Conference on Model Driven Engineering Languages and Systems Companion (MODELS-C)},
	author = {Chen, Boqi and Yi, Fandi and Varró, Dániel},
	month = oct,
	year = {2023},
	note = {Section: 0},
	keywords = {Ontologies, large language models, Taxonomy, Software, Training, Computer science, few-shot learning, Computational modeling, fine-tuning, Systematics, domain-specific constraints, taxonomy construction},
	pages = {588--596}
}

@article{chen2024ExtractingStructureInformation,
	title = {Extracting {Structure} {Information} from {Narrative} {Medical} {Reports} based on {LLMs}},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217280093&doi=10.1109%2FBIBM62325.2024.10822688&partnerID=40&md5=2ef76c9f7b1b72efc12493a0c6955074},
	doi = {10.1109/BIBM62325.2024.10822688},
	abstract = {Extracting structured information and key details from medical report narratives is crucial to support healthcare data management, analysis and decision-making. However, the specialized nature of the reports, the complexity of the contents, and the high accuracy requirements of the results pose significant challenges to the structuring task. In this paper, we develop an LLM-based method to extract structure information from medical report narratives. Defining the structuring problem as mapping the narrative reports to the domain ontology, we design a framework to develop specialized LLMs that automatically learn and establish the mappings. At the core of this framework are report partitioning and interactive training data generation modules are. By separating complete reports into logically independent segments and training the LLMs on these segments independently, the trained LLMs can accurately capture the semantic relationships within each segment. Additionally, we explore different LLMs and formulate a simplistic scoring method to compare their accuracy, enabling us to select the best-performing model. Experimental evaluation on a real-world breast ultrasound report dataset demonstrates that our method achieves high accuracy with a small training dataset (400 samples). Specifically, the accuracy of structural information extraction and the attribute-value matching accuracy both exceed 96\%.},
	journal = {2024 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)},
	author = {Chen, Dehua and Shen, Zijian and Wang, Mei and Dong, Na and Pan, Qiao and Su, Jianwen},
	month = dec,
	year = {2024},
	note = {Section: 0},
	keywords = {Ontologies, Large language model, Ontology, Language model, Large language models, Semantics, Information retrieval, Data mining, Standards, Training, Accuracy, Training data, Medical services, Medical examination reports, Report structuring, Ultrasonic imaging, Data accuracy, High-accuracy, Structured information, Data decision, Management analysis, Management decisions, Medical examination report, Structure information, Cannot download},
	pages = {5616--5623},
	annote = {ISSN: 2156-1133}
}

@article{chen2024OntologyTextAlignment,
	file = {References/pdf/chen2024OntologyTextAlignment.pdf},
	title = {Ontology {Text} {Alignment}: {Aligning} {Textual} {Content} to {Terminological} {Axioms}},
	volume = {392},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213316349&doi=10.3233%2FFAIA240639&partnerID=40&md5=2c1c97aa38f8bdd7b3fb3b8b1d142d78},
	doi = {10.3233/FAIA240639},
	abstract = {Despite the impressive advancements in Large Language Models (LLMs), their ability to perform reasoning and provide explainable outcomes remains a challenge, underscoring the continued relevance of ontologies in certain areas, particularly due to the reasoning and validation capabilities of ontologies. Ontology modelling and semantic search, due to their inherent complexity, still demand considerable human effort and expertise. Addressing this gap, our paper introduces the problem of ontology text alignment, which involves finding the most relevant axioms with respect to the given reference text. We propose an advanced Retrieval Augmented Generation framework that leverages BERT models and generative LLMs, together with ontology semantic enhancement based on atomic decomposition. Additionally, we have developed benchmarks in geology and biomedical areas. Our evaluation demonstrates the positive impact of our framework. © 2024 Elsevier B.V., All rights reserved.},
	journal = {Frontiers in Artificial Intelligence and Applications},
	author = {Chen, Jieying and Dong, Hang and Chen, Jiaoyan and Horrocks, Ian},
	year = {2024},
	note = {Section: 0},
	keywords = {Ontology, Ontology model, Language model, Semantics, Semantic search, Benchmarking, Ontology's, Ontology semantics, Validation capability, Model search, Reasoning capabilities, Text alignments, Textual content},
	pages = {1389 -- 1396},
	annote = {Type: Conference paper}
}

@article{chen2024OptimizingAutomatedCompliance,
	file = {References/pdf/chen2024OptimizingAutomatedCompliance.pdf},
	title = {Optimizing automated compliance checking with ontology-enhanced natural language processing: {Case} in the fire safety domain},
	volume = {371},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208974479&doi=10.1016%2Fj.jenvman.2024.123320&partnerID=40&md5=566f7641e4047b28f4e4b1a1b9c5439d},
	doi = {10.1016/j.jenvman.2024.123320},
	abstract = {The fire safety compliance checking (FSCC) plays a crucial role in ensuring the quality of fire engineering design and eliminating inherent fire hazards. It requires an objective and rational interpretation of fire regulations. However, the texts of fire regulations are filled with numerous rules related to spatial limitations, which pose a significant challenge in interpreting them. The current method of interpreting these rules mostly relies on manual translation, which is not efficient. To address this issue, this study proposes an innovative automated framework for interpreting rules by combining ontology technology with natural language processing (NLP). Through the utilization of pre-trained language models (PLMs), concepts and relationships are extracted from sentences, a domain-specific ontology is established, spatial knowledge is transformed into language-agnostic tree structures based on the ontology, and the semantic components of spatial relationships are extracted. The tree structure is then mapped to logical clauses based on semantic consistency, thereby improving the efficiency of interpretation. Experimental results demonstrate that the architecture achieves an F1 score of 86.27 for entity extraction and 81.81 for spatial relationship joint extraction tasks, with an accuracy of 96.26\% in the formalization of logical rules, highlighting its proficiency in automatically interpreting fire spatial rules. This study offers technical support to enhance public understanding of fire safety management and fire prevention predictions, thereby promoting the intelligent management of the building safety environment. © 2024 Elsevier B.V., All rights reserved.},
	journal = {Journal of Environmental Management},
	author = {Chen, Yian and Jiang, Huixian},
	year = {2024},
	note = {Section: 0},
	keywords = {Ontology, Language model, Named entity recognition, Ontology automatic construction, Pre-trained language model, Relationship extraction, Rule interpretation, Semantics, natural language processing, ontology, diagnosis, Natural Language Processing, Automated compliance checking, knowledge, prediction, language model, human, optimization, language, compliance, extraction method, article, Ontology's, Natural language processing systems, Fire hazards, Fires, clinical article, Agnostic, Automatic construction, compliance (physical), design method, fire, Fire extinguishers, fire protection, Fireproofing},
	annote = {Type: Article {\textbar} RAYYAN-LABELS: ontology-supported application}
}

@article{chen2024TowardControllableGenerative,
	title = {Toward {Controllable} {Generative} {Design}: {A} {Conceptual} {Design} {Generation} {Approach} {Leveraging} the {Function}-{Behavior}-{Structure} {Ontology} and {Large} {Language} {Models}},
	volume = {146},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199391540&doi=10.1115%2F1.4065562&partnerID=40&md5=bda3860dd2a3fca92a8532621c58deba},
	doi = {10.1115/1.4065562},
	abstract = {Recent research in the field of design engineering is primarily focusing on using AI technologies such as Large Language Models (LLMs) to assist early-stage design. The engineer or designer can use LLMs to explore, validate, and compare thousands of generated conceptual stimuli and make final choices. This was seen as a significant stride in advancing the status of the generative approach in computer-aided design. However, it is often difficult to instruct LLMs to obtain novel conceptual solutions and requirement-compliant in real design tasks, due to the lack of transparency and insufficient controllability of LLMs. This study presents an approach to leverage LLMs to infer Function-Behavior-Structure (FBS) ontology for high-quality design concepts. Prompting design based on the FBS model decomposes the design task into three sub-tasks including functional, behavioral, and structural reasoning. In each sub-task, prompting templates and specification signifiers are specified to guide the LLMs to generate concepts. User can determine the selected concepts by judging and evaluating the generated function-structure pairs. A comparative experiment has been conducted to evaluate the concept generation approach. According to the concept evaluation results, our approach achieves the highest scores in concept evaluation, and the generated concepts are more novel, useful, functional, and low cost compared to the baseline. © 2024 Elsevier B.V., All rights reserved.},
	number = {12},
	journal = {Journal of Mechanical Design},
	author = {Chen, Liuqing and Zuo, Haoyu and Cai, Zebin and Yin, Yuan and Zhang, Yuan and Sun, Lingyun and Childs, Peter R.N.},
	year = {2024},
	note = {Section: 0},
	keywords = {Large language model, Ontology, Language model, Machine learning, Conceptual design, Computer aided design, Computational linguistics, Generative design, Structural design, Architectural design, Machine-learning, Concept generation, Creativity and concept generation, Design tasks, Function evaluation, Function-behavior-structure model, Function-Behaviour-Structure ontologies, Subtask, Cannot download},
	annote = {Type: Article}
}

@article{chepurova2024PromptMeOne,
	file = {References/pdf/chepurova2024PromptMeOne.pdf},
	title = {Prompt {Me} {One} {More} {Time}: {A} {Two}-{Step} {Knowledge} {Extraction} {Pipeline} with {Ontology}-{Based} {Verification}},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200615475&partnerID=40&md5=0c13b89310c5035073d1803f66af5f52},
	abstract = {This study explores a method for extending real-world knowledge graphs (specifically, Wikidata) by extracting triplets from texts with the aid of Large Language Models (LLMs). We propose a two-step pipeline that includes the initial extraction of entity candidates, followed by their refinement and linkage to the canonical entities and relations of the knowledge graph. Finally, we utilize Wikidata relation constraints to select only verified triplets. We compare our approach to a model that was fine-tuned on a machine-generated dataset and demonstrate that it performs better on natural data. Our results suggest that LLM-based triplet extraction from texts, with subsequent verification, is a viable method for real-world applications. © 2024 Elsevier B.V., All rights reserved.},
	author = {Chepurova, Alla and Kuratov, Yuri M. and Bulatov, Aydar and Burtsev, Mikhail S.},
	year = {2024},
	note = {Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Ontology, Language model, Knowledge extraction, Ontology-based, Computational linguistics, Model-based OPC, Real-world, World knowledge},
	pages = {61 -- 77},
	annote = {Type: Conference paper}
}

@article{chow2024SemanticSearchUsing,
	title = {Semantic {Search} {Using} {LLM}-{Aided} {Topic} {Generation} on {Knowledge} {Graphs} for {Paper} {Discovery}},
	doi = {10.1109/ISCSLP63861.2024.10800417},
	abstract = {The exponential growth of academic papers presents a huge challenge for researchers, exacerbating the already tedious literature review process. Current tools like Google Scholar and Connected Papers offer solutions for text-based and citation-based searches but fail to address the need for finding semantically similar yet terminologically different papers efficiently. This paper proposes an innovative approach to paper discovery using semantic search to create a knowledge graph of topics and papers. By generating a tree of topics using ChatGPT 4o and calculating semantic similarity with SciBERT, this method aims to uncover relevant papers overlooked by traditional citation-based searches. The solution, validated through quantitative evaluation, demonstrates the potential to improve the efficiency and comprehensiveness of paper discovery.},
	journal = {2024 IEEE 14th International Symposium on Chinese Spoken Language Processing (ISCSLP)},
	author = {Chow, Sabrina and Guo, Lilian and Chow, Jonathan and Chia, Chelsea and Li, Sarah and Huang, Dong-Yan},
	month = nov,
	year = {2024},
	note = {Section: 0},
	keywords = {Knowledge graphs, Knowledge Graphs, Semantic search, Natural Language Processing (NLP), Semantic Search, Chatbots, Internet, Literature Review, Focusing, Rendering (computer graphics), Navigation, Bibliographies, SciBERT, Cannot download},
	pages = {353--357}
}

@article{chowdhury2025AutomatedFrameworkOntology,
	file = {References/pdf/chowdhury2025AutomatedFrameworkOntology.pdf},
	title = {An {Automated} {Framework} of {Ontology} {Generation} for {Abstract} {Concepts} {Using} {LLMs}},
	volume = {2435},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010069636&doi=10.1007%2F978-3-031-92178-0_14&partnerID=40&md5=798c765c413f4b8dbf5309e30c267d01},
	doi = {10.1007/978-3-031-92178-0_14},
	abstract = {This study introduces an automated framework for constructing ontologies of abstract concepts by integrating Large Language Models (LLMs) with semantic web technologies. The proposed system leverages advanced models, including ChatGPT-4, GPT-4, and Gemini-2.0 flash-exp, to extract entities and relationships from textual data, transforming them into structured ontologies represented in the Web Ontology Language (OWL). By adhering to semantic web standards, the framework ensures the creation of reusable, scalable, and interoperable ontologies that enable advanced applications. This methodology bridges the gap between unstructured data and structured cultural knowledge, enhancing the digital representation and understanding of cultural concepts. As a case study, the framework is applied to extract a cultural ontology from a Wikipedia page, demonstrating its effectiveness in converting unstructured textual data into structured knowledge. © 2025 Elsevier B.V., All rights reserved.},
	journal = {Communications in Computer and Information Science},
	author = {Chowdhury, Rafi Rashid and Goto, Takaaki and Tsuchida, Kensei and Kirishima, Tadaaki and Bandi, Ajay},
	year = {2025},
	note = {Section: 0},
	keywords = {Large language model, Ontology, Natural language processing, Language model, Knowledge management, OWL, RDF, Data mining, Textual data, Computational linguistics, Resource Description Framework (RDF), Language processing, Natural languages, Ontology's, Natural language processing systems, Computer software reusability, Abstract concept, Websites},
	pages = {170 -- 180},
	annote = {Type: Conference paper}
}

@article{christou2025ArtificialRelationshipsIn,
	file = {References/pdf/christou2025ArtificialRelationshipsIn.pdf},
	title = {Artificial {Relationships} in {Fiction}: {A} {Dataset} for {Advancing} {NLP} in {Literary} {Domains}},
	url = {https://aclanthology.org/2025.latechclfl-1.13/},
	doi = {10.18653/v1/2025.latechclfl-1.13},
	abstract = {Relation extraction (RE) in fiction presents unique NLP challenges due to implicit, narrative-driven relationships. Unlike factual texts, fiction weaves complex connections, yet existing RE datasets focus on non-fiction. To address this, we introduce Artificial Relationships in Fiction (ARF), a synthetically annotated dataset for literary RE. Built from diverse Project Gutenberg fiction, ARF considers author demographics, publication periods, and themes. We curated an ontology for fiction-specific entities and relations, and using GPT-4o, generated artificial relationships to capture narrative complexity. Our analysis demonstrates its value for finetuning RE models and advancing computational literary studies. By bridging a critical RE gap, ARF enables deeper exploration of fictional relationships, enriching NLP research at the intersection of storytelling and AI-driven literary analysis.},
	journal = {Proceedings of the 9th Joint SIGHUM Workshop on Computational Linguistics for Cultural Heritage, Social Sciences, Humanities and Literature (LaTeCH-CLfL 2025)},
	author = {Christou, Despina and Tsoumakas, Grigorios},
	editor = {Kazantseva, Anna and Szpakowicz, Stan and Degaetano-Ortlieb, Stefania and Bizzoni, Yuri and Pagel, Janis},
	month = may,
	year = {2025},
	note = {Place: Albuquerque, New Mexico
Publisher: Association for Computational Linguistics
Section: 0},
	pages = {130--147}
}

@article{ciatto2025LargeLanguageModels,
	file = {References/pdf/ciatto2025LargeLanguageModels.pdf},
	title = {Large language models as oracles for instantiating ontologies with domain-specific knowledge},
	volume = {310},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214522484&doi=10.1016%2Fj.knosys.2024.112940&partnerID=40&md5=52807f55e1c4bc0586b3cb13347e8ed6},
	doi = {10.1016/j.knosys.2024.112940},
	abstract = {Background: Endowing intelligent systems with semantic data commonly requires designing and instantiating ontologies with domain-specific knowledge. Especially in the early phases, those activities are typically performed manually by human experts possibly leveraging on their own experience. The resulting process is therefore time-consuming, error-prone, and often biased by the personal background of the ontology designer. Objective: To mitigate that issue, we propose a novel domain-independent approach to automatically instantiate ontologies with domain-specific knowledge, by leveraging on large language models (LLMs) as oracles. Methods: Starting from (i) an initial schema composed by inter-related classes and properties and (ii) a set of query templates, our method queries the LLM multiple times, and generates instances for both classes and properties from its replies. Thus, the ontology is automatically filled with domain-specific knowledge, compliant to the initial schema. As a result, the ontology is quickly and automatically enriched with manifold instances, which experts may consider to keep, adjust, discard, or complement according to their own needs and expertise. Contribution: We formalise our method in general way and instantiate it over various LLMs, as well as on a concrete case study. We report experiments rooted in the nutritional domain where an ontology of food meals and their ingredients is automatically instantiated from scratch, starting from a categorisation of meals and their relationships. There, we analyse the quality of the generated ontologies and compare ontologies attained by exploiting different LLMs. Experimentally, our approach achieves a quality metric that is up to five times higher than the state-of-the-art, while reducing erroneous entities and relations by up to ten times. Finally, we provide a SWOT analysis of the proposed method. © 2025 Elsevier B.V., All rights reserved.},
	journal = {Knowledge-Based Systems},
	author = {Ciatto, Giovanni and Agiollo, Andrea and Magnini, Matteo and Omicini, Andrea},
	year = {2025},
	note = {Section: 0},
	keywords = {Large language model, Ontology, Ontology Population, Language model, Domain-specific knowledge, Semantics, Modeling languages, Intelligent systems, Semantic data, Structured Query Language, Domain Knowledge, Ontology's, Property, Error prones, Human expert, Novel domain},
	annote = {Type: Article}
}

@article{ciroku2024RevontReverseEngineering,
	file = {References/pdf/ciroku2024RevontReverseEngineering.pdf},
	title = {{RevOnt}: {Reverse} engineering of competency questions from knowledge graphs via language models},
	volume = {82},
	issn = {1570-8268},
	url = {https://www.sciencedirect.com/science/article/pii/S1570826824000088},
	doi = {https://doi.org/10.1016/j.websem.2024.100822},
	abstract = {The process of developing ontologies – a formal, explicit specification of a shared conceptualisation – is addressed by well-known methodologies. As for any engineering development, its fundamental basis is the collection of requirements, which includes the elicitation of competency questions. Competency questions are defined through interacting with domain and application experts or by investigating existing datasets that may be used to populate the ontology i.e. its knowledge graph. The rise in popularity and accessibility of knowledge graphs provides an opportunity to support this phase with automatic tools. In this work, we explore the possibility of extracting competency questions from a knowledge graph. This reverses the traditional workflow in which knowledge graphs are built from ontologies, which in turn are engineered from competency questions. We describe in detail RevOnt, an approach that extracts and abstracts triples from a knowledge graph, generates questions based on triple verbalisations, and filters the resulting questions to yield a meaningful set of competency questions; the WDV dataset. This approach is implemented utilising the Wikidata knowledge graph as a use case, and contributes a set of core competency questions from 20 domains present in the WDV dataset. To evaluate RevOnt, we contribute a new dataset of manually-annotated high-quality competency questions, and compare the extracted competency questions by calculating their BLEU score against the human references. The results for the abstraction and question generation components of the approach show good to high quality. Meanwhile, the accuracy of the filtering component is above 86\%, which is comparable to the state-of-the-art classifications.},
	journal = {Journal of Web Semantics},
	author = {Ciroku, Fiorela and Berardinis, Jacopo de and Kim, Jongmo and Meroño-Peñuela, Albert and Presutti, Valentina and Simperl, Elena},
	year = {2024},
	note = {Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Ontology, Language model, Ontology development, Knowledge engineering, Data mining, Competency question extraction, Extraction, Ontology's, Abstracting, High quality, Work-flows, And filters, Automatic tools, Engineering development, Filtration},
	pages = {100822},
	annote = {Type: Article}
}

@article{crum2024EnrichingOntologiesWith,
	file = {References/pdf/crum2024EnrichingOntologiesWith.pdf},
	title = {Enriching {Ontologies} with {Disjointness} {Axioms} using {Large} {Language} {Models}},
	volume = {3853},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212711225&partnerID=40&md5=8e4efddbdf745c0480df90e78e4b6d2b},
	abstract = {Ontologies often lack explicit disjointness declarations between classes, despite their usefulness for sophisticated reasoning and consistency checking in Knowledge Graphs. In this study, we explore the potential of Large Language Models (LLMs) to enrich ontologies by identifying and asserting class disjointness axioms. Our approach aims at leveraging the implicit knowledge embedded in LLMs, using prompt engineering to elicit this knowledge for classifying ontological disjointness. We validate our methodology on the DBpedia ontology, focusing on open-source LLMs. Our findings suggest that LLMs, when guided by effective prompt strategies, can reliably identify disjoint class relationships, thus streamlining the process of ontology completion without extensive manual input. For comprehensive disjointness enrichment, we propose a process that takes logical relationships between disjointness and subclass statements into account in order to maintain satisfiability and reduce the number of calls to the LLM. This work provides a foundation for future applications of LLMs in automated ontology enhancement and offers insights into optimizing LLM performance through strategic prompt design. Our code is publicly available on GitHub at https://github.com/n28div/llm-disjointness. © 2024 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Crum, Elias and De Santis, Antonio and Ovide, Manon and Pan, Jiaxin and Pisu, Alessia and Lazzari, Nicolas and Rudolph, Sebastian},
	year = {2024},
	note = {Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Large language model, Ontology, Language model, Ontology enrichment, Consistency checking, Ontology's, Contrastive Learning, Dbpedia, Disjointness, Disjointness learning, Implicit knowledge},
	annote = {Type: Conference paper}
}

@article{dew2025DevelopingComprehensiveTask,
	file = {References/pdf/dew2025DevelopingComprehensiveTask.pdf},
	series = {{WWW} '25},
	title = {Developing a {Comprehensive} {Task} {Framework} for {Effective} {Workforce} {Analysis}},
	url = {https://doi.org/10.1145/3701716.3715172},
	doi = {10.1145/3701716.3715172},
	abstract = {Effective workforce analysis, planning, and management require a deep understanding of the tasks and skills associated with different roles. This paper introduces a novel methodology for developing a comprehensive task framework that leverages Large Language Models (LLMs) and large-scale job ads data. We first propose an innovative approach to task taxonomy design, which involves the decomposition and reconstruction of tasks into a hierarchical structure based on action-object pairings, systematically refined using LLMs. The methodology extends to integrating the taxonomy with occupation and skill linkages derived from job ads, ensuring alignment with real-world workforce dynamics. Finally, we demonstrate the practical value of this framework through a visual analytics system that enables interactive exploration and analysis of tasks, occupations, and associated skills, highlighting its potential to transform workforce analysis. Demo video: https://bit.ly/41txBZK},
	journal = {Companion Proceedings of the ACM on Web Conference 2025},
	author = {Dew, Rebecca and Li, Mingzhao and Liu, Weidong and Baratha Raj, Sandya},
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery
Section: 0},
	keywords = {large language model, visual analytics, gpt, workforce analysis},
	pages = {2819--2822},
	annote = {event-place: Sydney NSW, Australia}
}

@article{dimitrakopoulos2025EnhancedOntologyExtraction,
	file = {References/pdf/dimitrakopoulos2025EnhancedOntologyExtraction.pdf},
	series = {{WSC} '24},
	title = {Enhanced {Ontology} {Extraction}: {Integrating} {GPT} {AI} with {Human} {Knowledge} on the {Example} of {EU} {Standards} {Related} to {Semiconductor} {Supply} {Chains}},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217617379&doi=10.1109%2FWSC63780.2024.10838760&partnerID=40&md5=8e67c6383c556395af5749406deb7bf3},
	doi = {10.1109/WSC63780.2024.10838760},
	abstract = {This paper addresses challenges in creating ontologies for the semiconductor supply chain. Ontologies are crucial for seamless data exchange within the semantic web, enabling initiatives like GAIA-X and CatenA-X. Traditionally, ontology creation is complex. Here, we propose a novel AI-assisted method using large language models (LLMs) like ChatGPT 4 Turbo to support human experts. This collaboration aims to expedite ontology generation while maintaining quality. While initial tests show promise, refining the human-AI interface for clear content generation remains a focus. By improving this collaboration, we expect to create more accurate and complete ontologies, fostering efficient information sharing and strengthening the meaningfulness of standards within the semiconductor supply chain.},
	journal = {Proceedings of the Winter Simulation Conference},
	author = {Dimitrakopoulos, George and Ehm, Hans and Tsaousi, Eleni},
	year = {2025},
	note = {Place: Orlando, Florida, USA
Publisher: IEEE Press
Section: 0},
	keywords = {Ontologies, Knowledge graphs, Ontology, Language model, Semantic Web, Semantics, Modeling languages, Reliability, Ontology generation, Standards, Collaboration, Accuracy, Chatbots, Ontology Extraction, Supply chains, Information sharing, Ontology's, Semantic-Web, Human knowledge, Human expert, Ontology creations, Semiconducting indium phosphide, Semiconductor supply chain, Web-enabling},
	pages = {1955--1965},
	annote = {Type: Conference paper}
}

@article{dina2025LargeLanguageModels,
	file = {References/pdf/dina2025LargeLanguageModels.pdf},
	title = {Large {Language} {Models} for {Automated} {Characterization} of {Cybersecurity} {Vulnerabilities} using {N}-{Shot} {Learning}},
	volume = {38},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007898507&doi=10.32473%2Fflairs.38.1.138858&partnerID=40&md5=48fad2183b3a68b68e563f3a6dbd030a},
	doi = {10.32473/flairs.38.1.138858},
	abstract = {The US National Vulnerability Database is a public repository of cybersecurity vulnerabilities in software and hardware. This repository is maintained by the National Institute of Standards and Technology (NIST) that developed a Vulnerability Description Ontology framework for characterizing vulnerabilities. Despite advancements in secure software development and vulnerability detection techniques, the number of registered cybersecurity vulnerabilities continues to grow. Characterizing vulnerabilities is essential for selecting effective protection mechanisms to prevent or mitigate cybersecurity vulnerabilities in software and hardware and reduce cyber risks. Manual characterization of vulnerabilities is both time-consuming and costly. While many researchers employ Machine Learning (ML)-based methods to predict characterizations, these methods heavily rely on large amounts of labeled training data. To overcome the challenge of limited labeled data, this paper proposes a solution utilizing three Large Language Models (LLMs) - GPT-4o, Llama-3.1-405B, and Gemini-1.5-flash - to automate the characterization of vulnerabilities across 27 categories, grouped into five noun groups. We use both few-shot and zero-shot learning to prompt the LLMs. Our experimental results show that GPT-4o achieves F1-scores of 80\%, 90\%, 90\%, and 73\% in the context, impact-method, attack theater, and logical impact noun groups, respectively, using a few labeled samples. Additionally, Llama achieves an F1-score of 83\% in the mitigation noun group. © 2025 Elsevier B.V., All rights reserved.},
	journal = {Proceedings of the International Florida Artificial Intelligence Research Society Conference, FLAIRS},
	author = {Dina, Ayesha Siddiqua and Needham, Elijah and Ulybyshev, Denis},
	year = {2025},
	note = {Section: 0},
	keywords = {Language model, Cyber security, Cybersecurity, Computational linguistics, Zero-shot learning, Labeling, Learning systems, Ontology's, Labeled data, Network security, F1 scores, Hardware security, National Institute of Standards and Technology, National security, National vulnerability database, Public repositories, Secure software development, Software and hardwares, Vulnerability description},
	annote = {Type: Conference paper}
}

@article{dong2023OntologyEnrichmentTexts,
	file = {References/pdf/dong2023OntologyEnrichmentTexts.pdf},
	series = {{CIKM} '23},
	title = {Ontology {Enrichment} from {Texts}: {A} {Biomedical} {Dataset} for {Concept} {Discovery} and {Placement}},
	url = {https://doi.org/10.1145/3583780.3615126},
	doi = {10.1145/3583780.3615126},
	abstract = {Mentions of new concepts appear regularly in texts and require automated approaches to harvest and place them into Knowledge Bases (KB), e.g., ontologies and taxonomies. Existing datasets suffer from three issues, (i) mostly assuming that a new concept is pre-discovered and cannot support out-of-KB mention discovery; (ii) only using the concept label as the input along with the KB and thus lacking the contexts of a concept label; and (iii) mostly focusing on concept placement w.r.t a taxonomy of atomic concepts, instead of complex concepts, i.e., with logical operators. To address these issues, we propose a new benchmark, adapting MedMentions dataset (PubMed abstracts) with SNOMED CT versions in 2014 and 2017 under the Diseases sub-category and the broader categories of Clinical finding, Procedure, and Pharmaceutical / biologic product. We provide usage on the evaluation with the dataset for out-of-KB mention discovery and concept placement, adapting recent Large Language Model based methods.},
	journal = {Proceedings of the 32nd ACM International Conference on Information and Knowledge Management},
	author = {Dong, Hang and Chen, Jiaoyan and He, Yuan and Horrocks, Ian},
	year = {2023},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery
Section: 0},
	keywords = {Ontology, Language model, text mining, Ontology enrichment, Taxonomies, language models, SNOMED CT, Biomedical ontologies, biomedical ontologies, SNOMED-CT, Computational linguistics, Entity linking, ontology enrichment, entity linking, Text-mining, concept placement, Natural language processing systems, Concept discoveries, Concept placement, Automated approach, Knowledge taxonomies, Large dataset},
	pages = {5316--5320},
	annote = {event-place: Birmingham, United Kingdom}
}

@article{dong2024LanguageModelBased,
	file = {References/pdf/dong2024LanguageModelBased.pdf},
	title = {A {Language} {Model} {Based} {Framework} for {New} {Concept} {Placement} in {Ontologies}},
	volume = {14664},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194222248&doi=10.1007%2F978-3-031-60626-7_5&partnerID=40&md5=7646da39abb6a08ff3ab8c32975bb31e},
	doi = {10.1007/978-3-031-60626-7_5},
	abstract = {We investigate the task of inserting new concepts extracted from texts into an ontology using language models. We explore an approach with three steps: edge search which is to find a set of candidate locations to insert (i.e., subsumptions between concepts), edge formation and enrichment which leverages the ontological structure to produce and enhance the edge candidates, and edge selection which eventually locates the edge to be placed into. In all steps, we propose to leverage neural methods, where we apply embedding-based methods and contrastive learning with Pre-trained Language Models (PLMs) such as BERT for edge search, and adapt a BERT fine-tuning-based multi-label Edge-Cross-encoder, and Large Language Models (LLMs) such as GPT series, FLAN-T5, and Llama 2, for edge selection. We evaluate the methods on recent datasets created using the SNOMED CT ontology and the MedMentions entity linking benchmark. The best settings in our framework use fine-tuned PLM for search and a multi-label Cross-encoder for selection. Zero-shot prompting of LLMs is still not adequate for the task, and we propose explainable instruction tuning of LLMs for improved performance. Our study shows the advantages of PLMs and highlights the encouraging performance of LLMs that motivates future studies. © 2024 Elsevier B.V., All rights reserved.},
	journal = {Lecture Notes in Computer Science},
	author = {Dong, Hang and Chen, Jiaoyan and He, Yuan and Gao, Yongsheng and Horrocks, Ian},
	year = {2024},
	note = {Section: 0},
	keywords = {Large language model, Ontology, Language model, Pre-trained language model, Ontology enrichment, SNOMED-CT, Computational linguistics, Zero-shot learning, Ontology's, Signal encoding, Concept placement, Edge searches, Edge selection},
	pages = {79 -- 99},
	annote = {Type: Conference paper}
}

@article{doumanas2024IntegratingLlmsIn,
	file = {References/pdf/doumanas2024IntegratingLlmsIn.pdf},
	title = {Integrating {LLMs} in the {Engineering} of a {SAR} {Ontology}},
	volume = {714},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197341155&doi=10.1007%2F978-3-031-63223-5_27&partnerID=40&md5=1c65f9035a3b5087fefbfddea2be3ff9},
	doi = {10.1007/978-3-031-63223-5_27},
	abstract = {In Search and Rescue (SAR) missions, the integration of multiple sources of information may enhance operational efficiency and increase responsiveness significantly, improving situation awareness and aiding decision-making to save lives and mitigate incident impact. Ontologies are crucial for integrating and reasoning with data from diverse sources. Engineering a domain ontology for SAR can be better supported from an agile, collaborative, and iterative ontology engineering methodology (OEM), incorporating the interests of several stakeholders. Large Language Models (LLMs) can play a significant role in completing OEM processes. The goal of this work is to identify how ontology engineering (OE) tasks can be completed with the collaboration of LLMs and humans. The objectives of this paper are, a) to present preliminary exploration of LLMs to generate domain ontologies for the modeling of SAR missions in wildfire incidents b) to propose and evaluate an LLM-enhanced OE approach. In overall, the main contribution of the work presented in this paper is the analysis of LLMs capabilities to ontology engineering, and the evaluation of the synergy between humans and machines to efficiently represent knowledge, with specific focus in the SAR domain. © 2024 Elsevier B.V., All rights reserved.},
	journal = {IFIP Advances in Information and Communication Technology},
	author = {Doumanas, Dimitrios and Soularidis, Andreas and Kotis, Konstantinos I. and Vouros, George A.},
	year = {2024},
	note = {Section: 0},
	keywords = {Ontology engineering, Large language model, Ontology, Language model, Domain ontologies, Decision making, Computational linguistics, Iterative methods, Ontology's, Search and rescue, Ontology Engineering Methodologies, Multiple source, Rescue missions, Search missions},
	pages = {360 -- 374},
	annote = {Type: Conference paper}
}

@article{doumanas2025FineTuningLarge,
	file = {References/pdf/doumanas2025FineTuningLarge.pdf},
	title = {Fine-{Tuning} {Large} {Language} {Models} for {Ontology} {Engineering}: {A} {Comparative} {Analysis} of {GPT}-4 and {Mistral}},
	volume = {15},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218624656&doi=10.3390%2Fapp15042146&partnerID=40&md5=cd9c184dfaf18e7296ecdf2772a70ee0},
	doi = {10.3390/app15042146},
	abstract = {Ontology engineering (OE) plays a critical role in modeling and managing structured knowledge across various domains. This study examines the performance of fine-tuned large language models (LLMs), specifically GPT-4 and Mistral 7B, in efficiently automating OE tasks. Foundational OE textbooks are used as the basis for dataset creation and for feeding the LLMs. The methodology involved segmenting texts into manageable chapters, generating question–answer pairs, and translating visual elements into description logic to curate fine-tuned datasets in JSONL format. This research aims to enhance the models’ abilities to generate domain-specific ontologies, with hypotheses asserting that fine-tuned LLMs would outperform base models, and that domain-specific datasets would significantly improve their performance. Comparative experiments revealed that GPT-4 demonstrated superior accuracy and adherence to ontology syntax, albeit with higher computational costs. Conversely, Mistral 7B excelled in speed and cost efficiency but struggled with domain-specific tasks, often generating outputs that lacked syntactical precision and relevance. The presented results highlight the necessity of integrating domain-specific datasets to improve contextual understanding and practical utility in specialized applications, such as Search and Rescue (SAR) missions in wildfire incidents. Both models, despite their limitations, exhibited potential in understanding OE principles. However, their performance underscored the importance of aligning training data with domain-specific knowledge to emulate human expertise effectively. This study, based on and extending our previous work on the topic, concludes that fine-tuned LLMs with targeted datasets enhance their utility in OE, offering insights into improving future models for domain-specific applications. The findings advocate further exploration of hybrid solutions to balance accuracy and efficiency. © 2025 Elsevier B.V., All rights reserved.},
	number = {4},
	journal = {Applied Sciences (Switzerland)},
	author = {Doumanas, Dimitrios and Soularidis, Andreas and Spiliotopoulos, Dimitris and Vassilakis, Costas and Kotis, Konstantinos I.},
	year = {2025},
	note = {Section: 0},
	keywords = {Ontology engineering, Ontology, Language model, Domain-specific knowledge, Performance, Syntactics, Domain Knowledge, Domain specific, Fine tuning, Large language model fine-tuning, Search and rescue},
	annote = {Type: Article}
}

@article{díaz2024AutomaticKnowledgeGraph,
	file = {References/pdf/díaz2024AutomaticKnowledgeGraph.pdf},
	title = {Automatic knowledge-graph creation from historical documents: {The} {Chilean} dictatorship as a case study},
	volume = {3853},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212705684&partnerID=40&md5=d0fcc6d861c72eaca0134114f37b278e},
	abstract = {We present our results regarding the construction of a knowledge graph from historical documents related to the Chilean dictatorship period (1973-1990). Our approach uses LLMs to automatically recognize entities and relations between them and resolve conflicts between these values. To prevent hallucination, the interaction with the LLM is grounded in a simple ontology with four types of entities and seven types of relations. To evaluate our architecture, we use a gold standard graph constructed using a small subset of the documents, and compare this to the graph obtained from our approach when processing the same set of documents. Results show that the automatic construction manages to recognize a good portion of all the entities in the gold standard and that those not recognized are explained mainly by the level of granularity in which the information is structured in the graph and not because the automatic approach misses an important entity in the graph. Looking forward, we expect this report to encourage work on other similar projects focused on enhancing research in humanities and social science. However, we remark that better evaluation metrics are needed to accurately fine-tune these types of architectures. © 2024 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Díaz, Camila and Dunstan, Jocelyn and Etcheverry, Lorena and Fonck, Antonia and Grez, Alejandro and Mery, Domingo and Reutter, Juan L. and Rojas, Hugo},
	year = {2024},
	note = {Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Ontology, History, Ontology's, Case-studies, Simple++, Automatic construction, Automatic approaches, Gold standards, Historical documents, Humanities and social science, Types of relations},
	annote = {Type: Conference paper {\textbar} RAYYAN-LABELS: ontology-supported application}
}

@article{farmer2025DevelopmentEvaluation4m,
	file = {References/pdf/farmer2025DevelopmentEvaluation4m.pdf},
	title = {Development and evaluation of a {4M} taxonomy from nursing home staff text messages using a fine-tuned generative language model},
	volume = {32},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218408518&doi=10.1093%2Fjamia%2Focaf006&partnerID=40&md5=7e676688b8f034794501b78761b5c3b1},
	doi = {10.1093/jamia/ocaf006},
	abstract = {Objective: This study aimed to explore the utilization of a fine-tuned language model to extract expressions related to the Age-Friendly Health Systems 4M Framework (What Matters, Medication, Mentation, and Mobility) from nursing home worker text messages, deploy automated mapping of these expressions to a taxonomy, and explore the created expressions and relationships. Materials and Methods: The dataset included 21 357 text messages from healthcare workers in 12 Missouri nursing homes. A sample of 860 messages was annotated by clinical experts to form a "Gold Standard"dataset. Model performance was evaluated using classification metrics including Cohen's Kappa (κ), with κ ≥ 0.60 as the performance threshold. The selected model was fine-tuned. Extractions were clustered, labeled, and arranged into a structured taxonomy for exploration. Results: The fine-tuned model demonstrated improved extraction of 4M content (κ = 0.73). Extractions were clustered and labeled, revealing large groups of expressions related to care preferences, medication adjustments, cognitive changes, and mobility issues. Discussion: The preliminary development of the 4M model and 4M taxonomy enables knowledge extraction from clinical text messages and aids future development of a 4M ontology. Results compliment themes and findings in other 4M research. Conclusion: This research underscores the need for consensus building in ontology creation and the role of language models in developing ontologies, while acknowledging their limitations in logical reasoning and ontological commitments. Further development and context expansion with expert involvement of a 4M ontology are necessary. © 2025 Elsevier B.V., All rights reserved.},
	number = {3},
	journal = {Journal of the American Medical Informatics Association},
	author = {Farmer, Matthew Steven and Popescu, Mihail and Powell, Kimberly Ryan},
	year = {2025},
	note = {Section: 0},
	keywords = {natural language processing, ontology, Natural Language Processing, taxonomy, cognition, language model, human, benchmarking, ontology development, article, Humans, information processing, clinical decision making, consensus, Datasets as Topic, elderly care, health care personnel, home for the aged, interpersonal communication, logical reasoning, Missouri, nursing home, nursing home personnel, Nursing Homes, pattern recognition, text messaging, Text Messaging},
	pages = {535 -- 544},
	annote = {Type: Article}
}

@article{fathallah2024Llms4lifeLargeLanguage,
	file = {References/pdf/fathallah2024Llms4lifeLargeLanguage.pdf},
	title = {{LLMs4Life}: {Large} {Language} {Models} for {Ontology} {Learning} in {Life} {Sciences}},
	volume = {3967},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105006905423&partnerID=40&md5=f37af3ab894f04b53e3fc593ac858616},
	abstract = {Ontology learning in complex domains, such as life sciences, poses significant challenges for current Large Language Models (LLMs). Existing LLMs struggle to generate ontologies with multiple hierarchical levels, rich interconnections, and comprehensive class coverage due to constraints on the number of tokens they can generate and inadequate domain adaptation. To address these issues, we extend the NeOn-GPT pipeline for ontology learning using LLMs with advanced prompt engineering techniques and ontology reuse to enhance the generated ontologies' domain-specific reasoning and structural depth. Our work evaluates the capabilities of LLMs in ontology learning in the context of highly specialized and complex domains such as life science domains. To assess the logical consistency, completeness, and scalability of the generated ontologies, we use the AquaDiva ontology developed and used in the collaborative research center AquaDiva 1 as a case study. Our evaluation shows the viability of LLMs for ontology learning in specialized domains, providing solutions to longstanding limitations in model performance and scalability. © 2025 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Fathallah, Nadeen and Staab, Steffen and Algergawy, Alsayed},
	year = {2024},
	note = {Section: 0},
	keywords = {Large language model, Ontology, Language model, Ontology learning, Scalability, Reusability, Linguistics, Engineering education, Ontology's, 'current, Problem oriented languages, Computer simulation languages, Life science domain, Life-sciences, Neon-GPT, Hierarchical systems, Complex domains, Hierarchical level},
	annote = {Type: Conference paper}
}

@article{fathallah2025NeonGptLarge,
	file = {References/pdf/fathallah2025NeonGptLarge.pdf},
	title = {{NeOn}-{GPT}: {A} {Large} {Language} {Model}-{Powered} {Pipeline} for {Ontology} {Learning}},
	volume = {15344},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218469990&doi=10.1007%2F978-3-031-78952-6_4&partnerID=40&md5=071c0cc79dd4a7986f0497d28a7e43be},
	doi = {10.1007/978-3-031-78952-6_4},
	abstract = {We address the task of ontology learning by combining the structured NeOn methodology framework with Large Language Models (LLMs) for translating natural language domain descriptions into Turtle syntax ontologies. The main contribution of the paper is a prompt pipeline tailored for domain-agnostic modeling, exemplified through the application to a domain-specific case study: the wine ontology. The resulting pipeline is used to develop NeOn-GPT, a workflow for automatic ontology modeling, and its proof of concept implementation, integrated on top of the metaphactory platform. NeOn-GPT leverages the systematic approach of the NeOn methodology and LLMs’ generative capabilities to facilitate a more efficient ontology development process. We evaluate the proposed approach by conducting comprehensive evaluations using the Stanford wine ontology as the gold standard. The obtained results show, that LLMs are not fully equipped to perform procedural tasks required for ontology development, and lack the reasoning skills and domain expertise needed. Overall, LLMs require integration with the workflow or trajectory tools for continuous knowledge engineering tasks. Nevertheless, LLMs can significantly alleviate the time and expertise needed. Our code base is publicly available for research and development purposes, accessible at: https://github.com/andreamust/NEON-GPT. © 2025 Elsevier B.V., All rights reserved.},
	journal = {Lecture Notes in Computer Science},
	author = {Fathallah, Nadeen and Das, Arunav and de Giorgis, Stefano and Poltronieri, Andrea and Haase, Peter and Kovriguina, Liubov},
	year = {2025},
	note = {Section: 0},
	keywords = {Large language model, Ontology, Ontology model, Language model, Ontology learning, Information management, Ontology development, Knowledge engineering, Natural languages, Syntactics, Ontology's, Natural language processing systems, Domain description, Neon methodology, Work-flows, Incorrect information},
	pages = {36 -- 50},
	annote = {Type: Conference paper}
}

@article{fathallah2025TamingHallucinationsSemantic,
	file = {References/pdf/fathallah2025TamingHallucinationsSemantic.pdf},
	title = {Taming {Hallucinations}: {A} {Semantic} {Matching} {Evaluation} {Framework} for {LLM}-{Generated} {Ontologies}},
	volume = {3979},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009068954&partnerID=40&md5=b4220ec10d18b3bc6039a3c2da02ba9d},
	abstract = {Ontology learning using Large Language Models (LLMs) has shown promise yet remains challenged by hallucinations-spurious or inaccurate concepts and relationships that undermine domain validity. This issue is particularly critical in highly specialized fields such as life sciences, where ontology accuracy directly impacts knowledge representation and decision-making. In this work, we introduce an automated evaluation framework that systematically assesses the quality of LLM-generated ontologies by comparing their concepts and relationship triples against domain knowledge (i.e. expert-curated domain ontologies). Our approach leverages transformer-based semantic similarity methods to detect hallucinations, ensuring that generated ontologies align with real-world knowledge. We evaluate our framework using six LLM-generated ontologies, validating them against three reference ontologies with increasing domain specificity. This work establishes a scalable, automated approach for validating LLM-generated ontologies, paving the way for their broader adoption in complex, knowledge-intensive domains. © 2025 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Fathallah, Nadeen and Staab, Steffen and Algergawy, Alsayed},
	year = {2025},
	note = {Section: 0},
	keywords = {Large language model, Ontology, Language model, Ontology learning, Semantics, Ontology matching, Knowledge representation, Knowledge management, Decision making, Human computer interaction, Semantic matching, Evaluation framework, Learning systems, Domain Knowledge, Ontology's, Copyrights, Life science domain, Life-sciences, Neon-GPT},
	annote = {Type: Conference paper}
}

@article{feng2024ConstructionApplicationKnowledge,
	file = {References/pdf/feng2024ConstructionApplicationKnowledge.pdf},
	title = {Construction and {Application} of {Knowledge} {Graph} for {Water} {Engineering} {Scheduling} {Based} on {Large} {Language} {Model}},
	volume = {18},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195585807&doi=10.3778%2Fj.issn.1673-9418.2311098&partnerID=40&md5=09fbfb1b464d422201314ff64ff1a36b},
	doi = {10.3778/j.issn.1673-9418.2311098},
	abstract = {With the growth of water conservancy and the increasing demand for information, handling and representing large volumes of water-related data has become complex. Particularly, scheduling textual data often exists in natural language form, lacking clear structure and standardization. Processing and utilizing such diverse data necessitates extensive domain knowledge and professional expertise. To tackle this challenge, a method based on large language model has been proposed to construct a knowledge graph for water engineering scheduling. This approach involves collecting and preprocessing scheduling rule data at the data layer, leveraging large language models to extract embedded knowledge, constructing the ontology at the conceptual layer, and extracting the“three- step”method prompt strategy at the instance layer. Under the interaction of the data, conceptual, and instance layers, high-performance extraction of rule texts is achieved, and the construction of the dataset and knowledge graph is completed. Experimental results show that the F1 value of the extraction method in this paper reaches 85.5\%, and the effectiveness and rationality of the modules of the large language model are validated through ablation experiments. This graph integrates dispersed water conservancy rule information, effectively handles unstructured textual data, and offers visualization querying and functionality tracing. It aids professionals in assessing water conditions and selecting appropriate scheduling schemes, providing valuable support for conservancy decision-making and intelligent reasoning. © 2024 Elsevier B.V., All rights reserved.},
	number = {6},
	journal = {Journal of Frontiers of Computer Science and Technology},
	author = {Feng, Jun and Chang, Yanghong and Lu, Jiamin and Tang, Hailin and Lyu, Zhipeng and Qiu, Yuchun},
	year = {2024},
	note = {Section: 0},
	pages = {1637 -- 1647},
	annote = {Type: Article}
}

@article{feng2024OntologyGroundedAutomatic,
	file = {References/pdf/feng2024OntologyGroundedAutomatic.pdf},
	title = {Ontology-grounded {Automatic} {Knowledge} {Graph} {Construction} by {LLM} under {Wikidata} schema},
	volume = {3841},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210894055&partnerID=40&md5=42721ceb91e4dca1bd023f200ae069d5},
	abstract = {We propose an ontology-grounded approach to Knowledge Graph (KG) construction using Large Language Models (LLMs) on a knowledge base. An ontology is authored by generating Competency Questions (CQ) on knowledge base to discover knowledge scope, extracting relations from CQs, and attempt to replace equivalent relations by their counterpart in Wikidata. To ensure consistency and interpretability in the resulting KG, we ground generation of KG with the authored ontology based on extracted relations. Evaluation on benchmark datasets demonstrates competitive performance in knowledge graph construction task. Our work presents a promising direction for scalable KG construction pipeline with minimal human intervention, that yields high quality and human-interpretable KGs, which are interoperable with Wikidata semantics for potential knowledge base expansion. © 2024 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Feng, Xiaohan and Wu, Xixin and Meng, Helen Mei Ling},
	year = {2024},
	note = {Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Large language model, Ontology, Language model, Relation extraction, Semantics, Wikidata, Interpretability, Interpretable AI, Graph construction, Ontology's, Equivalent relation},
	pages = {117 -- 135},
	annote = {Type: Conference paper}
}

@article{ferraz2025CanLanguageModels,
	file = {References/pdf/ferraz2025CanLanguageModels.pdf},
	title = {Can {Language} {Models} {Align} {Biomedical} {Ontologies}?: {Evaluating} {Retrieval}-{Augmented} {Prompt} {Strategies} in {Bio}-{ML}},
	volume = {4001},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105012127875&partnerID=40&md5=644ab89c151aee621af0eef8183870b8},
	abstract = {Aligning biomedical ontologies presents a significant challenge due to their complexity and the highly domain-specific nature of their vocabulary. Recent advancements in Language Models (LMs) have led to their increasing application in ontology alignment tasks, offering promising results. However, a systematic evaluation of semantics-based prompting strategies for leveraging LMs in this context remains unexplored. This study investigates the effectiveness of different prompting techniques to enhance biomedical ontology alignment performance. We have developed a framework to support the design of LM-based queries to assess the semantic similarity between ontology classes. The framework interrogates the ontologies to align to extract relevant contextual information to inject into the LM prompts allowing the use of Retrieval Augmented Generation (RAG). We conduct preliminary experiments on selected hard cases from biomedical ontologies that compose the Ontology Alignment Evaluation Initiative Bio-ML track and provide some insights into the effectiveness, reliability, and limitations of prompt-based approaches in ontology matching. © 2025 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Ferraz, Lucas and Cotovio, Pedro Giesteira and Pesquita, Cátia},
	year = {2025},
	note = {Section: 0},
	keywords = {Ontology, Language model, Semantics, Knowledge representation, Ontology alignment, Query processing, Biomedical ontologies, Performance, Alignment, Computational linguistics, Ontology's, Knowledge-representation, Model-based OPC, Domain specific, Specific nature, Systematic evaluation},
	annote = {Type: Conference paper}
}

@article{funk2023TowardsOntologyConstruction,
	file = {References/pdf/funk2023TowardsOntologyConstruction.pdf},
	title = {Towards {Ontology} {Construction} with {Language} {Models}},
	volume = {3577},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179559244&partnerID=40&md5=33969446bee8becffb8a2e0211cb3651},
	abstract = {We present a method for automatically constructing a concept hierarchy for a given domain by querying a large language model. We apply this method to various domains using OpenAI’s GPT 3.5. Our experiments indicate that LLMs can be of considerable help for constructing concept hierarchies. © 2023 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Funk, Maurice and Hosemann, Simon and Jung, Jean Christoph and Lutz, Carsten},
	year = {2023},
	note = {Section: 0},
	keywords = {Language model, Ontology construction, Computational linguistics, Concept hierarchies},
	annote = {Type: Conference paper}
}

@article{gao2022ConstructionTourismAttraction,
	title = {Construction of {Tourism} {Attraction} {Knowledge} {Graph} {Based} on {Web} {Text} and {Transfer} {Learning}},
	volume = {47},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138141244&doi=10.13203%2Fj.whugis20220120&partnerID=40&md5=d681ee709b1c81368c826c6f6dfb7678},
	doi = {10.13203/j.whugis20220120},
	abstract = {Objectives The rapid development of information and communication technology has facilitated the online tourism service and massive web text, which provides a new opportunity for tourism sector planning and personalized recommendation. However, owing to the characteristics of semantic vagueness and low signal-to-noise ratio, the web text is difficult to get utilized directly. Therefore, how to integrate the technologies of knowledge engineering, natural language processing and machine learning, so as to form a formalized domain knowledge graph from abundant tourism text, has attracted much attention. Methods This paper proposes a tourism knowledge graph construction method based on tourism domain ontology and transfer learning. Firstly, the ontology of tourist attractions is defined based on the domain specifications and standards, which support a comprehensive and systematic description of the semantic characteristics of attractions. Secondly, a transfer learning method is adopted to transform the pre-training language model into a customized knowledge extractor to acquire knowledge triples accurately from web text, which is integrated with the scattered tourism-related information including tourist check-ins and POI (point of interest) attributes to build a systematic knowledge graph. Results Experimental results show that the proposed knowledge extractor improves the accuracy (average area under the curve) and integrity (the number of sematic characteristics) of acquisition of sematic knowledge by 50.7\% and 670\%, respectively, compared with the common LDA (latent Dirichlet allocation) model. The constructed knowledge graph of tourist attractions contained 77 039 entities, 16 types of relationship, and total 10 971 810 triples. Conclusions Through the unified organization paradigm of triplet knowledge, the study realizes the fusion and integration of multi-source heterogeneous tourism data, and addresses the potential systemic risk in the decision-making process based on a single data source. It is argued that the constructed knowledge graph can fully capture the real tourism scene, support in-depth analysis of tourist behaviors and demands at different scales and granularities, and provide decision support for sustainable developments of tourist destinations. © 2022 Elsevier B.V., All rights reserved.},
	number = {8},
	journal = {Wuhan Daxue Xuebao (Xinxi Kexue Ban)/Geomatics and Information Science of Wuhan University},
	author = {Gao, Jialiang and Lu, Feng and Peng, Peng and Xu, Yang},
	year = {2022},
	note = {Section: 0},
	keywords = {Knowledge acquisition, Knowledge graphs, Knowledge graph, Ontology, Semantics, machine learning, Machine learning, Decision support systems, Decision making, Transfer learning, Statistics, Engineering education, Learning systems, Domain Knowledge, Graph-based, Natural language processing systems, Learning algorithms, knowledge based system, Tourism management, Information and Communication Technologies, Signal to noise ratio, signal-to-noise ratio, tourism development, tourism management, Tourism services, Tourist attractions, tourist destination, Web text mining, Web texts, Web transfers, Cannot find},
	pages = {1191 -- 1219},
	annote = {Type: Article}
}

@article{georgakopoulos2024TextKnowledgeLeveraging,
	file = {References/pdf/georgakopoulos2024TextKnowledgeLeveraging.pdf},
	title = {From {Text} to {Knowledge}: {Leveraging} {LLMs} and {RAG} for {Relationship} {Extraction} in {Ontologies} and {Thesauri}},
	volume = {3967},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105006913033&partnerID=40&md5=ea70a64b726d1dc660804bf58efadf08},
	abstract = {Ontologies, vocabularies, and thesauri provide a shared conceptualisation for a domain. Manually maintaining and updating such knowledge systems when knowledge changes, does not scale for large domains, such as in biomedicine. Recently, large language models (LLMs) have been increasingly used as tools in knowledge engineering processes, offering new possibilities for the automatic creation and maintenance of knowledge systems. This work explores how LLMs can be leveraged for the automated extension of such knowledge systems. Specifically, we build on the DRAGON-AI framework, which integrates Retrieval-Augmented Generation (RAG) to provide LLMs with access to external knowledge sources for more faithful outputs. We investigate the ability of the framework to predict relationships between a given knowledge system and a novel concept. We do so for both an ontology and a thesaurus, and analyse the impact of (i) enriching prompts with contextual information as well as more clear instructions, (ii) an alternative retrieval approach, and (iii) using a conversational model versus an instruction-following model. The results show superior quality in the ontology generations for all models and approaches compared to the thesaurus. The two models show varied performance across the different experiment configurations with only the conversational model showing notably improved performance, in terms of F1, for the ontology with the custom retrieval approach. © 2025 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Georgakopoulos, Antonios and Van Ossenbruggen, Jacco and Stork, Lise},
	year = {2024},
	note = {Section: 0},
	keywords = {Knowledge acquisition, Large language model, Language model, Relationship extraction, Retrieval-augmented generation, Prompting, Performance, Knowledge system, Ontology's, Conversational model, DRAGON-AI},
	annote = {Type: Conference paper}
}

@article{ghazouani2025LlmDrivenCase,
	file = {References/pdf/ghazouani2025LlmDrivenCase.pdf},
	title = {{LLM}-{Driven} {Case}-{Base} {Populating} for {Structuring} and {Integrating} {Restoration} {Experiences}},
	volume = {15662},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010815398&doi=10.1007%2F978-3-031-96559-3_5&partnerID=40&md5=5edd9a3da5bfa66a6d0f852e64dcbc6c},
	doi = {10.1007/978-3-031-96559-3_5},
	abstract = {In Case-Based Reasoning (CBR), a case-base is a structured knowledge collection, often represented as an ontology with a TBox (conceptual structure) and ABox (concrete cases). This work emphasizes the need for a case-base to integrate knowledge from unstructured texts describing hydro-ecosystem restoration experiences, forming the foundation for a CBR framework to address new restoration challenges. However, populating the case-base from unstructured texts presents challenges due to fragmented, inconsistent, and implicit information. Therefore, we propose leveraging large language models (LLMs) to extract knowledge from unstructured texts, where the ontology population is approached as a generative knowledge extraction task. The results demonstrate that LLMs can effectively extract structured knowledge, facilitating the creation of a case-base for future projects. © 2025 Elsevier B.V., All rights reserved.},
	journal = {Lecture Notes in Computer Science},
	author = {Ghazouani, Fethi and Giustozzi, Franco and Le Ber, Florence},
	year = {2025},
	note = {Section: 0},
	keywords = {Knowledge acquisition, Large language model, Ontology, Language model, Knowledge management, Computational linguistics, Model-driven, Ecosystems, Ontology's, Conceptual structures, Structured knowledge, Case based reasoning, Unstructured texts, Case base, Casebased reasonings (CBR), Hydro-ecosystems, Restoration},
	pages = {67 -- 80},
	annote = {Type: Conference paper}
}

@article{giglou2023Llms4olLargeLanguage,
	file = {References/pdf/giglou2023Llms4olLargeLanguage.pdf},
	title = {{LLMs4OL}: {Large} {Language} {Models} for {Ontology} {Learning}},
	volume = {14265},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177183557&doi=10.1007%2F978-3-031-47240-4_22&partnerID=40&md5=0304490aebf9532fcf8f18d22aa760bf},
	doi = {10.1007/978-3-031-47240-4_22},
	abstract = {We propose the LLMs4OL approach, which utilizes Large Language Models (LLMs) for Ontology Learning (OL). LLMs have shown significant advancements in natural language processing, demonstrating their ability to capture complex language patterns in different knowledge domains. Our LLMs4OL paradigm investigates the following hypothesis: Can LLMs effectively apply their language pattern capturing capability to OL, which involves automatically extracting and structuring knowledge from natural language text? To test this hypothesis, we conduct a comprehensive evaluation using the zero-shot prompting method. We evaluate nine different LLM model families for three main OL tasks: term typing, taxonomy discovery, and extraction of non-taxonomic relations. Additionally, the evaluations encompass diverse genres of ontological knowledge, including lexicosemantic knowledge in WordNet, geographical knowledge in GeoNames, and medical knowledge in UMLS. The obtained empirical results show that foundational LLMs are not sufficiently suitable for ontology construction that entails a high degree of reasoning skills and domain expertise. Nevertheless, when effectively fine-tuned they just might work as suitable assistants, alleviating the knowledge acquisition bottleneck, for ontology construction. © 2023 Elsevier B.V., All rights reserved.},
	journal = {Lecture Notes in Computer Science},
	author = {Giglou, Hamed Babaei and D’Souza, Jennifer and Auer, Sören},
	year = {2023},
	note = {Section: 0},
	keywords = {Large language model, Ontology, Language model, Ontology learning, Data mining, Prompting, Ontology construction, Computational linguistics, Language patterns, Zero-shot learning, Learning systems, Ontology's, Natural language processing systems, Prompt-based learning},
	pages = {408 -- 427},
	annote = {Type: Conference paper}
}

@article{giglou2025Llms4omMatchingOntologies,
	file = {References/pdf/giglou2025Llms4omMatchingOntologies.pdf},
	title = {{LLMs4OM}: {Matching} {Ontologies} with {Large} {Language} {Models}},
	volume = {15344},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218455564&doi=10.1007%2F978-3-031-78952-6_3&partnerID=40&md5=c3c4db12909f8024518974717c695310},
	doi = {10.1007/978-3-031-78952-6_3},
	abstract = {Ontology Matching (OM), is a critical task in knowledge integration, where aligning heterogeneous ontologies facilitates data interoperability and knowledge sharing. Traditional OM systems often rely on expert knowledge or predictive models, with limited exploration of the potential of Large Language Models (LLMs). We present the LLMs4OM framework, a novel approach to evaluate the effectiveness of LLMs in OM tasks. This framework utilizes two modules for retrieval and matching, respectively, enhanced by zero-shot prompting across three ontology representations: concept, concept-parent, and concept-children. Through comprehensive evaluations using 20 OM datasets from various domains, we demonstrate that LLMs, under the LLMs4OM framework, can match and even surpass the performance of traditional OM systems, particularly in complex matching scenarios. Our results highlight the potential of LLMs to significantly contribute to the field of OM. © 2025 Elsevier B.V., All rights reserved.},
	journal = {Lecture Notes in Computer Science},
	author = {Giglou, Hamed Babaei and D’Souza, Jennifer and Engel, Felix C. and Auer, Sören},
	year = {2025},
	note = {Section: 0},
	keywords = {Large language model, Ontology, Language model, Ontology matching, Retrieval augmented generation, Ontology alignment, Expert systems, Zero-shot learning, Ontology's, Matching system, Matchings, Critical tasks, Zero-shot testing},
	pages = {25 -- 35},
	annote = {Type: Conference paper}
}

@article{gosselin2022SebmatcherResultsOaei,
	file = {References/pdf/gosselin2022SebmatcherResultsOaei.pdf},
	title = {{SEBMatcher} {Results} for {OAEI} 2022},
	volume = {3324},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146435366&partnerID=40&md5=304b1763207ce915a1271adf09143f62},
	abstract = {This paper presents the results of the Structural Embeddings with BERT Matcher (SEBMatcher) in the OAEI 2022 competition. SEBMatcher is a novel schema matching system that employs a 2 step approach: An unsupervised pretraining of a Masked Language Modeling BERT fed with random walks, followed by a supervised training of a BERT for sequence classification fed with positive and negative mappings. This is the first year of participation in the OAEI for SEBMatcher and it has obtained promising results in participating tracks. © 2023 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Gosselin, Francis and Zouaq, Amal},
	year = {2022},
	note = {Section: 0},
	keywords = {Language model, Ontology alignment, Modeling languages, Pre-training, Embeddings, Representation learning, Schema matching, Matching system, ISWC-2022, Random Walk, Supervised trainings, Might exclude},
	pages = {202 -- 209},
	annote = {Type: Conference paper}
}

@article{groza2023OntologyAgeRelated,
	file = {References/pdf/groza2023OntologyAgeRelated.pdf},
	title = {An ontology for {Age}-{Related} {Macular} {Degeneration} using ophthalmologists and language models},
	volume = {3415},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165747761&partnerID=40&md5=4afe6edcf9e1b17885effdbede323f78},
	abstract = {We aim to support monitoring of the current guidelines and scientific evidence in the management of Age-Related Macular Degeneration (AMD) in order to augment retinal specialists to develop a clinically oriented and consensual protocol for therapeutic approaches for AMD. First, we are engineering an ontology for AMD retinal condition using information from literature, related medical ontologies and domain knowledge from ophthalmologists. Second, we augment the knowledge engineer capabilities to populate and enrich the ontology using structured knowledge extracted from medical literature with the GPT-3 language model. Third, we perform reasoning to signal to the ophthalmologist differences or inconsistencies among different clinical studies, protocols or therapeutic approaches. © 2023 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Groza, Adrian Petru and Marginean, Anca Nicoleta and Delia Nicoara, Simona},
	year = {2023},
	note = {Section: 0},
	keywords = {Ontology, Language model, Reasoning, Medical ontology, Computational linguistics, Conflict detection, Ophthalmology, Domain Knowledge, Ontology's, 'current, Medical domains, Condition, Age-related macular degeneration, Scientific evidence},
	pages = {141 -- 142},
	annote = {Type: Conference paper}
}

@article{gupta2024EchoEnvironmentalSound,
	title = {{ECHO}: {Environmental} {Sound} {Classification} with {Hierarchical} {Ontology}-guided {Semi}-{Supervised} {Learning}},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205825848&doi=10.1109%2FCONECCT62155.2024.10677303&partnerID=40&md5=dd9414b66e627f0744370228215bd482},
	doi = {10.1109/CONECCT62155.2024.10677303},
	abstract = {Environment Sound Classification has been a well-studied research problem in the field of signal processing and till now more focus has been laid on fully supervised approaches. Recently, the focus has moved towards semi-supervised methods which concentrate on utilizing unlabeled data, and self-supervised methods which learn the intermediate representation through pretext tasks or contrastive learning. However, both approaches require a vast amount of unlabelled data to improve performance. In this work, we propose a novel framework called Environmental Sound Classification with Hierarchical Ontology-guided semi-supervised Learning (ECHO) that utilizes label ontology-based hierarchy to learn semantic representation by defining a novel pretext task. The model tries to predict coarse labels represented by the Large Language Model (LLM) based on ground truth label ontology, then further fine-tuned in a supervised way to predict the actual task. ECHO achieves a 1\% to 8\% accuracy improvement over baseline systems across UrbanSound8K, ESC-10, and ESC-50 datasets.},
	journal = {2024 IEEE International Conference on Electronics, Computing and Communication Technologies (CONECCT)},
	author = {Gupta, Pranav and Sharma, Raunak and Kumari, Rashmi and Aditya, Sri Krishna and Choudhary, Shwetank and Kumar, Sumit and M, Kanchana and R, Thilagavathy},
	month = jul,
	year = {2024},
	note = {Section: 0},
	keywords = {Ontologies, Ontology, Large language models, Semantics, semi-supervised learning, Contrastive learning, Federated learning, Self-supervised learning, Semi-supervised learning, Accuracy, Adversarial machine learning, Signal processing, Environment Sound Classification, Label ontology, Semisupervised learning, Ontology's, Contrastive Learning, Learn+, Environment sound classification, Environmental sound classifications, Research problems, Signal-processing, Sound classification, Unlabeled data, Cannot download},
	pages = {1--5},
	annote = {ISSN: 2766-2101}
}

@article{guryanov2025ApproachAutomatedOntology,
	title = {An {Approach} to {Automated} {Ontology} {Extraction} {From} {Technological} {Documentation} {Using} {NLP} and {LLM}},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009220232&doi=10.1109%2FICIEAM65163.2025.11028174&partnerID=40&md5=ae8cbf6929836ebcd5106cf7818cd65b},
	doi = {10.1109/ICIEAM65163.2025.11028174},
	abstract = {The paper presents an approach to constructing a formal description of a subject area using automated analysis of technological documentation. The first stage of the proposed approach is extracting data (terms, objects of the subject area) from technical documentation on the subject area. Then, a natural language query is formed for a large language model (LLM), which helps to extract relations between the extracted terms. At the final stage, an OWL ontology is formed by postprocessing the obtained data. Evaluation experiments were conducted on 16 documents (ISO) on the topic of “Space industry”. Experiments were also conducted to compare algorithms for extracting terms and relations using LLM and the C-value algorithm. The proposed approach has proven its effectiveness on strictly formalized texts.},
	journal = {2025 International Conference on Industrial Engineering, Applications and Manufacturing (ICIEAM)},
	author = {Guryanov, A. V. and Moshkin, V. S. and Dyrnochkin, A. A.},
	month = may,
	year = {2025},
	note = {Section: 0},
	keywords = {large language model, Ontologies, Large language model, Ontology, Natural language processing, Language model, Large language models, Manufacturing, natural language processing, ontology, OWL, Term, Language processing, Ontology Extraction, Documentation, Natural languages, Prototypes, Industries, design documentation, Industrial engineering, ISO Standards, technical documentation, term, Ontology's, Natural language processing systems, Query languages, C (programming language), Design documentation, Technical documentations, Cannot download},
	pages = {1011--1016},
	annote = {ISSN: 2993-4060}
}

@article{hannah2025LargeLanguageModels,
	file = {References/pdf/hannah2025LargeLanguageModels.pdf},
	title = {Large {Language} {Models} as {Knowledge} {Evaluation} {Agents}},
	volume = {3977},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105008495455&partnerID=40&md5=522713b4c09e34210bf1335f60193335},
	abstract = {With the recent rise of large language models, there has been a growing interest in employing LLMs in different knowledge engineering tasks, such as supporting the semi-automatic creation of KG schemata. This is the case also when leveraging semi-structured data by translating XML schemata into ontologies, where there is a need to inject additional knowledge that makes explicit the relationships between different entities. We investigate the viability of using LLMs as knowledge evaluation agents to assess the suitability of the injected knowledge; by using Gemini as an LLM-based proxy for a human evaluator, and we configure it with different parameter settings and prompt structures. The responses (i.e. the LLM-based assessment of the relationships) are compared against the set of assessments or evaluations carried out by domain experts. We find that despite encountering some issues, the use of LLMs as a proxy expert shows promise in their ability to understand complex domains and evaluate relationships with respect to that domain. © 2025 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Hannah, George and de Berardinis, Jacopo and Payne, Terry R. and Tamma, Valentina A.M. and Mitchell, Andrew and Piercy, Ellen and Johnson, Ewan and Ng, Andrew and Rostron, Harry and Konev, Boris Yu},
	year = {2025},
	note = {Section: 0},
	keywords = {Ontology engineering, Ontology, Language model, Knowledge management, Knowledge engineering, Prompt engineering, LLM evaluation, Agents, Domain Knowledge, Engineering tasks, Automatic creations, Knowledge evaluations, Semi-automatics, Semistructured data, XML-Schema},
	annote = {Type: Conference paper}
}

@article{hao2024AnalyzingLlama3,
	file = {References/pdf/hao2024AnalyzingLlama3.pdf},
	title = {Analyzing {Llama} 3-based {Approach} for {Axiom} {Translation} from {Ontologies}},
	volume = {3853},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212688634&partnerID=40&md5=2bb61c3b90845531b2a9b19696705ec7},
	abstract = {Ontology development involves a top-down approach where ontology engineers and domain experts collaboratively define and evaluate ontological elements and axioms. Translating ontology axioms into natural language can significantly aid in ontology evaluation by making the content more understandable to subject matter experts who may lack a background in knowledge engineering. In this preliminary study, we investigate the potential of large language models (LLMs) in axiom translation from ontologies to facilitate ontology evaluation. We utilize Llama 3 to translate 1,192 ontology axioms across 19 distinct axiom types from five published ontologies. Results show that 163 (13.67\%) of the Llama 3 translation of the axiom are accurately represented, 268 (22.48\%) are not accurately represented, and 761 (63.84\%) are partially accurate. Our manual evaluation of the Llama 3 translation indicates some competency in producing hierarchical natural language equivalents while revealing some limitations when translating complex axioms. Nonetheless, there are opportunities to improve the results with few-shot training or using LLMs to provide support in knowledge engineering for ontologies. © 2024 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Hao, Xubing and Cui, Licong and Tao, Cui and Roberts, Kirk E. and Amith, Muhammad Tuan},
	year = {2024},
	note = {Section: 0},
	keywords = {Ontology, Language model, Ontology development, Knowledge engineering, Natural languages, Subject matter experts, Ontology's, Ontology evaluations, Domain experts, Translation (languages), Ontological elements, Ontology axioms, Top down approaches},
	annote = {Type: Conference paper}
}

@article{haque2024UtilizingStructuralMetrics,
	file = {References/pdf/haque2024UtilizingStructuralMetrics.pdf},
	title = {Utilizing {Structural} {Metrics} from {Knowledge} {Graphs} to {Enhance} the {Robustness} {Quantification} of {Large} {Language} {Models}},
	doi = {10.1109/DSAA61799.2024.10722791},
	abstract = {The goal of this study is to determine whether large language models (LLMs) like CodeLlama, Mistral, and Vicuna can be used to build knowledge graphs (KGs) from textual data. We create class descriptions for well-known KGs such as DBpedia, YAGO, and Google Knowledge Graph, from which we extract RDF triples and enhance these graphs using different preprocessing methods. Six structural quality measures are used in the study to compare the constructed and existing KGs. Our results demonstrate how important LLMs are to improving KG construction and provide insightful information for KG construction researchers. Moreover, an in-depth analysis of popular open-source LLM models enables researchers to identify the most efficient model for various tasks, ensuring optimal performance in specific applications.},
	journal = {2024 IEEE 11th International Conference on Data Science and Advanced Analytics (DSAA)},
	author = {Haque, Mohd Ariful and Kamal, Marufa and George, Roy and Gupta, Kishor Datta},
	month = oct,
	year = {2024},
	note = {Section: 0},
	keywords = {Ontologies, Knowledge graphs, Large language models, Resource description framework, Data science, Robustness, Measurement, Internet, Analytical models},
	pages = {1--2},
	annote = {ISSN: 2766-4112}
}

@article{haris2024SemanticPerspectivesLake,
	file = {References/pdf/haris2024SemanticPerspectivesLake.pdf},
	title = {Semantic {Perspectives} on the {Lake} {District} {Writing}: {Spatial} {Ontology} {Modeling} and {Relation} {Extraction} for {Deeper} {Insights}},
	volume = {315},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205767309&doi=10.4230%2FLIPIcs.COSIT.2024.11&partnerID=40&md5=72fff5300bf9859aec90a94affa75bee},
	doi = {10.4230/LIPIcs.COSIT.2024.11},
	abstract = {Extracting spatial details from historical texts can be difficult, hindering our understanding of past landscapes. The study addresses this challenge by analyzing the Corpus of the Lake District Writing, focusing on the English Lake District region. We systematically link the theoretical notions from the core concepts of spatial information to provide basis for the problem domain. The conceptual foundation is further complemented with a spatial ontology and a custom gazetteer, allowing a formal and insightful semantic exploration of the massive unstructured corpus. The other contrasting side of the framework is the usage of LLMs for spatial relation extraction. We formulate prompts leveraging understanding of the LLMs of the intended task, curate a list of spatial relations representing the most recurring proximity or vicinity relations terms and extract semantic triples for the top five place names appearing in the corpus. We compare the extraction capabilities of three benchmark LLMs for a scholarly significant historical archive, representing their potential in a challenging and interdisciplinary research problem. Finally, the network comprising the semantic triples is enhanced by incorporating a gazetteer-based classification of the objects involved thus improving their spatial profiling. © 2024 Elsevier B.V., All rights reserved.},
	journal = {Leibniz International Proceedings in Informatics, LIPIcs},
	author = {Haris, Erum and Cohn, Anthony G. and Stell, John G.},
	year = {2024},
	note = {Section: 0},
	keywords = {Large language model, Ontology, Ontology model, Language model, Relation extraction, Semantics, Text mining, Modeling languages, Benchmarking, Spatial relations, Ontology's, Classification (of information), Economic and social effects, Ontology relations, Spatial humanity, Spatial narratives, Spatial ontologies},
	annote = {Type: Conference paper}
}

@article{he2023ExploringLargeLanguage,
	file = {References/pdf/he2023ExploringLargeLanguage.pdf},
	title = {Exploring {Large} {Language} {Models} for {Ontology} {Alignment}},
	volume = {3632},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184375684&partnerID=40&md5=43d321af25029eca4ea303b161851303},
	abstract = {This work investigates the applicability of recent generative Large Language Models (LLMs), such as the GPT series and Flan-T5, to ontology alignment for identifying concept equivalence mappings across ontologies. To test the zero-shot$^{\textrm{1}}$ performance of Flan-T5-XXL and GPT-3.5-turbo, we leverage challenging subsets from two equivalence matching datasets of the OAEI Bio-ML track, taking into account concept labels and structural contexts. Preliminary findings suggest that LLMs have the potential to outperform existing ontology alignment systems like BERTMap, given careful framework and prompt design. © 2024 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {He, Yuan and Chen, Jiaoyan and Dong, Hang and Horrocks, Ian},
	year = {2023},
	note = {Section: 0},
	keywords = {Large language model, Ontology, Language model, GPT, Ontology matching, Ontology alignment, Performance, Computational linguistics, Ontology's, Matchings, Concept equivalences, Flan-t5},
	annote = {Type: Conference paper}
}

@article{he2023LanguageModelAnalysis,
	file = {References/pdf/he2023LanguageModelAnalysis.pdf},
	title = {Language {Model} {Analysis} for {Ontology} {Subsumption} {Inference}},
	url = {https://aclanthology.org/2023.findings-acl.213/},
	doi = {10.18653/v1/2023.findings-acl.213},
	abstract = {Investigating whether pre-trained language models (LMs) can function as knowledge bases (KBs) has raised wide research interests recently. However, existing works focus on simple, triple-based, relational KBs, but omit more sophisticated, logic-based, conceptualised KBs such as OWL ontologies. To investigate an LM's knowledge of ontologies, we propose OntoLAMA, a set of inference-based probing tasks and datasets from ontology subsumption axioms involving both atomic and complex concepts. We conduct extensive experiments on ontologies of different domains and scales, and our results demonstrate that LMs encode relatively less background knowledge of Subsumption Inference (SI) than traditional Natural Language Inference (NLI) but can improve on SI significantly when a small number of samples are given. We will open-source our code and datasets.},
	journal = {Findings of the Association for Computational Linguistics: ACL 2023},
	author = {He, Yuan and Chen, Jiaoyan and Jimenez-Ruiz, Ernesto and Dong, Hang and Horrocks, Ian},
	editor = {Rogers, Anna and Boyd-Graber, Jordan and Okazaki, Naoaki},
	month = jul,
	year = {2023},
	note = {Place: Toronto, Canada
Publisher: Association for Computational Linguistics
Section: 0},
	keywords = {Ontology, Language model, Background knowledge, Computational linguistics, Language inference, Natural languages, Ontology's, Modeling analyzes, Open systems, Different domains, Simple++, OWL ontologies, Open source software, Research interests},
	pages = {3439--3453},
	annote = {Type: Conference paper}
}

@article{he2025StaticDynamicEmbedding,
	title = {Static and {Dynamic} {Embedding} {Approaches} to {Identify} {Is}-{A} {Relations} in {SNOMED} {CT}},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105012760706&doi=10.1109%2FICHI64645.2025.00050&partnerID=40&md5=483223ede657cc39d5d7756f354e5d48},
	doi = {10.1109/ICHI64645.2025.00050},
	abstract = {Systematized Nomenclature of Medicine - Clinical Terms (SNOMED CT) is a comprehensive clinical terminology with over 350,000 unique concepts and 1 million relationships. It serves as an essential resource for both clinical practice and medical research. Approximately 40\% of these relationships are of the is-a type, which is key to classifying concepts as subtypes or subclasses within broader categories and is fundamental for decision support systems and automated reasoning in clinical environments. Identifying is-a relationships in SNOMED CT is crucial for enhancing the accuracy of patient cohort queries, which form the backbone of clinical and research applications. Our study aims to use deep learning-based neural networks to determine whether a relationship between two concepts falls under the is-a or non-is-a categories. This approach can help detect misclassified or undefined is-a concept pairs, ultimately improving the quality of SNOMED CT ontology. We construct a node-edge-node structure for concept pairs and their relationships, which we then split into two categories: is-a and non-is-a classes. In this study, we propose two classification approaches. In the first approach using embeddingBag, the data are mapped into vector representations and used as input for a fully connected neural network to learn the patterns of the is-a relationship. During model training, 80\% of the data is used for training and the remaining 20\% for testing.We achieved a precision of 0.903, recall of 0.894, and F1 Score of 0.898 in predicting the is-a relation among the associated medical concepts. The second approach involved transformer-based models like BERT(Bidirectional Encoder Representations from Transformers), introduced by Devlin et al. [1], which dramatically advanced various natural language processing (NLP) tasks by offering deeply contextualized word embeddings. And RoBERTa(Robustly optimized BERT approach)[2], both BERT and RoBERTa models have significantly advanced the field of NLP. This work uses them as encoders connected to a classifier head to predict is-a or non-is-a categories. We fine-tune our models using a historical SNOMED CT dataset from 2017, while evaluation is carried out on new data introduced after 2023 in the 2024 release. With a recall of 0.933, precision of 0.933, F1 score of 0.932, accuracy of 0.933, and ROC of 0.972, RoBERTa outperforms the other baseline models (Support Vector Machine(SVM), K-Nearest Neighbors(KNN), Naive Bayes, and Multilayer Perceptron(MLP)) across all metrics. This work demonstrates that our implementation can effectively identify unknown is-a relations in future datasets.},
	journal = {2025 IEEE 13th International Conference on Healthcare Informatics (ICHI)},
	author = {He, Bofan and Cheng, Jerry Q. and Gu, Huanying},
	month = jun,
	year = {2025},
	note = {Section: 0},
	keywords = {Ontologies, Large language model, Ontology, Terminology, Natural language processing, Language model, BERT, Deep learning, Information retrieval, Deep Learning, Natural Language Processing, Large Language Model, Neural networks, Transformers, Clinical terms, Data models, Training, SNOMED-CT, Deep neural networks, Computational linguistics, Information Retrieval, Accuracy, Medical imaging, Language processing, Bidirectional encoder representation from transformer, Encoding, Natural languages, Bidirectional control, Classification of Multi Sentence, Vectors, Learning systems, Natural language processing systems, Classification (of information), Clinical research, Learning algorithms, Classification of multi sentence, Cannot download},
	pages = {369--378},
	annote = {ISSN: 2575-2634}
}

@article{hertling2021MatchingWithTransformers,
	file = {References/pdf/hertling2021MatchingWithTransformers.pdf},
	title = {Matching with {Transformers} in {MELT}},
	volume = {3063},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122652126&partnerID=40&md5=9cc2e930a5549028dc272c54d43b20a6},
	abstract = {One of the strongest signals for automated matching of on- tologies and knowledge graphs are the textual descriptions of the con- cepts. The methods that are typically applied (such as character- or token-based comparisons) are relatively simple, and therefore do not cap- ture the actual meaning of the texts. With the rise of transformer-based language models, text comparison based on meaning (rather than lexical features) is possible. In this paper, we model the ontology matching task as classification problem and present approaches based on transformer models. We further provide an easy to use implementation in the MELT framework which is suited for ontology and knowledge graph matching. We show that a transformer-based filter helps to choose the correct cor- respondences given a high-recall alignment and already achieves a good result with simple alignment post-processing methods.3 © 2022 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Hertling, Sven and Portisch, Jan Philipp and Paulheim, Heiko},
	year = {2021},
	note = {Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Ontology, Ontology matching, Optimisations, Transformer, Matchings, Textual description, Simple++, Automated matching, Matcher optimization, Strong signal},
	pages = {13 -- 24},
	annote = {Type: Conference paper}
}

@article{hertling2023OlalaOntologyMatching,
	file = {References/pdf/hertling2023OlalaOntologyMatching.pdf},
	series = {K-{CAP} '23},
	title = {{OLaLa}: {Ontology} {Matching} with {Large} {Language} {Models}},
	url = {https://doi.org/10.1145/3587259.3627571},
	doi = {10.1145/3587259.3627571},
	abstract = {Ontology (and more generally: Knowledge Graph) Matching is a challenging task where information in natural language is one of the most important signals to process. With the rise of Large Language Models, it is possible to incorporate this knowledge in a better way into the matching pipeline. A number of decisions still need to be taken, e.g., how to generate a prompt that is useful to the model, how information in the KG can be formulated in prompts, which Large Language Model to choose, how to provide existing correspondences to the model, how to generate candidates, etc. In this paper, we present a prototype that explores these questions by applying zero-shot and few-shot prompting with multiple open Large Language Models to different tasks of the Ontology Alignment Evaluation Initiative (OAEI). We show that with only a handful of examples and a well-designed prompt, it is possible to achieve results that are en par with supervised matching systems which use a much larger portion of the ground truth.},
	journal = {Proceedings of the 12th Knowledge Capture Conference 2023},
	author = {Hertling, Sven and Paulheim, Heiko},
	year = {2023},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery
Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Large language model, Ontology, Language model, Ontology matching, Ontology alignment, Large Language Model, Ontology Matching, Entity Resolution, Computational linguistics, Zero-shot learning, Natural languages, Ontology's, Matchings, Graph matchings, Entity resolutions},
	pages = {131--139},
	annote = {event-place: Pensacola, FL, USA}
}

@article{hertling2023OlalaResultsOaei,
	file = {References/pdf/hertling2023OlalaResultsOaei.pdf},
	title = {{OLaLa} {Results} for {OAEI} 2023},
	volume = {3591},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180814848&partnerID=40&md5=b8d5fac66dc9350abb833bd534428cf1},
	abstract = {This paper presents the results of the OLaLa matching system participating in the OAEI 2023. The system is based on sentence-transformers as well as large language models. The former is used to generate correspondence candidates which is independent of any overlapping tokens because the comparison is only based on embeddings. To finally select the best mappings, a large language model is used to decide if two given textual representations of the source and target concept are equal or not. Based on positive and negative words that the LLM predicts, a confidence is extracted. Still, there are a lot of decisions that heavily influence the final result like (1) how can each concept be verbalized into text, (2) which prompt to use, and (3) which language model to choose. A lot of combinations were executed and the most useful one is submitted and packaged as a matching system. © 2024 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Hertling, Sven and Paulheim, Heiko},
	year = {2023},
	note = {Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Large language model, Ontology, Language model, Ontology matching, Embeddings, Computational linguistics, Matching system, Target concept, Textual representation},
	pages = {170 -- 177},
	annote = {Type: Conference paper}
}

@article{hertling2025OaeiMachineLearning,
	file = {References/pdf/hertling2025OaeiMachineLearning.pdf},
	title = {{OAEI} {Machine} {Learning} {Dataset} for {Online} {Model} {Generation}},
	volume = {15344},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218459910&doi=10.1007%2F978-3-031-78952-6_34&partnerID=40&md5=5b80c994decba989f88eb8b7ad8fedd2},
	doi = {10.1007/978-3-031-78952-6_34},
	abstract = {Ontology and knowledge graph matching systems are evaluated annually by the Ontology Alignment Evaluation Initiative (OAEI). More and more systems use machine learning-based approaches, including large language models. The training and validation datasets are usually determined by the system developer and often a subset of the reference alignments are used. This sampling is against the OAEI rules and makes a fair comparison impossible. Furthermore, those models are trained offline (a trained and optimized model is packaged into the matcher) and therefore the systems are specifically trained for those tasks. In this paper, we introduce a dataset that contains training, validation, and test sets for most of the OAEI tracks. Thus, online model learning (the systems must adapt to the given input alignment without human intervention) is made possible to enable a fair comparison for ML-based systems. We showcase the usefulness of the dataset by fine-tuning the confidence thresholds of popular systems. © 2025 Elsevier B.V., All rights reserved.},
	journal = {Lecture Notes in Computer Science},
	author = {Hertling, Sven and Norouzi, Ebrahim and Sack, Harald},
	year = {2025},
	note = {Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Ontology matching, Ontology alignment, Model generation, Federated learning, Adversarial machine learning, Machine-learning, Ontology graphs, Contrastive Learning, Graph matching systems, Learning dataset, On-line modelling, Online model generation, Incorrect information},
	pages = {239 -- 243},
	annote = {Type: Conference paper}
}

@article{ho2024LeveragingMultiAgent,
	title = {Leveraging {Multi}-{Agent} {Systems} and {Large} {Language} {Models} for {Diabetes} {Knowledge} {Graphs}},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218046486&doi=10.1109%2FBigData62323.2024.10825608&partnerID=40&md5=c77248afa42583f64d40767d76a92524},
	doi = {10.1109/BigData62323.2024.10825608},
	abstract = {This paper presents a novel framework for constructing a diabetes-specific knowledge graph (KG) using a streamlined multi-agent system powered by Gemini-based Large Language Models (LLMs). Leveraging insights from the 2016 National Diabetes Survey (NNDS) conducted by the National Diabetes Education Program (NDEP), the framework extracts critical variables related to diagnosis, risk perception, medical advice, and self-management practices across diverse U.S. populations. By processing data from the NNDS’s extensive 94-question survey, the methodology performs adaptive ontology mapping using APIs for six major medical standards (e.g., SNOMED CT, ICD-11), ensuring semantic interoperability. Relationships between variables are identified and structured using RDF, RDFS, and OWL standards. The integration of LLMs with ontology tools like Protégé enhances automation and scalability. Results demonstrate the framework’s effectiveness in generating contextually rich and clinically relevant knowledge graphs, providing a robust foundation for advancing healthcare informatics and personalized diabetes management.},
	journal = {2024 IEEE International Conference on Big Data (BigData)},
	author = {Ho, Duy H. and Das, Udiptaman and Ho, Regina and Lee, Yugyung},
	month = dec,
	year = {2024},
	note = {Section: 0},
	keywords = {Ontologies, Knowledge graphs, Large Language Models, Knowledge graph, Large language model, Ontology, Language model, Ontology mapping, AI, OWL, RDF, Resource description framework, Medical education, Knowledge Graph, Multi-agent systems, Diagnosis, Standards, Ontology Mapping, Multi-Agent System, Scalability, Healthcare Informatics, Surveys, Diabetes, Medical diagnostic imaging, Medical services, Diseases, Health care informatics, Multiagent systems (MASs), Specific knowledge, Education programmes, Cannot download},
	pages = {3401--3410},
	annote = {ISSN: 2573-2978}
}

@article{hofer2024TowardsSelfConfiguring,
	file = {References/pdf/hofer2024TowardsSelfConfiguring.pdf},
	title = {Towards self-configuring {Knowledge} {Graph} {Construction} {Pipelines} using {LLMs} - {A} {Case} {Study} with {RML}},
	volume = {3718},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198642897&partnerID=40&md5=371a1c9b734a0892d1b084ed8ffefc48},
	abstract = {This paper explores using large language models (LLMs) to generate RDF mapping language (RML) files in the RDF turtle format as a key step towards self-configuring RDF knowledge graph construction pipelines. Our case study involves mapping a subset of the Internet Movie Database (IMDB) in JSON format given a target Movie ontology (selection of DBpedia Ontology OWL statements). We define and compute several scores to assess both the generated mapping files and the resulting graph using a manually created reference. Our findings demonstrate the promising potential of the state-of-the-art commercial LLMs in a zero-shot scenario. © 2024 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Hofer, Marvin and Frey, Johannes and Rahm, Erhard},
	year = {2024},
	note = {Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Ontology, Language model, Semantics, Knowledge graph construction, Mapping, Resource Description Framework (RDF), Zero-shot learning, Graph construction, Pipelines, Mapping generations, Automated RDF mapping language mapping generation, Language mapping, Large language model-KG-engineering, Mapping Language, RDF mapping},
	annote = {Type: Conference paper}
}

@article{huang2024LargeLanguageModel,
	file = {References/pdf/huang2024LargeLanguageModel.pdf},
	title = {Large {Language} {Model} for {Ontology} {Learning} in {Drinking} {Water} {Distribution} {Network} {Domain}},
	volume = {3967},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105006919338&partnerID=40&md5=481aaad47de18ac4cf4a517059109b8b},
	abstract = {Currently, most ontologies are created manually, which is time-consuming and labour-intensive. Meanwhile, the advanced capabilities of Large Language Models (LLMs) have proven beneficial in various domains, significantly improving the efficiency of text processing and text generation. Therefore, this paper focuses on the use of LLMs for ontology learning. It uses a manual ontology construction method as a basis to facilitate the LLMs for ontology learning. The proposed approach is based on Retrieval Augmented Generation (RAG), and passed queries to LLMs are based upon the manual ontology method - UPON Lite ontology. Two different variants of LLMs have been experimented with, and they all demonstrate the capability of ontology learning to varying degrees. This approach shows promising initial results in the direction of (semi-) automated ontology learning using LLMs and makes the ontology construction process easier for people without prior domain expertise.The final ontology was evaluated by the domain expert and ranked according to the defined criteria. Based on the evaluation results, the final ontology could be used as a base version, but it requires further fine-tuning by domain experts to ensure its accuracy and completeness. © 2025 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Huang, Yiwen and Karabulut, Erkan and Degeler, Victoria},
	year = {2024},
	note = {Section: 0},
	keywords = {Large language model, Ontology, Language model, Ontology learning, Ontology construction, Ontology's, Domain experts, Labour-intensive, Text-processing, Drinking water distribution networks, Network domains},
	annote = {Type: Conference paper}
}

@article{höltgen2025UtilizingLargeLanguage,
	file = {References/pdf/höltgen2025UtilizingLargeLanguage.pdf},
	title = {Utilizing large language models for semantic enrichment of infrastructure condition data: a comparative study of {GPT} and {Llama} models},
	volume = {4},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010910273&doi=10.1007%2Fs43503-025-00055-9&partnerID=40&md5=b3c8e5c70382506c88926aeba1af7937},
	doi = {10.1007/s43503-025-00055-9},
	abstract = {Relational databases containing construction-related data are widely used in the Architecture, Engineering, and Construction (AEC) industry to manage diverse datasets, including project management and building-specific information. This study explores the use of large language models (LLMs) to convert construction data from relational databases into formal semantic representations, such as the resource description framework (RDF). Transforming this data into RDF-encoded knowledge graphs enhances interoperability and enables advanced querying capabilities. However, existing methods like R2RML and Direct Mapping face significant challenges, including the need for domain expertise and scalability issues. LLMs, with their advanced natural language processing capabilities, offer a promising solution by automating the conversion process, reducing the reliance on expert knowledge, and semantically enriching data through appropriate ontologies. This paper evaluates the potential of four LLMs (two versions of GPT and Llama) to enhance data enrichment workflows in the construction industry and examines the limitations of applying these models to large-scale datasets. © 2025 Elsevier B.V., All rights reserved.},
	number = {1},
	journal = {AI in Civil Engineering},
	author = {Höltgen, L. and Zentgraf, Sven and Hagedorn, Philipp and König, Markus},
	year = {2025},
	note = {Section: 0},
	annote = {Type: Article}
}

@article{incitti2024LeveragingLlmsKnowledge,
	file = {References/pdf/incitti2024LeveragingLlmsKnowledge.pdf},
	title = {Leveraging {LLMs} for {Knowledge} {Engineering} from {Technical} {Manuals}: {A} {Case} {Study} in the {Medical} {Prosthesis} {Manufacturing} {Domain}},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207690564&doi=10.23919%2FFUSION59988.2024.10706469&partnerID=40&md5=a81498f29b7325e537a3070f58f46227},
	doi = {10.23919/FUSION59988.2024.10706469},
	abstract = {Ontologies are nowadays widely used to organize information across specific domains, being effective due to their hierarchical structure and the ability to explicitly represent relationships between concepts. Knowledge engineering, like compiling companies’ vast bodies of knowledge into these structures, however, still represents a time-consuming, largely manually performed process, esp. with significant amounts of knowledge often only recorded within unstructured text documents. Since the recently introduced Large Language Models (LLMs) excel on text summarization, this raises the question whether these could be exploited within dedicated knowledge fusion architectures to assist human knowledge engineers by automatically suggesting relevant classes, instances and relations extracted from textual corpora. We therefore propose a novel approach that leverages the taxonomic structure of a partially defined ontology to prompt LLMs for hierarchical knowledge organization. Unlike conventional methods that rely solely on static ontologies, our methodology dynamically generates prompts based on the ontology’s existing class taxonomy, prompting the LLM to generate responses that extract supplementary information from unstructured documents. It thus introduces the concept of using ontologies as scaffolds for guiding LLMs, in order to realize a mutual interplay between structured ontological knowledge and the soft fusion capabilities of LLMs. We evaluate our proposed algorithm on a real-world case study, performing a knowledge fusion task on heterogeneous technical documentation from a medical prosthesis manufacturer.},
	journal = {2024 27th International Conference on Information Fusion (FUSION)},
	author = {Incitti, Francesca and Salfinger, Andrea and Snidaro, Lauro and Challapalli, Sri},
	month = jul,
	year = {2024},
	note = {Section: 0},
	keywords = {Ontologies, Large Language Models, Large language model, Ontology, Ontology Population, Natural language processing, Language model, Large language models, Manufacturing, Knowledge engineering, Natural Language Processing, Taxonomies, Taxonomy, Knowledge Engineering, Organizations, Text summarization, Language processing, Documentation, Prosthetics, Manuals, Natural languages, Soft Fusion, Ontology's, Natural language processing systems, Case-studies, Scaffolds, Medical prosthesis, Scaffolds (biology), Soft fusions},
	pages = {1--8},
	annote = {Type: Conference paper}
}

@article{jaradeh2023AremotiveBridgingGap,
	file = {References/pdf/jaradeh2023AremotiveBridgingGap.pdf},
	title = {{ArEmotive} {Bridging} the {Gap}: {Automatic} {Ontology} {Augmentation} {Using} {Zero}-{Shot} {Classification} for {Fine}-{Grained} {Sentiment} {Analysis} of {Arabic} {Text}},
	volume = {11},
	issn = {2169-3536},
	doi = {10.1109/ACCESS.2023.3300737},
	abstract = {Human-computer interaction remains one of the final frontiers to conquer while held in perspective with the rapid developments and technology growth over recent years. It is an arduous task to convey the true human intent to the machine in order to generate a computerized relevant decision in a certain field. In recent years, focus has shifted to cover fields of study that relate to Sentiment Analysis (SA) to improve and ease the tasks of our daily lives. We Propose ArEmotive (Arabic Emotive), a fine-grained sentiment analysis system that is human-independent which can automatically grow its source of information allowing for more precision and a greater dataset each time it is used through ontology augmentation and classification. Our proposed architecture relies on multiple data sources running through certain pipelines to generate a central online repository utilized by any mobile system to access this info-base. This system is important because many researchers in the field of automated ontology alignment and ontology mapping achieved a semi-automated approach to map new ontologies out of old ones or to extend already existing ontologies with data from new ones. ArEmotive identifies fine-grained emotions in text based on a dynamic ontology enriched through ontology alignment, mapping and machine learning assisted classification, resulting in a structure that contributes in: a centralized dataset ever growing to fit the need of the users, a sustainable structure able to allocate new data sources without the need to modify the system, ability to generate appropriate information even with the absence of “parent” sources.},
	journal = {IEEE Access},
	author = {Jaradeh, Amer and Kurdy, Mohamad-Bassam},
	year = {2023},
	note = {Section: 0},
	keywords = {Ontologies, Sentiment analysis, Emotion recognition, Arabic NLP, Bridges, Soft sensors, Blogs, Social networking (online), Task analysis, fine-grained emotions, ontology augmentation},
	pages = {81318--81330}
}

@article{kalisz2024PromptEngineeringDomain,
	file = {References/pdf/kalisz2024PromptEngineeringDomain.pdf},
	title = {Prompt {Engineering} for {Domain}-{Oriented} {AI} {Support} {Tools}: {Ontologies}, {Mind} {Maps}, {Namespaces}, {Source} {Code} {Fragments}},
	volume = {1198},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201017640&doi=10.1007%2F978-3-031-61221-3_22&partnerID=40&md5=3dde669c6d90523827828f3386838acb},
	doi = {10.1007/978-3-031-61221-3_22},
	abstract = {Chat AI systems, recently popularised by ChatGPT, allow interactions by exchanging linear text messages. Graph-like structures introduced by Z.Hedrlín represent and transfer information better than the classical linear form. We examine the possibility of using these structures to improve communication with these AI systems. We show that it is possible to create a simple graph-like structure about a topic that better captures and transfers understanding of the AI system. © 2024 Elsevier B.V., All rights reserved.},
	journal = {Lecture Notes in Electrical Engineering},
	author = {Kalisz, Vít and Kalisz, Adam},
	year = {2024},
	note = {Section: 0},
	keywords = {ChatGPT, LLM, Graph, Trees (mathematics), Mind maps, Chat AI, Concept maps, Diagram, Free structuring, Google bard, Google+, Graph-like structures, Knowledge tree, Non linear, Non-linear form, Non-linear structuring, Orgpad, Tony buzan, WEB application, Web applications},
	pages = {447 -- 482},
	annote = {Type: Conference paper}
}

@article{karmakar2024UnstructuredDataKnowledge,
	file = {References/pdf/karmakar2024UnstructuredDataKnowledge.pdf},
	title = {From {Unstructured} {Data} to {Knowledge} {Graphs}: {An} {Application} for {Compliance} {Checking} {Problem}},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199652264&doi=10.22260%2FISARC2024%2F0112&partnerID=40&md5=6ede5ec9b90cd0b85d18aebed8162b28},
	doi = {10.22260/ISARC2024/0112},
	abstract = {The rule requirements of a building code are frequently violated to create financially viable designs. These deviations are subjected to condonation by the municipal commissioner if recognizable hardships are faced. The historical concession applications for similar cases are stored in an unstructured manner, creating a barrier to knowledge transfer. The subjective statements given by applicants are composed of logical structure, language, and embedded knowledge that requires years of experience from the domain expert to decipher. A knowledge graph (KG) representation of the problem can capture concepts and represent them visually, which is easy for novice stakeholders to understand. A Large Language Model (LLM)-based method is used in this study for ontology extraction in the form of concepts and relationships. Also, unstructured input preprocessing and entity disambiguation were performed to evaluate the applicability of KG in this domain. The performance of the proposed method was checked qualitatively in a case study from real-life project examples. The limitations and scopes for improvements were also highlighted. The outcome of this study indicates KG as a potential candidate for knowledge generation from the unstructured archival data of compliance checking. The target audience for this application can be the new architects, reviewers, and programmers working on developing the end-to-end automated compliance checking systems. Finally, applying these Artificial Intelligence (AI)-based knowledge transfer mechanisms can ignite future research on automated concession applications and approvals, laying a path to the digital transformation of the industry. © 2024 Elsevier B.V., All rights reserved.},
	journal = {Proceedings of the International Symposium on Automation and Robotics in Construction},
	author = {Karmakar, Ankan and Patel, Chintan and Delhi, Venkata Santosh Kumar},
	year = {2024},
	note = {Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Compliance checking, Knowledge management, Unstructured data, Graph representation, Code compliance checking, Knowledge transfer, Domain experts, Compliance control, Code compliance, Logical structure, Similar case},
	pages = {863 -- 871},
	annote = {Type: Conference paper}
}

@article{katyshev2023UsingTransformerModels,
	file = {References/pdf/katyshev2023UsingTransformerModels.pdf},
	series = {{SIGCSE} 2023},
	title = {Using {Transformer} {Models} for {Knowledge} {Graph} {Construction} in {Computer} {Science} {Education}},
	url = {https://doi.org/10.1145/3545947.3576365},
	doi = {10.1145/3545947.3576365},
	abstract = {The volume of information that can be used in the development of knowledge bases that can be used in education is constantly increasing. Also, this amount of data is very difficult to process and store. When designing a knowledge base to optimize the educational process, it is important to use ontologies. At the moment, the creation of an ontological knowledge model is the most promising option for storing and processing information. The article describes effective approaches for generating an ontological model using machine learning models based on the Transformer model.},
	journal = {Proceedings of the 54th ACM Technical Symposium on Computer Science Education V. 2},
	author = {Katyshev, Alexander and Anikin, Anton and Sychev, Oleg},
	year = {2023},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery
Section: 0},
	keywords = {machine learning, ontologies, semantics, transformers, neural networks, concepts, ontological graph, relations between concepts},
	pages = {1421},
	annote = {event-place: Toronto ON, Canada}
}

@article{khalov2025AutomaticMappingUpper,
	title = {Automatic {Mapping} of {Upper}-{Level} {Ontology} {Classes} ({DOLCE}) and {Domain}-{Specific} {Ontology} {ITSMO}},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105012762960&doi=10.1109%2FICAIBD64986.2025.11082040&partnerID=40&md5=03a58282e7ad85da2118c7855a3ebada},
	doi = {10.1109/ICAIBD64986.2025.11082040},
	abstract = {This paper proposes a method for extending the top-level ontology DOLCE (DOLCE-lite version, referred to as TLO) to the domain of IT services without expert involvement. The main challenge addressed is the automatic mapping of classes in conditions of a small number of objects ({\textbackslash}textless100) and the absence of annotated data. A review of existing approaches is conducted, their limitations are identified, and novel mapping methods are proposed, integrating embeddings and large language models. The suggested method achieved an 82.35\% mapping accuracy when integrating DOLCE and ITSMO ontologies. As a result, the ITO-seed ontology was developed, containing linked classes from DOLCE and ITSMO, which can be utilized in further research and in building knowledge graphs for IT Service Management (ITSM) systems.},
	journal = {2025 8th International Conference on Artificial Intelligence and Big Data (ICAIBD)},
	author = {Khalov, Andrey and Ataeva, Olga},
	month = may,
	year = {2025},
	note = {Section: 0},
	keywords = {Ontologies, Knowledge graphs, Ontology, Artificial intelligence, Large language models, GPT, BERT, Knowledge management, OWL, RDF, Resource description framework, Transformers, Prompt engineering, Information systems, prompt engineering, Reviews, mapping, clustering, Mapping, Graph neural networks, DOLCE, ITIL, owl2vec, rdf2vec, Ontology's, Birds, Clusterings, Owl2vec, Rdf2vec, Cannot download},
	pages = {795--802},
	annote = {ISSN: 2769-3554}
}

@article{khorashadizadeh2025ConstructionCanonicalizationEconomic,
	file = {References/pdf/khorashadizadeh2025ConstructionCanonicalizationEconomic.pdf},
	title = {Construction and {Canonicalization} of {Economic} {Knowledge} {Graphs} with {LLMs}},
	volume = {15459},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218928651&doi=10.1007%2F978-3-031-81221-7_23&partnerID=40&md5=94c3a938e4ac09f1e4a9b680f71629dc},
	doi = {10.1007/978-3-031-81221-7_23},
	abstract = {Ontology-based knowledge graphs, such as YAGO and Wikidata, rely on pre-defined schemas to organize and connect information. While effective, these systems are inherently domain-specific, requiring tailored ontologies that are costly, time-consuming, and demand expert knowledge to develop. To address these limitations, Open Information Extraction (OpenIE) offers a complementary approach by extracting structured information directly from unstructured text without needing a predefined schema. However, OpenIE results in a vast number of relations, often leading to redundancy and inconsistencies. To overcome this, we propose a novel approach that leverages Large Language Models (LLMs) for constructing a knowledge graph and for canonicalizing relations within it. Our method includes generating question-answer pairs from text, extracting triples from these pairs, and applying a two-step canonicalization process to ensure consistency and reduce redundancy. This paper presents our approach in detail, exploring related work, the construction of the knowledge graph, the canonicalization process, and the evaluation of our methods. © 2025 Elsevier B.V., All rights reserved.},
	journal = {Lecture Notes in Computer Science},
	author = {Khorashadizadeh, Hanieh and Mihindukulasooriya, Nandana and Ranji, Nilufar and Ezzabady, Morteza Kamaladdini and Ieng, Frédéric and Groppe, Jinghua and Benamara, Farah and Groppe, Sven Thilo},
	year = {2025},
	note = {Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Large language model, Ontology, Language model, Expert knowledge, Ontology-based, Open information extraction, Canonicalization, Ontology's, Domain specific, Economic knowledge},
	pages = {334 -- 343},
	annote = {Type: Conference paper}
}

@article{kim2025LlmAssistedOntology,
	file = {References/pdf/kim2025LlmAssistedOntology.pdf},
	title = {{LLM}-{Assisted} {Ontology} {Restriction} {Verification} {With} {Clustering}-{Based} {Description} {Generation}},
	volume = {13},
	issn = {2169-3536},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003435799&doi=10.1109%2FACCESS.2025.3562560&partnerID=40&md5=7fb7ff39e7103d7aba92020f3d6a17d9},
	doi = {10.1109/ACCESS.2025.3562560},
	abstract = {An ontology is a scheme for structuring relationships between concepts in a domain, promoting data interoperability and system integration. However, poorly designed ontologies can lead to errors and performance issues. While systems engineering has standardized evaluation guidelines (e.g., ISO/IEC), ontology engineering lacks such standards, leading to various independent evaluation methods. One frequent issue among novice developers is the misuse of ontology restrictions, particularly ‘allValuesFrom’ and ‘someValuesFrom’, which can significantly impact the correctness and reliability of ontologies. However, existing studies have not adequately addressed effective methods for detecting such errors. To address this gap, we propose a context-aware verification framework utilizing large language models to detect and correct misuse in ontology restrictions. Unlike conventional methods, our framework integrates contextual descriptions derived from ontological axioms, enabling more accurate verification. Additionally, we introduce a clustering-based description generation method that systematically organizes contextual information, further enhancing verification accuracy. Experimental evaluation conducted on diverse ontology datasets suggests that contextual integration improves verification performance. Moreover, the clustering-based description generation improves restriction misuse detection and correction compared to traditional approaches. By automating ontology restriction verification, this study contributes significantly to enhancing the reliability of ontology evaluation and provides a foundation for developing more scalable and standardized verification techniques.},
	journal = {IEEE Access},
	author = {Kim, Seungyeon and Kim, Donghyun and Hwang, Seokju and Lee, Kyong-Ho and Lee, Kyunghwa},
	year = {2025},
	note = {Section: 0},
	keywords = {Ontologies, Interoperability, Ontology, Semantics, Data interoperability, Ontology evaluation, System integration, Reliability, Software, Quality assessment, clustering, Scalability, Translation, Accuracy, text generation, Data systems, ISO Standards, IEC Standards, ontology restriction verification, Ontology's, Relationship between concepts, Ontology evaluations, Text generations, Clusterings, Ontology restriction verification, Performance issues},
	pages = {73603--73618},
	annote = {Type: Article}
}

@article{kollapally2024OntologySocialDeterminants,
	file = {References/pdf/kollapally2024OntologySocialDeterminants.pdf},
	title = {An {Ontology} for {Social} {Determinants} of {Education} ({SDoEd}) {Based} on {Human}-{AI} {Collaborative} {Approach}},
	volume = {40},
	issn = {1937-4771},
	abstract = {The use of computational ontologies is well-established in the field of Medical Informatics. The topic of Social Determinants of Health (SDoH) has also received extensive attention. Work at the intersection of ontologies and SDoH has been published. However, a standardized framework for Social Determinants of Education (SDoEd) is lacking. In this paper, we are closing the gap by introducing an SDoEd ontology for creating a precise conceptualization of the interplay between life circumstances of students and their possible educational achievements. The ontology was developed utilizing suggestions from ChatGPT-3.5-010422 and validated using peer-reviewed research articles. The first version of developed ontology was evaluated by human experts in the field of education and validated using standard ontology evaluation software. This version of the SDoEd ontology contains 231 domain concepts, 10 object properties, and 24 data properties.},
	number = {3},
	journal = {J. Comput. Sci. Coll.},
	author = {Kollapally, Navya Martin and Geller, James and Morreale, Patricia and Kwak, Daehan},
	month = oct,
	year = {2024},
	note = {Section: 0},
	pages = {191--203},
	annote = {Place: Evansville, IN, USA Publisher: Consortium for Computing Sciences in Colleges}
}

@article{kollapally2025OntologyEnrichmentUsing,
	file = {References/pdf/kollapally2025OntologyEnrichmentUsing.pdf},
	title = {Ontology enrichment using a large language model: {Applying} lexical, semantic, and knowledge network-based similarity for concept placement},
	volume = {168},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009015837&doi=10.1016%2Fj.jbi.2025.104865&partnerID=40&md5=048cd0ae96fafa94aebcf8534267778c},
	doi = {10.1016/j.jbi.2025.104865},
	abstract = {Objective: Ontologies are essential for representing the knowledge of a domain. To make ontologies useful, they must encompass a comprehensive domain view. To achieve ontology enrichment, there is a need to discover new concepts to be added, either because they were missed in the first place, or the state-of-the-art has advanced to develop new real-world concepts. Our goal is to develop an automatic enrichment pipeline using a seed ontology, a Large Language Model (LLM), and source of text. The pipeline is applied to the domain of Social Determinants of Health (SDoH), using PubMed as a source of concepts. In this work, the applicability and effectiveness of the enrichment pipeline is demonstrated by extending the SDoH Ontology called SOHOv1, however our methodology could be used in other domains as well. Methods: We first retrieved PubMed abstracts of candidate articles with existing SOHOv1 concepts as search terms. Next, we used GPT-4-1201 to extract semantic triples from the abstracts. We identified concepts from these triples utilizing lexical, semantic, and knowledge network-based filtering. We also compared the granularity of semantic triples extracted with our method to the triples in the SemMedDB (Semantic MEDLINE Database). The results were evaluated by human experts and standard ontology tools for checking consistency and semantic correctness. Results: We expanded SOHOv1, which contained 173 concepts and 585 axioms, including 207 logical axioms to SOHOv2, which contains 572 concepts, 1,542 axioms, including 725 logical axioms. Our methods identified more concepts than those extracted from SemMedDB for the same task. While we have shown the feasibility of our approach for an SDoH ontology, the methodology is generalizable to other ontologies with an existing seed ontology and text corpus. Conclusions: The contributions of this work are: Extracting semantic triples from PubMed abstracts using GPT-4-1201 utilizing prompt chaining; showing the superiority of triples from GPT-4-1201 over triples from SemMedDB for SDoH; using lexical and semantic similarity search techniques with knowledge network-based search to identify the concepts to be added to the ontology; confirming the quality of the new concepts with human experts. © 2025 Elsevier B.V., All rights reserved.},
	journal = {Journal of Biomedical Informatics},
	author = {Kollapally, Navya Martin and Geller, J. and Keloth, Vipina Kuttichi and He, Zhe and Xu, Julia},
	year = {2025},
	note = {Section: 0},
	keywords = {large language model, Large Language Models, Large language model, Ontology, Language model, Semantic Web, Semantics, data extraction, natural language processing, ontology, Search engines, Ontology enrichment, Semantic MEDLINE, Semantic MEDLINE database, Similarity search, Natural Language Processing, semantics, social determinants of health, safety, PubMed, Language, Data mining, Biological Ontologies, education, Knowledge organization, Knowledge based systems, knowledge, Computational linguistics, Database systems, community, ontology enrichment, built environment, depression, human, language, ontology development, Learning systems, Humans, Article, biological ontology, generative pretrained transformer, Medline, Natural language processing systems, Abstracting, academic failure, alcohol consumption, economic instability, health care access, health care disparity, high risk behavior, intermethod comparison, MEDLINE database, natural disaster, neighborhood, Ontology evaluations, Semantic MEDLINE database database, social aspect, Social determinants of healths},
	annote = {Type: Article}
}

@article{komarlu2024OntotypeOntologyGuided,
	file = {References/pdf/komarlu2024OntotypeOntologyGuided.pdf},
	series = {{KDD} '24},
	title = {{OntoType}: {Ontology}-{Guided} and {Pre}-{Trained} {Language} {Model} {Assisted} {Fine}-{Grained} {Entity} {Typing}},
	url = {https://doi.org/10.1145/3637528.3671745},
	doi = {10.1145/3637528.3671745},
	abstract = {Fine-grained entity typing (FET), which assigns entities in text with context-sensitive, fine-grained semantic types, is a basic but important task for knowledge extraction from unstructured text. FET has been studied extensively in natural language processing and typically relies on human-annotated corpora for training, which is costly and difficult to scale. Recent studies explore the utilization of pre-trained language models (PLMs) as a knowledge base to generate rich and context-aware weak supervision for FET. However, a PLM still requires direction and guidance to serve as a knowledge base as they often generate a mixture of rough and fine-grained types, or tokens unsuitable for typing. In this study, we vision that an ontology provides a semantics-rich, hierarchical structure, which will help select the best results generated by multiple PLM models and head words. Specifically, we propose a novel annotation-free, ontology-guided FET method, OntoType, which follows a type ontological structure, from coarse to fine, ensembles multiple PLM prompting results to generate a set of type candidates, and refines its type resolution, under the local context with a natural language inference model. Our experiments on the Ontonotes, FIGER, and NYT datasets using their associated ontological structures demonstrate that our method outperforms the state-of-the-art zero-shot fine-grained entity typing methods as well as a typical LLM method, ChatGPT. Our error analysis shows that refinement of the existing ontology structures will further improve fine-grained entity typing.},
	journal = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
	author = {Komarlu, Tanay and Jiang, Minhao and Wang, Xuan and Han, Jiawei},
	year = {2024},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery
Section: 0},
	keywords = {Ontology, Language model, Semantics, Modeling languages, Fine-grained entity typing, Natural language understanding, natural language understanding, fine-grained entity typing, masked language model prompting, zero-shot entity typing, Natural languages, Ontology's, Natural language processing systems, Inference engines, Economic and social effects, Fine grained, Context sensitive languages, Context-sensitive, Masked language model prompting, Ontological structures, Zero-shot entity typing},
	pages = {1407--1417},
	annote = {event-place: Barcelona, Spain}
}

@article{kommineni2024TowardsAutomationKnowledge,
	file = {References/pdf/kommineni2024TowardsAutomationKnowledge.pdf},
	title = {Towards the {Automation} of {Knowledge} {Graph} {Construction} {Using} {Large} {Language} {Models}},
	volume = {3874},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214197878&partnerID=40&md5=c4ce0ae9c8b2f8c98f2364b50cb3c716},
	abstract = {The conventional process of building Ontologies and Knowledge Graphs (KGs) heavily relies on human domain experts to define entities and relationship types, establish hierarchies, maintain relevance to the domain, fill the ABox (i.e., populate with instances), and ensure data quality (including amongst others accuracy and completeness). On the other hand, Large Language Models (LLMs) have recently gained popularity for their ability to understand and generate human-like natural language, offering promising ways to automate aspects of this process. This work explores the (semi-)automatic construction of KGs facilitated by different state-of-the-art LLMs: Mixtral 8x22B Instruct v0.1, GPT-4o, GPT-3.5, and Gemini. Our pipeline involves formulating competency questions (CQs), developing an ontology (TBox) based on these CQs, constructing KGs using the developed ontology, and evaluating the resultant KG with minimal to no involvement of human experts. We showcase the feasibility of our semi-automated pipeline by creating a KG on deep learning methodologies by exploiting scholarly publications. The answers generated via Retrieval-Augmented-Generation (RAG) were evaluated by a domain expert manually, and the KG was evaluated by matching the KG individuals to RAG-generated answers. Our findings suggest that employing LLMs could potentially reduce the human effort involved in the construction of KGs, although a human-in-the-loop approach is recommended to evaluate automatically generated KGs. © 2025 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Kommineni, Vamsi Krishna and König-Ries, Birgitta and Samuel, Sheeba},
	year = {2024},
	note = {Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Large language model, Ontology, Language model, Deep learning, Search engines, Modeling languages, Retrieval-augmented generation, Competency question, Graph construction, Domain Knowledge, Ontology's, Natural language processing systems, Ontology graphs, Domain experts, Human domain},
	pages = {19 -- 34},
	annote = {Type: Conference paper}
}

@article{kordi2025UsageChatgptIntegrating,
	file = {References/pdf/kordi2025UsageChatgptIntegrating.pdf},
	title = {On the {Usage} of {ChatGPT} for {Integrating} {CAPEC} {Attacks} into {ADVISE} {Meta} {Ontology}},
	volume = {3962},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105005835334&partnerID=40&md5=f59155512fca30b7fdaed22c4beed35f},
	abstract = {In today’s cybersecurity landscape, robust security assessment methodologies are essential for evaluating and improving systems, networks, applications, and data security. Modeling and simulation play an important role in this process by providing meaningful representations and analyses of attacks and defense strategies, particularly in systems where security breaches could have devastating consequences. The ADversary VIew Security Evaluation (ADVISE) Meta framework offers an ontology-based approach that, starting from a system’s architectural model, automatically generates detailed security models representing the attack steps that adversaries might take to achieve their goals. Manually extending the ADVISE Meta ontology with specific attack patterns is a challenging task that involves a deep understanding of the ontology, and its semantics. It also requires analyzing the attack paths to identify the necessary information in the ontology. To address this challenge we propose a methodology to facilitate the integration of attack patterns into the ADVISE Meta framework using ChatGPT. We focus on the Common Attack Pattern Enumeration and Classification (CAPEC) catalog by MITRE, a popular catalog with more than 500 attack patterns describing the common attributes and approaches used by adversaries to exploit known weaknesses in IT systems. ChatGPT is used as a support tool to interpret the descriptions of the attacks in the CAPEC catalog and systematically integrate the interpreted data into the ADVISE Meta ontology to generate the attack steps. © 2025 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Kordi, Marzieh and Mariotti, Francesco and Magrini, Roberto and Lollini, Paolo and Bondavalli, Andrea},
	year = {2025},
	note = {Section: 0},
	keywords = {ChatGPT, LLM, Cyber security, Security evaluation, Security modeling, Ontology's, Attack patterns, Common attack pattern enumeration and classification, Cyber attacks, Meta-frameworks, Meta-ontology},
	annote = {Type: Conference paper}
}

@article{kossack2021TomMatcherResults,
	file = {References/pdf/kossack2021TomMatcherResults.pdf},
	title = {{TOM} {Matcher} {Results} for {OAEI} 2021},
	volume = {3063},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85122692672&partnerID=40&md5=166ae259e2baee385eae401561937313},
	abstract = {This paper presents the matching system TOM together with its results in the Ontology Alignment Evaluation Initiative 2021 (OAEI 2021). This is the first participation of TOM in the OAEI. Very recently, transformers achieved remarkable results in the natural language processing community on a variety of tasks. The TOM match- ing system exploits a zero-shot transformer-based language model to cal- culate confidences for each instance. The matcher uses the pre-trained transformer model paraphrase-TinyBERT-L6-v2.3 © 2022 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Kossack, Daniel and Borg, Niklas and Knorr, Leon and Portisch, Jan Philipp},
	year = {2021},
	note = {Section: 0},
	keywords = {Ontology, Language model, Ontology matching, Ontology alignment, Transformer, Natural language processing systems, Matching system, Transformer modeling, Language mod- els},
	pages = {193 -- 198},
	annote = {Type: Conference paper}
}

@article{kougioumtzidou2024EndEndFramework,
	title = {An {End}-to-{End} {Framework} for {Cybersecurity} {Taxonomy} and {Ontology} {Generation} and {Updating}},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206170969&doi=10.1109%2FCSR61664.2024.10679346&partnerID=40&md5=6b9b5f05f1f9120cb0652ff6fa09d2ad},
	doi = {10.1109/CSR61664.2024.10679346},
	abstract = {Effective cyber-defense practices often require the use of structured knowledge representations, such as taxonomies and ontologies, to organise vast amounts of data and facili-tate knowledge representation and reasoning. To this end, we present an Artificial Intelligence (AI)-assisted framework for the construction and update of cybersecurity taxonomies and ontologies. The proposed framework can be divided into three main phases: Taxonomy Construction, Ontology Construction, and Taxonomy/Ontology Update, each phase consisting of both information extraction and semantic knowledge representation components. For information extraction, we employ a variety of techniques originating from Natural Language Processing (NLP), particularly Transformer Neural Networks. For constructing ontologies, we propose a conceptual ontology schema based on the STIX 2.1 standard for modeling information related to attacks, threats, and vulnerabilities, and use the Owlready2 Python library. Overall, our framework effectively builds cybersecurity taxonomies and ontologies and updates existing knowledge of both the generated and open-source taxonomies and ontologies.},
	journal = {2024 IEEE International Conference on Cyber Security and Resilience (CSR)},
	author = {Kougioumtzidou, Anna and Papoutsis, Angelos and Kavallieros, Dimitrios and Mavropoulos, Thanassis and Tsikrika, Theodora and Vrochidis, Stefanos and Kompatsiaris, Ioannis},
	month = sep,
	year = {2024},
	note = {Section: 0},
	keywords = {Ontologies, Large language model, Natural language processing, Language model, Semantics, artificial intelligence, large language models, natural language processing, ontologies, Cyber security, Knowledge representation, Semantic search, Transformers, Taxonomy, Dynamic update, cybersecurity, Vulnerability, Attack, Language processing, taxonomies, Natural languages, Smart grids, Filtering, attacks, dynamic update, vulnerabilities, Ontology's, Cyber attacks, Phishing, Cannot download},
	pages = {247--254},
	annote = {Type: Conference paper}
}

@article{langer2024CearAutomaticConstruction,
	file = {References/pdf/langer2024CearAutomaticConstruction.pdf},
	title = {{CEAR}: {Automatic} construction of a knowledge graph of chemical entities and roles from scientific literature},
	volume = {3882},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214555647&partnerID=40&md5=04edc0d3b18355b78d45472177627d17},
	journal = {CEUR Workshop Proceedings},
	author = {Langer, Stefan and Neuhaus, Fabian and Nürnberger, Andreas},
	year = {2024},
	note = {Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Large language model, Ontology, Language model, Named entity recognition, Ontology's, Automatic construction, Chemical entity, ChEBI, Formal representations, Scientific literature},
	annote = {Type: Conference paper}
}

@article{li2023DistillingSemanticConcept,
	file = {References/pdf/li2023DistillingSemanticConcept.pdf},
	series = {{SIGIR} '23},
	title = {Distilling {Semantic} {Concept} {Embeddings} from {Contrastively} {Fine}-{Tuned} {Language} {Models}},
	url = {https://doi.org/10.1145/3539618.3591667},
	doi = {10.1145/3539618.3591667},
	abstract = {Learning vectors that capture the meaning of concepts remains a fundamental challenge. Somewhat surprisingly, perhaps, pre-trained language models have thus far only enabled modest improvements to the quality of such concept embeddings. Current strategies for using language models typically represent a concept by averaging the contextualised representations of its mentions in some corpus. This is potentially sub-optimal for at least two reasons. First, contextualised word vectors have an unusual geometry, which hampers downstream tasks. Second, concept embeddings should capture the semantic properties of concepts, whereas contextualised word vectors are also affected by other factors. To address these issues, we propose two contrastive learning strategies, based on the view that whenever two sentences reveal similar properties, the corresponding contextualised vectors should also be similar. One strategy is fully unsupervised, estimating the properties which are expressed in a sentence from the neighbourhood structure of the contextualised word embeddings. The second strategy instead relies on a distant supervision signal from ConceptNet. Our experimental results show that the resulting vectors substantially outperform existing concept embeddings in predicting the semantic properties of concepts, with the ConceptNet-based strategy achieving the best results. These findings are furthermore confirmed in a clustering task and in the downstream task of ontology completion.},
	journal = {Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval},
	author = {Li, Na and Kteich, Hanane and Bouraoui, Zied and Schockaert, Steven},
	year = {2023},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery
Section: 0},
	keywords = {Language model, Semantics, language models, Embeddings, Word embedding, Contrastive learning, Computational linguistics, word embedding, ConceptNet, Commonsense knowledge, commonsense knowledge, contrastive learning, Vectors, Property, Down-stream, Word vectors, Semantic properties},
	pages = {216--226},
	annote = {event-place: Taipei, Taiwan}
}

@article{li2024LargeLanguageModel,
	title = {A {Large} {Language} {Model} {Based} {Knowledge} {Mining} {Method} for {Improving} the {Reliability} of {Fire} {Water} {Systems}},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215273182&doi=10.1109%2FSRSE63568.2024.10772514&partnerID=40&md5=0b65baf1820c442bba07118662a1fbd9},
	doi = {10.1109/SRSE63568.2024.10772514},
	abstract = {The fire water system plays a critical role in protecting both infrastructure and human lives. An essential aspect of enhancing the reliability of this system is fault diagnosis. However, the current fault diagnosis methods primarily rely on data-driven approaches, which often result in a high threshold for application due to their lack of interpretability. To tackle this challenge, this paper introduces a novel approach based on large language models for knowledge mining from textual data to extract fault information related to the fire water system, thereby enhancing the interpretability of data-driven fault diagnosis methods. The methodology followed in this paper consists of two main steps: firstly, analyzing the characteristics and principles of fire water system faults to develop a fault ontology, and secondly, creating a knowledge mining model using a large language model guided by the established fault ontology. Experimental findings indicate that the proposed model achieves an F1 score of 0.944, meeting the necessary criteria for effective knowledge mining in fire water system fault analysis. Furthermore, a comparative experiment was conducted to evaluate the performance of various encoder models, including GRU, BiGRU, LSTM, BiLSTM, and pre-trained large language model BERT. The results revealed a significant improvement in performance with the BERT encoder, showing increases in F1 scores of 22.12 \%, 2.27 \%, 17.41 \%, and 3.16 \% compared to the other models, respectively. This study provides valuable interpretative insights that can enhance the engineering applicability and reliability of data-driven fault diagnosis methods in fire water system.},
	journal = {2024 6th International Conference on System Reliability and Safety Engineering (SRSE)},
	author = {Li, Yi and Tian, Liwei and Yi, Chengyi and Li, Jingjing and Qin, Xiaodong and He, Yuxuan and Su, Huai},
	month = oct,
	year = {2024},
	note = {Section: 0},
	keywords = {large language model, Ontologies, Large language model, Language model, Large language models, Fault diagnosis, Data mining, Knowledge based systems, safety engineering, Intelligent systems, Interpretability, Knowledge mining, Water, Accuracy, Encoding, Bidirectional control, Analytical models, Reliability engineering, fire water system, knowledge mining, system reliability, Systems analysis, Data-driven fault diagnosis, Fault diagnosis method, Fire protection, Fire water system, Mine fires, System faults, System reliability, Water system, Cannot download},
	pages = {410--413},
	annote = {Type: Conference paper}
}

@article{li2024LlmDrivenOntology,
	file = {References/pdf/li2024LlmDrivenOntology.pdf},
	title = {{LLM}-{Driven} {Ontology} {Learning} to {Augment} {Student} {Performance} {Analysis} in {Higher} {Education}},
	volume = {14886},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200754108&doi=10.1007%2F978-981-97-5498-4_5&partnerID=40&md5=b38d1eef02307126f549df7cd2a0491c},
	doi = {10.1007/978-981-97-5498-4_5},
	abstract = {In educational settings, a challenge is the lack of linked and labeled data, hindering effective analysis. The integration of ontology facilitates the formulation of educational knowledge concepts, student behaviors, and their relations. Traditional ontology creation requires deep domain knowledge and significant manual effort. However, advancements in Large Language Models (LLMs) have offered a novel opportunity to automate and refine this process. In this paper, we propose an LLMs-driven educational ontology learning approach aimed to enhance student performance predictions. We leverage LLMs to process lecture slide texts to identify knowledge concepts and their interrelations, while question texts are used to associate them with the concepts they assess. This process facilitates the generation of the educational ontology that links knowledge concepts and maps to student interactions. Additionally, we deploy a dual-branch Graph Neural Network (GNN) with distance-weighted pooling to analyze both global and local graph information for student performance prediction. Our empirical results demonstrate the effectiveness of using LLMs for ontology-based enhancements in educational settings. © 2024 Elsevier B.V., All rights reserved.},
	journal = {Lecture Notes in Computer Science},
	author = {Li, Gen and Tang, Cheng and Chen, Li and Deguchi, Daisuke and Yamashita, Takayoshi and Shimada, Atsushi},
	year = {2024},
	note = {Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Large language model, Ontology, Language model, Knowledge management, Data mining, Performance prediction, Forecasting, Graph neural networks, Student performance prediction, Educational data mining, Students, Model-driven, Domain Knowledge, Ontology's, Education computing, Student performance},
	pages = {57 -- 68},
	annote = {Type: Conference paper}
}

@article{li2025AnchoredSemanticsAugmenting,
	file = {References/pdf/li2025AnchoredSemanticsAugmenting.pdf},
	title = {Anchored {Semantics}: {Augmenting} {Ontologies} via {Competency} {Questions}, {Self}-{Attention}, and {Predictive} {Graph} {Learning}},
	volume = {15906},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010817112&doi=10.1007%2F978-3-031-97635-3_23&partnerID=40&md5=a79006385e5bb752062dec2d382cd7a3},
	doi = {10.1007/978-3-031-97635-3_23},
	abstract = {We propose a framework that enriches ontologies by leveraging competency questions and distant supervision. The process begins by using an LLM to extract domain-relevant entities from the questions, followed by incremental refinement through short definitions anchored to a predefined dictionary. These entities and their hierarchies, along with associated queries, are embedded using a fine-tuned Llama3.2:1b and further processed through a self-attention mechanism to create unified representations. A directed acyclic graph models the dependencies between entities, with additional nodes derived from frequent co-occurrences in queries. A Graph Attention Network (GAT) is used for stable link prediction, discovering latent semantic relationships. These links are then labeled with specific relation types using a fine-tuned RoBERTa module. Evaluations using datasets from HPC training sessions and OpenAlex abstracts show significant improvements in link prediction and ontology enrichment over standard GAT and GraphSage baselines. © 2025 Elsevier B.V., All rights reserved.},
	journal = {Lecture Notes in Computer Science},
	author = {Li, Shengqi and Gupta, Amarnath},
	year = {2025},
	note = {Section: 0},
	keywords = {Ontology, Semantics, Link prediction, Competency question, Query processing, Distant supervision, Graph embeddings, Latent semantic analysis, Latent semantics, Undirected graphs, Attention mechanisms, Ontology's, Co-occurrence, Directed acyclic graph model, Directed graphs, Ontology augmentation},
	pages = {189 -- 197},
	annote = {Type: Conference paper}
}

@article{li2025ErnieUieAdvancing,
	file = {References/pdf/li2025ErnieUieAdvancing.pdf},
	title = {{ERNIE}-{UIE}: {Advancing} information extraction in {Chinese} medical knowledge graph},
	volume = {20},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105006545313&doi=10.1371%2Fjournal.pone.0325082&partnerID=40&md5=3597a24d4c3511060023944baefbfb17},
	doi = {10.1371/journal.pone.0325082},
	abstract = {Background The field of information extraction (IE) is currently exploring more versatile and efficient methods for minimization of reliance on extensive annotated datasets and integration of knowledge across tasks and domains. Objective We aim to evaluate and refine the application of the universal IE (UIE) technology in the field of Chinese medical expertise in terms of processing accuracy and efficiency. Methods Our model integrates ontology modeling, web scraping, UIE, fine-tuning strategies, and graph databases, thereby covering knowledge modeling, extraction, and storage techniques. The Enhanced Representation through Knowledge Integration-UIE (ERNIE-UIE) model is fine-tuned and optimized using a small amount of annotated data. A medical knowledge graph is then constructed, followed by validating the graph and conducting knowledge mining on the data stored within it. Results Incorporating the characteristics of whole-course management, we implemented a comprehensive medical knowledge graph–construction model and methodology. Entities and relationships were jointly extracted using the pretrained language model, resulting in 8,525 entity data points and 9,522 triple data points. The accuracy of the knowledge graph was verified using graph algorithms. Conclusion We optimized the construction process of a Chinese medical knowledge graph with minimal annotated data by utilizing a generative extraction paradigm, validating the graph’s efficacy and achieving commendable results. This approach addresses the challenge of insufficient annotated training corpora in low-resource knowledge graph construction, thereby contributing to cost savings in the development of knowledge graphs. © 2025 Elsevier B.V., All rights reserved.},
	number = {5},
	journal = {PLOS ONE},
	author = {Li, Bei and Li, Changbiao and Sun, Jianwei and Zeng, Xu and Chen, Xiaofan and Zheng, Jing},
	year = {2025},
	note = {Section: 0},
	keywords = {ontology, medical informatics, information retrieval, knowledge graph, China, Algorithms, Data Mining, knowledge, data mining, Databases, language model, algorithm, human, mining, article, procedures, drug therapy, open access publishing, cost control, data base, Factual, factual database, Information Storage and Retrieval, Medical Informatics},
	annote = {Type: Article}
}

@article{li2025GenerativeMetaLearning,
	file = {References/pdf/li2025GenerativeMetaLearning.pdf},
	series = {{SIGIR} '25},
	title = {Generative {Meta}-{Learning} for {Zero}-{Shot} {Relation} {Triplet} {Extraction}},
	url = {https://doi.org/10.1145/3726302.3729988},
	doi = {10.1145/3726302.3729988},
	abstract = {Zero-shot Relation Triplet Extraction (ZeroRTE) aims to extract relation triplets from texts containing unseen relation types. This capability benefits various downstream information retrieval (IR) tasks. The primary challenge lies in enabling models to generalize effectively to unseen relation categories. Existing approaches typically leverage the knowledge embedded in pre-trained language models to accomplish the generalization process. However, these methods focus solely on fitting the training data during training, without specifically improving the model's generalization performance, resulting in limited generalization capability. For this reason, we explore the integration of bi-level optimization (BLO) with pre-trained language models for learning generalized knowledge directly from the training data, and propose a generative meta-learning framework which exploits the 'learning-to-learn' ability of meta-learning to boost the generalization capability of generative models.Specifically, we introduce a BLO approach that simultaneously addresses data fitting and generalization. This is achieved by constructing an upper-level loss to focus on generalization and a lower-level loss to ensure accurate data fitting. Building on this, we subsequently develop three generative meta-learning methods, each tailored to a distinct category of meta-learning. Extensive experimental results demonstrate that our framework performs well on the ZeroRTE task. Our code is available at https://github.com/leeworry/TGM-MetaLearning.},
	journal = {Proceedings of the 48th International ACM SIGIR Conference on Research and Development in Information Retrieval},
	author = {Li, Wanli and Qian, Tieyun and Song, Yi and Zhang, Zeyu and Li, Jiawei and Chen, Zhuang and Zou, Lixin},
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery
Section: 0},
	keywords = {pre-trained language model, meta-learning, zero-shot learning, relation triplet extraction},
	pages = {1371--1381},
	annote = {event-place: Padua, Italy}
}

@article{li2025IntelligentSearchTechnology,
	title = {Intelligent search technology for {Jiaodong} gold mines based on large models and {GraphRAG}},
	volume = {32},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105014886324&doi=10.13745%2Fj.esf.sf.2025.4.77&partnerID=40&md5=79ba9877bf17de141655dfdeb22a5f11},
	doi = {10.13745/j.esf.sf.2025.4.77},
	abstract = {The Jiaodong gold deposit is a major concentration area of gold resources in eastern China, characterized by complex geological information and an extensive knowledge system. Traditional information retrieval methods struggle to meet the advanced demands of semantic understanding and knowledge reasoning in mineral exploration. To enhance geological knowledge service efficiency, this study develops an intelligent question-answering system for the Jiaodong gold deposit domain based on GraphRAG (Graph-enhanced Retrieval-Augmented Generation) technology. The research utilizes academic papers from CNKI as the corpus, employs OCR and large language models (LLMs) for text parsing and semantic standardization to establish an ontological knowledge system covering core concepts such as mineralization types, ore-controlling structures, and mineral assemblages. The system uses prompt engineering-driven LLMs to automatically extract entities and relationships, constructing a structured knowledge graph integrated into Neo4j. Furthermore, by combining semantic embedding with community clustering algorithms, a knowledge indexing network enables natural language question answering, semantic query expansion, and knowledge provenance. Evaluation results demonstrate the system’s superiority over traditional RAG and general models (e.g., ChatGPT-4o) in answer accuracy, contextual precision, and knowledge interpretability, exhibiting enhanced professional adaptability and reasoning capabilities. The findings provide a novel technical pathway for intelligent information services in gold deposits and theoretical support for knowledge of graph-enhanced language models in geoscience knowledge management. © 2025 Elsevier B.V., All rights reserved.},
	number = {4},
	journal = {Earth Science Frontiers},
	author = {Li, Bowen and Wang, Yongzh and Ding, Zhengjiang and Wang, Bin and Wen, Shibo and Dong, Yuhao and Ji, Zheng},
	year = {2025},
	note = {Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Ontology, Language model, Semantic Web, Semantics, Search engines, Information retrieval, Question answering, Query processing, Knowledge organization, Question Answering, Knowledge system, Clustering algorithms, Mineral exploration, Economic geology, Gold deposits, Gold mines, Graph RAG, Intelligent search, Jiaodong, Jiaodong gold deposit, Knowledge question answering, Large language mode, Not English},
	pages = {155 -- 164},
	annote = {Type: Article}
}

@article{li2025OntoconsMethodIntelligent,
	title = {{OntoCons}: {A} {Method} for {Intelligent} {Construction} of {Domain} {Ontology} {Models} for {Large} {Language} {Models}},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105012094740&doi=10.1109%2FNNICE64954.2025.11063905&partnerID=40&md5=99fdc72416564aaccebf00ec8b2b1c76},
	doi = {10.1109/NNICE64954.2025.11063905},
	abstract = {With the development of large language models technology, its application in the field of education has been steadily expanding. However, due to limitations in understanding specialized literature in vertical fields, large language models face serious issues of “hallucination” and prior bias when responding to teachers' questions about specialized domains. To address this, this paper proposes an intelligent construction framework for ontology models based on knowledge tuple extraction, called OntoCons, which introduces entity extraction and relation extraction methods into the field of ontology model construction. OntoCons transforms the ontology model construction problem into a knowledge tuple extraction problem, enhancing the transparency and interpretability of ontology model construction methods, and introduces subgraph encoding strategies to improve the accuracy of relation extraction. This research provides a new method for the intelligent construction of ontology models in vertical fields, improving the understanding and response quality of large language models in specialized domains by combining machine learning and manual analysis.},
	journal = {2025 5th International Conference on Neural Networks, Information and Communication Engineering (NNICE)},
	author = {Li, Yi and Lu, Wenxin and Xiang, Xiuzhen},
	month = jan,
	year = {2025},
	note = {Section: 0},
	keywords = {large language model, Ontologies, Large language model, Ontology, Ontology model, Language model, Relation extraction, Large language models, Machine learning, Knowledge extraction, Knowledge engineering, ontology model, Data mining, relation extraction, Extraction, knowledge extraction, entity extraction, Accuracy, Engineering education, Transforms, Encoding, Manuals, Reliability theory, Learning systems, Domain Knowledge, Entity extractions, Teaching, Intelligent constructions, Model construction, Tuples extraction, Vertical fields, Cannot download},
	pages = {706--712},
	annote = {Type: Conference paper}
}

@article{li2025ResearchConstructionDigital,
	file = {References/pdf/li2025ResearchConstructionDigital.pdf},
	series = {{AIIIP} '24},
	title = {Research on the {Construction} of {Digital} {Knowledge} {Graphs} {Based} on {Resources} of {National} {First}-{Class} {Undergraduate} {Programs}},
	url = {https://doi.org/10.1145/3707292.3707389},
	doi = {10.1145/3707292.3707389},
	abstract = {[Purpose/Significance]: The digitalization of education is an essential path to advancing higher education. The construction of knowledge graphs is a key approach to achieving the digitalization and intelligence of education. [Method/Process]: This paper leverages the rich video resources of existing national first-class undergraduate programs and, based on the teaching orientations of different universities, independently designs customized ontologies and extraction principles. These are then integrated into the LLM knowledge graph builder to ensure the hierarchical structure of the overall course framework. The course video content is transformed into text form, and large language models (LLMS) and word segmentation tools are used for core content extraction, text cleaning, and lexical analysis. The structured text is then converted into SPO (Subject-Predicate-Object) triplets database. [Results/Conclusions]: Finally, the database is imported into the LLM knowledge graph builder, which is pre-configured with extraction rules. It will automatically generate the knowledge graph. After the text is imported into the LLM knowledge graph builder, it will be manually checked to ensure it better meets the actual needs of the students. [Innovation/Limitations]: The research team plans to apply the knowledge graph to train a specialized knowledge-based Q\&amp;A assistant. This will support students' understanding and self-assessment of knowledge points in an online learning community. Student feedback will be used to improve and enrich the knowledge graph. Compared to existing methods, this approach better aligns with the constantly evolving digital teaching resources available online, offering more comprehensive and higher-level automation.},
	journal = {Proceedings of the 2024 3rd International Conference on Artificial Intelligence and Intelligent Information Processing},
	author = {Li, Yanjun and Yang, Ruiting and Guo, Donghao and Song, Yu},
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery
Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Ontology, Ontology construction, Federated learning, Students, personalized learning, A, ontology construction, course resources, intelligent Q\&amp, Hierarchical structures, Graph-based, Ontology's, Course resource, Curricula, High educations, Intelligent Q\&A, Personalized learning, Teaching, Undergraduate projects},
	pages = {353--359},
	annote = {Type: Conference paper}
}

@article{liao2025LargeLanguageModel,
	file = {References/pdf/liao2025LargeLanguageModel.pdf},
	title = {Large language model assisted fine-grained knowledge graph construction for robotic fault diagnosis},
	volume = {65},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215555067&doi=10.1016%2Fj.aei.2025.103134&partnerID=40&md5=90b6374c947ab57f039cf5dc80239c66},
	doi = {10.1016/j.aei.2025.103134},
	abstract = {With the rapid deployment of industrial robots in manufacturing, the demand for advanced maintenance techniques to sustain operational efficiency has become crucial. Fault diagnosis Knowledge Graph (KG) is essential as it interlinks multi-source data related to industrial robot faults, capturing multi-level semantic associations among different fault events. However, the construction and application of fine-grained fault diagnosis KG face significant challenges due to the inherent complexity of nested entities in maintenance texts and the severe scarcity of annotated industrial data. In this study, we propose a Large Language Model (LLM) assisted data augmentation approach, which handles the complex nested entities in maintenance corpora and constructs a more fine-grained fault diagnosis KG. Firstly, the fine-grained ontology is constructed via LLM Assistance in Industrial Nested Named Entity Recognition (assInNNER). Then, an Industrial Nested Label Classification Template (INCT) is designed, enabling the use of nested entities in Attention-map aware keyword selection for the Industrial Nested Language Model (ANLM) data augmentation methods. ANLM can effectively improve the model's performance in nested entity extraction when corpora are scarce. Subsequently, a Confidence Filtering Mechanism (CFM) is introduced to evaluate and select the generated data for enhancement, and assInNNER is further deployed to recall the negative samples corpus again to further improve performance. Experimental studies based on multi-source corpora demonstrate that compared to existing algorithms, our method achieves an average F1 increase of 8.25 \%, 3.31 \%, and 1.96 \% in 5\%, 10 \%, and 25 \% in few-shot settings, respectively. © 2025 Elsevier B.V., All rights reserved.},
	journal = {Advanced Engineering Informatics},
	author = {Liao, Xingming and Chen, Chong and Wang, Zhuowei and Liu, Ying and Wang, Tao and Cheng, Lianglun},
	year = {2025},
	note = {Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Large language model, Language model, Named entity recognition, Semantics, Data augmentation, Industrial robots, Graph construction, Faults diagnosis, Fine grained, Multi-Sources, Rapid deployments},
	annote = {Type: Article}
}

@article{ling2024NewIncrementalPipeline,
	file = {References/pdf/ling2024NewIncrementalPipeline.pdf},
	title = {A new incremental pipeline for concept formation driven by prior knowledge: {Application} on the {AI} {Act} domain},
	volume = {246},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213329685&doi=10.1016%2Fj.procs.2024.09.618&partnerID=40&md5=de7233c04a3f407dd8694add9c7c1636},
	doi = {10.1016/j.procs.2024.09.618},
	abstract = {In the Ontology Learning research domain, despite recent advancements, the performance of current non or semi-supervised approaches for concept formation remains sub-optimal, particularly from a single, small-sized corpus for a specialized domain. In order to answer the performance drawback, this paper introduces a novel pipeline, called CO-ISSC (Core Ontology-based Incremental Semi-Supervised Clustering), for concept formation towards ontology learning. This pipeline uses a PLM (Pre-trained Language Model) and combines in an incremental manner a semi-supervised dimension reduction technique and a clustering technique, guided by core concepts as prior knowledge to align results with the ontology domain. Its incremental nature enhances prior knowledge and boosts its performance. The CO-ISSC pipeline's performance is evaluated on the recent and significant AI Act text established by the European Union, which aims to ensure the safety, transparency, and non-discrimination of AI systems. To this end, we manually built a benchmark terminology for the AI Act domain given that no reference model exists yet. The results demonstrate promising performance of the CO-ISSC pipeline, outperforming baseline non-supervised or semi-supervised approaches such as DBSCAN, similarity measure based approaches, support vector machines and ANN. © 2024 Elsevier B.V., All rights reserved.},
	journal = {Procedia Computer Science},
	author = {Ling, Hongtao and Harzallah, Mounira and Bernelin, Margo and Marinica, Claudia and Serrano-Alvarado, Patricia},
	year = {2024},
	note = {Section: 0},
	keywords = {Ontology, Ontology learning, Ontology-based, Dimension reduction, Performance, Concept formation, Incremental pipeline, Self-supervised learning, Semi-supervised learning, Adversarial machine learning, Support vector machines, Domain Knowledge, Contrastive Learning, Clusterings, AI act domain, Prior-knowledge, Semi-supervised},
	pages = {2148 -- 2157},
	annote = {Issue: C Type: Conference paper}
}

@article{lippolis2025AssessingCapabilityLarge,
	file = {References/pdf/lippolis2025AssessingCapabilityLarge.pdf},
	title = {Assessing the {Capability} of {Large} {Language} {Models} for {Domain}-{Specific} {Ontology} {Generation}},
	volume = {3977},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105008494228&partnerID=40&md5=fe96df813eee91b10e9e7d0088ce1efc},
	abstract = {Large Language Models (LLMs) have shown significant potential for ontology engineering. However, it is still unclear to what extent they are applicable to the task of domain-specific ontology generation. In this study, we explore the application of LLMs for automated ontology generation and evaluate their performance across different domains. Specifically, we investigate the generalizability of two state-of-the-art LLMsDeepSeek and o1-preview, both equipped with reasoning capabilitiesby generating ontologies from a set of competency questions (CQs) and related user stories. Our experimental setup comprises six distinct domains carried out in existing ontology engineering projects and a total of 95 curated CQs designed to test the models reasoning for ontology engineering. Our findings show that with both LLMs, the performance of the experiments is remarkably consistent across all domains, indicating that these methods are capable of generalizing ontology generation tasks irrespective of the domain. These results highlight the potential of LLM-based approaches in achieving scalable and domain-agnostic ontology construction and lay the groundwork for further research into enhancing automated reasoning and knowledge representation techniques. © 2025 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Lippolis, Anna Sofia and Saeedizade, Mohammad Javad and Keskisärkkä, Robin and Gangemi, Aldo and Blomqvist, Eva and Nuzzolese, Andrea Giovanni},
	year = {2025},
	note = {Section: 0},
	keywords = {Ontology engineering, Large language model, Ontology, Language model, Knowledge representation, Ontology generation, Performance, Domain Knowledge, Ontology's, State of the art, Domain-specific ontologies, Different domains, Two-state},
	annote = {Type: Conference paper}
}

@article{lippolis2025OntogeniaOntologyGeneration,
	file = {References/pdf/lippolis2025OntogeniaOntologyGeneration.pdf},
	title = {Ontogenia: {Ontology} {Generation} with {Metacognitive} {Prompting} in {Large} {Language} {Models}},
	volume = {15344},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218451819&doi=10.1007%2F978-3-031-78952-6_38&partnerID=40&md5=45b240331711a18cc31af840ace6c730},
	doi = {10.1007/978-3-031-78952-6_38},
	abstract = {Recent advancements in Large Language Models (LLMs) have primarily focused on enhancing task-specific performances by experimenting with prompt design. Despite the proven effectiveness of Metacognitive Prompting (MP), its application in the field of ontology generation remains an uncharted territory. This study addresses this gap by exploring this prompting technique in supporting the ontology design process, particularly with GPT-4, where this strategy has demonstrated consistent superiority over conventional and more direct prompting methods in recent research. Our methodology, named Ontogenia, employs a gold-standard dataset of ontology competency questions translated into SPARQL-OWL queries. This approach allows us to explore various types and stages of knowledge refinement using MP, while adhering to the eXtreme Design methodology, a well-established protocol in ontology design. Finally, the quality and performance of the resulting ontologies are assessed using both standard ontology quality metrics and evaluation by an ontology expert. This research aims to enrich the discussion on methods of ontology generation driven by LLMs by presenting concrete results on the use of metacognitive prompting and ontology design patterns. © 2025 Elsevier B.V., All rights reserved.},
	journal = {Lecture Notes in Computer Science},
	author = {Lippolis, Anna Sofia and Ceriani, Miguel and Zuppiroli, Sara and Nuzzolese, Andrea Giovanni},
	year = {2025},
	note = {Section: 0},
	keywords = {Ontology engineering, Large language model, Ontology, Language model, Ontology design, Modeling languages, Competency question, Ontology generation, Performance, Ontology's, Metacognitive prompting, Metacognitives, Incorrect information},
	pages = {259 -- 265},
	annote = {Type: Conference paper}
}

@article{liu2021SelfAlignmentPretraining,
	file = {References/pdf/liu2021SelfAlignmentPretraining.pdf},
	title = {Self-{Alignment} {Pretraining} for {Biomedical} {Entity} {Representations}},
	url = {https://aclanthology.org/2021.naacl-main.334/},
	doi = {10.18653/v1/2021.naacl-main.334},
	abstract = {Despite the widespread success of self-supervised learning via masked language models (MLM), accurately capturing fine-grained semantic relationships in the biomedical domain remains a challenge. This is of paramount importance for entity-level tasks such as entity linking where the ability to model entity relations (especially synonymy) is pivotal. To address this challenge, we propose SapBERT, a pretraining scheme that self-aligns the representation space of biomedical entities. We design a scalable metric learning framework that can leverage UMLS, a massive collection of biomedical ontologies with 4M+ concepts. In contrast with previous pipeline-based hybrid systems, SapBERT offers an elegant one-model-for-all solution to the problem of medical entity linking (MEL), achieving a new state-of-the-art (SOTA) on six MEL benchmarking datasets. In the scientific domain, we achieve SOTA even without task-specific supervision. With substantial improvement over various domain-specific pretrained MLMs such as BioBERT, SciBERTand and PubMedBERT, our pretraining scheme proves to be both effective and robust.},
	journal = {Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies},
	author = {Liu, Fangyu and Shareghi, Ehsan and Meng, Zaiqiao and Basaldella, Marco and Collier, Nigel},
	editor = {Toutanova, Kristina and Rumshisky, Anna and Zettlemoyer, Luke and Hakkani-Tur, Dilek and Beltagy, Iz and Bethard, Steven and Cotterell, Ryan and Chakraborty, Tanmoy and Zhou, Yichao},
	month = jun,
	year = {2021},
	note = {Place: Online
Publisher: Association for Computational Linguistics
Section: 0},
	keywords = {Language model, Semantics, Pre-training, Semantic relationships, Computational linguistics, Biomedical domain, Fine grained, State of the art, Entity-level, Hybrid systems, Model entities, Self-align, Self-alignment},
	pages = {4228--4238},
	annote = {Type: Conference paper}
}

@article{liu2024UsingGenerativeLarge,
	file = {References/pdf/liu2024UsingGenerativeLarge.pdf},
	title = {Using {Generative} {Large} {Language} {Models} for {Hierarchical} {Relationship} {Prediction} in {Medical} {Ontologies}},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203690166&doi=10.1109%2FICHI61247.2024.00040&partnerID=40&md5=44d6691ccccf632afe6aa2f13128c9c9},
	doi = {10.1109/ICHI61247.2024.00040},
	abstract = {This study extends the exploration of ontology enrichment by evaluating the performance of various open-sourced Large Language Models (LLMs) on the task of predicting hierarchical relationships (IS-A) in medical ontologies including SNOMED CT Clinical Finding and Procedure hierarchies and the human Disease Ontology. With the previous finetuned BERT models for hierarchical relationship prediction as the baseline, we assessed eight open-source generative LLMs for the same task. We observed only three models, without finetuning, demonstrated comparable or superior performance compared to the baseline BERT -based models. The best performance model OpenChat achieved a macro average F1 score of 0.96 (0.95) on SNOMED CT Clinical Finding (Procedure) hierarchy, an increase over 7\% from the baseline 0.89 (0.85). On human Disease Ontology, OpenChat excels with an F1 score of 0.91, outperforming the second-best performance model Vicuna (0.84). Notably, some LLMs prove unsuitable for hierarchical relationship prediction tasks or appliable for concept placement of medical ontologies. We also explored various prompt templates and ensemble techniques to uncover potential confounding factors in applying LLMs for IS-A relation predictions for medical ontologies.},
	journal = {2024 IEEE 12th International Conference on Healthcare Informatics (ICHI)},
	author = {Liu, Hao and Zhou, Shuxin and Chen, Zhehuan and Perl, Yehoshua and Wang, Jiayin},
	month = jun,
	year = {2024},
	note = {Section: 0},
	keywords = {Ontologies, Large Language Models, Large language model, Language model, Large language models, Medical ontology, Human disease, SNOMED CT, Informatics, Medical Ontology, Performance, SNOMED-CT, Accuracy, Predictive models, Medical services, Task analysis, Hieratical Relation Prediction, Prompts Design, Prediction models, Generative adversarial networks, Hieratical relation prediction, Performance Modeling, Prompt design},
	pages = {248--256},
	annote = {ISSN: 2575-2634}
}

@article{liu2025LargeLanguageModel,
	file = {References/pdf/liu2025LargeLanguageModel.pdf},
	title = {Large language model enabled knowledge discovery of building-level electrification using permit data},
	volume = {343},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105006876397&doi=10.1016%2Fj.enbuild.2025.115890&partnerID=40&md5=55641cdb377f6fc74df931c0aa1a20c3},
	doi = {10.1016/j.enbuild.2025.115890},
	abstract = {Wide scale electrification is essential for decarbonization of the building sector, yet there is a significant knowledge gap regarding the specific locations, timelines, and types of electrification technologies that are being deployed. To address this gap, we developed an information framework powered by large language models (LLMs) to extract detailed electrification-related technology information from building permit text data. While U.S. building permit data is publicly available, it is often unstructured, incomplete, and highly variable. Our LLM-enabled system addresses these challenges by constructing a comprehensive building-level ontology that captures detailed attributes for six key electrification technologies: photovoltaics, electric vehicle chargers, energy storage systems, electric service panels, water heaters, and heat pumps. Our information extraction system exhibits strong performance, achieving 0.96 recall and 0.88 precision on our human-annotated test dataset. We experimentally deploy our framework on permit data in San Francisco County, California, demonstrating that it surpasses all existing public sources of electrification information in both spatiotemporal resolution and coverage. Our work provides new visibility into building electrification trends at scale, offering valuable insights for grid planners, policymakers, installers, and end-users to inform decision-making processes. © 2025 Elsevier B.V., All rights reserved.},
	journal = {Energy and Buildings},
	author = {Liu, Tony and Zanocco, Chad M. and Wang, Zhecheng and Huang, Tianyuan and Flora, June A. and Rajagopal, Ram S.},
	year = {2025},
	note = {Section: 0},
	keywords = {Large language model, Language model, Building permits, Spatiotemporal mapping, Decarbonisation, Building Information Model, Building levels, Buildings sector, Distributed Energy Resources, Knowledge gaps, Specific location},
	annote = {Type: Article}
}

@article{liu2025OntotuneOntologyDriven,
	file = {References/pdf/liu2025OntotuneOntologyDriven.pdf},
	series = {{WWW} '25},
	title = {{OntoTune}: {Ontology}-{Driven} {Self}-training for {Aligning} {Large} {Language} {Models}},
	url = {https://doi.org/10.1145/3696410.3714816},
	doi = {10.1145/3696410.3714816},
	abstract = {Existing domain-specific Large Language Models (LLMs) are typically developed by fine-tuning general-purposed LLMs with large-scale domain-specific corpora. However, training on large-scale corpora often fails to effectively organize domain knowledge of LLMs, leading to fragmented understanding. Inspired by how humans connect concepts and organize knowledge through mind maps, we aim to emulate this approach by using ontology with hierarchical conceptual knowledge to reorganize LLM's domain knowledge. From this perspective, we propose an ontology-driven self-training framework called OntoTune, which aims to align LLMs with ontology through in-context learning, enabling the generation of responses guided by the ontology. We leverage in-context learning to identify whether the LLM has acquired the specific concept's ontology knowledge, and select the entries not yet mastered by LLM as the training set to further align the LLM with ontology. Compared to existing domain LLMs based on newly collected large-scale domain-specific corpora, our OntoTune, which relies on the existing, long-term developed ontology and LLM itself, significantly reduces data maintenance costs and offers improved generalization ability. We conduct our study in the medical domain to evaluate the effectiveness of OntoTune, utilizing a standardized medical ontology, SNOMED CT as our ontology source. Experimental results demonstrate that OntoTune achieves state-of-the-art performance in both in-ontology task hypernym discovery and out-of-ontology task medical domain QA. Moreover, compared to the latest direct ontology injection method TaxoLLaMA, our OntoTune better preserves original knowledge of LLM. The code and data are available at https://github.com/zjukg/OntoTune.},
	journal = {Proceedings of the ACM on Web Conference 2025},
	author = {Liu, Zhiqiang and Gan, Chengtao and Wang, Junjie and Zhang, Yichi and Bo, Zhongpu and Sun, Mengshu and Chen, Huajun and Zhang, Wen},
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery
Section: 0},
	keywords = {large language model, Large language model, Language model, Domain knowledge, Self-training, align with ontology, self-training, Ontology's, Large-scales, Align with ontology, Domain specific, Existing domains, Scale domains},
	pages = {119--133},
	annote = {event-place: Sydney NSW, Australia}
}

@article{liu2025ResearchConstructionApplication,
	file = {References/pdf/liu2025ResearchConstructionApplication.pdf},
	title = {Research on the construction and application of problem-method-oriented academic graph empowered by {LLM}},
	volume = {28},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105012962905&doi=10.1007%2Fs10791-025-09675-2&partnerID=40&md5=a5e9b29e96ba8299450eb6d8d25e78df},
	doi = {10.1007/s10791-025-09675-2},
	abstract = {Nowadays, the volume of literature in each field is huge and is growing rapidly, which posts challenge to researchers’ literature review. In this circumstance, developing useful tool for achieving efficient literature management is of high value. Traditional literature management tools, such as tools for key word searching, paper recommendation, relation visualization, and keyword cloud drawing, are not suitable for conducting content-level literature review. To address the issues of traditional literature management tools, a novel problem and method-oriented fine-grained academic graph is proposed to facilitate the exploration of research questions, methodologies, study perspectives, and their connections hidden in massive literature. For building such graph, a new ontology dedicated for describing the features of research paper is developed, an innovative multi-relation join extraction model is proposed, and a creative approach for leveraging the Large Language Models (LLM) to augment the triplet extraction results generated by supervised-learning model is developed. Experiments on widely used benchmark datasets show that the proposed multi-relation extraction model is able to achieve at least 8.01\% and 8.65\% improvement on entity identification and relation classification respectively, compared with state-of-the-art models. The visualized demonstration of the proposed graph shows that our graph is capable of accurately capturing the problem network, method network and hot topics hidden in massive literature. The Q\&A system supported by the proposed graph demonstrates that our graph is really helpful for conducting literature review. © 2025 Elsevier B.V., All rights reserved.},
	number = {1},
	journal = {Discover Computing},
	author = {Liu, Qigang and Wang, Yinfan and Mu, Lifeng and Li, Jun},
	year = {2025},
	note = {Section: 0},
	annote = {Type: Article}
}

@article{llugiqi2025ExpertsLlmsEvaluating,
	file = {References/pdf/llugiqi2025ExpertsLlmsEvaluating.pdf},
	title = {From {Experts} to {LLMs}: {Evaluating} the {Quality} of {Automatically} {Generated} {Ontologies}},
	volume = {3977},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105008498807&partnerID=40&md5=b2b9fe8261f5ee963e6e69a1cf2d3f92},
	abstract = {Ontologies play a crucial role in knowledge representation, yet their manual construction requires domain expertise and effort. While previous work has focused on using large language models (LLMs) for assessing ontology creation, fully automated ontology generation remains underexplored. As a consequence, most research relies on a limited set of well-known ontologies or knowledge graphs, which constrains the evaluation of various tasks such as link prediction and knowledge graph completion. This highlights the need for diverse ontology benchmarks with varying characteristics, such as number of concepts, hierarchy depth and so on, to effectively evaluate tasks such as link prediction and knowledge graph completion. In this work, we investigate the feasibility of generating ontologies using LLMs and evaluate whether they can produce ontologies of comparable quality to human-built ones. Given a seed set of concepts, a target number of concepts, relations, and maximum hierarchy depth, we employ three different LLMs to generate ontologies within the heart disease domain. Defining a seed set of concepts is particularly important for modeling the features of tabular datasets, enabling structured knowledge representation for downstream tasks. We systematically evaluate the generated ontologies by analyzing their structural integrity, semantic coherence, and suitability for downstream tasks. Our results show that while LLM-generated ontologies differ structurally from human-built ones, they remain comparable in semantic similarity and downstream ML performance, with LLaMA-generated ontologies proving to be the most effective. These findings highlight the potential of LLM-generated ontologies not only to support automated knowledge representation but also to enhance ontology benchmarks by introducing diverse structural characteristics, enabling more comprehensive evaluations of machine learning tasks. © 2025 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Llugiqi, Majlinda and Ekaputra, Fajar J. and Sabou, Marta},
	year = {2025},
	note = {Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Ontology, Language model, Semantics, Benchmarking, Ontology generation, Computational linguistics, Learning systems, Domain Knowledge, Ontology's, Knowledge-representation, Ontology evaluations, AS-links, Domain-specific ontologies, Down-stream, Large-language model},
	annote = {Type: Conference paper}
}

@article{lo2024EndEndOntology,
	file = {References/pdf/lo2024EndEndOntology.pdf},
	title = {End-to-{End} {Ontology} {Learning} with {Large} {Language} {Models}},
	volume = {37},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000479241&partnerID=40&md5=f517a883bd55f9054bd7e3cb20e0ebd1},
	abstract = {Ontologies are useful for automatic machine processing of domain knowledge as they represent it in a structured format. Yet, constructing ontologies requires substantial manual effort. To automate part of this process, large language models (LLMs) have been applied to solve various subtasks of ontology learning. However, this partial ontology learning does not capture the interactions between subtasks. We address this gap by introducing OLLM, a general and scalable method for building the taxonomic backbone of an ontology from scratch. Rather than focusing on subtasks, like individual relations between entities, we model entire subcomponents of the target ontology by finetuning an LLM with a custom regulariser that reduces overfitting on high-frequency concepts. We introduce a novel suite of metrics for evaluating the quality of the generated ontology by measuring its semantic and structural similarity to the ground truth. In contrast to standard syntax-based metrics, our metrics use deep learning techniques to define more robust distance measures between graphs. Both our quantitative and qualitative results on Wikipedia show that OLLM outperforms subtask composition methods, producing more semantically accurate ontologies while maintaining structural integrity. We further demonstrate that our model can be effectively adapted to new domains, like arXiv, needing only a small number of training examples. Our source code and datasets are available at https://github.com/andylolu2/ollm. © 2025 Elsevier B.V., All rights reserved.},
	journal = {Advances in Neural Information Processing Systems},
	author = {Lo, Andy and Jiang, Albert Qiaochu and Li, Wenda and Jamnik, Mateja},
	year = {2024},
	note = {Section: 0},
	annote = {Type: Conference paper}
}

@article{lopes2022LearningDomainOntologies,
	file = {References/pdf/lopes2022LearningDomainOntologies.pdf},
	title = {Learning {Domain} {Ontologies} {Based} {On} {Top}-{Level} {Ontology} {Concepts} {Using} {Language} {Models} {And} {Informal} {Definitions}},
	volume = {3346},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85150217899&partnerID=40&md5=6161d8c3f141c3af53e3a240d368bb42},
	abstract = {Ontology development is a challenging task that encompasses many time-consuming activities. One of these activities is the classification of the domain entities (concepts and instances) according to top-level concepts. This activity is usually performed manually by an ontology engineer. However, when the set of entities increases in size, associating each domain entity to the proper top-level ontological concept becomes challenging and requires a high level of expertise in both the target domain and ontology engineering. In this context, this work describes an approach for learning domain ontologies based on top-level ontology concepts using informal definitions as input. In our approach, we used informal definitions of the domain entities as text input of a language model that predicts their proper top-level concepts. Also, we present a methodology to extract datasets from existing domain ontologies to evaluate the proposed approach. Our experiments show that we have promising results in classifying domain entities into top-level ontology concepts. © 2023 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Lopes, Alcides Gonçalves and Carbonera, Joel Lúis and Abel, Mara},
	year = {2022},
	note = {Section: 0},
	keywords = {Ontology, Language model, Ontology learning, Domain ontologies, Ontology development, Ontology-based, Text classification, Deep neural networks, Computational linguistics, Text processing, Ontology's, Classification (of information), Ontology concepts, Target domain, Domain entities},
	pages = {180 -- 185},
	annote = {Type: Conference paper}
}

@article{lopes2023UsingTermsInformal,
	file = {References/pdf/lopes2023UsingTermsInformal.pdf},
	title = {Using terms and informal definitions to classify domain entities into top-level ontology concepts: {An} approach based on language models},
	volume = {265},
	issn = {0950-7051},
	url = {https://www.sciencedirect.com/science/article/pii/S0950705123001351},
	doi = {https://doi.org/10.1016/j.knosys.2023.110385},
	abstract = {The classification of domain entities into top-level ontology concepts remains an activity performed manually by an ontology engineer. Although some works focus on automating this task by applying machine-learning approaches using textual sentences as input, they require the existence of the domain entities in external knowledge resources, such as pre-trained embedding models. In this context, this work proposes an approach that combines the term representing the domain entity and its informal definition into a single text sentence without requiring external knowledge resources. Thus, we use this sentence as the input of a deep neural network that contains a language model as a layer. Also, we present a methodology used to extract two novel datasets from the OntoWordNet ontology based on Dolce-Lite and Dolce-Lite-Plus top-level ontologies. Our experiments show that by using the transformer-based language models, we achieve promising results in classifying domain entities into 82 top-level ontology concepts, with 94\% regarding micro F1-score.},
	journal = {Knowledge-Based Systems},
	author = {Lopes, Alcides and Carbonera, Joel and Schmidt, Daniela and Garcia, Luan and Rodrigues, Fabricio and Abel, Mara},
	year = {2023},
	note = {Section: 0},
	keywords = {Ontology, Language model, Ontology learning, Top-level ontology, Embeddings, Deep neural networks, Computational linguistics, Knowledge resource, Learning systems, Ontology's, External knowledge, Ontology concepts, Domain entities, Machine learning approaches, Multilayer neural networks},
	pages = {110385},
	annote = {Type: Article}
}

@article{lopes2024CrossDomainClassification,
	file = {References/pdf/lopes2024CrossDomainClassification.pdf},
	title = {Cross-{Domain} {Classification} of {Domain} {Entities} into {Top}-{Level} {Ontology} {Concepts} {Using} {BERT}: {A} {Study} {Case} on the {BFO} {Domain} {Ontologies}},
	volume = {2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193935708&doi=10.5220%2F0012557600003690&partnerID=40&md5=e2743defc57c09f037e5c2bb310f611c},
	doi = {10.5220/0012557600003690},
	abstract = {Classifying domain entities into top-level ontology concepts using informal definitions remains an active research area with several open questions. One of these questions pertains to the quality of proposed pipelines employing language models for classifying informal definitions when training and testing samples are from different knowledge domains. This can introduce challenges due to varying vocabularies across domains or the potential for an entity to belong to different top-level concepts based on its domain. In this study, we present a study case where terms and informal definitions are extracted from 81 domain ontologies organized into 12 knowledge domains. We investigate the performance of a pipeline that utilizes the BERT language model for classifying domain entities into top-level concepts within a cross-domain classification scenario. Additionally, we explore various pipeline setups for input, preprocessing, and training steps. Our optimal classifier setup employs an unbalanced training methodology, no text preprocessing, and the concatenation of terms and informal definitions as input. Furthermore, we demonstrate that BERT yields promising results in classifying domain entities into top-level concepts within a cross-domain classification scenario. © 2024 Elsevier B.V., All rights reserved.},
	journal = {International Conference on Enterprise Information Systems, ICEIS - Proceedings},
	author = {Lopes, Alcides Gonçalves and Carbonera, Joel Lúis and Santos, Nicolau O. and Rodrigues, Fabrício Henrique Henrique and Garcia, Luan Fonseca and Abel, Mara},
	year = {2024},
	note = {Section: 0},
	keywords = {Ontology, Language model, Domain ontologies, Knowledge management, Computational linguistics, Cross-domain, Pipelines, Ontology's, Ontology concepts, Domain entities, Informal definition, Top-level ontology classification, Cross-domain classification, Study case},
	pages = {141 -- 148},
	annote = {Type: Conference paper}
}

@article{lopes2024HowClassifyDomain,
	file = {References/pdf/lopes2024HowClassifyDomain.pdf},
	title = {How to classify domain entities into top-level ontology concepts using large language models: {A} study across multiple labels, resources, and languages},
	volume = {3882},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214572340&partnerID=40&md5=2a7cc600567dd009cf3ccec08907c7c4},
	abstract = {Classifying domain entities into their respective top-level ontology concepts is a complex problem that typically demands manual analysis and deep expertise in the domain of interest and ontology engineering. Using an efficient approach to classify domain entities enhances data integration, interoperability, and the semantic clarity of ontologies, which are crucial for structured knowledge representation and modeling. Based on this, our main motivation is to help an ontology engineer with an automated approach to classify domain entities into top-level ontology concepts using informal definitions of these domain entities during the ontology development process. In this context, we hypothesize that the informal definitions encapsulate semantic information crucial for associating domain entities with specific top-level ontology concepts. Our approach leverages state-of-the-art language models to explore our hypothesis across multiple languages and informal definitions from different knowledge resources. In order to evaluate our proposal, we extracted multi-label datasets from the alignment of the OntoWordNet ontology and the BabelNet semantic network, covering the entire structure of the Dolce-Lite-Plus top-level ontology from most generic to most specific concepts. These datasets contain several different textual representation approaches of domain entities, including terms, example sentences, and informal definitions. Our experiments conducted 3 study cases, investigating the effectiveness of our proposal across different textual representation approaches, languages, and knowledge resources. We demonstrate that the best results are achieved using a classification pipeline with a K-Nearest Neighbor (KNN) method to classify the embedding representation of informal definitions from the Mistral large language model. The findings underscore the potential of informal definitions in reflecting top-level ontology concepts and point towards developing automated tools that could significantly aid ontology engineers during the ontology development process. © 2025 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Lopes, Alcides Gonçalves and Carbonera, Joel Lúis and Rodrigues, Fabrício Henrique Henrique and Garcia, Luan Fonseca and Abel, Mara},
	year = {2024},
	note = {Section: 0},
	keywords = {Ontology, Language model, Ontology learning, Semantics, Knowledge representation, Ontology development, Modeling languages, Development process, Domain Knowledge, Ontology's, Classification (of information), Ontology concepts, Domain entities, Informal definition, Top-level ontology classification, Data encapsulation, Multiple languages},
	annote = {Type: Conference paper}
}

@article{lops2025LumenLeveragingLarge,
	file = {References/pdf/lops2025LumenLeveragingLarge.pdf},
	title = {{LUMEN}: {Leveraging} {Large} {Language} {Models} for {Dynamic} {Ontologies} in {Wind} {Energy} {Domain} {Analysis}},
	volume = {3990},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010754197&partnerID=40&md5=6b34e7aa673f27053a6d25ee8cd45275},
	abstract = {This study introduces LUMEN (Latent Understanding through Modeling Embeddings in Natural language), a structured approach leveraging Large Language Models (LLMs) and semantic embeddings to construct a hierarchical thesaurus for the wind energy domain. Using a domain-specific corpus generated via Sketch Engine, LUMEN applies a three-step methodology: corpus creation, semantic label identification through LLM-based analysis, and hierarchical term classification via embedding-based semantic similarity calculations. We outline our machine learning configuration, including the embedding techniques and similarity metrics employed. Results indicate that LUMEN can capture nuanced subdomains and semantic interrelations within wind energy, despite occasional misclassification issues. Future research directions include systematic benchmarking against established ontology-building tools and multilingual adaptation to broaden applicability. © 2025 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Lops, Andrea and Sassi, Serena},
	year = {2025},
	note = {Section: 0},
	keywords = {Large language model, Ontology, Terminology, Natural language processing, Language model, Artificial intelligence, Semantics, Knowledge management, Modeling languages, Embeddings, Thesauri, Information systems, Computational linguistics, Power, Latent semantic analysis, Language processing, Natural languages, Natural language processing systems, Domain analysis, Domain tree, Model embedding, Wind power, Wind power research},
	annote = {Type: Conference paper}
}

@article{ludwig2024SpeechToJobshop,
	file = {References/pdf/ludwig2024SpeechToJobshop.pdf},
	title = {{SPEECH}-{TO}-{JOBSHOP}: {AN} {ONTOLOGY}-{DRIVEN} {DIGITAL} {ASSISTANT} {FOR} {SIMULATION} {MODELING}},
	volume = {38},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195222610&partnerID=40&md5=4df1984998f2d5b0192a4f7b121cb30c},
	abstract = {This paper introduces a novel method utilizing speech-based digital assistants and large language models (LLMs) to streamline the creation of simulation models for Job Shop Scheduling Problems (JSSP). The system simplifies the process by allowing natural language interactions for ontology-based model generation. The study evaluates the performance of various LLMs in ontology-based simulation modeling by benchmarking their ability to extract and assign semantical entities and relations. We found that ChatGPT-4Turbo is able to correctly identify all model elements given in descriptions of the production scenarios we tested, while less resource-intensive and open source models like Mixtral-8x7b and Zephyr-beta perform well in a less complex scenario. The findings demonstrate the potential of integrating LLMs and natural language processing in simulation modeling, significantly enhancing efficiency and reducing the need for manual modeling. © 2024 Elsevier B.V., All rights reserved.},
	journal = {Proceedings - European Council for Modelling and Simulation, ECMS},
	author = {Ludwig, Heiner and Betker, Vincent and Schmidt, Thorsten Lars and Kuhn, Mathias},
	year = {2024},
	note = {Section: 0},
	keywords = {Large language model, Ontology, Language model, Modeling languages, Benchmarking, Computational linguistics, Job shop scheduling, Ontology's, Natural language processing systems, Digital assistants, Job shop scheduling problems, Job-shop, Job-Shop scheduling, Novel methods, Simulation model, Simulation-modelling},
	pages = {143 -- 149},
	annote = {Issue: 1 Type: Conference paper}
}

@article{lyu2023CausalKnowledgeGraph,
	file = {References/pdf/lyu2023CausalKnowledgeGraph.pdf},
	title = {Causal knowledge graph construction and evaluation for clinical decision support of diabetic nephropathy},
	volume = {139},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147538756&doi=10.1016%2Fj.jbi.2023.104298&partnerID=40&md5=c209c46ed49ec0410bc473201929091f},
	doi = {10.1016/j.jbi.2023.104298},
	abstract = {Background: Many important clinical decisions require causal knowledge (CK) to take action. Although many causal knowledge bases for medicine have been constructed, a comprehensive evaluation based on real-world data and methods for handling potential knowledge noise are still lacking. Objective: The objectives of our study are threefold: (1) propose a framework for the construction of a large-scale and high-quality causal knowledge graph (CKG); (2) design the methods for knowledge noise reduction to improve the quality of the CKG; (3) evaluate the knowledge completeness and accuracy of the CKG using real-world data. Material and methods: We extracted causal triples from three knowledge sources (SemMedDB, UpToDate and Churchill's Pocketbook of Differential Diagnosis) based on rule methods and language models, performed ontological encoding, and then designed semantic modeling between electronic health record (EHR) data and the CKG to complete knowledge instantiation. We proposed two graph pruning strategies (co-occurrence ratio and causality ratio) to reduce the potential noise introduced by SemMedDB. Finally, the evaluation was carried out by taking the diagnostic decision support (DDS) of diabetic nephropathy (DN) as a real-world case. The data originated from a Chinese hospital EHR system from October 2010 to October 2020. The knowledge completeness and accuracy of the CKG were evaluated based on three state-of-the-art embedding methods (R-GCN, MHGRN and MedPath), the annotated clinical text and the expert review, respectively. Results: This graph included 153,289 concepts and 1,719,968 causal triples. A total of 1427 inpatient data were used for evaluation. Better results were achieved by combining three knowledge sources than using only SemMedDB (three models: area under the receiver operating characteristic curve (AUC): p {\textbackslash}textless 0.01, F1: p {\textbackslash}textless 0.01), and the graph covered 93.9 \% of the causal relations between diseases and diagnostic evidence recorded in clinical text. Causal relations played a vital role in all relations related to disease progression for DDS of DN (three models: AUC: p {\textbackslash}textgreater 0.05, F1: p {\textbackslash}textgreater 0.05), and after pruning, the knowledge accuracy of the CKG was significantly improved (three models: AUC: p {\textbackslash}textless 0.01, F1: p {\textbackslash}textless 0.01; expert review: average accuracy: + 5.5 \%). Conclusions: The results demonstrated that our proposed CKG could completely and accurately capture the abstract CK under the concrete EHR data, and the pruning strategies could improve the knowledge accuracy of our CKG. The CKG has the potential to be applied to the DDS of diseases. © 2023 Elsevier B.V., All rights reserved.},
	journal = {Journal of Biomedical Informatics},
	author = {Lyu, Kewei and Tian, Yu and Shang, Yong and Zhou, Tianshu and Yang, Ziyue and Liu, Qianghua and Yao, Xi and Zhang, Ping and Chen, Jianghua and Li, Jingsong},
	year = {2023},
	note = {Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Ontology, Semantics, machine learning, natural language processing, Decision support systems, Modeling languages, differential diagnosis, semantics, Quality control, Diagnosis, Electronic health record, Language, clinical decision support system, electronic health record, sentiment analysis, knowledge, decision support system, cardiovascular disease, Clinical, Causal knowledge, Diabetic nephropathy, human, language, Decision Support Systems, Diseases, Humans, Article, controlled study, diagnostic test accuracy study, Decision supports, Electronic health, Health records, Automated, automated pattern recognition, Pattern Recognition, receiver operating characteristic, disease exacerbation, Records management, Real-world, clinical evaluation, chronic kidney failure, chronic respiratory tract disease, diabetes mellitus, Diabetes Mellitus, Diabetic Nephropathies, diabetic nephropathy, Diagnostic decisions, glomerulopathy, insulin dependent diabetes mellitus, kidney disease, mathematical phenomena, metabolic acidosis, noise reduction, non insulin dependent diabetes mellitus, Three models, thyrotropin},
	annote = {Type: Article}
}

@article{macilenti2024PromptingIsNot,
	file = {References/pdf/macilenti2024PromptingIsNot.pdf},
	title = {Prompting is not all you need {Evaluating} {GPT}-4 performance on a real-world ontology alignment use case},
	volume = {246},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213321670&doi=10.1016%2Fj.procs.2024.09.557&partnerID=40&md5=4395b728eb94e98a4e4f110b2a408f1f},
	doi = {10.1016/j.procs.2024.09.557},
	abstract = {Ontology Alignment (OA) is a complex, demanding and error-prone task, requiring the intervention of domain and Semantic Web experts. Automating the alignment process thus becomes a must-do, especially when involving large datasets, to at least produce a first input for human experts. Automated ontology alignment could benefit from the outstanding language ability of Large Language Models (LLMs), which could implicitly provide the background knowledge that has been the Achilles' heel of traditional alignment systems. However, this requires a correct evaluation of the performance of LLMs and understanding the best way to incorporate them into more specific tools. In this paper, we show that a naive prompting approach on the popular GPT-4 model could face several problems when transferred to real-world use cases. To this end, we replicated the methods of Norouzi et al. (2023), applied to the OAEI 2022 conference track, on a reference alignment between a pair of datasets (reduced versions of two popular thesauri: European Commission's EuroVoc and TESEO, from the Italian Senate of the Republic), which has never been tested in OAEI evaluation campaigns. This reference alignment has several features common to real-world use cases: it is has a larger size than those considered in the study we replicated, it is not published online and is therefore not subject to data contamination and it involves relations between concepts that are more complex than simple equivalence. The replicated methods achieved a significantly lower performance on our reference alignment than on the OAEI 2022 conference track, suggesting that size, data contamination, and semantic complexity need to be considered when using LLMs for the alignment task. © 2024 Elsevier B.V., All rights reserved.},
	journal = {Procedia Computer Science},
	author = {Macilenti, Giulio and Stellato, Armando and Fiorelli, Manuel},
	year = {2024},
	note = {Section: 0},
	keywords = {Large language model, Ontology, Language model, Semantic technologies, Semantics, Ontology alignment, Performance, Latent semantic analysis, Large datasets, Semantic-Web, Human expert, Real-world, Error prone tasks},
	pages = {1289 -- 1298},
	annote = {Issue: C Type: Conference paper}
}

@article{magnini2024ActivelyLearningOntologies,
	file = {References/pdf/magnini2024ActivelyLearningOntologies.pdf},
	title = {Actively {Learning} {Ontologies} from {LLMs}: {First} {Results} ({Extended} {Abstract})},
	volume = {3739},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202829104&partnerID=40&md5=c17031ab39e0c1d51fce6e8892f975f6},
	abstract = {In active learning a learner attempts to acquire some kind of knowledge by posing questions to a teacher. Here we consider that the teacher is a language model and study the case in which the knowledge is expressed as an ontology. To evaluate the approach, we present first results testing logical consistency and the performance of GPT and other language models when answering whether concept inclusions from existing ℰℒ ontologies are ‘true’ or ‘false’. © 2024 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Magnini, Matteo and Ozaki, Ana and Squarcialupi, Riccardo},
	year = {2024},
	note = {Section: 0},
	keywords = {Active learning, Language model, Reinforcement learning, Performance, Federated learning, Active Learning, Adversarial machine learning, Ontology's, Contrastive Learning, Extended abstracts, Teachers', Language study, Logical consistency},
	annote = {Type: Conference paper}
}

@article{mai2025DoLlmsReally,
	file = {References/pdf/mai2025DoLlmsReally.pdf},
	title = {Do {LLMs} {Really} {Adapt} to {Domains}? {An} {Ontology} {Learning} {Perspective}},
	volume = {15231},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211249904&doi=10.1007%2F978-3-031-77844-5_7&partnerID=40&md5=38704b1d84f3911bba65b157ac5f2a75},
	doi = {10.1007/978-3-031-77844-5_7},
	abstract = {Large Language Models (LLMs) have demonstrated unprecedented prowess across various natural language processing tasks in various application domains. Recent studies show that LLMs can be leveraged to perform lexical semantic tasks, such as Knowledge Base Completion (KBC) or Ontology Learning (OL). However, it has not effectively been verified whether their success is due to their ability to reason over unstructured or semi-structured data, or their effective learning of linguistic patterns and senses alone. This unresolved question is particularly crucial when dealing with domain-specific data, where the lexical senses and their meaning can completely differ from what a LLM has learned during its training stage. This paper investigates the following question: Do LLMs really adapt to domains and remain consistent in the extraction of structured knowledge, or do they only learn lexical senses instead of reasoning? To answer this question and, we devise a controlled experiment setup that uses WordNet to synthesize parallel corpora, with English and gibberish terms. We examine the differences in the outputs of LLMs for each corpus in two OL tasks: relation extraction and taxonomy discovery. Empirical results show that, while adapting to the gibberish corpora, off-the-shelf LLMs do not consistently reason over semantic relationships between concepts, and instead leverage senses and their frame. However, fine-tuning improves the performance of LLMs on lexical semantic tasks even when the domain-specific terms are arbitrary and unseen during pre-training, hinting at the applicability of pre-trained LLMs for OL. © 2024 Elsevier B.V., All rights reserved.},
	journal = {Lecture Notes in Computer Science},
	author = {Mai, Huu Tan and Chu, Cuongxuan and Paulheim, Heiko},
	year = {2025},
	note = {Section: 0},
	keywords = {Large language model, Ontology, Language model, Ontology learning, Semantics, Federated learning, Latent semantic analysis, Domain adaptation, Language processing, Adversarial machine learning, Lexical semantics, Natural languages, Domain Knowledge, Natural language processing systems, Contrastive Learning, Domain specific, Applications domains, Semantic tasks, Incorrect information},
	pages = {126 -- 143},
	annote = {Type: Conference paper}
}

@article{maldonadosifuentes2024TowardsProtoArtificial,
	file = {References/pdf/maldonadosifuentes2024TowardsProtoArtificial.pdf},
	title = {Towards a {Proto} {Artificial} {General} {Intelligence}: {The} {Role} of {Large} {Language} {Model} {Ontologies} in its {Development}},
	volume = {28},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210772833&doi=10.13053%2FCyS-28-3-5200&partnerID=40&md5=11b4e51d55ef1d1b31e9000fc6d96fbe},
	doi = {10.13053/CyS-28-3-5200},
	abstract = {Proto Artificial General Intelligence (ProtoAGI) aims to create a versatile artificial intelligence system capable of autonomously performing diverse tasks. A foundational element of ProtoAGI is the Large Language Model (LLM) ontology, which plays a crucial role in organizing and retrieving information about different LLMs, enabling the selection of the most appropriate model for specific tasks. This ontology, the first of several designed to support ProtoAGI, addresses key challenges in managing and accessing information regarding LLM capabilities, performance, and task suitability. We present the methodology for constructing this ontology, covering data extraction, enrichment, and model recommendation using a generalized LLM API. The initial version of this ontology involved processing over a million tokens, underscoring the system’s complexity and the scale of information integrated. This ontology is designed for continuous updates, ensuring that ProtoAGI remains current with the latest advancements in LLMs. The ongoing development of this ontology marks a significant step in ProtoAGI’s evolution, following an initial proof-of-concept demonstrated during the 2024 eclipse, where the feasibility of integrating such a comprehensive LLM ontology into a general-purpose AI system was shown. By making this ontology accessible to the broader AI community, we aim to accelerate further advancements in AGI research and applications. © 2024 Elsevier B.V., All rights reserved.},
	number = {3},
	journal = {Computacion y Sistemas},
	author = {Maldonado-Sifuentes, Christian Efraín and Vargas-Santiago, Mariano and Solis-Gamboa, Samuel and Sidorov, G. and Lechuga-Gutierrez, Luis and González-Andrade, Francisco and del Carmen Heras Sánchez, María},
	year = {2024},
	note = {Section: 0},
	pages = {1401 -- 1415},
	annote = {Type: Article}
}

@article{maratsi2025ProposedMethodologySub,
	file = {References/pdf/maratsi2025ProposedMethodologySub.pdf},
	title = {A {Proposed} {Methodology} for {Sub}-{Ontology} {Development} in {Comprehensive} {Scientific} {Investigation} {Methods} and {Tooling}},
	volume = {2331},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105013971365&doi=10.1007%2F978-3-031-81974-2_3&partnerID=40&md5=781fa0b9db7a6cb02c568dd99d22e7d9},
	doi = {10.1007/978-3-031-81974-2_3},
	abstract = {The role of ontologies in facilitating search capabilities within large collections of data is critical; the integration and analysis of diverse data sources becomes feasible as ontologies frame the data conceptually and provide a common understanding of terms and their relationships- the lack of ontological and conceptual support entailing the opposite effect. Along with documents and data lost in the vast-ness of available yet disparate data sources, numerous scientific papers and published research remain undiscovered due to poor linking to their respective scientific domain and investigation method(s) described in them. Within the scope of this study is to retrieve existing Wikidata method codes for 3 disciplines: psychology, neuroscience and cultural heritage, and analyse them, with the purpose of identifying gaps in the usage of hierarchical levels or codes, and examining whether they are currently capable of sufficiently describing the methodological domains in question, while also pertaining to a suitable level of specificity in or-der for the related data to be efficiently and effectively queried and retrieved. The findings revealed several issues regarding the discoverability and semantic search capabilities to retrieve scientific literature papers on research (or investigation) methods and tooling for the in-word disciplines. In this light, a proposed methodology to alleviate the current situation is drafted, introducing the utilisation of technological means, such as LLMs, to assist in identifying orphan categories of methods or tools and, by benchmarking against basic existing ontologies (e.g., FrameNet or other related Linked Open Vocabularies), to enrich the hierarchical structure of current representation practices in this regard. © 2025 Elsevier B.V., All rights reserved.},
	journal = {Communications in Computer and Information Science},
	author = {Maratsi, Maria Ioanna and Gialoussi, Nina and Alexopoulos, Charalampos and Charalabidis, Yannis K.},
	year = {2025},
	note = {Section: 0},
	keywords = {Knowledge graphs, Interoperability, Ontology, LLM, Ontology mapping, Semantic Web, Semantic interoperability, Semantics, Semantic search, Wikidata, Open Data, Linked open data, Codes (symbols), Data handling, Linked open vocabulary, LOV, Scientific method, Scientific tool, Wikidata code},
	pages = {28 -- 43},
	annote = {Type: Conference paper}
}

@article{marchenko2024TaxorankconstructNovelRank,
	file = {References/pdf/marchenko2024TaxorankconstructNovelRank.pdf},
	title = {{TaxoRankConstruct}: {A} {Novel} {Rank}-based {Iterative} {Approach} to {Taxonomy} {Construction} with {Large} {Language} {Models}},
	volume = {3933},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-86000713232&partnerID=40&md5=e01af4385899f16ca8a870408073ad18},
	abstract = {Paper presents a novel method for the construction of taxonomical classifications (concept hierarchies) for concepts using large language models. Traditional methods of taxonomy construction often focus heavily on hypernym-hyponym relationships, emphasizing hierarchical connections between concepts. However, these approaches tend to overlook the qualitative attributes of objects that form the foundation of classification. In contrast, the approach proposed in this paper is based on the premise that "the properties of objects are primary, while the types of objects are secondary."This foundational idea drives the development of TaxoRankConstruct, a novel rank-based iterative approach that leverages Large Language Models (LLMs) to construct more nuanced taxonomies. This method aims to enhance the clarity and precision of taxonomical hierarchies by systematically organizing concepts based on specific, identifiable characteristics. © 2025 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Marchenko, Oleksandr O. and Dvoichenkov, Danylo},
	year = {2024},
	note = {Section: 0},
	keywords = {Large language model, Natural language processing, Language model, Ontology learning, Taxonomies, Language processing, Human-AI collaboration, Natural languages, Contrastive Learning, Concept hierarchies, Hierarchical classification, Taxonomy construction},
	pages = {11 -- 27},
	annote = {Type: Conference paper}
}

@article{mateiu2023OntologyEngineeringWith,
	file = {References/pdf/mateiu2023OntologyEngineeringWith.pdf},
	title = {Ontology engineering with {Large} {Language} {Models}},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193849216&doi=10.1109%2FSYNASC61333.2023.00038&partnerID=40&md5=82842416ae615f60e5776b5c7fd1ef98},
	doi = {10.1109/SYNASC61333.2023.00038},
	abstract = {We tackle the task of enriching ontologies by automatically translating natural language (NL) into Description Logic (DL). Since Large Language Models (LLMs) are the best tools for translations, we fine-tuned a GPT-3 model to convert NL into OWL Functional Syntax. For fine-tuning, we designed pairs of sentences in NL and the corresponding translations. This training pairs cover various aspects from ontology engineering: instances, class subsumption, domain and range of relations, object properties relationships, disjoint classes, complements, or cardinality restrictions. The resulted axioms are used to enrich an ontology, in a human supervised manner. The developed tool is publicly provided as a Protégé plugin.},
	journal = {2023 25th International Symposium on Symbolic and Numeric Algorithms for Scientific Computing (SYNASC)},
	author = {Mateiu, Patricia and Groza, Adrian},
	month = sep,
	year = {2023},
	note = {Section: 0},
	keywords = {Ontology engineering, Large language model, Ontology, Language model, large language models, OWL, Protege, Description logic, ontology engineering, Training, Computational linguistics, fine-tuning, Natural languages, Syntactics, Task analysis, Protege plugin, Scientific computing, Ontology's, Plug-ins, Fine tuning, Translation (languages), Data description},
	pages = {226--229},
	annote = {ISSN: 2470-881X}
}

@article{maudslay2022HomonymyInformationEnglish,
	file = {References/pdf/maudslay2022HomonymyInformationEnglish.pdf},
	title = {Homonymy {Information} for {English} {WordNet}},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145881520&partnerID=40&md5=7d6804fd4c3843c66e32af494ae8f6f5},
	abstract = {A widely acknowledged shortcoming of WordNet is that it lacks a distinction between word meanings which are systematically related (polysemy), and those which are coincidental (homonymy). Several previous works have attempted to fill this gap, by inferring this information using computational methods. We revisit this task, and exploit recent advances in language modelling to synthesise homonymy annotation for Princeton WordNet. Previous approaches treat the problem using clustering methods; by contrast, our method works by linking WordNet to the Oxford English Dictionary, which contains the information we need. To perform this alignment, we pair definitions based on their proximity in an embedding space produced by a Transformer model. Despite the simplicity of this approach, our best model attains an F1 of .97 on an evaluation set that we annotate. The outcome of our work is a high-quality homonymy annotation layer for Princeton WordNet, which we release. © 2023 Elsevier B.V., All rights reserved.},
	author = {Maudslay, Rowan Hall and Teufel, Simone},
	year = {2022},
	note = {Section: 0},
	keywords = {Ontology, Language model, Modeling languages, Polysemy, Embeddings, Wordnet, Word meaning, Clustering methods, Transformer modeling, Best model, Homonymy, Oxford english dictionary},
	pages = {90 -- 98},
	annote = {Type: Conference paper}
}

@article{menad2024SimhomerSiameseModels,
	file = {References/pdf/menad2024SimhomerSiameseModels.pdf},
	title = {{SiMHOMer}: {Siamese} {Models} for {Health} {Ontologies} {Merging} and {Validation} {Through} {Large} {Language} {Models}},
	volume = {14848},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202640943&doi=10.1007%2F978-3-031-64629-4_9&partnerID=40&md5=de2865e3afc8b4c91c14e156b4378612},
	doi = {10.1007/978-3-031-64629-4_9},
	abstract = {Ontologies play a key role in representing and structuring domain knowledge. In the biomedical domain, the need for this type of representation is crucial for structuring, coding, and retrieving data. However, available ontologies do not encompass all the relevant concepts and relationships. In this paper, we propose the framework SiMHOMer (Siamese Modela for Health Ontologies Merging), to semantically merge and integrate the most relevant ontologies in the healthcare domain, including diseases, symptoms, drugs, and adverse events. We propose to rely on the siamese neural models we developed and trained on biomedical data, BioSTransformers, to identify new relevant relations between different concepts and to create new semantic relations, the objective being to build a new consistent merging ontology that specialists could use as a new resource for various health-related use cases. To validate the new relations, we have leveraged existing relations in the UMLS Metathesaurus and the Semantic Network. To evaluate our findings, a large language model is also used. Our first results show promising improvements for future research. © 2024 Elsevier B.V., All rights reserved.},
	journal = {Lecture Notes in Computer Science},
	author = {Menad, Safaa and Abdeddaïm, Saïd and Soualmia, Lina F.},
	year = {2024},
	note = {Section: 0},
	keywords = {Large language model, Language model, Semantics, Electronic health record, Biomedical ontologies, Ontology merging, Domain knowledge, UMLS, Ontology's, Neural modelling, Siamese neural model, Ontology validations},
	pages = {117 -- 129},
	annote = {Type: Conference paper}
}

@article{menad2025BiostransformersHealthOntologies,
	file = {References/pdf/menad2025BiostransformersHealthOntologies.pdf},
	title = {{BioSTransformers} for {Health} {Ontologies} {Merging}},
	volume = {2454},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105005256728&doi=10.1007%2F978-3-031-87569-4_8&partnerID=40&md5=f9ad7e159e38ba7f06cc31bd6ae5256a},
	doi = {10.1007/978-3-031-87569-4_8},
	abstract = {Ontologies are fundamental for organizing and representing knowledge within a specific domain. In the biomedical domain, this type of representation is essential for structuring, coding, and retrieving data efficiently. However, existing biomedical ontologies often lack coverage of all relevant concepts and relationships in the same resource. In this paper, we describe our model for semantically merging and integrating diseases, symptoms, drugs, and adverse events into a single, unified resource. We propose leveraging BioSTransformers, our developed and trained siamese neural network models on biomedical data, to discover new relevant relationships between different biomedical concepts and create novel semantic relationships between these concepts. Our objective is to build a consistent, merged ontology that serves as a valuable resource for healthcare professionals across various health-related applications. To assess and validate the newly generated relationships, we plan to use external knowledge bases such as the UMLS Metathesaurus and the Semantic Network, alongside a large language model. Initial results are encouraging and pave the way for further research. © 2025 Elsevier B.V., All rights reserved.},
	journal = {Communications in Computer and Information Science},
	author = {Menad, Safaa and Abdeddaïm, Saïd and Soualmia, Lina F.},
	year = {2025},
	note = {Section: 0},
	keywords = {Large language model, Language model, Biomedical ontologies, Ontology merging, Adverse events, Biomedical domain, Diseases, Ontology's, Disease symptoms, Neural modelling, Siamese neural model},
	pages = {169 -- 181},
	annote = {Type: Conference paper}
}

@article{menad2025PredictingSimilaritiesBetween,
	file = {References/pdf/menad2025PredictingSimilaritiesBetween.pdf},
	title = {Predicting {Similarities} {Between} {Biomedical} {Ontologies} : {The} {UMLs} {Use}-{Case}},
	doi = {10.1109/CBMS65348.2025.00134},
	abstract = {Biomedical ontologies are crucial for organizing domain-specific knowledge, yet traditional alignment methods relying on lexical matching often fail to capture complex semantic relationships. To address this limitation, we propose a novel approach leveraging siamese neural networks and transformerbased models to enhance ontology alignment within the biomedical domain. Our method applies self-supervised contrastive learning to biomedical literature, optimizing the prediction of semantic similarities between concepts in the UMLS Metathesaurus. The results demonstrate that this approach surpasses lexical-based techniques by identifying contextual relationships and uncovering new interconnections among UMLS terminologies. This highlights the potential of our models in improving ontology alignment and enriching biomedical knowledge integration.},
	journal = {2025 IEEE 38th International Symposium on Computer-Based Medical Systems (CBMS)},
	author = {Menad, Safaa and Abdeddaïm, Saïd and Soualmia, Lina F.},
	month = jun,
	year = {2025},
	note = {Section: 0},
	keywords = {Ontologies, Ontology, Terminology, Semantics, Biomedical Ontology, Neural networks, Transformers, Vocabulary, Semantic Similarity, Unified modeling language, Contrastive learning, Alignment, UMLS Metathesaurus, Biological system modeling, Vectors, Matching, Sentence Embeddings, Siamese Neural Network},
	pages = {648--653},
	annote = {ISSN: 2372-9198}
}

@article{mijalcheva2022LearningRobustFood,
	file = {References/pdf/mijalcheva2022LearningRobustFood.pdf},
	title = {Learning {Robust} {Food} {Ontology} {Alignment}},
	doi = {10.1109/BigData55660.2022.10020417},
	abstract = {In today’s knowledge society, large number of information systems use many different individual schemes to represent data. Ontologies are a promising approach for formal knowledge representation and their number is growing rapidly. The semantic linking of these ontologies is a necessary prerequisite for establishing interoperability between the large number of services that structure the data with these ontologies. Consequently, the alignment of ontologies becomes a central issue when building a worldwide Semantic Web. There is a need to develop automatic or at least semi-automatic techniques to reduce the burden of manually creating and maintaining alignments. Ontologies are seen as a solution to data heterogeneity on the Web. However, the available ontologies are themselves a source of heterogeneity. On the Web, there are multiple ontologies that refer to the same domain, and with that comes the challenge of a given graph-based system using multiple ontologies whose taxonomy is different, but the semantics are the same. This can be overcome by aligning the ontologies or by finding the correspondence between their components.In this paper, we propose a method for indexing ontologies as a support to a solution for ontology alignment based on a neural network. In this process, for each semantic resource we combine the graph based representations from the RDF2vec model, together with the text representation from the BERT model in order to capture the semantic and structural features. This methodology is evaluated using the FoodOn and OntoFood ontologies, based on the Food Onto Map alignment dataset, which contains 155 unique and validly aligned resources. Using these limited resources, we managed to obtain accuracy of 74\% and F1 score of 75\% on the test set, which is a promising result that can be further improved in future. Furthermore, the methodology presented in this paper is both robust and ontology-agnostic. It can be applied to any ontology, regardless of the domain.},
	journal = {2022 IEEE International Conference on Big Data (Big Data)},
	author = {Mijalcheva, Viktorija and Davcheva, Ana and Gramatikov, Sasho and Jovanovik, Milos and Trajanov, Dimitar and Stojanov, Riste},
	month = dec,
	year = {2022},
	note = {Section: 0},
	keywords = {Ontologies, Natural language processing, Semantic Web, Semantics, Big Data, Neural networks, Embeddings, Taxonomy, Ontology Alignment, Training, Data linking, Data normalization, Text representation},
	pages = {4097--4104}
}

@article{molina2025RobotSituationTask,
	title = {Robot {Situation} and {Task} {Awareness} {Using} {Large} {Language} {Models} and {Ontologies}},
	doi = {10.1109/DSN-W65791.2025.00045},
	abstract = {Robot situation and task awareness requires a deep understanding of the environment, the domain knowledge, and task planning. We present a novel framework that integrates ontologies, Large Language Models (LLMs), and the Planning Domain Definition Language (PDDL) to enhance the comprehension capabilities of robotic systems. The framework employs an LLM to extract structured knowledge from natural language descriptions provided by a human user, populating an OWL ontology that captures relevant objects, properties, and relations. This populated ontology is then used to parse a PDDL Domain file and generate a corresponding PDDL Problem file to solve particular planning problems. This research contributes to the intersection of knowledge representation, natural language processing, and automated planning, providing a solution for intuitive human-robot interaction through LLMs.},
	journal = {2025 55th Annual IEEE/IFIP International Conference on Dependable Systems and Networks Workshops (DSN-W)},
	author = {Molina, Victor and Ruiz-Celada, Oriol and Suarez, Raul and Rosell, Jan and Zaplana, Isiah},
	month = jun,
	year = {2025},
	note = {Section: 0},
	keywords = {Ontologies, Large Language Models, Natural language processing, Large language models, ontologies, OWL, Planning, Human-robot interaction, Robots, Conferences, robotic manipulation, task planning, Cannot download},
	pages = {96--103},
	annote = {ISSN: 2325-6664}
}

@article{moskvoretskii2024AreLargeLanguage,
	file = {References/pdf/moskvoretskii2024AreLargeLanguage.pdf},
	title = {Are {Large} {Language} {Models} {Good} at {Lexical} {Semantics}? {A} {Case} of {Taxonomy} {Learning}},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195968824&partnerID=40&md5=62d830955a58a2e4366d6f4cd82571e1},
	abstract = {Recent studies on LLMs do not pay enousdfgh attention to linguistic and lexical semantic tasks, such as taxonomy learning. In this paper, we explore the capacities of Large Language Models featuring LLaMA-2 and Mistral for several Taxonomy-related tasks. We introduce a new methodology and algorithm for data collection via stochastic graph traversal leading to controllable data collection. Collected cases provide the ability to form nearly any type of graph operation. We test the collected dataset for learning taxonomy structure based on English WordNet and compare different input templates for fine-tuning LLMs. Moreover, we apply the fine-tuned models on such datasets on the downstream tasks achieving state-of-the-art results on the TexEval-2 dataset. © 2024 Elsevier B.V., All rights reserved.},
	author = {Moskvoretskii, Viktor and Panchenko, Alexander I. and Nikishina, Irina},
	year = {2024},
	note = {Section: 0},
	keywords = {Ontology, LLM, Language model, Semantics, Taxonomies, Wordnet, Computational linguistics, Data collection, Lexical semantics, Data acquisition, Learning systems, Semantic tasks, Taxonomy construction, Hypernym prediction, Linguistic semantics, Statistical tests, Stochastic systems, Taxonomy learning},
	pages = {1498 -- 1510},
	annote = {Type: Conference paper}
}

@article{mukanova2024LlmPoweredNatural,
	file = {References/pdf/mukanova2024LlmPoweredNatural.pdf},
	title = {{LLM}-{Powered} {Natural} {Language} {Text} {Processing} for {Ontology} {Enrichment}},
	volume = {14},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198457806&doi=10.3390%2Fapp14135860&partnerID=40&md5=4e0679495529c9ad85ba2cee224641c0},
	doi = {10.3390/app14135860},
	abstract = {This paper describes a method and technology for processing natural language texts and extracting data from the text that correspond to the semantics of an ontological model. The proposed method is distinguished by the use of a Large Language Model algorithm for text analysis. The extracted data are stored in an intermediate format, after which individuals and properties that reflect the specified semantics are programmatically created in the ontology. The proposed technology is implemented using the example of an ontological model that describes the geographical configuration and administrative–territorial division of Kazakhstan. The proposed method and technology can be applied in any subject areas for which ontological models have been developed. The results of the study can significantly improve the efficiency of using knowledge bases based on semantic networks by converting texts in natural languages into semantically linked data. © 2024 Elsevier B.V., All rights reserved.},
	number = {13},
	journal = {Applied Sciences (Switzerland)},
	author = {Mukanova, Assel S. and Milosz, Marek and Dauletkaliyeva, Assem and Nazyrova, Aizhan and Yelibayeva, Gaziza and Kuzin, Dmitrii A. and Kussepova, Lazzat T.},
	year = {2024},
	note = {Section: 0},
	annote = {Type: Article}
}

@article{noori2025LlmsInAction,
	file = {References/pdf/noori2025LlmsInAction.pdf},
	title = {{LLMs} in {Action}: {Robust} {Metrics} for {Evaluating} {Automated} {Ontology} {Annotation} {Systems}},
	volume = {16},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001031577&doi=10.3390%2Finfo16030225&partnerID=40&md5=0f97f7b802e682af93b9493065ed2e69},
	doi = {10.3390/info16030225},
	abstract = {Ontologies are critical for organizing and interpreting complex domain-specific knowledge, with applications in data integration, functional prediction, and knowledge discovery. As the manual curation of ontology annotations becomes increasingly infeasible due to the exponential growth of biomedical and genomic data, natural language processing (NLP)-based systems have emerged as scalable alternatives. Evaluating these systems requires robust semantic similarity metrics that account for hierarchical and partially correct relationships often present in ontology annotations. This study explores the integration of graph-based and language-based embeddings to enhance the performance of semantic similarity metrics. Combining embeddings generated via Node2Vec and large language models (LLMs) with traditional semantic similarity metrics, we demonstrate that hybrid approaches effectively capture both structural and semantic relationships within ontologies. Our results show that combined similarity metrics outperform individual metrics, achieving high accuracy in distinguishing child–parent pairs from random pairs. This work underscores the importance of robust semantic similarity metrics for evaluating and optimizing NLP-based ontology annotation systems. Future research should explore the real-time integration of these metrics and advanced neural architectures to further enhance scalability and accuracy, advancing ontology-driven analyses in biomedical research and beyond. © 2025 Elsevier B.V., All rights reserved.},
	number = {3},
	journal = {Information (Switzerland)},
	author = {Noori, Ali and Devkota, Pratik and Mohanty, Somya D. and Manda, Prashanti},
	year = {2025},
	note = {Section: 0},
	keywords = {Large language model, Language model, Semantics, Gene Ontology, Data integration, Gene ontology, Semantic similarity, Scalability, Graph embeddings, Data curation, Language processing, Natural languages, Ontology's, Natural language processing systems, Annotation systems, Ontology annotations, Similarity metrics},
	annote = {Type: Article}
}

@article{norouzi2023ConversationalOntologyAlignment,
	file = {References/pdf/norouzi2023ConversationalOntologyAlignment.pdf},
	title = {Conversational {Ontology} {Alignment} with {ChatGPT}},
	volume = {3591},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180754943&partnerID=40&md5=8a06be5d71f54f617249262d138c8531},
	abstract = {This study evaluates the applicability and efficiency of ChatGPT for ontology alignment using a naive approach. ChatGPT’s output is compared to the results of the Ontology Alignment Evaluation Initiative 2022 campaign using conference track ontologies. This comparison is intended to provide insights into the capabilities of a conversational large language model when used in a naive way for ontology matching and to investigate the potential advantages and disadvantages of this approach. © 2024 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Norouzi, Sanaz Saki and Mahdavinejad, Mohammad Saeid and Hitzler, Pascal Al},
	year = {2023},
	note = {Section: 0},
	keywords = {ChatGPT, Large language model, Ontology, Language model, Ontology matching, Ontology alignment, Prompt engineering, Schema matching, Computational linguistics, Ontology's, LLM behavior},
	pages = {61 -- 66},
	annote = {Type: Conference paper}
}

@article{norouzi2025ConexionConceptExtraction,
	file = {References/pdf/norouzi2025ConexionConceptExtraction.pdf},
	title = {{ConExion}: {Concept} {Extraction} with {Large} {Language} {Models}},
	volume = {3977},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105008495646&partnerID=40&md5=26d9192d1623044601ad692225d1c091},
	abstract = {In this paper, an approach for concept extraction from documents using pre-trained large language models (LLMs) is presented. Compared with conventional methods that extract keyphrases summarizing the important information discussed in a document, our approach tackles a more challenging task of extracting all present concepts related to the specific domain, not just the important ones. Through comprehensive evaluations of two widely used benchmark datasets, we demonstrate that our method improves the F{\textbackslash}textlessinf{\textbackslash}textgreater1{\textbackslash}textless/inf{\textbackslash}textgreater score compared to state-of-the-art techniques. Additionally, we explore the potential of using prompts within these models for unsupervised concept extraction. The extracted concepts are intended to support domain coverage evaluation of ontologies and facilitate ontology learning, highlighting the effectiveness of LLMs in concept extraction tasks. Our source code and datasets are publicly available at https://github.com/ISE-FIZKarlsruhe/concept\_extraction. © 2025 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Norouzi, Ebrahim and Hertling, Sven and Sack, Harald},
	year = {2025},
	note = {Section: 0},
	keywords = {Large language model, Ontology, Language model, Concept extraction, Extraction, Benchmark datasets, Comprehensive evaluation, Conventional methods, Key-phrase, Key-phrases extractions, Present keyphrase extraction, State-of-the-art techniques},
	annote = {Type: Conference paper}
}

@article{oba2021AutomaticClassificationOntology,
	file = {References/pdf/oba2021AutomaticClassificationOntology.pdf},
	title = {Automatic {Classification} for {Ontology} {Generation} by {Pretrained} {Language} {Model}},
	volume = {12798},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85112704288&doi=10.1007%2F978-3-030-79457-6_18&partnerID=40&md5=5cb2f6fa7ec2a1f6545b7a90c3c7f634},
	doi = {10.1007/978-3-030-79457-6_18},
	abstract = {In recent years, for systemizing enormous information on the Internet, ontology that organizes knowledge through a hierarchical structure of concepts has received a large amount of attention in spatiotemporal information science. However, constructing ontology manually requires a large amount of time and deep knowledge of the target field. Consequently, automating ontology generation from raw text corpus is required to meet the ontology demand. As an initial attempt of ontology generation with a neural network, a recurrent neural N = network (RNN)-based method is proposed. However, updating the architecture is possible because of the development in natural language processing (NLP). In contrast, the transfer learning of language models trained by a large unlabeled corpus such as bidirectional encoder representations from transformers (BERT) has yielded a breakthrough in NLP. Inspired by these achievements, to apply transfer learning of language models, we propose a novel workflow for ontology generation consisting of two-stage learning. This paper provides a quantitative comparison between the proposed method and the existing methods. Our result showed that our best method improved accuracy by over 12.5\%. © 2021 Elsevier B.V., All rights reserved.},
	journal = {Lecture Notes in Computer Science},
	author = {Oba, Atsushi and Paik, Incheon and Kuwana, Ayato},
	year = {2021},
	note = {Section: 0},
	keywords = {Ontology, Language model, Ontology generation, Intelligent systems, Transfer learning, Computational linguistics, Recurrent neural networks, Learning systems, Hierarchical structures, Natural language processing systems, Automatic classification, Deep knowledge, NAtural language processing, Quantitative comparison, Spatiotemporal information},
	pages = {210 -- 221},
	annote = {Type: Conference paper}
}

@article{ocker2023ExploringLargeLanguage,
	file = {References/pdf/ocker2023ExploringLargeLanguage.pdf},
	title = {Exploring {Large} {Language} {Models} as a {Source} of {Common}-{Sense} {Knowledge} for {Robots}},
	volume = {3632},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184382211&partnerID=40&md5=9fb8e419f9ec5f7722d6c3c66bf1f13b},
	abstract = {Service robots need common-sense knowledge to help humans in everyday situations as it enables them to understand the context of their actions. However, approaches that use ontologies face a challenge because common-sense knowledge is often implicit, i.e., it is obvious to humans but not explicitly stated. This paper investigates if Large Language Models (LLMs) can fill this gap. Our experiments reveal limited effectiveness in the selective extraction of contextual action knowledge, suggesting that LLMs may not be sufficient on their own. However, the large-scale extraction of general, actionable knowledge shows potential, indicating that LLMs can be a suitable tool for efficiently creating ontologies for robots. This paper shows that the technique used for knowledge extraction can be applied to populate a minimalist ontology, showcasing the potential of LLMs in synergy with formal knowledge representation. © 2024 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Ocker, Felix and Deigmoeller, Joerg and Eggert, Julian P.},
	year = {2023},
	note = {Section: 0},
	keywords = {Large language model, Ontology, Language model, Knowledge representation, Knowledge extraction, Service robots, Computational linguistics, Extraction, Commonsense knowledge, Robots, Ontology's, Large-scales, Formal knowledge representations, Selective extraction},
	annote = {Type: Conference paper}
}

@article{omar2023MeasurementChatgptPerformance,
	title = {Measurement of {ChatGPT} {Performance} in {Mapping} {Natural} {Language} {Speficaction} into an {Entity} {Relationship} {Diagram}},
	doi = {10.1109/ICSC58660.2023.10449869},
	abstract = {This paper explores the entity relationship diagram, a popular conceptual model used to depict entities, attributes, and relationships graphically. To help with this, we use ChatGPT, a sophisticated language model based on the GPT architecture, which can translate natural language text into an entity relationship diagram. The paper details the process of evaluating how well ChatGPT can perform compared to other state-of-the-art approaches for entity and relationship extraction. Our experimental findings demonstrate the strong ability of ChatGPT to translate natural language text into entity relationship diagrams, which has potential applications for knowledge graph building, data integration, and database schema design. Moreover, it can aid in automating the extraction and organization of information from unstructured text data, thereby simplifying the study of complex systems.},
	journal = {2023 IEEE 11th International Conference on Systems and Control (ICSC)},
	author = {Omar, Mussa A.},
	month = dec,
	year = {2023},
	note = {Section: 0},
	keywords = {ChatGPT, natural language processing, Machine learning, Software engineering, Chatbots, Natural languages, Adaptation models, Companies, Task analysis, entity relationship diagram, Cannot download},
	pages = {530--535},
	annote = {ISSN: 2379-0067}
}

@article{onoe2021ModelingFineGrained,
	file = {References/pdf/onoe2021ModelingFineGrained.pdf},
	title = {Modeling {Fine}-{Grained} {Entity} {Types} with {Box} {Embeddings}},
	url = {https://aclanthology.org/2021.acl-long.160/},
	doi = {10.18653/v1/2021.acl-long.160},
	abstract = {Neural entity typing models typically represent fine-grained entity types as vectors in a high-dimensional space, but such spaces are not well-suited to modeling these types' complex interdependencies. We study the ability of box embeddings, which embed concepts as d-dimensional hyperrectangles, to capture hierarchies of types even when these relationships are not defined explicitly in the ontology. Our model represents both types and entity mentions as boxes. Each mention and its context are fed into a BERT-based model to embed that mention in our box space; essentially, this model leverages typological clues present in the surface text to hypothesize a type representation for the mention. Box containment can then be used to derive both the posterior probability of a mention exhibiting a given type and the conditional probability relations between types themselves. We compare our approach with a vector-based typing model and observe state-of-the-art performance on several entity typing benchmarks. In addition to competitive typing performance, our box-based model shows better performance in prediction consistency (predicting a supertype and a subtype together) and confidence (i.e., calibration), demonstrating that the box-based model captures the latent type hierarchies better than the vector-based model does.},
	journal = {Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)},
	author = {Onoe, Yasumasa and Boratko, Michael and McCallum, Andrew and Durrett, Greg},
	editor = {Zong, Chengqing and Xia, Fei and Li, Wenjie and Navigli, Roberto},
	month = aug,
	year = {2021},
	note = {Place: Online
Publisher: Association for Computational Linguistics
Section: 0},
	pages = {2051--2064}
}

@article{onozuka2025AnalysisLlmsRdf,
	file = {References/pdf/onozuka2025AnalysisLlmsRdf.pdf},
	title = {Analysis of {LLMs} for {RDF} {Triple} {Generation}: {Semantic} and {Syntactic} {Evaluation} {Using} {WebNLG}},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009459996&doi=10.1109%2FICSC64641.2025.00025&partnerID=40&md5=a0086a1e9ef98246a60e66d2507f9e5a},
	doi = {10.1109/ICSC64641.2025.00025},
	abstract = {Using the WebNLG dataset as ground truth, we evaluate the capability of large language models (LLMs) to generate resource description framework triples from natural language input. The proposed method employs two complementary evaluation metrics: cosine similarity for assessing semantic proximity and graph edit distance for comparing structural aspects of triple sets. The analysis demonstrates that these metrics provide distinct yet complementary perspectives on semantic evaluation, enabling a comprehensive assessment of the natural language understanding capabilities of LLMs. Through this approach, we demonstrate that modern LLMs exhibit sophisticated abilities in integrated syntax and semantics processing by utilizing distributed representations where both types of information coexist within high-dimensional vector spaces. This integration suggests that understanding of language structure of LLMs transcends simple pattern recognition to achieve meaningful semantic comprehension.},
	journal = {2025 19th International Conference on Semantic Computing (ICSC)},
	author = {Onozuka, Soichi and Ohnishi, Takaaki},
	month = feb,
	year = {2025},
	note = {Section: 0},
	keywords = {Ontologies, Large language model, Ontology, Natural language processing, Language model, Large language models, Semantics, RDF, Resource description framework, Similarity, LLMs, Computational linguistics, Resource Description Framework (RDF), Latent semantic analysis, Measurement, Evaluation metrics, Ground truth, Natural languages, Syntactics, Vectors, Pattern recognition, Ontology's, Natural language processing systems, Large datasets, Vector spaces, RDF triples, Resources description frameworks},
	pages = {136--143},
	annote = {ISSN: 2472-9671}
}

@article{otsuki2025EfficientMaintenanceLarge,
	file = {References/pdf/otsuki2025EfficientMaintenanceLarge.pdf},
	title = {Efficient {Maintenance} of {Large}-{Scale} {Medical} {Dictionaries} {Using} {Large} {Language} {Models}: {A} {Case} for {Biomarkers}},
	volume = {329},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105013383391&doi=10.3233%2FSHTI250951&partnerID=40&md5=f2e9ca4306b90c3c282c72bd9b48ba1a},
	doi = {10.3233/SHTI250951},
	abstract = {Dictionaries are essential in natural language processing and provide significant value across tasks; however, their construction and maintenance are expensive. Leveraging manual revision histories to suggest automatic corrections for unedited terms offers a promising solution to enhance quality while reducing costs. This study proposes a method for automatically correcting metadata in a large-scale medical dictionary containing more than 500,000 terms. By utilizing large language models that excel in zero-shot settings, the system estimates the dictionary information without task-specific configurations. This method was demonstrated through experiments on variations in gene biomarker expression, a task that requires specialized medical knowledge. The results indicate that this approach can significantly reduce the dictionary maintenance burden. This record is sourced from MEDLINE/PubMed, a database of the U.S. National Library of Medicine},
	journal = {Studies in Health Technology and Informatics},
	author = {Otsuki, Yuka and Yada, Shuntaro and Nishiyama, Tomohiro and Sakurai, Toshiyuki and Okada, Masafumi and Kudo, Noriko and Kawabata, Kyoko and Fujimaki, Takako and Nagai, Hiroyuki and Wakamiya, Shoko},
	year = {2025},
	note = {Section: 0},
	keywords = {large language model, Large Language Models, natural language processing, Natural Language Processing, Biomarkers, human, Humans, biological marker, book, Dictionaries as Topic},
	pages = {804 -- 808},
	annote = {Type: Article}
}

@article{ourekouch2025RelcheckImprovingRelation,
	file = {References/pdf/ourekouch2025RelcheckImprovingRelation.pdf},
	title = {{RelCheck}: {Improving} {Relation} {Extraction} with {Ontology}-{Guided} and {LLM}-{Based} {Validation}},
	volume = {15718},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007980362&doi=10.1007%2F978-3-031-94575-5_24&partnerID=40&md5=e240bb1f207e7bb0f1d5f7e949973cc2},
	doi = {10.1007/978-3-031-94575-5_24},
	abstract = {Relation extraction (RE) is a key task in natural language processing (NLP) and a core component of information extraction. It focuses on identifying semantic relations between entities in text. Pretrained language models (PLMs), such as transformer-based models like BERT, XLNet and RoBERTa, have made notable progress in RE. Predictions of relations from these models are provided with varying confidence levels. While high-confidence predictions of relations are generally accurate, low-confidence predictions tend to be less precise and often lead to inaccuracies. The current research question is how to re-evaluate the low confidence predictions to ensure the overall confidence of a PLM. To solve this problem we propose a framework using automatically generated ontology schemas and LLMs. We first propose an algorithm that constructs ontology schemas from the RE datasets (TACRED and ReTACRED). Then we use LLMs to validate these low-confidence predictions through prompting to further improve the precision of final predictions. Experimental results on transformer-based models, GCN and LSTM-based models across two large-scale RE datasets (TACRED and ReTACRED) show significant improvements in precision and overall performance. © 2025 Elsevier B.V., All rights reserved.},
	journal = {Lecture Notes in Computer Science},
	author = {Ourekouch, Mounir and Koulali, Mohammed Amine and Erradi, Mohamed},
	year = {2025},
	note = {Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Large language model, Ontology, Language model, Relation extraction, Semantics, Knowledge graph construction, Ontology schema, Data mining, Forecasting, Computational linguistics, Extraction, Graph construction, Ontology's, Natural language processing systems, Large datasets, Prediction models, Confidence predictions, Model-based validation},
	pages = {441 -- 459},
	annote = {Type: Conference paper {\textbar} RAYYAN-LABELS: ontology-supported application}
}

@article{ouyang2024OntologyEnrichmentEffective,
	file = {References/pdf/ouyang2024OntologyEnrichmentEffective.pdf},
	series = {{KDD} '24},
	title = {Ontology {Enrichment} for {Effective} {Fine}-grained {Entity} {Typing}},
	url = {https://doi.org/10.1145/3637528.3671857},
	doi = {10.1145/3637528.3671857},
	abstract = {Fine-grained entity typing (FET) is the task of identifying specific entity types at a fine-grained level for entity mentions based on their contextual information. Conventional methods for FET require extensive human annotation, which is time-consuming and costly given the massive scale of data. Recent studies have been developing weakly supervised or zero-shot approaches. We study the setting of zero-shot FET where only an ontology is provided. However, most existing ontology structures lack rich supporting information and even contain ambiguous relations, making them ineffective in guiding FET. Recently developed language models, though promising in various few-shot and zero-shot NLP tasks, may face challenges in zero-shot FET due to their lack of interaction with task-specific ontology. In this study, we propose øurs, where we (1) enrich each node in the ontology structure with two categories of extra information:instance information for training sample augmentation andtopic information to relate types with contexts, and (2) develop a coarse-to-fine typing algorithm that exploits the enriched information by training an entailment model with contrasting topics and instance-based augmented training samples. Our experiments show that øurs achieves high-quality fine-grained entity typing without human annotation, outperforming existing zero-shot methods by a large margin and rivaling supervised methods. øurs also enjoys strong transferability to unseen and finer-grained types. We will open source this work upon acceptance.},
	journal = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
	author = {Ouyang, Siru and Huang, Jiaxin and Pillai, Pranav and Zhang, Yunyi and Zhang, Yu and Han, Jiawei},
	year = {2024},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery
Section: 0},
	keywords = {Ontology, Language model, Ontology enrichment, Modeling languages, language models, Fine-grained entity typing, Natural language inference, Supervised learning, Zero-shot learning, Language inference, fine-grained entity typing, natural language inference, zero-shot learning, Natural languages, Ontology's, Natural language processing systems, Inference engines, Fine grained, Human annotations, Training sample},
	pages = {2318--2327},
	annote = {event-place: Barcelona, Spain}
}

@article{pan2025RagApproachGenerating,
	file = {References/pdf/pan2025RagApproachGenerating.pdf},
	title = {A {RAG} {Approach} for {Generating} {Competency} {Questions} in {Ontology} {Engineering}},
	volume = {2331},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105013955848&doi=10.1007%2F978-3-031-81974-2_6&partnerID=40&md5=9076217b9a4a337e38d337f34bfddfc2},
	doi = {10.1007/978-3-031-81974-2_6},
	abstract = {Competency question (CQ) formulation is central to several ontology development and evaluation methodologies. Traditionally, the task of crafting these competency questions heavily relies on the effort of domain experts and knowledge engineers which is often time-consuming and labor-intensive. With the emergence of Large Language Models (LLMs), there arises the possibility to automate and enhance this process. Unlike other similar works which use existing ontologies or knowledge graphs as input to LLMs, we present a retrieval-augmented generation (RAG) approach that uses LLMs for the automatic generation of CQs given a set of scientific papers considered to be a domain knowledge base. We investigate its performance and specifically, we study the impact of different number of papers to the RAG and different temperature setting of the LLM. We conduct experiments using GPT-4 on two domain ontology engineering tasks and compare results against ground-truth CQs constructed by domain experts. Empirical assessments on the results, utilizing evaluation metrics (precision and consistency), reveal that compared to zero-shot prompting, adding relevant domain knowledge to the RAG improves the performance of LLMs on generating CQs for concrete ontology engineering tasks. © 2025 Elsevier B.V., All rights reserved.},
	journal = {Communications in Computer and Information Science},
	author = {Pan, Xueli and Ossenbruggen, Jacco Van and de Boer, Victor and Huang, Zhisheng},
	year = {2025},
	note = {Section: 0},
	keywords = {Ontology engineering, Knowledge graph, Large language model, Ontology, Language model, Ontology development, Competency question, Domain knowledge, Performance, Domain Knowledge, Ontology evaluations, Domain experts, Engineering tasks},
	pages = {70 -- 81},
	annote = {Type: Conference paper}
}

@article{peng2023OntologyMatchingUsing,
	file = {References/pdf/peng2023OntologyMatchingUsing.pdf},
	title = {Ontology {Matching} using {Textual} {Class} {Descriptions}},
	volume = {3591},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180776271&partnerID=40&md5=5115bca4fda57f89bac2412fb02a8506},
	abstract = {In this paper, we propose TEXTO, a TEXT-based Ontology matching system. This matcher leverages the rich semantic information of classes available in most ontologies by a combination of a pre-trained word embedding model and a pre-trained language model. Its performance is evaluated on the datasets of the OAEI Common Knowledge Graphs Track, augmented with the description of each class, and a new dataset based on the refreshed alignment of Schema.org and Wikidata. Our results demonstrate that TEXTO outperforms all state-of-art matchers in terms of precision, recall and F1 score. In particular, we show that almost perfect class alignment can be achieved using textual content only, excluding any structural information like the graph of classes or the instances of each class. © 2024 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Peng, Yiwen and Alam, Mehwish Afshar and Bonald, Thomas},
	year = {2023},
	note = {Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Ontology, Language model, Semantics, Ontology matching, Embeddings, Performance, Computational linguistics, Ontology's, Matching system, Textual information, Semantics Information, Common knowledge},
	pages = {67 -- 72},
	annote = {Type: Conference paper}
}

@article{peng2024RefiningWikidataTaxonomy,
	file = {References/pdf/peng2024RefiningWikidataTaxonomy.pdf},
	series = {{CIKM} '24},
	title = {Refining {Wikidata} {Taxonomy} using {Large} {Language} {Models}},
	url = {https://doi.org/10.1145/3627673.3679156},
	doi = {10.1145/3627673.3679156},
	abstract = {Due to its collaborative nature, Wikidata is known to have a complex taxonomy, with recurrent issues like the ambiguity between instances and classes, the inaccuracy of some taxonomic paths, the presence of cycles, and the high level of redundancy across classes. Manual efforts to clean up this taxonomy are time-consuming and prone to errors or subjective decisions. We present WiKC, a new version of Wikidata taxonomy cleaned automatically using a combination of Large Language Models (LLMs) and graph mining techniques. Operations on the taxonomy, such as cutting links or merging classes, are performed with the help of zero-shot prompting on an open-source LLM. The quality of the refined taxonomy is evaluated from both intrinsic and extrinsic perspectives, on a task of entity typing for the latter, showing the practical interest of WiKC.},
	journal = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
	author = {Peng, Yiwen and Bonald, Thomas and Alam, Mehwish},
	year = {2024},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery
Section: 0},
	keywords = {large language model, knowledge graphs, graph mining},
	pages = {5395--5399},
	annote = {event-place: Boise, ID, USA}
}

@article{perini2025BrickllmPythonLibrary,
	file = {References/pdf/perini2025BrickllmPythonLibrary.pdf},
	title = {{BrickLLM}: {A} {Python} library for generating {Brick}-compliant {RDF} graphs using {LLMs}},
	volume = {30},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-86000797991&doi=10.1016%2Fj.softx.2025.102121&partnerID=40&md5=7f6b3f13a501848795a1ca05f2d8be99},
	doi = {10.1016/j.softx.2025.102121},
	abstract = {One of the key challenges of Energy Management and Information Systems in buildings is related to the lack of interoperability, due to the absence of standardization of the underlying data models. In recent years, there has been a growing interest in using ontology-based metadata models to address this issue, as they offer a structured approach to organize and share information across diverse systems (e.g. Brick ontology). However, the creation of ontology-based metadata models is often a labor-intensive task that requires specific domain expertise, hindering the practical use of such data models. For this reason, in this work the BrickLLM Python library is introduced, which addresses this issue by generating Brick-compliant Resource Description Framework graphs through Large Language Models, automating the process of converting natural language building descriptions into machine-readable metadata. The library supports both cloud-based APIs (e.g., OpenAI, Anthropic, Fireworks AI), local models (e.g. LLaMa3.2, etc.) and evenfine-tuned ones. This paper explores the architecture, key functionalities, and practical applications of BrickLLM, showcasing its potential impact on the future of building systems monitoring and automation. © 2025 Elsevier B.V., All rights reserved.},
	journal = {SoftwareX},
	author = {Perini, Marco and Antonucci, Daniele and Giudice, Rocco and Piscitelli, Marco Savino and Capozzoli, Alfonso},
	year = {2025},
	note = {Section: 0},
	keywords = {Large language model, Ontology, Language model, Information management, RDF, Brick, Portability, Metadata, Energy, Ontology-based, RDF graph, Network security, In-buildings, Metadata model, Problem oriented languages, Structured approach},
	annote = {Type: Article}
}

@article{pham2025EnhancingOntologiesWith,
	file = {References/pdf/pham2025EnhancingOntologiesWith.pdf},
	title = {Enhancing {Ontologies} with {Large} {Language} {Models}: {A} {Semi}-{Automated} {Approach}},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105005143430&doi=10.24251%2Fhicss.2025.189&partnerID=40&md5=464e13815927a5a34910caab9c2bff4a},
	doi = {10.24251/hicss.2025.189},
	abstract = {The process of creating and maintaining domain ontologies is a time- and resource-intensive activity, given the dynamic nature of domain knowledge and the regular introduction of new terms. This study aims to determine the effectiveness of large language models (LLMs) in augmenting the domain ontology authoring process. We fine-tuned state-of-the-art pre-trained LLMs and evaluated their performance on two tasks: synonym identification and parent-child relationship identification. The models achieved 98\% accuracy in the first task and 75.4\% accuracy in the second, demonstrating significant capabilities in automating synonym identification and relationship classification. In addition to providing a methodological basis for further extending and improving these results, we demonstrate that LLMs can be effectively used in ontology development and maintenance. This can save time and effort in the process. © 2025 Elsevier B.V., All rights reserved.},
	journal = {Proceedings of the Annual Hawaii International Conference on System Sciences},
	author = {Pham, Anh T.V. and Huettemann, Sebastian and Mueller, Roland M.},
	year = {2025},
	note = {Section: 0},
	keywords = {Large language model, Ontology, Natural language processing, Language model, Domain ontologies, Ontology enrichment, Ontology extension, Language processing, Natural languages, Ontology's, Natural language processing systems, Transformer modeling, Automatic identification},
	pages = {1565 -- 1574},
	annote = {Type: Conference paper}
}

@article{piazza2024LargeLanguageModels,
	title = {Large {Language} {Models} for {Automatic} {Standardization} of {Cyber} {Deception} {Plans} based on the {Adversary} {Engagement} {Ontology}},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214561637&doi=10.1109%2FMILCOM61039.2024.10773797&partnerID=40&md5=6c47ba88a0ce6b2a790968dfdddcf22a},
	doi = {10.1109/MILCOM61039.2024.10773797},
	abstract = {Adversary Engagement Ontology (AEO) is a candidate ontology for the Unified Cyber Ontology (UCO), a community effort aimed at ontological standardization of cyber domain concepts and objects under a unifying framework. It forms a part of the Cyber Domain Ontology (CDO). In the past, community efforts and development have always been labor-intensive with regards to changes in ontology, example generation for adopters, and documentation generation. Large Language Models (LLMs), such as Claude-3.5-Sonnet and GPT4, have been proven capable of automating many tasks and aiding in human expert decision-making. Additionally, LLMs have been used in code interpretation, generation, and evaluation with efficiency and accuracy comparable to that of humans. This emergent capability of LLMs has led to the advantage of using LLMs to streamline the process of ontology development. Motivated by the aforementioned-approaches, we aim to demonstrate how these foundational LLMs can assist in ontology example generation and development, as well as be utilized to automate structured, albeit tedious tasks.},
	journal = {MILCOM 2024 - 2024 IEEE Military Communications Conference (MILCOM)},
	author = {Piazza, Nancirose and Upadhayay, Bibek and Scarpa, Ronald and Behzadan, Vahid},
	month = oct,
	year = {2024},
	note = {Section: 0},
	keywords = {Ontologies, Ontology, Natural language processing, Language model, Large language models, Domain ontologies, Ontology development, Standardization, Decision making, Accuracy, Documentation, Codes, Military communication, Adversary Engagement, Ontology's, Decisions makings, Human expert, Adversary engagement, Domain concepts, Labour-intensive, Plan-based, Cannot download},
	pages = {1--5},
	annote = {ISSN: 2155-7586}
}

@article{pisu2024ClassifyingScientificTopic,
	file = {References/pdf/pisu2024ClassifyingScientificTopic.pdf},
	title = {Classifying {Scientific} {Topic} {Relationships} with {SciBERT}},
	volume = {3759},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204687914&partnerID=40&md5=a41e6340c629d84f102448f83d2f523d},
	abstract = {Current AI systems, including smart search engines and recommendation systems tools for streamlining literature reviews, and interactive question-answering platforms, are becoming indispensable for researchers to navigate and understand the vast landscape of scientific knowledge.Taxonomies and ontologies of research topics are key to this process, but manually creating them is costly and often leads to outdated results.This poster paper shows the use of SciBERT model to automatically generate research topic ontologies.Our model excels at identifying semantic relationships between research topics, outperforming traditional methods.This approach promises to streamline the creation of accurate and up-to-date ontologies, enhancing the effectiveness of AI tools for researchers. © 2024 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Pisu, Alessia and Pompianu, Livio and Salatino, Angelo Antonio and Osborne, Francesco and Riboni, Daniele and Motta, Enrico and Reforgiato Recupero, Diego},
	year = {2024},
	note = {Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Language model, Semantics, Search engines, Question answering, Ontology generation, Recommender systems, Knowledge graph generation, AI systems, SciBERT, Ontology's, 'current, Graph generation, Research topics},
	annote = {Type: Conference paper}
}

@article{pisu2024LeveragingLanguageModels,
	file = {References/pdf/pisu2024LeveragingLanguageModels.pdf},
	title = {Leveraging {Language} {Models} for {Generating} {Ontologies} of {Research} {Topics}},
	volume = {3747},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203384989&partnerID=40&md5=be1194ae4f01daf079586c6797976a77},
	abstract = {The current generation of artificial intelligence technologies, such as smart search engines, recommendation systems, tools for systematic reviews, and question-answering applications, plays a crucial role in helping researchers manage and interpret scientific literature. Taxonomies and ontologies of research topics are a fundamental part of this environment as they allow intelligent systems and scientists to navigate the ever-growing number of research papers. However, creating these classifications manually is an expensive and time-consuming process, often resulting in outdated and coarse-grained representations. Consequently, researchers have been focusing on developing automated or semi-automated methods to create taxonomies of research topics. This paper studies the application of transformer-based language models for generating research topic ontologies. Specifically, we have developed a model leveraging SciBERT to identify four semantic relationships between research topics (supertopic, subtopic, same-as, and other) and conducted a comparative analysis against alternative solutions. The preliminary findings indicate that the transformer-based model significantly surpasses the performance of models reliant on traditional features. © 2024 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Pisu, Alessia and Pompianu, Livio and Salatino, Angelo Antonio and Osborne, Francesco and Riboni, Daniele and Motta, Enrico and Reforgiato Recupero, Diego},
	year = {2024},
	note = {Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Ontology, Language model, Semantics, Question answering, Taxonomies, Ontology generation, Recommender systems, Knowledge graph generation, SciBERT, Ontology's, Artificial intelligence technologies, Graph generation, Research topics, Current generation},
	pages = {11},
	annote = {Type: Conference paper}
}

@article{plu2025ComprehensiveBenchmarkEvaluating,
	file = {References/pdf/plu2025ComprehensiveBenchmarkEvaluating.pdf},
	title = {A {Comprehensive} {Benchmark} for {Evaluating} {LLM}-{Generated} {Ontologies}},
	volume = {3953},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003711461&partnerID=40&md5=8fd2db4b7f249a0ddbc9b672049723f2},
	abstract = {This paper presents a methodology for evaluating ontologies that are automatically generated by Large Language Models (LLMs). Our approach combines quantitative metrics that compare generated ontologies with respect to a human-made reference and qualitative user assessments across diverse domains. We apply this methodology to evaluate the ontologies produced by various LLMs, including Claude 3.5 Sonnet, GPT-4o, and GPT-4o-mini. The results demonstrate the benchmark’s effectiveness in identifying strengths and weaknesses of LLM-generated ontologies, providing valuable insights for improving automated ontology generation techniques. © 2025 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Plu, Julien and Escobar, Oscar Moreno and Trouillez, Edouard and Gapin, Axelle and Troncy, Raphaël},
	year = {2025},
	note = {Section: 0},
	keywords = {Large language model, Ontology, Language model, Ontology development, Evaluation, Ontology generation, Benchmark, Ontology's, Automatically generated, Diverse domains, Quantitative metric},
	annote = {Type: Conference paper}
}

@article{procko2023AutomaticGenerationBfo,
	file = {References/pdf/procko2023AutomaticGenerationBfo.pdf},
	title = {Automatic {Generation} of {BFO}-{Compliant} {Aristotelian} {Definitions} in {OWL} {Ontologies} with {GPT}},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184805224&doi=10.1109%2FTransAI60598.2023.00042&partnerID=40&md5=7f05736a0f125cf5bfd0cf0230dd81c3},
	doi = {10.1109/TransAI60598.2023.00042},
	abstract = {Ontologies are representational artifacts that purport to accurately describe some aspect of reality, including the entities and the relations that hold between them. In computer science, ontologies are software artifacts containing the schematic structure for machine-readable knowledge, typically formed as a graph of subject-predicate-object triples, constrained through Description Logics. These resources and their relations are self-defining, i.e., some resource may be defined by considering all its stated relations. Resources are often attended with natural language annotations, that humans may read and interpret, such as labels and definitions. Many long-standing ontologies have useless lexical definitions that define resources cyclically, e.g., a FOAF: Person is simply defined as “A person”. In Aristotelian terms, the definition of a thing should be reducible, by using terms simpler than itself, such that every definition can be unpacked up to the most general thing, which can only be defined by stating examples and use cases. This paper presents an innovative technique that leverages the Generative Pre-trained Transformer (GPT) large language model, GPT -4, for automatically generating Aristotelian definition annotations for OWL classes that engenders compliance with the Basic Formal Ontology standard.},
	journal = {2023 Fifth International Conference on Transdisciplinary AI (TransAI)},
	author = {Procko, Tyler Thomas and Ochoa, Omar and Elvira, Timothy},
	month = sep,
	year = {2023},
	note = {Section: 0},
	keywords = {Ontology, GPT, Linked data, ontology, OWL, Annotations, Description logic, Transformers, Software, Epistemology, Generative pre-trained transformer, Linked Data, BFO, Regulatory compliance, epistemology, Automatic Generation, Natural languages, Maintenance engineering, Ontology's, Birds, Linked datum, OWL ontologies, Data description, Schematic structures, Software artefacts},
	pages = {141--146},
	annote = {Type: Conference paper}
}

@article{procko2023Gpt4Stochastic,
	file = {References/pdf/procko2023Gpt4Stochastic.pdf},
	title = {{GPT}-4: {A} {Stochastic} {Parrot} or {Ontological} {Craftsman}? {Discovering} {Implicit} {Knowledge} {Structures} in {Large} {Language} {Models}},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184808375&doi=10.1109%2FTransAI60598.2023.00043&partnerID=40&md5=1508a82f1a0c8b3376895ff708ffdb11},
	doi = {10.1109/TransAI60598.2023.00043},
	abstract = {Ontologies are representational artifacts that purport to accurately portray the aspect of reality under the purview of the ontologists laboring upon them. Ontologies exist in a spectrum of formality, from lexical thesauri to knowledge graphs, to collections of statements of first-order logic. The recent proliferation of Large Language Models (LLMs) has brought to bear interactive “knowledge bases” with general awareness of most things. As ontologists create ontologies from their understanding of reality; and as LLMs, presumably, possess some “understanding” of reality, embedded in their vector matrices corresponding to lexical terms from massive quantities of learned texts, a question is posed: what form of ontology can an LLM create when prompted about some novel facet of reality, without explicitly asking it for an ontology? I.e., will an LLM categorize things into bins, or a subsumption hierarchy, or perhaps something else? LLMs, as they are understood, respond when prompted with the most likely response, because they are predictors of next tokens, i.e., they are stochastic parrots. In any case, it is posited that, if prompted without any explicit request for an ontology, an LLM can produce an ontology of novel form, effectively granting insight into the “understanding” an LLM has of the world, as all humans possess an understanding of the world that ontologies are based upon. This paper explores the use of the flagship LLM, GPT-4, in forming an ontology of a novel domain.},
	journal = {2023 Fifth International Conference on Transdisciplinary AI (TransAI)},
	author = {Procko, Tyler Thomas and Elvira, Timothy and Ochoa, Omar},
	month = sep,
	year = {2023},
	note = {Section: 0},
	keywords = {Knowledge graphs, Large language model, Ontology, Language model, GPT, large language models, ontology, OWL, taxonomy, Taxonomy, Formal logic, Organizations, Computational linguistics, Visualization, Supervised learning, First order logic, Natural languages, Stochastic processes, Ontology's, Birds, Implicit knowledge, Stochastic systems, Knowledge structures, Spectra's, Stochastic models, Stochastics},
	pages = {147--154},
	annote = {Type: Conference paper}
}

@article{pruski2025EnhancingEscoWith,
	title = {Enhancing {ESCO} with {Generative} {AI}: {A} {Dynamic} {Approach} to {Supporting} 21st {Century} {Education}},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105008223380&doi=10.1109%2FEDUCON62633.2025.11016516&partnerID=40&md5=b97ab1cd1b30a3fd2cf619db06f6e211},
	doi = {10.1109/EDUCON62633.2025.11016516},
	abstract = {In the rapidly evolving landscape of engineering education, upskilling and lifelong learning have become critical to maintaining competitiveness and fostering innovation. The use of ontologies, such as the European Skills, Competences, Qualifications, and Occupations (ESCO), plays a crucial role in organizing and managing the skills required for modern engineering roles. However, the slow pace of ontology updates and the lack of contextual adaptability present significant challenges, leading to outdated and irrelevant information for educators, learners, and industry professionals. This paper explores the potential of integrating Large Language Models (LLMs) with knowledge engineering to accelerate the process of updating ontologies like ESCO. By dynamically analyzing data and incor-porating contextual information, LLMs offer promising avenues for enhancing the evolution and precision of these ontologies. We discuss the potential impact of this approach in engineering education, particularly in aligning ups killing and reskilling efforts with the demands of emerging technologies such as AI -driven automation and digital engineering. This paper aims to highlight how LLMs can support the creation of more responsive, context-aware learning frameworks, ultimately sustaining educational ex-cellence and fostering critical thinking in engineering education.},
	journal = {2025 IEEE Global Engineering Education Conference (EDUCON)},
	author = {Pruski, Cédric and Gallais, Marie and Da Silveira, Marcos},
	month = apr,
	year = {2025},
	note = {Section: 0},
	keywords = {Ontologies, Large language model, Ontology, LLM, Language model, Large language models, Knowledge engineering, Ontology evolution, Robustness, Technological innovation, Contextualization, Engineering education, Soft sensors, lifelong learning, Multilingual, Industries, Qualifications, Upskilling, Ontology's, Dynamic approaches, Industry professionals, Life long learning, Modern engineering, Cannot download},
	pages = {1--5},
	annote = {ISSN: 2165-9567}
}

@article{qiang2024AgentOmLeveraging,
	file = {References/pdf/qiang2024AgentOmLeveraging.pdf},
	title = {Agent-{OM}: {Leveraging} {LLM} {Agents} for {Ontology} {Matching}},
	volume = {18},
	issn = {2150-8097},
	url = {https://doi.org/10.14778/3712221.3712222},
	doi = {10.14778/3712221.3712222},
	abstract = {Ontology matching (OM) enables semantic interoperability between different ontologies and resolves their conceptual heterogeneity by aligning related entities. OM systems currently have two prevailing design paradigms: conventional knowledge-based expert systems and newer machine learning-based predictive systems. While large language models (LLMs) and LLM agents have revolutionised data engineering and have been applied creatively in many domains, their potential for OM remains underexplored. This study introduces a novel agent-powered LLM-based design paradigm for OM systems. With consideration of several specific challenges in leveraging LLM agents for OM, we propose a generic framework, namely Agent-OM (Agent for Ontology Matching), consisting of two Siamese agents for retrieval and matching, with a set of OM tools. Our framework is implemented in a proof-of-concept system. Evaluations of three Ontology Alignment Evaluation Initiative (OAEI) tracks over state-of-the-art OM systems show that our system can achieve results very close to the long-standing best performance on simple OM tasks and can significantly improve the performance on complex and few-shot OM tasks.},
	number = {3},
	journal = {Proc. VLDB Endow.},
	author = {Qiang, Zhangcheng and Wang, Weiqing and Taylor, Kerry},
	month = nov,
	year = {2024},
	note = {Section: 0},
	keywords = {Interoperability, Ontology, Language model, Semantic interoperability, Semantics, Ontology matching, Search engines, Expert systems, Performance, Adversarial machine learning, Learning systems, Ontology's, Matching system, Model agents, Design paradigm, Knowledge-based expert systems, Related entities},
	pages = {516--529},
	annote = {Publisher: VLDB Endowment}
}

@article{qiang2025OaeiLlmBenchmark,
	file = {References/pdf/qiang2025OaeiLlmBenchmark.pdf},
	title = {{OAEI}-{LLM}: {A} {Benchmark} {Dataset} for {Understanding} {Large} {Language} {Model} {Hallucinations} in {Ontology} {Matching}},
	volume = {3953},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003710219&partnerID=40&md5=2bc85a3f291179ba30149f9d98dc04dc},
	abstract = {Hallucinations of large language models (LLMs) commonly occur in domain-specific downstream tasks, with no exception in ontology matching (OM). The prevalence of using LLMs for OM raises the need for benchmarks to better understand LLM hallucinations. The OAEI-LLM dataset is an extended version of the Ontology Alignment Evaluation Initiative (OAEI) datasets that evaluate LLM-specific hallucinations in OM tasks. We outline the methodology used in dataset construction and schema extension, and provide examples of potential use cases. © 2025 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Qiang, Zhangcheng and Taylor, Kerry L. and Wang, Weiqing and Jiang, Jing},
	year = {2025},
	note = {Section: 0},
	keywords = {Large language model, Language model, Ontology matching, Ontology alignment, Modeling languages, Large datasets, Domain specific, Down-stream, Benchmark datasets, Extended versions, Large language model hallucination},
	annote = {Type: Conference paper}
}

@article{racharak2024AutomatedMedicalRdf,
	title = {An {Automated} {Medical} {Rdf} {Knowledge} {Graph} {Construction} {From} {Text} {Using} in-{Context} {Learning}},
	doi = {10.1109/KSE63888.2024.11063495},
	abstract = {The parameterized knowledge within large language models (LLMs), like ChatGPT, offers a significant opportunity for modelling domain knowledge base from text. However, LLMs' context sensitivity can hinder obtaining precise and taskaligned outcomes, thus requiring a suitable design for leveraging prompt engineering. This study explores the efficacy of different prompting methods for RDF knowledge graph construction from medical documents as our preliminary investigation, aiming to develop an efficient pipeline for a large-scale automatic knowledge graph construction according to semantic web standards and technologies. The results show that leveraging in-context learning within LLMs is capable of extracting an array of precise RDF triples from text. We perform a qualitative analysis of the extracted triples with different prompt templates, giving insights that could guide potential development in the research field.},
	journal = {2024 16th International Conference on Knowledge and System Engineering (KSE)},
	author = {Racharak, Teeradaj and Wang, Tongyu and Jearanaiwongkul, Watanee},
	month = nov,
	year = {2024},
	note = {Section: 0},
	keywords = {Ontologies, Knowledge graphs, Large language models, Resource description framework, Knowledge engineering, Prompt engineering, Prompting, Standards, OpenAI, Few-shot, Sensitivity, Resource Description Framework, Pipelines, Systems engineering and theory, Generative Knowledge Graph Extraction, Cannot download},
	pages = {465--471},
	annote = {ISSN: 2694-4804}
}

@article{reales2024CoreConceptIdentification,
	file = {References/pdf/reales2024CoreConceptIdentification.pdf},
	title = {Core {Concept} {Identification} in {Educational} {Resources} via {Knowledge} {Graphs} and {Large} {Language} {Models}},
	volume = {5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208722616&doi=10.1007%2Fs42979-024-03341-y&partnerID=40&md5=758642118b6621a5065b31a83abbb2cd},
	doi = {10.1007/s42979-024-03341-y},
	abstract = {The growing demand for online education raises the question of which learning resources should be included in online programs to ensure students achieve their desired learning outcomes. By automatically identifying the core concepts in educational materials, teachers can select coherent and relevant resources for their courses. This work explores the use of Large Language Models (LLMs) to identify core concepts in educational resources. We propose three different pipelines for building knowledge graphs from lecture transcripts using LLMs and ontologies such as DBpedia. These knowledge graphs are then utilized to determine the central concepts (nodes) within the educational resources. Results show that LLM-constructed knowledge graphs when guided by ontologies, achieve state-of-the-art performance in core concept identification. © 2025 Elsevier B.V., All rights reserved.},
	number = {8},
	journal = {SN Computer Science},
	author = {Reales, Daniel and Manrique, Rubén Francisco and Grévisse, Christian},
	year = {2024},
	note = {Section: 0},
	annote = {Type: Article}
}

@article{rebboud2025BenchmarkingLlmBased,
	file = {References/pdf/rebboud2025BenchmarkingLlmBased.pdf},
	title = {Benchmarking {LLM}-based {Ontology} {Conceptualization}: {A} {Proposal}},
	volume = {3953},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003719390&partnerID=40&md5=3a9798338e35ed4a969743b0278931bb},
	abstract = {This study presents a benchmark proposal designed to enhance knowledge engineering tasks through the use of large language models (LLMs). As LLMs become increasingly pivotal in knowledge extraction and modeling, it is crucial to evaluate and improve their performance. Building on prior work aiming at reverse generating competency questions (CQs) from existing ontologies, we introduce a benchmark focused on specific knowledge modeling tasks including ontology documentation, ontology generation, and query generation. In addition, we propose a baseline evaluation framework that applies various techniques, such as semantic comparison, ontology evaluation criteria, and structural comparison, using both existing ground truth datasets and newly proposed ontologies with corresponding CQs and documentation. This rigorous evaluation aims to provide a deeper understanding of LLM capabilities and contribute to their optimization in knowledge engineering applications. © 2025 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Rebboud, Youssra and Lisena, Pasquale and Tailhardat, Lionel and Troncy, Raphaël},
	year = {2025},
	note = {Section: 0},
	keywords = {Knowledge acquisition, Knowledge graph, Large language model, Language model, Knowledge extraction, Conceptual design, Knowledge model, Performance, Ontology's, Knowledge-representation, Model-based OPC, Knowledge organization system (KOS), Engineering tasks, Benchmark proposal, Image representation},
	annote = {Type: Conference paper}
}

@article{rebboud2025CanLlmsGenerate,
	file = {References/pdf/rebboud2025CanLlmsGenerate.pdf},
	title = {Can {LLMs} {Generate} {Competency} {Questions}?},
	volume = {15344},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218474145&doi=10.1007%2F978-3-031-78952-6_7&partnerID=40&md5=4f9c4d533bce3706de5a09e47bb22cb3},
	doi = {10.1007/978-3-031-78952-6_7},
	abstract = {Large Language Models have shown high performances in a large number of tasks, being recently applied also to support Knowledge Graphs construction. An important step for data modeling consists in the definition of a set of competency questions, which are often used as a guide for the development of an ontology and as a mean to evaluate the resulting schema. In this work, we investigate the suitability of LLMs for the automatic generation of competency questions given an existing ontology. We compare different large language models under various settings in order to give a comprehensive overview of what LLMs can do to support the knowledge engineer. © 2025 Elsevier B.V., All rights reserved.},
	journal = {Lecture Notes in Computer Science},
	author = {Rebboud, Youssra and Tailhardat, Lionel and Lisena, Pasquale and Troncy, Raphaël},
	year = {2025},
	note = {Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Ontology, LLM, Language model, Modeling languages, Data modeling, Performance, Automatic Generation, Graph construction, Ontology's, Support knowledge},
	pages = {71 -- 80},
	annote = {Type: Conference paper}
}

@article{regino2024GeneratingECommerce,
	file = {References/pdf/regino2024GeneratingECommerce.pdf},
	title = {Generating {E}-commerce {Related} {Knowledge} {Graph} from {Text}: {Open} {Challenges} and {Early} {Results} using {LLMs}},
	volume = {3747},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203334838&partnerID=40&md5=ac53dff8d619e6e1d33d20a00efdd161},
	abstract = {E-commerce systems need to use and manage vast amounts of unstructured textual data. This poses significant challenges for knowledge representation, information retrieval, and recommendation tasks. This study investigates the generation of E-commerce-related Knowledge Graphs (KGs) from text. In particular, we explore using Large Language Models (LLMs). Our approach integrates ontology with text-based examples from existing KGs via prompts to create structured RDF triples. We outline a four-step method encompassing text classification, extracting relevant characteristics, generating RDF triples, and assessing the generated triples. Each step leverages LLM instructions to process unstructured text. We discuss the insights, challenges, and potential future directions, highlighting the significance of integrating ontology elements with unstructured text for generating semantically enriched KGs. Through case experimentations, we demonstrate the effectiveness and applicability of our solution in the E-commerce domain. © 2024 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Regino, Andre Gomes and César Dos Reis, Júlio},
	year = {2024},
	note = {Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Large language model, Ontology, Language model, Structured Query Language, Ontology's, Unstructured texts, RDF triples, E-commerce systems, Knowledge graph enhancement, Marketplaces, Text-to-triple},
	pages = {18},
	annote = {Type: Conference paper}
}

@article{reif2024ChatbotBasedOntology,
	file = {References/pdf/reif2024ChatbotBasedOntology.pdf},
	title = {Chatbot-{Based} {Ontology} {Interaction} {Using} {Large} {Language} {Models} and {Domain}-{Specific} {Standards}},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207845394&doi=10.1109%2FETFA61755.2024.10711065&partnerID=40&md5=6e55dc21dbf2c13a30448996fcb6cb63},
	doi = {10.1109/ETFA61755.2024.10711065},
	abstract = {The following contribution introduces a concept that employs Large Language Models (LLMs) and a chatbot interface to enhance SPARQL query generation for ontologies, thereby facilitating intuitive access to formalized knowledge. Utilizing natural language inputs, the system converts user inquiries into accurate SPARQL queries that strictly query the factual content of the ontology, effectively preventing misinformation or fabrication by the LLM. To enhance the quality and precision of outcomes, additional textual information from established domain-specific standards is integrated into the ontology for precise descriptions of its concepts and relationships. An experimental study assesses the accuracy of generated SPARQL queries, revealing significant benefits of using LLMs for querying ontologies and highlighting areas for future research.},
	journal = {2024 IEEE 29th International Conference on Emerging Technologies and Factory Automation (ETFA)},
	author = {Reif, Jonathan and Jeleniewski, Tom and Gill, Milapji Singh and Gehlhoff, Felix and Fay, Alexander},
	month = sep,
	year = {2024},
	note = {Section: 0},
	keywords = {Ontologies, Large Language Models, Large language model, Ontology, Language model, Large language models, Semantic Web, Semantics, Industry 4.0, Standards, Cyber-physical systems, Accuracy, Chatbots, Cyber-Physical Systems, Fake news, Fabrication, Natural languages, Manufacturing automation, Structured Query Language, Ontology's, Query languages, Cybe-physical systems, Semantic-Web, Domain specific, Query generation, Cannot download},
	pages = {1--4},
	annote = {ISSN: 1946-0759 {\textbar} RAYYAN-LABELS: SPARQL}
}

@article{rezayi2025ExploringNewFrontiers,
	file = {References/pdf/rezayi2025ExploringNewFrontiers.pdf},
	title = {Exploring {New} {Frontiers} in {Agricultural} {NLP}: {Investigating} the {Potential} of {Large} {Language} {Models} for {Food} {Applications}},
	volume = {11},
	issn = {2332-7790},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201463745&doi=10.1109%2FTBDATA.2024.3442542&partnerID=40&md5=5b2de44b44642ac5f1b62bf16a120c7f},
	doi = {10.1109/TBDATA.2024.3442542},
	abstract = {This paper explores new frontiers in agricultural natural language processing (NLP) by investigating the effectiveness of food-related text corpora for pretraining transformer-based language models. Specifically, we focus on semantic matching, establishing mappings between food descriptions and nutrition data through fine-tuning AgriBERT with the FoodOn ontology. Our work introduces an expanded comparison with state-of-the-art language models such as GPT-4, Mistral-large, Claude 3 Sonnet, and Gemini 1.0 Ultra. This exploratory investigation, rather than a direct comparison, aims to understand how AgriBERT, a domain-specific, fine-tuned, open-source model, complements the broad knowledge and generative abilities of these advanced LLMs in addressing the unique challenges of the agricultural sector. We also experiment with other applications, such as cuisine prediction from ingredients, expanding our research to include various NLP tasks beyond semantic matching. Overall, this paper underscores the potential of integrating domain-specific models like AgriBERT with advanced LLMs to enhance the performance and applicability of agricultural NLP applications.},
	number = {3},
	journal = {IEEE Transactions on Big Data},
	author = {Rezayi, Saed and Liu, Zhengliang and Wu, Zihao and Dhakal, Chandra and Ge, Bao and Dai, Haixing and Mai, Gengchen and Liu, Ninghao and Zhen, Chen and Liu, Tianming and Li, Sheng},
	month = jun,
	year = {2025},
	note = {Section: 0},
	keywords = {ChatGPT, Natural language processing, Language model, Semantics, natural language processing, Modeling languages, language models, Context modeling, Data models, Training, Semantic matching, semantic matching, Language processing, Natural languages, Biological system modeling, food applications, Task analysis, Context models, Food applications},
	pages = {1235--1246},
	annote = {Type: Article}
}

@article{riquelmegarcía2025AnnotationBiologicalSamples,
	file = {References/pdf/riquelmegarcía2025AnnotationBiologicalSamples.pdf},
	title = {Annotation of biological samples data to standard ontologies with support from large language models},
	volume = {27},
	issn = {2001-0370},
	url = {https://www.sciencedirect.com/science/article/pii/S2001037025001837},
	doi = {https://doi.org/10.1016/j.csbj.2025.05.020},
	abstract = {The semantic integration of biological data is hindered by the vast heterogeneity of data sources and their limited semantic formalization. A crucial step in this process is mapping data elements to ontological concepts, which typically involves substantial manual effort. Large Language Models (LLMs) have demonstrated potential in automating complex language-related tasks and may offer a solution to streamline biological data annotation. This study investigates the utility of LLMs—specifically various base and fine-tuned GPT models—for the automatic assignment of ontological identifiers to biological sample labels. We evaluated model performance in annotating labels to four widely used ontologies: the Cell Line Ontology (CLO), Cell Ontology (CL), Uber-anatomy Ontology (UBERON), and BRENDA Tissue Ontology (BTO). Our dataset was compiled from publicly available, high-quality databases containing biologically relevant sequence information, which suffers from inconsistent annotation practices, complicating integrative analyses. Model outputs were compared against annotations generated by text2term, a state-of-the-art annotation tool. The fine-tuned GPT model outperformed both the base models and text2term in annotating cell lines and cell types, particularly for the CL and UBERON ontologies, achieving a precision of 47–64\% and a recall of 88–97\%. In contrast, base models exhibited significantly lower performance. These results suggest that fine-tuned LLMs can accelerate and improve the accuracy of biological data annotation. Nonetheless, our evaluation highlights persistent challenges, including variable precision across ontology categories and the continued need for expert curation to ensure annotation validity.},
	journal = {Computational and Structural Biotechnology Journal},
	author = {Riquelme-García, Andrea and Mulero-Hernández, Juan and Fernández-Breis, Jesualdo Tomás},
	year = {2025},
	note = {Section: 0},
	keywords = {large language model, Large language model, Ontology, Language model, Large language models, Bioinformatics, Biological samples, Data interoperability, Generative AI, ontology, data interoperability, Data annotation, Formal concept analysis, generative artificial intelligence, human, ontology development, medical ontology, Article, female, Ontology's, false positive result, human cell, medical research, data base, anatomical concepts, anatomy ontology, Base models, Biological data, biological product, Cell lines, false negative result, HeLa cell line, Tissue culture, uterine epithelium},
	pages = {2155--2167},
	annote = {Type: Article}
}

@article{rodrigues2023UseChatgptClassifying,
	file = {References/pdf/rodrigues2023UseChatgptClassifying.pdf},
	title = {On the {Use} of {ChatGPT} for {Classifying} {Domain} {Terms} {According} to {Upper} {Ontologies}},
	volume = {14319},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177226095&doi=10.1007%2F978-3-031-47112-4_24&partnerID=40&md5=dca995c6f4355d84ee7c1ba5820fa9bd},
	doi = {10.1007/978-3-031-47112-4_24},
	abstract = {In this paper, we report an experiment to investigate the performance of ChatGPT in the task of classifying domain terms according to the categories of upper-level ontologies. The experiment consisted of (1) starting a conversation in ChatGPT with a contextual prompt listing the categories of an upper-level ontology along with their definitions, (2) submitting a follow-up prompt with a list of terms from a domain along with informal definitions, (3) asking ChatGPT to classify the terms according to the categories of the chosen upper-level ontology and explain its decision, and (4) comparing the answers of ChatGPT with the classification proposed by experts in the chosen ontology. Given the results, we evaluated the success rate of ChatGPT in performing the task and analyzed the cases of misclassification to understand the possible reasons underlying them. Based on that, we made some considerations about the extent to which we can employ ChatGPT as an assistant tool for the task of classifying domain terms into upper-level ontologies. For our experiment, we selected a set of 19 terms from the manufacturing domain that were gathered by the Industrial Ontologies Foundry (IOF) and for which there are informal textual definitions reflecting a community view of them. Also, as a baseline for comparison, we resorted to publicly available classifications of such terms according to DOLCE and BFO upper-level ontologies, which resulted from a thorough ontological analysis of those terms and informal definitions by experts in each of the ontologies. © 2023 Elsevier B.V., All rights reserved.},
	journal = {Lecture Notes in Computer Science},
	author = {Rodrigues, Fabrício Henrique Henrique and Lopes, Alcides Gonçalves and Dos Santos, Nicolau O. and Garcia, Luan Fonseca and Carbonera, Joel Lúis and Abel, Mara},
	year = {2023},
	note = {Section: 0},
	keywords = {ChatGPT, Large language model, Ontology, LLM, Language model, Manufacturing, BFO, DOLCE, Ontology's, Term classification, Foundries, Industrial ontology foundry},
	pages = {249 -- 258},
	annote = {Type: Conference paper}
}

@article{sadruddin2025Llms4schemadiscoveryHumanIn,
	file = {References/pdf/sadruddin2025Llms4schemadiscoveryHumanIn.pdf},
	title = {{LLMs4SchemaDiscovery}: {A} {Human}-in-the-{Loop} {Workflow} for {Scientific} {Schema} {Mining} with {Large} {Language} {Models}},
	volume = {15719},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007760723&doi=10.1007%2F978-3-031-94578-6_14&partnerID=40&md5=09f8a3feeee6d10d3656ede32cca3b1e},
	doi = {10.1007/978-3-031-94578-6_14},
	abstract = {Extracting structured information from unstructured text is crucial for modeling real-world processes, but traditional schema mining relies on semi-structured data, limiting scalability. This paper introduces schema-miner, a novel tool that combines large language models with human feedback to automate and refine schema extraction. Through an iterative workflow, it organizes properties from text, incorporates expert input, and integrates domain-specific ontologies for semantic depth. Applied to materials science—specifically atomic layer deposition—schema-miner demonstrates that expert-guided LLMs generate semantically rich schemas suitable for diverse real-world applications. © 2025 Elsevier B.V., All rights reserved.},
	journal = {Lecture Notes in Computer Science},
	author = {Sadruddin, Sameer and D’Souza, Jennifer and Poupaki, Eleni and Watkins, Alex and Giglou, Hamed Babaei and Rula, Anisa and Karasulu, Bora and Auer, Sören and Mackus, Adrie and Kessels, Erwin},
	year = {2025},
	note = {Section: 0},
	keywords = {Large language model, Language model, Semantics, Human-in-the-loop, Work-flows, Unstructured texts, Human-in-the-loop workflow, Multilayers, Schema discovery, Schema mining, Scientific schema, Structured information},
	pages = {244 -- 261},
	annote = {Type: Conference paper}
}

@article{saeedizade2024NavigatingOntologyDevelopment,
	file = {References/pdf/saeedizade2024NavigatingOntologyDevelopment.pdf},
	title = {Navigating {Ontology} {Development} with {Large} {Language} {Models}},
	volume = {14664},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194261410&doi=10.1007%2F978-3-031-60626-7_8&partnerID=40&md5=baaad02d5b7b04faf346edad72360685},
	doi = {10.1007/978-3-031-60626-7_8},
	abstract = {Ontology engineering is a complex and time-consuming task, even with the help of current modelling environments. Often the result is error-prone unless developed by experienced ontology engineers. However, with the emergence of new tools, such as generative AI, inexperienced modellers might receive assistance. This study investigates the capability of Large Language Models (LLMs) to generate OWL ontologies directly from ontological requirements. Specifically, our research question centres on the potential of LLMs in assisting human modellers, by generating OWL modelling suggestions and alternatives. We experiment with several state-of-the-art models. Our methodology incorporates diverse prompting techniques like Chain of Thoughts (CoT), Graph of Thoughts (GoT), and Decomposed Prompting, along with the Zero-shot method. Results show that currently, GPT-4 is the only model capable of providing suggestions of sufficient quality, and we also note the benefits and drawbacks of the prompting techniques. Overall, we conclude that it seems feasible to use advanced LLMs to generate OWL suggestions, which are at least comparable to the quality of human novice modellers. Our research is a pioneering contribution in this area, being the first to systematically study the ability of LLMs to assist ontology engineers. © 2024 Elsevier B.V., All rights reserved.},
	journal = {Lecture Notes in Computer Science},
	author = {Saeedizade, Mohammad Javad and Blomqvist, Eva},
	year = {2024},
	note = {Section: 0},
	keywords = {Ontology engineering, Large language model, Ontology, Language model, Ontology development, Computational linguistics, Zero-shot learning, Ontology's, Birds, Error prones, Current modeling, Modeling environments, OWL ontologies, Time-consuming tasks},
	pages = {143 -- 161},
	annote = {Type: Conference paper}
}

@article{saetia2024FinancialProductOntology,
	file = {References/pdf/saetia2024FinancialProductOntology.pdf},
	title = {Financial {Product} {Ontology} {Population} with {Large} {Language} {Models}},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204898551&doi=10.18653%2Fv1%2F2024.textgraphs-1.4&partnerID=40&md5=bfa3b333c19f905f0559a241ed50be00},
	doi = {10.18653/v1/2024.textgraphs-1.4},
	abstract = {Ontology population, which aims to extract structured data to enrich domain-specific ontologies from unstructured text, typically faces challenges in terms of data scarcity and linguistic complexity, particularly in specialized fields such as retail banking. In this study, we investigate the application of large language models (LLMs) to populate domain-specific ontologies of retail banking products from Thai corporate documents. We compare traditional span-based approaches to LLMs-based generative methods, with different prompting techniques. Our findings reveal that while span-based methods struggle with data scarcity and the complex linguistic structure, LLMs-based generative approaches substantially outperform, achieving a 61.05\% F1 score, with the most improvement coming from providing examples in the prompts. This improvement highlights the potential of LLMs for ontology population tasks, offering a scalable and efficient solution for structured information extraction, especially in low-resource language settings. © 2024 Elsevier B.V., All rights reserved.},
	author = {Saetia, Chanatip and Phruetthiset, Jiratha and Chalothorn, Tawunrat and Lertsutthiwong, Monchai and Taerungruang, Supawat and Buabthong, Pakpoom},
	year = {2024},
	note = {Section: 0},
	keywords = {Ontology, Ontology Population, Language model, Computational linguistics, Structured data, Data scarcity, Model-based OPC, Unstructured texts, Domain-specific ontologies, Financial products, Product Ontologies, Retail banking},
	pages = {53 -- 60},
	annote = {Type: Conference paper}
}

@article{sahbi2024AutomaticOntologyPopulation,
	file = {References/pdf/sahbi2024AutomaticOntologyPopulation.pdf},
	title = {Automatic {Ontology} {Population} from {Textual} {Advertisements}: {LLM} vs. {Semantic} {Approach}},
	volume = {246},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211219376&doi=10.1016%2Fj.procs.2024.09.364&partnerID=40&md5=a07ef1696c731a6c2952f13728042482},
	doi = {10.1016/j.procs.2024.09.364},
	abstract = {Automatic ontology population involves identifying, extracting and integrating information from various sources to instantiate the classes and properties of an ontology, thereby building a domain Knowledge Graph (KG). In this paper, we compare two text-based ontology population techniques: KOnPoTe, a semantic approach based on textual and domain knowledge analysis, and a generative AI approach utilizing Claude, a Large Language Model (LLM). We present experiments conducted on two French sales advertisement domains: real estate and boats, and discuss the strengths and limitations of both approaches. © 2024 Elsevier B.V., All rights reserved.},
	journal = {Procedia Computer Science},
	author = {Sahbi, Aya and Alec, Céline and Beust, Pierre},
	year = {2024},
	note = {Section: 0},
	keywords = {Knowledge graph, Large language model, Ontology, Ontology Population, Language model, Semantics, Modeling languages, Semantic approach, Domain knowledge, Domain Knowledge, Automatic ontology, Property, Extracting information, Generative adversarial networks, Marketing, Integrating information, Textual advertisement},
	pages = {3083 -- 3092},
	annote = {Issue: C Type: Conference paper}
}

@article{sahbi2025SemanticVs,
	file = {References/pdf/sahbi2025SemanticVs.pdf},
	title = {Semantic vs. {LLM}-based approach: {A} case study of {KOnPoTe} vs. {Claude} for ontology population from {French} advertisements},
	volume = {156},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211195979&doi=10.1016%2Fj.datak.2024.102392&partnerID=40&md5=7adba98e00024b722539b1e6c7c8ebdc},
	doi = {10.1016/j.datak.2024.102392},
	abstract = {Automatic ontology population is the process of identifying, extracting, and integrating relevant information from diverse sources to instantiate the classes and properties specified in an ontology, thereby creating a Knowledge Graph (KG) for a particular domain. In this study, we evaluate two approaches for ontology population from text: KOnPoTe, a semantic technique that employs textual and domain knowledge analysis, and a generative AI method leveraging Claude, a Large Language Model (LLM). We conduct comparative experiments on three French advertisement domains: real estate, boats, and restaurants to assess the performance of these techniques. Our analysis highlights the respective strengths and limitations of the semantic approach and the LLM-based one in the context of the ontology population process. © 2024 Elsevier B.V., All rights reserved.},
	journal = {Data and Knowledge Engineering},
	author = {Sahbi, Aya and Alec, Céline and Beust, Pierre},
	year = {2025},
	note = {Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Large language model, Ontology, Ontology Population, Language model, Semantics, Domain Knowledge, Ontology's, Model based approach, Automatic ontology, Property, Case-studies, Textual description},
	annote = {Type: Article}
}

@article{sainz2021Ask2transformersZeroShot,
	file = {References/pdf/sainz2021Ask2transformersZeroShot.pdf},
	title = {{Ask2Transformers}: {Zero}-shot domain labelling with pre-trained language models},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85119149541&partnerID=40&md5=02af5dddcf0ffae9926edf8de4a38bdb},
	abstract = {In this paper we present a system that exploits different pre-trained Language Models for assigning domain labels to WordNet synsets without any kind of supervision. Furthermore, the system is not restricted to use a particular set of domain labels. We exploit the knowledge encoded within different off-the-shelf pre-trained Language Models and task formulations to infer the domain label of a particular WordNet definition. The proposed zero-shot system achieves a new state-of-the-art on the English dataset used in the evaluation. © 2021 Elsevier B.V., All rights reserved.},
	author = {Sainz, Oscar and Rigau, German},
	year = {2021},
	note = {Section: 0},
	keywords = {Ontology, Language model, Wordnet, Computational linguistics, Labelings, State of the art, Synsets},
	pages = {44 -- 52},
	annote = {Type: Conference paper}
}

@article{sampels2024OntomatchResultsOaei,
	file = {References/pdf/sampels2024OntomatchResultsOaei.pdf},
	title = {{OntoMatch} {Results} for {OAEI} 2024},
	volume = {3897},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216387360&partnerID=40&md5=f3574fe259d893ec448d7aeae809d538},
	abstract = {This paper presents the results of OntoMatch in the OAEI 2024 competition. OntoMatch is an ontology matching system that combines graph search algorithms with zero-shot prompting of Large Language Models (LLMs) to produce class correspondences. The system follows an iterative approach involving neighbourhood candidate selection, context extraction using graph search techniques, verbalising of context and zero-shot LLM prompting with templates. Each iteration concludes with a cardinality filter to refine the alignments. OntoMatch was evaluated on the OAEI conference benchmark dataset. The results demonstrate the impact of incorporating graph-based contextual information alongside carefully crafted prompt templates, achieving competitive scores and highlighting the effectiveness of LLM-driven approaches for ontology alignment. © 2025 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Sampels, Julian},
	year = {2024},
	note = {Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Large language model, Ontology, Language model, Ontology matching, Modeling languages, Zero-shot learning, Graph search, Matching system, Graph-search algorithms, Iterative approach, Neighbourhood, Prompt generation},
	pages = {124 -- 131},
	annote = {Type: Conference paper}
}

@article{schaeffer2024PertinenceLlmsOntology,
	file = {References/pdf/schaeffer2024PertinenceLlmsOntology.pdf},
	title = {On the {Pertinence} of {LLMs} for {Ontology} {Learning}},
	volume = {3874},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214247692&partnerID=40&md5=a817900503c26a5320cf55725e593f4d},
	abstract = {Ontology learning from text is traditionally approached as sub-tasks tackled with linguistic, statistical or logic-based methods. Large language models and their generation capabilities have recently caught much interest. We investigate the pertinence of such generative models for ontology learning. We evaluate the created ontologies on two different use cases by aligning with a reference ontology and compare components for each sub-task using the OLAF ontology learning framework. In addition to demonstrating the relevance of large language models for ontology learning, we discuss component combinations, LLM size, and environmental impact in creating efficient pipelines while limiting resource consumption. © 2025 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Schaeffer, Marion and Sesboüé, Matthias and Charbonnier, Léa and Delestre, Nicolas and Kotowicz, Jean Philippe and Zanni-Merk, Cécilia},
	year = {2024},
	note = {Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Ontology, LLM, Language model, Ontology learning, Knowledge graph construction, Federated learning, Generative model, Adversarial machine learning, Graph construction, Ontology's, Contrastive Learning, Subtask, Learning from texts},
	pages = {1 -- 18},
	annote = {Type: Conference paper}
}

@article{schneider2023NlfoaNaturalLanguage,
	file = {References/pdf/schneider2023NlfoaNaturalLanguage.pdf},
	series = {K-{CAP} '23},
	title = {{NLFOA}: {Natural} {Language} {Focused} {Ontology} {Alignment}},
	url = {https://doi.org/10.1145/3587259.3627560},
	doi = {10.1145/3587259.3627560},
	abstract = {For Ontology Alignment (OA), the task is to align semantically equivalent concepts and relations from different ontologies. This task plays a crucial role in many downstream tasks and applications in academia and industry. Since manually aligning ontologies is inefficient and costly, numerous approaches exist to do this automatically. However, most approaches are tailored to specific domains, are rule-based systems or based on feature engineering, and require external knowledge. The most recent advances in the field of OA rely on the widely proven effectiveness of pre-trained language models to represent the human-generated language that describes the entities in an ontology. However, these approaches additionally require sophisticated algorithms or Graph Neural Networks to exploit an ontology’s graphical structure to achieve state-of-the-art performance. In this work, we present NLFOA, or Natural Language Focused Ontology Alignment, which purely focuses on the natural language contained in ontologies to process the ontology’s semantics as well as graphical structure. An evaluation of our approach on common OA datasets shows superior results when finetuning with only a small number of training samples. Additionally, it demonstrates strong results in a zero-shot setting which could be employed in an active learning setup to reduce human labor when manually aligning ontologies significantly.},
	journal = {Proceedings of the 12th Knowledge Capture Conference 2023},
	author = {Schneider, Florian and Dash, Sarthak and Bagchi, Sugato and Mihindukulasooriya, Nandana and Gliozzo, Alfio Massimiliano},
	year = {2023},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery
Section: 0},
	keywords = {Knowledge graph, Ontology, Language model, Semantics, Ontology alignment, Graph neural networks, Zero-shot learning, Ontology Alignment Sentence Transformers Zero-Shot, Natural languages, Ontology's, External knowledge, Down-stream, Feature engineerings, Graphical structures, Ontology alignment sentence transformer zero-shot, Rules based systems},
	pages = {114--121},
	annote = {event-place: Pensacola, FL, USA}
}

@article{shan2025LargeLanguageModels,
	file = {References/pdf/shan2025LargeLanguageModels.pdf},
	title = {Large language {Models}-empowered automatic knowledge graph development based on multi-modal data for building health resilience},
	volume = {68},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010563058&doi=10.1016%2Fj.aei.2025.103655&partnerID=40&md5=329bb060f38e387aae8af0f77b054252},
	doi = {10.1016/j.aei.2025.103655},
	abstract = {Improving the health resilience of building (BHR) helps keep stable health status of both the building and its occupants under disasters. As BHR is an emerging concept, there is no structured knowledge graph to understand the whole process of BHR under disasters. Therefore, this study aims to build a structured BHR knowledge graph based on multi-modal data, providing sufficient structured knowledge for BHR enhancement. An automated knowledge graph construction approach is proposed to empower the ontology design and triple extraction by large language models (LLMs), and validation processes based on In-context Learning (ICL) prompts. A case study is conducted to construct the knowledge graph of BHR under rainstorms in Hong Kong. The performance of the proposed LLMs-empowered knowledge extraction is also validated based on natural language processing metrics and LLMs-based Evaluation (LLMs-Eval). BHR knowledge graph indicates the potential relations between disasters, factors, response actions, and the health status of the building and occupants, and provides insight to guide the BHR enhancement. The superiority of the proposed LLMs-empowered automated knowledge graph construction approach is proven, implying LLMs have great potential in knowledge graph construction, not only for BHR but also for other concepts that require structured knowledge for further explorations and analyses. © 2025 Elsevier B.V., All rights reserved.},
	journal = {Advanced Engineering Informatics},
	author = {Shan, Tianlong and Zhang, Fan and Chan, Albert P.C. and Zhu, Shiyao and Li, Kaijian},
	year = {2025},
	note = {Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Large language model, Ontology, Language model, Building health resilience, Multi-modal data, Rainstorm, Graph theory, Extraction, Graph construction, Graphic methods, Construction approaches, Health status, Modal analysis, Natural language processing systems, Structured knowledge},
	annote = {Type: Article}
}

@article{shi2025EvidenceTriangulatorUsing,
	file = {References/pdf/shi2025EvidenceTriangulatorUsing.pdf},
	title = {Evidence triangulator: using large language models to extract and synthesize causal evidence across study designs},
	volume = {16},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105012984973&doi=10.1038%2Fs41467-025-62783-x&partnerID=40&md5=6c7c0d7e6de22060d6fb918902827e12},
	doi = {10.1038/s41467-025-62783-x},
	abstract = {Health strategies increasingly emphasize both behavioural and biomedical interventions, yet the complex and often contradictory guidance on diet, behavior, and health outcomes complicates evidence-based decision-making. Evidence triangulation across diverse study designs is essential for balancing biases and establishing causality, but scalable, automated methods for achieving this are lacking. In this study, we assess the performance of large language models in extracting both ontological and methodological information from scientific literature to automate evidence triangulation. A two-step extraction approach—focusing on exposure-outcome concepts first, followed by relation extraction—outperforms a one-step method, particularly in identifying the direction of effect (F1 = 0.86) and statistical significance (F1 = 0.96). Using salt intake and blood pressure as a case study, we calculate the Convergency of Evidence and Level of Convergency, finding a strong excitatory effect of salt on blood pressure (942 studies), and weak excitatory effect on cardiovascular diseases and deaths (124 studies). This approach complements traditional meta-analyses by integrating evidence across study designs, and enabling rapid, dynamic assessment of scientific controversies. © 2025 Elsevier B.V., All rights reserved.},
	number = {1},
	journal = {Nature Communications},
	author = {Shi, Xuanyu and Zhao, Wenjing and Chen, Ting and Yang, Chao and Du, Jian},
	year = {2025},
	note = {Section: 0},
	keywords = {large language model, Large Language Models, data extraction, ontology, information retrieval, Causality, knowledge graph, adverse event, methodology, etiology, cardiovascular disease, accuracy, human, gold standard, nomenclature, language, causality, Humans, Article, predictive model, accuracy assessment, analytical error, blood, blood pressure, Blood Pressure, Cardiovascular Diseases, cardiovascular mortality, case study, Cochrane Library, detection method, Dietary, dietary intake, drug effect, evidence synthesis, internal validity, ischemic heart disease, Medical Subject Headings, Medline, Mendelian randomization analysis, observational study, outcome assessment, probability, randomized controlled trial (topic), Research Design, salt intake, scientific literature, sodium chloride, Sodium Chloride, study design, triangulation},
	annote = {Type: Article}
}

@article{shimizu2025AcceleratingKnowledgeGraph,
	file = {References/pdf/shimizu2025AcceleratingKnowledgeGraph.pdf},
	title = {Accelerating knowledge graph and ontology engineering with large language models},
	volume = {85},
	issn = {1570-8268},
	url = {https://www.sciencedirect.com/science/article/pii/S1570826825000022},
	doi = {https://doi.org/10.1016/j.websem.2025.100862},
	abstract = {Large Language Models bear the promise of significant acceleration of key Knowledge Graph and Ontology Engineering tasks, including ontology modeling, extension, modification, population, alignment, as well as entity disambiguation. We lay out LLM-based Knowledge Graph and Ontology Engineering as a new and coming area of research, and argue that modular approaches to ontologies will be of central importance.},
	journal = {Journal of Web Semantics},
	author = {Shimizu, Cogan and Hitzler, Pascal},
	year = {2025},
	note = {Section: 0},
	keywords = {Knowledge graphs, Ontology engineering, Knowledge graph, Large language model, Ontology modeling, Ontology Population, Ontology model, Language model, Large language models, Ontology population, Entity disambiguation, Knowledge graph engineering, Modular ontologies, Ontology alignment},
	pages = {100862},
	annote = {Type: Article}
}

@article{shlyk2024RealRetrievalAugmented,
	file = {References/pdf/shlyk2024RealRetrievalAugmented.pdf},
	title = {{REAL}: {A} {Retrieval}-{Augmented} {Entity} {Linking} {Approach} for {Biomedical} {Concept} {Recognition}},
	url = {https://aclanthology.org/2024.bionlp-1.29/},
	doi = {10.18653/v1/2024.bionlp-1.29},
	abstract = {Large Language Models (LLMs) offer an appealing alternative to training dedicated models for many Natural Language Processing (NLP) tasks. However, outdated knowledge and hallucination issues can be major obstacles in their application in knowledge-intensive biomedical scenarios. In this study, we consider the task of biomedical concept recognition (CR) from unstructured scientific literature and explore the use of Retrieval Augmented Generation (RAG) to improve accuracy and reliability of the LLM-based biomedical CR. Our approach, named REAL (Retrieval Augmented Entity Linking), combines the generative capabilities of LLMs with curated knowledge bases to automatically annotate natural language texts with concepts from bio-ontologies. By applying REAL to benchmark corpora on phenotype concept recognition, we show its effectiveness in improving LLM-based CR performance. This research highlights the potential of combining LLMs with external knowledge sources to advance biomedical text processing.},
	journal = {Proceedings of the 23rd Workshop on Biomedical Natural Language Processing},
	author = {Shlyk, Darya and Groza, Tudor and Mesiti, Marco and Montanelli, Stefano and Cavalleri, Emanuele},
	editor = {Demner-Fushman, Dina and Ananiadou, Sophia and Miwa, Makoto and Roberts, Kirk and Tsujii, Junichi},
	month = aug,
	year = {2024},
	note = {Place: Bangkok, Thailand
Publisher: Association for Computational Linguistics
Section: 0},
	keywords = {Language model, Concept recognition, Benchmarking, Performance, Computational linguistics, Language processing, Natural languages, Natural language processing systems, Model-based OPC, External knowledge, Natural languages texts, Scientific literature, Bio-ontologies},
	pages = {380--389},
	annote = {Type: Conference paper}
}

@article{silva2024AiAssistedDomain,
	file = {References/pdf/silva2024AiAssistedDomain.pdf},
	series = {{MODELS} {Companion} '24},
	title = {{AI} {Assisted} {Domain} {Modeling} {Explainability} and {Traceability}},
	url = {https://doi.org/10.1145/3652620.3688197},
	doi = {10.1145/3652620.3688197},
	abstract = {Domain Models are abstract representations of selected elements in a domain that is created in a collaborative process between domain and modeler experts. The participants share domain knowledge to conceptualize and reason about the elements that will create the domain models. Through this exchange, a comprehensive and accurate representation of the domain is achieved, ensuring that the model captures the relevant aspects and relationships in the domain. Research in Artificial Intelligence (AI) has explored various methods to assist in the creation of domain models from text using Natural Language Processing (NLP) and Machine Learning (ML). Recent advancements with Large Language Models (LLMs) have shown that it is possible to create domain models using prompting techniques; however, the generated domain models contain errors and remain constrained by the performance of the LLM used.Despite the impressive capabilities of LLMs to create domain models, it is evident that it does not address the needs of domain and modelers experts that participate in the creation of domain models. Every AI technique has its advantages and limitations that must be integrated with human feedback in a collaboration process. Therefore, we propose an approach that incorporates human-AI collaboration supported by AI assistants that follows a dialogue approach to understand the users needs and purpose to suggest relevant models. Our proposal combines symbolic and subsymbolic AI techniques with explainability and traceability of the decisions that assist to create domain models that are relevant for the users.},
	journal = {Proceedings of the ACM/IEEE 27th International Conference on Model Driven Engineering Languages and Systems},
	author = {Silva Mercado, Jonathan},
	year = {2024},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery
Section: 0},
	keywords = {large language models, uncertainty, explainability, domain modeling, traceability},
	pages = {130--135},
	annote = {event-place: Linz, Austria}
}

@article{silva2024ComplexMultiOntology,
	file = {References/pdf/silva2024ComplexMultiOntology.pdf},
	title = {Complex {Multi}-{Ontology} {Alignment} {Through} {Geometric} {Operations} on {Language} {Embeddings}},
	volume = {392},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213368903&doi=10.3233%2FFAIA240632&partnerID=40&md5=2a4ee19f34446fb87dbc163e17bc4910},
	doi = {10.3233/FAIA240632},
	abstract = {With knowledge graphs increasing in popularity, aligning and integrating them is paramount to ensure their usefulness and reusability. A key step in this process is ontology matching, whereby the semantic models of KGs are aligned into a single cohesive semantic backbone. While finding simple pairwise equivalences between entities in two ontologies is well addressed by state-of-the-art algorithms, finding more complex mappings that can include multiple entities from different ontologies is far from solved, despite their importance in ensuring a deep and meaningful integration of KGs. We propose a novel complex ontology matching approach that explores geometric operations over the shared semantic space afforded by large language models, enabling the discovery of complex mappings that are missed by purely lexical approaches. We evaluate our approach on several biomedical ontologies using partial reference alignments and manual expert validation. Our approach improves on the performance of a purely lexical approach while also increasing the coverage of complex multi-ontology alignments by 20 to 80\%, which translates to a 97\% coverage of the source ontologies. Moreover, the manual evaluation of the mappings produced by LLM shows that it achieves a high level of precision. This work demonstrates that the use of LLMs can improve on the performance of traditional lexical strategies. © 2024 Elsevier B.V., All rights reserved.},
	journal = {Frontiers in Artificial Intelligence and Applications},
	author = {Silva, Marta Contreiras and Faria, Daniel and Pesquita, Cátia},
	year = {2024},
	note = {Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Ontology, Semantics, Ontology matching, Ontology alignment, Semantic modelling, Embeddings, Mapping, Performance, Graph embeddings, Reusability, Latent semantic analysis, Ontology's, Complex mapping, Geometric operations, Multi-ontologies},
	pages = {1333 -- 1340},
	annote = {Type: Conference paper}
}

@article{soares2025ExploringLargeLanguage,
	file = {References/pdf/soares2025ExploringLargeLanguage.crdownload},
	title = {Exploring a {Large} {Language} {Model} for {Transforming} {Taxonomic} {Data} into {OWL}: {Lessons} {Learned} and {Implications} for {Ontology} {Development}},
	volume = {7},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105008033640&doi=10.3724%2F2096-7004.di.2025.0020&partnerID=40&md5=6058e3e1f68e29e82ea9f1764e6f68fb},
	doi = {10.3724/2096-7004.di.2025.0020},
	abstract = {Managing scientific names in ontologies that represent species taxonomies is challenging due to the ever-evolving nature of these taxonomies. Manually maintaining these names becomes increasingly difficult when dealing with thousands of scientific names. To address this issue, this paper investigates the use of ChatGPT-4 to automate the development of the Organism module in the Agricultural Product Types Ontology (APTO) for species classification. Our methodology involved leveraging ChatGPT-4 to extract data from the GBIF Backbone API and generate OWL files for further integration in APTO. Two alternative approaches were explored: (1) issuing a series of prompts for ChatGPT-4 to execute tasks via the BrowserOP plugin and (2) directing ChatGPT-4 to design a Python algorithm to perform analogous tasks. Both approaches rely on a prompting method where we provide instructions, context, input data, and an output indicator. The first approach showed scalability limitations, while the second approach used the Python algorithm to overcome these challenges, but it struggled with typographical errors in data handling. This study highlights the potential of Large language models like ChatGPT-4 to streamline the management of species names in ontologies. Despite certain limitations, these tools offer promising advancements in automating taxonomy-related tasks and improving the efficiency of ontology development. © 2025 Elsevier B.V., All rights reserved.},
	number = {2},
	journal = {Data Intelligence},
	author = {Soares, Filipi Miranda and Saraiva, Antônio Mauro and Ferreira Pires, L. Ferreira and da Silva Santos, Luiz Olavo Bonino and Moreira, Dilvan De Abreu and Correa, Fernando Elias and Braghetto, Kelly Rosa and Drucker, Debora P. and Delbem, Alexandre Claudio Botazzo},
	year = {2025},
	note = {Section: 0},
	keywords = {ChatGPT, Knowledge graphs, Knowledge graph, Ontology, Language model, Ontology development, Metadata, Taxonomies, Python, Agriculture, Ontology's, Birds, Data assimilation, Data handling, High level languages, Plug-ins, Product types, Species classification, Typographical errors},
	pages = {265 -- 302},
	annote = {Type: Article}
}

@article{sorokoletova2024TowardsScalableAi,
	file = {References/pdf/sorokoletova2024TowardsScalableAi.pdf},
	title = {Towards a scalable {AI}-driven framework for data-independent {Cyber} {Threat} {Intelligence} {Information} {Extraction}},
	doi = {10.1109/FLLM63129.2024.10852465},
	abstract = {Cyber Threat Intelligence (CTI) is critical for mitigating threats to organizations, governments, and institutions, yet the necessary data are often dispersed across diverse formats. AI-driven solutions for CTI Information Extraction (IE) typically depend on high-quality, annotated data, which are not always available. This paper introduces 0-CTI, a scalable AI-based framework designed for efficient CTI Information Extraction. Leveraging advanced Natural Language Processing (NLP) techniques, particularly Transformer-based architectures, the proposed system processes complete text sequences of CTI reports to extract a cyber ontology of named entities and their relationships.Our contribution is the development of 0-CTI, the first modular framework for CTI Information Extraction that supports both supervised and zero-shot learning. Unlike existing state-of-the-art models that rely heavily on annotated datasets, our system enables fully dataless operation through zero-shot methods for both Entity and Relation Extraction, making it adaptable to various data availability scenarios. Additionally, our supervised Entity Extractor surpasses current state-of-the-art performance in cyber Entity Extraction, highlighting the dual strength of the framework in both low-resource and data-rich environments.By aligning the system’s outputs with the Structured Threat Information Expression (STIX) format, a standard for information exchange in the cybersecurity domain, 0-CTI standardizes extracted knowledge, enhancing communication and collaboration in cybersecurity operations.},
	journal = {2024 2nd International Conference on Foundation and Large Language Models (FLLM)},
	author = {Sorokoletova, Olga and Antonioni, Emanuele and Colò, Giordano},
	month = nov,
	year = {2024},
	note = {Section: 0},
	keywords = {Ontologies, Natural language processing, Large language models, Information retrieval, Natural Language Processing, Transformers, Data mining, Cyber threat intelligence, Named Entity Recognition, Cyber Threat Intelligence, Relation Extraction, Computer security, Standards organizations, Zero shot learning, Structured Threat Information Expression},
	pages = {398--406}
}

@article{soularidis2024LlmAssistedGeneration,
	title = {{LLM}-{Assisted} {Generation} of {SWRL} {Rules} from {Natural} {Language}},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105008498105&doi=10.1109%2FAIxDKE63520.2024.00008&partnerID=40&md5=5e63e58a9654eba4991ac8cb40693cc7},
	doi = {10.1109/AIxDKE63520.2024.00008},
	abstract = {Recently, Large Language Models (LLMs) have attracted great attention due to their remarkable performance in human-like text generation and reasoning skills (although their memory and hallucination problems still remain key issues to tackle more efficiently). LLMs have been applied to various application domains, including Knowledge Graph (KG) generation, question and answering over KGs and text-to-SPARQL translation. In this work, we investigate the capabilities of LLMs in text-to-SWRL translation, i.e., translation of Natural Language (NL) rules into Semantic Web Rule Language (SWRL) rules, put in the context of an industrial Ontology Engineering (OE) environment called GLUON, presenting our first experimental results. The aim of this work is to identify the level of automation that is adequate for the LLM to generate well-formed SWRL rules, towards the development of an LLM-based framework, as a plugin to the GLUON OE environment. In this direction we leverage and combine the reasoning capabilities of GPT-4o model, the Retrieval-Augmented Generation (RAG) technology, and prompt engineering. We employ quantitative and qualitative metrics to evaluate the generated SWRL rules, focusing on the correct syntax and the level of human intervention. © 2025 Elsevier B.V., All rights reserved.},
	author = {Soularidis, Andreas and Kotis, Konstantinos I. and Lamolle, Myriam and Mejdoul, Zakaria and Lortal, Gaëlle and Vouros, George A.},
	year = {2024},
	note = {Section: 0},
	keywords = {Ontology engineering, Large language model, Ontology, Language model, Knowledge management, Retrieval-augmented generation, Semantic web rule language, Performance, Computational linguistics, Natural languages, Natural language processing systems, Translation (languages), Rules languages, Semantic Web rules, Engineering environment, Cannot download},
	pages = {7 -- 12},
	annote = {Type: Conference paper}
}

@article{sousa2024TowardsGeneratingComplex,
	file = {References/pdf/sousa2024TowardsGeneratingComplex.pdf},
	title = {Towards {Generating} {Complex} {Alignments} with {Large} {Language} {Models} via {Prompt} {Engineering}},
	volume = {3897},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216423330&partnerID=40&md5=0a2afeab7c303ab8425938365e9b4ee6},
	abstract = {Still few ontology matching approaches focus on generating alignments by a Large Language Model (LLM), especially in the complex matching task. This paper proposes an approach that leverages the capabilities of LLMs to perform complex ontology matching. The method integrates subsets of both source and target ontologies into the prompt and, as a response, the LLM generates alignments in the structured EDOAL format, rather than natural language descriptions. This reduction technique, based on the automatic generation of SPARQL queries, tackles the challenge of large prompt sizes, reduces the search space, and enables efficient processing on consumer-grade hardware. This approach is evaluated on the Conference and Geolink datasets from the OAEI complex track, demonstrating improved scalability and the ability to produce well-formed EDOAL. Key contributions include the development of a SPARQL-based prompt engineering strategy and the application of few-shot learning techniques to complex alignment generation. © 2025 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Sousa, Guilherme and Lima, Rinaldo Jose De and Trojahn, Cassia},
	year = {2024},
	note = {Section: 0},
	keywords = {Large language model, Ontology, Language model, Ontology matching, SPARQL, Modeling languages, Complex matching, Natural languages, Ontology's, Natural language processing systems, Matchings, Language description, Reduction techniques},
	pages = {43 -- 56},
	annote = {Type: Conference paper}
}

@article{stork2024EnablingSocialDemography,
	file = {References/pdf/stork2024EnablingSocialDemography.pdf},
	title = {Enabling {Social} {Demography} {Research} {Using} {Semantic} {Technologies}},
	volume = {14665},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195271433&doi=10.1007%2F978-3-031-60635-9_12&partnerID=40&md5=b632337dffe85b9fc216b98f19dc9198},
	doi = {10.1007/978-3-031-60635-9_12},
	abstract = {A shift in scientific publishing from paper-based to knowledge-based practices promotes reproducibility, machine actionability and knowledge discovery. This is important for disciplines like social demography, where study indicators are often social constructs such as race or education, hypothesis tests are challenging to compare due to their limited temporal and spatial coverage, and research output is presented in natural language, which can be ambiguous and imprecise. In this work, we present the MIRA resource, to aid researchers in their research workflow, and publish FAIR findings. MIRA consists of: (1) an ontology for social demography research, (2) a method for automated ontology population by prompting Large Language Models, and (3) a knowledge graph populated in terms of the ontology by annotating a set of research papers on health inequality. The resource allows researchers to formally represent their social demography research hypotheses, discovering research biases and novel research questions. © 2024 Elsevier B.V., All rights reserved.},
	journal = {Lecture Notes in Computer Science},
	author = {Stork, Lise and Zijdeman, Richard Lindert and Tiddi, Ilaria and Ten Teije, Annette},
	year = {2024},
	note = {Section: 0},
	keywords = {Knowledge graphs, Information extraction, Knowledge graph, Ontology, Semantic technologies, Semantic Web, Semantics, Demography, Ontology's, Scientific knowledge, Scientific knowledge graph, Knowledge based, Health inequality, Hypothesis representation, Population statistics, Social demography},
	pages = {199 -- 216},
	annote = {Type: Conference paper}
}

@article{strader2024IndoorOutdoor3d,
	title = {Indoor and {Outdoor} {3D} {Scene} {Graph} {Generation} {Via} {Language}-{Enabled} {Spatial} {Ontologies}},
	volume = {9},
	issn = {2377-3766},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189615964&doi=10.1109%2FLRA.2024.3384084&partnerID=40&md5=86b59d43a6f2399478a764bbb05e2117},
	doi = {10.1109/LRA.2024.3384084},
	abstract = {This letter proposes an approach to build 3D scene graphs in arbitrary indoor and outdoor environments. Such extension is challenging; the hierarchy of concepts that describe an outdoor environment is more complex than for indoors, and manually defining such hierarchy is time-consuming and does not scale. Furthermore, the lack of training data prevents the straightforward application of learning-based tools used in indoor settings. To address these challenges, we propose two novel extensions. First, we develop methods to build a spatial ontology defining concepts and relations relevant for indoor and outdoor robot operation. In particular, we use a Large Language Model (LLM) to build such an ontology, thus largely reducing the amount of manual effort required. Second, we leverage the spatial ontology for 3D scene graph construction using Logic Tensor Networks (LTN) to add logical rules, or axioms (e.g., “a beach contains sand”), which provide additional supervisory signals at training time thus reducing the need for labelled data, providing better predictions, and even allowing predicting concepts unseen at training time. We test our approach in a variety of datasets, including indoor, rural, and coastal environments, and show that it leads to a significant increase in the quality of the 3D scene graph generation with sparsely annotated data.},
	number = {6},
	journal = {IEEE Robotics and Automation Letters},
	author = {Strader, Jared and Hughes, Nathan and Chen, William and Speranzon, Alberto and Carlone, Luca},
	month = jun,
	year = {2024},
	note = {Section: 0},
	keywords = {Ontologies, Ontology, Artificial intelligence, Semantics, Modeling languages, Scene understanding, Indoor environment, Training data, Solid modeling, Three-dimensional displays, Semantic scene understanding, 3D scene graphs, AI-based methods, Image analysis, semantic scene understanding, spatial ontologies, Spatial resolution, Ontology's, Three dimensional computer graphics, Personnel training, Spatial ontologies, 3d scene graph, 3D scenes, AI-based method, Scene-graphs, Solid modelling, Three dimensional displays, Three-dimensional display, Cannot download},
	pages = {4886--4893},
	annote = {Type: Article}
}

@article{strakova2023ExtendingEventType,
	file = {References/pdf/strakova2023ExtendingEventType.pdf},
	title = {Extending an {Event}-type {Ontology}: {Adding} {Verbs} and {Classes} {Using} {Fine}-tuned {LLMs} {Suggestions}},
	url = {https://aclanthology.org/2023.law-1.9/},
	doi = {10.18653/v1/2023.law-1.9},
	abstract = {In this project, we have investigated the use of advanced machine learning methods, specifically fine-tuned large language models, for pre-annotating data for a lexical extension task, namely adding descriptive words (verbs) to an existing (but incomplete, as of yet) ontology of event types. Several research questions have been focused on, from the investigation of a possible heuristics to provide at least hints to annotators which verbs to include and which are outside the current version of the ontology, to the possible use of the automatic scores to help the annotators to be more efficient in finding a threshold for identifying verbs that cannot be assigned to any existing class and therefore they are to be used as seeds for a new class. We have also carefully examined the correlation of the automatic scores with the human annotation. While the correlation turned out to be strong, its influence on the annotation proper is modest due to its near linearity, even though the mere fact of such pre-annotation leads to relatively short annotation times.},
	journal = {Proceedings of the 17th Linguistic Annotation Workshop (LAW-XVII)},
	author = {Straková, Jana and Fučíková, Eva and Hajič, Jan and Urešová, Zdeňka},
	editor = {Prange, Jakob and Friedrich, Annemarie},
	month = jul,
	year = {2023},
	note = {Place: Toronto, Canada
Publisher: Association for Computational Linguistics
Section: 0},
	keywords = {Ontology, Language model, Learning systems, Ontology's, 'current, Research questions, Event Types, Human annotations, Machine learning methods},
	pages = {85--95},
	annote = {Type: Conference paper}
}

@article{sun2024AreLargeLanguage,
	file = {References/pdf/sun2024AreLargeLanguage.pdf},
	title = {Are {Large} {Language} {Models} a {Good} {Replacement} of {Taxonomies}?},
	volume = {17},
	issn = {2150-8097},
	url = {https://doi.org/10.14778/3681954.3681973},
	doi = {10.14778/3681954.3681973},
	abstract = {Large language models (LLMs) demonstrate an impressive ability to internalize knowledge and answer natural language questions. Although previous studies validate that LLMs perform well on general knowledge while presenting poor performance on long-tail nuanced knowledge, the community is still doubtful about whether the traditional knowledge graphs should be replaced by LLMs. In this paper, we ask if the schema of knowledge graph (i.e., taxonomy) is made obsolete by LLMs. Intuitively, LLMs should perform well on common taxonomies and at taxonomy levels that are common to people. Unfortunately, there lacks a comprehensive benchmark that evaluates the LLMs over a wide range of taxonomies from common to specialized domains and at levels from root to leaf so that we can draw a confident conclusion. To narrow the research gap, we constructed a novel taxonomy hierarchical structure discovery benchmark named TaxoGlimpse to evaluate the performance of LLMs over taxonomies. TaxoGlimpse covers ten representative taxonomies from common to specialized domains with in-depth experiments of different levels of entities in this taxonomy from root to leaf. Our comprehensive experiments of eighteen LLMs under three prompting settings validate that LLMs perform miserably poorly in handling specialized taxonomies and leaf-level entities. Specifically, the QA accuracy of the best LLM drops by up to 30\% as we go from common to specialized domains and from root to leaf levels of taxonomies.},
	number = {11},
	journal = {Proc. VLDB Endow.},
	author = {Sun, Yushi and Xin, Hao and Sun, Kai and Xu, Yifan Ethan and Yang, Xiao and Dong, Xin Luna and Tang, Nan and Chen, Lei},
	month = jul,
	year = {2024},
	note = {Section: 0},
	pages = {2919--2932},
	annote = {Publisher: VLDB Endowment}
}

@article{sun2025Docs2kgHumanLlm,
	file = {References/pdf/sun2025Docs2kgHumanLlm.pdf},
	series = {{WWW} '25},
	title = {{Docs2KG}: {A} {Human}-{LLM} {Collaborative} {Approach} to {Unified} {Knowledge} {Graph} {Construction} from {Heterogeneous} {Documents}},
	url = {https://doi.org/10.1145/3701716.3715309},
	doi = {10.1145/3701716.3715309},
	abstract = {Enterprises generate vast amounts of unstructured documents, posing challenges for knowledge extraction and representation. Large language models (LLMs) offer strong potential for processing such data but struggle with factual accuracy and provenance. Knowledge graphs (KGs) provide a structured framework to address these limitations [6], yet constructing high-quality KGs from heterogeneous data remains a challenge. To address this issue, we present Docs2KG, a modular framework to build high-quality KGs from diverse unstructured documents. We first employs state-of-the-art document processing techniques to extract textual content, tabular data, and figures. The extracted information is then unified into a multifaceted KG with three aspects: (1) a Layout KG capturing document structural hierarchies, (2) a Metadata KG preserving document properties, and (3) a Semantic KG representing domain-specific entities and relationships. Docs2KG supports multiple construction paradigms for Semantic KG: ontology-based approaches, hybrid NLP pipelines with LLM verification, LLM-guided ontology generation, and specialized models for named entity recognition, event extraction, and causal relationship identification to enhance semantic coverage and accuracy. A key feature of Docs2KG is its human-in-the-loop verification interface, enabling iterative quality assessment and refinement of the resulting KGs. Docs2KG is openly available at https://docs2kg.ai4wa.com, with the aim of advancing knowledge graph construction research and accelerating enterprise applications through high-quality knowledge graph construction.},
	journal = {Companion Proceedings of the ACM on Web Conference 2025},
	author = {Sun, Qiang and Luo, Yuanyi and Zhang, Wenxiao and Li, Sirui and Li, Jichunyang and Niu, Kai and Kong, Xiangrui and Liu, Wei},
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery
Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Ontology, Language model, Semantics, knowledge graph, Data mining, Heterogeneous data, Graph theory, Extraction, Unstructured data, unstructured data, heterogeneous data, Graph construction, Iterative methods, Data handling, Information retrieval systems, Collaborative approach, Data accuracy, High quality, Quality knowledge, Semantics knowledge, Unstructured documents},
	pages = {801--804},
	annote = {event-place: Sydney NSW, Australia}
}

@article{svatek2024WelcomeNewbornEntity,
	file = {References/pdf/svatek2024WelcomeNewbornEntity.pdf},
	title = {Welcome, newborn entity! on handling newly generated entities in ontology transformation},
	volume = {3967},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105006920019&partnerID=40&md5=a57ad8bb2d6f629d92714d9b77231eb1},
	abstract = {Modeling can be seen both as an engineering and a design task. Even when clear requirements are available for an ontology modeling endevour, many times the requirements can be solved in several different ways. Even further, when requirements change and evolve, a certain modeling style, or pattern, may no longer be the best choice. However, refactoring an ontology due to such changes in requirements, or due to the desire to align better with other external ontologies or data sets, is a complex and tedious process, also requiring extensive expertise. Attempting to automate part of the ontology transformation process, by identifying typical transformation patterns, and creating tool support for their semi-automated application, is therefore an important research topic. One specific sub-task of such automation is the naming of new entities (e.g. classes or properties) that are generated through the pattern application. In this paper we discuss the need for such automated naming support, and show the feasibility of introducing Large Language Models (LLMs) for taking the automation one step further. © 2025 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Svátek, Vojtech and Ŝváb-Zamazal, Ondr̂ej Ř.Ej and Haniková, Kateřina and Chudán, David and Saeedizade, Mohammad Javad and Blomqvist, Eva},
	year = {2024},
	note = {Section: 0},
	keywords = {Large language model, Ontology model, Language model, OWL, Requirements engineering, Ontology's, Design tasks, Best choice, Entity naming, Ontology transformation, Requirements change},
	annote = {Type: Conference paper}
}

@article{taboada2025OntologyMatchingWith,
	file = {References/pdf/taboada2025OntologyMatchingWith.pdf},
	title = {Ontology matching with {Large} {Language} {Models} and prioritized depth-first search},
	volume = {123},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105004876116&doi=10.1016%2Fj.inffus.2025.103254&partnerID=40&md5=60448dc85d882e6b0594bd7acd43f80a},
	doi = {10.1016/j.inffus.2025.103254},
	abstract = {Ontology matching (OM) plays a key role in enabling data interoperability and knowledge sharing. Recently, methods based on Large Language Model (LLMs) have shown great promise in OM, particularly through the use of a retrieve-then-prompt pipeline. In this approach, relevant target entities are first retrieved and then used to prompt the LLM to predict the final matches. Despite their potential, these systems still present limited performance and high computational overhead. To address these issues, we introduce MILA, a novel approach that embeds a retrieve-identify-prompt pipeline within a prioritized depth-first search (PDFS) strategy. This approach efficiently identifies a large number of semantic correspondences with high accuracy, limiting LLM requests to only the most borderline cases. We evaluated MILA using three challenges from the 2024 edition of the Ontology Alignment Evaluation Initiative. Our method achieved the highest F-Measure in five of seven unsupervised tasks, outperforming state-of-the-art OM systems by up to 17\%. It also performed better than or comparable to the leading supervised OM systems. MILA further exhibited task-agnostic performance, remaining stable across all tasks and settings, while significantly reducing runtime. These findings highlight that high-performance LLM-based OM can be achieved through a combination of programmed (PDFS), learned (embedding vectors), and prompting-based heuristics, without the need of domain-specific heuristics or fine-tuning. © 2025 Elsevier B.V., All rights reserved.},
	journal = {Information Fusion},
	author = {Taboada, Maria Jesús Salvador and Martínez, Diego and Arideh, Mohammed and Mosquera, Rosa},
	year = {2025},
	note = {Section: 0},
	keywords = {Large language model, Interoperability, Language model, Data interoperability, Greedy search, Ontology matching, Retrieval augmented generation, Zero-shot setting, Performance, Depth first, Matching system},
	annote = {Type: Article}
}

@article{tang2023DomainKnowledgeDistillation,
	title = {Domain {Knowledge} {Distillation} from {Large} {Language} {Model}: {An} {Empirical} {Study} in the {Autonomous} {Driving} {Domain}},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186526218&doi=10.1109%2FITSC57777.2023.10422308&partnerID=40&md5=eb8968513a3c5a2be5a84e95c070417e},
	doi = {10.1109/ITSC57777.2023.10422308},
	abstract = {Engineering knowledge-based (or expert) systems require extensive manual effort and domain knowledge. As Large Language Models (LLMs) are trained using an enormous amount of cross-domain knowledge, it becomes possible to automate such engineering processes. This paper presents an empirical automation and semi-automation framework for domain knowledge distillation using prompt engineering and the LLM ChatGPT. We assess the framework empirically in the autonomous driving domain and present our key observations. In our implementation, we construct the domain knowledge ontology by “chatting” with ChatGPT. The key finding is that while fully automated domain ontology construction is possible, human supervision and early intervention typically improve efficiency and output quality as they lessen the effects of response randomness and the butterfly effect. We, therefore, also develop a web-based distillation assistant enabling supervision and flexible intervention at runtime. We hope our findings and tools could inspire future research toward revolutionizing the engineering of knowledge-based systems across application domains.},
	journal = {2023 IEEE 26th International Conference on Intelligent Transportation Systems (ITSC)},
	author = {Tang, Yun and Da Costa, Antonio A. Bruto and Zhang, Xizhe and Patrick, Irvine and Khastgir, Siddartha and Jennings, Paul},
	month = sep,
	year = {2023},
	note = {Section: 0},
	keywords = {large language model, Ontologies, Large language model, Ontology, Language model, Domain ontologies, Knowledge engineering, Autonomous vehicles, Intelligent transportation systems, Domain knowledge, Autonomous driving, Empirical studies, Computational linguistics, Cross-domain, Engineering knowledge, Chatbots, autonomous driving, Manuals, Runtime, domain ontology distillation, Domain Knowledge, Distillation, Domain ontology distillation, Knowledge experts, Cannot download},
	pages = {3893--3900},
	annote = {ISSN: 2153-0017}
}

@article{taye2023OntologyLearningFramework,
	title = {An {Ontology} {Learning} {Framework} for unstructured {Arabic} {Text}},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184808063&doi=10.1109%2FISAS60782.2023.10391548&partnerID=40&md5=383c7dfc97308ff44961706ab31047f2},
	doi = {10.1109/ISAS60782.2023.10391548},
	abstract = {Ontologies are widely regarded as valuable sources of semantics and interoperability in all artificially intelligent systems. Due to the rapid growth of unstructured data on the web, studying how to automatically get ontology from unstructured text is important. Therefore, ontology learning (OL) is an important process in the business world. It involves finding and extracting concepts from the text so that these concepts can be used for things such as information retrieval. Unfortunately, learning ontology is not easy for some reasons, and there has not been much research on how to automatically learn a domain-specific ontology from data.Ontology Studying Arabic text is not as developed as learning Latin text. There is almost no automated support for using Arabic literary knowledge in semantically enabled systems. Machine learning (ML) has proven beneficial in numerous fields, including text mining. By employing neural language models such as AraBERT, it is possible to obtain word embeddings as distributed word representations from textual input using machine learning. However, the application of machine learning to aid the development of Arabic ontology is largely unexplored. This research examines the performance of AraBERT for ontology learning tasks in Arabic. Early performance results as an application of Arabic ontology learning are promising. In this research, we provide a method for populating an existing ontology with instance information extracted from the input natural language text. This prototype has achieved an information extraction accuracy of 91\%.},
	journal = {2023 7th International Symposium on Innovative Approaches in Smart Technologies (ISAS)},
	author = {Taye, Mohammad Mustafa and Abulail, Rawan and Al-Oudat, Mohammad},
	month = nov,
	year = {2023},
	note = {Section: 0},
	keywords = {Ontologies, Interoperability, Ontology, Natural language processing, Ontology learning, Semantic Web, Semantics, Text mining, Semantic representation, Machine learning, Information retrieval, Arabic ontology, Data mining, Intelligent systems, Arabic Ontology, Language processing, Natural languages, Prototypes, Learning systems, Ontology Learning (OL), Natural language Processing (NLP), semantic representation, Ontology's, Natural language processing systems, Learning algorithms, Semantic-Web, Cannot download},
	pages = {1--12},
	annote = {Type: Conference paper}
}

@article{teclaw2025BuildingInformationModel,
	file = {References/pdf/teclaw2025BuildingInformationModel.pdf},
	title = {Building information model and schema cross-validation using semantics – conceptual framework},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105010599305&doi=10.1177%2F14780771251352954&partnerID=40&md5=e22edf984918c7575e8f14ed451fd433},
	doi = {10.1177/14780771251352954},
	abstract = {Ensuring consistency between Mechanical, Electrical, and Plumbing (MEP) schema drawings and Building Information Models (BIM) is essential for design accuracy and minimizing data discrepancies in construction projects. While BIM provides detailed 3D visualizations of building components, schematic drawings remain crucial for capturing the logical and functional relationships within early-stage designs. However, discrepancies between these two representations often arise, necessitating extensive manual verification. This study introduces a conceptual framework for automated cross-validation between MEP schema drawings and BIM models by leveraging semantic representations. The framework utilizes AI-driven technologies, particularly Large Language Models (LLMs), to extract structured knowledge from both schematics and BIM data, translating this information into machine-readable formats based on the Brick ontology. By integrating semantic web technologies and multimodal processing, the proposed framework effectively identifies inconsistencies in airflow distribution, system connectivity, and performance parameters. This approach significantly enhances the efficiency and accuracy of design validation, minimizes data discrepancies, and fosters interoperability among heterogeneous data sources. Initial findings demonstrate the scalability and effectiveness of semantic-based validation, suggesting substantial benefits for MEP-BIM integration. Future research will extend the framework to additional MEP domains, including electrical and plumbing systems, and further refine AI-based recognition methods. © 2025 Elsevier B.V., All rights reserved.},
	journal = {International Journal of Architectural Computing},
	author = {Teclaw, Wojciech and Łuczkowski, Marcin and Labonnote, Nathalie and Hjelseth, Eilif},
	year = {2025},
	note = {Section: 0},
	keywords = {Large language model, Interoperability, Ontology, Language model, Semantic Web, Semantics, Information theory, Validation, Building Information Modelling, Construction projects, Conceptual frameworks, Architectural design, Building Information Model, Data accuracy, and plumbing, Cross validation, electrical, Information schema, Mechanical, Three dimensional computer graphics},
	annote = {Type: Article}
}

@article{toro2024DynamicRetrievalAugmented,
	file = {References/pdf/toro2024DynamicRetrievalAugmented.pdf},
	title = {Dynamic {Retrieval} {Augmented} {Generation} of {Ontologies} using {Artificial} {Intelligence} ({DRAGON}-{AI})},
	volume = {15},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206568005&doi=10.1186%2Fs13326-024-00320-3&partnerID=40&md5=a23bb98318ff68a24095821e8384557b},
	doi = {10.1186/s13326-024-00320-3},
	abstract = {Background: Ontologies are fundamental components of informatics infrastructure in domains such as biomedical, environmental, and food sciences, representing consensus knowledge in an accurate and computable form. However, their construction and maintenance demand substantial resources and necessitate substantial collaboration between domain experts, curators, and ontology experts. We present Dynamic Retrieval Augmented Generation of Ontologies using AI (DRAGON-AI), an ontology generation method employing Large Language Models (LLMs) and Retrieval Augmented Generation (RAG). DRAGON-AI can generate textual and logical ontology components, drawing from existing knowledge in multiple ontologies and unstructured text sources. Results: We assessed performance of DRAGON-AI on de novo term construction across ten diverse ontologies, making use of extensive manual evaluation of results. Our method has high precision for relationship generation, but has slightly lower precision than from logic-based reasoning. Our method is also able to generate definitions deemed acceptable by expert evaluators, but these scored worse than human-authored definitions. Notably, evaluators with the highest level of confidence in a domain were better able to discern flaws in AI-generated definitions. We also demonstrated the ability of DRAGON-AI to incorporate natural language instructions in the form of GitHub issues. Conclusions: These findings suggest DRAGON-AI's potential to substantially aid the manual ontology construction process. However, our results also underscore the importance of having expert curators and ontology editors drive the ontology generation process. © 2024 Elsevier B.V., All rights reserved.},
	number = {1},
	journal = {Journal of Biomedical Semantics},
	author = {Toro, Sabrina and Anagnostopoulos, Anna V. and Bello, Susan M. and Blumberg, Kai Lewis and Cameron, Rhiannon and Carmody, Leigh C. and Diehl, Alexander D. and Dooley, Damion M. and Duncan, William D. and Fey, Petra},
	year = {2024},
	note = {Section: 0},
	keywords = {artificial intelligence, natural language processing, information retrieval, Natural Language Processing, Artificial Intelligence, Biological Ontologies, procedures, biological ontology, Information Storage and Retrieval},
	annote = {Type: Article}
}

@article{totoian2024HybridomOntologyMatching,
	file = {References/pdf/totoian2024HybridomOntologyMatching.pdf},
	title = {{HybridOM}: {Ontology} {Matching} using {Hybrid} {Search}},
	volume = {3897},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216388200&partnerID=40&md5=6c536aafb8b92a07ed02734fedb6f96c},
	abstract = {Ontology matching targets identical concepts from different ontologies with the final purpose of interoperability and ontologies merging. The matching task is not restricted to ontologies, it is also relevant for knowledge graphs. Ontology matching solutions based on transformer-based embeddings, textual similarity, logical mapping, or Large Language Models (LLMs) are still facing problems, mainly due to the lack of uniform information about the concepts and lack of homogeneous semantic granularity along different ontologies. In this work, we present a framework that combines vector-based similarity and string-based similarity through hybrid searches. LLMs are used to generate descriptions for ontology concepts, hence the concepts' representation is enriched and the alignment process can benefit from both the knowledge captured by the initial ontologies and the extended LLM-generated textual descriptions. The proposed system, HybridOM, is an unsupervised approach independent of the ontologies' domain. HybridOM is evaluated within Bio-ML 2024 track for the task of concept matching. It achieves the highest values for F1-score and Recall for most of the ontology pairs while maintaining a balance between precision and recall. The proposed method has been adapted for industrial usage in a human capital management product called msg.ProfileMap. © 2025 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Totoian, Marius Horatiu and Marginean, Anca Nicoleta and Blohm, Philipp and Hussain, Mir Nawab},
	year = {2024},
	note = {Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Large language model, Ontology, Language model, Semantics, Ontology matching, Ontology merging, Ontology's, Hybrid search, Human resource management, Vector database, Verbalization},
	pages = {138 -- 145},
	annote = {Type: Conference paper}
}

@article{trappey2025PatentLitigationMining,
	file = {References/pdf/trappey2025PatentLitigationMining.pdf},
	title = {Patent litigation mining using a large language model—{Taking} unmanned aerial vehicle development as the case domain},
	volume = {80},
	issn = {0172-2190},
	url = {https://www.sciencedirect.com/science/article/pii/S0172219024000723},
	doi = {https://doi.org/10.1016/j.wpi.2024.102332},
	abstract = {As unmanned aerial vehicle (UAV), also called “drone”, swiftly advances with innovative functions and applications, the surge in patent applications has profoundly reshaped the intellectual property (IP) landscape in the UAV industry, leading to a growing number of litigations. This study is structured in two phases, aiming to develop an intelligent approach to analyzing the trend and evolution of patent litigations. The first phase involves macro- and micro-patent analyses of the related technology domain. Macro patent analysis elucidates the fundamental patent information in the drone industry, while micro patent analysis leverages the technology function matrix (TFM) to identify R\&D hotspots and potentials. The second phase involves litigation (judgement) mining based on large language model (LLM). Beginning with the construction of a knowledge ontology, the domain infringement landscape can be detected through TFMs. A comparative analysis of the two-phase TFMs (i.e., both TFMs of patent and infringement allocations) is then conducted to pinpoint the key legal actions and the relevant technology. To drill deeper in infringement mining, dynamic topic modeling (DTM) is applied to analyze trends and dynamics in drone controller technology over time. This study aims to strengthen IP protection by developing an intelligent litigation mining approach that adopts large language model (LLM) and uses UAV/drone litigation studies as examples to show how the approach being applied in the industry.},
	journal = {World Patent Information},
	author = {Trappey, Amy J. C. and Chou, Shao-Chien and Li, Gi-Kuen J.},
	year = {2025},
	note = {Section: 0},
	keywords = {Large language model, Drone, Dynamic topic modeling, Patent analysis, Patent litigation mining, Technology function matrix, Unmanned aerial vehicle (UAV)},
	pages = {102332},
	annote = {Type: Article}
}

@article{tsaneva2024LlmDrivenOntology,
	file = {References/pdf/tsaneva2024LlmDrivenOntology.pdf},
	title = {{LLM}-driven {Ontology} {Evaluation}: {Verifying} {Ontology} {Restrictions} with {ChatGPT}},
	volume = {3747},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203385177&partnerID=40&md5=7ab507fcd01da145dd09b126148403a6},
	abstract = {Recent advancements in artificial intelligence, particularly in large language models (LLMs), have sparked interest in their application to knowledge engineering (KE) tasks. While existing research has primarily explored the utilisation of LLMs for constructing and completing semantic resources such as ontologies and knowledge graphs, the evaluation of these resources-addressing quality issues- has not yet been thoroughly investigated. To address this gap, we propose an LLM-driven approach for the verification of ontology restrictions. We replicate our previously conducted human-in-the-loop experiment using ChatGPT-4 instead of human contributors to assess whether comparable ontology verification results can be obtained. We find that (1) ChatGPT-4 achieves intermediate-to-expert scores on an ontology modelling qualification test; (2) the model performs ontology restriction verification with accuracy of 92.22\%; (3) combining model answers on the same ontology axiom represented in different formalisms improves the accuracy to 96.67\%; and (4) higher accuracy is observed in identifying defects related to the incompleteness of ontology axioms compared to errors due to restrictions misuse. Our results highlight the potential of LLMs in supporting knowledge engineering tasks and outline future research directions in the area. © 2024 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Tsaneva, Stefani and Vasic, Stefan and Sabou, Marta},
	year = {2024},
	note = {Section: 0},
	keywords = {Knowledge graph, Large language model, Ontology, Language model, Semantics, Modeling languages, Semantic resources, Defect detection, Model-driven, Ontology's, Ontology graphs, Ontology evaluations, Engineering tasks, Engineering research, Errors, Ontology axioms},
	pages = {15},
	annote = {Type: Conference paper}
}

@article{tsaneva2025BenchmarkingOntologyValidation,
	file = {References/pdf/tsaneva2025BenchmarkingOntologyValidation.pdf},
	title = {Benchmarking {Ontology} {Validation} {Capabilities} of {LLMs}},
	volume = {3953},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003709629&partnerID=40&md5=a794337d7764e3e883482385a1b47794},
	abstract = {With the advent of Generative AI, numerous approaches exploring large language models (LLMs) have been proposed for addressing a number of Knowledge Engineering (KE) tasks. Yet, the status of this research field is rather preliminary and there is, for now, no systematic and comprehensive understanding on how LLMs perform on selected knowledge engineering tasks (e.g., what is their expertise level in understanding ontology modeling concepts). Such insights would be crucial for researchers working in this field to support with selecting the most suitable LLMs during experiment design. This situation is exacerbated by the rapid expansion in the number of available LLMs. We therefore see the need for methodologies and tools that allow (comparatively) assessing LLM capabilities. To address this need, we propose the creation of an assessment test benchmark for evaluating the LLM knowledge engineering skills. We present ongoing work and preliminary results on assessing the expertise of LLMs in terms of a concrete KE task, namely ontology validation. Our experiments highlight the superiority of proprietary models on this task, particularly GPT-4o and Claude-Sonnet-3.5, over open source models. Lastly, we identify the need of a community-driven comparative LLM assessment platform that facilitates resource sharing and experience exchange, while protecting the integrity and privacy of the envisioned benchmark. We share (i) the current version of the qualification tests and (ii) its implementation for assessing LLM capabilities for ontology validation. © 2025 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Tsaneva, Stefani and Herwanto, Guntur Budi and Sabou, Marta},
	year = {2025},
	note = {Section: 0},
	keywords = {Large language model, Ontology model, Language model, Engineering tasks, Engineering research, Assessment test, Expertise evaluation, Modeling concepts, Ontology validations, Research fields, Validation capability},
	annote = {Type: Conference paper}
}

@article{tupayachi2024TowardsNextGeneration,
	file = {References/pdf/tupayachi2024TowardsNextGeneration.pdf},
	title = {Towards {Next}-{Generation} {Urban} {Decision} {Support} {Systems} through {AI}-{Powered} {Construction} of {Scientific} {Ontology} {Using} {Large} {Language} {Models}—{A} {Case} in {Optimizing} {Intermodal} {Freight} {Transportation}},
	volume = {7},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207278547&doi=10.3390%2Fsmartcities7050094&partnerID=40&md5=8aac4eff5a2cd83bba2ce13f8f44fd59},
	doi = {10.3390/smartcities7050094},
	abstract = {Highlights: What are the main findings? We have developed an integrated and automated methodology that leverages a pre-trained Large Language Model (LLM) to generate scenario-based ontologies and knowledge graphs from research articles and technical manuals. Our methodology utilizes the ChatGPT API as the primary reasoning engine, supplemented by Natural Language Processing modules and carefully engineered prompts. This combination enables an automated tool capable of generating ontologies independently. The ontologies generated through our AI-powered method are interoperable and can significantly facilitate the design of data models and software architecture, particularly in the development of urban decision support systems. What is the implication of the main finding? We compared ontologies generated by our LLM with those created by human experts through CQ-based qualitative evaluation, assessing the reliability and feasibility of our approach. The methodology has been successfully applied to intermodal freight data and simulations. This has allowed us to generate a scenario-based ontology and knowledge graph that enhances data discovery, integration, and management, thereby supporting network optimization and multiple criteria decision analysis. Our methodology is both generalizable and adaptive, enabling the automation of ontology generation to support the development of urban and environmental decision support systems across various disciplines. The incorporation of Artificial Intelligence (AI) models into various optimization systems is on the rise. However, addressing complex urban and environmental management challenges often demands deep expertise in domain science and informatics. This expertise is essential for deriving data and simulation-driven insights that support informed decision-making. In this context, we investigate the potential of leveraging the pre-trained Large Language Models (LLMs) to create knowledge representations for supporting operations research. By adopting ChatGPT-4 API as the reasoning core, we outline an applied workflow that encompasses natural language processing, Methontology-based prompt tuning, and Generative Pre-trained Transformer (GPT), to automate the construction of scenario-based ontologies using existing research articles and technical manuals of urban datasets and simulations. From these ontologies, knowledge graphs can be derived using widely adopted formats and protocols, guiding various tasks towards data-informed decision support. The performance of our methodology is evaluated through a comparative analysis that contrasts our AI-generated ontology with the widely recognized pizza ontology, commonly used in tutorials for popular ontology software. We conclude with a real-world case study on optimizing the complex system of multi-modal freight transportation. Our approach advances urban decision support systems by enhancing data and metadata modeling, improving data integration and simulation coupling, and guiding the development of decision support strategies and essential software components. © 2024 Elsevier B.V., All rights reserved.},
	number = {5},
	journal = {Smart Cities},
	author = {Tupayachi, Jose and Xu, Haowen and Omitaomu, Olufemi A. and Camur, Mustafa Can and Sharmin, Aliza and Li, Xueping},
	year = {2024},
	note = {Section: 0},
	pages = {2392 -- 2421},
	annote = {Type: Article}
}

@article{valcalvo2025OntogenixLeveragingLarge,
	file = {References/pdf/valcalvo2025OntogenixLeveragingLarge.pdf},
	title = {{OntoGenix}: {Leveraging} {Large} {Language} {Models} for enhanced ontology engineering from datasets},
	volume = {62},
	issn = {0306-4573},
	url = {https://www.sciencedirect.com/science/article/pii/S0306457324004011},
	doi = {https://doi.org/10.1016/j.ipm.2024.104042},
	abstract = {Knowledge Graphs integrate data from multiple, heterogeneous sources, using ontologies to facilitate data interoperability. Ontology development is a resource-consuming task that requires the collaborative work of domain experts and ontology engineers. Therefore, companies invest considerable resources in order to generate and maintain Enterprise Knowledge Graphs and ontologies from large and complex datasets, most of which can be unfamiliar for ontology engineers. In this work, we study the use of Large Language Models to aid in the development of ontologies from datasets, ultimately increasing the automation of the generation of ontology-based Knowledge Graphs. As a result we have developed a structured workflow that leverages Large Language Models to enhance ontology engineering through data pre-processing, ontology planning, building, and entity improvement. Our method is also able to generate mappings and RDF data, but in this work we focus on the ontologies. The pipeline has been implemented in the OntoGenix tool. In this work we show the results of the application of OntoGenix to six datasets related to commercial activities. The findings indicate that the ontologies produced exhibit patterns of coherent modeling, and features that closely resemble those created by humans, although the most complex situations are better reflected by the ontologies developed by humans.},
	number = {3},
	journal = {Information Processing \& Management},
	author = {Val-Calvo, Mikel and Aranguren, Mikel Egaña and Mulero-Hernández, Juan and Almagro-Hernández, Ginés and Deshmukh, Prashant and Bernabé-Díaz, José Antonio and Espinoza-Arias, Paola and Sánchez-Fernández, José Luis and Mueller, Juergen and Fernández-Breis, Jesualdo Tomás},
	year = {2025},
	note = {Section: 0},
	keywords = {Knowledge graphs, Large Language Models, Ontology engineering, Knowledge graph, Large language model, Language model, Data interoperability, Ontology development, Modeling languages, Ontology's, Data assimilation, Collaborative Work, Domain experts, Heterogeneous sources},
	pages = {104042},
	annote = {Type: Article}
}

@article{vieira2024TowardMethodGenerate,
	title = {Toward a {Method} to {Generate} {Capability} {Ontologies} from {Natural} {Language} {Descriptions}},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207822437&doi=10.1109%2FETFA61755.2024.10710783&partnerID=40&md5=102ee20eccf408c633442c86eed6632e},
	doi = {10.1109/ETFA61755.2024.10710783},
	abstract = {To achieve a flexible and adaptable system, capabil-ity ontologies are increasingly leveraged to describe functions in a machine-interpretable way. However, modeling such complex ontological descriptions is still a manual and error-prone task that requires a significant amount of effort and ontology expertise. This contribution presents an innovative method to automate capability ontology modeling using Large Language Models (LLMs), which have proven to be well suited for such tasks. Our approach requires only a natural language description of a capability, which is then automatically inserted into a predefined prompt using a few-shot prompting technique. After prompting an LLM, the resulting capability ontology is automatically verified through various steps in a loop with the LLM to check the overall correctness of the capability ontology. First, a syntax check is performed, then a check for contradictions, and finally a check for hallucinations and missing ontology elements. Our method greatly reduces manual effort, as only the initial natural language description and a final human review and possible correction are necessary, thereby streamlining the capability ontology generation process.},
	journal = {2024 IEEE 29th International Conference on Emerging Technologies and Factory Automation (ETFA)},
	author = {Vieira da Silva, Luis Miguel and Kocher, Aljosha and Gehlhoff, Felix and Fay, Alexander},
	month = sep,
	year = {2024},
	note = {Section: 0},
	keywords = {Ontologies, Large Language Models, Large language model, Ontology, Language model, Large language models, Semantic Web, Semantics, Modeling languages, LLMs, Model generation, Reviews, Skill, Skills, Testing, Manuals, Natural languages, Syntactics, Adaptation models, Costs, Manufacturing automation, Capabilities, Model-Generation, Ontology's, Natural language processing systems, Semantic-Web, Capability, Cannot download},
	pages = {1--4},
	annote = {ISSN: 1946-0759}
}

@article{vieira2024UseLargeLanguage,
	title = {On the {Use} of {Large} {Language} {Models} to {Generate} {Capability} {Ontologies}},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197107836&doi=10.1109%2FETFA61755.2024.10710775&partnerID=40&md5=544ef7ed4c7c396646d5da759dd60db8},
	doi = {10.1109/ETFA61755.2024.10710775},
	abstract = {Capability ontologies are increasingly used to model functionalities of systems or machines. The creation of such onto-logical models with all properties and constraints of capabilities is very complex and can only be done by ontology experts. However, Large Language Models (LLMs) have shown that they can generate machine-interpretable models from natural language text input and thus support engineers / ontology experts. Therefore, this paper investigates how LLMs can be used to create capability ontologies. We present a study with a series of experiments in which capabilities with varying complexities are generated using different prompting techniques and with different LLMs. Errors in the generated ontologies are recorded and compared. To analyze the quality of the generated ontologies, a semi-automated approach based on RDF syntax checking, OWL reasoning, and SHACL constraints is used. The results of this study are very promising because even for complex capabilities, the generated ontologies are almost free of errors.},
	journal = {2024 IEEE 29th International Conference on Emerging Technologies and Factory Automation (ETFA)},
	author = {Vieira da Silva, Luis Miguel and Kocher, Aljosha and Gehlhoff, Felix and Fay, Alexander},
	month = sep,
	year = {2024},
	note = {Section: 0},
	keywords = {Ontologies, Large Language Models, Large language model, Ontology, Language model, Large language models, Semantic Web, Semantics, OWL, Resource description framework, LLMs, Cognition, Model generation, Skill, Computational linguistics, Skills, Complexity theory, Testing, Logical models, Natural languages, Shape, Syntactics, Capabilities, Model-Generation, Ontology's, Natural language processing systems, Semantic-Web, Capability, Cannot download},
	pages = {1--8},
	annote = {ISSN: 1946-0759}
}

@article{vrolijk2024OntologyLearningEsco,
	file = {References/pdf/vrolijk2024OntologyLearningEsco.pdf},
	title = {Ontology {Learning} for {ESCO}: {Leveraging} {LLMs} to {Navigate} {Labor} {Dynamics}},
	volume = {3853},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212710838&partnerID=40&md5=c99afbb428f4560ed7610a55af6ef3b2},
	abstract = {The labor market is a dynamic environment that supports numerous knowledge-driven applications through ontologies, such as ESCO and O*NET. Maintaining the relevance and accuracy of information within these ontologies and taxonomies is both resource-intensive and time-consuming. In this paper, we propose an ontology learning system that utilizes self-supervised learning, retrieval-augmented generation, and autoregressive language models to identify, classify, and link labor market mentions and entities from raw job postings. Additionally, we demonstrate the language model's ability to discover "alternative labels" and "preferred labels", and perform relation classification. © 2024 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Vrolijk, Jarno and Poslavsky, Victor and Bijl, Thijmen and Popov, Maksim and Mahdavi, Rana and Shokri, Mohammad},
	year = {2024},
	note = {Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Ontology, Natural language processing, Language model, Ontology learning, Self-supervised learning, Semi-supervised learning, Language processing, Adversarial machine learning, Natural languages, Ontology's, Labour market, Wages, Commerce, Dynamic environments, Labor dynamics},
	annote = {Type: Conference paper}
}

@article{vukovic2024DialogueOntologyRelation,
	file = {References/pdf/vukovic2024DialogueOntologyRelation.pdf},
	title = {Dialogue {Ontology} {Relation} {Extraction} via {Constrained} {Chain}-of-{Thought} {Decoding}},
	url = {https://aclanthology.org/2024.sigdial-1.33/},
	doi = {10.18653/v1/2024.sigdial-1.33},
	abstract = {State-of-the-art task-oriented dialogue systems typically rely on task-specific ontologies for fulfilling user queries. The majority of task-oriented dialogue data, such as customer service recordings, comes without ontology and annotation. Such ontologies are normally built manually, limiting the application of specialised systems. Dialogue ontology construction is an approach for automating that process and typically consists of two steps: term extraction and relation extraction. In this work, we focus on relation extraction in a transfer learning set-up. To improve the generalisation, we propose an extension to the decoding mechanism of large language models. We adapt Chain-of-Thought (CoT) decoding, recently developed for reasoning problems, to generative relation extraction. Here, we generate multiple branches in the decoding space and select the relations based on a confidence threshold. By constraining the decoding to ontology terms and relations, we aim to decrease the risk of hallucination. We conduct extensive experimentation on two widely used datasets and find improvements in performance on target ontology for source fine-tuned and one-shot prompted large language models.},
	journal = {Proceedings of the 25th Annual Meeting of the Special Interest Group on Discourse and Dialogue},
	author = {Vukovic, Renato and Arps, David and van Niekerk, Carel and Ruppik, Benjamin Matthias and Lin, Hsien-chin and Heck, Michael and Gasic, Milica},
	editor = {Kawahara, Tatsuya and Demberg, Vera and Ultes, Stefan and Inoue, Koji and Mehri, Shikib and Howcroft, David and Komatani, Kazunori},
	month = sep,
	year = {2024},
	note = {Place: Kyoto, Japan
Publisher: Association for Computational Linguistics
Section: 0},
	pages = {370--384}
}

@article{wang2022AmdResultsOaei,
	file = {References/pdf/wang2022AmdResultsOaei.pdf},
	title = {{AMD} {Results} for {OAEI} 2022},
	volume = {3324},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85146423755&partnerID=40&md5=5d40e36481c36d7e9d14b4536f18bebe},
	abstract = {AgreementMakerDeep (AMD) is a new flexible and extensible ontology matching system. It exploits the contextual and structural information of ontologies by infusing knowledge to pre-trained masked language model, and then filter the output mappings using knowledge graph embedding techniques. AMD learns from classes and their relations between classes by constructing vector representations into the low dimensional embedding space with knowledge graph embedding methods. The results demonstrate that AMD achieves a competitive performance in many OAEI tracks, but AMD has limitations for property and instance matching. © 2023 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Wang, Zhu},
	year = {2022},
	note = {Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Ontology, Language model, Ontology matching, Computational linguistics, Graph embeddings, Knowledge graph embedding, Pre-train language model, Ontology's, Matching system, Vector spaces, Structural information, Contextual information},
	pages = {145 -- 152},
	annote = {Type: Conference paper}
}

@article{wang2023AmdResultsOaei,
	file = {References/pdf/wang2023AmdResultsOaei.pdf},
	title = {{AMD} {Results} for {OAEI} 2023},
	volume = {3591},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180779638&partnerID=40&md5=5de524163e7e345de6e2c5ebd3bde262},
	abstract = {AgreementMakerDeep (AMD) is a new flexible and extensible ontology matching system. It exploits the contextual and structural information of ontologies by infusing knowledge to pre-trained masked language model, and then filter the output mappings using knowledge graph embedding techniques. AMD learns from classes and their relations between classes by constructing vector representations into the low dimensional embedding space with knowledge graph embedding methods. The results demonstrate that AMD achieves a competitive performance in many OAEI tracks, but AMD has limitations for property and instance matching. © 2024 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Wang, Zhu},
	year = {2023},
	note = {Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Large language model, Ontology, Language model, Ontology matching, Computational linguistics, Graph embeddings, Knowledge graph embedding, Ontology's, Matching system, Vector spaces, Structural information, Contextual information},
	pages = {146 -- 153},
	annote = {Type: Conference paper}
}

@article{wang2023ContextualizedStructuralSelf,
	file = {References/pdf/wang2023ContextualizedStructuralSelf.pdf},
	title = {Contextualized {Structural} {Self}-supervised {Learning} for {Ontology} {Matching}},
	volume = {3591},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180754259&partnerID=40&md5=3cffc4029e8fbfd6858798439a8e6d9b},
	abstract = {Ontology matching (OM) entails the identification of semantic relationships between concepts within two or more knowledge graphs (KGs) and serves as a critical step in integrating KGs from various sources. Recent advancements in deep OM models have harnessed the power of transformer-based language models and the advantages of knowledge graph embedding. Nevertheless, these OM models still face persistent challenges, such as a lack of reference alignments, runtime latency, and unexplored different graph structures within an end-to-end framework. In this study, we introduce a novel self-supervised learning OM framework with input ontologies, called LaKERMap. This framework capitalizes on the contextual and structural information of concepts by integrating implicit knowledge into transformers. Specifically, we aim to capture multiple structural contexts, encompassing both local and global interactions, by employing distinct training objectives. To assess our methods, we utilize the Bio-ML datasets and tasks. The findings from our innovative approach reveal that LaKERMap surpasses state-of-the-art systems in terms of alignment quality and inference time. Our models and codes are available here https://github.com/ellenzhuwang/lakermap. © 2024 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Wang, Zhu},
	year = {2023},
	note = {Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Ontology, Semantics, Ontology matching, Semantic relationships, Graph embeddings, Power, Self-supervised learning, Supervised learning, Knowledge graph embedding, Graphic methods, Relationship between concepts, Critical steps, Matching models},
	pages = {37 -- 48},
	annote = {Type: Conference paper}
}

@article{wang2024CanLargeLanguage,
	file = {References/pdf/wang2024CanLargeLanguage.pdf},
	title = {Can {Large} {Language} {Models} {Understand} {DL}-{Lite} {Ontologies}? {An} {Empirical} {Study}},
	url = {https://aclanthology.org/2024.findings-emnlp.141/},
	doi = {10.18653/v1/2024.findings-emnlp.141},
	abstract = {Large language models (LLMs) have shown significant achievements in solving a wide range of tasks. Recently, LLMs' capability to store, retrieve and infer with symbolic knowledge has drawn a great deal of attention, showing their potential to understand structured information. However, it is not yet known whether LLMs can understand Description Logic (DL) ontologies. In this work, we empirically analyze the LLMs' capability of understanding DL-Lite ontologies covering 6 representative tasks from syntactic and semantic aspects. With extensive experiments, we demonstrate both the effectiveness and limitations of LLMs in understanding DL-Lite ontologies. We find that LLMs can understand formal syntax and model-theoretic semantics of concepts and roles. However, LLMs struggle with understanding TBox NI transitivity and handling ontologies with large ABoxes. We hope that our experiments and analyses provide more insights into LLMs and inspire to build more faithful knowledge engineering solutions.},
	journal = {Findings of the Association for Computational Linguistics: EMNLP 2024},
	author = {Wang, Keyu and Qi, Guilin and Li, Jiaqi and Zhai, Songlin},
	editor = {Al-Onaizan, Yaser and Bansal, Mohit and Chen, Yun-Nung},
	month = nov,
	year = {2024},
	note = {Place: Miami, Florida, USA
Publisher: Association for Computational Linguistics
Section: 0},
	keywords = {Ontology, Language model, Semantics, Knowledge engineering, Description logic, Empirical studies, Computational linguistics, Latent semantic analysis, Formal modeling, Syntactics, Ontology's, Structured information, Experiment and analysis, Formal syntaxes, Model-theoretic semantics, Symbolic knowledge},
	pages = {2503--2519},
	annote = {Type: Conference paper}
}

@article{wang2024ResearchKnowledgeGraph,
	title = {Research on {Knowledge} {Graph} {Extraction} {Methods} for {Chinese} {STEM} {Curriculum}},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215598070&doi=10.1109%2FMLNLP63328.2024.10800180&partnerID=40&md5=6e0a74fed87abe5a73acc1ed74985a8b},
	doi = {10.1109/MLNLP63328.2024.10800180},
	abstract = {STEM education, as an innovative teaching model, has gained widespread attention in recent years. However, the lack of relevant textbooks and learning resources has made its implementation challenging. Developing interdisciplinary knowledge graphs tailored for STEM education has become an urgent issue. To address this, a knowledge extraction framework named Llms4edu is proposed, which utilizes a series of effective prompts to guide large language models in knowledge extraction. Specifically, the knowledge extraction task is transformed into multiple rounds of question-and-answer interactions with the LLM, gradually identifying entity-relation triplets from subject data. Through experiments, an F1-score of 89.4\% was achieved on the named entity recognition task in the chemistry subject, and an F1-score of 66.7\% on the relation extraction task. Finally, a subject ontology model was built for subject text, and a subject data set was constructed using Llms4edu, which includes three subjects of junior high school mathematics, physics, and chemistry, a total of 2,511 entities, 2,010 relationship triples, and cross-disciplinary knowledge is linked to construct a cross-disciplinary knowledge graph.},
	journal = {2024 7th International Conference on Machine Learning and Natural Language Processing (MLNLP)},
	author = {Wang, Changlong and Sang, Xiujuan and Wang, Xijie and Gao, Yuan and Liu, Yi},
	month = oct,
	year = {2024},
	note = {Section: 0},
	keywords = {large language model, Ontologies, Knowledge graphs, Knowledge graph, Large language model, Language model, Named entity recognition, Large language models, Knowledge extraction, Knowledge engineering, Annotations, Data mining, Prompt engineering, prompt engineering, Training, Federated learning, STEM education, Adversarial machine learning, Chemistry, interdisciplinary knowledge graph, Physics, Contrastive Learning, F1 scores, Graph extractions, Cross-disciplinary, Interdisciplinary knowledge graph, Cannot download},
	pages = {1--8},
	annote = {Type: Conference paper}
}

@article{wei2025KnowledgeEnhancedOntology,
	file = {References/pdf/wei2025KnowledgeEnhancedOntology.pdf},
	title = {Knowledge-enhanced ontology-to-vector for automated ontology concept enrichment in {BIM}},
	volume = {45},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000158606&doi=10.1016%2Fj.jii.2025.100836&partnerID=40&md5=69dfeed55bf716337ecd255e2daf40be},
	doi = {10.1016/j.jii.2025.100836},
	abstract = {Building Information Modeling (BIM) relies on standardized ontologies like IfcOWL to address interoperability. However, the increasing complexity and diversity of construction information requirements demand automated enrichment of BIM ontologies, which is hindered by several factors, including complexity in ontology structure, scalability limitations, and domain-specific issues. Manual curation and maintenance of ontologies are labor-intensive and time-consuming, particularly as the scope of BIM projects expands. Despite these challenges, the construction industry lacks an effective automated approach for ontology concept enrichment. Thus, this study proposes a knowledge-enhanced ontology-to-vector (Keno2Vec) approach for automated BIM ontology concept enrichment, which can (1) encode ontology elements into meaningful and semantically rich embeddings by employing the BERT model to integrate both ontological information (names and labels) and external knowledge (definitions from authoritative knowledge bases), effectively addressing the domain expression specificity and complexity of BIM ontologies; and (2) provide a flexible framework that supports various downstream tasks of ontology concept enrichment by utilizing the resulting embeddings, thereby improving the task-specific adaptability and variability. Experimental results on datasets derived from the large-scale ifcOWL and two smaller BIM ontologies demonstrate that Keno2Vec significantly outperforms existing ontology embedding approaches in terms of accuracy and adaptability. For example, Keno2Vec achieves F1 scores on ifcOWL of nearly 87 \% for subsumption prediction, 60 \% for property identification, 95 \% for membership recognition, and 100 \% and 90 \% for category-based and schema-based concept classification, respectively. Additional analysis highlights the potential of Keno2Vec for improving BIM ontology encoding and benefiting downstream applications. © 2025 Elsevier B.V., All rights reserved.},
	journal = {Journal of Industrial Information Integration},
	author = {Wei, Yinyi and Li, Xiao},
	year = {2025},
	note = {Section: 0},
	keywords = {Ontology, Natural language processing, Language model, Pre-trained language model, Semantics, Ontology concept enrichment, Ontology embedding, Semantic representation, Modeling languages, Embeddings, Building Information Modelling, Language processing, Natural languages, Ontology's, Natural language processing systems, Building information modeling ontology, Encoding (symbols), Ontology concepts},
	annote = {Type: Article}
}

@article{wu2023DoPlmsKnow,
	file = {References/pdf/wu2023DoPlmsKnow.pdf},
	title = {Do {PLMs} {Know} and {Understand} {Ontological} {Knowledge}?},
	volume = {1},
	url = {https://aclanthology.org/2023.acl-long.173/},
	doi = {10.18653/v1/2023.acl-long.173},
	abstract = {Ontological knowledge, which comprises classes and properties and their relationships, is integral to world knowledge. It is significant to explore whether Pretrained Language Models (PLMs) know and understand such knowledge. However, existing PLM-probing studies focus mainly on factual knowledge, lacking a system- atic probing of ontological knowledge. In this paper, we focus on probing whether PLMs store ontological knowledge and have a semantic un- derstanding of the knowledge rather than rote memorization of the surface form. To probe whether PLMs know ontological knowledge, we investigate how well PLMs memorize: (1) types of entities; (2) hierarchical relationships among classes and properties, e.g., Person is a subclass of Animal and Member of Sports Team is a subproperty of Member of ; (3) domain and range constraints of properties, e.g., the subject of Member of Sports Team should be a Person and the object should be a Sports Team. To further probe whether PLMs truly understand ontological knowledge beyond memorization, we comprehensively study whether they can reliably perform logical reasoning with given knowledge according to ontological entailment rules. Our probing results show that PLMs can memorize certain ontological knowledge and utilize implicit knowledge in reasoning. How- ever, both the memorizing and reasoning per- formances are less than perfect, indicating in- complete knowledge and understanding.},
	journal = {Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
	author = {Wu, Weiqi and Jiang, Chengyue and Jiang, Yong and Xie, Pengjun and Tu, Kewei},
	editor = {Rogers, Anna and Boyd-Graber, Jordan and Okazaki, Naoaki},
	month = jul,
	year = {2023},
	note = {Place: Toronto, Canada
Publisher: Association for Computational Linguistics
Section: 0},
	keywords = {Ontology, Language model, Semantics, Factual knowledge, Computational linguistics, Logical reasoning, Sports, Property, Implicit knowledge, Semantics understanding, Surface forms, World knowledge, Domain constraint, Range constraints},
	pages = {3080--3101},
	annote = {Type: Conference paper}
}

@article{wu2024OntologyExtensionBy,
	file = {References/pdf/wu2024OntologyExtensionBy.pdf},
	title = {Ontology extension by online clustering with large language model agents},
	volume = {7},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206991474&doi=10.3389%2Ffdata.2024.1463543&partnerID=40&md5=4a013d00d9628be6b3bacdc7b5c1de48},
	doi = {10.3389/fdata.2024.1463543},
	abstract = {An ontology is a structured framework that categorizes entities, concepts, and relationships within a domain to facilitate shared understanding, and it is important in computational linguistics and knowledge representation. In this paper, we propose a novel framework to automatically extend an existing ontology from streaming data in a zero-shot manner. Specifically, the zero-shot ontology extension framework uses online and hierarchical clustering to integrate new knowledge into existing ontologies without substantial annotated data or domain-specific expertise. Focusing on the medical field, this approach leverages Large Language Models (LLMs) for two key tasks: Symptom Typing and Symptom Taxonomy among breast and bladder cancer survivors. Symptom Typing involves identifying and classifying medical symptoms from unstructured online patient forum data, while Symptom Taxonomy organizes and integrates these symptoms into an existing ontology. The combined use of online and hierarchical clustering enables real-time and structured categorization and integration of symptoms. The dual-phase model employs multiple LLMs to ensure accurate classification and seamless integration of new symptoms with minimal human oversight. The paper details the framework's development, experiments, quantitative analyses, and data visualizations, demonstrating its effectiveness in enhancing medical ontologies and advancing knowledge-based systems in healthcare. © 2024 Elsevier B.V., All rights reserved.},
	journal = {Frontiers in Big Data},
	author = {Wu, Guanchen and Ling, Chen and Graetz, Ilana and Zhao, Liang},
	year = {2024},
	note = {Section: 0},
	annote = {Type: Article}
}

@article{wu2025TaxonomyInferenceTabular,
	file = {References/pdf/wu2025TaxonomyInferenceTabular.pdf},
	title = {Taxonomy {Inference} for {Tabular} {Data} {Using} {Large} {Language} {Models}},
	volume = {15718},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105008012410&doi=10.1007%2F978-3-031-94575-5_22&partnerID=40&md5=59fb679fd3a86e06b779edbbdc66d3bd},
	doi = {10.1007/978-3-031-94575-5_22},
	abstract = {Taxonomy inference for tabular data is a critical task of schema inference, aiming at discovering entity types (i.e., concepts) of the tables and building their hierarchy. It can play an important role in data management, data exploration, ontology learning, and many data-centric applications. Existing schema inference systems focus more on XML, JSON or RDF data, and often rely on lexical formats and structures of the data for calculating similarities, with limited exploitation of the semantics of the text across a table. Motivated by recent works on taxonomy completion and construction using Large Language Models (LLMs), this paper presents two LLM-based methods for taxonomy inference for tables: (i) EmTT which embeds columns by fine-tuning with contrastive learning encoder-alone LLMs like BERT and utilises clustering for hierarchy construction, and (ii) GeTT which generates table entity types and their hierarchy by iterative prompting using a decoder-alone LLM like GPT-4. Extensive evaluation on three real-world datasets with six metrics covering different aspects of the output taxonomies has demonstrated that EmTT and GeTT can both produce taxonomies with strong consistency relative to the Ground Truth. © 2025 Elsevier B.V., All rights reserved.},
	journal = {Lecture Notes in Computer Science},
	author = {Wu, Zhenyu and Chen, Jiaoyan and Paton, Norman W.},
	year = {2025},
	note = {Section: 0},
	keywords = {Large language model, Ontology, Language model, Semantics, Information management, Taxonomies, Data mining, Prompt learning, Computational linguistics, Data exploration, Tabular data, Learning systems, Critical tasks, Entity-types, Management data, Schema inference, Taxonomy inference},
	pages = {403 -- 422},
	annote = {Type: Conference paper}
}

@article{xiang2025GEtiIncorporating,
	file = {References/pdf/xiang2025GEtiIncorporating.pdf},
	title = {G-{ETI}: {Incorporating} {Graph} {Information} for {Improved} {Unsupervised} {Event} {Type} {Induction}},
	volume = {15437},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211910786&doi=10.1007%2F978-981-96-0567-5_31&partnerID=40&md5=978fdc6d4dfee4a7c17c2c5cf2e73151},
	doi = {10.1007/978-981-96-0567-5_31},
	abstract = {An event ontology is useful for the semantic integration of heterogeneous datasets related to events. To reduce manual efforts in event ontology construction, several Event-Type Induction (ETI) methods were proposed to automatically find new event types from a given data source. Existing ETI methods utilize a corpus-based data source, and achieve the ETI goal via document clustering over pre-trained neural text embeddings. Most of the ETI methods require a semi-supervised setting to obtain a satisfactory result. In this paper, we improve ETI performance by incorporating graph-based data sources, which usually consists of event nodes, participant subjects/objects and the relational edges. Our motivation is that event type information learned from an event graph can complement that learned from text. This idea leads to the Graph-ETI (G-ETI) algorithm, where event clusters are initially identified from text embeddings and later refined through graph-based label propagation. Our algorithm naturally supports the unsupervised ETI setting where no event types are known beforehand. Moreover, we also provide an LLM-based naming module to generate appropriate names for the new event clusters. In the experiment, our method exhibits better event clustering performance compared to existing baselines, especially in the unsupervised setting. These improved clustering assignments combined with our LLM naming module can lead to high-quality ETI capability, which facilitates the event ontology construction process. © 2024 Elsevier B.V., All rights reserved.},
	journal = {Lecture Notes in Computer Science},
	author = {Xiang, Lingzhi and Li, Qing and Li, Xiang and Diao, Xingchun},
	year = {2025},
	note = {Section: 0},
	keywords = {Ontology, Semantics, Event ontology, Embeddings, Ontology construction, Performance, Graph embeddings, Graph algorithms, Data-source, Event graphs, Event ontology construction, Event Types, Event-type induction, Induction method},
	pages = {443 -- 455},
	annote = {Type: Conference paper}
}

@article{xiang2025KnowledgeGraphBased,
	file = {References/pdf/xiang2025KnowledgeGraphBased.pdf},
	title = {A {Knowledge} {Graph}-{Based} {Approach} for {Construction} {Safety} {Hazards} {Management} and {Rectification} {Measures} {Intelligent} {Recommendation}},
	volume = {630},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105000670719&doi=10.1007%2F978-3-031-84224-5_10&partnerID=40&md5=5fd09180629d082b432de3a2b2457b35},
	doi = {10.1007/978-3-031-84224-5_10},
	abstract = {Identification and rectification of safety hazards are crucial for the safety management of a construction site. However, the absence of structured knowledge necessitates a heavy reliance on experienced managers or experts for construction safety management. This dependence on manual formulation of rectification measures results in inefficient safety management and underutilization of data value. This study proposes a knowledge graph based approach for the safety hazards inspections and recommendation of rectification measures, which consists of four steps: (1) constructing the semantic expression framework of safety hazard ontology for information extraction; (2) extracting entities from textual and semi-structured data using a large language model (ChatGLM-6B); (3) knowledge fusion and inference; (4) storing structured knowledge and developing semantic retrieval and safety hazard rectification measures recommendation. The proposed method was validated in a hydropower project, where a knowledge graph of safety hazards was constructed, consisting of 108,000 entities and 121 relationships. The results demonstrate that this method can automatically provide targeted rectification measures for safety hazards such as fire, falls from heights, scaffold collapse and electric shock. This work can provide a practical reference for improving the effectiveness of the construction project safety management. © 2025 Elsevier B.V., All rights reserved.},
	journal = {Lecture Notes in Civil Engineering},
	author = {Xiang, Yunfei and Lin, Peng and Luo, Yiming and Xu, Houlei and Ning, Zeyu and Qiao, Yu and Zhou, Mengxia},
	year = {2025},
	note = {Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Project management, Semantics, Information management, Construction safety, Safety management, Graph-based, Structured knowledge, Scaffolds, Construction sites, Data values, Hazard management, Intelligent recommendation, Safety hazards},
	pages = {133 -- 141},
	annote = {Type: Conference paper}
}

@article{xie2024OntologyEmbeddingsSubsumption,
	title = {Ontology {Embeddings} for {Subsumption} {Prediction} {Based} on {Graph} {Language} {Model}},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105007428875&doi=10.1109%2FDSInS64146.2024.10992171&partnerID=40&md5=2b1f28e91fc4db4db48fd3da725f8872},
	doi = {10.1109/DSInS64146.2024.10992171},
	abstract = {With the growing importance of knowledge graphs in artificial intelligence, accurately modeling hierarchical relationships in ontologies has become a critical issue in knowledge representation learning. To address this, this paper proposes an ontology embedding framework based on graph language models, named GLMSubs, aimed at enhancing the prediction of subclass relationships. The GLMSubs framework adopts a two-stage strategy of “multi-semantic view partitioning” and “advanced training of graph language models”. Initially, it deconstructs the ontology's concepts, attributes, and instance information into five types of semantic views, such as class hierarchy view and class-attribute relationship view, through a multi-view partitioning mechanism, comprehensively capturing information from different semantic dimensions. Subsequently, the framework employs graph language models for joint training on the multi-view data to obtain embeddings that integrate both semantic and structural information. Experiments on datasets such as FoodOn and GO validate the effectiveness of GLMSubs, demonstrating that its performance in class hierarchy relationship prediction tasks significantly surpasses existing methods.},
	journal = {2024 4th International Conference on Digital Society and Intelligent Systems (DSInS)},
	author = {Xie, Jiangcun and Li, Ren and Yang, Jianxi and Xiao, Qiao},
	month = nov,
	year = {2024},
	note = {Section: 0},
	keywords = {Ontologies, Knowledge graphs, Knowledge graph, Language model, Semantics, OWL ontology, OWL, Resource description framework, knowledge graph, Embeddings, Knowledge representation learning, Training, Proteins, Biological system modeling, Predictive models, Medical services, graph language models, knowledge representation learning, Ontology's, Knowledge-representation, Image representation, Graph languages, OWL ontologies, Graph language model, Semantic views, Cannot download},
	pages = {133--137},
	annote = {Type: Conference paper {\textbar} RAYYAN-LABELS: Good for referencing}
}

@article{xilong2025LeveragingLargeLanguage,
	file = {References/pdf/xilong2025LeveragingLargeLanguage.pdf},
	title = {Leveraging large language models for classification of cultural heritage domain terms: {A} case study on {CIDOC} {CRM}},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105001112222&doi=10.1145%2F3677389.3702562&partnerID=40&md5=1bdc8619fb50a59d64cd1ccdbdf3d972},
	doi = {10.1145/3677389.3702562},
	abstract = {Large language models (LLMs) have recently revolutionized human language understanding and generation. Ontology is considered one of the primary cornerstones for representing knowledge in a more meaningful way on the semantic web. It s significant to explore whether LLMs know and understand such ontological knowledge. In this paper, we report an experiment to investigate the performance of LLMs in the task of classifying cultural heritage domain terms to upper-level ontology. We first probed the understanding and memorization of CIDOC CRM ontological knowledge by LLMs. Then, we further leverage LLMs to classify domain terms into the structure of CRM, and compare the match type with experts. Our initial findings indicate that LLMs demonstrate a certain level of awareness and comprehension of CIDOC CRM ontological knowledge. LLMs have shown potential as valuable assistants in enhancing ontology engineering and knowledge-intensive tasks. © 2025 Elsevier B.V., All rights reserved.},
	journal = {Proceedings of the ACM/IEEE Joint Conference on Digital Libraries},
	author = {Xilong, Hou and Junhan, Zang and Wang, Xiaoguang},
	year = {2025},
	note = {Section: 0},
	keywords = {Large language model, Ontology, Language model, Semantics, Language understanding, History, CIDOC CRM, Domain Knowledge, Ontology's, Classification (of information), Economic and social effects, Human language, Case-studies, Cultural heritages, Ontological knowledge probing, Term classification},
	annote = {Type: Conference paper}
}

@article{xiong2025EnhancingPatentMatching,
	file = {References/pdf/xiong2025EnhancingPatentMatching.pdf},
	series = {{SIGIR} '25},
	title = {Enhancing the {Patent} {Matching} {Capability} of {Large} {Language} {Models} via the {Memory} {Graph}},
	url = {https://doi.org/10.1145/3726302.3729970},
	doi = {10.1145/3726302.3729970},
	abstract = {Intellectual Property (IP) management involves strategically protecting and utilizing intellectual assets to enhance organizational innovation, competitiveness, and value creation. Patent matching is a crucial task in intellectual property management, which facilitates the organization and utilization of patents. Existing models often rely on the emergent capabilities of Large Language Models (LLMs) and leverage them to identify related patents directly. However, these methods usually depend on matching keywords and overlook the hierarchical classification and categorical relationships of patents. In this paper, we propose MemGraph, a method that augments the patent matching capabilities of LLMs by incorporating a memory graph derived from their parametric memory. Specifically, MemGraph prompts LLMs to traverse their memory to identify relevant entities within patents, followed by attributing these entities to corresponding ontologies. After traversing the memory graph, we utilize extracted entities and ontologies to improve the capability of LLM in comprehending the semantics of patents. Experimental results on the PatentMatch dataset demonstrate the effectiveness of MemGraph, achieving a 17.68\% performance improvement over baseline LLMs. The further analysis highlights the generalization ability of MemGraph across various LLMs, both in-domain and out-of-domain, and its capacity to enhance the internal reasoning processes of LLMs during patent matching. All data and codes are available at https://github.com/NEUIR/MemGraph.},
	journal = {Proceedings of the 48th International ACM SIGIR Conference on Research and Development in Information Retrieval},
	author = {Xiong, Qiushi and Xu, Zhipeng and Liu, Zhenghao and Wang, Mengjia and Chen, Zulong and Sun, Yue and Gu, Yu and Li, Xiaohua and Yu, Ge},
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery
Section: 0},
	keywords = {Large language model, Ontology, Language model, Semantics, large language models, Retrieval-augmented generation, retrieval-augmented generation, memory graph, patent matching, Ontology's, Copyrights, Intellectual assets, Intellectual property management, Matchings, Memory graph, Organizational innovation, Patent matching, Patents and inventions},
	pages = {337--347},
	annote = {event-place: Padua, Italy}
}

@article{yang2024LlmSupportedApproach,
	title = {An {LLM} supported approach to ontology and knowledge graph construction},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217280910&doi=10.1109%2FBIBM62325.2024.10822222&partnerID=40&md5=5fb25a53e38880819cbef3caab99f1a6},
	doi = {10.1109/BIBM62325.2024.10822222},
	abstract = {The continuous development in the medical field faces multiple challenges in managing a large amount of literature and research results using traditional ontology and knowledge graph construction methods. These challenges include high labor costs, limited coverage, and poor dynamism of traditional ontology and knowledge graph construction methods. Large language models (LLMs) can solve various natural language processing tasks and can understand and generate human-like natural language, which makes automated construction of ontology expansion and knowledge graphs (KGs) possible. This paper proposes an ontology expansion method based on LLMs, using LLMs to formulate competency questions (CQs) to extend the initial ontology, and then constructing the knowledge graph based on the extended ontology. We demonstrated the feasibility of the method by creating a knowledge graph for breast cancer treatment. The combination of LLMs-based medical ontology and knowledge graph can achieve more efficient medical knowledge management and application, promoting the informatization and intelligent development of the medical field.},
	journal = {2024 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)},
	author = {Yang, Hang and Xiao, Liang and Zhu, Rujun and Liu, Ziji and Chen, Jianxia},
	month = dec,
	year = {2024},
	note = {Section: 0},
	keywords = {Ontologies, Knowledge graphs, Knowledge graph, Large language model, Ontology, LLM, Natural language processing, Language model, Large language models, Semantic Web, Reliability, Usability, Medical knowledge, Iterative methods, Natural languages, Refining, Medical services, Breast cancer treatment, Ontology's, Natural language processing systems, Ontology graphs, Graphitization, Graph-construction method, Medical fields, Wages, Cannot download},
	pages = {5240--5246},
	annote = {ISSN: 2156-1133}
}

@article{yang2025KnowledgeGraphBased,
	keywords = {Cannot download},
	title = {Knowledge graph-based dual-modal collaborative {QA} framework for hydropower operation and maintenance},
	volume = {2025},
	doi = {10.1049/icp.2025.2348},
	abstract = {Maintenance of hydropower equipment is essential for ensuring a reliable supply of renewable energy. However, in practical maintenance operations, technicians rely heavily on personal experience and extensive domain manuals, which can reduce the accuracy and efficiency of decision-making processes. This paper proposes a knowledge graph-based dual-modal collaborative QA (KGD-QA) framework for hydropower operation and maintenance. Firstly, a multi-granularity segmentation strategy is used to divide domain manuals into thematically grouped text blocks and path-labeled sentence units. Secondly, a LoRA-fine-tuned large language model (LLM), guided by domain ontologies and chain-of-thought prompts, extracts entity-relation triples. Finally, a dual-modal QA mechanism is designed to integrate knowledge graph subgraph queries and text vector retrieval, enabling information acquisition in both detailed and global modes. Experimental results show that, compared with baseline model, this approach improves the accuracy of knowledge extraction while the dual-modal collaborative QA retrieval method provides more traceable and evidence-backed responses to maintenance-related queries. This framework offers a novel paradigm for advancing intelligent operation and maintenance technologies for hydropower equipment.},
	journal = {15th Prognostics and System Health Management Conference (PHM 2025)},
	author = {Yang, Ye and Duan, Ran and Yi, Xinyang and Ma, Qicheng and Liu, Jie and Hu, Zhongxu and Hu, Youmin},
	month = jun,
	year = {2025},
	note = {Section: 0},
	pages = {152--157},
	annote = {RAYYAN-LABELS: ontology-supported application}
}

@article{yao2025KnowledgeGraphConstruction,
	file = {References/pdf/yao2025KnowledgeGraphConstruction.pdf},
	title = {From knowledge graph construction to retrieval-augmented generation: a framework for comprehensive earthquake emergency support},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105009902479&doi=10.1080%2F10095020.2025.2514813&partnerID=40&md5=0c9769723dc40c230bc7a317e19a3a0e},
	doi = {10.1080/10095020.2025.2514813},
	abstract = {Effective decision-making during earthquake emergencies requires rapid access to accurate, structured, and context-specific knowledge. However, existing knowledge resources in this domain are fragmented, heterogeneous, and largely unstructured, causing decision-makers to rely heavily on intuition or scattered textual materials, which often results in delayed, inconsistent, or suboptimal emergency responses. To address these challenges, this study proposes a structured framework integrating large language models (LLMs) with knowledge representation techniques to systematically construct domain-specific knowledge graphs (KGs) tailored explicitly for earthquake emergency scenarios. The framework comprises three primary stages: (1) developing an ontology that encompasses the complete earthquake emergency management cycle–prevention, preparedness, response, and recovery–as well as earthquake-specific measures, models, terminology, and attributes; (2) guiding LLMs with structured prompts to extract entities, relationships, and attributes from unstructured data; and (3) employing a knowledge fusion strategy to resolve ambiguities and consolidate information across the graph. From a corpus of 2682 professional documents, including emergency plans, technical standards, and specialized books, the framework extracted 284,801 entities and over 80,000 unique relationship types, subsequently consolidated into approximately 1000 meaningful categories. The final KG, refined through entity fusion and clustering, comprises over 268,000 nodes and 833,000 relationships. To effectively utilize the constructed KG, we developed an Improved Hybrid Retrieval-Augmented Generation (HybridRAG) application framework, integrating symbolic retrieval from the KG with semantic similarity-based retrieval from a vector database. This dual retrieval approach enables LLMs to generate responses that are both semantically coherent and deeply grounded in operational knowledge. Comparative experiments conducted on a newly constructed dataset of 150 earthquake-specific questions demonstrated that the Improved HybridRAG method significantly outperforms standard methods–including LLM-only, semantic vector-based retrieval, and purely symbolic retrieval–in accuracy, clarity, comprehensiveness, conciseness, and relevance. These findings validate the advantage of combining structured and semantic knowledge retrieval, illustrating the framework’s capability to provide reliable, contextually aligned, and actionable insights for decision-makers in earthquake emergency scenarios. Future work will focus on improving attribute completeness, refining entity alignment techniques to capture complex semantic nuances, and exploring multimodal data integration to further extend the KG’s utility. This study underscores the potential of systematically combining structured KGs and LLMs to significantly enhance decision-making capabilities in disaster management contexts. © 2025 Elsevier B.V., All rights reserved.},
	journal = {Geo-Spatial Information Science},
	author = {Yao, Liwei and Ren, Fu and Du, Kaixuan and Du, Qingyun},
	year = {2025},
	note = {Section: 0},
	annote = {Type: Article}
}

@article{ye2022OntologyEnhancedPrompt,
	file = {References/pdf/ye2022OntologyEnhancedPrompt.pdf},
	series = {{WWW} '22},
	title = {Ontology-enhanced {Prompt}-tuning for {Few}-shot {Learning}},
	url = {https://doi.org/10.1145/3485447.3511921},
	doi = {10.1145/3485447.3511921},
	abstract = {Few-shot Learning (FSL) is aimed to make predictions based on a limited number of samples. Structured data such as knowledge graphs and ontology libraries has been leveraged to benefit the few-shot setting in various tasks. However, the priors adopted by the existing methods suffer from challenging knowledge missing, knowledge noise, and knowledge heterogeneity, which hinder the performance for few-shot learning. In this study, we explore knowledge injection for FSL with pre-trained language models and propose ontology-enhanced prompt-tuning (OntoPrompt). Specifically, we develop the ontology transformation based on the external knowledge graph to address the knowledge missing issue, which fulfills and converts structure knowledge to text. We further introduce span-sensitive knowledge injection via a visible matrix to select informative knowledge to handle the knowledge noise issue. To bridge the gap between knowledge and text, we propose a collective training algorithm to optimize representations jointly. We evaluate our proposed OntoPrompt in three tasks, including relation extraction, event extraction, and knowledge graph completion, with eight datasets. Experimental results demonstrate that our approach can obtain better few-shot performance than baselines.},
	journal = {Proceedings of the ACM Web Conference 2022},
	author = {Ye, Hongbin and Zhang, Ningyu and Deng, Shumin and Chen, Xiang and Chen, Hui and Xiong, Feiyu and Chen, Xi and Chen, Huajun},
	year = {2022},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery
Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Ontology, Relation extraction, Few-shot Learning, Knowledge management, Knowledge graph completion, Performance, Event Extraction, Extraction, Few-shot learning, Relation Extraction, Prompt-tuning, Knowledge Graph Completion, Ontology's, Events extractions, Prediction-based, Number of samples},
	pages = {778--787},
	annote = {event-place: Virtual Event, Lyon, France {\textbar} RAYYAN-LABELS: ontology-supported application}
}

@article{yhdego2025AutomatedOntologyGeneration,
	title = {Automated {Ontology} {Generation} for {Zero}-shot {Defect} {Identification} in {Manufacturing}},
	issn = {1558-3783},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85217032682&doi=10.1109%2FTASE.2025.3537463&partnerID=40&md5=e5ab810de0ed81cdcfa98e466137c161},
	doi = {10.1109/TASE.2025.3537463},
	abstract = {A lack of labeled data presents a significant challenge to automatic defect identification in manufacturing, which is a crucial step in process control and certification during process development. State-of-the-art transfer learning is incapable of handling such zero-shot learning (ZSL) when defect labels are absent in training datasets. The latest research on ZSL leverages natural language processing (NLP) based on large language models (LLM) and shows promise by supplementing information to generate labels. However, its performance is hampered by the supporting LLMs pre-trained on generic vocabulary that failed to characterize manufacturing defects accurately. This paper establishes a methodology to automatically extract multi-level attributes from literature to improve defect representation, thereby facilitating ZSL. The extracted attributes contribute to a hierarchical knowledge graph, called defect ontology, to characterize multiple aspects of manufacturing defects. The proposed algorithm takes the defect images and associated text from the literature as input and develops an unsupervised method to identify the hierarchical relationships among the tokenized information extracted from the input text-feature corpora. The hierarchical graph is refined to retain the most relevant information by a pruning algorithm based on a minimum path search. A walk algorithm, along with NLP, parsed the generated ontology to create embedding of defects to enable zero-shot attribute learning to identify defects. The proposed method advances the ZSL methodology by automatically creating a hierarchical knowledge representation from literature and images to replace generic vocabulary in LLM adopted by ZSL algorithms, thus improving defect representation. The case studies are among the earlier attempts to demonstrate the feasibility of using literature data from public sources to extract attributes automatically to identify defects in a real additive manufacturing process based on direct-ink-writing.},
	journal = {IEEE Transactions on Automation Science and Engineering},
	author = {Yhdego, Tsegai O. and Wang, Hui},
	year = {2025},
	note = {Section: 0},
	keywords = {Ontologies, Knowledge graph, Ontology, Language model, Automation, Manufacturing, Certification, Vocabulary, Data mining, Smart manufacturing, Ontology generation, Transfer learning, Graph embeddings, Self-supervised learning, Semi-supervised learning, Process control, Unsupervised learning, Zero-shot learning, Accuracy, Language processing, Natural languages, Zero shot learning, defect identification, manufacturing automation, self-supervised learning, Ontology's, Natural language processing systems, Labeled data, Network security, Manufacturing data processing, Manufacturing Automation, Defect identification, Gluing, Hierarchical knowledge, Manufacturing defects, Cannot download},
	pages = {1--1},
	annote = {Type: Article}
}

@article{yorsh2022TextOntologyMapping,
	file = {References/pdf/yorsh2022TextOntologyMapping.pdf},
	title = {Text-to-{Ontology} {Mapping} via {Natural} {Language} {Processing} {Models}},
	volume = {3226},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85139875540&partnerID=40&md5=6da54e850bc7b9fa8ff112f3ca724e7b},
	abstract = {The paper presents work in progress attempting to solve a text-to-ontology mapping problem. While ontologies are being created as formal specifications of shared conceptualizations of application domains, different users often create different ontologies to represent the same domain. For better reasoning about concepts in scientific papers, it is desired to pick the ontology which best matches concepts present in the input text. We have started to automatize this process and attack the problem by utilizing state-of-the-art NLP tools and neural networks. Given a specific set of ontologies, we experiment with different training pipelines for NLP machine learning models with the aim to construct representative embeddings for the text-to-ontology matching task. We assess the final result through visualizing the latent space and exploring the mappings between an input text and ontology classes. © 2022 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Yorsh, Uladzislau and Behr, Alexander S. and Kockmann, Norbert and Holeňa, Martin},
	year = {2022},
	note = {Section: 0},
	keywords = {Ontology, Language model, Ontology mapping, BERT, Mapping, Text analysis, Language processing, Natural languages, Ontology's, Natural language processing systems, Learning algorithms, Matchings, Fasttext, Matching text to ontology},
	pages = {28 -- 34},
	annote = {Type: Conference paper}
}

@article{zaitoun2023OntoevalAutomatedOntology,
	file = {References/pdf/zaitoun2023OntoevalAutomatedOntology.pdf},
	series = {{WWW} '23 {Companion}},
	title = {{OntoEval}: an {Automated} {Ontology} {Evaluation} {System}},
	url = {https://doi.org/10.1145/3543873.3587318},
	doi = {10.1145/3543873.3587318},
	abstract = {Developing semantically-aware web services requires comprehensive and accurate ontologies. Evaluating an existing ontology or adapting it is a labor-intensive and complex task for which no automated tools exist. Nevertheless, in this paper we propose a tool that aims at making this vision come true, i.e., we present a tool for the automated evaluation of ontologies that allows one to rapidly assess an ontology’s coverage of a domain and identify specific problems in the ontology’s structure. The tool evaluates the domain coverage and correctness of parent-child relations of a given ontology based on domain information derived from a text corpus representing the domain. The tool provides both overall statistics and detailed analysis of sub-graphs of the ontology. In the demo, we show how these features can be used for the iterative improvement of an ontology.},
	journal = {Companion Proceedings of the ACM Web Conference 2023},
	author = {Zaitoun, Antonio and Sagi, Tomer and Hose, Katja},
	year = {2023},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery
Section: 0},
	keywords = {BERT, natural language processing, ontology, knowledge engineering},
	pages = {82--85},
	annote = {event-place: Austin, TX, USA}
}

@article{zeginis2025ApplyingOntologyAware,
	file = {References/pdf/zeginis2025ApplyingOntologyAware.pdf},
	series = {{PCI} '24},
	title = {Applying an ontology-aware zero-shot {LLM} prompting approach for information extraction in {Greek}: the case of {DIAVGEIA} gov gr},
	url = {https://doi.org/10.1145/3716554.3716603},
	doi = {10.1145/3716554.3716603},
	abstract = {Large Language Models (LLMs) have attracted considerable attention, primarily due to their potential to revolutionize sectors that heavily rely on textual information. Governance is one such sector. Public administrations around the globe produce millions of documents including laws, administrative decisions and acts (e.g., travel/budget approvals) that contain valuable information in unstructured way. The documents are usually stored at document-centered repositories. As a result the actual data of the documents cannot be further searched or processed. The availability of structured metadata of the documents (e.g., who has traveled, where, when) could further enhance the searching and processing of the documents as well as enable data analytics. The construction of metadata can be done through information extraction approaches such as Named Entity Recognition (NER), Relation Extraction (RE) and Event Extraction (EE) on the documents. LLMs are recently used successfully for information extraction tasks, while ontologies are traditionally used for meaningful data modeling. The aim of the paper is to apply and evaluate an ontology-aware zero-shot LLM prompting approach for information extraction in Greek language documents available in DIAVGEIA.gov.gr - the Greek Open Government portal for administrative documents. The evaluation assesses various LLM models/sizes for various difficulties of information extraction tasks. Overall the results are very promising, since most LLM models, even smaller ones, performed very well for all tasks in Greek.},
	journal = {Proceedings of the 28th Pan-Hellenic Conference on Progress in Computing and Informatics},
	author = {Zeginis, Dimitris and Kalampokis, Evangelos and Tarabanis, Konstantinos},
	year = {2025},
	note = {Place: New York, NY, USA
Publisher: Association for Computing Machinery
Section: 0},
	keywords = {Information extraction, Large language model, Ontology, LLM, Language model, Named entity recognition, Relation extraction, Modeling languages, Information retrieval, Metadata, Data mining, Public administration, Data analytics, NER, Greek, Ontology's, Information retrieval systems, Structured metadatas, Textual information},
	pages = {324--330},
	annote = {Type: Conference paper}
}

@article{zeng2024Xlore3Large,
	file = {References/pdf/zeng2024Xlore3Large.pdf},
	title = {{XLORE} 3: {A} {Large}-{Scale} {Multilingual} {Knowledge} {Graph} from {Heterogeneous} {Wiki} {Knowledge} {Resources}},
	volume = {42},
	issn = {1046-8188},
	url = {https://doi.org/10.1145/3660521},
	doi = {10.1145/3660521},
	abstract = {In recent years, knowledge graph (KG) has attracted significant attention from academia and industry, resulting in the development of numerous technologies for KG construction, completion, and application. XLORE is one of the largest multilingual KGs built from Baidu Baike and Wikipedia via a series of knowledge modeling and acquisition methods. In this article, we utilize systematic methods to improve XLORE's data quality and present its latest version, XLORE 3, which enables the effective integration and management of heterogeneous knowledge from diverse resources. Compared with previous versions, XLORE 3 has three major advantages: (1) We design a comprehensive and reasonable schema, namely XLORE ontology, which can effectively organize and manage entities from various resources. (2) We merge equivalent entities in different languages to facilitate knowledge sharing. We provide a large-scale entity linking system to establish the associations between unstructured text and structured KG. (3) We design a multi-strategy knowledge completion framework, which leverages pre-trained language models and vast amounts of unstructured text to discover missing and new facts. The resulting KG contains 446 concepts, 2,608 properties, 66 million entities, and more than 2 billion facts. It is available and downloadable online at , providing a valuable resource for researchers and practitioners in various fields.},
	number = {6},
	journal = {ACM Trans. Inf. Syst.},
	author = {Zeng, Kaisheng and Jin, Hailong and Lv, Xin and Zhu, Fangwei and Hou, Lei and Zhang, Yi and Pang, Fan and Qi, Yu and Liu, Dingxiao and Li, Juanzi and Feng, Ling},
	month = aug,
	year = {2024},
	note = {Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, knowledge management, Knowledge fusion, Schema construction, Entity alignment, Entity linking, entity linking, Knowledge resource, Entity typing, entity alignment, entity typing, knowledge completion, knowledge fusion, schema construction, Large-scales, Unstructured texts, Knowledge completion},
	annote = {Place: New York, NY, USA Publisher: Association for Computing Machinery}
}

@article{zengeya2025AttentionBasedDeep,
	file = {References/pdf/zengeya2025AttentionBasedDeep.pdf},
	title = {An {Attention}-{Based} {Deep} {Learning} {Model} for {Term} {Extraction} from {Text} {Using} {BERT}},
	volume = {632},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105013199652&doi=10.1007%2F978-3-031-94439-0_6&partnerID=40&md5=6179d97728d4ea73b61714699c6d9ce6},
	doi = {10.1007/978-3-031-94439-0_6},
	abstract = {Extracting terms from text is relevant in many applications such as document summarizing, question answering, ontology learning and many more. However, the unstructured nature of textual data poses significant hurdles that make the automatic extraction of terms from text a challenging task. Furthermore, while significant research efforts have been dedicated to term extraction from textual data, the incorporation of domain knowledge and context awareness as a way of enriching the extracted terms remains a challenge. To tackle these challenges, this study proposes an attention-based Deep Learning model for term extraction from text using the Bidirectional Encoder Representations from Transformers (BERT) language model. The model uses (1) web scraping for term extraction from web pages, (2) BERT encoder for enriching term extraction through contextualization and cosine similarity to extract domain-specific terms and (3) WordNet for adding knowledge context and disambiguation through vocabulary labeling. The proposed system was applied to five different data samples from the horticulture domain and was evaluated with various metrics including accuracy, precision, and F1-score. The experimental results indicate that the proposed model improves the domain-specific term extraction and vocabulary labeling with an accuracy of 73\%, a precision of 89\%, a recall of 79\%, as well as F1-Score of 84\%, better than the related studies. © 2025 Elsevier B.V., All rights reserved.},
	journal = {Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST},
	author = {Zengeya, Tsitsi and Fonou-Dombeu, Jean Vincent and Gwetu, Mandlenkosi Victor},
	year = {2025},
	note = {Section: 0},
	keywords = {Ontology, Deep learning, Term extraction, Intelligent systems, Textual data, Wordnet, Extraction, Bidirectional encoder representation from transformer, Learning systems, Text processing, Domain Knowledge, Natural language processing systems, Signal encoding, F1 scores, Domain specific, Learning models, Labelings, Cosine similarity measures, Vocabulary building, Websites},
	pages = {87 -- 102},
	annote = {Type: Conference paper}
}

@article{zhang2024LargeLanguageModel,
	file = {References/pdf/zhang2024LargeLanguageModel.pdf},
	title = {Large {Language} {Model} {Assisted} {Multi}-{Agent} {Dialogue} for {Ontology} {Alignment}},
	volume = {2024},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192997204&partnerID=40&md5=5a51d0a74903a3408ce05f2f077d62e6},
	abstract = {Ontology alignment is critical in cross-domain integration; however, it typically necessitates the involvement of a human domain-expert, which can make the task costly. Although a variety of machine-learning approaches have been proposed that can simplify this task by learning the patterns from experts, such techniques are still susceptible to domain knowledge updates that could potentially change the patterns and lead to extra expert involvement. The use of Large Language Models (LLMs) has demonstrated a general cognitive ability, which has the potential to assist ontology alignment from the cognition level, thus obviating the need for costly expert involvement. However, the process by which the output of LLMs is generated can be opaque and thus the reliability and interpretability of such models is not always predictable. This paper proposes a dialogue model, in which multiple agents negotiate the correspondence between two knowledge sets with the support from an LLM. We demonstrate that this approach not only reduces the need for the involvement of a domain expert for ontology alignment, but that the results are interpretable despite the use of LLMs. © 2024 Elsevier B.V., All rights reserved.},
	journal = {Proceedings of the International Joint Conference on Autonomous Agents and Multiagent Systems, AAMAS},
	author = {Zhang, Shiyao and Dong, Yuji and Zhang, Yichuan and Payne, Terry R. and Zhang, Jie},
	year = {2024},
	note = {Section: 0},
	keywords = {Large language model, Ontology, Language model, Ontology alignment, Computational linguistics, Cross-domain, Autonomous agents, Multi agent systems, Learning systems, Domain Knowledge, Multi agent, Domain experts, Human domain, Dialog, Machine learning approaches, Negotiation},
	pages = {2594 -- 2596},
	annote = {Type: Conference paper}
}

@article{zhang2025ConstructionApplicationKnowledge,
	title = {Construction and application of knowledge graph for flood defense and rescue of water infrastructure},
	volume = {56},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105003194264&doi=10.13243%2Fj.cnki.slxb.20240268&partnerID=40&md5=adcb1bd8c0ce18aa28812655424bec12},
	doi = {10.13243/j.cnki.slxb.20240268},
	abstract = {The knowledge platform is an important component in digital twin of water conservancy. However, water conservancy knowledge is dispersed across multi —source texts, which exhibit obvious unstructured and frag-mented characteristics, and knowledge extraction and effective utilization face challenges. To addresses the issues of low data quality and underutilization of knowledge in the field, this study focuses on the texts of flood defense and emergency rescue, and proposes an intelligent method for constructing a flood defense and emergency rescue knowdedge graph by improving the knowledge extraction model and combining unstructured data and external semi-structured data. Initially, a large language model is employed to extract term from unstructured texts and construct an ontology model based on term themes, a pretraining module is used to enhance text representation features, and a convolutional module is introduced to improve the entity knowdedge extraction model, and an entity data enhance-ment method is proposed to improve model accuracy. Then external encyclopedia data is extracted to expand the knowdedge coverage to build a complete flood defense and rescue knowledge graph. Experimental results demonstrate that the proposed model achieves an Fl score of 89.91\% in entity knowdedge extraction, significantly outperforming baseline models. Finally, the application method of knowdedge graph in the field of flood defense and rescue is introduced, which can form a knowdedge engine for digital twin of water conservancy construction, providing knowledge support for flood control research and decision-making. © 2025 Elsevier B.V., All rights reserved.},
	number = {3},
	journal = {Shuili Xuebao/Journal of Hydraulic Engineering},
	author = {Zhang, Dongliang and Zhou, Wei and Ma, Gang and Wang, Xudong and Liu, Yu and Wang, Xiaomao},
	year = {2025},
	note = {Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Ontology, Knowledge extraction, Emergency rescue, Multi-Sources, Extraction modeling, Flood control, Flood defence, Flood defense and rescue, Multi—source data, Source data, Water conservancy, Cannot find},
	pages = {341 -- 353},
	annote = {Type: Article}
}

@article{zhang2025NovelDualStrategy,
	file = {References/pdf/zhang2025NovelDualStrategy.pdf},
	title = {A {Novel} {Dual}-{Strategy} {Approach} for {Constructing} {Knowledge} {Graphs} in the {Home} {Appliance} {Fault} {Domain}},
	volume = {18},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105014352969&doi=10.3390%2Fa18080485&partnerID=40&md5=2f3d9626ee0b08b84c8e0aa9e2c7f935},
	doi = {10.3390/a18080485},
	abstract = {Knowledge graph technology holds significant importance for efficient fault diagnosis in household appliances. However, the scarcity of public fault diagnosis data and the lack of automated knowledge extraction pose major challenges to knowledge graph construction. To address issues such as ambiguous entity boundaries, severe entity nesting, and poor entity extraction performance in fault diagnosis texts, this paper proposes a dual-strategy progressive knowledge extraction framework. First, to tackle the high complexity of fault diagnosis texts, an entity recognition model named RoBERTa-zh-BiLSTM-MUL-CRF is designed, improving the accuracy of nested entity extraction. Second, leveraging the semantic understanding capability of large language models, a progressive prompting strategy is adopted for ontology alignment and relation extraction, achieving automated knowledge extraction. Experimental results show that the proposed named entity recognition model outperforms traditional models, with improvements of 3.87\%, 5.82\%, and 2.05\% in F1-score, recall, and precision, respectively. Additionally, the large language model demonstrates better performance in ontology alignment compared to traditional machine learning models. The constructed knowledge graph for household appliance fault diagnosis integrates structured fault diagnosis information. It effectively processes unstructured fault texts and supports visual queries and entity tracing. This framework can assist maintenance personnel in making rapid judgments, thereby improving fault diagnosis efficiency. © 2025 Elsevier B.V., All rights reserved.},
	number = {8},
	journal = {Algorithms},
	author = {Zhang, Daokun and Zhang, Jian and Jia, Yanhe and Liao, Mengjie},
	year = {2025},
	note = {Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Large language model, Ontology, Language model, Named entity recognition, Relationship extraction, Semantics, Knowledge extraction, Knowledge management, Failure analysis, Performance, Graph theory, Extraction, Fault detection, Learning systems, Domestic appliances, Entity extractions, Faults diagnosis, Home appliance fault},
	annote = {Type: Article}
}

@article{zhang2025OntochatFrameworkConversational,
	file = {References/pdf/zhang2025OntochatFrameworkConversational.pdf},
	title = {{OntoChat}: {A} {Framework} for {Conversational} {Ontology} {Engineering} {Using} {Language} {Models}},
	volume = {15344},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85218459527&doi=10.1007%2F978-3-031-78952-6_10&partnerID=40&md5=77776a3fa6293cb8bdfb5f1e88063c21},
	doi = {10.1007/978-3-031-78952-6_10},
	abstract = {Ontology engineering (OE) in large projects poses a number of challenges arising from the heterogeneous backgrounds of the various stakeholders, domain experts, and their complex interactions with ontology designers. This multi-party interaction often creates systematic ambiguities and biases from the elicitation of ontology requirements, which directly affect the design, evaluation and may jeopardise the target reuse. Meanwhile, current OE methodologies strongly rely on manual activities (e.g., interviews, discussion pages). After collecting evidence on the most crucial OE activities, we introduce OntoChat, a framework for conversational ontology engineering that supports requirement elicitation, analysis, and testing. By interacting with a conversational agent, users can steer the creation of user stories and the extraction of competency questions, while receiving computational support to analyse the overall requirements and test early versions of the resulting ontologies. We evaluate OntoChat by replicating the engineering of the Music Meta Ontology, and collecting preliminary metrics on the effectiveness of each component from users. We release all code at https://github.com/King-s-Knowledge-Graph-Lab/OntoChat. © 2025 Elsevier B.V., All rights reserved.},
	journal = {Lecture Notes in Computer Science},
	author = {Zhang, Bohui and Carriero, Valentina Anita and Schreiberhuber, Katrin and Tsaneva, Stefani and González, Lucía Sánchez and Kim, Jongmo and de Berardinis, Jacopo},
	year = {2025},
	note = {Section: 0},
	keywords = {Ontology engineering, Large language model, Ontology, Language model, Competency question, Requirements engineering, Design evaluation, Chatbots, Ontology's, Domain experts, Computational creativities, Large programs, Multiparty interaction},
	pages = {102 -- 121},
	annote = {Type: Conference paper}
}

@article{zheng2025UnsupervisedOntologyConstruction,
	file = {References/pdf/zheng2025UnsupervisedOntologyConstruction.pdf},
	title = {An {Unsupervised} {Ontology} {Construction} {Method} {Based} on {Pre}-trained {Language} {Model}},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-105013077743&doi=10.1145%2F3730436.3730532&partnerID=40&md5=e921376d1dd8149b1f6af466fd0859fb},
	doi = {10.1145/3730436.3730532},
	abstract = {With the fast growth of text data, the importance of automatic ontology construction has grown significantly. The proposed article provides a novel approach by applying pre-trained language models to automatically construct the ontology. The framework consists of two sequential phases: automatic concept discovery and automatic relation discovery. In the context of automatic concept discovery, instances and their embedding vectors are extracted first through Named Entity Recognition (NER). Then, the unsupervised affinity propagation (AP) clustering algorithm is applied to classify these embedding vectors, resulting in the discovery of the concepts. A denoising method is discussed to obtain higher accuracy with respect to the concepts obtained to reduce noise caused by complete clustering. Related to automatic relation discovery between concepts (mentioned in the next section), the process generates inexplicable concepts that are contextually similar based on the embedded vectors of instances mapping over the two entities. This can enable unsupervised automatic discovery of relations between the contextually related concepts. This method shows a certain feasibility and achieves early effectiveness in unsupervised automatic ontology construction with the experimental results. © 2025 Elsevier B.V., All rights reserved.},
	author = {Zheng, Hanqi and Ouyang, Guige and Huang, Yongzhong},
	year = {2025},
	note = {Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Ontology, Language model, Pre-trained language model, Embeddings, Data mining, Ontology construction, Clustering algorithms, Affinity propagation, Automatic ontology, Automatic ontology construction, Concept discoveries, Construction method},
	pages = {588 -- 595},
	annote = {Type: Conference paper}
}

@article{zotova2022ClinidmapTowardsClinical,
	file = {References/pdf/zotova2022ClinidmapTowardsClinical.pdf},
	title = {{ClinIDMap}: {Towards} a {Clinical} {IDs} {Mapping} for {Data} {Interoperability}},
	url = {https://aclanthology.org/2022.lrec-1.390/},
	abstract = {This paper presents ClinIDMap, a tool for mapping identifiers between clinical ontologies and lexical resources. ClinIDMap interlinks identifiers from UMLS, SMOMED-CT, ICD-10 and the corresponding Wikipedia articles for concepts from the UMLS Metathesaurus. Our main goal is to provide semantic interoperability across the clinical concepts from various knowledge bases. As a side effect, the mapping enriches already annotated corpora in multiple languages with new labels. For instance, spans manually annotated with IDs from UMLS can be annotated with Semantic Types and Groups, and its corresponding SNOMED CT and ICD-10 IDs. We also experiment with sequence labelling models for detecting Diagnosis and Procedures concepts and for detecting UMLS Semantic Groups trained on Spanish, English, and bilingual corpora obtained with the new mapping procedure. The ClinIDMap tool is publicly available.},
	journal = {Proceedings of the Thirteenth Language Resources and Evaluation Conference},
	author = {Zotova, Elena and Cuadros, Montse and Rigau, German},
	editor = {Calzolari, Nicoletta and Béchet, Frédéric and Blache, Philippe and Choukri, Khalid and Cieri, Christopher and Declerck, Thierry and Goggi, Sara and Isahara, Hitoshi and Maegaard, Bente and Mariani, Joseph and Mazo, Hélène and Odijk, Jan and Piperidis, Stelios},
	month = jun,
	year = {2022},
	note = {Place: Marseille, France
Publisher: European Language Resources Association
Section: 0},
	pages = {3661--3669}
}

@article{ŝvabzamazal2024TowardsPatternBased,
	file = {References/pdf/ŝvabzamazal2024TowardsPatternBased.pdf},
	title = {Towards {Pattern}-based {Complex} {Ontology} {Matching} using {SPARQL} and {LLM}},
	volume = {3759},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204733796&partnerID=40&md5=5f38b3109696be1d51c0bc9e2ef0d2c3},
	abstract = {Complex ontology matching is a process to match complex structures in ontologies.While many matching tools tackle simple ontology matching, complex ontology matching is still rare.However, one entity in one ontology can be similar to a complex structure (1-to-n) or even complex structures can be on both sides (m-to-n).Therefore, the application, e.g., data integration, must consider complex correspondences within ontology alignment.Our poster paper presents a pattern-based approach where particular SPARQL queries correspond to a specific pattern, e.g., Class by Attribute Type (CAT), for its detection.SPARQL queries are anchored to entities from simple correspondences on input.Detected complex correspondence candidates are verbalized to be validated by the Large Language Model (LLM).Further, we provide a zero-shot prompting preliminary experiment and evaluation.The poster paper is equipped with the Jupyter notebook for automation of the pipeline and the full report of the experiment at: https://github.com/OndrejZamazal/ComplexOntologyMatching-SEMANTiCS2024. © 2024 Elsevier B.V., All rights reserved.},
	journal = {CEUR Workshop Proceedings},
	author = {Ŝváb-Zamazal, Ondr̂ej Ř.Ej},
	year = {2024},
	note = {Section: 0},
	keywords = {Knowledge graphs, Knowledge graph, Large language model, Ontology, Language model, Semantics, Ontology matching, Modeling languages, Structured Query Language, Ontology's, Complexes structure, Simple++, Complex ontology matching, Complex correspondences},
	annote = {Type: Conference paper}
}


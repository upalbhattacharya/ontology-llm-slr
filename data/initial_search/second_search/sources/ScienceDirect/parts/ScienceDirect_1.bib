@article{CHEN20244283,
title = {LKPNR: Large Language Models and Knowledge Graph for Personalized News Recommendation Framework},
journal = {Computers, Materials and Continua},
volume = {79},
number = {3},
pages = {4283-4296},
year = {2024},
issn = {1546-2218},
doi = {https://doi.org/10.32604/cmc.2024.049129},
url = {https://www.sciencedirect.com/science/article/pii/S1546221824000225},
author = {Hao Chen and Runfeng Xie and Xiangyang Cui and Zhou Yan and Xin Wang and Zhanwei Xuan and Kai Zhang},
keywords = {Large language models, news recommendation, knowledge graphs (KG)},
abstract = {Accurately recommending candidate news to users is a basic challenge of personalized news recommendation systems. Traditional methods are usually difficult to learn and acquire complex semantic information in news texts, resulting in unsatisfactory recommendation results. Besides, these traditional methods are more friendly to active users with rich historical behaviors. However, they can not effectively solve the long tail problem of inactive users. To address these issues, this research presents a novel general framework that combines Large Language Models (LLM) and Knowledge Graphs (KG) into traditional methods. To learn the contextual information of news text, we use LLMs’ powerful text understanding ability to generate news representations with rich semantic information, and then, the generated news representations are used to enhance the news encoding in traditional methods. In addition, multi-hops relationship of news entities is mined and the structural information of news is encoded using KG, thus alleviating the challenge of long-tail distribution. Experimental results demonstrate that compared with various traditional models, on evaluation indicators such as AUC, MRR, nDCG@5 and nDCG@10, the framework significantly improves the recommendation performance. The successful integration of LLM and KG in our framework has established a feasible way for achieving more accurate personalized news recommendation. Our code is available at https://github.com/Xuan-ZW/LKPNR.}
}
@article{WANG2025104054,
title = {A novel large-language-model-driven framework for named entity recognition},
journal = {Information Processing & Management},
volume = {62},
number = {3},
pages = {104054},
year = {2025},
issn = {0306-4573},
doi = {https://doi.org/10.1016/j.ipm.2024.104054},
url = {https://www.sciencedirect.com/science/article/pii/S0306457324004138},
author = {Zhenhua Wang and Huiru Chen and Guang Xu and Ming Ren},
keywords = {Large language model, Named entity recognition, In-context learning, Contrastive learning, Knowledge graph},
abstract = {Named entity recognition (NER) stands as the foundational pillar of knowledge graphs across multiple domains. Despite progress in NER using large language models (LLMs), challenges persist regarding the selection of LLMs, the retrieval of demonstrations, and the design of prompts. We introduce a novel framework for NER, termed LLMCC, which elucidates the synergistic interactions between different LLMs. Two new methods, SemnRank and InforLaw-thought, are proposed to address the issue of redundancy in demonstrations and to elevate prompt quality for boosting LLM's capabilities. Furthermore, LLMCC is trained through a new entity-aware contrastive learning. Extensive experiments across five domains confirm the competitiveness of LLMCC (surpassing ten recent studies by a margin of over 5% in F1 score), as well as the effectiveness of SemnRank and InforLaw-thought. We uncover a series of insights regarding information laws, prompting strategies, demonstration selections, and training designs. This research significantly advances the incorporation of LLMs into the construction of knowledge graphs.}
}
@article{SINGH2025100128,
title = {A survey on chatbots and large language models: Testing and evaluation techniques},
journal = {Natural Language Processing Journal},
volume = {10},
pages = {100128},
year = {2025},
issn = {2949-7191},
doi = {https://doi.org/10.1016/j.nlp.2025.100128},
url = {https://www.sciencedirect.com/science/article/pii/S2949719125000044},
author = {Sonali Uttam Singh and Akbar Siami Namin},
keywords = {Large Language Models (LLM), Chatbot, Conversational Chatbot, Intelligent Personal Assistant (IPA), ChatGPT, Natural Language Understanding (NLU), Natural Language Processing (NLP)},
abstract = {Chatbots have been quite developed in the recent decades and evolved along with the field of Artificial Intelligence (AI), enabling powerful capabilities in tasks such as text generation and summarization, sentiment analysis, and many other interesting Natural Language Processing (NLP) based tasks. Advancements in language models (LMs), specifically LLMs, have played an important role in improving the capabilities of chatbots. This survey paper provides a comprehensive overview in chatbot with the integration of LLMs, primarily focusing on the testing, evaluation and performance techniques and frameworks associated with it. The paper discusses the foundational concepts of chatbots and their evolution, highlights the challenges and opportunities they present by reviewing the state-of-the-art papers associated with the chatbots design, testing and evaluation. The survey also delves into the key components of chatbot systems, including Natural Language Understanding (NLU), dialogue management, and Natural Language Generation (NLG), and examine how LLMs have influenced each of these components. Furthermore, the survey examines the ethical considerations and limitations associated with LLMs. The paper primarily focuses on investigating the evaluation techniques and metrics used to assess the performance and effectiveness of these language models. This paper aims to provide an overview of chatbots and highlights the need for an appropriate framework in regards to testing and evaluating these chatbots and the LLMs associated with it in order to provide efficient and proper knowledge to user and potentially improve its quality based on advancements in the field of machine learning.}
}
@article{WICKRAMASEKARA2025301859,
title = {Exploring the potential of large language models for improving digital forensic investigation efficiency},
journal = {Forensic Science International: Digital Investigation},
volume = {52},
pages = {301859},
year = {2025},
issn = {2666-2817},
doi = {https://doi.org/10.1016/j.fsidi.2024.301859},
url = {https://www.sciencedirect.com/science/article/pii/S2666281724001860},
author = {Akila Wickramasekara and Frank Breitinger and Mark Scanlon},
keywords = {Digital forensics, Large language models, LLM, Investigative process, Challenges},
abstract = {The ever-increasing workload of digital forensic labs raises concerns about law enforcement's ability to conduct both cyber-related and non-cyber-related investigations promptly. Consequently, this article explores the potential and usefulness of integrating Large Language Models (LLMs) into digital forensic investigations to address challenges such as bias, explainability, censorship, resource-intensive infrastructure, and ethical and legal considerations. A comprehensive literature review is carried out, encompassing existing digital forensic models, tools, LLMs, deep learning techniques, and the use of LLMs in investigations. The review identifies current challenges within existing digital forensic processes and explores both the obstacles and the possibilities of incorporating LLMs. In conclusion, the study states that the adoption of LLMs in digital forensics, with appropriate constraints, has the potential to improve investigation efficiency, improve traceability, and alleviate the technical and judicial barriers faced by law enforcement entities.}
}
@article{HATEM2024327,
title = {Up To Date: Automatic Updating Knowledge Graphs Using LLMs},
journal = {Procedia Computer Science},
volume = {244},
pages = {327-334},
year = {2024},
note = {6th International Conference on AI in Computational Linguistics},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.10.206},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924030072},
author = {Shahenda Hatem and Ghada Khoriba and Mohamed H. Gad-Elrab and Mohamed ElHelw},
keywords = {Knowledge Graphs, Large Language Models, Retrieval augmented generation},
abstract = {Maintaining up-to-date knowledge graphs (KGs) is essential for enhancing the accuracy and relevance of artificial intelligence (AI) applications, especially with sensitive domains. Yet, major KGs are either manually maintained (e.g., Wikidata) or infrequently rebuilt (e.g., DBpedia & YAGO). Thus, they contain many outdated facts. The rise of Large Language Models (LLMs) reasoning and Augmented Retrieval Generation approaches (RAG) gives KGs an interface to other trusted sources. This paper introduces a methodology utilizing Large Language Models (LLMs) to validate and update KG facts automatically. In particular, we utilize LLM reasoning capabilities to determine potentially outdated facts. After that, we use RAG techniques to generate an accurate fix for the fact. Experimental results on several LLMs and real-world datasets demonstrate the ability of our approach to propose accurate fixes. In addition, our experiments highlight the efficacy of few-shot prompts over zero-shot prompts.}
}
@article{HYVONEN2025100852,
title = {Serendipitous knowledge discovery on the Web of Wisdom based on searching and explaining interesting relations in knowledge graphs},
journal = {Journal of Web Semantics},
volume = {85},
pages = {100852},
year = {2025},
issn = {1570-8268},
doi = {https://doi.org/10.1016/j.websem.2024.100852},
url = {https://www.sciencedirect.com/science/article/pii/S1570826824000386},
author = {Eero Hyvönen},
keywords = {Knowledge graphs, Relational search, Knowledge discovery, Information retrieval, Large Language Models, Generative AI},
abstract = {This paper maintains that the Semantic Web is changing into a kind of Web of Wisdom (WoW) where AI-based problem solving, based on symbolic search and sub-symbolic methods, and Information Retrieval (IR) merge: IR is seen as a process for solving information-related problems of the end user with explanations, a form of knowledge discovery. As a case of example, relational search is concerned, i.e., solving problems of the type “How are X1…Xn related to Y1…Ym?”. For example: how is Pablo Picasso related to Barcelona? The idea is to find explainable “interesting” or even serendipitous associations in Knowledge Graphs (KG) and textual web contents. It is argued that domain knowledge-based symbolic methods based of KGs are needed to complement domain-agnostic graph-based methods and Generative AI (GenAI) boosted by Large Language Models (LLM). By using domain specific knowledge, it is possible to find and explain meaningful reliable textual answers, answer quantitative questions, and use data analyses and visualizations for explaining and studying the relations.}
}
@article{VALCALVO2025104042,
title = {OntoGenix: Leveraging Large Language Models for enhanced ontology engineering from datasets},
journal = {Information Processing & Management},
volume = {62},
number = {3},
pages = {104042},
year = {2025},
issn = {0306-4573},
doi = {https://doi.org/10.1016/j.ipm.2024.104042},
url = {https://www.sciencedirect.com/science/article/pii/S0306457324004011},
author = {Mikel Val-Calvo and Mikel {Egaña Aranguren} and Juan Mulero-Hernández and Ginés Almagro-Hernández and Prashant Deshmukh and José Antonio Bernabé-Díaz and Paola Espinoza-Arias and José Luis Sánchez-Fernández and Juergen Mueller and Jesualdo Tomás Fernández-Breis},
keywords = {Knowledge graphs, Large Language Models, Ontology engineering},
abstract = {Knowledge Graphs integrate data from multiple, heterogeneous sources, using ontologies to facilitate data interoperability. Ontology development is a resource-consuming task that requires the collaborative work of domain experts and ontology engineers. Therefore, companies invest considerable resources in order to generate and maintain Enterprise Knowledge Graphs and ontologies from large and complex datasets, most of which can be unfamiliar for ontology engineers. In this work, we study the use of Large Language Models to aid in the development of ontologies from datasets, ultimately increasing the automation of the generation of ontology-based Knowledge Graphs. As a result we have developed a structured workflow that leverages Large Language Models to enhance ontology engineering through data pre-processing, ontology planning, building, and entity improvement. Our method is also able to generate mappings and RDF data, but in this work we focus on the ontologies. The pipeline has been implemented in the OntoGenix tool. In this work we show the results of the application of OntoGenix to six datasets related to commercial activities. The findings indicate that the ontologies produced exhibit patterns of coherent modeling, and features that closely resemble those created by humans, although the most complex situations are better reflected by the ontologies developed by humans.}
}
@article{WU2024101030,
title = {Exploring the reversal curse and other deductive logical reasoning in BERT and GPT-based large language models},
journal = {Patterns},
volume = {5},
number = {9},
pages = {101030},
year = {2024},
issn = {2666-3899},
doi = {https://doi.org/10.1016/j.patter.2024.101030},
url = {https://www.sciencedirect.com/science/article/pii/S2666389924001636},
author = {Da Wu and Jingye Yang and Kai Wang},
keywords = {BERT, GPT, large language model, LLM, reversal curse, auto-regressive model, bidirectional encoder, deductive logical reasoning},
abstract = {Summary
The “Reversal Curse” describes the inability of autoregressive decoder large language models (LLMs) to deduce “B is A” from “A is B,” assuming that B and A are distinct and can be uniquely identified from each other. This logical failure suggests limitations in using generative pretrained transformer (GPT) models for tasks like constructing knowledge graphs. Our study revealed that a bidirectional LLM, bidirectional encoder representations from transformers (BERT), does not suffer from this issue. To investigate further, we focused on more complex deductive reasoning by training encoder and decoder LLMs to perform union and intersection operations on sets. While both types of models managed tasks involving two sets, they struggled with operations involving three sets. Our findings underscore the differences between encoder and decoder models in handling logical reasoning. Thus, selecting BERT or GPT should depend on the task’s specific needs, utilizing BERT’s bidirectional context comprehension or GPT’s sequence prediction strengths.}
}
@article{LAVRINOVICS2025100844,
title = {Knowledge Graphs, Large Language Models, and Hallucinations: An NLP Perspective},
journal = {Journal of Web Semantics},
volume = {85},
pages = {100844},
year = {2025},
issn = {1570-8268},
doi = {https://doi.org/10.1016/j.websem.2024.100844},
url = {https://www.sciencedirect.com/science/article/pii/S1570826824000301},
author = {Ernests Lavrinovics and Russa Biswas and Johannes Bjerva and Katja Hose},
keywords = {LLM, Factuality, Knowledge Graphs, Hallucinations},
abstract = {Large Language Models (LLMs) have revolutionized Natural Language Processing (NLP) based applications including automated text generation, question answering, chatbots, and others. However, they face a significant challenge: hallucinations, where models produce plausible-sounding but factually incorrect responses. This undermines trust and limits the applicability of LLMs in different domains. Knowledge Graphs (KGs), on the other hand, provide a structured collection of interconnected facts represented as entities (nodes) and their relationships (edges). In recent research, KGs have been leveraged to provide context that can fill gaps in an LLM’s understanding of certain topics offering a promising approach to mitigate hallucinations in LLMs, enhancing their reliability and accuracy while benefiting from their wide applicability. Nonetheless, it is still a very active area of research with various unresolved open problems. In this paper, we discuss these open challenges covering state-of-the-art datasets and benchmarks as well as methods for knowledge integration and evaluating hallucinations. In our discussion, we consider the current use of KGs in LLM systems and identify future directions within each of these challenges.}
}
@article{KONDINSKI20242070,
title = {Knowledge graph representation of zeolitic crystalline materials††Electronic supplementary information (ESI) available. See DOI: https://doi.org/10.1039/d4dd00166d},
journal = {Digital Discovery},
volume = {3},
number = {10},
pages = {2070-2084},
year = {2024},
issn = {2635-098X},
doi = {https://doi.org/10.1039/d4dd00166d},
url = {https://www.sciencedirect.com/science/article/pii/S2635098X24001669},
author = {Aleksandar Kondinski and Pavlo Rutkevych and Laura Pascazio and Dan N. Tran and Feroz Farazi and Srishti Ganguly and Markus Kraft},
abstract = {Zeolites are complex and porous crystalline inorganic materials that serve as hosts for a variety of molecular, ionic and cluster species. Formal, machine-actionable representation of this chemistry presents a challenge as a variety of concepts need to be semantically interlinked. This work demonstrates the potential of knowledge engineering in overcoming this challenge. We develop ontologies OntoCrystal and OntoZeolite, enabling the representation and instantiation of crystalline zeolite information into a dynamic, interoperable knowledge graph called The World Avatar (TWA). In TWA, crystalline zeolite instances are semantically interconnected with chemical species that act as guests in these materials. Information can be obtained via custom or templated SPARQL queries administered through a user-friendly web interface. Unstructured exploration is facilitated through natural language processing using the Marie System, showcasing promise for the blended large language model – knowledge graph approach in providing accurate responses on zeolite chemistry in natural language.}
}
@article{SHIM2025103001,
title = {OmEGa(Ω): Ontology-based information extraction framework for constructing task-centric knowledge graph from manufacturing documents with large language model},
journal = {Advanced Engineering Informatics},
volume = {64},
pages = {103001},
year = {2025},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2024.103001},
url = {https://www.sciencedirect.com/science/article/pii/S1474034624006529},
author = {Midan Shim and Hyojun Choi and Heeyeon Koo and Kaehyun Um and Kyong-Ho Lee and Sanghyun Lee},
keywords = {Ontology modeling, Manufacturing and maintenance process, Information extraction, Knowledge graph, Document understanding, Large language model},
abstract = {Manufacturing industry relies heavily on technical documents that encapsulate specialized knowledge essential for optimizing production and maintenance processes. However, extracting meaningful insights from these documents is challenging due to their complex structure, domain-specific terminology, and multimodal content, which includes text, images, and tables. Furthermore, there is a contextual gap between the generic training data of pre-trained language models (PLMs) and the specialized knowledge required for manufacturing documents. To address these issues, a Task-Centric Ontology (TCO) is designed to describe fundamental manufacturing tasks, and develop OmEGa, an Ontology-based Information Extraction Framework for Task-Centric Knowledge Graphs. OmEGa leverages large language models (LLMs) to perform instance recognition and relation classification on multimodal documents. By utilizing spatial embedding and modality linking, OmEGa addresses structural challenges, while TCO-driven reasoning mitigates contextual challenges. Experimental results demonstrate the effectiveness of OmEGa, achieving strong performance on both proprietary and open-source datasets. Additionally, a Knowledge Graph Question Answering (KGQA) system built on the extracted task-centric knowledge shows promise in enhancing communication among domain experts in the manufacturing sector.}
}
@article{HAYAWI2024101533,
title = {Generative AI and large language models: A new frontier in reverse vaccinology},
journal = {Informatics in Medicine Unlocked},
volume = {48},
pages = {101533},
year = {2024},
issn = {2352-9148},
doi = {https://doi.org/10.1016/j.imu.2024.101533},
url = {https://www.sciencedirect.com/science/article/pii/S2352914824000893},
author = {Kadhim Hayawi and Sakib Shahriar and Hany Alashwal and Mohamed Adel Serhani},
keywords = {Reverse vaccinology, Large language models (LLMs), AI, Generative AI, Vaccine candidate identification, AI ethics, Vaccines},
abstract = {Reverse vaccinology is an emerging concept in the field of vaccine development as it facilitates the identification of potential vaccine candidates. Biomedical research has been revolutionized with the recent innovations in Generative Artificial Intelligence (AI) and Large Language Models (LLMs). The intersection of these two technologies is explored in this study. In this study, the impact of Generative AI and LLMs in the field of vaccinology is explored. Through a comprehensive analysis of existing research, prospective use cases, and an experimental case study, this research highlights that LLMs and Generative AI have the potential to enhance the efficiency and accuracy of vaccine candidate identification. This work also discusses the ethical and privacy challenges, such as data consent and potential biases, raised by such applications that require careful consideration. This study paves the way for experts, researchers, and policymakers to further investigate the role and impact of Generative AI and LLM in vaccinology and medicine.}
}
@article{BADINI2025100275,
title = {Enhancing mechanical and bioinspired materials through generative AI approaches},
journal = {Next Materials},
volume = {6},
pages = {100275},
year = {2025},
issn = {2949-8228},
doi = {https://doi.org/10.1016/j.nxmate.2024.100275},
url = {https://www.sciencedirect.com/science/article/pii/S2949822824001722},
author = {Silvia Badini and Stefano Regondi and Raffaele Pugliese},
keywords = {Mechanical materials, Bioinspired materials, Additive manufacturing, Generative AI, Human-machine interaction},
abstract = {The integration of generative artificial intelligence (AI) into the design and additive manufacturing processes of mechanical and bioinspired materials has emerged as a transformative approach in engineering and material science, allowing to explore relationships across different field (e.g., mechanics-biology) or disparate domains (e.g., failure mechanics-3D printing). In addition, generative AI techniques, including generative adversarial networks (GAN), genetic algorithms, and large language models (LLMs), offer efficient and tunable solutions for optimizing material properties, reducing production costs, and accelerating the development timelines. In the field of mechanical materials design, generative AI enables the rapid generation of novel structures with enhanced mechanical performance. Instead, bioinspired materials design benefits significantly from the synergy of generative AI with bioinspired concepts and additive manufacturing. By harnessing generative algorithms and topology optimization, researchers can explore complex biological phenomena and translate them into innovative engineering solutions. Lastly, the emergence of LLMs in additive manufacturing optimization demonstrates their potential to optimize printing parameters, debug errors, and enhance productivity. This review highlights the pivotal role of generative AI in advancing materials science and engineering, unlocking new possibilities for innovation, and accelerating the development of efficient material solutions. As generative AI continues to evolve, its integration promises to revolutionize engineering design and drive the field towards unprecedented levels of efficiency, thus turns information into knowledge.}
}
@article{COLOMBO2025104082,
title = {An LLM-assisted ETL pipeline to build a high-quality knowledge graph of the Italian legislation},
journal = {Information Processing & Management},
volume = {62},
number = {4},
pages = {104082},
year = {2025},
issn = {0306-4573},
doi = {https://doi.org/10.1016/j.ipm.2025.104082},
url = {https://www.sciencedirect.com/science/article/pii/S030645732500024X},
author = {Andrea Colombo and Anna Bernasconi and Stefano Ceri},
keywords = {Law, Knowledge graph, Property graph, Large language models, Data quality},
abstract = {The increasing complexity of legislative systems, characterized by an ever-growing number of laws and their interdependencies, has highlighted the utility of Knowledge Graphs (KGs) as an effective data model for organizing such information, compared to traditional methods, often based on relational models, which struggle to efficiently represent interlinked data, such as references within laws, hindering efficient knowledge discovery. A paradigm shift in modeling legislative data is already ongoing with the adoption of common international standards, predominantly XML-based, such as Akoma Ntoso (AKN) and the Legal Knowledge Interchange Format, which aim to capture fundamental aspects of laws shared across different legislations and simplify the task of creating Knowledge Graphs through the use of XML tags and identifiers. However, to enable advanced analysis and data discovery within these KGs, it is necessary to carefully check, complement, and enrich KG nodes and edges with properties, either metadata or additional derived knowledge, that enhance the quality and utility of the model, for instance, by leveraging the capabilities of state-of-the-art Large Language Models. In this paper, we present an ETL pipeline for modeling and querying the Italian legislation in a Knowledge Graph, by adopting the property graph model and the AKN standard implemented in the Italian system. The property graph model offers a good compromise between knowledge representation and the possibility of performing graph analytics, which we consider essential for enabling advanced pattern detection. Then, we enhance the KG with valuable properties by employing carefully fine-tuned open-source LLMs, i.e., BERT and Mistral-7B models, which enrich and augment the quality of the KG, allowing in-depth analysis of legislative data.}
}
@article{BUCHMANN2024102324,
title = {Large language models: Expectations for semantics-driven systems engineering},
journal = {Data & Knowledge Engineering},
volume = {152},
pages = {102324},
year = {2024},
issn = {0169-023X},
doi = {https://doi.org/10.1016/j.datak.2024.102324},
url = {https://www.sciencedirect.com/science/article/pii/S0169023X2400048X},
author = {Robert Buchmann and Johann Eder and Hans-Georg Fill and Ulrich Frank and Dimitris Karagiannis and Emanuele Laurenzi and John Mylopoulos and Dimitris Plexousakis and Maribel Yasmina Santos},
keywords = {Large language models, Systems engineering, Conceptual modeling, Knowledge engineering},
abstract = {The hype of Large Language Models manifests in disruptions, expectations or concerns in scientific communities that have focused for a long time on design-oriented research. The current experiences with Large Language Models and associated products (e.g. ChatGPT) lead to diverse positions regarding the foreseeable evolution of such products from the point of view of scholars who have been working with designed abstractions for most of their careers - typically relying on deterministic design decisions to ensure systems and automation reliability. Such expectations are collected in this paper in relation to a flavor of systems engineering that relies on explicit knowledge structures, introduced here as “semantics-driven systems engineering”. The paper was motivated by the panel discussion that took place at CAiSE 2023 in Zaragoza, Spain, during the workshop on Knowledge Graphs for Semantics-driven Systems Engineering (KG4SDSE). The workshop brought together Conceptual Modeling researchers with an interest in specific applications of Knowledge Graphs and the semantic enrichment benefits they can bring to systems engineering. The panel context and consensus are summarized at the end of the paper, preceded by a proposed research agenda considering the expressed positions.}
}
@article{FAN2024103646,
title = {CuPe-KG: Cultural perspective–based knowledge graph construction of tourism resources via pretrained language models},
journal = {Information Processing & Management},
volume = {61},
number = {3},
pages = {103646},
year = {2024},
issn = {0306-4573},
doi = {https://doi.org/10.1016/j.ipm.2024.103646},
url = {https://www.sciencedirect.com/science/article/pii/S0306457324000062},
author = {Zhanling Fan and Chongcheng Chen},
keywords = {Knowledge graph, Pretrained language models, Cultural tourism, Cultural type, ChatGPT, Travel intelligence},
abstract = {Tourism knowledge graphs lack cultural content, limiting their usefulness for cultural tourists.This paper presents the development of a cultural perspective-based knowledge graph (CuPe-KG). We evaluated fine-tuning ERNIE 3.0 (FT-ERNIE) and ChatGPT for cultural type recognition to strengthen the relationship between tourism resources and cultures. Our investigation used an annotated cultural tourism resource dataset containing 2,745 items across 16 cultural types. The results showed accuracy scores for FT-ERNIE and ChatGPT of 0.81 and 0.12, respectively, with FT-ERNIE achieving a micro-F1 score of 0.93, a 26 percentage point lead over ChatGPT's score of 0.67. These underscore FT-ERNIE's superior performance (the shortcoming is the need to annotate data) while highlighting ChatGPT's limitations because of insufficient Chinese training data and lower identification accuracy in professional knowledge. A novel ontology was designed to facilitate the construction of CuPe-KG, including elements such as cultural types, historical figures, events, and intangible cultural heritage. CuPe-KG effectively addresses cultural tourism visitors’ information retrieval needs.}
}
@article{SAHBI20243083,
title = {Automatic Ontology Population from Textual Advertisements: LLM vs. Semantic Approach},
journal = {Procedia Computer Science},
volume = {246},
pages = {3083-3092},
year = {2024},
note = {28th International Conference on Knowledge Based and Intelligent information and Engineering Systems (KES 2024)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.09.364},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924023925},
author = {Aya Sahbi and Céline Alec and Pierre Beust},
keywords = {Ontology Population, LLM, Textual Advertisement},
abstract = {Automatic ontology population involves identifying, extracting and integrating information from various sources to instantiate the classes and properties of an ontology, thereby building a domain Knowledge Graph (KG). In this paper, we compare two text-based ontology population techniques: KOnPoTe, a semantic approach based on textual and domain knowledge analysis, and a generative AI approach utilizing Claude, a Large Language Model (LLM). We present experiments conducted on two French sales advertisement domains: real estate and boats, and discuss the strengths and limitations of both approaches.}
}
@article{JIANG2024100723,
title = {Generating the assembly instructions of helicopter subassemblies using the hierarchical pruning strategy and large language model},
journal = {Journal of Industrial Information Integration},
volume = {42},
pages = {100723},
year = {2024},
issn = {2452-414X},
doi = {https://doi.org/10.1016/j.jii.2024.100723},
url = {https://www.sciencedirect.com/science/article/pii/S2452414X24001663},
author = {Mingjie Jiang and Yu Guo and Shaohua Huang and Jun Pu},
keywords = {Assembly instruction generation, Knowledge graph, Subgraph matching, Large language model, Helicopter subassembly assembly},
abstract = {Assembly instructions are process documents in detail describing the operation steps, materials, tools, fixtures, and assembly sequences in assembly procedures. Due to assembly instructions including numerous contents, and the content being easy for workers to understand, process designers need to spend lots of time thinking and authoring assembly instructions to ensure that workers can complete the assembly task according to the assembly instructions. Focusing on the difficulties of the variety of assembly instructions and the process factors implicit in the standard languages of assembly instructions, a method of assembly instruction generation for helicopter subassemblies is proposed. First, a data representation model of multi-source heterogeneous knowledge and information based on knowledge graphs is designed and established. Then, a hierarchical pruning VF3 algorithm is presented to reuse assembly instructions according to hybrid similarity. Finally, a process factor revision model based on RoBERTa-BiLSTM-CRF is proposed to generate revised assembly instructions. Helicopter subassemblies, which contain 11,240 assembly procedures, are used to evaluate the performance of the method for generating assembly instructions. The proposed method greatly reduces the time cost of assembly instruction authoring and promotes the intelligent development of assembly process design.}
}
@article{MA2024104488,
title = {Large language models in food science: Innovations, applications, and future},
journal = {Trends in Food Science & Technology},
volume = {148},
pages = {104488},
year = {2024},
issn = {0924-2244},
doi = {https://doi.org/10.1016/j.tifs.2024.104488},
url = {https://www.sciencedirect.com/science/article/pii/S092422442400164X},
author = {Peihua Ma and Shawn Tsai and Yiyang He and Xiaoxue Jia and Dongyang Zhen and Ning Yu and Qin Wang and Jaspreet K.C. Ahuja and Cheng-I Wei},
keywords = {Natural language processing, Generative AI, Pre-trained model, Large language model},
abstract = {Background
Large Language Models (LLMs) are increasingly significant in food science, transforming areas such as recipe development, nutritional analysis, food safety, and supply chain management. These models bring sophisticated decision-making, predictive analytics, and natural language processing capabilities to various aspects of food science.
Scope and approach
The review focuses on the application of LLMs in enhancing food science, with a strong emphasis on food safety, especially in contaminant detection and risk assessment. It addresses the roles of AI and LLMs in regulatory compliance and food quality control. Challenges like data biases, misinformation risks, and implementation hurdles, including data limitations and ethical concerns, are discussed. The necessity for interdisciplinary collaboration to overcome these challenges is also highlighted.
Key findings and conclusions
LLMs hold significant potential in automating processes and improving accuracy and efficiency in the global food system. Successful implementation requires continuous updates and ethical considerations. The paper provides insights for academics, industry professionals, and policymakers on the impact of LLMs in food science, emphasizing the importance of interdisciplinary efforts in this domain. Despite potential challenges, the integration of LLMs in food science promises transformative advancements.}
}
@article{ERICKSON2025100853,
title = {LLM experimentation through knowledge graphs: Towards improved management, repeatability, and verification},
journal = {Journal of Web Semantics},
volume = {85},
pages = {100853},
year = {2025},
issn = {1570-8268},
doi = {https://doi.org/10.1016/j.websem.2024.100853},
url = {https://www.sciencedirect.com/science/article/pii/S1570826824000398},
author = {John S. Erickson and Henrique Santos and Vládia Pinheiro and Jamie P. McCusker and Deborah L. McGuinness},
keywords = {Generative large language models, Knowledge graphs, Retrieval-Augmented Generation, Explainability and governance in AI},
abstract = {Generative large language models (LLMs) have transformed AI by enabling rapid, human-like text generation, but they face challenges, including managing inaccurate information generation. Strategies such as prompt engineering, Retrieval-Augmented Generation (RAG), and incorporating domain-specific Knowledge Graphs (KGs) aim to address their issues. However, challenges remain in achieving the desired levels of management, repeatability, and verification of experiments, especially for developers using closed-access LLMs via web APIs, complicating integration with external tools. To tackle this, we are exploring a software architecture to enhance LLM workflows by prioritizing flexibility and traceability while promoting more accurate and explainable outputs. We describe our approach and provide a nutrition case study demonstrating its ability to integrate LLMs with RAG and KGs for more robust AI solutions.}
}
@article{SUN2025128726,
title = {SF-GPT: A training-free method to enhance capabilities for knowledge graph construction in LLMs},
journal = {Neurocomputing},
volume = {613},
pages = {128726},
year = {2025},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2024.128726},
url = {https://www.sciencedirect.com/science/article/pii/S0925231224014978},
author = {Lizhuang Sun and Peng Zhang and Fang Gao and Yuan An and Zhixing Li and Yuanwei Zhao},
keywords = {Knowledge graph, Triple extraction, Large language model, Knowledge fusion},
abstract = {Knowledge graphs (KGs) are constructed by extracting knowledge triples from text and fusing knowledge, enhancing information retrieval efficiency. Current methods for knowledge triple extraction include ”Pretrain and Fine-tuning” and Large Language Models (LLMs). The former shifts effort from manual extraction to dataset annotation and suffers from performance degradation with different test and training set distributions. LLMs-based methods face errors and incompleteness in extraction. We introduce SF-GPT, a training-free method to address these issues. Firstly, we propose the Entity Extraction Filter (EEF) module to filter triple generation results, addressing evaluation and cleansing challenges. Secondly, we introduce a training-free Entity Alignment Module based on Entity Alias Generation (EAG), tackling semantic richness and interpretability issues in LLM-based knowledge fusion. Finally, our Self-Fusion Subgraph strategy uses multi-response self-fusion and a common entity list to filter triple results, reducing noise from LLMs’ multi-responses. In experiments, SF-GPT showed a 55.5% increase in recall and a 32.6% increase in F1 score on the BDNC dataset compared to the UniRel model trained on the NYT dataset and achieved a 5% improvement in F1 score compared to GPT-4+EEF baseline on the WebNLG dataset in the case of a fusion round of three. SF-GPT offers a promising way to extract knowledge from unstructured information.}
}
@article{ZHANG2025104220,
title = {AttacKG+: Boosting attack graph construction with Large Language Models},
journal = {Computers & Security},
volume = {150},
pages = {104220},
year = {2025},
issn = {0167-4048},
doi = {https://doi.org/10.1016/j.cose.2024.104220},
url = {https://www.sciencedirect.com/science/article/pii/S0167404824005261},
author = {Yongheng Zhang and Tingwen Du and Yunshan Ma and Xiang Wang and Yi Xie and Guozheng Yang and Yuliang Lu and Ee-Chien Chang},
keywords = {Cyber threat intelligence analysis, Attack graph construction, Large Language Models},
abstract = {Attack graph construction seeks to convert textual cyber threat intelligence (CTI) reports into structured representations, portraying the evolutionary traces of cyber attacks. Even though previous research has proposed various methods to construct attack graphs, they generally suffer from limited generalization capability to diverse knowledge types as well as requirement of expertise in model design and tuning. Addressing these limitations, we seek to utilize Large Language Models (LLMs), which have achieved enormous success in a broad range of tasks given exceptional capabilities in both language understanding and zero-shot task fulfillment. Thus, we propose a fully automatic LLM-based framework to construct attack graphs named: AttacKG+. Our framework consists of four consecutive modules: rewriter, parser, identifier, and summarizer, each of which is implemented by instruction prompting and in-context learning empowered by LLMs. Furthermore, we upgrade the existing attack knowledge schema and propose a comprehensive version. We represent a cyber attack as a temporally unfolding event, each temporal step of which encapsulates three layers of representation, including behavior graph, MITRE TTP labels, and state summary. Extensive evaluation demonstrates that: (1) our formulation seamlessly satisfies the information needs in threat event analysis, (2) our construction framework is effective in faithfully and accurately extracting the information defined by AttacKG+. and (3) our attack graph directly benefits downstream security practices such as attack reconstruction. All the code and datasets will be released upon acceptance.}
}
@article{BABAIHA2024100095,
title = {Rationalism in the face of GPT hypes: Benchmarking the output of large language models against human expert-curated biomedical knowledge graphs},
journal = {Artificial Intelligence in the Life Sciences},
volume = {5},
pages = {100095},
year = {2024},
issn = {2667-3185},
doi = {https://doi.org/10.1016/j.ailsci.2024.100095},
url = {https://www.sciencedirect.com/science/article/pii/S2667318524000023},
author = {Negin Sadat Babaiha and Sathvik Guru Rao and Jürgen Klein and Bruce Schultz and Marc Jacobs and Martin Hofmann-Apitius},
keywords = {Large language models (LLMs), Natural language processing (NLP), Biomedical text mining, Biomedical knowledge graphs, Biological expression language (BEL)},
abstract = {Biomedical knowledge graphs (KGs) hold valuable information regarding biomedical entities such as genes, diseases, biological processes, and drugs. KGs have been successfully employed in challenging biomedical areas such as the identification of pathophysiology mechanisms or drug repurposing. The creation of high-quality KGs typically requires labor-intensive multi-database integration or substantial human expert curation, both of which take time and contribute to the workload of data processing and annotation. Therefore, the use of automatic systems for KG building and maintenance is a prerequisite for the wide uptake and utilization of KGs. Technologies supporting the automated generation and updating of KGs typically make use of Natural Language Processing (NLP), which is optimized for extracting implicit triples described in relevant biomedical text sources. At the core of this challenge is how to improve the accuracy and coverage of the information extraction module by utilizing different models and tools. The emergence of pre-trained large language models (LLMs), such as ChatGPT which has grown in popularity dramatically, has revolutionized the field of NLP, making them a potential candidate to be used in text-based graph creation as well. So far, no previous work has investigated the power of LLMs on the generation of cause-and-effect networks and KGs encoded in Biological Expression Language (BEL). In this paper, we present initial studies towards one-shot BEL relation extraction using two different versions of the Generative Pre-trained Transformer (GPT) models and evaluate its performance by comparing the extracted results to a highly accurate, manually curated BEL KG curated by domain experts.}
}
@article{HOLLAND2024100,
title = {Large language model based agent for process planning of fiber composite structures},
journal = {Manufacturing Letters},
volume = {40},
pages = {100-103},
year = {2024},
issn = {2213-8463},
doi = {https://doi.org/10.1016/j.mfglet.2024.03.010},
url = {https://www.sciencedirect.com/science/article/pii/S2213846324000221},
author = {Maximilian Holland and Kunal Chaudhari},
keywords = {Large language model, Generative AI, Planning agent, Process planning, Fiber composites, LangChain, OpenAI},
abstract = {Process planning is a crucial activity, connecting product development and manufacturing of fiber composite structures. Recently published Large Language Models (LLM) promise more flexible and autonomous workflows compared to state of the art automation methods. An autonomous agent for process planning of fiber composite structures is implemented with the LangChain framework, based on OpenAI’s GPT-4 language model. The agent is equipped with deterministic tools which encode a-priori process planning knowledge. It can handle different process planning problems, such as cycle time estimation and resource allocation. Combinations thereof are solved through executing a multi-step solution path.}
}
@article{MUSTAPHA2025103066,
title = {A survey of emerging applications of large language models for problems in mechanics, product design, and manufacturing},
journal = {Advanced Engineering Informatics},
volume = {64},
pages = {103066},
year = {2025},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2024.103066},
url = {https://www.sciencedirect.com/science/article/pii/S1474034624007171},
author = {K.B. Mustapha},
keywords = {Pre-trained language models, Large language models, Generative AI, Generative pre-trained transformer, Mechanical engineering, Engineering design, Manufacturing, Mechanics, Intelligent digital twins, Intelligent maintenance, Creativity},
abstract = {In the span of three years, the application of large language models (LLMs) has accelerated across a multitude of professional sectors. Amid this development, a new collection of studies has manifested around leveraging LLMs for segments of the mechanical engineering (ME) field. Concurrently, it has become clear that general-purpose LLMs faced hurdles when deployed in this domain, partly due to their training on discipline-agnostic data. Accordingly, there is a recent uptick of derivative ME-specific LLMs being reported. As the research community shifts towards these new LLM-centric solutions for ME-related problems, the shift compels a deeper look at the diffusion of LLMs in this emerging landscape. Consequently, this review consolidates the diversity of ME-tailored LLMs use cases and identifies the supportive technical stacks associated with these implementations. Broadly, the review demonstrates how various categories of LLMs are re-shaping concrete aspects of engineering design, manufacturing and applied mechanics. At a more specific level, it uncovered emerging LLMs’ role in boosting the intelligence of digital twins, enriching bidirectional communication within the human-cyber-physical infrastructure, advancing the development of intelligent process planning in manufacturing and facilitating inverse mechanics. It further spotlights the coupling of LLMs with other generative models for promoting efficient computer-aided conceptual design, prototyping, knowledge discovery and creativity. Finally, it revealed training modalities/infrastructures necessary for developing ME-specific language models, discussed LLMs' features that are incongruent with typical engineering workflows, and concluded with prescriptive approaches to mitigate impediments to the progressive adoption of LLMs as part of advanced intelligent solutions.}
}
@article{KIM20242190,
title = {Assessing the utility of large language models for phenotype-driven gene prioritization in the diagnosis of rare genetic disease},
journal = {The American Journal of Human Genetics},
volume = {111},
number = {10},
pages = {2190-2202},
year = {2024},
issn = {0002-9297},
doi = {https://doi.org/10.1016/j.ajhg.2024.08.010},
url = {https://www.sciencedirect.com/science/article/pii/S0002929724002969},
author = {Junyoung Kim and Kai Wang and Chunhua Weng and Cong Liu},
keywords = {large language model, rare disease diagnosis, gene prioritization, precision medicine, artificial intelligence, generative pre-trained transformers, phenotypes},
abstract = {Summary
Phenotype-driven gene prioritization is fundamental to diagnosing rare genetic disorders. While traditional approaches rely on curated knowledge graphs with phenotype-gene relations, recent advancements in large language models (LLMs) promise a streamlined text-to-gene solution. In this study, we evaluated five LLMs, including two generative pre-trained transformers (GPT) series and three Llama2 series, assessing their performance across task completeness, gene prediction accuracy, and adherence to required output structures. We conducted experiments, exploring various combinations of models, prompts, phenotypic input types, and task difficulty levels. Our findings revealed that the best-performed LLM, GPT-4, achieved an average accuracy of 17.0% in identifying diagnosed genes within the top 50 predictions, which still falls behind traditional tools. However, accuracy increased with the model size. Consistent results were observed over time, as shown in the dataset curated after 2023. Advanced techniques such as retrieval-augmented generation (RAG) and few-shot learning did not improve the accuracy. Sophisticated prompts were more likely to enhance task completeness, especially in smaller models. Conversely, complicated prompts tended to decrease output structure compliance rate. LLMs also achieved better-than-random prediction accuracy with free-text input, though performance was slightly lower than with standardized concept input. Bias analysis showed that highly cited genes, such as BRCA1, TP53, and PTEN, are more likely to be predicted. Our study provides valuable insights into integrating LLMs with genomic analysis, contributing to the ongoing discussion on their utilization in clinical workflows.}
}
@article{ZHENG2025115173,
title = {Mastering building management systems data points tagging with minimal examples: unveiling the power of large language models},
journal = {Energy and Buildings},
volume = {328},
pages = {115173},
year = {2025},
issn = {0378-7788},
doi = {https://doi.org/10.1016/j.enbuild.2024.115173},
url = {https://www.sciencedirect.com/science/article/pii/S0378778824012891},
author = {Zhiyu Zheng and Sylvain Marié and Elham Farazdaghi and Esma Yahia and Khal Makhoul and Théo Lagarde and Rani El Meouche and Fakhreddine Ababsa},
keywords = {Large Language Models, Building Management Systems, Brick Ontology, Semantic Web Technologies, Metadata Tagging, Few-Shot Learning, Prompt Engineering},
abstract = {The heterogeneity of metadata within Building Management Systems (BMS) poses substantial challenges for advanced analytics, including cross-building analysis. Over the past decade, metadata standard schemas such as Brick have been developed to address this challenge. Nevertheless, mapping BMS metadata with such standards accurately and efficiently continues to be a demanding task across both new and existing buildings. This work explores the application of Large Language Models (LLMs) to tag BMS data points, thus facilitating metadata standardization efforts. Manual or rule-based methods are not only labor-intensive but also error-prone. Similarly, supervised learning approaches using Machine Learning (ML) and Natural Language Processing (NLP) demand extensive labeled datasets, often making them laborious and inflexible to new BMS metadata types and tasks. We propose a novel three-step framework that enhances the tagging process by integrating a LLM with few-shot prompting and an embedding model. This approach not only improves result interpretability but also effectively mitigates hallucinations. This framework is further supported by analyses of the LLM’s inherent capabilities, prompt-aided specific interpretation and output formatting, and evaluations of few-shot sizes. Tested across five different building datasets, our approach, leveraging few-shot examples, achieves performance comparable to state-of-the-art supervised learning methods that rely on large labeled datasets.}
}
@article{HOU2025112622,
title = {Low-resource knowledge graph completion based on knowledge distillation driven by large language models},
journal = {Applied Soft Computing},
volume = {169},
pages = {112622},
year = {2025},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2024.112622},
url = {https://www.sciencedirect.com/science/article/pii/S1568494624013966},
author = {Wenlong Hou and Weidong Zhao and Ning Jia and Xianhui Liu},
keywords = {Knowledge graph completion, Knowledge reasoning, Link prediction, Large language models},
abstract = {Knowledge graph completion (KGC) refines the existing knowledge graph (KG) by predicting missing entities or relations. Existing methods are mainly based on embeddings or texts but only perform better with abundant labeled data. Hence, KGC in resource-constrained settings is a significant problem, which faces challenges of data imbalance across relations and lack of relation label semantics. Considering that Large Language Models (LLMs) demonstrate powerful reasoning and generation capabilities, this work proposes an LLM-driven Knowledge Graph Completion Distillation (KGCD) model to address low-resource KGC. A two-stage framework is developed, involving teacher-student distillation by using LLM to improve reasoning, followed by fine-tuning on real-world low-resource datasets. To deal with data imbalance, a hybrid prompt design for LLM is proposed, which includes rethink and open prompts. Furthermore, a virtual relation label generation strategy enhances the model’s understanding of triples. Extensive experiments on three benchmarks have shown that KGCD’s effectiveness for low-resource KGC, achieving improvements in Mean Reciprocal Rank (MRR) by 11% and Hits@1 by 10% on the WN18, MRR by 10% and Hits@1 by 14% on the WN18RR, and MRR by 12% and Hits@1 by 11% on the YAGO3-10.}
}
@article{CIATTO2025112940,
title = {Large language models as oracles for instantiating ontologies with domain-specific knowledge},
journal = {Knowledge-Based Systems},
volume = {310},
pages = {112940},
year = {2025},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2024.112940},
url = {https://www.sciencedirect.com/science/article/pii/S0950705124015740},
author = {Giovanni Ciatto and Andrea Agiollo and Matteo Magnini and Andrea Omicini},
keywords = {Ontology population, Large language models, Nutrition, Automation, Domain-specific knowledge},
abstract = {Background:
Endowing intelligent systems with semantic data commonly requires designing and instantiating ontologies with domain-specific knowledge. Especially in the early phases, those activities are typically performed manually by human experts possibly leveraging on their own experience. The resulting process is therefore time-consuming, error-prone, and often biased by the personal background of the ontology designer.
Objective:
To mitigate that issue, we propose a novel domain-independent approach to automatically instantiate ontologies with domain-specific knowledge, by leveraging on large language models (LLMs) as oracles.
Methods:
Starting from (i) an initial schema composed by inter-related classes and properties and (ii) a set of query templates, our method queries the LLM multiple times, and generates instances for both classes and properties from its replies. Thus, the ontology is automatically filled with domain-specific knowledge, compliant to the initial schema. As a result, the ontology is quickly and automatically enriched with manifold instances, which experts may consider to keep, adjust, discard, or complement according to their own needs and expertise.
Contribution:
We formalise our method in general way and instantiate it over various LLMs, as well as on a concrete case study. We report experiments rooted in the nutritional domain where an ontology of food meals and their ingredients is automatically instantiated from scratch, starting from a categorisation of meals and their relationships. There, we analyse the quality of the generated ontologies and compare ontologies attained by exploiting different LLMs. Experimentally, our approach achieves a quality metric that is up to five times higher than the state-of-the-art, while reducing erroneous entities and relations by up to ten times. Finally, we provide a SWOT analysis of the proposed method.}
}
@article{WALLER2024103940,
title = {Questionable devices: Applying a large language model to deliberate carbon removal},
journal = {Environmental Science & Policy},
volume = {162},
pages = {103940},
year = {2024},
issn = {1462-9011},
doi = {https://doi.org/10.1016/j.envsci.2024.103940},
url = {https://www.sciencedirect.com/science/article/pii/S1462901124002740},
author = {Dr. Laurie Waller and Dr. David Moats and Dr. Emily Cox and Dr. Rob Bellamy},
keywords = {Carbon removal, Deliberation, Devices, Publics, Experiments in participation, Large language models, Generative AI},
abstract = {This paper presents a device-centred approach to deliberation, developed in deliberative workshops appraising methods for removing carbon dioxide from the air. Our approach involved deploying the Large Language Model application ChatGPT (sometimes termed “generative AI”) to elicit questions and generate texts about carbon removal. We develop the notion of the “questionable” device to foreground the informational unruliness ChatGPT introduced into the deliberations. The analysis highlights occasions where the deliberative apparatus became a focus of collective critique, including over: issue definitions, expert-curated resources, lay identities and social classifications. However, in this set-up ChatGPT was all too often engaged unquestioningly as an instrument for informing discussion; its instrumental lure disguising the unruliness it introduced into the workshops. In concluding, we elaborate the notion of questionable devices and reflect on the way carbon removal has been “devised” as a field in want of informed deliberation.}
}
@article{ONG2025126648,
title = {Dynamic link prediction: Using language models and graph structures for temporal knowledge graph completion with emerging entities and relations},
journal = {Expert Systems with Applications},
volume = {272},
pages = {126648},
year = {2025},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2025.126648},
url = {https://www.sciencedirect.com/science/article/pii/S0957417425002702},
author = {Ryan Ong and Jiahao Sun and Yi-Ke Guo and Ovidiu Serban},
keywords = {Dynamic knowledge graphs, Language models, Link prediction},
abstract = {Knowledge graphs (KGs) represent real-world facts through entities and relations. However, static KGs fail to capture continuously emerging entities and relations over time. Temporal knowledge graphs address this by incorporating time information or providing multiple sequential snapshots of a static knowledge graph. Most existing work focuses on static KGs with fixed sets of entities and relations, meaning existing methods still struggle to encode emerging entities and relations. Therefore, we propose a novel methodology of combining language models and graph structure to enable the encoding of unseen entities and relations for temporal KG completion. Specifically, we encode relations with RoBERTa and entities using neighbouring relations alongside the entity’s relation type to provide contextual information. We evaluate our methodology on three datasets with emerging entities and relations over temporal snapshots: LKGE-Hybrid, FB-MBE, and the mergers and acquisitions domain TKGQA dataset. Our experiments show that our model achieves new state-of-the-art results on FB-MBE and LKGE-Hybrid while providing strong benchmark results for the TKGQA dataset. Our ablation studies show us that graph structure information is only beneficial if there is sufficient connectivity with the knowledge graph since sparser knowledge graphs can lead to noisy signals. We also explore the performance of Llama v2 on temporal link prediction, and the results show that current LLMs struggle with domain-specific temporal link prediction. Overall, our work provides an essential advance around effectively encoding continuously emerging entities and relations for temporal link prediction across evolving knowledge graphs over time.}
}
@article{WANG2025103342,
title = {Multi large language model collaboration framework for few-shot link prediction in evolutionary fault diagnosis event graphs},
journal = {Journal of Process Control},
volume = {145},
pages = {103342},
year = {2025},
issn = {0959-1524},
doi = {https://doi.org/10.1016/j.jprocont.2024.103342},
url = {https://www.sciencedirect.com/science/article/pii/S0959152424001823},
author = {Tian Wang and Ping Wang and Feng Yang and Shuai Wang and Qiang Fang and Meng Chi},
keywords = {Fault diagnosis, Evolutionary event graph, Link prediction, Large language model},
abstract = {Fault-tolerant control is crucial for ensuring flight safety in aircraft. However, existing methods for fault diagnosis in nonlinear systems face challenges such as data sparsity, limited generalization, and lack of explainability. To address these challenges, this paper proposes a multi-large language model (LLM) collaboration framework for few-shot link prediction in evolutionary fault diagnosis event graphs. The framework consists of two modules: the Clustering Language Model (LMc) and the Prediction Language Model (LMP). LMc utilizes the semantic understanding capabilities of LLMs to cluster entities and decompose large-scale graph data into smaller subgraphs, mitigating the impact of data sparsity on link prediction. LMP leverages the reasoning capabilities of LLMs to perform link prediction within each subgraph and fuses the prediction results to enhance accuracy and generalization. The completion of the link serves as a means to an end, which is to conduct fault diagnosis reasoning on a more detailed knowledge graph, thereby significantly improving the accuracy of fault diagnosis. Experimental results demonstrate that the proposed framework outperforms traditional embedding models and existing meta-learning methods on multiple datasets, particularly for sparse and background-rich datasets. This approach offers a novel solution for fault diagnosis in nonlinear systems, with significant theoretical and practical value.}
}
@article{SEQUEDA2025100858,
title = {Knowledge Graphs as a source of trust for LLM-powered enterprise question answering},
journal = {Journal of Web Semantics},
volume = {85},
pages = {100858},
year = {2025},
issn = {1570-8268},
doi = {https://doi.org/10.1016/j.websem.2024.100858},
url = {https://www.sciencedirect.com/science/article/pii/S1570826824000441},
author = {Juan Sequeda and Dean Allemang and Bryon Jacob},
keywords = {Knowledge Graph, LLM, Large Language Model, Generative AI, Question answering, Knowledge engineering, SPARQL, SQL, OWL, R2RML},
abstract = {Generative AI provides an innovative and exciting way to manage knowledge and data at any scale; for small projects, at the enterprise level, and even at a world wide web scale. It is tempting to think that Generative AI has made other knowledge-based technologies obsolete; that anything we wanted to do with knowledge-based systems, Knowledge Graphs or even expert systems can instead be done with Generative AI. Our position is counter to that conclusion. Our practical experience on implementing enterprise question answering systems using Generative AI has shown that Knowledge Graphs support this infrastructure in multiple ways: they provide a formal framework to evaluate the validity of a query generated by an LLM, serve as a foundation for explaining results, and offer access to governed and trusted data. In this position paper, we share our experience, present industry needs, and outline the opportunities for future research contributions.}
}
@article{BRAHMACHARY2025129272,
title = {Large language model-based evolutionary optimizer: Reasoning with elitism},
journal = {Neurocomputing},
volume = {622},
pages = {129272},
year = {2025},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2024.129272},
url = {https://www.sciencedirect.com/science/article/pii/S0925231224020435},
author = {Shuvayan Brahmachary and Subodh M. Joshi and Aniruddha Panda and Kaushik Koneripalli and Arun Kumar Sagotra and Harshil Patel and Ankush Sharma and Ameya D. Jagtap and Kaushic Kalyanaraman},
keywords = {Large language models, Evolutionary Optimizers, Multi-objective optimization, Aerodynamic Design},
abstract = {Large Language Models (LLMs) have demonstrated remarkable reasoning abilities, prompting interest in their application as black-box optimizers. This paper asserts that LLMs possess the capability for zero-shot optimization across diverse scenarios, including multi-objective and high-dimensional problems. We introduce a novel population-based method for numerical optimization using LLMs called Large Language-Model-Based Evolutionary Optimizer (LEO). Our hypothesis is supported through numerical examples, spanning benchmark and industrial engineering problems such as supersonic nozzle shape optimization, heat transfer, and windfarm layout optimization. We compare our method to several gradient-based and gradient-free optimization approaches. While LLMs yield comparable results to state-of-the-art methods, their imaginative nature and propensity to hallucinate demand careful handling. We provide practical guidelines for obtaining reliable answers from LLMs and discuss method limitations and potential research directions.}
}
@article{XIAO2025102888,
title = {A comprehensive survey of large language models and multimodal large language models in medicine},
journal = {Information Fusion},
volume = {117},
pages = {102888},
year = {2025},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2024.102888},
url = {https://www.sciencedirect.com/science/article/pii/S1566253524006663},
author = {Hanguang Xiao and Feizhong Zhou and Xingyue Liu and Tianqi Liu and Zhipeng Li and Xin Liu and Xiaoxuan Huang},
keywords = {Large language model, Multimodal large language model, Medicine, Healthcare, Clinical application},
abstract = {Since the release of ChatGPT and GPT-4, large language models (LLMs) and multimodal large language models (MLLMs) have attracted widespread attention for their exceptional capabilities in understanding, reasoning, and generation, introducing transformative paradigms for integrating artificial intelligence into medicine. This survey provides a comprehensive overview of the development, principles, application scenarios, challenges, and future directions of LLMs and MLLMs in medicine. Specifically, it begins by examining the paradigm shift, tracing the transition from traditional models to LLMs and MLLMs, and highlighting the unique advantages of these LLMs and MLLMs in medical applications. Next, the survey reviews existing medical LLMs and MLLMs, providing detailed guidance on their construction and evaluation in a clear and systematic manner. Subsequently, to underscore the substantial value of LLMs and MLLMs in healthcare, the survey explores five promising applications in the field. Finally, the survey addresses the challenges confronting medical LLMs and MLLMs and proposes practical strategies and future directions for their integration into medicine. In summary, this survey offers a comprehensive analysis of the technical methodologies and practical clinical applications of medical LLMs and MLLMs, with the goal of bridging the gap between these advanced technologies and clinical practice, thereby fostering the evolution of the next generation of intelligent healthcare systems.}
}
@article{ZHANG2025125861,
title = {LLM-TSFD: An industrial time series human-in-the-loop fault diagnosis method based on a large language model},
journal = {Expert Systems with Applications},
volume = {264},
pages = {125861},
year = {2025},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2024.125861},
url = {https://www.sciencedirect.com/science/article/pii/S0957417424027283},
author = {Qi Zhang and Chao Xu and Jie Li and Yicheng Sun and Jinsong Bao and Dan Zhang},
keywords = {Time series, Fault diagnosis 2.0, Task-driven, Large language model, Human-in-the-loop},
abstract = {Industrial time series data provides real-time information about the operational status of equipment and helps identify anomalies. Data-driven and knowledge-guided methods have become predominant in this field. However, these methods depend on industrial domain knowledge and high-quality industrial data which can lead to issues such as unclear diagnostic results and lengthy development cycles. This paper introduces a novel human-in-the-loop task-driven approach to reduce reliance on manually annotated data and improve the interpretability of diagnostic outcomes. This approach utilises a large language model for fault detection, fostering process autonomy and enhancing human–machine collaboration. Furthermore, this paper explores four key roles of the large language model: managing the data pipeline, correcting causality, controlling model management, and making decisions about diagnostic results. Additionally, it presents a prompt structure designed for fault diagnosis of time series data, enabling the large language model to realize task-driven. Finally, the paper validates the proposed framework through a case study in the context of steel metallurgy.}
}
@article{SEO2025,
title = {Performance Assessment of Large Language Models in Medical Consultation: Comparative Study},
journal = {JMIR Medical Informatics},
volume = {13},
year = {2025},
issn = {2291-9694},
doi = {https://doi.org/10.2196/64318},
url = {https://www.sciencedirect.com/science/article/pii/S229196942500033X},
author = {Sujeong Seo and Kyuli Kim and Heyoung Yang},
keywords = {artificial intelligence, biomedical, large language model, depression, similarity measurement, text validity},
abstract = {Background
The recent introduction of generative artificial intelligence (AI) as an interactive consultant has sparked interest in evaluating its applicability in medical discussions and consultations, particularly within the domain of depression.
Objective
This study evaluates the capability of large language models (LLMs) in AI to generate responses to depression-related queries.
Methods
Using the PubMedQA and QuoraQA data sets, we compared various LLMs, including BioGPT, PMC-LLaMA, GPT-3.5, and Llama2, and measured the similarity between the generated and original answers.
Results
The latest general LLMs, GPT-3.5 and Llama2, exhibited superior performance, particularly in generating responses to medical inquiries from the PubMedQA data set.
Conclusions
Considering the rapid advancements in LLM development in recent years, it is hypothesized that version upgrades of general LLMs offer greater potential for enhancing their ability to generate “knowledge text” in the biomedical domain compared with fine-tuning for the biomedical field. These findings are expected to contribute significantly to the evolution of AI-based medical counseling systems.}
}
@article{YU2025104068,
title = {Amplifying commonsense knowledge via bi-directional relation integrated graph-based contrastive pre-training from large language models},
journal = {Information Processing & Management},
volume = {62},
number = {3},
pages = {104068},
year = {2025},
issn = {0306-4573},
doi = {https://doi.org/10.1016/j.ipm.2025.104068},
url = {https://www.sciencedirect.com/science/article/pii/S030645732500010X},
author = {Liu Yu and Fenghui Tian and Ping Kuang and Fan Zhou},
keywords = {Commonsense knowledge, Large language models, Knowledge generation, LLMs for KG generation},
abstract = {Commonsense knowledge graph acquisition (CKGA) is vital in numerous knowledge-intensive applications such as question-answering and knowledge reasoning. Conventional CKGA methods rely on node-level and unidirectional relations, making them suffer from a shallow grasp of between entities and relations. Moreover, they also demand expensive, labor-intensive human annotations, and the yielding CK lacks diversity and quality. Existing commonsense knowledge bases such as ConceptNet or ATOMIC often struggle with significant scarcity and pose a major challenge in meeting the high demand for a vast amount of commonsense information. Given the recent momentum of large language models (LLMs), there is growing interest in leveraging them to overcome the above challenges. In this study, we propose a new paradigm to amplify commonsense knowledge via bi-directional relation integrated graph-based contrastive pre-training (BIRGHT) from the newest foundation models. BRIGHT is an integral and closed-loop framework composed of corpora construction, further contrastive pre-training, task-driven instruction tuning, filtering strategy, and an evaluation system. The key of BRIGHT is to leverage reverse relations to create a symmetric graph and transform the bi-directional relations into sentence-level ones. The reverse sentences are considered positive examples for forward sentences, and three types of negatives are introduced to ensure efficient contrastive learning, which mitigates the “reversal curse” issue as evidenced in experiments. Empirical results demonstrate that BRIGHT is able to generate novel knowledge (up to 397K) and that the GPT-4 acceptance rate is high quality, with up to 90.51% (ATOMIC) and 85.59% (ConceptNet) accuracy at top 1, which approaches human performance for these resources. Our BRIGHT is publicly available at https://github.com/GreyHuu/BRIGHT/tree/main.}
}
@article{LI2024112588,
title = {KnowBug: Enhancing Large language models with bug report knowledge for deep learning framework bug prediction},
journal = {Knowledge-Based Systems},
volume = {305},
pages = {112588},
year = {2024},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2024.112588},
url = {https://www.sciencedirect.com/science/article/pii/S095070512401222X},
author = {Chenglong Li and Zheng Zheng and Xiaoting Du and Xiangyue Ma and Zhengqi Wang and Xinheng Li},
keywords = {Bug report, Bug prediction, Deep learning framework, Large language model},
abstract = {Understanding and predicting the bug type is crucial for developers striving to enhance testing efficiency and reduce software release problems. Bug reports, although semi-structured, contain valuable semantic information, making their comprehension critical for accurate bug prediction. Recent advances in large language models (LLMs), especially generative LLMs, have demonstrated their power in natural language processing. Many studies have utilized these models to understand various forms of textual data. However, the capability of LLMs to fully understand bug reports remains uncertain. To tackle this challenge, we propose KnowBug, a framework designed to augment LLMs with knowledge from bug reports to improve their ability to predict bug types. In this framework, we utilize bug reports from open-source deep learning frameworks, design specialized prompts, and fine-tune LLMs to assess KnowBug’s proficiency in understanding bug reports and predicting different bug types.}
}
@article{YOU2025,
title = {Developing a Predictive Platform for Salmonella Antimicrobial Resistance Based on a Large Language Model and Quantum Computing},
journal = {Engineering},
year = {2025},
issn = {2095-8099},
doi = {https://doi.org/10.1016/j.eng.2025.01.013},
url = {https://www.sciencedirect.com/science/article/pii/S209580992500030X},
author = {Yujie You and Kan Tan and Zekun Jiang and Le Zhang},
keywords = { resistance prediction, Pan-genomics, Large language model, Quantum computing, Bioinformatics},
abstract = {As a common foodborne pathogen, Salmonella poses risks to public health safety, common given the emergence of antimicrobial-resistant strains. However, there is currently a lack of systematic platforms based on large language models (LLMs) for Salmonella resistance prediction, data presentation, and data sharing. To overcome this issue, we firstly propose a two-step feature-selection process based on the chi-square test and conditional mutual information maximization to find the key Salmonella resistance genes in a pan-genomics analysis and develop an LLM-based Salmonella antimicrobial-resistance predictive (SARPLLM) algorithm to achieve accurate antimicrobial-resistance prediction, based on Qwen2 LLM and low-rank adaptation. Secondly, we optimize the time complexity to compute the sample distance from the linear to logarithmic level by constructing a quantum data augmentation algorithm denoted as QSMOTEN. Thirdly, we build up a user-friendly Salmonella antimicrobial-resistance predictive online platform based on knowledge graphs, which not only facilitates online resistance prediction for users but also visualizes the pan-genomics analysis results of the Salmonella datasets.}
}
@article{JEON2025103076,
title = {Hybrid large language model approach for prompt and sensitive defect management: A comparative analysis of hybrid, non-hybrid, and GraphRAG approaches},
journal = {Advanced Engineering Informatics},
volume = {64},
pages = {103076},
year = {2025},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2024.103076},
url = {https://www.sciencedirect.com/science/article/pii/S1474034624007274},
author = {Kahyun Jeon and Ghang Lee},
keywords = {Housing defect management, Large language model (LLM), Question–answering (QA), Fine-tuning, Graph-retrieval augmented generation (GraphRAG), Synthetic data generation},
abstract = {This study aims to propose a large language model (LLM)-enhanced defect question-answering (QA) method that can secure private and sensitive data while yielding high performance. Prompt responses to residents’ complaints are crucial for preventing recurring defects. However, traditional defect analysis and response methods rely on the expertise of a few skilled workers, making it difficult to ensure timely responses. The rapid advancement of LLMs offers a potential solution for improving defect QA tasks. However, many companies prohibit the use of closed-source LLM services, such as ChatGPT, due to concerns about potential data breaches. One possible solution is to use open-source LLMs like Llama and BERT, which can be locally installed and used. However, open-source LLMs typically perform worse than closed-source LLMs. Although the performance of open-source LLMs can be greatly improved through fine-tuning, the preparation of training datasets requires a significant amount of time and labor. To address these challenges, this study proposes a hybrid defect QA method that deploys an open-source LLM for defect management to secure sensitive information, and a closed-source LLM for generating a training dataset to reduce both the time and labor required. To validate the proposed method, we compare it to the state-of-the-art LLMs, GPT-4o and Llama 3, as well as graph retrieval-augmented generation (GraphRAG)-based QA systems, which have been extensively studied recently. Our results show that the hybrid LLM-based QA method achieved the highest ROUGE score of 81.6%. These findings demonstrate superior practical applicability, enabling cost-effective data generation and reliable domain adaptation within a secure data environment. This approach is beneficial for domain-specific tasks beyond defect management, where the accurate provision of specialized information and integration of historical knowledge are essential.}
}
@article{MISHRA2025104045,
title = {PageLLM: Incremental approach for updating a Security Knowledge Graph by using Page ranking and Large language model},
journal = {Information Processing & Management},
volume = {62},
number = {3},
pages = {104045},
year = {2025},
issn = {0306-4573},
doi = {https://doi.org/10.1016/j.ipm.2024.104045},
url = {https://www.sciencedirect.com/science/article/pii/S0306457324004047},
author = {Chinmaya Mishra and Himangshu Sarma and Saravanan M.},
keywords = {Security knowledge graph, Knowledge graph, Knowledge representation learning, Page ranking, Embedding, Generative AI, Large language models (LLMs), Static knowledge graph (SKG), Incremental knowledge graph (IKG), Full knowledge graph (FKG)},
abstract = {Due to increase in cyber crime and evolution of sophisticated tools and techniques, Threat Intelligence plays a critical role. It helps defenders to stay ahead of attackers by developing the right defense mechanism to invade those attacks. In this regards security knowledge graph plays a critical role which can be used to signify complex entities and their relationship in a graphical structure. Further projecting those entities and relationships in to the lower dimension using several embedding techniques such as TransE help in many down streaming task. The learned embedding can be used to predict new cyber threat which is very helpful for defenders to stay alert and develop necessary weapons to stay ahead of an attack. One of the major challenge security knowledge graph has its dynamic nature of changing intelligence. Active learning can be used to only update the substantial portion of embedding rather than retraining the knowledge graph from scratch which has higher time and space complexity. Also given the rise in generative AI and large language models which are super rich in context, there is a scope of utilizing those for building a robust and good quality security knowledge graph. We will discuss a novel methodology called PageLLM which utilizes page ranking and LLMs to enable active learning in an incremental way and will improve the quality of knowledge graph through enriched context.}
}
@article{JUNG2025103445,
title = {PersonaCraft: Leveraging language models for data-driven persona development},
journal = {International Journal of Human-Computer Studies},
volume = {197},
pages = {103445},
year = {2025},
issn = {1071-5819},
doi = {https://doi.org/10.1016/j.ijhcs.2025.103445},
url = {https://www.sciencedirect.com/science/article/pii/S1071581925000023},
author = {Soon-Gyo Jung and Joni Salminen and Kholoud Khalil Aldous and Bernard J. Jansen},
keywords = {Personas, Persona generation, Survey research, Large language models, Generative AI},
abstract = {Generative AI, with its large language models (LLMs), provides various opportunities for the development of user-centric systems in human–computer interaction (HCI). Yet, use cases of LLMs in HCI are still scarce, calling for developing and evaluating real systems. We present PersonaCraft, a data-driven persona system using LLMs to address this need. The system analyzes a common source of user data – surveys – and generates personas, humanized representations of real segments in the data. By integrating LLMs with survey data analysis, PersonaCraft combines persona development and modern artificial intelligence methodologies to provide researchers and designers with user-centric insights from nearly any survey dataset about people. Various evaluations of the system, including with internal evaluators, general users (n = 127), and user experience professionals (n = 21), indicated that PersonaCraft personas scored high on all evaluation criteria of clarity, completeness, fluency, consistency, and credibility. The application of PersonaCraft can extend across a range of domains, including user research and population-level people research.}
}
@article{ZHANG2025102883,
title = {A survey on potentials, pathways and challenges of large language models in new-generation intelligent manufacturing},
journal = {Robotics and Computer-Integrated Manufacturing},
volume = {92},
pages = {102883},
year = {2025},
issn = {0736-5845},
doi = {https://doi.org/10.1016/j.rcim.2024.102883},
url = {https://www.sciencedirect.com/science/article/pii/S0736584524001704},
author = {Chao Zhang and Qingfeng Xu and Yongrui Yu and Guanghui Zhou and Keyan Zeng and Fengtian Chang and Kai Ding},
keywords = {Large language models, Intelligent manufacturing, New-generation artificial intelligence, LLM applications, Industry 5.0},
abstract = {Nowadays, Industry 5.0 starts to gain attention, which advocates that intelligent manufacturing should adequately consider the roles and needs of humans. In this context, how to enhance human capabilities or even liberate humans from the processes of perception, learning, decision-making, and execution has been one of the key issues to be addressed in intelligent manufacturing. Large language models (LLMs), as the breakthrough in new-generation artificial intelligence, could provide human-like interaction, reasoning, and replies suitable for various application scenarios, thus demonstrating significant potential to address the above issues by providing aid or becoming partners for humans in perception, learning, decision-making, and execution in intelligent manufacturing. The combination of LLMs and intelligent manufacturing has inherent advantages and is expected to become the next research hotspot. Hence, this paper primarily conducts a systematic literature review on the application of LLMs in intelligent manufacturing to identify the promising research topics with high potential for further investigations. Firstly, this paper reveals the concept, connotation, and foundational architecture of LLMs. Then, several typical and trending interdisciplinary LLM applications, such as healthcare, drug discovery, social & economic, education, and software development, are summarized, on which an LLM-enabled intelligent manufacturing architecture is designed to provide a reference for applying LLMs in intelligent manufacturing. Thirdly, the specific pathways for applying LLMs in intelligent manufacturing are explored from the perspectives of design, production, and service. Finally, this paper identifies the limitations, barriers, and challenges that will be encountered during the research and application of LLMs in intelligent manufacturing, while providing potential research directions to address these limitations, barriers, and challenges.}
}
@article{HANNAH2025100843,
title = {On the legal implications of Large Language Model answers: A prompt engineering approach and a view beyond by exploiting Knowledge Graphs},
journal = {Journal of Web Semantics},
volume = {84},
pages = {100843},
year = {2025},
issn = {1570-8268},
doi = {https://doi.org/10.1016/j.websem.2024.100843},
url = {https://www.sciencedirect.com/science/article/pii/S1570826824000295},
author = {George Hannah and Rita T. Sousa and Ioannis Dasoulas and Claudia d’Amato},
keywords = {Knowledge Graph, Large Language Models, Prompt engineering, Legislative texts},
abstract = {With the recent surge in popularity of Large Language Models (LLMs), there is the rising risk of users blindly trusting the information in the response. Nevertheless, there are cases where the LLM recommends actions that have potential legal implications and this may put the user in danger. We provide an empirical analysis on multiple existing LLMs showing the urgency of the problem. Hence, we propose a first short-term solution, consisting in an approach for isolating these legal issues through prompt engineering. We prove that this solution is able to stem some risks related to legal implications, nonetheless we also highlight some limitations. Hence, we argue on the need for additional knowledge-intensive resources and specifically Knowledge Graphs for fully solving these limitations. For the purpose, we draw our proposal aiming at designing and developing a solution powered by a legal Knowledge Graph (KG) that, besides capturing and alerting the user on possible legal implications coming from the LLM answers, is also able to provide actual evidence for them by supplying citations of the interested laws. We conclude with a brief discussion on the issues that may be needed to solve for building a comprehensive legal Knowledge Graph}
}
@article{ZHOU2024102333,
title = {CausalKGPT: Industrial structure causal knowledge-enhanced large language model for cause analysis of quality problems in aerospace product manufacturing},
journal = {Advanced Engineering Informatics},
volume = {59},
pages = {102333},
year = {2024},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2023.102333},
url = {https://www.sciencedirect.com/science/article/pii/S1474034623004615},
author = {Bin Zhou and Xinyu Li and Tianyuan Liu and Kaizhou Xu and Wei Liu and Jinsong Bao},
keywords = {Aerospace product, Causal quality-related knowledge graph, Large language model, Causal knowledge graph-guided prompt, Cause analysis of quality defects},
abstract = {The whole cycle for manufacturing aerospace thin-walled shells is a lengthy and sophisticated process. A large amount of quality-related data exists within and between processes, involving many types of quality defects and influencing factors. However, there are ambiguous causal associations among quality-related data affecting the shape-properties of the shell. Also, the coupling of long processes and multiple factors makes it hard to analyze the main factors that affect the quality defects in shell manufacturing. In this paper, taking into account the advantages of causal Scientology and the large language model (LLM), we propose an industrial structure causal knowledge-enhanced large language model for the cause analysis of quality defects in aerospace product manufacturing. To reinforce the causal associations among quality-related data deriving from manufacturing documents (product defect survey sheets, quality inspection, and maintenance reports), a structure causal graph-based sum-product network (SCG-SPN) model is designed to model machining quality-related knowledge and eliminate pseudo-association confounding factors by doing an intervention. Thus, a causal quality-related knowledge graph (CQKG) with high-quality causal associations is constructed. With this, to provide a trustworthy guarantee in responding to quality problem solving, we construct a quality-related prompt dataset with multi-round conversations based on CQKG. Then, a novel P-tuning that adapts to utilize external CQKG instructions is designed to fine-tune an open-source ChatGLM base model. Based on this, a causal knowledge graph-augmented LLM, named CausalKGPT, is developed to enable reasoning and responding to quality defects in both Chinese and English. It uses natural text descriptions related to quality defects as input and takes a quality-related causal knowledge graph as an additional corpus. Finally, the case study shows that the CausalKGPT performs with more expertise and reliability in responding to quality question solving of aerospace shell manufacturing than the classic commercial models like ChatGPT and GPT4. The results indicate that the proposed method may provide a trustworthy guide in assisting workers to analyze quality defects in aerospace products.}
}
@article{YAO2024100211,
title = {A survey on large language model (LLM) security and privacy: The Good, The Bad, and The Ugly},
journal = {High-Confidence Computing},
volume = {4},
number = {2},
pages = {100211},
year = {2024},
issn = {2667-2952},
doi = {https://doi.org/10.1016/j.hcc.2024.100211},
url = {https://www.sciencedirect.com/science/article/pii/S266729522400014X},
author = {Yifan Yao and Jinhao Duan and Kaidi Xu and Yuanfang Cai and Zhibo Sun and Yue Zhang},
keywords = {Large Language Model (LLM), LLM security, LLM privacy, ChatGPT, LLM attacks, LLM vulnerabilities},
abstract = {Large Language Models (LLMs), such as ChatGPT and Bard, have revolutionized natural language understanding and generation. They possess deep language comprehension, human-like text generation capabilities, contextual awareness, and robust problem-solving skills, making them invaluable in various domains (e.g., search engines, customer support, translation). In the meantime, LLMs have also gained traction in the security community, revealing security vulnerabilities and showcasing their potential in security-related tasks. This paper explores the intersection of LLMs with security and privacy. Specifically, we investigate how LLMs positively impact security and privacy, potential risks and threats associated with their use, and inherent vulnerabilities within LLMs. Through a comprehensive literature review, the paper categorizes the papers into “The Good” (beneficial LLM applications), “The Bad” (offensive applications), and “The Ugly” (vulnerabilities of LLMs and their defenses). We have some interesting findings. For example, LLMs have proven to enhance code security (code vulnerability detection) and data privacy (data confidentiality protection), outperforming traditional methods. However, they can also be harnessed for various attacks (particularly user-level attacks) due to their human-like reasoning abilities. We have identified areas that require further research efforts. For example, Research on model and parameter extraction attacks is limited and often theoretical, hindered by LLM parameter scale and confidentiality. Safe instruction tuning, a recent development, requires more exploration. We hope that our work can shed light on the LLMs’ potential to both bolster and jeopardize cybersecurity.}
}
@article{TRAPPEY2024102332,
title = {Patent litigation mining using a large language model—Taking unmanned aerial vehicle development as the case domain},
journal = {World Patent Information},
pages = {102332},
year = {2024},
issn = {0172-2190},
doi = {https://doi.org/10.1016/j.wpi.2024.102332},
url = {https://www.sciencedirect.com/science/article/pii/S0172219024000723},
author = {Amy J.C. Trappey and Shao-Chien Chou and Gi-Kuen J. Li},
keywords = {Unmanned aerial vehicle (UAV), Drone, Patent analysis, Patent litigation mining, Technology function matrix, Dynamic topic modeling, Large language model},
abstract = {As unmanned aerial vehicle (UAV), also called “drone”, swiftly advances with innovative functions and applications, the surge in patent applications has profoundly reshaped the intellectual property (IP) landscape in the UAV industry, leading to a growing number of litigations. This study is structured in two phases, aiming to develop an intelligent approach to analyzing the trend and evolution of patent litigations. The first phase involves macro- and micro-patent analyses of the related technology domain. Macro patent analysis elucidates the fundamental patent information in the drone industry, while micro patent analysis leverages the technology function matrix (TFM) to identify R&D hotspots and potentials. The second phase involves litigation (judgement) mining based on large language model (LLM). Beginning with the construction of a knowledge ontology, the domain infringement landscape can be detected through TFMs. A comparative analysis of the two-phase TFMs (i.e., both TFMs of patent and infringement allocations) is then conducted to pinpoint the key legal actions and the relevant technology. To drill deeper in infringement mining, dynamic topic modeling (DTM) is applied to analyze trends and dynamics in drone controller technology over time. This study aims to strengthen IP protection by developing an intelligent litigation mining approach that adopts large language model (LLM) and uses UAV/drone litigation studies as examples to show how the approach being applied in the industry.}
}
@article{BENJIRA2025102405,
title = {Automated mapping between SDG indicators and open data: An LLM-augmented knowledge graph approach},
journal = {Data & Knowledge Engineering},
volume = {156},
pages = {102405},
year = {2025},
issn = {0169-023X},
doi = {https://doi.org/10.1016/j.datak.2024.102405},
url = {https://www.sciencedirect.com/science/article/pii/S0169023X24001290},
author = {Wissal Benjira and Faten Atigui and Bénédicte Bucher and Malika Grim-Yefsah and Nicolas Travers},
keywords = {Sustainable Development Goals (SDG), Large language model (LLM), Knowledge graph (KG), Open data, Schema mapping},
abstract = {Meeting the Sustainable Development Goals (SDGs) presents a large-scale challenge for all countries. SDGs established by the United Nations provide a comprehensive framework for addressing global issues. To monitor progress towards these goals, we need to develop key performance indicators and integrate and analyze heterogeneous datasets. The definition of these indicators requires the use of existing data and metadata. However, the diversity of data sources and formats raises major issues in terms of structuring and integration. Despite the abundance of open data and metadata, its exploitation remains limited, leaving untapped potential for guiding urban policies towards sustainability. Thus, this paper introduces a novel approach for SDG indicator computation, leveraging the capabilities of Large Language Models (LLMs) and Knowledge Graphs (KGs). We propose a method that combines rule-based filtering with LLM-powered schema mapping to establish semantic correspondences between diverse data sources and SDG indicators, including disaggregation. Our approach integrates these mappings into a KG, which enables indicator computation by querying graph’s topology. We evaluate our method through a case study focusing on the SDG Indicator 11.7.1 about accessibility of public open spaces. Our experimental results show significant improvements in accuracy, precision, recall, and F1-score compared to traditional schema mapping techniques.}
}
@article{HUSSIEN2025125914,
title = {RAG-based explainable prediction of road users behaviors for automated driving using knowledge graphs and large language models},
journal = {Expert Systems with Applications},
volume = {265},
pages = {125914},
year = {2025},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2024.125914},
url = {https://www.sciencedirect.com/science/article/pii/S0957417424027817},
author = {Mohamed Manzour Hussien and Angie Nataly Melo and Augusto Luis Ballardini and Carlota Salinas Maldonado and Rubén Izquierdo and Miguel Ángel Sotelo},
keywords = {Road users’ behaviors, Explainable predictions, Pedestrian crossing actions, Lane change maneuvers, Autonomous driving},
abstract = {The prediction of road user behaviors in the context of autonomous driving has attracted considerable attention from the scientific community in recent years. Most works focus on predicting behaviors based on kinematic information alone, a simplification of reality since road users are humans, and as such they are highly influenced by their surrounding context. In addition, a large plethora of research works rely on powerful Deep Learning techniques, which exhibit high-performance metrics in prediction tasks but may lack the ability to fully understand and exploit the contextual semantic information contained in the road scene, not to mention their inability to provide explainable predictions that can be understood by humans. In this work, we propose an explainable road users’ behavior prediction system that integrates the reasoning abilities of Knowledge Graphs (KG) and the expressiveness capabilities of Large Language Models (LLM) by using Retrieval Augmented Generation (RAG) techniques. For that purpose, Knowledge Graph Embeddings (KGE) and Bayesian inference are combined to allow the deployment of a fully inductive reasoning system that enables the issuing of predictions that rely on legacy information contained in the graph, as well as on current evidence gathered in real-time by onboard sensors. Two use cases have been implemented following the proposed approach: 1) Prediction of pedestrians’ crossing actions; and 2) Prediction of lane change maneuvers. In both cases, the performance attained exceeds the current state-of-the-art in terms of anticipation and F1 score, showing a promising avenue for future research in this field.}
}
@article{CHEN2024104804,
title = {Enhancing emergency decision-making with knowledge graphs and large language models},
journal = {International Journal of Disaster Risk Reduction},
volume = {113},
pages = {104804},
year = {2024},
issn = {2212-4209},
doi = {https://doi.org/10.1016/j.ijdrr.2024.104804},
url = {https://www.sciencedirect.com/science/article/pii/S2212420924005661},
author = {Minze Chen and Zhenxiang Tao and Weitong Tang and Tingxin Qin and Rui Yang and Chunli Zhu},
keywords = {Emergency decision support, Large language model, Knowledge graph, Decision support system},
abstract = {Emergency management urgently requires comprehensive knowledge while having a high possibility to go beyond individuals’ cognitive scope. Therefore, artificial intelligence(AI) supported decision-making under that circumstance is of vital importance. Recent emerging large language models (LLM) provide a new direction for enhancing targeted machine intelligence. However, the utilization of LLM directly would inevitably introduce unreliable output for its inherent issue of hallucination and poor reasoning skills. In this work, we develop a system called Enhancing Emergency decision-making with Knowledge Graph and LLM (E-KELL), which provides evidence-based decision-making in various emergency stages. The study constructs a structured emergency knowledge graph and guides LLMs to reason over it via a prompt chain. In real-world evaluations, E-KELL demonstrates significant improvement over baseline models in various emergency response scenarios, as rated by emergency commanders and firefighters. This work introduces a novel approach to applying LLMs to enhance emergency decision-making.}
}
@article{XIAO2024104730,
title = {FuseLinker: Leveraging LLM’s pre-trained text embeddings and domain knowledge to enhance GNN-based link prediction on biomedical knowledge graphs},
journal = {Journal of Biomedical Informatics},
volume = {158},
pages = {104730},
year = {2024},
issn = {1532-0464},
doi = {https://doi.org/10.1016/j.jbi.2024.104730},
url = {https://www.sciencedirect.com/science/article/pii/S1532046424001485},
author = {Yongkang Xiao and Sinian Zhang and Huixue Zhou and Mingchen Li and Han Yang and Rui Zhang},
keywords = {Link Prediction, Knowledge graph, Graph Neural Network, Large Language Model, Drug Repurposing},
abstract = {Objective
To develop the FuseLinker, a novel link prediction framework for biomedical knowledge graphs (BKGs), which fully exploits the graph’s structural, textual and domain knowledge information. We evaluated the utility of FuseLinker in the graph-based drug repurposing task through detailed case studies.
Methods
FuseLinker leverages fused pre-trained text embedding and domain knowledge embedding to enhance the graph neural network (GNN)-based link prediction model tailored for BKGs. This framework includes three parts: a) obtain text embeddings for BKGs using embedding-visible large language models (LLMs), b) learn the representations of medical ontology as domain knowledge information by employing the Poincaré graph embedding method, and c) fuse these embeddings and further learn the graph structure representations of BKGs by applying a GNN-based link prediction model. We evaluated FuseLinker against traditional knowledge graph embedding models and a conventional GNN-based link prediction model across four public BKG datasets. Additionally, we examined the impact of using different embedding-visible LLMs on FuseLinker’s performance. Finally, we investigated FuseLinker’s ability to generate medical hypotheses through two drug repurposing case studies for Sorafenib and Parkinson’s disease.
Results
By comparing FuseLinker with baseline models on four BKGs, our method demonstrates superior performance. The Mean Reciprocal Rank (MRR) and Area Under receiver operating characteristic Curve (AUROC) for KEGG50k, Hetionet, SuppKG and ADInt are 0.969 and 0.987, 0.548 and 0.903, 0.739 and 0.928, and 0.831 and 0.890, respectively.
Conclusion
Our study demonstrates that FuseLinker is an effective novel link prediction framework that integrates multiple graph information and shows significant potential for practical applications in biomedical and clinical tasks. Source code and data are available at https://github.com/YKXia0/FuseLinker.}
}
@article{QIANG2025129373,
title = {Enhancing few-shot KB-VQA with panoramic image captions guided by Large Language Models},
journal = {Neurocomputing},
volume = {623},
pages = {129373},
year = {2025},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2025.129373},
url = {https://www.sciencedirect.com/science/article/pii/S0925231225000451},
author = {Pengpeng Qiang and Hongye Tan and Xiaoli Li and Dian Wang and Ru Li and Xinyi Sun and Hu Zhang and Jiye Liang},
keywords = {Knowledge-based visual question answering, Image caption, Large language model, In-context learning},
abstract = {Current state-of-the-art (SOTA) KB-VQA techniques involve transforming images into image captions as prompts to harness the potent reasoning capabilities of large language models (LLMs) for generating answers. However, generic image captions often fall short in capturing crucial visual details, essential for LLMs to deliver precise responses. To address this challenge, we propose an image captioning model that effectively utilizes a set of visual language models, such as BLIP2, GRiT, OCR, etc., to extract rich visual information from images. Subsequently, we employ the inferential and summarization capabilities of LLM to generate panoramic image descriptions enriched with intricate details. Simultaneously, we employ Contextual Constraint Examples and Constraint Instruction to mitigate the potential hallucination issues arising from LLM-generated image captions. Extensive experiments validate the superiority and scalability of our proposed method, achieving significant improvements over SOTA methods in challenging few-shot settings. For instance, on the challenging OK-VQA, our method outperforms PICa by 6.5%. On the VQAv2 dataset, our method surpasses the SOTA approach by 5.4%.}
}
@article{LEE2024105846,
title = {Performance comparison of retrieval-augmented generation and fine-tuned large language models for construction safety management knowledge retrieval},
journal = {Automation in Construction},
volume = {168},
pages = {105846},
year = {2024},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2024.105846},
url = {https://www.sciencedirect.com/science/article/pii/S092658052400582X},
author = {Jungwon Lee and Seungjun Ahn and Daeho Kim and Dongkyun Kim},
keywords = {Large Language Model (LLM), Retrieval-Augmented Generation (RAG), Fine-tuned LLM, Construction safety, Knowledge graph},
abstract = {Construction safety standards are in unstructured formats like text and images, complicating their effective use in daily tasks. This paper compares the performance of Retrieval-Augmented Generation (RAG) and fine-tuned Large Language Model (LLM) for the construction safety knowledge retrieval. The RAG model was created by integrating GPT-4 with a knowledge graph derived from construction safety guidelines, while the fine-tuned LLM was fine-tuned using a question-answering dataset derived from the same guidelines. These models' performance is tested through case studies, using accident synopses as a query to generate preventive measurements. The responses were assessed using metrics, including cosine similarity, Euclidean distance, BLEU, and ROUGE scores. It was found that both models outperformed GPT-4, with the RAG model improving by 21.5 % and the fine-tuned LLM by 26 %. The findings highlight the relative strengths and weaknesses of the RAG and fine-tuned LLM approaches in terms of applicability and reliability for safety management.}
}
@article{BENJDIRA2025107723,
title = {Prompting Robotic Modalities (PRM): A structured architecture for centralizing language models in complex systems},
journal = {Future Generation Computer Systems},
volume = {166},
pages = {107723},
year = {2025},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2025.107723},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X25000184},
author = {Bilel Benjdira and Anis Koubaa and Anas M. Ali},
keywords = {Expert systems architectures, Robotics, Languages models in robotics, Prompting robotic modalities, Large language models, LLMs, Vision language models, VLMs, Robotic operating system, ROS, ROS2, Robotic prompt engineering, Visual prompt, LLM prompt},
abstract = {Despite significant advancements in robotics and AI, existing systems often struggle to integrate diverse modalities (e.g., image, sound, actuator data) into a unified framework, resulting in fragmented architectures that limit adaptability, scalability, and explainability. To address these gaps, this paper introduces Prompting Robotic Modalities (PRM), a novel architecture that centralizes language models for controlling and managing complex systems through natural language. In PRM, each system modality (e.g., image, sound, actuator) is handled independently by a Modality Language Model (MLM), while a central Task Modality, powered by a Large Language Model (LLM), orchestrates complex tasks using information from the MLMs. Each MLM is trained on datasets that pair modality-specific data with rich textual descriptions, enabling intuitive, language-based interaction. We validate PRM with two main contributions: (1) ROSGPT_Vision, a new open-source ROS 2 package (available at https://github.com/bilel-bj/ROSGPT_Vision) for visual modality tasks, achieving up to 66% classification accuracy in driver-focus monitoring—surpassing other tested models in its category; and (2) CarMate, a driver-distraction detection application that significantly reduces development time and cost by allowing rapid adaptation to new monitoring tasks via simple prompt adjustments. In addition, we develop a Navigation Language Model (NLM) that converts free-form human language orders into detailed ROS commands, underscoring PRM’s modality-agnostic adaptability. Experimental results demonstrate that PRM simplifies system development, outperforms baseline vision-language approaches in specialized tasks (e.g., driver monitoring), reduces complexity through prompt engineering rather than extensive coding, and enhances explainability via natural-language-based diagnostics. Hence, PRM lays a promising foundation for next-generation complex and robotic systems by integrating advanced language model capabilities at their core, making them more adaptable to new environments, cost-effective, and user-friendly.}
}
@article{LIANG2024870,
title = {A survey of LLM-augmented knowledge graph construction and application in complex product design},
journal = {Procedia CIRP},
volume = {128},
pages = {870-875},
year = {2024},
note = {34th CIRP Design Conference},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2024.07.069},
url = {https://www.sciencedirect.com/science/article/pii/S2212827124007911},
author = {Xinxin Liang and Zuoxu Wang and Mingrui Li and Zhijie Yan},
keywords = {Knowledge Graph, Large Language Model, Design: challenges & Innovation},
abstract = {In the field of complex product design, deploying knowledge graphs (KGs) has become a promising trend due to its strength on exploiting and applying the large-scale, complex, and specialized domain knowledge. In recent years, large language models (LLMs) have also attracted much attention due to their outstanding performance in natural language understanding and generation. However, in the research of complex product design dominated by domain knowledge, few studies involve LLMS and KG at the same time. To fill this gap, we survey 42 articles published in the last four years, focusing on three key questions. The combination of LLM and KG in specific applications in complex product design is deeply discussed. The analysis reveals how these techniques facilitate data collection, design concept formation and design process optimization and proposes a technical framework combining LLM and KG for complex product design domain. In addition, we identify key challenges and propose directions for future research. As an explorative survey paper, this paper provides insightful ideas for implementing more specialized domain knowledge graph in complex product design field.}
}
@article{HAKANSSON20245458,
title = {Generative AI and Large Language Models - Benefits, Drawbacks, Future and Recommendations},
journal = {Procedia Computer Science},
volume = {246},
pages = {5458-5468},
year = {2024},
note = {28th International Conference on Knowledge Based and Intelligent information and Engineering Systems (KES 2024)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.09.689},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924027492},
author = {Anne Håkansson and Gloria Phillips-Wren},
keywords = {Natural Language Processing, Generative AI, Large Language Models},
abstract = {Natural language processing, with parsing and generation, has a long tradition. Parsing has been easier to perform than a generation but with generative artificial intelligence (a.k.a Gen AI) and large language models (abbr. LLMs), this has changed. Generative artificial intelligence is a type of artificial intelligence that uses a large data set to create something in the genre of that data set. It can generate different outputs ranging from texts, audio, objects, pictures, and paintings to videos, but also synthetic data. LLMs use deep learning and deep neural networks to train on large text corpora for recognizing and generating texts. These models are based on massive data sets, collected from databases and the web. They use transformer models to detect how elements in sequences relate to each other. This provides context support. Two well-known large language models are the Generative Pre-trained Transformer, GPT, used in ChatGPT and Bidirectional Encoder Representations from Transformers, BERT. Although LLMs have advantages, they have problems. This paper presents generative artificial intelligence and LLMs with benefits and drawbacks. Results from applying these models have shown that they can work well for accuracy in specificity, user personalization and human-computer communication but they may not provide acceptable, reliable and truthful results. For example, ethics, hallucinations and incorrect information, or misjudgments, are some major problems. The paper ends with future directions, research questions on LLMs, and recommendations.}
}
@article{CAO2024,
title = {An Automatic and End-to-End System for Rare Disease Knowledge Graph Construction Based on Ontology-Enhanced Large Language Models: Development Study},
journal = {JMIR Medical Informatics},
volume = {12},
year = {2024},
issn = {2291-9694},
doi = {https://doi.org/10.2196/60665},
url = {https://www.sciencedirect.com/science/article/pii/S2291969424001881},
author = {Lang Cao and Jimeng Sun and Adam Cross},
keywords = {rare disease, clinical informatics, LLM, natural language processing, machine learning, artificial intelligence, large language models, data extraction, ontologies, knowledge graphs, text mining},
abstract = {Background
Rare diseases affect millions worldwide but sometimes face limited research focus individually due to low prevalence. Many rare diseases do not have specific International Classification of Diseases, Ninth Edition (ICD-9) and Tenth Edition (ICD-10), codes and therefore cannot be reliably extracted from granular fields like “Diagnosis” and “Problem List” entries, which complicates tasks that require identification of patients with these conditions, including clinical trial recruitment and research efforts. Recent advancements in large language models (LLMs) have shown promise in automating the extraction of medical information, offering the potential to improve medical research, diagnosis, and management. However, most LLMs lack professional medical knowledge, especially concerning specific rare diseases, and cannot effectively manage rare disease data in its various ontological forms, making it unsuitable for these tasks.
Objective
Our aim is to create an end-to-end system called automated rare disease mining (AutoRD), which automates the extraction of rare disease–related information from medical text, focusing on entities and their relations to other medical concepts, such as signs and symptoms. AutoRD integrates up-to-date ontologies with other structured knowledge and demonstrates superior performance in rare disease extraction tasks. We conducted various experiments to evaluate AutoRD’s performance, aiming to surpass common LLMs and traditional methods.
Methods
AutoRD is a pipeline system that involves data preprocessing, entity extraction, relation extraction, entity calibration, and knowledge graph construction. We implemented this system using GPT-4 and medical knowledge graphs developed from the open-source Human Phenotype and Orphanet ontologies, using techniques such as chain-of-thought reasoning and prompt engineering. We quantitatively evaluated our system’s performance in entity extraction, relation extraction, and knowledge graph construction. The experiment used the well-curated dataset RareDis2023, which contains medical literature focused on rare disease entities and their relations, making it an ideal dataset for training and testing our methodology.
Results
On the RareDis2023 dataset, AutoRD achieved an overall entity extraction F1-score of 56.1% and a relation extraction F1-score of 38.6%, marking a 14.4% improvement over the baseline LLM. Notably, the F1-score for rare disease entity extraction reached 83.5%, indicating high precision and recall in identifying rare disease mentions. These results demonstrate the effectiveness of integrating LLMs with medical ontologies in extracting complex rare disease information.
Conclusions
AutoRD is an automated end-to-end system for extracting rare disease information from text to build knowledge graphs, addressing critical limitations of existing LLMs by improving identification of these diseases and connecting them to related clinical features. This work underscores the significant potential of LLMs in transforming health care, particularly in the rare disease domain. By leveraging ontology-enhanced LLMs, AutoRD constructs a robust medical knowledge base that incorporates up-to-date rare disease information, facilitating improved identification of patients and resulting in more inclusive research and trial candidacy efforts.}
}
@article{CHANG2024,
title = {Use of SNOMED CT in Large Language Models: Scoping Review},
journal = {JMIR Medical Informatics},
volume = {12},
year = {2024},
issn = {2291-9694},
doi = {https://doi.org/10.2196/62924},
url = {https://www.sciencedirect.com/science/article/pii/S2291969424001364},
author = {Eunsuk Chang and Sumi Sung},
keywords = {SNOMED CT, ontology, knowledge graph, large language models, natural language processing, language models},
abstract = {Background
Large language models (LLMs) have substantially advanced natural language processing (NLP) capabilities but often struggle with knowledge-driven tasks in specialized domains such as biomedicine. Integrating biomedical knowledge sources such as SNOMED CT into LLMs may enhance their performance on biomedical tasks. However, the methodologies and effectiveness of incorporating SNOMED CT into LLMs have not been systematically reviewed.
Objective
This scoping review aims to examine how SNOMED CT is integrated into LLMs, focusing on (1) the types and components of LLMs being integrated with SNOMED CT, (2) which contents of SNOMED CT are being integrated, and (3) whether this integration improves LLM performance on NLP tasks.
Methods
Following the PRISMA-ScR (Preferred Reporting Items for Systematic Reviews and Meta-Analyses extension for Scoping Reviews) guidelines, we searched ACM Digital Library, ACL Anthology, IEEE Xplore, PubMed, and Embase for relevant studies published from 2018 to 2023. Studies were included if they incorporated SNOMED CT into LLM pipelines for natural language understanding or generation tasks. Data on LLM types, SNOMED CT integration methods, end tasks, and performance metrics were extracted and synthesized.
Results
The review included 37 studies. Bidirectional Encoder Representations from Transformers and its biomedical variants were the most commonly used LLMs. Three main approaches for integrating SNOMED CT were identified: (1) incorporating SNOMED CT into LLM inputs (28/37, 76%), primarily using concept descriptions to expand training corpora; (2) integrating SNOMED CT into additional fusion modules (5/37, 14%); and (3) using SNOMED CT as an external knowledge retriever during inference (5/37, 14%). The most frequent end task was medical concept normalization (15/37, 41%), followed by entity extraction or typing and classification. While most studies (17/19, 89%) reported performance improvements after SNOMED CT integration, only a small fraction (19/37, 51%) provided direct comparisons. The reported gains varied widely across different metrics and tasks, ranging from 0.87% to 131.66%. However, some studies showed either no improvement or a decline in certain performance metrics.
Conclusions
This review demonstrates diverse approaches for integrating SNOMED CT into LLMs, with a focus on using concept descriptions to enhance biomedical language understanding and generation. While the results suggest potential benefits of SNOMED CT integration, the lack of standardized evaluation methods and comprehensive performance reporting hinders definitive conclusions about its effectiveness. Future research should prioritize consistent reporting of performance comparisons and explore more sophisticated methods for incorporating SNOMED CT’s relational structure into LLMs. In addition, the biomedical NLP community should develop standardized evaluation frameworks to better assess the impact of ontology integration on LLM performance.}
}
@article{MA2024128490,
title = {A review of graph neural networks and pretrained language models for knowledge graph reasoning},
journal = {Neurocomputing},
volume = {609},
pages = {128490},
year = {2024},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2024.128490},
url = {https://www.sciencedirect.com/science/article/pii/S092523122401261X},
author = {Jiangtao Ma and Bo Liu and Kunlin Li and Chenliang Li and Fan Zhang and Xiangyang Luo and Yaqiong Qiao},
keywords = {Knowledge graph reasoning, Graph neural networks, Pretrained language models, Logic rules},
abstract = {Knowledge Graph (KG) stores human knowledge facts in an intuitive graphical structure but faces challenges such as incomplete construction or inability to handle new knowledge. Knowledge Graph Reasoning (KGR) can make KGs more accurate, complete, and trustworthy to support various artificial intelligence applications better. Currently, the popular KGR methods are based on graph neural networks (GNNs). Recent studies have shown that hybrid logic rules and synergized pre-trained language models (PLMs) can enhance the GNN-based KGR methods. These methods mainly focus on data sparsity, insufficient knowledge evolution patterns, multi-modal fusion, and few-shot reasoning. Although many studies have been conducted, there are still few review papers that comprehensively summarize and explore KGR methods related to GNNs, logic rules, and PLMs. Therefore, this paper provides a comprehensive review of GNNs and PLMs for KGR based on a large number of high-quality papers. To present a clear overview of KGR, we propose a general framework. Specifically, we first introduce the KG preparation. Then we provide an overview of KGR methods, in which we categorize KGR methods into GNNs-based, logic rules-enhanced, and pre-trained language models-enhanced KGR methods. Furthermore, we also compare and analyze the GNN-based KGR methods in two scenarios. Moreover, we also present the application of KGR in different fields. Finally, we discuss the current challenges and future research directions for KGR.}
}
@article{VENKATASUBRAMANIAN2025108895,
title = {Quo Vadis ChatGPT? From large language models to Large Knowledge Models},
journal = {Computers & Chemical Engineering},
volume = {192},
pages = {108895},
year = {2025},
issn = {0098-1354},
doi = {https://doi.org/10.1016/j.compchemeng.2024.108895},
url = {https://www.sciencedirect.com/science/article/pii/S0098135424003132},
author = {Venkat Venkatasubramanian and Arijit Chakraborty},
keywords = {Artificial intelligence, Large language model, Knowledge graph, Domain-specific language processing, Machine learning, Hybrid AI},
abstract = {The startling success of ChatGPT and other large language models (LLMs) using transformer-based generative neural network architecture in applications such as natural language processing and image synthesis has many researchers excited about potential opportunities in process systems engineering (PSE). The almost human-like performance of LLMs in these areas is indeed very impressive, surprising, and a major breakthrough. Their capabilities are very useful in certain tasks, such as writing first drafts of documents, code writing assistance, text summarization, etc. However, their success is limited in highly scientific domains as they cannot yet reason, plan, or explain due to their lack of in-depth mechanistic domain knowledge. This is a problem in domains such as chemical engineering as they are governed by fundamental laws of physics and chemistry (and biology), constitutive relations, and highly technical knowledge about materials, processes, and systems. Although purely data-driven machine learning has its immediate uses, the long-term success of AI in scientific and engineering domains would depend on developing hybrid AI systems that combine first principles and technical knowledge effectively. We call these hybrid AI systems Large Knowledge Models (LKMs), as they will not be limited to only NLP-based techniques or NLP-like applications. In this paper, we discuss the challenges and opportunities in developing such systems in chemical engineering.}
}
@article{CHANDRASEKHAR2024100232,
title = {AMGPT: A large language model for contextual querying in additive manufacturing},
journal = {Additive Manufacturing Letters},
volume = {11},
pages = {100232},
year = {2024},
issn = {2772-3690},
doi = {https://doi.org/10.1016/j.addlet.2024.100232},
url = {https://www.sciencedirect.com/science/article/pii/S2772369024000409},
author = {Achuth Chandrasekhar and Jonathan Chan and Francis Ogoke and Olabode Ajenifujah and Amir {Barati Farimani}},
keywords = {Large language models, Retrieval-augmented generation, Machine learning, Contextual querying, Laser powder bed fusion},
abstract = {Generalized large language models (LLMs) such as GPT-4 may not provide specific answers to queries formulated by materials science researchers. These models may produce a high-level outline but lack the capacity to return detailed instructions on manufacturing and material properties of novel alloys. We introduce “AMGPT”, a specialized LLM text generator designed for metal AM queries. The goal of AMGPT is to assist researchers and users in navigating a curated corpus of literature. Instead of training from scratch, we employ a pre-trained Llama2-7B model from Hugging Face in a Retrieval-Augmented Generation (RAG) setup, utilizing it to dynamically incorporate information from ∼50 AM papers and textbooks in PDF format. Mathpix is used to convert these PDF documents into TeX format, facilitating their integration into the RAG pipeline managed by LlamaIndex. A query retrieval function has also been added, enabling the system to fetch relevant literature from Elsevier journals based on the context of the query. Expert evaluations of this project highlight that specific embeddings from the RAG setup accelerate response times and maintain coherence in the generated text.}
}
@article{SAHBI2025102392,
title = {Semantic vs. LLM-based approach: A case study of KOnPoTe vs. Claude for ontology population from French advertisements},
journal = {Data & Knowledge Engineering},
volume = {156},
pages = {102392},
year = {2025},
issn = {0169-023X},
doi = {https://doi.org/10.1016/j.datak.2024.102392},
url = {https://www.sciencedirect.com/science/article/pii/S0169023X24001162},
author = {Aya Sahbi and Céline Alec and Pierre Beust},
keywords = {Ontology population, LLM, Textual descriptions},
abstract = {Automatic ontology population is the process of identifying, extracting, and integrating relevant information from diverse sources to instantiate the classes and properties specified in an ontology, thereby creating a Knowledge Graph (KG) for a particular domain. In this study, we evaluate two approaches for ontology population from text: KOnPoTe, a semantic technique that employs textual and domain knowledge analysis, and a generative AI method leveraging Claude, a Large Language Model (LLM). We conduct comparative experiments on three French advertisement domains: real estate, boats, and restaurants to assess the performance of these techniques. Our analysis highlights the respective strengths and limitations of the semantic approach and the LLM-based one in the context of the ontology population process.}
}
@article{FAN20241269,
title = {Unleashing the Potential of Large Language Models for Knowledge Augmentation: A Practical Experiment on Incremental Sheet Forming},
journal = {Procedia Computer Science},
volume = {232},
pages = {1269-1278},
year = {2024},
note = {5th International Conference on Industry 4.0 and Smart Manufacturing (ISM 2023)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.01.125},
url = {https://www.sciencedirect.com/science/article/pii/S187705092400125X},
author = {Haolin Fan and Jerry Fuh and Wen Feng Lu and A. Senthil Kumar and Bingbing Li},
keywords = {Incremental Sheet Forming, Large Language Models, Domain Knowledge Augmentation, Fine-tuning},
abstract = {As the influence of Incremental Sheet Forming (ISF) grows in manufacturing sectors, so does the demand for precise and updated knowledge construction in this domain. In this research, we evaluate the capability of Large Language Models (LLMs) to capture domain-specific knowledge, using ISF as a case study. Recognizing common LLMs’ limitations such as potential inaccuracies and outdated information reliance, we propose a comprehensive approach involving automated and adaptive knowledge extraction, enrichment, and integration into an ISF-specific dataset. We then fine-tune the LLMs for ISF-related text classification and prompt response tasks. Our results reveal a significant enhancement in LLMs’ performance within the ISF domain, with a domain knowledge acquisition rate exceeding that of GPT-3.5 by 10.4%, achieved by the fine-tuned Alpaca-33B model. Additionally, we introduce a novel conversational prototype designed to refine the accuracy and relevance of LLMs in the ISF domain. Our findings will guide future efforts in downstream tasks such as ISF-domain knowledge graph construction and quality prediction.}
}
@article{GUAN2025102359,
title = {Leveraging large language models for peptide antibiotic design},
journal = {Cell Reports Physical Science},
volume = {6},
number = {1},
pages = {102359},
year = {2025},
issn = {2666-3864},
doi = {https://doi.org/10.1016/j.xcrp.2024.102359},
url = {https://www.sciencedirect.com/science/article/pii/S2666386424006738},
author = {Changge Guan and Fabiano C. Fernandes and Octavio L. Franco and Cesar {de la Fuente-Nunez}},
abstract = {Summary
Large language models (LLMs) have significantly impacted various domains of our society, including recent applications in complex fields such as biology and chemistry. These models, built on sophisticated neural network architectures and trained on extensive datasets, are powerful tools for designing, optimizing, and generating molecules. This review explores the role of LLMs in discovering and designing antibiotics, focusing on peptide molecules. We highlight advancements in drug design and outline the challenges of applying LLMs in these areas.}
}
@article{SUNIL2024102665,
title = {The gene function prediction challenge: Large language models and knowledge graphs to the rescue},
journal = {Current Opinion in Plant Biology},
volume = {82},
pages = {102665},
year = {2024},
issn = {1369-5266},
doi = {https://doi.org/10.1016/j.pbi.2024.102665},
url = {https://www.sciencedirect.com/science/article/pii/S1369526624001560},
author = {Rohan Shawn Sunil and Shan Chun Lim and Manoj Itharajula and Marek Mutwil},
abstract = {Elucidating gene function is one of the ultimate goals of plant science. Despite this, only ∼15 % of all genes in the model plant Arabidopsis thaliana have comprehensively experimentally verified functions. While bioinformatical gene function prediction approaches can guide biologists in their experimental efforts, neither the performance of the gene function prediction methods nor the number of experimental characterization of genes has increased dramatically in recent years. In this review, we will discuss the status quo and the trajectory of gene function elucidation and outline the recent advances in gene function prediction approaches. We will then discuss how recent artificial intelligence advances in large language models and knowledge graphs can be leveraged to accelerate gene function predictions and keep us updated with scientific literature.}
}
@article{ZENG2025112837,
title = {KoSEL: Knowledge subgraph enhanced large language model for medical question answering},
journal = {Knowledge-Based Systems},
volume = {309},
pages = {112837},
year = {2025},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2024.112837},
url = {https://www.sciencedirect.com/science/article/pii/S0950705124014710},
author = {Zefan Zeng and Qing Cheng and Xingchen Hu and Yan Zhuang and Xinwang Liu and Kunlun He and Zhong Liu},
keywords = {Domain-specific, Knowledge graph, Large language model, Medical question answering, Privacy, Retrieval},
abstract = {The integration of medical knowledge graphs (KGs) and large language models (LLMs) for medical question answering (Q&A) has attracted considerable interest in recent studies. However, current approaches that combine KGs and LLMs tend to either integrate KGs directly into the fine-tuning process of LLMs or use entire KGs as a contextual prompt base for LLMs to reason, raising concerns regarding potential data leakage and reasoning confusion. In this study, we propose KoSEL (Knowledge Subgraph Enhanced Large Language Model), a novel medical Q&A framework based on KG-enhanced LLMs. KoSEL comprises two modules: Knowledge Retrieval (KR) and Reasoning and Answering (RA). The KR module is LLM-independent and employs an entity-linking algorithm and a subgraph construction and fusion strategy to retrieve question-relevant knowledge. The RA module conveys prompts to the LLM for information extraction, knowledge fusion, reasoning, and answer generation. KoSEL, which is designed as a plug-and-play framework, effectively fuses structural and textual knowledge while ensuring efficiency and privacy. The construction of a precise and refined subgraph reduces knowledge noise and the number of input graph tokens, thus mitigating hallucination issues. Extensive experiments demonstrated that KoSEL outperformed advanced methods in terms of knowledge retrieval efficiency (20.27% reduction in retrieval time), knowledge utilization (15.16% increase in utilization rate), and data protection (113.50% reduction in data leakage rate), resulting in higher-quality answers for medical Q&A tasks (1.50% improvement in answer score).}
}
@article{LI2025104769,
title = {BiomedRAG: A retrieval augmented large language model for biomedicine},
journal = {Journal of Biomedical Informatics},
volume = {162},
pages = {104769},
year = {2025},
issn = {1532-0464},
doi = {https://doi.org/10.1016/j.jbi.2024.104769},
url = {https://www.sciencedirect.com/science/article/pii/S1532046424001874},
author = {Mingchen Li and Halil Kilicoglu and Hua Xu and Rui Zhang},
keywords = {Retrieval-augmented generation, Large language model},
abstract = {Retrieval-augmented generation (RAG) involves a solution by retrieving knowledge from an established database to enhance the performance of large language models (LLM). , these models retrieve information at the sentence or paragraph level, potentially introducing noise and affecting the generation quality. To address these issues, we propose a novel BiomedRAG framework that directly feeds automatically retrieved chunk-based documents into the LLM. Our evaluation of BiomedRAG across four biomedical natural language processing tasks using eight datasets demonstrates that our proposed framework not only improves the performance by 9.95% on average, but also achieves state-of-the-art results, surpassing various baselines by 4.97%. BiomedRAG paves the way for more accurate and adaptable LLM applications in the biomedical domain.}
}
@article{LIU2024119280,
title = {MAKG: A maritime accident knowledge graph for intelligent accident analysis and management},
journal = {Ocean Engineering},
volume = {312},
pages = {119280},
year = {2024},
issn = {0029-8018},
doi = {https://doi.org/10.1016/j.oceaneng.2024.119280},
url = {https://www.sciencedirect.com/science/article/pii/S0029801824026180},
author = {Dongge Liu and Liang Cheng},
keywords = {Maritime accident, Knowledge graph, Named entity recognition, BERT, Prompt learning},
abstract = {With the increasing frequency of human activities at sea, maritime accidents are occurring more often. Analyzing and mining maritime accident cases can help uncover the causal mechanisms behind these incidents, thereby enhancing maritime safety. As an emerging technology for knowledge management and mining, knowledge graphs offer significant support for the storage, reasoning, and decision-making processes related to maritime accidents. In this study, we established a knowledge graph construction and application framework for maritime accidents to facilitates the extraction and management of maritime knowledge from unstructured texts. First, 581 accident reports released by the China Maritime Safety Administration over the past decade (2014–2023) were used as the data basis for analysis and construction of the maritime accident ontology structure using the seven-step method, which comprises 8 entity types, 8 relationship types, and 18 attribute entity types. Second, We proposed MBERT-BiLSTM-CRF-SF, a named entity recognition model based on domain pretraining and self-training, to reduce graph construction costs. This model achieved state-of-the-art performance in the maritime domain, with an F1 score of 0.910 ± 0.006, which is about 5% higher than the mainstream model. In addition, we proposed an entity alignment method based on font and semantics to refine knowledge further. On the basis of the proposed method, we constructed a large, high-quality maritime accident knowledge graph (MAKG) system that contains 16,099 entities and 20,809 relationship instances. Finally, we reduced the complexity of applying knowledge graphs by integrating the CRISPE prompt learning framework of the large language model, and experiments on graph traversal, pattern recognition, and aggregation analysis were conducted to assess the quality of MAKG. Results demonstrate that MAKG can effectively enhance the efficiency of querying and reasoning about maritime accident information, thus providing significant support for the prevention and management of maritime accidents.}
}
@article{SIEPMANN2025100378,
title = {An automated information extraction model for unstructured discharge letters using large language models and GPT-4},
journal = {Healthcare Analytics},
volume = {7},
pages = {100378},
year = {2025},
issn = {2772-4425},
doi = {https://doi.org/10.1016/j.health.2024.100378},
url = {https://www.sciencedirect.com/science/article/pii/S2772442524000807},
author = {Robert M. Siepmann and Giulia Baldini and Cynthia S. Schmidt and Daniel Truhn and Gustav Anton Müller-Franzes and Amin Dada and Jens Kleesiek and Felix Nensa and René Hosch},
keywords = {Large language models, Automated information extraction, Artificial intelligence, Generative pre-trained transformer (GPT), ChatGPT, Discharge letters},
abstract = {The administrative burden of manually extracting clinical information from discharge letters is a common challenge in healthcare. This study aims to explore the use of Large Language Models (LLMs), specifically Generative Pretrained Transformer 4 (GPT-4) by OpenAI, for automated extraction of diagnoses, medications, and allergies from discharge letters. Data for this study were sourced from two healthcare institutions in Germany, comprising discharge letters for ten patients from each institution. The first experiment is conducted using a standardized prompt for information extraction. However, challenges were encountered, and the prompt was fine-tuned in a second experiment to improve the results. We further tested whether open-source LLMs can achieve similar results. In the first experiment, primary diagnoses were identified with 85% accuracy and secondary diagnoses with 55.8%. Medications and allergies were extracted with 85.9% and 100% accuracy, respectively. The International Classification of Diseases, 10th revision (ICD-10) codes for the identified diagnoses achieved an accuracy of 85% for primary diagnoses and 60.7% for secondary diagnoses. Anatomical Therapeutic Chemical (ATC) codes were identified with an accuracy of 78.8%. On the other hand, open-source LLMs did not provide similar levels of accuracy and could not consistently fill the template. With prompt fine-tuning in the second experiment, the primary diagnoses, secondary diagnoses, and medications could be predicted with 95%, 88.9%, and 92.2% accuracy, respectively. GPT-4 shows excellent potential for automated extraction of crucial diagnostic and medication information from discharge letters, presumably lowering the administrative burden for healthcare professionals and improving patient outcomes.}
}
@article{SHIMIZU2025100862,
title = {Accelerating knowledge graph and ontology engineering with large language models},
journal = {Journal of Web Semantics},
pages = {100862},
year = {2025},
issn = {1570-8268},
doi = {https://doi.org/10.1016/j.websem.2025.100862},
url = {https://www.sciencedirect.com/science/article/pii/S1570826825000022},
author = {Cogan Shimizu and Pascal Hitzler},
keywords = {Knowledge graph engineering, Ontology engineering, Large language models, Modular ontologies, Ontology modeling, Ontology population, Ontology alignment, Entity disambiguation},
abstract = {Large Language Models bear the promise of significant acceleration of key Knowledge Graph and Ontology Engineering tasks, including ontology modeling, extension, modification, population, alignment, as well as entity disambiguation. We lay out LLM-based Knowledge Graph and Ontology Engineering as a new and coming area of research, and argue that modular approaches to ontologies will be of central importance.}
}
@article{KUANG2024100146,
title = {Harnessing multimodal large language models for traffic knowledge graph generation and decision-making},
journal = {Communications in Transportation Research},
volume = {4},
pages = {100146},
year = {2024},
issn = {2772-4247},
doi = {https://doi.org/10.1016/j.commtr.2024.100146},
url = {https://www.sciencedirect.com/science/article/pii/S2772424724000295},
author = {Senyun Kuang and Yang Liu and Xin Wang and Xinhua Wu and Yintao Wei}
}
@article{XU2025104047,
title = {Historical facts learning from Long-Short Terms with Language Model for Temporal Knowledge Graph Reasoning},
journal = {Information Processing & Management},
volume = {62},
number = {3},
pages = {104047},
year = {2025},
issn = {0306-4573},
doi = {https://doi.org/10.1016/j.ipm.2024.104047},
url = {https://www.sciencedirect.com/science/article/pii/S0306457324004060},
author = {Wenjie Xu and Ben Liu and Miao Peng and Zihao Jiang and Xu Jia and Kai Liu and Lei Liu and Min Peng},
keywords = {Knowledge graph, Temporal knowledge graph reasoning, Pre-trained language model, Large-scale language model},
abstract = {Temporal Knowledge Graph Reasoning (TKGR) aims to reason the missing parts in TKGs based on historical facts from different time periods. Traditional GCN-based TKGR models depend on structured relations between entities. To utilize the rich linguistic information in TKGs, some models have focused on applying pre-trained language models (PLMs) to TKGR. However, previous PLM-based models still face some issues: (1) they did not mine the associations in relations; (2) they did not differentiate the impact of historical facts from different time periods. (3) they introduced external knowledge to enhance the performance without fully utilizing the inherent reasoning capabilities of PLMs. To deal with these issues, we propose HFL: Historical Facts Learning from Long-Short Terms with Language Model for TKGR. Firstly, we construct time tokens for different types of time intervals to use timestamps and input the historical facts relevant to the query into the PLMs to learn the associations in relations. Secondly, we take a multi-perspective sampling strategy to learn from different time periods and use the original text information in TKGs or even no text information to learn reasoning abilities without any external knowledge. Finally, we perform HFL on four TKGR benchmarks, and the experiment results demonstrate that HFL has great competitiveness compared to both graph-based and PLM-based models. Additionally, we design a variant that applies HFL to LLMs and evaluate the performance of different LLMs.}
}
@article{WANG2024102820,
title = {Knowledge graph of agricultural engineering technology based on large language model},
journal = {Displays},
volume = {85},
pages = {102820},
year = {2024},
issn = {0141-9382},
doi = {https://doi.org/10.1016/j.displa.2024.102820},
url = {https://www.sciencedirect.com/science/article/pii/S0141938224001847},
author = {Haowen Wang and Ruixue Zhao},
keywords = {LLM, Knowledge graph},
abstract = {Agriculture is an industry that has evolved alongside human evolution and has faithfully fulfilled its core mission of food supply. With the reduction of rural labor, the progress of artificial intelligence and the development of Internet of Things technology, it is hoped that the efficiency and productivity of the agricultural industry can be improved. Recently, with the development of information and intelligent technology, agricultural production and management have been significantly enhanced. However, there is still a considerable challenge in effectively integrating the vast amount of fragmented information for downstream applications. An agricultural knowledge graph (AGKG) will serve as the foundation for achieving these goals. Knowledge graphs can be general or domain-specific, and are the basis for many applications, such as search engines, online question-and-answer services, and knowledge inference. Therefore, there are many knowledge graphs, including Wikidata and DBpedia, for accessing structured knowledge. Although some general knowledge graphs contain some entities and relationships related to agriculture, there are no domain-specific knowledge graphs specifically for agricultural applications. Therefore, this paper proposes an agricultural knowledge graph (AGKG) for automatically integrating large amounts of agricultural data from the Internet. By applying natural language processing and deep learning technologies, AGKG can automatically identify agricultural entities from unstructured text and connect them to form a knowledge graph. In addition, we have described the typical scenarios of our AGKG and validated it through real-world applications such as agricultural entity retrieval and agricultural question-answering.}
}
@article{HU2024103999,
title = {LLM-TIKG: Threat intelligence knowledge graph construction utilizing large language model},
journal = {Computers & Security},
volume = {145},
pages = {103999},
year = {2024},
issn = {0167-4048},
doi = {https://doi.org/10.1016/j.cose.2024.103999},
url = {https://www.sciencedirect.com/science/article/pii/S0167404824003043},
author = {Yuelin Hu and Futai Zou and Jiajia Han and Xin Sun and Yilei Wang},
keywords = {Threat intelligence, Large language model, Knowledge graph, TTP classification},
abstract = {Open-source threat intelligence is often unstructured and cannot be directly applied to the next detection and defense. By constructing a knowledge graph through open-source threat intelligence, we can better apply this information to intrusion detection. However, the current methods for constructing knowledge graphs face limitations due to the domain-specific attributes of entities and the analysis of lengthy texts, and they require large amounts of labeled data. Furthermore, there is a lack of authoritative open-source annotated threat intelligence datasets, which require significant manual effort. Moreover, it is noteworthy that current research often neglects the textual descriptions of attack behaviors, resulting in the loss of vital information to understand intricate cyber threats. To address these issues, we propose LLM-TIKG that applies the large language model to construct a knowledge graph from unstructured open-source threat intelligence. The few-shot learning capability of GPT is leveraged to achieve data annotation and augmentation, thereby creating the datasets for fine-tuning a smaller language model (7B). Using the fine-tuned model, we perform topic classification on the collected reports, extract entities and relationships, and extract TTPs from the attack description. This process results in the construction of a threat intelligence knowledge graph, enabling automated and universal analysis of textualized threat intelligence. The experimental results demonstrate improved performance in both named entity recognition and TTP classification, achieving the precision of 87.88% and 96.53%, respectively.}
}
@article{GAO2024105634,
title = {Exploring bridge maintenance knowledge graph by leveraging GrapshSAGE and text encoding},
journal = {Automation in Construction},
volume = {166},
pages = {105634},
year = {2024},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2024.105634},
url = {https://www.sciencedirect.com/science/article/pii/S0926580524003704},
author = {Yan Gao and Guanyu Xiong and Haijiang Li and Jarrod Richards},
keywords = {Bridge maintenance knowledge graph, Text encoding, Graph neural networks, Node classification, Link prediction},
abstract = {Knowledge graphs (KGs) are crucial in documenting bridge maintenance expertise. However, existing KG schemas lack integration of bridge design and practical inspection insights. Meanwhile, traditional methods for node feature initialization, relying on meticulous manual encoding or word embeddings, are inadequate for real-world maintenance textual data. To address these challenges, this paper introduces a bridge maintenance-oriented KG (BMKG) schema and approaches for graph data mining, including node-layer classification and link prediction. These methods leverage large language model (LLM)-based text encoding combined with GraphSAGE, demonstrating excellent performance in semantic enrichment and KG completion on deficient BMKGs. Additionally, ablation studies reveal the superiority of the pre-trained BERT text encoder and the L2 distance pairwise scoring calculator. Furthermore, a practical implementation framework integrating these approaches is developed for routine bridge maintenance, which can facilitate various practical applications, such as maintenance planning, and has the potential to enhance the efficiency of engineers' documentation work.}
}
@article{LECU2024443,
title = {Using LLMs and ontologies to extract causal relationships from medical abstracts},
journal = {Procedia Computer Science},
volume = {244},
pages = {443-452},
year = {2024},
note = {6th International Conference on AI in Computational Linguistics},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.10.219},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924030205},
author = {Alexandru Lecu and Adrian Groza and Lezan Hawizy},
keywords = {Causal Relation Extraction, Knowledge Graphs, Large Language Models, Age-Related Macular Degeneration},
abstract = {The substantiation of the causal relationships behind its development is very important in identifying possible interventions and early treatment. Knowledge Graphs (KG) play a crucial role in the medical research domain by organizing data into interconnected structures that represent relationships between entities such as disease, treatments, and progressions. This paper shows a complete workflow that demonstrates the extraction of causal relationships from medical abstracts using a fine-tuned GPT-based model and the integration of these relationships into a KG.}
}
@article{LI2025113052,
title = {CoLE: A collaborative legal expert prompting framework for large language models in law},
journal = {Knowledge-Based Systems},
volume = {311},
pages = {113052},
year = {2025},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2025.113052},
url = {https://www.sciencedirect.com/science/article/pii/S0950705125000991},
author = {Bo Li and Shuang Fan and Shaolin Zhu and Lijie Wen},
keywords = {Artificial intelligence, Natural language processing, Legal large language models},
abstract = {Large Language Models (LLMs) have achieved remarkable outcomes in various natural language processing tasks. However, their application to the highly specialized field of law presents unique challenges. Legal language, characterized by complex syntax, domain-specific terminology, and nuanced logical relationships, poses significant hurdles for existing NLP models in accurately understanding and processing legal queries. Furthermore, the sheer volume of legal documents complicates information retrieval and knowledge extraction, making it difficult for models to pinpoint relevant legal articles and cases. Moreover, existing legal LLMs often struggle to effectively handle colloquial user queries and lack efficient mechanisms for selecting the most relevant demonstrations in In-Context Learning (ICL), hindering their ability to provide accurate and comprehensive legal advice. In order to address these issues, we propose a novel prompting framework named “Collaborative Legal Experts” (CoLE). This framework draws inspiration from teamwork paradigms in real-world legal case processing. First, we design an intent identification module to analyze user queries for identifying potential intents and law domains. Then, through two subsequent processes, potential background information and the best demonstration are generated. Finally, we design a prompt generator to assemble prompts generated from the previous steps. It combines with the LLMs to generate the final answer. Notably, we find that the self-generated information by LLMs has a smaller gap when fused with LLMs. We evaluate performance by integrating it with 7 general-purpose Chinese LLMs and comparing its performance against 8 specialized legal LLMs across 10 datasets, including Single-Choice, Multiple-Choice, and Question&Answer. The results indicate that integrating with CoLE’s LLMs has the potential to significantly enhance performance in the law field, particularly without the need for annotated datasets or model parameter updates. Moreover, our proposed model outperforms all state-of-the-art LLMs in law. The code is available at https://github.com/liboaccn/cole.}
}
@article{FAN2025113644,
title = {AutoMEX: Streamlining material extrusion with AI agents powered by large language models and knowledge graphs},
journal = {Materials & Design},
volume = {251},
pages = {113644},
year = {2025},
issn = {0264-1275},
doi = {https://doi.org/10.1016/j.matdes.2025.113644},
url = {https://www.sciencedirect.com/science/article/pii/S0264127525000644},
author = {Haolin Fan and Junlin Huang and Jilong Xu and Yifei Zhou and Jerry Ying Hsi Fuh and Wen Feng Lu and Bingbing Li},
keywords = {Material extrusion, Large language models, Artificial intelligence agents, Knowledge graphs, Autonomous additive manufacturing},
abstract = {Additive manufacturing (AM), particularly material extrusion (MEX), has become a versatile and widely adopted technology with significant applications in the consumer goods and healthcare industries. Despite its affordability, adaptability, and user-friendliness advantages, MEX faces challenges in scaling for mass production due to limited process automation and fragmented domain knowledge, leaving gaps in end-to-end workflow integration. We propose AutoMEX, an innovative framework that integrates large language models (LLMs) as artificial intelligence (AI) agents to automate the MEX process to address these limitations. AutoMEX utilizes a knowledge graph (KG) derived from the scientific literature to enable LLMs to provide expert recommendations on material selection, process parameters, and design considerations, thereby improving accessibility and efficiency. With minimal human intervention, the framework encompasses a complete workflow, including CAD model generation, printing parameter recommendation, slicing, and machine operation. Experimental validation demonstrated a query acceptance rate of 94.6% for the recommendation system and up to a 9.6% improvement in print strength when employing the recommended parameters. These results highlight enhanced quality, autonomy, and customization of AM outputs, making AutoMEX suitable for batch production and streamlined manufacturing processes. While the framework shows promising potential, challenges such as the computational demands of advanced LLMs and the need for continual updates to the KG remain areas for future work. Overall, AutoMEX offers a pathway toward broader adoption and scalability of MEX technology, advancing the field of AM through enhanced automation and efficiency.}
}
@article{XIA2024102728,
title = {Leveraging error-assisted fine-tuning large language models for manufacturing excellence},
journal = {Robotics and Computer-Integrated Manufacturing},
volume = {88},
pages = {102728},
year = {2024},
issn = {0736-5845},
doi = {https://doi.org/10.1016/j.rcim.2024.102728},
url = {https://www.sciencedirect.com/science/article/pii/S0736584524000140},
author = {Liqiao Xia and Chengxi Li and Canbin Zhang and Shimin Liu and Pai Zheng},
keywords = {Large language model, Smart manufacturing, Industry 4.0, Knowledge management, Generative AI},
abstract = {The emergence of large language models (LLM), like GPT, is revolutionizing the field of information retrieval, finding applications across a wide range of domains. However, the intricate domain knowledge and the unique software paradigms inherent to the manufacturing sector have posed significant barriers to the effective utilization of LLM. To address this divide, an error-assisted fine-tuning approach is proposed to adapt LLM specifically for the manufacturing domain. Initially, the LLM is fine-tuned using a manufacturing-domain corpus, allowing it to learn and adapt to the nuances of the manufacturing field. Additionally, the injection of a labeled dataset into a pre-configured LLM enhances its ability to identify key elements within the domain. To ensure the generation of syntactically valid programs in domain-specific languages, and to accommodate environmental constraints, an error-assisted iterative prompting procedure is introduced, which facilitates the generation of reliable and expected code. Experimental results demonstrate the model’s proficiency in accurately responding to manufacturing-related queries and its effectiveness in generating reliable code, where the accuracy of judgment querying can experience an improvement of approximately 4.1%. By expanding the applicability of LLM to the manufacturing industry, it is hoped that this research will pave the way for a broad array of new LLM-based applications within manufacturing.}
}
@article{BASHIR2025102406,
title = {Logic-infused knowledge graph QA: Enhancing large language models for specialized domains through Prolog integration},
journal = {Data & Knowledge Engineering},
volume = {157},
pages = {102406},
year = {2025},
issn = {0169-023X},
doi = {https://doi.org/10.1016/j.datak.2025.102406},
url = {https://www.sciencedirect.com/science/article/pii/S0169023X25000011},
author = {Aneesa Bashir and Rong Peng and Yongchang Ding},
keywords = {Knowledge Graph Question Answering (KGQA), Large language models (LLMs), Logical programming (Prolog), Named entity recognition (NER), Multi-hop reasoning, Transformer, BERT},
abstract = {Efficiently answering questions over complex, domain-specific knowledge graphs remain a substantial challenge, as large language models (LLMs) often lack the logical reasoning abilities and particular knowledge required for such tasks. This paper presents a novel framework integrating LLMs with logical programming languages like Prolog for Logic-Infused Knowledge Graph Question Answering (KGQA) in specialized domains. The proposed methodology uses a transformer-based encoder–decoder architecture. An encoder reads the question, and a named entity recognition (NER) module connects entities to the knowledge graph. The extracted entities are fed into a grammar-guided decoder, producing a logical form (Prolog query) that captures the semantic constraints and relationships. The Prolog query is executed over the knowledge graph to perform symbolic reasoning and retrieve relevant answer entities. Comprehensive experiments on the MetaQA benchmark dataset demonstrate the superior performance of this logic-infused method in accurately identifying correct answer entities from the knowledge graph. Even when trained on a limited subset of annotated data, it outperforms state-of-the-art baselines, achieving 89.60 % and F1-scores of up to 89.61 %, showcasing its effectiveness in enhancing large language models with symbolic reasoning capabilities for specialized question-answering tasks. The seamless integration of LLMs and logical programming enables the proposed framework to reason effectively over complex, domain-specific knowledge graphs, overcoming a key limitation of existing KGQA systems. In specialized domains, the interpretability provided by representing questions such as Prologue queries is a valuable asset.}
}
@article{YANG2025102868,
title = {GS-KGC: A generative subgraph-based framework for knowledge graph completion with large language models},
journal = {Information Fusion},
volume = {117},
pages = {102868},
year = {2025},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2024.102868},
url = {https://www.sciencedirect.com/science/article/pii/S1566253524006468},
author = {Rui Yang and Jiahao Zhu and Jianping Man and Hongze Liu and Li Fang and Yi Zhou},
keywords = {Knowledge graph, Knowledge graph completion, Large language models, Question answer},
abstract = {Knowledge graph completion (KGC) focuses on identifying missing triples in a knowledge graph (KG) , which is crucial for many downstream applications. Given the rapid development of large language models (LLMs), some LLM-based methods are proposed for KGC task. However, most of them focus on prompt engineering while overlooking the fact that finer-grained subgraph information can aid LLMs in generating more accurate answers. In this paper, we propose a novel completion framework called Generative Subgraph-based KGC (GS-KGC), which utilizes subgraph information as contextual reasoning and employs a QA approach to achieve the KGC task. This framework primarily includes a subgraph partitioning algorithm designed to generate negatives and neighbors. Specifically, negatives can encourage LLMs to generate a broader range of answers, while neighbors provide additional contextual insights for LLM reasoning. Furthermore, we found that GS-KGC can discover potential triples within the KGs and new facts beyond the KGs. Experiments conducted on four common KGC datasets highlight the advantages of the proposed GS-KGC, e.g., it shows a 5.6% increase in Hits@3 compared to the LLM-based model CP-KGC on the FB15k-237N, and a 9.3% increase over the LLM-based model TECHS on the ICEWS14.}
}
@article{UHM2025105926,
title = {Effectiveness of retrieval augmented generation-based large language models for generating construction safety information},
journal = {Automation in Construction},
volume = {170},
pages = {105926},
year = {2025},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2024.105926},
url = {https://www.sciencedirect.com/science/article/pii/S0926580524006629},
author = {Miyoung Uhm and Jaehee Kim and Seungjun Ahn and Hoyoung Jeong and Hongjo Kim},
keywords = {LLMs (large language models), RAG (retrieval-augmented generation), Personalized safety, Construction safety information generation},
abstract = {While Generative Pre-Trained Transformers (GPT)-based models offer high potential for context-specific information generation, inaccurate numerical responses, a lack of detailed information, and hallucination problems remain as the main challenges for their use in assisting safety engineering and management tasks. To address the challenges, this paper systematically evaluates the effectiveness of the Retrieval-Augmented Generation-based GPT (RAG-GPT) model for generating detailed and specific construction safety information. The RAG-GPT model was compared with four other GPT models, evaluating the models' responses from three different groups––2 researchers, 10 construction safety experts, and 30 construction workers. Quantitative analysis demonstrated that the RAG-GPT model showed superior performance compared to the other models. Experts rated the RAG-GPT model as providing more contextually relevant answers, with high marks for accuracy and essential information inclusion. The findings indicate that the RAG strategy, which uses vector data to enhance information retrieval, significantly improves the accuracy of construction safety information.}
}
@article{CELINO2025100850,
title = {Procedural knowledge management in Industry 5.0: Challenges and opportunities for knowledge graphs},
journal = {Journal of Web Semantics},
volume = {84},
pages = {100850},
year = {2025},
issn = {1570-8268},
doi = {https://doi.org/10.1016/j.websem.2024.100850},
url = {https://www.sciencedirect.com/science/article/pii/S1570826824000362},
author = {Irene Celino and Valentina Anita Carriero and Antonia Azzini and Ilaria Baroni and Mario Scrocca},
keywords = {Procedural knowledge, Industry 5.0, Knowledge graphs, Artificial Intelligence},
abstract = {With digital transformation, industrial companies today are facing the challenges to change and innovate their business, by leveraging digital technologies and tools to support their processes and their operations. One of their main challenges is the management of the company knowledge, especially when tacit and owned by industry workers. In this paper, we illustrate how knowledge graphs can be the turning point to allow industry workers digitize and exploit the knowledge about the “what”, the “how” and the “why” of their everyday activities. In particular, we focus on the “how” by illustrating the challenges related to procedural knowledge management, i.e., the knowledge about processes and workflows that employees need to follow, and comply with, to correctly execute their tasks, in order to improve efficiency and effectiveness, to reduce risks and human errors and to optimize operations. We also explain the relationship in this context between knowledge graphs and sub-symbolic AI approaches.}
}
@article{XU2025126585,
title = {Towards normalized clinical information extraction in Chinese radiology report with large language models},
journal = {Expert Systems with Applications},
volume = {271},
pages = {126585},
year = {2025},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2025.126585},
url = {https://www.sciencedirect.com/science/article/pii/S0957417425002076},
author = {Qinwei Xu and Xingkun Xu and Chenyi Zhou and Zuozhu Liu and Feiyue Huang and Shaoxin Li and Lifeng Zhu and Zhian Bai and Yuchen Xu and Weiguo Hu},
keywords = {Clinical information extraction, Large language models, Instruction tuning, Data-efficient learning, Chinese radiology reports},
abstract = {Radiology reports serve as a fundamental component within electronic medical records. Converting unstructured free-text reports into structured formats holds paramount importance for the management and utilization of radiology reports. In this paper, we propose a novel information extraction paradigm named normalized clinical information extraction (NCIE) for Chinese radiology reports. Specifically, NCIE operates in an end-to-end fashion to extract normalized and structured clinical information without decomposing the information extraction process into multiple intermediate tasks. Motivated by recent progress in Large Language Models (LLMs), we address the NCIE problem based on the instruction tuning of LLMs. The proposed approach, termed Radiological Information End-to-end Extraction with LLM (RIEEL), excels at extracting structural information comprising radiological observations alongside their corresponding anatomical locations and status. To ensure the model in learning the normalized medical concepts correctly, we establish a radiology knowledge base with expert knowledge and further curate a high-quality instruction tuning dataset. Moreover, we incorporate two data-efficient learning strategies based on data augmentation and self-training to enhance the model’s NCIE capabilities during instruction tuning. Through extensive experiments, we demonstrate that the proposed RIEEL achieves superior performances with different state-of-the-arts backbone LLMs, including Qwen1.5, Baichuan2 and LLaMA3. Remarkably, the best version of RIEEL surpasses GPT-4 in NCIE by a substantial margin of 30.61% in terms of the F1 score.}
}
@article{DAQUIN2025100854,
title = {On the role of knowledge graphs in AI-based scientific discovery},
journal = {Journal of Web Semantics},
volume = {84},
pages = {100854},
year = {2025},
issn = {1570-8268},
doi = {https://doi.org/10.1016/j.websem.2024.100854},
url = {https://www.sciencedirect.com/science/article/pii/S1570826824000404},
author = {Mathieu d’Aquin},
keywords = {Scientific discovery, Knowledge graphs, Machine learning, Interpretability},
abstract = {Research and the scientific activity are widely seen as an area where the current trends in AI, namely the development of deep learning models (including large language models), are having an increasing impact. Indeed, the ability of such models to extrapolate from data, seemingly finding unknown patterns relating implicit features of the objects under study to their properties can, at the very least, help accelerate and scale up those studies as demonstrated in fields such as molecular biology and chemistry. Knowledge graphs, on the other hand, have more traditionally been used to organize information around the scientific activity, keeping track of existing knowledge, of conducted experiments, of interactions within the research community, etc. However, for machine learning models to be truly used as a tool for scientific advancement, we have to find ways for the knowledge implicitly gained by these models from their training to be integrated with the explicitly represented knowledge captured through knowledge graphs. Based on our experience in ongoing projects in the domain of material science, in this position paper, we discuss the role that knowledge graphs can play in new methodologies for scientific discovery. These methodologies are based on the creation of large and opaque neural models. We therefore focus on the research challenges we need to address to support aligning such neural models to knowledge graphs for them to become a knowledge-level interface to those neural models.}
}
@article{WANG2024361,
title = {Ontology-integrated tuning of large language model for intelligent maintenance},
journal = {CIRP Annals},
volume = {73},
number = {1},
pages = {361-364},
year = {2024},
issn = {0007-8506},
doi = {https://doi.org/10.1016/j.cirp.2024.04.012},
url = {https://www.sciencedirect.com/science/article/pii/S000785062400026X},
author = {Peng Wang and John Karigiannis and Robert X. Gao},
keywords = {Maintenance, Machine learning, Large language models},
abstract = {As new AI technologies such as Large Language Models (LLM) quickly evolve, the need for enhancing general-purpose LLMs with physical knowledge to better serve the manufacturing community has been increasingly recognized. This paper presents a method that tailors GPT-3.5 with domain-specific knowledge for intelligent aircraft maintenance. Specifically, aircraft ontology is investigated to curate maintenance logs with encoded component hierarchical structure to fine-tune GPT-3.5. Experimental results demonstrate the effectiveness of the developed method in accurately identifying defective components and providing consistent maintenance action recommendations, outperforming general-purpose GPT-3.5 and GPT-4.0. The method can be adapted to other domains in manufacturing and beyond.}
}
@article{KABAL20242617,
title = {Enhancing Domain-Independent Knowledge Graph Construction through OpenIE Cleaning and LLMs Validation},
journal = {Procedia Computer Science},
volume = {246},
pages = {2617-2626},
year = {2024},
note = {28th International Conference on Knowledge Based and Intelligent information and Engineering Systems (KES 2024)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.09.436},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924024761},
author = {Othmane Kabal and Mounira Harzallah and Fabrice Guillet and Ryutaro Ichise},
keywords = {Knowledge graph, From raw text, Domain-independent building, Knowledge graph construction pipeline, LLMs based validation, Information Extraction, LLMs for KG},
abstract = {In the challenging context of Knowledge Graph (KG) construction from text, traditional approaches often rely on Open Information Extraction (OpenIE) pipelines. However, they are prone to generating many incorrect triplets. While domain specific Named Entity Recognition (NER) is commonly used to enhance the results, it compromises the domain independence and misses crucial triplets. To address these limitations, we introduce G-T2KG, a novel pipeline for KG construction that aims to preserve the domain independence while reducing incorrect triplets, thus offering a cost-effective solution without the need for domain-specific adaptations. Our pipeline utilizes state-of-the-art OpenIE combined with both a noun phrase-based cleaning and a LLMs based validation. It is evaluated using gold standards in two distinct domains (i.e., computer science and music) that we have constructed in the context of this study. On computer science corpus, the experimental results demonstrate a higher recall as compared to state-of-the-art approaches, and a higher precision notably increased by the integration of LLMs. Experiments on the music corpus show good performance, underscoring the versatility and effectiveness of G-T2KG in domain-independent KG construction.}
}
@article{ANISUZZAMAN2025100184,
title = {Fine-Tuning Large Language Models for Specialized Use Cases},
journal = {Mayo Clinic Proceedings: Digital Health},
volume = {3},
number = {1},
pages = {100184},
year = {2025},
issn = {2949-7612},
doi = {https://doi.org/10.1016/j.mcpdig.2024.11.005},
url = {https://www.sciencedirect.com/science/article/pii/S2949761224001147},
author = {D.M. Anisuzzaman and Jeffrey G. Malins and Paul A. Friedman and Zachi I. Attia},
abstract = {Large language models (LLMs) are a type of artificial intelligence, which operate by predicting and assembling sequences of words that are statistically likely to follow from a given text input. With this basic ability, LLMs are able to answer complex questions and follow extremely complex instructions. Products created using LLMs such as ChatGPT by OpenAI and Claude by Anthropic have created a huge amount of traction and user engagements and revolutionized the way we interact with technology, bringing a new dimension to human-computer interaction. Fine-tuning is a process in which a pretrained model, such as an LLM, is further trained on a custom data set to adapt it for specialized tasks or domains. In this review, we outline some of the major methodologic approaches and techniques that can be used to fine-tune LLMs for specialized use cases and enumerate the general steps required for carrying out LLM fine-tuning. We then illustrate a few of these methodologic approaches by describing several specific use cases of fine-tuning LLMs across medical subspecialties. Finally, we close with a consideration of some of the benefits and limitations associated with fine-tuning LLMs for specialized use cases, with an emphasis on specific concerns in the field of medicine.}
}
@article{CHENG2024109361,
title = {A link prediction method for Chinese financial event knowledge graph based on graph attention networks and convolutional neural networks},
journal = {Engineering Applications of Artificial Intelligence},
volume = {138},
pages = {109361},
year = {2024},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2024.109361},
url = {https://www.sciencedirect.com/science/article/pii/S0952197624015197},
author = {Haitao Cheng and Ke Wang and Xiaoying Tan},
keywords = {Chinese financial event knowledge graph, Link prediction, Graph attention network, Convolutional neural network, Large language model},
abstract = {Finance is a knowledge-intensive domain in nature, with its data containing a significant amount of interconnected information. Constructing a financial knowledge graph is an important application for transforming financial text/web content into machine-readable data. However, the complexity of Chinese financial knowledge and the dynamic and evolving nature of Chinese financial data often lead to incomplete knowledge graphs. To address this challenge, we propose a novel link prediction method for Chinese financial event knowledge graph based on Graph Attention Networks and Convolutional Neural Networks. Our method begins with the construction of the foundational Chinese financial event knowledge graph using a relational triple extraction module integrated with a large language model framework, along with a Prompting with Iterative Verification (PiVe) module for validation. To enhance the completeness of the knowledge graph, we introduce an encoder-decoder framework, where a graph attention network with joint embeddings of financial event entities and relations acts as the encoder, while a Convolutional Knowledge Base embedding model (ConvKB) serves as the decoder. This framework effectively aggregates crucial neighbor information and captures global relationships among entity and relation embeddings. Extensive comparative experiments demonstrate the utility and accuracy of this method, ultimately enabling the effective completion of Chinese financial event knowledge graphs.}
}
@article{MICHEL2025104175,
title = {Seeing economic development like a large language model. A methodological approach to the exploration of geographical imaginaries in generative AI},
journal = {Geoforum},
volume = {158},
pages = {104175},
year = {2025},
issn = {0016-7185},
doi = {https://doi.org/10.1016/j.geoforum.2024.104175},
url = {https://www.sciencedirect.com/science/article/pii/S0016718524002367},
author = {Boris Michel and Yannick Ecker},
abstract = {The recent hype surrounding the disruptive potential of AI technologies in the form of large language models or text to image generators also raises questions for geographical research and practice. These questions include the power relations and inequalities inscribed in these systems, their significance for work and labor relations, their ecological and economic impact, but also the geographical and spatial imaginaries they reproduce. This article focuses on the latter and formulates a series of theoretical and methodological considerations for dealing with the output of these systems. As we assume that outputs generated by large language models will play an increasing role in the future, both in public and media discourses as well as in the discourses and practices of spatial planning and economic policy making, we consider it important to gain a critical understanding of these socio-technical systems. The empirical object of investigation of this paper is generated output that deals with questions of regional development and economic challenges in three European regions that are currently particularly affected by the transition to a climate-neutral economy and are designated by the European Union as Just Transition Fund Territories. We are particularly interested in how geographical imaginaries about these regions are formulated, how economic and social problems of these regions are presented and how this is translated into planning advice and development plans.}
}
@article{HE2025102963,
title = {A survey of large language models for healthcare: from data, technology, and applications to accountability and ethics},
journal = {Information Fusion},
volume = {118},
pages = {102963},
year = {2025},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2025.102963},
url = {https://www.sciencedirect.com/science/article/pii/S1566253525000363},
author = {Kai He and Rui Mao and Qika Lin and Yucheng Ruan and Xiang Lan and Mengling Feng and Erik Cambria},
keywords = {Healthcare application, Large language model, Medicine, Pretrained language model},
abstract = {The utilization of large language models (LLMs) for Healthcare has generated both excitement and concern due to their ability to effectively respond to free-text queries with certain professional knowledge. This survey outlines the capabilities of the currently developed Healthcare LLMs and explicates their development process, to provide an overview of the development road map from traditional Pretrained Language Models (PLMs) to LLMs. Specifically, we first explore the potential of LLMs to enhance the efficiency and effectiveness of various Healthcare applications highlighting both the strengths and limitations. Secondly, we conduct a comparison between the previous PLMs and the latest LLMs, and summarize related Healthcare training data, learning methods, and usage. Finally, the unique concerns associated with deploying LLMs are investigated, particularly regarding fairness, accountability, transparency, and ethics. Besides, we support researchers by compiling a collection of open-source resources11https://github.com/KaiHe-CatOwner/LLM-for-Healthcare.. Summarily, we contend that a significant paradigm shift is underway, transitioning from PLMs to LLMs. This shift encompasses a move from discriminative AI approaches to generative AI approaches, as well as a move from model-centered methodologies to data-centered methodologies. We determine that the biggest obstacle of using LLMs in Healthcare are fairness, accountability, transparency and ethics.}
}
@article{YANG2024112155,
title = {Enhancing text-based knowledge graph completion with zero-shot large language models: A focus on semantic enhancement},
journal = {Knowledge-Based Systems},
volume = {300},
pages = {112155},
year = {2024},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2024.112155},
url = {https://www.sciencedirect.com/science/article/pii/S0950705124007895},
author = {Rui Yang and Jiahao Zhu and Jianping Man and Li Fang and Yi Zhou},
keywords = {Knowledge graph, Knowledge graph completion, Large language models, Semantic enhancement},
abstract = {The design and development of text-based knowledge graph completion (KGC) methods leveraging textual entity descriptions are at the forefront of research. These methods involve advanced optimization techniques such as soft prompts and contrastive learning to enhance KGC models. The effectiveness of text-based methods largely hinges on the quality and richness of the training data. Large language models (LLMs) can utilize straightforward prompts to alter text data, thereby enabling data augmentation for KGC. Nevertheless, LLMs typically demand substantial computational resources. To address these issues, we introduce a framework termed constrained prompts for KGC (CP-KGC). This CP-KGC framework designs prompts that adapt to different datasets to enhance semantic richness. Additionally, CP-KGC employs a context constraint strategy to effectively identify polysemous entities within KGC datasets. Through extensive experimentation, we have verified the effectiveness of this framework. Even after quantization, the LLM (Qwen-7B-Chat-int4) still enhances the performance of text-based KGC methods.11Code and datasets are available at https://github.com/sjlmg/CP-KGC. This study extends the performance limits of existing models and promotes further integration of KGC with LLMs.}
}
@article{FERRAG2025,
title = {Generative AI in Cybersecurity: A Comprehensive Review of LLM Applications and Vulnerabilities},
journal = {Internet of Things and Cyber-Physical Systems},
year = {2025},
issn = {2667-3452},
doi = {https://doi.org/10.1016/j.iotcps.2025.01.001},
url = {https://www.sciencedirect.com/science/article/pii/S2667345225000082},
author = {Mohamed Amine Ferrag and Fatima Alwahedi and Ammar Battah and Bilel Cherif and Abdechakour Mechri and Norbert Tihanyi and Tamas Bisztray and Merouane Debbah},
keywords = {Generative AI, LLM, Transformer, Security, Cyber Security},
abstract = {This paper provides a comprehensive review of the future of cybersecurity through Generative AI and Large Language Models (LLMs). We explore LLM applications across various domains, including hardware design security, intrusion detection, software engineering, design verification, cyber threat intelligence, malware detection, and phishing detection. We present an overview of LLM evolution and its current state, focusing on advancements in models such as GPT-4, GPT-3.5, Mixtral-8x7B, BERT, Falcon2, and LLaMA. Our analysis extends to LLM vulnerabilities, such as prompt injection, insecure output handling, data poisoning, DDoS attacks, and adversarial instructions. We delve into mitigation strategies to protect these models, providing a comprehensive look at potential attack scenarios and prevention techniques. Furthermore, we evaluate the performance of 42 LLM models in cybersecurity knowledge and hardware security, highlighting their strengths and weaknesses. We thoroughly evaluate cybersecurity datasets for LLM training and testing, covering the lifecycle from data creation to usage and identifying gaps for future research. In addition, we review new strategies for leveraging LLMs, including techniques like Half-Quadratic Quantization (HQQ), Reinforcement Learning with Human Feedback (RLHF), Direct Preference Optimization (DPO), Quantized Low-Rank Adapters (QLoRA), and Retrieval-Augmented Generation (RAG). These insights aim to enhance real-time cybersecurity defenses and improve the sophistication of LLM applications in threat detection and response. Our paper provides a foundational understanding and strategic direction for integrating LLMs into future cybersecurity frameworks, emphasizing innovation and robust model deployment to safeguard against evolving cyber threats.}
}
@article{LIAO2025103134,
title = {Large language model assisted fine-grained knowledge graph construction for robotic fault diagnosis},
journal = {Advanced Engineering Informatics},
volume = {65},
pages = {103134},
year = {2025},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2025.103134},
url = {https://www.sciencedirect.com/science/article/pii/S1474034625000278},
author = {Xingming Liao and Chong Chen and Zhuowei Wang and Ying Liu and Tao Wang and Lianglun Cheng},
keywords = {Knowledge Graph, Large Language Model, Fault Diagnosis, Industrial Robots},
abstract = {With the rapid deployment of industrial robots in manufacturing, the demand for advanced maintenance techniques to sustain operational efficiency has become crucial. Fault diagnosis Knowledge Graph (KG) is essential as it interlinks multi-source data related to industrial robot faults, capturing multi-level semantic associations among different fault events. However, the construction and application of fine-grained fault diagnosis KG face significant challenges due to the inherent complexity of nested entities in maintenance texts and the severe scarcity of annotated industrial data. In this study, we propose a Large Language Model (LLM) assisted data augmentation approach, which handles the complex nested entities in maintenance corpora and constructs a more fine-grained fault diagnosis KG. Firstly, the fine-grained ontology is constructed via LLM Assistance in Industrial Nested Named Entity Recognition (assInNNER). Then, an Industrial Nested Label Classification Template (INCT) is designed, enabling the use of nested entities in Attention-map aware keyword selection for the Industrial Nested Language Model (ANLM) data augmentation methods. ANLM can effectively improve the model’s performance in nested entity extraction when corpora are scarce. Subsequently, a Confidence Filtering Mechanism (CFM) is introduced to evaluate and select the generated data for enhancement, and assInNNER is further deployed to recall the negative samples corpus again to further improve performance. Experimental studies based on multi-source corpora demonstrate that compared to existing algorithms, our method achieves an average F1 increase of 8.25 %, 3.31 %, and 1.96 % in 5%, 10 %, and 25 % in few-shot settings, respectively.}
}
@article{KUNZE2025547,
title = {Large Language Models Applied to Health Care Tasks May Improve Clinical Efficiency, Value of Care Rendered, Research, and Medical Education},
journal = {Arthroscopy: The Journal of Arthroscopic & Related Surgery},
volume = {41},
number = {3},
pages = {547-556},
year = {2025},
issn = {0749-8063},
doi = {https://doi.org/10.1016/j.arthro.2024.12.010},
url = {https://www.sciencedirect.com/science/article/pii/S0749806324010478},
author = {Kyle N. Kunze and Benedict U. Nwachukwu and Mark P. Cote and Prem N. Ramkumar},
abstract = {Large language models (LLMs) are generative artificial intelligence models that create content on the basis of the data on which it was trained. Processing capabilities have evolved from text only to being multimodal including text, images, audio, and video features. In health care settings, LLMs are being applied to several clinically important areas, including patient care and workflow efficiency, communications, hospital operations and data management, medical education, practice management, and health care research. Under the umbrella of patient care, several core use cases of LLMs include simplifying documentation tasks, enhancing patient communication (interactive language and written), conveying medical knowledge, and performing medical triage and diagnosis. However, LLMs warrant scrutiny when applied to health care tasks, as errors may have negative implications for health care outcomes, specifically in the context of perpetuating bias, ethical considerations, and cost-effectiveness. Customized LLMs developed for more narrow purposes may help overcome certain performance limitations, transparency challenges, and biases present in contemporary generalized LLMs by curating training data. Methods of customizing LLMs broadly fall under 4 categories: prompt engineering, retrieval augmented generation, fine-tuning, and agentic augmentation, with each approach conferring different information-retrieval properties for the LLM.
Level of Evidence
Level V, expert opinion.}
}
@article{FU2025105347,
title = {Generative AI in the context of assistive technologies: Trends, limitations and future directions},
journal = {Image and Vision Computing},
volume = {154},
pages = {105347},
year = {2025},
issn = {0262-8856},
doi = {https://doi.org/10.1016/j.imavis.2024.105347},
url = {https://www.sciencedirect.com/science/article/pii/S0262885624004529},
author = {Biying Fu and Abdenour Hadid and Naser Damer},
keywords = {Assistive AI, Generative AI, Generative models, Assistive systems, Assistive technologies and services},
abstract = {With the tremendous successes of Large Language Models (LLMs) like ChatGPT for text generation and Dall-E for high-quality image generation, generative Artificial Intelligence (AI) models have shown a hype in our society. Generative AI seamlessly delved into different aspects of society ranging from economy, education, legislation, computer science, finance, and even healthcare. This article provides a comprehensive survey on the increased and promising use of generative AI in assistive technologies benefiting different parties, ranging from the assistive system developers, medical practitioners, care workforce, to the people who need the care and the comfort. Ethical concerns, biases, lack of transparency, insufficient explainability, and limited trustworthiness are major challenges when using generative AI in assistive technologies, particularly in systems that impact people directly. Key future research directions to address these issues include creating standardized rules, establishing commonly accepted evaluation metrics and benchmarks for explainability and reasoning processes, and making further advancements in understanding and reducing bias and its potential harms. Beyond showing the current trends of applying generative AI in the scope of assistive technologies in four identified key domains, which include care sectors, medical sectors, helping people in need, and co-working, the survey also discusses the current limitations and provides promising future research directions to foster better integration of generative AI in assistive technologies.}
}
@article{XU202449,
title = {GeoPredict-LLM: Intelligent tunnel advanced geological prediction by reprogramming large language models},
journal = {Intelligent Geoengineering},
volume = {1},
number = {1},
pages = {49-57},
year = {2024},
issn = {3050-6190},
doi = {https://doi.org/10.1016/j.ige.2024.10.005},
url = {https://www.sciencedirect.com/science/article/pii/S3050619024000053},
author = {Zhenhao Xu and Zhaoyang Wang and Shucai Li and Xiao Zhang and Peng Lin},
keywords = {Advanced geological prediction, Large language model, Data diffusion, Multisource data, Multimodal data, Knowledge graph},
abstract = {With the improvement of multisource information sensing and data acquisition capabilities inside tunnels, the availability of multimodal data in tunnel engineering has significantly increased. However, due to structural differences in multimodal data, traditional intelligent advanced geological prediction models have limited capacity for data fusion. Furthermore, the lack of pre-trained models makes it difficult for neural networks trained from scratch to deeply explore the features of multimodal data. To address these challenges, we utilize the fusion capability of knowledge graph for multimodal data and the pre-trained knowledge of large language models (LLMs) to establish an intelligent advanced geological prediction model (GeoPredict-LLM). First, we develop an advanced geological prediction ontology model, forming a knowledge graph database. Using knowledge graph embeddings, multisource and multimodal data are transformed into low-dimensional vectors with a unified structure. Secondly, pre-trained LLMs, through reprogramming, reconstruct these low-dimensional vectors, imparting linguistic characteristics to the data. This transformation effectively reframes the complex task of advanced geological prediction as a "language-based" problem, enabling the model to approach the task from a linguistic perspective. Moreover, we propose the prompt-as-prefix method, which enables output generation, while freezing the core of the LLM, thereby significantly reduces the number of training parameters. Finally, evaluations show that compared to neural network models without pre-trained models, GeoPredict-LLM significantly improves prediction accuracy. It is worth noting that as long as a knowledge graph database can be established, GeoPredict-LLM can be adapted to multimodal data mining tasks with minimal modifications.}
}
@article{SHI2024678,
title = {Interoperable information modelling leveraging asset administration shell and large language model for quality control toward zero defect manufacturing},
journal = {Journal of Manufacturing Systems},
volume = {77},
pages = {678-696},
year = {2024},
issn = {0278-6125},
doi = {https://doi.org/10.1016/j.jmsy.2024.10.011},
url = {https://www.sciencedirect.com/science/article/pii/S0278612524002395},
author = {Dachuan Shi and Philipp Liedl and Thomas Bauernhansl},
keywords = {Interoperability, Large language model, Ontology, Asset administration shell, Zero defect manufacturing, Information modelling, Quality control, Industry 4.0},
abstract = {In the era of Industry 4.0, Zero Defect Manufacturing (ZDM) has emerged as a prominent strategy for quality improvement, emphasizing data-driven approaches for defect prediction, prevention, and mitigation. The success of ZDM heavily depends on the availability and quality of data typically collected from diverse and heterogeneous sources during production and quality control, presenting challenges in data interoperability. Addressing this, we introduce a novel approach leveraging Asset Administration Shell (AAS) and Large Language Models (LLMs) for creating interoperable information models that incorporate semantic contextual information to enhance the interoperability of data integration in the quality control process. AAS, initiated by German industry stakeholders, shows a significant advancement in information modeling, blending ontology and digital twin concepts for the virtual representation of assets. In this work, we develop a systematic, use-case-driven methodology for AAS-based information modeling. This methodology guides the design and implementation of AAS models, ensuring model properties are presented in a unified structure and reference external standardized vocabularies to maintain consistency across different systems. To automate this referencing process, we propose a novel LLM-based algorithm to semantically search model properties within a standardized vocabulary repository. This algorithm significantly reduces manual intervention in model development. A case study in the injection molding domain demonstrates the practical application of our approach, showcasing the integration and linking of product quality and machine process data with the help of the developed AAS models. Statistical evaluation of our LLM-based semantic search algorithm confirms its efficacy in enhancing data interoperability. This methodology offers a scalable and adaptable solution for various industrial use cases, promoting widespread data interoperability in the context of Industry 4.0.}
}
@article{LI2025125920,
title = {Taming large language models to implement diagnosis and evaluating the generation of LLMs at the semantic similarity level in acupuncture and moxibustion},
journal = {Expert Systems with Applications},
volume = {264},
pages = {125920},
year = {2025},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2024.125920},
url = {https://www.sciencedirect.com/science/article/pii/S0957417424027878},
author = {Shusheng Li and Wenjun Tan and Changshuai Zhang and Jiale Li and Haiyan Ren and Yanliang Guo and Jing Jia and Yangyang Liu and Xingfang Pan and Jing Guo and Wei Meng and Zhaoshui He},
keywords = {Artificial intelligence, Large language model, Traditional chinese medicine, Acupuncture and moxibustion, Prompting, Evaluation},
abstract = {With the rapid advancement of artificial intelligence and deep learning technologies, large language models (LLMs) such as ChatGPT and GPT-4 have made significant progress in comprehending and responding to human instructions. Acupuncture and moxibustion, therapeutic modalities in Traditional Chinese Medicine (TCM), possess extensive knowledge beneficial for patient treatment. Currently, acupuncture diagnosis relies on the experience and skills of individual acupuncturists, emphasizing the need for research to improve diagnostic accuracy through objective methods. Therefore, the integration of LLMs into the field of acupuncture can facilitate the recommendation of personalized acupuncture treatment programs. However, the application of general LLMs to the field of acupuncture diagnosis often yields suboptimal results. In addition, most LLM evaluation metrics depend solely on literal overlap and fail to capture semantic similarity. To address these challenges, this paper introduces AcupunctureGPT, a specialized large language model for acupuncture diagnosis, aimed at exploring the potential application of LLMs in this field. Patient Diagnostic Acupuncture Data is constructed to enhance the diagnostic capabilities of AcupunctureGPT in acupuncture. The Generated Knowledge Filter Prompting approach is proposed to improve the accuracy of LLMs in identifying similar diseases through the development and filtering of knowledge statements. The Sentence Similarity Evaluation Module (SSEM) is employed to assess the generation quality of LLMs at the semantic level. The Sentence Adaptive Enhancement Fusion Module (SAEFM), proposed within SSEM, enhances the adaptive fusion of output features at various levels. Experimental results demonstrate that AcupunctureGPT outperforms other large language models in diagnosing diseases and devising reasonable treatment plans. Furthermore, the evaluation metrics proposed in this paper have been validated for effectiveness.}
}
@article{ZHENG2024104738,
title = {PLRTE: Progressive learning for biomedical relation triplet extraction using large language models},
journal = {Journal of Biomedical Informatics},
volume = {159},
pages = {104738},
year = {2024},
issn = {1532-0464},
doi = {https://doi.org/10.1016/j.jbi.2024.104738},
url = {https://www.sciencedirect.com/science/article/pii/S1532046424001564},
author = {Yi-Kai Zheng and Bi Zeng and Yi-Chun Feng and Lu Zhou and Yi-Xue Li},
keywords = {Large language model, Relation triplet extraction, Biomedical text mining, Supervised fine-tuning, Natural language processing, Named entity recognition},
abstract = {Document-level relation triplet extraction is crucial in biomedical text mining, aiding in drug discovery and the construction of biomedical knowledge graphs. Current language models face challenges in generalizing to unseen datasets and relation types in biomedical relation triplet extraction, which limits their effectiveness in these crucial tasks. To address this challenge, our study optimizes models from two critical dimensions: data-task relevance and granularity of relations, aiming to enhance their generalization capabilities significantly. We introduce a novel progressive learning strategy to obtain the PLRTE model. This strategy not only enhances the model’s capability to comprehend diverse relation types in the biomedical domain but also implements a structured four-level progressive learning process through semantic relation augmentation, compositional instruction, and dual-axis level learning. Our experiments on the DDI and BC5CDR document-level biomedical relation triplet datasets demonstrate a significant performance improvement of 5% to 20% over the current state-of-the-art baselines. Furthermore, our model exhibits exceptional generalization capabilities on the unseen Chemprot and GDA datasets, further validating the effectiveness of optimizing data-task association and relation granularity for enhancing model generalizability.}
}
@article{GUAN2024100070,
title = {Drug discovery and development in the era of artificial intelligence: From machine learning to large language models},
journal = {Artificial Intelligence Chemistry},
volume = {2},
number = {1},
pages = {100070},
year = {2024},
issn = {2949-7477},
doi = {https://doi.org/10.1016/j.aichem.2024.100070},
url = {https://www.sciencedirect.com/science/article/pii/S2949747724000289},
author = {Shenghui Guan and Guanyu Wang},
keywords = {Machine learning, Drug Discovery, Bioinformatics},
abstract = {Drug Research and Development (R&D) is a complex and difficult process, and current drug R&D faces the challenges of long time span, high investment, and high failure rate. Machine learning, with its powerful learning ability to characterize big data and complex networks, is increasingly effective to improve the efficiency and success rate of drug R&D. Here we review some recent examples of the application of machine learning methods in six areas: disease gene prediction, virtual screening, drug molecule generation, molecular attribute prediction, and prediction of drug combination synergism. We also discuss the advantages of integrative learning in multi-attribute prediction. Integrative models based on base learners constructed from data of different dimensions on the one hand fully utilize the information contained in these data, and on the other hand improve the average prediction performance. Finally, we envision a new paradigm for drug discovery and development: a large language model acts as a central hub to organize public resources into a knowledge base, validating the knowledge with computational software and smaller predictive models, as well as high-throughput automated screening platforms based on organoidal technologies, to speed up development and reduce the differences in efficacy between disease models and humans to improve the success rate of a drug.}
}
@article{RIEMER2024102824,
title = {Conceptualizing generative AI as style engines: Application archetypes and implications},
journal = {International Journal of Information Management},
volume = {79},
pages = {102824},
year = {2024},
issn = {0268-4012},
doi = {https://doi.org/10.1016/j.ijinfomgt.2024.102824},
url = {https://www.sciencedirect.com/science/article/pii/S0268401224000720},
author = {Kai Riemer and Sandra Peter},
keywords = {Generative AI, Large language models, Style engines, AI assistants, AI agents},
abstract = {The rise of generative AI has brought with it a surprising paradox: systems that excel at tasks once thought to be uniquely human, like fluent conversation or persuasive writing, while simultaneously failing to meet traditional expectations of computing, in terms of reliability, accuracy, and veracity (e.g., given the various issues with so-called ‘hallucinations’). We argue that, when generative AI is seen through a traditional computing lens, its development focuses on optimizing for traditional computing traits that remain in principle unattainable. This risks backgrounding what is most novel and defining about it. As probabilistic technologies, generative AIs do not store, in any traditional sense, any data or content. Rather, essential features of training data become encoded in deep neural networks as patterns, that become practically available as styles. We discuss what happens when the distinction between objects and their appearance dissolves and all aspects of images or text become understood as styles, accessible for exploration and creative combination and generation. For example, defining visual qualities of entities like ‘chair’ or ‘cat’ become available as ‘chair-ness’ or ‘cat-ness’ for creative image generation. We argue that, when understood as style engines, unique generative AI capabilities become conceptualized as complementing traditional computing ones. This will aid both computing practitioners and information systems researchers in reconciling and integrating generative AI into the traditional IS landscape. Our conceptualization leads us to propose four archetypes of generative AI application and use, and to highlight future avenues for information systems research made visible by this conceptualization, as well as implications for practice and policymaking.}
}
@article{LI20242481,
title = {Enhancing Relational Triple Extraction in Specific Domains: Semantic Enhancement and Synergy of Large Language Models and Small Pre-Trained Language Models},
journal = {Computers, Materials and Continua},
volume = {79},
number = {2},
pages = {2481-2503},
year = {2024},
issn = {1546-2218},
doi = {https://doi.org/10.32604/cmc.2024.050005},
url = {https://www.sciencedirect.com/science/article/pii/S1546221824002248},
author = {Jiakai Li and Jianpeng Hu and Geng Zhang},
keywords = {Relational triple extraction, semantic interaction, large language models, data augmentation, specific domains},
abstract = {In the process of constructing domain-specific knowledge graphs, the task of relational triple extraction plays a critical role in transforming unstructured text into structured information. Existing relational triple extraction models face multiple challenges when processing domain-specific data, including insufficient utilization of semantic interaction information between entities and relations, difficulties in handling challenging samples, and the scarcity of domain-specific datasets. To address these issues, our study introduces three innovative components: Relation semantic enhancement, data augmentation, and a voting strategy, all designed to significantly improve the model’s performance in tackling domain-specific relational triple extraction tasks. We first propose an innovative attention interaction module. This method significantly enhances the semantic interaction capabilities between entities and relations by integrating semantic information from relation labels. Second, we propose a voting strategy that effectively combines the strengths of large language models (LLMs) and fine-tuned small pre-trained language models (SLMs) to reevaluate challenging samples, thereby improving the model’s adaptability in specific domains. Additionally, we explore the use of LLMs for data augmentation, aiming to generate domain-specific datasets to alleviate the scarcity of domain data. Experiments conducted on three domain-specific datasets demonstrate that our model outperforms existing comparative models in several aspects, with F1 scores exceeding the State of the Art models by 2%, 1.6%, and 0.6%, respectively, validating the effectiveness and generalizability of our approach.}
}
@article{SHENG2025104060,
title = {Confusing negative commonsense knowledge generation with hierarchy modeling and LLM-enhanced filtering},
journal = {Information Processing & Management},
volume = {62},
number = {3},
pages = {104060},
year = {2025},
issn = {0306-4573},
doi = {https://doi.org/10.1016/j.ipm.2025.104060},
url = {https://www.sciencedirect.com/science/article/pii/S0306457325000020},
author = {Yaqing Sheng and Weixin Zeng and Jiuyang Tang and Lihua Liu and Xiang Zhao},
keywords = {Knowledge graph, Large language model, Negative statement},
abstract = {While most of the world’s knowledge exists in a positive and affirmative form, negative knowledge also plays a significant role by showing what is not true or what not to think, and has yet been largely overlooked. Existing negative commonsense knowledge generation methods adopt the generation-filtering paradigm, while the produced negative statements are easy to detect and fail to contribute to both human perception and task-specific algorithms that require negative samples for training. In response, we put forward CONEG, a negative commonsense knowledge generation framework that generates confusing statements, featuring hierarchy modeling in candidate generation and LLM-enhanced two-stage filtering. Specifically, in the candidate generation stage, we identify congeners for entity phrases in the commonsense knowledge base using box embeddings, which can effectively capture the hierarchical correlations among entity phrases and produce confusing candidates. In the candidate filtering stage, we design a two-stage filtering strategy, consisting of intrinsic triple confidence measuring and extrinsic refinement through large language models with group-based instructions, which can effectively filter out true facts and low-quality negative candidates. We empirically evaluate our proposal on both intrinsic assessment and downstream tasks, and the results demonstrate that CONEG and its components are effective in terms of producing confusing negative knowledge, surpassing the state-of-the-art methods.}
}
@article{LI2024100612,
title = {Building a knowledge graph to enrich ChatGPT responses in manufacturing service discovery},
journal = {Journal of Industrial Information Integration},
volume = {40},
pages = {100612},
year = {2024},
issn = {2452-414X},
doi = {https://doi.org/10.1016/j.jii.2024.100612},
url = {https://www.sciencedirect.com/science/article/pii/S2452414X24000566},
author = {Yunqing Li and Binil Starly},
keywords = {Digital supply chain, Knowledge graph, ChatGPT, Manufacturing service discovery},
abstract = {Sourcing and identification of new manufacturing partners is crucial for manufacturing system integrators to enhance agility and reduce risk through supply chain diversification in the global economy. The advent of advanced large language models has captured significant interest, due to their ability to generate comprehensive and articulate responses across a wide range of knowledge domains. However, the system often falls short in accuracy and completeness when responding to domain-specific inquiries, particularly in areas like manufacturing service discovery. This research explores the potential of leveraging Knowledge Graphs in conjunction with ChatGPT to streamline the process for prospective clients in identifying small manufacturing enterprises. In this study, we propose a method that integrates bottom-up ontology with advanced machine learning models to develop a Manufacturing Service Knowledge Graph from an array of structured and unstructured data sources, including the digital footprints of small-scale manufacturers throughout North America. The Knowledge Graph and the learned graph embedding vectors are leveraged to tackle intricate queries within the digital supply chain network, responding with enhanced reliability and greater interpretability. The approach highlighted is scalable to millions of entities that can be distributed to form a global Manufacturing Service Knowledge Network Graph that can potentially interconnect multiple types of Knowledge Graphs that span industry sectors, geopolitical boundaries, and business domains. The dataset developed for this study, now publicly accessible, encompasses more than 13,000 manufacturers’ weblinks, manufacturing services, certifications, and location entity types.}
}
@article{CHEN2024111165,
title = {Systems engineering issues for industry applications of large language model},
journal = {Applied Soft Computing},
volume = {151},
pages = {111165},
year = {2024},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2023.111165},
url = {https://www.sciencedirect.com/science/article/pii/S1568494623011833},
author = {Wang Chen and Liu Yan-yi and Guo Tie-zheng and Li Da-peng and He Tao and Li Zhi and Yang Qing-wen and Wang Hui-han and Wen Ying-you},
keywords = {LLM, AIGC, Systems engineering, CDSS, Industry application},
abstract = {Large language model (LLM) is an important direction in the development of AGI, but its technology is still in rapid change, and its capabilities still have obvious deficiencies and imbalances, with persistent problems such as hallucination, value non-alignment, weak specialization, and black-box effect. In this case, how to apply LLM to different professional fields and develop high-quality AIGC industry applications has become a great challenge for ISVs. Building AIGC industry applications based on LLM is not simply a matter of functional realization. Although researchers and open-source communities have proposed numerous application development frameworks or tool components, there is a lack of overall architecture design for systems engineering and a lack of discussion on theories and methods of LLM application development in large-scale industry domains, such as healthcare, government affairs, finance, and media. This paper analyzes the basic ideas of LLM industry applications development, defines the functional requirements and feature requirements of LLM industry applications, puts forward the concept of Large Language Model Systems Engineering (LLM-SE), and develops an AI assisted clinical risk prediction system for amyloidosis disease based on the architecture of LLM-SE, which adopt knowledge engineering, quality engineering, etc., and verifies the LLM-SE development architecture and methodology.}
}
@article{NAJI20243694,
title = {Towards an LLM based approach for medical e-consent},
journal = {Procedia Computer Science},
volume = {246},
pages = {3694-3701},
year = {2024},
note = {28th International Conference on Knowledge Based and Intelligent information and Engineering Systems (KES 2024)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.09.187},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924021987},
author = {Mouncef Naji and Maroua Masmoudi and Hajer Baazaoui Zghal},
keywords = {E-consent, Large Language Model, knowledge graph, Healthcare Information Systems},
abstract = {The question of informed and voluntary consent emerges as a matter of significance in healthcare. Obtaining informed consent, encounters many obstacles coupled with systemic, clinician-related, and patient-related factors, demanding interventions at different levels. This paper introduces a novel approach to present personalized consent based on Large Language Models (LLMs). The personalization of information is displayed through the combination of the LLM with a knowledge graph. We focus in our approach on how the knowledge graph enhances and personalize content generation, allowing therefore the acquisition of informed consent. The paper focuses as well on aspects related to hyper-parameters of information retrieval that help giving better prompt to the LLM. Experiments have showcased intresting results in terms of personalization and information retrieval using metrics of Rouge, Faithfulness and Relevance.}
}
@article{ADHIKARY2024,
title = {Exploring the Efficacy of Large Language Models in Summarizing Mental Health Counseling Sessions: Benchmark Study},
journal = {JMIR Mental Health},
volume = {11},
year = {2024},
issn = {2368-7959},
doi = {https://doi.org/10.2196/57306},
url = {https://www.sciencedirect.com/science/article/pii/S2368795924000775},
author = {Prottay Kumar Adhikary and Aseem Srivastava and Shivani Kumar and Salam Michael Singh and Puneet Manuja and Jini K Gopinath and Vijay Krishnan and Swati Kedia Gupta and Koushik Sinha Deb and Tanmoy Chakraborty},
keywords = {mental health, counseling summarization, large language models, digital health, artificial intelligence, AI},
abstract = {Background
Comprehensive session summaries enable effective continuity in mental health counseling, facilitating informed therapy planning. However, manual summarization presents a significant challenge, diverting experts’ attention from the core counseling process. Leveraging advances in automatic summarization to streamline the summarization process addresses this issue because this enables mental health professionals to access concise summaries of lengthy therapy sessions, thereby increasing their efficiency. However, existing approaches often overlook the nuanced intricacies inherent in counseling interactions.
Objective
This study evaluates the effectiveness of state-of-the-art large language models (LLMs) in selectively summarizing various components of therapy sessions through aspect-based summarization, aiming to benchmark their performance.
Methods
We first created Mental Health Counseling-Component–Guided Dialogue Summaries, a benchmarking data set that consists of 191 counseling sessions with summaries focused on 3 distinct counseling components (also known as counseling aspects). Next, we assessed the capabilities of 11 state-of-the-art LLMs in addressing the task of counseling-component–guided summarization. The generated summaries were evaluated quantitatively using standard summarization metrics and verified qualitatively by mental health professionals.
Results
Our findings demonstrated the superior performance of task-specific LLMs such as MentalLlama, Mistral, and MentalBART evaluated using standard quantitative metrics such as Recall-Oriented Understudy for Gisting Evaluation (ROUGE)-1, ROUGE-2, ROUGE-L, and Bidirectional Encoder Representations from Transformers Score across all aspects of the counseling components. Furthermore, expert evaluation revealed that Mistral superseded both MentalLlama and MentalBART across 6 parameters: affective attitude, burden, ethicality, coherence, opportunity costs, and perceived effectiveness. However, these models exhibit a common weakness in terms of room for improvement in the opportunity costs and perceived effectiveness metrics.
Conclusions
While LLMs fine-tuned specifically on mental health domain data display better performance based on automatic evaluation scores, expert assessments indicate that these models are not yet reliable for clinical application. Further refinement and validation are necessary before their implementation in practice.}
}
@article{SHI2025102837,
title = {Dual data mapping with fine-tuned large language models and asset administration shells toward interoperable knowledge representation},
journal = {Robotics and Computer-Integrated Manufacturing},
volume = {91},
pages = {102837},
year = {2025},
issn = {0736-5845},
doi = {https://doi.org/10.1016/j.rcim.2024.102837},
url = {https://www.sciencedirect.com/science/article/pii/S0736584524001248},
author = {Dachuan Shi and Olga Meyer and Michael Oberle and Thomas Bauernhansl},
keywords = {Interoperability, Large language model, Asset administration shell, Digital twin, Entity matching, Knowledge representation},
abstract = {In the context of Industry 4.0, ensuring the compatibility of digital twins (DTs) with existing software systems in the manufacturing sector presents a significant challenge. The Asset Administration Shell (AAS), conceptualized as the standardized DT for an asset, offers a powerful framework that connects the DT with the established software infrastructure through interoperable knowledge representation. Although the IEC 63278 series specifies the AAS metamodel, it lacks a matching strategy for automating the mapping between proprietary data from existing software and AAS information models. Addressing this gap, we introduce a novel dual data mapping system (DDMS) that utilizes a fine-tuned open-source large language model (LLM) for entity matching. This system facilitates not only the mapping between existing software and AAS models but also between AAS models and standardized vocabulary dictionaries, thereby enhancing the model's semantic interoperability. A case study within the injection molding domain illustrates the practical application of DDMS for the automated creation of AAS instances, seamlessly integrating the manufacturer's existing data. Furthermore, we extensively investigate the potential of fine-tuning decode-only LLMs as generative classifiers and encoding-based classifiers for the entity matching task. To this end, we establish two AAS-specific datasets by collecting and compiling AAS-related resources. In addition, supplementary experiments are performed on general entity-matching benchmark datasets to ensure that our empirical conclusions and insights are generally applicable. The experiment results indicate that the fine-tuned generative LLM classifier achieves slightly better results, while the encoding-based classifier enables much faster inference. Furthermore, the fine-tuned LLM surpasses all state-of-the-art approaches for entity matching, including GPT-4 enhanced with in-context learning and chain of thoughts. This evidence highlights the effectiveness of the proposed DDMS in bridging the interoperability gap within DT applications, offering a scalable solution for the manufacturing industry.}
}
@article{REMADI2024102313,
title = {To prompt or not to prompt: Navigating the use of Large Language Models for integrating and modeling heterogeneous data},
journal = {Data & Knowledge Engineering},
volume = {152},
pages = {102313},
year = {2024},
issn = {0169-023X},
doi = {https://doi.org/10.1016/j.datak.2024.102313},
url = {https://www.sciencedirect.com/science/article/pii/S0169023X24000375},
author = {Adel Remadi and Karim {El Hage} and Yasmina Hobeika and Francesca Bugiotti},
keywords = {Data engineering, Large language models, Conceptual schema modeling, Entity resolution, Data integration, Property graph models},
abstract = {Manually integrating data of diverse formats and languages is vital to many artificial intelligence applications. However, the task itself remains challenging and time-consuming. This paper highlights the potential of Large Language Models (LLMs) to streamline data extraction and resolution processes. Our approach aims to address the ongoing challenge of integrating heterogeneous data sources, encouraging advancements in the field of data engineering. Applied on the specific use case of learning disorders in higher education, our research demonstrates LLMs’ capability to effectively extract data from unstructured sources. It is then further highlighted that LLMs can enhance data integration by providing the ability to resolve entities originating from multiple data sources. Crucially, the paper underscores the necessity of preliminary data modeling decisions to ensure the success of such technological applications. By merging human expertise with LLM-driven automation, this study advocates for the further exploration of semi-autonomous data engineering pipelines.}
}
@article{AMOORE2024103134,
title = {A world model: On the political logics of generative AI},
journal = {Political Geography},
volume = {113},
pages = {103134},
year = {2024},
issn = {0962-6298},
doi = {https://doi.org/10.1016/j.polgeo.2024.103134},
url = {https://www.sciencedirect.com/science/article/pii/S0962629824000830},
author = {Louise Amoore and Alexander Campolo and Benjamin Jacobsen and Ludovico Rella},
abstract = {The computational logics of large language models (LLMs) or generative AI – from the early models of CLIP and BERT to the explosion of text and image generation via ChatGPT and DALL-E − are increasingly penetrating the social and political world. Not merely in the direct sense that generative AI models are being deployed to govern difficult problems, whether decisions on the battlefield or responses to pandemic, but also because generative AI is shaping and delimiting the political parameters of what can be known and actioned in the world. Contra the promise of a generalizable “world model” in computer science, the article addresses how and why generative AI gives rise to a model of the world, and with it a set of political logics and governing rationalities that have profound and enduring effects on how we live today. The article traces the genealogies of generative AI models, how they have come into being, and why some concepts and techniques that animate these models become durable forms of knowledge that actively shape the world, even long after a specific material commercial GPT model has moved on to a new iteration. Though generative AI retains significant traces of former scientific and computational regimes – in statistical practices, probabilistic knowledge, and so on – it is also dislocating epistemological arrangements and opening them to novel ways of perceiving, characterising, classifying, and knowing the world. Four defining aspects of the political logic of generative AI are elaborated: i) generativity as something more than the capacity to generate image or text outputs, so that a generative logic acts upon the world understood as estimates of “underlying distributions” in data; ii) latency as a political logic of compression in which (by contrast with claims to reduction or distortion) the thing that is hidden, unknown or latent becomes surfaced and amenable to being governed; iii) broken and parallelized sequences as the ordering device of the political logic of generative AI, where attention frameworks radically change the possibilities for governing non-linear problems; iv) pre-training and fine-tuning as a computational logic of generative AI that simultaneously shapes a “zero shot politics” oriented towards unencountered data and new tasks. Across each of the four aspects, the article maps the emerging contemporary political logic of generative AI.}
}
@article{YE202443,
title = {Generative AI for visualization: State of the art and future directions},
journal = {Visual Informatics},
volume = {8},
number = {2},
pages = {43-66},
year = {2024},
issn = {2468-502X},
doi = {https://doi.org/10.1016/j.visinf.2024.04.003},
url = {https://www.sciencedirect.com/science/article/pii/S2468502X24000160},
author = {Yilin Ye and Jianing Hao and Yihan Hou and Zhan Wang and Shishi Xiao and Yuyu Luo and Wei Zeng},
keywords = {Visualization, Generative AI},
abstract = {Generative AI (GenAI) has witnessed remarkable progress in recent years and demonstrated impressive performance in various generation tasks in different domains such as computer vision and computational design. Many researchers have attempted to integrate GenAI into visualization framework, leveraging the superior generative capacity for different operations. Concurrently, recent major breakthroughs in GenAI like diffusion models and large language models have also drastically increased the potential of GenAI4VIS. From a technical perspective, this paper looks back on previous visualization studies leveraging GenAI and discusses the challenges and opportunities for future research. Specifically, we cover the applications of different types of GenAI methods including sequence, tabular, spatial and graph generation techniques for different tasks of visualization which we summarize into four major stages: data enhancement, visual mapping generation, stylization and interaction. For each specific visualization sub-task, we illustrate the typical data and concrete GenAI algorithms, aiming to provide in-depth understanding of the state-of-the-art GenAI4VIS techniques and their limitations. Furthermore, based on the survey, we discuss three major aspects of challenges and research opportunities including evaluation, dataset, and the gap between end-to-end GenAI methods and visualizations. By summarizing different generation algorithms, their current applications and limitations, this paper endeavors to provide useful insights for future GenAI4VIS research.}
}
@article{XU2024,
title = {Data Set and Benchmark (MedGPTEval) to Evaluate Responses From Large Language Models in Medicine: Evaluation Development and Validation},
journal = {JMIR Medical Informatics},
volume = {12},
year = {2024},
issn = {2291-9694},
doi = {https://doi.org/10.2196/57674},
url = {https://www.sciencedirect.com/science/article/pii/S2291969424000760},
author = {Jie Xu and Lu Lu and Xinwei Peng and Jiali Pang and Jinru Ding and Lingrui Yang and Huan Song and Kang Li and Xin Sun and Shaoting Zhang},
keywords = {ChatGPT, LLM, assessment, data set, benchmark, medicine},
abstract = {Background
Large language models (LLMs) have achieved great progress in natural language processing tasks and demonstrated the potential for use in clinical applications. Despite their capabilities, LLMs in the medical domain are prone to generating hallucinations (not fully reliable responses). Hallucinations in LLMs’ responses create substantial risks, potentially threatening patients’ physical safety. Thus, to perceive and prevent this safety risk, it is essential to evaluate LLMs in the medical domain and build a systematic evaluation.
Objective
We developed a comprehensive evaluation system, MedGPTEval, composed of criteria, medical data sets in Chinese, and publicly available benchmarks.
Methods
First, a set of evaluation criteria was designed based on a comprehensive literature review. Second, existing candidate criteria were optimized by using a Delphi method with 5 experts in medicine and engineering. Third, 3 clinical experts designed medical data sets to interact with LLMs. Finally, benchmarking experiments were conducted on the data sets. The responses generated by chatbots based on LLMs were recorded for blind evaluations by 5 licensed medical experts. The evaluation criteria that were obtained covered medical professional capabilities, social comprehensive capabilities, contextual capabilities, and computational robustness, with 16 detailed indicators. The medical data sets include 27 medical dialogues and 7 case reports in Chinese. Three chatbots were evaluated: ChatGPT by OpenAI; ERNIE Bot by Baidu, Inc; and Doctor PuJiang (Dr PJ) by Shanghai Artificial Intelligence Laboratory.
Results
Dr PJ outperformed ChatGPT and ERNIE Bot in the multiple-turn medical dialogues and case report scenarios. Dr PJ also outperformed ChatGPT in the semantic consistency rate and complete error rate category, indicating better robustness. However, Dr PJ had slightly lower scores in medical professional capabilities compared with ChatGPT in the multiple-turn dialogue scenario.
Conclusions
MedGPTEval provides comprehensive criteria to evaluate chatbots by LLMs in the medical domain, open-source data sets, and benchmarks assessing 3 LLMs. Experimental results demonstrate that Dr PJ outperforms ChatGPT and ERNIE Bot in social and professional contexts. Therefore, such an assessment system can be easily adopted by researchers in this community to augment an open-source data set.}
}
@article{XIAO2023417,
title = {Knowledge graph-based manufacturing process planning: A state-of-the-art review},
journal = {Journal of Manufacturing Systems},
volume = {70},
pages = {417-435},
year = {2023},
issn = {0278-6125},
doi = {https://doi.org/10.1016/j.jmsy.2023.08.006},
url = {https://www.sciencedirect.com/science/article/pii/S0278612523001577},
author = {Youzi Xiao and Shuai Zheng and Jiancheng Shi and Xiaodong Du and Jun Hong},
keywords = {Knowledge graph, Process planning, Process knowledge graph, CAPP},
abstract = {Computer-aided process planning is the bridge between computer-aided design and computer-aided manufacturing. With the advent of the intelligent manufacturing era, process knowledge is important for process planning. Knowledge graph is a semantic representation method of knowledge that has attracted extensive attention from the industry and academia. Process planning using the process knowledge graph has become an important development direction for computer-aided process planning. From the analysis of the published reviews, there have been many computer-aided process planning reviews with different focuses. We focus on the techniques and applications of knowledge graph in manufacturing process planning. Therefore, this paper comprehensively reviews knowledge graphs in manufacturing process planning. We analyze the key technologies of process knowledge graph, including process knowledge representation, process knowledge extraction, process knowledge graph construction, process knowledge graph refinement, process knowledge graph validation, and process generation. We also explore the combination of process knowledge graphs and large language models. Finally, potential future research directions are proposed.}
}
@article{JALALI2024109801,
title = {Large language models in electronic laboratory notebooks: Transforming materials science research workflows},
journal = {Materials Today Communications},
volume = {40},
pages = {109801},
year = {2024},
issn = {2352-4928},
doi = {https://doi.org/10.1016/j.mtcomm.2024.109801},
url = {https://www.sciencedirect.com/science/article/pii/S2352492824017823},
author = {Mehrdad Jalali and Yi Luo and Lachlan Caulfield and Eric Sauter and Alexei Nefedov and Christof Wöll},
keywords = {Materials science research, Natural language processing (NLP), Electronic laboratory notebooks (ELNs), Large language models (LLMs), Knowledge extraction, Scientific data management},
abstract = {In recent years, there has been a surge in research efforts dedicated to harnessing the capabilities of Large Language Models (LLMs) in various domains, particularly in material science. This paper delves into the transformative role of LLMs within Electronic Laboratory Notebooks (ELNs) for scientific research. ELNs represent a pivotal technological advancement, providing a digital platform for researchers to record and manage their experiments, data, and findings. This study explores the potential of LLMs to revolutionize fundamental aspects of science, including experimental methodologies, data analysis, and knowledge extraction within the ELN framework. We present a demonstrative showcase of LLM applications in ELN environments and, furthermore, we conduct a series of empirical evaluations to critically assess the practical impact of LLMs in enhancing research processes within the dynamic field of materials science. Our findings illustrate how LLMs can significantly elevate the quality and efficiency of research outcomes in ELNs, thereby advancing knowledge and innovation in materials science research and beyond.}
}
@article{SONNENBURG2024153933,
title = {Artificial intelligence-based data extraction for next generation risk assessment: Is fine-tuning of a large language model worth the effort?},
journal = {Toxicology},
volume = {508},
pages = {153933},
year = {2024},
issn = {0300-483X},
doi = {https://doi.org/10.1016/j.tox.2024.153933},
url = {https://www.sciencedirect.com/science/article/pii/S0300483X24002142},
author = {Anna Sonnenburg and Benthe {van der Lugt} and Johannes Rehn and Paul Wittkowski and Karsten Bech and Florian Padberg and Dimitra Eleftheriadou and Todor Dobrikov and Hans Bouwmeester and Carla Mereu and Ferdinand Graf and Carsten Kneuer and Nynke I. Kramer and Tilmann Blümmel},
keywords = {Artificial intelligence, Risk Assessment, Systematic literature review, Automated data extraction, Large Language models, Fine-tuning},
abstract = {To underpin scientific evaluations of chemical risks, agencies such as the European Food Safety Authority (EFSA) heavily rely on the outcome of systematic reviews, which currently require extensive manual effort. One specific challenge constitutes the meaningful use of vast amounts of valuable data from new approach methodologies (NAMs) which are mostly reported in an unstructured way in the scientific literature. In the EFSA-initiated project ‘AI4NAMS’, the potential of large language models (LLMs) was explored. Models from the GPT family, where GPT refers to Generative Pre-trained Transformer, were used for searching, extracting, and integrating data from scientific publications for NAM-based risk assessment. A case study on bisphenol A (BPA), a substance of very high concern due to its adverse effects on human health, focused on the structured extraction of information on test systems measuring biologic activities of BPA. Fine-tuning of a GPT-3 model (Curie base model) for extraction tasks was tested and the performance of the fine-tuned model was compared to the performance of a ready-to-use model (text-davinci-002). To update findings from the AI4NAMS project and to check for technical progress, the fine-tuning exercise was repeated and a newer ready-to-use model (text-davinci-003) served as comparison. In both cases, the fine-tuned Curie model was found to be superior to the ready-to-use model. Performance improvement was also obvious between text-davinci-002 and the newer text-davinci-003. Our findings demonstrate how fine-tuning and the swift general technical development improve model performance and contribute to the growing number of investigations on the use of AI in scientific and regulatory tasks.}
}
@article{LOPEZ2025100845,
title = {Enhancing foundation models for scientific discovery via multimodal knowledge graph representations},
journal = {Journal of Web Semantics},
volume = {84},
pages = {100845},
year = {2025},
issn = {1570-8268},
doi = {https://doi.org/10.1016/j.websem.2024.100845},
url = {https://www.sciencedirect.com/science/article/pii/S1570826824000313},
author = {Vanessa Lopez and Lam Hoang and Marcos Martinez-Galindo and Raúl Fernández-Díaz and Marco Luca Sbodio and Rodrigo Ordonez-Hurtado and Mykhaylo Zayats and Natasha Mulligan and Joao Bettencourt-Silva},
keywords = {Multimodal graph learning, Multimodal knowledge graphs, Knowledge-enhanced drug discovery},
abstract = {Foundation Models (FMs) hold transformative potential to accelerate scientific discovery, yet reaching their full capacity in complex, highly multimodal domains such as genomics, drug discovery, and materials science requires a deeper consideration of the contextual nature of the scientific knowledge. We revisit the synergy between FMs and Multimodal Knowledge Graph (MKG) representation and learning, exploring their potential to enhance predictive and generative tasks in biomedical contexts like drug discovery. We seek to exploit MKGs to improve generative AI models’ ability to capture intricate domain-specific relations and facilitate multimodal fusion. This integration promises to accelerate discovery workflows by providing more meaningful multimodal knowledge-enhanced representations and contextual evidence. Despite this potential, challenges and opportunities remain, including fusing multiple sequential, structural and knowledge modalities and models leveraging the strengths of each; developing scalable architectures for multi-task multi-dataset learning; creating end-to-end workflows to enhance the trustworthiness of biomedical FMs using knowledge from heterogeneous datasets and scientific literature; the domain data bottleneck and the lack of a unified representation between natural language and chemical representations; and benchmarking, specifically the transfer learning to tasks with limited data (e.g., unseen molecules and proteins, rear diseases). Finally, fostering openness and collaboration is key to accelerate scientific breakthroughs.}
}
@article{CARTA20242235,
title = {A Zero-Shot Strategy for Knowledge Graph Engineering Using GPT-3.5},
journal = {Procedia Computer Science},
volume = {246},
pages = {2235-2243},
year = {2024},
note = {28th International Conference on Knowledge Based and Intelligent information and Engineering Systems (KES 2024)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.09.573},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924026231},
author = {Salvatore Carta and Alessandro Giuliani and Marco Manolo Manca and Leonardo Piano and Alessandro Sebastian Podda and Livio Pompianu and Sandro Gabriele Tiddia},
keywords = {Knowledge Engineering, Knowledge Graphs, Large Language Models},
abstract = {In the recent digitization era, capturing, representing, and understanding knowledge is essential in countless real-world scenarios. Knowledge graphs emerged as a powerful tool for representing information through an adequately interconnected and interpretable structure in such a context. Nevertheless, generating proper knowledge graphs usually requires significant manual effort and domain expertise, resulting in graphs often affected by human subjectivity, limited scalability, or inability to capture implicit knowledge or handle heterogeneity. This paper proposes an innovative zero-shot strategy tailored to uncover reliable knowledge from text leveraging the recent highly effective generative large language models, with a particular focus on the GPT-3.5 model. Our proposal aims to create a suitable knowledge graph or improve existing ones by discovering missing qualitative triples. To assess the effectiveness of our methodology, we performed experiments on domain-specific datasets, confirming its potential for scalable and versatile knowledge discovery.}
}
@article{JOSE2024124603,
title = {Advancing multimodal diagnostics: Integrating industrial textual data and domain knowledge with large language models},
journal = {Expert Systems with Applications},
volume = {255},
pages = {124603},
year = {2024},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2024.124603},
url = {https://www.sciencedirect.com/science/article/pii/S0957417424014702},
author = {Sagar Jose and Khanh T.P Nguyen and Kamal Medjaher and Ryad Zemouri and Mélanie Lévesque and Antoine Tahan},
keywords = {Fault detection and diagnostics, Large language model, Expert knowledge, Technical language processing, Multimodal data},
abstract = {The rapid advancement and application of large language models (LLMs) in various domains prompt an investigation into their potential in the field of prognostics and health management (PHM), particularly for enhancing data-driven model capabilities. This study explores the integration of domain knowledge accumulated in unstructured text data such as technical documents and maintenance logs into diagnostics models using LLMs. The study demonstrates the new possibilities to exploit data that are traditionally underutilized due to their complexity and the presence of domain-specific jargon. By leveraging LLMs for contextual understanding and information extraction from such texts, this study proposes a novel approach that combines textual data with existing condition monitoring systems to improve the accuracy of diagnostics models. A case study on hydrogenerators illustrates the feasibility and value of integrating LLMs into PHM systems. The findings suggest that the incorporation of LLMs can lead to more informed, accurate diagnostics, ultimately enhancing operational efficiency and safety within industrial environments.}
}
@article{RAMRAKHIYANI2025103892,
title = {Gauging, enriching and applying geography knowledge in Pre-trained Language Models},
journal = {Information Processing & Management},
volume = {62},
number = {1},
pages = {103892},
year = {2025},
issn = {0306-4573},
doi = {https://doi.org/10.1016/j.ipm.2024.103892},
url = {https://www.sciencedirect.com/science/article/pii/S0306457324002516},
author = {Nitin Ramrakhiyani and Vasudeva Varma and Girish Keshav Palshikar and Sachin Pawar},
keywords = {Pre-trained language models, Geography knowledge, Language model probing},
abstract = {To employ Pre-trained Language Models (PLMs) as knowledge containers in niche domains it is important to gauge the knowledge of these PLMs about facts in these domains. It is also an important pre-requisite to know how much enrichment effort is required to make them better. As part of this work, we aim to gauge and enrich small PLMs for knowledge of world geography. Firstly, we develop a moderately sized dataset of masked sentences covering 24 different fact types about world geography to estimate knowledge of PLMs on these facts. We hypothesize that for this niche domain, smaller PLMs may not be well equipped. Secondly, we enrich PLMs with this knowledge through fine-tuning and check if the knowledge in the dataset is infused sufficiently. We further hypothesize that linguistic variability in the manual templates used to embed the knowledge in masked sentences does not affect the knowledge infusion. Finally, we demonstrate the application of PLMs to tourism blog search and Wikidata KB augmentation. In both applications, we aim at showing the effectiveness of using PLMs to achieve competitive performance.}
}
@article{PLONKA2025126711,
title = {A comparative evaluation of the effectiveness of document splitters for large language models in legal contexts},
journal = {Expert Systems with Applications},
volume = {272},
pages = {126711},
year = {2025},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2025.126711},
url = {https://www.sciencedirect.com/science/article/pii/S0957417425003331},
author = {Mateusz Płonka and Krzysztof Kocot and Kacper Hołda and Krzysztof Daniec and Aleksander Nawrat},
keywords = {Large language models, Retrieval-augmented generation, Legal documents, Context splitters, Semantic splitting},
abstract = {The study explores the development and application of an advanced artificial intelligence-based system aimed at improving the efficiency and accuracy of legal document processing. Due to the specific nature and complexity of legal texts, traditional document management techniques often prove inadequate and error-prone, creating significant challenges for legal practitioners. The proposed method leverages natural language processing and machine learning algorithms to automate key processes such as analysis, search, and classification. By utilizing vector embedding techniques, the system enables precise information retrieval from large legal document collections, while advanced splitting methods generate concise and relevant chunks of extensive texts. The study employs a Retrieval-Augmented Generation approach, combining Large Language Models (LLMs) with external knowledge bases to enhance the accuracy and contextual relevance of generated responses, addressing common issues such as hallucinations and outdated information in traditional LLMs. The research provides an in-depth analysis of the application of various text-splitting algorithms in the context of legal document databases. The findings highlight the characteristics of appropriate algorithms and offer recommendations on the conditions under which specific mechanisms should be employed.}
}
@article{KASPRZIK2024160,
title = {The Automation of Subject Indexing at ZBW and the Role of Metadata in Times of Large Language Models},
journal = {Procedia Computer Science},
volume = {249},
pages = {160-166},
year = {2024},
note = {16th International Conference on Current Research Information Systems (CRIS 2024)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.11.059},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924032708},
author = {Anna Kasprzik},
keywords = {subject indexing, automation, machine learning, artificial intelligence, IT infrastructure, metadata, large language models},
abstract = {Subject indexing is one of the core activities of libraries. Due to the proliferation of digital documents it is no longer possible to annotate every single document intellectually, which is why we need to explore the potentials of automation. At ZBW the efforts to automate the subject indexing process started as early as 2000 with experiments involving external partners and commercial software. The conclusion from that first period was that supposedly shelf-ready solutions would not cover the requirements of the library. In 2014 the decision was made to start doing the necessary applied research in-house by establishing a corresponding PhD position. However, the prototypical machine learning solutions they developed were yet to be integrated into productive operations at the library. Therefore in 2020 an additional position for a software engineer was established and a 4-year pilot phase was initiated with the goal to build a software architecture that allows for real-time subject indexing with our trained models and the integration thereof into the other metadata workflows at ZBW. This paper gives an account of how we tackled the task of transferring results from applied research into a productive subject indexing service (the “AutoSE service”), including the milestones we have reached, the challenges we were facing on a strategic level, and the measures and resources (computing power, software, personnel) that were needed in order to be able to effect the transfer and get a first version going, which went live in 2021. The models used by AutoSE until now were models from classical machine learning. We therefore also touch on the question if and how the recent advent of large language models (LLMs) has changed our outlook on the task of automating subject indexing and on the role of metadata in information management and retrieval in general, and the ways in which it impacts our research and development roadmap going forward.}
}
@article{JEMAL2025125648,
title = {A new approach for competency frameworks mapping using large language models},
journal = {Expert Systems with Applications},
volume = {263},
pages = {125648},
year = {2025},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2024.125648},
url = {https://www.sciencedirect.com/science/article/pii/S0957417424025156},
author = {Imene Jemal and Naoussi Sijou Wilfried Armand and Belkacem Chikhaoui},
keywords = {Competency framework, Framework competency mapping, Large language models, Natural language processing, Project management, PMBOK},
abstract = {Competency frameworks are essential for organizations to align their workforce with strategic goals and for individuals to assess and develop their skills. However, the absence of a universal or unified competency framework presents a challenge, as each framework is subject to distinct guidelines and standards. Moreover, within a single framework, continuous updates to align with evolving standards can lead to equivalent competencies being expressed in different ways. Despite the fundamental similarity of the competencies, this divergence across frameworks can impede interoperability and complicate the aggregation of data from multiple frameworks. This paper addresses this issue by proposing an approach that leverages large language models (LLMs) for mapping competency frameworks to enhance interoperability among frameworks. We investigated various pre-trained LLMs to encode competency names from each framework. Subsequently, we employed cosine similarity to measure semantic similarity scores, which facilitated the identification of equivalent or closely related competencies across different frameworks. We evaluated our approach using three competency frameworks for project management, each aligned with different editions of the Project Management Body of Knowledge (PMBOK) standards. The experimental results demonstrate the effectiveness of the proposed approach in ameliorating frameworks interoperability.}
}
@article{CHARTIER2025102383,
title = {HiBenchLLM: Historical Inquiry Benchmarking for Large Language Models},
journal = {Data & Knowledge Engineering},
volume = {156},
pages = {102383},
year = {2025},
issn = {0169-023X},
doi = {https://doi.org/10.1016/j.datak.2024.102383},
url = {https://www.sciencedirect.com/science/article/pii/S0169023X24001071},
author = {Mathieu Chartier and Nabil Dakkoune and Guillaume Bourgeois and Stéphane Jean},
keywords = {Large Language Models, Historical Inquiry, Benchmarking},
abstract = {Large Language Models (LLMs) such as ChatGPT or Bard have significantly transformed information retrieval and captured the public’s attention with their ability to generate customized responses across various topics. In this paper, we analyze the capabilities of different LLMs to generate responses related to historical facts in French. Our objective is to evaluate their reliability, comprehensiveness, and relevance for direct usability or extraction. To accomplish this, we propose a benchmark consisting of numerous historical questions covering various types, themes, and difficulty levels. Our evaluation of responses provided by 14 selected LLMs reveals several limitations in both content and structure. In addition to an overall insufficient precision rate, we observe uneven treatment of the French language, along with issues related to verbosity and inconsistency in the responses generated by LLMs.}
}
@article{ZOU2025129589,
title = {A novel large language model enhanced joint learning framework for fine-grained sentiment analysis on drug reviews},
journal = {Neurocomputing},
volume = {626},
pages = {129589},
year = {2025},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2025.129589},
url = {https://www.sciencedirect.com/science/article/pii/S0925231225002619},
author = {Haochen Zou and Yongli Wang},
keywords = {Fine-grained sentiment analysis, Aspect-based sentiment analysis, Large language model, Health informatics},
abstract = {Patient feedback on drug reviews extracted from social media platforms and online forums provides genuine sentiment information regarding post-medication usage. The insights are invaluable for prospective patients seeking appropriate medical guidance and stakeholders within the biomedical industry aiming to improve products. This paper presents a novel joint learning framework for fine-grained aspect-based sentiment analysis on drug reviews. By leveraging prior biomedical knowledge from the domain-specific pre-trained large language model, we address the challenge of fine-grained aspect-based sentiment analysis by collaboratively integrating both coarse and fine-grained contextual features within the text content, capturing precise biomedical aspect terms and the corresponding sentiment polarities. To the best of our knowledge, this work pioneers the initial introduction of a joint learning framework based on the fine-tuned biomedical large language model for fine-grained aspect-based sentiment analysis within drug reviews. By conducting extensive experiments on publicly available drug review datasets and comparing the constructed architecture with state-of-the-art techniques, the joint learning framework outperforms baseline competitors across evaluation metrics.}
}
@article{YU2024100076,
title = {Large-language models: The game-changers for materials science research},
journal = {Artificial Intelligence Chemistry},
volume = {2},
number = {2},
pages = {100076},
year = {2024},
issn = {2949-7477},
doi = {https://doi.org/10.1016/j.aichem.2024.100076},
url = {https://www.sciencedirect.com/science/article/pii/S2949747724000344},
author = {Songlin Yu and Nian Ran and Jianjun Liu},
keywords = {Large language models, Agent, LLM for materials, Artificial intelligence, Materials science research, Intelligent laboratory},
abstract = {Large Language Models (LLMs), such as GPT-4, are precipitating a new "industrial revolution" by significantly enhancing productivity across various domains. These models encode an extensive corpus of scientific knowledge from vast textual datasets, functioning as near-universal generalists with the ability to engage in natural language communication and exhibit advanced reasoning capabilities. Notably, agents derived from LLMs can comprehend user intent and autonomously design, plan, and utilize tools to execute intricate tasks. These attributes are particularly advantageous for materials science research, an interdisciplinary field characterized by numerous complex and time-intensive activities. The integration of LLMs into materials science research holds the potential to fundamentally transform the research paradigm in this field.}
}
@article{YIN2025107388,
title = {A novel approach to unlocking the synergy of large language models and chemical knowledge in biomedical signal applications},
journal = {Biomedical Signal Processing and Control},
volume = {103},
pages = {107388},
year = {2025},
issn = {1746-8094},
doi = {https://doi.org/10.1016/j.bspc.2024.107388},
url = {https://www.sciencedirect.com/science/article/pii/S1746809424014460},
author = {Zilong Yin and Haoyu Wang and Bin Chen and Hangling Sun and Anji Li and Chenyu Zhou},
keywords = {Biomedical signal processing, Supervised chemical knowledge, Large language models, Molecular property prediction},
abstract = {This work explores the potential of using the pre-trained large language model Llama2 to address challenges in biomedical signal processing and control (BSPC), particularly in predicting the electronic and functional properties of organic molecules, an area of growing importance in fields such as drug discovery and materials science. Current approaches in BSPC often rely on specialized graph neural network models, which can be limited in their ability to capture the complex relationships inherent in molecular structures. To address this, we demonstrate that a fine-tuned Llama2 model can accurately predict the highest occupied molecular orbital (HOMO) and lowest unoccupied molecular orbital (LUMO) energies of organic semiconductor molecules, with performance comparable to state-of-the-art specialized models. To further enhance the model’s robustness and generalization, we propose several key innovations, including optimized simplified molecular input line entry system (SMILES) tokenization, incorporation of chemical knowledge as auxiliary supervised tasks, and a low-rank adaptation (LORA) based fine-tuning strategy. These techniques enable the language model to simultaneously learn SMILES prediction and acquire relevant chemical knowledge, while also improving its handling of incomplete structural information and ability to generalize to ”unseen” molecular classes. The work also discusses the limitations of using large language models for molecular property prediction, such as the lack of interpretability and the need for improved handling of non-standard SMILES representations, highlighting the potential of this approach in BSPC while identifying areas for further improvement.}
}
@article{GU2025112694,
title = {CECA: An intelligent large-language-model-enabled method for accounting embodied carbon in buildings},
journal = {Building and Environment},
volume = {272},
pages = {112694},
year = {2025},
issn = {0360-1323},
doi = {https://doi.org/10.1016/j.buildenv.2025.112694},
url = {https://www.sciencedirect.com/science/article/pii/S0360132325001763},
author = {Xierong Gu and Cheng Chen and Yuan Fang and Ron Mahabir and Lei Fan},
keywords = {Embodied carbon, Large language model, Machine learning, Artificial intelligence, Life cycle assessment, Building},
abstract = {The construction sector's contribution to global carbon emissions is significant, with embodied carbon accounting for around 40 % of the sector's total emissions and even more than 50 % in the case of net-zero energy buildings. Traditional life cycle assessment methods for embodied carbon accounting are time-consuming and labor-intensive, hindering rapid evaluation of carbon footprint in buildings. This study presents a novel construction embodied carbon assessment (CECA) method. It uses large language models for intelligent semantic parsing and automatically matches material and equipment information with corresponding carbon emission factors. Based on our experiments, CECA outperforms traditional machine learning algorithms, achieving a matching accuracy of 0.8412. Validation across 18 real-world building cases demonstrates that the CECA method with Claude-3.5 achieves comparable carbon accounting accuracy to traditional life cycle assessment methods, with an average mean absolute percentage error of 12.5 %. Additionally, CECA significantly enhances computational efficiency, achieving a 216-fold improvement—approximately 60 ss for CECA compared to 3.6 h for LCA in our experiment where adopted BIM models are already available. Furthermore, the CECA method can identify carbon emission contributions of various materials and components, facilitating carbon optimization during the building design process. By advancing the application of large language models in evaluating embodied carbon in buildings, the CECA method offers a promising solution for rapid, accurate, and automated embodied carbon accounting, addressing the growing demand for efficient carbon evaluation and management in construction projects.}
}
@article{DING2025112663,
title = {Large language models for cyber resilience: A comprehensive review, challenges, and future perspectives},
journal = {Applied Soft Computing},
volume = {170},
pages = {112663},
year = {2025},
issn = {1568-4946},
doi = {https://doi.org/10.1016/j.asoc.2024.112663},
url = {https://www.sciencedirect.com/science/article/pii/S1568494624014376},
author = {Weiping Ding and Mohamed Abdel-Basset and Ahmed M. Ali and Nour Moustafa},
keywords = {Large Language Model, Cyber Resilience, Cyber Security, Data Privacy and Protection, Network and Endpoint Security},
abstract = {Interconnect cyber system is used by various users and organizations worldwide to perform different activities. These activities are combined with digital information and systems around the organizations to obtain higher accuracy and performance. However, these combinations of activities have faced cyber threats and attacks by single or multiple attackers. So, protecting and saving users' and organizations' sensitive data is a big challenge. So, the cyber resilience concept refers to the ability to prepare, absorb, recover, and adapt against cyberattacks and threats. It is used to mitigate cyberattacks and risks by the ability of the system to recover from threats. Artificial intelligence models enhance cyber resilience using machine learning and deep learning models. One of the most common components of artificial intelligence is large language models (LLM). It is used to understand language from text data and extract features to predict future words or missing in text datasets. LLM can enhance cyber resilience by providing various benefits for users and organizations. We divide the cyber resilience strategies into five parts. We review the LLM in each part, including security posture, data privacy and protection, security awareness, network security, and security automation. The fundamentals of LLMs are introduced as pre-trained models, transformers, encoders, and decoders. Then, we review the challenges of LLM in cyber resilience and cyber defense methods to overcome these challenges. We applied the LLM into three case studies including two for email spam text classifications and one for cyber threat detection. We obtained higher accuracy including 96.67 %, 90.70 %, and 89.94 % from three case studies respectively. Then we compared our LLM with other traditional machine learning models. The results show the LLM has higher accuracy, precision, recall, and f1 score compared with other models. Finally, the future directions of LLM in cyber resilience are provided.}
}
@article{AGARONNIK2025243,
title = {Large Language Models to Identify Advance Care Planning in Patients With Advanced Cancer},
journal = {Journal of Pain and Symptom Management},
volume = {69},
number = {3},
pages = {243-250.e1},
year = {2025},
issn = {0885-3924},
doi = {https://doi.org/10.1016/j.jpainsymman.2024.11.016},
url = {https://www.sciencedirect.com/science/article/pii/S088539242401128X},
author = {Nicole D. Agaronnik and Joshua Davis and Christopher R. Manz and James A. Tulsky and Charlotta Lindvall},
keywords = {Large language models, Advance care planning, Goals of care, Artificial intelligence},
abstract = {Context
Efficiently tracking Advance Care Planning (ACP) documentation in electronic heath records (EHRs) is essential for quality improvement and research efforts. The use of large language models (LLMs) offers a novel approach to this task.
Objectives
To evaluate the ability of LLMs to identify ACP in EHRs for patients with advanced cancer and compare performance to gold-standard manual chart review and natural language processing (NLP).
Methods
EHRs from patients with advanced cancer followed at seven Dana Farber Cancer Center (DFCI) clinics in June 2024. We utilized GPT-4o-2024-05-13 within DFCI's HIPAA-secure digital infrastructure. We designed LLM prompts to identify ACP domains: goals of care, limitation of life-sustaining treatment, hospice, and palliative care. We developed a novel hallucination index to measure production of factually-incorrect evidence by the LLM. Performance was compared to gold-standard manual chart review and NLP.
Results
60 unique patients associated with 528 notes were used to construct the gold-standard data set. LLM prompts had sensitivity ranging from 0.85 to 1.0, specificity ranging from 0.80 to 0.91, and accuracy ranging from 0.81 to 0.91 across domains. The LLM had better sensitivity than NLP for identifying complex topics such as goals of care. Average hallucination index for notes identified by LLM was less than 0.5, indicating a low probability of hallucination. Despite lower precision compared to NLP, false positive documentation identified by LLMs was clinically-relevant and useful for guiding management.
Conclusion
LLMs can capture ACP domains from EHRs, with sensitivity exceeding NLP methods for complex domains such as goals of care. Future studies should explore approaches for scaling this methodology.}
}
@article{FLAHARTY20241819,
title = {Evaluating large language models on medical, lay-language, and self-reported descriptions of genetic conditions},
journal = {The American Journal of Human Genetics},
volume = {111},
number = {9},
pages = {1819-1833},
year = {2024},
issn = {0002-9297},
doi = {https://doi.org/10.1016/j.ajhg.2024.07.011},
url = {https://www.sciencedirect.com/science/article/pii/S0002929724002556},
author = {Kendall A. Flaharty and Ping Hu and Suzanna Ledgister Hanchard and Molly E. Ripper and Dat Duong and Rebekah L. Waikel and Benjamin D. Solomon},
keywords = {large language model, deep learning, in-context prompting, artificial intelligence, machine learning, medical genetics, medical genomics},
abstract = {Summary
Large language models (LLMs) are generating interest in medical settings. For example, LLMs can respond coherently to medical queries by providing plausible differential diagnoses based on clinical notes. However, there are many questions to explore, such as evaluating differences between open- and closed-source LLMs as well as LLM performance on queries from both medical and non-medical users. In this study, we assessed multiple LLMs, including Llama-2-chat, Vicuna, Medllama2, Bard/Gemini, Claude, ChatGPT3.5, and ChatGPT-4, as well as non-LLM approaches (Google search and Phenomizer) regarding their ability to identify genetic conditions from textbook-like clinician questions and their corresponding layperson translations related to 63 genetic conditions. For open-source LLMs, larger models were more accurate than smaller LLMs: 7b, 13b, and larger than 33b parameter models obtained accuracy ranges from 21%–49%, 41%–51%, and 54%–68%, respectively. Closed-source LLMs outperformed open-source LLMs, with ChatGPT-4 performing best (89%–90%). Three of 11 LLMs and Google search had significant performance gaps between clinician and layperson prompts. We also evaluated how in-context prompting and keyword removal affected open-source LLM performance. Models were provided with 2 types of in-context prompts: list-type prompts, which improved LLM performance, and definition-type prompts, which did not. We further analyzed removal of rare terms from descriptions, which decreased accuracy for 5 of 7 evaluated LLMs. Finally, we observed much lower performance with real individuals’ descriptions; LLMs answered these questions with a maximum 21% accuracy.}
}
@article{LI2025102995,
title = {Vision-Language Models in medical image analysis: From simple fusion to general large models},
journal = {Information Fusion},
volume = {118},
pages = {102995},
year = {2025},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2025.102995},
url = {https://www.sciencedirect.com/science/article/pii/S1566253525000685},
author = {Xiang Li and Like Li and Yuchen Jiang and Hao Wang and Xinyu Qiao and Ting Feng and Hao Luo and Yong Zhao},
keywords = {Vision-language model, Modality fusion, Medical image analysis, Large model},
abstract = {Vision-Language Model (VLM) is a kind of multi-modality deep learning model that aims to fuse visual information with language information to enhance the understanding and analysis of visual content. VLM was originally used to integrate multi-modality information and improve task accuracy. Then, VLM was further developed in combination with zero-shot and few-shot learning to solve the problem of insufficient medical labels. At present, it is the technical basis of the popular medical general large model. Its role is no longer limited to simple information fusion. This paper makes a comprehensive review for the development and application of VLM-based medical image analysis technology. Specifically, this paper first introduces the basic principle and explains the pre-training and fine-tuning framework. Then, the research progress of medical image classification, segmentation, report generation, question answering, image generation, large model and other application scenarios is introduced. This paper also summarizes seven main characteristics of medical image VLM, and analyzes the specific embodiment of these characteristics in each task. Finally, the challenges, potential solutions and future directions in this field are discussed. VLM is still in a rapid development in the field of medical image analysis, and a continuously updated repository of papers and code has been built, it is available at https://github.com/XiangQA-Q/VLM-in-MIA.}
}
@article{DAGA2025100846,
title = {Process Knowledge Graphs (PKG): Towards unpacking and repacking AI applications},
journal = {Journal of Web Semantics},
volume = {84},
pages = {100846},
year = {2025},
issn = {1570-8268},
doi = {https://doi.org/10.1016/j.websem.2024.100846},
url = {https://www.sciencedirect.com/science/article/pii/S1570826824000325},
author = {Enrico Daga},
keywords = {Knowledge graphs, Prompt engineering, Data science pipelines, Data pipelines documentation, Data pipelines design},
abstract = {In the past years, a new generation of systems has emerged, which apply recent advances in generative Artificial Intelligence (AI) in combination with traditional technologies. Specifically, generative AI is being delegated tasks in natural language or vision understanding within complex hybrid architectures that also include databases, procedural code, and interfaces. Process Knowledge Graphs (PKG) have a long-standing tradition within symbolic AI research. On the one hand, PKGs can play an important role in describing complex, hybrid applications, thus opening the way for addressing fundamental challenges such as explaining and documenting such systems (unpacking). On the other hand, by organising complex processes in simpler building blocks, PKGs can potentially increase accuracy and control over such systems (repacking). In this position paper, we discuss opportunities and challenges of PGRs and their potential role towards a more robust and principled design of AI applications.}
}
@article{DAI2024107530,
title = {TCMChat: A generative large language model for traditional Chinese medicine},
journal = {Pharmacological Research},
volume = {210},
pages = {107530},
year = {2024},
issn = {1043-6618},
doi = {https://doi.org/10.1016/j.phrs.2024.107530},
url = {https://www.sciencedirect.com/science/article/pii/S1043661824004754},
author = {Yizheng Dai and Xin Shao and Jinlu Zhang and Yulong Chen and Qian Chen and Jie Liao and Fei Chi and Junhua Zhang and Xiaohui Fan},
keywords = {Traditional Chinese medicine, Large language model, Dialogue system, Pre-training, Supervised fine-tuning},
abstract = {The utilization of ground-breaking large language models (LLMs) accompanied with dialogue system has been progressively prevalent in the medical domain. Nevertheless, the expertise of LLMs in Traditional Chinese Medicine (TCM) remains restricted despite several TCM LLMs proposed recently. Herein, we introduced TCMChat (https://xomics.com.cn/tcmchat), a generative LLM with pre-training (PT) and supervised fine-tuning (SFT) on large-scale curated TCM text knowledge and Chinese Question-Answering (QA) datasets. In detail, we first compiled a customized collection of six scenarios of Chinese medicine as the training set by text mining and manual verification, involving TCM knowledgebase, choice question, reading comprehension, entity extraction, medical case diagnosis, and herb or formula recommendation. Next, we subjected the model to PT and SFT, using the Baichuan2–7B-Chat as the foundation model. The benchmarking datasets and case studies further demonstrate the superior performance of TCMChat in comparison to existing models. Our code, data and model are publicly released on GitHub (https://github.com/ZJUFanLab/TCMChat) and HuggingFace (https://huggingface.co/ZJUFanLab), providing high-quality knowledgebase for the research of TCM modernization with a user-friendly dialogue web tool.}
}
@article{OZEN2025100679,
title = {Extracting chemical food safety hazards from the scientific literature automatically using large language models},
journal = {Applied Food Research},
volume = {5},
number = {1},
pages = {100679},
year = {2025},
issn = {2772-5022},
doi = {https://doi.org/10.1016/j.afres.2024.100679},
url = {https://www.sciencedirect.com/science/article/pii/S2772502224002890},
author = {Neris Özen and Wenjuan Mu and Esther D. {van Asselt} and Leonieke M. {van den Bulk}},
keywords = {Chemical contamination, Food safety, Information extraction, Prompt engineering, Natural language processing, Artificial intelligence},
abstract = {The number of scientific articles published in the domain of food safety has consistently been increasing over the last few decades. It has therefore become unfeasible for food safety experts to read all relevant literature related to food safety and the occurrence of hazards in the food chain. However, it is important that food safety experts are aware of the newest findings and can access this information in an easy and concise way. In this study, an approach is presented to automate the extraction of chemical hazards from the scientific literature through large language models. The large language model was used out-of-the-box and applied on scientific abstracts; no extra training of the models or a large computing cluster was required. Three different styles of prompting the model were tested to assess which was the most optimal for the task at hand. The prompts were optimized with two validation foods (leafy greens and shellfish) and the final performance of the best prompt was evaluated using three test foods (dairy, maize and salmon). The specific wording of the prompt was found to have a considerable effect on the results. A prompt breaking the task down into smaller steps performed best overall. This prompt reached an average accuracy of 93 % and contained many chemical contaminants already included in food monitoring programs, validating the successful retrieval of relevant hazards for the food safety domain. The results showcase how valuable large language models can be for the task of automatic information extraction from the scientific literature.}
}
@article{PANAGOULIAS20241181,
title = {Knowledge Space reduction via Sequential Language Model Integration},
journal = {Procedia Computer Science},
volume = {246},
pages = {1181-1190},
year = {2024},
note = {28th International Conference on Knowledge Based and Intelligent information and Engineering Systems (KES 2024)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.09.544},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924025894},
author = {Dimitrios P. Panagoulias and Maria Virvou and George A. Tsihrintzis},
keywords = {AI-empowered software engineering, Large Language Models, GPT, BERT},
abstract = {In Large Language Models (LLMs), such as GPT, BERT, Mistral or others, “reducing the domain space” for text generation involves limiting the range of content that can be utilized for generating responses. This approach aims at enhancing the relevance and precision of the text produced. While various strategies exist to achieve this, this work explores Sequential Language Model Integration (SLMI), which mirrors the organization and distribution of knowledge across different fields of expertise. More specifically, SLMI is the technique of linking multiple LLMs (LLM-Chains) in a systematic manner. In this paper, we refer to a process of choosing, linking and connecting LLMs with other services (often to complete a generative task, invoke external functions and machine learning services, or tackle problems) as “Large Language Models as a Service”. We outline the development and evaluation process of an SLMI methodology to refine response accuracy. Focusing on the medical field, we also establish a framework for knowledge reduction based on “knowledge paths”, analogous to the distinct specializations within medicine. We apply this framework to a dermatology case study and utilize our evaluation pipeline to assess the results. Reducing the knowledge domain from medicine in general down to dermatology, we tested our methodology and found gains regarding accuracy and diagnostic improvement, as well as a reduction in costs regarding total tokens generated.}
}
@article{RUAN2025105746,
title = {CPRS: a clinical protocol recommendation system based on LLMs},
journal = {International Journal of Medical Informatics},
volume = {195},
pages = {105746},
year = {2025},
issn = {1386-5056},
doi = {https://doi.org/10.1016/j.ijmedinf.2024.105746},
url = {https://www.sciencedirect.com/science/article/pii/S138650562400409X},
author = {Jingkai Ruan and Qianmin Su and Zihang Chen and Jihan Huang and Ying Li},
keywords = {Recommendation system, LLMs, Knowledge graph, Clinical trial},
abstract = {Background: As fundamental documents in clinical trials, clinical trial protocols are intended to ensure that trials are conducted according to the objectives set by researchers. The advent of large models with superior semantic performance compared to traditional models provides fresh perspectives for research recommendations in clinical trial protocols. Method: A clinical trial protocol recommendation system based on Large Language Models (LLMs) is proposed in this paper, combining GPT-4 and knowledge graph to assist in clinical trial protocol recommendations. Using knowledge graphs as an auxiliary tool, a finite set of clinical trial projects with similar features is identified. Subsequently, through the semantic capabilities of GPT-4, targeted recommendations are made to patients. Results: Experiments were conducted to compare GPT-4 and multiple models from the SBERT family that handle semantic similarity. The results indicate that GPT-4 is capable of better sorting clinical trial protocols based on similarity criteria and offering targeted recommendations to patients. Consequently, this capability meets the matching requirements between projects and patients and enhances the automation of clinical trial protocol recommendations. Additionally, in the future, personal factors of patients will be fully considered during the recommendation process to provide more accurate and personalized protocol recommendations. Conclusion: By integrating knowledge graphs and LLMs, a better understanding and processing of clinical trial protocol information can be achieved, enabling the recommendation of appropriate protocols for patients and enhancing both matching efficiency and accuracy. Furthermore, the application of this system contributes to the automation of clinical trial protocol recommendations, playing a crucial role in medical research institutions such as clinical trial research institutes and public health management departments. Additionally, it significantly aids in advancing the development of clinical trials and the medical field at large.}
}
@article{RAMOS20252514,
title = {A review of large language models and autonomous agents in chemistry},
journal = {Chemical Science},
volume = {16},
number = {6},
pages = {2514-2572},
year = {2025},
issn = {2041-6520},
doi = {https://doi.org/10.1039/d4sc03921a},
url = {https://www.sciencedirect.com/science/article/pii/S2041652024020650},
author = {Mayk Caldas Ramos and Christopher J. Collison and Andrew D. White},
abstract = {Large language models (LLMs) have emerged as powerful tools in chemistry, significantly impacting molecule design, property prediction, and synthesis optimization. This review highlights LLM capabilities in these domains and their potential to accelerate scientific discovery through automation. We also review LLM-based autonomous agents: LLMs with a broader set of tools to interact with their surrounding environment. These agents perform diverse tasks such as paper scraping, interfacing with automated laboratories, and synthesis planning. As agents are an emerging topic, we extend the scope of our review of agents beyond chemistry and discuss across any scientific domains. This review covers the recent history, current capabilities, and design of LLMs and autonomous agents, addressing specific challenges, opportunities, and future directions in chemistry. Key challenges include data quality and integration, model interpretability, and the need for standard benchmarks, while future directions point towards more sophisticated multi-modal agents and enhanced collaboration between agents and experimental methods. Due to the quick pace of this field, a repository has been built to keep track of the latest studies: https://github.com/ur-whitelab/LLMs-in-science.}
}
@article{KALYAN2024100048,
title = {A survey of GPT-3 family large language models including ChatGPT and GPT-4},
journal = {Natural Language Processing Journal},
volume = {6},
pages = {100048},
year = {2024},
issn = {2949-7191},
doi = {https://doi.org/10.1016/j.nlp.2023.100048},
url = {https://www.sciencedirect.com/science/article/pii/S2949719123000456},
author = {Katikapalli Subramanyam Kalyan},
keywords = {Large language models, LLMs, GPT-3, ChatGPT, GPT-4, Transformers, LLM survey},
abstract = {Large language models (LLMs) are a special class of pretrained language models (PLMs) obtained by scaling model size, pretraining corpus and computation. LLMs, because of their large size and pretraining on large volumes of text data, exhibit special abilities which allow them to achieve remarkable performances without any task-specific training in many of the natural language processing tasks. The era of LLMs started with OpenAI’s GPT-3 model, and the popularity of LLMs has increased exponentially after the introduction of models like ChatGPT and GPT4. We refer to GPT-3 and its successor OpenAI models, including ChatGPT and GPT4, as GPT-3 family large language models (GLLMs). With the ever-rising popularity of GLLMs, especially in the research community, there is a strong need for a comprehensive survey which summarizes the recent research progress in multiple dimensions and can guide the research community with insightful future research directions. We start the survey paper with foundation concepts like transformers, transfer learning, self-supervised learning, pretrained language models and large language models. We then present a brief overview of GLLMs and discuss the performances of GLLMs in various downstream tasks, specific domains and multiple languages. We also discuss the data labelling and data augmentation abilities of GLLMs, the robustness of GLLMs, the effectiveness of GLLMs as evaluators, and finally, conclude with multiple insightful future research directions. To summarize, this comprehensive survey paper will serve as a good resource for both academic and industry people to stay updated with the latest research related to GLLMs.}
}
@article{MERONOPENUELA2025100847,
title = {KG.GOV: Knowledge graphs as the backbone of data governance in AI},
journal = {Journal of Web Semantics},
volume = {85},
pages = {100847},
year = {2025},
issn = {1570-8268},
doi = {https://doi.org/10.1016/j.websem.2024.100847},
url = {https://www.sciencedirect.com/science/article/pii/S1570826824000337},
author = {Albert Meroño-Peñuela and Elena Simperl and Anelia Kurteva and Ioannis Reklos},
keywords = {Knowledge graphs, AI, Governance},
abstract = {As (generative) Artificial Intelligence continues to evolve, so do the challenges associated with governing the data that powers it. Ensuring data quality, privacy, security, and ethical use become more and more challenging due to the increasing volume and variety of the data, the complexity of AI models, and the rapid pace of technological advancement. Knowledge graphs have the potential to play a significant role in enabling data governance in AI, as we move beyond their traditional use as data organisational systems. To address this, we present KG.gov, a framework that positions KGs at a higher abstraction level within AI workflows, and enables them as a backbone of AI data governance. We illustrate the three dimensions of KG.gov: modelling data, alternative representations, and describing behaviour; and describe the insights and challenges of three use cases implementing them: Croissant, a vocabulary to model and document ML datasets; WikiPrompts, a collaborative KG of prompts and prompt workflows to study their behaviour at scale; and Multimodal transformations, an approach for multimodal KGs harmonisation and completion aiming at broadening access to knowledge.}
}
@article{GU2024102822,
title = {Automatic quantitative stroke severity assessment based on Chinese clinical named entity recognition with domain-adaptive pre-trained large language model},
journal = {Artificial Intelligence in Medicine},
volume = {150},
pages = {102822},
year = {2024},
issn = {0933-3657},
doi = {https://doi.org/10.1016/j.artmed.2024.102822},
url = {https://www.sciencedirect.com/science/article/pii/S0933365724000642},
author = {Zhanzhong Gu and Xiangjian He and Ping Yu and Wenjing Jia and Xiguang Yang and Gang Peng and Penghui Hu and Shiyan Chen and Hongjie Chen and Yiguang Lin},
keywords = {Automatic stroke severity assessment, Chinese electronic health records, Clinical named entity recognition, Domain-adaptive pre-training, Large language model},
abstract = {Background:
Stroke is a prevalent disease with a significant global impact. Effective assessment of stroke severity is vital for an accurate diagnosis, appropriate treatment, and optimal clinical outcomes. The National Institutes of Health Stroke Scale (NIHSS) is a widely used scale for quantitatively assessing stroke severity. However, the current manual scoring of NIHSS is labor-intensive, time-consuming, and sometimes unreliable. Applying artificial intelligence (AI) techniques to automate the quantitative assessment of stroke on vast amounts of electronic health records (EHRs) has attracted much interest.
Objective:
This study aims to develop an automatic, quantitative stroke severity assessment framework through automating the entire NIHSS scoring process on Chinese clinical EHRs.
Methods:
Our approach consists of two major parts: Chinese clinical named entity recognition (CNER) with a domain-adaptive pre-trained large language model (LLM) and automated NIHSS scoring. To build a high-performing CNER model, we first construct a stroke-specific, densely annotated dataset “Chinese Stroke Clinical Records” (CSCR) from EHRs provided by our partner hospital, based on a stroke ontology that defines semantically related entities for stroke assessment. We then pre-train a Chinese clinical LLM coined “CliRoberta” through domain-adaptive transfer learning and construct a deep learning-based CNER model that can accurately extract entities directly from Chinese EHRs. Finally, an automated, end-to-end NIHSS scoring pipeline is proposed by mapping the extracted entities to relevant NIHSS items and values, to quantitatively assess the stroke severity.
Results:
Results obtained on a benchmark dataset CCKS2019 and our newly created CSCR dataset demonstrate the superior performance of our domain-adaptive pre-trained LLM and the CNER model, compared with the existing benchmark LLMs and CNER models. The high F1 score of 0.990 ensures the reliability of our model in accurately extracting the entities for the subsequent automatic NIHSS scoring. Subsequently, our automated, end-to-end NIHSS scoring approach achieved excellent inter-rater agreement (0.823) and intraclass consistency (0.986) with the ground truth and significantly reduced the processing time from minutes to a few seconds.
Conclusion:
Our proposed automatic and quantitative framework for assessing stroke severity demonstrates exceptional performance and reliability through directly scoring the NIHSS from diagnostic notes in Chinese clinical EHRs. Moreover, this study also contributes a new clinical dataset, a pre-trained clinical LLM, and an effective deep learning-based CNER model. The deployment of these advanced algorithms can improve the accuracy and efficiency of clinical assessment, and help improve the quality, affordability and productivity of healthcare services.}
}
@article{YI2025128684,
title = {Fine-grained detoxification framework via instance-level prefixes for large language models},
journal = {Neurocomputing},
volume = {611},
pages = {128684},
year = {2025},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2024.128684},
url = {https://www.sciencedirect.com/science/article/pii/S0925231224014553},
author = {Xin Yi and Linlin Wang and Xiaoling Wang and Liang He},
keywords = {Large language model, Detoxification framework, Safety and security},
abstract = {Large Language Models (LLMs) have demonstrated remarkable performance across various natural language processing (NLP) tasks. However, their practical usability is often compromised by a propensity to generate toxic content, such as insults, threats, and profanity, particularly in response to adversarial prompts. Several fine-tuning and decoding approaches have been employed to address this challenge to mitigate toxicity. Nevertheless, these methods typically necessitate additional resources, such as high-quality training data or auxiliary models, thereby incurring extra costs. In this paper, we propose a novel detoxification framework, Fine-Grained Detoxification via Instance-Level Prefixes (FGDILP), which effectively mitigates the generation of toxic text without incurring additional training costs. Specifically, FGDILP leverages contextualized representations in attention space by contrasting a positive prefix-prepended prompt against multiple negative prefix-prepended prompts at the instance level. This methodology facilitates the construction of fine-grained subtoxicity vectors, which are subsequently fused to adjust the original generation pathway when responding to raw prompts. Our results demonstrate that FGDILP enables controlled text generation concerning detoxification at both the utterance and context levels. While our method slightly impacts generation fluency and diversity, it significantly outperforms prompt-based baselines regarding detoxification effectiveness. Our code is available at https://github.com/xinykou/FGDILP.}
}
@article{JAHAN2024108189,
title = {A comprehensive evaluation of large Language models on benchmark biomedical text processing tasks},
journal = {Computers in Biology and Medicine},
volume = {171},
pages = {108189},
year = {2024},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2024.108189},
url = {https://www.sciencedirect.com/science/article/pii/S0010482524002737},
author = {Israt Jahan and Md Tahmid Rahman Laskar and Chun Peng and Jimmy Xiangji Huang},
keywords = {Large language models, ChatGPT, PaLM, LLaMA, Claude, Transformer, Natural language processing, LLM evaluation},
abstract = {Recently, Large Language Models (LLMs) have demonstrated impressive capability to solve a wide range of tasks. However, despite their success across various tasks, no prior work has investigated their capability in the biomedical domain yet. To this end, this paper aims to evaluate the performance of LLMs on benchmark biomedical tasks. For this purpose, a comprehensive evaluation of 4 popular LLMs in 6 diverse biomedical tasks across 26 datasets has been conducted. To the best of our knowledge, this is the first work that conducts an extensive evaluation and comparison of various LLMs in the biomedical domain. Interestingly, we find based on our evaluation that in biomedical datasets that have smaller training sets, zero-shot LLMs even outperform the current state-of-the-art models when they were fine-tuned only on the training set of these datasets. This suggests that pre-training on large text corpora makes LLMs quite specialized even in the biomedical domain. We also find that not a single LLM can outperform other LLMs in all tasks, with the performance of different LLMs may vary depending on the task. While their performance is still quite poor in comparison to the biomedical models that were fine-tuned on large training sets, our findings demonstrate that LLMs have the potential to be a valuable tool for various biomedical tasks that lack large annotated data.}
}
@article{LI2025104789,
title = {Improving entity recognition using ensembles of deep learning and fine-tuned large language models: A case study on adverse event extraction from VAERS and social media},
journal = {Journal of Biomedical Informatics},
pages = {104789},
year = {2025},
issn = {1532-0464},
doi = {https://doi.org/10.1016/j.jbi.2025.104789},
url = {https://www.sciencedirect.com/science/article/pii/S1532046425000188},
author = {Yiming Li and Deepthi Viswaroopan and William He and Jianfu Li and Xu Zuo and Hua Xu and Cui Tao},
keywords = {Named-entity recognition, VAERS, Generative pre-trained transformer (GPT), Large language model (LLM), Social media, Deep learning},
abstract = {Objective
Adverse event (AE) extraction following COVID-19 vaccines from text data is crucial for monitoring and analyzing the safety profiles of immunizations, identifying potential risks and ensuring the safe use of these products. Traditional deep learning models are adept at learning intricate feature representations and dependencies in sequential data, but often require extensive labeled data. In contrast, large language models (LLMs) excel in understanding contextual information, but exhibit unstable performance on named entity recognition (NER) tasks, possibly due to their broad but unspecific training. This study aims to evaluate the effectiveness of LLMs and traditional deep learning models in AE extraction, and to assess the impact of ensembling these models on performance.
Methods
In this study, we utilized reports and posts from the Vaccine Adverse Event Reporting System (VAERS) (n = 230), Twitter (n = 3,383), and Reddit (n = 49) as our corpora. Our goal was to extract three types of entities: vaccine, shot, and adverse event (ae). We explored and fine-tuned (except GPT-4) multiple LLMs, including GPT-2, GPT-3.5, GPT-4, Llama-2 7b, and Llama-2 13b, as well as traditional deep learning models like Recurrent neural network (RNN) and Bidirectional Encoder Representations from Transformers for Biomedical Text Mining (BioBERT). To enhance performance, we created ensembles of the three models with the best performance. For evaluation, we used strict and relaxed F1 scores to evaluate the performance for each entity type, and micro-average F1 was used to assess the overall performance.
Results
The ensemble demonstrated the best performance in identifying the entities “vaccine,” “shot,” and “ae,” achieving strict F1-scores of 0.878, 0.930, and 0.925, respectively, and a micro-average score of 0.903. These results underscore the significance of fine-tuning models for specific tasks and demonstrate the effectiveness of ensemble methods in enhancing performance.
Conclusion
In conclusion, this study demonstrates the effectiveness and robustness of ensembling fine-tuned traditional deep learning models and LLMs, for extracting AE-related information following COVID-19 vaccination. This study contributes to the advancement of natural language processing in the biomedical domain, providing valuable insights into improving AE extraction from text data for pharmacovigilance and public health surveillance}
}
@article{CONG2025101700,
title = {Demystifying large language models in second language development research},
journal = {Computer Speech & Language},
volume = {89},
pages = {101700},
year = {2025},
issn = {0885-2308},
doi = {https://doi.org/10.1016/j.csl.2024.101700},
url = {https://www.sciencedirect.com/science/article/pii/S0885230824000834},
author = {Yan Cong},
keywords = {Large language models, Natural language processing, Automatic essay scoring, L2 writing development, L2 interlanguage, Bilingualism},
abstract = {Evaluating students' textual response is a common and critical task in language research and education practice. However, manual assessment can be tedious and may lack consistency, posing challenges for both scientific discovery and frontline teaching. Leveraging state-of-the-art large language models (LLMs), we aim to define and operationalize LLM-Surprisal, a numeric representation of the interplay between lexical diversity and syntactic complexity, and to empirically and theoretically demonstrate its relevance for automatic writing assessment and Chinese L2 (second language) learners’ English writing development. We developed an LLM-based natural language processing pipeline that can automatically compute text Surprisal scores. By comparing Surprisal metrics with the widely used classic indices in L2 studies, we extended the usage of computational metrics in Chinese learners’ L2 English writing. Our analyses suggested that LLM-Surprisals can distinguish L2 from L1 (first language) writing, index L2 development stages, and predict scores provided by human professionals. This indicated that the Surprisal dimension may manifest itself as critical aspects in L2 development. The relative advantages and disadvantages of these approaches were discussed in depth. We concluded that LLMs are promising tools that can enhance L2 research. Our showcase paves the way for more nuanced approaches to computationally assessing and understanding L2 development. Our pipelines and findings will inspire language teachers, learners, and researchers to operationalize LLMs in an innovative and accessible manner.}
}
@article{KONSTANTINOU2024621,
title = {Leveraging Generative AI Prompt Programming for Human-Robot Collaborative Assembly},
journal = {Procedia CIRP},
volume = {128},
pages = {621-626},
year = {2024},
note = {34th CIRP Design Conference},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2024.03.040},
url = {https://www.sciencedirect.com/science/article/pii/S2212827124007510},
author = {Christos Konstantinou and Dimitris Antonarakos and Panagiotis Angelakis and Christos Gkournelos and George Michalos and Sotiris Makris},
keywords = {Generative AI, Human Robot collaboration, Design informatics},
abstract = {In manufacturing, traditional robotic programming methodologies have often been focused on independent operation, offering limited capabilities for seamless human-robot collaboration. This paper introduces a paradigm shift in collaborative production systems by leveraging generative artificial intelligence (AI), specifically large language models (LLMs). Contrary to traditional methods that rely on pre-defined assembly instructions, this paper introduces a novel framework employing primitive knowledge of the production process, including product design and required assembly steps. By integrating LLMs and a behavior tree-based system control, this approach enables programmers to rapidly deploy collaborative assembly procedures by expediting the programming of robotic operations. The system also incorporates Natural Language Processing (NLP) technologies, which facilitate real-time alterations in assembly steps, leading to reduced overall production time. The framework’s behavior tree-based control architecture allows for dynamic adaptability, offering optimized solutions across a range of assembly scenarios. The results of the framework’s deployment suggest that this innovative programming paradigm significantly enhances both the adaptability and efficiency of collaborative manufacturing settings.}
}
@article{YANG2024100085,
title = {Understanding natural language: Potential application of large language models to ophthalmology},
journal = {Asia-Pacific Journal of Ophthalmology},
volume = {13},
number = {4},
pages = {100085},
year = {2024},
issn = {2162-0989},
doi = {https://doi.org/10.1016/j.apjo.2024.100085},
url = {https://www.sciencedirect.com/science/article/pii/S2162098924000860},
author = {Zefeng Yang and Deming Wang and Fengqi Zhou and Diping Song and Yinhang Zhang and Jiaxuan Jiang and Kangjie Kong and Xiaoyi Liu and Yu Qiao and Robert T. Chang and Ying Han and Fei Li and Clement C. Tham and Xiulan Zhang},
keywords = {Large language model, Ophthalmology, Artificial intelligence, ChatGPT},
abstract = {Large language models (LLMs), a natural language processing technology based on deep learning, are currently in the spotlight. These models closely mimic natural language comprehension and generation. Their evolution has undergone several waves of innovation similar to convolutional neural networks. The transformer architecture advancement in generative artificial intelligence marks a monumental leap beyond early-stage pattern recognition via supervised learning. With the expansion of parameters and training data (terabytes), LLMs unveil remarkable human interactivity, encompassing capabilities such as memory retention and comprehension. These advances make LLMs particularly well-suited for roles in healthcare communication between medical practitioners and patients. In this comprehensive review, we discuss the trajectory of LLMs and their potential implications for clinicians and patients. For clinicians, LLMs can be used for automated medical documentation, and given better inputs and extensive validation, LLMs may be able to autonomously diagnose and treat in the future. For patient care, LLMs can be used for triage suggestions, summarization of medical documents, explanation of a patient’s condition, and customizing patient education materials tailored to their comprehension level. The limitations of LLMs and possible solutions for real-world use are also presented. Given the rapid advancements in this area, this review attempts to briefly cover many roles that LLMs may play in the ophthalmic space, with a focus on improving the quality of healthcare delivery.}
}
@article{LEI20241257,
title = {Materials science in the era of large language models: a perspective††Electronic supplementary information (ESI) available. See DOI: https://doi.org/10.1039/d4dd00074a},
journal = {Digital Discovery},
volume = {3},
number = {7},
pages = {1257-1272},
year = {2024},
issn = {2635-098X},
doi = {https://doi.org/10.1039/d4dd00074a},
url = {https://www.sciencedirect.com/science/article/pii/S2635098X24001190},
author = {Ge Lei and Ronan Docherty and Samuel J. Cooper},
abstract = {Large Language Models (LLMs) have garnered considerable interest due to their impressive natural language capabilities, which in conjunction with various emergent properties make them versatile tools in workflows ranging from complex code generation to heuristic finding for combinatorial problems. In this paper we offer a perspective on their applicability to materials science research, arguing their ability to handle ambiguous requirements across a range of tasks and disciplines means they could be a powerful tool to aid researchers. We qualitatively examine basic LLM theory, connecting it to relevant properties and techniques in the literature before providing two case studies that demonstrate their use in task automation and knowledge extraction at-scale. At their current stage of development, we argue LLMs should be viewed less as oracles of novel insight, and more as tireless workers that can accelerate and unify exploration across domains. It is our hope that this paper can familiarise materials science researchers with the concepts needed to leverage these tools in their own research.}
}
@article{DAI2025106956,
title = {Large Language Model Enhanced Logic Tensor Network for Stance Detection},
journal = {Neural Networks},
volume = {183},
pages = {106956},
year = {2025},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2024.106956},
url = {https://www.sciencedirect.com/science/article/pii/S0893608024008852},
author = {Genan Dai and Jiayu Liao and Sicheng Zhao and Xianghua Fu and Xiaojiang Peng and Hu Huang and Bowen Zhang},
keywords = {Logic tensor network, Stance detection, Chain-of-thought},
abstract = {Social media platforms, rich in user-generated content, offer a unique perspective on public opinion, making stance detection an essential task in opinion mining. However, traditional deep neural networks for stance detection often suffer from limitations, including the requirement for large amounts of labeled data, uninterpretability of prediction results, and difficulty in incorporating human intentions and domain knowledge. This paper introduces the First-Order Logic Aggregated Reasoning framework (FOLAR), an innovative approach that integrates first-order logic (FOL) with large language models (LLMs) to enhance the interpretability and efficacy of stance detection. FOLAR comprises three key components: a Knowledge Elicitation module that generates FOL rules using a chain-of-thought prompting method, a Logic Tensor Network (LTN) that encodes these rules for stance detection, and a Multi-Decision Fusion mechanism that aggregates LTNs’ outputs to minimize biases and improve robustness. Our experiments on standard benchmarks demonstrate the effectiveness of FOLAR, showing it as a promising solution for explainable and accurate stance detection. The source code will be made publicly available to foster further research.}
}
@article{LIU2025103920,
title = {EvoPath: Evolutionary meta-path discovery with large language models for complex heterogeneous information networks},
journal = {Information Processing & Management},
volume = {62},
number = {1},
pages = {103920},
year = {2025},
issn = {0306-4573},
doi = {https://doi.org/10.1016/j.ipm.2024.103920},
url = {https://www.sciencedirect.com/science/article/pii/S0306457324002796},
author = {Shixuan Liu and Haoxiang Cheng and Yunfei Wang and Yue He and Changjun Fan and Zhong Liu},
keywords = {Meta-path discovery, Large language models, Heterogeneous information networks},
abstract = {Heterogeneous Information Networks (HINs) encapsulate diverse entity and relation types, with meta-paths providing essential meta-level semantics for knowledge reasoning, although their utility is constrained by discovery challenges. While Large Language Models (LLMs) offer new prospects for meta-path discovery due to their extensive knowledge encoding and efficiency, their adaptation faces challenges such as corpora bias, lexical discrepancies, and hallucination. This paper pioneers the mitigation of these challenges by presenting EvoPath, an innovative framework that leverages LLMs to efficiently identify high-quality meta-paths. EvoPath is carefully designed, with each component aimed at addressing issues that could lead to potential knowledge conflicts. With a minimal subset of HIN facts, EvoPath iteratively generates and evolves meta-paths by dynamically replaying meta-paths in the buffer with prioritization based on their scores. Comprehensive experiments on three large, complex HINs with hundreds of relations demonstrate that our framework, EvoPath, enables LLMs to generate high-quality meta-paths through effective prompting, confirming its superior performance in HIN reasoning tasks. Further ablation studies validate the effectiveness of each module within the framework.}
}
@article{WONG2024104082,
title = {Construction contract risk identification based on knowledge-augmented language models},
journal = {Computers in Industry},
volume = {157-158},
pages = {104082},
year = {2024},
issn = {0166-3615},
doi = {https://doi.org/10.1016/j.compind.2024.104082},
url = {https://www.sciencedirect.com/science/article/pii/S0166361524000101},
author = {Saika Wong and Chunmo Zheng and Xing Su and Yinqiu Tang},
keywords = {Large language models, Construction contract risk, Knowledge augmentation, Knowledge database},
abstract = {Contract review is an essential step in construction projects to prevent potential losses. However, the current methods for reviewing construction contracts lack effectiveness and reliability, leading to time-consuming and error-prone processes. Although large language models (LLMs) have shown promise in revolutionizing natural language processing (NLP) tasks, they struggle with domain-specific knowledge and addressing specialized issues. This paper presents a novel approach that leverages LLMs with construction contract knowledge to emulate the process of contract review by human experts. Our tuning-free approach incorporates construction contract domain knowledge to enhance language models for identifying construction contract risks. The use of natural language when building the domain knowledge base facilitates practical implementation. We evaluated our method on real construction contracts and achieved solid performance. Additionally, we investigated how LLMs employ logical thinking during the task and provided insights and recommendations for future research.}
}
@article{BULLA2025100609,
title = {Large Language Models meet moral values: A comprehensive assessment of moral abilities},
journal = {Computers in Human Behavior Reports},
pages = {100609},
year = {2025},
issn = {2451-9588},
doi = {https://doi.org/10.1016/j.chbr.2025.100609},
url = {https://www.sciencedirect.com/science/article/pii/S2451958825000247},
author = {Luana Bulla and Stefano {De Giorgis} and Misael Mongiovì and Aldo Gangemi},
keywords = {Large Language Models, Value detection, Natural language inference, Natural Language Processing},
abstract = {Automatic moral classification in textual data is crucial for various fields including Natural Language Processing (NLP), social sciences, and ethical AI development. Despite advancements in supervised models, their performance often suffers when faced with real-world scenarios due to overfitting to specific data distributions. To address these limitations, we propose leveraging state-of-the-art Large Language Models (LLMs) trained on extensive common-sense data for unsupervised moral classification. We introduce an innovative evaluation framework that directly compares model outputs with human annotations, ensuring an assessment of model performance. Our methodology explores the effectiveness of different LLM sizes and prompt designs in moral value detection tasks, considering both multi-label and binary classification scenarios. We present experimental results using the Moral Foundation Reddit Corpus (MFRC) and discuss implications for future research in ethical AI development and human–computer interaction. Experimental results demonstrate that GPT-4 achieves superior performance, followed by GPT-3.5, Llama-70B, Mixtral-8x7B, Mistral-7B and Llama-7B. Additionally, the study reveals significant variations in model performance across different moral domains, particularly between everyday morality and political contexts. Our work provides meaningful insights into the use of zero-shot and few-shot models for moral value detection and discusses the potential and limitations of current technology in this task.}
}
@article{GOPFERT2024100383,
title = {Opportunities for large language models and discourse in engineering design},
journal = {Energy and AI},
volume = {17},
pages = {100383},
year = {2024},
issn = {2666-5468},
doi = {https://doi.org/10.1016/j.egyai.2024.100383},
url = {https://www.sciencedirect.com/science/article/pii/S2666546824000491},
author = {Jan Göpfert and Jann M. Weinand and Patrick Kuckertz and Detlef Stolten},
keywords = {Product development process, Conceptual design, Design methodology, Design generation, Natural language processing, Foundation models, Multi-modal models},
abstract = {In recent years, large language models have achieved breakthroughs on a wide range of benchmarks in natural language processing and continue to increase in performance. Recently, the advances of large language models have raised interest outside the natural language processing community and could have a large impact on daily life. In this paper, we pose the question: How will large language models and other foundation models shape the future product development process? We provide the reader with an overview of the subject by summarizing both recent advances in natural language processing and the use of information technology in the engineering design process. We argue that discourse should be regarded as the core of engineering design processes, and therefore should be represented in a digital artifact. On this basis, we describe how foundation models such as large language models could contribute to the design discourse by automating parts thereof that involve creativity and reasoning, and were previously reserved for humans. We describe how simulations, experiments, topology optimizations, and other process steps can be integrated into a machine-actionable, discourse-centric design process. As an example, we present a design discourse on the optimization of wind turbine blades. Finally, we outline the future research that will be necessary for the implementation of the conceptualized framework.}
}
@article{LAI2024181,
title = {Large language models in law: A survey},
journal = {AI Open},
volume = {5},
pages = {181-196},
year = {2024},
issn = {2666-6510},
doi = {https://doi.org/10.1016/j.aiopen.2024.09.002},
url = {https://www.sciencedirect.com/science/article/pii/S2666651024000172},
author = {Jinqi Lai and Wensheng Gan and Jiayang Wu and Zhenlian Qi and Philip S. Yu},
keywords = {Artificial intelligence, LLMs, Justice, Legal model},
abstract = {The advent of artificial intelligence (AI) has significantly impacted the traditional judicial industry. Moreover, recently, with the development of AI-generated content (AIGC), AI and law have found applications in various domains, including image recognition, automatic text generation, and interactive chat. With the rapid emergence and growing popularity of large models, it is evident that AI will drive transformation in the traditional judicial industry. However, the application of legal large language models (LLMs) is still in its nascent stage. Several challenges need to be addressed. In this paper, we aim to provide a comprehensive survey of legal LLMs. We not only conduct an extensive survey of LLMs but also expose their applications in the judicial system. We first provide an overview of AI technologies in the legal field and showcase the recent research in LLMs. Then, we discuss the practical implementations presented by legal LLMs, such as providing legal advice to users and assisting judges during trials. In addition, we explore the limitations of legal LLMs, including data, algorithms, and judicial practice. Finally, we summarize practical recommendations and propose future development directions to address these challenges.}
}
@article{FENG2024117540,
title = {Large language models for biomolecular analysis: From methods to applications},
journal = {TrAC Trends in Analytical Chemistry},
volume = {171},
pages = {117540},
year = {2024},
issn = {0165-9936},
doi = {https://doi.org/10.1016/j.trac.2024.117540},
url = {https://www.sciencedirect.com/science/article/pii/S0165993624000220},
author = {Ruijun Feng and Chi Zhang and Yang Zhang},
keywords = {Large language model, Biomolecular analysis, Fine-tuning, Prompt engineering, Parameter-efficient fine-tuning, In-context learning, Protein structure analysis, Protein sequence generation, Gene sequence analysis, Molecular representation learning},
abstract = {Large language models (LLMs) are proving to be very useful in many fields, especially chemistry and biology, because of their amazing capabilities. Biomolecular data is often represented sequentially, much like textual data used to train LLMs. However, developing LLMs from scratch requires a substantial amount of data and computational resources, which may not be feasible for most researchers. A more workable solution to this problem is to change the inputs or parameters so that the previously trained general LLMs can pick up the specific knowledge needed for biomolecular analysis. These adaption strategies lower the amount of data and hardware needed, providing a more affordable option. This review provides the introduction of two popular LLM adaptation techniques: fine-tuning and prompt engineering, along with their uses in the analysis of molecules, proteins, and genes. A thorough overview of current common datasets and pre-trained models is also provided. This review outlines the possible advantages and difficulties of LLMs for biomolecular analysis, opening the door for chemists and biologists to effectively utilize LLMs in their future studies.}
}
@article{MOCANU2023100036,
title = {Knowledge representation and acquisition in the era of large language models: Reflections on learning to reason via PAC-Semantics},
journal = {Natural Language Processing Journal},
volume = {5},
pages = {100036},
year = {2023},
issn = {2949-7191},
doi = {https://doi.org/10.1016/j.nlp.2023.100036},
url = {https://www.sciencedirect.com/science/article/pii/S294971912300033X},
author = {Ionela G. Mocanu and Vaishak Belle},
keywords = {Pac-semantics, Logical knowledge bases, Knowledge acquisition},
abstract = {Human beings are known for their remarkable ability to comprehend, analyse, and interpret common sense knowledge. This ability is critical for exhibiting intelligent behaviour, often defined as a mapping from beliefs to actions, which has led to attempts to formalize and capture explicit representations in the form of databases, knowledge bases, and ontologies in AI agents. But in the era of large language models (LLMs), this emphasis might seem unnecessary. After all, these models already capture the extent of human knowledge and can infer appropriate things from it (presumably) as per some innate logical rules. The question then is whether they can also be trained to perform mathematical computations. Although the consensus on the reliability of such models is still being studied, early results do seem to suggest they do not offer logically and mathematically consistent results. In this short summary article, we articulate the motivations for still caring about logical/symbolic artefacts and representations, and report on recent progress in learning to reason via the so-called probably approximately correct (PAC)-semantics.}
}
@article{WU2024429,
title = {ProcessCarbonAgent: A large language models-empowered autonomous agent for decision-making in manufacturing carbon emission management},
journal = {Journal of Manufacturing Systems},
volume = {76},
pages = {429-442},
year = {2024},
issn = {0278-6125},
doi = {https://doi.org/10.1016/j.jmsy.2024.08.008},
url = {https://www.sciencedirect.com/science/article/pii/S0278612524001729},
author = {Tao Wu and Jie Li and Jinsong Bao and Qiang Liu},
keywords = {Knowledge-intensive production, Large language models, Autonomous agents, Assisted decision-making, Process carbon agent, Carbon emission management},
abstract = {Knowledge-intensive production represents a primary trend in industrial manufacturing, which heavily relies on the production logs of large-scale, historically similar orders for enhancing production efficiency and process quality. These logs are essential for predicting resource allocation and identifying bottlenecks in throughput. As a result, root cause analysis of the production process state is crucial for supporting decision-making in these settings. However, current methodologies heavily depend on expert knowledge, making the analysis time-consuming and inefficient for large-scale, multivariable processes. Although the development of large language models and autonomous agents presents a potential solution, these models are limited in their direct interaction with event logs due to inadequate data representation, token constraints, and insufficient accuracy. Therefore, enabling the interactive capabilities of large language models to overcome these specific limitations in process event data and industrial domain illusions poses a significant challenge. To address these issues, this paper introduces the ProcessCarbonAgent framework, an autonomous agent empowered by large language models, designed to enhance decision-making within industrial processes. Initially, a process data agent combines predefined semantic text representation methods with process template prompting strategies to improve interaction capabilities. Subsequently, an intention agent utilizing self-information and large language models is developed to address context length limitations by identifying and eliminating redundancies. Finally, a two-stage confidence estimation method is implemented to refine the precision of decision-making assistance, thereby improving the accuracy of decisions supported by large language models. Experiments with textile industry carbon emission data reveal that the assisted decision-making scores employing a compression ratio of 0.5, closely align with scores from manually labeled evaluations, with a 98% overlap across scoring intervals. Moreover, in contrast to relying solely on the original evaluation method, the two-stage confidence estimation method has led to a 20% increase in accuracy performance. The ProcessCarbonAgent achieved scores of 16.64, 55.13, 26.32, and 34.17 on METEOR, BERTScore, NUBIA, and BLEURT, respectively. The results demonstrate that the ProcessCarbonAgent framework significantly enhances the decision-making process for high-carbon emission states in industrial production, providing technical support for the low-carbon transformation and intelligent upgrading of these processes.}
}
@article{RAY2024174,
title = {Large language models in laparoscopic surgery: A transformative opportunity},
journal = {Laparoscopic, Endoscopic and Robotic Surgery},
volume = {7},
number = {4},
pages = {174-180},
year = {2024},
issn = {2468-9009},
doi = {https://doi.org/10.1016/j.lers.2024.07.002},
url = {https://www.sciencedirect.com/science/article/pii/S2468900924000483},
author = {Partha Pratim Ray},
keywords = {Large language model, Artificial intelligence, Generative artificial intelligence, Laparoscopy, Surgery},
abstract = {This opinion paper explores the transformative potential of large language models (LLMs) in laparoscopic surgery and argues for their integration to enhance surgical education, decision support, reporting, and patient care. LLMs can revolutionize surgical education by providing personalized learning experiences and accelerating skill acquisition. Intelligent decision support systems powered by LLMs can assist surgeons in making complex decisions, optimizing surgical workflows, and improving patient outcomes. Moreover, LLMs can automate surgical reporting and generate personalized patient education materials, streamlining documentation and improving patient engagement. However, challenges such as data scarcity, surgical semantic capture, real-time inference, and integration with existing systems need to be addressed for successful LLM integration. The future of laparoscopic surgery lies in the seamless integration of LLMs, enabling autonomous robotic surgery, predictive surgical planning, intraoperative decision support, virtual surgical assistants, and continuous learning. By harnessing the power of LLMs, laparoscopic surgery can be transformed, empowering surgeons and ultimately benefiting patients.}
}
@article{HUANG2024109100,
title = {Knowledge graph based reasoning in medical image analysis: A scoping review},
journal = {Computers in Biology and Medicine},
volume = {182},
pages = {109100},
year = {2024},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2024.109100},
url = {https://www.sciencedirect.com/science/article/pii/S0010482524011855},
author = {Qinghua Huang and Guanghui Li},
keywords = {Medical diagnosis, Medical expert systems, Knowledge graph, Medical image analysis},
abstract = {Automated computer-aided diagnosis (CAD) is becoming more significant in the field of medicine due to advancements in computer hardware performance and the progress of artificial intelligence. The knowledge graph is a structure for visually representing knowledge facts. In the last decade, a large body of work based on knowledge graphs has effectively improved the organization and interpretability of large-scale complex knowledge. Introducing knowledge graph inference into CAD is a research direction with significant potential. In this review, we briefly review the basic principles and application methods of knowledge graphs firstly. Then, we systematically organize and analyze the research and application of knowledge graphs in medical imaging-assisted diagnosis. We also summarize the shortcomings of the current research, such as medical data barriers and deficiencies, low utilization of multimodal information, and weak interpretability. Finally, we propose future research directions with possibilities and potentials to address the shortcomings of current approaches.}
}
@article{SUN2025103135,
title = {Enhancing multimodal-input object goal navigation by leveraging large language models for inferring room–object relationship knowledge},
journal = {Advanced Engineering Informatics},
volume = {65},
pages = {103135},
year = {2025},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2025.103135},
url = {https://www.sciencedirect.com/science/article/pii/S147403462500028X},
author = {Leyuan Sun and Asako Kanezaki and Guillaume Caron and Yusuke Yoshiyasu},
keywords = {Object-goal navigation, Large language model, Multimodal fusion, Multitask learning, Room segmentation, Sim2real transfer},
abstract = {Object-goal navigation is a task in embodied AI where an agent is navigated to a specified object within unfamiliar indoor scenarios. This task is crucial for engineering activities such as training agents in 3D simulated environments and deploying these models in actual mobile robots. Extensive research has been conducted to develop various navigation methods, including end-to-end reinforcement learning and modular map-based approaches. However, fully enabling an agent to perceive and understand the environment, and to navigate towards a target object as efficiently as humans, remains a considerable challenge. In this study, we introduce a data-driven and modular map-based approach, trained on a dataset incorporated with common-sense knowledge of object-to-room relationships extracted from a Large Language Model (LLM), aiming to enhance the efficiency of object-goal navigation. This approach enables the agent to seek the target object in rooms where it is commonly found (e.g., a bed in a bedroom, a couch in a living room), according to LLM-based common-sense knowledge. Additionally, we employ the multi-channel Swin-Unet architecture for multi-task learning, integrating multimodal sensory inputs to effectively extract meaningful features for spatial comprehension and navigation. Results from the Habitat simulator show that our framework surpasses the baseline by an average of 10.6% in the Success-weighted by Path Length (SPL) efficiency metric. Real-world demonstrations confirm that our method can effectively navigate multiple rooms in the object-goal navigation task. For further details and real-world demonstrations, please visit our project webpage (https://sunleyuan.github.io/ObjectNav).}
}
@article{LEE2024,
title = {Unlocking the Secrets Behind Advanced Artificial Intelligence Language Models in Deidentifying Chinese-English Mixed Clinical Text: Development and Validation Study},
journal = {Journal of Medical Internet Research},
volume = {26},
year = {2024},
issn = {1438-8871},
doi = {https://doi.org/10.2196/48443},
url = {https://www.sciencedirect.com/science/article/pii/S143888712400030X},
author = {You-Qian Lee and Ching-Tai Chen and Chien-Chang Chen and Chung-Hong Lee and Peitsz Chen and Chi-Shin Wu and Hong-Jie Dai},
keywords = {code mixing, electronic health record, deidentification, pretrained language model, large language model, ChatGPT},
abstract = {Background
The widespread use of electronic health records in the clinical and biomedical fields makes the removal of protected health information (PHI) essential to maintain privacy. However, a significant portion of information is recorded in unstructured textual forms, posing a challenge for deidentification. In multilingual countries, medical records could be written in a mixture of more than one language, referred to as code mixing. Most current clinical natural language processing techniques are designed for monolingual text, and there is a need to address the deidentification of code-mixed text.
Objective
The aim of this study was to investigate the effectiveness and underlying mechanism of fine-tuned pretrained language models (PLMs) in identifying PHI in the code-mixed context. Additionally, we aimed to evaluate the potential of prompting large language models (LLMs) for recognizing PHI in a zero-shot manner.
Methods
We compiled the first clinical code-mixed deidentification data set consisting of text written in Chinese and English. We explored the effectiveness of fine-tuned PLMs for recognizing PHI in code-mixed content, with a focus on whether PLMs exploit naming regularity and mention coverage to achieve superior performance, by probing the developed models’ outputs to examine their decision-making process. Furthermore, we investigated the potential of prompt-based in-context learning of LLMs for recognizing PHI in code-mixed text.
Results
The developed methods were evaluated on a code-mixed deidentification corpus of 1700 discharge summaries. We observed that different PHI types had preferences in their occurrences within the different types of language-mixed sentences, and PLMs could effectively recognize PHI by exploiting the learned name regularity. However, the models may exhibit suboptimal results when regularity is weak or mentions contain unknown words that the representations cannot generate well. We also found that the availability of code-mixed training instances is essential for the model’s performance. Furthermore, the LLM-based deidentification method was a feasible and appealing approach that can be controlled and enhanced through natural language prompts.
Conclusions
The study contributes to understanding the underlying mechanism of PLMs in addressing the deidentification process in the code-mixed context and highlights the significance of incorporating code-mixed training instances into the model training phase. To support the advancement of research, we created a manipulated subset of the resynthesized data set available for research purposes. Based on the compiled data set, we found that the LLM-based deidentification method is a feasible approach, but carefully crafted prompts are essential to avoid unwanted output. However, the use of such methods in the hospital setting requires careful consideration of data security and privacy concerns. Further research could explore the augmentation of PLMs and LLMs with external knowledge to improve their strength in recognizing rare PHI.}
}
@article{ZHANG2025115001,
title = {Data-driven building load prediction and large language models: Comprehensive overview},
journal = {Energy and Buildings},
volume = {326},
pages = {115001},
year = {2025},
issn = {0378-7788},
doi = {https://doi.org/10.1016/j.enbuild.2024.115001},
url = {https://www.sciencedirect.com/science/article/pii/S0378778824011174},
author = {Yake Zhang and Dijun Wang and Guansong Wang and Peng Xu and Yihao Zhu},
keywords = {Data-driven approach, Building load prediction, Machine learning, Large language models, Feature engineering, Data preparation, Room-scale load prediction, Retrieval augmented generation},
abstract = {Building load forecasting is essential for optimizing the architectural design and managing energy efficiently, enhancing the performance of Heating, Ventilation, and Air Conditioning systems, and enhancing occupant comfort. With advancements in data science and machine learning, the focus on predicting building loads through data analysis has significantly intensified as a research domain. However, previous studies have typically faced challenges such as data scarcity, improper feature extraction methods, and weak model generalization capabilities. To gain a deeper understanding of these issues, a comprehensive review of data processing, feature selection, and model selection methods in previous research is conducted from the perspective of the entire load forecasting process. The aim is to identify the most suitable methods for each step of load forecasting to enhance prediction accuracy. This review surveys the research progress of statistical learning methods, traditional machine learning methods, deep learning methods, and hybrid methods in different application scenarios of building load prediction. Then, it emphasized the critical role of data preprocessing and focused on techniques like data fusion and transfer learning to overcome data shortages and bolster the models’ ability to generalize. Moreover, the obtainment of significant features from building characteristics, weather data, and operational statistics to boost prediction accuracy is explored. A notable contribution of this review is the proposed technical framework for EnergyPlus model generation using LLM-based Retrieval Augmented Generation (RAG) technology and room- level load prediction with Spatio-Temporal Graph Neural Networks. This framework utilize architectural design drawings to achieve an “end-to-end” prediction process, aiming to reduce the professional threshold of load prediction and provide technical support for fine-grained regulation of building operation. Exploratory experiment is conducted using a single-zone building model to verify the feasibility of LLM-generated EnergyPlus models, with IDF simulation file generation taking only 196 s. Room-level load forecasting with LLMs remains to be explored further. It is reasonable to believe that the methods proposed in this review hold promise for advancing data-driven building load forecasting technologies.}
}
@incollection{KARKERA2024,
title = {Large Language Models for Pathway Curation: A Preliminary Investigation},
booktitle = {Reference Module in Life Sciences},
publisher = {Elsevier},
year = {2024},
isbn = {978-0-12-809633-8},
doi = {https://doi.org/10.1016/B978-0-323-95502-7.00254-2},
url = {https://www.sciencedirect.com/science/article/pii/B9780323955027002542},
author = {Nikitha Karkera and Nikshita Karkera and Mahanash Kumar and Vishnuvardhan P. Srinivasulu and Samik Ghosh and Sucheendra K. Palaniappan},
keywords = {Generative AI, Gpt3.5, Gpt4, LLM, Pathway curation},
abstract = {The pathway curation task involves analyzing scientific literature to identify and represent cellular processes as pathways. This process, often time-consuming and labor-intensive, requires significant curation efforts amidst the rapidly growing biomedical literature. Natural Language Processing (NLP) offers a promising method to automatically extract these interactions from scientific texts. Despite immense progress, there remains room for improvement in these systems. The emergence of Large Language Models (LLMs) provides a promising solution for this challenge. Our study conducts a preliminary investigation into leveraging LLMs for the pathway curation task. This paper first presents a review of the current state-of-the-art algorithms for the pathway curation task. Our objective is to check the feasibility and formulate strategies of using these LLMs to improve the accuracy of pathway curation task. Our experiments demonstrate that our GPT-3.5 based fine-tuned models outperforms existing state-of-the-art methods. Specifically, our model achieved a 10 basis point improvement in overall recall and F1 score compared to the best existing algorithms. These findings highlight the potential of LLMs in pathway curation tasks, warranting further research and substantial efforts in this direction.}
}
@article{SU202412200,
title = {Automation and machine learning augmented by large language models in a catalysis study},
journal = {Chemical Science},
volume = {15},
number = {31},
pages = {12200-12233},
year = {2024},
issn = {2041-6520},
doi = {https://doi.org/10.1039/d3sc07012c},
url = {https://www.sciencedirect.com/science/article/pii/S2041652024010794},
author = {Yuming Su and Xue Wang and Yuanxiang Ye and Yibo Xie and Yujing Xu and Yibin Jiang and Cheng Wang},
abstract = {Recent advancements in artificial intelligence and automation are transforming catalyst discovery and design from traditional trial-and-error manual mode into intelligent, high-throughput digital methodologies. This transformation is driven by four key components, including high-throughput information extraction, automated robotic experimentation, real-time feedback for iterative optimization, and interpretable machine learning for generating new knowledge. These innovations have given rise to the development of self-driving labs and significantly accelerated materials research. Over the past two years, the emergence of large language models (LLMs) has added a new dimension to this field, providing unprecedented flexibility in information integration, decision-making, and interacting with human researchers. This review explores how LLMs are reshaping catalyst design, heralding a revolutionary change in the fields.}
}
@article{ZHOU2024103705,
title = {ProMvSD: Towards unsupervised knowledge graph anomaly detection via prior knowledge integration and multi-view semantic-driven estimation},
journal = {Information Processing & Management},
volume = {61},
number = {4},
pages = {103705},
year = {2024},
issn = {0306-4573},
doi = {https://doi.org/10.1016/j.ipm.2024.103705},
url = {https://www.sciencedirect.com/science/article/pii/S0306457324000657},
author = {Yunfeng Zhou and Cui Zhu and Wenjun Zhu},
keywords = {Knowledge graph, Anomaly detection, Pre-trained language models, Semantics, Unsupervised learning},
abstract = {Knowledge graphs (KGs) have found extensive applications within intelligent systems, such as information retrieval. Much of the research has predominantly focused on completing missing knowledge, with little consideration given to examining errors. Unfortunately, during customizing KGs, diverse unpredictable errors are virtually unavoidable to be introduced, and these anomalies significantly impact the performance of applications. Detecting erroneous knowledge presents a formidable challenge due to the costly acquisition of ground-truth labels. In this work, we develop an unsupervised anomaly detection framework named ProMvSD, aiming to adapt KGs of varying scales via serialization components. To overcome the insufficient contextual information provided by the topological structure, we introduce the large language model as a reasoner to extract prior knowledge from extensive pre-trained textual data, thereby enhancing the understanding of KGs. Anomalous triple may result in a larger semantic gap between the head and tail neighborhoods. To uncover latent anomalies effectively, we propose a multi-view semantic-driven model (MvSD) based on the assumptions of self-consistency and information stability. MvSD jointly estimates the suspiciousness of triples from three hyperviews: node-view semantic contradiction, triple-view semantic gap, and pathway-view semantic gap. Extensive experiments on three English benchmark KGs and a Chinese medical KG demonstrate that, for the top 1% of the most suspicious triples, we can detect real anomalies with at most 99.9% accuracy. Furthermore, ProMvSD significantly outperforms state-of-the-art representation learning baselines, achieving a 29.2% improvement in detecting all anomalies.}
}
@article{WANG2024,
title = {An Entity Extraction Pipeline for Medical Text Records Using Large Language Models: Analytical Study},
journal = {Journal of Medical Internet Research},
volume = {26},
year = {2024},
issn = {1438-8871},
doi = {https://doi.org/10.2196/54580},
url = {https://www.sciencedirect.com/science/article/pii/S1438887124001493},
author = {Lei Wang and Yinyao Ma and Wenshuai Bi and Hanlin Lv and Yuxiang Li},
keywords = {clinical data extraction, large language models, feature hallucination, modular approach, unstructured data processing},
abstract = {Background
The study of disease progression relies on clinical data, including text data, and extracting valuable features from text data has been a research hot spot. With the rise of large language models (LLMs), semantic-based extraction pipelines are gaining acceptance in clinical research. However, the security and feature hallucination issues of LLMs require further attention.
Objective
This study aimed to introduce a novel modular LLM pipeline, which could semantically extract features from textual patient admission records.
Methods
The pipeline was designed to process a systematic succession of concept extraction, aggregation, question generation, corpus extraction, and question-and-answer scale extraction, which was tested via 2 low-parameter LLMs: Qwen-14B-Chat (QWEN) and Baichuan2-13B-Chat (BAICHUAN). A data set of 25,709 pregnancy cases from the People’s Hospital of Guangxi Zhuang Autonomous Region, China, was used for evaluation with the help of a local expert’s annotation. The pipeline was evaluated with the metrics of accuracy and precision, null ratio, and time consumption. Additionally, we evaluated its performance via a quantified version of Qwen-14B-Chat on a consumer-grade GPU.
Results
The pipeline demonstrates a high level of precision in feature extraction, as evidenced by the accuracy and precision results of Qwen-14B-Chat (95.52% and 92.93%, respectively) and Baichuan2-13B-Chat (95.86% and 90.08%, respectively). Furthermore, the pipeline exhibited low null ratios and variable time consumption. The INT4-quantified version of QWEN delivered an enhanced performance with 97.28% accuracy and a 0% null ratio.
Conclusions
The pipeline exhibited consistent performance across different LLMs and efficiently extracted clinical features from textual data. It also showed reliable performance on consumer-grade hardware. This approach offers a viable and effective solution for mining clinical research data from textual records.}
}
@article{CHEN2024105873,
title = {Knowledge graph for safety management standards of water conservancy construction engineering},
journal = {Automation in Construction},
volume = {168},
pages = {105873},
year = {2024},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2024.105873},
url = {https://www.sciencedirect.com/science/article/pii/S0926580524006095},
author = {Yun Chen and Gengyang Lu and Ke Wang and Shu Chen and Chenfei Duan},
keywords = {Water conservancy construction engineering, Knowledge graph, Safety management standards, ALBERT-BiLSTM-CRF, Association rules},
abstract = {With the increasing demand for water conservancy engineering (WCE), the number of safety accidents during construction has continued to rise, requiring an urgent improvement in construction safety. The existing safety management regulations for water conservancy construction engineering (WCCE) comprise a considerable amount of text, with cross-references between different standards severely reducing their use efficiency. To address this issue, this paper proposes an ALBERT-BiLSTM-CRF model based on textual data from WCCE safety management standards. ALBERT, a lightweight pretrained language model, is integrated with the BiLSTM-CRF to construct an intelligent text entity recognition method. Association rules are used to extract entity relationships, and a knowledge graph representing the WCCE safety management standards is established. The results show that the ALBERT-BiLSTM-CRF algorithm improves the precision, with a recognition accuracy exceeding 85 %. Case studies validate that the constructed knowledge graph can quickly query safety standard knowledge, aiding in the generation of safety measures.}
}
@article{YANG2024100887,
title = {Enhancing phenotype recognition in clinical notes using large language models: PhenoBCBERT and PhenoGPT},
journal = {Patterns},
volume = {5},
number = {1},
pages = {100887},
year = {2024},
issn = {2666-3899},
doi = {https://doi.org/10.1016/j.patter.2023.100887},
url = {https://www.sciencedirect.com/science/article/pii/S266638992300288X},
author = {Jingye Yang and Cong Liu and Wendy Deng and Da Wu and Chunhua Weng and Yunyun Zhou and Kai Wang},
keywords = {Human Phenotype Ontology, named entity recognition, transformer, clinical notes, electronic health records, BERT, GPT},
abstract = {Summary
To enhance phenotype recognition in clinical notes of genetic diseases, we developed two models—PhenoBCBERT and PhenoGPT—for expanding the vocabularies of Human Phenotype Ontology (HPO) terms. While HPO offers a standardized vocabulary for phenotypes, existing tools often fail to capture the full scope of phenotypes due to limitations from traditional heuristic or rule-based approaches. Our models leverage large language models to automate the detection of phenotype terms, including those not in the current HPO. We compare these models with PhenoTagger, another HPO recognition tool, and found that our models identify a wider range of phenotype concepts, including previously uncharacterized ones. Our models also show strong performance in case studies on biomedical literature. We evaluate the strengths and weaknesses of BERT- and GPT-based models in aspects such as architecture and accuracy. Overall, our models enhance automated phenotype detection from clinical texts, improving downstream analyses on human diseases.}
}
@article{CHEN2024104016,
title = {A survey of large language models for cyber threat detection},
journal = {Computers & Security},
volume = {145},
pages = {104016},
year = {2024},
issn = {0167-4048},
doi = {https://doi.org/10.1016/j.cose.2024.104016},
url = {https://www.sciencedirect.com/science/article/pii/S0167404824003213},
author = {Yiren Chen and Mengjiao Cui and Ding Wang and Yiyang Cao and Peian Yang and Bo Jiang and Zhigang Lu and Baoxu Liu},
keywords = {Large language models, Cyber security, Threat detection, Literature review},
abstract = {With the increasing complexity of cyber threats and the expanding scope of cyberspace, there exist progressively more challenges in cyber threat detection. It is proven that most previous threat detection models may become inadequate due to the escalation of hacker attacks. However, recent research has shown that some of these problems can be effectively addressed by Large Language Models (LLMs) directly or indirectly. Nowadays, a growing number of security researchers are adopting LLMs for analyzing various cyber threats. According to the investigation, we found that while there are numerous emerging reviews on the utilization of LLMs in some fields of cyber security, there is currently a lack of a comprehensive review on the application of LLMs in the threat detection stage. Through retrieving and collating existing works in recent years, we examined various threat detection and monitoring tasks for which LLMs may be well-suited, including cyber threat intelligence, phishing email detection, threat prediction, logs analysis, and so on. Additionally, the review explored the specific stages of different detection tasks in which LLMs are involved, evaluating the points at which LLMs are optimized. For instance, LLMs have been found to enhance the interpretability of log analysis in real-time anomaly event discovery. Additionally, we discussed some tasks where LLMs may not be suitable and explored future directions and challenges in this field. By providing a detailed status update and comprehensive insights, this review aims to assist security researchers in leveraging LLMs to enhance existing detection frameworks or develop domain-specific LLMs.}
}
@article{LOPEZUBEDA2024105443,
title = {Evaluation of large language models performance against humans for summarizing MRI knee radiology reports: A feasibility study},
journal = {International Journal of Medical Informatics},
volume = {187},
pages = {105443},
year = {2024},
issn = {1386-5056},
doi = {https://doi.org/10.1016/j.ijmedinf.2024.105443},
url = {https://www.sciencedirect.com/science/article/pii/S1386505624001060},
author = {Pilar López-Úbeda and Teodoro Martín-Noguerol and Carolina Díaz-Angulo and Antonio Luna},
keywords = {Radiology report summarization, Natural Language Processing, Large Language Model, Knee MRI reports, Human expert evaluation},
abstract = {Objectives
This study addresses the critical need for accurate summarization in radiology by comparing various Large Language Model (LLM)-based approaches for automatic summary generation. With the increasing volume of patient information, accurately and concisely conveying radiological findings becomes crucial for effective clinical decision-making. Minor inaccuracies in summaries can lead to significant consequences, highlighting the need for reliable automated summarization tools.
Methods
We employed two language models — Text-to-Text Transfer Transformer (T5) and Bidirectional and Auto-Regressive Transformers (BART) — in both fine-tuned and zero-shot learning scenarios and compared them with a Recurrent Neural Network (RNN). Additionally, we conducted a comparative analysis of 100 MRI report summaries, using expert human judgment and criteria such as coherence, relevance, fluency, and consistency, to evaluate the models against the original radiologist summaries. To facilitate this, we compiled a dataset of 15,508 retrospective knee Magnetic Resonance Imaging (MRI) reports from our Radiology Information System (RIS), focusing on the findings section to predict the radiologist's summary.
Results
The fine-tuned models outperform the neural network and show superior performance in the zero-shot variant. Specifically, the T5 model achieved a Rouge-L score of 0.638. Based on the radiologist readers' study, the summaries produced by this model were found to be very similar to those produced by a radiologist, with about 70% similarity in fluency and consistency between the T5-generated summaries and the original ones.
Conclusions
Technological advances, especially in NLP and LLM, hold great promise for improving and streamlining the summarization of radiological findings, thus providing valuable assistance to radiologists in their work.}
}
@article{WYSOCKA2024104724,
title = {Large Language Models, scientific knowledge and factuality: A framework to streamline human expert evaluation},
journal = {Journal of Biomedical Informatics},
volume = {158},
pages = {104724},
year = {2024},
issn = {1532-0464},
doi = {https://doi.org/10.1016/j.jbi.2024.104724},
url = {https://www.sciencedirect.com/science/article/pii/S1532046424001424},
author = {Magdalena Wysocka and Oskar Wysocki and Maxime Delmas and Vincent Mutel and André Freitas},
keywords = {Factual knowledge, Large language models, Antibiotic discovery, Retrieval-augmented generation},
abstract = {Objective:
The paper introduces a framework for the evaluation of the encoding of factual scientific knowledge, designed to streamline the manual evaluation process typically conducted by domain experts. Inferring over and extracting information from Large Language Models (LLMs) trained on a large corpus of scientific literature can potentially define a step change in biomedical discovery, reducing the barriers for accessing and integrating existing medical evidence. This work explores the potential of LLMs for dialoguing with biomedical background knowledge, using the context of antibiotic discovery.
Methods:
The framework involves three evaluation steps, each assessing different aspects sequentially: fluency, prompt alignment, semantic coherence, factual knowledge, and specificity of the generated responses. By splitting these tasks between non-experts and experts, the framework reduces the effort required from the latter. The work provides a systematic assessment on the ability of eleven state-of-the-art LLMs, including ChatGPT, GPT-4 and Llama 2, in two prompting-based tasks: chemical compound definition generation and chemical compound–fungus relation determination.
Results:
Although recent models have improved in fluency, factual accuracy is still low and models are biased towards over-represented entities. The ability of LLMs to serve as biomedical knowledge bases is questioned, and the need for additional systematic evaluation frameworks is highlighted.
Conclusion:
While LLMs are currently not fit for purpose to be used as biomedical factual knowledge bases in a zero-shot setting, there is a promising emerging property in the direction of factuality as the models become domain specialised, scale up in size and level of human feedback.}
}
@article{ALGHERAIRY2025101697,
title = {Prompting large language models for user simulation in task-oriented dialogue systems},
journal = {Computer Speech & Language},
volume = {89},
pages = {101697},
year = {2025},
issn = {0885-2308},
doi = {https://doi.org/10.1016/j.csl.2024.101697},
url = {https://www.sciencedirect.com/science/article/pii/S0885230824000809},
author = {Atheer Algherairy and Moataz Ahmed},
keywords = {Task Oriented Dialogue, User simulator, Large language models, Prompting, Agenda-based simulator},
abstract = {Large Language Models (LLMs) have gained widespread popularity due to their instruction-following abilities. In this study, we evaluate their ability in simulating user interactions for task-oriented dialogue (TOD) systems. Our findings demonstrate that prompting LLMs reveals their promising capabilities for training and testing dialogue policies, eliminating the need for domain expertise in crafting complex rules or relying on large annotated data, as required by traditional simulators. The results show that the dialogue system trained with the ChatGPT simulator achieves a success rate of 59%, comparable to a 62% success rate of the dialogue system trained with the manual-rules, agenda-based user simulator (ABUS). Furthermore, the dialogue system trained with the ChatGPT simulator demonstrates better generalization ability compared to the dialogue system trained with the ABUS. Its success rate outperforms that of the dialogue system trained with the ABUS by 4% on GenTUS, 5% on the ChatGPT Simulator, and 3% on the Llama simulator. Nevertheless, LLM-based user simulators provide challenging environment, lexically rich, diverse, and random responses. Llama simulator outperforms the human reference in all lexical diversity metrics with a margin of 0.66 in SE, 0.39 in CE, 0.01 in MSTTR, 0.04 in HDD, and 0.55 in MTLD, while the ChatGPT simulator achieves comparable results. This ultimately contributes to enhancing the system’s ability to generalize more effectively.}
}
@article{TAN2024108290,
title = {MedChatZH: A tuning LLM for traditional Chinese medicine consultations},
journal = {Computers in Biology and Medicine},
volume = {172},
pages = {108290},
year = {2024},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2024.108290},
url = {https://www.sciencedirect.com/science/article/pii/S0010482524003743},
author = {Yang Tan and Zhixing Zhang and Mingchen Li and Fei Pan and Hao Duan and Zijie Huang and Hua Deng and Zhuohang Yu and Chen Yang and Guoyang Shen and Peng Qi and Chengyuan Yue and Yuxian Liu and Liang Hong and Huiqun Yu and Guisheng Fan and Yun Tang},
keywords = {Generative large language models (LLMs), Question-answering (QA), Dialogue model, Traditional Chinese medical QA, Fine-tuning},
abstract = {Generative Large Language Models (LLMs) have achieved significant success in various natural language processing tasks, including Question-Answering (QA) and dialogue systems. However, most models are trained on English data and lack strong generalization in providing answers in Chinese. This limitation is especially evident in specialized domains like traditional Chinese medical QA, where performance suffers due to the absence of fine-tuning and high-quality datasets. To address this, we introduce MedChatZH, a dialogue model optimized for Chinese medical QA based on transformer decoder with LLaMA architecture. Continued pre-training on a curated corpus of Chinese medical books is followed by fine-tuning with a carefully selected medical instruction dataset, resulting in MedChatZH outperforming several Chinese dialogue baselines on a real-world medical dialogue dataset. Our model, code, and dataset are publicly available on GitHub (https://github.com/tyang816/MedChatZH) to encourage further research in traditional Chinese medicine and LLMs.}
}
@article{LIU2024127505,
title = {ZVQAF: Zero-shot visual question answering with feedback from large language models},
journal = {Neurocomputing},
volume = {580},
pages = {127505},
year = {2024},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2024.127505},
url = {https://www.sciencedirect.com/science/article/pii/S0925231224002765},
author = {Cheng Liu and Chao Wang and Yan Peng and Zhixu Li},
keywords = {Feedback, Large language model, Visual question answering},
abstract = {Due to the prominent zero-shot generalization in new language tasks shown by large language models (LLMs), applying LLMs for zero-shot visual question answering (VQA) has been a new trend. However, most prior approaches directly use off-the-shelf captioning models to generate captions that compose in-context examples for LLMs, and such generated captions may be uninformative, thus leading the LLMs to give false predictions. To address this, we propose zero-shot VQA with feedback from LLMs (ZVQAF), a framework that applies LLMs to discriminate the quality of generated captions and leverages this feedback to train the captioning model. ZVQAF consists of two stages: the first stage is the training with feedback, which enables the captioning model to recognize the task objective and information requirements from the LLM, and the second stage is utilizing the optimized captioning model and LLM for inference. Extensive experiments show that ZVQAF achieves zero-shot VQA performance that is comparable or even superior to those previous zero-shot, few-shot, and end-to-end training approaches. For example, on VQAv2 test dataset, ZVQAF outperforms Flamingo (Alayrac et al., 2022) which employs end-to-end training by a large margin of 8.0%. In addition, on A-OKVQA dataset, ZVQAF outperforms zero-shot method Img2LLM (Guo et al., 2023) by 3.8% when employing LLMs with similar scales.}
}
@article{GORIDKOV2024964,
title = {What's in this LCA Report? A Case Study on Harnessing Large Language Models to Support Designers in Understanding Life Cycle Reports},
journal = {Procedia CIRP},
volume = {122},
pages = {964-969},
year = {2024},
note = {31st CIRP Conference on Life Cycle Engineering},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2024.01.131},
url = {https://www.sciencedirect.com/science/article/pii/S2212827124001756},
author = {Nicole Goridkov and Ye Wang and Kosa Goucher-Lambert},
keywords = {sustainable design, life cycle reports, document understanding, knowledge management, large language models},
abstract = {Life cycle assessment (LCA) is a well-established approach and benchmark for design for sustainability efforts, in which detailed reports are produced that can serve as decision-making guides for developing new products. However, LCA reports are typically dense and technically complex, making it difficult for many engineering design project stakeholders to appropriately leverage the information found within them. Our work seeks to understand and improve the transfer of knowledge from LCA reports during the early stages of the design process, specifically leveraging the natural language capabilities of large language models (LLMs). In this paper, we investigate how four LCA-and sustainability-centric prompting frameworks can extract relevant design knowledge from LCA reports, demonstrated through a case study where an LLM (ChatGPT) is prompted on a provided electric toothbrush LCA report. Key findings illustrate the prompting frameworks can establish high-level summaries and identify life-cycle specific information, but the development of specific and design-focused sub-prompts will allow for richer understanding. We envision designers can use these proposed frameworks to query an LLM to gain context and insights from relevant LCA reports. The proposed techniques serve as a basis for automatic knowledge extraction from life cycle documents, creating accessible information in a user-friendly manner for designers who look to develop life-cycle-informed products.}
}
@article{NERELLA2024102900,
title = {Transformers and large language models in healthcare: A review},
journal = {Artificial Intelligence in Medicine},
volume = {154},
pages = {102900},
year = {2024},
issn = {0933-3657},
doi = {https://doi.org/10.1016/j.artmed.2024.102900},
url = {https://www.sciencedirect.com/science/article/pii/S0933365724001428},
author = {Subhash Nerella and Sabyasachi Bandyopadhyay and Jiaqing Zhang and Miguel Contreras and Scott Siegel and Aysegul Bumin and Brandon Silva and Jessica Sena and Benjamin Shickel and Azra Bihorac and Kia Khezeli and Parisa Rashidi},
keywords = {Transformers, Healthcare, Electronic Health Records, Large Language Models, Medical Imaging, Natural Language Processing},
abstract = {With Artificial Intelligence (AI) increasingly permeating various aspects of society, including healthcare, the adoption of the Transformers neural network architecture is rapidly changing many applications. Transformer is a type of deep learning architecture initially developed to solve general-purpose Natural Language Processing (NLP) tasks and has subsequently been adapted in many fields, including healthcare. In this survey paper, we provide an overview of how this architecture has been adopted to analyze various forms of healthcare data, including clinical NLP, medical imaging, structured Electronic Health Records (EHR), social media, bio-physiological signals, biomolecular sequences. Furthermore, which have also include the articles that used the transformer architecture for generating surgical instructions and predicting adverse outcomes after surgeries under the umbrella of critical care. Under diverse settings, these models have been used for clinical diagnosis, report generation, data reconstruction, and drug/protein synthesis. Finally, we also discuss the benefits and limitations of using transformers in healthcare and examine issues such as computational cost, model interpretability, fairness, alignment with human values, ethical implications, and environmental impact.}
}
@article{TAYLOR2024103009,
title = {Developing healthcare language model embedding spaces},
journal = {Artificial Intelligence in Medicine},
volume = {158},
pages = {103009},
year = {2024},
issn = {0933-3657},
doi = {https://doi.org/10.1016/j.artmed.2024.103009},
url = {https://www.sciencedirect.com/science/article/pii/S0933365724002513},
author = {Niall Taylor and Dan Schofield and Andrey Kormilitzin and Dan W. Joyce and Alejo Nevado-Holgado},
keywords = {LLMs, Contrastive loss, Embeddings, Healthcare, Classification},
abstract = {Pre-trained Large Language Models (LLMs) have revolutionised Natural Language Processing (NLP) tasks, but often struggle when applied to specialised domains such as healthcare. The traditional approach of pre-training on large datasets followed by task-specific fine-tuning is resource-intensive and poorly aligned with the constraints of many healthcare settings. This presents a significant challenge for deploying LLM-based NLP solutions in medical contexts, where data privacy, computational resources, and domain-specific language pose unique obstacles. This study aims to develop and evaluate efficient methods for adapting smaller LLMs to healthcare-specific datasets and tasks. We seek to identify pre-training approaches that can effectively instil healthcare competency in compact LLMs under tight computational budgets, a crucial capability for responsible and sustainable deployment in local healthcare settings. We explore three specialised pre-training methods to adapt smaller LLMs to different healthcare datasets: traditional Masked Language modelling (MLM), Deep Contrastive Learning for Unsupervised Textual Representations (DeCLUTR), and a novel approach utilising metadata categories from healthcare settings. These methods are assessed across multiple healthcare datasets, with a focus on downstream document classification tasks. We evaluate the performance of the resulting LLMs through classification accuracy and analysis of the derived embedding spaces. Contrastively trained models consistently outperform other approaches on classification tasks, delivering strong performance with limited labelled data and fewer model parameter updates. While our novel metadata-based pre-training does not further improve classifications across datasets, it yields interesting embedding cluster separability. Importantly, all domain-adapted LLMs outperform their publicly available, general-purpose base models, validating the importance of domain specialisation. This research demonstrates the efficacy of specialised pre-training methods in adapting compact LLMs to healthcare tasks, even under resource constraints. We provide guidelines for pre-training specialised healthcare LLMs and motivate continued inquiry into contrastive objectives. Our findings underscore the potential of these approaches for aligning small LLMs with privacy-sensitive medical tasks, offering a path toward more efficient and responsible NLP deployment in healthcare settings. This work contributes to the broader goal of making advanced NLP techniques accessible and effective in specialised domains, particularly where resource limitations and data sensitivity are significant concerns.}
}
@article{BENEDETTO2025100353,
title = {Assessing how accurately large language models encode and apply the common European framework of reference for languages},
journal = {Computers and Education: Artificial Intelligence},
volume = {8},
pages = {100353},
year = {2025},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2024.100353},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X24001565},
author = {Luca Benedetto and Gabrielle Gaudeau and Andrew Caines and Paula Buttery},
keywords = {Large language models, Language learning, Common European Framework of Reference for Languages},
abstract = {Large Language Models (LLMs) can have a transformative effect on a variety of domains, including education, and it is therefore pressing to understand whether these models have knowledge of – or, in other words, how they have encoded – the specific pedagogical requirements of different educational domains, and whether they use this when performing educational tasks. In this work, we propose an approach to evaluate the knowledge – or encoding – that the LLMs have of the Common European Framework of Reference for Languages (CEFR), and use it to evaluate five modern LLMs. Our study shows that the suite of tasks we propose is quite challenging for all the LLMs, and they often provide results which are not satisfactory and would be unusable in educational applications, suggesting that – even if they encode some information about the CEFR – this knowledge is not really leveraged when performing downstream tasks.}
}
@article{DECARDINELSON2024108723,
title = {Generative AI and process systems engineering: The next frontier},
journal = {Computers & Chemical Engineering},
volume = {187},
pages = {108723},
year = {2024},
issn = {0098-1354},
doi = {https://doi.org/10.1016/j.compchemeng.2024.108723},
url = {https://www.sciencedirect.com/science/article/pii/S0098135424001418},
author = {Benjamin Decardi-Nelson and Abdulelah S. Alshehri and Akshay Ajagekar and Fengqi You},
keywords = {Generative AI, Process systems engineering, Large language models, Multiscale},
abstract = {This review article explores how emerging generative artificial intelligence (GenAI) models, such as large language models (LLMs), can enhance solution methodologies within process systems engineering (PSE). These cutting-edge GenAI models, particularly foundation models (FMs), which are pre-trained on extensive, general-purpose datasets, offer versatile adaptability for a broad range of tasks, including responding to queries, image generation, and complex decision-making. Given the close relationship between advancements in PSE and developments in computing and systems technologies, exploring the synergy between GenAI and PSE is essential. We begin our discussion with a compact overview of both classic and emerging GenAI models, including FMs, and then dive into their applications within key PSE domains: synthesis and design, optimization and integration, and process monitoring and control. In each domain, we explore how GenAI models could potentially advance PSE methodologies, providing insights and prospects for each area. Furthermore, the article identifies and discusses potential challenges in fully leveraging GenAI within PSE, including multiscale modeling, data requirements, evaluation metrics and benchmarks, and trust and safety, thereby deepening the discourse on effective GenAI integration into systems analysis, design, optimization, operations, monitoring, and control. This paper provides a guide for future research focused on the applications of emerging GenAI in PSE.}
}
@article{CHEN2025104213,
title = {AECR: Automatic attack technique intelligence extraction based on fine-tuned large language model},
journal = {Computers & Security},
volume = {150},
pages = {104213},
year = {2025},
issn = {0167-4048},
doi = {https://doi.org/10.1016/j.cose.2024.104213},
url = {https://www.sciencedirect.com/science/article/pii/S0167404824005194},
author = {Minghao Chen and Kaijie Zhu and Bin Lu and Ding Li and Qingjun Yuan and Yuefei Zhu},
keywords = {Cyber threat intelligence (CTI), Attack technique extraction, Prompt engineering, Large language model (LLM), Advanced persistent threat (APT)},
abstract = {Cyber Threat Intelligence (CTI) reports contain resourceful intelligence on cyber-attack campaigns, which provides great help for security analysts to infer attack trends and enhance their defenses. However, due to the diversity of report content and writing styles, current intelligence extraction is mostly based on time-consuming manual efforts. Moreover, existing automatic methods generally neglect the importance of background knowledge and produce inexact extraction results. These problems prevent the effective utilization and sharing of intelligence from CTI reports. In this paper, we primarily focus on the automatic extraction of attack technique (AT) intelligence, which reveals patterns of attack behaviors and hardly changes over time. We propose a novel automatic AT extraction pipeline for CTI reports (AECR). AECR explores the feasibility of extracting AT intelligence based on a fined-tuned large language model (LLM). Particularly, we endow the selected LLM with enhanced domain-specific knowledge to improve its comprehension of AT-relevant content and alleviate the hallucination problem. Experimental results demonstrate that AECR outperforms state-of-the-art methods by a wide margin with a reasonable time cost. Specifically, we improve the accuracy, precision, recall, and F1-score by 108%, 37.2%, 22.4%, and 67.5% respectively. To the best of our knowledge, AECR is the first to perform AT extraction based on fine-tuned LLM.}
}
@article{LE2024100052,
title = {The performance of large language models on fictional consult queries indicates favorable potential for AI-assisted vascular surgery consult handling},
journal = {JVS-Vascular Insights},
volume = {2},
pages = {100052},
year = {2024},
issn = {2949-9127},
doi = {https://doi.org/10.1016/j.jvsvi.2023.100052},
url = {https://www.sciencedirect.com/science/article/pii/S2949912723000491},
author = {Quang Le and Kedar S. Lavingia and Michael Amendola},
keywords = {Artificial intelligence, Consult, Delivery of care, Large language model, Vascular emergencies},
abstract = {Objective
Recently, the use of large language models (LLMs) in medicine has become a prominent topic of discussion due to the rapid improvement of these tools in understanding and responding to natural language. Several models are widely available to the public, both proprietary and open-sourced. We aim to evaluate the possible use of such LLMs in vascular surgery by understanding their abilities to process common consult requests.
Methods
The senior author created 25 fictional vascular surgery consultation queries based on common consultation requests. Five attending surgeons and four LLMs (GPT 3.5, GPT 4, Bard, and Falcon 40B) were asked to answer whether each consult was an emergency that needed immediate attention within an hour. Responders were also asked whether the next best step was an examination, additional imaging, or an urgent operation. GPT 3.5 and 4 also provided free-response answers on the next best step, graded by attending surgeons based on scientific accuracy, possible harm, and content completeness.
Results
The rates of accurate emergency identification were 88%, 100%, 76%, and 88% for GPT 3.5, GPT 4, Falcon 40B, and Bard, respectively. Although they have similar overall accuracy, GPT 3.5 has a high sensitivity at 100%, whereas Bard has a high specificity at 90%. GPT 4.0 had 100% sensitivity and specificity. LLMs agreed with the majority surgeon opinion on the next best step in 64% (GPT 3.5), 32% (GPT 4), 68% (Falcon 40B), and 36% (Bard) of cases. GPT 3.5 and 4 had a collective ratio of 89.5% of answers adhering to the scientific consensus. Only 5% of responses were highly likely to cause clinically significant harm. Although only 4% included incorrect content, 17.5% of answers missed important content. There was no significant difference between GPT 3.5 and 4 regarding the free-response grade.
Conclusions
Existing, widely available LLMs exhibited a solid ability to identify vascular emergencies, with GPT 4.0 agreeing with surgeon attendings in 100% of cases. However, these models continue to have identifiable deficiencies in treatment recommendations, a higher-level task. Future models might help triage incoming consults and provide preliminary management suggestions. The utility of such tools in clinical practice remains to be explored.}
}
@article{KAUR2025100315,
title = {Harnessing the power of language models in cybersecurity: A comprehensive review},
journal = {International Journal of Information Management Data Insights},
volume = {5},
number = {1},
pages = {100315},
year = {2025},
issn = {2667-0968},
doi = {https://doi.org/10.1016/j.jjimei.2024.100315},
url = {https://www.sciencedirect.com/science/article/pii/S2667096824001046},
author = {Ramanpreet Kaur and Tomaž Klobučar and Dušan Gabrijelčič},
keywords = {Cybersecurity, Large language model, Fine-tuning, BERT},
abstract = {Language models are transforming cybersecurity by addressing critical challenges such as the growing skills gap, the need for expertise augmentation, and knowledge retention. These models offer scalable, adaptable, and round-the-clock defenses against evolving cyber threats. By generating human-like text, processing data efficiently, and providing actionable responses, language models bridge the gap between automated systems and human expertise for different cybersecurity applications. However, the application and adaptation of language models for cyber security is still in its infancy. This review explores the use of general models, such as BERT, and larger models in cybersecurity research. It provides a structured framework for developing customized language models tailored to applications including content analysis, software and systems analysis, threat intelligence and monitoring, and cyber vetting. The study critically examines challenges, such as data confidentiality, infrastructure requirements, integration complexity and the evolving threat landscape. Moreover, it underscores the need for transparency, responsible use, and bias mitigation to ensure reliable and secure deployment of these models. In addition, this work critically examines the socio-technical dimensions of language model integration, focusing on their impact on organizational workflows, decision making and human-machine collaboration. By considering both technical and socio-technical considerations, this review provides a roadmap for future research and development. It highlights the potential of language models to improve organizational resilience, ensure secure implementation, and support informed decision-making in cybersecurity practice.}
}
@article{AFSHAR2024104707,
title = {On the role of the UMLS in supporting diagnosis generation proposed by Large Language Models},
journal = {Journal of Biomedical Informatics},
volume = {157},
pages = {104707},
year = {2024},
issn = {1532-0464},
doi = {https://doi.org/10.1016/j.jbi.2024.104707},
url = {https://www.sciencedirect.com/science/article/pii/S1532046424001254},
author = {Majid Afshar and Yanjun Gao and Deepak Gupta and Emma Croxford and Dina Demner-Fushman},
keywords = {Artificial intelligence, Knowledge representation (computer), Natural language processing, Unified medical language system, Evaluation methodology, Differential diagnoses},
abstract = {Objective:
Traditional knowledge-based and machine learning diagnostic decision support systems have benefited from integrating the medical domain knowledge encoded in the Unified Medical Language System (UMLS). The emergence of Large Language Models (LLMs) to supplant traditional systems poses questions of the quality and extent of the medical knowledge in the models’ internal knowledge representations and the need for external knowledge sources. The objective of this study is three-fold: to probe the diagnosis-related medical knowledge of popular LLMs, to examine the benefit of providing the UMLS knowledge to LLMs (grounding the diagnosis predictions), and to evaluate the correlations between human judgments and the UMLS-based metrics for generations by LLMs.
Methods:
We evaluated diagnoses generated by LLMs from consumer health questions and daily care notes in the electronic health records using the ConsumerQA and Problem Summarization datasets. Probing LLMs for the UMLS knowledge was performed by prompting the LLM to complete the diagnosis-related UMLS knowledge paths. Grounding the predictions was examined in an approach that integrated the UMLS graph paths and clinical notes in prompting the LLMs. The results were compared to prompting without the UMLS paths. The final experiments examined the alignment of different evaluation metrics, UMLS-based and non-UMLS, with human expert evaluation.
Results:
In probing the UMLS knowledge, GPT-3.5 significantly outperformed Llama2 and a simple baseline yielding an F1 score of 10.9% in completing one-hop UMLS paths for a given concept. Grounding diagnosis predictions with the UMLS paths improved the results for both models on both tasks, with the highest improvement (4%) in SapBERT score. There was a weak correlation between the widely used evaluation metrics (ROUGE and SapBERT) and human judgments.
Conclusion:
We found that while popular LLMs contain some medical knowledge in their internal representations, augmentation with the UMLS knowledge provides performance gains around diagnosis generation. The UMLS needs to be tailored for the task to improve the LLMs predictions. Finding evaluation metrics that are aligned with human judgments better than the traditional ROUGE and BERT-based scores remains an open research question.}
}
@article{ABDELAZIM202466,
title = {Multi-Hop Arabic LLM Reasoning in Complex QA},
journal = {Procedia Computer Science},
volume = {244},
pages = {66-75},
year = {2024},
note = {6th International Conference on AI in Computational Linguistics},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.10.179},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924029806},
author = {Hazem Abdelazim and Tony Begemy and Ahmed Galal and Hala Sedki and Ali Mohamed},
keywords = {Large Language Models, Retrieval Augmented Generation, Arabic NLP},
abstract = {The introduction of Large Language Models (LLMs), and generative AI has significantly transformed the field of natural language processing. These models have exhibited profound reasoning capabilities, marking considerable progress across diverse general knowledge reasoning tasks. Consequently, the deployment of LLMs in domain-specific contexts has become a prime objective for governments and corporations eager to leverage the generative AI revolution. However, the Arabic language has notably lagged in attention and development compared to other languages in this arena. This research endeavors to delve into various facets of Arabic closed-domain question and answering systems that emulate the reasoning requirements of private enterprise data. Our study focuses on the practical deployment of Arabic LLMs in targeted applications, specifically utilizing the ACQAD (Arabic Complex Question Answering Dataset), which exhibits multi-hop reasoning. Different strategies are experimented using Long Context Window (LCW) and Retrieval Augmented Generation (RAG). Results showed that decomposing complex questions using Chain-of-Thought reasoning considerably improved the performance from 75% to 92% using LCW, but at much higher token cost compared to RAG. Trade-of between cost and performance showed that 80% accuracy can be attained using only 30% of the cost using RAG Sentence - level embeddings. Microsoft E5 embedding model is used and OpenAI GPT4-turbo LLM which proved superior reasoning performance compared to other Arabic LLMs}
}
@article{CHEN2025102982,
title = {Integrating large language model and digital twins in the context of industry 5.0: Framework, challenges and opportunities},
journal = {Robotics and Computer-Integrated Manufacturing},
volume = {94},
pages = {102982},
year = {2025},
issn = {0736-5845},
doi = {https://doi.org/10.1016/j.rcim.2025.102982},
url = {https://www.sciencedirect.com/science/article/pii/S0736584525000365},
author = {Chong Chen and Kuanhong Zhao and Jiewu Leng and Chao Liu and Junming Fan and Pai Zheng},
keywords = {Large language models, Digital twins, Industry 5.0, Intelligent manufacturing},
abstract = {In Industry 5.0, where human ingenuity is combined with cutting-edge technologies such as artificial intelligence (AI) and robotics to revolutionize manufacturing with a focus on sustainability and human well-being, Digital Twins (DT) have become essential to real-time optimization. However, the complexity of managing DT for large-scale systems poses challenges in terms of data transmission, analytics, and advanced applications, which can be potentially addressed by Large Language Model (LLM). This research firstly performs a literature review to study the roles and functions of LLM in DT in the context of Industry 5.0. Subsequently, we propose a framework named Interactive-DT for LLM-DT integration that reveals the technical pathway for how LLM can be effectively integrated and function within DT environments. Within this framework, the roles and functionalities of LLM at the edge layer, DT layer, and service layer are elaborated upon. Finally, the identified research gaps and prospects for the integration of LLM and DT are outlined and discussed. The research outcomes of this paper highlight the potential of LLM to augment DT capabilities through improved construction and operation, enhanced cloud-edge collaboration, and sophisticated data analytics, ultimately promoting industrial practices that are both efficient and aligned with human-centric and sustainability principles in Industry 5.0.}
}
@article{VISALLI2025105456,
title = {Can natural language processing or large language models replace human operators for pre-processing word and sentence-based free comments sensory evaluation data?},
journal = {Food Quality and Preference},
volume = {127},
pages = {105456},
year = {2025},
issn = {0950-3293},
doi = {https://doi.org/10.1016/j.foodqual.2025.105456},
url = {https://www.sciencedirect.com/science/article/pii/S095032932500031X},
author = {Michel Visalli and Ronan Symoneaux and Cécile Mursic and Margaux Touret and Flore Lourtioux and Kipédène Coulibaly and Benjamin Mahieu},
keywords = {Open ended questions, ChatGPT, Textual data, Consumer test, Method comparison, Drivers of liking},
abstract = {The free comment (FC) method enables the collection of insights on products based on consumers' natural language. The primary drawback is the need for extensive data pre-processing. This study compared the results of three data pre-processing techniques applied to FC data related to the perception of six madeleines by two panels of 100 consumers: manual pre-processing by four human experts, automated pre-processing by an expert system, and automated pre-processing by the large language model ChatGPT. Two modes of data collection were used: responses only with words or short expressions (“FC words”), or responses based on complete sentences (“FC sentences”). Various indicators (number of words extracted, number of concepts retained, pre-processing time, level of repeatability/discrimination/stability of findings) were computed and compared between data collection modes and pre-processing techniques. It was shown that the automated systems performed correctly with FC words; however, they were less effective at extracting relevant words from FC sentences. The findings from statistical analyses following automated pre-processing were less repeatable and discriminative compared to those from the most proficient human operators. It was also demonstrated that, beyond the overall differences between products, the pre-processing of FC data can be a major source of non-reproducibility in findings, depending on the operators and the level of detail they consider when extracting information. Finally, the advantages and disadvantages of each pre-processing technique were summarized, along with several recommendations for pre-processing and analysing FC data at the appropriate level of granularity to draw robust conclusions.}
}
@article{SIVARAJKUMAR2024,
title = {An Empirical Evaluation of Prompting Strategies for Large Language Models in Zero-Shot Clinical Natural Language Processing: Algorithm Development and Validation Study},
journal = {JMIR Medical Informatics},
volume = {12},
year = {2024},
issn = {2291-9694},
doi = {https://doi.org/10.2196/55318},
url = {https://www.sciencedirect.com/science/article/pii/S2291969424000383},
author = {Sonish Sivarajkumar and Mark Kelley and Alyssa Samolyk-Mazzanti and Shyam Visweswaran and Yanshan Wang},
keywords = {large language model, LLM, LLMs, natural language processing, NLP, in-context learning, prompt engineering, evaluation, zero-shot, few shot, prompting, GPT, language model, language, models, machine learning, clinical data, clinical information, extraction, BARD, Gemini, LLaMA-2, heuristic, prompt, prompts, ensemble},
abstract = {Background
Large language models (LLMs) have shown remarkable capabilities in natural language processing (NLP), especially in domains where labeled data are scarce or expensive, such as the clinical domain. However, to unlock the clinical knowledge hidden in these LLMs, we need to design effective prompts that can guide them to perform specific clinical NLP tasks without any task-specific training data. This is known as in-context learning, which is an art and science that requires understanding the strengths and weaknesses of different LLMs and prompt engineering approaches.
Objective
The objective of this study is to assess the effectiveness of various prompt engineering techniques, including 2 newly introduced types—heuristic and ensemble prompts, for zero-shot and few-shot clinical information extraction using pretrained language models.
Methods
This comprehensive experimental study evaluated different prompt types (simple prefix, simple cloze, chain of thought, anticipatory, heuristic, and ensemble) across 5 clinical NLP tasks: clinical sense disambiguation, biomedical evidence extraction, coreference resolution, medication status extraction, and medication attribute extraction. The performance of these prompts was assessed using 3 state-of-the-art language models: GPT-3.5 (OpenAI), Gemini (Google), and LLaMA-2 (Meta). The study contrasted zero-shot with few-shot prompting and explored the effectiveness of ensemble approaches.
Results
The study revealed that task-specific prompt tailoring is vital for the high performance of LLMs for zero-shot clinical NLP. In clinical sense disambiguation, GPT-3.5 achieved an accuracy of 0.96 with heuristic prompts and 0.94 in biomedical evidence extraction. Heuristic prompts, alongside chain of thought prompts, were highly effective across tasks. Few-shot prompting improved performance in complex scenarios, and ensemble approaches capitalized on multiple prompt strengths. GPT-3.5 consistently outperformed Gemini and LLaMA-2 across tasks and prompt types.
Conclusions
This study provides a rigorous evaluation of prompt engineering methodologies and introduces innovative techniques for clinical information extraction, demonstrating the potential of in-context learning in the clinical domain. These findings offer clear guidelines for future prompt-based clinical NLP research, facilitating engagement by non-NLP experts in clinical NLP advancements. To the best of our knowledge, this is one of the first works on the empirical evaluation of different prompt engineering approaches for clinical NLP in this era of generative artificial intelligence, and we hope that it will inspire and inform future research in this area.}
}
@article{KOSONOCKY20241150,
title = {Mining patents with large language models elucidates the chemical function landscape††Electronic supplementary information (ESI) available. See DOI: https://doi.org/10.1039/d4dd00011k},
journal = {Digital Discovery},
volume = {3},
number = {6},
pages = {1150-1159},
year = {2024},
issn = {2635-098X},
doi = {https://doi.org/10.1039/d4dd00011k},
url = {https://www.sciencedirect.com/science/article/pii/S2635098X24000925},
author = {Clayton W. Kosonocky and Claus O. Wilke and Edward M. Marcotte and Andrew D. Ellington},
abstract = {The fundamental goal of small molecule discovery is to generate chemicals with target functionality. While this often proceeds through structure-based methods, we set out to investigate the practicality of methods that leverage the extensive corpus of chemical literature. We hypothesize that a sufficiently large text-derived chemical function dataset would mirror the actual landscape of chemical functionality. Such a landscape would implicitly capture complex physical and biological interactions given that chemical function arises from both a molecule's structure and its interacting partners. To evaluate this hypothesis, we built a Chemical Function (CheF) dataset of patent-derived functional labels. This dataset, comprising 631 K molecule–function pairs, was created using an LLM- and embedding-based method to obtain 1.5 K unique functional labels for approximately 100 K randomly selected molecules from their corresponding 188 K unique patents. We carry out a series of analyses demonstrating that the CheF dataset contains a semantically coherent textual representation of the functional landscape congruent with chemical structural relationships, thus approximating the actual chemical function landscape. We then demonstrate through several examples that this text-based functional landscape can be leveraged to identify drugs with target functionality using a model able to predict functional profiles from structure alone. We believe that functional label-guided molecular discovery may serve as an alternative approach to traditional structure-based methods in the pursuit of designing novel functional molecules.}
}
@article{ZHANG2025126651,
title = {SecLMNER: A framework for enhanced named entity recognition in multi-source cybersecurity data using large language models},
journal = {Expert Systems with Applications},
volume = {271},
pages = {126651},
year = {2025},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2025.126651},
url = {https://www.sciencedirect.com/science/article/pii/S0957417425002738},
author = {Yunlong Zhang and Jingju Liu and Xiaofeng Zhong and Lei Wu},
keywords = {Cybersecurity, Named entity recognition, Large language models, Open-source intelligence},
abstract = {In the realm of cybersecurity, Named Entity Recognition (NER) has predominantly centered on cyber threat intelligence. However, cybersecurity-related information often resides in open-source intelligence and unprocessed tool outputs. With structured, semi-structured, and unstructured text data coexisting, traditional BERT-based NER methods encounter challenges in handling diverse data formats and technical terminology richness. To tackle these obstacles, this paper presents a framework that integrates large language models for NER in multi-source cybersecurity data. Leveraging decoder-based large language models’ generative capabilities, the framework intelligently crafts natural language segments containing data information for enhanced adaptability. Subsequently, the SecureBERT model, excelling as the premier open-source solution for NER in the network security domain, leverages a pre-trained encoder tailored for cybersecurity text to proficiently detect diverse entities and associated information embedded within natural language segments. The experimental findings demonstrate that our proposed method outperforms traditional BERT and its variants in fine-tuning across five distinct cybersecurity text data sources. The results reveal that by integrating three generative language models, each with parameters under 10 billion, we achieve an improvement in Recall ranging from 8.1% to 21.81% over the state-of-the-art open-source SecureBERT, and an increase in F1 score from 6.19% to 16.7%. Moreover, with the enhancements to our framework, the NER performance can match that of open-source large-parameter language models.}
}
@article{PANDEY2025104244,
title = {Generating product reviews from aspect-based ratings using large language models},
journal = {Journal of Retailing and Consumer Services},
volume = {84},
pages = {104244},
year = {2025},
issn = {0969-6989},
doi = {https://doi.org/10.1016/j.jretconser.2025.104244},
url = {https://www.sciencedirect.com/science/article/pii/S0969698925000232},
author = {Prince Pandey and Jyoti Prakash Singh},
keywords = {E-commerce, GPT, LLM, Review, Feedback},
abstract = {The rapid growth of e-commerce has made textual reviews and product ratings crucial for consumer purchase decisions. However, the overall Likert scale rating of the product does not convey any information about major aspects of a product. In contrast, many textual reviews often lack detailing of various aspects of the product, leading to incomplete feedback. This paper proposes a framework that generates detailed textual reviews from user-provided ratings on various aspects of a product using large language models (LLMs). Our approach enhances the online product review system by integrating specific feedback from structured ratings, resulting in more detailed and reliable product reviews. Our results show that AI-generated reviews exhibit high readability, coherence, relevance, and informativeness, rivaling human-written reviews to the extent that distinguishing between the two proves challenging, even for human evaluators. This research contributes to develop more accurate and comprehensive review systems, enhancing the overall quality and usefulness of e-commerce reviews and empowering consumers to make informed purchasing decisions. The proposed framework offers a valuable tool for businesses and e-commerce platforms to improve product reviews, enhance customer satisfaction, and increase sales.}
}
@article{KOSTOPOLUS2025102894,
title = {Student use of generative AI as a composing process supplement: Concerns for intellectual property and academic honesty},
journal = {Computers and Composition},
volume = {75},
pages = {102894},
year = {2025},
issn = {8755-4615},
doi = {https://doi.org/10.1016/j.compcom.2024.102894},
url = {https://www.sciencedirect.com/science/article/pii/S8755461524000707},
author = {Emma Kostopolus},
keywords = {Artificial intelligence, Intellectual property, Academic honesty, Multimodality},
abstract = {This article discusses the nuanced challenges of using Generative Artificial Intelligence in multimodal compositions while maintaining an ethical adherence to ideas of academic honesty and intellectual property. Through examining hypothetical scenarios, we can see that multimodality complicates the concept of “fair use” in academic contexts, since image or audio generation via AI functions differently than text generated by a Large Language Model. In thinking through the case studies, the article presents an argument for how educators can still use Generative AI in their multimodal composition assignments, through teaching students to us it as a process supplement and to always be critically aware of their citational responsibilities. This understanding of Generative AI use is placed in conversation with our understanding of intellectual property law as relates to both the classroom and broader digital composing environments, to better prepare students to create texts in their future careers.}
}
@article{LUO2024100488,
title = {Large language model-based code generation for the control of construction assembly robots: A hierarchical generation approach},
journal = {Developments in the Built Environment},
volume = {19},
pages = {100488},
year = {2024},
issn = {2666-1659},
doi = {https://doi.org/10.1016/j.dibe.2024.100488},
url = {https://www.sciencedirect.com/science/article/pii/S2666165924001698},
author = {Hanbin Luo and Jianxin Wu and Jiajing Liu and Maxwell Fordjour Antwi-Afari},
keywords = {Construction assembly robot, Large language model, Code generation, , Human–robot collaboration},
abstract = {Offline programming (OLP) is a mainstream approach for controlling assembly robots at construction sites. However, existing methods are tailored to specific assembly tasks and workflows, and thus lack flexibility. Additionally, the emerging large language model (LLM)-based OLP cannot effectively handle the code logic of robot programming. Thus, this paper addresses the question: How can robot control programs be generated effectively and accurately for diverse construction assembly tasks using LLM techniques? This paper describes a closed user-on-the-loop control framework for construction assembly robots based on LLM techniques. A hierarchical strategy to generate robot control programs is proposed to logically integrate code generation at high and low levels. Additionally, customized application programming interfaces and a chain of action are combined to enhance the LLM's understanding of assembly action logic. An assembly task set was designed to evaluate the feasibility and reliability of the proposed approach. The results show that the proposed approach (1) is widely applicable to diverse assembly tasks, and (2) can improve the quality of the generated code by decreasing the number of errors. Our approach facilitates the automation of construction assembly tasks by simplifying the robot control process.}
}
@article{KUMAR2024100308,
title = {AOPWIKI-EXPLORER: An interactive graph-based query engine leveraging large language models},
journal = {Computational Toxicology},
volume = {30},
pages = {100308},
year = {2024},
issn = {2468-1113},
doi = {https://doi.org/10.1016/j.comtox.2024.100308},
url = {https://www.sciencedirect.com/science/article/pii/S2468111324000100},
author = {Saurav Kumar and Deepika Deepika and Karin Slater and Vikas Kumar},
keywords = {Adverse outcome pathway, Large language model, Graph database, Risk assessment, Artificial intelligence, Data integration, Information retrieval, Information extraction},
abstract = {Adverse Outcome Pathways (AOPs) provide a basis for non-animal testing, by outlining the cascade of molecular and cellular events initiated upon stressor exposure, leading to adverse effects. In recent years, the scientific community has shown interest in developing AOPs through crowdsourcing, with the results archived in the AOP-Wiki: a centralized repository coordinated by the OECD, hosting nearly 512 AOPs (April, 2023). However, the AOP-Wiki platform currently lacks a versatile querying system, which hinders developers' exploration of the AOP network and impedes its practical use in risk assessment. This work proposes to unleash the full potential of the AOP-Wiki archive by adapting its data into a Labelled Property Graph (LPG) schema. Additionally, the tool offers a visual network query interface for both database-specific and natural language queries, facilitating the retrieval and analysis of graph data. The multi-query interface allows non-technical users to construct flexible queries, thereby enhancing the potential for AOP exploration. By reducing the time and technical requirements, the present query engine enhances the practical utilization of the valuable data within AOP-Wiki. To evaluate the platform, a case study is presented with three levels of use-case scenarios (simple, moderate, and complex queries). AOPWIKI-EXPLORER is freely available on GitHub (https://github.com/Crispae/AOPWiki_Explorer) for wider community reach and further enhancement.}
}
@article{CHIZHIKOVA2025108515,
title = {Automatic TNM staging of colorectal cancer radiology reports using pre-trained language models},
journal = {Computer Methods and Programs in Biomedicine},
volume = {259},
pages = {108515},
year = {2025},
issn = {0169-2607},
doi = {https://doi.org/10.1016/j.cmpb.2024.108515},
url = {https://www.sciencedirect.com/science/article/pii/S016926072400508X},
author = {Mariia Chizhikova and Pilar López-Úbeda and Teodoro Martín-Noguerol and Manuel C. Díaz-Galiano and L. Alfonso Ureña-López and Antonio Luna and M. Teresa Martín-Valdivia},
keywords = {Colorectal cancer staging, NLP, TNM, Text classification, Transformer, Language models},
abstract = {Background and Objective:
Colorectal cancer is one of the major causes of cancer death worldwide. Essential for prognosis and treatment planning, TNM staging offers critical insights into the advancement of colorectal cancer. However, manual TNM staging from colon magnetic resonance imaging (MRI) is a laborious and error prone process. This study introduces an automated text classification system for TNM staging of colon MRI images in Spanish.
Methods:
A dataset of 1319 Spanish colon MRI reports was collected and manually labeled with TNM staging. In order to automate the task of TNM staging, a multimodal system was proposed. The system is based on RoBERTa language model pre-trained on a combination of biomedical and clinical Spanish language corpora and uses Natural Language Processing (NLP) techniques to extract relevant categorical and numerical features from MRI reports.
Results:
The performance of the system was evaluated using different metrics and the results obtained are very promising: the best performance among the proposed systems reached 0.7464, 0.8792 and 0.6776 of macro F1-score for T, N and M respectively.
Conclusions:
This study demonstrates the feasibility of using a language model for automatic TNM staging based on Spanish clinical reports of colorectal cancer patients. The proposed system can be a useful tool to improve the efficiency and accuracy of colorectal cancer diagnosis.}
}
@article{CADEDDU2024108166,
title = {A comparative analysis of knowledge injection strategies for large language models in the scholarly domain},
journal = {Engineering Applications of Artificial Intelligence},
volume = {133},
pages = {108166},
year = {2024},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2024.108166},
url = {https://www.sciencedirect.com/science/article/pii/S0952197624003245},
author = {Andrea Cadeddu and Alessandro Chessa and Vincenzo {De Leo} and Gianni Fenu and Enrico Motta and Francesco Osborne and Diego {Reforgiato Recupero} and Angelo Salatino and Luca Secchi},
keywords = {Knowledge injection, Knowledge graphs, Large language models, Transformers, BERT, Classification, Natural language processing},
abstract = {In recent years, transformer-based models have emerged as powerful tools for natural language processing tasks, demonstrating remarkable performance in several domains. However, they still present significant limitations. These shortcomings become more noticeable when dealing with highly specific and complex concepts, particularly within the scientific domain. For example, transformer models have particular difficulties when processing scientific articles due to the domain-specific terminologies and sophisticated ideas often encountered in scientific literature. To overcome these challenges and further enhance the effectiveness of transformers in specific fields, researchers have turned their attention to the concept of knowledge injection. Knowledge injection is the process of incorporating outside knowledge into transformer models to improve their performance on certain tasks. In this paper, we present a comprehensive study of knowledge injection strategies for transformers within the scientific domain. Specifically, we provide a detailed overview and comparative assessment of four primary methodologies, evaluating their efficacy in the task of classifying scientific articles. For this purpose, we constructed a new benchmark including both 24K labelled papers and a knowledge graph of 9.2K triples describing pertinent research topics. We also developed a full codebase to easily re-implement all knowledge injection strategies in different domains. A formal evaluation indicates that the majority of the proposed knowledge injection methodologies significantly outperform the baseline established by Bidirectional Encoder Representations from Transformers.}
}
@article{BZDOK2024698,
title = {Data science opportunities of large language models for neuroscience and biomedicine},
journal = {Neuron},
volume = {112},
number = {5},
pages = {698-717},
year = {2024},
issn = {0896-6273},
doi = {https://doi.org/10.1016/j.neuron.2024.01.016},
url = {https://www.sciencedirect.com/science/article/pii/S0896627324000424},
author = {Danilo Bzdok and Andrew Thieme and Oleksiy Levkovskyy and Paul Wren and Thomas Ray and Siva Reddy},
abstract = {Large language models (LLMs) are a new asset class in the machine-learning landscape. Here we offer a primer on defining properties of these modeling techniques. We then reflect on new modes of investigation in which LLMs can be used to reframe classic neuroscience questions to deliver fresh answers. We reason that LLMs have the potential to (1) enrich neuroscience datasets by adding valuable meta-information, such as advanced text sentiment, (2) summarize vast information sources to overcome divides between siloed neuroscience communities, (3) enable previously unthinkable fusion of disparate information sources relevant to the brain, (4) help deconvolve which cognitive concepts most usefully grasp phenomena in the brain, and much more.}
}
@article{GUO2024,
title = {Large Language Models for Mental Health Applications: Systematic Review},
journal = {JMIR Mental Health},
volume = {11},
year = {2024},
issn = {2368-7959},
doi = {https://doi.org/10.2196/57400},
url = {https://www.sciencedirect.com/science/article/pii/S2368795924001173},
author = {Zhijun Guo and Alvina Lai and Johan H Thygesen and Joseph Farrington and Thomas Keen and Kezhi Li},
keywords = {large language models, mental health, digital health care, ChatGPT, Bidirectional Encoder Representations from Transformers, BERT},
abstract = {Background
Large language models (LLMs) are advanced artificial neural networks trained on extensive datasets to accurately understand and generate natural language. While they have received much attention and demonstrated potential in digital health, their application in mental health, particularly in clinical settings, has generated considerable debate.
Objective
This systematic review aims to critically assess the use of LLMs in mental health, specifically focusing on their applicability and efficacy in early screening, digital interventions, and clinical settings. By systematically collating and assessing the evidence from current studies, our work analyzes models, methodologies, data sources, and outcomes, thereby highlighting the potential of LLMs in mental health, the challenges they present, and the prospects for their clinical use.
Methods
Adhering to the PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) guidelines, this review searched 5 open-access databases: MEDLINE (accessed by PubMed), IEEE Xplore, Scopus, JMIR, and ACM Digital Library. Keywords used were (mental health OR mental illness OR mental disorder OR psychiatry) AND (large language models). This study included articles published between January 1, 2017, and April 30, 2024, and excluded articles published in languages other than English.
Results
In total, 40 articles were evaluated, including 15 (38%) articles on mental health conditions and suicidal ideation detection through text analysis, 7 (18%) on the use of LLMs as mental health conversational agents, and 18 (45%) on other applications and evaluations of LLMs in mental health. LLMs show good effectiveness in detecting mental health issues and providing accessible, destigmatized eHealth services. However, assessments also indicate that the current risks associated with clinical use might surpass their benefits. These risks include inconsistencies in generated text; the production of hallucinations; and the absence of a comprehensive, benchmarked ethical framework.
Conclusions
This systematic review examines the clinical applications of LLMs in mental health, highlighting their potential and inherent risks. The study identifies several issues: the lack of multilingual datasets annotated by experts, concerns regarding the accuracy and reliability of generated content, challenges in interpretability due to the “black box” nature of LLMs, and ongoing ethical dilemmas. These ethical concerns include the absence of a clear, benchmarked ethical framework; data privacy issues; and the potential for overreliance on LLMs by both physicians and patients, which could compromise traditional medical practices. As a result, LLMs should not be considered substitutes for professional mental health services. However, the rapid development of LLMs underscores their potential as valuable clinical aids, emphasizing the need for continued research and development in this area.
Trial Registration
PROSPERO CRD42024508617; https://www.crd.york.ac.uk/prospero/display_record.php?RecordID=508617}
}
@article{ZHANG2024100549,
title = {Automatic bridge inspection database construction through hybrid information extraction and large language models},
journal = {Developments in the Built Environment},
volume = {20},
pages = {100549},
year = {2024},
issn = {2666-1659},
doi = {https://doi.org/10.1016/j.dibe.2024.100549},
url = {https://www.sciencedirect.com/science/article/pii/S2666165924002308},
author = {Chenhong Zhang and Xiaoming Lei and Ye Xia and Limin Sun},
keywords = {Bridge inspection data, Natural language processing, Information extraction, Large languge model, Pseudo label},
abstract = {Regular bridge inspections generate extensive reports that, while critical for maintenance, often remain underutilized due to their unstructured format. Traditional information extraction methods depend on intricate labeling systems that commonly require time-consuming and labor-intensive labeling. This paper presents a novel bridge inspection database construction method leveraging LLM-assisted information extraction. First, we introduce the pseudo-labelling method using a closed-source LLM to generate high-quality data. Then we propose the hybrid extraction pipeline to extract relevant information segments and process them by a generation-based IE model, fine-tuned on pseudo-labeled data. Finally, the extracted data is used to construct the bridge inspection database. The proposed method, validated with real-world data, not only demonstrates higher extraction precision than the closed-source LLM used for pseudo-labeling but also outperforms traditional methods in both data preparation time and extraction accuracy. This approach provides a scalable solution for more proactive and data-driven bridge maintenance strategies.}
}
@article{MICHELET2024301683,
title = {ChatGPT, Llama, can you write my report? An experiment on assisted digital forensics reports written using (local) large language models},
journal = {Forensic Science International: Digital Investigation},
volume = {48},
pages = {301683},
year = {2024},
note = {DFRWS EU 2024 - Selected Papers from the 11th Annual Digital Forensics Research Conference Europe},
issn = {2666-2817},
doi = {https://doi.org/10.1016/j.fsidi.2023.301683},
url = {https://www.sciencedirect.com/science/article/pii/S2666281723002020},
author = {Gaëtan Michelet and Frank Breitinger},
keywords = {Digital forensics investigation, Local large language models, ChatGPT, Report automation, Assisted report writing},
abstract = {Generative AIs, especially Large Language Models (LLMs) such as ChatGPT or Llama, have advanced significantly, positioning them as valuable tools for digital forensics. While initial studies have explored the potential of ChatGPT in the context of investigations, the question of to what extent LLMs can assist the forensic report writing process remains unresolved. To answer the question, this article first examines forensic reports with the goal of generalization (e.g., finding the ‘average structure’ of a report). We then evaluate the strengths and limitations of LLMs for generating the different parts of the forensic report using a case study. This work thus provides valuable insights into the automation of report writing, a critical facet of digital forensics investigations. We conclude that combined with thorough proofreading and corrections, LLMs may assist practitioners during the report writing process but at this point cannot replace them.}
}
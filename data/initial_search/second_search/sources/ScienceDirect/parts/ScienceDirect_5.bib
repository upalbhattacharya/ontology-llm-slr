@article{LI2025191,
title = {An interactive address matching method based on a graph attention mechanism},
journal = {International Journal of Cognitive Computing in Engineering},
volume = {6},
pages = {191-200},
year = {2025},
issn = {2666-3074},
doi = {https://doi.org/10.1016/j.ijcce.2024.12.003},
url = {https://www.sciencedirect.com/science/article/pii/S266630742400055X},
author = {Ming Li and Jialin Su and Zhiyu Song and Juping Qiu and Yongping Lin},
keywords = {Address matching, Interactive address matching graph attention model, Attention-based feature interaction method, Directed graph},
abstract = {Problem:
Modernizing and standardizing place names and addresses is a key challenge in the development of smart cities.
Purpose:
This paper proposes a solution to address matching challenges, such as incomplete descriptions, reversed word order, and the diverse descriptions often found in Chinese addresses.
Method:
Leveraging the hierarchical structure of Chinese addresses, this study introduces the interactive address matching graph attention model (IAMGAM). In the IAMGAM, an attention-based feature interaction method (AFIM) is employed. To reflect the hierarchical nature of address elements, a directed graph is used to model the address data, and the model is trained and tested using a graph attention mechanism.
Results:
Experiments demonstrate that the IAMGAM achieves an accuracy and F1-score of 99.61%. Compared with the existing address matching methods, the IAMGAM improves the accuracy by 0.66% to 2.57%, and the F1-score by 0.68% to 2.55%, outperforming baseline models. Additionally, ablation experiments confirm the effectiveness of each component within the model. Furthermore, when fine-tuned using ChatGLM2-6B, the results show that the IAMGAM still outperforms ChatGLM2-6B.
Conclusion:
IAMGAM demonstrates excellent performance in Chinese address matching tasks, and the Large Language Model (LLM)-based methods, such as ChatGLM2-6B, show great potential for future development in this area.}
}
@article{WANG2025112351,
title = {MPLinker: Multi-template Prompt-tuning with adversarial training for Issue–commit Link recovery},
journal = {Journal of Systems and Software},
volume = {223},
pages = {112351},
year = {2025},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2025.112351},
url = {https://www.sciencedirect.com/science/article/pii/S0164121225000196},
author = {Bangchao Wang and Yang Deng and Ruiqi Luo and Peng Liang and Tingting Bi},
keywords = {Prompt-tuning, Issue–commit Link recovery, Pre-trained language model, Natural language processing},
abstract = {In recent years, the pre-training, prompting and prediction paradigm, known as prompt-tuning, has achieved significant success in Natural Language Processing (NLP). Issue–commit Link Recovery (ILR) in Software Traceability (ST) plays an important role in improving the reliability, quality, and security of software systems. The current ILR methods convert the ILR into a classification task using pre-trained language models (PLMs) and dedicated neural networks. These methods do not fully utilize the semantic information embedded in PLMs, failing to achieve acceptable performance. To address this limitation, we introduce a novel paradigm: Multi-template Prompt-tuning with adversarial training for issue–commit Link recovery (MPLinker). MPLinker redefines the ILR task as a cloze task via template-based prompt-tuning and incorporates adversarial training to enhance model generalization and reduce overfitting. We evaluated MPLinker on six open-source projects using a comprehensive set of performance metrics. The experiment results demonstrate that MPLinker achieves an average F1-score of 96.10%, Precision of 96.49%, Recall of 95.92%, MCC of 94.04%, AUC of 96.05%, and ACC of 98.15%, significantly outperforming existing state-of-the-art methods. Overall, MPLinker improves the performance and generalization of ILR models and introduces innovative concepts and methods for ILR. The replication package for MPLinker is available at https://github.com/WTU-intelligent-software-development/MPLinker.}
}
@article{CHEN2024105158,
title = {Augmented reality, deep learning and vision-language query system for construction worker safety},
journal = {Automation in Construction},
volume = {157},
pages = {105158},
year = {2024},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2023.105158},
url = {https://www.sciencedirect.com/science/article/pii/S0926580523004181},
author = {Haosen Chen and Lei Hou and Shaoze Wu and Guomin Zhang and Yang Zou and Sungkon Moon and Muhammed Bhuiyan},
keywords = {Construction safety, Deep learning, Vision-language models, Augmented reality},
abstract = {Low situational awareness contributes to safety incidents in construction. Existing Deep Learning (DL)-based applications lack the capability to provide context-specific and interactive feedback that is essential for workers to fully understand their surrounding environments. This paper proposes the Visual Construction Safety Query (VCSQ) system. The system encompasses real-time Image Captioning (IC), safety-centric Visual Question Answering (VQA), and keyword-based Image-Text Retrieval (ITR), integrated with head-mounted Augmented Reality (AR) devices. System validation includes benchmarks and real-world images. The ITR module posted high recall rates of 0.801 and 0.835 for Recall@5 and @10. The VQA module achieved an 89.7% accuracy rate, and the IC module had a SPICE score of 0.449. Feasibility tests and surveys confirmed the system's practical advantages in different construction scenarios. This study establishes an integration roadmap adaptable to future advancements in interactive DL and immersive AR.}
}
@article{SINGLA2024,
title = {Developing a Chatbot to Support Individuals With Neurodevelopmental Disorders: Tutorial},
journal = {Journal of Medical Internet Research},
volume = {26},
year = {2024},
issn = {1438-8871},
doi = {https://doi.org/10.2196/50182},
url = {https://www.sciencedirect.com/science/article/pii/S1438887124003224},
author = {Ashwani Singla and Ritvik Khanna and Manpreet Kaur and Karen Kelm and Osmar Zaiane and Cory Scott Rosenfelt and Truong An Bui and Navid Rezaei and David Nicholas and Marek Z Reformat and Annette Majnemer and Tatiana Ogourtsova and Francois Bolduc},
keywords = {chatbot, user interface, knowledge graph, neurodevelopmental disability, autism, intellectual disability, attention-deficit/hyperactivity disorder},
abstract = {Families of individuals with neurodevelopmental disabilities or differences (NDDs) often struggle to find reliable health information on the web. NDDs encompass various conditions affecting up to 14% of children in high-income countries, and most individuals present with complex phenotypes and related conditions. It is challenging for their families to develop literacy solely by searching information on the internet. While in-person coaching can enhance care, it is only available to a minority of those with NDDs. Chatbots, or computer programs that simulate conversation, have emerged in the commercial sector as useful tools for answering questions, but their use in health care remains limited. To address this challenge, the researchers developed a chatbot named CAMI (Coaching Assistant for Medical/Health Information) that can provide information about trusted resources covering core knowledge and services relevant to families of individuals with NDDs. The chatbot was developed, in collaboration with individuals with lived experience, to provide information about trusted resources covering core knowledge and services that may be of interest. The developers used the Django framework (Django Software Foundation) for the development and used a knowledge graph to depict the key entities in NDDs and their relationships to allow the chatbot to suggest web resources that may be related to the user queries. To identify NDD domain–specific entities from user input, a combination of standard sources (the Unified Medical Language System) and other entities were used which were identified by health professionals as well as collaborators. Although most entities were identified in the text, some were not captured in the system and therefore went undetected. Nonetheless, the chatbot was able to provide resources addressing most user queries related to NDDs. The researchers found that enriching the vocabulary with synonyms and lay language terms for specific subdomains enhanced entity detection. By using a data set of numerous individuals with NDDs, the researchers developed a knowledge graph that established meaningful connections between entities, allowing the chatbot to present related symptoms, diagnoses, and resources. To the researchers’ knowledge, CAMI is the first chatbot to provide resources related to NDDs. Our work highlighted the importance of engaging end users to supplement standard generic ontologies to named entities for language recognition. It also demonstrates that complex medical and health-related information can be integrated using knowledge graphs and leveraging existing large datasets. This has multiple implications: generalizability to other health domains as well as reducing the need for experts and optimizing their input while keeping health care professionals in the loop. The researchers' work also shows how health and computer science domains need to collaborate to achieve the granularity needed to make chatbots truly useful and impactful.}
}
@article{JAHANIYEKTA2024100078,
title = {The general intelligence of GPT–4, its knowledge diffusive and societal influences, and its governance},
journal = {Meta-Radiology},
volume = {2},
number = {2},
pages = {100078},
year = {2024},
issn = {2950-1628},
doi = {https://doi.org/10.1016/j.metrad.2024.100078},
url = {https://www.sciencedirect.com/science/article/pii/S2950162824000316},
author = {Mohammad Mahdi {Jahani Yekta}},
keywords = {GPT–4, Artificial general intelligence, Knowledge diffusion, Interpretability and explainability, Societal influences, Governance},
abstract = {Recent breakthroughs in artificial intelligence (AI) research include advancements in natural language processing (NLP) achieved by large language models (LLMs), and; in particular, generative pre–trained transformer (GPT) architectures. The latest GPT developed by OpenAI, GPT–4, has shown remarkable intelligence across various domains and tasks. It exhibits capabilities in abstraction, comprehension, vision, computer coding, mathematics, and more, suggesting it to be a significant step towards artificial general intelligence (AGI), a level of AI that possesses capabilities similar to human intelligence. This paper explores this AGI, its knowledge diffusive and societal influences, and its governance. In addition to coverage of the major associated topics studied in the literature, and making up for their loopholes, we scrutinize how GPT-4 can facilitate the diffusion of knowledge across different areas of science by promoting their interpretability and explainability (IE) to inexperts. Where applicable, the topics are also accompanied by their specific potential implications on medical imaging.}
}
@article{RABBI2024105443,
title = {AI integration in construction safety: Current state, challenges, and future opportunities in text, vision, and audio based applications},
journal = {Automation in Construction},
volume = {164},
pages = {105443},
year = {2024},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2024.105443},
url = {https://www.sciencedirect.com/science/article/pii/S0926580524001791},
author = {Ahmed Bin Kabir Rabbi and Idris Jeelani},
keywords = {Artificial intelligence, Construction safety, Safety management, Automated safety},
abstract = {High occupational injury and fatality rate in the construction industry is a serious global concern. Recognizing AI as a solution to enhance safety performance, this study reviews 153 papers to assess and categorize current AI applications in construction, focusing on text, visual, and audio data, while also identifying challenges and future research opportunities. Real-time monitoring, hazard detection, and information extraction are identified as key areas where AI is applied, with a notable reliance on deep neural networks, object recognition, and Natural Language Processing. The review highlights major challenges, including the need for high-quality data management, semantic feature representation, and occluded object detection. Additionally, it underscores the untapped potential of audio-based AI and the advancements possible with Large Language Models for text interpretation. The findings emphasize the need for integrated, multi-faceted AI systems and advocate for responsible AI deployment to mitigate safety risks on construction sites.}
}
@article{BIBI2024101865,
title = {Enhancing source code retrieval with joint Bi-LSTM-GNN architecture: A comparative study with ChatGPT-LLM},
journal = {Journal of King Saud University - Computer and Information Sciences},
volume = {36},
number = {2},
pages = {101865},
year = {2024},
issn = {1319-1578},
doi = {https://doi.org/10.1016/j.jksuci.2023.101865},
url = {https://www.sciencedirect.com/science/article/pii/S1319157823004196},
author = {Nazia Bibi and Ayesha Maqbool and Tauseef Rana},
keywords = {Code reuse, Recommendation systems, Code recommendation, Joint model, Source code retrieval, Deep learning, LSTM, GNN, Bi-directional LSTM},
abstract = {Retrieving relevant source code from large repositories is a significant and ongoing challenge in the field of software engineering, primarily due to the vast and ever-expanding amount of available code. Existing deep learning methods, although effective to some extent, exhibit limitations in capturing the intricate and complex structural information embedded within source code, which hinders their ability to provide highly accurate retrieval results. This study endeavors to tackle this prominent issue by introducing a novel and innovative approach known as the Joint Bi-directional LSTM and Graph Neural Networks (JBLG) model for source code retrieval. The central aim is to harness the combined strengths and capabilities of Bi-directional Long Short-Term Memory (LSTM) networks and Graph Neural Networks (GNNs) to significantly enhance the model’s capacity to capture and interpret the complex structural characteristics intrinsic to source code. The proposed JBLG model employs a unique fusion of Bi-directional LSTM, which excels in capturing sequential and temporal dependencies within code, and GNN, which is adept at modeling the intricate graph structure of the code. By leveraging this hybrid architecture, the model aims to provide a comprehensive and highly effective solution for source code retrieval tasks. To assess the efficacy of the JBLG model, extensive experiments are conducted, and the model’s performance is evaluated against well-established benchmarks, including LSTM, GNN, and ChatGPT, using two diverse datasets: CodeSearchNet and CosBench datasets. These evaluations span multiple programming languages, ensuring a comprehensive and robust assessment of the model’s capabilities. The experimental results indicate that the JBLG model consistently outperforms its counterparts, including Bi-LSTM, GNN, ChatGPT, and DGMS, across various evaluation metrics. the JBLG model showcases an exceptional ability to handle and extract the intricate structural information inherent in source code, resulting in significantly enhanced retrieval accuracy. The JBLG model emerges as a highly promising solution for real-world source code retrieval applications, with the potential to revolutionize the field. The success of this model underscores the importance of combining deep learning techniques like Bi-directional LSTM and GNNs for tackling complex software engineering challenges. Furthermore, future research directions could involve exploring advanced techniques such as attention mechanisms and extending the model’s applicability to other software engineering tasks like code summarization and code completion. The findings of this study are expected to have a lasting impact on the advancement of source code retrieval methodologies.}
}
@article{MAO2024101988,
title = {A survey on semantic processing techniques},
journal = {Information Fusion},
volume = {101},
pages = {101988},
year = {2024},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2023.101988},
url = {https://www.sciencedirect.com/science/article/pii/S1566253523003044},
author = {Rui Mao and Kai He and Xulang Zhang and Guanyi Chen and Jinjie Ni and Zonglin Yang and Erik Cambria},
keywords = {Semantic processing, Word sense disambiguation, Anaphora resolution, Named entity recognition, Concept extraction, Subjectivity detection},
abstract = {Semantic processing is a fundamental research domain in computational linguistics. In the era of powerful pre-trained language models and large language models, the advancement of research in this domain appears to be decelerating. However, the study of semantics is multi-dimensional in linguistics. The research depth and breadth of computational semantic processing can be largely improved with new technologies. In this survey, we analyzed five semantic processing tasks, e.g., word sense disambiguation, anaphora resolution, named entity recognition, concept extraction, and subjectivity detection. We study relevant theoretical research in these fields, advanced methods, and downstream applications. We connect the surveyed tasks with downstream applications because this may inspire future scholars to fuse these low-level semantic processing tasks with high-level natural language processing tasks. The review of theoretical research may also inspire new tasks and technologies in the semantic processing domain. Finally, we compare the different semantic processing techniques and summarize their technical trends, application trends, and future directions.}
}
@article{ZERMATTEN2025621,
title = {Learning transferable land cover semantics for open vocabulary interactions with remote sensing images},
journal = {ISPRS Journal of Photogrammetry and Remote Sensing},
volume = {220},
pages = {621-636},
year = {2025},
issn = {0924-2716},
doi = {https://doi.org/10.1016/j.isprsjprs.2025.01.006},
url = {https://www.sciencedirect.com/science/article/pii/S0924271625000061},
author = {Valérie Zermatten and Javiera Castillo-Navarro and Diego Marcos and Devis Tuia},
keywords = {Land cover mapping, Open vocabulary semantic segmentation, Vision-language model for remote sensing},
abstract = {Why should we confine land cover classes to rigid and arbitrary definitions? Land cover mapping is a central task in remote sensing image processing, but the rigorous class definitions can sometimes restrict the transferability of annotations between datasets. Open vocabulary recognition, i.e. using natural language to define a specific object or pattern in an image, breaks free from predefined nomenclature and offers flexible recognition of diverse categories with a more general image understanding across datasets and labels. The open vocabulary framework opens doors to search for concepts of interest, beyond individual class boundaries. In this work, we propose to use Text As supervision for COntrastive Semantic Segmentation (TACOSS), and we design an open vocabulary semantic segmentation model that extends its capacities beyond that of a traditional model for land cover mapping: In addition to visual pattern recognition, TACOSS leverages the common sense knowledge captured by language models and is capable of interpreting the image at the pixel level, attributing semantics to each pixel and removing the constraints of a fixed set of land cover labels. By learning to match visual representations with text embeddings, TACOSS can transition smoothly from one set of labels to another and enables the interaction with remote sensing images in natural language. Our approach combines a pretrained text encoder with a visual encoder and adopts supervised contrastive learning to align the visual and textual modalities. We explore several text encoders and label representation methods and compare their abilities to encode transferable land cover semantics. The model’s capacity to predict a set of different land cover labels on an unseen dataset is also explored to illustrate the generalization capacities across domains of our approach. Overall, TACOSS is a general method and permits adapting between different sets of land cover labels with minimal computational overhead. Code is publicly available online11https://github.com/eceo-epfl/RS-OVSS..}
}
@article{LI2025103996,
title = {Basis is also explanation: Interpretable Legal Judgment Reasoning prompted by multi-source knowledge},
journal = {Information Processing & Management},
volume = {62},
number = {3},
pages = {103996},
year = {2025},
issn = {0306-4573},
doi = {https://doi.org/10.1016/j.ipm.2024.103996},
url = {https://www.sciencedirect.com/science/article/pii/S0306457324003558},
author = {Shangyuan Li and Shiman Zhao and Zhuoran Zhang and Zihao Fang and Wei Chen and Tengjiao Wang},
keywords = {Legal judgment prediction, Prompt learning, Contrastive learning, Knowledge encoding, Interpretability},
abstract = {The task of Legal Judgment Prediction (LJP) aims to forecast case outcomes by analyzing fact descriptions, playing a pivotal role in enhancing judicial system efficiency and fairness. Existing LJP methods primarily focus on improving representations of fact descriptions to enhance judgment performance. However, these methods typically depend on the superficial case information and neglect the underlying legal basis, resulting in a lack of in-depth reasoning and interpretability in the judgment process of long-tail or confusing cases. Recognizing that the basis for judgments in real-world legal contexts encompasses both factual logic and related legal knowledge, we introduce the interpretable legal judgment reasoning framework with multi-source knowledge prompted. The essence of this framework is to transform the implicit factual logic of cases and external legal knowledge into explicit basis for judgment, aiming to enhance not only the accuracy of judgment predictions but also the interpretability of the reasoning process. Specifically, we design a chain prompt reasoning module that guides a large language model to elucidate factual logic basis through incremental reasoning, aligning the model prior knowledge with task-oriented knowledge in the process. To match the above fact-based information with legal knowledge basis, we propose a contrastive knowledge fusing module to inject external statutes knowledge into the fact description embedding. It pushes away the distance of similar knowledge in the semantic space during the encoding of external knowledge base without manual annotation, thus improving the judgment prediction performance of long-tail and confusing cases. Experimental results on two real datasets indicate that our framework significantly outperforms existing LJP baseline methods in accuracy and interpretability, achieving new state-of-the-art performance. In addition, tests on specially constructed long-tail and confusing case datasets demonstrate that the proposed framework possesses improved generalization abilities for predicting these complex cases.}
}
@article{ASKARIZADE2025125649,
title = {Enhancing rumor detection with data augmentation and generative pre-trained transformer},
journal = {Expert Systems with Applications},
volume = {262},
pages = {125649},
year = {2025},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2024.125649},
url = {https://www.sciencedirect.com/science/article/pii/S0957417424025168},
author = {Mojgan Askarizade},
keywords = {Fake news detection, Finetuned language model, Neural network classifier, Rumor detection, Generative pre-trained transformer, Data augmentation},
abstract = {The advent of social networks has facilitated the rapid dissemination of false information, including rumors, leading to significant societal and individual damages. Extensive research has been dedicated to rumor detection, ranging from machine learning techniques to neural networks. However, the existing methods could not learn the deep concepts of the rumor text to detect the rumor. In addition, imbalanced datasets in the rumor domain reduce the effectiveness of these algorithms. This study addresses this challenge by leveraging the Generative Pre-trained Transformer 2 (GPT-2) model to generate rumor-like texts, thus creating a balanced dataset. Subsequently, a novel approach for classifying rumor texts is proposed by modifying the GPT-2 model. We compare our results with state-of-art machine learning and deep learning methods as well as pre-trained models on the PHEME, Twitter15, and Twitter16 datasets. Our findings demonstrate that the proposed model, implementing advanced artificial intelligence techniques, has improved accuracy and F-measure in the application of detecting rumors compared to previous methods.}
}
@article{ZHU2025109589,
title = {Soft Prompt-tuning with Self-Resource Verbalizer for short text streams},
journal = {Engineering Applications of Artificial Intelligence},
volume = {139},
pages = {109589},
year = {2025},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2024.109589},
url = {https://www.sciencedirect.com/science/article/pii/S0952197624017470},
author = {Yi Zhu and Ye Wang and Yun Li and Jipeng Qiang and Yunhao Yuan},
keywords = {Short text streams, Prompt-tuning, Soft template, Verbalizer, Text classification},
abstract = {Short text streams such as real-time news and search snippets have attained vast amounts of attention and research in recent decades, the characteristics of high generation velocity, feature sparsity, and high ambiguity accentuate both the importance and challenges to language models. However, most of the existing short text stream classification methods can neither automatically select relevant knowledge components for arbitrary samples, nor expand knowledge internally instead of rely on external open knowledge base to address the inherent limitations of short text stream. In this paper, we propose a Soft Prompt-tuning with Self-Resource Verbalizer (SPSV for short) for short text stream classification, the soft prompt with self-resource knowledgeable expansion is conducted for updating label words space to address evolved semantic topics in the data streams. Specifically, the automatic constructed prompt is first generated to instruct the model prediction, which is optimized to address the problem of high velocity and topic drift in short text streams. Then, in each chunk, the projection between category names and label words space, i.e. verbalizer, is updated, which is constructed by internal knowledge expansion from the short text itself. Through comprehensive experiments on four well-known benchmark datasets, we validate the superb performance of our method compared to other short text stream classification and fine-tuning PLMs methods, which achieves up to more than 90% classification accuracy with the counts of data chunk increased.}
}
@article{JIM2024100059,
title = {Recent advancements and challenges of NLP-based sentiment analysis: A state-of-the-art review},
journal = {Natural Language Processing Journal},
volume = {6},
pages = {100059},
year = {2024},
issn = {2949-7191},
doi = {https://doi.org/10.1016/j.nlp.2024.100059},
url = {https://www.sciencedirect.com/science/article/pii/S2949719124000074},
author = {Jamin Rahman Jim and Md Apon Riaz Talukder and Partha Malakar and Md Mohsin Kabir and Kamruddin Nur and M.F. Mridha},
keywords = {Sentiment classification, Text classification, Natural language processing, Emotion detection, Sentiment analysis},
abstract = {Sentiment analysis is a method within natural language processing that evaluates and identifies the emotional tone or mood conveyed in textual data. Scrutinizing words and phrases categorizes them into positive, negative, or neutral sentiments. The significance of sentiment analysis lies in its capacity to derive valuable insights from extensive textual data, empowering businesses to grasp customer sentiments, make informed choices, and enhance their offerings. For the further advancement of sentiment analysis, gaining a deep understanding of its algorithms, applications, current performance, and challenges is imperative. Therefore, in this extensive survey, we began exploring the vast array of application domains for sentiment analysis, scrutinizing them within the context of existing research. We then delved into prevalent pre-processing techniques, datasets, and evaluation metrics to enhance comprehension. We also explored Machine Learning, Deep Learning, Large Language Models and Pre-trained models in sentiment analysis, providing insights into their advantages and drawbacks. Subsequently, we precisely reviewed the experimental results and limitations of recent state-of-the-art articles. Finally, we discussed the diverse challenges encountered in sentiment analysis and proposed future research directions to mitigate these concerns. This extensive review provides a complete understanding of sentiment analysis, covering its models, application domains, results analysis, challenges, and research directions.}
}
@article{NASARIAN2024102412,
title = {Designing interpretable ML system to enhance trust in healthcare: A systematic review to proposed responsible clinician-AI-collaboration framework},
journal = {Information Fusion},
volume = {108},
pages = {102412},
year = {2024},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2024.102412},
url = {https://www.sciencedirect.com/science/article/pii/S1566253524001908},
author = {Elham Nasarian and Roohallah Alizadehsani and U.Rajendra Acharya and Kwok-Leung Tsui},
keywords = {Interpretable ML, AI-based medical devices, Unstructured data, Medical large language models, Human-computer-interaction, Wearable medical devices, Explainable casual analysis, Responsible AI},
abstract = {Background
Artificial intelligence (AI)-based medical devices and digital health technologies, including medical sensors, wearable health trackers, telemedicine, mobile health (mHealth), large language models (LLMs), and digital care twins (DCTs), significantly influence the process of clinical decision support systems (CDSS) in healthcare and medical applications. However, given the complexity of medical decisions, it is crucial that results generated by AI tools not only be correct but also carefully evaluated, understandable, and explainable to end-users, especially clinicians. The lack of interpretability in communicating AI clinical decisions can lead to mistrust among decision-makers and a reluctance to use these technologies.
Objective
This paper systematically reviews the processes and challenges associated with interpretable machine learning (IML) and explainable artificial intelligence (XAI) within the healthcare and medical domains. Its main goals are to examine the processes of IML and XAI, their related methods, applications, and the implementation challenges they pose in digital health interventions (DHIs), particularly from a quality control perspective, to help understand and improve communication between AI systems and clinicians. The IML process is categorized into pre-processing interpretability, interpretable modeling, and post-processing interpretability. This paper aims to foster a comprehensive understanding of the significance of a robust interpretability approach in clinical decision support systems (CDSS) by reviewing related experimental results. The goal is to provide future researchers with insights for creating clinician-AI tools that are more communicable in healthcare decision support systems and offer a deeper understanding of their challenges.
Methods
Our research questions, eligibility criteria, and primary goals were proved using the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) guideline and the PICO (population, intervention, control, and outcomes) method. We systematically searched PubMed, Scopus, and Web of Science databases using sensitive and specific search strings. Subsequently, duplicate papers were removed using EndNote and Covidence. A two-phase selection process was then carried out on Covidence, starting with screening by title and abstract, followed by a full-text appraisal. The Meta Quality Appraisal Tool (MetaQAT) was used to assess the quality and risk of bias. Finally, a standardized data extraction tool was employed for reliable data mining.
Results
The searches yielded 2,241 records, from which 555 duplicate papers were removed. During the title and abstract screening step, 958 papers were excluded, and the full-text review step excluded 482 studies. Subsequently, in quality and risk of bias assessment, 172 papers were removed. 74 publications were selected for data extraction, which formed 10 insightful reviews and 64 related experimental studies.
Conclusion
The paper provides general definitions of explainable artificial intelligence (XAI) in the medical domain and introduces a framework for interpretability in clinical decision support systems structured across three levels. It explores XAI-related health applications within each tier of this framework, underpinned by a review of related experimental findings. Furthermore, the paper engages in a detailed discussion of quality assessment tools for evaluating XAI in intelligent health systems. It also presents a step-by-step roadmap for implementing XAI in clinical settings. To direct future research toward bridging current gaps, the paper examines the importance of XAI models from various angles and acknowledges their limitations.}
}
@article{MANZANARESSALOR2025112945,
title = {Enhancing text anonymization via re-identification risk-based explainability},
journal = {Knowledge-Based Systems},
volume = {310},
pages = {112945},
year = {2025},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2024.112945},
url = {https://www.sciencedirect.com/science/article/pii/S095070512401579X},
author = {Benet Manzanares-Salor and David Sánchez},
keywords = {Privacy protection, Neural language models, Explainability, Text anonymization, Re-identification},
abstract = {Text anonymization is a challenging task usually carried out by human annotators, thereby incurring significant economic and temporal costs. Even though automated approaches have been proposed to mitigate those costs, practical mechanisms for text anonymization mostly rely on named entity recognition (NER), which is acknowledged to offer insufficient privacy protection. To tackle this issue, we propose a methodology to enhance the privacy protection attained by any text anonymization mechanism –with a focus on NER-based ones–, while providing empirical guarantees against re-identification rooted on the k-anonymity privacy model. Our method relies on a neural language model trained on the aggregated background knowledge that can be leveraged to conduct re-identification attacks. Then, it employs explainability techniques to detect and iteratively mask the unprotected terms that caused the greatest re-identification risk until a user-defined k-anonymity level is reached. On the contrary to most existing methods in the text anonymization literature, our approach allows to intuitively configure the desired level of protection, and to tune the trade-off between privacy and data utility preservation. Experiments show that our method is able to significantly and consistently lower the re-identification risk of NER-based anonymizations, and to compete against more sophisticated state-of-the-art text anonymization methods while being free of their costs and external dependencies.}
}
@article{RAMONI202431,
title = {Artificial intelligence in scientific medical writing: Legitimate and deceptive uses and ethical concerns},
journal = {European Journal of Internal Medicine},
volume = {127},
pages = {31-35},
year = {2024},
issn = {0953-6205},
doi = {https://doi.org/10.1016/j.ejim.2024.07.012},
url = {https://www.sciencedirect.com/science/article/pii/S0953620524002954},
author = {Davide Ramoni and Cosimo Sgura and Luca Liberale and Fabrizio Montecucco and John P.A. Ioannidis and Federico Carbone},
keywords = {Artificial intelligence, Chatbots, ChatGPT, Medical writing, Natural language understanding, Large language models},
abstract = {The debate surrounding the integration of artificial intelligence (AI) into scientific writing has already attracted significant interest in medical and life sciences. While AI can undoubtedly expedite the process of manuscript creation and correction, it raises several criticisms. The crossover between AI and health sciences is relatively recent, but the use of AI tools among physicians and other scientists who work in the life sciences is growing very fast. Within this whirlwind, it is becoming essential to realize where we are heading and what the limits are, including an ethical perspective. Modern conversational AIs exhibit a context awareness that enables them to understand and remember any conversation beyond any predefined script. Even more impressively, they can learn and adapt as they engage with a growing volume of human language input. They all share neural networks as background mathematical models and differ from old chatbots for their use of a specific network architecture called transformer model [1]. Some of them exceed 100 terabytes (TB) (e.g., Bloom, LaMDA) or even 500 TB (e.g., Megatron-Turing NLG) of text data, the 4.0 version of ChatGPT (GPT-4) was trained with nearly 45 TB, but stays updated by the internet connection and may integrate with different plugins that enhance its functionality, making it multimodal.}
}
@incollection{GHANDIKOTA2024171,
title = {Chapter Seven - Application of artificial intelligence and machine learning in drug repurposing},
editor = {Vijai Singh},
series = {Progress in Molecular Biology and Translational Science},
publisher = {Academic Press},
volume = {205},
pages = {171-211},
year = {2024},
booktitle = {New Approach for Drug Repurposing Part A},
issn = {1877-1173},
doi = {https://doi.org/10.1016/bs.pmbts.2024.03.030},
url = {https://www.sciencedirect.com/science/article/pii/S1877117324000851},
author = {Sudhir K. Ghandikota and Anil G. Jegga},
keywords = {Drug repurposing, Drug repositioning, Artificial Intelligence, De novo drug discovery, Machine Learning, Deep Learning, Network analysis},
abstract = {The purpose of drug repurposing is to leverage previously approved drugs for a particular disease indication and apply them to another disease. It can be seen as a faster and more cost-effective approach to drug discovery and a powerful tool for achieving precision medicine. In addition, drug repurposing can be used to identify therapeutic candidates for rare diseases and phenotypic conditions with limited information on disease biology. Machine learning and artificial intelligence (AI) methodologies have enabled the construction of effective, data-driven repurposing pipelines by integrating and analyzing large-scale biomedical data. Recent technological advances, especially in heterogeneous network mining and natural language processing, have opened up exciting new opportunities and analytical strategies for drug repurposing. In this review, we first introduce the challenges in repurposing approaches and highlight some success stories, including those during the COVID-19 pandemic. Next, we review some existing computational frameworks in the literature, organized on the basis of the type of biomedical input data analyzed and the computational algorithms involved. In conclusion, we outline some exciting new directions that drug repurposing research may take, as pioneered by the generative AI revolution.}
}
@article{PANOUTSOPOULOS2024109268,
title = {Investigating the effect of different fine-tuning configuration scenarios on agricultural term extraction using BERT},
journal = {Computers and Electronics in Agriculture},
volume = {225},
pages = {109268},
year = {2024},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2024.109268},
url = {https://www.sciencedirect.com/science/article/pii/S0168169924006598},
author = {Hercules Panoutsopoulos and Borja Espejo-Garcia and Stephan Raaijmakers and Xu Wang and Spyros Fountas and Christopher Brewster},
keywords = {Automatic term extraction, Agriculture, Agriculture-BERT, Fine tuning configuration scenarios, Silver standard corpus},
abstract = {This paper compares different transformer-based language models for automatic term extraction from agriculture-related texts. Agriculture is an important economic sector faced with severe environmental and societal challenges. The collection, annotation and sharing of agricultural scientific knowledge is key to enabling the agricultural sector to address its challenges. Automatic term extraction is a Natural Language Processing task that can provide solutions to text tagging and annotation towards better knowledge and information exchange. It is concerned with the identification of terms pertaining to a domain, or area of expertise, in text and is an important step in knowledge base creation and update pipelines. Transformer-based language modeling technologies like BERT have become popular for automatic term extraction, but limited work has been undertaken so far in applying these methods to agriculture. This paper systematically compares Agriculture-BERT to Sci-BERT, RoBERTa, and vanilla BERT, which were fine-tuned for the automatic extraction of agricultural terms from English texts. The greatest challenge faced in our research was the scarcity of agriculture-related gold standard corpora for measuring automatic term extraction performance. Our results show that, with a few exceptions, Agriculture-BERT performs better than the other models considered in our research. Our main contribution and novelty of the presented research is the investigation of the impact that different language model fine-tuning configuration scenarios had on the term extraction task. More specifically, we tested different scenarios related to the model layers kept frozen, or being updated, during training, to measure the impact they may have on Agriculture-BERT’s performance in automatic term extraction. Our results show that the best performance was achieved by: (i) the “embedding layer updated + all encoder layers updated” scenario for the identification of terms also seen during training; (ii) the “embedding layer frozen + all encoder layers updated” scenario for the identification of terms being synonyms to those seen during training; and (iii) the “embedding layer updated + top 4 encoder layers updated” scenario for identifying terms neither seen during training nor being synonyms to those seen during training (novel terms).}
}
@incollection{HARALAMBOUS2024,
title = {Natural Language Processing},
booktitle = {Reference Module in Social Sciences},
publisher = {Elsevier},
year = {2024},
isbn = {978-0-443-15785-1},
doi = {https://doi.org/10.1016/B978-0-323-95504-1.00090-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780323955041000909},
author = {Yannis Haralambous},
keywords = {Attention mechanism, Chatbots, ChatGPT, Computational linguistics, Deep learning, ELIZA, Ethics in AI, Interpretability, Language generation, Large language models (LLM), Machine learning, Machine translation, Natural language processing (NLP), Neural networks, Sentiment analysis, Speech recognition, Statistical methods, Summarization, Text classification, Word embeddings},
abstract = {Natural Language Processing (NLP) evolved from rule-based systems in the 1960s–70s to statistical methods in the 1980s–90s, and finally to the deep learning revolution of the 21st century. The key milestones of its evolution include ELIZA, an early chatbot (1966), a focus on formal grammars and knowledge-based systems (1980s), the rise of statistical methods and machine learning (1990s), the popularization of word embeddings (2013), sequence-to-sequence models and attention mechanisms (2014–2016) and large language models like BERT, GPT-3, and ChatGPT (in the recent years). Major NLP applications can be classified in three categories: those that have linguistic input and non-linguistic output (e.g., text classification, sentiment analysis), those that transform linguistic input to linguistic output (e.g., machine translation, summarization), and those that are based on non-linguistic input (or no input at all) and have linguistic output (e.g., weather report generation, poetry generation). As for chatbots, they are comprehensive NLP applications, encompassing multiple tasks. Key challenges in NLP are the difficulty of machine translation and the importance of context in language understanding. Significant progress has been made with deep learning and large language models, but issues remain, like the lack of interpretability and ethical concerns. We provide resources for further learning, including popular textbooks, online courses, scientific journals, and mention platforms like Hugging Face and Kaggle for accessing datasets and models. Looking to the future, we anticipate increased multimodal integration, efforts to support under-resourced languages, and a focus on addressing interpretability and ethical issues in large language models. Overall, NLP is as a rapidly evolving field that has made significant strides in understanding and generating human language, with exciting possibilities and important challenges ahead.}
}
@article{ALREFAIE2024108654,
title = {Chemical, biological, radiological and nuclear event detection and classification using ontology interrogation and social media data},
journal = {Engineering Applications of Artificial Intelligence},
volume = {135},
pages = {108654},
year = {2024},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2024.108654},
url = {https://www.sciencedirect.com/science/article/pii/S0952197624008121},
author = {Mohamed Taher Alrefaie and Tom W. Jackson and Ejovwoke Onojeharho and Suzanne Elayan},
keywords = {Ontology, Disaster management, Information retrieval, Social media analysis, Machine learning, Natural language processing},
abstract = {In an era where chemical, biological, radiological, and nuclear (CBRN) incidents present a grave threat to public safety, timely and accurate information is paramount. The complexity of the CBRN concept encompasses a range of incidents, each with unique and overlapping symptoms, related substances, and event descriptions. This study introduces an innovative approach to the development of a CBRN-specific ontology, uniting diverse data sources and domain expertise to construct a comprehensive repository of CBRN events, sub-events, their causes, symptoms, and toxic substances. Unlike prior methodologies reliant on keyword searches and predefined categories, our approach enables a holistic analysis of textual data by capturing intricate relationships between symptoms and toxic substances. We leverage this ontology in conjunction with a tailored interrogation algorithm to detect potential CBRN incidents through social media data. The algorithm was then tested on datasets of three actual CBRN incidents, one fictional incident (TV show) that simulated a nuclear incident and one non-CBRN. The interrogation algorithm was able to detect the five CBRN incidents accurately. However, the study showcased the need to extend the algorithm to distinguish between real and fictional CBRN incidents. These findings underscore the potential of this approach to deliver timely information on potential CBRN incidents. Nevertheless, the study acknowledged the inherent challenges and limitations in utilizing social media data, including the risk of misinformation, fictional events, fake news, and interference from malicious actors, all of which can affect the accuracy and reliability of the information collected.}
}
@article{NIELSEN2025,
title = {Investigating the Classification of Living Kidney Donation Experiences on Reddit and Understanding the Sensitivity of ChatGPT to Prompt Engineering: Content Analysis},
journal = {JMIR AI},
volume = {4},
year = {2025},
issn = {2817-1705},
doi = {https://doi.org/10.2196/57319},
url = {https://www.sciencedirect.com/science/article/pii/S2817170525000067},
author = {Joshua Nielsen and Xiaoyu Chen and LaShara Davis and Amy Waterman and Monica Gentili},
keywords = {prompt engineering, generative artificial intelligence, kidney donation, transplant, living donor},
abstract = {Background
Living kidney donation (LKD), where individuals donate one kidney while alive, plays a critical role in increasing the number of kidneys available for those experiencing kidney failure. Previous studies show that many generous people are interested in becoming living donors; however, a huge gap exists between the number of patients on the waiting list and the number of living donors yearly.
Objective
To bridge this gap, we aimed to investigate how to identify potential living donors from discussions on public social media forums so that educational interventions could later be directed to them.
Methods
Using Reddit forums as an example, this study described the classification of Reddit content shared about LKD into three classes: (1) present (presently dealing with LKD personally), (2) past (dealt with LKD personally in the past), and (3) other (LKD general comments). An evaluation was conducted comparing a fine-tuned distilled version of the Bidirectional Encoder Representations from Transformers (BERT) model with inference using GPT-3.5 (ChatGPT). To systematically evaluate ChatGPT’s sensitivity to distinguishing between the 3 prompt categories, we used a comprehensive prompt engineering strategy encompassing a full factorial analysis in 48 runs. A novel prompt engineering approach, dialogue until classification consensus, was introduced to simulate a deliberation between 2 domain experts until a consensus on classification was achieved.
Results
BERT and GPT-3.5 exhibited classification accuracies of approximately 75% and 78%, respectively. Recognizing the inherent ambiguity between classes, a post hoc analysis of incorrect predictions revealed sensible reasoning and acceptable errors in the predictive models. Considering these acceptable mismatched predictions, the accuracy improved to 89.3% for BERT and 90.7% for GPT-3.5.
Conclusions
Large language models, such as GPT-3.5, are highly capable of detecting and categorizing LKD-targeted content on social media forums. They are sensitive to instructions, and the introduced dialogue until classification consensus method exhibited superior performance over stand-alone reasoning, highlighting the merit in advancing prompt engineering methodologies. The models can produce appropriate contextual reasoning, even when final conclusions differ from their human counterparts.}
}
@article{JO2025298,
title = {Comprehensive review of advances in machine-learning-driven optimization and characterization of perovskite materials for photovoltaic devices},
journal = {Journal of Energy Chemistry},
volume = {101},
pages = {298-323},
year = {2025},
issn = {2095-4956},
doi = {https://doi.org/10.1016/j.jechem.2024.09.043},
url = {https://www.sciencedirect.com/science/article/pii/S2095495624006673},
author = {Bonghyun Jo and Wenning Chen and Hyun Suk Jung},
keywords = {Perovskite solar cell, Data-driven machine learning, Characterization, Perovskite materials},
abstract = {Perovskite solar cells (PSCs) have developed rapidly, positioning them as potential candidates for next-generation renewable energy sources. However, conventional trial-and-error approaches and the vast compositional parameter space continue to pose challenges in the pursuit of exceptional performance and high stability of perovskite-based optoelectronics. The increasing demand for novel materials in optoelectronic devices and establishment of substantial databases has enabled data-driven machine-learning (ML) approaches to swiftly advance in the materials field. This review succinctly outlines the fundamental ML procedures, techniques, and recent breakthroughs, particularly in predicting the physical characteristics of perovskite materials. Moreover, it highlights research endeavors aimed at optimizing and screening materials to enhance the efficiency and stability of PSCs. Additionally, this review highlights recent efforts in using characterization data for ML, exploring their correlations with material properties and device performance, which are actively being researched, but they have yet to receive significant attention. Lastly, we provide future perspectives, such as leveraging Large Language Models (LLMs) and text-mining, to expedite the discovery of novel perovskite materials and expand their utilization across various optoelectronic fields.}
}
@article{PAPASTRATIS2024112291,
title = {Can ChatGPT provide appropriate meal plans for NCD patients?},
journal = {Nutrition},
volume = {121},
pages = {112291},
year = {2024},
issn = {0899-9007},
doi = {https://doi.org/10.1016/j.nut.2023.112291},
url = {https://www.sciencedirect.com/science/article/pii/S0899900723003192},
author = {Ilias Papastratis and Andreas Stergioulas and Dimitrios Konstantinidis and Petros Daras and Kosmas Dimitropoulos},
keywords = {ChatGPT, Nutrition, Artificial intelligence, Recommendation systems},
abstract = {Objectives
Dietary habits significantly affect health conditions and are closely related to the onset and progression of non-communicable diseases (NCDs). Consequently, a well-balanced diet plays an important role in lessening the effects of various disorders, including NCDs. Several artificial intelligence recommendation systems have been developed to propose healthy and nutritious diets. Most of these systems use expert knowledge and guidelines to provide tailored diets and encourage healthier eating habits. However, new advances in large language models such as ChatGPT, with their ability to produce human-like responses, have led individuals to search for advice in several tasks, including diet recommendations. This study aimed to determine the ability of ChatGPT models to generate appropriate personalized meal plans for patients with obesity, cardiovascular diseases, and type 2 diabetes.
Methods
Using a state-of-the-art knowledge-based recommendation system as a reference, we assessed the meal plans generated by two large language models in terms of energy intake, nutrient accuracy, and meal variability.
Results
Experimental results with different user profiles revealed the potential of ChatGPT models to provide personalized nutritional advice.
Conclusion
Additional supervision and guidance by nutrition experts or knowledge-based systems are required to ensure meal appropriateness for users with NCDs.}
}
@article{SHAMSHIRI2024105200,
title = {Text mining and natural language processing in construction},
journal = {Automation in Construction},
volume = {158},
pages = {105200},
year = {2024},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2023.105200},
url = {https://www.sciencedirect.com/science/article/pii/S0926580523004600},
author = {Alireza Shamshiri and Kyeong Rok Ryu and June Young Park},
keywords = {Text mining, Natural language processing, Machine learning, Computational linguistics, Language models, Construction, Project management},
abstract = {Text mining (TM) and natural language processing (NLP) have stirred interest within the construction field, as they offer enhanced capabilities for managing and analyzing text-based information. This highlights the need for a systematic review to identify the status quo, gaps, and future directions from the perspective of construction management. A review was conducted by aligning the objectives of 205 publications with the specific domains, areas, tasks, and processes outlined in construction management practices. This review reveals multiple facets of the construction sector empowered by TM/NLP approaches and highlights essential voids demanding consideration for automation possibilities and minimizing manual tasks. Ultimately, following identified obstacles, the review results indicate potential research opportunities: (1) strengthening overlooked construction aspects, (2) coupling diverse data formats, and (3) leveraging pre-trained language models and reinforcement learning. The findings will provide vital insights, fostering further progress in TM/NLP research and its applications in academia and industry.}
}
@article{MAO2025102712,
title = {A survey on pragmatic processing techniques},
journal = {Information Fusion},
volume = {114},
pages = {102712},
year = {2025},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2024.102712},
url = {https://www.sciencedirect.com/science/article/pii/S1566253524004901},
author = {Rui Mao and Mengshi Ge and Sooji Han and Wei Li and Kai He and Luyao Zhu and Erik Cambria},
keywords = {Pragmatic processing, Metaphor understanding, Sarcasm detection, Personality recognition, Aspect extraction, Sentiment polarity detection},
abstract = {Pragmatics, situated in the domains of linguistics and computational linguistics, explores the influence of context on language interpretation, extending beyond the literal meaning of expressions. It constitutes a fundamental element for natural language understanding in machine intelligence. With the advancement of large language models, the research focus in natural language processing has predominantly shifted toward high-level task processing, inadvertently downplaying the importance of foundational pragmatic processing tasks. Nevertheless, pragmatics serves as a crucial medium for unraveling human language cognition. The exploration of pragmatic processing stands as a pivotal facet in realizing linguistic intelligence. This survey encompasses important pragmatic processing techniques for subjective and emotive tasks, such as personality recognition, sarcasm detection, metaphor understanding, aspect extraction, and sentiment polarity detection. It spans theoretical research, the forefront of pragmatic processing techniques, and downstream applications, aiming to highlight the significance of these low-level tasks in advancing natural language understanding and linguistic intelligence.}
}
@article{ZHU2025129008,
title = {Soft prompt-tuning for unsupervised domain adaptation via self-supervision},
journal = {Neurocomputing},
volume = {617},
pages = {129008},
year = {2025},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2024.129008},
url = {https://www.sciencedirect.com/science/article/pii/S092523122401779X},
author = {Yi Zhu and Shuqin Wang and Yun Li and Yunhao Yuan and Jipeng Qiang},
keywords = {Unsupervised domain adaptation, Soft prompt-tuning, Cross-domain text classification, Verbalizer construction},
abstract = {Unsupervised domain adaptation methods aim to facilitate learning tasks in unlabeled target domains using labeled information from related source domains. Recently, prompt-tuning has emerged as a powerful instrument to incorporate templates that reformulate input examples into equivalent cloze-style phrases. However, there are still two great challenges for domain adaptation: (1) Existing prompt-tuning methods only rely on the general knowledge distributed in upstream pre-trained language models to alleviate the domain discrepancy. How to incorporate specific features in the source and target domains into prompt-tuning model is still divergent and under-explored; (2) In the prompt-tuning, either the crafted template methods are time-consuming and labor-intensive, or automatic prompt generation methods cannot achieve satisfied performance. To address these issues, in this paper, we propose an innovative Soft Prompt-tuning method for Unsupervised Domain Adaptation via Self-Supervision, which combines two novel ideas: Firstly, instead of only stimulating knowledge distributed in the pre-trained model, we further employ hierarchically clustered optimization strategies in a self-supervised manner to retrieve knowledge for the verbalizer construction in prompt-tuning. Secondly, we construct prompts with the special designed verbalizer that facilitate the transfer of learning representations across domains, which can consider both the automatic template generation and cross-domain classification performance. Extensive experimental results demonstrate that our method even outperforms SOTA baselines that utilize external open knowledge with much less computational time.}
}
@article{DEMURO20241,
title = {Artificial intelligence and the ethnographic encounter: Transhuman language ontologies, or what it means “to write like a human, think like a machine”},
journal = {Language & Communication},
volume = {96},
pages = {1-12},
year = {2024},
issn = {0271-5309},
doi = {https://doi.org/10.1016/j.langcom.2024.02.002},
url = {https://www.sciencedirect.com/science/article/pii/S0271530924000119},
author = {Eugenia Demuro and Laura Gurney},
keywords = {Artificial intelligence, Language ontologies, Ethnographic encounter, Transhumanism, Posthumanism},
abstract = {In this paper, we employ the language ontologies framework to artificial intelligence (specifically, OpenAI's ChatGPT) to investigate the ‘ethnographic encounter’ between human and non-human language users. Our focus is on the exchange and interplay between human language users and non-human artificial language generators in the production of written text. We analyse how such programs transform our understanding of what language is or might be; their practices to create language are unfamiliar, and yet they make sense to human interlocutors. Drawing from, and building on, the language ontologies framework, we discuss the practices involved in such encounters and suggest the need for an updated ‘toolkit’ in our understanding of language to account for transhuman interactions.}
}
@article{RATHORE2024108926,
title = {ToxinPred 3.0: An improved method for predicting the toxicity of peptides},
journal = {Computers in Biology and Medicine},
volume = {179},
pages = {108926},
year = {2024},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2024.108926},
url = {https://www.sciencedirect.com/science/article/pii/S0010482524010114},
author = {Anand Singh Rathore and Shubham Choudhury and Akanksha Arora and Purva Tijare and Gajendra P.S. Raghava},
keywords = {Toxic motifs, Virtual screening, Machine learning, Deep learning, Large language models, Ensemble/hybrid method},
abstract = {Toxicity emerges as a prominent challenge in the design of therapeutic peptides, causing the failure of numerous peptides during clinical trials. In 2013, our group developed ToxinPred, a computational method that has been extensively adopted by the scientific community for predicting peptide toxicity. In this paper, we propose a refined variant of ToxinPred that showcases improved reliability and accuracy in predicting peptide toxicity. Initially, we utilized a similarity/alignment-based approach employing BLAST to predict toxic peptides, which yielded satisfactory accuracy; however, the method suffered from inadequate coverage. Subsequently, we employed a motif-based approach using MERCI software to uncover specific patterns or motifs that are exclusively observed in toxic peptides. The search for these motifs in peptides allowed us to predict toxic peptides with a high level of specificity with poor sensitivity. To overcome the coverage limitations, we developed alignment-free methods using machine/deep learning techniques to balance sensitivity and specificity of prediction. Deep learning model (ANN - LSTM with fixed sequence length) developed using one-hot encoding achieved a maximum AUROC of 0.93 with MCC of 0.71 on an independent dataset. Machine learning model (extra tree) developed using compositional features of peptides achieved a maximum AUROC of 0.95 with MCC of 0.78. We also developed large language models and achieved maximum AUC of 0.93 using ESM2-t33. Finally, we developed hybrid or ensemble methods combining two or more methods to enhance performance. Our specific hybrid method, which combines a motif-based approach with a machine learning-based model, achieved a maximum AUROC of 0.98 with MCC 0.81 on an independent dataset. In this study, all models were trained and tested on 80 % of data using five-fold cross-validation and evaluated on the remaining 20 % of data called independent dataset. The evaluation of all methods on an independent dataset revealed that the method proposed in this study exhibited better performance than existing methods. To cater to the needs of the scientific community, we have developed a standalone software, pip package and web-based server ToxinPred3 (https://github.com/raghavagps/toxinpred3 and https://webs.iiitd.edu.in/raghava/toxinpred3/).}
}
@article{KIM2025112269,
title = {Technological applications of social robots to create healthy and comfortable smart home environment},
journal = {Building and Environment},
volume = {267},
pages = {112269},
year = {2025},
issn = {0360-1323},
doi = {https://doi.org/10.1016/j.buildenv.2024.112269},
url = {https://www.sciencedirect.com/science/article/pii/S0360132324011119},
author = {Hakpyeong Kim and Minjin Kong and Seunghoon Jung and Jaewon Jeoung and Hyuna Kang and Taehoon Hong},
keywords = {Smart home, Home automation, Social robot, Emotion recognition, Personal assistance},
abstract = {The increasing demand for healthy and comfortable living environments has driven significant advancements in smart home technology. However, current developments often overlook the importance of users’ social-emotional needs and the contextual dynamics within the home environment. This study proposes the integration of social robots as a promising solution to address these gaps. By enhancing smart home functionalities, social robots offer a more holistic approach to smart home design. A comprehensive literature review was conducted using the PRISMA methodology combined with large language model-based topic modeling to identify current research trends in social robotics. The analysis revealed five key research areas: (i) social-emotional intelligence, (ii) physical embodiment, (iii) elderly care, (iv) pediatric care, and (v) therapeutic applications. The study discusses how the core functionalities of social robots can enhance user experience by positively influencing the sensing, perception, and action layers of smart home systems. The findings suggest that the evolution of smart home technology should prioritize not only functional improvements but also the social and emotional well-being of users. Integrating social robots into smart homes will foster more human-centric, interactive, and satisfying living environments.}
}
@article{WANG2024102664,
title = {A few-shot word-structure embedded model for bridge inspection reports learning},
journal = {Advanced Engineering Informatics},
volume = {62},
pages = {102664},
year = {2024},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2024.102664},
url = {https://www.sciencedirect.com/science/article/pii/S1474034624003124},
author = {Yuchen Wang and Yanjie Zhu and Wen Xiong and C.S. Cai},
keywords = {Bridge maintenance, Deep learning, Information extraction, Integrated embedding, Pre-trained language model, Smart bridge},
abstract = {Intelligent bridge maintenance requires the comprehensive utilization of inspection records, as they contain valuable insights into structures’ long-term service conditions. To efficiently focus and utilize this data from extensive reports, reliable extraction methods are highly sought after. However, the heavy reliance on large amounts of manually annotated data limits the applicability and practicability of existing information extraction methods from bridge inspection reports, especially given the non-uniformity in report formats and expressions. To address this issue, this study proposed a few-shot information extraction model for bridge inspection reports understanding, comprising Word and Structure Integration Embeddings, Bi-directional Long Short-Term Memory (BiLSTM), and Condition Random Field (CRF). The model’s strength lies in its easy-to-implement word-structure embedding approach, which combines domain-specific word representations and sentence structure information. Specifically, the bridge inspection-domain pre-trained language model was further pre-trained and fine-tuned to obtain word embeddings, containing prior knowledge of the domain and tasks. Moreover, a novel encoding method was designed to generate sentence structure embeddings from dependency syntactic analysis results, providing textual representation information. Finally, the integrated word-structure embeddings, created by aligning dimensions for concatenation, were fed into the BiLSTM-CRF architecture to capture contextual dependencies and constrain extraction results. Empirical evaluations conducted on four few-shot datasets with 10, 30, 50, and 100 samples demonstrate that the proposed model achieved high accuracy and F1 score, outperforming prior methods, general domain models, and large language models. Specifically, in a dataset containing 50 sentences, our model achieved an accuracy of up to 0.9357 and an F1 score of 0.8683, representing an average increase of 38.4% higher than these methods. Ablation experiments revealed the contributions of each model component. These results suggest that the proposed model can accurately extract key information from bridge inspection reports even with limited training data scenarios, thereby facilitating applications such as structural condition evaluation and maintenance decision-making.}
}
@article{JOSHI2024124283,
title = {Saliency infused dialogue response generation: Improving task oriented text generation using feature attribution},
journal = {Expert Systems with Applications},
volume = {255},
pages = {124283},
year = {2024},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2024.124283},
url = {https://www.sciencedirect.com/science/article/pii/S0957417424011497},
author = {Ratnesh Kumar Joshi and Arindam Chatterjee and Asif Ekbal},
keywords = {Natural language generation, Saliency, Dialogue Systems, End-to-End generation},
abstract = {Challenges persist in dialogue scenarios, particularly in multi-turn dialogues where response generation often disregards contextual information beyond the last user utterance, resulting in fluent yet inadequate responses. This paper addresses these issues by identifying and resolving common shortcomings in base model responses during response generation and proposes methods to enhance response quality in unannotated dialogue settings. Our approach involves augmenting information from multiple sources, including keywords, salient features, and knowledge graph triples. We compare the effectiveness of these methods against both the base model and human annotation, which includes dialogue acts and entities. Our findings demonstrate that appending extracted tokens significantly enhances response quality compared to annotated information. In task-oriented dialogue, models perform best when infused with saliency and knowledge graph triples, as shown in the MultiWOZ dataset. Conversely, focusing solely on saliency yields better results for open-domain dialogue, as demonstrated with the DailyDialog dataset. For contextual relevance, the information infusion could also approach the performance of the LLama2 model with only a tenth of the available parameters.}
}
@article{LIU2024100099,
title = {A systematic evaluation of GPT-4V's multimodal capability for chest X-ray image analysis},
journal = {Meta-Radiology},
volume = {2},
number = {4},
pages = {100099},
year = {2024},
issn = {2950-1628},
doi = {https://doi.org/10.1016/j.metrad.2024.100099},
url = {https://www.sciencedirect.com/science/article/pii/S2950162824000535},
author = {Yunyi Liu and Yingshu Li and Zhanyu Wang and Xinyu Liang and Lingqiao Liu and Lei Wang and Leyang Cui and Zhaopeng Tu and Longyue Wang and Luping Zhou},
keywords = {GPT-4V, Medical image, Radiology report generation medical visual question answering medical visual grounding, Large language model evaluation},
abstract = {This work evaluates GPT-4V's multimodal capability for medical image analysis, focusing on three representative tasks radiology report generation, medical visual question answering, and medical visual grounding. For the evaluation, a set of prompts is designed for each task to induce the corresponding capability of GPT-4V to produce sufficiently good outputs. Three evaluation ways including quantitative analysis, human evaluation, and case study are employed to achieve an in-depth and extensive evaluation. Our evaluation shows that GPT-4V excels in understanding medical images can generate high-quality radiology reports and effectively answer questions about medical images. Meanwhile, it is found that its performance for medical visual grounding needs to be substantially improved. In addition, we observe the discrepancy between the evaluation outcome from quantitative analysis and that from human evaluation. This discrepancy suggests the limitations of conventional metrics in assessing the performance of large language models like GPT-4V and the necessity of developing new metrics for automatic quantitative analysis.}
}
@article{BENFENATI2024586,
title = {A Retrieval-augmented Generation application for Question-Answering in Nutrigenetics Domain},
journal = {Procedia Computer Science},
volume = {246},
pages = {586-595},
year = {2024},
note = {28th International Conference on Knowledge Based and Intelligent information and Engineering Systems (KES 2024)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.09.467},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924025092},
author = {Domenico Benfenati and Giovanni Maria {De Filippis} and Antonio Maria Rinaldi and Cristiano Russo and Cristian Tommasino},
keywords = {Retrieval-augmented generation, AI-generated content, Large language models, Information Retrieval, Nutrigenetics, Personalized nutrition},
abstract = {The domain of nutrigenetics investigates the complex relationship between genetic variations and individual dietary responses, encompassing a wide array of disciplines, including genomics, nutrition science, bioinformatics, and personalized medicine. This field is marked by its intricate data landscape, necessitating innovative approaches to effectively manage and interpret the vast volumes of information involved. Given nutrigenetic data sheer volume and complexity, traditional AI models often struggle to maintain comprehensive and up-to-date knowledge. In this paper, we propose an implementation of the Retrieval-Augmented Generation (RAG) strategy to address the question-answering task in nutrigenetic domain. This framework enhances the accuracy and relevancy of outputs produced by an advanced Large Language Model, circumventing the exhaustive model fine-tuning process. As a result, our RAG approach not only alleviates the computational demand but also fortifies against data leakage concerns, particularly critical in the sensitive area of nutrigenetics. The implementation of RAG in the nutrigenetic domain not only addresses the existing challenges but also paves the way for more advanced and efficient exploration of nutrigenetic data. Our proposed workflow could advance the understanding of nutrigenetic interactions and personalized nutrition.}
}
@article{SIKSTROM2024105140,
title = {Pedagogical agents communicating and scaffolding students' learning: High school teachers' and students' perspectives},
journal = {Computers & Education},
volume = {222},
pages = {105140},
year = {2024},
issn = {0360-1315},
doi = {https://doi.org/10.1016/j.compedu.2024.105140},
url = {https://www.sciencedirect.com/science/article/pii/S0360131524001544},
author = {Pieta Sikström and Chiara Valentini and Anu Sivunen and Tommi Kärkkäinen},
keywords = {Pedagogical agent, Secondary education, User-centered design, Human–machine communication (HMC), Human-to-human communication script},
abstract = {Pedagogical agents (PAs) communicate verbally and non-verbally with students in digital and virtual reality/augmented reality learning environments. PAs have been shown to be beneficial for learning, and generative artificial intelligence, such as large language models, can improve PAs' communication abilities significantly. K-12 education is underrepresented in learning technology research and teachers' and students' insights have not been considered when developing PA communication. The current study addresses this research gap by conducting and analyzing semi-structured, in-depth interviews with eleven high school teachers and sixteen high school students about their expectations for PAs' communication capabilities. The interviewees identified relational and task-related communication capabilities that a PA should perform to communicate effectively with students and scaffold their learning. PA communication that is simultaneously affirmative and relational can induce immediacy, foster the relationship and engagement with a PA, and support students' learning management. Additionally, the teachers and students described the activities and technological aspects that should be considered when designing conversational PAs. The study showed that teachers and students applied human-to-human communication scripts when outlining their desired PA communication characteristics. The study offers novel insights and recommendations to researchers and developers on the communicational, pedagogical, and technological aspects that must be considered when designing communicative PAs that scaffold students’ learning, and discusses the contributions on human–machine communication in education.}
}
@article{DINGIL2024e33645,
title = {Understanding state-of-the-art situation of transport planning strategies in earthquake-prone areas by using AI-supported literature review methodology},
journal = {Heliyon},
volume = {10},
number = {13},
pages = {e33645},
year = {2024},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2024.e33645},
url = {https://www.sciencedirect.com/science/article/pii/S2405844024096762},
author = {Ali Enes Dingil and Ondrej Pribyl},
keywords = {artificial intelligence, Information retrieval, AI-Supported review, Earth-quake prone areas, Seismic risk, Transport planning, Transport system},
abstract = {Aim
This review aims to explore earthquake-based transport strategies in seismic areas, providing state-of-the-art insights into the components necessary to guide urban planners and policymakers in their decision-making processes.
Outputs
The review provides a variety of methodologies and approaches employed for the reinforcement planning and emergency demand management to analyze and evaluate the impact of seismic events on transportation systems, in turn to develop strategies for preparedness, mitigation, response, and recovery phases. The selection of the appropriate approach depends on factors such as the specific transport system, urbanization level and type, built environment, and critical components involved.
Originality and value
Besides providing a distinctive illustration of the integration of transportation and seismic literature as a valuable consolidated resource, this article introduces a novel methodology named ALARM for conducting state-of-the-art reviews on any topic, incorporating AI through the utilization of large language models (LLMs) built upon transformer deep neural networks, along with indexing data structures (in this study mainly OPEN-AI DAVINCI-003 model and vector-storing index). Hence, it is of paramount significance as the first instance of implementing LLMs within academic review standards. This paves the way for the potential integration of AI and human collaboration to become a standard practice under enhanced criteria for comprehending and analyzing specific information.}
}
@article{SONNENSCHEIN2024120232,
title = {Validating and constructing behavioral models for simulation and projection using automated knowledge extraction},
journal = {Information Sciences},
volume = {662},
pages = {120232},
year = {2024},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2024.120232},
url = {https://www.sciencedirect.com/science/article/pii/S0020025524001452},
author = {Tabea S. Sonnenschein and G. Ardine {de Wit} and Nicolette R. {den Braver} and Roel C.H. Vermeulen and Simon Scheider},
keywords = {Validation, Knowledge extraction, Knowledge synthesis, Knowledge graph, Behavior modeling, Simulation, Ontology, BERT, Named-entity recognition},
abstract = {Human behavior may be one of the most challenging phenomena to model and validate. This paper proposes a method for automatically extracting and compiling evidence on human behavior determinants into a knowledge graph. The method (1) extracts associations of behavior determinants and choice options in relation to study groups and moderators from published studies using Natural Language Processing and Deep Learning, (2) synthesizes the extracted evidence into a knowledge graph, and (3) sub-selects the model components and relationships that are relevant and robust. The method can be used to either (4a) construct a structurally valid simulation model before proceeding with calibration or (4b) to validate the structure of existing simulation models. To demonstrate the feasibility of the method, we discuss an example implementation with mode of transport as behavior choice. We find that including non-frequently studied significant behavior determinants drastically improves the model's explanatory power in comparison to only including frequently studied variables. The paper serves as a proof-of-concept which can be reused, extended or adapted for various purposes.}
}
@article{ZHANG2025129307,
title = {ChatGPT in threefold: As attacker, target, and evaluator in adversarial attacks},
journal = {Neurocomputing},
volume = {621},
pages = {129307},
year = {2025},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2024.129307},
url = {https://www.sciencedirect.com/science/article/pii/S0925231224020782},
author = {Yunting Zhang and Lin Ye and Kai Tan and Zeshu Tian and Baisong Li and Hongli Zhang},
keywords = {Adversarial example, Textual adversarial attack, ChatGPT, Text classification, Perturbation},
abstract = {ChatGPT is one of the most popular large language models (LLMs). It has achieved state-of-the-art (SOTA) performance in various natural language processing (NLP) tasks. Recent studies have shown that deep learning (DL) models reveal vulnerability to adversarial texts. However, current research on the security of ChatGPT is still in its nascent stages. In this paper, ChatGPT plays three roles in adversarial attacks: an attack method, a target model, and an evaluation tool. We propose a novel black-box word-level adversarial text generation method, ChatGPT Tricker (CGT), for the text classification task. In the framework of adversarial text generation based on word importance, CGT introduces imperceptible perturbations to the original text by utilizing ChatGPT prompts, aiming to craft adversarial texts. Subsequently, we leverage the transferability of adversarial texts to attack ChatGPT and assess its robustness against such attacks. Additionally, we introduce an innovative fluency evaluation method for adversarial texts based on ChatGPT. We define a novel concept termed offset average difference (OAD) to provide a practical formula for the computation of fluency scores. The proposed method enables automated evaluation without human intervention. We utilize CGT to attack both BERT and ChatGPT on real-world English and Chinese text classification datasets. Experimental results demonstrate that CGT balances various aspects of attack performance well. CGT produces more fluent adversarial texts while achieving an attack success rate close to the SOTA baselines. Concurrently, the results also indicate that ChatGPT resists English adversarial texts but is vulnerable to Chinese ones. On the Chinese dataset, CGT can attack ChatGPT with a success rate exceeding 30%.}
}
@article{CORLATESCU2024108154,
title = {The automated model of comprehension version 4.0 – Validation studies and integration of ChatGPT},
journal = {Computers in Human Behavior},
volume = {154},
pages = {108154},
year = {2024},
issn = {0747-5632},
doi = {https://doi.org/10.1016/j.chb.2024.108154},
url = {https://www.sciencedirect.com/science/article/pii/S0747563224000219},
author = {Dragos-Georgian Corlatescu and Micah Watanabe and Stefan Ruseti and Mihai Dascalu and Danielle S. McNamara},
keywords = {Natural language processing, Reading comprehension, Automated model of comprehension, ChatGPT, Large language models},
abstract = {Modeling reading comprehension processes is a critical task for Learning Analytics, as accurate models of the reading process can be used to match students to texts, identify appropriate interventions, and predict learning outcomes. This paper introduces an improved version of the Automated Model of Comprehension, namely version 4.0. AMoC has its roots in two theoretical models of the comprehension process (i.e., the Construction-Integration model and the Landscape model), and the new version leverages state-of-the-art Large Language models, more specifically ChatGPT, to have a better contextualization of the text and a simplified construction of the underlying graph model. Besides showcasing the usage of the model, the study introduces three in-depth psychological validations that argue for the model's adequacy in modeling reading comprehension. In these studies, we demonstrated that AMoC is in line with the theoretical background proposed by the Construction-Integration and Landscape models, and it is better at replicating results from previous human psychological experiments than its predecessor. Thus, AMoC v4.0 can be further used as an educational tool to, for example, help teachers design better learning materials personalized for student profiles. Additionally, we release the code from AMoC v4.0 as open source in a Google Collab Notebook and a GitHub repository.}
}
@article{ZHAO2025104040,
title = {INSNER: A generative instruction-based prompting method for boosting performance in few-shot NER},
journal = {Information Processing & Management},
volume = {62},
number = {3},
pages = {104040},
year = {2025},
issn = {0306-4573},
doi = {https://doi.org/10.1016/j.ipm.2024.104040},
url = {https://www.sciencedirect.com/science/article/pii/S0306457324003996},
author = {Peiwen Zhao and Chong Feng and Peiguang Li and Guanting Dong and Sirui Wang},
keywords = {Named Entity Recognition, Information extraction, Few-shot learning, Prompt-based learning},
abstract = {Most existing Named Entity Recognition (NER) methods require a large scale of labeled data and exhibit poor performance in low-resource scenarios. Thus in this paper, we propose INSNER, a generative INStruction-based prompting method for few-shot NER. Specifically, we introduce a unified instruction to guide the model in extracting correct entities in response to the instruction, and construct synthetic verbalizers, which support complex types, to encourage effective knowledge transfer. We organize the NER results in natural language form, which mitigates the gap between pre-training and fine-tuning of language models. Furthermore, to facilitate the model to learn task-related knowledge and rich label semantics, we introduce entity-oriented prompt-tuning as an auxiliary task. We conduct in-domain and cross-domain experiments in few-shot settings on 4 datasets, and extensive analyses to validate the effectiveness and generalization ability of INSNER. Experimental results demonstrate that INSNER significantly outperforms current methods in few-shot settings, especially huge improvements(+12.0% F1) over the powerful ChatGPT in MIT Movie Complex both under a 10-shot setting.}
}
@article{GIORDANO2025104186,
title = {Decomposing maintenance actions into sub-tasks using natural language processing: A case study in an Italian automotive company},
journal = {Computers in Industry},
volume = {164},
pages = {104186},
year = {2025},
issn = {0166-3615},
doi = {https://doi.org/10.1016/j.compind.2024.104186},
url = {https://www.sciencedirect.com/science/article/pii/S0166361524001143},
author = {Vito Giordano and Gualtiero Fantoni},
keywords = {Natural language processing, Text mining, Maintenance work order, Industrial applications, Association rule mining, Large language model},
abstract = {Industry 4.0 has led to a huge increase in data coming from machine maintenance. At the same time, advances in Natural Language Processing (NLP) and Large Language Models provide new ways to analyse this data. In our research, we use NLP to analyse maintenance work orders, and specifically the descriptions of failures and the corresponding repair actions. Many NLP studies have focused on failure descriptions for categorising them, extracting specific information about failure, or supporting failure analysis methodologies (such as FMEA). Whereas, the analysis of repair actions and its relationship with failure remains underexplored. Addressing this gap, our study makes three significant contributions. Firstly, we focused on the Italian language, which presents additional challenges due to the dominance of NLP systems that are mainly designed for English. Secondly, it proposes a method for automatically subdividing a repair action into a set of sub-tasks. Lastly, it introduces an approach that employs association rule mining to recommend sub-tasks to maintainers when addressing failures. We tested our approach with a case study from an automotive company in Italy. The case study provides insights into the current barriers faced by NLP applications in maintenance, offering a glimpse into the future opportunities for smart maintenance systems.}
}
@article{ZONG2025100916,
title = {Recent progress on machine learning with limited materials data: Using tools from data science and domain knowledge},
journal = {Journal of Materiomics},
volume = {11},
number = {3},
pages = {100916},
year = {2025},
issn = {2352-8478},
doi = {https://doi.org/10.1016/j.jmat.2024.07.002},
url = {https://www.sciencedirect.com/science/article/pii/S2352847824001552},
author = {Bangtan Zong and Jinshan Li and Tinghuan Yuan and Jun Wang and Ruihao Yuan},
keywords = {Small datasets, Data augmentation, Transfer learning, Active learning, Domain knowledge},
abstract = {One key challenge in materials informatics is how to effectively use the material data of small size to search for desired materials from a huge unexplored material space. We review the recent progress on the use of tools from data science and domain knowledge to mitigate the issues arising from limited materials data. The enhancement of data quality and amount via data augmentation and feature engineering is first summarized and discussed. Then the strategies that use ensemble model and transfer learning for improved machine learning model are overviewed. Next, we move to the active learning with emphasis on the uncertainty quantification and evaluation. Subsequently, the merits of the combination of domain knowledge and machine learning are stressed. Finally, we discuss some applications of large language models in the field of materials science. We summarize this review by posing the challenges and opportunities in the field of machine learning for small material data.}
}
@article{LI2025112016,
title = {The neural correlates of logical-mathematical symbol systems processing resemble that of spatial cognition more than natural language processing},
journal = {iScience},
pages = {112016},
year = {2025},
issn = {2589-0042},
doi = {https://doi.org/10.1016/j.isci.2025.112016},
url = {https://www.sciencedirect.com/science/article/pii/S2589004225002767},
author = {Yuannan Li and Shan Xu and Jia Liu},
keywords = {logical-mathematical symbols processing, natural language processing, spatial cognition, language of thought, large language model},
abstract = {SUMMARY
The ability to use logical-mathematical symbols (LMS), encompassing tasks such as calculation, reasoning, and programming, is special to humans with recent emergence. LMS processing was suggested to build upon fundamental cognitive systems through neuronal recycling, with natural language processing and spatial cognition as key candidates. This study used meta-analyses and synthesized neural maps of representative LMS tasks, including reasoning, calculation, and mental programming, to compare their neural correlates with those of the two systems. Our results revealed greater activation overlap and multivariate similarity between LMS and spatial cognition than with language processing. Hierarchical clustering further indicated that LMS tasks were indistinguishable from spatial tasks at the neural level, suggesting an inherent connection. Our findings support the hypothesis that spatial cognition is the basis of LMS processing, shedding light on the logical reasoning limitations of large language models, particularly those lacking explicit spatial representations.}
}
@article{DAI2024292,
title = {Facilitating Students’ Adaptive Help-seeking and Peer Interactions through an Analytics-enhanced Forum in Engineering Design Education},
journal = {Procedia CIRP},
volume = {128},
pages = {292-297},
year = {2024},
note = {34th CIRP Design Conference},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2024.06.024},
url = {https://www.sciencedirect.com/science/article/pii/S2212827124006735},
author = {Yun Dai and Ziyan Lin and Ang Liu},
keywords = {help-seeking, peer support, learning analytics, design thinking, engineering education},
abstract = {Design often takes place in collective and collaborative settings, and interactions and mutual support among peers have been a critical component of design education. However, in most of the existing design courses, students often work in small groups and peer interactions are limited to group members, which limits the range and depth of knowledge exchange. To complement the group-based activities, this study designs and assesses an analytics-enhanced discussion forum for whole-class interactions. The forum adopts ontology-based recommender systems and anomaly detection techniques to tailor the threads and contents for individual students in a personalized way. This analytics-enhanced forum was implemented in a large-size undergraduate design course (n = 313), and data about student responses to this forum was compared with data from the previous year’s course that adopted a conventional forum (n = 280). From the statistical analysis, students learning with the analytics-enhanced forum demonstrated significantly higher degrees of design practices (specifically, empathize, define, ideate, and test), collaborative learning, and course satisfaction. Qualitative analysis of students’ focus-group interviews shows their perceived benefits and concerns of the analytics-enhanced forum. The study also suggests integrating generative artificial intelligence and large language models to support students’ design thinking and collaborative design.}
}
@article{CHEN2024102593,
title = {AskNatureNet: A divergent thinking tool based on bio-inspired design knowledge},
journal = {Advanced Engineering Informatics},
volume = {62},
pages = {102593},
year = {2024},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2024.102593},
url = {https://www.sciencedirect.com/science/article/pii/S1474034624002416},
author = {Liuqing Chen and Zebin Cai and Zhaojun Jiang and Jianxi Luo and Lingyun Sun and Peter Childs and Haoyu Zuo},
keywords = {Bio-inspired design, Semantic network, Divergent thinking, Design creativity, Design ideation},
abstract = {Divergent thinking is a process in design by exploring multiple possible solutions, is crucial in the early stages of design to break fixation and expand the design ideation. Design-by-Analogy promotes divergent thinking, by studying solutions have solved similar problems and using this knowledge to make inferences and solve problems in new and unfamiliar situations. Bio-inspired design (BID) is a form of design by analogy and its knowledge provides diverse sources for analogy, making BID knowledge as a potential source for divergent thinking. Existing BID database has focused on collecting BID cases and facilitating the retrieval of biological knowledge. Despite its success, applying BID knowledge into divergent thinking still encounters challenge, as the association between source domain and target domain are always limited within a single case. In this work, a novel approach is proposed to support divergent thinking from three subsequent phases: encoding, retrieval and mapping. Specifically, biological knowledge is encoded in a triple form by employing a large language model (LLM) to extract key information from a well-known BID knowledge base. The created triples are implemented in a semantic network to facilitate bidirectional retrieval modes: problem-driven and solution-driven, as well as mapping for divergent thinking. The mapping algorithm calculates the semantic similarity between nodes in the semantic network based on their attributes in three progressive steps by following the paradigm of divergent thinking. The proposed approach is implemented as tool called AskNatureNet,11https://www.asknaturenet.com/. which supports divergent thinking by retrieving and mapping knowledge in a visualized interactive semantic network. An ideation case study on evaluating the effectiveness of AskNatureNet shows that our tool is capable of supporting divergent thinking efficiently.}
}
@incollection{GURTU20251617,
title = {Chapter 101 - Use of Artificial Intelligence (AI) in Cybersecurity},
editor = {John R. Vacca},
booktitle = {Computer and Information Security Handbook (Fourth Edition)},
publisher = {Morgan Kaufmann},
edition = {Fourth Edition},
pages = {1617-1624},
year = {2025},
isbn = {978-0-443-13223-0},
doi = {https://doi.org/10.1016/B978-0-443-13223-0.00101-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780443132230001016},
author = {Anurag Gurtu and Damien Lim},
keywords = {AI algorithm, AI fuzzing, AI model, Automation, Bayesian, Cyber threats, Cyberattacks, Cybersecurity, Data poisoning, Deep learning, Deep neural networks, Generative AI, Knowledge graph, Learning mode, Least squares, Machine learning, Malware, Malware sandbox, Natural language processing, Next generation firewall, Password cracking, Random forest, Reinforcement learning, Security posture, Supervised learning, Threat actor, Threat detection, Threat response, Training data, Unsupervised learning, User entity behavior analytics, Virtual assistants, Worm generation},
abstract = {Artificial Intelligence (AI) is actively utilized and works in the background to benefit consumers and businesses. This chapter focuses on how AI can be used to enhance cybersecurity and the challenges and risks involved. It covers the fundamentals, algorithms, and learning modes of AI and how they can be applied to various security technologies and processes. There are many different AI models, but specific examples stand out as proven applications to cybersecurity, such as machine learning (ML), deep learning (DL), generative AI (GenAI), natural language processing (NLP), and knowledge graph (KG). They can work together to create powerful technologies, including virtual assistants for cybersecurity. We balance the conversation with reviewing inherent weaknesses found in AI. The impact of AI on cybersecurity is quite significant in that it helps fill the skill gap, accelerate threat detection, automate processes, and improve security posture. On the other hand, threat actors can misuse and exploit AI to create more sophisticated and evasive cyberattacks. Some examples of AI abuse include AI fuzzing, password cracking, worm generation, and data poisoning. Lastly, we examine the factors that influence the adoption of AI and its future, such as organization size, industry vertical, barriers, and governance.}
}
@article{NGO2025102966,
title = {Integrating personalized and contextual information in fine-grained emotion recognition in text: A multi-source fusion approach with explainability},
journal = {Information Fusion},
volume = {118},
pages = {102966},
year = {2025},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2025.102966},
url = {https://www.sciencedirect.com/science/article/pii/S1566253525000399},
author = {Anh Ngo and Jan Kocoń},
keywords = {Emotion recognition, Sentence sequence classification, Personalization, Data cartography, Natural Language Processing (NLP), Explainable artificial, Intelligence (XAI)},
abstract = {Emotion recognition in textual data is a rapidly evolving field with diverse applications. While the state-of-the-art (SOTA) models based on pre-trained large language models (LLMs) have demonstrated significant achievements, the existing approaches often overlook fine-grained emotional nuances within individual sentences and the influence of contextual information. Additionally, despite the growing interest in personalized Natural Language Processing, recent studies have highlighted limitations in the literature, particularly the lack of explainability methods to interpret the improvements observed in these models. This study explores the CLARIN-Emo dataset to demonstrate the effectiveness of integrating personalized and contextual information for accurate emotion detection. By framing textual emotion recognition as a sequence sentence classification (SSC) task and leveraging transformer-based architectures, the proposed multi-source fusion approach significantly outperformed the baseline model, which considers each sentence in isolation. Furthermore, a personalized method, referred to as UserID, captures user-specific characteristics by assigning each annotator a unique identifier, significantly enhancing emotion prediction accuracy. This work also introduces an extension of Data Maps by differentiating dynamic training metrics to analyze the models’ training behaviors. The results validate the capability of this approach in visually interpreting and facilitating performance comparisons between models.}
}
@article{QIN2025102994,
title = {A Comprehensive Taxonomy of Machine Consciousness},
journal = {Information Fusion},
pages = {102994},
year = {2025},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2025.102994},
url = {https://www.sciencedirect.com/science/article/pii/S1566253525000673},
author = {Ruilin Qin and Changle Zhou and Mengjie He},
keywords = {Consciousness, machine consciousness, artificial consciousness, conscious robot, qualia, large language model},
abstract = {Machine consciousness (MC) is the ultimate challenge to artificial intelligence. Although great progress has been made in artificial intelligence and robotics, consciousness is still an enigma and machines are far from having it. To clarify the concepts of consciousness and the research directions of machine consciousness, in this review, a comprehensive taxonomy for machine consciousness is proposed, categorizing it into seven types: MC-Perception, MC-Cognition, MC-Behavior, MC-Mechanism, MC-Self, MC-Qualia and MC-Test, where the first six types aim to achieve a certain kind of conscious ability, and the last type aims to provide evaluation methods and criteria for machine consciousness. For each type, the specific research contents and future developments are discussed in detail. Especially, the machine implementations of three influential consciousness theories, i.e. global workspace theory, integrated information theory and higher-order theory, are elaborated in depth. Moreover, the challenges and outlook of machine consciousness are analyzed in detail from both theoretical and technical perspectives, with emphasis on new methods and technologies that have the potential to realize machine consciousness, such as brain-inspired computing, quantum computing and hybrid intelligence. The ethical implications of machine consciousness are also discussed. Finally, a comprehensive implementation framework of machine consciousness is provided, integrating five suggested research perspectives: consciousness theories, computational methods, cognitive architectures, experimental systems, and test platforms, paving the way for the future developments of machine consciousness.}
}
@article{BRASE20241923,
title = {Digital chemistry: navigating the confluence of computation and experimentation – definition, status quo, and future perspective},
journal = {Digital Discovery},
volume = {3},
number = {10},
pages = {1923-1932},
year = {2024},
issn = {2635-098X},
doi = {https://doi.org/10.1039/d4dd00130c},
url = {https://www.sciencedirect.com/science/article/pii/S2635098X24001530},
author = {Stefan Bräse},
abstract = {Digital chemistry represents a transformative approach integrating computational methods, digital data, and automation within the chemical sciences. It is defined by using digital toolkits and algorithms to simulate, predict, accelerate, and analyze chemical processes and properties, augmenting traditional experimental methods. The current status quo of digital chemistry is marked by rapid advancements in several key areas: high-throughput screening, machine learning models, quantum chemistry, and laboratory automation. These technologies have enabled unprecedented speeds in discovering and optimizing new molecules, materials, and reactions. Digital retrosynthesis and structure–active prediction tools have supported these endeavors. Furthermore, integrating large-language models and robotics in chemistry labs (e.g. demonstrated in self-driving labs) have begun to automate routine tasks and complex decision-making processes. Looking forward, the future of digital and digitalized chemistry is poised for significant growth, driven by the increasing accessibility of computational resources, the expansion of chemical databases, and the refinement of artificial intelligence algorithms. This evolution promises to accelerate innovation in drug discovery, materials science, and sustainable manufacturing, ultimately leading to more efficient, cost-effective, and environmentally friendly chemical research and production. The challenge lies in advancing the technology itself, fostering interdisciplinary collaboration, and ensuring the ethical use of digital tools in chemical research.}
}
@article{CHARI2023102498,
title = {Informing clinical assessment by contextualizing post-hoc explanations of risk prediction models in type-2 diabetes},
journal = {Artificial Intelligence in Medicine},
volume = {137},
pages = {102498},
year = {2023},
issn = {0933-3657},
doi = {https://doi.org/10.1016/j.artmed.2023.102498},
url = {https://www.sciencedirect.com/science/article/pii/S093336572300012X},
author = {Shruthi Chari and Prasant Acharya and Daniel M. Gruen and Olivia Zhang and Elif K. Eyigoz and Mohamed Ghalwash and Oshani Seneviratne and Fernando Suarez Saiz and Pablo Meyer and Prithwish Chakraborty and Deborah L. McGuinness},
keywords = {User-driven, Clinical explainability, Contextual explanations, Question-answering approach, Type-2 diabetes comorbidity risk prediction},
abstract = {Medical experts may use Artificial Intelligence (AI) systems with greater trust if these are supported by ‘contextual explanations’ that let the practitioner connect system inferences to their context of use. However, their importance in improving model usage and understanding has not been extensively studied. Hence, we consider a comorbidity risk prediction scenario and focus on contexts regarding the patients’ clinical state, AI predictions about their risk of complications, and algorithmic explanations supporting the predictions. We explore how relevant information for such dimensions can be extracted from Medical guidelines to answer typical questions from clinical practitioners. We identify this as a question answering (QA) task and employ several state-of-the-art Large Language Models (LLM) to present contexts around risk prediction model inferences and evaluate their acceptability. Finally, we study the benefits of contextual explanations by building an end-to-end AI pipeline including data cohorting, AI risk modeling, post-hoc model explanations, and prototyped a visual dashboard to present the combined insights from different context dimensions and data sources, while predicting and identifying the drivers of risk of Chronic Kidney Disease (CKD) - a common type-2 diabetes (T2DM) comorbidity. All of these steps were performed in deep engagement with medical experts, including a final evaluation of the dashboard results by an expert medical panel. We show that LLMs, in particular BERT and SciBERT, can be readily deployed to extract some relevant explanations to support clinical usage. To understand the value-add of the contextual explanations, the expert panel evaluated these regarding actionable insights in the relevant clinical setting. Overall, our paper is one of the first end-to-end analyses identifying the feasibility and benefits of contextual explanations in a real-world clinical use case. Our findings can help improve clinicians’ usage of AI models.}
}
@article{WANG2025100759,
title = {Towards cognitive intelligence-enabled product design: The evolution, state-of-the-art, and future of AI-enabled product design},
journal = {Journal of Industrial Information Integration},
volume = {43},
pages = {100759},
year = {2025},
issn = {2452-414X},
doi = {https://doi.org/10.1016/j.jii.2024.100759},
url = {https://www.sciencedirect.com/science/article/pii/S2452414X24002024},
author = {Zuoxu Wang and Xinxin Liang and Mingrui Li and Shufei Li and Jihong Liu and Lianyu Zheng},
keywords = {Engineering product design, Cognitive computing, Knowledge graph, Industrial products and services design, Design knowledge support, Knowledge reasoning},
abstract = {Engineering design researchers have increasing interests in leveraging artificial intelligence (AI) techniques to a wide range of product design tasks, such as customer requirement analysis, product concept generation, design synthesis, and decision-making in product design. Indeed, AI techniques perform excellently on well-defined design tasks with clear problem definition, specialized solutions, and abundant training data. However, facing the ever-evolving AI techniques rapidly and radically changing the product design manner, there is still a lack of a systematic summary about the current stage of AI-enabled product design. Besides, although the current AI-enabled product design performs excellently on the well-defined tasks, the other advanced design tasks that need cognitive capability can still hardly be satisfyingly completed by the current product design system. This study systematically reviewed the literature on AI-enabled product design to understand its evolution and state-of-the-arts. To bridge the semantic gap between humans and systems, a novel cognitive intelligence-enabled product design (CIPD) framework is proposed, in which cognitive intelligence is the key enabler. The CIPD's key aspects, including its system architecture, human-like capabilities, enabling technologies, and potential applications, are also systematically discussed. It is hoped that this study could contribute to the future directions of the product design field and offer insightful guidance to the practitioners and researchers in their product design process.}
}
@article{WU2024106666,
title = {Generative commonsense knowledge subgraph retrieval for open-domain dialogue response generation},
journal = {Neural Networks},
volume = {180},
pages = {106666},
year = {2024},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2024.106666},
url = {https://www.sciencedirect.com/science/article/pii/S0893608024005902},
author = {Sixing Wu and Jiong Yu and Jiahao Chen and Wei Zhou},
keywords = {Response generation, Knowledge grounded response generation, Commonsense knowledge},
abstract = {Grounding on a commonsense knowledge subgraph can help the model generate more informative and diverse dialogue responses. Prior Traverse-based works explicitly retrieve a subgraph from the external knowledge base (eKB). Notably, the available knowledge is strictly restricted by the eKB. To break this restriction, Generative Retrieval methods externalize knowledge from the language model. However, they always generate boring knowledge due to their one-pass externalization procedure. This work proposes a novel TiLM Traverse in Language Model (TiLM), which uses three ‘Chain-of-Thought’ sub-tasks, i.e., Query Entity Production, Topic Entity Prediction, and Knowledge Subgraph Completion, to build a high-quality knowledge subgraph to ground the next Response Generation without explicitly accessing the eKB in inference. Experimental results on both Chinese and English datasets demonstrate TiLM’s outstanding performance even only with a small scale of parameters.}
}
@article{SONG2025109572,
title = {Korean football in-game conversation state tracking dataset for dialogue and turn level evaluation},
journal = {Engineering Applications of Artificial Intelligence},
volume = {139},
pages = {109572},
year = {2025},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2024.109572},
url = {https://www.sciencedirect.com/science/article/pii/S0952197624017305},
author = {Sangmin Song and Juhyoung Park and Juhwan Choi and Junho Lee and Kyohoon Jin and YoungBin Kim},
keywords = {Dialogue state tracking, Data annotation, Large language model},
abstract = {Recent research in dialogue state tracking has made significant progress in tracking user goals through dialogue-level and turn-level approaches, but existing research primarily focused on predicting dialogue-level belief states. In this study, we present the KICK: Korean football In-game Conversation state tracKing dataset, which introduces a conversation-based approach. This approach leverages the roles of casters and commentators within the self-contained context of sports broadcasting to examine how utterances impact the belief state at both the dialogue-level and turn-level. Towards this end, we propose a task that aims to track the states of a specific time turn and understand conversations during the entire game. The proposed dataset comprises 228 games and 2463 events over one season, with a larger number of tokens per dialogue and turn, making it more challenging than existing datasets. Experiments revealed that the roles and interactions of casters and commentators are important for improving the zero-shot state tracking performance. By better understanding role-based utterances, we identify distinct approaches to the overall game process and events at specific turns.}
}
@article{CHOI2024115042,
title = {GPT-based data-driven urban building energy modeling (GPT-UBEM): Concept, methodology, and case studies},
journal = {Energy and Buildings},
volume = {325},
pages = {115042},
year = {2024},
issn = {0378-7788},
doi = {https://doi.org/10.1016/j.enbuild.2024.115042},
url = {https://www.sciencedirect.com/science/article/pii/S0378778824011587},
author = {Sebin Choi and Sungmin Yoon},
keywords = {Urban building energy modeling (UBEM), Urban informatics, Top-down, Large language model (LLM), GPT, Technical exploration},
abstract = {Achieving carbon neutrality is a critical global goal, with urban building energy modeling (UBEM) playing a pivotal role by providing data-driven insights to optimize energy consumption and reduce emissions. This paper introduces GPT-based urban building energy modeling (GPT-UBEM), a novel approach utilizing GPT’s advanced capabilities to address key UBEM challenges using GPT-4o. The study aimed to demonstrate the effectiveness of GPT-UBEM in performing UBEM tasks and to explore its potential in overcoming traditional limitations. Specifically, (1) basic analytics of urban data, (2) data analysis and energy prediction, (3) building feature engineering and optimization, and (4) energy signature analysis were conducted in four case studies. These analyses were applied to 2,000 buildings in Seoul and 31 buildings in Gangwon-do, South Korea. Through case study, the findings highlighted the ability of GPT-UBEM to integrate diverse data sources, optimize building features for high accuracy in prediction models, and provide valuable insights for urban planners and policymakers through the use of expert domain knowledge and intervention. Additionally, based on the results derived from GPT-UBEM in this study, the current limitations of GPT-UBEM (L1 to L3) and future research directions (F1 to F4) have been outlined.}
}
@article{KEFALIDIS2024104203,
title = {The question answering system GeoQA2 and a new benchmark for its evaluation},
journal = {International Journal of Applied Earth Observation and Geoinformation},
volume = {134},
pages = {104203},
year = {2024},
issn = {1569-8432},
doi = {https://doi.org/10.1016/j.jag.2024.104203},
url = {https://www.sciencedirect.com/science/article/pii/S1569843224005594},
author = {Sergios-Anestis Kefalidis and Dharmen Punjani and Eleni Tsalapati and Konstantinos Plas and Maria-Aggeliki Pollali and Pierre Maret and Manolis Koubarakis},
keywords = {Geospatial knowledge graphs, Geospatial question answering},
abstract = {We present the question answering engine GeoQA2 which is able to answer geospatial questions over the union of knowledge graphs YAGO2 and YAGO2geo. We also present the dataset GeoQuestions1089 which consists of 1089 natural language questions, their corresponding SPARQL or GeoSPARQL queries and their answers over the union of the same knowledge graphs. We use this dataset to compare the effectiveness of GeoQA2 and the system of Hamzei et al. 2022 and make it publicly available to be used by other researchers. Our evaluation shows that although the engine GeoQA2 performs better than the engine of Hamzei et al. 2022, both engines have ample room for improvement in their question answering performance.}
}
@article{HAN2025112805,
title = {A plug-and-play knowledge-enhanced module for medical reports generation},
journal = {Knowledge-Based Systems},
volume = {309},
pages = {112805},
year = {2025},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2024.112805},
url = {https://www.sciencedirect.com/science/article/pii/S0950705124014394},
author = {Qinyu Han and Zhihao Yang and Hongfei Lin and Tian Qin},
keywords = {Medical report generation, Dialogue summarization, Knowledge graph, Heterogeneous graph network},
abstract = {Medical reports generation from patient–doctor conversations aims to capture the salient contents from dialogues in the form of medical reports, to assist the healthcare archiving and follow-ups. Unlike general summarization tasks, summaries in specialized domains, such as medical report generation, require stronger support from domain-specific knowledge to enhance the internal logic specific to their field. However, existing methods either model the context sequentially without incorporating knowledge graphs, resulting in unclear representation of domain-specific logical structures, or introduce the expert medical knowledge using homogeneous graphs, which fail to effectively fuse information from different semantic spaces. To address this, we propose to incorporate the knowledge into the step of context modeling by introducing a plug-and-play heterogeneous graph encoder. Furthermore, a fact-aware module is introduced to help our model in integrating key context information filtered by external knowledge during decoding. Compared with previous works, our method makes full use of knowledge, and the proposed modules demonstrate easy adaption on existing frameworks. Experimental results on two public medical dialogue summarization datasets indicate that our method significantly outperforms a range of baselines while being smaller and capable of achieving the state-of-the-art performance11Code is available at https://github.com/salvatoreferragamo/Med-HGE..}
}
@article{LIN2024122254,
title = {Reinforcement learning and bandits for speech and language processing: Tutorial, review and outlook},
journal = {Expert Systems with Applications},
volume = {238},
pages = {122254},
year = {2024},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2023.122254},
url = {https://www.sciencedirect.com/science/article/pii/S0957417423027562},
author = {Baihan Lin},
keywords = {Reinforcement learning, Bandits, Speech processing, Natural language processing, Speech recognition, Large language models, Survey, Perspective},
abstract = {In recent years, reinforcement learning and bandits have transformed a wide range of real-world applications including healthcare, finance, recommendation systems, robotics, and last but not least, the speech and natural language processing. While most speech and language applications of reinforcement learning algorithms are centered around improving the training of deep neural networks with its flexible optimization properties, there are still many grounds to explore to utilize the benefits of reinforcement learning, such as its reward-driven adaptability, state representations, temporal structures and generalizability. In this survey, we present an overview of recent advancements of reinforcement learning and bandits including those in the large language models, and discuss how they can be effectively employed to solve speech and natural language processing problems with models that are adaptive, interactive and scalable.}
}
@article{SUN2024111975,
title = {Harnessing domain insights: A prompt knowledge tuning method for aspect-based sentiment analysis},
journal = {Knowledge-Based Systems},
volume = {298},
pages = {111975},
year = {2024},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2024.111975},
url = {https://www.sciencedirect.com/science/article/pii/S0950705124006099},
author = {Xinjie Sun and Kai Zhang and Qi Liu and Meikai Bao and Yanjiang Chen},
keywords = {LLMs, Prompt tuning, Domain knowledge base, Co-occurrence gate, Hybrid prompt},
abstract = {Aspect-based sentiment analysis (ABSA) endeavours predict the sentiment polarity of specific aspects of a given review. Recently, prompt tuning has been widely explored and has achieved remarkable success in improving semantic comprehension in several NLP tasks. However, most existing methods consider semantic tuning for various tasks and overlook domain knowledge, such as common-sense background knowledge. This not only limits the model’s ability to understand and apply domain knowledge but also often leads to the model’s inability to fully utilise domain-specific information, resulting in poor semantic quality and inferior model performance. To bridge this gap, we conducted a systematic study of Prompt Tuning with Domain Knowledge (PTDK) for ABSA, which aimed to design efficient prompts that guide the model to learn the knowledge of specific aspects in ABSA. Specifically, we first fine-tune the Large Language Models (LLMs) using hard prompts, which enhance the ability to extract enriched domain insights from the knowledge base. Additionally, we employed a Co-occurrence Gate to meticulously filter and refine the domain knowledge. This mechanism enhances the domain representation capability of the prompt template by selecting the most similar parts that are independently generated from a vast amount of domain knowledge for each comment. Simultaneously, a emphhybrid prompt templatewas constructed. This template integrates hard prompts and trainable soft prompts to compensate for the lack of specificity in hard prompts and to facilitate the integration of specific masks in various domain vectors. This hybrid strategy further enhances our ability to utilise domain-specific knowledge when performing ABSA. Experimental results on three public datasets – Restaurant, Laptop, and Twitter – demonstrate that our method consistently outperforms the current state-of-the-art baselines in all cases. The accuracies were 88.63%, 82.65%, and 81.65%, respectively, and F1-scores were 83.38%, 79.68%, and 80.36%, respectively. This translates into an average increase in accuracy of 0.97% and an enhancement in the F1-score of 1.03%. These enhancements not only validate the efficacy of our approach but also have substantial practical implications for real-world scenarios that require sophisticated sentiment analysis, such as the evaluation of customer feedback on e-commerce platforms.}
}
@article{CHAKHTOUNA2024428,
title = {Modeling Speech Emotion Recognition via ImageBind representations},
journal = {Procedia Computer Science},
volume = {236},
pages = {428-435},
year = {2024},
note = {International Symposium on Green Technologies and Applications (ISGTA’2023)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.05.050},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924010664},
author = {Adil CHAKHTOUNA and Sara SEKKATE and Abdellah ADIB},
keywords = {ImageBind, Speech Emotion Recognition, Embedding representations, IEMOCAP, Nu-SVM},
abstract = {Speech Emotion Recognition (SER) refers to the ability of Machine Learning (ML) and Deep Learning (DL) techniques to accurately predict people's emotional states from speech signals. significant progress has been achieved in the SER domain involving the incorporation of DL models to introduce novel features extraction processes. This paper introduces the use of deep representations learned from the multi-modal Large Language Model (LLM) called ImageBind. These representations were subsequently provided as input to the Nu-Support Vector Machine (Nu-SVM) with RBF kernel for the classification task. The experiments were executed using the IEMOCAP database within the context of a Speaker-Dependent (SD) scenario. The method achieved a noteworthy overall accuracy rate of 80.58% for the four emotions of IEMOCAP, representing a substantial improvement over well-established methods in the existing body of literature. Thus, affirming that the proposed methodology, founded upon ImageBind representations, introduces a novel perspective to the field of SER.}
}
@article{XIAO2024124475,
title = {TPKE-QA: A gapless few-shot extractive question answering approach via task-aware post-training and knowledge enhancement},
journal = {Expert Systems with Applications},
volume = {254},
pages = {124475},
year = {2024},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2024.124475},
url = {https://www.sciencedirect.com/science/article/pii/S0957417424013411},
author = {Qiao Xiao and Ren Li and Jianxi Yang and Yu Chen and Shixin Jiang and Di Wang},
keywords = {Extractive question answering, Few-shot, Post-training, Knowledge enhancement, Task-aware, Pretrained Language Model},
abstract = {Few-shot extractive question answering (EQA) is a challenging task in natural language processing, whose current methods are mainly based on pretrained language models (PLMs). Data augmentation is often employed to improve the answer predictions of EQA models in few-shot settings. However, due to the differences between pretraining objectives and the EQA task, as well as embedding space alignment bottlenecks, the performance of few-shot EQA models must be improved. We propose TPKE-QA, a few-shot extractive Question Answering approach via Task-aware Post-training and Knowledge Enhancement, with entity-noun-oriented span selection in post-training, which can automatically generate EQA-style examples from a large-scale unlabeled corpus. By post-training based on generated examples, the gap between PLMs and the EQA task is effectively filled. To avoid embedding space alignment issues, a knowledge-enhanced sequence generation and knowledge injection approach for the EQA task enables gapless knowledge enhancement and fine-tuning on the post-trained model. In experiments, TPKE-QA achieved state-of-the-art results in most few-shot settings on the MRQA 2019 benchmark.}
}
@article{GAO2025200475,
title = {TourismNER: A Tourism Named Entity Recognition method based on entity boundary joint prediction},
journal = {Intelligent Systems with Applications},
volume = {25},
pages = {200475},
year = {2025},
issn = {2667-3053},
doi = {https://doi.org/10.1016/j.iswa.2025.200475},
url = {https://www.sciencedirect.com/science/article/pii/S2667305325000018},
author = {Kai Gao and Jiahao Zhou and Yunxian Chi and Yimin Wen},
keywords = {Natural Language Processing, Tourism Named Entity Recognition, Entity boundary recognition, Joint prediction},
abstract = {Tourism named entity recognition is indispensable in tourism information extraction, and plays a crucial role in constructing tourism knowledge map and enhancing tourism knowledge quiz system. The difficulty of tourism named entity recognition lies in its complex nested structure, and the lengthy entity naming length. To address these existing problems, we propose a tourism named entity recognition model that jointly predicts entity boundaries, adopting a training strategy of data preprocessing to enhance the model’s ability for tourism named entity boundary recognition, while our model introduces a pre-trained Bert model as well as BiLSTM coding to enhance the representation of the model’s contexts, and uses a combined predictor of Biaffine and MLP to enhance the model’s recognition performance for boundaries, as well as introducing label smoothing cross entropy to smooth the target labels during the training process. Experiments are conducted on three datasets with different granularities. From the analysis of the experimental results, it can be seen that the named entity recognition method achieves higher accuracy and F1 value compared with the optimal baseline model, and also proves the effectiveness and generality of the modeling method proposed in this paper.}
}
@article{GAO2024103802,
title = {Self-supervised BGP-graph reasoning enhanced complex KBQA via SPARQL generation},
journal = {Information Processing & Management},
volume = {61},
number = {5},
pages = {103802},
year = {2024},
issn = {0306-4573},
doi = {https://doi.org/10.1016/j.ipm.2024.103802},
url = {https://www.sciencedirect.com/science/article/pii/S0306457324001614},
author = {Feng Gao and Yan Yang and Peng Gao and Ming Gu and Shangqing Zhao and Yuefeng Chen and Hao Yuan and Man Lan and Aimin Zhou and Liang He},
keywords = {Knowledge base question answering, Semantic parsing, Intermediate representation, SPARQL query generation, Basic graph pattern, Graph neural networks},
abstract = {Knowledge base question answering aims to answer complex questions from large-scale knowledge bases. Although existing generative language models that translate questions into SPARQL queries have achieved promising results, there are still generation errors due to redundancies or errors in the knowledge fed to the generative models and difficulties in representing the implicit logic of knowledge as the specific syntax of SPARQL. To address above issues, we propose TrackerQA, a novel self-supervised reasoning framework based on basic graph patterns (BGP) to determine precise paths and enhance SPARQL generation. First, we develop a contrastive learning semantic matching model to reduce the large knowledge searching space. Then, we built a BGP parser that parses the recalled knowledge and constraints into BGP graphs, which can deconstruct complex knowledge into BGP triples and naturally obtain supervision from gold SPARQL. Next, we design a self-supervised BGP graph neural network that encodes knowledge through graph transformation layers with directed message-passing control and employs a question-aware attention mechanism to predict the exact BGP paths. Finally, a SPARQL generator integrates the paths into a pre-trained language model to improve the performance of SPARQL generation. Experiments on the KQA Pro dataset show that our model achieves state-of-the-art answering accuracy scores of 95.32%, being the closest to the human level at 97.5%, and reasons out KB paths with F1 scores of 0.98 for nodes and 0.99 for edges.}
}
@article{OBRIEN2024249,
title = {Machine learning for hypothesis generation in biology and medicine: exploring the latent space of neuroscience and developmental bioelectricity},
journal = {Digital Discovery},
volume = {3},
number = {2},
pages = {249-263},
year = {2024},
issn = {2635-098X},
doi = {https://doi.org/10.1039/d3dd00185g},
url = {https://www.sciencedirect.com/science/article/pii/S2635098X2400024X},
author = {Thomas O'Brien and Joel Stremmel and Léo Pio-Lopez and Patrick McMillen and Cody Rasmussen-Ivey and Michael Levin},
abstract = {Artificial intelligence is a powerful tool that could be deployed to accelerate the scientific enterprise. Here we address a major unmet need: use of existing scientific literature to generate novel hypotheses. We use a deep symmetry between the fields of neuroscience and developmental bioelectricity to evaluate a new tool, FieldSHIFT. FieldSHIFT is an in-context learning framework using a large language model to facilitate candidate scientific research from existing published studies, serving as a tool to generate hypotheses at scale. We release a new dataset for translating between the neuroscience and developmental bioelectricity domains and show how FieldSHIFT helps human scientists explore a latent space of papers that could exist, providing a rich field of suggested future research. We demonstrate the performance of FieldSHIFT for hypothesis generation relative to human-generated developmental biology research directions then test a key prediction of this model using bioinformatics, showing a surprising conservation of molecular mechanisms involved in cognitive behavior and developmental morphogenesis. By allowing scientists to rapidly explore symmetries and meta-parameters that exist in a corpus of scientific papers, we show how machine learning can potentiate human creativity and assist with one of the most interesting and crucial aspects of research: identifying insights from data and generating potential candidates for research agendas.}
}
@article{TCHUITCHEU2024110734,
title = {Table representation learning using heterogeneous graph embedding},
journal = {Pattern Recognition},
volume = {156},
pages = {110734},
year = {2024},
issn = {0031-3203},
doi = {https://doi.org/10.1016/j.patcog.2024.110734},
url = {https://www.sciencedirect.com/science/article/pii/S0031320324004850},
author = {Willy Carlos Tchuitcheu and Tan Lu and Ann Dooms},
keywords = {Document parsing, Table representation learning, Semantic meta-path, Heterogeneous graph embedding, Permutation invariance},
abstract = {Tables, especially when having complex layouts, contain rich semantic information. However, effectively learning from tables to uncover such semantic information remains challenging. The rapid progress in natural language processing does not necessarily correspond to equivalent advancements in table parsing, which often requires joint visual and language modeling. Indeed, humans can quickly derive semantic meaning from table entries by associating them with corresponding column and/or row headers. Motivated by this observation, we propose a new heterogeneous Graph-based Table Representation Learning (GTRL) framework. GTRL combines graph-based visual modeling with sequence-based language modeling to learn granular per-cell embeddings that are sensitive to the semantic meaning of cells within their corresponding table context. We systematically evaluate the proposed GTRL framework using two datasets: a new adhesive table benchmark comprising complex tables extracted from industrial documents for learning per-entry semantics, and a publicly available large-scale dataset that enables learning header semantics from column tables. Experimental results demonstrate the competitive performance of the proposed GTRL, which often exhibits reduced computational complexity compared to state-of-the-art table representation learning models.}
}
@article{GIORDANO20241170,
title = {POPCORN: Fictional and Synthetic Intelligence Reports for Named Entity Recognition and Relation Extraction Tasks},
journal = {Procedia Computer Science},
volume = {246},
pages = {1170-1180},
year = {2024},
note = {28th International Conference on Knowledge Based and Intelligent information and Engineering Systems (KES 2024)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.09.542},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924025870},
author = {Bastien Giordano and Maxime Prieur and Nakanyseth Vuth and Sylvain Verdy and Kévin Cousot and Gilles Sérasset and Guillaume Gadek and Didier Schwab and Cédric Lopez},
keywords = {Synthetic Data Generation, Dataset, Natural Language Processing, Large Language Models, Information Extraction},
abstract = {POPCORN is a research project aiming at maturing Information Extraction (IE) solutions for intelligence services. Due to defense security constraints, reports analyzed by intelligence services are not to be accessible to the scientific community. To address this challenge, we propose a dataset made of “fictional” (handcrafted) and “synthetic” (AI generated) French reports. Those synthetic reports are produced by an innovative approach that generates texts closely resembling real-world intelligence reports, facilitating the training and evaluation of IE tasks such as Entity and Relation Extraction. Experiments demonstrate the interest of synthetic reports to enhance the performance of IE models, showcasing their potential to augment real-world intelligence operations.}
}
@article{BOURDIN2024396,
title = {NLP in SMEs for industry 4.0: opportunities and challenges},
journal = {Procedia Computer Science},
volume = {239},
pages = {396-403},
year = {2024},
note = {CENTERIS – International Conference on ENTERprise Information Systems / ProjMAN - International Conference on Project MANagement / HCist - International Conference on Health and Social Care Information Systems and Technologies 2023},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.06.186},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924014297},
author = {Mathieu Bourdin and Thomas Paviot and Robert Pellerin and Samir Lamouri},
keywords = {Natural Language Processing, Industry 4.0, Machine Learning, Large Language Models, SMEs},
abstract = {Natural Language Processing is the field of Computer Science that focuses on analyzing and processing natural language, mainly human text or speech. Recent trends in Natural Language Processing have led to the development of Large Language Models (LLMs): huge models trained on high amounts of data that achieve unprecedented performances in many tasks, such as answering questions, summarizing texts, or coding. These new tools have a wide range of applications and are being developed by many companies. However, Small and Medium Enterprises (SMEs) struggle to implement these new technologies, mainly because of the lack of resources. This paper aims to show the opportunities and challenges related to NLP-based solutions in SMEs based on a literature review. The main result is that NLP-based solutions have a wide range of applications in various companies, including SMEs, and may lead to many changes. However, there are still many obstacles to developing these tools in SMEs: SMEs lack specialized know-how to develop these solutions and do not often have standardized data. Moreover, there exists nearly no support for SMEs in the scientific literature to develop these tools.}
}
@article{CLAY2025109808,
title = {Natural language processing techniques applied to the electronic health record in clinical research and practice - an introduction to methodologies},
journal = {Computers in Biology and Medicine},
volume = {188},
pages = {109808},
year = {2025},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2025.109808},
url = {https://www.sciencedirect.com/science/article/pii/S0010482525001581},
author = {Benjamin Clay and Henry I. Bergman and Safa Salim and Gabriele Pergola and Joseph Shalhoub and Alun H. Davies},
keywords = {natural language processing, NLP, methodology, electronic health record, EHR},
abstract = {Natural Language Processing (NLP) has the potential to revolutionise clinical research utilising Electronic Health Records (EHR) through the automated analysis of unstructured free text. Despite this potential, relatively few applications have entered real-world clinical practice. This paper aims to introduce the whole pipeline of NLP methodologies for EHR analysis to the clinical researcher, with case studies to demonstrate the application of these methods in the existing literature. Essential pre-processing steps are introduced, followed by the two major classes of analytical frameworks: statistical methods and Artificial Neural Networks (ANNs). Case studies which apply statistical and ANN-based methods are then provided and discussed, illustrating information extraction tasks for objective and subjective information, and classification/prediction tasks using supervised and unsupervised approaches. State-of-the-art large language models and future directions for research are then discussed. This educational article aims to bridge the gap between the clinical researcher and the NLP expert, providing clinicians with a background understanding of the NLP techniques relevant to EHR analysis, allowing engagement with this rapidly evolving area of research, which is likely to have a major impact on clinical practice in coming years.}
}
@article{ZNAIDI2024408,
title = {Automatic Abstracting For Bibliographic Record Semantic Enrichment},
journal = {Procedia Computer Science},
volume = {244},
pages = {408-415},
year = {2024},
note = {6th International Conference on AI in Computational Linguistics},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.10.215},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924030163},
author = {Nassreddine Znaidi and Amel Fraisse and Fadoua Ouamani},
keywords = {Bibliographic record, Multilingualism, Automatic summarizing, Natural language processing, Large Language Model},
abstract = {Cultural heritage institutions store and digitize large amounts of bibliographic data within archives to make records accessible to archivists, librarians, and the general public. However, cataloging standards vary from one archive to another, which limits the sharing and use of these data. To address this issue, it is necessary to work on multilingual bibliographic records and enrich them. This would help standardize and harmonize the information, facilitating interoperability between different databases and systems. Enriching multilingual bibliographic data is essential to open up and provide broader access to these resources, thereby enhancing the dissemination of cultural heritage and enabling more efficient use by an international audience. This paper proposes a new methodology built within the framework of the interdisciplinary ROSETTA project, dedicated to enrichment of multilingual Bibliographic Records for Transnational Works. To experiment with our approach, we select 30 transnational literary works that have been translated into 15 languages, including non-dominant languages. We aggregate multilingual bibliographic records for these works from various sources. We employ an Large language model(LLM) model to enrich these records by generating summaries of works and calculating the similarity between different translations. To ensure quality and accuracy, we had Mark Twain experts at Stanford University meticulously evaluate each summary for fidelity, clarity, and coherence, and received positive feedback highlighting their precision and ability to capture the essence of the original work.}
}
@article{PANG2025102852,
title = {Towards cognition-augmented human-centric assembly: A visual computation perspective},
journal = {Robotics and Computer-Integrated Manufacturing},
volume = {91},
pages = {102852},
year = {2025},
issn = {0736-5845},
doi = {https://doi.org/10.1016/j.rcim.2024.102852},
url = {https://www.sciencedirect.com/science/article/pii/S073658452400139X},
author = {Jiazhen Pang and Pai Zheng and Junming Fan and Tianyuan Liu},
keywords = {Cognitive assistance, Human-centric assembly, Computer vision, Metaverse, Cloud service, Large language model, Brain computer interface},
abstract = {Human-centric assembly is emerging as a promising paradigm for achieving mass personalization in the context of Industry 5.0, as it fully capitalizes on the advantages of human flexibility with robot assistance. However, in small-batch and highly customized assembly tasks, frequently changes in production procedures pose significant cognition challenges. To address this, leveraging computer vision technology to enhance human cognition becomes a feasible solution. Therefore, this review aims to explore the cognitive characteristics of human beings and classify existing computer vision technologies in a manner that discusses the future development of cognition-augmented human-centric assembly. The concept of cognition-augmented assembly is first proposed based on the brain's functional structure - the frontal, parietal, temporal, and occipital lobes. Corresponding to these brain regions, cognitive issues in spatiality, memory, knowledge, and decision-making are summarized. Recent studies conducted between 2014 and 2023 on visual computation of assembly are categorized into four groups: position registration, multi-layer recognition, contextual perception, and mixed-reality fusion, all aimed at addressing these cognitive challenges. The applications and limitations of current computer vision technology are discussed. Furthermore, considering the rapidly evolving technologies such as the metaverse, cloud services, large language models, and brain-computer interfaces, future trends on computer vision are prospected to augment human cognition corresponding to the cognitive issues.}
}
@article{KAGAN2024100658,
title = {Toward a nomenclature consensus for diverse intelligent systems: Call for collaboration},
journal = {The Innovation},
volume = {5},
number = {5},
pages = {100658},
year = {2024},
issn = {2666-6758},
doi = {https://doi.org/10.1016/j.xinn.2024.100658},
url = {https://www.sciencedirect.com/science/article/pii/S2666675824000961},
author = {Brett J. Kagan and Michael Mahlis and Anjali Bhat and Josh Bongard and Victor M. Cole and Phillip Corlett and Christopher Gyngell and Thomas Hartung and Bianca Jupp and Michael Levin and Tamra Lysaght and Nicholas Opie and Adeel Razi and Lena Smirnova and Ian Tennant and Peter Thestrup Wade and Ge Wang},
abstract = {Summary
Disagreements about language use are common both between and within fields. Where interests require multidisciplinary collaboration or the field of research has the potential to impact society at large, it becomes critical to minimize these disagreements where possible. The development of diverse intelligent systems, regardless of the substrate (e.g., silicon vs. biology), is a case where both conditions are met. Significant advancements have occurred in the development of technology progressing toward these diverse intelligence systems. Whether progress is silicon based, such as the use of large language models, or through synthetic biology methods, such as the development of organoids, a clear need for a community-based approach to seeking consensus on nomenclature is now vital. Here, we welcome collaboration from the wider scientific community, proposing a pathway forward to achieving this intention, highlighting key terms and fields of relevance, and suggesting potential consensus-making methods to be applied.}
}
@article{NGUYEN2025103949,
title = {Retrieve–Revise–Refine: A novel framework for retrieval of concise entailing legal article set},
journal = {Information Processing & Management},
volume = {62},
number = {1},
pages = {103949},
year = {2025},
issn = {0306-4573},
doi = {https://doi.org/10.1016/j.ipm.2024.103949},
url = {https://www.sciencedirect.com/science/article/pii/S030645732400308X},
author = {Chau Nguyen and Phuong Nguyen and Le-Minh Nguyen},
keywords = {Retrieval–Revise–Refine framework, Legal article set retrieval, Information retrieval, COLIEE competition, Large language models},
abstract = {The retrieval of entailing legal article sets aims to identify a concise set of legal articles that holds an entailment relationship with a legal query or its negation. Unlike traditional information retrieval that focuses on relevance ranking, this task demands conciseness. However, prior research has inadequately addressed this need by employing traditional methods. To bridge this gap, we propose a three-stage Retrieve–Revise–Refine framework which explicitly addresses the need for conciseness by utilizing both small and large language models (LMs) in distinct yet complementary roles. Empirical evaluations on the COLIEE 2022 and 2023 datasets demonstrate that our framework significantly enhances performance, achieving absolute increases in the macro F2 score by 3.17% and 4.24% over previous state-of-the-art methods, respectively. Specifically, our Retrieve stage, employing various tailored fine-tuning strategies for small LMs, achieved a recall rate exceeding 0.90 in the top-5 results alone—ensuring comprehensive coverage of entailing articles. In the subsequent Revise stage, large LMs narrow this set, improving precision while sacrificing minimal coverage. The Refine stage further enhances precision by leveraging specialized insights from small LMs, resulting in a relative improvement of up to 19.15% in the number of concise article sets retrieved compared to previous methods. Our framework offers a promising direction for further research on specialized methods for retrieving concise sets of entailing legal articles, thereby more effectively meeting the task’s demands.}
}
@article{ELZ2024104017,
title = {The IDMP Ontology – A Catalyst to Unleash the Potential of AI and Accelerate Data-Driven Decisions with Industry-Wide Standards},
journal = {Drug Discovery Today},
volume = {29},
number = {6},
pages = {104017},
year = {2024},
issn = {1359-6446},
doi = {https://doi.org/10.1016/j.drudis.2024.104017},
url = {https://www.sciencedirect.com/science/article/pii/S1359644624001429},
author = {Sheila R. Elz and Gerd R. Kleemann and Torsten Osthus and Martin Petracchi and Raphael Sergent}
}
@article{KEARNS2024543,
title = {The Application of Knowledge Engineering via the Use of a Biomimetic Digital Twin Ecosystem, Phenotype-Driven Variant Analysis, and Exome Sequencing to Understand the Molecular Mechanisms of Disease},
journal = {The Journal of Molecular Diagnostics},
volume = {26},
number = {7},
pages = {543-551},
year = {2024},
issn = {1525-1578},
doi = {https://doi.org/10.1016/j.jmoldx.2024.03.004},
url = {https://www.sciencedirect.com/science/article/pii/S152515782400062X},
author = {William G. Kearns and Georgios Stamoulis and Joseph Glick and Lawrence Baisch and Andrew Benner and Dalton Brough and Luke Du and Bradford Wilson and Laura Kearns and Nicholas Ng and Maya Seshan and Raymond Anchan},
abstract = {Applied artificial intelligence, particularly large language models, in biomedical research is accelerating, but effective discovery and validation requires a toolset without limitations or bias. On January 30, 2023, the National Academies of Sciences, Engineering, and Medicine (NAS) appointed an ad hoc committee to identify the needs and opportunities to advance the mathematical, statistical, and computational foundations of digital twins in applications across science, medicine, engineering, and society. On December 15, 2023, the NAS released a 164-page report, “Foundational Research Gaps and Future Directions for Digital Twins.” This report described the importance of using digital twins in biomedical research. The current study was designed to develop an innovative method that incorporated phenotype-ranking algorithms with knowledge engineering via a biomimetic digital twin ecosystem. This ecosystem applied real-world reasoning principles to nonnormalized, raw data to identify hidden or "dark" data. Clinical exome sequencing study on patients with endometriosis indicated four variants of unknown clinical significance potentially associated with endometriosis-related disorders in nearly all patients analyzed. One variant of unknown clinical significance was identified in all patient samples and could be a biomarker for diagnostics. To the best of our knowledge, this is the first study to incorporate the recommendations of the NAS to biomedical research. This method can be used to understand the mechanisms of any disease, for virtual clinical trials, and to identify effective new therapies.}
}
@article{BU2024111148,
title = {Efficient utilization of pre-trained models: A review of sentiment analysis via prompt learning},
journal = {Knowledge-Based Systems},
volume = {283},
pages = {111148},
year = {2024},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2023.111148},
url = {https://www.sciencedirect.com/science/article/pii/S0950705123008985},
author = {Kun Bu and Yuanchao Liu and Xiaolong Ju},
keywords = {Sentiment analysis, Prompt learning, Word embedding, Pre-trained models, Natural language processing},
abstract = {Sentiment analysis is one of the traditional well-known tasks in Natural Language Processing (NLP) research. In recent years, Pre-trained Models (PMs) have become one of the frontiers of NLP, and the knowledge in PMs is usually leveraged to improve machine learning models' performance for a variety of downstream NLP tasks including sentiment analysis. However, there are also some shortcomings in PM-based approaches. For example, many studies pointed out there are gaps between pre-training and fine-tuning. In addition, because of the time-consuming and high-cost data annotation process, the labeled training data are usually precious and scarce, which often leads to the over-fitting of models. The recent advent of prompt learning technology provides a promising solution to the above challenges. In this paper, we first discussed the background of prompt learning and its basic principle. Prompt learning changes the model input by adding templates, allowing learning tasks to adapt actively to pre-trained models, and therefore can promote the innovation and applicability of pre-trained models. Then we investigated the evolution of sentiment analysis and explored the application of prompt learning to different sentiment analysis tasks. Our research and review show that prompt learning is more suitable for sentiment analysis tasks and can achieve good performance. Finally, we also provided some future research directions on prompt-based sentiment analysis. Our survey demonstrated that prompt learning can facilitate the efficient utilization of pre-trained models in sentiment analysis and other tasks, which makes it a new paradigm worthy of further exploration.}
}
@article{ZENG2024123400,
title = {Research on the application of knowledge mapping and knowledge structure construction based on adaptive learning model},
journal = {Expert Systems with Applications},
volume = {249},
pages = {123400},
year = {2024},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2024.123400},
url = {https://www.sciencedirect.com/science/article/pii/S0957417424002653},
author = {Xiyin Zeng and Shouqiang Liu},
keywords = {Personalized learing, Pedagogy, Interactive learning environments, Applications},
abstract = {This project has developed a geometry learning software that integrates multiple computer technologies to address the challenges of deep analysis of knowledge points and establishing connections in learning software. The software combines Long Short-Term Memory (LSTM) and Residual Neural Network (ResNet101) to encode text and image features. A self-attention mechanism is used to fuse information from both modalities, enabling decoding of geometric models and classification of corresponding knowledge points.This project uses LSTM and ResNet101 models to extract text and visual features for problem-solving using the Multi Mode Thinking Chain (CoT) method. Classification labels are utilized to generate text responses for problem-solving ideas. Furthermore, a recommendation module is proposed, which combines knowledge tracking and neural collaborative filtering algorithms to capture student behavior and knowledge point vectors. Implicit factors representing students' mastery of different knowledge points are used as inputs in neural collaborative filtering for personalized recommendations. The results demonstrate improvements in accuracy using the ResNet + LSTM multimodal algorithm, achieving a 13 % increase compared to single-modal classification. The multimodal CoT approach also outperforms language models like GPT3.5 and VisualBert by 10 %. Additionally, the combined algorithm of knowledge tracking and neural collaborative filtering shows a 13.3 % higher F1 value compared to ordinary algorithms, confirming the superiority of the adopted method in this project.}
}
@article{LIU2025112278,
title = {Agent design pattern catalogue: A collection of architectural patterns for foundation model based agents},
journal = {Journal of Systems and Software},
volume = {220},
pages = {112278},
year = {2025},
issn = {0164-1212},
doi = {https://doi.org/10.1016/j.jss.2024.112278},
url = {https://www.sciencedirect.com/science/article/pii/S0164121224003224},
author = {Yue Liu and Sin Kit Lo and Qinghua Lu and Liming Zhu and Dehai Zhao and Xiwei Xu and Stefan Harrer and Jon Whittle},
keywords = {Agent, Foundation model, Large language model, Pattern, Software engineering, Responsible AI},
abstract = {Foundation model-enabled generative artificial intelligence facilitates the development and implementation of agents, which can leverage distinguished reasoning and language processing capabilities to takes a proactive, autonomous role to pursue users’ goals. Nevertheless, there is a lack of systematic knowledge to guide practitioners in designing the agents considering challenges of goal-seeking (including generating instrumental goals and plans), such as hallucinations inherent in foundation models, explainability of reasoning process, complex accountability, etc. To address this issue, we have performed a systematic literature review to understand the state-of-the-art foundation model-based agents and the broader ecosystem. In this paper, we present a pattern catalogue consisting of 18 architectural patterns with analyses of the context, forces, and trade-offs as the outcomes from the previous literature review. We propose a decision model for selecting the patterns. The proposed catalogue can provide holistic guidance for the effective use of patterns, and support the architecture design of foundation model-based agents by facilitating goal-seeking and plan generation.}
}
@article{ARMARY2025100693,
title = {Ontology learning towards expressiveness: A survey},
journal = {Computer Science Review},
volume = {56},
pages = {100693},
year = {2025},
issn = {1574-0137},
doi = {https://doi.org/10.1016/j.cosrev.2024.100693},
url = {https://www.sciencedirect.com/science/article/pii/S1574013724000765},
author = {Pauline Armary and Cheikh Brahim El-Vaigh and Ouassila {Labbani Narsis} and Christophe Nicolle},
keywords = {Ontology learning, Heavyweight ontology, Ontology, Axioms, Rules},
abstract = {Ontology learning, particularly axiom learning, is a challenging task that focuses on building expressive and decidable ontologies. The literature proposes several research efforts aimed to resolve the complexities inherent in axiom and rule learning, which seeks to automatically infer logical constructs from diverse data sources. The goal of this paper is to conduct a comprehensive review of existing work in this domain. It aims to critically analyze the contributions and limitations of current approaches, providing a clear understanding of the state-of-the-art and identifying areas where further research is needed.}
}
@article{ZAVARELLA2024e32479,
title = {Triplétoile: Extraction of knowledge from microblogging text},
journal = {Heliyon},
volume = {10},
number = {12},
pages = {e32479},
year = {2024},
issn = {2405-8440},
doi = {https://doi.org/10.1016/j.heliyon.2024.e32479},
url = {https://www.sciencedirect.com/science/article/pii/S2405844024085104},
author = {Vanni Zavarella and Sergio Consoli and Diego {Reforgiato Recupero} and Gianni Fenu and Simone Angioni and Davide Buscaldi and Danilo Dessí and Francesco Osborne},
keywords = {Information extraction, Knowledge graphs, Social media analysis, Named entity recognition, Hierarchical clustering, Word embeddings},
abstract = {Numerous methods and pipelines have recently emerged for the automatic extraction of knowledge graphs from documents such as scientific publications and patents. However, adapting these methods to incorporate alternative text sources like micro-blogging posts and news has proven challenging as they struggle to model open-domain entities and relations, typically found in these sources. In this paper, we propose an enhanced information extraction pipeline tailored to the extraction of a knowledge graph comprising open-domain entities from micro-blogging posts on social media platforms. Our pipeline leverages dependency parsing and classifies entity relations in an unsupervised manner through hierarchical clustering over word embeddings. We provide a use case on extracting semantic triples from a corpus of 100 thousand tweets about digital transformation and publicly release the generated knowledge graph. On the same dataset, we conduct two experimental evaluations, showing that the system produces triples with precision over 95% and outperforms similar pipelines of around 5% in terms of precision, while generating a comparatively higher number of triples.}
}
@article{GAVRIILIDIS20241886,
title = {A mini-review on perturbation modelling across single-cell omic modalities},
journal = {Computational and Structural Biotechnology Journal},
volume = {23},
pages = {1886-1896},
year = {2024},
issn = {2001-0370},
doi = {https://doi.org/10.1016/j.csbj.2024.04.058},
url = {https://www.sciencedirect.com/science/article/pii/S2001037024001417},
author = {George I. Gavriilidis and Vasileios Vasileiou and Aspasia Orfanou and Naveed Ishaque and Fotis Psomopoulos},
keywords = {Perturbation, Single-cell RNA sequencing, ScRNAseq, Machine learning, Deep learning},
abstract = {Recent advances in single-cell omics technology have transformed the landscape of cellular and molecular research, enriching the scope and intricacy of cellular characterisation. Perturbation modelling seeks to comprehensively grasp the effects of external influences like disease onset or molecular knock-outs or external stimulants on cellular physiology, specifically on transcription factors, signal transducers, biological pathways, and dynamic cell states. Machine and deep learning tools transform complex perturbational phenomena in algorithmically tractable tasks to formulate predictions based on various types of single-cell datasets. However, the recent surge in tools and datasets makes it challenging for experimental biologists and computational scientists to keep track of the recent advances in this rapidly expanding filed of single-cell modelling. Here, we recapitulate the main objectives of perturbation modelling and summarise novel single-cell perturbation technologies based on genetic manipulation like CRISPR or compounds, spanning across omic modalities. We then concisely review a burgeoning group of computational methods extending from classical statistical inference methodologies to various machine and deep learning architectures like shallow models or autoencoders, to biologically informed approaches based on gene regulatory networks, and to combinatorial efforts reminiscent of ensemble learning. We also discuss the rising trend of large foundational models in single-cell perturbation modelling inspired by large language models. Lastly, we critically assess the challenges that underline single-cell perturbation modelling while pointing towards relevant future perspectives like perturbation atlases, multi-omics and spatial datasets, causal machine learning for interpretability, multi-task learning for performance and explainability as well as prospects for solving interoperability and benchmarking pitfalls.}
}
@article{LI2025100894,
title = {A concise review of intelligent game agent},
journal = {Entertainment Computing},
volume = {52},
pages = {100894},
year = {2025},
issn = {1875-9521},
doi = {https://doi.org/10.1016/j.entcom.2024.100894},
url = {https://www.sciencedirect.com/science/article/pii/S1875952124002623},
author = {Hui Li and Xinyi Pang and Bixia Sun and Kexin Liu},
keywords = {Intelligent agent, Artificial intelligence, Monte Carlo tree, Reinforcement learning, Large language models},
abstract = {Intelligent game agents are crafted using AI technologies to mimic player behavior and make decisions autonomously. Over the past decades, the scope of intelligent agents has broadened from chess to encompass content generation, player modeling, and result prediction, reflecting the field’s evolving and multifaceted nature. In this paper, we conduct a systematic review of recent literature on intelligent methods and applications of game agents, along with general game agent frameworks. Our findings suggest that creating general intelligent agents remains a significant challenge, yet it is worthwhile to explore methods that better integrate the strengths of different techniques to build more robust and adaptable intelligent game agents.}
}
@article{SHAHRIAR2025104358,
title = {A comprehensive review of current trends, challenges, and opportunities in text data privacy},
journal = {Computers & Security},
volume = {151},
pages = {104358},
year = {2025},
issn = {0167-4048},
doi = {https://doi.org/10.1016/j.cose.2025.104358},
url = {https://www.sciencedirect.com/science/article/pii/S0167404825000471},
author = {Sakib Shahriar and Rozita Dara and Rajen Akalu},
keywords = {Privacy enhancing solutions, Text data, Natural language processing, Artificial intelligence, Machine learning, Privacy risk},
abstract = {The emergence of smartphones and internet accessibility around the globe have enabled billions of people to be connected to the digital world. Due to the popularity of instant messaging applications and social media, a large quantity of personal data is in text format, and processing text data in a privacy-preserving manner poses unique challenges. While existing reviews focus on privacy concerns from specific algorithmic perspectives or target only a particular domain, such as healthcare or smart metering, they fail to provide a comprehensive view that addresses the multi-layered privacy risks inherent to text data processing. Existing works often limit their scope to specialized solutions like differential privacy, anonymization, or federated learning, neglecting a broader spectrum of challenges. To fill this gap, we present a comprehensive review of privacy-enhancing solutions for text data processing in the present literature and classify the works into six categories of privacy risks: (i) unintentional memorability, (ii) membership inference, (iii) exposure and re-identification, (iv) language models and word embeddings, (v) authorship attribution, and (vi) collaborative processing. We then analyze existing privacy-enhancing solutions for text data by considering the aforementioned privacy risks. Finally, we identified several research gaps, including the need for comprehensive privacy metrics, explainable algorithms, and privacy in social media analytics.}
}
@article{YU2024104765,
title = {Artificial intelligence in paleontology},
journal = {Earth-Science Reviews},
volume = {252},
pages = {104765},
year = {2024},
issn = {0012-8252},
doi = {https://doi.org/10.1016/j.earscirev.2024.104765},
url = {https://www.sciencedirect.com/science/article/pii/S0012825224000928},
author = {Congyu Yu and Fangbo Qin and Akinobu Watanabe and Weiqi Yao and Ying Li and Zichuan Qin and Yuming Liu and Haibing Wang and Qigao Jiangzuo and Allison Y. Hsiang and Chao Ma and Emily Rayfield and Michael J. Benton and Xing Xu},
keywords = {Paleontology, Fossil, Artificial intelligence, Machine learning, Deep learning, Classification, Segmentation, Prediction},
abstract = {The accumulation of large datasets and increasing data availability have led to the emergence of data-driven paleontological studies, which reveal an unprecedented picture of evolutionary history. However, the fast-growing quantity and complication of data modalities make data processing laborious and inconsistent, while also lacking clear benchmarks to evaluate data collection and generation, and the performances of different methods on similar tasks. Recently, artificial intelligence (AI) has become widely practiced across scientific disciplines, but not so much to date in paleontology where traditionally manual workflows have been more usual. In this study, we review >70 paleontological AI studies since the 1980s, covering major tasks including micro- and macrofossil classification, image segmentation, and prediction. These studies feature a wide range of techniques such as Knowledge-Based Systems (KBS), neural networks, transfer learning, and many other machine learning methods to automate a variety of paleontological research workflows. Here, we discuss their methods, datasets, and performance and compare them with more conventional AI studies. We attribute the recent increase in paleontological AI studies most to the lowering of the entry bar in training and deployment of AI models rather than innovations in fossil data compilation and methods. We also present recently developed AI implementations such as diffusion model content generation and Large Language Models (LLMs) that may interface with paleontological research in the future. Even though AI has not yet been a significant part of the paleontologist's toolkit, successful implementation of AI is growing and shows promise for paradigm-transformative effects on paleontological research in the years to come.}
}
@article{ZHAO2024111843,
title = {From easy to hard: Improving personalized response generation of task-oriented dialogue systems by leveraging capacity in open-domain dialogues},
journal = {Knowledge-Based Systems},
volume = {295},
pages = {111843},
year = {2024},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2024.111843},
url = {https://www.sciencedirect.com/science/article/pii/S0950705124004775},
author = {Meng Zhao and Lifang Wang and Zejun Jiang and Yushuang Liu and Ronghan Li and Zhongtian Hu and Xinyu Lu},
keywords = {Task-oriented dialogue system, Personalized response generation, Knowledge base, Pre-trained language model},
abstract = {A task-oriented dialogue system (TOD) is an important application of artificial intelligence. In the past few years, works on personalized TODs have attracted increased research attention and have seen much progress. The main challenge of such dialogue systems is finding ways to exploit user profiles under conditions of fixed and monolithic dialogue style. However, most of the existing works overlook the observation that the personalization capability of the dialogue system is fundamental and generic, and they treat all attributes of the user profile equally throughout the dialogue flows, which makes them inadequate for developing a well-performing personalized TOD. In this paper, we propose a two-stage learning framework equipped with GPT2 as a backbone to alleviate the above two problems. In the first learning phase, we finetune the GPT2 model on the personalized open-domain dialogues to preliminarily acquire personalization power. Then, we transfer this power to personalized task-oriented dialogues for the second stage of learning. After that, we enable the proposed model to be capable of the desired personalization capacity. Moreover, we present a dynamic profile fusion mechanism and an auxiliary task that detects which attributes contribute to the current utterance to facilitate the model’s performance. Eventually, we rewrite the attribute descriptions of user profiles in sentences to mitigate the consistency gap between the open-domain and task-oriented dialogues. The experimental results show that the proposed model achieves superior results compared to the state-of-the-art models on two versions of the Personalized bAbI dataset.}
}
@article{ISHMAM2024102270,
title = {From image to language: A critical analysis of Visual Question Answering (VQA) approaches, challenges, and opportunities},
journal = {Information Fusion},
volume = {106},
pages = {102270},
year = {2024},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2024.102270},
url = {https://www.sciencedirect.com/science/article/pii/S1566253524000484},
author = {Md. Farhan Ishmam and Md. Sakib Hossain Shovon and M.F. Mridha and Nilanjan Dey},
keywords = {Visual Question Answering, Vision language pre-training, Multimodal learning, Multimodal large language models},
abstract = {The multimodal task of Visual Question Answering (VQA) encompassing elements of Computer Vision (CV) and Natural Language Processing (NLP), aims to generate answers to questions on any visual input. Over time, the scope of VQA has expanded from datasets focusing on an extensive collection of natural images to datasets featuring synthetic images, video, 3D environments, and various other visual inputs. The emergence of large pre-trained networks has shifted the early VQA approaches relying on feature extraction and fusion schemes to vision language pre-training (VLP) techniques. However, there is a lack of comprehensive surveys that encompass both traditional VQA architectures and contemporary VLP-based methods. Furthermore, the VLP challenges in the lens of VQA haven’t been thoroughly explored, leaving room for potential open problems to emerge. Our work presents a survey in the domain of VQA that delves into the intricacies of VQA datasets and methods over the field’s history, introduces a detailed taxonomy to categorize the facets of VQA, and highlights the recent trends, challenges, and scopes for improvement. We further generalize VQA to multimodal question answering, explore tasks related to VQA, and present a set of open problems for future investigation. The work aims to navigate both beginners and experts by shedding light on the potential avenues of research and expanding the boundaries of the field.}
}
@article{BUGHIO20245330,
title = {GenAI in Rule-based Systems for IoMT Security: Testing and Evaluation},
journal = {Procedia Computer Science},
volume = {246},
pages = {5330-5339},
year = {2024},
note = {28th International Conference on Knowledge Based and Intelligent information and Engineering Systems (KES 2024)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.09.652},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924027078},
author = {Kulsoom S. Bughio and David M. Cook and Syed Afaq A. Shah},
keywords = {Artificial Intelligence, IoMT, Ruled-based Systems, Vulnerability Detection, Gen AI},
abstract = {Generative AI (GenAI) represents a significant advancement in Artificial intelligence research, offering numerous benefits and opening new avenues for innovation across various domains. In healthcare, Generative AI has shown promise in applications such as drug discovery, personalized medicine, and medical imaging. This paper examines the role of Generative AI in rule-based systems, where vulnerabilities are detected with the help of formal logic. In this context, the ruleset is generated and tested to evaluate the performance of rule-based systems with the aid of GenAI. The effectiveness of the GenAI tool was evaluated using a publicly available case study from a laboratory setting. The results show that using generative Artificial intelligence in rule-based systems leads to increased creativity, continuous learning, and robust performance. GenAI responded to each use case and provided the desired results compared to traditional rule-based systems. This integration of advanced AI techniques with traditional rule-based systems ensures that these hybrid systems perform reliably and effectively.}
}
@article{AVOGADRO2024112447,
title = {Feature/vector entity retrieval and disambiguation techniques to create a supervised and unsupervised semantic table interpretation approach},
journal = {Knowledge-Based Systems},
volume = {304},
pages = {112447},
year = {2024},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2024.112447},
url = {https://www.sciencedirect.com/science/article/pii/S0950705124010815},
author = {Roberto Avogadro and Fabio D’Adda and Marco Cremaschi},
keywords = {Semantic web, Knowledge base, Knowledge base construction, Knowledge base extension, Knowledge graph, Semantic table interpretation, Table annotation, Data enrichment, Tabular data},
abstract = {Recently, there has been an increasing interest in extracting and annotating tables on the Web. This activity allows the transformation of textual data into machine-readable formats to enable the execution of various artificial intelligence tasks, e.g., semantic search and dataset extension. Semantic Table Interpretation (STI) is the process of annotating elements in a table. The paper explores Semantic Table Interpretation, addressing the challenges of Entity Retrieval and Entity Disambiguation in the context of Knowledge Graphs (KGs). It introduces LamAPI, an Information Retrieval system with string/type-based filtering and s-elBat, an Entity Disambiguation technique that combines heuristic and ML-based approaches. By applying the acquired know-how in the field and extracting algorithms, techniques and components from our previous STI approaches and the state of the art, we have created a new platform capable of annotating any tabular data, ensuring a high level of quality.}
}
@article{RASHIDI2025100688,
title = {Introduction to Artificial Intelligence and Machine Learning in Pathology and Medicine: Generative and Nongenerative Artificial Intelligence Basics},
journal = {Modern Pathology},
volume = {38},
number = {4},
pages = {100688},
year = {2025},
issn = {0893-3952},
doi = {https://doi.org/10.1016/j.modpat.2024.100688},
url = {https://www.sciencedirect.com/science/article/pii/S0893395224002680},
author = {Hooman H. Rashidi and Joshua Pantanowitz and Matthew G. Hanna and Ahmad P. Tafti and Parth Sanghani and Adam Buchinsky and Brandon Fennell and Mustafa Deebajah and Sarah Wheeler and Thomas Pearce and Ibrahim Abukhiran and Scott Robertson and Octavia Palmer and Mert Gur and Nam K. Tran and Liron Pantanowitz},
keywords = {artificial intelligence, ChatGPT, generative AI, generative pretrained transformer, machine learning, supervised & unsupervised ML},
abstract = {This manuscript serves as an introduction to a comprehensive 7-part review article series on artificial intelligence (AI) and machine learning (ML) and their current and future influence within pathology and medicine. This introductory review provides a comprehensive grasp of this fast-expanding realm and its potential to transform medical diagnosis, workflow, research, and education. Fundamental terminology employed in AI-ML is covered using an extensive dictionary. The article also provides a broad overview of the main domains in the AI-ML field, encompassing both generative and nongenerative (traditional) AI, thereby serving as a primer to the other 6 review articles in this series that describe the details about statistics, regulations, bias, ethical dilemmas, and ML-Ops in AI-ML. The intent of these review articles is to better equip individuals who are or will be working in an AI-enabled health care system.}
}
@article{ZHANG2024106073,
title = {Bayesian deep learning: An enhanced AI framework for legal reasoning alignment},
journal = {Computer Law & Security Review},
volume = {55},
pages = {106073},
year = {2024},
issn = {0267-3649},
doi = {https://doi.org/10.1016/j.clsr.2024.106073},
url = {https://www.sciencedirect.com/science/article/pii/S0267364924001390},
author = {Chuyue Zhang and Yuchen Meng},
keywords = {Legal AI, Legal reasoning, Deep learning, Bayesian deep learning, Bayesian neural networks},
abstract = {The integration of artificial intelligence into the field of law has penetrated the underlying logic of legal operations. Currently, legal AI systems face difficulties in representing legal knowledge, exhibit insufficient legal reasoning capabilities, have poor explainability, and are inefficient in handling causal inference and uncertainty. In legal practice, various legal reasoning methods (deductive reasoning, inductive reasoning, abductive reasoning, etc.) are often intertwined and used comprehensively. However, the reasoning modes employed by current legal AI systems are inadequate. Identifying AI models that are more suitable for legal reasoning is crucial for advancing the development of legal AI systems. Distinguished from the current high-profile large language models, we believe that Bayesian reasoning is highly compatible with legal reasoning, as it can perferm abductive reasoning, excel at causal inference, and admits the "defeasibility" of reasoning conclusions, which is consistent with the cognitive development pattern of legal professionals from apriori to posteriori. AI models based on Bayesian methods can also become the main technological support for legal AI systems. Bayesian neural networks have advantages in uncertainty modeling, avoiding overfitting, and explainability. Legal AI systems based on Bayesian deep learning frameworks can combine the advantages of deep learning and probabilistic graphical models, facilitating the exchange and supplementation of information between perception tasks and reasoning tasks. In this paper, we take perpetrator prediction systems and legal judegment prediction systems as examples to discuss the construction and basic operation modes of the Bayesian deep learning framework. Bayesian deep learning can enhance reasoning ability, improve the explainability of models, and make the reasoning process more transparent and visualizable. Furthermore, Bayesian deep learning framework is well-suited for human-machine collaborative tasks, enabling the complementary strengths of humans and machines.}
}
@article{LI2025129609,
title = {A novel rumor detection method focusing on social psychology with graph attention network},
journal = {Neurocomputing},
volume = {626},
pages = {129609},
year = {2025},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2025.129609},
url = {https://www.sciencedirect.com/science/article/pii/S0925231225002814},
author = {Lina Li and Guoxing Liu and Yu Liu and Qinghe Yu and Cheng Luo and Nianfeng Li},
keywords = {Rumor detection, Social psychology, Graph attention networks, Feature fusion, Large language models},
abstract = {The proliferation of online social media has led to an increase in the spread of rumors. Current rumor detection methods have not adequately considered the impact of social psychology and have neglected to integrate text features with other characteristics. This paper introduces a multi-feature fusion rumor detection model, Social Psychology-based Graph ATtention network (SPGAT), designed to enhance the accuracy of rumor detection. In this model, social psychological features are extracted using large language models, encompassing user emotion, social identity, group emotional resonance, and social influence. These features aim to deeply capture the essential attributes of rumors. Concurrently, a multi-head dynamic graph attention convolutional network is constructed. This network amalgamates complex structural features with essential features, thereby effectively capturing spatial propagation features and significant features while paying attention to the high-dimensional hidden features of rumors. Furthermore, a neural network is designed to comprehensively integrate the high-dimensional features of rumors, and rumor detection is achieved through a fully connected layer. Extensive experiments are conducted on three public datasets. Compared to the latest typical detection methods, the proposed method demonstrates certain advantages. Specifically, the accuracy and F1 score of rumor detection are improved by 5.87% and 4.4% on average on Weibo, PHEME 5, and PHEME 9 datasets compared to the latest baselines, respectively. Meanwhile, we verify and analyze the key role of socio-psychological characteristics in rumor propagation, which provides strong support for an in-depth understanding of the rumor propagation mechanism.}
}
@article{JIN2024104988,
title = {PubMed and beyond: biomedical literature search in the age of artificial intelligence},
journal = {eBioMedicine},
volume = {100},
pages = {104988},
year = {2024},
issn = {2352-3964},
doi = {https://doi.org/10.1016/j.ebiom.2024.104988},
url = {https://www.sciencedirect.com/science/article/pii/S2352396424000239},
author = {Qiao Jin and Robert Leaman and Zhiyong Lu},
keywords = {Artificial intelligence, Biomedical literature search},
abstract = {Summary
Biomedical research yields vast information, much of which is only accessible through the literature. Consequently, literature search is crucial for healthcare and biomedicine. Recent improvements in artificial intelligence (AI) have expanded functionality beyond keywords, but they might be unfamiliar to clinicians and researchers. In response, we present an overview of over 30 literature search tools tailored to common biomedical use cases, aiming at helping readers efficiently fulfill their information needs. We first discuss recent improvements and continued challenges of the widely used PubMed. Then, we describe AI-based literature search tools catering to five specific information needs: 1. Evidence-based medicine. 2. Precision medicine and genomics. 3. Searching by meaning, including questions. 4. Finding related articles with literature recommendation. 5. Discovering hidden associations through literature mining. Finally, we discuss the impacts of recent developments of large language models such as ChatGPT on biomedical information seeking.}
}
@article{XIA2023313,
title = {Enhancing intelligent IoT services development by integrated multi-token code completion},
journal = {Computer Communications},
volume = {212},
pages = {313-323},
year = {2023},
issn = {0140-3664},
doi = {https://doi.org/10.1016/j.comcom.2023.10.014},
url = {https://www.sciencedirect.com/science/article/pii/S0140366423003791},
author = {Yu Xia and Tian Liang and WeiHuan Min and Li Kuang and Honghao Gao},
keywords = {Intelligent device-free sensing, Code completion, Language model, Graph neural network},
abstract = {The Internet of Things (IoT) is a revolutionary network of interconnected devices embedded with sensors and software that enables seamless communication, data sharing, and intelligent decision-making in the form of IoT services. To facilitate the efficient development of IoT services, code completion technique provides a promising solution by providing suggestions for missing code snippets. The development trend of IoT services is to support more mobile device terminals. Mobile devices are portable and easy to use, allowing IoT device operation and management anytime and anywhere. However, the current multi-token completion methods struggle to guarantee code generation quality under the constraints of low resources and low latency, making it difficult to fully support IoT service development. We propose a multi-token code completion framework, S2RCC, which completes code from skeleton to refinement with dual encoder and dual decoder. The framework consists of two phases: first, the code skeleton, which is the simplification of code containing structure-sensitive tokens, is predicted based on the semantics of the code context; second, the broken context is repaired with the predicted skeleton, and then parsed into the code structure so that the specific tokens can be generated combining the semantics and structure of context. Furthermore, we then provide an implementation of the framework, representing the repaired code as an improved Heterogeneous code graph and fusing the semantics and structure of code context by the three-layer stacked attention. We conducted experiments on multi-token completion datasets, showing that our model has achieved the state-of-the-art with the smallest possible scale and the fastest generation speed.}
}
@article{JUST2024102883,
title = {Natural language processing for innovation search – Reviewing an emerging non-human innovation intermediary},
journal = {Technovation},
volume = {129},
pages = {102883},
year = {2024},
issn = {0166-4972},
doi = {https://doi.org/10.1016/j.technovation.2023.102883},
url = {https://www.sciencedirect.com/science/article/pii/S0166497223001943},
author = {Julian Just},
keywords = {Natural language processing, Innovation search, Innovation intermediation, Front-end of innovation, AI-based innovation management, Systematic literature review},
abstract = {Applying artificial intelligence (AI), especially natural language processing (NLP), to harness large amounts of information from patent databases, online communities, social media, or crowdsourcing platforms is becoming increasingly popular to help organizations find promising solutions. In the era of non-human innovation intermediaries, we should begin to view NLP not only as a useful technology applied in different innovation practices but also as an intermediary orchestrating valuable information. Previous research has not taken this perspective, and knowledge about its intermediation activities and functions is limited. This study reviews 167 academic articles to better understand how NLP approaches can enrich intermediation in early-stage innovation search. It identifies 18 distinctive innovation practices taking over activities like forecasting trends, illustrating technology and idea landscapes, filtering out distinctive contributions, recombining domain-specific and analogous knowledge, or matching problems with solutions. While certain NLP capabilities complement each other, the analysis shows that the choice of the most appropriate approach depends on the characteristics of the innovation practice. Innovation researchers and practitioners should rethink current roles and responsibilities in AI-based innovation processes. As seen in the recent emergence of large language models (LLMs), the rapidly evolving field offers many future research opportunities and practical benefits.}
}
@article{DING2025126232,
title = {Tagging knowledge concepts for math problems based on multi-label text classification},
journal = {Expert Systems with Applications},
volume = {267},
pages = {126232},
year = {2025},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2024.126232},
url = {https://www.sciencedirect.com/science/article/pii/S0957417424030999},
author = {Ziqi Ding and Xiaolu Wang and Yuzhuo Wu and Guitao Cao and Liangyu Chen},
keywords = {Hierarchical multi-label classification, Deep learning, Attention mechanism, K12 math problems},
abstract = {Tagging knowledge concepts for course problems is essential for intelligent tutoring systems. Traditional manual tagging methods, usually performed by domain experts, are time-consuming and subject to individual biases. Consequently, research on automatic tagging technology is of substantial practical importance. Recently, text classification techniques have been applied to this task; however, these methods are inadequate for math problems due to their complexity, which includes formulaic content and hierarchical relationships among knowledge concepts. Although large language models (LLMs) have also been explored for this purpose, their generative nature and high computational cost pose challenges for direct application in tutoring systems. In this paper, we propose an automatic knowledge concept tagging model LHABS based on RoBERTa. This model integrates hierarchical label-semantic attention, which captures hierarchical knowledge concepts information, and multi-label smoothing, which combines textual features to help reduce overfitting, thus enhancing text classification performance. Our experimental evaluation on four datasets demonstrates that our model outperforms state-of-the-art methods. We also validate the effectiveness of hierarchical label-semantic attention and multi-label smoothing through our experiments. The code and data are available at: https://github.com/xuqiang124/atmk_system.}
}
@article{SCHAEFFER20232106,
title = {OLAF: An Ontology Learning Applied Framework},
journal = {Procedia Computer Science},
volume = {225},
pages = {2106-2115},
year = {2023},
note = {27th International Conference on Knowledge Based and Intelligent Information and Engineering Sytems (KES 2023)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2023.10.201},
url = {https://www.sciencedirect.com/science/article/pii/S1877050923013595},
author = {Marion Schaeffer and Matthias Sesboüé and Jean-Philippe Kotowicz and Nicolas Delestre and Cecilia Zanni-Merk},
keywords = {ontology learning, ontology, knowledge acquisition, ontology-based system, framework, automation, NLP},
abstract = {Since the beginning of the century, research on ontology learning has gained popularity. Automatically extracting and structuring knowledge relevant to a domain of interest from unstructured textual data is a major scientific challenge. After studying the main existing methods, such as Text2Onto, we propose a new approach with a modular ontology learning framework focusing on automatically extracting knowledge from raw text sources. We consider tasks from data pre-processing to axiom extraction. Whereas previous contributions considered ontology learning systems as tools to help the domain expert craft a reusable ontology, we developed the proposed framework with full automation in mind to build a minimum viable ontology targeted at an application. Ontology Learning Applied Framework (OLAF) has been generically designed to build specific ontologies whatever the application domain, use case and text data. We implement an initial version and test the framework on an ontology-based system, a search engine for technical products.}
}
@article{PENG2025103067,
title = {Hybrid approach for drug-target interaction predictions in ischemic stroke models},
journal = {Artificial Intelligence in Medicine},
volume = {161},
pages = {103067},
year = {2025},
issn = {0933-3657},
doi = {https://doi.org/10.1016/j.artmed.2025.103067},
url = {https://www.sciencedirect.com/science/article/pii/S0933365725000028},
author = {Jing-Jie Peng and Yi-Yue Zhang and Rui-Feng Li and Wen-Jun Zhu and Hong-Rui Liu and Hui-Yin Li and Bin Liu and Dong-Sheng Cao and Jun Peng and Xiu-Ju Luo},
keywords = {Drug target interaction, Machine learning, Large-language-model, Cerdulatinib, Ischemic stroke, Cell death},
abstract = {Multiple cell death mechanisms are triggered during ischemic stroke and they are interconnected in a complex network with extensive crosstalk, complicating the development of targeted therapies. We therefore propose a novel framework for identifying disease-specific drug-target interaction (DTI), named strokeDTI, to extract key nodes within an interconnected graph network of activated pathways via leveraging transcriptomic sequencing data. Our findings reveal that the drugs a model can predict are highly representative of the characteristics of the database the model is trained on. However, models with comparable performance yield diametrically opposite predictions in real testing scenarios. Our analysis reveals a correlation between the reported literature on drug-target pairs and their binding scores. Leveraging this correlation, we introduced an additional module to assess the predictive validity of our model for each unique target, thereby improving the reliability of the framework's predictions. Our framework identified Cerdulatinib as a potential anti-stroke drug via targeting multiple cell death pathways, particularly necroptosis and apoptosis. Experimental validation in in vitro and in vivo models demonstrated that Cerdulatinib significantly attenuated stroke-induced brain injury via inhibiting multiple cell death pathways, improving neurological function, and reducing infarct volume. This highlights strokeDTI's potential for disease-specific drug-target identification and Cerdulatinib's potential as a potent anti-stroke drug.}
}
@article{YANG2024107924,
title = {RDmaster: A novel phenotype-oriented dialogue system supporting differential diagnosis of rare disease},
journal = {Computers in Biology and Medicine},
volume = {169},
pages = {107924},
year = {2024},
issn = {0010-4825},
doi = {https://doi.org/10.1016/j.compbiomed.2024.107924},
url = {https://www.sciencedirect.com/science/article/pii/S0010482524000088},
author = {Jian Yang and Liqi Shu and Mingyu Han and Jiarong Pan and Lihua Chen and Tianming Yuan and Linhua Tan and Qiang Shu and Huilong Duan and Haomin Li},
keywords = {Rare disease, Human phenotype ontology, Differential diagnosis, Phenomic and genomic diagnostics, Electronic differential diagnostic support system},
abstract = {Background
Clinicians often lack the necessary expertise to differentially diagnose multiple underlying rare diseases (RDs) due to their complex and overlapping clinical features, leading to misdiagnoses and delayed treatments. The aim of this study is to develop a novel electronic differential diagnostic support system for RDs.
Method
Through integrating two Bayesian diagnostic methods, a candidate list was generated with enhance clinical interpretability for the further Q&A based differential diagnosis (DDX). To achieve an efficient Q&A dialogue strategy, we introduce a novel metric named the adaptive information gain and Gini index (AIGGI) to evaluate the expected gain of interrogated phenotypes within real-time diagnostic states.
Results
This DDX tool called RDmaster has been implemented as a web-based platform (http://rdmaster.nbscn.org/). A diagnostic trial involving 238 published RD patients revealed that RDmaster outperformed existing RD diagnostic tools, as well as ChatGPT, and was shown to enhance the diagnostic accuracy through its Q&A system.
Conclusions
The RDmaster offers an effective multi-omics differential diagnostic technique and outperforms existing tools and popular large language models, particularly enhancing differential diagnosis in collecting diagnostically beneficial phenotypes.}
}
@article{PFANSCHILLING2025109369,
title = {NeST: The neuro-symbolic transpiler},
journal = {International Journal of Approximate Reasoning},
volume = {179},
pages = {109369},
year = {2025},
issn = {0888-613X},
doi = {https://doi.org/10.1016/j.ijar.2025.109369},
url = {https://www.sciencedirect.com/science/article/pii/S0888613X25000106},
author = {Viktor Pfanschilling and Hikaru Shindo and Devendra Singh Dhami and Kristian Kersting},
keywords = {Probabilistic programming, Neuro-symbolic, Large language models, Tractable probabilistic models},
abstract = {Tractable Probabilistic Models such as Sum-Product Networks are a powerful category of models that offer a rich choice of fast probabilistic queries. However, they are limited in the distributions they can represent, e.g., they cannot define distributions using loops or recursion. To move towards more complex distributions, we introduce a novel neurosymbolic programming language, Sum Product Loop Language (SPLL), along with the Neuro-Symbolic Transpiler (NeST). SPLL aims to build inference code most closely resembling Tractable Probabilistic Models. NeST is the first neuro-symbolic transpiler—a compiler from one high-level language to another. It generates inference code from SPLL but natively supports other computing platforms, too. This way, SPLL can seamlessly interface with e.g. pretrained (neural) models in PyTorch or Julia. The result is a language that can run probabilistic inference on more generalized distributions, reason on neural network outputs, and provide gradients for training.}
}
@article{XIANG2024103607,
title = {A cross-guidance cross-lingual model on generated parallel corpus for classical Chinese machine reading comprehension},
journal = {Information Processing & Management},
volume = {61},
number = {2},
pages = {103607},
year = {2024},
issn = {0306-4573},
doi = {https://doi.org/10.1016/j.ipm.2023.103607},
url = {https://www.sciencedirect.com/science/article/pii/S0306457323003448},
author = {Junyi Xiang and Maofu Liu and Qiyuan Li and Chen Qiu and Huijun Hu},
keywords = {Classical Chinese machine reading comprehension, Chinese diachronic gap, Cross-guidance cross-lingual model, Parallel corpus generation},
abstract = {Chinese diachronic gap is a key issue in classical Chinese machine reading comprehension (CCMRC). Preceding work on bridging this gap has been mostly restricted to limited monolingual classical Chinese corpora pre-training and lexical knowledge integration, which require a great deal of human resources. In this paper, we propose a cross-guidance cross-lingual model (CGCLM), pre-trained on a classical and modern Chinese parallel corpus generated from a large language model, to bridge the Chinese diachronic gap and reduce the manual effort. The CGCLM facilitates accurate translation by providing in-context examples and feedback based on the longest common substring between source and target sentences, thereby avoiding untranslated Chinese words. Specifically, we consider three pre-training tasks, i.e., cross-masked language modeling, linguistic label cross-prediction, and semantic cross-aware translation language modeling. The knowledge acquired from masked tokens uncovering and linguistic label predicting can lead to the implicit semantic alignment between two language styles. Taking advantage of the semantic similarity between the same syntactic levels of parallel pairs, cross-aware modeling integrates and transmits contextualized semantic information. We utilize an 18.6G monolingual corpus to create a 37.2G parallel corpus. Manual evaluation has resulted in only acceptable discrepancies between our generated and human-edited parallel corpora. Extensive experimental results show that our proposed model outperforms the state-of-the-art by an average accuracy of 3.13%, 2.44%, and 2.17% on CCMRC, classical Chinese language understanding evaluation (CCLUE), and modern Chinese language understanding evaluation (MCLUE) tasks.}
}
@article{EKAPUTRA2025100855,
title = {Pattern-based engineering of Neurosymbolic AI Systems},
journal = {Journal of Web Semantics},
volume = {85},
pages = {100855},
year = {2025},
issn = {1570-8268},
doi = {https://doi.org/10.1016/j.websem.2024.100855},
url = {https://www.sciencedirect.com/science/article/pii/S1570826824000416},
author = {Fajar J. Ekaputra},
keywords = {Neurosymbolic AI, Knowledge graphs, AI system engineering, Design patterns},
abstract = {The symbiotic combination of sub-symbolic and symbolic AI techniques is a significant trend in AI, leading to the fast-paced development of various techniques that integrate these paradigms to build intelligent systems. However, the wealth of heterogeneous architectural options for combining the paradigms into Neurosymbolic AI (NeSy-AI) systems poses significant challenges. In particular, there is currently no standardized way to design, engineer, and document such systems that encompass visual and formal notations. Existing works aim to address this challenge by systematically modelling NeSy-AI systems as design patterns that include process, data, and human interactions. However, these works focus on capturing specific views of the system rather than aiming to support the broad process of AI system engineering. This paper outlines a vision of pattern-based AI Systems engineering, aiming to support the engineering process of NeSy-AI systems with tasks such as system documentation and artefact generation through interlinked visual and formal notations with Knowledge Graphs at its core.}
}
@article{KONG2024108533,
title = {Recurrent event query decoder for document-level event extraction},
journal = {Engineering Applications of Artificial Intelligence},
volume = {133},
pages = {108533},
year = {2024},
issn = {0952-1976},
doi = {https://doi.org/10.1016/j.engappai.2024.108533},
url = {https://www.sciencedirect.com/science/article/pii/S0952197624006912},
author = {Jing Kong and Zhouwang Yang},
keywords = {Document-level event extraction, Transformers, Recurrent decoder},
abstract = {Document-level event extraction is a challenging task in natural language processing, as it involves multiple events within a document and scattered event arguments across sentences. To tackle these challenges, we propose a recurrent event query decoder, i.e., a recurrent module that dynamically updates event queries to capture cross-event dependencies. Our approach then generates arguments by extracting role-argument relations using bilinear mapping, which helps address the issue of scattered arguments. Experimental results demonstrate that our proposed approach outperforms state-of-the-art models on a large-scale public dataset and actual application data, achieving significant improvements in F1-score. In domain-specific event extraction applications, our method achieves higher accuracy with fewer resources compared to general-purpose large language models.}
}
@article{VERES2023102208,
title = {Self supervised learning and the poverty of the stimulus},
journal = {Data & Knowledge Engineering},
volume = {147},
pages = {102208},
year = {2023},
issn = {0169-023X},
doi = {https://doi.org/10.1016/j.datak.2023.102208},
url = {https://www.sciencedirect.com/science/article/pii/S0169023X2300068X},
author = {Csaba Veres and Jennifer Sampson},
keywords = {Classification, Learnability, Text mining, Machine Learning, NLP, Language},
abstract = {Diathesis alternations are the possible expressions of the arguments of verbs in different, systematically related subcategorization frames. Semantically similar verbs such as spill and spray can behave differently with respect to the alternations they can participate in. For example one can “spill/spray water on the plant”, but while one can “spray the plant with water”, it is odd to say “spill the plant with water”. “Spray” is a verb which can alternate between syntactic frames while “spill” is not alternating. How human speakers learn the difference between such verbs is not clearly understood, because the primary linguistic data (PLD) they receive does not appear sufficient to infer the knowledge required for adult competence. More generally the poverty of the stimulus (POS) hypothesis states that the PLD is not sufficient for a learner to infer full adult competence of language. That is, learning relies on prior constraints introduced by the language faculty. We tested state-of-the-art machine learning models trained by self supervision, and found some evidence that they could in fact learn the correct pattern of acceptability judgement in the locative alternation. However, we argued that this was partially a result of fine-tuning which introduced negative evidence into the learning data, which facilitated shortcut learning. Large language models (LLMs) cannot learn some linguistic facts from normal language data, but they can compensate to some extent by learning spurious correlated features when negative feedback is introduced during the training cycle.}
}
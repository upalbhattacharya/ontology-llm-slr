@article{LIU2024411,
title = {Self-X heterogeneous attributed graph embedding-based product configuration framework for cognitive mass personalization},
journal = {Journal of Manufacturing Systems},
volume = {76},
pages = {411-428},
year = {2024},
issn = {0278-6125},
doi = {https://doi.org/10.1016/j.jmsy.2024.08.014},
url = {https://www.sciencedirect.com/science/article/pii/S0278612524001778},
author = {Yangshengyan Liu and Fu Gu and Jianfeng Guo},
keywords = {Cognitive mass personalization, Industrial knowledge graph, Smart product-service system, Product configuration, Heterogeneous attributed graph embedding, Cognitive computing},
abstract = {Cognitive mass personalization (CMP) is a promising manufacturing paradigm; equipped with cognitive capabilities like reasoning, CMP satisfies changeable needs via configuring personalized products at scale. In CMP, knowledge graphs (KGs) are exploited by smart product-service systems (SPSS) to support cognitive configuration/reconfiguration processes. However, the extant KG-enabled SPSSs are built upon fixed configurations and hybrid frameworks due to lacking a graph embedding (GE) model to render cognitive configuration decisions. In fact, GE is scarcely used in SPSS configuration, because it is not only compromised by the heterogeneity of KGs entailed by content-related specifications and complex structures but also influenced by the feature randomness and feature drift problems, which are triggered by accumulative errors and inconsistent objectives due to noisy assignments and different configuration tasks, separately. To address these limitations, a Self-X Heterogeneous Attributed Graph Embedding (SXHAGE) model is proposed in a Self-X architecture, which includes 1) self-attention graph attention networks, 2) a self-adaptive autoencoder, and 3) self-optimizing training objectives, to present heterogeneous data through jointly optimizing heterogeneous attributed entities and relations. A systematic SXHAGE-based configuration framework, in which product family design and configuration recommending are enabled by graph clustering and link prediction, is developed as a continuous updating loop to proactively configure personalized products. A real-world case study, i.e., configure personalized electric clippers via a web-based sustainable configuration platform, is performed to validate the applicability of the proposed framework in the CMP context. Moreover, extensive experiments on the case study dataset demonstrate the superiority of SXHAGE over the state-of-the-art algorithms, e.g., surpassing Deep Neighbor-Aware Embedding (DNENC) by 18 % in F1-score for graph clustering and by 5 % in ROC-AUC for link prediction.}
}
@article{CHIOSA2024114802,
title = {A portable application framework for energy management and information systems (EMIS) solutions using Brick semantic schema},
journal = {Energy and Buildings},
volume = {323},
pages = {114802},
year = {2024},
issn = {0378-7788},
doi = {https://doi.org/10.1016/j.enbuild.2024.114802},
url = {https://www.sciencedirect.com/science/article/pii/S0378778824009186},
author = {Roberto Chiosa and Marco Savino Piscitelli and Marco Pritoni and Alfonso Capozzoli},
keywords = {Energy management and information systems, Portable application, Brick metadata schema, Anomaly detection, Machine learning},
abstract = {This paper introduces a portable framework for developing, scaling and maintaining energy management and information systems (EMIS) applications using an ontology-based approach. Key contributions include an interoperable layer based on Brick schema, the formalization of application constraints pertaining metadata and data requirements, and a field demonstration. The framework allows for querying metadata models, fetching data, preprocessing, and analyzing data, thereby offering a modular and flexible workflow for application development. Its effectiveness is demonstrated through a case study involving the development and implementation of a data-driven anomaly detection tool for the photovoltaic systems installed at the Politecnico di Torino, Italy. During eight months of testing, the framework was used to tackle practical challenges including: (i) developing a machine learning-based anomaly detection pipeline, (ii) replacing data-driven models during operation, (iii) optimizing model deployment and retraining, (iv) handling critical changes in variable naming conventions and sensor availability (v) extending the pipeline from one system to additional ones.}
}
@article{GROZA2025100057,
title = {Realising the potential impact of artificial intelligence for rare diseases – A framework},
journal = {Rare},
volume = {3},
pages = {100057},
year = {2025},
issn = {2950-0087},
doi = {https://doi.org/10.1016/j.rare.2024.100057},
url = {https://www.sciencedirect.com/science/article/pii/S2950008724000401},
author = {Tudor Groza and Chun-Hung Chan and David A. Pearce and Gareth Baynam},
keywords = {Rare diseases, Patient journey, Generative artificial intelligence, Diagnosis, Care coordination},
abstract = {Rare diseases (RD) are conditions affecting fewer than 1 in 2000 persons, with over 7000 largely genetic RDs affecting 3.5 %-5.9 % of the global population, or approximately 262.9–446.2 million people. The substantial healthcare burden and costs, such as the $1 trillion annual expense in the USA, highlight the urgent need for improved RD management. The International Rare Diseases Research Consortium (IRDiRC) addresses this need through global collaboration, aiming for timely and accurate diagnosis, development of 1000 new therapies, and methodologies to measure impact by 2027. IRDiRC's initiatives include biannual meetings and workshops, like the AI-focused workshop in October 2023. This identified AI as crucial for advancing RD research and proposed a Framework for AI to enhance the RD patient journey by addressing efficiency and quality of life through modular solutions mapped to critical stages. The Framework integrates diverse data sources to improve diagnosis, treatment, and impact assessment, reflecting a holistic, cross-sector approach. By guiding multi-stakeholder efforts, the Framework aims to harness AI’s potential to significantly improve rare disease care.}
}
@article{LI2024112294,
title = {DANTE: Dialog graph enhanced prompt learning for conversational question answering over KGs},
journal = {Knowledge-Based Systems},
volume = {301},
pages = {112294},
year = {2024},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2024.112294},
url = {https://www.sciencedirect.com/science/article/pii/S0950705124009286},
author = {Jingyang Li and Shengli Song and Sitong Yan and Guangneng Hu and Chengen Lai and Yulong Zhou},
keywords = {Conversational question answering, Knowledge graphs, Pre-train prompt and predict, Graph prompt},
abstract = {In this study, we focus on the task of selecting high-quality answers selection in knowledge-graph-based (KG-based) conversational question answering (ConvQA) system. Effectively exploring a user’s intention and modeling historical interaction records are challenging. To address this challenge, we propose the Dialog grAph eNhanced prompT lEarning (DANTE) model, which simultaneously integrates sequential and structural information from questions and interactive logic. While the structural information was exploited in previous studies by simply converting it into linear strings in a “pre-train, predict” paradigm, DANTE comprises the use of a novel graph representation for jointly modeling the QA pairs, relevant KG paths, and dialog contexts. The dialog graph constructs in both the turn-level and dialog-level, where DANTE fuses the structural and sequential information deeply in a “pre-train, prompt, and predict” manner. The experimental results showed that DANTE improves the absolute points by 7.1% and 8.2% in terms of the P@1 and mean reciprocal rank metrics, respectively, on the ConvQuestions/ConvRef benchmark compared with state-of-the-art baselines.}
}
@article{MUMUNI2025113,
title = {Automated data processing and feature engineering for deep learning and big data applications: A survey},
journal = {Journal of Information and Intelligence},
volume = {3},
number = {2},
pages = {113-153},
year = {2025},
issn = {2949-7159},
doi = {https://doi.org/10.1016/j.jiixd.2024.01.002},
url = {https://www.sciencedirect.com/science/article/pii/S2949715924000027},
author = {Alhassan Mumuni and Fuseini Mumuni},
keywords = {AutoML, Automated data preprocessing, Data processing, Automated feature engineering, Generative artificial intelligence, Big data},
abstract = {Modern approach to artificial intelligence (AI) aims to design algorithms that learn directly from data. This approach has achieved impressive results and has contributed significantly to the progress of AI, particularly in the sphere of supervised deep learning. It has also simplified the design of machine learning systems as the learning process is highly automated. However, not all data processing tasks in conventional deep learning pipelines have been automated. In most cases data has to be manually collected, preprocessed and further extended through data augmentation before they can be effective for training. Recently, special techniques for automating these tasks have emerged. The automation of data processing tasks is driven by the need to utilize large volumes of complex, heterogeneous data for machine learning and big data applications. Today, end-to-end automated data processing systems based on automated machine learning (AutoML) techniques are capable of taking raw data and transforming them into useful features for big data tasks by automating all intermediate processing stages. In this work, we present a thorough review of approaches for automating data processing tasks in deep learning pipelines, including automated data preprocessing – e.g., data cleaning, labeling, missing data imputation, and categorical data encoding – as well as data augmentation (including synthetic data generation using generative AI methods) and feature engineering – specifically, automated feature extraction, feature construction and feature selection. In addition to automating specific data processing tasks, we discuss the use of AutoML methods and tools to simultaneously optimize all stages of the machine learning pipeline.}
}
@article{LIU2024102300,
title = {Emotion detection for misinformation: A review},
journal = {Information Fusion},
volume = {107},
pages = {102300},
year = {2024},
issn = {1566-2535},
doi = {https://doi.org/10.1016/j.inffus.2024.102300},
url = {https://www.sciencedirect.com/science/article/pii/S1566253524000782},
author = {Zhiwei Liu and Tianlin Zhang and Kailai Yang and Paul Thompson and Zeping Yu and Sophia Ananiadou},
keywords = {Sentiment analysis, Emotion detection, Misinformation, Rumor, Fake news, Stance detection},
abstract = {With the advent of social media, an increasing number of netizens are sharing and reading posts and news online. However, the huge volumes of misinformation (e.g., fake news and rumors) that flood the internet can adversely affect people’s lives, and have resulted in the emergence of rumor and fake news detection as a hot research topic. The emotions and sentiments of netizens, as expressed in social media posts and news, constitute important factors that can help to distinguish fake news from genuine news and to understand the spread of rumors. This article comprehensively reviews emotion-based methods for misinformation detection, with a particular focus on advanced fusion methods. We begin by explaining the strong links between emotions and misinformation. We subsequently provide a detailed analysis of a range of misinformation detection methods that employ a variety of emotion, sentiment and stance-based features, and describe their strengths and weaknesses. Finally, we discuss a number of ongoing challenges in emotion-based misinformation detection based on large language models, and suggest future research directions, including data collection (multi-platform, multilingual), annotation, benchmark, multimodality, and interpretability.}
}
@article{KO2025478,
title = {MDCKE: Multimodal deep-context knowledge extractor that integrates contextual information},
journal = {Alexandria Engineering Journal},
volume = {119},
pages = {478-492},
year = {2025},
issn = {1110-0168},
doi = {https://doi.org/10.1016/j.aej.2025.01.119},
url = {https://www.sciencedirect.com/science/article/pii/S1110016825001474},
author = {Hyojin Ko and Joon Yoo and Ok-Ran Jeong},
keywords = {Multimodal knowledge graph, Multimodal data fusing, Information extraction, Named entity recognition, Relation extraction, Natural language processing, Image processing},
abstract = {Extraction of comprehensive information from diverse data sources remains a significant challenge in contemporary research. Although multimodal Named Entity Recognition (NER) and Relation Extraction (RE) tasks have garnered significant attention, existing methods often focus on surface-level information, underutilizing the potential depth of the available data. To address this issue, this study introduces a Multimodal Deep-Context Knowledge Extractor (MDCKE) that generates hierarchical multi-scale images and captions from original images. These connectors between image and text enhance information extraction by integrating more complex data relationships and contexts to build a multimodal knowledge graph. Captioning precedes feature extraction, leveraging semantic descriptions to align global and local image features and enhance inter- and intramodality alignment. Experimental validation on the Twitter2015 and Multimodal Neural Relation Extraction (MNRE) datasets demonstrated the novelty and accuracy of MDCKE, resulting in an improvement in the F1-score by up to 5.83% and 26.26%, respectively, compared to State-Of-The-Art (SOTA) models. MDCKE was compared with top models, case studies, and simulations in low-resource settings, proving its flexibility and efficacy. An ablation study further corroborated the contribution of each component, resulting in an approximately 6% enhancement in the F1-score across the datasets.}
}
@article{DING2024103637,
title = {A plug-and-play adapter for consistency identification in task-oriented dialogue systems},
journal = {Information Processing & Management},
volume = {61},
number = {3},
pages = {103637},
year = {2024},
issn = {0306-4573},
doi = {https://doi.org/10.1016/j.ipm.2023.103637},
url = {https://www.sciencedirect.com/science/article/pii/S0306457323003746},
author = {Zeyuan Ding and Zhihao Yang and Hongfei Lin},
keywords = {Consistency identification, Task-oriented dialogue, Knowledge injection, Fusion mechanism, Adapter module},
abstract = {Task-oriented Dialogue system (ToD) has gained significant attention due to its aim to assist users in accomplishing various tasks. However, the neural network-based dialogue system is like a black box, which may lead to erroneous responses and result in an unfriendly user experience. To address this issue, consistency identification is proposed to prevent generating inconsistent responses. However, the existing consistency identification methods require frequent interaction with the knowledge base, making them susceptible to the introduction of noise during the knowledge base fusion process, ultimately leading to a decline in performance. In this paper, we propose a plug-and-play method for consistency identification, which can introduce external knowledge into the internal reasoning process of the pre-trained language model (PLM) without modifying PLM’s structure. Additionally, we design a new fusion mechanism that effectively fuses the knowledge base information related to the current utterance, which helps the model avoid introducing noise from the irrelevant knowledge base. The experimental results demonstrate that our method achieves state-of-the-art performance on the consistency identification task, improving F1 scores by 2.9% absolute points over the previous methods. Finally, we investigate different knowledge base fusion methods and provide extensive experiments to show the advantages of our proposed method.}
}
@article{ZHAO2023100005,
title = {When brain-inspired AI meets AGI},
journal = {Meta-Radiology},
volume = {1},
number = {1},
pages = {100005},
year = {2023},
issn = {2950-1628},
doi = {https://doi.org/10.1016/j.metrad.2023.100005},
url = {https://www.sciencedirect.com/science/article/pii/S295016282300005X},
author = {Lin Zhao and Lu Zhang and Zihao Wu and Yuzhong Chen and Haixing Dai and Xiaowei Yu and Zhengliang Liu and Tuo Zhang and Xintao Hu and Xi Jiang and Xiang Li and Dajiang Zhu and Dinggang Shen and Tianming Liu},
abstract = {Artificial General Intelligence (AGI) has been a long-standing goal of humanity, with the aim of creating machines capable of performing any intellectual task that humans can do. To achieve this, AGI researchers draw inspiration from the human brain and seek to replicate its principles in intelligent machines. Brain-inspired artificial intelligence is a field that has emerged from this endeavor, combining insights from neuroscience, psychology, and computer science to develop more efficient and powerful AI systems. In this article, we provide a comprehensive overview of brain-inspired AI from the perspective of AGI. We begin with the current progress in brain-inspired AI and its extensive connection with AGI. We then cover the important characteristics for both human intelligence and AGI (e.g., scaling, multimodality, and reasoning). We discuss important technologies toward achieving AGI in current AI systems, such as in-context learning and prompt tuning. We also investigate the evolution of AGI systems from both algorithmic and infrastructural perspectives. Finally, we explore the limitations and future of AGI.}
}
@article{TRAPPEY2020101980,
title = {Identify trademark legal case precedents - Using machine learning to enable semantic analysis of judgments},
journal = {World Patent Information},
volume = {62},
pages = {101980},
year = {2020},
issn = {0172-2190},
doi = {https://doi.org/10.1016/j.wpi.2020.101980},
url = {https://www.sciencedirect.com/science/article/pii/S0172219019300638},
author = {Charles V. Trappey and Amy J.C. Trappey and Bo-Hung Liu},
keywords = {Trademark infringement, Clustering, Latent dirichlet allocation, Precedence analysis, Recommendation platform},
abstract = {Legal case precedents have a considerable impact on the development of litigation strategies. This research uses the neural network language modeling (NNLM) approach to analyze and identify judgment documents of US trademark (TM) litigation cases as precedents of a given target case. In this research, the NNLM has been trained using 4835 TM litigation documents. There are more than 800,000 words in the entire training text set including more than 150,000 vocabularies. The words in TM legal documents are vectorized to train the NN model for e-discovery of semantically correlated precedents and their features. Specifically, non-supervised machine learning (ML) methods, including clustering and Latent Dirichlet Allocation (LDA), are applied to form the TM legal document clusters, topics, and key terminologies used to characterize the TM case descriptions and precedents. The definition of the clusters, topics and corresponding key terms enhance the ability of the system to recommend and explain similar case judgments for any given TM case of interest or a cease and desist letter with detailed claims of infringement. Further, the intelligent approach provides macro and micro views for companies to research TM litigation trends as a means to better protect their brand equity.}
}
@article{DUNSIN2025100299,
title = {Reinforcement learning for an efficient and effective malware investigation during cyber incident response},
journal = {High-Confidence Computing},
pages = {100299},
year = {2025},
issn = {2667-2952},
doi = {https://doi.org/10.1016/j.hcc.2025.100299},
url = {https://www.sciencedirect.com/science/article/pii/S2667295225000030},
author = {Dipo Dunsin and Mohamed Chahine Ghanem and Karim Ouazzane and Vassil Vassilev},
keywords = {Cyber incident, Digital forensics, Artificial intelligence, Reinforcement learning, Markov Chain, MDP, DFIR, Malware, Incident response},
abstract = {The ever-escalating prevalence of malware is a serious cybersecurity threat, often requiring advanced post-incident forensic investigation techniques. This paper proposes a framework to enhance malware forensics by leveraging reinforcement learning (RL). The approach combines heuristic and signature-based methods, supported by RL through a unified MDP model, which breaks down malware analysis into distinct states and actions. This optimisation enhances the identification and classification of malware variants. The framework employs Q-learning and other techniques to boost the speed and accuracy of detecting new and unknown malware, outperforming traditional methods. We tested the experimental framework across multiple virtual environments infected with various malware types. The RL agent collected forensic evidence and improved its performance through Q-tables and temporal difference learning. The epsilon-greedy exploration strategy, in conjunction with Q-learning updates, effectively facilitated transitions. The learning rate depended on the complexity of the MDP environment: higher in simpler ones for quicker convergence and lower in more complex ones for stability. This RL-enhanced model significantly reduced the time required for post-incident malware investigations, achieving a high accuracy rate of 94% in identifying malware. These results indicate RL’s potential to revolutionise post-incident forensics investigations in cybersecurity. Future work will incorporate more advanced RL algorithms and large language models (LLMs) to further enhance the effectiveness of malware forensic analysis.}
}
@article{ZHU2025125976,
title = {Pre-training graph autoencoder incorporating hierarchical topology knowledge},
journal = {Expert Systems with Applications},
volume = {265},
pages = {125976},
year = {2025},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2024.125976},
url = {https://www.sciencedirect.com/science/article/pii/S0957417424028434},
author = {Hongyin Zhu and Yakun Li and Luyang Liu and Haonan Tong and Qunyang Lin and Chuang Zhang},
keywords = {Graph pre-training, Hierarchical topology knowledge, Graph autoencoder, Subgraph regularization},
abstract = {Existing graph pre-training methods demonstrate their ability to generate vertex representations beneficial for downstream machine-learning tasks. However, the quality of these representations is often influenced by the choice of learning algorithm. While masking strategies are commonly employed, random masks can lead to noisy neighborhoods and incomplete graph topology, hampering learning efficiency and increasing computational costs. When a significant portion of neighbors are randomly masked, the central vertex lacks sufficient contextual information. To address this challenge, we integrate hierarchical topology knowledge to enhance masking strategies, thereby preserving the major topology and minimizing training costs. Our method leverages 3 distinct masking techniques: global-aware, local-aware, and element-aware masking. Global-aware masking encourages the model to capture the graph’s overall topology, while local-aware masking focuses on capturing vertex interactions. Element-aware masking enhances the model’s robustness against noise and structural variations. By incorporating these 3 strategies, our method mitigates the impact of random noise and structural variations during training, yielding more robust and effective vertex representations. To further optimize the model, we introduce a fine-grained subgraph regularization, which reduces the model’s parameter count by penalizing divergence in subgraph embeddings across multiple views. We assess the effectiveness of our approach on 3 datasets, highlighting its performance improvements while achieving a reduction of 25% in model parameters.}
}
@article{QIU2024105863,
title = {Semantic information extraction and search of mineral exploration data using text mining and deep learning methods},
journal = {Ore Geology Reviews},
volume = {165},
pages = {105863},
year = {2024},
issn = {0169-1368},
doi = {https://doi.org/10.1016/j.oregeorev.2023.105863},
url = {https://www.sciencedirect.com/science/article/pii/S0169136823005796},
author = {Qinjun Qiu and Miao Tian and Liufeng Tao and Zhong Xie and Kai Ma},
keywords = {Mineral exploration data, Semantic search, Text mining, Topic extraction, Knowledge graph},
abstract = {Large-scale mineral resource reports offer a wealth of information for geological knowledge mining and mineral explorers’ knowledge discovery. The geological conditions in which mineral deposits develop may be learned a great deal from these mineral exploration reports. Mineral exploration data may be queried and aggregated to effectively mitigate future exploration risks and reduce costs. However, due to the reports being presented in unstructured textual format, it becomes challenging to extract valuable geological data without manually scanning through a vast number of reports. This laborious process poses difficulties for geologists. To address this issue, this paper proposes a system that extracts a set of geologically relevant keywords/keyphrases of each chapter from each mineral exploration reposts using latent Dirichlet allocation (LDA), develops a topic graph, recognizes the geological entity and related relations for constructing a knowledge graph, and uses visualization of those graphs (e.g., topic graphs and knowledge graphs) to explore the contents of the report. The text mining and machine learning technique described here serves as the foundation for future research into incorporating semantic analysis into geological information extraction. The findings of this study show how automated text analysis may help with the quick processing of huge quantities of reports in order to identify target mineral systems and their related geological location and rock mineral composition. The suggested approaches can quickly and reliably convert mineral exploration data (e.g., text, figure, and table) into a structured form, which is a hitherto untouched field in geological knowledge mining.}
}
@article{WANG2024128580,
title = {Zero-shot text classification with knowledge resources under label-fully-unseen setting},
journal = {Neurocomputing},
volume = {610},
pages = {128580},
year = {2024},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2024.128580},
url = {https://www.sciencedirect.com/science/article/pii/S0925231224013511},
author = {Yuqi Wang and Wei Wang and Qi Chen and Kaizhu Huang and Anh Nguyen and Suparna De},
keywords = {Zero-shot learning, Knowledge graph embedding, Natural language processing, Textual analysis, Multi-class classification},
abstract = {Classification techniques are at the heart of many real-world applications, e.g. sentiment analysis, recommender systems and automatic text annotation, to process and analyse large-scale textual data in multiple fields. However, the effectiveness of natural language processing models can only be confirmed when a large amount of up-to-date training data is available. An unprecedented amount of data is continuously created, and new topics are introduced, making it less likely or even infeasible to collect labelled samples covering all topics for training models. We attempt to study the extreme case: there is no labelled data for model training, and the model, without being adapted to any specific dataset, will be directly applied to the testing samples. We propose a transformer-based framework to encode sentences in a contextualised way and leverage the existing knowledge resources, i.e. ConceptNet and WordNet, to integrate both descriptive and structural knowledge for better performance. To enhance the robustness of the model, we design an adversarial example generator based on relations from external knowledge bases. The framework is evaluated on both general and specific domain text classification datasets. Results show that the proposed framework can outperform the existing competitive state-of-the-art baselines, delivering new benchmark results.}
}
@article{KAHN2025115027,
title = {More than 50 years of consumer behavior research: What will the future look like?},
journal = {Journal of Business Research},
volume = {186},
pages = {115027},
year = {2025},
issn = {0148-2963},
doi = {https://doi.org/10.1016/j.jbusres.2024.115027},
url = {https://www.sciencedirect.com/science/article/pii/S0148296324005319},
author = {Barbara E. Kahn and Anne V. Wilson},
abstract = {To understand how consumer behavior research has evolved and what the future might hold, we first summarize the intellectual trajectory of scholarship in the area and briefly describe the research paradigms that developed over time. We report on the trends in research topics over the years and the “hot topics” projected for the near future. We also discuss the internal and external forces that fundamentally shape research and scholars. These forces provide both constraints and opportunities that will define the future of the field. We predict that some forces, unfortunately, incentivize scholars to examine more minor, less influential research questions. However, new sources of data and areas of inquiry are simultaneously providing opportunities for innovation and creativity in exploring how consumer behavior will change or evolve in response to macroeconomic factors, such as social issues, political movements, or rapid technological advances.}
}
@article{TANG2024109543,
title = {ResiAdvNet: A named entity recognition model for potato diseases and pests based on progressive residual structures and adversarial training},
journal = {Computers and Electronics in Agriculture},
volume = {227},
pages = {109543},
year = {2024},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2024.109543},
url = {https://www.sciencedirect.com/science/article/pii/S0168169924009347},
author = {Wentao Tang and Xianhuan Wen and Miao Li and Yuqi Chen and Zelin Hu},
keywords = {Named entity recognition, ResiAdvNet, Potato disease and pest, Progressive residual structure, Adversarial training},
abstract = {Conventional named entity recognition methods based on pretrained models often focus on utilizing the output of the final layer of a pretrained model while ignoring the linguistic features embedded in its internal layers. To utilize pretrained models more fully, this paper proposes a named entity recognition model called ResiAdvNet, which combines progressive residual structures with adversarial training. This proposed model is applied to potato disease and pest identification. MacBERT is utilized as the pretrained model and residual blocks are used to aggregate the outputs of its internal layers, obtaining a final output that emphasizes information from all layers. This output is subsequently fed into a bidirectional long-short term memory network for context modeling and finally passed through a conditional random field to obtain the globally optimal tagging sequence. Additionally, adversarial training is introduced as a means to enhance model robustness. By introducing adversarial examples during training, the model learns more robust feature representations, thereby improving its performance when facing unknown inputs. ResiAdvNet was tested with on a custom dataset called PpdKED over five trials with an average F1 score of approximately 0.9225, significantly outperforming other models. Experimental results demonstrate that the proposed model can efficiently extract entities related to potato diseases and pests, laying a solid foundation for the subsequent tasks of relation extraction and knowledge graph construction.}
}
@article{ARIKKAT2024103990,
title = {OSTIS: A novel Organization-Specific Threat Intelligence System},
journal = {Computers & Security},
volume = {145},
pages = {103990},
year = {2024},
issn = {0167-4048},
doi = {https://doi.org/10.1016/j.cose.2024.103990},
url = {https://www.sciencedirect.com/science/article/pii/S0167404824002955},
author = {Dincy R. Arikkat and Vinod P. and Rafidha Rehiman K.A. and Serena Nicolazzo and Antonino Nocera and Georgiana Timpau and Mauro Conti},
keywords = {Cyber Threat Intelligence, Cybersecurity knowledge graph, Organization-specific threat intelligence, Relation extraction, Named entity recognition, Natural language processing, Explainable AI},
abstract = {With the increasing complexity and frequency of cyber attacks, organizations recognize the need for a proactive and targeted approach to safeguard their digital assets and operations. Every industry faces a distinct array of threats shaped by factors such as its industrial objective, geographic footprint, workforce size, revenue, partnerships, and the extent of its digital assets. This results in a wide heterogeneity in threat landscapes, which necessitates tailored threat intelligence sources. While some security practitioners may gravitate towards extensive sources, relying solely on volume-based solutions often leads to “alert fatigue”. For this reason, organization-specific threat intelligence has acquired a growing importance in cybersecurity defense. This work presents a complete and novel framework called OSTIS (Organization-Specific Threat Intelligence System) for generating and managing organization-specific Cyber Threat Intelligence (CTI) data. Our approach identifies reliable security blogs from which we gather CTI data through a custom and focused Web Crawler. Relevant content from such sources is, then, identified and extracted using automated deep-learning models. Moreover, our AI-driven solution maps CTI data to specific domain scenarios, such as education, finance, government, healthcare, industrial control systems, and IoT. To validate and gain insights from the trained models, we also include an explainable AI (XAI, for short) task carried out by leveraging the SHapley Additive exPlanations (SHAP) tool. This allows us to interpret the prediction process and discern influential content from data. The last step of our framework consists of the generation of an Organization Specific Threat Intelligence Knowledge Graph (OSTIKG), empowering organizations to identify and visualize attack patterns and incidents, promptly. To create this graph, we develop and adapt several techniques to extract diverse entities, including malware groups, campaigns, attack types, malware types, software tools, and so forth, and to identify relationships among them. Finally, through an extensive experimental campaign, we certify the validity and performance of all the components of our framework, which shows a 0.84 F1-score in the identification of relevant content, a 0.93 F1-score for the domain classification, and a 0.95 and 0.89 F1-score in the identification of entities and relations to build our OSTIKG graph.}
}
@article{ZHANG2025125059,
title = {Deep generative models in energy system applications: Review, challenges, and future directions},
journal = {Applied Energy},
volume = {380},
pages = {125059},
year = {2025},
issn = {0306-2619},
doi = {https://doi.org/10.1016/j.apenergy.2024.125059},
url = {https://www.sciencedirect.com/science/article/pii/S0306261924024437},
author = {Xiangyu Zhang and Andrew Glaws and Alexandre Cortiella and Patrick Emami and Ryan N. King},
keywords = {Generative artificial intelligence, Deep generative models, Energy systems, Smart grid},
abstract = {In recent years, with the advent of mature machine learning products like ChatGPT, Stable Diffusion, and Sora, the world has witnessed tremendous changes driven by the rapid development of generative artificial intelligence (GAI). Beyond applications in text, speech, image, and video creation, deep generative models (DGMs) underpinning these cutting-edge technologies have also been employed by domain researchers to address scientific and engineering challenges. This paper aims to fill a gap in the research community by providing a comprehensive review of how DGMs have been utilized in energy system applications. Based on five of the most popular DGMs, we review and categorize 228 research articles into five focus areas: data generation, forecasting, situational awareness, modeling, and optimal decision-making. Through this classification, we uncover trends in how DGMs are employed for each type of problem, highlighting GAI techniques that contribute to breakthroughs over traditional methods. We discuss limitations in existing literature, engineering challenges, and propose future directions, all tailored to the unique nature of problems in energy system engineering. Our goal is to offer insights for energy system domain researchers, providing a comprehensive view of existing studies and potential future opportunities.}
}
@article{LOUGE2025126641,
title = {Events-based semantic services composition in Industry 4.0 using Asset Administration Shell meta-model for digital twins},
journal = {Expert Systems with Applications},
volume = {271},
pages = {126641},
year = {2025},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2025.126641},
url = {https://www.sciencedirect.com/science/article/pii/S0957417425002635},
author = {Thierry Louge and Sina Namaki Araghi and Mohamed Hedi Karray and Arkopaul Sarkar},
keywords = {Ontologies, Semantic services, Asset Administration Shell, Industry 4.0, Digital twins},
abstract = {Since the emergence of the Semantic Web concept, considerable work has focused on service composition using ontology-based approaches. Meanwhile, the concept of Industry 4.0 has emerged, emphasizing the benefits of utilizing data and computing devices in close proximity to production lines, exemplified by concepts like digital twins. However, these two fields rarely intersect, and the requirements for integrating domain-specific knowledge into business processes with event feedback during processes execution differ between these contexts. With the recent advancements in the semantization of industrial standards, such as the Asset Administration Shell, this work explores the elements of a semantic model for describing equipment, enabling the semantic composition of equipment as services. We propose an ontology, COMPAAS, designed to facilitate the composition of production lines that can react to events reported by their components, allowing the system to adjust its behavior accordingly. This approach also addresses the removal and addition of hardware or software elements within the chain, and the entire concept is validated through a minimal use case that demonstrates the improved flexibility of the production line in response to potential disturbances.}
}
@article{DURAN2025112310,
title = {A review on artificial intelligence applications for facades},
journal = {Building and Environment},
volume = {269},
pages = {112310},
year = {2025},
issn = {0360-1323},
doi = {https://doi.org/10.1016/j.buildenv.2024.112310},
url = {https://www.sciencedirect.com/science/article/pii/S0360132324011521},
author = {Ayca Duran and Christoph Waibel and Valeria Piccioni and Bernd Bickel and Arno Schlueter},
keywords = {Literature review, Building facades, Computer vision, Machine learning, Deep learning},
abstract = {This review applies a transformer-based topic model to reveal trends and relationships in Artificial Intelligence (AI)-driven facade research, with a focus on architectural, environmental, and structural aspects. AI methods reviewed include Machine Learning (ML), Deep Learning (DL), and Computer Vision (CV). Overall, a significantly growing interest in applying AI methods can be observed across all research areas. However, noticeable differences exist between the three topics. While CV and DL techniques are applied to image data in research on the architectural design of facades, research on environmental aspects of facades often uses numerical data with relatively small datasets and classical ML models. Research on facade structure also tends to use image data but also incorporates numerical performance prediction. A major limitation remains a lack of generalizability, which could be addressed by more comprehensive datasets and novel DL techniques. These include concepts such as Physics-Informed Neural Networks, where domain knowledge is integrated into hybrid data-driven models, and multi-modal diffusion models, which offer generative modeling capabilities to support inverse and forward design tasks. The trends and directions outlined in this review suggest that AI will continue to advance facade research and, in line with other domains, has the potential to achieve a level of maturity suitable for adoption beyond academia and into practice.}
}
@article{DAVID2024216,
title = {Decentralized research data management: introducing SoVisu+},
journal = {Procedia Computer Science},
volume = {249},
pages = {216-223},
year = {2024},
note = {16th International Conference on Current Research Information Systems (CRIS 2024)},
issn = {1877-0509},
doi = {https://doi.org/10.1016/j.procs.2024.11.067},
url = {https://www.sciencedirect.com/science/article/pii/S1877050924032782},
author = {Reymond David and Tabariès Alaric},
keywords = {SoVisu+, Decentralized research data management, CRISalid consortium, Knowledge graph, Self-archiving, Solid Pods, Linked Data, Research evaluation practices, Open science, Community collaboration},
abstract = {This research proposes SoVisu+, a new system for managing research data in a decentralized way, building upon the foundation laid by the CRISalid consortium, a community-driven approach to research information management. Traditional, centralized systems have issues like fragmented data, unchecked and outdated information. SoVisu+ tackles these problems by giving researchers more control over their data and fostering collaboration to build a shared knowledge graph. Researchers benefit from features like self-archiving accompaniment, AI driven helpers and real-time profile views, while institutions gain access to more reliable and comprehensive data. SoVisu+ expects to employ cutting-edge technologies like Solid Pods and Linked Data to streamline data management and improve research evaluation practices. Overall, SoVisu+ aims to create a more transparent and collaborative research ecosystem that ultimately accelerates scientific progress.}
}
@incollection{LENCI2024,
title = {Artificial Intelligence and Language☆},
booktitle = {Reference Module in Social Sciences},
publisher = {Elsevier},
year = {2024},
isbn = {978-0-443-15785-1},
doi = {https://doi.org/10.1016/B978-0-323-95504-1.00241-6},
url = {https://www.sciencedirect.com/science/article/pii/B9780323955041002416},
author = {Alessandro Lenci and Andrea Vestrucci},
keywords = {Artificial intelligence (AI), Symbolic AI, Subsymbolic AI, Hybrid AI, Large language models (LLMs), Neuro-symbolic AI, Natural language inference, Machine learning (ML), Natural language reasoning, Inferential tasks, Semantic gap},
abstract = {This article explores the roles of three primary paradigms of Artificial Intelligence (AI)—symbolic, subsymbolic, and hybrid—in natural language reasoning and inferential tasks. Symbolic AI leverages explicit knowledge representations and logical rules to provide high interpretability and precision, making it suitable for tasks requiring clear and verifiable reasoning. However, its rigidity and lack of scalability limit its effectiveness in handling the nuanced nature of human language. Subsymbolic AI, driven by machine learning, deep learning, and large language models, excels in flexibility and adaptability by learning from vast datasets. While capable of generating human-like text and performing complex inferences, subsymbolic AI faces challenges such as semantic gaps, susceptibility to biases, and a lack of transparency in decision-making processes. Hybrid AI combines the strengths of both symbolic and subsymbolic approaches, aiming to create more robust and reliable systems. By integrating explicit reasoning capabilities with data-driven learning, hybrid models enhance interpretability while maintaining adaptability to diverse linguistic contexts. This article concludes by emphasizing the need for continued research to refine these integrations, address current limitations, and pave the way for more intelligent and trustworthy language reasoning systems.}
}
@article{RAGO2025104291,
title = {Argumentative review aggregation and dialogical explanations},
journal = {Artificial Intelligence},
volume = {340},
pages = {104291},
year = {2025},
issn = {0004-3702},
doi = {https://doi.org/10.1016/j.artint.2025.104291},
url = {https://www.sciencedirect.com/science/article/pii/S0004370225000104},
author = {Antonio Rago and Oana Cocarascu and Joel Oksanen and Francesca Toni},
keywords = {Argumentation, Argument mining, Review aggregation, Dialogical interaction, Conversational explanation},
abstract = {The aggregation of online reviews is one of the dominant methods of quality control for users in various domains, from retail to entertainment. Consequently, explainable aggregation of reviews is increasingly sought-after. We introduce quantitative argumentation technology to this setting, towards automatically generating reasoned review aggregations equipped with dialogical explanations. To this end, we define a novel form of argumentative dialogical agent (ADA), using ontologies to harbour information from reviews into argumentation frameworks. These agents may then be evaluated with a quantitative argumentation semantics and used to mediate the generation of dialogical explanations for item recommendations based on the reviews. We show how to deploy ADAs in three different contexts in which argumentation frameworks are mined from text, guided by ontologies. First, for hotel recommendations, we use a human-authored ontology and exemplify the potential range of dialogical explanations afforded by ADAs. Second, for movie recommendations, we empirically evaluate an ADA based on a bespoke ontology (extracted semi-automatically, by natural language processing), by demonstrating that its quantitative evaluations, which are shown to satisfy desirable theoretical properties, are comparable with those on a well-known movie review aggregation website. Finally, for product recommendation in e-commerce, we use another bespoke ontology (extracted fully automatically, by natural language processing, from a website's reviews) to construct an ADA which is then empirically evaluated favourably against review aggregations from the website.}
}
@article{FENG2025110897,
title = {Data-driven supply chains mapping and disruption analysis: The case of automotive SoC enterprises in China},
journal = {Computers & Industrial Engineering},
volume = {201},
pages = {110897},
year = {2025},
issn = {0360-8352},
doi = {https://doi.org/10.1016/j.cie.2025.110897},
url = {https://www.sciencedirect.com/science/article/pii/S0360835225000427},
author = {Jiawei Feng and Mengsi Cai and Fangze Dai and Shuo Liu and Tianci Bu and Xiaoyu Zhang and Huijun Zheng and Xin Lu},
keywords = {Supply chain, Complex networks, Interaction disruption models, Cascade failure},
abstract = {Effective modeling of modern supply chains is crucial for improving visibility, mitigating systemic risks, and developing resilient strategies. However, data limitations imposed by industry sensitivity and competition have hindered research in this area. Combining big data and complex network theory, this study introduces an Open Supplier Knowledge Extraction and Complement (OSKEC) approach, incorporating cross-domain named entity recognition, firm entity fuzzy matching, and supplier relation inferring, to construct highly reliable supply chain networks from limited information. Applying OSKEC on the Chinese automotive Systems-on-Chips (SoCs) industry approves its effectiveness in enhancing supply chain visibility and resilience. Topological analysis for the built supply chain network reveals a clear scale-free degree distribution, implying a strong heterogeneity for the interdependence of entities in the network. Specifically, NVIDIA, Qualcomm, and Mobileye occupy the majority share of the automotive SoC market in China, while local enterprises only hold a smaller portion. We further develop two interaction disruption models (IDMs) which simulate the impact of various disturbances on firms with different recovery capacities and risk-transfer strategies, and find that a risk-transfer enterprise strategy may lead to a rapid collapse of the network in the early stages of disruptions. In general, the study improves the understanding of modern supply chain dynamics and inform effective risk management strategies in the Chinese automotive SoC sector.}
}
@article{LIU2024,
title = {Evaluating Medical Entity Recognition in Health Care: Entity Model Quantitative Study},
journal = {JMIR Medical Informatics},
volume = {12},
year = {2024},
issn = {2291-9694},
doi = {https://doi.org/10.2196/59782},
url = {https://www.sciencedirect.com/science/article/pii/S2291969424001455},
author = {Shengyu Liu and Anran Wang and Xiaolei Xiu and Ming Zhong and Sizhu Wu},
keywords = {natural language processing, NLP, model evaluation, macrofactors, medical named entity recognition models},
abstract = {Background
Named entity recognition (NER) models are essential for extracting structured information from unstructured medical texts by identifying entities such as diseases, treatments, and conditions, enhancing clinical decision-making and research. Innovations in machine learning, particularly those involving Bidirectional Encoder Representations From Transformers (BERT)–based deep learning and large language models, have significantly advanced NER capabilities. However, their performance varies across medical datasets due to the complexity and diversity of medical terminology. Previous studies have often focused on overall performance, neglecting specific challenges in medical contexts and the impact of macrofactors like lexical composition on prediction accuracy. These gaps hinder the development of optimized NER models for medical applications.
Objective
This study aims to meticulously evaluate the performance of various NER models in the context of medical text analysis, focusing on how complex medical terminology affects entity recognition accuracy. Additionally, we explored the influence of macrofactors on model performance, seeking to provide insights for refining NER models and enhancing their reliability for medical applications.
Methods
This study comprehensively evaluated 7 NER models—hidden Markov models, conditional random fields, BERT for Biomedical Text Mining, Big Transformer Models for Efficient Long-Sequence Attention, Decoding-enhanced BERT with Disentangled Attention, Robustly Optimized BERT Pretraining Approach, and Gemma—across 3 medical datasets: Revised Joint Workshop on Natural Language Processing in Biomedicine and its Applications (JNLPBA), BioCreative V CDR, and Anatomical Entity Mention (AnatEM). The evaluation focused on prediction accuracy, resource use (eg, central processing unit and graphics processing unit use), and the impact of fine-tuning hyperparameters. The macrofactors affecting model performance were also screened using the multilevel factor elimination algorithm.
Results
The fine-tuned BERT for Biomedical Text Mining, with balanced resource use, generally achieved the highest prediction accuracy across the Revised JNLPBA and AnatEM datasets, with microaverage (AVG_MICRO) scores of 0.932 and 0.8494, respectively, highlighting its superior proficiency in identifying medical entities. Gemma, fine-tuned using the low-rank adaptation technique, achieved the highest accuracy on the BioCreative V CDR dataset with an AVG_MICRO score of 0.9962 but exhibited variability across the other datasets (AVG_MICRO scores of 0.9088 on the Revised JNLPBA and 0.8029 on AnatEM), indicating a need for further optimization. In addition, our analysis revealed that 2 macrofactors, entity phrase length and the number of entity words in each entity phrase, significantly influenced model performance.
Conclusions
This study highlights the essential role of NER models in medical informatics, emphasizing the imperative for model optimization via precise data targeting and fine-tuning. The insights from this study will notably improve clinical decision-making and facilitate the creation of more sophisticated and effective medical NER models.}
}
@article{RIHM2024100004,
title = {Transforming research laboratories with connected digital twins},
journal = {Nexus},
volume = {1},
number = {1},
pages = {100004},
year = {2024},
issn = {2950-1601},
doi = {https://doi.org/10.1016/j.ynexs.2024.100004},
url = {https://www.sciencedirect.com/science/article/pii/S2950160124000020},
author = {Simon D. Rihm and Jiaru Bai and Aleksandar Kondinski and Sebastian Mosbach and Jethro Akroyd and Markus Kraft},
keywords = {laboratory automation, comprehensive digital twins, connected digital twins, AI scientist, dynamic knowledge graphs, self-driving laboratories, knowledge discovery, smart lab, lab management, research facility},
abstract = {To substantially expedite scientific discovery, research laboratories need to be further automated. In this regard, the scientific community envisions an “artificial intelligence scientist” capable of planning, conducting, and assessing experiments based on higher-order goals and reasoning capabilities. We argue that a paradigm shift is necessary to bridge the gap between the current trajectory of lab automation and this vision. Adopting a systems perspective reveals several key challenges that must be addressed. We argue that achieving holistic lab automation requires a network of comprehensive distributed digital twins grounded in a universal knowledge model. Dynamic knowledge graphs are expected to play an important role, and we introduce a framework encompassing all aspects of experimental research, including infrastructure and peripheries. Our framework considers human-machine interactions from the outset to empower a goal-driven approach that brings automation to autonomy.}
}
@article{AHMADI2024104211,
title = {3D scene generation for zero-shot learning using ChatGPT guided language prompts},
journal = {Computer Vision and Image Understanding},
volume = {249},
pages = {104211},
year = {2024},
issn = {1077-3142},
doi = {https://doi.org/10.1016/j.cviu.2024.104211},
url = {https://www.sciencedirect.com/science/article/pii/S1077314224002923},
author = {Sahar Ahmadi and Ali Cheraghian and Townim Faisal Chowdhury and Morteza Saberi and Shafin Rahman},
keywords = {Zero-shot learning, Deep learning, Point cloud object, Contrastive learning},
abstract = {Zero-shot learning in the realm of 3D point cloud data remains relatively unexplored compared to its 2D image counterpart. This domain introduces fresh challenges due to the absence of robust pre-trained feature extraction models. To tackle this, we introduce a prompt-guided method for 3D scene generation and supervision, enhancing the network’s ability to comprehend the intricate relationships between seen and unseen objects. Initially, we utilize basic prompts resembling scene annotations generated from one or two point cloud objects. Recognizing the limited diversity of basic prompts, we employ ChatGPT to expand them, enriching the contextual information within the descriptions. Subsequently, leveraging these descriptions, we arrange point cloud objects’ coordinates to fabricate augmented 3D scenes. Lastly, employing contrastive learning, we train our proposed architecture end-to-end, utilizing pairs of 3D scenes and prompt-based captions. We posit that 3D scenes facilitate more efficient object relationships than individual objects, as demonstrated by the effectiveness of language models like BERT in contextual understanding. Our prompt-guided scene generation method amalgamates data augmentation and prompt-based annotation, thereby enhancing 3D ZSL performance. We present ZSL and generalized ZSL results on both synthetic (ModelNet40, ModelNet10, and ShapeNet) and real-scanned (ScanOjbectNN) 3D object datasets. Furthermore, we challenge the model by training with synthetic data and testing with real-scanned data, achieving state-of-the-art performance compared to existing 2D and 3D ZSL methods in the literature. Codes and models are available at: https://github.com/saharahmadisohraviyeh/ChatGPT_ZSL_3D.}
}
@article{SAKONG2024121165,
title = {Higher-order knowledge-enhanced recommendation with heterogeneous hypergraph multi-attention},
journal = {Information Sciences},
volume = {680},
pages = {121165},
year = {2024},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2024.121165},
url = {https://www.sciencedirect.com/science/article/pii/S002002552401079X},
author = {Darnbi Sakong and Viet Hung Vu and Thanh Trung Huynh and Phi Le Nguyen and Hongzhi Yin and Quoc Viet Hung Nguyen and Thanh Tam Nguyen},
keywords = {Hypergraph embedding, Knowledge-based recommender systems, Self-supervised learning, Graph-based collaborative filtering},
abstract = {Recent advancements in recommender systems have focused on integrating knowledge graphs (KGs) to leverage their auxiliary information. The core idea of KG-enhanced recommenders is to incorporate rich semantic information for more accurate recommendations. However, two main challenges persist: i) Neglecting complex higher-order interactions in the KG-based user-item network, potentially leading to sub-optimal recommendations, and ii) Dealing with the heterogeneous modalities of input sources, such as user-item bipartite graphs and KGs, which may introduce noise and inaccuracies. To address these issues, we present a novel Knowledge-enhanced Heterogeneous Hypergraph Recommender System (KHGRec). KHGRec captures group-wise characteristics of both the interaction network and the KG, modeling complex connections in the KG. Using a collaborative knowledge heterogeneous hypergraph (CKHG), it employs two hypergraph encoders to model group-wise interdependencies and ensure explainability. Additionally, it fuses signals from the input graphs with cross-view self-supervised learning and attention mechanisms. Extensive experiments on four real-world datasets show our model's superiority over various state-of-the-art baselines, with an average 5.18% relative improvement. Additional tests on noise resilience, missing data, and cold-start problems demonstrate the robustness of our KHGRec framework. Our model and evaluation datasets are publicly available at https://github.com/viethungvu1998/KHGRec.}
}
@article{JONNAKUTI2024100707,
title = {PolyAMiner-Bulk is a deep learning-based algorithm that decodes alternative polyadenylation dynamics from bulk RNA-seq data},
journal = {Cell Reports Methods},
volume = {4},
number = {2},
pages = {100707},
year = {2024},
issn = {2667-2375},
doi = {https://doi.org/10.1016/j.crmeth.2024.100707},
url = {https://www.sciencedirect.com/science/article/pii/S2667237524000213},
author = {Venkata Soumith Jonnakuti and Eric J. Wagner and Mirjana Maletić-Savatić and Zhandong Liu and Hari Krishna Yalamanchili},
keywords = {alternative polyadenylation (APA), post-transcriptional regulation, deep learning, large language model (LLM), bioinformatics, computational biology, gene regulation},
abstract = {Summary
Alternative polyadenylation (APA) is a key post-transcriptional regulatory mechanism; yet, its regulation and impact on human diseases remain understudied. Existing bulk RNA sequencing (RNA-seq)-based APA methods predominantly rely on predefined annotations, severely impacting their ability to decode novel tissue- and disease-specific APA changes. Furthermore, they only account for the most proximal and distal cleavage and polyadenylation sites (C/PASs). Deconvoluting overlapping C/PASs and the inherent noisy 3′ UTR coverage in bulk RNA-seq data pose additional challenges. To overcome these limitations, we introduce PolyAMiner-Bulk, an attention-based deep learning algorithm that accurately recapitulates C/PAS sequence grammar, resolves overlapping C/PASs, captures non-proximal-to-distal APA changes, and generates visualizations to illustrate APA dynamics. Evaluation on multiple datasets strongly evinces the performance merit of PolyAMiner-Bulk, accurately identifying more APA changes compared with other methods. With the growing importance of APA and the abundance of bulk RNA-seq data, PolyAMiner-Bulk establishes a robust paradigm of APA analysis.}
}
@article{LU2025129145,
title = {A novel span-based Knowledge-enhanced framework for aspect sentiment triplet extraction},
journal = {Neurocomputing},
volume = {619},
pages = {129145},
year = {2025},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2024.129145},
url = {https://www.sciencedirect.com/science/article/pii/S0925231224019167},
author = {Heng-yang Lu and Rui Cong and Wei Nie and Tian-ci Liu and Wei Fang},
keywords = {Aspect sentiment triplet extraction, Sentiment analysis, Attention mechanism, Common-sense knowledge},
abstract = {Aspect Sentiment Triplet Extraction (ASTE) is a subtask of Aspect-based Sentiment Analysis, which aims to identify all aspect sentiment triplets in given sentences. ASTE is an important research task to discover sentimental opinions in online social media. Existing ASTE models are usually based on pipeline or joint strategy. The pipeline-based methods may suffer from error propagation. The joint-based methods could avoid error propagation in an end-to-end manner, which have become the more popular choice. Among these joint-based ASTE models, the syntactic information from the dependency tree is widely used. However, the dependency tree may fail to connect the aspect and opinion terms in some cases, which causes the lack of interaction in triplets. Inspired by the work of Liang et al. on the Aspect Sentiment Classification (ASC) task, we integrate common-sense knowledge into the ASTE task, which can bring more important information to the modeling of context representation. To address these limitations, this paper first involves common-sense sentiment knowledge along with syntactic dependency knowledge to get better representations of contexts. The syntactic and common-sense knowledge can contribute to the interpretability when extracting the sentiment elements. We also introduce a self-attention mechanism based on the orthogonal loss function to better capture the interactions between words. We evaluated our model on four public datasets with recently proposed baselines in F1-score metric, especially 3.62%, 4.14%, 3.58% and 2.22% higher on 14Res, 14Lap, 15Res, and 16Res, compared to the SSJE approach, respectively. Experimental results show that our method outperforms SOTA models on three datasets.}
}
@article{GILLINGS2025100121,
title = {How humans and machines identify discourse topics: A methodological triangulation},
journal = {Applied Corpus Linguistics},
volume = {5},
number = {1},
pages = {100121},
year = {2025},
issn = {2666-7991},
doi = {https://doi.org/10.1016/j.acorp.2025.100121},
url = {https://www.sciencedirect.com/science/article/pii/S2666799125000048},
author = {Mathew Gillings and Sylvia Jaworska},
keywords = {Triangulation, Topic modelling, CADS, Concordance analysis, Close reading, LLMs},
abstract = {Identifying and exploring discursive topics in texts is of interest to not only linguists, but to researchers working across the full breadth of the social sciences. This paper reports on an exploratory study assessing the influence that analytical method has on the identification and labelling of topics, which might lead to varying interpretations of texts. Using a corpus of corporate sustainability reports, totalling 98,277 words, we asked 6 different researchers to interrogate the corpus and decide on its main ‘topics’ via four different methods: LLM-assisted analyses; topic modelling; concordance analysis; and close reading. These methods differ according to the amount of data that can be analysed at once, the amount of textual context available to the researcher, and the focus of the analysis (i.e., micro to macro). The paper explores how the identified topics differed both between analysts using the same method, and between methods. We conclude with a series of tentative observations regarding the benefits and limitations of each method, and offer recommendations for researchers in choosing which analytical technique to select.}
}
@article{CREMA2023104557,
title = {Advancing Italian biomedical information extraction with transformers-based models: Methodological insights and multicenter practical application},
journal = {Journal of Biomedical Informatics},
volume = {148},
pages = {104557},
year = {2023},
issn = {1532-0464},
doi = {https://doi.org/10.1016/j.jbi.2023.104557},
url = {https://www.sciencedirect.com/science/article/pii/S1532046423002782},
author = {Claudio Crema and Tommaso Mario Buonocore and Silvia Fostinelli and Enea Parimbelli and Federico Verde and Cira Fundarò and Marina Manera and Matteo Cotta Ramusino and Marco Capelli and Alfredo Costa and Giuliano Binetti and Riccardo Bellazzi and Alberto Redolfi},
keywords = {Natural language processing, Deep learning, Biomedical text mining, Language model, Transformer},
abstract = {The introduction of computerized medical records in hospitals has reduced burdensome activities like manual writing and information fetching. However, the data contained in medical records are still far underutilized, primarily because extracting data from unstructured textual medical records takes time and effort. Information Extraction, a subfield of Natural Language Processing, can help clinical practitioners overcome this limitation by using automated text-mining pipelines. In this work, we created the first Italian neuropsychiatric Named Entity Recognition dataset, PsyNIT, and used it to develop a Transformers-based model. Moreover, we collected and leveraged three external independent datasets to implement an effective multicenter model, with overall F1-score 84.77 %, Precision 83.16 %, Recall 86.44 %. The lessons learned are: (i) the crucial role of a consistent annotation process and (ii) a fine-tuning strategy that combines classical methods with a “low-resource” approach. This allowed us to establish methodological guidelines that pave the way for Natural Language Processing studies in less-resourced languages.}
}
@article{SIMA2025110941,
title = {Small and medium-sized enterprise dedicated knowledge exploitation mechanism: A recommender system based on knowledge relatedness},
journal = {Computers & Industrial Engineering},
pages = {110941},
year = {2025},
issn = {0360-8352},
doi = {https://doi.org/10.1016/j.cie.2025.110941},
url = {https://www.sciencedirect.com/science/article/pii/S0360835225000877},
author = {Xingyu Sima and Thierry Coudert and Laurent Geneste and Aymeric {de Valroger}},
keywords = {Knowledge management (KM), Knowledge exploitation, Knowledge graph (KG), Knowledge relatedness, Recommender system (RS), Small and medium-sized enterprises (SMEs)},
abstract = {Knowledge is a vital asset for organizations, especially in today’s Industry 4.0 context with the ever-increasing amount of information being produced. Organizations must consider knowledge management (KM) to create a sustainable competitive advantage. Currently, KM is applied relatively well in large organizations; however, small and medium-sized enterprises (SMEs) encounter various constraints. Knowledge exploitation is a key phase in KM for the retrieval of relevant knowledge. Therefore, a recommender system (RS), which is a promising and widely used information technology (IT) tool, is proposed in this study, for SMEs to enable effective knowledge exploitation. The RS can be adapted to SME KM specificities and a dedicated RS based on knowledge relatedness derived from different information sources is proposed herein. The proposed RS enables the recommendation of knowledge item balancing: i) historical application data, that is, information regarding how items were related during past projects, and ii) initial relatedness knowledge, which represents the relationships between knowledge items defined by knowledge experts. The proposed RS was developed in collaboration with the Axsens-bte SME, who specialize in consultancy and training in the supply chain, Industry 4.0, and quality requirements management. The proposed RS improved SME KM processes and increased efficiency in terms of exploiting knowledge assets. This demonstrated the ability of the proposed RS to assist SMEs in efficiently and effectively navigating complex information environments.}
}
@article{XU2025107580,
title = {Learning protein language contrastive models with multi-knowledge representation},
journal = {Future Generation Computer Systems},
volume = {164},
pages = {107580},
year = {2025},
issn = {0167-739X},
doi = {https://doi.org/10.1016/j.future.2024.107580},
url = {https://www.sciencedirect.com/science/article/pii/S0167739X24005442},
author = {Wenjun Xu and Yingchun Xia and Bifan Sun and Zihao Zhao and Lianggui Tang and Xiaobo Zhou and Qingyong Wang and Lichuan Gu},
keywords = {Protein representation learning, Contrastive learning, Multi-knowledge embeddings, Convex approximation},
abstract = {Protein representation learning plays a crucial role in obtaining a comprehensive understanding of biological regulatory mechanisms and in developing proteins and drugs for therapeutic purposes. However, labeled proteins, such as sequenced and functionally annotated data, are incomplete and few. Thus, contrastive learning has emerged as the preferred technique for learning meaningful representations from unlabeled data samples. In addition, at present, natural proteins cannot be fully described by extracting protein knowledge from a single domain. Therefore, Pro-CoRL, a protein contrastive models framework based on multi-knowledge representation learning, was proposed in this study. In particular, Pro-CoRL smooths the objective function using convex approximation, thereby improving the stability of training. Extensive experiments on predicting protein–protein interaction types and clustering protein families have confirmed the high accuracy and robustness of Pro-CoRL.}
}
@article{REN20241619,
title = {TCMM: A unified database for traditional Chinese medicine modernization and therapeutic innovations},
journal = {Computational and Structural Biotechnology Journal},
volume = {23},
pages = {1619-1630},
year = {2024},
issn = {2001-0370},
doi = {https://doi.org/10.1016/j.csbj.2024.04.016},
url = {https://www.sciencedirect.com/science/article/pii/S2001037024001053},
author = {Zhixiang Ren and Yiming Ren and Zeting Li and Huan Xu},
keywords = {Traditional Chinese medicine, Database, Knowledge graph, Deep learning, Graph neural network},
abstract = {Mining the potential of traditional Chinese medicine (TCM) in treating modern diseases requires a profound understanding of its action mechanism and a comprehensive knowledge system that seamlessly bridges modern medical insights with traditional theories. However, existing databases for modernizing TCM are plagued by varying degrees of information loss, which impede the multidimensional dissection of pharmacological effects. To address this challenge, we introduce traditional Chinese medicine modernization (TCMM), the currently largest modernized TCM database that integrates pioneering intelligent pipelines. By aligning high-quality TCM and modern medicine data, TCMM boasts the most extensive TCM modernization knowledge, including 20 types of modernized TCM concepts such as prescription, ingredient, target and 46 biological relations among them, totaling 3,447,023 records. We demonstrate the efficacy and reliability of TCMM with two features, prescription generation and knowledge discovery, the outcomes show consistency with biological experimental results. A publicly available web interface is at https://www.tcmm.net.cn/.}
}
@article{NYAMATHI2024,
title = {Establishing the Foundations of Emotional Intelligence in Care Companion Robots to Mitigate Agitation Among High-Risk Patients With Dementia: Protocol for an Empathetic Patient-Robot Interaction Study},
journal = {JMIR Research Protocols},
volume = {13},
year = {2024},
issn = {1929-0748},
doi = {https://doi.org/10.2196/55761},
url = {https://www.sciencedirect.com/science/article/pii/S1929074824004803},
author = {Adeline Nyamathi and Nikil Dutt and Jung-Ah Lee and Amir M Rahmani and Mahkameh Rasouli and Donna Krogh and Erik Krogh and David Sultzer and Humayun Rashid and Hamza Liaqat and Riyam Jawad and Farhan Azhar and Ali Ahmad and Bilal Qamar and Taha Yasin Bhatti and Chet Khay and Jocelyn Ludlow and Lisa Gibbs and Julie Rousseau and Mahyar Abbasian and Yutong Song and Cheonkam Jeong and Sabine Brunswicker},
keywords = {persons with dementia, empathy-based care companion robot, agitation, fall risk, artificial intelligence, AI},
abstract = {Background
An estimated 6.7 million persons are living with dementia in the United States, a number expected to double by 2060. Persons experiencing moderate to severe dementia are 4 to 5 times more likely to fall than those without dementia, due to agitation and unsteady gait. Socially assistive robots fail to address the changing emotional states associated with agitation, and it is unclear how emotional states change, how they impact agitation and gait over time, and how social robots can best respond by showing empathy.
Objective
This study aims to design and validate a foundational model of emotional intelligence for empathetic patient-robot interaction that mitigates agitation among those at the highest risk: persons experiencing moderate to severe dementia.
Methods
A design science approach will be adopted to (1) collect and store granular, personal, and chronological data using Personicle (an open-source software platform developed to automatically collect data from phones and other devices), incorporating real-time visual, audio, and physiological sensing technologies in a simulation laboratory and at board and care facilities; (2) develop statistical models to understand and forecast the emotional state, agitation level, and gait pattern of persons experiencing moderate to severe dementia in real time using machine learning and artificial intelligence and Personicle; (3) design and test an empathy-focused conversation model, focused on storytelling; and (4) test and evaluate this model for a care companion robot (CCR) in the community.
Results
The study was funded in October 2023. For aim 1, architecture development for Personicle data collection began with a search for existing open-source data in January 2024. A community advisory board was formed and met in December 2023 to provide feedback on the use of CCRs and provide personal stories. Full institutional review board approval was received in March 2024 to place cameras and CCRs at the sites. In March 2024, atomic marker development was begun. For aim 2, after a review of open-source data on patients with dementia, the development of an emotional classifier was begun. Data labeling was started in April 2024 and completed in June 2024 with ongoing validation. Moreover, the team established a baseline multimodal model trained and validated on healthy-person data sets, using transformer architecture in a semisupervised manner, and later retrained on the labeled data set of patients experiencing moderate to severe dementia. In April 2024, empathy alignment of large language models was initiated using prompt engineering and reinforcement learning.
Conclusions
This innovative caregiving approach is designed to recognize the signs of agitation and, upon recognition, intervene with empathetic verbal communication. This proposal has the potential to have a significant impact on an emerging field of computational dementia science by reducing unnecessary agitation and falls of persons experiencing moderate to severe dementia, while reducing caregiver burden.
International Registered Report Identifier (IRRID)
PRR1-10.2196/55761}
}
@article{SYED2024100238,
title = {Airline reviews processing: Abstractive summarization and rating-based sentiment classification using deep transfer learning},
journal = {International Journal of Information Management Data Insights},
volume = {4},
number = {2},
pages = {100238},
year = {2024},
issn = {2667-0968},
doi = {https://doi.org/10.1016/j.jjimei.2024.100238},
url = {https://www.sciencedirect.com/science/article/pii/S2667096824000272},
author = {Ayesha Ayub Syed and Ford Lumban Gaol and Alfred Boediman and Widodo Budiharto},
keywords = {Airline reviews, Domain adaptation, Opinion summarization, Review rating, Sentiment classification, Two-stage finetuning},
abstract = {Opinion summarization and sentiment classification are key processes for understanding, analyzing, and leveraging information from customer opinions. The rapid and ceaseless increase in big data of reviews on e-commerce platforms, social media, or review portals becomes a stimulus for the automation of these processes. In recent years, deep transfer learning has opted to solve many challenging tasks in Natural Language Processing (NLP) relieving the hassles of exhaustive training and the requirement of extensive labelled datasets. In this work, we propose frameworks for Abstractive Summarization (ABS) and Sentiment Analysis (SA) of airline reviews using Pretrained Language Models (PLM). The abstractive summarization model goes through two finetuning stages, the first one, for domain adaptation and the second one, for final task learning. Several studies in the literature empirically demonstrate that review rating has a positive correlation with sentiment valence. For the sentiment classification framework, we used the rating value as a signal to determine the review sentiment, and the model is built on top of BERT (Bidirectional Encoder Representations from Transformers) architecture. We evaluated our models comprehensively with multiple metrics. Our results indicate competitive performance of the models in terms of most of the evaluation metrics.}
}
@article{KONDINSKI20241071,
title = {Hacking decarbonization with a community-operated CreatorSpace},
journal = {Chem},
volume = {10},
number = {4},
pages = {1071-1083},
year = {2024},
issn = {2451-9294},
doi = {https://doi.org/10.1016/j.chempr.2023.12.018},
url = {https://www.sciencedirect.com/science/article/pii/S2451929423006198},
author = {Aleksandar Kondinski and Sebastian Mosbach and Jethro Akroyd and Andrew Breeson and Yong Ren Tan and Simon Rihm and Jiaru Bai and Markus Kraft},
keywords = {decarbonization, chemistry, knowledge graphs, agents, CreatorSpace},
abstract = {Summary
The pressing challenge of decarbonization encompasses a vast combinatorial space of interlinked technologies, thus necessitating an increased reliance on artificial intelligence (AI)-assisted molecular modeling and data analytics. Our backcasting analysis proposes a future rich in efficient decarbonization technologies, such as sustainable fuels for aviation and shipping, as well as carbon capture and utilization. We then retrace the path to this proposed future with the guidance of two constraints: the maximization of scientists’ creative capacities and the evolution of a world-centric AI. Our exploration leads us to the concept of a “CreatorSpace,” a distributed digital system resembling existing hackerspaces and makerspaces known for accelerating the prototyping of new technologies worldwide. The CreatorSpace serves as a virtual, semantic platform where chemists, engineers, and materials scientists can freely collaborate, integrating chemical knowledge with cross-scale, cross-technology tools, and operations. This streamlined molecular-to-process-design pathway facilitates a diverse array of solutions for decarbonization and other sustainability technologies.}
}
@article{MING2024104658,
title = {Enhancing the coverage of SemRep using a relation classification approach},
journal = {Journal of Biomedical Informatics},
volume = {155},
pages = {104658},
year = {2024},
issn = {1532-0464},
doi = {https://doi.org/10.1016/j.jbi.2024.104658},
url = {https://www.sciencedirect.com/science/article/pii/S1532046424000765},
author = {Shufan Ming and Rui Zhang and Halil Kilicoglu},
keywords = {Biomedical relation extraction, Relation classification, Large language models, SemRep, SemMedDB},
abstract = {Objective:
Relation extraction is an essential task in the field of biomedical literature mining and offers significant benefits for various downstream applications, including database curation, drug repurposing, and literature-based discovery. The broad-coverage natural language processing (NLP) tool SemRep has established a solid baseline for extracting subject–predicate–object triples from biomedical text and has served as the backbone of the Semantic MEDLINE Database (SemMedDB), a PubMed-scale repository of semantic triples. While SemRep achieves reasonable precision (0.69), its recall is relatively low (0.42). In this study, we aimed to enhance SemRep using a relation classification approach, in order to eventually increase the size and the utility of SemMedDB.
Methods:
We combined and extended existing SemRep evaluation datasets to generate training data. We leveraged the pre-trained PubMedBERT model, enhancing it through additional contrastive pre-training and fine-tuning. We experimented with three entity representations: mentions, semantic types, and semantic groups. We evaluated the model performance on a portion of the SemRep Gold Standard dataset and compared it to SemRep performance. We also assessed the effect of the model on a larger set of 12K randomly selected PubMed abstracts.
Results:
Our results show that the best model yields a precision of 0.62, recall of 0.81, and F1 score of 0.70. Assessment on 12K abstracts shows that the model could double the size of SemMedDB, when applied to entire PubMed. We also manually assessed the quality of 506 triples predicted by the model that SemRep had not previously identified, and found that 67% of these triples were correct.
Conclusion:
These findings underscore the promise of our model in achieving a more comprehensive coverage of relationships mentioned in biomedical literature, thereby showing its potential in enhancing various downstream applications of biomedical literature mining. Data and code related to this study are available at https://github.com/Michelle-Mings/SemRep_RelationClassification.}
}
@incollection{KATO20242839,
title = {Prototype of Automated Physical Model Builder: Challenges and Opportunities},
editor = {Flavio Manenti and Gintaras V. Reklaitis},
series = {Computer Aided Chemical Engineering},
publisher = {Elsevier},
volume = {53},
pages = {2839-2844},
year = {2024},
booktitle = {34th European Symposium on Computer Aided Process Engineering / 15th International Symposium on Process Systems Engineering},
issn = {1570-7946},
doi = {https://doi.org/10.1016/B978-0-443-28824-1.50474-9},
url = {https://www.sciencedirect.com/science/article/pii/B9780443288241504749},
author = {Shota Kato and Manabu Kano},
keywords = {Artificial intelligence, Physical model, Digital twin, Natural language processing, Process modelling},
abstract = {In the process industry, physical models are indispensable, yet current models sometimes compromise accuracy or incur substantial computational costs. Such cases require new physical models, but the traditional approach to building physical models is reliant on expert knowledge and is time-consuming. This necessitates the development of a new efficient physical model building methodology. Our research aims to establish automated physical model builder, AutoPMoB, which builds physical models from manufacturing process literature. The realization of AutoPMoB requires developing several methods, including those for collecting documents related to the target process and accurately extracting information for physical model building from the documents. In this study, we develop an AutoPMoB prototype, employing a large language model alongside a model building approach previously proposed in our research. The prototype's application to a continuous stirred tank reactor showed its capability to extract necessary data accurately, although the initial attempts did not yield the anticipated models. Subsequent modifications in unifying expressions led to successful model building, underscoring the effectiveness of our system in leveraging literature for physical model building. Advancing AutoPMoB towards practical deployment necessitates specific enhancements, particularly in methods for equivalence judgment of definitions, retrieval of relevant documents, integration of non-documentary information, and domain-specific adaptation.}
}
@article{SONG2024104,
title = {Relation-aware deep neural network enables more efficient biomedical knowledge acquisition from massive literature},
journal = {AI Open},
volume = {5},
pages = {104-114},
year = {2024},
issn = {2666-6510},
doi = {https://doi.org/10.1016/j.aiopen.2024.08.002},
url = {https://www.sciencedirect.com/science/article/pii/S2666651024000123},
author = {Chenyang Song and Zheni Zeng and Changyao Tian and Kuai Li and Yuan Yao and Suncong Zheng and Zhiyuan Liu and Maosong Sun},
keywords = {Biomedical knowledge retrieval, Biomedical relation modeling, Deep learning, Pre-trained language model},
abstract = {Biomedical knowledge is typically organized in a relational scheme, such as chemical-disease relation, gene-disease relation, and gene-pathway relation. Biomedical scientists heavily rely on search engines to acquire up-to-date relational knowledge from massive biomedical articles. The navigation efficiency of the retrieval process, however, is significantly restricted by keyword matching techniques unaware of the biomedical relations of these keywords in articles. To bridge the gap between existing retrieval techniques and practical access demands for relational knowledge, we present a novel framework, Biomedical Relation-Aware Document Ranking (BioRADR), capable of retrieving articles expressing specific relations with respect to the queried entity pair. Based on a deep neural network, BioRADR can be trained from large-scale data automatically annotated via distant supervision, and empirical evaluation reveals that it outperforms the strongest baseline by over 8 points in NDCG@1. We implement an online system (http://bioradr.ai.thunlp.org/) based on BioRADR, enabling more efficient relation-oriented retrieval of biomedical articles.}
}
@article{TAO202579,
title = {Intelligent emergency assisted decision-making method based on standard digitalization: Hazardous chemical accidents in industrial parks},
journal = {Journal of Safety Science and Resilience},
volume = {6},
number = {1},
pages = {79-92},
year = {2025},
issn = {2666-4496},
doi = {https://doi.org/10.1016/j.jnlssr.2024.06.009},
url = {https://www.sciencedirect.com/science/article/pii/S2666449624000513},
author = {Zhenxiang Tao and Xiaohan Liu and Ying Li and Peifeng Hu and Weitong Tang and Ning Luo and Jiansong Wu and Rui Yang},
keywords = {Public safety, Emergency response, Assisted decision, Knowledge graph, Standard digitization},
abstract = {Contemporary society is confronted with multifaceted challenges, and the intricate interplay of interconnected factors significantly complicates emergency response efforts. Current practices rely on quick decisions by domain experts; however, the limitations of individual expertise and the urgency of crises hinder both precision and standardization. To address these issues, we propose a novel approach: an intelligent method for emergency decision-making grounded in a standardized digital knowledge graph. First, our study examined the underlying theory of standardized digital transformation and event-chain evolution. This led to the construction of a knowledge graph encompassing standard emergency knowledge, as well as supplementary derivative data pertinent to event response. Second, through the application of semantic analysis and intention recognition of the decision target, coherent and interpretable query sentences for the decision system were crafted. These query sentences then served as a conduit for retrieving standard emergency knowledge relevant to the current emergency situation, as well as potential secondary disasters. The overarching goal is to provide emergency decision makers with effective support mechanisms that are both well informed and tailored to the specific demands of each situation.}
}
@article{FENG2024124462,
title = {Focusing on differences! Sample framework enhances semantic textual similarity with external knowledge},
journal = {Expert Systems with Applications},
volume = {255},
pages = {124462},
year = {2024},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2024.124462},
url = {https://www.sciencedirect.com/science/article/pii/S0957417424013289},
author = {Jianzhou Feng and Junxin Liu and Chenghan Gu and Haotian Qi and Zhongcan Ren and Kehan Xu and Yuanzhuo Wang},
keywords = {Semantic similarity task, Differential information, Sentence embeddings},
abstract = {Recently, the widespread application of pre-trained language models (PLMs) such as BERT and RoBERTa has significantly enhanced the performance of tasks related to text semantic similarity. However, methods solely based on PLMs inadequately account for the differential information between sentence pairs, thus underestimating the importance of this information in sentence matching. In this paper, we propose the enriching Differential information with External Knowledge framework (DEK), an approach that explicitly extracts differential information and enriches semantics using external knowledge. Specifically, we devise a module for extracting differential words from sentence pairs, obtain synonyms of differential words from WordNet, and construct a differential information graph. We employ Graph Convolutional Networks (GCNs) to extract features from this graph and subsequently integrate this information into sentence embeddings. In this work, we demonstrate that incorporating differential information enables PLMs-based methods to better focus on the differing aspects of sentences. Moreover, DEK seamlessly adapts to contrastive learning of sentence embeddings models, including SimCSE and PromptBert, among others. Comparing to baseline, our method has improved spearman correlation between 0.22 and 0.64, yielding competitive results in the experiments.}
}
@article{SHI2025107191,
title = {Knowledge-Guided Semantically Consistent Contrastive Learning for sequential recommendation},
journal = {Neural Networks},
volume = {185},
pages = {107191},
year = {2025},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2025.107191},
url = {https://www.sciencedirect.com/science/article/pii/S089360802500070X},
author = {Chenglong Shi and Surong Yan and Shuai Zhang and Haosen Wang and Kwei-Jay Lin},
keywords = {Sequential recommendation, Contrastive learning, Knowledge graph, Semantic consistency},
abstract = {Contrastive learning has gained dominance in sequential recommendation due to its ability to derive self-supervised signals for addressing data sparsity problems. However, caused by random augmentations (e.g., crop, mask, and reorder), existing methods may produce positive views with inconsistent semantics, which degrades performance. Although some efforts have been made by providing new operations (e.g., insert and substitute), challenges have not been well addressed due to information scarcity. Inspired by the massive semantic relationships in the Item Knowledge Graph (IKG), we propose a Knowledge-Guided Semantically consistent Contrastive Learning model for sequential recommendation (KGSCL). Specifically, we introduce two knowledge-guided augmentation operations, KG-substitute and KG-insert, to create semantically consistent and meaningful views. These operations add knowledge-related items from the neighbors in the IKG to augment the sequence, aligning real-world associations to retain original semantics. Meanwhile, we design a co-occurrence-based sampling strategy to complement knowledge-guided augmentations for selecting more correlated neighbors. Moreover, we introduce a view-target CL to model the correlation between semantically consistent views and target items since they exhibit similar user preferences. Experimental results on six widely used datasets demonstrate the effectiveness of our KGSCL in recommendation performance, robustness, and model convergence compared with 14 state-of-the-art competitors. Our code is available at: https://github.com/LFM-bot/KGSCL.}
}
@article{VETTER2024102831,
title = {Towards a framework for local interrogation of AI ethics: A case study on text generators, academic integrity, and composing with ChatGPT},
journal = {Computers and Composition},
volume = {71},
pages = {102831},
year = {2024},
issn = {8755-4615},
doi = {https://doi.org/10.1016/j.compcom.2024.102831},
url = {https://www.sciencedirect.com/science/article/pii/S8755461524000070},
author = {Matthew A. Vetter and Brent Lucia and Jialei Jiang and Mahmoud Othman},
keywords = {Artificial intelligence (AI), Academic integrity, Text generators, academic policy, Composition pedagogy, Ethics},
abstract = {Ethical frameworks for text generators (TGs) in education are generally concerned with personalized instruction, a dependency on data, biases in training data, academic integrity, and lack of creativity from students. While broad-level, institutional guidelines provide value in understanding the ethical dimensions of artificial intelligence (AI) for the classroom, there is a need for a more ecological understanding of how AI ethics might be constructed locally, one that takes into account the negotiation of AI between teacher and student. This article investigates how an educational ethical framework for AI use emerges through a qualitative case study of one composition student's interaction with and understanding of using ChatGPT as a type of writing partner. Analysis of interview data and student logs uncover what we term an emergent “local ethic” – a framework that is capable of exploring unique ethical considerations, values, and norms that develop at the most foundational unit of higher education – the individual classroom. Our framework is meant to provide a heuristic for other writing teacher-scholars as they interrogate issues related to pedagogy, student criticality, agency, reliability, and access within the context of powerful AI systems.}
}
@article{KUGIC2024,
title = {Processing of Short-Form Content in Clinical Narratives: Systematic Scoping Review},
journal = {Journal of Medical Internet Research},
volume = {26},
year = {2024},
issn = {1438-8871},
doi = {https://doi.org/10.2196/57852},
url = {https://www.sciencedirect.com/science/article/pii/S1438887124006009},
author = {Amila Kugic and Ingrid Martin and Luise Modersohn and Peter Pallaoro and Markus Kreuzthaler and Stefan Schulz and Martin Boeker},
keywords = {electronic health records, EHR, clinical narratives, natural language processing, machine learning, deep learning, rule-based approach, short-form expression, disambiguation, word embedding, vector representations, language modeling, human-in-the-loop, feature extraction},
abstract = {Background
Clinical narratives are essential components of electronic health records. The adoption of electronic health records has increased documentation time for hospital staff, leading to the use of abbreviations and acronyms more frequently. This brevity can potentially hinder comprehension for both professionals and patients.
Objective
This review aims to provide an overview of the types of short forms found in clinical narratives, as well as the natural language processing (NLP) techniques used for their identification, expansion, and disambiguation.
Methods
In the databases Web of Science, Embase, MEDLINE, EBMR (Evidence-Based Medicine Reviews), and ACL Anthology, publications that met the inclusion criteria were searched according to PRISMA (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) guidelines for a systematic scoping review. Original, peer-reviewed publications focusing on short-form processing in human clinical narratives were included, covering the period from January 2018 to February 2023. Short-form types were extracted, and multidimensional research methodologies were assigned to each target objective (identification, expansion, and disambiguation). NLP study recommendations and study characteristics were systematically assigned occurrence rates for evaluation.
Results
Out of a total of 6639 records, only 19 articles were included in the final analysis. Rule-based approaches were predominantly used for identifying short forms, while string similarity and vector representations were applied for expansion. Embeddings and deep learning approaches were used for disambiguation.
Conclusions
The scope and types of what constitutes a clinical short form were often not explicitly defined by the authors. This lack of definition poses challenges for reproducibility and for determining whether specific methodologies are suitable for different types of short forms. Analysis of a subset of NLP recommendations for assessing quality and reproducibility revealed only partial adherence to these recommendations. Single-character abbreviations were underrepresented in studies on clinical narrative processing, as were investigations in languages other than English. Future research should focus on these 2 areas, and each paper should include descriptions of the types of content analyzed.}
}
@incollection{DANU2024,
title = {Idiolect},
booktitle = {Reference Module in Social Sciences},
publisher = {Elsevier},
year = {2024},
isbn = {978-0-443-15785-1},
doi = {https://doi.org/10.1016/B978-0-323-95504-1.00122-8},
url = {https://www.sciencedirect.com/science/article/pii/B9780323955041001228},
author = {Julija Danu and Krzysztof Kredens and Tim Grant},
keywords = {Idiolect, Linguistic individual, Style, Authorship, Authorship analysis, Forensic linguistics},
abstract = {We examine the development of the idea of the linguistic individual and the concept of idiolect from antiquity to contemporary theories and provide a brief survey of international approaches to these discussions, and empirical attempts to establish the evidence of existence of idiolects before looking at applications, primarily in forensic linguistic casework. The future indicates that interest in Large Language Models is likely to influence development of both theory and empirical evidence that idiolects exist.}
}
@article{BABAIAN2024114172,
title = {Entity recognition from colloquial text},
journal = {Decision Support Systems},
volume = {179},
pages = {114172},
year = {2024},
issn = {0167-9236},
doi = {https://doi.org/10.1016/j.dss.2024.114172},
url = {https://www.sciencedirect.com/science/article/pii/S0167923624000058},
author = {Tamara Babaian and Jennifer Xu},
keywords = {Entity recognition, Symptom recognition, Natural language processing, Training strategies, Design science},
abstract = {Extraction of concepts and entities of interest from non-formal texts such as social media posts and informal communication is an important capability for decision support systems in many domains, including healthcare, customer relationship management, and others. Despite the recent advances in training large language models for a variety of natural language processing tasks, the developed models and techniques have mainly focused on formal texts and do not perform as well on colloquial data, which is characterized by a number of distinct challenges. In our research, we focus on the healthcare domain and investigate the problem of symptom recognition from colloquial texts by designing and evaluating several training strategies for BERT-based model fine-tuning. These strategies are distinguished by the choice of the base model, the training corpora, and application of term perturbations in the training data. The best-performing models trained using these strategies outperform the state-of-the-art specialized symptom recognizer by a large margin. Through a series of experiments, we have found specific patterns of model behavior associated with the training strategies we designed. We present design principles for training strategies for effective entity recognition in colloquial texts based on our findings.}
}
@article{LI2025111176,
title = {Pseudo-labeling with keyword refining for few-supervised video captioning},
journal = {Pattern Recognition},
volume = {159},
pages = {111176},
year = {2025},
issn = {0031-3203},
doi = {https://doi.org/10.1016/j.patcog.2024.111176},
url = {https://www.sciencedirect.com/science/article/pii/S0031320324009270},
author = {Ping Li and Tao Wang and Xinkui Zhao and Xianghua Xu and Mingli Song},
keywords = {Video captioning, Few supervision, Pseudo-labeling, Keyword refiner, Gated fusion},
abstract = {Video captioning generate a sentence that describes the video content. Existing methods always require a number of captions (e.g., 10 or 20) per video to train the model, which is quite costly. In this work, we explore the possibility of using only one or very few ground-truth sentences, and introduce a new task named few-supervised video captioning. Specifically, we propose a few-supervised video captioning framework that consists of lexically constrained pseudo-labeling module and keyword-refined captioning module. Unlike the random sampling in natural language processing that may cause invalid modifications (i.e., edit words), the former module guides the model to edit words using some actions (e.g., copy, replace, insert, and delete) by a pretrained token-level classifier, and then fine-tunes candidate sentences by a pretrained language model. Meanwhile, the former employs the repetition penalized sampling to encourage the model to yield concise pseudo-labeled sentences with less repetition, and selects the most relevant sentences upon a pretrained video-text model. Moreover, to keep semantic consistency between pseudo-labeled sentences and video content, we develop the transformer-based keyword refiner with the video-keyword gated fusion strategy to emphasize more on relevant words. Extensive experiments on several benchmarks demonstrate the advantages of the proposed approach in both few-supervised and fully-supervised scenarios.}
}
@article{YANG2024120134,
title = {Information bottleneck based knowledge selection for commonsense reasoning},
journal = {Information Sciences},
volume = {660},
pages = {120134},
year = {2024},
issn = {0020-0255},
doi = {https://doi.org/10.1016/j.ins.2024.120134},
url = {https://www.sciencedirect.com/science/article/pii/S0020025524000471},
author = {Zhao Yang and Yuanzhe Zhang and Pengfei Cao and Cao Liu and Jiansong Chen and Jun Zhao and Kang Liu},
keywords = {Commonsense reasoning, Knowledge selection, Information bottleneck, KG-augmented model},
abstract = {KG-augmented models usually endow existing models with external knowledge graphs, which achieve promising performance in various knowledge-intensive tasks, such as commonsense reasoning. Existing methods mainly first exploited heuristic ways for retrieving the relevant knowledge subgraphs according to the input, and then utilized some effective encoders, such as GNNs, to encode the symbolic knowledge into the neural reasoning networks. However, whether the whole retrieved knowledge subgraphs are really relevant or useful for the reasoning process was seldom considered. Actually, according to our observations and analysis, most retrieved knowledge is noisy and useless to the reasoning models, which would hurt the final performance. To remedy this, this paper proposes information bottleneck based knowledge selection (IBKS), which is able to select useful knowledge from the retrieved knowledge subgraph. Expectedly, the selected knowledge could better improve the commonsense reasoning ability of the model. Moreover, IBKS is model-agnostic and could be plugged into any existing KG-augmented model. Extensive experimental results show that IBKS could effectively improve commonsense reasoning performance.}
}
@article{CHAU2024102666,
title = {Advancing plant single-cell genomics with foundation models},
journal = {Current Opinion in Plant Biology},
volume = {82},
pages = {102666},
year = {2024},
issn = {1369-5266},
doi = {https://doi.org/10.1016/j.pbi.2024.102666},
url = {https://www.sciencedirect.com/science/article/pii/S1369526624001572},
author = {Tran N. Chau and Xuan Wang and John M. McDowell and Song Li},
abstract = {Single-cell genomics, combined with advanced AI models, hold transformative potential for understanding complex biological processes in plants. This article reviews deep-learning approaches in single-cell genomics, focusing on foundation models, a type of large-scale, pretrained, multi-purpose generative AI models. We explore how these models, such as Generative Pre-trained Transformers (GPT), Bidirectional Encoder Representations from Transformers (BERT), and other Transformer-based architectures, are applied to extract meaningful biological insights from diverse single-cell datasets. These models address challenges in plant single-cell genomics, including improved cell-type annotation, gene network modeling, and multi-omics integration. Moreover, we assess the use of Generative Adversarial Networks (GANs) and diffusion models, focusing on their capacity to generate high-fidelity synthetic single-cell data, mitigate dropout events, and handle data sparsity and imbalance. Together, these AI-driven approaches hold immense potential to enhance research in plant genomics, facilitating discoveries in crop resilience, productivity, and stress adaptation.}
}
@article{JONEK2024139,
title = {Manual assembly planning with AI Image Generators},
journal = {Procedia CIRP},
volume = {130},
pages = {139-144},
year = {2024},
note = {57th CIRP Conference on Manufacturing Systems 2024 (CMS 2024)},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2024.10.068},
url = {https://www.sciencedirect.com/science/article/pii/S2212827124012216},
author = {Michael Jonek and Malte Bast and Martin Manns},
keywords = {Production planning, AI-assisted planning, AI art, Assembly instructions, Manual assembly},
abstract = {For small and medium-sized enterprises (SMEs), the planning of manual assembly activities represents a significant cost and resource factor, requiring precision and meticulous organization. To ensure a stable competitive and economical production, the steps involved in manual assembly must be optimized. In today’s digital era, Artificial Intelligences (AI) offer innovative approaches and opportunities to streamline processes. In addition to LLM AIs, AI image generators are currently attracting a lot of attention as they generate very realistic and detailed images based on a given description. Images or visualisations of the situation are often used to make work instructions in manual assembly easier to understand. AI image generators can be used to visualise assembly process steps for automatically generated work instructions. In this research, a quantitative measure is proposed that can be used to rate how correctly the actual situation is depicted by highlighting incorrect or false objects and operations and assessing the accuracy of the context. The measure is validated by qualitatively evaluating images created with DALL-E 3 in an user study by both workers and planning experts from industry and comparing them with the quantitative measure. This will enable further research in the field of automated work planning and the comparison of different AI image generation tools for use in assembly planning.}
}
@article{PALLOTTINO2025109919,
title = {Applications and perspectives of Generative Artificial Intelligence in agriculture},
journal = {Computers and Electronics in Agriculture},
volume = {230},
pages = {109919},
year = {2025},
issn = {0168-1699},
doi = {https://doi.org/10.1016/j.compag.2025.109919},
url = {https://www.sciencedirect.com/science/article/pii/S0168169925000250},
author = {Federico Pallottino and Simona Violino and Simone Figorilli and Catello Pane and Jacopo Aguzzi and Giacomo Colle and Eugenio {Nerio Nemmi} and Alessandro Montaghi and Damianos Chatzievangelou and Francesca Antonucci and Lavinia Moscovini and Alessandro Mei and Corrado Costa and Luciano Ortenzi},
keywords = {GAI, GAN, NLP, LLMs, ChatGPT, Microsoft Copilot},
abstract = {Artificial Intelligence (AI) applications related to agriculture have recently gained in use and attention. They are indeed valuable tools for interpreting data, improving production chains, and optimizing the use of natural resources. Among AI models, the most recent and promising area is represented by Generative Artificial Intelligence (GAI). After an initial description of its general model architectures, this work aims to review its practical uses and potentials in the following individual sectors: agriculture, precision farming, and animal farming, as well as interdisciplinary applications. The literature search was carried out using the SCOPUS, Google Scholar, and Web of Science databases. GAI holds immense potential for revolutionizing agriculture, offering solutions ranging from precision farming to pest management and supply chain optimization. Though some applications can extend beyond efficiency gains, and hallucinations occurrence i.e. false output information presented as fact, remains an open issue, GAI can be decisive for tasks like improving training datasets, refining models, and facilitating time series analysis. This review extensively describes the vital importance of these tasks for agriculture, precision and animal farming, caused by the rise of new technologies. As a result, by embracing and responsibly implementing GAI applications, it is possible to create a more sustainable and resilient future for agriculture and precision farming. GAI have the capacity to extract specific information from big data systems, offering huge potential to meet a growing global population demand and consequent environmental challenges for the future.}
}
@article{HU2023104527,
title = {Learning entity-oriented representation for biomedical relation extraction},
journal = {Journal of Biomedical Informatics},
volume = {147},
pages = {104527},
year = {2023},
issn = {1532-0464},
doi = {https://doi.org/10.1016/j.jbi.2023.104527},
url = {https://www.sciencedirect.com/science/article/pii/S1532046423002484},
author = {Ying Hu and Yanping Chen and Yongbin Qin and Ruizhang Huang},
keywords = {Biomedical natural language processing, Overlapping semantics, Information extraction},
abstract = {Biomedical Relation Extraction (BioRE) aims to automatically extract semantic relations for given entity pairs and is of great significance in biomedical research. Current popular methods often utilize pretrained language models to extract semantic features from individual input instances, which frequently suffer from overlapping semantics. Overlapping semantics refers to the situation in which a sentence contains multiple entity pairs that share the same context, leading to highly similar information between these entity pairs. In this study, we propose a model for learning Entity-oriented Representation (EoR) that aims to improve the performance of the model by enhancing the discriminability between entity pairs. It contains three modules: sentence representation, entity-oriented representation, and output. The first module learns the global semantic information of the input instance; the second module focuses on extracting the semantic information of the sentence from the target entities; and the third module enhances distinguishability among entity pairs and classifies the relation type. We evaluated our approach on four BioRE tasks with eight datasets, and the experiments showed that our EoR achieved state-of-the-art performance for PPI, DDI, CPI, and DPI tasks. Further analysis demonstrated the benefits of entity-oriented semantic information in handling multiple entity pairs in the BioRE task.}
}
@article{ZHAO2023126708,
title = {ChatAgri: Exploring potentials of ChatGPT on cross-linguistic agricultural text classification},
journal = {Neurocomputing},
volume = {557},
pages = {126708},
year = {2023},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2023.126708},
url = {https://www.sciencedirect.com/science/article/pii/S0925231223008317},
author = {Biao Zhao and Weiqiang Jin and Javier {Del Ser} and Guang Yang},
keywords = {Agricultural text classification, Very large pre-trained language model, Generative Pre-trained Transformer (GPT), ChatGPT, GPT-4},
abstract = {In the era of sustainable smart agriculture, a vast amount of agricultural news text is posted online, accumulating significant agricultural knowledge. To efficiently access this knowledge, effective text classification techniques are urgently needed. Deep learning approaches, such as fine-tuning strategies on pre-trained language models (PLMs), have shown remarkable performance gains. Nonetheless, these methods face several complex challenges, including limited agricultural training data, poor domain transferability (especially across languages), and complex and expensive deployment of large models. Inspired by the success of recent ChatGPT models (e.g., GPT-3.5, GPT-4), this work explores the potential of applying ChatGPT in the field of agricultural informatization. Various crucial factors, such as prompt construction, answer parsing, and different ChatGPT variants, are thoroughly investigated to maximize its capabilities. A preliminary comparative study is conducted, comparing ChatGPT with PLMs-based fine-tuning methods and PLMs-based prompt-tuning methods. Empirical results demonstrate that ChatGPT effectively addresses the mentioned research challenges and bottlenecks, making it an ideal solution for agricultural text classification. Moreover, ChatGPT achieves comparable performance to existing PLM-based fine-tuning methods, even without fine-tuning on agricultural data samples. We hope this preliminary study could inspire the emergence of a general-purpose AI paradigm for agricultural text processing.}
}
@article{MAHBOUBI2024104004,
title = {Evolving techniques in cyber threat hunting: A systematic review},
journal = {Journal of Network and Computer Applications},
volume = {232},
pages = {104004},
year = {2024},
issn = {1084-8045},
doi = {https://doi.org/10.1016/j.jnca.2024.104004},
url = {https://www.sciencedirect.com/science/article/pii/S1084804524001814},
author = {Arash Mahboubi and Khanh Luong and Hamed Aboutorab and Hang Thanh Bui and Geoff Jarrad and Mohammed Bahutair and Seyit Camtepe and Ganna Pogrebna and Ejaz Ahmed and Bazara Barry and Hannah Gately},
keywords = {Threat hunting, Hypothesis, Machine learning, OpenAI voice engine, Cyber threat intelligence, Generative AI},
abstract = {In the rapidly changing cybersecurity landscape, threat hunting has become a critical proactive defense against sophisticated cyber threats. While traditional security measures are essential, their reactive nature often falls short in countering malicious actors’ increasingly advanced tactics. This paper explores the crucial role of threat hunting, a systematic, analyst-driven process aimed at uncovering hidden threats lurking within an organization’s digital infrastructure before they escalate into major incidents. Despite its importance, the cybersecurity community grapples with several challenges, including the lack of standardized methodologies, the need for specialized expertise, and the integration of cutting-edge technologies like artificial intelligence (AI) for predictive threat identification. To tackle these challenges, this survey paper offers a comprehensive overview of current threat hunting practices, emphasizing the integration of AI-driven models for proactive threat prediction. Our research explores critical questions regarding the effectiveness of various threat hunting processes and the incorporation of advanced techniques such as augmented methodologies and machine learning. Our approach involves a systematic review of existing practices, including frameworks from industry leaders like IBM and CrowdStrike. We also explore resources for intelligence ontologies and automation tools. The background section clarifies the distinction between threat hunting and anomaly detection, emphasizing systematic processes crucial for effective threat hunting. We formulate hypotheses based on hidden states and observations, examine the interplay between anomaly detection and threat hunting, and introduce iterative detection methodologies and playbooks for enhanced threat detection. Our review encompasses supervised and unsupervised machine learning approaches, reasoning techniques, graph-based and rule-based methods, as well as other innovative strategies. We identify key challenges in the field, including the scarcity of labeled data, imbalanced datasets, the need for integrating multiple data sources, the rapid evolution of adversarial techniques, and the limited availability of human expertise and data intelligence. The discussion highlights the transformative impact of artificial intelligence on both threat hunting and cybercrime, reinforcing the importance of robust hypothesis development. This paper contributes a detailed analysis of the current state and future directions of threat hunting, offering actionable insights for researchers and practitioners to enhance threat detection and mitigation strategies in the ever-evolving cybersecurity landscape.}
}
@article{LI2022102098,
title = {Ontology-based knowledge representation and semantic topic modeling for intelligent trademark legal precedent research},
journal = {World Patent Information},
volume = {68},
pages = {102098},
year = {2022},
issn = {0172-2190},
doi = {https://doi.org/10.1016/j.wpi.2022.102098},
url = {https://www.sciencedirect.com/science/article/pii/S0172219022000059},
author = {Gi-Kuen J. Li and Charles V. Trappey and Amy J.C. Trappey and Annie A.S. Li},
keywords = {Legal research, Ontology-based knowledge system, Latent Dirichlet allocation (LDA), Semantic topic modeling},
abstract = {An intelligent methodology and its prototype system are developed for automatically discovering legal precedents using semantic analysis. The concept of the trademark legal precedent recommendation was originated from our TE2020 conference paper. The approach is to identify matching cases related to given seed case with respect to their legal case brief attributes using advanced text mining techniques. In the paper, dynamic topic modeling is further developed to analyze the dataset over three time-sequential cohorts to identify trademark law topics varied over time. Further, the prototype system was demonstrated and verified using real trademark case analysis with satisfactory results.}
}
@article{LIANG2024106583,
title = {An unsupervised multi-view contrastive learning framework with attention-based reranking strategy for entity alignment},
journal = {Neural Networks},
volume = {179},
pages = {106583},
year = {2024},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2024.106583},
url = {https://www.sciencedirect.com/science/article/pii/S0893608024005070},
author = {Yan Liang and Weishan Cai and Minghao Yang and Yuncheng Jiang},
keywords = {Entity alignment, Knowledge graphs, Graph attention network, Contrastive learning, Reranking strategy},
abstract = {Entity alignment is a crucial task in knowledge graphs, aiming to match corresponding entities from different knowledge graphs. Due to the scarcity of pre-aligned entities in real-world scenarios, research focused on unsupervised entity alignment has become more popular. However, current unsupervised entity alignment methods suffer from a lack of informative entity guidance, hindering their ability to accurately predict challenging entities with similar names and structures. To solve these problems, we present an unsupervised multi-view contrastive learning framework with an attention-based reranking strategy for entity alignment, named AR-Align. In AR-Align, two kinds of data augmentation methods are employed to provide a complementary view for neighborhood and attribute, respectively. Next, a multi-view contrastive learning method is introduced to reduce the semantic gap between different views of the augmented entities. Moreover, an attention-based reranking strategy is proposed to rerank the hard entities through calculating their weighted sum of embedding similarities on different structures. Experimental results indicate that AR-Align outperforms most both supervised and unsupervised state-of-the-art methods on three benchmark datasets.}
}
@article{SARKER2024935,
title = {Explainable AI for cybersecurity automation, intelligence and trustworthiness in digital twin: Methods, taxonomy, challenges and prospects},
journal = {ICT Express},
volume = {10},
number = {4},
pages = {935-958},
year = {2024},
issn = {2405-9595},
doi = {https://doi.org/10.1016/j.icte.2024.05.007},
url = {https://www.sciencedirect.com/science/article/pii/S2405959524000572},
author = {Iqbal H. Sarker and Helge Janicke and Ahmad Mohsin and Asif Gill and Leandros Maglaras},
keywords = {Cybersecurity, Explainable AI, Machine learning, Data-driven, Automation, Intelligent decision-making, Trustworthiness, Digital twin},
abstract = {Digital twins (DTs) are an emerging digitalization technology with a huge impact on today’s innovations in both industry and research. DTs can significantly enhance our society and quality of life through the virtualization of a real-world physical system, providing greater insights about their operations and assets, as well as enhancing their resilience through real-time monitoring and proactive maintenance. DTs also pose significant security risks, as intellectual property is encoded and more accessible, as well as their continued synchronization to their physical counterparts. The rapid proliferation and dynamism of cyber threats in today’s digital environments motivate the development of automated and intelligent cyber solutions. Today’s industrial transformation relies heavily on artificial intelligence (AI), including machine learning (ML) and data-driven technologies that allow machines to perform tasks such as self-monitoring, investigation, diagnosis, future prediction, and decision-making intelligently. However, to effectively employ AI-based models in the context of cybersecurity, human-understandable explanations, and their trustworthiness, are significant factors when making decisions in real-world scenarios. This article provides an extensive study of explainable AI (XAI) based cybersecurity modeling through a taxonomy of AI and XAI methods that can assist security analysts and professionals in comprehending system functions, identifying potential threats and anomalies, and ultimately addressing them in DT environments in an intelligent manner. We discuss how these methods can play a key role in solving contemporary cybersecurity issues in various real-world applications. We conclude this paper by identifying crucial challenges and avenues for further research, as well as directions on how professionals and researchers might approach and model future-generation cybersecurity in this emerging field.}
}
@article{WEI2025273,
title = {Machine learning-assisted retrosynthesis planning: Current status and future prospects},
journal = {Chinese Journal of Chemical Engineering},
volume = {77},
pages = {273-292},
year = {2025},
issn = {1004-9541},
doi = {https://doi.org/10.1016/j.cjche.2024.10.014},
url = {https://www.sciencedirect.com/science/article/pii/S1004954124003720},
author = {Yixin Wei and Leyu Shan and Tong Qiu and Diannan Lu and Zheng Liu},
keywords = {Retrosynthesis planning, Machine learning, Artificial intelligence, Synthetic pathway, Chemoinformatics},
abstract = {Machine learning-assisted retrosynthesis planning aims to utilize machine learning (ML) algorithms to find synthetic pathways for target compounds. In recent years, with the development of artificial intelligence (AI), especially ML, researchers’ interest in ML-assisted retrosynthesis planning has rapidly increased, bringing development and opportunities to the field. In this review, we aim to provide a comprehensive understanding of ML-assisted retrosynthesis planning. We first discuss the formal definition and the objective of retrosynthesis planning, and organize a modular framework which includes four modules: data preparation, data preprocessing, pathway generation and evaluation, and pathway verification. Then, we sequentially review the current status of the first three modules (except pathway verification) in the ML-assisted retrosynthesis planning framework, including ideas, methods, and latest progress. Following that, we specifically discuss large language models in retrosynthesis planning. Finally, we summarize the extant challenges that are faced by current ML-assisted retrosynthesis planning research and offer a perspective on future research directions and development.}
}
@article{WANG20237,
title = {ChatGPT for design, manufacturing, and education},
journal = {Procedia CIRP},
volume = {119},
pages = {7-14},
year = {2023},
note = {The 33rd CIRP Design Conference},
issn = {2212-8271},
doi = {https://doi.org/10.1016/j.procir.2023.04.001},
url = {https://www.sciencedirect.com/science/article/pii/S2212827123004262},
author = {Xingzhi Wang and Nabil Anwer and Yun Dai and Ang Liu},
keywords = {Artificial Intelligence, Engineering Design, Product Development, Smart Manufacturing, ChatGPT, AI-generated content, Education},
abstract = {The manufacturing industry involves innumerable complex tasks that require significant knowledge and experience to execute. With the rapid development of artificial intelligence, particularly with the emergence of powerful large language models such as ChatGPT, new opportunities have risen to provide knowledge through conversation. With its seemingly endless knowledge base and highly organized response style, ChatGPT is expected to revolutionize every aspect of the industry. However, the extent of ChatGPT's capabilities and how they could contribute to the industry's future revolution remains unclear. In light of this, this paper performed a systematic testing of ChatGPT to uncover its advantages and limitations. Based on the testing results, the authors provided some prospects and critical research questions of ChatGPT from a manufacturing perspective. Furthermore, the authors recommended a technology development roadmap to successfully integrate ChatGPT into the manufacturing industry.}
}
@article{GAO2023104286,
title = {DR.BENCH: Diagnostic Reasoning Benchmark for Clinical Natural Language Processing},
journal = {Journal of Biomedical Informatics},
volume = {138},
pages = {104286},
year = {2023},
issn = {1532-0464},
doi = {https://doi.org/10.1016/j.jbi.2023.104286},
url = {https://www.sciencedirect.com/science/article/pii/S1532046423000072},
author = {Yanjun Gao and Dmitriy Dligach and Timothy Miller and John Caskey and Brihat Sharma and Matthew M. Churpek and Majid Afshar},
keywords = {Natural language processing, Clinical diagnostic reasoning, Clinical diagnostic decision support, Clinical natural language processing benchmark},
abstract = {The meaningful use of electronic health records (EHR) continues to progress in the digital era with clinical decision support systems augmented by artificial intelligence. A priority in improving provider experience is to overcome information overload and reduce the cognitive burden so fewer medical errors and cognitive biases are introduced during patient care. One major type of medical error is diagnostic error due to systematic or predictable errors in judgement that rely on heuristics. The potential for clinical natural language processing (cNLP) to model diagnostic reasoning in humans with forward reasoning from data to diagnosis and potentially reduce cognitive burden and medical error has not been investigated. Existing tasks to advance the science in cNLP have largely focused on information extraction and named entity recognition through classification tasks. We introduce a novel suite of tasks coined as Diagnostic Reasoning Benchmarks, Dr.Bench, as a new benchmark for developing and evaluating cNLP models with clinical diagnostic reasoning ability. The suite includes six tasks from ten publicly available datasets addressing clinical text understanding, medical knowledge reasoning, and diagnosis generation. DR.BENCH is the first clinical suite of tasks designed to be a natural language generation framework to evaluate pre-trained language models for diagnostic reasoning. The goal of DR. BENCH is to advance the science in cNLP to support downstream applications in computerized diagnostic decision support and improve the efficiency and accuracy of healthcare providers during patient care. We fine-tune and evaluate the state-of-the-art generative models on DR.BENCH. Experiments show that with domain adaptation pre-training on medical knowledge, the model demonstrated opportunities for improvement when evaluated in DR. BENCH. We share DR. BENCH as a publicly available GitLab repository with a systematic approach to load and evaluate models for the cNLP community. We also discuss the carbon footprint produced during the experiments and encourage future work on DR.BENCH to report the carbon footprint.}
}
@article{FICKO2025100257,
title = {Reflective thinking meets artificial intelligence: Synthesizing sustainability transition knowledge in left-behind mountain regions},
journal = {Geography and Sustainability},
volume = {6},
number = {1},
pages = {100257},
year = {2025},
issn = {2666-6839},
doi = {https://doi.org/10.1016/j.geosus.2024.100257},
url = {https://www.sciencedirect.com/science/article/pii/S2666683924001202},
author = {Andrej Ficko and Simo Sarkki and Yasar Selman Gultekin and Antonia Egli and Juha Hiedanpää},
keywords = {Artificial intelligence, Innovation, Reflective thinking, Scientific imagination, Text mining, Text summarization},
abstract = {We demonstrate a multi-method approach towards discovering and structuring sustainability transition knowledge in marginalized mountain regions. By employing reflective thinking, artificial intelligence (AI)-powered text summarization and text mining, we synthesize experts’ narratives on sustainable development challenges and solutions in Kardüz Upland, Türkiye. We then analyze their alignment with the UN Sustainable Development Goals (SDGs) using document embedding. Investment in infrastructure, education, and resilient socio-ecological systems emerged as priority sectors to combat poor infrastructure, geographic isolation, climate change, poverty, depopulation, unemployment, low education levels, and inadequate social services. The narratives were closest in substance to SDG 1, 3, and 11. Social dimensions of sustainability were more pronounced than environmental dimensions. The presented approach supports policymakers in organizing loosely structured sustainability transition knowledge and fragmented data corpora, while also advancing AI applications for designing and planning sustainable development policies at the regional level.}
}
@article{GAN2024102337,
title = {Entity type inference based on path walking and inter-types relationships},
journal = {Data & Knowledge Engineering},
volume = {153},
pages = {102337},
year = {2024},
issn = {0169-023X},
doi = {https://doi.org/10.1016/j.datak.2024.102337},
url = {https://www.sciencedirect.com/science/article/pii/S0169023X24000612},
author = {Yi Gan and Zhihui Su and Gaoyong Lu and Pengju Zhang and Aixiang Cui and Jiawei Jiang and Duanbing Chen},
keywords = {ET-PT, Entity type inference, Path walking, Inter-types relationships},
abstract = {As a crucial task for knowledge graphs (KGs), knowledge graph entity type inference (KGET) has garnered increasing attention in recent years. However, recent methods overlook the long-distance information pertaining to entities and the inter-types relationships. The neglect of long-distance information results in the omission of crucial entity relationships and neighbors, consequently leading to the loss of path information associated with missing types. To address this, a path-walking strategy is utilized to identify two-hop triplet paths of the crucial entity for encoding long-distance entity information. Moreover, the absence of inter-types relationships can lead to the loss of the neighborhood information of types, such as co-occurrence information. To ensure a comprehensive understanding of inter-types relationships, we consider interactions not only with the types of single entity but also with different types of entities. Finally, in order to comprehensively represent entities for missing types, considering both the dimensions of path information and neighborhood information, we propose an entity type inference model based on path walking and inter-types relationships, denoted as “ET-PT”. This model effectively extracts comprehensive entity information, thereby obtaining the most complete semantic representation of entities. The experimental results on publicly available datasets demonstrate that the proposed method outperforms state-of-the-art approaches.}
}
@article{ZHANG2024104220,
title = {An event logic graph for geographic environment observation planning in disaster chain monitoring},
journal = {International Journal of Applied Earth Observation and Geoinformation},
volume = {134},
pages = {104220},
year = {2024},
issn = {1569-8432},
doi = {https://doi.org/10.1016/j.jag.2024.104220},
url = {https://www.sciencedirect.com/science/article/pii/S1569843224005764},
author = {Yunbo Zhang and Wenjie Chen and Bingshu Huang and Zongran Zhang and Jie Li and Ruishan Gao and Ke Wang and Chuli Hu},
keywords = {Event logic graph, Disaster chain, Geographic environment, Observation planning, Knowledge ontology, Event reasoning},
abstract = {Effective geographic environment observation planning is the key to obtain disaster monitoring and warning information. The previous researches can only make observation plans for a single disaster at some specific stages. They are difficult to apply to the dynamic evolution of the disaster chain. Timely and comprehensive geographic environment observation planning is urgently needed to provide high-value monitoring data for the identification and response of secondary disaster chains. Event logic graph (ELG) shows great potential in evolutionary law expression and chain event reasoning. Therefore, this study proposed an observation ELG (OELG), in which events and their logical relationships are modeled as nodes and edges to express the occurrence and development motivation of observation events. The disaster chain observation planning can be transformed into the reasoning of potential continuous observation events. Subsequently, an OELG-based geographic environment observation planning framework was proposed, which realizes the construction, instantiation, and plan reasoning of OELG. The observation planning experiment was carried out taking the flood disaster chain that occurred in Beijing, China and Nordrhein-Westfalen, Germany as examples. The results show that OELG can generate disaster chain observation plan more timely, comprehensively, and continuously than other models, thus providing support for disaster chain risk monitoring and emergency response.}
}
@article{ZHAO2024107055,
title = {A joint communication and computation design for semantic wireless communication with probability graph},
journal = {Journal of the Franklin Institute},
volume = {361},
number = {13},
pages = {107055},
year = {2024},
issn = {0016-0032},
doi = {https://doi.org/10.1016/j.jfranklin.2024.107055},
url = {https://www.sciencedirect.com/science/article/pii/S0016003224004769},
author = {Zhouxiang Zhao and Zhaohui Yang and Xu Gan and Quoc-Viet Pham and Chongwen Huang and Wei Xu and Zhaoyang Zhang},
keywords = {Semantic communication, Knowledge graph, Probability graph, Joint communication and computation},
abstract = {In this paper, the problem of joint communication and computation design for probability graph-based semantic communication over wireless networks is investigated. In the considered model, the base station (BS) extracts the compressed small-sized semantic data by removing redundant information based on the shared knowledge base between the transceivers. In particular, the knowledge base is represented as a probability graph, which summarizes the statistic relations of massive knowledge graphs. On the user side, the compressed information is accurately inferred on the basis of the same probability graph as the BS. Although this approach brings additional computation resource consumption for semantic information extraction, it effectively reduces communication resource consumption through the transmission of small-sized data. Both the communication and computation cost models are derived based on the inference process of the probability graph. Based on the formulated models, the problem of joint communication and computation resource allocation is proposed to minimize the total energy consumption of the network considering both latency and power limitations. To solve this problem, the closed-form solution of the transmission power is obtained with fixed semantic compression ratio. Then, an effective linear search-based algorithm is proposed to obtain the optimal solution of the considered problem with low complexity. Simulation results demonstrate the effectiveness of the proposed system compared with the conventional non-semantic schemes.}
}
@article{MARTINS2024105385,
title = {Unlocking human-like conversations: Scoping review of automation techniques for personalized healthcare interventions using conversational agents},
journal = {International Journal of Medical Informatics},
volume = {185},
pages = {105385},
year = {2024},
issn = {1386-5056},
doi = {https://doi.org/10.1016/j.ijmedinf.2024.105385},
url = {https://www.sciencedirect.com/science/article/pii/S1386505624000480},
author = {Ana Martins and Ana Londral and Isabel {L. Nunes} and Luís {V. Lapão}},
keywords = {Conversational Agents, Automation, Personalization, Natural Language Processing, Artificial Intelligence, Healthcare},
abstract = {Background
Conversational agents (CAs) offer a sustainable approach to deliver personalized interventions and improve health outcomes.
Objectives
To review how human-like communication and automation techniques of CAs in personalized healthcare interventions have been implemented. It is intended for designers and developers, computational scientists, behavior scientists, and biomedical engineers who aim at developing CAs for healthcare interventions.
Methodology
A scoping review was conducted in accordance with PRISMA Extension for Scoping Review. A search was performed in May 2023 in Web of Science, Pubmed, Scopus and IEEE databases. Search results were extracted, duplicates removed, and the remaining results were screened. Studies that contained personalized and automated CAs within the healthcare domain were included. Information regarding study characterization, and human-like communication and automation techniques was extracted from articles that met the eligibility criteria.
Results
Twenty-three studies were selected. These articles described the development of CAs designed for patients to either self-manage their diseases (such as diabetes, mental health issues, cancer, asthma, COVID-19, and other chronic conditions) or to enhance healthy habits. The human-like communication characteristics studied encompassed aspects like system flexibility, personalization, and affective characteristics. Seven studies used rule-based models, eleven applied retrieval-based techniques for content delivery, five used AI models, and six integrated affective computing.
Conclusions
The increasing interest in employing CAs for personalized healthcare interventions is noteworthy. The adaptability of dialogue structures and personalization features is still limited. Unlocking human-like conversations may encompass the use of affective computing and generative AI to help improve user engagement. Future research should focus on the integration of holistic methods to describe the end-user, and the safe use of generative models.}
}
@article{KADDOURA2024101911,
title = {EnhancedBERT: A feature-rich ensemble model for Arabic word sense disambiguation with statistical analysis and optimized data collection},
journal = {Journal of King Saud University - Computer and Information Sciences},
volume = {36},
number = {1},
pages = {101911},
year = {2024},
issn = {1319-1578},
doi = {https://doi.org/10.1016/j.jksuci.2023.101911},
url = {https://www.sciencedirect.com/science/article/pii/S1319157823004652},
author = {Sanaa Kaddoura and Reem Nassar},
keywords = {Arabic natural language processing, Word sense disambiguation, Machine learning, Knowledge-based, BERT, Performance evaluation},
abstract = {Accurate assignment of meaning to a word based on its context, known as Word Sense Disambiguation (WSD), remains challenging across languages. Extensive research aims to develop automated methods for determining word senses in different contexts. However, the literature lacks the presence of datasets generated for the Arabic language WSD. This paper presents a dataset comprising a hundred polysemous Arabic words. Each word in the dataset encompasses 3–8 distinct senses, with ten example sentences per sense. Some statistical operations are conducted to gain insights into the dataset, enlightening its characteristics and properties. Subsequently, a novel WSD approach is proposed to utilize similarity measures and find the overlap between contextual information and dictionary definitions. The proposed method uses the power of BERT, a pre-trained language model, to enable effective Arabic word disambiguation. In training, new features are integrated to improve the model's ability to differentiate between various senses of words. The proposed BERT models are combined to compose an ensemble model architecture to improve the classification performances. The performance of the WSD system outperforms state-of-the-art systems, achieving an approximate F1-score of 96 %. Statistical analyses are performed to evaluate the overall performance of the WSD approach by providing additional information on model predictions. A case study was implemented to test the effectiveness of WSD in sentiment analysis, a downstream task.}
}
@article{BAAJ2024109206,
title = {Synergies between machine learning and reasoning - An introduction by the Kay R. Amel group},
journal = {International Journal of Approximate Reasoning},
volume = {171},
pages = {109206},
year = {2024},
note = {Synergies between Machine Learning and Reasoning},
issn = {0888-613X},
doi = {https://doi.org/10.1016/j.ijar.2024.109206},
url = {https://www.sciencedirect.com/science/article/pii/S0888613X24000938},
author = {Ismaïl Baaj and Zied Bouraoui and Antoine Cornuéjols and Thierry Denœux and Sébastien Destercke and Didier Dubois and Marie-Jeanne Lesot and João Marques-Silva and Jérôme Mengin and Henri Prade and Steven Schockaert and Mathieu Serrurier and Olivier Strauss and Christel Vrain},
keywords = {Accountability, Background knowledge, Explainability, Neurosymbolic AI, Rule-based models, Uncertainty},
abstract = {This paper proposes a tentative and original survey of meeting points between Knowledge Representation and Reasoning (KRR) and Machine Learning (ML), two areas which have been developed quite separately in the last four decades. First, some common concerns are identified and discussed such as the types of representation used, the roles of knowledge and data, the lack or the excess of information, or the need for explanations and causal understanding. Then, the survey is organised in seven sections covering most of the territory where KRR and ML meet. We start with a section dealing with prototypical approaches from the literature on learning and reasoning: Inductive Logic Programming, Statistical Relational Learning, and Neurosymbolic AI, where ideas from rule-based reasoning are combined with ML. Then we focus on the use of various forms of background knowledge in learning, ranging from additional regularisation terms in loss functions, to the problem of aligning symbolic and vector space representations, or the use of knowledge graphs for learning. Then, the next section describes how KRR notions may benefit to learning tasks. For instance, constraints can be used as in declarative data mining for influencing the learned patterns; or semantic features are exploited in low-shot learning to compensate for the lack of data; or yet we can take advantage of analogies for learning purposes. Conversely, another section investigates how ML methods may serve KRR goals. For instance, one may learn special kinds of rules such as default rules, fuzzy rules or threshold rules, or special types of information such as constraints, or preferences. The section also covers formal concept analysis and rough sets-based methods. Yet another section reviews various interactions between Automated Reasoning and ML, such as the use of ML methods in SAT solving to make reasoning faster. Then a section deals with works related to model accountability, including explainability and interpretability, fairness and robustness. Finally, a section covers works on handling imperfect or incomplete data, including the problem of learning from uncertain or coarse data, the use of belief functions for regression, a revision-based view of the EM algorithm, the use of possibility theory in statistics, or the learning of imprecise models. This paper thus aims at a better mutual understanding of research in KRR and ML, and how they can cooperate. The paper is completed by an abundant bibliography.}
}
@article{WANG2024127674,
title = {A multi-view graph learning model with dual strategies for solving math word problems},
journal = {Neurocomputing},
volume = {587},
pages = {127674},
year = {2024},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2024.127674},
url = {https://www.sciencedirect.com/science/article/pii/S0925231224004454},
author = {Zhiwei Wang and Qi Lang and Xiaodong Liu and Wenlin Jing},
keywords = {Math word problem, Natural language processing, Text mining, Multi-view graph learning},
abstract = {Recently, graph-based deep learning models have exhibited remarkable performance in generating solution expressions for the math word problem (MWP). However, most of these models have not taken into account the limitations and errors in constructing prior knowledge graphs, which may affect their accuracy and reliability in practical applications. In addition, during graph learning, they focus on extracting information from each given graph, while neglecting the adaptability and unification of graph representation learning. In this paper, we propose a novel multi-view graph learning-to-tree model with dual-strategy (MVG-DS-T), in which it performs adaptive and consistent multi-view representation learning through two benchmark graphs. Specifically, we construct benchmark graphs via semantic dependency parsing of MWP text, considering both semantic and quantitative aspects, i.e., semantic graph and quantitative graph. Then, the reconstruction strategy is employed to reconstruct the structure of the benchmark graphs to capture the adaptive representation information suitable for downstream tasks, while the alignment strategy is utilized to overcome the limitation of independent view representations by unifying the semantic and quantity embedding information through graph structure. Also, an adaptive length normalized loss balancing term for the tree-based decoder is introduced to control the model focus on label length during training, resulting in better equation generation. Extensive experiments demonstrate the effectiveness of the proposed approach on the MWP task. The empirical results show that MVG-DS-T achieves performance comparable to that of the state-of-the-art graph-based models in the existing literature.}
}
@article{TZIRIDES2024100184,
title = {Combining human and artificial intelligence for enhanced AI literacy in higher education},
journal = {Computers and Education Open},
volume = {6},
pages = {100184},
year = {2024},
issn = {2666-5573},
doi = {https://doi.org/10.1016/j.caeo.2024.100184},
url = {https://www.sciencedirect.com/science/article/pii/S2666557324000247},
author = {Anastasia Olga (Olnancy) Tzirides and Gabriela Zapata and Nikoleta Polyxeni Kastania and Akash K. Saini and Vania Castro and Sakinah A. Ismael and Yu-ling You and Tamara Afonso dos Santos and Duane Searsmith and Casey O'Brien and Bill Cope and Mary Kalantzis},
keywords = {Adult learning, Cooperative learning, Collaborative learning, Human-computer interface, Post-Secondary Education, Teaching/Learning Strategies},
abstract = {This paper seeks to contribute to the emergent literature on Artificial Intelligence (AI) literacy in higher education. Specifically, this convergent, mixed methods case study explores the impact of employing Generative AI (GenAI) tools and cyber-social teaching methods on the development of higher education students’ AI literacy. Three 8-week courses on advanced digital technologies for education in a graduate program in the College of Education at a mid-western US university served as the study sites. Data were based on 37 participants’ experiences with two different types of GenAI tools–a GenAI reviewer and GenAI image generator platforms. The application of the GenAI review tool relied on precision fine-tuning and transparency in AI-human interactions, while the AI image generation tools facilitated the participants’ reflection on their learning experiences and AI's role in education. Students’ interaction with both tools was designed to foster their learning regarding GenAI's strengths and limitations, and their responsible application in educational contexts. The findings revealed that the participants appeared to feel more comfortable using GenAI tools after their course experiences. The results also point to the students’ enhanced ability to understand and critically assess the value of AI applications in education. This study contributes to existing work on AI in higher education by introducing a novel pedagogical approach for AI literacy development showcasing the synergy between humans and artificial intelligence.}
}
@article{ZHENG2023105067,
title = {Dynamic prompt-based virtual assistant framework for BIM information search},
journal = {Automation in Construction},
volume = {155},
pages = {105067},
year = {2023},
issn = {0926-5805},
doi = {https://doi.org/10.1016/j.autcon.2023.105067},
url = {https://www.sciencedirect.com/science/article/pii/S0926580523003278},
author = {Junwen Zheng and Martin Fischer},
keywords = {Building information modeling, Generative pre-trained transformer, Virtual assistant, Information search, Natural language processing, Artificial intelligence, BIMS-GPT, Prompt engineering, Large language model, Information retrieval},
abstract = {Efficient information search from building information models (BIMs) requires deep BIM knowledge or extensive engineering efforts for building natural language (NL)-based interfaces. To address this challenge, this paper introduces a dynamic prompt-based virtual assistant framework dubbed “BIMS-GPT” that integrates generative pre-trained transformer (GPT) technologies, supporting NL-based BIM search. To understand users' NL queries, extract relevant information from BIM databases, and deliver NL responses along with 3D visualizations, a dynamic prompt-based process was developed. In a case study, BIMS-GPT's functionality is demonstrated through a virtual assistant prototype for a hospital building. When evaluated with a BIM query dataset, the approach achieves accuracy rates of 99.5% for classifying NL queries with incorporating 2% of the data in prompts. This paper contributes to the advancement of effective and versatile virtual assistants for BIMs in the construction industry as it significantly enhances BIM accessibility while reducing the engineering and training data prerequisites for processing NL queries.}
}
@article{YAGER20241933,
title = {Towards a science exocortex},
journal = {Digital Discovery},
volume = {3},
number = {10},
pages = {1933-1957},
year = {2024},
issn = {2635-098X},
doi = {https://doi.org/10.1039/d4dd00178h},
url = {https://www.sciencedirect.com/science/article/pii/S2635098X2400158X},
author = {Kevin G. Yager},
abstract = {Artificial intelligence (AI) methods are poised to revolutionize intellectual work, with generative AI enabling automation of text analysis, text generation, and simple decision making or reasoning. The impact to science is only just beginning, but the opportunity is significant since scientific research relies fundamentally on extended chains of cognitive work. Here, we review the state of the art in agentic AI systems, and discuss how these methods could be extended to have even greater impact on science. We propose the development of an exocortex, a synthetic extension of a person's cognition. A science exocortex could be designed as a swarm of AI agents, with each agent individually streamlining specific researcher tasks, and whose inter-communication leads to emergent behavior that greatly extend the researcher's cognition and volition.}
}
@article{FIEDLER202454,
title = {Generative Pre-trained Transformer for Pediatric Stroke Research: A Pilot Study},
journal = {Pediatric Neurology},
volume = {160},
pages = {54-59},
year = {2024},
issn = {0887-8994},
doi = {https://doi.org/10.1016/j.pediatrneurol.2024.07.001},
url = {https://www.sciencedirect.com/science/article/pii/S0887899424002522},
author = {Anna K. Fiedler and Kai Zhang and Tia S. Lal and Xiaoqian Jiang and Stuart M. Fraser},
keywords = {Pediatric stroke, IPSS, GPT, PS-GPT, LLM},
abstract = {Background
Pediatric stroke is an important cause of morbidity in children. Although research can be challenging, large amounts of data have been captured through collaborative efforts in the International Pediatric Stroke Study (IPSS). This study explores the use of an advanced artificial intelligence program, the Generative Pre-trained Transformer (GPT), to enter pediatric stroke data into the IPSS.
Methods
The most recent 50 clinical notes of patients with ischemic stroke or cerebral venous sinus thrombosis at the UTHealth Pediatric Stroke Clinic were deidentified. Domain-specific prompts were engineered for an offline artificial intelligence program (GPT) to answer IPSS questions. Responses from GPT were compared with the human rater. Percent agreement was assessed across 50 patients for each of the 114 queries developed from the IPSS database outcome questionnaire.
Results
GPT demonstrated strong performance on several questions but showed variability overall. In its early iterations it was able to match human judgment occasionally with an accuracy score of 1.00 (n = 20, 17.5%), but it scored as low as 0.26 in some patients. Prompts were adjusted in four subsequent iterations to increase accuracy. In its fourth iteration, agreement was 93.6%, with a maximum agreement of 100% and minimum of 62%. Of 2400 individual items assessed, our model entered 2247 (93.6%) correctly and 153 (6.4%) incorrectly.
Conclusions
Although our tailored generative model with domain-specific prompt engineering and ontological guidance shows promise for research applications, further refinement is needed to enhance its accuracy. It cannot enter data entirely independently, but it can be employed in tandem with human oversight contributing to a collaborative approach that reduces overall effort.}
}
@incollection{LI2024149,
title = {Chapter 7 - Deployment roadmap of proactive human–robot collaboration},
editor = {Shufei Li and Pai Zheng and Lihui Wang},
booktitle = {Proactive Human-Robot Collaboration Toward Human-Centric Smart Manufacturing},
publisher = {Elsevier},
pages = {149-192},
year = {2024},
isbn = {978-0-443-13943-7},
doi = {https://doi.org/10.1016/B978-0-44-313943-7.00014-4},
url = {https://www.sciencedirect.com/science/article/pii/B9780443139437000144},
author = {Shufei Li and Pai Zheng and Lihui Wang},
keywords = {Deployment roadmap of proactive human–robot collaboration, Scene perception, Knowledge representation, Decision making, Collaborative control},
abstract = {This chapter presents a stepwise procedure for the development of Proactive HRC systems comprising four key modules: scene perception, knowledge representation, decision making, and collaborative control. For each module, we provide a comprehensive research roadmap of related technologies and offer an advanced algorithm as a feasible solution. The perception module is dedicated to perceiving the human–robot–workspace environment, as detailed in Section 7.1. Meanwhile, knowledge representation focuses on acquiring semantic knowledge of manufacturing tasks and transferring human expertise to robots for cognitive inference, as illustrated in Section 7.2. In Section 7.3, we delve into the decision-making module, which empowers the HRC system to make intelligent decisions for optimized trajectory planning and human information support, adapting to changing environmental conditions. Additionally, Section 7.4 provides an overview of various algorithms for robot collaborative control at the operational level. These four aspects have witnessed the widespread adoption of cutting-edge cognitive computing techniques such as deep learning, reinforcement learning, transfer learning, large language model, etc., resulting in significant enhancements to Proactive HRC system performance.}
}
@article{TRAGER2024466,
title = {Artificial intelligence for nonmelanoma skin cancer},
journal = {Clinics in Dermatology},
volume = {42},
number = {5},
pages = {466-476},
year = {2024},
note = {Artificial Intelligence II},
issn = {0738-081X},
doi = {https://doi.org/10.1016/j.clindermatol.2024.06.016},
url = {https://www.sciencedirect.com/science/article/pii/S0738081X24001007},
author = {Megan H. Trager and Emily R. Gordon and Alyssa Breneman and Chunhua Weng and Faramarz H. Samie},
abstract = {Nonmelanoma skin cancers (NMSCs) are among the top five most common cancers globally. NMSC is an area with great potential for novel application of diagnostic tools including artificial intelligence (AI). In this scoping review, we aimed to describe the applications of AI in the diagnosis and treatment of NMSC. Twenty-nine publications described AI applications to dermatopathology including lesion classification and margin assessment. Twenty-five publications discussed AI use in clinical image analysis, showing that algorithms are not superior to dermatologists and may rely on unbalanced, nonrepresentative, and nontransparent training data sets. Sixteen publications described the use of AI in cutaneous surgery for NMSC including use in margin assessment during excisions and Mohs surgery, as well as predicting procedural complexity. Eleven publications discussed spectroscopy, confocal microscopy, thermography, and the AI algorithms that analyze and interpret their data. Ten publications pertained to AI applications for the discovery and use of NMSC biomarkers. Eight publications discussed the use of smartphones and AI, specifically how they enable clinicians and patients to have increased access to instant dermatologic assessments but with varying accuracies. Five publications discussed large language models and NMSC, including how they may facilitate or hinder patient education and medical decision-making. Three publications pertaining to the skin of color and AI for NMSC discussed concerns regarding limited diverse data sets for the training of convolutional neural networks. AI demonstrates tremendous potential to improve diagnosis, patient and clinician education, and management of NMSC. Despite excitement regarding AI, data sets are often not transparently reported, may include low-quality images, and may not include diverse skin types, limiting generalizability. AI may serve as a tool to increase access to dermatology services for patients in rural areas and save health care dollars. These benefits can only be achieved, however, with consideration of potential ethical costs.}
}
@article{MODI2024104603,
title = {Extracting adverse drug events from clinical Notes: A systematic review of approaches used},
journal = {Journal of Biomedical Informatics},
volume = {151},
pages = {104603},
year = {2024},
issn = {1532-0464},
doi = {https://doi.org/10.1016/j.jbi.2024.104603},
url = {https://www.sciencedirect.com/science/article/pii/S1532046424000212},
author = {Salisu Modi and Khairul Azhar Kasmiran and Nurfadhlina {Mohd Sharef} and Mohd Yunus Sharum},
keywords = {Adverse drug events, Pipeline approach, Joint task learning, Multi-task learning, Named entity recognition, Relation extraction},
abstract = {Background
An adverse drug event (ADE) is any unfavorable effect that occurs due to the use of a drug. Extracting ADEs from unstructured clinical notes is essential to biomedical text extraction research because it helps with pharmacovigilance and patient medication studies.
Objective
From the considerable amount of clinical narrative text, natural language processing (NLP) researchers have developed methods for extracting ADEs and their related attributes. This work presents a systematic review of current methods.
Methodology
Two biomedical databases have been searched from June 2022 until December 2023 for relevant publications regarding this review, namely the databases PubMed and Medline. Similarly, we searched the multi-disciplinary databases IEEE Xplore, Scopus, ScienceDirect, and the ACL Anthology. We adopted the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) 2020 statement guidelines and recommendations for reporting systematic reviews in conducting this review. Initially, we obtained 5,537 articles from the search results from the various databases between 2015 and 2023. Based on predefined inclusion and exclusion criteria for article selection, 100 publications have undergone full-text review, of which we consider 82 for our analysis.
Results
We determined the general pattern for extracting ADEs from clinical notes, with named entity recognition (NER) and relation extraction (RE) being the dual tasks considered. Researchers that tackled both NER and RE simultaneously have approached ADE extraction as a “pipeline extraction” problem (n = 22), as a “joint task extraction” problem (n = 7), and as a “multi-task learning” problem (n = 6), while others have tackled only NER (n = 27) or RE (n = 20). We further grouped the reviews based on the approaches for data extraction, namely rule-based (n = 8), machine learning (n = 11), deep learning (n = 32), comparison of two or more approaches (n = 11), hybrid (n = 12) and large language models (n = 8). The most used datasets are MADE 1.0, TAC 2017 and n2c2 2018.
Conclusion
Extracting ADEs is crucial, especially for pharmacovigilance studies and patient medications. This survey showcases advances in ADE extraction research, approaches, datasets, and state-of-the-art performance in them. Challenges and future research directions are highlighted. We hope this review will guide researchers in gaining background knowledge and developing more innovative ways to address the challenges.}
}
@article{WEI2024106559,
title = {A cross-temporal contrastive disentangled model for ancient Chinese understanding},
journal = {Neural Networks},
volume = {179},
pages = {106559},
year = {2024},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2024.106559},
url = {https://www.sciencedirect.com/science/article/pii/S0893608024004830},
author = {Yuting Wei and Yangfu Zhu and Ting Bai and Bin Wu},
keywords = {Ancient Chinese understanding, Cross-temporal, Low-resource language, Disentangled representation, Contrastive learning},
abstract = {Ancient Chinese is a crucial bridge for understanding Chinese history and culture. Most existing works utilize high-resource modern Chinese to understand low-resource ancient Chinese, but they fail to fully consider the semantic and syntactic gaps between them due to their changes over time, resulting in the misunderstanding of ancient Chinese. Hence, we propose a novel language pre-training framework for ancient Chinese understanding based on the Cross-temporal Contrastive Disentanglement Model (CCDM), which bridges the gap between modern and ancient Chinese with their parallel corpus. Specifically, we first explore a cross-temporal data augmentation method by disentangling and reconstructing the parallel ancient-modern corpus. It is noteworthy that the proposed decoupling strategy takes full account of the cross-temporal character between ancient and modern Chinese. Then, cross-temporal contrastive learning is exploited to train the model by fully leveraging the cross-temporal information. Finally, the trained language model is utilized for downstream tasks. We conduct extensive experiments on six ancient Chinese understanding tasks. Results demonstrate that our model outperforms the state-of-the-art baselines. Our framework also holds potential applicability to other languages that have undergone evolutionary changes, leading to shifts in syntax and semantics.11Our model is available at https://github.com/yuting-wei/CCDM.}
}
@article{SUN2025111461,
title = {Knowledge Enhanced Prompt Learning Framework for Financial News Recommendation},
journal = {Pattern Recognition},
pages = {111461},
year = {2025},
issn = {0031-3203},
doi = {https://doi.org/10.1016/j.patcog.2025.111461},
url = {https://www.sciencedirect.com/science/article/pii/S0031320325001219},
author = {ShaoBo Sun and Xiaoming Pan and Shuang Qi and Jun Gao},
keywords = {News recommendation, Prompt learning, Knowledge graph, Topic, Sentiment},
abstract = {The aim of financial news recommendation systems is to deliver personalized and timely financial information. Traditional methods face challenges, including the complexity of financial news, which requires stock-related external knowledge and accounts for users' interests in various stocks, industries, and concepts. Additionally, the financial domain's timeliness necessitates adaptable recommender systems, especially in few-shot and cold-start scenarios. To address these challenges, we propose a knowledge-enhanced prompt learning framework for financial news recommendation (FNRKPL). FNRKPL incorporates a financial news knowledge graph and transforms triple information into prompt language to strengthen the recommendation model's knowledge base. Personalized prompt templates are designed to account for users' topic preferences and sentiment tendencies, integrating knowledge, topic, and sentiment prompts. Furthermore, a knowledge-enhanced prompt learning mechanism enhances the model's generalization and adaptability in few-shot and cold-start scenarios. Extensive experiments on real-world corporate datasets validate FNRKPL's effectiveness in both data-rich and resource-poor conditions.}
}
@article{KALUTHARAGE2025104318,
title = {Neurosymbolic learning and domain knowledge-driven explainable AI for enhanced IoT network attack detection and response},
journal = {Computers & Security},
volume = {151},
pages = {104318},
year = {2025},
issn = {0167-4048},
doi = {https://doi.org/10.1016/j.cose.2025.104318},
url = {https://www.sciencedirect.com/science/article/pii/S0167404825000070},
author = {Chathuranga Sampath Kalutharage and Xiaodong Liu and Christos Chrysoulas},
keywords = {Neurosymbolic learning, Attack detection, Explainable artificial intelligence, Expert knowledge, Threat intelligence},
abstract = {In the dynamic landscape of network security, where cyberattacks continuously evolve, robust and adaptive detection mechanisms are essential, particularly for safeguarding Internet of Things (IoT) networks. This paper introduces an advanced anomaly detection model that utilizes Artificial Intelligence (AI) to identify network anomalies based on traffic features, explaining the most influential factors behind each detected anomaly. The model integrates domain knowledge stored in a knowledge graph to verify whether the detected anomaly constitutes a legitimate attack. Upon validation, the model identifies which core cybersecurity principles—Confidentiality, Integrity, or Availability (CIA)—are violated by mapping influential feature values. This is followed by an alignment with the MITRE ATT&CK framework to provide insights into potential attack tactics, techniques, and intelligence-driven countermeasures. By leveraging explainable AI (XAI) and incorporating expert domain knowledge, our approach bridges the gap between complex AI predictions and human-understandable decision-making, thereby enhancing both detection accuracy and result interpretability. This transparency facilitates faster responses and real-time decision-making while improving adaptability to new, unseen cyber threats. Our evaluation on network traffic datasets demonstrates that the model not only excels in detecting and explaining anomalies but also achieves an overall detection accuracy of 0.97 with the integration of domain knowledge for attack legitimacy. Furthermore, it provides 100% accuracy for threat intelligence based on the MITRE ATT&CK framework, ensuring that security measures are verifiable, actionable, and ultimately strengthen IoT environment defenses by delivering real-time threat intelligence and responses, thus minimizing human response time.}
}
@article{KANG2024249,
title = {The Intelligent Infectious Disease Active Surveillance and early warning system in China: An application of dengue prevention and control},
journal = {Global Transitions},
volume = {6},
pages = {249-255},
year = {2024},
issn = {2589-7918},
doi = {https://doi.org/10.1016/j.glt.2024.10.004},
url = {https://www.sciencedirect.com/science/article/pii/S2589791824000185},
author = {Liangyu Kang and Jian Hu and Kangning Cai and Wenzhan Jing and Min Liu and Wannian Liang},
keywords = {Artificial intelligence, Surveillance, Early warning, Infectious diseases, China},
abstract = {Utilizing advanced information technologies such as big data and artificial intelligence (AI), China has established and implemented the Intelligent Infectious Disease Active Surveillance and Early Warning System. It provides new tools for the surveillance, early warning, and response to infectious diseases, enhancing the timeliness, scientific basis, and efficiency of epidemic control efforts. The system comprises four functional modules including multi-channel active surveillance, intelligent early warning, data-driven risk assessment, and smart emergency response. This paper provides a detailed overview of the structure and functions of the Intelligent Infectious Disease Active Surveillance and Early Warning System in China, with a specific focus on its application in dengue prevention and control in Hainan Province from February to May 2024. Firstly, the system can proactively capture and integrate heterogeneous surveillance data from multiple sources. Based on these multi-channel data, users can select appropriate warning indicators and AI models to automatically trigger early warnings. Using vast amounts of surveillance data, the system can construct machine learning models to accurately assess the transmission risk of infectious diseases. In terms of emergency response, the system offers powerful tools for early diagnosis, smart epidemiological investigation, digital contact tracing, vaccine and drug development, and evaluation of intervention measures. This system facilitates early detection, reporting, and management of outbreaks, serving as a valuable reference for other countries and regions. Nevertheless, continuous efforts are needed to strengthen scientific research and multidisciplinary collaboration, establish reliable data collection mechanisms, enhance continuous model monitoring and adjustments, and leverage the latest large language models. In the future, the system will be further optimized to help control emerging and major infectious diseases more effectively.}
}
@article{RASHIDI2025100687,
title = {Generative Artificial Intelligence in Pathology and Medicine: A Deeper Dive},
journal = {Modern Pathology},
volume = {38},
number = {4},
pages = {100687},
year = {2025},
issn = {0893-3952},
doi = {https://doi.org/10.1016/j.modpat.2024.100687},
url = {https://www.sciencedirect.com/science/article/pii/S0893395224002679},
author = {Hooman H. Rashidi and Joshua Pantanowitz and Alireza Chamanzar and Brandon Fennell and Yanshan Wang and Rama R. Gullapalli and Ahmad Tafti and Mustafa Deebajah and Samer Albahra and Eric Glassy and Matthew G. Hanna and Liron Pantanowitz},
keywords = {ChatGPT, diffusion, generative adversarial network, generative artificial intelligence, generative pretrained transformer, multiagent},
abstract = {This review article builds upon the introductory piece in our 7-part series, delving deeper into the transformative potential of generative artificial intelligence (Gen AI) in pathology and medicine. The article explores the applications of Gen AI models in pathology and medicine, including the use of custom chatbots for diagnostic report generation, synthetic image synthesis for training new models, data set augmentation, hypothetical scenario generation for educational purposes, and the use of multimodal along with multiagent models. This article also provides an overview of the common categories within Gen AI models, discussing open-source and closed-source models, as well as specific examples of popular models such as GPT-4, Llama, Mistral, DALL-E, Stable Diffusion, and their associated frameworks (eg, transformers, generative adversarial networks, diffusion-based neural networks), along with their limitations and challenges, especially within the medical domain. We also review common libraries and tools that are currently deemed necessary to build and integrate such models. Finally, we look to the future, discussing the potential impact of Gen AI on health care, including benefits, challenges, and concerns related to privacy, bias, ethics, application programming interface costs, and security measures.}
}
@article{GUO2024111964,
title = {DP-DDCL: A discriminative prototype with dual decoupled contrast learning method for few-shot object detection},
journal = {Knowledge-Based Systems},
volume = {297},
pages = {111964},
year = {2024},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2024.111964},
url = {https://www.sciencedirect.com/science/article/pii/S0950705124005987},
author = {Yinsai Guo and Liyan Ma and Xiangfeng Luo and Shaorong Xie},
keywords = {Few-shot object detection, Discriminative prototype, Domain knowledge, Discriminative multimodal cross-attention, Dual decoupled contrast learning},
abstract = {Few-shot object detection (FSOD) can effectively improve object detection performance with limited training data, attracting increasing interest from researchers. Due to the limited sample size, there is often a large variance in the learned features, resulting in deviating from the class center and being confused with other classes. People are often able to accurately identify few-shot objects based on discriminative information. Motivated by it, we propose a discriminative prototype with dual decoupled contrast learning (DP-DDCL) method to address the issue of limited training data in FSOD. By introducing domain knowledge comprising the CLIP and attribute knowledge graph to obtain explicit and implicit semantic and visual information, we construct a novel discriminative prototype that enhances the representation of different classes (especially few-shot samples). Simultaneously, dual decoupled contrast learning consists of the decoupled of positive and negative samples, and the decoupled of discriminative prototype and instance contrast learning is proposed. It makes samples of the same class cluster around their respective class prototype while maintaining a clear semantic boundary between different classes. Extensive experiments demonstrate the efficacy of our method, surpassing the current state-of-the-art in any-shot and all-data splits, with maximum performance gains of up to +9.15% on the standard PASCAL VOC benchmark and +2.5% on the challenging COCO benchmark.}
}
@article{FUCHS2024102735,
title = {Intermediate representations to improve the semantic parsing of building regulations},
journal = {Advanced Engineering Informatics},
volume = {62},
pages = {102735},
year = {2024},
issn = {1474-0346},
doi = {https://doi.org/10.1016/j.aei.2024.102735},
url = {https://www.sciencedirect.com/science/article/pii/S1474034624003835},
author = {Stefan Fuchs and Johannes Dimyadi and Michael Witbrock and Robert Amor},
keywords = {Semantic parsing, Building regulation, Transformer, Intermediate representation, Automated compliance checking},
abstract = {Recent developments show that large transformer-based language models have the capability to generate coherent text and source code in response to user prompts. This capability can be used in the construction domain to interpret building regulations and convert them into a formal representation usable for automated compliance checking. While base-size models can already be taught to perform semantic parsing with decent quality, this paper shows how Intermediate Representations (IRs) can be used to improve the semantic parsing quality. With reversible IRs, the training time was reduced to almost a quarter of the initial duration, and through adding a hierarchical parsing step, improvements of up to 6.6% on F1 scores were reached. Furthermore, intermediate representations provide a novel and interpretable method towards a human-in-the-loop approach for translating building regulations into a formal representation.}
}
@article{FAYE2023102230,
title = {A novel hybrid approach for text encoding: Cognitive Attention To Syntax model to detect online misinformation},
journal = {Data & Knowledge Engineering},
volume = {148},
pages = {102230},
year = {2023},
issn = {0169-023X},
doi = {https://doi.org/10.1016/j.datak.2023.102230},
url = {https://www.sciencedirect.com/science/article/pii/S0169023X23000903},
author = {Géraud Faye and Wassila Ouerdane and Guillaume Gadek and Souhir Gahbiche and Sylvain Gatepaille},
keywords = {Misinformation detection, Hybrid AI, Neurosymbolism, Natural Language Processing, Classification, Web information systems},
abstract = {Most approaches for text encoding rely on the attention mechanism, at the core of the transformers architecture and large language models. The understanding of this mechanism is still limited and present inconvenients such as lack of interpretability, large requirements of data and low generalization. Based on current understanding of the attention mechanism, we propose CATS (Cognitive Attention To Syntax), a neurosymbolic attention encoding approach based on the syntactic understanding of texts. This approach has on-par to better performance compared to classical attention and displays expected advantages of neurosymbolic AI such as better functioning with little data and better explainability. This layer has been tested on the task of misinformation detection but is general and could be used in any task involving natural language processing.}
}
@article{PURSNANI2023100183,
title = {Performance of ChatGPT on the US fundamentals of engineering exam: Comprehensive assessment of proficiency and potential implications for professional environmental engineering practice},
journal = {Computers and Education: Artificial Intelligence},
volume = {5},
pages = {100183},
year = {2023},
issn = {2666-920X},
doi = {https://doi.org/10.1016/j.caeai.2023.100183},
url = {https://www.sciencedirect.com/science/article/pii/S2666920X23000620},
author = {Vinay Pursnani and Yusuf Sermet and Musa Kurt and Ibrahim Demir},
keywords = {ChatGPT, Fundamentals of engineering exam, AI in education, Prompt modification techniques, Large language models (LLMs), Responsible AI integration},
abstract = {In recent years, advancements in artificial intelligence (AI) have led to the development of large language models like GPT-4, demonstrating potential applications in various fields, including education. This study investigates the feasibility and effectiveness of using ChatGPT, a GPT-4 based model, in achieving satisfactory performance on the Fundamentals of Engineering (FE) Environmental Exam. This study further shows a significant improvement in the model's accuracy when answering FE exam questions through noninvasive prompt modifications, substantiating the utility of prompt modification as a viable approach to enhance AI performance in educational contexts. Furthermore, the findings reflect remarkable improvements in mathematical capabilities across successive iterations of ChatGPT models, showcasing their potential in solving complex engineering problems. Our paper also explores future research directions, emphasizing the importance of addressing AI challenges in education, enhancing accessibility and inclusion for diverse student populations, and developing AI-resistant exam questions to maintain examination integrity. By evaluating the performance of ChatGPT in the context of the FE Environmental Exam, this study contributes valuable insights into the potential applications and limitations of large language models in educational settings. As AI continues to evolve, these findings offer a foundation for further research into the responsible and effective integration of AI models across various disciplines, ultimately optimizing the learning experience and improving student outcomes.}
}
@article{BERGOMI2024102924,
title = {Reshaping free-text radiology notes into structured reports with generative question answering transformers},
journal = {Artificial Intelligence in Medicine},
volume = {154},
pages = {102924},
year = {2024},
issn = {0933-3657},
doi = {https://doi.org/10.1016/j.artmed.2024.102924},
url = {https://www.sciencedirect.com/science/article/pii/S0933365724001660},
author = {Laura Bergomi and Tommaso M. Buonocore and Paolo Antonazzo and Lorenzo Alberghi and Riccardo Bellazzi and Lorenzo Preda and Chandra Bortolotto and Enea Parimbelli},
keywords = {Natural language processing, Clinical text, Generative artificial intelligence, Radiology, Lymphoma, Biomedical information extraction},
abstract = {Background
Radiology reports are typically written in a free-text format, making clinical information difficult to extract and use. Recently, the adoption of structured reporting (SR) has been recommended by various medical societies thanks to the advantages it offers, e.g. standardization, completeness, and information retrieval. We propose a pipeline to extract information from Italian free-text radiology reports that fits with the items of the reference SR registry proposed by a national society of interventional and medical radiology, focusing on CT staging of patients with lymphoma.
Methods
Our work aims to leverage the potential of Natural Language Processing and Transformer-based models to deal with automatic SR registry filling. With the availability of 174 Italian radiology reports, we investigate a rule-free generative Question Answering approach based on the Italian-specific version of T5: IT5. To address information content discrepancies, we focus on the six most frequently filled items in the annotations made on the reports: three categorical (multichoice), one free-text (free-text), and two continuous numerical (factual). In the preprocessing phase, we encode also information that is not supposed to be entered. Two strategies (batch-truncation and ex-post combination) are implemented to comply with the IT5 context length limitations. Performance is evaluated in terms of strict accuracy, f1, and format accuracy, and compared with the widely used GPT-3.5 Large Language Model. Unlike multichoice and factual, free-text answers do not have 1-to-1 correspondence with their reference annotations. For this reason, we collect human-expert feedback on the similarity between medical annotations and generated free-text answers, using a 5-point Likert scale questionnaire (evaluating the criteria of correctness and completeness).
Results
The combination of fine-tuning and batch splitting allows IT5 ex-post combination to achieve notable results in terms of information extraction of different types of structured data, performing on par with GPT-3.5. Human-based assessment scores of free-text answers show a high correlation with the AI performance metrics f1 (Spearman's correlation coefficients>0.5, p-values<0.001) for both IT5 ex-post combination and GPT-3.5. The latter is better at generating plausible human-like statements, even if it systematically provides answers even when they are not supposed to be given.
Conclusions
In our experimental setting, a fine-tuned Transformer-based model with a modest number of parameters (i.e., IT5, 220 M) performs well as a clinical information extraction system for automatic SR registry filling task. It can extract information from more than one place in the report, elaborating it in a manner that complies with the response specifications provided by the SR registry (for multichoice and factual items), or that closely approximates the work of a human-expert (free-text items); with the ability to discern when an answer is supposed to be given or not to a user query.}
}
@article{CHEN2024123478,
title = {GAP: A novel Generative context-Aware Prompt-tuning method for relation extraction},
journal = {Expert Systems with Applications},
volume = {248},
pages = {123478},
year = {2024},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2024.123478},
url = {https://www.sciencedirect.com/science/article/pii/S0957417424003439},
author = {Zhenbin Chen and Zhixin Li and Yufei Zeng and Canlong Zhang and Huifang Ma},
keywords = {Relation extraction, Prompt-tuning, Pretrained language model, Few-shot learning, Contrastive learning},
abstract = {Prompt-tuning was proposed to bridge the gap between pretraining and downstream tasks, and it has achieved promising results in Relation Extraction (RE). Although the existing prompt-based RE methods have outperformed the methods based on fine-tuning paradigm, these methods require domain experts to design prompt templates, making them hard to be generalized. In this paper, we propose a Generative context-Aware Prompt-tuning method (GAP) to address these limitations. Our method consists of three crucial modules: (1) a pretrained prompt generator module that extracts or generates the relation triggers from the context and embeds them into the prompt tokens, (2) an in-domain adaptive pretraining module that further trains the Pretrained Language Models (PLMs) to promote the adaptability of the model, and (3) a joint contrastive loss that prevents PLMs from generating unrelated content and optimizes our model more effectively. We observe that the context-enhanced prompt tokens generated by GAP can better guide PLMs to make more accurate predictions. And the in-domain pretraining can effectively inject domain knowledge to enhance the robustness of the model. We conduct experiments on four public RE datasets with supervised and few-shot settings. The experimental results have demonstrated the superiority of GAP over existing benchmark methods and GAP shows remarkable improvements in few-shot settings, with average F1 score enhancements of 3.5%, 2.7%, and 3.4% on the TACRED, TACREV, and Re-TACRED datasets, respectively. Furthermore, GAP still achieved state-of-the-art (SOTA) performance in supervised settings.}
}
@article{WU2024453,
title = {Improving few-shot relation extraction through semantics-guided learning},
journal = {Neural Networks},
volume = {169},
pages = {453-461},
year = {2024},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2023.10.053},
url = {https://www.sciencedirect.com/science/article/pii/S0893608023006196},
author = {Hui Wu and Yuting He and Yidong Chen and Yu Bai and Xiaodong Shi},
keywords = {Few-shot relation extraction, Prototype network, Relation information, Semantics-guided learning, Relation graph learning, Contrastive learning},
abstract = {Few-shot relation extraction (few-shot RE) aims to recognize relations between the entity pair in a given text by utilizing very few annotated instances. As a simple yet efficient approach, prototype network-based methods often directly incorporate relation information to enhance prototype representation or leverage contrastive learning to mitigate prediction confusion. Despite achieving good results, the above methods are still susceptible to false judgments of outlier samples and confusion of similar classes. To address these issues, we propose a novel Semantics-Guided Learning (SemGL) method that more effectively utilizes relation information to enhance both the representations of instances and prototypes for improving the performance of few-shot RE. First, SemGL employs the prompt encoder to encode various prompt templates of instances and relation information and obtains more accurate semantic representations of instances, instance prototypes, and concept prototypes via the prompt enhancement from large language models. Then, SemGL introduces a novel technique called relation graph learning, which leverages concept prototypes to cluster homogeneous instances together, emphasizing relation-specific features of concrete instances. Simultaneously, SemGL employs instance-level contrastive learning between instance prototypes and support instances to distinguish between intra-class instances and inter-class instances to promote shared features among intra-class instances. Additionally, prototype-level contrastive learning leverages concept prototypes to pull closer relation-specific features of the concept prototype and shared features of the instance prototype from the same relation. Finally, SemGL utilizes new relation prototypes that integrate interpretable features of concept prototypes and shared features of instance prototypes for prediction. Experimental results on two publicly available few-shot RE datasets demonstrate the effectiveness and efficiency of SemGL in introducing relation information, with particularly promising results for the domain adaptation challenge task.}
}
@article{YIN2024104731,
title = {Augmenting biomedical named entity recognition with general-domain resources},
journal = {Journal of Biomedical Informatics},
volume = {159},
pages = {104731},
year = {2024},
issn = {1532-0464},
doi = {https://doi.org/10.1016/j.jbi.2024.104731},
url = {https://www.sciencedirect.com/science/article/pii/S1532046424001497},
author = {Yu Yin and Hyunjae Kim and Xiao Xiao and Chih Hsuan Wei and Jaewoo Kang and Zhiyong Lu and Hua Xu and Meng Fang and Qingyu Chen},
keywords = {Natural Language Processing, Biomedical Named Entity Recognition, Transfer Learning},
abstract = {Objective
Training a neural network-based biomedical named entity recognition (BioNER) model usually requires extensive and costly human annotations. While several studies have employed multi-task learning with multiple BioNER datasets to reduce human effort, this approach does not consistently yield performance improvements and may introduce label ambiguity in different biomedical corpora. We aim to tackle those challenges through transfer learning from easily accessible resources with fewer concept overlaps with biomedical datasets.
Methods
We proposed GERBERA, a simple-yet-effective method that utilized general-domain NER datasets for training. We performed multi-task learning to train a pre-trained biomedical language model with both the target BioNER dataset and the general-domain dataset. Subsequently, we fine-tuned the models specifically for the BioNER dataset.
Results
We systematically evaluated GERBERA on five datasets of eight entity types, collectively consisting of 81,410 instances. Despite using fewer biomedical resources, our models demonstrated superior performance compared to baseline models trained with additional BioNER datasets. Specifically, our models consistently outperformed the baseline models in six out of eight entity types, achieving an average improvement of 0.9% over the best baseline performance across eight entities. Our method was especially effective in amplifying performance on BioNER datasets characterized by limited data, with a 4.7% improvement in F1 scores on the JNLPBA-RNA dataset.
Conclusion
This study introduces a new training method that leverages cost-effective general-domain NER datasets to augment BioNER models. This approach significantly improves BioNER model performance, making it a valuable asset for scenarios with scarce or costly biomedical datasets. We make data, codes, and models publicly available via https://github.com/qingyu-qc/bioner_gerbera.}
}
@incollection{CHANG202319,
title = {Chapter 2 - Data-centric artificial intelligence in health care: progress, shortcomings, and remedies},
editor = {Tung-Hung Su and Jia-Horng Kao},
booktitle = {Artificial Intelligence, Machine Learning, and Deep Learning in Precision Medicine in Liver Diseases},
publisher = {Academic Press},
pages = {19-49},
year = {2023},
isbn = {978-0-323-99136-0},
doi = {https://doi.org/10.1016/B978-0-323-99136-0.00005-2},
url = {https://www.sciencedirect.com/science/article/pii/B9780323991360000052},
author = {Edward Y. Chang},
keywords = {Artificial intelligence, Data-centric AI, Diagnostic procedure, Generative AI, Health care, KG, KG-GANS, Knowledge-guided, Knowledge-guided GANs, Natural language processing, Pre-trained language model, Prompting},
abstract = {Deep learning owes its success to a large volume of training data, which provide good coverage to all expressions of a semantic. In the medical domain, we desire to have training data that can cover all manifestations of a disease, to train a model that can accurately predict it. Unfortunately, no breakthrough has yet been made in image-based diagnosis because of the lack of high-quality annotated data. This chapter presents the importance of the data-centric approach for learning good representations of a disease. We examine four widely used training data generation and aggregation methods (data augmentation, transfer learning, federated learning, and generative adversarial network [GANs]) and analyze their shortcomings. To remedy such shortcomings, we propose knowledge-guided (KG)-GANs to guide training data generation with domain knowledge. Finally, we discuss our work since 2020 in modeling consciousness to interact with pretrained language models to acquire domain knowledge to regulate KG-GANs.}
}
@article{ZHANG2025129374,
title = {DIRel: Joint relational triple extraction through dual implicit relation},
journal = {Neurocomputing},
volume = {624},
pages = {129374},
year = {2025},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2025.129374},
url = {https://www.sciencedirect.com/science/article/pii/S0925231225000463},
author = {Liang Zhang and Nan Zheng},
keywords = {Joint extraction, Dual implicit relation, Knowledge graph},
abstract = {Joint extraction of entities and relations from unstructured texts is essential in information extraction and knowledge graph construction. Existing approaches usually extract entities in one identical relation space to construct relational triples, but ignore the difference between the relation of entity pairs and the relation of token pairs in entity pairs. Therefore, previous joint methods suffer from the problem of coarse-grained relations and redundant information. To address this issue, we propose a novel joint entity and relation extraction model based on dual implicit relation, named DIRel. Specifically, our model consists of an implicit relation predictor and a dual implicit relation tagging scheme. The former predicts all possible implicit relations belonging to each token pair, respectively. The latter ensures an effective decoding process that extracts relational triples according to the implicit relations predicted. With comprehensive experiments on three widely used datasets, we demonstrate that DIRel is more effective and computationally efficient.}
}
@article{CHOU2024104064,
title = {Implicit and explicit commonsense for multi-sentence video captioning},
journal = {Computer Vision and Image Understanding},
volume = {247},
pages = {104064},
year = {2024},
issn = {1077-3142},
doi = {https://doi.org/10.1016/j.cviu.2024.104064},
url = {https://www.sciencedirect.com/science/article/pii/S1077314224001450},
author = {Shih-Han Chou and James J. Little and Leonid Sigal},
keywords = {Instruction generation, Video captioning, Commonsense reasoning},
abstract = {Existing dense or paragraph video captioning approaches rely on holistic representations of videos, possibly coupled with learned object/action representations, to condition hierarchical language decoders. However, they fundamentally lack the commonsense knowledge of the world required to reason about progression of events, causality, and even the function of certain objects within a scene. To address this limitation we propose a novel video captioning Transformer-based model, that takes into account both implicit (visuo-lingual and purely linguistic) and explicit (knowledge-base) commonsense knowledge. We show that these forms of knowledge, in isolation and in combination, enhance the quality of produced captions. Further, inspired by imitation learning, we propose a new task of instruction generation, where the goal is to produce a set of linguistic instructions from a video demonstration of its performance. We formalize the task using the ALFRED dataset generated using an AI2-THOR environment. While instruction generation is conceptually similar to paragraph captioning, it differs in the fact that it exhibits stronger object persistence, as well as spatially-aware and causal sentence structure. We show that our commonsense knowledge enhanced approach produces significant improvements on this task (up to 57% in METEOR and 8.5% in CIDEr), as well as the state-of-the-art result on more traditional video captioning in the ActivityNet Captions dataset.}
}
@article{ABDUL2024108051,
title = {Improving preliminary clinical diagnosis accuracy through knowledge filtering techniques in consultation dialogues},
journal = {Computer Methods and Programs in Biomedicine},
volume = {246},
pages = {108051},
year = {2024},
issn = {0169-2607},
doi = {https://doi.org/10.1016/j.cmpb.2024.108051},
url = {https://www.sciencedirect.com/science/article/pii/S0169260724000476},
author = {Ashu Abdul and Binghong Chen and Siginamsetty Phani and Jenhui Chen},
keywords = {Disease, Knowledge graph, Natural language processing, Patient syndrome, Preliminary clinical diagnosis, Transformers},
abstract = {Background and Objective
Symptom descriptions by ordinary people are often inaccurate or vague when seeking medical advice, which often leads to inaccurate preliminary clinical diagnoses. To address this issue, we propose a deep learning model named the knowledgeable diagnostic transformer (KDT) for the natural language processing (NLP)-based preliminary clinical diagnoses.
Methods
The KDT extracts symptom-disease relation triples (h,r,t) from patient symptom descriptions by using a proposed bipartite medical knowledge graph (bMKG). To avoid too many relation triples causing the knowledge noise issue, we propose a knowledge inclusion-exclusion approach (KIA) to eliminate undesirable triples (a knowledge filtering layer). Next, we combine token embedding techniques with the transformer model to predict the diseases that patients may encounter.
Results
To train the KDT, a medical diagnosis question-answering dataset (named MDQA dataset) containing large-scale, high-quality questions (patient syndrome description) and answering (diagnosis) corpora with 2.6M entries (1.07GB in size) in Mandarin was built. We also train the KDT with the National Institutes of Health (NIH) English dataset (MedQuAD). The KDT marks a transformative approach by achieving a remarkable accuracy of 99% for different evaluation metrics when compared with the baseline transformers used for the NLP-based preliminary clinical diagnoses approaches.
Conclusions
In essence, our study not only demonstrates the effectiveness of the KDT in enhancing diagnostic precision but also underscores its potential to revolutionize the field of preliminary clinical diagnoses. By harnessing the power of knowledge-based approaches and advanced NLP techniques, we have paved the way for more accurate and reliable diagnoses, ultimately benefiting both healthcare providers and patients. The KDT has the potential to significantly reduce misdiagnoses and improve patient outcomes, marking a pivotal advancement in the realm of medical diagnostics.}
}
@article{CHEN2025107068,
title = {Unified Knowledge-Guided Molecular Graph Encoder with multimodal fusion and multi-task learning},
journal = {Neural Networks},
volume = {184},
pages = {107068},
year = {2025},
issn = {0893-6080},
doi = {https://doi.org/10.1016/j.neunet.2024.107068},
url = {https://www.sciencedirect.com/science/article/pii/S0893608024009973},
author = {Mukun Chen and Xiuwen Gong and Shirui Pan and Jia Wu and Fu Lin and Bo Du and Wenbin Hu},
keywords = {Knowledge graphs, Message Passing Neural Networks, Multimodal fusion, Attention mechanism, Molecular modeling},
abstract = {The remarkable success of Graph Neural Networks underscores their formidable capacity to assimilate multimodal inputs, markedly enhancing performance across a broad spectrum of domains. In the context of molecular modeling, considerable efforts have been made to enrich molecular representations by integrating data from diverse aspects. Nevertheless, current methodologies frequently compartmentalize geometric and semantic components, resulting in a fragmented approach that impairs the holistic integration of molecular attributes. This constrained scope limits the generalizability and efficacy of such models in downstream applications. A pivotal challenge lies in harmonizing heterogeneous data sources, particularly in addressing the inherent inconsistencies and sparsity within multimodal molecular datasets. To overcome these limitations, we present the Unified Knowledge-Guided Molecular Graph Encoder (UKGE), a groundbreaking framework that leverages heterogeneous graphs to unify the representation of diverse molecular modalities. Unlike prior methods, UKGE reconciles geometric and semantic features through the use of elemental knowledge graphs (KGs) and meta-path definitions by constructing Unified Molecular Graphs, enabling comprehensive and unified molecular representations. It employs an innovative Meta-Path Aware Message Passing mechanism within its molecular encoder, enhancing the integration of multimodal data. Additionally, a multi-task learning strategy balances data from different modalities, further enriching UKGE’s capability to embed complex biological insights.Empirical evaluations highlight UKGE’s excellence across tasks: DDI prediction achieves 96.91% ACC and 99.14% AUC in warm-start settings, with 83.15% ACC in cold-start scenarios. For CPI prediction, it reaches 0.644 CI on Davis and 0.659 on KIBA. In LBDD, it achieves 99.3% validity, 98.4% uniqueness, and 98.9% novelty, establishing UKGE as a state-of-the-art molecular modeling framework.}
}
@article{LI2024112119,
title = {Multi-aspect Knowledge-enhanced Hypergraph Attention Network for Conversational Recommendation Systems},
journal = {Knowledge-Based Systems},
volume = {299},
pages = {112119},
year = {2024},
issn = {0950-7051},
doi = {https://doi.org/10.1016/j.knosys.2024.112119},
url = {https://www.sciencedirect.com/science/article/pii/S0950705124007536},
author = {Xiaokang Li and Yihao Zhang and Yonghao Huang and Kaibei Li and Yunjia Zhang and Xibin Wang},
keywords = {Conversational recommendation systems, Knowledge graph, Hypergraph attention network, Dual attention mechanism},
abstract = {Conversational recommendation systems (CRS) aim to proactively elicit user preferences through multi-turn conversations for item recommendations. However, most existing works focus solely on user’s current conversation information, which fails to capture user implicit preferences comprehensively. Moreover, these approaches primarily center around pairwise relations among data in CRS to enhance item representations, while largely overlooking the complicated relationships in CRS. To address these limitations, we propose a hypergraph-based knowledge-enhanced CRS model namely Multi-aspect Knowledge-enhanced Hypergraph Attention Network for Conversational Recommendation Systems (MKHCR). We construct three hypergraphs based on multiple aspects knowledge to mine high-order relations among data for enhancing user implicit preference representations. Specifically, we build a session hypergraph to capture high-order complicated relations in the historical conversations to explore user implicit preferences. To mitigate the data scarcity issue, we incorporate knowledge graphs and items review information, modeling them within hypergraph structure to learn complicated semantic relationships, thereby enhancing item representations. Moreover, a hypergraph attention network with a dual attention mechanism is proposed to flexibly aggregate important high-order features from these hypergraphs, which contributes to enhance user preference representations for both the recommendation and conversation generation tasks. Extensive experiments on two publicly available CRS datasets validate the effectiveness of our proposed MKHCR model, which exhibits significant improvements across key evaluation metrics, including HR@50, MRR@50, and NDCG@50, achieving enhancements of 6.76%, 9.16%, and 7.92%, respectively.}
}
@article{WANG2023103953,
title = {Are the BERT family zero-shot learners? A study on their potential and limitations},
journal = {Artificial Intelligence},
volume = {322},
pages = {103953},
year = {2023},
issn = {0004-3702},
doi = {https://doi.org/10.1016/j.artint.2023.103953},
url = {https://www.sciencedirect.com/science/article/pii/S0004370223000991},
author = {Yue Wang and Lijun Wu and Juntao Li and Xiaobo Liang and Min Zhang},
keywords = {Pre-trained language model, Zero-shot text classification, Prompt-based learning},
abstract = {Starting from the resurgence of deep learning, language models (LMs) have never been so popular. Through simply increasing model scale and data size, large LMs pre-trained with self-supervision objectives demonstrate awe-inspiring results on both task performance and generalization. At the early stage, supervised fine-tuning is indispensable in adapting pre-trained language models (PLMs) to downstream tasks. Later on, the sustained growth of model capacity and data size, as well as newly presented pre-training techniques, make the PLMs perform well under the few-shot setting, especially in the recent paradigm of prompt-based learning. After witnessing the success of PLMs for few-shot tasks, we propose to further study the potential and limitations of PLMs for the zero-shot setting. We utilize 3 models from the most popular BERT family to launch the empirical study on 20 different datasets. We are surprised to find that some simple strategies (without the need of human efforts or unsupervised data) can yield very promising results on a few widely-used datasets, e.g., 88.34%(±0.60) accuracy on the IMDB dataset, and 84.88%(±2.83) accuracy on the Amazon dataset, which outperforms manually created prompts without engineering in achieving much better and stable performance with the accuracy of 74.06%(±13.04), 75.54%(±11.77) for comparison. However, we also observe some limitations of PLMs under the zero-shot setting, particularly for the language understanding tasks (e.g., GLUE, SuperGLUE).2}
}
@article{RIVIERE2024637,
title = {Proceedings from the inaugural Artificial Intelligence in Primary Immune Deficiencies (AIPID) conference},
journal = {Journal of Allergy and Clinical Immunology},
volume = {153},
number = {3},
pages = {637-642},
year = {2024},
issn = {0091-6749},
doi = {https://doi.org/10.1016/j.jaci.2024.01.002},
url = {https://www.sciencedirect.com/science/article/pii/S0091674924000332},
author = {Jacques G. Rivière and Pere {Soler Palacín} and Manish J. Butte},
keywords = {Artificial intelligence, machine learning, large language models, natural language processing, electronic health records, inborn errors of immunity, diagnosis, ethics},
abstract = {Here, we summarize the proceedings of the inaugural Artificial Intelligence in Primary Immune Deficiencies conference, during which experts and advocates gathered to advance research into the applications of artificial intelligence (AI), machine learning, and other computational tools in the diagnosis and management of inborn errors of immunity (IEIs). The conference focused on the key themes of expediting IEI diagnoses, challenges in data collection, roles of natural language processing and large language models in interpreting electronic health records, and ethical considerations in implementation. Innovative AI-based tools trained on electronic health records and claims databases have discovered new patterns of warning signs for IEIs, facilitating faster diagnoses and enhancing patient outcomes. Challenges in training AIs persist on account of data limitations, especially in cases of rare diseases, overlapping phenotypes, and biases inherent in current data sets. Furthermore, experts highlighted the significance of ethical considerations, data protection, and the necessity for open science principles. The conference delved into regulatory frameworks, equity in access, and the imperative for collaborative efforts to overcome these obstacles and harness the transformative potential of AI. Concerted efforts to successfully integrate AI into daily clinical immunology practice are still needed.}
}
@article{WANG2025128829,
title = {Multi-modal soft prompt-tuning for Chinese Clickbait Detection},
journal = {Neurocomputing},
volume = {614},
pages = {128829},
year = {2025},
issn = {0925-2312},
doi = {https://doi.org/10.1016/j.neucom.2024.128829},
url = {https://www.sciencedirect.com/science/article/pii/S092523122401600X},
author = {Ye Wang and Yi Zhu and Yun Li and Liting Wei and Yunhao Yuan and Jipeng Qiang},
keywords = {Chinese Clickbait Detection, Soft prompt-tuning, Multi-modal},
abstract = {With the rapid growth of Chinese online services, clickbait has proliferated at an unprecedented rate, designed to manipulate users into clicking for increased traffic or advertising promotion. Such clickbait not only facilitates the spread of fake news and misinformation but also enables click-jacking attacks, redirecting users to deceptive websites that steal personal information. These harmful activities can result in significant losses and serious repercussions. The widespread presence of clickbait underscores both the importance and the challenges of developing effective detection methods. To date, the research paradigm of clickbait detection evolved from deep neural networks to fine-tuned Pre-trained Language Models (PLMs) and, more recently, into prompt-tuning models. However, these methods may suffer two main limitations: (1) they fail to utilize the multi-modal context information in news or posts and explore the higher-level feature representations to enhance the performance of clickbait detection; (2) they largely ignore the diverse range of Chinese expressive forms and neglect the complex semantics and syntactic structures of textual content to assist in learning a better news representation. To overcome these limitations, we proposed a Multi-modal Soft Prompt-tuning Method (MSP) for Chinese Clickbait Detection, which jointly models the textual and image information into a continuous prompt embedding as the input of PLMs. Specifically, firstly, the soft prompt-tuning model including Graph Attention Network and Contrastive Language-Image Pre-training are employed to learn the feature representations of texts and images in news or posts, respectively. Then the obtained text and image representations are re-input into the soft prompt-tuning model with automatic template generation. The extensive experiments on three Chinese clickbait detection datasets demonstrate that our MSP achieved state-of-the-art performance.}
}
@article{SAITO2024125149,
title = {Leveraging multiple behaviors and explicit preferences for job recommendation},
journal = {Expert Systems with Applications},
volume = {258},
pages = {125149},
year = {2024},
issn = {0957-4174},
doi = {https://doi.org/10.1016/j.eswa.2024.125149},
url = {https://www.sciencedirect.com/science/article/pii/S0957417424020165},
author = {Yosuke Saito and Kazunari Sugiyama},
keywords = {Job recommendation, Multi-behavior recommendation, Graph representation learning, Metric learning},
abstract = {Numerous job openings have been posted online, indicating the increasing importance of job recommendations. Recently, job seekers often enter their preferences into job search websites to receive some job recommendations that they hope to apply for. To achieve this goal, the following two types of data are available: (1) auxiliary behavior data such as viewing job postings, bookmarking them and (2) explicit preference data such as conditions for a job that each job seeker desires. Although limited research has employed both (1) and (2) simultaneously, no sophisticated job recommendation method leverages multiple types of interactions and explicit preferences to achieve high accuracy. Given this point, we propose a method for job recommendation that employs auxiliary behavior data and each user’s explicit preference data simultaneously. Additionally, our proposed method addresses multiple behavior overlaps and refines the latent representations. Furthermore, the integration method of the latent representations obtained from each of the two modules addresses the consistency of user preferences and the similarity with job postings, enabling a more accurate estimation of user preferences. Experimental results on our dataset constructed from an actual job search website show that our proposed model outperforms the best baseline by 31.4% and 32.8% in terms of Mean Reciprocal Rank (MRR) and Normalized Discounted Cumulative Gain@5 (nDCG@5), respectively. We have released our source codes.11https://github.com/saitoxu/JME-ESWA.}
}
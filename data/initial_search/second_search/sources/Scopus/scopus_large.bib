Scopus
EXPORT DATE: 11 February 2025

@ARTICLE{Ciatto2025,
	author = {Ciatto, Giovanni and Agiollo, Andrea and Magnini, Matteo and Omicini, Andrea},
	title = {Large language models as oracles for instantiating ontologies with domain-specific knowledge},
	year = {2025},
	journal = {Knowledge-Based Systems},
	volume = {310},
	doi = {10.1016/j.knosys.2024.112940},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214522484&doi=10.1016%2fj.knosys.2024.112940&partnerID=40&md5=47c824ae744809fb6572d72d1cf3c4a3},
	abstract = {Background: Endowing intelligent systems with semantic data commonly requires designing and instantiating ontologies with domain-specific knowledge. Especially in the early phases, those activities are typically performed manually by human experts possibly leveraging on their own experience. The resulting process is therefore time-consuming, error-prone, and often biased by the personal background of the ontology designer. Objective: To mitigate that issue, we propose a novel domain-independent approach to automatically instantiate ontologies with domain-specific knowledge, by leveraging on large language models (LLMs) as oracles. Methods: Starting from (i) an initial schema composed by inter-related classes and properties and (ii) a set of query templates, our method queries the LLM multiple times, and generates instances for both classes and properties from its replies. Thus, the ontology is automatically filled with domain-specific knowledge, compliant to the initial schema. As a result, the ontology is quickly and automatically enriched with manifold instances, which experts may consider to keep, adjust, discard, or complement according to their own needs and expertise. Contribution: We formalise our method in general way and instantiate it over various LLMs, as well as on a concrete case study. We report experiments rooted in the nutritional domain where an ontology of food meals and their ingredients is automatically instantiated from scratch, starting from a categorisation of meals and their relationships. There, we analyse the quality of the generated ontologies and compare ontologies attained by exploiting different LLMs. Experimentally, our approach achieves a quality metric that is up to five times higher than the state-of-the-art, while reducing erroneous entities and relations by up to ten times. Finally, we provide a SWOT analysis of the proposed method. © 2025 The Authors},
	author_keywords = {Automation; Domain-specific knowledge; Large language models; Nutrition; Ontology population},
	keywords = {Intelligent systems; Modeling languages; Ontology; Semantics; Structured Query Language; Domain-specific knowledge; Error prones; Human expert; Language model; Large language model; Novel domain; Ontology Population; Ontology's; Property; Semantic data; Domain Knowledge},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Xu2025,
	author = {Xu, Tianhan and Li, Bin},
	title = {KELLM: Knowledge-Enhanced Label-Wise Large Language Model for Safe and Interpretable Drug Recommendation},
	year = {2025},
	journal = {Electronics (Switzerland)},
	volume = {14},
	number = {1},
	doi = {10.3390/electronics14010154},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214524421&doi=10.3390%2felectronics14010154&partnerID=40&md5=a15ac1c2666add3c6d45376fd3257d40},
	abstract = {The proliferation of electronic health records (EHRs) and advances in deep learning have enabled personalized drug combination recommendations. However, traditional deep learning models often lack the contextual understanding and medical knowledge integration necessary for accurate predictions. While large language model (LLM)-based approaches address some of these challenges, they still fall short in incorporating critical medical knowledge, addressing comprehensive safety constraints such as multi-disease drug contraindications (MDCs), and providing sufficient interpretability of the causal mechanisms behind their outputs. To overcome these limitations, we propose KELLM, a knowledge-enhanced LLM framework for drug recommendations. By linking medical entities in EHRs to an external medical knowledge graph, inputs are enriched with causal chains, enhancing both prediction accuracy and interpretability. Additionally, we introduce a fine-tuned label-wise LLaMA model designed for multi-label classification, which incorporates safety considerations such as drug-drug interactions (DDIs) and MDCs to ensure clinically accurate and safe recommendations. Experimental results show that KELLM achieves state-of-the-art performance in effectiveness and safety metrics, while also providing evidence-based insights through causal chains that clarify its reasoning process. This establishes a new benchmark for trustworthy, interpretable drug combination recommendations. © 2025 by the authors.},
	author_keywords = {drug combination recommendation; label-wise LLaMA; large language models; medical causal chains; multi-disease drug contraindications},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Jiang2025221,
	author = {Jiang, Zongli and Feng, Chen and Zhang, Jinli and Bai, Xiaolu},
	title = {Graph Data Understanding and Interpretation Enabled by Large Language Models},
	year = {2025},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) },
	volume = {15389 LNAI},
	pages = {221 – 233},
	doi = {10.1007/978-981-96-0821-8_15},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213337631&doi=10.1007%2f978-981-96-0821-8_15&partnerID=40&md5=9708b7dfcb6ee28e4cdac6e471d41741},
	abstract = {The emergence of Large Language Models (LLMs) has driven the progress of deep learning. With the development of LLMs, they have gained the ability to process various types of input, including images and videos. However, there is still a significant gap in LLMs’ understanding of graph structure data and its inherent complexity. Graph Neural Networks (GNNs) are a mature model that is specifically designed as a neural network model for handling irregular graph structure data. However, the challenge is how to combine the advantages of GNNs and LLMs, not just relying on the performance of GNNs on graph structure datasets. Inspired by the progress of LLMs, This paper proposes a novel approach that integrates graph structure information with textual data, aiming to leverage the power of LLMs in understanding complex graph-based data. Our framework involves standardizing both graph structures and text datasets into a consistent length embedding, ensuring compatibility with LLM processing requirements. A lightweight converter is employed to forge links between disparate data modalities, preserving the integrity and characteristics of each original data while converting them into a unified representation. Furthermore, this framework incorporates Retrieval Augmented Thoughts (RAT) to enable the effective integration of external knowledge sources, thereby enriching the context and coherence of generated responses. Through rigorous evaluation against prevailing benchmarks, the proposed method showcases superior performance across four distinct datasets, outperforming cutting-edge GNNs models currently dominating the field. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2025.},
	author_keywords = {Deep Learning; Graph Neural Networks; Large Language Models; Retrieval Augmented Thoughts},
	keywords = {Deep learning; Graph neural networks; Neural network models; Deep learning; Graph data; Graph neural networks; Graph structures; Language model; Large language model; Neural network model; Performance; Retrieval augmented thought; Structure data; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Gui202559,
	author = {Gui, Honghao and Qiao, Shuofei and Zhang, Jintian and Ye, Hongbin and Sun, Mengshu and Liang, Lei and Pan, Jeff Z. and Chen, Huajun and Zhang, Ningyu},
	title = {InstructIE: A Bilingual Instruction-based Information Extraction Dataset},
	year = {2025},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) },
	volume = {15233 LNCS},
	pages = {59 – 79},
	doi = {10.1007/978-3-031-77847-6_4},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211241549&doi=10.1007%2f978-3-031-77847-6_4&partnerID=40&md5=0e75ad225194ab7c0ba5249db78c9201},
	abstract = {Large language models can perform well on general natural language tasks, but their effectiveness is still suboptimal for information extraction (IE). Recent works indicate that the main reason lies in the lack of extensive data on IE instructions. Note that the existing datasets on IE instructions not only have limited coverage but also involve high construction costs. To address this issue, we introduce InstructIE, a bilingual instruction-based IE dataset, which covers 12 diverse domains. We propose KG2Instruction, a framework specifically for the automatic generation of such datasets. Additionally, we manually annotate the test set. Experimental results demonstrate that large language models trained with InstructIE can not only obtain better IE capabilities but also enhance zero-shot performance compared with baselines. Resource Type: New Dataset Source Repo:https://huggingface.co/datasets/zjunlp/InstructIE DOI:https://doi.org/10.5281/zenodo.10970777 License: Attribution-NonCommercial-ShareAlike 4.0 International © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.},
	author_keywords = {Dataset; Information Extraction; Knowledge Graph; Knowledge Graph Construction; Large Language Models},
	keywords = {Bilinguals; Dataset; Graph construction; Information extraction; Knowledge graph construction; Knowledge graphs; Language model; Large language model; Natural languages; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{2025,
	title = {25th International Conference on Web Information Systems Engineering, WISE 2024},
	year = {2025},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) },
	volume = {15436 LNCS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211324377&partnerID=40&md5=710cfb0decd068c922cc3591fcb9639b},
	abstract = {The proceedings contain 132 papers. The special focus in this conference is on Web Information Systems Engineering. The topics include: TAKE: Tracing Associative Empathy Keywords for Generating Empathetic Responses Based on Graph Attention; intent Identification Using Few-Shot and Active Learning with User Feedback; CLIMB: Imbalanced Data Modelling Using Contrastive Learning with Limited Labels; equivariant Diffusion-Based Sequential Hypergraph Neural Networks with Co-attention Fusion for Information Diffusion Prediction; CL3: A Collaborative Learning Framework for the Medical Data Ensuring Data Privacy in the Hyperconnected Environment; selectivity Estimation for Spatial Filters Using Optimizer Feedback: A Machine Learning Perspective; on Adversarial Training with Incorrect Labels; model Lake : A New Alternative for Machine Learning Models Management and Governance; a Benchmark Test Suite for Multiple Traveling Salesmen Problem with Pivot Cities; Deconfounded Causality-Aware Parameter-Efficient Fine-Tuning for Problem-Solving Improvement of LLMs; Regularized Multi-LLMs Collaboration for Enhanced Score-Based Causal Discovery; Combining Uncensored and Censored LLMs for Ransomware Generation; Therapying Outside the Box: Innovating the Implementation and Evaulation of CBT in Therapeutic Artificial Agents; iText2KG: Incremental Knowledge Graphs Construction Using Large Language Models; “Is this Site Legit?”: LLMs for Scam Website Detection; Towards Enhancing Linked Data Retrieval in Conversational UIs Using Large Language Models; BioLinkerAI: Capturing Knowledge Using LLMs to Enhance Biomedical Entity Linking; Enhancing LLMs Contextual Knowledge with Ontologies for Personalised Food Recommendation; ShizishanGPT: An Agricultural Large Language Model Integrating Tools and Resources; Web-Based AI Assistant for Medical Imaging: A Case Study on Predicting Spontaneous Preterm Birth via Ultrasound Images; satellite-Driven Deep Learning Algorithm for Bathymetry Extraction; Would You Trust an AI Doctor? Building Reliable Medical Predictions with Kernel Dropout Uncertainty; empowering Visual Navigation: A Deep-Learning Solution for Enhanced Accessibility and Safety Among the Visually Impaired; A Transformer and LSTM Model for Electricity Consumption Forecasting and User’s Behavior Influence.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Fuellen2025,
	author = {Fuellen, Georg and Kulaga, Anton and Lobentanzer, Sebastian and Unfried, Maximilian and Avelar, Roberto A. and Palmer, Daniel and Kennedy, Brian K.},
	title = {Validation requirements for AI-based intervention-evaluation in aging and longevity research and practice},
	year = {2025},
	journal = {Ageing Research Reviews},
	volume = {104},
	doi = {10.1016/j.arr.2024.102617},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212214255&doi=10.1016%2fj.arr.2024.102617&partnerID=40&md5=ea72dfee0429120a10c4bfd844b41df9},
	abstract = {The field of aging and longevity research is overwhelmed by vast amounts of data, calling for the use of Artificial Intelligence (AI), including Large Language Models (LLMs), for the evaluation of geroprotective interventions. Such evaluations should be correct, useful, comprehensive, explainable, and they should consider causality, interdisciplinarity, adherence to standards, longitudinal data and known aging biology. In particular, comprehensive analyses should go beyond comparing data based on canonical biomedical databases, suggesting the use of AI to interpret changes in biomarkers and outcomes. Our requirements motivate the use of LLMs with Knowledge Graphs and dedicated workflows employing, e.g., Retrieval-Augmented Generation. While naive trust in the responses of AI tools can cause harm, adding our requirements to LLM queries can improve response quality, calling for benchmarking efforts and justifying the informed use of LLMs for advice on longevity interventions. © 2024 The Authors},
	author_keywords = {Large Language Models; Longevity; Preventive Medicine},
	keywords = {biological marker; aged; aging; artificial intelligence; benchmarking; causality; human; information retrieval; large language model; longevity; preventive medicine; prophylaxis; review; very elderly; workflow},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Zhao2025241,
	author = {Zhao, Yiming and Chen, Jie and Wu, Nannan and Wang, Wenjun},
	title = {Empowering Comprehensive Biomedical Information Analysis with Large Language Models},
	year = {2025},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) },
	volume = {15390 LNAI},
	pages = {241 – 255},
	doi = {10.1007/978-981-96-0840-9_17},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213295993&doi=10.1007%2f978-981-96-0840-9_17&partnerID=40&md5=514cf9532c270a19dab61cb2957d2345},
	abstract = {This study addresses the challenges of extracting and analyzing biomedical information from vast amounts of unstructured text data using Large Language Models (LLMs). With the advent of big data and advancements in AI, traditional methods of manual data processing are no longer sufficient. Leveraging LLMs, such as the Qwen 115B model, specifically tailored for the biomedical domain, we propose a novel method that facilitates efficient knowledge extraction and integration. This method not only automates the extraction of valuable medical knowledge from unstructured texts but also structures this knowledge into a knowledge graph, aiding clinical decision-making and scientific research. Through specialized fine-tuning and advanced frameworks for information extraction, our approach demonstrates superior performance in handling biomedical text data. Comparative experiments and real-world applications validate the effectiveness of our method in tasks such as diagnostic assistance, drug discovery, and disease prediction, showcasing its potential impact on healthcare and biomedical sciences. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2025.},
	author_keywords = {Biomedical Information; Knowledge Graphs; Large Language Models},
	keywords = {Biomedical domain; Biomedical information; Knowledge extraction; Knowledge graphs; Knowledge integration; Language model; Large language model; Novel methods; Text data; Unstructured texts; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Venkatasubramanian2025,
	author = {Venkatasubramanian, Venkat and Chakraborty, Arijit},
	title = {Quo Vadis ChatGPT? From large language models to Large Knowledge Models},
	year = {2025},
	journal = {Computers and Chemical Engineering},
	volume = {192},
	doi = {10.1016/j.compchemeng.2024.108895},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213832539&doi=10.1016%2fj.compchemeng.2024.108895&partnerID=40&md5=2e27466cb9e609a9258e383a61c8b5f6},
	abstract = {The startling success of ChatGPT and other large language models (LLMs) using transformer-based generative neural network architecture in applications such as natural language processing and image synthesis has many researchers excited about potential opportunities in process systems engineering (PSE). The almost human-like performance of LLMs in these areas is indeed very impressive, surprising, and a major breakthrough. Their capabilities are very useful in certain tasks, such as writing first drafts of documents, code writing assistance, text summarization, etc. However, their success is limited in highly scientific domains as they cannot yet reason, plan, or explain due to their lack of in-depth mechanistic domain knowledge. This is a problem in domains such as chemical engineering as they are governed by fundamental laws of physics and chemistry (and biology), constitutive relations, and highly technical knowledge about materials, processes, and systems. Although purely data-driven machine learning has its immediate uses, the long-term success of AI in scientific and engineering domains would depend on developing hybrid AI systems that combine first principles and technical knowledge effectively. We call these hybrid AI systems Large Knowledge Models (LKMs), as they will not be limited to only NLP-based techniques or NLP-like applications. In this paper, we discuss the challenges and opportunities in developing such systems in chemical engineering. © 2024 The Authors},
	author_keywords = {Artificial intelligence; Domain-specific language processing; Hybrid AI; Knowledge graph; Large language model; Machine learning},
	keywords = {Adversarial machine learning; Contrastive Learning; Generative adversarial networks; Hybrid materials; Knowledge graph; Natural language processing systems; AI systems; Domain-specific language processing; Domains specific languages; Hybrid AI; Knowledge graphs; Knowledge model; Language model; Language processing; Large language model; Machine-learning; Domain Knowledge},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Lazzarinetti2025214,
	author = {Lazzarinetti, Giorgio and Manzoni, Sara and Zoppis, Italo},
	title = {Automating Resume Analysis: Knowledge Graphs via Prompt Engineering},
	year = {2025},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) },
	volume = {15450 LNAI},
	pages = {214 – 227},
	doi = {10.1007/978-3-031-80607-0_17},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215666790&doi=10.1007%2f978-3-031-80607-0_17&partnerID=40&md5=5cd85f1105032b76903f528479bc11d6},
	abstract = {The rapid digitization of recruitment processes and the growing complexity of resume data have posed significant challenges in managing and extracting information from such sources. Traditional methods necessitate innovative approaches that can adapt and scale effectively. This paper introduces a methodology employing Large Language Models (LLMs) facilitated by advanced prompt engineering techniques, to construct Knowledge Graphs (KGs) directly from resumes. Our approach bypasses the extensive customization typically required for domain-specific tasks, leveraging the intrinsic capabilities of LLMs to interpret and organize complex data. We evaluate our methodology, focusing particularly on Named Entity Recognition (NER) as a measure of effectiveness. The results demonstrate superior performance of our system against baseline models. Additionally, we explore the practical applicability of our system through a novel self-consistency metric, which further attests to the method’s ability to accurately capture and reproduce essential resume information in KG format. This study not only underscores the potential of LLMs in automated information extraction but also opens up new avenues for research and application in the HR technology domain and beyond. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.},
	author_keywords = {Deep Learning; Knowledge Graph; Large Language Model; Prompt Engineering; Resume Analysis; Text to Graph},
	keywords = {Deep learning; Deep learning; Digitisation; Extracting information; Knowledge graphs; Language model; Large language model; Prompt engineering; Recruitment process; Resume analyze; Text to graph; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Qiao2025,
	author = {Qiao, Guanhua and Zhang, Dachuan and Zhang, Nana and Shen, Xiaotao and Jiao, Xidong and Lu, Wenwei and Fan, Daming and Zhao, Jianxin and Zhang, Hao and Chen, Wei and Zhu, Jinlin},
	title = {Food recommendation towards personalized wellbeing},
	year = {2025},
	journal = {Trends in Food Science and Technology},
	volume = {156},
	doi = {10.1016/j.tifs.2025.104877},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215215573&doi=10.1016%2fj.tifs.2025.104877&partnerID=40&md5=f37ce0e01e8363611b0f94d111fb03da},
	abstract = {Background: The intersection of nutrition and technology gave birth to the research of food recommendation system (FRS), which marked the transformation of traditional diet to a more personalized and healthy direction. The FRS uses advanced data analysis and machine learning technology to provide customized dietary advice according to users' personal preferences, and nutritional needs, which plays a vital role in promoting public health and reducing disease risks. Scope and approach: This review presents the architecture of FRS and deeply discusses various recommendation algorithms, including the content-based method, collaborative filtering method, knowledge graph-based method, and hybrid methods. The review further introduces existing data resources and evaluation metrics, and highlights key technologies in user profiling and food analysis. In addition, the wide application of personalized FRS is summarized, and the importance of these systems in satisfying users' dietary preferences and maintaining balanced nutrition is emphasized. Finally, the key challenges and development trends of FRS are deeply analyzed from data level, model level and user experience level. Key findings and conclusions: Personalized FRS shows great potential in helping users make healthier dietary decisions. Although there are still many challenges, such as dealing with heterogeneous data and interpretability. But with the progress of technology, there will be broader development in the future. For example, the powerful data processing ability of deep learning will effectively improve the accuracy of the system. In addition, the application of interactive recommendation system and large language model will also provide strong support for satisfying user experience and improving acceptance. © 2025 Elsevier Ltd},
	author_keywords = {Food recommendation system; Machine learning; Personalized diet; Precision nutrition; Recommendation algorithm},
	keywords = {Food recommendation system; Machine learning technology; Machine-learning; Personal preferences; Personalized diet; Precision nutrition; Recommendation algorithms; System use; Users' experiences; Wellbeing},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Chen2025,
	author = {Chen, Guojun and Chen, Panfeng and Wang, Qi and Li, Hui and Zhou, Xin and Wang, Xibin and Yu, Aihua and Deng, Xingzhi},
	title = {EMGE: Entities and Mentions Gradual Enhancement with semantics and connection modelling for document-level relation extraction},
	year = {2025},
	journal = {Knowledge-Based Systems},
	volume = {309},
	doi = {10.1016/j.knosys.2024.112777},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210609637&doi=10.1016%2fj.knosys.2024.112777&partnerID=40&md5=c3aeb07ad3d24f6c80264768381658ac},
	abstract = {Relation extraction is the process of identifying connections between entities in unstructured text and is a critical component of entity-centred information extraction to uncover latent knowledge structures in complex documents. Although graph-based methods have pushed the state-of-the-art forward in relation extraction, current approaches still exhibit limitations. These include incomplete capture of graph structural features, inadequate modelling of long-distance dependencies and imprecise representation of complex entity interactions. A novel Entities and Mentions Gradual Enhancement framework called EMGE is proposed. It integrates both contextual and structural information to robustly enhance entity representations for document-level relation extraction. It comprises three primary components: 1) a dynamic relation aware enhancement mechanism to comprehensively encode graph structural features; 2) a multi-scale feature enhancement module to effectively capture long-distance dependencies; and 3) an entity-mention pair enhancement mechanism to yield precise representations of classification targets. Extensive empirical evaluation on five widely-adopted datasets demonstrates that EMGE achieves promising performance. Particularly noteworthy are the substantial gains obtained on the challenging CDR dataset, where EMGE achieved relative improvements of 1.5%, 8.8%, and 3.5% over the strongest baseline in terms of the Intra-F1, Inter-F1 and Overall-F1 metrics, respectively. Further experimental results demonstrate that the proposed model outperforms the popular large language model in relation extraction tasks. Our code is available on github. 1 © 2024 Elsevier B.V.},
	author_keywords = {Document-level relation extraction; Graph structures; Knowledge enhancement; Long-distance dependency},
	keywords = {Semantics; Connection model; Document-level relation extraction; Enhancement mechanism; Graph structures; Knowledge enhancement; Long-distance dependencies; Relation extraction; Semantic modelling; Structural feature; Unstructured texts; Knowledge graph},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{2025,
	title = {26th International Conference on Information Integration and Web Intelligence, iiWAS 2024},
	year = {2025},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) },
	volume = {15342 LNCS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212253172&partnerID=40&md5=5f4500486ebf9c039d0e8b8e9d3f35af},
	abstract = {The proceedings contain 52 papers. The special focus in this conference is on Information Integration and Web Intelligence. The topics include: Financial News Classification Using Language Learning Models and Reinforcement Learning; ExtractGPT: Exploring the Potential of Large Language Models for Product Attribute Value Extraction; Feature Extraction for Claim Check-Worthiness Prediction Tasks Using LLM; training Data for Dialogue Generation Considering Philosophies; Finding Adequate Additional Layer of Auxiliary Task in BERT-Based Multi-task Learning; ponzi Scheme Detection and Prevention in Blockchain Platforms Using Machine Learning: A Systematic Literature Review; Cross-Chain Personal Data Exchange on EVM Platforms: Enhancing Transparency, and Equity; Incentivize Peer Review Without Rewarding: Using OSS-Like Citation Pull Request; towards Website X-Ray for Europe’s Municipalities: Unveiling Digital Transformation with Multimodal Embeddings; evolving Applications of Conversational Agents in Healthcare: A Literature Review; hybrid Edge-Cloud Federated Learning: The Case of Lightweight Smoking Detection; anonymization of Unstructured Health Data in Spanish; when Good Enough is the Best Option: Use of Digital Sufficiency to Fight Climate Change; multi-target Feature Selection Method for Predicting User-Level Psychological Status from Text; FIEAP: A Machine Learning Approach for Fair and Interpretable Employee Attrition Prediction; HOCON34k: A Corpus of Hate Speech in Online Comments from German Newspapers; SISIS: Sequence Indexing for SImilarity Search; top-k on Sequences: A New Approach to Enhanced Similarity Search; exploratory Data Analysis of Time Series Using Pre-segmented Clustering; a Data Science Approach for Predicting Soccer Passes Using Positional Data; a Method for Integrating Heterogeneous Data into a Knowledge Graph; predicting Knowledge Graph Updates from Edit Histories; Automatic Extraction of RML-star Mappings from Property Graphs; Exploring the Role of UML in Data Modelling for NoSQL Databases: Position Paper; railway Systems’ Ontologies: A Literature Review and an Alignment Proposal; Combining GraphSAGE and Label Propagation for Node Classification in Graphs.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Sun2025,
	author = {Sun, Lizhuang and Zhang, Peng and Gao, Fang and An, Yuan and Li, Zhixing and Zhao, Yuanwei},
	title = {SF-GPT: A training-free method to enhance capabilities for knowledge graph construction in LLMs},
	year = {2025},
	journal = {Neurocomputing},
	volume = {613},
	doi = {10.1016/j.neucom.2024.128726},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207646223&doi=10.1016%2fj.neucom.2024.128726&partnerID=40&md5=65cff6dae0f8945b04ffeb303be2dbb4},
	abstract = {Knowledge graphs (KGs) are constructed by extracting knowledge triples from text and fusing knowledge, enhancing information retrieval efficiency. Current methods for knowledge triple extraction include ”Pretrain and Fine-tuning” and Large Language Models (LLMs). The former shifts effort from manual extraction to dataset annotation and suffers from performance degradation with different test and training set distributions. LLMs-based methods face errors and incompleteness in extraction. We introduce SF-GPT, a training-free method to address these issues. Firstly, we propose the Entity Extraction Filter (EEF) module to filter triple generation results, addressing evaluation and cleansing challenges. Secondly, we introduce a training-free Entity Alignment Module based on Entity Alias Generation (EAG), tackling semantic richness and interpretability issues in LLM-based knowledge fusion. Finally, our Self-Fusion Subgraph strategy uses multi-response self-fusion and a common entity list to filter triple results, reducing noise from LLMs’ multi-responses. In experiments, SF-GPT showed a 55.5% increase in recall and a 32.6% increase in F1 score on the BDNC dataset compared to the UniRel model trained on the NYT dataset and achieved a 5% improvement in F1 score compared to GPT-4+EEF baseline on the WebNLG dataset in the case of a fusion round of three. SF-GPT offers a promising way to extract knowledge from unstructured information. © 2024 Elsevier B.V.},
	author_keywords = {Knowledge fusion; Knowledge graph; Large language model; Triple extraction},
	keywords = {Entity extractions; F1 scores; Graph construction; Information retrieval efficiency; Knowledge fusion; Knowledge graphs; Language model; Large language model; Multiresponse; Triple extraction; algorithm; Article; artificial intelligence; artificial neural network; classification algorithm; clinical decision support system; entity alias generation; entity extraction filter; human; knowledge; large language model; learning algorithm; machine learning; natural language processing; protein secondary structure; self fusion subgraph for minimizing triple noise; theory construction; training; Knowledge graph},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Hussien2025,
	author = {Hussien, Mohamed Manzour and Melo, Angie Nataly and Ballardini, Augusto Luis and Maldonado, Carlota Salinas and Izquierdo, Rubén and Sotelo, Miguel Ángel},
	title = {RAG-based explainable prediction of road users behaviors for automated driving using knowledge graphs and large language models},
	year = {2025},
	journal = {Expert Systems with Applications},
	volume = {265},
	doi = {10.1016/j.eswa.2024.125914},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210679908&doi=10.1016%2fj.eswa.2024.125914&partnerID=40&md5=40808409602716e384a61d4d0237a45f},
	abstract = {The prediction of road user behaviors in the context of autonomous driving has attracted considerable attention from the scientific community in recent years. Most works focus on predicting behaviors based on kinematic information alone, a simplification of reality since road users are humans, and as such they are highly influenced by their surrounding context. In addition, a large plethora of research works rely on powerful Deep Learning techniques, which exhibit high-performance metrics in prediction tasks but may lack the ability to fully understand and exploit the contextual semantic information contained in the road scene, not to mention their inability to provide explainable predictions that can be understood by humans. In this work, we propose an explainable road users’ behavior prediction system that integrates the reasoning abilities of Knowledge Graphs (KG) and the expressiveness capabilities of Large Language Models (LLM) by using Retrieval Augmented Generation (RAG) techniques. For that purpose, Knowledge Graph Embeddings (KGE) and Bayesian inference are combined to allow the deployment of a fully inductive reasoning system that enables the issuing of predictions that rely on legacy information contained in the graph, as well as on current evidence gathered in real-time by onboard sensors. Two use cases have been implemented following the proposed approach: 1) Prediction of pedestrians’ crossing actions; and 2) Prediction of lane change maneuvers. In both cases, the performance attained exceeds the current state-of-the-art in terms of anticipation and F1 score, showing a promising avenue for future research in this field. © 2024 The Authors},
	author_keywords = {Autonomous driving; Explainable predictions; Lane change maneuvers; Pedestrian crossing actions; Road users’ behaviors},
	keywords = {Footbridges; Motor transportation; Prediction models; Autonomous driving; Explainable prediction; Knowledge graphs; Lane change; Lane change maneuver; Language model; Pedestrian crossing action; Road users; Road user’ behavior; User behaviors; Semantics},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Feng2025367,
	author = {Feng, Tuoyu and Wang, Gangliang and Qiao, Zijian and Li, Weiping and Zhang, Yusong and Guo, Qinglang},
	title = {SbSER: Step-by-Step Enhanced Reasoning Framework for Large Language Model with External Subgraph Generation; [SbSER:基于外部子图生成的大语言模型分步增强推理框架]},
	year = {2025},
	journal = {Journal of Frontiers of Computer Science and Technology},
	volume = {19},
	number = {2},
	pages = {367 – 373},
	doi = {10.3778/j.issn.1673-9418.2409054},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215867935&doi=10.3778%2fj.issn.1673-9418.2409054&partnerID=40&md5=0343b0d4ae022b61e49d0c2f16992e0d},
	abstract = {Large language models (LLMs) have achieved significant success across various tasks, particularly in machine translation, text generation, and question-answering systems since their inception. Their applications have rapidly expanded to more complex tasks. However, despite their impressive performance in many areas, LLMs still face significant challenges in tasks that require deep reasoning and logical deduction. This is mainly due to the fact that during training, LLMs rely heavily on large volumes of textual data, which often fail to comprehensively cover specialized knowledge across all domains. As a result, LLMs tend to generate“hallucinations”in handling domain-specific problems, meaning they output inaccurate or factually incorrect answers. This issue can be mitigated by incorporating external knowledge graphs (KG) to assist in the reasoning process of LLMs. This paper presents the SbSER, a step-by-step enhanced reasoning framework for LLMs with external subgraph generation. Firstly, it guides the LLMs to do accurate semantic parsing through generating clear subgraph Schemas, converting questions into logical retrieval statements. Secondly, it imports knowledge triples into a graph database to complete precise knowledge retrieval. Finally, it achieves the final enhanced reasoning answer through the combination of two reasoning methods: direct retrieval reasoning and joint retrieval reasoning. Experiments demonstrate that the proposed SbSER achieves outstanding results across multiple datasets, significantly enhancing the ability of LLMs to solve complex problems. © 2025 Journal of Computer Engineering and Applications Beijing Co., Ltd.; Science Press. All rights reserved.},
	author_keywords = {large language model; step-by-step reasoning; subgraph generation},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Zeng2025,
	author = {Zeng, Zefan and Cheng, Qing and Hu, Xingchen and Zhuang, Yan and Liu, Xinwang and He, Kunlun and Liu, Zhong},
	title = {KoSEL: Knowledge subgraph enhanced large language model for medical question answering},
	year = {2025},
	journal = {Knowledge-Based Systems},
	volume = {309},
	doi = {10.1016/j.knosys.2024.112837},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211386228&doi=10.1016%2fj.knosys.2024.112837&partnerID=40&md5=47b64b65fe886ebc309e6934cc741341},
	abstract = {The integration of medical knowledge graphs (KGs) and large language models (LLMs) for medical question answering (Q&A) has attracted considerable interest in recent studies. However, current approaches that combine KGs and LLMs tend to either integrate KGs directly into the fine-tuning process of LLMs or use entire KGs as a contextual prompt base for LLMs to reason, raising concerns regarding potential data leakage and reasoning confusion. In this study, we propose KoSEL (Knowledge Subgraph Enhanced Large Language Model), a novel medical Q&A framework based on KG-enhanced LLMs. KoSEL comprises two modules: Knowledge Retrieval (KR) and Reasoning and Answering (RA). The KR module is LLM-independent and employs an entity-linking algorithm and a subgraph construction and fusion strategy to retrieve question-relevant knowledge. The RA module conveys prompts to the LLM for information extraction, knowledge fusion, reasoning, and answer generation. KoSEL, which is designed as a plug-and-play framework, effectively fuses structural and textual knowledge while ensuring efficiency and privacy. The construction of a precise and refined subgraph reduces knowledge noise and the number of input graph tokens, thus mitigating hallucination issues. Extensive experiments demonstrated that KoSEL outperformed advanced methods in terms of knowledge retrieval efficiency (20.27% reduction in retrieval time), knowledge utilization (15.16% increase in utilization rate), and data protection (113.50% reduction in data leakage rate), resulting in higher-quality answers for medical Q&A tasks (1.50% improvement in answer score). © 2024},
	author_keywords = {Domain-specific; Knowledge graph; Large language model; Medical question answering; Privacy; Retrieval},
	keywords = {Data privacy; Differential privacy; Information leakage; Knowledge graph; Modeling languages; Data leakage; Domain specific; Knowledge graphs; Knowledge retrieval; Language model; Large language model; Medical question answering; Privacy; Retrieval; Subgraphs; Question answering},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{2025,
	title = {23rd International Conference of the Italian Association for Artificial Intelligence, AIxIA 2024},
	year = {2025},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) },
	volume = {15450 LNAI},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215701776&partnerID=40&md5=f50880624ac7fb3d5504443badcc2adb},
	abstract = {The proceedings contain 25 papers. The special focus in this conference is on Italian Association for Artificial Intelligence. The topics include: A Novel Approach for Leveraging Agent-Based Experts on Large Language Models to Enable Data Sharing Among Heterogeneous IoT Devices in Agriculture; an Extensive Empirical Analysis of Macro-actions for Numeric Planning; feature Selection on Contextual Embedding Pushing the Sparseness; neuro-Symbolic Integration for Open Set Recognition in Network Intrusion Detection; MM-IGLU-IT: Multi-modal Interactive Grounded Language Understanding in Italian; IDADA: A Blended Inductive-Deductive Approach for Data Augmentation; HaWANet: Road Scene Understanding with Multi-modal Sensor Data Using Height-Width-Driven Attention Network; hybrid Classification of European Legislation Using Sustainable Development Goals; supporting Decision-Making for City Management Through Automated Planning and Execution; NutriWell: An Explainable Ontology-Based FoodAI Service for Nutrition and Health Management; regular Clocks for Temporal Task Specifications in Reinforcement Learning; a Real-Time Support with Haptic Feedback for Safer Driving Using Monocular Camera; relating Explanations with the Inductive Biases of Deep Graph Networks; integrating Temporal Planning and Knowledge Representation to Generate Personalized Touristic Itineraries; ASR Systems Under Acoustic Challenges: A Multilingual Study; automating Resume Analysis: Knowledge Graphs via Prompt Engineering; combined Text-Visual Attention Models for Robot Task Learning and Execution; ICE: An Evaluation Metric to Assess Symbolic Knowledge Quality; hierarchical Knowledge Extraction from Opaque Machine Learning Predictors; on Different Symbolic Music Representations for Algorithmic Composition Approaches Based on Neural Sequence Models; DR-Minerva: A Multimodal Language Model Based on Minerva for Diagnostic Information Retrieval; REPAIR Platform: Robot-AidEd PersonAlIzed Rehabilitation; Integrating Classical Planners with GPT-Based Planning Policies.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Wadhwa2025237,
	author = {Wadhwa, Somin and Hassanzadeh, Oktie and Bhattacharjya, Debarun and Barker, Ken and Ni, Jian},
	title = {Distilling Event Sequence Knowledge From Large Language Models},
	year = {2025},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) },
	volume = {15231 LNCS},
	pages = {237 – 255},
	doi = {10.1007/978-3-031-77844-5_13},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211225740&doi=10.1007%2f978-3-031-77844-5_13&partnerID=40&md5=862f4f67e22fb9fc7bc18b1db54af556},
	abstract = {Event sequence models have been found to be highly effective in the analysis and prediction of events. Building such models requires availability of abundant high-quality event sequence data. In certain applications, however, clean structured event sequences are not available, and automated sequence extraction results in data that is too noisy and incomplete. In this work, we explore the use of Large Language Models (LLMs) to generate event sequences that can effectively be used for probabilistic event model construction. This can be viewed as a mechanism of distilling event sequence knowledge from LLMs. Our approach relies on a Knowledge Graph (KG) of event concepts with partial causal relations to guide the generative language model for causal event sequence generation. We show that our approach can generate high-quality event sequences, filling a knowledge gap in the input KG. Furthermore, we explore how the generated sequences can be leveraged to discover useful and more complex structured knowledge from pattern mining and probabilistic event models. We release our sequence generation code and evaluation framework, as well as corpus of event sequence data. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.},
	author_keywords = {Knowledge Distillation; Knowledge Graphs; Large Language Models},
	keywords = {Event model; Event sequence; High quality; Knowledge distillation; Knowledge graphs; Language model; Large language model; Probabilistics; Sequence data; Sequence generation; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Vollmers2025174,
	author = {Vollmers, Daniel and Srivastava, Nikit and Zahera, Hamada M. and Moussallem, Diego and Ngomo, Axel-Cyrille Ngonga},
	title = {UniQ-Gen: Unified Query Generation Across Multiple Knowledge Graphs},
	year = {2025},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) },
	volume = {15370 LNAI},
	pages = {174 – 189},
	doi = {10.1007/978-3-031-77792-9_11},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210886308&doi=10.1007%2f978-3-031-77792-9_11&partnerID=40&md5=6960ea1dfd6ae04dd1b52b024bfa2dc1},
	abstract = {Generating SPARQL queries is crucial for extracting relevant information from diverse knowledge graphs. However, the structural and semantic differences among these graphs necessitate training or fine-tuning a tailored model for each one. In this paper, we propose UniQ-Gen, a unified query generation approach to generate SPARQL queries across various knowledge graphs. UniQ-Gen integrates entity recognition, disambiguation, and linking through a BERT-NER model and employs cross-encoder ranking to align questions with the Freebase ontology. We conducted several experiments on different benchmark datasets such as LC-QuAD 2.0, GrailQA, and QALD-10. The evaluation results demonstrate that our approach achieves performance equivalent to or better than models fine-tuned for individual knowledge graphs. This finding suggests that fine-tuning a unified model on a heterogeneous dataset of SPARQL queries across different knowledge graphs eliminates the need for separate models for each graph, thereby reducing resource requirements. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.},
	author_keywords = {KGQA; Large Language Models; Question Answering over Knowledge Graphs; SPARQL Generation},
	keywords = {Query languages; Question answering; Semantics; Structured Query Language; Fine tuning; KGQA; Knowledge graphs; Language model; Large language model; Query generation; Question Answering; Question answering over knowledge graph; SPARQL generation; Structural differences; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Jaldi2025,
	author = {Jaldi, Chris Davis and Ilkou, Eleni and Schroeder, Noah and Shimizu, Cogan},
	title = {Education in the era of Neurosymbolic AI},
	year = {2025},
	journal = {Journal of Web Semantics},
	volume = {85},
	doi = {10.1016/j.websem.2024.100857},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214136464&doi=10.1016%2fj.websem.2024.100857&partnerID=40&md5=78714176ec42864d85c7cafa1d295b16},
	abstract = {Education is poised for a transformative shift with the advent of neurosymbolic artificial intelligence (NAI), which will redefine how we support deeply adaptive and personalized learning experiences. The integration of Knowledge Graphs (KGs) with Large Language Models (LLMs), a significant and popular form of NAI, presents a promising avenue for advancing personalized instruction via neurosymbolic educational agents. By leveraging structured knowledge, these agents can provide individualized learning experiences that align with specific learner preferences and desired learning paths, while also mitigating biases inherent in traditional AI systems. NAI-powered education systems will be capable of interpreting complex human concepts and contexts while employing advanced problem-solving strategies, all grounded in established pedagogical frameworks. In this paper, we propose a system that leverages the unique affordances of KGs, LLMs, and pedagogical agents – embodied characters designed to enhance learning – as critical components of a hybrid NAI architecture. We discuss the rationale for our system design and the preliminary findings of our work. We conclude that education in the era of NAI will make learning more accessible, equitable, and aligned with real-world skills. This is an era that will explore a new depth of understanding in educational tools. © 2025 The Authors},
	author_keywords = {Agents; Education; Knowledge graphs; Large language models; Neurosymbolic AI},
	keywords = {Adversarial machine learning; Contrastive Learning; Federated learning; Problem solving; Adaptive learning; Educational agents; Integration of knowledge; Knowledge graphs; Language model; Large language model; Learning experiences; Neurosymbolic AI; Personalized instruction; Personalized learning; Knowledge graph},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Erickson2025,
	author = {Erickson, John S. and Santos, Henrique and Pinheiro, Vládia and McCusker, Jamie P. and McGuinness, Deborah L.},
	title = {LLM experimentation through knowledge graphs: Towards improved management, repeatability, and verification},
	year = {2025},
	journal = {Journal of Web Semantics},
	volume = {85},
	doi = {10.1016/j.websem.2024.100853},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214468074&doi=10.1016%2fj.websem.2024.100853&partnerID=40&md5=a62753e1399494f61fca9291379a09ae},
	abstract = {Generative large language models (LLMs) have transformed AI by enabling rapid, human-like text generation, but they face challenges, including managing inaccurate information generation. Strategies such as prompt engineering, Retrieval-Augmented Generation (RAG), and incorporating domain-specific Knowledge Graphs (KGs) aim to address their issues. However, challenges remain in achieving the desired levels of management, repeatability, and verification of experiments, especially for developers using closed-access LLMs via web APIs, complicating integration with external tools. To tackle this, we are exploring a software architecture to enhance LLM workflows by prioritizing flexibility and traceability while promoting more accurate and explainable outputs. We describe our approach and provide a nutrition case study demonstrating its ability to integrate LLMs with RAG and KGs for more robust AI solutions. © 2025 The Authors},
	author_keywords = {Explainability and governance in AI; Generative large language models; Knowledge graphs; Retrieval-Augmented Generation},
	keywords = {Generative adversarial networks; Information management; Explainability and governance in AI; Generative large language model; Human like; Inaccurate information; Information generation; Knowledge graphs; Language model; Model experimentations; Retrieval-augmented generation; Text generations; Knowledge graph},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Li2025,
	author = {Li, Chao and Petzold, Frank},
	title = {Ontology-Driven Mixture-of-Domain Documentation: A Backbone Approach Enabling Question Answering for Additive Construction},
	year = {2025},
	journal = {Buildings},
	volume = {15},
	number = {1},
	doi = {10.3390/buildings15010133},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214466051&doi=10.3390%2fbuildings15010133&partnerID=40&md5=dd579bc34759f9f809a86450ef5e2806},
	abstract = {Advanced construction techniques, such as additive manufacturing (AM) and modular construction, offer promising solutions to address labor shortages, reduce CO2 emissions, and enhance material efficiency. Despite their potential, the adoption of these innovative methods is hindered by the construction industry’s fragmented expertise. Building Information Modeling (BIM) is frequently suggested to integrate this diverse knowledge, but existing BIM-based approaches lack a robust framework for systematically documenting and retrieving the cross-domain knowledge essential for construction projects. To bridge this gap, this paper presents an ontology-driven methodology for documenting and utilizing expert knowledge, with a focus on AM in construction. Based on a well-founded ontological framework, a set of modular ontologies is formalized for individual domains. Additionally, a prototypical documentation tool is developed to elevate recorded information and BIM models as a knowledge graph. This knowledge graph will interface with advanced large language models (LLMs), enabling effective question answering and knowledge retrieval. © 2025 by the authors.},
	author_keywords = {additive construction; building information modeling; documentation; ontology},
	keywords = {Knowledge graph; Modeling languages; Ontology; Additive construction; Advanced construction; Building Information Modelling; Construction technique; Documentation; Knowledge graphs; Labor shortages; Modulars; Ontology's; Question Answering; Question answering},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Diamant2025D1016,
	author = {Diamant, Ido and Clarke, Daniel J. B and Evangelista, John Erol and Lingam, Nathania and Ma'Ayan, Avi},
	title = {Harmonizome 3.0: Integrated knowledge about genes and proteins from diverse multi-omics resources},
	year = {2025},
	journal = {Nucleic Acids Research},
	volume = {53},
	number = {D1},
	pages = {D1016 – D1028},
	doi = {10.1093/nar/gkae1080},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214585404&doi=10.1093%2fnar%2fgkae1080&partnerID=40&md5=7c329a8c9f2ce3c7f9747ceda61ea4b9},
	abstract = {By processing and abstracting diverse omics datasets into associations between genes and their attributes, the Harmonizome database enables researchers to explore and integrate knowledge about human genes from many central omics resources. Here, we introduce Harmonizome 3.0, a significant upgrade to the original Harmonizome database. The upgrade adds 26 datasets that contribute nearly 12 million associations between genes and various attribute types such as cells and tissues, diseases, and pathways. The upgrade has a dataset crossing feature to identify gene modules that are shared across datasets. To further explain significantly high gene set overlap between dataset pairs, a large language model (LLM) composes a paragraph that speculates about the reasons behind the high overlap. The upgrade also adds more data formats and visualization options. Datasets are downloadable as knowledge graph (KG) assertions and visualized with Uniform Manifold Approximation and Projection (UMAP) plots. The KG assertions can be explored via a user interface that visualizes gene-Attribute associations as ball-And-stick diagrams. Overall, Harmonizome 3.0 is a rich resource of processed omics datasets that are provided in several AI-ready formats. Harmonizome 3.0 is available at https://maayanlab.cloud/Harmonizome/.  © 2025 The Author(s) 2024.},
	keywords = {Databases, Genetic; Genes; Genomics; Humans; Internet; Multiomics; Proteins; Software; User-Computer Interface; protein; adult; article; assertiveness; gene; gene regulatory network; human; large language model; multiomics; omics; computer interface; gene; genetic database; genetics; genomics; Internet; metabolism; multiomics; procedures; software},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Gold Open Access}
}

@ARTICLE{Zhang2025,
	author = {Zhang, Yongheng and Du, Tingwen and Ma, Yunshan and Wang, Xiang and Xie, Yi and Yang, Guozheng and Lu, Yuliang and Chang, Ee-Chien},
	title = {AttacKG+: Boosting attack graph construction with Large Language Models},
	year = {2025},
	journal = {Computers and Security},
	volume = {150},
	doi = {10.1016/j.cose.2024.104220},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211989672&doi=10.1016%2fj.cose.2024.104220&partnerID=40&md5=36a3a3f32f0145c01a83b8282441c9ad},
	abstract = {Attack graph construction seeks to convert textual cyber threat intelligence (CTI) reports into structured representations, portraying the evolutionary traces of cyber attacks. Even though previous research has proposed various methods to construct attack graphs, they generally suffer from limited generalization capability to diverse knowledge types as well as requirement of expertise in model design and tuning. Addressing these limitations, we seek to utilize Large Language Models (LLMs), which have achieved enormous success in a broad range of tasks given exceptional capabilities in both language understanding and zero-shot task fulfillment. Thus, we propose a fully automatic LLM-based framework to construct attack graphs named: AttacKG+. Our framework consists of four consecutive modules: rewriter, parser, identifier, and summarizer, each of which is implemented by instruction prompting and in-context learning empowered by LLMs. Furthermore, we upgrade the existing attack knowledge schema and propose a comprehensive version. We represent a cyber attack as a temporally unfolding event, each temporal step of which encapsulates three layers of representation, including behavior graph, MITRE TTP labels, and state summary. Extensive evaluation demonstrates that: (1) our formulation seamlessly satisfies the information needs in threat event analysis, (2) our construction framework is effective in faithfully and accurately extracting the information defined by AttacKG+. and (3) our attack graph directly benefits downstream security practices such as attack reconstruction. All the code and datasets will be released upon acceptance. © 2024 The Authors},
	author_keywords = {Attack graph construction; Cyber threat intelligence analysis; Large Language Models},
	keywords = {Computer viruses; Knowledge graph; Attack graph; Attack graph construction; Cybe threat intelligence analyze; Cyber threats; Cyber-attacks; Evolutionary traces; Graph construction; Intelligence analysis; Language model; Large language model; Cyber attacks},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Freidel2025180,
	author = {Freidel, Sebastian and Schwarz, Emanuel},
	title = {Knowledge graphs in psychiatric research: Potential applications and future perspectives},
	year = {2025},
	journal = {Acta Psychiatrica Scandinavica},
	volume = {151},
	number = {3},
	pages = {180 – 191},
	doi = {10.1111/acps.13717},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196153702&doi=10.1111%2facps.13717&partnerID=40&md5=bad36025f29abc2db3e55680558a98bb},
	abstract = {Background: Knowledge graphs (KGs) remain an underutilized tool in the field of psychiatric research. In the broader biomedical field KGs are already a significant tool mainly used as knowledge database or for novel relation detection between biomedical entities. This review aims to outline how KGs would further research in the field of psychiatry in the age of Artificial Intelligence (AI) and Large Language Models (LLMs). Methods: We conducted a thorough literature review across a spectrum of scientific fields ranging from computer science and knowledge engineering to bioinformatics. The literature reviewed was taken from PubMed, Semantic Scholar and Google Scholar searches including terms such as “Psychiatric Knowledge Graphs”, “Biomedical Knowledge Graphs”, “Knowledge Graph Machine Learning Applications”, “Knowledge Graph Applications for Biomedical Sciences”. The resulting publications were then assessed and accumulated in this review regarding their possible relevance to future psychiatric applications. Results: A multitude of papers and applications of KGs in associated research fields that are yet to be utilized in psychiatric research was found and outlined in this review. We create a thorough recommendation for other computational researchers regarding use-cases of these KG applications in psychiatry. Conclusion: This review illustrates use-cases of KG-based research applications in biomedicine and beyond that may aid in elucidating the complex biology of psychiatric illness and open new routes for developing innovative interventions. We conclude that there is a wealth of opportunities for KG utilization in psychiatric research across a variety of application areas including biomarker discovery, patient stratification and personalized medicine approaches. © 2024 The Author(s). Acta Psychiatrica Scandinavica published by John Wiley & Sons Ltd.},
	author_keywords = {knowledge graphs; machine learning; personalized medicine; psychiatry},
	keywords = {artificial intelligence; digital twin; human; knowledge graph; large language model; machine learning; medical research; mental disease; mental disease assessment; psychiatry; Review},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{2025,
	title = {17th International Conference on Interactive Digital Storytelling, ICIDS 2024},
	year = {2025},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) },
	volume = {15467 LNCS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214081243&partnerID=40&md5=0e94bd9d015448a048ad906b50cf555b},
	abstract = {The proceedings contain 41 papers. The special focus in this conference is on Interactive Digital Storytelling. The topics include: Where’s the Finance?: A Transmedia Storytelling Experience to Engage Young Adults in Financial Educational Content; navigating Sexualization: A Thematic Analysis of Sexualized Character Design in Modern Video Game Narratives; emotional Believability of Non-playable Game Characters - Animations of Anger, Sadness and Happiness; Finding Queerness in Gaming: How Players See LGBTQ+ Themes in Non-queer Games; popcorn Movie: Dynamic Narrative Feedback for Spontaneous Live Action Video Storytelling; DreaMR: The Effects of Multisensory Design on Cross-Modal Perception Across Genres with Mixed Reality Concert; building Visual Novels with Social Simulation and Storylets; a Tool for the Calculation of Characters’ Emotions; teaching Data Storytelling in a Computational Thinking Course for Students in Communications Careers; el Centro (The Downtown): A Collaborative Transmedia Project Among Ibero-American Universities; subliminal Teaching for Elderly People Through Crossmedia Storytelling; affective Sound: Developing a Critical Framework for Audio-Based Interactive Digital Narratives; What if We Educated Students Assuming They can Think? Introducing the Critical Education Framework (CEF) for Interactive Narratives, Games and Related Fields; fostering Empathy Through Inclusive Interactive Digital Narratives; interactive Digital Narratives for Modern Historical Research; design of Knowledge Graphs for Interactive Digital Narratives Authoring; Being Water: Collaborating with an LLM in an Interactive Digital Narrative (IDN) as Speculative Aesthetics; Exploring Collaborative Interactive Digital Narrative Creation in Higher Education Through Narrative Analysis: A Case Study on COVID-19 Storytelling; The IDN Design Model: A Proposal for an Extended SPP Model.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Wang2025,
	author = {Wang, Zhenhua and Chen, Huiru and Xu, Guang and Ren, Ming},
	title = {A novel large-language-model-driven framework for named entity recognition},
	year = {2025},
	journal = {Information Processing and Management},
	volume = {62},
	number = {3},
	doi = {10.1016/j.ipm.2024.104054},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213205016&doi=10.1016%2fj.ipm.2024.104054&partnerID=40&md5=6537ee24b71a3b4a5a056e9f0115b8f3},
	abstract = {Named entity recognition (NER) stands as the foundational pillar of knowledge graphs across multiple domains. Despite progress in NER using large language models (LLMs), challenges persist regarding the selection of LLMs, the retrieval of demonstrations, and the design of prompts. We introduce a novel framework for NER, termed LLMCC, which elucidates the synergistic interactions between different LLMs. Two new methods, SemnRank and InforLaw-thought, are proposed to address the issue of redundancy in demonstrations and to elevate prompt quality for boosting LLM's capabilities. Furthermore, LLMCC is trained through a new entity-aware contrastive learning. Extensive experiments across five domains confirm the competitiveness of LLMCC (surpassing ten recent studies by a margin of over 5% in F1 score), as well as the effectiveness of SemnRank and InforLaw-thought. We uncover a series of insights regarding information laws, prompting strategies, demonstration selections, and training designs. This research significantly advances the incorporation of LLMs into the construction of knowledge graphs. © 2024 Elsevier Ltd},
	author_keywords = {Contrastive learning; In-context learning; Knowledge graph; Large language model; Named entity recognition},
	keywords = {Adversarial machine learning; Knowledge graph; Context learning; In contexts; In-context learning; Knowledge graphs; Language model; Large language model; Model-driven; Multiple domains; Named entity recognition; Synergistic interaction; Contrastive Learning},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{d'Aquin2025,
	author = {d'Aquin, Mathieu},
	title = {On the role of knowledge graphs in AI-based scientific discovery},
	year = {2025},
	journal = {Journal of Web Semantics},
	volume = {84},
	doi = {10.1016/j.websem.2024.100854},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213265517&doi=10.1016%2fj.websem.2024.100854&partnerID=40&md5=88ba80101d5cc60fbc9ddc4433c50dd6},
	abstract = {Research and the scientific activity are widely seen as an area where the current trends in AI, namely the development of deep learning models (including large language models), are having an increasing impact. Indeed, the ability of such models to extrapolate from data, seemingly finding unknown patterns relating implicit features of the objects under study to their properties can, at the very least, help accelerate and scale up those studies as demonstrated in fields such as molecular biology and chemistry. Knowledge graphs, on the other hand, have more traditionally been used to organize information around the scientific activity, keeping track of existing knowledge, of conducted experiments, of interactions within the research community, etc. However, for machine learning models to be truly used as a tool for scientific advancement, we have to find ways for the knowledge implicitly gained by these models from their training to be integrated with the explicitly represented knowledge captured through knowledge graphs. Based on our experience in ongoing projects in the domain of material science, in this position paper, we discuss the role that knowledge graphs can play in new methodologies for scientific discovery. These methodologies are based on the creation of large and opaque neural models. We therefore focus on the research challenges we need to address to support aligning such neural models to knowledge graphs for them to become a knowledge-level interface to those neural models. © 2024 The Author},
	author_keywords = {Interpretability; Knowledge graphs; Machine learning; Scientific discovery},
	keywords = {Adversarial machine learning; Contrastive Learning; Federated learning; 'current; Implicit features; Interpretability; Knowledge graphs; Language model; Learning models; Machine-learning; Neural modelling; Scientific activity; Scientific discovery; Knowledge graph},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Albayrak2025,
	author = {Albayrak, Abdulkadir and Xiao, Yao and Mukherjee, Piyush and Barnett, Sarah S. and Marcou, Cherisse A. and Hart, Steven N.},
	title = {Enhancing human phenotype ontology term extraction through synthetic case reports and embedding-based retrieval: A novel approach for improved biomedical data annotation},
	year = {2025},
	journal = {Journal of Pathology Informatics},
	volume = {16},
	doi = {10.1016/j.jpi.2024.100409},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211050660&doi=10.1016%2fj.jpi.2024.100409&partnerID=40&md5=5230b3947886df032f1be71d84c72453},
	abstract = {With the increasing utilization of exome and genome sequencing in clinical and research genetics, accurate and automated extraction of human phenotype ontology (HPO) terms from clinical texts has become imperative. Traditional methods for HPO term extraction, such as PhenoTagger, often face limitations in coverage and precision. In this study, we propose a novel approach that leverages large language models (LLMs) to generate synthetic sentences with clinical context, which were semantically encoded into vector embeddings. These embeddings are linked to HPO terms, creating a robust knowledgebase that facilitates precise information retrieval. Our method circumvents the known issue of LLM hallucinations by storing and querying these embeddings within a true database, ensuring accurate context matching without the need for a predictive model. We evaluated the performance of three different embedding models, all of which demonstrated substantial improvements over PhenoTagger. Top recall (sensitivity), precision (positive-predictive value, PPV), and F1 are 0.64, 0.64, and 0.64, respectively, which were 31%, 10%, and 21% better than PhenoTagger. Furthermore, optimal performance was achieved when we combined the best performing embedding model with PhenoTagger (a.k.a. Fused model), resulting in recall (sensitivity), precision (PPV), and F1 values of 0.7, 0.7, and 0.7, respectively, which are 10%, 10%, and 10% better than the best embedding models. Our findings underscore the potential of this integrated approach to enhance the precision and reliability of HPO term extraction, offering a scalable and effective solution for biomedical data annotation. © 2024 The Authors},
	author_keywords = {Human phenotype ontology; PhenoTagger; Vector embeddings},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Yu2025,
	author = {Yu, Pengfei and Gu, Jingjing and Pi, Dechang and Zhou, Qiang and Wang, Qiuhong},
	title = {Aspect-Aware Graph Interaction Attention Network for Aspect Category Sentiment Analysis},
	year = {2025},
	journal = {IEEE Transactions on Emerging Topics in Computational Intelligence},
	doi = {10.1109/TETCI.2025.3526285},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216847521&doi=10.1109%2fTETCI.2025.3526285&partnerID=40&md5=33a1b79e5030990268bf4ab5d7f760dd},
	abstract = {This paper explores an implicit Aspect Category Sentiment Analysis task, which aims to determine the sentiment polarities of given aspect categories in social reviews. Currently, most researchers focus more on explicit aspect and rarely work on implicit aspect. Meanwhile, due to the semantic complexity of natural language, it is difficult for existing methods to retrieve such implicit semantics in sentences. To this end, we propose a novel framework, the Aspect-aware Graph Interaction Attention Network (AGIAN), which concentrates on aspect-related information implicitly in sentences and identifies its corresponding sentiment polarity. Specifically, first, we introduce an aspect-aware graph to represent potential associations between the implicit aspect category and the sentence. Then, we utilize two types of graph neural networks to extract rich relational semantics. Finally, we design a graph interaction mechanism to integrate sentiment features specific to the aspect category for sentiment classification. We evaluate the performance of the proposed framework on six publicly available benchmark datasets. Extensive experiments demonstrate that, compared to some competitive baseline methods, AGIAN can effectively improve accuracy and achieve state-of-the-art performance on the F1-score.  © 2025 IEEE.},
	author_keywords = {graph neural network; interaction attention mechanism; large language model; Sentiment analysis; social review},
	keywords = {Knowledge graph; Neural network models; Semantics; Attention mechanisms; Graph neural networks; Implicit semantics; Interaction attention mechanism; Language model; Large language model; Natural languages; Relational semantics; Sentiment analysis; Social review; Graph neural networks},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Zheng2025,
	author = {Zheng, Zhiyu and Marié, Sylvain and Farazdaghi, Elham and Yahia, Esma and Makhoul, Khal and Lagarde, Théo and Meouche, Rani El and Ababsa, Fakhreddine},
	title = {Mastering building management systems data points tagging with minimal examples: unveiling the power of large language models},
	year = {2025},
	journal = {Energy and Buildings},
	volume = {328},
	doi = {10.1016/j.enbuild.2024.115173},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213251513&doi=10.1016%2fj.enbuild.2024.115173&partnerID=40&md5=b95821a2b3052984e4b2ccd433d92dea},
	abstract = {The heterogeneity of metadata within Building Management Systems (BMS) poses substantial challenges for advanced analytics, including cross-building analysis. Over the past decade, metadata standard schemas such as Brick have been developed to address this challenge. Nevertheless, mapping BMS metadata with such standards accurately and efficiently continues to be a demanding task across both new and existing buildings. This work explores the application of Large Language Models (LLMs) to tag BMS data points, thus facilitating metadata standardization efforts. Manual or rule-based methods are not only labor-intensive but also error-prone. Similarly, supervised learning approaches using Machine Learning (ML) and Natural Language Processing ( NLP) demand extensive labeled datasets, often making them laborious and inflexible to new BMS metadata types and tasks. We propose a novel three-step framework that enhances the tagging process by integrating a LLM with few-shot prompting and an embedding model. This approach not only improves result interpretability but also effectively mitigates hallucinations. This framework is further supported by analyses of the LLM's inherent capabilities, prompt-aided specific interpretation and output formatting, and evaluations of few-shot sizes. Tested across five different building datasets, our approach, leveraging few-shot examples, achieves performance comparable to state-of-the-art supervised learning methods that rely on large labeled datasets. © 2024 Elsevier B.V.},
	author_keywords = {Brick Ontology; Building Management Systems; Few-Shot Learning, Prompt Engineering; Large Language Models; Metadata Tagging; Semantic Web Technologies},
	keywords = {Adversarial machine learning; Brick; Labeled data; Natural language processing systems; Ontology; Semantics; Supervised learning; Zero-shot learning; Brick ontology; Building management system; Datapoints; Few-shot learning, prompt engineering; Labeled dataset; Language model; Large language model; Metadata tagging; Ontology's; Semantic Web technology; Self-supervised learning},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Wang2025,
	author = {Wang, Tian and Wang, Ping and Yang, Feng and Wang, Shuai and Fang, Qiang and Chi, Meng},
	title = {Multi large language model collaboration framework for few-shot link prediction in evolutionary fault diagnosis event graphs},
	year = {2025},
	journal = {Journal of Process Control},
	volume = {145},
	doi = {10.1016/j.jprocont.2024.103342},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211021109&doi=10.1016%2fj.jprocont.2024.103342&partnerID=40&md5=51ce5d08a0250841f3a4bec8c7e7f63d},
	abstract = {Fault-tolerant control is crucial for ensuring flight safety in aircraft. However, existing methods for fault diagnosis in nonlinear systems face challenges such as data sparsity, limited generalization, and lack of explainability. To address these challenges, this paper proposes a multi-large language model (LLM) collaboration framework for few-shot link prediction in evolutionary fault diagnosis event graphs. The framework consists of two modules: the Clustering Language Model (LMc) and the Prediction Language Model (LMP). LMc utilizes the semantic understanding capabilities of LLMs to cluster entities and decompose large-scale graph data into smaller subgraphs, mitigating the impact of data sparsity on link prediction. LMP leverages the reasoning capabilities of LLMs to perform link prediction within each subgraph and fuses the prediction results to enhance accuracy and generalization. The completion of the link serves as a means to an end, which is to conduct fault diagnosis reasoning on a more detailed knowledge graph, thereby significantly improving the accuracy of fault diagnosis. Experimental results demonstrate that the proposed framework outperforms traditional embedding models and existing meta-learning methods on multiple datasets, particularly for sparse and background-rich datasets. This approach offers a novel solution for fault diagnosis in nonlinear systems, with significant theoretical and practical value. © 2024},
	author_keywords = {Evolutionary event graph; Fault diagnosis; Large language model; Link prediction},
	keywords = {Aircraft accidents; Graph embeddings; Knowledge graph; Nonlinear systems; Prediction models; Collaboration framework; Data sparsity; Event graphs; Evolutionary event graph; Evolutionary events; Faults diagnosis; Generalisation; Language model; Large language model; Link prediction; Semantics},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Hou2025,
	author = {Hou, Wenlong and Zhao, Weidong and Jia, Ning and Liu, Xianhui},
	title = {Low-resource knowledge graph completion based on knowledge distillation driven by large language models},
	year = {2025},
	journal = {Applied Soft Computing},
	volume = {169},
	doi = {10.1016/j.asoc.2024.112622},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212441309&doi=10.1016%2fj.asoc.2024.112622&partnerID=40&md5=4ac86e35a4538c10e47ab8cf158f07d0},
	abstract = {Knowledge graph completion (KGC) refines the existing knowledge graph (KG) by predicting missing entities or relations. Existing methods are mainly based on embeddings or texts but only perform better with abundant labeled data. Hence, KGC in resource-constrained settings is a significant problem, which faces challenges of data imbalance across relations and lack of relation label semantics. Considering that Large Language Models (LLMs) demonstrate powerful reasoning and generation capabilities, this work proposes an LLM-driven Knowledge Graph Completion Distillation (KGCD) model to address low-resource KGC. A two-stage framework is developed, involving teacher-student distillation by using LLM to improve reasoning, followed by fine-tuning on real-world low-resource datasets. To deal with data imbalance, a hybrid prompt design for LLM is proposed, which includes rethink and open prompts. Furthermore, a virtual relation label generation strategy enhances the model's understanding of triples. Extensive experiments on three benchmarks have shown that KGCD's effectiveness for low-resource KGC, achieving improvements in Mean Reciprocal Rank (MRR) by 11% and Hits@1 by 10% on the WN18, MRR by 10% and Hits@1 by 14% on the WN18RR, and MRR by 12% and Hits@1 by 11% on the YAGO3-10. © 2024 Elsevier B.V.},
	author_keywords = {Knowledge graph completion; Knowledge reasoning; Large language models; Link prediction},
	keywords = {Graph embeddings; Data imbalance; Embeddings; Knowledge graph completion; Knowledge graphs; Knowledge reasoning; Labeled data; Language model; Large language model; Link prediction; Mean reciprocal ranks; Knowledge graph},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Zhong2025,
	author = {Zhong, Hao and Zhang, Qi and Li, Weisheng and Lin, Ronghua and Tang, Yong},
	title = {KPLLM-STE: Knowledge-enhanced and prompt-aware large language models for short-text expansion},
	year = {2025},
	journal = {World Wide Web},
	volume = {28},
	number = {1},
	doi = {10.1007/s11280-024-01322-y},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212677553&doi=10.1007%2fs11280-024-01322-y&partnerID=40&md5=870079b5304c51a0672f9364cdb9505c},
	abstract = {Short-text Expansion plays a significant role in enhancing the quality, diversity, and practicality of Short-text, helping users to more comprehensively understand the content expressed in the Short-text. In this paper, we aim to enhance the capabilities of large language models in short-text expansion through knowledge graphs and propose the knowledge-enhanced and prompt-aware large language models. First, we construct a multi-dimensional knowledge graph that includes semantics, sentiment, and topics based on large language models in domain-specific text. Second, we propose a method for mining prompts of Short-text across the three dimensions of semantics, sentiment, and topics based on the constructed multi-dimensional knowledge graph. Finally, we match triplets in the constructed knowledge graph based on the generated prompts in the three dimensions. The matched triplets is then integrated by the large language model to generate a expansion of given short-text. Experiments are conducted using three large language models on two public datasets, and the results indicate that our model shows improvements across multiple metrics for text similarity, readability, and coherence compared to the short-text expansion generated by the baseline large language models and existing methods. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.},
	author_keywords = {Knowledge graph; Large language model; Prompt; Short-text expansion},
	keywords = {Expansion; Semantics; Text mining; Domain specific; Graph-based; Knowledge graphs; Language model; Large language model; Multi dimensional; Prompt; Short texts; Short-text expansion; Three dimensions; Knowledge graph},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Lairgi2025214,
	author = {Lairgi, Yassir and Moncla, Ludovic and Cazabet, Rémy and Benabdeslem, Khalid and Cléau, Pierre},
	title = {iText2KG: Incremental Knowledge Graphs Construction Using Large Language Models},
	year = {2025},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) },
	volume = {15439 LNCS},
	pages = {214 – 229},
	doi = {10.1007/978-981-96-0573-6_16},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211193597&doi=10.1007%2f978-981-96-0573-6_16&partnerID=40&md5=acd4df06b02b87e4075991a7aca2b783},
	abstract = {Most available data is unstructured, making it challenging to access valuable information. Automatically building Knowledge Graphs (KGs) is crucial for structuring data and making it accessible, allowing users to search for information effectively. KGs also facilitate insights, inference, and reasoning. Traditional NLP methods, such as named entity recognition and relation extraction, are key in information retrieval but face limitations, including predefined entity types and the need for supervised learning. Current research leverages large language models’ capabilities, such as zero- or few-shot learning. However, unresolved and semantically duplicated entities and relations still pose challenges, leading to inconsistent graphs and requiring extensive post-processing. Additionally, most approaches are topic-dependent. In this paper, we propose iText2KG (The code and the dataset are available at https://github.com/AuvaLab/itext2kg), a method for incremental, topic-independent KG construction without post-processing. This plug-and-play, zero-shot method is applicable across a wide range of KG construction scenarios and comprises four modules: Documents Distiller, Incremental Entities Extractor, Incremental Relations Extractor, and Graph Integrator. Our method demonstrates superior performance compared to baseline methods across three scenarios: converting scientific papers to graphs, websites to graphs, and CVs to graphs.  © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2025.},
	author_keywords = {Knowledge Graph Construction; Large Language Models; Natural Language Processing},
	keywords = {Information retrieval; Modeling languages; Natural language processing systems; Self-supervised learning; Semantics; Supervised learning; Zero-shot learning; Graph construction; Knowledge graph construction; Knowledge graphs; Language model; Language processing; Large language model; Named entity recognition; Natural language processing; Natural languages; Post-processing; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Zhang2025,
	author = {Zhang, Song and He, Lei and Wang, Dong and Bao, Hongyun and Zheng, Suncong and Liu, Yuqiao and Xiao, Baihua and Li, Jiayue and Lu, Dongyuan and Zheng, Nan},
	title = {ProSyno: context-free prompt learning for synonym discovery},
	year = {2025},
	journal = {Frontiers of Computer Science},
	volume = {19},
	number = {6},
	doi = {10.1007/s11704-024-3900-z},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211602672&doi=10.1007%2fs11704-024-3900-z&partnerID=40&md5=bb525c5ca47410cc63758520d8f66f25},
	abstract = {Synonym discovery is important in a wide variety of concept-related tasks, such as entity/concept mining and industrial knowledge graph (KG) construction. It intends to determine whether two terms refer to the same concept in semantics. Existing methods rely on contexts or KGs. However, these methods are often impractical in some cases where contexts or KGs are not available. Therefore, this paper proposes a context-free prompt learning based synonym discovery method called ProSyno, which takes the world’s largest freely available dictionary Wiktionary as a semantic source. Based on a pre-trained language model (PLM), we employ a prompt learning method to generalize to other datasets without any fine-tuning. Thus, our model is more appropriate for context-free situation and can be easily transferred to other fields. Experimental results demonstrate its superiority comparing with state-of-the-art methods. © Higher Education Press 2025.},
	author_keywords = {large language model; prompt learning; synonym discovery},
	keywords = {Adversarial machine learning; Latent semantic analysis; Semantics; Concept mining; Context-free; Fine tuning; Graph construction; Knowledge graphs; Language model; Large language model; Learning methods; Prompt learning; Synonym discovery; Contrastive Learning},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{2025,
	title = {17th IFIP 8.1 Working Conference on the Practice of Enterprise Modeling, PoEM 2024},
	year = {2025},
	journal = {Lecture Notes in Business Information Processing},
	volume = {538 LNBIP},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211387247&partnerID=40&md5=47c70ef63dc8844321bd3c79b82e5687},
	abstract = {The proceedings contain 17 papers. The special focus in this conference is on Practice of Enterprise Modeling. The topics include: Fostering Digital Progression of Society: Exploratory Case Studies of Third Place for Services; using Enterprise Modeling for Dealing with Complexity of Elderly Care in Sweden; evaluation of Categorization Patterns for Conceptual Modeling of IoT Applications; SmartCML: A Visual Modeling Language to Enhance the Comprehensibility of Smart Contract Implementations; assessing Model Quality Using Large Language Models; grass-Root Enterprise Modelling: How Large Language Models Can Help; investigating the Effectiveness of Feedback-Driven Exercises on Deadlock Detection Skills in Conceptual Modelling; knowledge Graphs as a Scholarly Data Fabric: A Data Silo Transformation Pipeline with Visualization Semantics; enriching Business Process Event Logs with Multimodal Evidence; towards Timeline-Based Layout for Process Mining; Conceptualisation and (Meta)modelling of Problem-Solution Chains in Early Business-IT Alignment and System Design; SymboleoAC: An Access Control Model for Legal Contracts; Functional Security in Automation: The FAST Approach; Configuration of Software Product Lines Driven by the Softgoals: The TEAEM Approach; the Dual Nature of Organizational Policies.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Belani2025,
	author = {Belani, Hrvoje and Šolić, Petar and Zdravevski, Eftim and Trajkovik, Vladimir},
	title = {Internet of Things Ontologies for Well-Being, Aging and Health: A Scoping Literature Review},
	year = {2025},
	journal = {Electronics (Switzerland)},
	volume = {14},
	number = {2},
	doi = {10.3390/electronics14020394},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215982835&doi=10.3390%2felectronics14020394&partnerID=40&md5=69bc1501559cfc69ea6b34075c0e7699},
	abstract = {Internet of Things aims to simplify and automate complicated tasks by using sensors and other inputs for collecting huge amounts of data, processing them in the cloud and on the edge networks, and allowing decision making toward further interactions via actuators and other outputs. As connected IoT devices rank in billions, semantic interoperability remains one of the permanent challenges, where ontologies can provide a great contribution. The main goal of this paper is to analyze the state of research on semantic interoperability in well-being, aging, and health IoT services by using ontologies. This was achieved by analyzing the following research questions: “Which IoT ontologies have been used to implement well-being, aging and health services?” and “What is the dominant approach to achieve semantic interoperability of IoT solutions for well-being, aging and health?’ We conducted a scoping literature review of research papers from 2013 to 2024 by applying the PRISMA-ScR meta-analysis methodology with a custom-built software tool for an exhaustive search through the following digital libraries: IEEE Xplore, PubMed, MDPI, Elsevier ScienceDirect, and Springer Nature Link. By thoroughly analyzing 30 studies from an initial pool of more than 80,000 studies, we conclude that IoT ontologies for well-being, aging, and health services increasingly adopt Semantic Web of Things standards to achieve semantic interoperability by integrating heterogeneous data through unified semantic models. Emerging approaches, like semantic communication, Large Language Models Edge Intelligence, and sustainability-driven IoT analytics, can further enhance service efficiency and promote a holistic “One Well-Being, Aging, and Health” framework. © 2025 by the authors.},
	author_keywords = {aging; e-health; health; Internet of Things (IoT); ontology; scoping literature review; semantic interoperability; semantic web; well-being},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Lu2025295,
	author = {Lu, Jiamin and Zhang, Jing and Feng, Jun and An, Qi},
	title = {Survey on Construction Method of Temporal Knowledge Graph; [时序知识图谱构建研究综述]},
	year = {2025},
	journal = {Journal of Frontiers of Computer Science and Technology},
	volume = {19},
	number = {2},
	pages = {295 – 315},
	doi = {10.3778/j.issn.1673-9418.2406089},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215858261&doi=10.3778%2fj.issn.1673-9418.2406089&partnerID=40&md5=0fa6df91318d1b0295b0083980370986},
	abstract = {As a bridge connecting data, knowledge, and intelligence, knowledge graph has been widely applied in fields such as search assistance, intelligent recommendation, question-answering systems, and natural language processing. However, with the expansion of application scenarios, static knowledge graph has shown limitations in handling dynamic knowledge. The emergence of temporal knowledge graph addresses this shortcoming by integrating temporal information into the graph structure, enabling a more accurate representation of dynamic changes in knowledge. This paper provides a comprehensive study on the construction of temporal knowledge graph. It begins by introducing the concept of temporal knowledge graph and clarifying its value in handling dynamic knowledge. Then, it delves into the construction process of temporal knowledge graph, dividing the core process into three key stages: knowledge extraction, knowledge fusion, and knowledge computing. Subsequently, it thoroughly organizes each stage, and each stage is detailed with task definitions, research summaries, and the application of large language models. In the knowledge extraction stage, it focuses on named entity recognition, relation extraction, and time information extraction; in the fusion stage, it discusses entity alignment and entity linking; and in the computation stage, it focuses on knowledge reasoning. Finally, it explores the challenges faced at each stage and looks forward to future research directions. © 2025 Journal of Computer Engineering and Applications Beijing Co., Ltd.; Science Press. All rights reserved.},
	author_keywords = {knowledge extraction; knowledge fusion; knowledge reasoning; temporal information extraction; temporal knowledge graph},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Sheng2025,
	author = {Sheng, Yaqing and Zeng, Weixin and Tang, Jiuyang and Liu, Lihua and Zhao, Xiang},
	title = {Confusing negative commonsense knowledge generation with hierarchy modeling and LLM-enhanced filtering},
	year = {2025},
	journal = {Information Processing and Management},
	volume = {62},
	number = {3},
	doi = {10.1016/j.ipm.2025.104060},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214831124&doi=10.1016%2fj.ipm.2025.104060&partnerID=40&md5=4b34c0b77bd16ab93d24d1ccba91a231},
	abstract = {While most of the world's knowledge exists in a positive and affirmative form, negative knowledge also plays a significant role by showing what is not true or what not to think, and has yet been largely overlooked. Existing negative commonsense knowledge generation methods adopt the generation-filtering paradigm, while the produced negative statements are easy to detect and fail to contribute to both human perception and task-specific algorithms that require negative samples for training. In response, we put forward CONEG, a negative commonsense knowledge generation framework that generates confusing statements, featuring hierarchy modeling in candidate generation and LLM-enhanced two-stage filtering. Specifically, in the candidate generation stage, we identify congeners for entity phrases in the commonsense knowledge base using box embeddings, which can effectively capture the hierarchical correlations among entity phrases and produce confusing candidates. In the candidate filtering stage, we design a two-stage filtering strategy, consisting of intrinsic triple confidence measuring and extrinsic refinement through large language models with group-based instructions, which can effectively filter out true facts and low-quality negative candidates. We empirically evaluate our proposal on both intrinsic assessment and downstream tasks, and the results demonstrate that CONEG and its components are effective in terms of producing confusing negative knowledge, surpassing the state-of-the-art methods. © 2025 Elsevier Ltd},
	author_keywords = {Knowledge graph; Large language model; Negative statement},
	keywords = {Knowledge graph; Candidate generation; Commonsense knowledge; Generation method; Hierarchy models; Knowledge generations; Knowledge graphs; Language model; Large language model; Negative statement; World knowledge; Wiener filtering},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Fan2025,
	author = {Fan, Haolin and Huang, Junlin and Xu, Jilong and Zhou, Yifei and Fuh, Jerry Ying Hsi and Lu, Wen Feng and Li, Bingbing},
	title = {AutoMEX: Streamlining material extrusion with AI agents powered by large language models and knowledge graphs},
	year = {2025},
	journal = {Materials and Design},
	volume = {251},
	doi = {10.1016/j.matdes.2025.113644},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216545332&doi=10.1016%2fj.matdes.2025.113644&partnerID=40&md5=ddce7bd88b8e203d0d47a32fd0aa14c7},
	abstract = {Additive manufacturing (AM), particularly material extrusion (MEX), has become a versatile and widely adopted technology with significant applications in the consumer goods and healthcare industries. Despite its affordability, adaptability, and user-friendliness advantages, MEX faces challenges in scaling for mass production due to limited process automation and fragmented domain knowledge, leaving gaps in end-to-end workflow integration. We propose AutoMEX, an innovative framework that integrates large language models (LLMs) as artificial intelligence (AI) agents to automate the MEX process to address these limitations. AutoMEX utilizes a knowledge graph (KG) derived from the scientific literature to enable LLMs to provide expert recommendations on material selection, process parameters, and design considerations, thereby improving accessibility and efficiency. With minimal human intervention, the framework encompasses a complete workflow, including CAD model generation, printing parameter recommendation, slicing, and machine operation. Experimental validation demonstrated a query acceptance rate of 94.6% for the recommendation system and up to a 9.6% improvement in print strength when employing the recommended parameters. These results highlight enhanced quality, autonomy, and customization of AM outputs, making AutoMEX suitable for batch production and streamlined manufacturing processes. While the framework shows promising potential, challenges such as the computational demands of advanced LLMs and the need for continual updates to the KG remain areas for future work. Overall, AutoMEX offers a pathway toward broader adoption and scalability of MEX technology, advancing the field of AM through enhanced automation and efficiency. © 2025 The Authors},
	author_keywords = {Artificial intelligence agents; Autonomous additive manufacturing; Knowledge graphs; Large language models; Material extrusion},
	keywords = {Knowledge graph; Adopted technology; Artificial intelligence agent; Autonomous additive manufacturing; Consumer Goods; Healthcare industry; Knowledge graphs; Language model; Large language model; Material extrusion; User friendliness; Extrusion},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Chen2025112,
	author = {Chen, Xingyu and Dong, Ligang and Han, Meng},
	title = {A Comprehensive Evaluation Method for KG-Augmented Large Language Models},
	year = {2025},
	journal = {Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST},
	volume = {600 LNICST},
	pages = {112 – 121},
	doi = {10.1007/978-3-031-78806-2_7},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216083876&doi=10.1007%2f978-3-031-78806-2_7&partnerID=40&md5=b4733905d31ce14488aecdfe27aafeff},
	abstract = {Integrating factual information from knowledge graphs (KGs) into large language models (LLMs) has emerged as a promising approach to mitigate hallucination issues inherent in LLMs. This augmentation not only addresses the problem of generating inaccurate or fictional content but also offers avenues for tailoring LLMs to specific domains. Despite the potential benefits, the current body of research lacks a thorough examination of how KG augmentation influences various large language models. This paper introduces a comprehensive evaluation method specifically designed for assessing the performance of KG-augmented LLMs. By evaluating these frameworks across multiple dimensions, the proposed method aims to provide a nuanced understanding of the strengths and limitations associated with integrating KGs into LLM-based question-answering systems. The systematic evaluation is expected to offer valuable insights, guiding future research endeavors and facilitating enhancements in this emerging field. This approach contributes to advancing the integration of KGs with LLMs and fostering the development of more robust and context-aware language models tailored to specific knowledge domains. © ICST Institute for Computer Sciences, Social Informatics and Telecommunications Engineering 2025.},
	author_keywords = {Augmented; Knowledge Graph; Large Language Model},
	keywords = {Context sensitive languages; Economic and social effects; Modeling languages; Problem oriented languages; Question answering; 'current; Augmented; Comprehensive evaluation; Evaluation methods; Factual information; Graph augmentation; Knowledge graphs; Language model; Large language model; Potential benefits; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{2025,
	title = {25th International Conference on Web Information Systems Engineering, WISE 2024},
	year = {2025},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) },
	volume = {15440 LNCS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211202068&partnerID=40&md5=66d4fb20a327f8d7017e57af8a1c9cc0},
	abstract = {The proceedings contain 132 papers. The special focus in this conference is on Web Information Systems Engineering. The topics include: TAKE: Tracing Associative Empathy Keywords for Generating Empathetic Responses Based on Graph Attention; intent Identification Using Few-Shot and Active Learning with User Feedback; CLIMB: Imbalanced Data Modelling Using Contrastive Learning with Limited Labels; equivariant Diffusion-Based Sequential Hypergraph Neural Networks with Co-attention Fusion for Information Diffusion Prediction; CL3: A Collaborative Learning Framework for the Medical Data Ensuring Data Privacy in the Hyperconnected Environment; selectivity Estimation for Spatial Filters Using Optimizer Feedback: A Machine Learning Perspective; on Adversarial Training with Incorrect Labels; model Lake : A New Alternative for Machine Learning Models Management and Governance; a Benchmark Test Suite for Multiple Traveling Salesmen Problem with Pivot Cities; Deconfounded Causality-Aware Parameter-Efficient Fine-Tuning for Problem-Solving Improvement of LLMs; Regularized Multi-LLMs Collaboration for Enhanced Score-Based Causal Discovery; Combining Uncensored and Censored LLMs for Ransomware Generation; Therapying Outside the Box: Innovating the Implementation and Evaulation of CBT in Therapeutic Artificial Agents; iText2KG: Incremental Knowledge Graphs Construction Using Large Language Models; “Is this Site Legit?”: LLMs for Scam Website Detection; Towards Enhancing Linked Data Retrieval in Conversational UIs Using Large Language Models; BioLinkerAI: Capturing Knowledge Using LLMs to Enhance Biomedical Entity Linking; Enhancing LLMs Contextual Knowledge with Ontologies for Personalised Food Recommendation; ShizishanGPT: An Agricultural Large Language Model Integrating Tools and Resources; Web-Based AI Assistant for Medical Imaging: A Case Study on Predicting Spontaneous Preterm Birth via Ultrasound Images; satellite-Driven Deep Learning Algorithm for Bathymetry Extraction; Would You Trust an AI Doctor? Building Reliable Medical Predictions with Kernel Dropout Uncertainty; empowering Visual Navigation: A Deep-Learning Solution for Enhanced Accessibility and Safety Among the Visually Impaired; A Transformer and LSTM Model for Electricity Consumption Forecasting and User’s Behavior Influence.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Feng2025,
	author = {Feng, Yichun and Zhou, Lu and Ma, Chao and Zheng, Yikai and He, Ruikun and Li, Yixue},
	title = {Knowledge graph–based thought: a knowledge graph–enhanced LLM framework for pan-cancer question answering},
	year = {2025},
	journal = {GigaScience},
	volume = {14},
	doi = {10.1093/gigascience/giae082},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214348323&doi=10.1093%2fgigascience%2fgiae082&partnerID=40&md5=4cacfc566459b27a4149695b2c7f085e},
	abstract = {Background: In recent years, large language models (LLMs) have shown promise in various domains, notably in biomedical sciences. However, their real-world application is often limited by issues like erroneous outputs and hallucinatory responses. Results: We developed the knowledge graph–based thought (KGT) framework, an innovative solution that integrates LLMs with knowledge graphs (KGs) to improve their initial responses by utilizing verifiable information from KGs, thus significantly reducing factual errors in reasoning. The KGT framework demonstrates strong adaptability and performs well across various open-source LLMs. Notably, KGT can facilitate the discovery of new uses for existing drugs through potential drug–cancer associations and can assist in predicting resistance by analyzing relevant biomarkers and genetic mechanisms. To evaluate the knowledge graph question answering task within biomedicine, we utilize a pan-cancer knowledge graph to develop a pan-cancer question answering benchmark, named pan-cancer question answering. Conclusions: The KGT framework substantially improves the accuracy and utility of LLMs in the biomedical field. This study serves as a proof of concept, demonstrating its exceptional performance in biomedical question answering. © The Author(s) 2025.},
	author_keywords = {knowledge graph question answering; large language model; pan-cancer knowledge graph; prompt engineering},
	keywords = {Algorithms; Computational Biology; Humans; Knowledge Bases; Neoplasms; carteolol; propranolol; rezvilutamide; Article; biomedicine; cancer growth; cancer therapy; classification algorithm; clinical decision making; computer model; drug repositioning; gene expression; human; knowledge; large language model; machine learning; malignant neoplasm; natural language processing; personalized medicine; pharmacy (shop); questionnaire; training; transcriptomics; algorithm; bioinformatics; genetics; knowledge base; neoplasm; procedures},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{2025,
	title = {5th Latin American Conference on Geographical Information Systems, GIS-LATAM 2024},
	year = {2025},
	journal = {Communications in Computer and Information Science},
	volume = {2298 CCIS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214101363&partnerID=40&md5=259dd5fd5cd120c24a275bd08b27e43c},
	abstract = {The proceedings contain 14 papers. The special focus in this conference is on Geographical Information Systems. The topics include: Google Earth Engine Based Forest Monitoring and Decision Support: Evidence from Elrawashdah Forest, Sudan; geospatial Intelligence for Circular Economy in Mexico City; Integrating a GIS Enhanced Security System in Wireless Sensor Networks (WSN): A Geospatial Deployment Approach; spatio-Temporal Analysis of Diabetes-Related Hospitalizations: Geographical Areas of Mexico; school Clustering Through Machine Learning and Geospatial Analysis; spatial Regression Models on Sexual Violence Against Women in Mexico City; geographic Gamification Strategies in Mathematics Education: Enhancing Linear Algebra Learning at the Technological University of Cancún; Spatial Analysis of Student Feedback on Learning Management Systems in Mathematics: Leveraging GIS for Enhanced Insights; semi-automatic Construction of Knowledge Graphs on Natural Disasters in Mexico Using Large Language Models; spatial and Seasonal Patterns of Rainfall Climate Teleconnections in Three Hydropower Generation Basins in Tropical Ecuador; implementation of Spatial Correlations and Kernel Densities to Identify Deficiencies in the Coverage of Public Health Infrastructure; indices and State of Vegetation Health, Obtained with Multispectral Cameras, in Two Thermal Springs of the Sierra Madre Oriental.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{De Santis2025304,
	author = {De Santis, Antonio and Balduini, Marco and De Santis, Federico and Proia, Andrea and Leo, Arsenio and Brambilla, Marco and Della Valle, Emanuele},
	title = {Integrating Large Language Models and Knowledge Graphs for Extraction and Validation of Textual Test Data},
	year = {2025},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) },
	volume = {15233 LNCS},
	pages = {304 – 323},
	doi = {10.1007/978-3-031-77847-6_17},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211195122&doi=10.1007%2f978-3-031-77847-6_17&partnerID=40&md5=aaa19d41507e17377f75bb1dfc0e7370},
	abstract = {Aerospace manufacturing companies, such as Thales Alenia Space, design, develop, integrate, verify, and validate products characterized by high complexity and low volume. They carefully document all phases for each product but analyses across products are challenging due to the heterogeneity and unstructured nature of the data in documents. In this paper, we propose a hybrid methodology that leverages Knowledge Graphs (KGs) in conjunction with Large Language Models (LLMs) to extract and validate data contained in these documents. We consider a case study focused on test data related to electronic boards for satellites. To do so, we extend the Semantic Sensor Network ontology. We store the metadata of the reports in a KG, while the actual test results are stored in parquet accessible via a Virtual Knowledge Graph. The validation process is managed using an LLM-based approach. We also conduct a benchmarking study to evaluate the performance of state-of-the-art LLMs in executing this task. Finally, we analyze the costs and benefits of automating preexisting processes of manual data extraction and validation for subsequent cross-report analyses. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.},
	author_keywords = {Data Extraction; Knowledge Graphs; Large Language Models; Space Industry},
	keywords = {Aerospace industry; Benchmarking; Metadata; Semantics; Aerospace manufacturing; Data extraction; High complexity; Knowledge graphs; Language model; Large language model; Manufacturing companies; Space design; Space industry; Test data; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Mishra2025,
	author = {Mishra, Chinmaya and Sarma, Himangshu and M., Saravanan},
	title = {PageLLM: Incremental approach for updating a Security Knowledge Graph by using Page ranking and Large language model},
	year = {2025},
	journal = {Information Processing and Management},
	volume = {62},
	number = {3},
	doi = {10.1016/j.ipm.2024.104045},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213286963&doi=10.1016%2fj.ipm.2024.104045&partnerID=40&md5=ab8e5984413fc17de4deb3146270a93e},
	abstract = {Due to increase in cyber crime and evolution of sophisticated tools and techniques, Threat Intelligence plays a critical role. It helps defenders to stay ahead of attackers by developing the right defense mechanism to invade those attacks. In this regards security knowledge graph plays a critical role which can be used to signify complex entities and their relationship in a graphical structure. Further projecting those entities and relationships in to the lower dimension using several embedding techniques such as TransE help in many down streaming task. The learned embedding can be used to predict new cyber threat which is very helpful for defenders to stay alert and develop necessary weapons to stay ahead of an attack. One of the major challenge security knowledge graph has its dynamic nature of changing intelligence. Active learning can be used to only update the substantial portion of embedding rather than retraining the knowledge graph from scratch which has higher time and space complexity. Also given the rise in generative AI and large language models which are super rich in context, there is a scope of utilizing those for building a robust and good quality security knowledge graph. We will discuss a novel methodology called PageLLM which utilizes page ranking and LLMs to enable active learning in an incremental way and will improve the quality of knowledge graph through enriched context. © 2024 Elsevier Ltd},
	author_keywords = {Embedding; Full knowledge graph (FKG); Generative AI; Incremental knowledge graph (IKG); Knowledge graph; Knowledge representation learning; Large language models (LLMs); Page ranking; Security knowledge graph; Static knowledge graph (SKG)},
	keywords = {Active learning; Adversarial machine learning; Contrastive Learning; Graph embeddings; Embeddings; Full knowledge graph; Generative AI; Incremental knowledge graph; Knowledge graphs; Knowledge representation learning; Knowledge-representation; Language model; Large language model; Page ranking; Security knowledge graph; Static knowledge; Static knowledge graph; Knowledge graph},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Hyvönen2025,
	author = {Hyvönen, Eero},
	title = {Serendipitous knowledge discovery on the Web of Wisdom based on searching and explaining interesting relations in knowledge graphs},
	year = {2025},
	journal = {Journal of Web Semantics},
	volume = {85},
	doi = {10.1016/j.websem.2024.100852},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214086632&doi=10.1016%2fj.websem.2024.100852&partnerID=40&md5=71b49dc935ab524ba8c89e6ab250ad69},
	abstract = {This paper maintains that the Semantic Web is changing into a kind of Web of Wisdom (WoW) where AI-based problem solving, based on symbolic search and sub-symbolic methods, and Information Retrieval (IR) merge: IR is seen as a process for solving information-related problems of the end user with explanations, a form of knowledge discovery. As a case of example, relational search is concerned, i.e., solving problems of the type “How are X1…Xn related to Y1…Ym?”. For example: how is Pablo Picasso related to Barcelona? The idea is to find explainable “interesting” or even serendipitous associations in Knowledge Graphs (KG) and textual web contents. It is argued that domain knowledge-based symbolic methods based of KGs are needed to complement domain-agnostic graph-based methods and Generative AI (GenAI) boosted by Large Language Models (LLM). By using domain specific knowledge, it is possible to find and explain meaningful reliable textual answers, answer quantitative questions, and use data analyses and visualizations for explaining and studying the relations. © 2024 The Author},
	author_keywords = {Generative AI; Information retrieval; Knowledge discovery; Knowledge graphs; Large Language Models; Relational search},
	keywords = {Domain Knowledge; Generative AI; Knowledge graphs; Language model; Large language model; Problem-solving; Relational search; Semantic-Web; Sub-symbolic; Symbolic methods; Symbolic search; Knowledge graph},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{2025,
	title = {23rd International Semantic Web Conference, ISWC 2024},
	year = {2025},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) },
	volume = {15231 LNCS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211222309&partnerID=40&md5=71ccee63d4ef2e070099e7c9ff12adea},
	abstract = {The proceedings contain 44 papers. The special focus in this conference is on Semantic Web. The topics include: Relationships Are Complicated! An Analysis of Relationships Between Datasets on the Web; multi-view Transformer-Based Network for Prerequisite Learning in Concept Graphs; knowledge Graph Structure as Prompt: Improving Small Language Models Capabilities for Knowledge-Based Causal Discovery; Repairing Networks of EL⊥ Ontologies Using Weakening and Completing; Do LLMs Really Adapt to Domains? An Ontology Learning Perspective; supervised Relational Learning with Selective Neighbor Entities for Few-Shot Knowledge Graph Completion; knowledge Graphs for Enhancing Large Language Models in Entity Disambiguation; unaligned Federated Knowledge Graph Embedding; finetuning Generative Large Language Models with Discrimination Instructions for Knowledge Graph Completion; blink: Blank Node Matching Using Embeddings; distilling Event Sequence Knowledge From Large Language Models.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Dhanda2025,
	author = {Dhanda, Mandeep and Rogers, Benedict Alexander and Hall, Stephanie and Dekoninck, Elies and Dhokia, Vimal},
	title = {Reviewing human-robot collaboration in manufacturing: Opportunities and challenges in the context of industry 5.0},
	year = {2025},
	journal = {Robotics and Computer-Integrated Manufacturing},
	volume = {93},
	doi = {10.1016/j.rcim.2024.102937},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214277411&doi=10.1016%2fj.rcim.2024.102937&partnerID=40&md5=f46ac2189082f1606acddfc28a697359},
	abstract = {Industry 4.0 (I4.0) has been characterized by the increasing use of automation, artificial intelligence, and big data in manufacturing. It has brought different machines, tools, robots and devices together through integration with cyber-physical systems as well as Internet of Things and computer systems. This has dramatically improved efficiency, productivity, and flexibility of automated systems, but it has also raised concerns about the impact of automation on jobs, the ethical considerations and the future of work in general. Industry 5.0 (I5.0) is the next manufacturing paradigm evolution and builds on I4.0 with the addition of ‘people’, in which robots will be designed to work alongside humans in a safe and efficient manner. Human-robot collaboration (HRC) is its key enabler. In manufacturing, HRC has the potential to improve safety, efficiency, and productivity by allowing humans to focus on tasks that require creativity, judgment, and flexibility, while robots perform more repetitive and dangerous tasks. This paper explores the concept of HRC and its advancement within 21st century industry. It identifies the opportunities and challenges arising from the interactions between robots and humans in manufacturing applications, assembly, and inspection. It also highlights the significance of HRC in I4.0 and its potential in I5.0. In addition, the role of artificial intelligence, machine learning, large language models, information modelling (ontologies) and new emerging digital technologies (augmented reality, virtual reality, digital twins, cyber-physical system) in the development of HRC and I5.0 is documented and discussed adding new perspectives to the growing literature in this area. This investigation sheds light on the emerging paradigms that have come about as parts of I5.0 and the transformative role of human-robot interaction in shaping the future of manufacturing. This critical review provides a realistic picture of manufacturing automation and the benefits and weaknesses of current HRC systems. It presents a researched view on the concept, needs, enabling technologies and system frameworks of human-robot interaction in manufacturing, providing a practical vision and research agenda for future work in this area and its associated systems. © 2024 The Author(s)},
	author_keywords = {Artificial Intelligence; Digital Manufacturing; Human Robot Collaboration; Industry 5.0; Ontology},
	keywords = {Augmented reality; Computer aided manufacturing; Human robot interaction; Industrial robots; Ontology; Robot learning; Virtual environments; Automated systems; Cybe-physical systems; Cyber-physical systems; Digital manufacturing; Human-robot collaboration; Humans-robot interactions; Industry 5.0; Manufacturing challenges; Manufacturing opportunities; Ontology's; Smart manufacturing},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Pons2025162,
	author = {Pons, Gerard and Bilalli, Besim and Queralt, Anna},
	title = {Knowledge Graphs for Enhancing Large Language Models in Entity Disambiguation},
	year = {2025},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) },
	volume = {15231 LNCS},
	pages = {162 – 179},
	doi = {10.1007/978-3-031-77844-5_9},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211213831&doi=10.1007%2f978-3-031-77844-5_9&partnerID=40&md5=dcfa9474f4c733e39500a23243b3940d},
	abstract = {Recent advances in Large Language Models (LLMs) have positioned them as a prominent solution for Natural Language Processing tasks. Notably, they can approach these problems in a zero or few-shot manner, thereby eliminating the need for training or fine-tuning task-specific models. However, LLMs face some challenges, including hallucination and the presence of outdated knowledge or missing information from specific domains in the training data. These problems cannot be easily solved by retraining the models with new data as it is a time-consuming and expensive process. To mitigate these issues, Knowledge Graphs (KGs) have been proposed as a structured external source of information to enrich LLMs. With this idea, in this work we use KGs to enhance LLMs for zero-shot Entity Disambiguation (ED). For that purpose, we leverage the hierarchical representation of the entities’ classes in a KG to gradually prune the candidate space as well as the entities’ descriptions to enrich the input prompt with additional factual knowledge. Our evaluation on popular ED datasets shows that the proposed method outperforms non-enhanced and description-only enhanced LLMs, and has a higher degree of adaptability than task-specific models. Furthermore, we conduct an error analysis and discuss the impact of the leveraged KG’s semantic expressivity on the ED performance.  © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.},
	author_keywords = {Entity Disambiguation; Knowledge Graphs; Large Language Models},
	keywords = {Natural language processing systems; Semantics; Entity disambiguation; Fine tuning; Knowledge graphs; Knowledge information; Language model; Language processing; Large language model; Missing information; Natural languages; Task-specific models; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Mai2025126,
	author = {Mai, Huu Tan and Chu, Cuong Xuan and Paulheim, Heiko},
	title = {Do LLMs Really Adapt to Domains? An Ontology Learning Perspective},
	year = {2025},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) },
	volume = {15231 LNCS},
	pages = {126 – 143},
	doi = {10.1007/978-3-031-77844-5_7},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211249904&doi=10.1007%2f978-3-031-77844-5_7&partnerID=40&md5=1635a63b59141f8cc972899f30a2a43e},
	abstract = {Large Language Models (LLMs) have demonstrated unprecedented prowess across various natural language processing tasks in various application domains. Recent studies show that LLMs can be leveraged to perform lexical semantic tasks, such as Knowledge Base Completion (KBC) or Ontology Learning (OL). However, it has not effectively been verified whether their success is due to their ability to reason over unstructured or semi-structured data, or their effective learning of linguistic patterns and senses alone. This unresolved question is particularly crucial when dealing with domain-specific data, where the lexical senses and their meaning can completely differ from what a LLM has learned during its training stage. This paper investigates the following question: Do LLMs really adapt to domains and remain consistent in the extraction of structured knowledge, or do they only learn lexical senses instead of reasoning? To answer this question and, we devise a controlled experiment setup that uses WordNet to synthesize parallel corpora, with English and gibberish terms. We examine the differences in the outputs of LLMs for each corpus in two OL tasks: relation extraction and taxonomy discovery. Empirical results show that, while adapting to the gibberish corpora, off-the-shelf LLMs do not consistently reason over semantic relationships between concepts, and instead leverage senses and their frame. However, fine-tuning improves the performance of LLMs on lexical semantic tasks even when the domain-specific terms are arbitrary and unseen during pre-training, hinting at the applicability of pre-trained LLMs for OL. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.},
	author_keywords = {domain adaptation; LLMs; ontology learning},
	keywords = {Adversarial machine learning; Contrastive Learning; Federated learning; Latent semantic analysis; Natural language processing systems; Ontology; Semantics; Applications domains; Domain adaptation; Domain specific; Language model; Language processing; Large language model; Lexical semantics; Natural languages; Ontology learning; Semantic tasks; Domain Knowledge},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Yang2025284,
	author = {Yang, Shuting and Liu, Zehui and Mayer, Wolfgang and Ding, Ningpei and Wang, Ying and Huang, Yu and Wu, Pengfei and Li, Wanli and Li, Lin and Zhang, Hong-Yu and Feng, Zaiwen},
	title = {ShizishanGPT: An Agricultural Large Language Model Integrating Tools and Resources},
	year = {2025},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) },
	volume = {15439 LNCS},
	pages = {284 – 298},
	doi = {10.1007/978-981-96-0573-6_21},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211248934&doi=10.1007%2f978-981-96-0573-6_21&partnerID=40&md5=aa8627cf7982a444ea430adcd14554bc},
	abstract = {Recent developments in large language models (LLMs) have led to significant improvements in intelligent dialogue systems’ ability to handle complex inquiries. However, current LLMs still exhibit limitations in specialized domain knowledge, particularly in technical fields such as agriculture. To address this problem, we propose ShizishanGPT, an intelligent question answering system for agriculture based on the Retrieval Augmented Generation (RAG) framework and agent architecture. ShizishanGPT consists of five key modules: including a generic GPT-4 based module for answering general questions; a search engine module that compensates for the problem that the large language model’s own knowledge cannot be updated in a timely manner; an agricultural knowledge graph module for providing domain facts; a retrieval module which uses RAG to supplement domain knowledge; and an agricultural agent module, which invokes specialized models for crop phenotype prediction, gene expression analysis, and so on. We evaluated the ShizishanGPT using a dataset containing 100 agricultural questions specially designed for this study. The experimental results show that the tool significantly outperforms general LLMs as it provides more accurate and detailed answers due to its modular design and integration of different domain knowledge sources. Our source code, dataset, and model weights are publicly available at https://github.com/Zaiwen/CropGPT. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2025.},
	author_keywords = {Agricultural information system; Knowledge Graphs; Large Language Models; Retrieval Augmented Generation},
	keywords = {Domain Knowledge; Question answering; Speech enhancement; 'current; Agricultural information systems; Domain knowledge; Intelligent dialogue systems; Intelligent question answering systems; Knowledge graphs; Language model; Large language model; Retrieval augmented generation; Technical fields; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Daga2025,
	author = {Daga, Enrico},
	title = {Process Knowledge Graphs (PKG): Towards unpacking and repacking AI applications},
	year = {2025},
	journal = {Journal of Web Semantics},
	volume = {84},
	doi = {10.1016/j.websem.2024.100846},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212591713&doi=10.1016%2fj.websem.2024.100846&partnerID=40&md5=709dc97ecafbb77d9d6540b656c85839},
	abstract = {In the past years, a new generation of systems has emerged, which apply recent advances in generative Artificial Intelligence (AI) in combination with traditional technologies. Specifically, generative AI is being delegated tasks in natural language or vision understanding within complex hybrid architectures that also include databases, procedural code, and interfaces. Process Knowledge Graphs (PKG) have a long-standing tradition within symbolic AI research. On the one hand, PKGs can play an important role in describing complex, hybrid applications, thus opening the way for addressing fundamental challenges such as explaining and documenting such systems (unpacking). On the other hand, by organising complex processes in simpler building blocks, PKGs can potentially increase accuracy and control over such systems (repacking). In this position paper, we discuss opportunities and challenges of PGRs and their potential role towards a more robust and principled design of AI applications. © 2024 The Author},
	author_keywords = {Data pipelines design; Data pipelines documentation; Data science pipelines; Knowledge graphs; Prompt engineering},
	keywords = {Data Science; Data pipeline design; Data pipeline documentation; Data pipelines; Data science pipeline; Knowledge graphs; Natural language understanding; Pipeline design; Process knowledge; Prompt engineering; Knowledge graph},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{2025,
	title = {25th International Conference on Web Information Systems Engineering, WISE 2024},
	year = {2025},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) },
	volume = {15439 LNCS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211245787&partnerID=40&md5=2487abf9e418ce205764be9e26b982cd},
	abstract = {The proceedings contain 132 papers. The special focus in this conference is on Web Information Systems Engineering. The topics include: TAKE: Tracing Associative Empathy Keywords for Generating Empathetic Responses Based on Graph Attention; intent Identification Using Few-Shot and Active Learning with User Feedback; CLIMB: Imbalanced Data Modelling Using Contrastive Learning with Limited Labels; equivariant Diffusion-Based Sequential Hypergraph Neural Networks with Co-attention Fusion for Information Diffusion Prediction; CL3: A Collaborative Learning Framework for the Medical Data Ensuring Data Privacy in the Hyperconnected Environment; selectivity Estimation for Spatial Filters Using Optimizer Feedback: A Machine Learning Perspective; on Adversarial Training with Incorrect Labels; model Lake : A New Alternative for Machine Learning Models Management and Governance; a Benchmark Test Suite for Multiple Traveling Salesmen Problem with Pivot Cities; Deconfounded Causality-Aware Parameter-Efficient Fine-Tuning for Problem-Solving Improvement of LLMs; Regularized Multi-LLMs Collaboration for Enhanced Score-Based Causal Discovery; Combining Uncensored and Censored LLMs for Ransomware Generation; Therapying Outside the Box: Innovating the Implementation and Evaulation of CBT in Therapeutic Artificial Agents; iText2KG: Incremental Knowledge Graphs Construction Using Large Language Models; “Is this Site Legit?”: LLMs for Scam Website Detection; Towards Enhancing Linked Data Retrieval in Conversational UIs Using Large Language Models; BioLinkerAI: Capturing Knowledge Using LLMs to Enhance Biomedical Entity Linking; Enhancing LLMs Contextual Knowledge with Ontologies for Personalised Food Recommendation; ShizishanGPT: An Agricultural Large Language Model Integrating Tools and Resources; Web-Based AI Assistant for Medical Imaging: A Case Study on Predicting Spontaneous Preterm Birth via Ultrasound Images; satellite-Driven Deep Learning Algorithm for Bathymetry Extraction; Would You Trust an AI Doctor? Building Reliable Medical Predictions with Kernel Dropout Uncertainty; empowering Visual Navigation: A Deep-Learning Solution for Enhanced Accessibility and Safety Among the Visually Impaired; A Transformer and LSTM Model for Electricity Consumption Forecasting and User’s Behavior Influence.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{2025,
	title = {26th International Conference on Information Integration and Web Intelligence, iiWAS 2024},
	year = {2025},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) },
	volume = {15343 LNCS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212494941&partnerID=40&md5=fa2aecd7173d4fed3f498bd4793aadb2},
	abstract = {The proceedings contain 52 papers. The special focus in this conference is on Information Integration and Web Intelligence. The topics include: Financial News Classification Using Language Learning Models and Reinforcement Learning; ExtractGPT: Exploring the Potential of Large Language Models for Product Attribute Value Extraction; Feature Extraction for Claim Check-Worthiness Prediction Tasks Using LLM; training Data for Dialogue Generation Considering Philosophies; Finding Adequate Additional Layer of Auxiliary Task in BERT-Based Multi-task Learning; ponzi Scheme Detection and Prevention in Blockchain Platforms Using Machine Learning: A Systematic Literature Review; Cross-Chain Personal Data Exchange on EVM Platforms: Enhancing Transparency, and Equity; Incentivize Peer Review Without Rewarding: Using OSS-Like Citation Pull Request; towards Website X-Ray for Europe’s Municipalities: Unveiling Digital Transformation with Multimodal Embeddings; evolving Applications of Conversational Agents in Healthcare: A Literature Review; hybrid Edge-Cloud Federated Learning: The Case of Lightweight Smoking Detection; anonymization of Unstructured Health Data in Spanish; when Good Enough is the Best Option: Use of Digital Sufficiency to Fight Climate Change; multi-target Feature Selection Method for Predicting User-Level Psychological Status from Text; FIEAP: A Machine Learning Approach for Fair and Interpretable Employee Attrition Prediction; HOCON34k: A Corpus of Hate Speech in Online Comments from German Newspapers; SISIS: Sequence Indexing for SImilarity Search; top-k on Sequences: A New Approach to Enhanced Similarity Search; exploratory Data Analysis of Time Series Using Pre-segmented Clustering; a Data Science Approach for Predicting Soccer Passes Using Positional Data; a Method for Integrating Heterogeneous Data into a Knowledge Graph; predicting Knowledge Graph Updates from Edit Histories; Automatic Extraction of RML-star Mappings from Property Graphs; Exploring the Role of UML in Data Modelling for NoSQL Databases: Position Paper; railway Systems’ Ontologies: A Literature Review and an Alignment Proposal; Combining GraphSAGE and Label Propagation for Node Classification in Graphs.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{2025,
	title = {25th International Conference on Web Information Systems Engineering, WISE 2024},
	year = {2025},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) },
	volume = {15437 LNCS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211933765&partnerID=40&md5=8a299731440a5243bcc0d221790637e0},
	abstract = {The proceedings contain 132 papers. The special focus in this conference is on Web Information Systems Engineering. The topics include: TAKE: Tracing Associative Empathy Keywords for Generating Empathetic Responses Based on Graph Attention; intent Identification Using Few-Shot and Active Learning with User Feedback; CLIMB: Imbalanced Data Modelling Using Contrastive Learning with Limited Labels; equivariant Diffusion-Based Sequential Hypergraph Neural Networks with Co-attention Fusion for Information Diffusion Prediction; CL3: A Collaborative Learning Framework for the Medical Data Ensuring Data Privacy in the Hyperconnected Environment; selectivity Estimation for Spatial Filters Using Optimizer Feedback: A Machine Learning Perspective; on Adversarial Training with Incorrect Labels; model Lake : A New Alternative for Machine Learning Models Management and Governance; a Benchmark Test Suite for Multiple Traveling Salesmen Problem with Pivot Cities; Deconfounded Causality-Aware Parameter-Efficient Fine-Tuning for Problem-Solving Improvement of LLMs; Regularized Multi-LLMs Collaboration for Enhanced Score-Based Causal Discovery; Combining Uncensored and Censored LLMs for Ransomware Generation; Therapying Outside the Box: Innovating the Implementation and Evaulation of CBT in Therapeutic Artificial Agents; iText2KG: Incremental Knowledge Graphs Construction Using Large Language Models; “Is this Site Legit?”: LLMs for Scam Website Detection; Towards Enhancing Linked Data Retrieval in Conversational UIs Using Large Language Models; BioLinkerAI: Capturing Knowledge Using LLMs to Enhance Biomedical Entity Linking; Enhancing LLMs Contextual Knowledge with Ontologies for Personalised Food Recommendation; ShizishanGPT: An Agricultural Large Language Model Integrating Tools and Resources; Web-Based AI Assistant for Medical Imaging: A Case Study on Predicting Spontaneous Preterm Birth via Ultrasound Images; satellite-Driven Deep Learning Algorithm for Bathymetry Extraction; Would You Trust an AI Doctor? Building Reliable Medical Predictions with Kernel Dropout Uncertainty; empowering Visual Navigation: A Deep-Learning Solution for Enhanced Accessibility and Safety Among the Visually Impaired; A Transformer and LSTM Model for Electricity Consumption Forecasting and User’s Behavior Influence.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{2025,
	title = {23rd International Semantic Web Conference, ISWC 2024},
	year = {2025},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) },
	volume = {15233 LNCS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211205922&partnerID=40&md5=d567acf8e8c3d035e95493e20cc3d39c},
	abstract = {The proceedings contain 44 papers. The special focus in this conference is on Semantic Web. The topics include: Relationships Are Complicated! An Analysis of Relationships Between Datasets on the Web; multi-view Transformer-Based Network for Prerequisite Learning in Concept Graphs; knowledge Graph Structure as Prompt: Improving Small Language Models Capabilities for Knowledge-Based Causal Discovery; Repairing Networks of EL⊥ Ontologies Using Weakening and Completing; Do LLMs Really Adapt to Domains? An Ontology Learning Perspective; supervised Relational Learning with Selective Neighbor Entities for Few-Shot Knowledge Graph Completion; knowledge Graphs for Enhancing Large Language Models in Entity Disambiguation; unaligned Federated Knowledge Graph Embedding; finetuning Generative Large Language Models with Discrimination Instructions for Knowledge Graph Completion; blink: Blank Node Matching Using Embeddings; distilling Event Sequence Knowledge From Large Language Models.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Greif2025,
	author = {Greif, Lucas and Hauck, Svenja and Kimmig, Andreas and Ovtcharova, Jivka},
	title = {A Knowledge Graph Framework to Support Life Cycle Assessment for Sustainable Decision-Making},
	year = {2025},
	journal = {Applied Sciences (Switzerland)},
	volume = {15},
	number = {1},
	doi = {10.3390/app15010175},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214495096&doi=10.3390%2fapp15010175&partnerID=40&md5=1b6ecdb9de846877a529bc89ca9bb18e},
	abstract = {This study introduces a comprehensive knowledge graph (KG)-based framework designed to support sustainable decision-making by integrating, enriching, and analyzing heterogeneous data sources. The proposed methodology leverages domain expertise, real-world data, and synthetic data generated through language models to address challenges in life cycle assessment (LCA), particularly data scarcity and inconsistency. By modeling the entire product lifecycle, including engineering, production, usage, and disposal phases, the framework facilitates early-stage design decision-making and provides actionable insights for sustainability improvements. The methodology is validated through a case study on 3D printing (3DP), demonstrating its ability to manage complex data, highlight relationships between engineering decisions and environmental impacts, and mitigate data scarcity in the early phases of product development in the context of LCAs. In conclusion, the results demonstrate the framework’s potential to drive sustainable innovation in manufacturing. © 2024 by the authors.},
	author_keywords = {3D printing; artificial intelligence; knowledge graph; large language models; sustainability},
	keywords = {Knowledge graph; Sustainable development goals; 3-D printing; 3D-printing; Data scarcity; Graph framework; Graph-based; Heterogeneous data sources; Knowledge graphs; Language model; Large language model; Sustainable decision makings; Life cycle assessment},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{2025,
	title = {23rd International Semantic Web Conference, ISWC 2024},
	year = {2025},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) },
	volume = {15232 LNCS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211199051&partnerID=40&md5=23e027d24e29ea07ff2b1cce6f3ba9d2},
	abstract = {The proceedings contain 44 papers. The special focus in this conference is on Semantic Web. The topics include: Relationships Are Complicated! An Analysis of Relationships Between Datasets on the Web; multi-view Transformer-Based Network for Prerequisite Learning in Concept Graphs; knowledge Graph Structure as Prompt: Improving Small Language Models Capabilities for Knowledge-Based Causal Discovery; Repairing Networks of EL⊥ Ontologies Using Weakening and Completing; Do LLMs Really Adapt to Domains? An Ontology Learning Perspective; supervised Relational Learning with Selective Neighbor Entities for Few-Shot Knowledge Graph Completion; knowledge Graphs for Enhancing Large Language Models in Entity Disambiguation; unaligned Federated Knowledge Graph Embedding; finetuning Generative Large Language Models with Discrimination Instructions for Knowledge Graph Completion; blink: Blank Node Matching Using Embeddings; distilling Event Sequence Knowledge From Large Language Models.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Lavrinovics2025,
	author = {Lavrinovics, Ernests and Biswas, Russa and Bjerva, Johannes and Hose, Katja},
	title = {Knowledge Graphs, Large Language Models, and Hallucinations: An NLP Perspective},
	year = {2025},
	journal = {Journal of Web Semantics},
	volume = {85},
	doi = {10.1016/j.websem.2024.100844},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213832166&doi=10.1016%2fj.websem.2024.100844&partnerID=40&md5=a71d61e092d8ce474587165a99f253fd},
	abstract = {Large Language Models (LLMs) have revolutionized Natural Language Processing (NLP) based applications including automated text generation, question answering, chatbots, and others. However, they face a significant challenge: hallucinations, where models produce plausible-sounding but factually incorrect responses. This undermines trust and limits the applicability of LLMs in different domains. Knowledge Graphs (KGs), on the other hand, provide a structured collection of interconnected facts represented as entities (nodes) and their relationships (edges). In recent research, KGs have been leveraged to provide context that can fill gaps in an LLM's understanding of certain topics offering a promising approach to mitigate hallucinations in LLMs, enhancing their reliability and accuracy while benefiting from their wide applicability. Nonetheless, it is still a very active area of research with various unresolved open problems. In this paper, we discuss these open challenges covering state-of-the-art datasets and benchmarks as well as methods for knowledge integration and evaluating hallucinations. In our discussion, we consider the current use of KGs in LLM systems and identify future directions within each of these challenges. © 2024},
	author_keywords = {Factuality; Hallucinations; Knowledge Graphs; LLM},
	keywords = {Natural language processing systems; Question answering; Structured Query Language; Chatbots; Factuality; Hallucination; Knowledge graphs; Language model; Language processing; Large language model; Natural languages; Question Answering; Text generations; Knowledge graph},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{2025,
	title = {25th International Conference on Web Information Systems Engineering, WISE 2024},
	year = {2025},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) },
	volume = {15438 LNCS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211327214&partnerID=40&md5=e7fa3d09bc1021d158bec2e6e8d7a440},
	abstract = {The proceedings contain 132 papers. The special focus in this conference is on Web Information Systems Engineering. The topics include: TAKE: Tracing Associative Empathy Keywords for Generating Empathetic Responses Based on Graph Attention; intent Identification Using Few-Shot and Active Learning with User Feedback; CLIMB: Imbalanced Data Modelling Using Contrastive Learning with Limited Labels; equivariant Diffusion-Based Sequential Hypergraph Neural Networks with Co-attention Fusion for Information Diffusion Prediction; CL3: A Collaborative Learning Framework for the Medical Data Ensuring Data Privacy in the Hyperconnected Environment; selectivity Estimation for Spatial Filters Using Optimizer Feedback: A Machine Learning Perspective; on Adversarial Training with Incorrect Labels; model Lake : A New Alternative for Machine Learning Models Management and Governance; a Benchmark Test Suite for Multiple Traveling Salesmen Problem with Pivot Cities; Deconfounded Causality-Aware Parameter-Efficient Fine-Tuning for Problem-Solving Improvement of LLMs; Regularized Multi-LLMs Collaboration for Enhanced Score-Based Causal Discovery; Combining Uncensored and Censored LLMs for Ransomware Generation; Therapying Outside the Box: Innovating the Implementation and Evaulation of CBT in Therapeutic Artificial Agents; iText2KG: Incremental Knowledge Graphs Construction Using Large Language Models; “Is this Site Legit?”: LLMs for Scam Website Detection; Towards Enhancing Linked Data Retrieval in Conversational UIs Using Large Language Models; BioLinkerAI: Capturing Knowledge Using LLMs to Enhance Biomedical Entity Linking; Enhancing LLMs Contextual Knowledge with Ontologies for Personalised Food Recommendation; ShizishanGPT: An Agricultural Large Language Model Integrating Tools and Resources; Web-Based AI Assistant for Medical Imaging: A Case Study on Predicting Spontaneous Preterm Birth via Ultrasound Images; satellite-Driven Deep Learning Algorithm for Bathymetry Extraction; Would You Trust an AI Doctor? Building Reliable Medical Predictions with Kernel Dropout Uncertainty; empowering Visual Navigation: A Deep-Learning Solution for Enhanced Accessibility and Safety Among the Visually Impaired; A Transformer and LSTM Model for Electricity Consumption Forecasting and User’s Behavior Influence.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Allemang2025324,
	author = {Allemang, Dean and Sequeda, Juan},
	title = {Increasing the Accuracy of LLM Question-Answering Systems with Ontologies},
	year = {2025},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) },
	volume = {15233 LNCS},
	pages = {324 – 339},
	doi = {10.1007/978-3-031-77847-6_18},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211242388&doi=10.1007%2f978-3-031-77847-6_18&partnerID=40&md5=d276ff074dea73c801fe062efc46c97b},
	abstract = {There is increasing evidence that question-answering (QA) systems with Large Language Models (LLMs), which employ a knowledge graph representation of an enterprise SQL database (Text-to-SPARQL), achieve higher accuracy compared to systems that answer questions directly on SQL databases (Text-to-SQL). The objective of this research is to further improve the accuracy of these LLM Question Answering systems. Our approach, Ontology-based Query Check (OBQC), is to check the LLM generated SPARQL query against the semantics specified by the ontology. A query will be flagged as incorrect and prevented from execution if it does not align with the ontological semantics. The study also explores the LLM’s capability in repairing a SPARQL query given an explanation of the error (LLM Repair). Our methods are evaluated using the chat with the data benchmark. The primary finding is our method further increases the accuracy overall by 21.59% thus pushing the overall accuracy level to 65.63%. These results provide further evidence that investing knowledge graphs, namely the ontology, provides higher accuracy for LLM powered question answering systems. Our method is a component of the data.world AI Context Engine which is being widely used by customers in Generative AI production use cases that enable business users to chat with SQL databases. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.},
	keywords = {Database systems; Knowledge graph; Ontology; Semantics; Structured Query Language; Graph representation; High-accuracy; Knowledge graphs; Language model; Model questions; Model repair; Ontology's; Ontology-based query; Question answering systems; SQL database},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Yu2025,
	author = {Yu, Liu and Tian, Fenghui and Kuang, Ping and Zhou, Fan},
	title = {Amplifying commonsense knowledge via bi-directional relation integrated graph-based contrastive pre-training from large language models},
	year = {2025},
	journal = {Information Processing and Management},
	volume = {62},
	number = {3},
	doi = {10.1016/j.ipm.2025.104068},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215364164&doi=10.1016%2fj.ipm.2025.104068&partnerID=40&md5=e41c26cedf9737e13b61535ee6539c0a},
	abstract = {Commonsense knowledge graph acquisition (CKGA) is vital in numerous knowledge-intensive applications such as question-answering and knowledge reasoning. Conventional CKGA methods rely on node-level and unidirectional relations, making them suffer from a shallow grasp of between entities and relations. Moreover, they also demand expensive, labor-intensive human annotations, and the yielding CK lacks diversity and quality. Existing commonsense knowledge bases such as ConceptNet or ATOMIC often struggle with significant scarcity and pose a major challenge in meeting the high demand for a vast amount of commonsense information. Given the recent momentum of large language models (LLMs), there is growing interest in leveraging them to overcome the above challenges. In this study, we propose a new paradigm to amplify commonsense knowledge via bi-directional relation integrated graph-based contrastive pre-training (BIRGHT) from the newest foundation models. BRIGHT is an integral and closed-loop framework composed of corpora construction, further contrastive pre-training, task-driven instruction tuning, filtering strategy, and an evaluation system. The key of BRIGHT is to leverage reverse relations to create a symmetric graph and transform the bi-directional relations into sentence-level ones. The reverse sentences are considered positive examples for forward sentences, and three types of negatives are introduced to ensure efficient contrastive learning, which mitigates the “reversal curse” issue as evidenced in experiments. Empirical results demonstrate that BRIGHT is able to generate novel knowledge (up to 397K) and that the GPT-4 acceptance rate is high quality, with up to 90.51% (ATOMIC) and 85.59% (ConceptNet) accuracy at top 1, which approaches human performance for these resources. Our BRIGHT is publicly available at https://github.com/GreyHuu/BRIGHT/tree/main. © 2025 Elsevier Ltd},
	author_keywords = {Commonsense knowledge; Knowledge generation; Large language models; LLMs for KG generation},
	keywords = {Knowledge graph; Bi-directional; Commonsense knowledge; Graph-based; Knowledge generations; Knowledge graphs; Language model; Large language model; Large language model for KG generation; Pre-training; Contrastive Learning},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Feng202514485,
	author = {Feng, Wenyan and Li, Yuhang and Ma, Chunhao and Yu, Lisai},
	title = {From ChatGPT to Sora: Analyzing Public Opinions and Attitudes on Generative Artificial Intelligence in Social Media},
	year = {2025},
	journal = {IEEE Access},
	volume = {13},
	pages = {14485 – 14498},
	doi = {10.1109/ACCESS.2025.3530683},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215949907&doi=10.1109%2fACCESS.2025.3530683&partnerID=40&md5=718d06733f4e8d9942c585443f07e9f3},
	abstract = {This study examines public opinions, emotional tendencies, and psychological linguistic characteristics associated with the launch of OpenAI's ChatGPT and the advanced video generation model, Sora, by analyzing discussions on the Chinese social media platform Weibo. A total of 24,727 valid user-generated texts (1,762,296 words) were collected and analyzed using Python and its associated APIs. Word co-occurrence network analysis, topic modeling based on Latent Dirichlet Allocation (LDA), and emotional characteristics based on the DLUT Emotion Ontology and psycholinguistic analyses based on the Linguistic Inquiry and Word Count (LIWC) dictionary were employed to explore public views on these generative AI technologies. The findings reveal a shift in public focus over time, from initial excitement about technological advancements to growing interest in commercialization, labor, education, ethics, and global competition. The public's emotional responses to AI were a mix of excitement and apprehension. The study identifies seven distinct emotional types, providing a nuanced understanding of public psychological reactions, which contrasts with previous binary classifications. This research contributes valuable insights for policymakers, businesses, and researchers, highlighting the public's evolving acceptance of generative AI technologies. © 2025 The Authors.},
	author_keywords = {ChatGPT; Generative artificial intelligence; psycholinguistics; sentiment analysis; sora; topic modeling},
	keywords = {Social psychology; AI Technologies; ChatGPT; Generative artificial intelligence; Psycholinguistic; Public attitudes; Public opinions; Sentiment analysis; Social media; Sora; Topic Modeling; Generative adversarial networks},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@CONFERENCE{Lin2025,
	author = {Lin, Tianzhen and Liu, Hengyu and Wang, Cui and Yang, Huimin},
	title = {Construction of the proprietary model of metro intelligent customer service based on open source large language model},
	year = {2025},
	journal = {Proceedings of SPIE - The International Society for Optical Engineering},
	volume = {13422},
	doi = {10.1117/12.3050797},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216928095&doi=10.1117%2f12.3050797&partnerID=40&md5=8ce1108a7533aac08512d4e69678577a},
	abstract = {The growth of passenger flow in Qingdao Metro has led to the rise of customer service demand. The existing customer service system is constructed based on NLP and knowledge graph, which has the problems of inaccurate understanding of questions, low correlation of answers, and low passenger satisfaction. With the development of large language model technology, customized large language models combined with domain-specific knowledge are increasingly applied to practical application scenarios. After comparing the mainstream open-source large language models, this paper selects Qwen2-7B model as the base model, combines the special knowledge of Qingdao Metro customer service field, generates the Qingdao Metro special customer service model through pre-training and fine-tuning, and develops the Qingdao Metro intelligent customer service agent by means of retrieval-augmented generation and prompt engineering. The evaluation test shows that the score of the model reaches 87 points, which is greater than the 80 points of the Qwen2-7B general model and the 45 points of the existing customer service system. Compared with the original customer service system of Qingdao Metro, the answer accuracy of the model is increased by 38%, and the answer accuracy is increased by 16% compared with the general model. The proprietary large language model of metro intelligent customer service based on open source large language model can effectively solve passenger problems and improve passenger satisfaction. © 2025 SPIE.},
	author_keywords = {adaptive fine-tuning; intelligent customer service; large language model; retrieval-augmented generation; urban rail transit},
	keywords = {Customer satisfaction; Light rail transit; Mass transportation; Problem oriented languages; Railroad transportation; Subways; Urban transportation; Adaptive fine-tuning; Customer service systems; Customer-service; Intelligent customer service; Language model; Large language model; Open-source; Qingdao; Retrieval-augmented generation; Urban rail transit; Sales},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Huang2025,
	author = {Huang, Shubin and Cai, Yi and Yuan, Li and Wang, Jiexin},
	title = {A knowledge-enhanced network for joint multimodal entity-relation extraction},
	year = {2025},
	journal = {Information Processing and Management},
	volume = {62},
	number = {3},
	doi = {10.1016/j.ipm.2024.104033},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213264535&doi=10.1016%2fj.ipm.2024.104033&partnerID=40&md5=78bb33fc8f643cbb0d2bcae83e3a35b1},
	abstract = {In the domain of multimodal analysis, Multimodal Named Entity Recognition (MNER) and Multimodal Relation Extraction (MRE) are two pivotal tasks aiming at identifying named entities and their relations by leveraging integrated information from text–image pairs. Recently, Joint Multimodal Entity-Relation Extraction (JMERE) has emerged as a unified task to combine MNER and MRE, exploiting the bidirectional interactions between the two tasks for enhanced performance. However, existing JMERE studies primarily focus on improving visual information utilization through feature alignment, often falling short when social media texts and accompanying images lack sufficient information, leading to inaccuracies in entity type and relation recognition. To tackle this challenge, we propose KEJME, a knowledge-enhanced network tailored for the JMERE task. KEJME utilizes GPT-3.5 and ConceptNet as knowledge sources to supplement the missing context information of text–image pairs by infusing external knowledge. Moreover, to ensure the relevance of imported knowledge, we introduce a knowledge feature selection module, which performs a fine-grained selection of knowledge features according to different visual objects and textual entities. Numerous experiments have demonstrated that KEJME significantly surpasses state-of-the-art methods, achieving substantial improvements in both recall and F1 score. These findings highlight the critical role of external knowledge integration and fine-grained knowledge selection in advancing multimodal entity-relation extraction. © 2024},
	author_keywords = {Joint multimodal entity-relation extraction; Knowledge graphs; Large language models},
	keywords = {Feature Selection; Entity relation extractions; Image pairs; Joint multimodal entity-relation extraction; Knowledge graphs; Language model; Large language model; Multi-modal; Named entity recognition; Relation extraction; Text images; Knowledge graph},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Zhu2025,
	author = {Zhu, Lilu and Su, Xiaolu and Tang, Jiaxuan and Hu, Yanfeng and Wang, Yang},
	title = {View-Based Knowledge-Augmented Multimodal Semantic Understanding for Optical Remote Sensing Images},
	year = {2025},
	journal = {IEEE Transactions on Geoscience and Remote Sensing},
	doi = {10.1109/TGRS.2025.3532349},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216226535&doi=10.1109%2fTGRS.2025.3532349&partnerID=40&md5=efc5d9675824186742e7c3d19f9eb673},
	abstract = {Optical remote sensing (RS) images serve as a pivotal source of geographic information. Owing to the continuous development of deep learning technology, the evolving demands for multisource optical RS of the public shifted from recognition and acquisition of explicit features to comprehension and application of the fine-grained semantics and relationships implied in images. To address this challenge, we propose a semantic-augmented approach integrated multiview knowledge graph for a comprehensive understanding of optical RS images (RSMVKF). The RSMVKF delves into the structured representations of external knowledge from different human-like cognitive views and further explores the discovery ability of high-level features on the basis of multiple modalities and granularities. Specifically, the RSMVKF consists of two stages. First, we guide a large language model to condense relevant knowledge from lengthy external knowledge passages and generate a view-level knowledge graph (RS-VKG). Then, an asymmetric multimodal contrastive network model (RS-M2CL) is designed to investigate efficient semantic augmentation. In this way, two types of contrastive loss functions, cross-modal and cross-granularity, are adopted to improve the understanding of implicit knowledge. The experimental results demonstrate that the RSMVKF greatly improves several perception tasks and reasoning tasks with rich features in optical RS imagery. In particular, in perception tasks such as fine-grained object detection and k-nearest neighbor retrieval, the RSMVKF yields enhancements of 6.7% and 8.1%, respectively. In addition, in knowledge-driven reasoning tasks such as RS image captioning, RS visual grounding and RS visual question answering, the RSMVKF demonstrates superior performance with margins of 8.9%, 5.3%, and 11.4%, respectively. © 2025 IEEE.},
	author_keywords = {fine-grained semantics and relationships; multimodal contrastive network; multiview knowledge graph; Optical remote sensing images; semantic-augmented approach},
	keywords = {Contrastive Learning; Deep learning; Nearest neighbor search; Network theory (graphs); Semantics; Visual languages; Fine grained; Fine-grained semantic and relationship; Knowledge graphs; Multi-modal; Multi-views; Multimodal contrastive network; Multiview knowledge graph; Optical remote sensing; Optical remote sensing image; Remote sensing images; Semantic-augmented approach; Knowledge graph},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Ferraris2025125,
	author = {Ferraris, Davide and Kotis, Konstantinos and Kalloniatis, Christos},
	title = {Enhancing TrUStAPIS Methodology in the Web of Things with LLM-Generated IoT Trust Semantics},
	year = {2025},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) },
	volume = {15056 LNCS},
	pages = {125 – 144},
	doi = {10.1007/978-981-97-8798-2_7},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215544187&doi=10.1007%2f978-981-97-8798-2_7&partnerID=40&md5=5af298fe41e46ae5ca8d0e6bac9a5899},
	abstract = {In the Internet of Things (IoT) there are ecosystems where their physical’smart’ entities virtually interact with each other. Often, this interaction occurs among unknown entities, making trust an essential requirement to overcome uncertainty in several aspects of this interaction. However, trust is a complex concept, and incorporating it in IoT is still a challenging topic. For this reason, it is highly significant to specify and model trust in early stages of the System Development Life Cycle (SDLC) of IoT-integrated systems, thus enhancing the aforementioned task. TrUStAPIS is a requirements engineering methodology recently introduced for incorporating trust requirements during IoT-based system design. The scope of this paper is to provide an extension of TrUStAPIS by introducing IoT trust semantics compatible with the W3C Web of Things (WoT) recommendations generated with the assistance of Large Language Models (LLMs). Taking advantage of LLMs as a tool for integrating and refining existing methodologies, in this paper we present our work towards a revision of the TrUStAPIS methodology. In this work, we contribute a new conceptual model and a refined JSON-LD ontology that takes into account IoT trust semantics, providing eventually a valuable tool for software engineers to design and model IoT-based systems and services. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2025.},
	author_keywords = {Internet of Things (IoT); JSON-LD; Large Language Model (LLM); Trust; Web of Things (WoT)},
	keywords = {Problem oriented languages; Software design; Internet of thing; JSON-LD; Language model; Large language model; Model trusts; Systems development life cycle; Trust; Uncertainty; Unknown entities; Web of thing; Requirements engineering},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Liu2025199,
	author = {Liu, Yang and Tian, Xiaobin and Sun, Zequn and Hu, Wei},
	title = {Finetuning Generative Large Language Models with Discrimination Instructions for Knowledge Graph Completion},
	year = {2025},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) },
	volume = {15231 LNCS},
	pages = {199 – 217},
	doi = {10.1007/978-3-031-77844-5_11},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211246698&doi=10.1007%2f978-3-031-77844-5_11&partnerID=40&md5=a79ed844b0ef02aa45c870bc9fe94717},
	abstract = {Traditional knowledge graph (KG) completion models learn embeddings to predict missing facts. Recent works attempt to complete KGs in a text-generation manner with large language models (LLMs). However, they need to ground the output of LLMs to KG entities, which inevitably brings errors. In this paper, we present a finetuning framework, DIFT, aiming to unleash the KG completion ability of LLMs and avoid grounding errors. Given an incomplete fact, DIFT employs a lightweight model to obtain candidate entities and finetunes an LLM with discrimination instructions to select the correct one from the given candidates. To improve performance while reducing instruction data, DIFT uses a truncated sampling method to select useful facts for finetuning and injects KG embeddings into the LLM. Extensive experiments on benchmark datasets demonstrate the effectiveness of our proposed framework. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.},
	author_keywords = {Instruction tuning; Knowledge graph completion; Large language model},
	keywords = {Graph embeddings; Embeddings; Improve performance; Instruction tuning; Knowledge graph completion; Knowledge graphs; Language model; Large language model; Learn+; Text generations; Traditional knowledge; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Susanti202587,
	author = {Susanti, Yuni and Färber, Michael},
	title = {Knowledge Graph Structure as Prompt: Improving Small Language Models Capabilities for Knowledge-Based Causal Discovery},
	year = {2025},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) },
	volume = {15231 LNCS},
	pages = {87 – 106},
	doi = {10.1007/978-3-031-77844-5_5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211201070&doi=10.1007%2f978-3-031-77844-5_5&partnerID=40&md5=439f4f7bc4948195a977f708951aa621},
	abstract = {Causal discovery aims to estimate causal structures among variables based on observational data. Large Language Models (LLMs) offer a fresh perspective to tackle the causal discovery problem by reasoning on the metadata associated with variables rather than their actual data values, an approach referred to as knowledge-based causal discovery. In this paper, we investigate the capabilities of Small Language Models (SLMs, defined as LLMs with fewer than 1 billion parameters) with prompt-based learning for knowledge-based causal discovery. Specifically, we present “KG Structure as Prompt”, a novel approach for integrating structural information from a knowledge graph, such as common neighbor nodes and metapaths, into prompt-based learning to enhance the capabilities of SLMs. Experimental results on three types of biomedical and open-domain datasets under few-shot settings demonstrate the effectiveness of our approach, surpassing most baselines and even conventional fine-tuning approaches trained on full datasets. Our findings further highlight the strong capabilities of SLMs: in combination with knowledge graphs and prompt-based learning, SLMs demonstrate the potential to surpass LLMs with larger number of parameters. Our code and datasets are available on GitHub.1(https://github.com/littleflow3r/kg-structure-as-prompt) © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.},
	author_keywords = {causal relation; knowledge graph; language model},
	keywords = {Adversarial machine learning; Contrastive Learning; Actual data values; Causal relations; Fine tuning; Graph structures; Knowledge based; Knowledge graphs; Language model; Neighbour nodes; Observational data; Structural information; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Yang2025,
	author = {Yang, Rui and Zhu, Jiahao and Man, Jianping and Liu, Hongze and Fang, Li and Zhou, Yi},
	title = {GS-KGC: A generative subgraph-based framework for knowledge graph completion with large language models},
	year = {2025},
	journal = {Information Fusion},
	volume = {117},
	doi = {10.1016/j.inffus.2024.102868},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213078617&doi=10.1016%2fj.inffus.2024.102868&partnerID=40&md5=d3f616478a490d56502257600cbc5bcb},
	abstract = {Knowledge graph completion (KGC) focuses on identifying missing triples in a knowledge graph (KG), which is crucial for many downstream applications. Given the rapid development of large language models (LLMs), some LLM-based methods are proposed for KGC task. However, most of them focus on prompt engineering while overlooking the fact that finer-grained subgraph information can aid LLMs in generating more accurate answers. In this paper, we propose a novel completion framework called Generative Subgraph-based KGC (GS-KGC), which utilizes subgraph information as contextual reasoning and employs a QA approach to achieve the KGC task. This framework primarily includes a subgraph partitioning algorithm designed to generate negatives and neighbors. Specifically, negatives can encourage LLMs to generate a broader range of answers, while neighbors provide additional contextual insights for LLM reasoning. Furthermore, we found that GS-KGC can discover potential triples within the KGs and new facts beyond the KGs. Experiments conducted on four common KGC datasets highlight the advantages of the proposed GS-KGC, e.g., it shows a 5.6% increase in Hits@3 compared to the LLM-based model CP-KGC on the FB15k-237N, and a 9.3% increase over the LLM-based model TECHS on the ICEWS14. © 2024 Elsevier B.V.},
	author_keywords = {Knowledge graph; Knowledge graph completion; Large language models; Question answer},
	keywords = {Generative adversarial networks; Downstream applications; Knowledge graph completion; Knowledge graphs; Language model; Large language model; Model-based method; Model-based OPC; Question answer; Subgraphs; Knowledge graph},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Xiang20251055,
	author = {Xiang, Yunfei and Lin, Peng and Luo, Yiming and Ning, Zeyu and Liu, Yuanguang and Liu, Ke},
	title = {Integrating Knowledge Graph and Large Language Model for Safety Management Regulatory Texts},
	year = {2025},
	journal = {Mechanisms and Machine Science},
	volume = {175 MMS},
	pages = {1055 – 1062},
	doi = {10.1007/978-3-031-81673-4_76},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215576892&doi=10.1007%2f978-3-031-81673-4_76&partnerID=40&md5=70328c4bbb8b0af69507081b025a8ca6},
	abstract = {The safety management in the infrastructure industry is governed by a variety of regulatory documents and management codes. However, the current regulation compliance checking often relies on manual or exhaustive matching methods, which can result in issues such as inconsistent rating scales, artificial manipulation, and time-consuming procedures. Therefore, this study presents a novel approach that integrates knowledge graph (KG) and large language model (LLM) to facilitate knowledge mining and application in safety management regulatory texts. First, a semantic expression framework is established to represent the domain knowledge of regulatory texts. Subsequently, considering the requirements of rule interpretation, knowledge extraction is carried out on the regulatory texts to obtain KG. Then, based on the prompt-tuning, the KG is leveraged to enhance LLM’s inference of regulatory documents and management codes. Finally, a safety management workflow based on automatic rule interpretation is proposed and successfully applied to a hydropower project. The results demonstrate that this method can effectively enhance the interpretability of safety management codes and reduce reliance on domain experts. This study substantiates the effectiveness of integrating KG and LLM for knowledge mining and application. This work can provide a practical reference for enhancing automated and intelligent safety management in the infrastructure industry. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.},
	author_keywords = {Automated compliance checking; Knowledge graph; Large language model; Safety management},
	keywords = {Hydroelectric power plants; Inference engines; Knowledge graph; Automated compliance checking; Infrastructure industry; Knowledge application; Knowledge graphs; Knowledge mining; Language model; Large language model; Regulatory documents; Regulatory management; Safety management; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Polo-Bautista2025148,
	author = {Polo-Bautista, Luis Roberto and Orantes-Jiménez, Sandra Dinora and Carrillo-Brenes, Francisco and Vilches-Blázquez, Luis M.},
	title = {Semi-automatic Construction of Knowledge Graphs on Natural Disasters in Mexico Using Large Language Models},
	year = {2025},
	journal = {Communications in Computer and Information Science},
	volume = {2298 CCIS},
	pages = {148 – 167},
	doi = {10.1007/978-3-031-80017-7_10},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214095969&doi=10.1007%2f978-3-031-80017-7_10&partnerID=40&md5=09b68cf5890cb0021665a534829dfefb},
	abstract = {The growing trend of developing Large Language Models (LLMs) has gained popularity due to their ability to process and generate natural language, which has applications in various industries. However, the use of LLMs to build domain-specific knowledge graphs remains challenging due to the reliance on human experts to define entities and relationships and to address problems such as information granularity, lack of timeliness, etc. This work presents a workflow that integrates three different LLMs (Llama 3, GPT-4o, and Claude 3 Sonnet) to perform a semiautomated construction of knowledge graphs from news related to natural disasters in Mexico. This ongoing work provides a preliminary assessment of the ability of LLMs to represent specific knowledge domains, with the potential to improve accessibility and retrieval of relevant data, thus facilitating future identification of associations and patterns related to natural disasters. The experiments carried out have shown that our workflow enriches the identification and relationships of entities from the news corpus. However, our current evaluation shows that the LLMs used are far from replacing human intervention. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.},
	author_keywords = {Knowledge graphs; Large Language Models; Mexico; Natural Disasters; News},
	keywords = {Disasters; Domain Knowledge; Automatic construction; Knowledge graphs; Language model; Large language model; Me-xico; Natural disasters; Natural languages; News; Semi-automatics; Work-flows; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Sahbi2025,
	author = {Sahbi, Aya and Alec, Céline and Beust, Pierre},
	title = {Semantic vs. LLM-based approach: A case study of KOnPoTe vs. Claude for ontology population from French advertisements},
	year = {2025},
	journal = {Data and Knowledge Engineering},
	volume = {156},
	doi = {10.1016/j.datak.2024.102392},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211195979&doi=10.1016%2fj.datak.2024.102392&partnerID=40&md5=02c515e48e4f87f8a37fa3a9d5820e8f},
	abstract = {Automatic ontology population is the process of identifying, extracting, and integrating relevant information from diverse sources to instantiate the classes and properties specified in an ontology, thereby creating a Knowledge Graph (KG) for a particular domain. In this study, we evaluate two approaches for ontology population from text: KOnPoTe, a semantic technique that employs textual and domain knowledge analysis, and a generative AI method leveraging Claude, a Large Language Model (LLM). We conduct comparative experiments on three French advertisement domains: real estate, boats, and restaurants to assess the performance of these techniques. Our analysis highlights the respective strengths and limitations of the semantic approach and the LLM-based one in the context of the ontology population process. © 2024 The Authors},
	author_keywords = {LLM; Ontology population; Textual descriptions},
	keywords = {Domain Knowledge; Ontology; Semantics; Automatic ontology; Case-studies; Knowledge graphs; Language model; Large language model; Model based approach; Ontology Population; Ontology's; Property; Textual description; Knowledge graph},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Bashir2025,
	author = {Bashir, Aneesa and Peng, Rong and Ding, Yongchang},
	title = {Logic-infused knowledge graph QA: Enhancing large language models for specialized domains through Prolog integration},
	year = {2025},
	journal = {Data and Knowledge Engineering},
	volume = {157},
	doi = {10.1016/j.datak.2025.102406},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216548630&doi=10.1016%2fj.datak.2025.102406&partnerID=40&md5=ac54bb02e7892f25f830b0f1b98e34ab},
	abstract = {Efficiently answering questions over complex, domain-specific knowledge graphs remain a substantial challenge, as large language models (LLMs) often lack the logical reasoning abilities and particular knowledge required for such tasks. This paper presents a novel framework integrating LLMs with logical programming languages like Prolog for Logic-Infused Knowledge Graph Question Answering (KGQA) in specialized domains. The proposed methodology uses a transformer-based encoder–decoder architecture. An encoder reads the question, and a named entity recognition (NER) module connects entities to the knowledge graph. The extracted entities are fed into a grammar-guided decoder, producing a logical form (Prolog query) that captures the semantic constraints and relationships. The Prolog query is executed over the knowledge graph to perform symbolic reasoning and retrieve relevant answer entities. Comprehensive experiments on the MetaQA benchmark dataset demonstrate the superior performance of this logic-infused method in accurately identifying correct answer entities from the knowledge graph. Even when trained on a limited subset of annotated data, it outperforms state-of-the-art baselines, achieving 89.60 % and F1-scores of up to 89.61 %, showcasing its effectiveness in enhancing large language models with symbolic reasoning capabilities for specialized question-answering tasks. The seamless integration of LLMs and logical programming enables the proposed framework to reason effectively over complex, domain-specific knowledge graphs, overcoming a key limitation of existing KGQA systems. In specialized domains, the interpretability provided by representing questions such as Prologue queries is a valuable asset. © 2025},
	author_keywords = {BERT; Knowledge Graph Question Answering (KGQA); Large language models (LLMs); Logical programming (Prolog); Multi-hop reasoning; Named entity recognition (NER); Transformer},
	keywords = {Decoding; Domain Knowledge; PROLOG (programming language); Query languages; Semantics; Structured Query Language; BERT; Knowledge graph question answering; Knowledge graphs; Language model; Large language model; Logical programming; Logical programming (prolog); Multi-hop reasoning; Multi-hops; Named entity recognition; Question Answering; Transformer; Knowledge graph},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Gu2025,
	author = {Gu, Zhining and Li, Wenwen and Zhou, Bing and Wang, Yikang and Chen, Yanbing and Ye, Shan and Wang, Kejin and Gu, Hongkai and Kang, Yuhao},
	title = {GISphere Knowledge Graph for Geography Education: Recommending Graduate Geographic Information System/Science Programs},
	year = {2025},
	journal = {Transactions in GIS},
	volume = {29},
	number = {1},
	doi = {10.1111/tgis.13283},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211170723&doi=10.1111%2ftgis.13283&partnerID=40&md5=65a71fd180f04e858bb91b9ec48b80a6},
	abstract = {The growing global interest in Geographic Information System/Science (GIS) programs has led to an increased demand for higher education in this field. However, students often struggle to identify suitable programs and faculty due to the overwhelming options and the lack of personalized guidance. This paper presents GISphere-KG, an AI-powered platform based on the GISphere project. It combines knowledge graph (KG) and large language models (LLMs) to enhance the search and recommendation of GIS-related graduate programs. GISphere-KG offers four key features: (1) interactive conversation that provides natural language responses to applicants' inquiries; (2) efficient information retrieval through semantic relationships built within the KG; (3) discovery of professors whose research interests align with those of the applicants, offering more choices within specific research fields; and (4) personalized program recommendations tailored to applicants' academic and career developments. Our platform aims to provide a user-friendly tool that assists prospective students in achieving their career goals and enriching the geography community by attracting more talent and promoting global geography education. © 2024 John Wiley & Sons Ltd.},
	author_keywords = {education; GIS; information retrieval; knowledge graph; large language model; program recommendation},
	keywords = {Information hiding; Information retrieval; Students; Geographic information; Geographic information system/science; Geography educations; High educations; Knowledge graphs; Language model; Large language model; Personalized guidance; Program recommendation; Science projects; geography education; GIS; student; Knowledge graph},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Xiang2025443,
	author = {Xiang, Lingzhi and Li, Qing and Li, Xiang and Diao, Xingchun},
	title = {G-ETI: Incorporating Graph Information for Improved Unsupervised Event Type Induction},
	year = {2025},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) },
	volume = {15437 LNCS},
	pages = {443 – 455},
	doi = {10.1007/978-981-96-0567-5_31},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211910786&doi=10.1007%2f978-981-96-0567-5_31&partnerID=40&md5=ade90e6a026d1f0a39b10b493014b9c7},
	abstract = {An event ontology is useful for the semantic integration of heterogeneous datasets related to events. To reduce manual efforts in event ontology construction, several Event-Type Induction (ETI) methods were proposed to automatically find new event types from a given data source. Existing ETI methods utilize a corpus-based data source, and achieve the ETI goal via document clustering over pre-trained neural text embeddings. Most of the ETI methods require a semi-supervised setting to obtain a satisfactory result. In this paper, we improve ETI performance by incorporating graph-based data sources, which usually consists of event nodes, participant subjects/objects and the relational edges. Our motivation is that event type information learned from an event graph can complement that learned from text. This idea leads to the Graph-ETI (G-ETI) algorithm, where event clusters are initially identified from text embeddings and later refined through graph-based label propagation. Our algorithm naturally supports the unsupervised ETI setting where no event types are known beforehand. Moreover, we also provide an LLM-based naming module to generate appropriate names for the new event clusters. In the experiment, our method exhibits better event clustering performance compared to existing baselines, especially in the unsupervised setting. These improved clustering assignments combined with our LLM naming module can lead to high-quality ETI capability, which facilitates the event ontology construction process. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2025.},
	author_keywords = {Event Graph; Event Ontology Construction; Event-Type Induction},
	keywords = {Graph algorithms; Graph embeddings; Ontology; Data-source; Embeddings; Event graphs; Event ontology; Event ontology construction; Event Types; Event-type induction; Induction method; Ontology construction; Performance; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{2025,
	title = {23rd China National Conference on Computational Linguistics, CCL 2024},
	year = {2025},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) },
	volume = {14761 LNAI},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211360723&partnerID=40&md5=16c5a4a8f2f3b0bb57c2d02cae201a7c},
	abstract = {The proceedings contain 34 papers. The special focus in this conference is on Computational Linguistics. The topics include: Joint Similarity Guidance Hash Coding Based on Adaptive Weight Mixing Strategy For Cross-Modal Retrieval; generate-then-Revise: An Effective Synthetic Training Data Generation Framework for Event Detection; e3: Optimizing Language Model Training for Translation via Enhancing Efficiency and Effectiveness; multi-features Enhanced Multi-task Learning for Vietnamese Treebank Conversion; SimCLNMT: A Simple Contrastive Learning Method for Enhancing Neural Machine Translation Quality; translate-and-Revise: Boosting Large Language Models for Constrained Translation; a Multi-task Biomedical Named Entity Recognition Method Based on Data Augmentation; biomedical Event Causal Relation Extraction by Reasoning Optimal Entity Relation Path; joint Entity and Relation Extraction Based on Bidirectional Update and Long-Term Memory Gate Mechanism; MFE-NER: Multi-feature Fusion Embedding for Chinese Named Entity Recognition; UDAA: An Unsupervised Domain Adaptation Adversarial Learning Framework for Zero-Resource Cross-Domain Named Entity Recognition; triple-view Event Hierarchy Model for Biomedical Event Representation; dialectMoE: An End-to-End Multi-dialect Speech Recognition Model with Mixture-of-Experts; distinguishing Neural Speech Synthesis Models Through Fingerprints in Speech Waveforms; knowledge Graph-Enhanced Recommendation with Box Embeddings; Readability-Guided Idiom-Aware Sentence Simplification (RISS) for Chinese; a Tone-Based Hierarchical Structure of Chinese Prosody; Linguistic Guidance for Sequence-to-Sequence AMR Parsing; Automatic Construction of the English Sentence Pattern Structure Treebank for Chinese ESL Learners; cost-Efficient Crowdsourcing for Span-Based Sequence Labeling: Worker Selection and Data Augmentation; DLUE: Benchmarking Document Language Understanding; do Large Language Models Understand Conversational Implicature – A Case Study with a Chinese Sitcom; emoFake: An Initial Dataset for Emotion Fake Audio Detection; going Beyond Passages: Readability Assessment for Book-Level Long Texts; mitigating the Bias of Large Language Model Evaluation; PPDAC: A Plug-and-Play Data Augmentation Component for Few-Shot Extractive Question Answering; Sentence-Space Metrics (SSM) for the Evaluation of Sentence Comprehension.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Lopez2025,
	author = {Lopez, Vanessa and Hoang, Lam and Martinez-Galindo, Marcos and Fernández-Díaz, Raúl and Sbodio, Marco Luca and Ordonez-Hurtado, Rodrigo and Zayats, Mykhaylo and Mulligan, Natasha and Bettencourt-Silva, Joao},
	title = {Enhancing foundation models for scientific discovery via multimodal knowledge graph representations},
	year = {2025},
	journal = {Journal of Web Semantics},
	volume = {84},
	doi = {10.1016/j.websem.2024.100845},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213079148&doi=10.1016%2fj.websem.2024.100845&partnerID=40&md5=ec47f62ef32ff03a88281a295a913215},
	abstract = {Foundation Models (FMs) hold transformative potential to accelerate scientific discovery, yet reaching their full capacity in complex, highly multimodal domains such as genomics, drug discovery, and materials science requires a deeper consideration of the contextual nature of the scientific knowledge. We revisit the synergy between FMs and Multimodal Knowledge Graph (MKG) representation and learning, exploring their potential to enhance predictive and generative tasks in biomedical contexts like drug discovery. We seek to exploit MKGs to improve generative AI models’ ability to capture intricate domain-specific relations and facilitate multimodal fusion. This integration promises to accelerate discovery workflows by providing more meaningful multimodal knowledge-enhanced representations and contextual evidence. Despite this potential, challenges and opportunities remain, including fusing multiple sequential, structural and knowledge modalities and models leveraging the strengths of each; developing scalable architectures for multi-task multi-dataset learning; creating end-to-end workflows to enhance the trustworthiness of biomedical FMs using knowledge from heterogeneous datasets and scientific literature; the domain data bottleneck and the lack of a unified representation between natural language and chemical representations; and benchmarking, specifically the transfer learning to tasks with limited data (e.g., unseen molecules and proteins, rear diseases). Finally, fostering openness and collaboration is key to accelerate scientific breakthroughs. © 2024},
	author_keywords = {Knowledge-enhanced drug discovery; Multimodal graph learning; Multimodal knowledge graphs},
	keywords = {Drug discovery; Foundation models; Graph representation; Knowledge graphs; Knowledge-enhanced drug discovery; Multi-modal; Multimodal graph learning; Multimodal knowledge graph; Scientific discovery; Knowledge graph},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Wang2025107,
	author = {Wang, Yong and Qin, Jiajun and Huang, Yourui and Deng, Jiangzhou},
	title = {Design of University Research Management Question Answering System Integrating Knowledge Graph and Large Language Models; [融合知识图谱和大模型的高校科研管理问答系统设计]},
	year = {2025},
	journal = {Journal of Frontiers of Computer Science and Technology},
	volume = {19},
	number = {1},
	pages = {107 – 117},
	doi = {10.3778/j.issn.1673-9418.2406009},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214352907&doi=10.3778%2fj.issn.1673-9418.2406009&partnerID=40&md5=e6b7ca7b8bdd4746d14b219237186460},
	abstract = {Scientific research management is a crucial aspect of university management. However, existing scientific research management systems cannot meet the individual needs of users. This paper focuses on transforming university scientific research management towards intelligence as the demand orientation, and combines knowledge graph, traditional model and large language models to jointly build a new university scientific research management question answering system. Firstly, the scientific research knowledge is collected to build a scientific research knowledge graph. Then, a multitask model is used for semantic parsing, simultaneously performing intent classification and entity extraction. Finally, the parsing results are used to generate query statements to retrieve information from the knowledge graph and answer general questions. Additionally, large language models are combined with knowledge graph to assist in processing open problems. Experimental results on datasets with associated intents and entities show that the F1 values of the adopted multi-task model in intent classification and entity recognition tasks are 0.958 and 0.937, respectively, surpassing other comparison models and single-task models. The Cypher generation test demonstrates the effectiveness of the custom Prompt in stimulating the emergent abilities of large language models. The accuracy of text-generated Cyphers using large language models reaches 85.8%, effectively handling open questions based on knowledge graph. The accuracy of the question answering system built with knowledge graph, traditional model and large language models is 0.935, which well meets the needs of intelligent question and answer. © 2025 Journal of Computer Engineering and Applications Beijing Co., Ltd.; Science Press. All rights reserved.},
	author_keywords = {intent classification; knowledge graph; large language models; multi-task model; named entity recognition},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Vasu2025134,
	author = {Vasu, Rosni and Sarasua, Cristina and Bernstein, Abraham},
	title = {SciHyp: A Fine-Grained Dataset Describing Hypotheses and Their Components from Scientific Articles},
	year = {2025},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) },
	volume = {15233 LNCS},
	pages = {134 – 152},
	doi = {10.1007/978-3-031-77847-6_8},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211207601&doi=10.1007%2f978-3-031-77847-6_8&partnerID=40&md5=fbde4f8263c5877a525ecf0c85708224},
	abstract = {Scientific discovery entails a detailed understanding and structuring of existing hypotheses—a challenging task due to the variety and complexity of the scientific texts. Despite efforts in domains like bio-medicine and invasion biology, there does not seem to be a curated fine-grained hypothesis dataset derived from scientific articles. This paper presents SciHyp, a novel dataset containing the RDF description of 689 unique hypothesis sentences from 479 scientific articles in the computer science domain. The dataset describes hypotheses of two types: relation-finding hypotheses (526), which indicate a relationship between variables, and comparative (274) hypotheses, which specify comparisons between samples based on a variable and an operator. We created the dataset using a novel and multi-step annotation pipeline incorporating expert annotation, Large Language Models (LLMs) including BERT, Sci-BERT, and crowd-based refinement. Our pipeline effectively identified non-hypothesis sentences with a 96.1% consensus rate between the LLMs and crowd annotations, demonstrating its effectiveness in identifying relevant sentences that contain hypotheses. Furthermore, we extracted the individual components of hypotheses (i.e., their variables and the relation between them) using an in-context learning approach based on GPT-4. We believe the SciHyp dataset will benefit the scientific community by offering a structured dataset for model training and evaluation, and adapting the procedure to curate and analyse large-scale hypothesis datasets. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.},
	author_keywords = {Hypotheses Annotation; Information Extraction; Knowledge Graph; Large Language Models; Scientific Hypotheses; Scientific Knowledge Management},
	keywords = {Fine grained; Hypothesis annotation; Information extraction; Knowledge graphs; Language model; Large language model; Scientific articles; Scientific discovery; Scientific Hypothesis; Scientific knowledge management; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{2025,
	title = {17th International Conference on Interactive Digital Storytelling, ICIDS 2024},
	year = {2025},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) },
	volume = {15468 LNCS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214003660&partnerID=40&md5=94e17355038132cdf213d4e89c91f02f},
	abstract = {The proceedings contain 41 papers. The special focus in this conference is on Interactive Digital Storytelling. The topics include: Where’s the Finance?: A Transmedia Storytelling Experience to Engage Young Adults in Financial Educational Content; navigating Sexualization: A Thematic Analysis of Sexualized Character Design in Modern Video Game Narratives; emotional Believability of Non-playable Game Characters - Animations of Anger, Sadness and Happiness; Finding Queerness in Gaming: How Players See LGBTQ+ Themes in Non-queer Games; popcorn Movie: Dynamic Narrative Feedback for Spontaneous Live Action Video Storytelling; DreaMR: The Effects of Multisensory Design on Cross-Modal Perception Across Genres with Mixed Reality Concert; building Visual Novels with Social Simulation and Storylets; a Tool for the Calculation of Characters’ Emotions; teaching Data Storytelling in a Computational Thinking Course for Students in Communications Careers; el Centro (The Downtown): A Collaborative Transmedia Project Among Ibero-American Universities; subliminal Teaching for Elderly People Through Crossmedia Storytelling; affective Sound: Developing a Critical Framework for Audio-Based Interactive Digital Narratives; What if We Educated Students Assuming They can Think? Introducing the Critical Education Framework (CEF) for Interactive Narratives, Games and Related Fields; fostering Empathy Through Inclusive Interactive Digital Narratives; interactive Digital Narratives for Modern Historical Research; design of Knowledge Graphs for Interactive Digital Narratives Authoring; Being Water: Collaborating with an LLM in an Interactive Digital Narrative (IDN) as Speculative Aesthetics; Exploring Collaborative Interactive Digital Narrative Creation in Higher Education Through Narrative Analysis: A Case Study on COVID-19 Storytelling; The IDN Design Model: A Proposal for an Extended SPP Model.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Young2025,
	author = {Young, Cameron C. and Enichen, Ellie and Rivera, Christian and Auger, Corinne A. and Grant, Nathan and Rao, Arya and Succi, Marc D.},
	title = {Diagnostic Accuracy of a Custom Large Language Model on Rare Pediatric Disease Case Reports},
	year = {2025},
	journal = {American Journal of Medical Genetics, Part A},
	volume = {197},
	number = {2},
	doi = {10.1002/ajmg.a.63878},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203964043&doi=10.1002%2fajmg.a.63878&partnerID=40&md5=7ad8cb35f16633f5b67bcd6373fc285d},
	abstract = {Accurately diagnosing rare pediatric diseases frequently represent a clinical challenge due to their complex and unusual clinical presentations. Here, we explore the capabilities of three large language models (LLMs), GPT-4, Gemini Pro, and a custom-built LLM (GPT-4 integrated with the Human Phenotype Ontology [GPT-4 HPO]), by evaluating their diagnostic performance on 61 rare pediatric disease case reports. The performance of the LLMs were assessed for accuracy in identifying specific diagnoses, listing the correct diagnosis among a differential list, and broad disease categories. In addition, GPT-4 HPO was tested on 100 general pediatrics case reports previously assessed on other LLMs to further validate its performance. The results indicated that GPT-4 was able to predict the correct diagnosis with a diagnostic accuracy of 13.1%, whereas both GPT-4 HPO and Gemini Pro had diagnostic accuracies of 8.2%. Further, GPT-4 HPO showed an improved performance compared with the other two LLMs in identifying the correct diagnosis among its differential list and the broad disease category. Although these findings underscore the potential of LLMs for diagnostic support, particularly when enhanced with domain-specific ontologies, they also stress the need for further improvement prior to integration into clinical practice. © 2024 Wiley Periodicals LLC.},
	author_keywords = {artificial intelligence; diagnostic support; genetics; large language models; pediatric rare disease},
	keywords = {Child; Humans; Pediatrics; Phenotype; Rare Diseases; adrenal insufficiency; Article; artificial intelligence; artificial neural network; Bartter syndrome; bradycardia; case report; childhood disease; clinical practice; congenital heart disease; diagnostic accuracy; diagnostic test accuracy study; fever; gene ontology; genetics; Gitelman syndrome; human; hypoglycemia; hypotension; hypothermia; hypothyroidism; infant; language test; large language model; lethargy; machine learning; muscle hypotonia; natural language processing; phenotype; physiological stress; pseudohypoaldosteronism type 1; rare disease; seizure; sepsis; short stature; child; diagnosis; pediatrics},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Hannah2025,
	author = {Hannah, George and Sousa, Rita T. and Dasoulas, Ioannis and d'Amato, Claudia},
	title = {On the legal implications of Large Language Model answers: A prompt engineering approach and a view beyond by exploiting Knowledge Graphs},
	year = {2025},
	journal = {Journal of Web Semantics},
	volume = {84},
	doi = {10.1016/j.websem.2024.100843},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212850125&doi=10.1016%2fj.websem.2024.100843&partnerID=40&md5=5dedf0bf98928d8562f8f5679f862233},
	abstract = {With the recent surge in popularity of Large Language Models (LLMs), there is the rising risk of users blindly trusting the information in the response. Nevertheless, there are cases where the LLM recommends actions that have potential legal implications and this may put the user in danger. We provide an empirical analysis on multiple existing LLMs showing the urgency of the problem. Hence, we propose a first short-term solution, consisting in an approach for isolating these legal issues through prompt engineering. We prove that this solution is able to stem some risks related to legal implications, nonetheless we also highlight some limitations. Hence, we argue on the need for additional knowledge-intensive resources and specifically Knowledge Graphs for fully solving these limitations. For the purpose, we draw our proposal aiming at designing and developing a solution powered by a legal Knowledge Graph (KG) that, besides capturing and alerting the user on possible legal implications coming from the LLM answers, is also able to provide actual evidence for them by supplying citations of the interested laws. We conclude with a brief discussion on the issues that may be needed to solve for building a comprehensive legal Knowledge Graph © 2024 The Authors},
	author_keywords = {Knowledge Graph; Large Language Models; Legislative texts; Prompt engineering},
	keywords = {Empirical analysis; Knowledge graphs; Language model; Large language model; Legal implications; Legal issues; Legal knowledge; Legislative text; Prompt engineering; Short-term solutions; Knowledge graph},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Constantinou2025,
	author = {Constantinou, Anthony C. and Kitson, Neville K. and Zanga, Alessio},
	title = {Using GPT-4 to guide causal machine learning},
	year = {2025},
	journal = {Expert Systems with Applications},
	volume = {268},
	doi = {10.1016/j.eswa.2024.126120},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213826948&doi=10.1016%2fj.eswa.2024.126120&partnerID=40&md5=edf2527417c032ae103171d1c30eb5f9},
	abstract = {Since its introduction to the public, ChatGPT has had an unprecedented impact. While some experts praised AI advancements and highlighted their potential risks, others have been critical about the accuracy and usefulness of Large Language Models (LLMs). In this paper, we are interested in the ability of LLMs to identify causal relationships. We focus on the well-established GPT-4 (Turbo) and evaluate its performance under the most restrictive conditions, by isolating its ability to infer causal relationships based solely on the variable labels without being given any other context by humans, demonstrating the minimum level of effectiveness one can expect when it is provided with label-only information. We show that questionnaire participants judge the GPT-4 graphs as the most accurate in the evaluated categories, closely followed by knowledge graphs constructed by domain experts, with causal Machine Learning (ML) far behind. We use these results to highlight the important limitation of causal ML, which often produces causal graphs that violate common sense, affecting trust in them. However, we show that pairing GPT-4 with causal ML overcomes this limitation, resulting in graphical structures learnt from real data that align more closely with those identified by domain experts, compared to structures learnt by causal ML alone. Overall, our findings suggest that despite GPT-4 not being explicitly designed to reason causally, it can still be a valuable tool for causal representation, as it improves the causal discovery process of causal ML algorithms that are designed to do just that. © 2024 The Author(s)},
	author_keywords = {Bayesian networks; Causal discovery; ChatGPT; Directed acyclic graphs; Knowledge graphs; LLMs; Structure learning},
	keywords = {Adversarial machine learning; Contrastive Learning; Acyclic graphs; Bayesia n networks; Causal discovery; ChatGPT; Directed acyclic graph; Knowledge graphs; Language model; Large language model; Machine-learning; Structure-learning; Knowledge graph},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Shim2025,
	author = {Shim, Midan and Choi, Hyojun and Koo, Heeyeon and Um, Kaehyun and Lee, Kyong-Ho and Lee, Sanghyun},
	title = {OmEGa(Ω): Ontology-based information extraction framework for constructing task-centric knowledge graph from manufacturing documents with large language model},
	year = {2025},
	journal = {Advanced Engineering Informatics},
	volume = {64},
	doi = {10.1016/j.aei.2024.103001},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211447959&doi=10.1016%2fj.aei.2024.103001&partnerID=40&md5=3b18f14809a1e0a0b11f8f91abfbf59b},
	abstract = {Manufacturing industry relies heavily on technical documents that encapsulate specialized knowledge essential for optimizing production and maintenance processes. However, extracting meaningful insights from these documents is challenging due to their complex structure, domain-specific terminology, and multimodal content, which includes text, images, and tables. Furthermore, there is a contextual gap between the generic training data of pre-trained language models (PLMs) and the specialized knowledge required for manufacturing documents. To address these issues, a Task-Centric Ontology (TCO) is designed to describe fundamental manufacturing tasks, and develop OmEGa, an Ontology-based Information Extraction Framework for Task-Centric Knowledge Graphs. OmEGa leverages large language models (LLMs) to perform instance recognition and relation classification on multimodal documents. By utilizing spatial embedding and modality linking, OmEGa addresses structural challenges, while TCO-driven reasoning mitigates contextual challenges. Experimental results demonstrate the effectiveness of OmEGa, achieving strong performance on both proprietary and open-source datasets. Additionally, a Knowledge Graph Question Answering (KGQA) system built on the extracted task-centric knowledge shows promise in enhancing communication among domain experts in the manufacturing sector. © 2024 Elsevier Ltd},
	author_keywords = {Document understanding; Information extraction; Knowledge graph; Large language model; Manufacturing and maintenance process; Ontology modeling},
	keywords = {Manufacturing data processing; Modeling languages; Ontology; Smart manufacturing; Document understanding; Information extraction; Knowledge graphs; Language model; Large language model; Maintenance process; Manufacturing process; Ontology model; Ontology-based information extraction; Specialized knowledge; Knowledge graph},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Ruan2025,
	author = {Ruan, Jingkai and Su, Qianmin and Chen, Zihang and Huang, Jihan and Li, Ying},
	title = {CPRS: a clinical protocol recommendation system based on LLMs},
	year = {2025},
	journal = {International Journal of Medical Informatics},
	volume = {195},
	doi = {10.1016/j.ijmedinf.2024.105746},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211047180&doi=10.1016%2fj.ijmedinf.2024.105746&partnerID=40&md5=37acadd680459601d77a2832afb26f31},
	abstract = {Background: As fundamental documents in clinical trials, clinical trial protocols are intended to ensure that trials are conducted according to the objectives set by researchers. The advent of large models with superior semantic performance compared to traditional models provides fresh perspectives for research recommendations in clinical trial protocols. Method: A clinical trial protocol recommendation system based on Large Language Models (LLMs) is proposed in this paper, combining GPT-4 and knowledge graph to assist in clinical trial protocol recommendations. Using knowledge graphs as an auxiliary tool, a finite set of clinical trial projects with similar features is identified. Subsequently, through the semantic capabilities of GPT-4, targeted recommendations are made to patients. Results: Experiments were conducted to compare GPT-4 and multiple models from the SBERT family that handle semantic similarity. The results indicate that GPT-4 is capable of better sorting clinical trial protocols based on similarity criteria and offering targeted recommendations to patients. Consequently, this capability meets the matching requirements between projects and patients and enhances the automation of clinical trial protocol recommendations. Additionally, in the future, personal factors of patients will be fully considered during the recommendation process to provide more accurate and personalized protocol recommendations. Conclusion: By integrating knowledge graphs and LLMs, a better understanding and processing of clinical trial protocol information can be achieved, enabling the recommendation of appropriate protocols for patients and enhancing both matching efficiency and accuracy. Furthermore, the application of this system contributes to the automation of clinical trial protocol recommendations, playing a crucial role in medical research institutions such as clinical trial research institutes and public health management departments. Additionally, it significantly aids in advancing the development of clinical trials and the medical field at large. © 2024 Elsevier B.V.},
	author_keywords = {Clinical trial; Knowledge graph; LLMs; Recommendation system},
	keywords = {Clinical research; dapagliflozin; Clinical protocols; Clinical trial; Finite set; Knowledge graphs; Language model; Large language model; Large models; Matchings; Performance; Traditional models; accuracy; Article; artificial intelligence; Chinese medicine; clinical protocol; clinical trial protocol; drug research; fatty liver; follow up; human; medical record; medical research; non insulin dependent diabetes mellitus; nonalcoholic fatty liver; professional knowledge; root mean squared error; United States; workflow; Knowledge graph},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Val-Calvo2025,
	author = {Val-Calvo, Mikel and Egaña Aranguren, Mikel and Mulero-Hernández, Juan and Almagro-Hernández, Ginés and Deshmukh, Prashant and Bernabé-Díaz, José Antonio and Espinoza-Arias, Paola and Sánchez-Fernández, José Luis and Mueller, Juergen and Fernández-Breis, Jesualdo Tomás},
	title = {OntoGenix: Leveraging Large Language Models for enhanced ontology engineering from datasets},
	year = {2025},
	journal = {Information Processing and Management},
	volume = {62},
	number = {3},
	doi = {10.1016/j.ipm.2024.104042},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212843729&doi=10.1016%2fj.ipm.2024.104042&partnerID=40&md5=4899211436b8421e5fbb421e3c04676e},
	abstract = {Knowledge Graphs integrate data from multiple, heterogeneous sources, using ontologies to facilitate data interoperability. Ontology development is a resource-consuming task that requires the collaborative work of domain experts and ontology engineers. Therefore, companies invest considerable resources in order to generate and maintain Enterprise Knowledge Graphs and ontologies from large and complex datasets, most of which can be unfamiliar for ontology engineers. In this work, we study the use of Large Language Models to aid in the development of ontologies from datasets, ultimately increasing the automation of the generation of ontology-based Knowledge Graphs. As a result we have developed a structured workflow that leverages Large Language Models to enhance ontology engineering through data pre-processing, ontology planning, building, and entity improvement. Our method is also able to generate mappings and RDF data, but in this work we focus on the ontologies. The pipeline has been implemented in the OntoGenix tool. In this work we show the results of the application of OntoGenix to six datasets related to commercial activities. The findings indicate that the ontologies produced exhibit patterns of coherent modeling, and features that closely resemble those created by humans, although the most complex situations are better reflected by the ontologies developed by humans. © 2024 The Authors},
	author_keywords = {Knowledge graphs; Large Language Models; Ontology engineering},
	keywords = {Data assimilation; Modeling languages; Collaborative Work; Data interoperability; Domain experts; Heterogeneous sources; Knowledge graphs; Language model; Large language model; Ontology development; Ontology engineering; Ontology's; Knowledge graph},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Kim20257273,
	author = {Kim, Wooyoung and Jung, Haemin and Kim, Wooju},
	title = {Knowledge Graph as Pre-Training Corpus for Structural Reasoning via Multi-Hop Linearization},
	year = {2025},
	journal = {IEEE Access},
	volume = {13},
	pages = {7273 – 7283},
	doi = {10.1109/ACCESS.2024.3523579},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213683860&doi=10.1109%2fACCESS.2024.3523579&partnerID=40&md5=b62157b50794dbbbbd5ba310388b4a8f},
	abstract = {Large language models have demonstrated exceptional performance across various natural language processing tasks. However, their reliance on unstructured text corpora for pre-training limits their effectiveness in tasks requiring structured reasoning such as multi-hop question-answering. Knowledge Graphs provide a rich, structured source of relational data, offering an opportunity to enhance the reasoning capabilities of Large language models. In this paper, we propose a novel framework, Knowledge Graph as Pre-training Corpus (KGPC), which transforms knowledge graphs into text using a multi-hop linearization process. Unlike existing approaches that linearize singular triples, our method captures the interconnected nature of knowledge graphs by linking multiple triples across multiple hops, preserving their relational structure during the pre-training phase. This structured knowledge injection improves language models to perform complex reasoning tasks. We evaluate our approach on multi-hop reasoning benchmarks, demonstrating significant performance gains over existing models, particularly in question-answering tasks. Our results highlight the potential of multi-hop linearization in enhancing the structural reasoning capacity of language models, reducing error propagation, and improving the integration of structured knowledge into language models. © 2013 IEEE.},
	author_keywords = {knowledge graph; Large language model; multi-hop reasoning; question-answering},
	keywords = {Question answering; Structured Query Language; Knowledge graphs; Language model; Large language model; Linearisation; Multi-hop reasoning; Multi-hops; Pre-training; Question Answering; Structural reasoning; Training corpus; Knowledge graph},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Bagozi2025273,
	author = {Bagozi, Ada and Bianchini, Devis and Melchiori, Michele and Rula, Anisa},
	title = {Enhancing LLMs Contextual Knowledge with Ontologies for Personalised Food Recommendation},
	year = {2025},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) },
	volume = {15439 LNCS},
	pages = {273 – 283},
	doi = {10.1007/978-981-96-0573-6_20},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211242004&doi=10.1007%2f978-981-96-0573-6_20&partnerID=40&md5=4665c8600885baa290af26c2ac24b771},
	abstract = {Food recommendation systems help consumers make sustainable and nutritionally complete choices, promoting healthy eating habits and addressing the growing interest in food sustainability and waste reduction. Large Language Models (LLMs), such as ChatGPT, are increasingly used for food recommendations due to their natural language processing capabilities. However, providing personalised and contextually relevant suggestions remains challenging because of the lack of a robust conceptualisation of healthy and sustainable food aligned with users’ dietary and lifestyle preferences. Ontologies can address this by offering a structured and semantically rich framework for organising information. In this paper, we propose a modular ontology to enhance the contextual knowledge of LLMs, enabling them to deliver personalised, contextually relevant food recommendations. The ontology’s modules are based on competency questions derived from a research project focused on sustainable and healthy food recommendations. To evaluate the effectiveness of this approach, we conducted experiments where ChatGPT-4 answered these competency questions with and without ontology integration. The answers were then assessed in a user study. Preliminary experimental results indicate significant improvements in the quality and relevance of recommendations when the ontology is employed. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2025.},
	author_keywords = {Consumer Empowerment; Large Language Models; Multi-perspective Ontology Engineering; Sustainable Food Recommendation},
	keywords = {Consumer empowerment; Contextual knowledge; Eating habits; Language model; Large language model; Multi-perspective; Multi-perspective ontology engineering; Ontology engineering; Ontology's; Sustainable food recommendation},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Li2025350,
	author = {Li, Yansheng and Zhong, Zhenyu and Meng, Qingxiang and Mao, Zhidian and Dang, Bo and Wang, Tao and Feng, Yuanjun and Zhang, Yongjun},
	title = {Intelligent Purification of Natural Resource Element Change Polygons Driven by Remote Sensing Spatiotemporal Knowledge Graphs; [遥感时空知识图谱驱动的自然资源要素变化图斑智能净化]},
	year = {2025},
	journal = {Journal of Geo-Information Science},
	volume = {27},
	number = {2},
	pages = {350 – 366},
	doi = {10.12082/dqxxkx.2025.240571},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216841172&doi=10.12082%2fdqxxkx.2025.240571&partnerID=40&md5=180644f7c04930d59a352d4058b4ed97},
	abstract = {[Objectives] With the development of deep learning technology, the ability to monitor changes in natural resource elements using remote sensing images has significantly improved. While deep learning change detection models excel at extracting low-level semantic information from remote sensing images, they face challenges in distinguishing land-use type changes from non-land-use type changes, such as crop rotation, natural fluctuations in water levels, and forest degradation. To ensure a high recall rate in change detection, these models often generate a large number of false positive change polygons, requiring substantial manual effort to eliminate these false alarms. [Methods] To address this issue, this paper proposes a natural resource element change polygon purification algorithm driven by remote sensing spatiotemporal knowledge graph. The algorithm aims to minimize the false positive rate while maintaining a high recall rate, thereby improving the efficiency of natural resource element change monitoring. To support the intelligent construction and effective reasoning of the spatiotemporal knowledge graph, this study designed a remote sensing spatiotemporal knowledge graph ontology model taking into account spatiotemporal characteristics and developed a GraphGIS toolkit that integrates graph database storage and computation. This paper also introduces a vector knowledge extraction method based on the native spatial analysis of the GraphGIS graph database, a remote sensing image knowledge extraction method based on efficient fine-tuning of the SkySense visual large model, and a polygon purification knowledge extraction method based on the SeqGPT large language model. Under the constraints of the spatiotemporal ontology model, vector, image, and text knowledge converge to form a remote sensing spatiotemporal knowledge graph. Inspired by the manual operation methods for change polygon purification, this paper developed an automatic purification method of change polygons based on first-order logical reasoning within the knowledge graph. To improve the concurrent processing and human-computer interaction, this paper developed a remote sensing spatiotemporal knowledge graph management and service system. [Results] For the task of purifying natural resource element change polygons in Guangdong Province from March to June 2024, the proposed method achieved a true-preserved rate of 95.37% and a false-removed rate of 21.82%. [Conclusions] The intelligent purification algorithm and system for natural resource element change polygons proposed in this study effectively reduce false positives while preserving real change polygons. This approach significantly enhances the efficiency of natural resource element change monitoring. © 2025 Science Press. All rights reserved.},
	author_keywords = {first-order logic reasoning; large language model; natural resource element change monitoring; remote sensing image change detection; remote sensing large model; spatial computing in graph database; spatiotemporal intelligence; spatiotemporal knowledge graph},
	keywords = {Deforestation; Graph Databases; Image retrieval; Knowledge graph; Ontology; Photomapping; Semantics; First order logic; First-order logic reasoning; Graph database; Image change detection; Knowledge graphs; Language model; Large language model; Large models; Logic reasoning; Natural resource element change monitoring; Remote sensing image change detection; Remote sensing images; Remote sensing large model; Remote-sensing; Resource element; Spatial computing; Spatial computing in graph database; Spatiotemporal intelligence; Spatiotemporal knowledge graph},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Koubaa2025355,
	author = {Koubaa, Anis and Ammar, Adel and Boulila, Wadii},
	title = {Next-generation human-robot interaction with ChatGPT and robot operating system},
	year = {2025},
	journal = {Software - Practice and Experience},
	volume = {55},
	number = {2},
	pages = {355 – 382},
	doi = {10.1002/spe.3377},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205287419&doi=10.1002%2fspe.3377&partnerID=40&md5=057521c5337ae930c0c53bb95dd27464},
	abstract = {This article presents an innovative concept that harnesses the capabilities of large language models (LLMs) to revolutionize human-robot interaction. This work aims to connect large language models with the Robot Operating System (ROS), the primary development framework for robotics applications. We develop a package for ROS that seamlessly integrates ChatGPT with ROS2-based robotic systems. The core idea is to leverage prompt engineering with LLMs, utilizing unique properties such as ability eliciting, chain-of-thought, and instruction tuning. The concept employs ontology development to convert unstructured natural language commands into structured robotic instructions specific to the application context through prompt engineering. We capitalize on LLMs' zero-shots and few-shots learning capabilities by eliciting structured robotic commands from unstructured human language inputs. To demonstrate the feasibility of this concept, we implemented a proof-of-concept that integrates ChatGPT with ROS2, showcasing the transformation of human language instructions into spatial navigation commands for a ROS2-enabled robot. Besides, we quantitatively evaluated this transformation over three use cases (ground robot, unmanned aerial vehicle, and Robotic arm) and five LLMs (LLaMA-7b, LLaMA2-7b, LLaMA2-70b, GPT-3.5, and GPT-4) on a set of 3000 natural language commands. Our system serves as a new stride towards Artificial General Intelligence (AGI) and paves the way for the robotics and natural language processing communities to collaborate in creating novel, intuitive human-robot interactions. The open-source implementation of our system on ROS 2 is available on GitHub. © 2024 John Wiley & Sons Ltd.},
	author_keywords = {ChatGPT; human-robot interaction; large language models; mobile robots; ontology; robot operating system},
	keywords = {Mobile robots; Ontology; Problem oriented languages; Robot applications; Robot learning; Robot Operating System; Robotic arms; Unmanned aerial vehicles (UAV); Zero-shot learning; ChatGPT; Development frameworks; Human language; Humans-robot interactions; Language model; Large language model; Natural languages; Ontology's; Robotic systems; Robotics applications; Human robot interaction},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Sequeda2025,
	author = {Sequeda, Juan and Allemang, Dean and Jacob, Bryon},
	title = {Knowledge Graphs as a source of trust for LLM-powered enterprise question answering},
	year = {2025},
	journal = {Journal of Web Semantics},
	volume = {85},
	doi = {10.1016/j.websem.2024.100858},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216449491&doi=10.1016%2fj.websem.2024.100858&partnerID=40&md5=341fe1bc8125aaafc1f3d8907b841021},
	abstract = {Generative AI provides an innovative and exciting way to manage knowledge and data at any scale; for small projects, at the enterprise level, and even at a world wide web scale. It is tempting to think that Generative AI has made other knowledge-based technologies obsolete; that anything we wanted to do with knowledge-based systems, Knowledge Graphs or even expert systems can instead be done with Generative AI. Our position is counter to that conclusion. Our practical experience on implementing enterprise question answering systems using Generative AI has shown that Knowledge Graphs support this infrastructure in multiple ways: they provide a formal framework to evaluate the validity of a query generated by an LLM, serve as a foundation for explaining results, and offer access to governed and trusted data. In this position paper, we share our experience, present industry needs, and outline the opportunities for future research contributions. © 2025 The Authors},
	author_keywords = {Generative AI; Knowledge engineering; Knowledge Graph; Large Language Model; LLM; OWL; Question answering; R2RML; SPARQL; SQL},
	keywords = {Expert systems; Generative adversarial networks; Question answering; Structured Query Language; Generative AI; Knowledge graphs; Knowledge-based technology; Language model; Large language model; LLM; OWL; Question Answering; R2RML; SPARQL; Knowledge graph},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Jundong2025164,
	author = {Jundong, Zhang and Jiangfeng, Liu and Jingpeng, Deng and Yanhua, Liu and Qi, Huang},
	title = {Research on the Framework of Online Medical Health Wisdom Q&A Services Driven by Knowledge Graph and Large Language Model; [图模驱动的在线医疗健康智慧问答服务研究]},
	year = {2025},
	journal = {Journal of Modern Information},
	volume = {45},
	number = {1},
	pages = {164 – 176},
	doi = {10.3969/j.issn.1008-0821.2025.01.012},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214408089&doi=10.3969%2fj.issn.1008-0821.2025.01.012&partnerID=40&md5=bf7ea214689bba6f39f5ce6e68b0777d},
	abstract = {Purpose/Significance] Scholars mostly focused on pursuing the cutting-edge technology of medical intel- ligence Q&A, with less exploration and research on basie theories, and the two have not been integrated and developed. Method/Process On the basis of distinguishing relevant concepts, this study first elaborated on the connotation and char- acteristics of wisdom Q&A services in the field of online healthcare. Then, it deeply analyzed the connection between knowledge graphs and large language models, well as the complementary integration ideas of the two in the field of online healthcare wisdom Q&A. Finally, it proposed a framework of online medical health wisdom Q&A services driven by knowl- edge graphs and large language models. Result/Conclusion The article integrates the theoretical characteristics of medi cal wisdom Q&A services throughout the entire process of wisdom Q&A services, and innovatively proposes that its wisdom Q&A services should include three parts; the construction of medical knowledge graphs driven by large language models, the training of medical large models enhanced by knowledge graphs, and the process of wisdom Q&A services driven by knowledge graphs and large language models. This study achieved a deep integration of theory and technology, and the re- search results can be used for practical work in subsequent medical wisdom Q&A services. © 2025 Editorial Board of Journal of Modern Information. All rights reserved.},
	author_keywords = {knowledge graph; large language model; online medical health; wisdom Q&A services},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Benjira2025,
	author = {Benjira, Wissal and Atigui, Faten and Bucher, Bénédicte and Grim-Yefsah, Malika and Travers, Nicolas},
	title = {Automated mapping between SDG indicators and open data: An LLM-augmented knowledge graph approach},
	year = {2025},
	journal = {Data and Knowledge Engineering},
	volume = {156},
	doi = {10.1016/j.datak.2024.102405},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214962382&doi=10.1016%2fj.datak.2024.102405&partnerID=40&md5=32858e299a7e9ee744941d2592cb9ab0},
	abstract = {Meeting the Sustainable Development Goals (SDGs) presents a large-scale challenge for all countries. SDGs established by the United Nations provide a comprehensive framework for addressing global issues. To monitor progress towards these goals, we need to develop key performance indicators and integrate and analyze heterogeneous datasets. The definition of these indicators requires the use of existing data and metadata. However, the diversity of data sources and formats raises major issues in terms of structuring and integration. Despite the abundance of open data and metadata, its exploitation remains limited, leaving untapped potential for guiding urban policies towards sustainability. Thus, this paper introduces a novel approach for SDG indicator computation, leveraging the capabilities of Large Language Models (LLMs) and Knowledge Graphs (KGs). We propose a method that combines rule-based filtering with LLM-powered schema mapping to establish semantic correspondences between diverse data sources and SDG indicators, including disaggregation. Our approach integrates these mappings into a KG, which enables indicator computation by querying graph's topology. We evaluate our method through a case study focusing on the SDG Indicator 11.7.1 about accessibility of public open spaces. Our experimental results show significant improvements in accuracy, precision, recall, and F1-score compared to traditional schema mapping techniques. © 2025 The Authors},
	author_keywords = {Knowledge graph (KG); Large language model (LLM); Open data; Schema mapping; Sustainable Development Goals (SDG)},
	keywords = {Data accuracy; Knowledge graph; Automated mapping; Data and metadata; Data-source; Knowledge graph; Knowledge graphs; Language model; Large language model; Large-scales; Schema mappings; Sustainable development goal; Sustainable development goals},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Sahadevan2025,
	author = {Sahadevan, Vijayalaxmi and Joshi, Rohin and Borg, Kane and Singh, Vishal and Singh, Abhishek Raj and Muhammed, Bilal and Beemaraj, Soban Babu and Joshi, Amol},
	title = {Knowledge augmented generalizer specializer: A framework for early stage design exploration},
	year = {2025},
	journal = {Advanced Engineering Informatics},
	volume = {65},
	doi = {10.1016/j.aei.2025.103141},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216774787&doi=10.1016%2fj.aei.2025.103141&partnerID=40&md5=08af8a0932cecebc1eb1f969a2c67127},
	abstract = {In non-routine engineering design projects, the design outcome is determined by how the problem is formulated and represented in the early conceptual stage. The problem representation comprises schemas, ontologies, variables, and parameters relevant to the given problem class. Despite the critical role of early conceptual decisions in shaping the eventual design outcome, most of the computational support and automation are focused on the latter stages of parametric modelling, problem-solving, and optimization. There is inadequate support for aiding and automating problem formulation, variable and parameter identification and representation, and early-stage conceptual decisions. Therefore, this paper presents an innovative, transparent, and explainable method employing semantic reasoning to automate the step-by-step conceptual design generation process, including problem formulation, identification and representation of the variables and parameters and their dependencies. The method is realized through a novel framework called Knowledge Augmented Generalizer Specializer (KAGS). KAGS employs the Function-Behavior-Structure (FBS) ontology and the Graph-of-Thought (GoT) mechanism to enable automated reasoning with a Large Language Model (LLM). The workflow comprises various stages: problem breakdown, design prototype creation, assessment, and prototype merging. The framework is implemented and tested on a Subsea Layout (SSL) planning problem, a special class of infrastructure planning projects in deep-sea oil and gas production systems. The experimentations with KAGS demonstrate its capacity to support problem formulation, hierarchical decomposition, and solution generation. The research also provides new insights into the FBS framework and meta-level reasoning in early design stages. © 2025 Elsevier Ltd},
	keywords = {Design Exploration; Design outcomes; Early stage designs; Engineering design programs; Model problems; Ontology's; Parametric models; Problem formulation; Problem representation; Routine engineerings; Gas industry},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Liao2025,
	author = {Liao, Xingming and Chen, Chong and Wang, Zhuowei and Liu, Ying and Wang, Tao and Cheng, Lianglun},
	title = {Large language model assisted fine-grained knowledge graph construction for robotic fault diagnosis},
	year = {2025},
	journal = {Advanced Engineering Informatics},
	volume = {65},
	doi = {10.1016/j.aei.2025.103134},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215555067&doi=10.1016%2fj.aei.2025.103134&partnerID=40&md5=2f8b1b154146589fcaced6c127100ebb},
	abstract = {With the rapid deployment of industrial robots in manufacturing, the demand for advanced maintenance techniques to sustain operational efficiency has become crucial. Fault diagnosis Knowledge Graph (KG) is essential as it interlinks multi-source data related to industrial robot faults, capturing multi-level semantic associations among different fault events. However, the construction and application of fine-grained fault diagnosis KG face significant challenges due to the inherent complexity of nested entities in maintenance texts and the severe scarcity of annotated industrial data. In this study, we propose a Large Language Model (LLM) assisted data augmentation approach, which handles the complex nested entities in maintenance corpora and constructs a more fine-grained fault diagnosis KG. Firstly, the fine-grained ontology is constructed via LLM Assistance in Industrial Nested Named Entity Recognition (assInNNER). Then, an Industrial Nested Label Classification Template (INCT) is designed, enabling the use of nested entities in Attention-map aware keyword selection for the Industrial Nested Language Model (ANLM) data augmentation methods. ANLM can effectively improve the model's performance in nested entity extraction when corpora are scarce. Subsequently, a Confidence Filtering Mechanism (CFM) is introduced to evaluate and select the generated data for enhancement, and assInNNER is further deployed to recall the negative samples corpus again to further improve performance. Experimental studies based on multi-source corpora demonstrate that compared to existing algorithms, our method achieves an average F1 increase of 8.25 %, 3.31 %, and 1.96 % in 5%, 10 %, and 25 % in few-shot settings, respectively. © 2025 Elsevier Ltd},
	author_keywords = {Fault Diagnosis; Industrial Robots; Knowledge Graph; Large Language Model},
	keywords = {Industrial robots; Semantics; Data augmentation; Faults diagnosis; Fine grained; Graph construction; Knowledge graphs; Language model; Large language model; Multi-Sources; Named entity recognition; Rapid deployments; Knowledge graph},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Liu2025,
	author = {Liu, Wei and He, Yixue and Wang, Chao and Xie, Shaorong and Li, Weimin},
	title = {Beyond expression: Comprehensive visualization of knowledge triplet facts},
	year = {2025},
	journal = {Information Processing and Management},
	volume = {62},
	number = {3},
	doi = {10.1016/j.ipm.2025.104062},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215239038&doi=10.1016%2fj.ipm.2025.104062&partnerID=40&md5=9334a95c0a1e14febda2f0fa5022ac89},
	abstract = {Multi-modal Knowledge Graphs (KGs) enhance traditional KGs by incorporating multi-modal data to bridge the information gap in natural language processing (NLP) tasks. One direct method to incorporate multi-modal data is to associate structured KG with corresponding image modalities, thereby visualizing entities and triplet facts. However, existing visualization methods for triplet facts often exclude triplet facts containing abstract entities and non-visual relations, resulting in their disassociation from corresponding image modalities. This exclusion compromises the completeness and utility of multi-modal KGs. In this paper, we aim to construct a comprehensive multi-modal KG that includes abstract entities and non-visual relations, ensuring complete visualization of every triplet fact. To achieve this purpose, we propose a method for the integration of image Retrieval-Generation-Editing (RGE) to completely and accurately visualize each triplet fact. Initially, we correct the triplet facts by integrating a Large Language Model (LLM) with a retrieved knowledge database about triplet facts. Subsequently, by providing appropriate contextual examples to the LLM, we generate visual elements of relations, enriching the semantics of the triplet facts. We then employ image retrieval to obtain images that reflect the semantics of each triplet fact. For those triplet facts for which images cannot be directly retrieved, we utilize image generation and editing to create and modify images that can express the semantics of the triplet facts. Through the RGE method, we construct a multi-modal KG named DB15KFACT, which includes 86,722 triplet facts, 274 relations, 12,842 entities, and 387,096 images. The construction of DB15KFACT has resulted in a fourfold increase in the number of relations compared to the previous multi-modal KG, ImgFact. In experiments, both automatic and manual evaluations confirm the quality of DB15KFACT. The results demonstrate that the DB15KFACT significantly enhances model performance in link prediction and relation classification. Notably, in link prediction, the model optimized with DB15KFACT achieves a 7.12% improvement in the H@10 metric compared to existing solutions. © 2025 Elsevier Ltd},
	author_keywords = {Generating model; Multi-modal Knowledge Graph; Non-visual relation; Visual element; Visual relation},
	keywords = {Natural language processing systems; Semantics; Generating models; Image modality; Knowledge graphs; Multi-modal; Multi-modal data; Multi-modal knowledge graph; Non visuals; Non-visual relation; Visual elements; Visual relation; Knowledge graph},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Gangemi2025,
	author = {Gangemi, Aldo and Nuzzolese, Andrea Giovanni},
	title = {Logic Augmented Generation},
	year = {2025},
	journal = {Journal of Web Semantics},
	volume = {85},
	doi = {10.1016/j.websem.2024.100859},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215626101&doi=10.1016%2fj.websem.2024.100859&partnerID=40&md5=055878e4aea3e672f11749f801b9445d},
	abstract = {Semantic Knowledge Graphs (SKG) face challenges with scalability, flexibility, contextual understanding, and handling unstructured or ambiguous information. However, they offer formal and structured knowledge enabling highly interpretable and reliable results by means of reasoning and querying. Large Language Models (LLMs) may overcome those limitations, making them suitable in open-ended tasks and unstructured environments. Nevertheless, LLMs are hardly interpretable and often unreliable. To take the best out of LLMs and SKGs, we envision Logic Augmented Generation (LAG) to combine the benefits of the two worlds. LAG uses LLMs as Reactive Continuous Knowledge Graphs that can generate potentially infinite relations and tacit knowledge on-demand. LAG uses SKGs to inject a discrete heuristic dimension with clear logical and factual boundaries. We exemplify LAG in two tasks of collective intelligence, i.e., medical diagnostics and climate projections. Understanding the properties and limitations of LAG, which are still mostly unknown, is of utmost importance for enabling a variety of tasks involving tacit knowledge in order to provide interpretable and effective results. © 2025 The Authors},
	author_keywords = {Knowledge graphs; Large language models; Logic augmented generation},
	keywords = {Semantics; Structured Query Language; Contextual understanding; Formal knowledge; Knowledge graphs; Language model; Large language model; Logic augmented generation; Reliable results; Semantics knowledge; Structured knowledge; Tacit knowledge; Knowledge graph},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}@CONFERENCE{Yang2024193,
	author = {Yang, Da and Liu, Shutian and Fu, Haoyang and Shen, Jiayi},
	title = {Research and Practice on the Construction of Course Ideological and Political Education Based on Knowledge Graphs and Large Language Models},
	year = {2024},
	journal = {ACM International Conference Proceeding Series},
	pages = {193 – 198},
	doi = {10.1145/3700297.3700331},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215676245&doi=10.1145%2f3700297.3700331&partnerID=40&md5=a04355d0073b145d21fbf43a5f01417b},
	abstract = {Knowledge graphs and large language models (LLMs) have become important tools for educational innovation. This paper explores the application of these two technologies in the construction of ideological and political education in university courses. The paper begins by analyzing the importance of course-based ideological and political education and the challenges currently faced. It then introduces the role of knowledge graphs in integrating educational resources and constructing knowledge systems, as well as the potential and current status of LLMs in natural language processing and providing personalized educational content. This study presents a method that integrates the use of knowledge graphs and LLMs to construct resources and application systems for course-based ideological and political education. The results of practical case studies demonstrate that the proposed method improves the efficiency of constructing ideological and political education content, enhances the effectiveness of moral education within courses, and contributes to the innovative development of ideological and political education. © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.},
	author_keywords = {Course Ideological and Political Education; Educational Innovation; Knowledge Graph; Large Language Model (LLM)},
	keywords = {Course ideological and political education; Current status; Educational innovations; Educational resource; Ideological and political educations; Knowledge graphs; Knowledge system; Language model; Large language model; University course; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Huang2025511,
	author = {Huang, Weichen and Ju, Xinyue and Zhou, You and Xu, Yipeng and Yang, Gang},
	title = {Two Semantic Information Extension Enhancement Methods For Zero-Shot Learning},
	year = {2025},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) },
	volume = {15035 LNCS},
	pages = {511 – 525},
	doi = {10.1007/978-981-97-8620-6_35},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208201848&doi=10.1007%2f978-981-97-8620-6_35&partnerID=40&md5=a46d474f50fcb34afb79eca3055cb9b3},
	abstract = {In the domain of computer vision, Zero-Shot Learning (ZSL) achieves the classification of unseen class objects through the utilization of semantic information of class relationships. Acquiring richer semantic information and representation pose a significant avenue for enhancing learner performance. Existing studies of ZSL predominately address this challenge only by introducing knowledge graphs and graph neural networks, overlooking inadequacies in the original semantic information, the intrinsic hierarchical and the directional characteristics within the graph structure. This paper proposes two semantic information enhancing methods for ZSL, respectively tailored for regular datasets and large-scale datasets. Facing regular ZSL datasets, our method leverages textual knowledge within large language models, extending traditional 2-dimensional attribute annotations to a 3-dimensional space to obtain more comprehensive class-level semantic information. Addressing the large ZSL tasks, our approach combines enhanced semantic information with external knowledge graphs to simulate class relationships, employing the intrinsic structure and directionality of graphs to bolster semantic representations. We validated our approaches on four traditional ZSL datasets and the ImageNet dataset. The experimental results manifested significant improvements in ZSL performance, underscoring the potential of our methods. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2025.},
	author_keywords = {Attribute Expansion; Knowledge Graph; Semantic Enhancement; Zero-Shot Learning},
	keywords = {Adversarial machine learning; Contrastive Learning; Knowledge graph; Attribute expansion; Class objects; Class relationship; Information extension; Knowledge graphs; Learning dataset; Semantic enhancements; Semantic representation; Semantics Information; Vision Zero; Zero-shot learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Hornsteiner2024,
	author = {Hornsteiner, Markus and Kreussel, Michael and Steindl, Christoph and Ebner, Fabian and Empl, Philip and Schönig, Stefan},
	title = {Real-Time Text-to-Cypher Query Generation with Large Language Models for Graph Databases},
	year = {2024},
	journal = {Future Internet},
	volume = {16},
	number = {12},
	doi = {10.3390/fi16120438},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213083235&doi=10.3390%2ffi16120438&partnerID=40&md5=924316bad8e41f3c12ee242e51abdaa2},
	abstract = {Based on their ability to efficiently and intuitively represent real-world relationships and structures, graph databases are gaining increasing popularity. In this context, this paper proposes an innovative integration of a Large Language Model into NoSQL databases and Knowledge Graphs to bridge the gap in field of Text-to-Cypher queries, focusing on Neo4j. Using the Design Science Research Methodology, we developed a Natural Language Interface which can receive user queries in real time, convert them into Cypher Query Language (CQL), and perform targeted queries, allowing users to choose from different graph databases. In addition, the user interaction is expanded by an additional chat function based on the chat history, as well as an error correction module, which elevates the precision of the generated Cypher statements. Our findings show that the chatbot is able to accurately and efficiently solve the tasks of database selection, chat history referencing, and CQL query generation. The developed system therefore makes an important contribution to enhanced interaction with graph databases, and provides a basis for the integration of further and multiple database technologies and LLMs, due to its modular pipeline architecture. © 2024 by the authors.},
	author_keywords = {chatbot; ChatGPT; cypher language; graph database; knowledge graphs; LLM; natural language interface; Neo4j; question answering},
	keywords = {C (programming language); Knowledge graph; Natural language processing systems; Query languages; Structured Query Language; Chatbots; ChatGPT; Cipher language; Graph database; Knowledge graphs; LLM; Natural language interfaces; Neo4j; Question Answering; Real- time; Graph Databases},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@CONFERENCE{Papoutsoglou2024,
	author = {Papoutsoglou, Maria and Meditskos, Georgios and Bassiliades, Nick and Kontopoulos, Efstratios and Vrochidis, Stefanos},
	title = {Mapping the Current Status of CTI Knowledge Graphs through a Bibliometric Analysis},
	year = {2024},
	journal = {ACM International Conference Proceeding Series},
	doi = {10.1145/3688671.3688738},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215981296&doi=10.1145%2f3688671.3688738&partnerID=40&md5=607d82bb1d0e18c0c63990469d72c640},
	abstract = {Bibliometric analysis in the field of cybersecurity and Cyber Threat Intelligence (CTI) is crucial for identifying research trends, key themes, and collaborative networks, which can guide future research directions and policy decisions.This paper presents a comprehensive bibliometric analysis of the current status of research on knowledge graphs in cybersecurity, highlighting significant trends and thematic clusters.The analysis reveals a rapidly growing interest in integrating knowledge graphs with advanced machine learning and AI techniques, such as deep learning and neural networks, to enhance cyber threat intelligence and response strategies.Key findings include the prominence of natural language processing, entity recognition, and relation extraction as critical methodologies in this field.Thematic evolution analysis shows the adoption of large language models (LLMs) and an ongoing focus on structured knowledge representation.The study underscores the potential of knowledge graphs to improve cybersecurity through better data organization, threat detection, and intelligence extraction. © 2024 Copyright held by the owner/author(s).},
	author_keywords = {Bibliometric Analysis; CTI; Cybersecurity; Knowledge Graphs},
	keywords = {Adversarial machine learning; Cyber attacks; Bibliometrics analysis; Collaborative network; Current status; Cybe threat intelligence; Cyber security; Cyber threats; Direction decisions; Future research directions; Knowledge graphs; Research trends; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{2025,
	title = {24th International Conference on Knowledge Engineering and Knowledge Management, EKAW 2024},
	year = {2025},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) },
	volume = {15370 LNAI},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210830354&partnerID=40&md5=d375d5519e08237fdbfd4b4d7c6290ec},
	abstract = {The proceedings contain 28 papers. The special focus in this conference is on Knowledge Engineering and Knowledge Management. The topics include: Influence Beyond Similarity: A Contrastive Learning Approach to Object Influence Retrieval; Discovering a Representative Set of Link Keys in RDF Datasets; understanding the Impact of Entity Linking on the Topology of Entity Co-occurrence Networks for Social Media Analysis; Empowering CamemBERT Legal Entity Extraction With LLM Boostrapping; Lexicalization Is All You Need: Examining the Impact of Lexical Knowledge in a Compositional QALD System; on the Roles of Competency Questions in Ontology Engineering; structured Representations for Narratives; comparing Symbolic and Embedding-Based Approaches for Relational Blocking; uniQ-Gen: Unified Query Generation Across Multiple Knowledge Graphs; LLM-Driven Knowledge Extraction in Temporal and Description Logics; FaVEL: Fact Validation Ensemble Learning; a Framework for Evaluating Entity Alignment Impact on Downstream Knowledge Discovery; Scholarly Wikidata: Population and Exploration of Conference Data in Wikidata Using LLMs; understanding Inflicted Injuries in Young Children: Toward an Ontology Based Approach; a Review and Comparison of Competency Question Engineering Approaches; A Generic Framework to Better Understand and Compare FAIRness Measures; ORKA: An Ontology for Robotic Knowledge Acquisition; transformers in the Service of Description Logic-Based Contexts; additive Counterfactuals for Explaining Link Predictions on Knowledge Graphs; peGazUs: A Knowledge Graph Based Approach to Build Urban Perpetual Gazetteers; ontology-Constrained Generation of Domain-Specific Clinical Summaries; contextualizing Entity Representations for Zero-Shot Relation Extraction with Masked Language Models; validating a Functional Status Knowledge Graph in a Large-Scale Living Lab; human Evaluation of Procedural Knowledge Graph Extraction from Text with Large Language Models; modelling and Mining Knowledge About Computational Complexity; generating a Question Answering Dataset About Geographic Changes in a Knowledge Graph.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Ali2025295,
	author = {Ali, Syed Juned and Naganathan, Varun and Bork, Dominik},
	title = {Establishing Traceability Between Natural Language Requirements and Software Artifacts by Combining RAG and LLMs},
	year = {2025},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) },
	volume = {15238 LNCS},
	pages = {295 – 314},
	doi = {10.1007/978-3-031-75872-0_16},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209545892&doi=10.1007%2f978-3-031-75872-0_16&partnerID=40&md5=94e267626c8c00c9d58b31a192408001},
	abstract = {Software Engineering aims to effectively translate stakeholders’ requirements into executable code to fulfill their needs. Traceability from natural language use case requirements to classes in a UML class diagram, subsequently translated into code implementation, is essential in systems development and maintenance. Tasks such as assessing the impact of changes and enhancing software reusability require a clear link between these requirements and their software implementation. However, establishing such links manually across extensive codebases is prohibitively challenging. Requirements, typically articulated in natural language, embody semantics that clarify the purpose of the codebase. Conventional traceability methods, relying on textual similarities between requirements and code, often suffer from low precision due to the semantic gap between high-level natural language requirements and the syntactic nature of code. The advent of Large Language Models (LLMs) provides new methods to address this challenge through their advanced capability to interpret both natural language and code syntax. Furthermore, representing code as a knowledge graph facilitates the use of graph structural information to enhance traceability links. This paper introduces an LLM-supported retrieval augmented generation approach for enhancing requirements traceability to the class diagram of the code, incorporating keyword, vector, and graph indexing techniques, and their integrated application. We present a comparative analysis against conventional methods and among different indexing strategies and parameterizations on the performance. Our results demonstrate how this methodology significantly improves the efficiency and accuracy of establishing traceability links in software development processes. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.},
	author_keywords = {Large Language Models; LLM; Requirements Engineering; Requirements Traceability; Retrieval Augmented Generation},
	keywords = {Application programs; Computer software maintenance; Computer software reusability; High level languages; Indexing (materials working); Indexing (of information); Knowledge graph; Program translators; Requirements engineering; Reusability; Search engines; Software design; Syntactics; Translation (languages); Language model; Large language model; Natural language requirements; Natural languages; Requirement engineering; Requirements traceability; Retrieval augmented generation; Traceability links; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Lee2024,
	author = {Lee, Chang-Shing and Wang, Mei-Hui and Chen, Chih-Yu and Yang, Sheng-Chi and Reformat, Marek and Kubota, Naoyuki and Pourabdollah, Amir},
	title = {Integrating quantum CI and generative AI for Taiwanese/English co-learning},
	year = {2024},
	journal = {Quantum Machine Intelligence},
	volume = {6},
	number = {2},
	doi = {10.1007/s42484-024-00195-8},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204902378&doi=10.1007%2fs42484-024-00195-8&partnerID=40&md5=2927cf3197b57c54dd85c5f36f44b8b5},
	abstract = {This paper proposes a quantum computational intelligence (QCI) model integrated with generative artificial intelligence (GAI) for Taiwanese/English language co-learning applications within human–machine interactions, focusing on Trustworthy AI Dialogue Engine (TAIDE)-based knowledge graph construction and multimodal data transformation. The QCI model comprises two main phases: human–machine interaction and data processing for quantum circuit generation and real-world applications. During the human–machine interaction phase, a synergy between human intelligence (HI) and machine intelligence (MI) enables young students to gain familiarity with CI that converges with QCI. The second phase involves data processing, which encompasses stages of data preprocessing, analysis, and evaluation. The methodology is applied to two distinct applications: Application 1 focuses on constructing a knowledge graph using the Ollama platform and the TAIDE model developed by the Taiwanese government based on the LLaMa 2 model. Application 2 addresses the GAI images to text/voice and text/voice to GAI images, depending on the type of Taiwanese/English data collected. Subsequently, the QCI model is refined through particle swarm optimization (PSO) and genetic algorithm neural networks (GANN). Moreover, a quantum fuzzy inference mechanism (QFIM) is integrated into the developed QCI&AI-FML learning platform to generate quantum circuits for the QCI model, which helps teach young students and facilitate their learning of QCI. The experimental results indicate that the QCI model significantly enhances human–machine collaboration. Looking forward, we plan to extend the QCI model to reach more young learners. © The Author(s), under exclusive licence to Springer Nature Switzerland AG 2024.},
	author_keywords = {Generative AI; Genetic algorithm neural network; Human–machine interaction; Knowledge graph; Particle swarm optimization; Quantum computational intelligence; TAIDE},
	keywords = {Adversarial machine learning; Fuzzy neural networks; Government data processing; Graph neural networks; Inference engines; Metadata; Quantum electronics; Swarm intelligence; Generative AI; Genetic algorithm neural network; Human machine interaction; Knowledge graphs; Neural-networks; Particle swarm; Particle swarm optimization; Quantum computational intelligence; Swarm optimization; Trustworthy AI dialog engine; Particle swarm optimization (PSO)},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{2025,
	title = {13th CCF International Conference on Natural Language Processing and Chinese Computing, NLPCC 2024},
	year = {2025},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) },
	volume = {15361 LNAI},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210069441&partnerID=40&md5=2ed30a44fabc4f8aa077f5807c3dffbe},
	abstract = {The proceedings contain 194 papers. The special focus in this conference is on Natural Language Processing and Chinese Computing. The topics include: Hierarchical Knowledge Aggregation for Personalized Response Generation in Dialogue Systems; multi-hop Reading Comprehension Model Based on Abstract Meaning Representation and Multi-task Joint Learning; Leveraging Large Language Models for QA Dialogue Dataset Construction and Analysis in Public Services; MCFC: A Momentum-Driven Clicked Feature Compressed Pre-trained Language Model for Information Retrieval; integrating Syntax Tree and Graph Neural Network for Conversational Question Answering over Heterogeneous Sources; pqE: Zero-Shot Document Expansion for Dense Retrieval with Large Language Models; CKF: Conditional Knowledge Fusion Method for CommonSense Question Answering; MPPQA: Structure-Aware Extractive Multi-span Question Answering for Procedural Documents; GraphLLM: A General Framework for Multi-hop Question Answering over Knowledge Graphs Using Large Language Models; local or Global Optimization for Dialogue Discourse Parsing; structure and Behavior Dual-Graph Reasoning with Integrated Key-Clue Parsing for Multi-party Dialogue Reading Comprehension; enhancing Emotional Support Conversation with Cognitive Chain-of-Thought Reasoning; a Simple and Effective Span Interaction Modeling Method for Enhancing Multiple Span Question Answering; FacGPT: An Effective and Efficient Method for Evaluating Knowledge-Based Visual Question Answering; PAPER: A Persona-Aware Chain-of-Thought Learning Framework for Personalized Dialogue Response Generation; towards Building a Robust Knowledge Intensive Question Answering Model with Large Language Models; model-Agnostic Knowledge Distillation Between Heterogeneous Models; exploring Multimodal Information Fusion in Spoken Off-Topic Degree Assessment; integrating Hierarchical Key Information and Semantic Difference Features for Long Text Matching; CausalAPM: Generalizable Literal Disentanglement for NLU Debiasing; W2CL: A Multi-task Learning Approach to Improve Domain-Specific Sentence Classification Through Word Classification and Contrastive Learning; outperforming Larger Models on Text Classification Through Continued Pre-training; semantic Knowledge Enhanced and Global Pointer Optimized Method for Medical Nested Entity Recognition.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{2025,
	title = {1st International Symposium on Leveraging Applications of Formal Methods, AISoLA 2023},
	year = {2025},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) },
	volume = {14129 LNCS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208640724&partnerID=40&md5=4f5d430402228fce3f5fc50d614edf5f},
	abstract = {The proceedings contain 54 papers. The special focus in this conference is on Leveraging Applications of Formal Methods. The topics include: Coding Historical Causes of Death Data with Large Language Models; teaching the Specialized Language of Mathematics with a Data-Driven Approach: What Data Do We Use?; interoperating Civil Registration of Death and Census Data: Old Age and Marriage as Categories of Analysis; From Data Science to Modular Workflows Changing Perspectives from Data to Platform: DBDIrl 1864-1922 Case Study; Mapping Madness: HGIS and the Analysis of Irish Patient Records; digitised Historical Sources and Non-digital Humanists: An Interdisciplinary Challenge?; using Passive Sensing to Identify Depression; The GraphBRAIN Framework for Knowledge Graph Management and Its Applications to Cultural Heritage; Challenges for AI in Healthcare Systems; towards a Multi-dimensional Health Data Analysis Framework; Future Opportunities for Systematic AI Support in Healthcare; CRISP-PCCP – A Development Methodology Supporting FDA Approval for Machine Learning Enabled Medical Devices; Model Driven Development for AI-Based Healthcare Systems: A Review; balancing Transparency and Risk: An Overview of the Security and Privacy Risks of Open-Source Machine Learning Models; AI-Related Risk and Uncertainty; Leveraging Actionable Explanations to Improve People’s Reactions to AI-Based Decisions; from Explanation Correctness to Explanation Goodness: Only Provably Correct Explanations Can Save the World; Thinking Outside the Box?: Regulatory Sandboxes as a Tool for AI Regulation; AI and Democratic Equality: How Surveillance Capitalism and Computational Propaganda Threaten Democracy; Safeguarding AI-Based Software Development and Verification using Witnesses (Position Paper); End-to-End AI Generated Runtime Verification from Natural Language Specification; AI-Assisted Programming with Test-Based Refinement; safer Than Perception: Increasing Resilience of Automated Vehicles Against Misperception.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Dohi2024,
	author = {Dohi, Eisuke and Takatsuki, Terue and Tateisi, Yuka and Fujiwara, Toyofumi and Yamamoto, Yasunori},
	title = {Examining HPO by organ and system to facilitate practical use by clinicians},
	year = {2024},
	journal = {Genomics and Informatics},
	volume = {22},
	number = {1},
	doi = {10.1186/s44342-024-00024-1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209785282&doi=10.1186%2fs44342-024-00024-1&partnerID=40&md5=d2ca5558f31d7617738594b0a00386a2},
	abstract = {The Human Phenotype Ontology (HPO) is widely used for annotating clinical text data, and sufficient annotation is crucial for the effective utilization of clinical texts. It was known that the use of LLMs can successfully extract symptoms and findings, but cannot annotate them with the HPO. We hypothesized that one of the potential issue for this is the lack of appropriate terms in the HPO. Therefore, during the Biomedical Linked Annotation Hackathon 8 (BLAH8), we attempted the following two tasks in order to grasp the overall picture of HPO. (1) Extract all HPO terms for each of the 23 HPO subclasses (defined as categories) directly under the HPO "Phenotypic abnormality" and then (2) search for major attributes in each of 23 categories. We employed LLM for these two tasks related to examining HPO and, at the same time, found that LLM didn't work well without ingenuity for tasks that lacked sentences and context. A manual search for terms within each category revealed that the HPO contains a mix of terms with four major attributes: (1) Disease Name, (2) Condition, (3) Test Data, and (4) Symptoms and Findings. Manual curation showed that the ratio of symptoms and findings varied from 0 to 93.1% across categories. For clinicians, who are end-users of medical terminology including HPO, it is difficult to understand ontologies. However, for good quality ontology is also important for good-quality data, and a clinician’s help is essential. It is also important to make the overall picture and limitations of ontologies easy to understand in order to bring out the explanatory power of LLMs and artificial intelligence. © The Author(s) 2024.},
	author_keywords = {Annotation; Biological ontologies; Large Language Model; Phenotype},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Xiang2024,
	author = {Xiang, Wenkai and Xiong, Zhaoping and Chen, Huan and Xiong, Jiacheng and Zhang, Wei and Fu, Zunyun and Zheng, Mingyue and Liu, Bing and Shi, Qian},
	title = {FAPM: functional annotation of proteins using multimodal models beyond structural modeling},
	year = {2024},
	journal = {Bioinformatics},
	volume = {40},
	number = {12},
	doi = {10.1093/bioinformatics/btae680},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211995402&doi=10.1093%2fbioinformatics%2fbtae680&partnerID=40&md5=34a3572ea2c6efe3ddd2e37e3c7949a9},
	abstract = {Motivation: Assigning accurate property labels to proteins, like functional terms and catalytic activity, is challenging, especially for proteins without homologs and “tail labels” with few known examples. Previous methods mainly focused on protein sequence features, overlooking the semantic meaning of protein labels. Results: We introduce functional annotation of proteins using multimodal models (FAPM), a contrastive multimodal model that links natural language with protein sequence language. This model combines a pretrained protein sequence model with a pretrained large language model to generate labels, such as Gene Ontology (GO) functional terms and catalytic activity predictions, in natural language. Our results show that FAPM excels in understanding protein properties, outperforming models based solely on protein sequences or structures. It achieves state-of-the-art performance on public benchmarks and in-house experimentally annotated phage proteins, which often have few known homologs. Additionally, FAPM’s flexibility allows it to incorporate extra text prompts, like taxonomy information, enhancing both its predictive performance and explainability. This novel approach offers a promising alternative to current methods that rely on multiple sequence alignment for protein annotation. Availability and implementation: The online demo is at: https://huggingface.co/spaces/wenkai/FAPM_demo. © The Author(s) 2024.},
	keywords = {Computational Biology; Databases, Protein; Gene Ontology; Molecular Sequence Annotation; Natural Language Processing; Proteins; Sequence Analysis, Protein; Software; protein; amino acid sequence; article; bacteriophage; benchmarking; catalysis; controlled study; diagnosis; gene ontology; human; large language model; nonhuman; prediction; sequence alignment; bioinformatics; chemistry; metabolism; molecular genetics; natural language processing; procedures; protein database; sequence analysis; software},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Qiao2025136,
	author = {Qiao, Zijian and Li, Nan and Huang, Chenxi and Wang, Gangliang and Liang, Shenglin and Lin, Hui and Guo, Qinglang},
	title = {GraphLLM: A General Framework for Multi-hop Question Answering over Knowledge Graphs Using Large Language Models},
	year = {2025},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) },
	volume = {15359 LNAI},
	pages = {136 – 148},
	doi = {10.1007/978-981-97-9431-7_11},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209806365&doi=10.1007%2f978-981-97-9431-7_11&partnerID=40&md5=3f214b4e0ae85800b4a4155fad8eeb24},
	abstract = {The task of multi-hop question answering over knowledge graphs (KGQA) is designed to identify answer entities for a given question through reasoning across multiple edges over KGs. This task presents persistent challenges: as the number of hops increases, both the reasoning complexity and the pool of candidate answers expand, resulting in suboptimal outcomes. Due to the powerful semantic understanding and logical reasoning capabilities of large language models, we propose a general framework for multi-hop KQGA using large language models (LLMs), named GraphLLM. Specifically, GraphLLM involves employing the semantic understanding and reasoning abilities of LLMs to decompose multi-hop questions through a Divide-And-Conquer approach and construct sub-graphs, transforming complex problems into several simple sub-questions. We obtain the ultimate answer by iteratively using Graph Neural Networks (GNNs) to solve sub-questions. By conducting experiments on benchmarks WebQSP and MetaQA, results indicate that GraphLLM exhibits outstanding performance compared to leading methods. We successfully demonstrate a collaborative example of LLMs and GNNs, offering a novel approach to addressing intricate multi-hop KGQA. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2025.},
	author_keywords = {Graph Neural Network; Knowledge Graph; Large Language Model; Multi-hop Question Answering},
	keywords = {Graph neural networks; Modeling languages; Semantics; Graph neural networks; Knowledge graphs; Language model; Large language model; Logical reasoning; Multi-hop question answering; Multi-hops; Number of hops; Question Answering; Semantics understanding; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Shi2024678,
	author = {Shi, Dachuan and Liedl, Philipp and Bauernhansl, Thomas},
	title = {Interoperable information modelling leveraging asset administration shell and large language model for quality control toward zero defect manufacturing},
	year = {2024},
	journal = {Journal of Manufacturing Systems},
	volume = {77},
	pages = {678 – 696},
	doi = {10.1016/j.jmsy.2024.10.011},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207646345&doi=10.1016%2fj.jmsy.2024.10.011&partnerID=40&md5=2aca853c79dfa5e9d5f6455ef885247a},
	abstract = {In the era of Industry 4.0, Zero Defect Manufacturing (ZDM) has emerged as a prominent strategy for quality improvement, emphasizing data-driven approaches for defect prediction, prevention, and mitigation. The success of ZDM heavily depends on the availability and quality of data typically collected from diverse and heterogeneous sources during production and quality control, presenting challenges in data interoperability. Addressing this, we introduce a novel approach leveraging Asset Administration Shell (AAS) and Large Language Models (LLMs) for creating interoperable information models that incorporate semantic contextual information to enhance the interoperability of data integration in the quality control process. AAS, initiated by German industry stakeholders, shows a significant advancement in information modeling, blending ontology and digital twin concepts for the virtual representation of assets. In this work, we develop a systematic, use-case-driven methodology for AAS-based information modeling. This methodology guides the design and implementation of AAS models, ensuring model properties are presented in a unified structure and reference external standardized vocabularies to maintain consistency across different systems. To automate this referencing process, we propose a novel LLM-based algorithm to semantically search model properties within a standardized vocabulary repository. This algorithm significantly reduces manual intervention in model development. A case study in the injection molding domain demonstrates the practical application of our approach, showcasing the integration and linking of product quality and machine process data with the help of the developed AAS models. Statistical evaluation of our LLM-based semantic search algorithm confirms its efficacy in enhancing data interoperability. This methodology offers a scalable and adaptable solution for various industrial use cases, promoting widespread data interoperability in the context of Industry 4.0. © 2024 The Authors},
	author_keywords = {Asset administration shell; Industry 4.0; Information modelling; Interoperability; Large language model; Ontology; Quality control; Zero defect manufacturing},
	keywords = {Network security; Steganography; Asset administration shell; Data interoperability; Information Modeling; Language model; Large language model; Model properties; Ontology's; Shell models; Zero defect manufacturing; Zero defects; Statistical process control},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Lai2024,
	author = {Lai, Po-Ting and Coudert, Elisabeth and Aimo, Lucila and Axelsen, Kristian and Breuza, Lionel and de Castro, Edouard and Feuermann, Marc and Morgat, Anne and Pourcel, Lucille and Pedruzzi, Ivo and Poux, Sylvain and Redaschi, Nicole and Rivoire, Catherine and Sveshnikova, Anastasia and Wei, Chih-Hsuan and Leaman, Robert and Luo, Ling and Lu, Zhiyong and Bridge, Alan},
	title = {EnzChemRED, a rich enzyme chemistry relation extraction dataset},
	year = {2024},
	journal = {Scientific Data},
	volume = {11},
	number = {1},
	doi = {10.1038/s41597-024-03835-7},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203337764&doi=10.1038%2fs41597-024-03835-7&partnerID=40&md5=58b4796711a9cc0aa516401292206658},
	abstract = {Expert curation is essential to capture knowledge of enzyme functions from the scientific literature in FAIR open knowledgebases but cannot keep pace with the rate of new discoveries and new publications. In this work we present EnzChemRED, for Enzyme Chemistry Relation Extraction Dataset, a new training and benchmarking dataset to support the development of Natural Language Processing (NLP) methods such as (large) language models that can assist enzyme curation. EnzChemRED consists of 1,210 expert curated PubMed abstracts where enzymes and the chemical reactions they catalyze are annotated using identifiers from the protein knowledgebase UniProtKB and the chemical ontology ChEBI. We show that fine-tuning language models with EnzChemRED significantly boosts their ability to identify proteins and chemicals in text (86.30% F1 score) and to extract the chemical conversions (86.66% F1 score) and the enzymes that catalyze those conversions (83.79% F1 score). We apply our methods to abstracts at PubMed scale to create a draft map of enzyme functions in literature to guide curation efforts in UniProtKB and the reaction knowledgebase Rhea. © This is a U.S. Government work and not under copyright protection in the US; foreign copyright protection may apply 2024.},
	keywords = {Databases, Protein; Enzymes; Knowledge Bases; Natural Language Processing; PubMed; enzyme; chemistry; knowledge base; Medline; natural language processing; protein database},
	type = {Data paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access}
}

@ARTICLE{2025,
	title = {13th CCF International Conference on Natural Language Processing and Chinese Computing, NLPCC 2024},
	year = {2025},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) },
	volume = {15363 LNAI},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210097754&partnerID=40&md5=337aabcfa0ef143893629fc93c93b815},
	abstract = {The proceedings contain 194 papers. The special focus in this conference is on Natural Language Processing and Chinese Computing. The topics include: Hierarchical Knowledge Aggregation for Personalized Response Generation in Dialogue Systems; multi-hop Reading Comprehension Model Based on Abstract Meaning Representation and Multi-task Joint Learning; Leveraging Large Language Models for QA Dialogue Dataset Construction and Analysis in Public Services; MCFC: A Momentum-Driven Clicked Feature Compressed Pre-trained Language Model for Information Retrieval; integrating Syntax Tree and Graph Neural Network for Conversational Question Answering over Heterogeneous Sources; pqE: Zero-Shot Document Expansion for Dense Retrieval with Large Language Models; CKF: Conditional Knowledge Fusion Method for CommonSense Question Answering; MPPQA: Structure-Aware Extractive Multi-span Question Answering for Procedural Documents; GraphLLM: A General Framework for Multi-hop Question Answering over Knowledge Graphs Using Large Language Models; local or Global Optimization for Dialogue Discourse Parsing; structure and Behavior Dual-Graph Reasoning with Integrated Key-Clue Parsing for Multi-party Dialogue Reading Comprehension; enhancing Emotional Support Conversation with Cognitive Chain-of-Thought Reasoning; a Simple and Effective Span Interaction Modeling Method for Enhancing Multiple Span Question Answering; FacGPT: An Effective and Efficient Method for Evaluating Knowledge-Based Visual Question Answering; PAPER: A Persona-Aware Chain-of-Thought Learning Framework for Personalized Dialogue Response Generation; towards Building a Robust Knowledge Intensive Question Answering Model with Large Language Models; model-Agnostic Knowledge Distillation Between Heterogeneous Models; exploring Multimodal Information Fusion in Spoken Off-Topic Degree Assessment; integrating Hierarchical Key Information and Semantic Difference Features for Long Text Matching; CausalAPM: Generalizable Literal Disentanglement for NLU Debiasing; W2CL: A Multi-task Learning Approach to Improve Domain-Specific Sentence Classification Through Word Classification and Contrastive Learning; outperforming Larger Models on Text Classification Through Continued Pre-training; semantic Knowledge Enhanced and Global Pointer Optimized Method for Medical Nested Entity Recognition.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Azam2024360,
	author = {Azam, Muhammad and Chen, Yibo and Arowolo, Micheal Olaolu and Liu, Haowang and Popescu, Mihail and Xu, Dong},
	title = {A comprehensive evaluation of large language models in mining gene relations and pathway knowledge},
	year = {2024},
	journal = {Quantitative Biology},
	volume = {12},
	number = {4},
	pages = {360 – 374},
	doi = {10.1002/qub2.57},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196492629&doi=10.1002%2fqub2.57&partnerID=40&md5=5fc803ea745fe5b065c820d4f3bb91b5},
	abstract = {Understanding complex biological pathways, including gene–gene interactions and gene regulatory networks, is critical for exploring disease mechanisms and drug development. Manual literature curation of biological pathways cannot keep up with the exponential growth of new discoveries in the literature. Large-scale language models (LLMs) trained on extensive text corpora contain rich biological information, and they can be mined as a biological knowledge graph. This study assesses 21 LLMs, including both application programming interface (API)-based models and open-source models in their capacities of retrieving biological knowledge. The evaluation focuses on predicting gene regulatory relations (activation, inhibition, and phosphorylation) and the Kyoto Encyclopedia of Genes and Genomes (KEGG) pathway components. Results indicated a significant disparity in model performance. API-based models GPT-4 and Claude-Pro showed superior performance, with an F1 score of 0.4448 and 0.4386 for the gene regulatory relation prediction, and a Jaccard similarity index of 0.2778 and 0.2657 for the KEGG pathway prediction, respectively. Open-source models lagged behind their API-based counterparts, whereas Falcon-180b and llama2-7b had the highest F1 scores of 0.2787 and 0.1923 in gene regulatory relations, respectively. The KEGG pathway recognition had a Jaccard similarity index of 0.2237 for Falcon-180b and 0.2207 for llama2-7b. Our study suggests that LLMs are informative in gene network analysis and pathway mapping, but their effectiveness varies, necessitating careful model selection. This work also provides a case study and insight into using LLMs das knowledge graphs. Our code is publicly available at the website of GitHub (Muh-aza). © 2024 The Author(s). Quantitative Biology published by John Wiley & Sons Australia, Ltd on behalf of Higher Education Press.},
	author_keywords = {biomedical text mining; gene–gene interaction; KEGG pathway; large language model},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access}
}

@ARTICLE{Bandi2025157,
	author = {Bandi, Ajay and Babu, Jameer and Zeng, Ruida and Muthyala, Sai Ram},
	title = {Enhancing Generative AI Chatbot Accuracy Using Knowledge Graph},
	year = {2025},
	journal = {Communications in Computer and Information Science},
	volume = {2244 CCIS},
	pages = {157 – 167},
	doi = {10.1007/978-3-031-75201-8_11},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207833318&doi=10.1007%2f978-3-031-75201-8_11&partnerID=40&md5=e00cefe0c6fdba4ffd0de2c948dbb7f3},
	abstract = {In recent years, generative AI chatbots have significantly improved in their ability to simulate human-like conversations. However, ensuring the accuracy and contextual relevance of their responses remains a challenge. This paper presents an innovative approach to enhancing the accuracy of generative AI chatbots by integrating knowledge graphs using Neo4j. We demonstrate how combining structured data from Knowledge Graphs with advanced large language models can result in more accurate and context-aware chatbot interactions. By implementing this approach, we aim to provide a robust framework for developing intelligent chatbots that can deliver precise and contextually appropriate responses. We created three categories of test cases: Data-Relevant Inquiries, Non-Contextual Queries, and Contextually Relevant but Data-Irrelevant Questions. The accuracy obtained for the data-relevant test cases was 91.44%. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.},
	author_keywords = {Chatbot; Cypher; Generative AI; Knowledge graphs; Large Language Model (LLM); Neo4j; Retrieval and Augmented Generation (RAG); Similarity search; Vector index; Word embeddings},
	keywords = {Generative adversarial networks; Structured Query Language; Chatbots; Cipher; Embeddings; Generative AI; Knowledge graphs; Language model; Large language model; Neo4j; Retrieval and augmented generation; Similarity search; Vector index; Word embedding; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Chen20245725,
	author = {Chen, Jiao and Ma, Luyi and Li, Xiaohan and Xu, Jianpeng and Cho, Jason H. D. and Nag, Kaushiki and Korpeoglu, Evren and Kumar, Sushant and Achan, Kannan},
	title = {Relation labeling in product knowledge graphs with large language models for e-commerce},
	year = {2024},
	journal = {International Journal of Machine Learning and Cybernetics},
	volume = {15},
	number = {12},
	pages = {5725 – 5743},
	doi = {10.1007/s13042-024-02274-5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201426726&doi=10.1007%2fs13042-024-02274-5&partnerID=40&md5=5fc6558ed7be5ae8ab2fb697aeb12f7a},
	abstract = {Product Knowledge Graphs (PKGs) play a crucial role in enhancing e-commerce system performance by providing structured information about entities and their relationships, such as complementary or substitutable relations between products or product types, which can be utilized in recommender systems. However, relation labeling in PKGs remains a challenging task due to the dynamic nature of e-commerce domains and the associated cost of human labor. Recently, breakthroughs in Large Language Models (LLMs) have shown surprising results in numerous natural language processing tasks, especially in the in-context learning (ICL). In this paper, we conduct an empirical study of LLMs for relation labeling in e-commerce PKGs, investigating their powerful learning capabilities in natural language and effectiveness in predicting relations between product types with few-shot in-context learning. We evaluate the performance of various LLMs, including PaLM-2, GPT-3.5, and Llama-2, on benchmark datasets for e-commerce relation labeling tasks. We use different prompt engineering techniques to examine their impact on model performance. Our results show that LLMs can achieve competitive performance compared to human labelers using just 1–5 labeled examples per relation. We also illustrate the bias issues in LLMs towards minority ethnic groups. Additionally, we show that LLMs significantly outperform existing KG completion models or classification methods in relation labeling for e-commerce KGs and exhibit performance strong enough to replace human labeling. Beyond empirical investigations, we also carry out a theoretical analysis to explain the superior capability of LLMs in few-shot ICL by comparing it with kernel regression. © The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature 2024.},
	author_keywords = {E-commerce; Few-shot learning; Knowledge Graph; Large Language Model; Product Relation; Recommendation},
	keywords = {Adversarial machine learning; Commerce; Contrastive Learning; Marketplaces; Natural language processing systems; Zero-shot learning; E- commerces; Few-shot learning; In contexts; Knowledge graphs; Labelings; Language model; Large language model; Product knowledge; Product relation; Recommendation; Knowledge graph},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Song20241,
	author = {Song, Xiaoning and Jiang, Qiyi and Zhang, Wenjie and Wu, Xiaojun},
	title = {Food Knowledge Graph-based Intelligent Perception Question Answering; [基于食品知识图谱的智能感知问答]},
	year = {2024},
	journal = {Journal of Chinese Institute of Food Science and Technology},
	volume = {24},
	number = {12},
	pages = {1 – 12},
	doi = {10.16429/j.1009-7848.2024.12.001},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216831326&doi=10.16429%2fj.1009-7848.2024.12.001&partnerID=40&md5=c1b7d24557e56876970fefb9832f31fc},
	abstract = {Food safety is of vital importance to people's lives. With the improvement of living standards, public concern about food safety has also increased, and the urgent need for reliable and effective information response has arisen. Existing intelligent question-answering systems, such as those based on text vector libraries, have made some progress in knowledge reasoning, problem handling, and semantic relationship recognition, but still have some shortcomings; question-answering systems based on knowledge graphs face inherent challenges in terms of graph construction cost and information recall rate; while question-answering systems based on template matching are poor in question generalization ability and context understanding. This paper proposes an innovative knowledge graph-based intelligent perception question-answering system based on large language models (LLM). Using large language models to improve the shortcomings of the template matching method, combining text vector libraries and knowledge graphs at the same time, and introducing high-dimensional vector semantic search technology into the knowledge graph retrieval process to improve the knowledge graph retrieval recall rate. This innovative approach significantly improves the overall performance of the question-answering system and the user's experience. © 2024 Chinese Institute of Food Science and Technology. All rights reserved.},
	author_keywords = {artificial intelligence; food safety; intelligent question answering; knowledge graph; large language models},
	keywords = {Question answering; Template matching; Food-safety; Graph-based; Intelligent perception; Intelligent question answering; Knowledge graphs; Language model; Large language model; Question Answering; Question answering systems; Recall rate; Knowledge graph},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Yu2024,
	author = {Yu, Alessandra N.C. and Lowe, Leroy and Schiller, Daniela},
	title = {Future considerations for the Human Affectome: Reply to commentaries},
	year = {2024},
	journal = {Neuroscience and Biobehavioral Reviews},
	volume = {167},
	doi = {10.1016/j.neubiorev.2024.105901},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205440605&doi=10.1016%2fj.neubiorev.2024.105901&partnerID=40&md5=2afa09350e7ee3ce9ac8906ce75c431d},
	keywords = {abstraction; academic interest; affective level; affective phenomena; algorithm; central empirical task; cognition; consciousness; goal directed process; human; human affectome; large language model; Note; ontology; phenotype; scientific literature; teleology; adult; article},
	type = {Note},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{ALMutairi2024,
	author = {ALMutairi, Mariam and AlKulaib, Lulwah and Wang, Shengkun and Chen, Zhiqian and ALMutairi, Youssif and Alenazi, Thamer M. and Luther, Kurt and Lu, Chang-Tien},
	title = {FHIRViz: Multi-Agent Platform for FHIR Visualization to Advance Healthcare Analytics},
	year = {2024},
	journal = {ACM-BCB 2024 - 15th ACM Conference on Bioinformatics, Computational Biology, and Health Informatics},
	doi = {10.1145/3698587.3701392},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216420981&doi=10.1145%2f3698587.3701392&partnerID=40&md5=54eb64ead36550708b286596fadbc2b1},
	abstract = {The shift to electronic health records (EHRs) has enhanced patient care and research, but data sharing and complex clinical terminology remain challenges. The Fast Healthcare Interoperability Resource (FHIR) addresses interoperability issues, though extracting insights from FHIR data is still difficult. Traditional analytics often miss critical clinical context, and managing FHIR data requires advanced skills that are in short supply. This study presents FHIRViz, a novel analytics tool that integrates FHIR data with a semantic layer via a knowledge graph. It employs a large language model (LLM) system to extract insights and visualize them effectively. A retrieval vector store improves performance by saving successful generations for fine-tuning. FHIRViz translates clinical queries into actionable insights with high accuracy. Results show FHIRViz with GPT-4 achieving 92.62% accuracy, while Gemini 1.5 Pro reaches 89.34%, demonstrating the tool’s potential in overcoming healthcare data analytics challenges. © 2024 Copyright held by the owner/author(s).},
	author_keywords = {Clinical Analytics; FHIR; Health Informatics; Knowledge Graph; LLMs; Multi-Agent; visualization},
	keywords = {Clinical research; Knowledge graph; Clinical analytic; Electronic health; Fast healthcare interoperability resource; Health informatics; Health records; Healthcare Interoperability; Knowledge graphs; LLM; Multi agent; Multi-agent platforms; Electronic health record},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Lima2024,
	author = {Lima, Matthew and Muddana, Charandatta and Xiao, Zhengyang and Bandyopadhyay, Anindita and Wangikar, Pramod P. and Pakrasi, Himadri B. and Tang, Yinjie J.},
	title = {The new chassis in the flask: Advances in Vibrio natriegens biotechnology research},
	year = {2024},
	journal = {Biotechnology Advances},
	volume = {77},
	doi = {10.1016/j.biotechadv.2024.108464},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206177890&doi=10.1016%2fj.biotechadv.2024.108464&partnerID=40&md5=18818e9cc2b0c313166434655f43c8c5},
	abstract = {Biotechnology has been built on the foundation of a small handful of well characterized and well-engineered organisms. Recent years have seen a breakout performer gain attention as a new entrant into the bioengineering toolbox: Vibrio natriegens. This review covers recent research efforts into making V. natriegens a biotechnology platform, using a large language model (LLM) and knowledge graph to expedite the literature survey process. Scientists have made advancements in research pertaining to the fundamental metabolic characteristics of V. natriegens, development and characterization of synthetic biology tools, systems biology analysis and metabolic modeling, bioproduction and metabolic engineering, and microbial ecology. Each of these subcategories has relevance to the future of V. natriegens for bioengineering applications. In this review, we cover these recent advancements and offer context for the impact they may have on the field, highlighting benefits and drawbacks of using this organism. From examining the recent bioengineering research, it appears that V. natriegens is on the precipice of becoming a platform bacterium for the future of biotechnology. © 2024},
	author_keywords = {Biomanufacturing; Genome scale model; Knowledge graph; Large language model; Synthetic biology; Systems biology},
	keywords = {Biotechnology; Metabolic Engineering; Synthetic Biology; Systems Biology; Vibrio; Vibrio natriegens; Abiotic; Bio-manufacturing; Genome-scale model; Knowledge graphs; Language model; Large language model; Recent researches; Research efforts; Synthetic biology; Systems biology; Vibrio natriegens; bacterium; bioengineering; biology; biotechnology; knowledge; biotechnology; genetics; metabolic engineering; procedures; synthetic biology; systems biology; Vibrio; Biotic},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Alfasi202433,
	author = {Alfasi, Daniel and Shapira, Tal and Barr, Anat Bremler},
	title = {VulnScopper: Unveiling Hidden Links Between Unseen Security Entities},
	year = {2024},
	journal = {GNNet 2024 - Proceedings of the 3rd GNNet Workshop on Graph Neural Networking Workshop, Co-Located with: CoNEXT 2024},
	pages = {33 – 40},
	doi = {10.1145/3694811.3697819},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216583765&doi=10.1145%2f3694811.3697819&partnerID=40&md5=1dcef95c0d0205012e628aa5d1f55b99},
	abstract = {The Common Vulnerabilities and Exposures (CVE) system is crucial for cybersecurity, providing standardized identification of vulnerabilities. In February 2024, the National Vulnerability Database (NVD) announced it could no longer enrich new CVEs due to increasing volumes, significantly impacting global security efforts. This paper introduces VulnScopper, an innovative approach to automate and enhance vulnerability enrichment using Graph Neural Networks (GNNs). VulnScopper combines Knowledge Graphs (KG) with Natural Language Processing (NLP) by leveraging ULTRA, a GNN-based knowledge graph foundation model, alongside a Large Language Model (LLM). VulnScopper’s inductive approach enables it to handle unseen entities, overcoming a crucial limitation of previous CVE enrichment methods. We evaluate VulnScopper on the NVD dataset in inductive and transductive setups for CVE to Common Platform Enumerations (CPE) linking. Our results show that VulnScopper outperforms state-of-the-art techniques, achieving up to 60% Hits@10 accuracy in linking CVEs to CPE on unseen CVE records. We demonstrate VulnScopper’s effectiveness on unseen 2023 CVEs, showcasing its ability to uncover new vulnerable products and potentially reduce vulnerability remediation time. © 2024 Copyright held by the owner/author(s).},
	author_keywords = {CPE; CVE; CWE; Cybersecurity; Graph Neural Networks (GNN); Knowledge Graphs; Large Language Models (LLM); Link Prediction; Vulnerabilities},
	keywords = {Graph neural networks; Modeling languages; Natural language processing systems; Common platform; Common platform enumeration; Common vulnerabilities and exposures; CWE; Cyber security; Graph neural network; Graph neural networks; Knowledge graphs; Language model; Large language model; Link prediction; Vulnerability; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Lei2024,
	author = {Lei, Xinyu and Cao, Xue and Zhang, Faye and Lai, Qifang and Gao, Pengcheng and Li, Yue-hong},
	title = {Study of carbonate alkalinity-induced hepatic tissue damage in Hefang crucian carp (Carassius auratus) based on transcriptomic analysis},
	year = {2024},
	journal = {Comparative Biochemistry and Physiology - Part D: Genomics and Proteomics},
	volume = {52},
	doi = {10.1016/j.cbd.2024.101351},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208504918&doi=10.1016%2fj.cbd.2024.101351&partnerID=40&md5=60a7ad7d728a7310fcd09b95c1978070},
	abstract = {This study investigated the effects of different sodium bicarbonate (NaHCO3) concentrations (0 g/L, 1 g/L, and 3 g/L) on Hefang crucian carp (12.0 ± 1.1 g) over a 96-hour period. The experiment is divided into three groups, each with three replicates, and each replicate contains 30 fish. We employed a comprehensive approach integrating histology, physiological and biochemical assays, transcriptomics, as well as artificial intelligence (AI)-assisted analysis. This multifaceted method allowed us to examine changes in gill and liver morphology, osmoregulation, antioxidant capacity, immune response, and physiological metabolism. Results showed that gill and liver tissue damage increased with rising water alkalinity. Serum sodium (Na+), potassium (K+), blood ammonia, and gill Na+/K+-ATPase (NKA) levels increased significantly (p < 0.05). Hepatic antioxidant enzymes initially increased, then decreased with prolonged stress. Serum and liver immunoenzyme indices were higher in bicarbonate-treated groups compared to controls. Carbonate treatment altered lipid and glucose metabolism in both serum and liver. Transcriptome analysis, enhanced by large language models (LLMs), revealed differentially expressed genes (DEGs) significantly associated with ion binding, transport, apoptosis, and metabolism. In conclusion, excessive carbonate intake in fish alters serum physiological functions and affects hepatic metabolic functions. Crucian carp primarily regulate hepatic antioxidant systems, utilize carbohydrate breakdown for energy requirements, and employ lipids in osmoregulation. This study provides insights into fish adaptation to saline-alkaline environments and offers support for the development of aquaculture in saline-alkaline waters. © 2024},
	author_keywords = {Carbonate alkalinity stress; Histological analysis; Liver injury; Transcriptomics},
	keywords = {Animals; Carbonates; Carps; Gene Expression Profiling; Gills; Goldfish; Liver; Transcriptome; 6 phosphofructokinase; acetate coenzyme A ligase; acetyl coenzyme A carboxylase; adenosine triphosphatase (potassium sodium); aminotransferase; ammonia; bicarbonate; carnitine palmitoyl transaminase 1; enzyme; fatty acid synthase; hexokinase; lipoprotein lipase; liver triacylglycerol lipase; potassium; pyruvate kinase; sodium; unclassified drug; carbonic acid derivative; transcriptome; adult; alkalinity; ammonia blood level; animal experiment; animal model; animal tissue; antioxidant activity; apoptosis; Article; artificial intelligence; carbohydrate metabolism; concentration (parameter); controlled study; differential gene expression; enzyme blood level; functional enrichment analysis; gene ontology; gill; glucose metabolism; goldfish; histopathology; immune response; ion transport; KEGG; large language model; lipid metabolism; liver injury; liver metabolism; liver tissue; metabolism; nonhuman; osmoregulation; potassium blood level; RNA sequencing; sodium blood level; transcriptomics; animal; carp; drug effect; gene expression profiling; genetics; goldfish; liver},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Liu2025255,
	author = {Liu, Jinzhe and Huang, Xiangsheng and Chen, Zhuo and Fang, Yin},
	title = {DRAK: Unlocking Molecular Insights with Domain-Specific Retrieval-Augmented Knowledge in LLMs},
	year = {2025},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) },
	volume = {15360 LNAI},
	pages = {255 – 267},
	doi = {10.1007/978-981-97-9434-8_20},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210098710&doi=10.1007%2f978-981-97-9434-8_20&partnerID=40&md5=7fe57ab27bc4c43e530a7d42c5e4c6be},
	abstract = {Large Language Models (LLMs) typically manifest knowledge gap in specialized applications due to pre-training on generalized textual corpora. Although fine-tuning and modality alignment aim to bridge this gap, their inability to provide comprehensive knowledge coverage leads to LLMs delivering imprecise responses. To address these challenges, we introduce a scalable and adaptable non-parametric knowledge injection framework, Domain-specificRetrieval-AugmentedKnowledge (DRAK), aimed at bolstering LLMs’ knowledge reasoning ability through context examples. DRAK integrates retrieval enhancement and structured knowledge graph recall of high-quality instances, utilizing retrieved examples to unlock LLMs’ context-relevant molecular learning capabilities, offering a universal solution for specific domains. Our validation of DRAK’s effectiveness and generalizability in the biomolecular domain, achieving superior performance across twelve tasks involving both molecule-oriented and bioinformatics texts within the Mol-Instructions dataset. This demonstration of DRAK’s ability to unearth molecular insights establishes a standardized approach for LLMs in navigating the complexities of knowledge-intensive challenges. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2025.},
	author_keywords = {Biomolecular domain; Knowledge injection; Retrieval-augmented knowledge},
	keywords = {Bioinformatics; Biomolecules; Knowledge graph; Natural language processing systems; Bio-molecular; Biomolecular domain; Domain specific; Fine tuning; Knowledge gaps; Knowledge injection; Language model; Molecular insights; Pre-training; Retrieval-augmented knowledge; Domain Knowledge},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Toro2024,
	author = {Toro, Sabrina and Anagnostopoulos, Anna V. and Bello, Susan M. and Blumberg, Kai and Cameron, Rhiannon and Carmody, Leigh and Diehl, Alexander D. and Dooley, Damion M. and Duncan, William D. and Fey, Petra and Gaudet, Pascale and Harris, Nomi L. and Joachimiak, Marcin P. and Kiani, Leila and Lubiana, Tiago and Munoz-Torres, Monica C. and O‘Neil, Shawn and Osumi-Sutherland, David and Puig-Barbe, Aleix and Reese, Justin T. and Reiser, Leonore and Robb, Sofia MC. and Ruemping, Troy and Seager, James and Sid, Eric and Stefancsik, Ray and Weber, Magalie and Wood, Valerie and Haendel, Melissa A. and Mungall, Christopher J.},
	title = {Dynamic Retrieval Augmented Generation of Ontologies using Artificial Intelligence (DRAGON-AI)},
	year = {2024},
	journal = {Journal of Biomedical Semantics},
	volume = {15},
	number = {1},
	doi = {10.1186/s13326-024-00320-3},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206568005&doi=10.1186%2fs13326-024-00320-3&partnerID=40&md5=22bc17dbc78786d7aa562484bd258d12},
	abstract = {Background: Ontologies are fundamental components of informatics infrastructure in domains such as biomedical, environmental, and food sciences, representing consensus knowledge in an accurate and computable form. However, their construction and maintenance demand substantial resources and necessitate substantial collaboration between domain experts, curators, and ontology experts. We present Dynamic Retrieval Augmented Generation of Ontologies using AI (DRAGON-AI), an ontology generation method employing Large Language Models (LLMs) and Retrieval Augmented Generation (RAG). DRAGON-AI can generate textual and logical ontology components, drawing from existing knowledge in multiple ontologies and unstructured text sources. Results: We assessed performance of DRAGON-AI on de novo term construction across ten diverse ontologies, making use of extensive manual evaluation of results. Our method has high precision for relationship generation, but has slightly lower precision than from logic-based reasoning. Our method is also able to generate definitions deemed acceptable by expert evaluators, but these scored worse than human-authored definitions. Notably, evaluators with the highest level of confidence in a domain were better able to discern flaws in AI-generated definitions. We also demonstrated the ability of DRAGON-AI to incorporate natural language instructions in the form of GitHub issues. Conclusions: These findings suggest DRAGON-AI's potential to substantially aid the manual ontology construction process. However, our results also underscore the importance of having expert curators and ontology editors drive the ontology generation process. © The Author(s) 2024.},
	author_keywords = {Artificial intelligence; Biocuration; Knowledge graphs; Large language models; Ontologies; Ontology engineering},
	keywords = {Artificial Intelligence; Biological Ontologies; Information Storage and Retrieval; Natural Language Processing; artificial intelligence; biological ontology; information retrieval; natural language processing; procedures},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access}
}

@ARTICLE{Koh20243454,
	author = {Koh, Eugene and Sunil, Rohan Shawn and Lam, Hilbert Yuen In and Mutwil, Marek},
	title = {Confronting the data deluge: How artificial intelligence can be used in the study of plant stress},
	year = {2024},
	journal = {Computational and Structural Biotechnology Journal},
	volume = {23},
	pages = {3454 – 3466},
	doi = {10.1016/j.csbj.2024.09.010},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205292409&doi=10.1016%2fj.csbj.2024.09.010&partnerID=40&md5=5ce6fd4e4098d68e00906af5b2e87bec},
	abstract = {The advent of the genomics era enabled the generation of high-throughput data and computational methods that serve as powerful hypothesis-generating tools to understand the genomic and gene functional basis of plant stress resilience. The proliferation of experimental and analytical methods used in biology has resulted in a situation where plentiful data exists, but the volume and heterogeneity of this data has made analysis a significant challenge. Current advanced deep-learning models have displayed an unprecedented level of comprehension and problem-solving ability, and have been used to predict gene structure, function and expression based on DNA or protein sequence, and prominently also their use in high-throughput phenomics in agriculture. However, the application of deep-learning models to understand gene regulatory and signalling behaviour is still in its infancy. We discuss in this review the availability of data resources and bioinformatic tools, and several applications of these advanced ML/AI models in the context of plant stress response, and demonstrate the use of a publicly available LLM (ChatGPT) to derive a knowledge graph of various experimental and computational methods used in the study of plant stress. We hope this will stimulate further interest in collaboration between computer scientists, computational biologists and plant scientists to distil the deluge of genomic, transcriptomic, proteomic, metabolomic and phenomic data into meaningful knowledge that can be used for the benefit of humanity. © 2024 The Authors},
	author_keywords = {Artificial intelligence; Large language models; Large-scale data; Plant stress resilience},
	keywords = {Deep learning; Gene expression; Plant diseases; DNA; Functional basis; Genomic era; Genomics; High-throughput data; Language model; Large language model; Large scale data; Learning models; Plant stress; Plant stress resilience; amino acid sequence; analytic method; artificial intelligence; biologist; ChatGPT; deep learning; gene structure; genomics; large language model; machine learning; nonhuman; phenomics; plant stress; problem solving; review; signal transduction},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Gold Open Access}
}

@ARTICLE{Bronzini2024,
	author = {Bronzini, Marco and Nicolini, Carlo and Lepri, Bruno and Passerini, Andrea and Staiano, Jacopo},
	title = {Glitter or gold? Deriving structured insights from sustainability reports via large language models},
	year = {2024},
	journal = {EPJ Data Science},
	volume = {13},
	number = {1},
	doi = {10.1140/epjds/s13688-024-00481-2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195597218&doi=10.1140%2fepjds%2fs13688-024-00481-2&partnerID=40&md5=8f15a5c870c193ef56585deb0716e421},
	abstract = {Over the last decade, several regulatory bodies have started requiring the disclosure of non-financial information from publicly listed companies, in light of the investors’ increasing attention to Environmental, Social, and Governance (ESG) issues. Publicly released information on sustainability practices is often disclosed in diverse, unstructured, and multi-modal documentation. This poses a challenge in efficiently gathering and aligning the data into a unified framework to derive insights related to Corporate Social Responsibility (CSR). Thus, using Information Extraction (IE) methods becomes an intuitive choice for delivering insightful and actionable data to stakeholders. In this study, we employ Large Language Models (LLMs), In-Context Learning, and the Retrieval-Augmented Generation (RAG) paradigm to extract structured insights related to ESG aspects from companies’ sustainability reports. We then leverage graph-based representations to conduct statistical analyses concerning the extracted insights. These analyses revealed that ESG criteria cover a wide range of topics, exceeding 500, often beyond those considered in existing categorizations, and are addressed by companies through a variety of initiatives. Moreover, disclosure similarities emerged among companies from the same region or sector, validating ongoing hypotheses in the ESG literature. Lastly, by incorporating additional company attributes into our analyses, we investigated which factors impact the most on companies’ ESG ratings, showing that ESG disclosure affects the obtained ratings more than other financial or company data. © The Author(s) 2024.},
	author_keywords = {Bipartite graph analyses; ESG dimensions; In-context learning; Interpretability; Knowledge graphs; Large language models; Non-financial disclosures},
	keywords = {Computational linguistics; Data mining; Finance; Gold; Knowledge graph; Learning systems; Sustainable development; Bipartite graph analyze; Bipartite graphs; Context learning; Environmental, social, and governance dimension; Financial disclosure; Graph analysis; In contexts; In-context learning; Interpretability; Knowledge graphs; Language model; Large language model; Non-financial disclosure; Graphic methods},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access}
}

@CONFERENCE{Patel2024,
	author = {Patel, Parth and Chiu, Yu-Chiao and Hunag, Yufei and Zhang, Jianqiu},
	title = {MetaphorPrompt - An Analogical Reasoning Approach for Extracting Causal Links from Biological Text},
	year = {2024},
	journal = {ACM-BCB 2024 - 15th ACM Conference on Bioinformatics, Computational Biology, and Health Informatics},
	doi = {10.1145/3698587.3701384},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216429464&doi=10.1145%2f3698587.3701384&partnerID=40&md5=301ba3d2496ec7d9606dafea3d22b0a9},
	abstract = {In recent years, Large Language Models (LLMs) have revolutionized Natural Language Processing (NLP), offering significant improvements for extracting complex information from biomedical literature. Our research introduces a novel metaphor-based approach, MetaphorPrompt, to enhance the accuracy of extracting molecular regulatory pathways (MRPs) from biomedical texts. This method employs LLMs such as GPT4 to develop metaphors that map biological processes onto familiar, real-world scenarios, facilitating a better understanding and extracting causal events in MRPs. MetaphorPrompt is tested using the reguloGPT dataset and compared to a baseline method (without metaphors) and reguloGPT’s best prompt. Test results demonstrate improved precision, recall, and F1 scores in node and edge prediction of causal event links through analogical reasoning. The effect of in-context learning (ICL) in MetaphorPrompt is investigated, and it is found that analogical reasoning offers significant improvements over ICL. This supports the claim that LLMs can perform novel problem-solving through analogical reasoning. This work paves the way for more intuitive and user-friendly representations of MRPs in biomedical data, ultimately contributing to advancements in biomedical NLP, knowledge graph construction, and effective applications of LLMs in novel problem-solving through analogical reasoning. © 2024 Copyright is held by the owner/author(s).},
	author_keywords = {Analogical Reasoning; Causal Event Links; GPT4; Knowledge Graph; LLM; Metaphor; Molecular Regulation Pathway; Prompt},
	keywords = {Natural language processing systems; Analogical reasoning; Causal event link; GPT4; Knowledge graphs; Language model; Large language model; Metaphor; Molecular regulation; Molecular regulation pathway; Prompt; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Li20243840,
	author = {Li, Hao and Yue, Peng and Tapete, Deodato and Cigna, Francesca and Wu, Qiuju and Xiang, Longgang and Lu, Binbin},
	title = {ESDC: An open Earth science data corpus to support geoscientific literature information extraction},
	year = {2024},
	journal = {Science China Earth Sciences},
	volume = {67},
	number = {12},
	pages = {3840 – 3854},
	doi = {10.1007/s11430-023-1444-9},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208914104&doi=10.1007%2fs11430-023-1444-9&partnerID=40&md5=c5beaa67879faaa5c1e7925a477cb033},
	abstract = {Over the past ten years, large amounts of original research data related to Earth system science have been made available at a rapidly increasing rate. Such growing data stock helps researchers understand the human-Earth system across different fields. A substantial amount of this data is published by geoscientists as open-access in authoritative journals. If the information stored in this literature is properly extracted, there is significant potential to build a domain knowledge base. However, this potential remains largely unfulfilled in geoscience, with one of the biggest obstacles being the lack of publicly available related corpora and baselines. To fill this gap, the Earth Science Data Corpus (ESDC), an academic text corpus of 600 abstracts, was built from the international journal Earth System Science Data (ESSD). To the best of our knowledge, ESDC is the first corpus with the needed detail to provide a professional training dataset for knowledge extraction and construction of domain-specific knowledge graphs from massive amounts of literature. The production process of ESDC incorporates both the contextual features of spatiotemporal entities and the linguistic characteristics of academic literature. Furthermore, annotation guidelines and procedures tailored for Earth science data are formulated to ensure reliability. ChatGPT with zero- and few-shot prompting, BARTNER generative, and W2NER discriminative models were trained on ESDC to evaluate the performance of the name entity recognition task and showed increasing performance metrics, with the highest achieved by BARTNER. Performance metrics for various entity types output by each model were also assessed. We utilized the trained BARTNER model to perform model inference on a larger unlabeled literature corpus, aiming to automatically extract a broader and richer set of entity information. Subsequently, the extracted entity information was mapped and associated with the Earth science data knowledge graph. Around this knowledge graph, this paper validates multiple downstream applications, including hot topic research analysis, scientometric analysis, and knowledge-enhanced large language model question-answering systems. These applications have demonstrated that the ESDC can provide scientists from different disciplines with information on Earth science data, help them better understand and obtain data, and promote further exploration in their respective professional fields. © Science China Press 2024.},
	author_keywords = {Corpus; Earth science data; Information extraction; Knowledge graph; Scientometric research},
	keywords = {Earth system science; Miocene; Question answering; Corpus; Earth science data; Earth system science; Information extraction; Knowledge graphs; Large amounts; Performance metrices; Research data; Scientometric research; Scientometrics; academic research; database; Earth science; information management; knowledge based system; publishing; Knowledge graph},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Shen202592,
	author = {Shen, Zizhuo and Li, Wei and Shao, Yanqiu},
	title = {Evaluation and Analysis of the Chinese Semantic Dependency Understanding Ability of Large Language Models},
	year = {2025},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) },
	volume = {15361 LNAI},
	pages = {92 – 104},
	doi = {10.1007/978-981-97-9437-9_8},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210084420&doi=10.1007%2f978-981-97-9437-9_8&partnerID=40&md5=b8e308bcf80d313ecc76c3114ca96232},
	abstract = {Semantic Dependency Graph is a framework for representing deep semantic knowledge through flexible graph structures. While recent works indicate that large language models (LLMs) have impressive language and knowledge understanding abilities, it remains unclear whether they can understand this deep semantic knowledge. To explore this problem, we design four prompt-style probing tasks from aspects of semantic structure and semantic relations to adapt the inherent abilities of LLMs. To ensure thorough evaluation, we conduct extensive experiments in both in-context learning (ICL) and supervised fine-tuning (SFT) scenarios. Our findings indicate that the understanding of deep semantic knowledge requires larger parameter scale, especially the understanding of high-order semantic structure knowledge and semantic relation knowledge. Furthermore, our experiments reveal that while LLMs perform well on the in-domain (ID) test set via SFT, their generalization ability on out-of-domain (OOD) test set remains inadequate. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2025.},
	author_keywords = {Evaluation; Large Language Model; Semantic Dependency Graph},
	keywords = {Semantics; Dependency graphs; Evaluation; Fine tuning; Language model; Large language model; Semantic dependency; Semantic dependency graph; Semantic relations; Semantic structures; Semantics knowledge; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{2025,
	title = {33rd International Conference on Software and Data Engineering, SEDE 2024},
	year = {2025},
	journal = {Communications in Computer and Information Science},
	volume = {2244 CCIS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207838337&partnerID=40&md5=53e3af3b37346b63cc6ef216daa8f852},
	abstract = {The proceedings contain 14 papers. The special focus in this conference is on Software and Data Engineering. The topics include: Embracing Residuality Theory in Software Architecture to Address Uncertainty: Key Challenges and Strategies; zoned Role-Based Approach to System Design, Implementation, and Access Control of Integrated Web Applications; enhancing IoT Network Defense: A Comparative Study of Machine Learning Algorithms for Attack Classification; a Survey and Insights on Modern Game Development Processes for Software Engineering Education; evaluating the Impact of Combinatorial Interaction Testing on Test Automation: A Case Study from Industry; JSMBox—A Runtime Monitoring Framework for Analyzing and Classifying Malicious JavaScript; securing Wireless Sensor Network from Rank Attack Using Fast Sensor Data Encryption and Decryption Protocol; Enhancing Transparency and Privacy in Financial Fraud Detection: The Integration of Explainable AI and Federated Learning; Enhancing Generative AI Chatbot Accuracy Using Knowledge Graph; ReVisE: Emulated Visual Outfit Generation from User Reviews Using Generative-AI; A Case Study on AI to Automate Simulation Modelling; racial Disparity in Breast Cancer Prognosis.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{2024,
	title = {GeoAI 2024 - Proceedings of the 7th ACM SIGSPATIAL International Workshop on AI for Geographic Knowledge Discovery},
	year = {2024},
	journal = {GeoAI 2024 - Proceedings of the 7th ACM SIGSPATIAL International Workshop on AI for Geographic Knowledge Discovery},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215120816&partnerID=40&md5=e3b1b2d90e43eb627b497f891bdc5af9},
	abstract = {The proceedings contain 16 papers. The topics discussed include: cross-lingual clustering using large language models; edge activating module: learning edge-to-edge features for mobility flow generation; multivariate testing of sampling techniques to address class imbalance in building use type classification; road networks matching supercharged with embeddings; encoding agent trajectories as representations with sequence transformers; geometric feature enhanced knowledge graph embedding and spatial reasoning; Text2Seg: zero-shot remote sensing image semantic segmentation via text-guided visual foundation models; self-supervised pretraining with edge guidance for building damage assessment; leveraging large multimodal models to augment image-based building damage assessment; leveraging large language models for generating labeled mineral site record linkage data; and spatial task-explicity matters in prompting large multimodal models for spatial planning.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Zhang2025176,
	author = {Zhang, Yifeng and Jiang, Ming and Zhao, Qi},
	title = {GRACE: Graph-Based Contextual Debiasing for Fair Visual Question Answering},
	year = {2025},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) },
	volume = {15075 LNCS},
	pages = {176 – 194},
	doi = {10.1007/978-3-031-72643-9_11},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210811630&doi=10.1007%2f978-3-031-72643-9_11&partnerID=40&md5=f9de559d9d39a96ddb2613584eb3f817},
	abstract = {Large language models (LLMs) exhibit exceptional reasoning capabilities and have played significant roles in knowledge-based visual question-answering (VQA) systems. By conditioning on in-context examples and task-specific prompts, they comprehensively understand input questions and provide answers relevant to the context. However, due to the reliance on in-context examples, LLMs are susceptible to inheriting dataset biases in context descriptions and the provided examples. Innovative methods are required to ensure that LLMs can deliver unbiased yet contextually relevant responses. To tackle this challenge, we present GRAph-based Contextual DEbiasing (GRACE), a novel graph-based method for debiasing knowledge-based VQA models. This approach consists of two novel and generally applicable components. First, we propose an unsupervised context graph learning method that combats biases by explicitly creating a balanced context graph under the guidance of fairness constraints. Second, building upon the context graph, we consider both semantic features and reasoning processes to enhance prompting with more relevant and diverse in-context examples. Through extensive experimentation on both in-distribution (OK-VQA) and out-of-distribution (VQA-CP, GQA-OOD) datasets, we demonstrate the effectiveness of GRACE in mitigating biases and achieving generalization. Additionally, analyses of the model performance across gender groups demonstrate GRACE’s potential impacts on social equity. Our source code is publicly available at https://github.com/SuperJohnZhang/ContextGraphKVQA. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.},
	author_keywords = {Debias; Knowledge VQA; Large Language Model},
	keywords = {Contrastive Learning; Knowledge graph; Modeling languages; Semantics; Visual languages; De-biasing; Debias; Graph-based; In contexts; Knowledge based; Knowledge visual question-answering; Language model; Large language model; Question Answering; Reasoning capabilities; Question answering},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{2025,
	title = {13th CCF International Conference on Natural Language Processing and Chinese Computing, NLPCC 2024},
	year = {2025},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) },
	volume = {15362 LNAI},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210098383&partnerID=40&md5=ce94db8d5651356908fa4e8a25b1958a},
	abstract = {The proceedings contain 194 papers. The special focus in this conference is on Natural Language Processing and Chinese Computing. The topics include: Hierarchical Knowledge Aggregation for Personalized Response Generation in Dialogue Systems; multi-hop Reading Comprehension Model Based on Abstract Meaning Representation and Multi-task Joint Learning; Leveraging Large Language Models for QA Dialogue Dataset Construction and Analysis in Public Services; MCFC: A Momentum-Driven Clicked Feature Compressed Pre-trained Language Model for Information Retrieval; integrating Syntax Tree and Graph Neural Network for Conversational Question Answering over Heterogeneous Sources; pqE: Zero-Shot Document Expansion for Dense Retrieval with Large Language Models; CKF: Conditional Knowledge Fusion Method for CommonSense Question Answering; MPPQA: Structure-Aware Extractive Multi-span Question Answering for Procedural Documents; GraphLLM: A General Framework for Multi-hop Question Answering over Knowledge Graphs Using Large Language Models; local or Global Optimization for Dialogue Discourse Parsing; structure and Behavior Dual-Graph Reasoning with Integrated Key-Clue Parsing for Multi-party Dialogue Reading Comprehension; enhancing Emotional Support Conversation with Cognitive Chain-of-Thought Reasoning; a Simple and Effective Span Interaction Modeling Method for Enhancing Multiple Span Question Answering; FacGPT: An Effective and Efficient Method for Evaluating Knowledge-Based Visual Question Answering; PAPER: A Persona-Aware Chain-of-Thought Learning Framework for Personalized Dialogue Response Generation; towards Building a Robust Knowledge Intensive Question Answering Model with Large Language Models; model-Agnostic Knowledge Distillation Between Heterogeneous Models; exploring Multimodal Information Fusion in Spoken Off-Topic Degree Assessment; integrating Hierarchical Key Information and Semantic Difference Features for Long Text Matching; CausalAPM: Generalizable Literal Disentanglement for NLU Debiasing; W2CL: A Multi-task Learning Approach to Improve Domain-Specific Sentence Classification Through Word Classification and Contrastive Learning; outperforming Larger Models on Text Classification Through Continued Pre-training; semantic Knowledge Enhanced and Global Pointer Optimized Method for Medical Nested Entity Recognition.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Huang2024,
	author = {Huang, Qing and Sun, Yanbang and Xing, Zhenchang and Cao, Yuanlong and Chen, Jieshan and Xu, Xiwei and Jin, Huan and Lu, Jiaxing},
	title = {Let’s Discover More API Relations: A Large Language Model-Based AI Chain for Unsupervised API Relation Inference},
	year = {2024},
	journal = {ACM Transactions on Software Engineering and Methodology},
	volume = {33},
	number = {8},
	doi = {10.1145/3680469},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212940900&doi=10.1145%2f3680469&partnerID=40&md5=6adb420a48eb94a6ff87e4e72b3e85f4},
	abstract = {APIs have intricate relations that can be described in text and represented as knowledge graphs to aid software engineering tasks. Existing relation extraction methods have limitations, such as limited API text corpus, and are affected by the characteristics of the input text. To address these limitations, we propose utilizing large language models (LLMs) (e.g., GPT-3.5) as a neural knowledge base for API relation inference. This approach leverages the entire Web used to pre-train LLMs as a knowledge base and is insensitive to the context and complexity of input texts. To ensure accurate inference, we design an AI chain consisting of three AI modules: API Fully Qualified Name (FQN) Parser, API Knowledge Extractor, and API Relation Decider. The accuracy of the API FQN Parser and API Relation Decider is 0.81 and 0.83, respectively. Using the generative capacity of the LLM and our approach’s inference capability, we achieve an average F1 value of 0.76 under the three datasets, significantly higher than the state-of-the-art method’s average F1 value of 0.40. Compared to the original CoT and modularized CoT methods, our AI chain design has improved the performance of API relation inference by 71% and 49%, respectively. Meanwhile, the prompt ensembling strategy enhances the performance of our approach by 32%. The API relations inferred by our method can be further organized into structured forms to provide support for other software engineering tasks. © 2024 Copyright held by the owner/author(s)},
	author_keywords = {AI Chain; API Relation; Knowledge Inference; Large Language Model},
	keywords = {Knowledge graph; AI chain; API relation; Engineering tasks; F1 values; Knowledge graphs; Knowledge inference; Language model; Large language model; Model-based OPC; Performance; Chains},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Cheng2024,
	author = {Cheng, Haitao and Wang, Ke and Tan, Xiaoying},
	title = {A link prediction method for Chinese financial event knowledge graph based on graph attention networks and convolutional neural networks},
	year = {2024},
	journal = {Engineering Applications of Artificial Intelligence},
	volume = {138},
	doi = {10.1016/j.engappai.2024.109361},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204469835&doi=10.1016%2fj.engappai.2024.109361&partnerID=40&md5=5ae4c791bd1140c14a488d46849bd70a},
	abstract = {Finance is a knowledge-intensive domain in nature, with its data containing a significant amount of interconnected information. Constructing a financial knowledge graph is an important application for transforming financial text/web content into machine-readable data. However, the complexity of Chinese financial knowledge and the dynamic and evolving nature of Chinese financial data often lead to incomplete knowledge graphs. To address this challenge, we propose a novel link prediction method for Chinese financial event knowledge graph based on Graph Attention Networks and Convolutional Neural Networks. Our method begins with the construction of the foundational Chinese financial event knowledge graph using a relational triple extraction module integrated with a large language model framework, along with a Prompting with Iterative Verification (PiVe) module for validation. To enhance the completeness of the knowledge graph, we introduce an encoder-decoder framework, where a graph attention network with joint embeddings of financial event entities and relations acts as the encoder, while a Convolutional Knowledge Base embedding model (ConvKB) serves as the decoder. This framework effectively aggregates crucial neighbor information and captures global relationships among entity and relation embeddings. Extensive comparative experiments demonstrate the utility and accuracy of this method, ultimately enabling the effective completion of Chinese financial event knowledge graphs. © 2024 Elsevier Ltd},
	author_keywords = {Chinese financial event knowledge graph; Convolutional neural network; Graph attention network; Large language model; Link prediction},
	keywords = {Convolutional neural networks; Decentralized finance; Graph neural networks; Prediction models; Chinese financial event knowledge graph; Convolutional neural network; Financial events; Graph attention network; Graph-based; Knowledge graphs; Language model; Large language model; Link prediction; Prediction methods; Knowledge graph},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Piyathilake2025206,
	author = {Piyathilake, Vinuri and Dilni, Thuthi and Pushpananda, Randil and De Silva, Lasanthi and Zaheed, Yumna},
	title = {Towards a Conversational AI Chatbot to Assist Farmers in Disease Detection},
	year = {2025},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) },
	volume = {14967 LNAI},
	pages = {206 – 217},
	doi = {10.1007/978-3-031-73497-7_17},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210144021&doi=10.1007%2f978-3-031-73497-7_17&partnerID=40&md5=2c93e4daeeb11d180da6bf07b48b07e6},
	abstract = {Agricultural diseases exert a profound impact on both crop yield and quality, leading to substantial losses in global food production. Consequently, the need for timely disease recognition has become increasingly evident throughout the cultivation process. However, a major challenge lies in the limited expertise of farmers to identify diseases at an early stage. Furthermore, even if changes in crops are detected, there may be a lack of knowledge regarding appropriate remedies. Resorting to expert consultations for on-site assessments can be time-consuming, risking the widespread transmission of infectious diseases. In order to bridge the knowledge gap between experts and farmers, the utilization of a conversational agent, which can provide continuous multilingual personalized support, has emerged as a promising avenue. Thus, this paper provides a comprehensive overview of existing agricultural chatbots, detailing their architectural designs and methods for handling the required knowledge. Recognizing a significant gap between the requirements for a personalized multilingual chatbot for plant disease detection and existing solutions, the study proposes a hybrid model that integrates an ontology-based knowledgebase, open-source frameworks, and a large language model-based architecture to develop a more intelligent chatbot for detecting paddy diseases in Sri Lanka. The ultimate goal of this work is to develop a voice-enabled agricultural assistant, promoting inclusivity and user-friendliness for farmers with limited digital literacy in the future.  © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.},
	author_keywords = {Conversational Agents; Large Language Models; Ontology-Based Knowledgebase; Personalized Chatbots; Plant Disease Detection; Precision Agriculture},
	keywords = {Ontology; Chatbots; Conversational agents; Disease detection; Knowledge basis (KBs); Language model; Large language model; Ontology-based; Ontology-based knowledgebase; Personalized chatbot; Plant disease; Plant disease detection; Precision Agriculture; Chatbots},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Phan2025277,
	author = {Phan, Long Ngo Hoang and Do, Phuc},
	title = {ViFoodNLI: A Dataset for Vietnamese Natural Language Inference in Local Cuisine},
	year = {2025},
	journal = {Communications in Computer and Information Science},
	volume = {2191 CCIS},
	pages = {277 – 289},
	doi = {10.1007/978-981-97-9616-8_22},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209933639&doi=10.1007%2f978-981-97-9616-8_22&partnerID=40&md5=91788c1ea73227bf0c12d9050223c38a},
	abstract = {This paper introduces the ViFoodNLI dataset, a natural language inference (NLI) dataset for Vietnamese. While recent efforts have been made to build high-quality NLI datasets for Vietnamese and some Cross-Lingual NLI Corpus (with support for Vietnamese) for multiple domains, our dataset specifically focuses on the field of local cuisine. The main reason for choosing this field is that cuisine is a significant component of Vietnamese culture, and thus the dataset encompasses many characteristics of the Vietnamese language. By collecting information on culinary topics from reliable news sources, we have developed various methods and logics such as knowledge graphs and Generative AI to create high-quality pairs of premise and hypothesis sentences. Through rigorous testing, the dataset has achieved significant results, creating momentum for future research and practical applications. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2025.},
	author_keywords = {Local Cuisine; Natural Language Inference (NLI); Vietnamese},
	keywords = {Food ingredients; Cross-lingual; High quality; Knowledge graphs; Language inference; Local cuisine; Multiple domains; Natural language inference; Natural languages; News sources; Vietnamese},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Reales2024,
	author = {Reales, Daniel and Manrique, Rubén and Grévisse, Christian},
	title = {Core Concept Identification in Educational Resources via Knowledge Graphs and Large Language Models},
	year = {2024},
	journal = {SN Computer Science},
	volume = {5},
	number = {8},
	doi = {10.1007/s42979-024-03341-y},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208722616&doi=10.1007%2fs42979-024-03341-y&partnerID=40&md5=2f00dd2264b56961734268d3dd93f2f5},
	abstract = {The growing demand for online education raises the question of which learning resources should be included in online programs to ensure students achieve their desired learning outcomes. By automatically identifying the core concepts in educational materials, teachers can select coherent and relevant resources for their courses. This work explores the use of Large Language Models (LLMs) to identify core concepts in educational resources. We propose three different pipelines for building knowledge graphs from lecture transcripts using LLMs and ontologies such as DBpedia. These knowledge graphs are then utilized to determine the central concepts (nodes) within the educational resources. Results show that LLM-constructed knowledge graphs when guided by ontologies, achieve state-of-the-art performance in core concept identification. © The Author(s) 2024.},
	author_keywords = {Core concept identification; Knowledge graphs; Large language models},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Ibrahim2024,
	author = {Ibrahim, Nourhan and Aboulela, Samar and Ibrahim, Ahmed and Kashef, Rasha},
	title = {A survey on augmenting knowledge graphs (KGs) with large language models (LLMs): models, evaluation metrics, benchmarks, and challenges},
	year = {2024},
	journal = {Discover Artificial Intelligence},
	volume = {4},
	number = {1},
	doi = {10.1007/s44163-024-00175-8},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208628740&doi=10.1007%2fs44163-024-00175-8&partnerID=40&md5=802ab3a29fd1e74d8de6d2aa36b774b8},
	abstract = {Integrating Large Language Models (LLMs) with Knowledge Graphs (KGs) enhances the interpretability and performance of AI systems. This research comprehensively analyzes this integration, classifying approaches into three fundamental paradigms: KG-augmented LLMs, LLM-augmented KGs, and synergized frameworks. The evaluation examines each paradigm’s methodology, strengths, drawbacks, and practical applications in real-life scenarios. The findings highlight the substantial impact of these integrations in fundamentally improving real-time data analysis, efficient decision-making, and promoting innovation across various domains. In this paper, we also describe essential evaluation metrics and benchmarks for assessing the performance of these integrations, addressing challenges like scalability and computational overhead, and providing potential solutions. This comprehensive analysis underscores the profound impact of these integrations on improving real-time data analysis, enhancing decision-making efficiency, and fostering innovation across various domains. © The Author(s) 2024.},
	author_keywords = {Deep learning (DL); Evaluation metrics; Knowledge graphs (KGs); Large language models (LLMs); Retrieval augmentation generation (RAG)},
	keywords = {Benchmarking; Decision making; Deep learning; Decisions makings; Deep learning; Evaluation metrics; Knowledge graph; Knowledge graphs; Language model; Large language model; Performance; Real time data analysis; Retrieval augmentation generation; Knowledge graph},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Giri2024,
	author = {Giri, Swagarika Jaharlal and Ibtehaz, Nabil and Kihara, Daisuke},
	title = {GO2Sum: generating human-readable functional summary of proteins from GO terms},
	year = {2024},
	journal = {npj Systems Biology and Applications},
	volume = {10},
	number = {1},
	doi = {10.1038/s41540-024-00358-0},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187902454&doi=10.1038%2fs41540-024-00358-0&partnerID=40&md5=d4d91b8ec872d56fb1898ebc8a4ea328},
	abstract = {Understanding the biological functions of proteins is of fundamental importance in modern biology. To represent a function of proteins, Gene Ontology (GO), a controlled vocabulary, is frequently used, because it is easy to handle by computer programs avoiding open-ended text interpretation. Particularly, the majority of current protein function prediction methods rely on GO terms. However, the extensive list of GO terms that describe a protein function can pose challenges for biologists when it comes to interpretation. In response to this issue, we developed GO2Sum (Gene Ontology terms Summarizer), a model that takes a set of GO terms as input and generates a human-readable summary using the T5 large language model. GO2Sum was developed by fine-tuning T5 on GO term assignments and free-text function descriptions for UniProt entries, enabling it to recreate function descriptions by concatenating GO term descriptions. Our results demonstrated that GO2Sum significantly outperforms the original T5 model that was trained on the entire web corpus in generating Function, Subunit Structure, and Pathway paragraphs for UniProt entries. © The Author(s) 2024.},
	keywords = {Gene Ontology; Humans; Proteins; Software; protein; gene ontology; genetics; human; software},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Liu2024,
	author = {Liu, Dongge and Cheng, Liang},
	title = {MAKG: A maritime accident knowledge graph for intelligent accident analysis and management},
	year = {2024},
	journal = {Ocean Engineering},
	volume = {312},
	doi = {10.1016/j.oceaneng.2024.119280},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204184779&doi=10.1016%2fj.oceaneng.2024.119280&partnerID=40&md5=2a1c8287062fa23e821d7a7cbcb3107d},
	abstract = {With the increasing frequency of human activities at sea, maritime accidents are occurring more often. Analyzing and mining maritime accident cases can help uncover the causal mechanisms behind these incidents, thereby enhancing maritime safety. As an emerging technology for knowledge management and mining, knowledge graphs offer significant support for the storage, reasoning, and decision-making processes related to maritime accidents. In this study, we established a knowledge graph construction and application framework for maritime accidents to facilitates the extraction and management of maritime knowledge from unstructured texts. First, 581 accident reports released by the China Maritime Safety Administration over the past decade (2014–2023) were used as the data basis for analysis and construction of the maritime accident ontology structure using the seven-step method, which comprises 8 entity types, 8 relationship types, and 18 attribute entity types. Second, We proposed MBERT-BiLSTM-CRF-SF, a named entity recognition model based on domain pretraining and self-training, to reduce graph construction costs. This model achieved state-of-the-art performance in the maritime domain, with an F1 score of 0.910 ± 0.006, which is about 5% higher than the mainstream model. In addition, we proposed an entity alignment method based on font and semantics to refine knowledge further. On the basis of the proposed method, we constructed a large, high-quality maritime accident knowledge graph (MAKG) system that contains 16,099 entities and 20,809 relationship instances. Finally, we reduced the complexity of applying knowledge graphs by integrating the CRISPE prompt learning framework of the large language model, and experiments on graph traversal, pattern recognition, and aggregation analysis were conducted to assess the quality of MAKG. Results demonstrate that MAKG can effectively enhance the efficiency of querying and reasoning about maritime accident information, thus providing significant support for the prevention and management of maritime accidents. © 2024 The Authors},
	author_keywords = {BERT; Knowledge graph; Maritime accident; Named entity recognition; Prompt learning},
	keywords = {China; Decision making; Semantics; Accident analysis; Accident management; BERT; Entity-types; Graph construction; Knowledge graphs; Maritime accidents; Maritime safety; Named entity recognition; Prompt learning; accident; accident prevention; complexity; decision making; information system; maritime transportation; performance assessment; transportation safety; transportation technology; Knowledge graph},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Gao2024,
	author = {Gao, Zijing and Liu, Qiao and Zeng, Wanwen and Jiang, Rui and Wong, Wing Hung},
	title = {EpiGePT: a pretrained transformer-based language model for context-specific human epigenomics},
	year = {2024},
	journal = {Genome Biology},
	volume = {25},
	number = {1},
	doi = {10.1186/s13059-024-03449-7},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212500671&doi=10.1186%2fs13059-024-03449-7&partnerID=40&md5=48368ca5f129f7b65638d210f5eaab31},
	abstract = {The inherent similarities between natural language and biological sequences have inspired the use of large language models in genomics, but current models struggle to incorporate chromatin interactions or predict in unseen cellular contexts. To address this, we propose EpiGePT, a transformer-based model designed for predicting context-specific human epigenomic signals. By incorporating transcription factor activities and 3D genome interactions, EpiGePT outperforms existing methods in epigenomic signal prediction tasks, especially in cell-type-specific long-range interaction predictions and genetic variant impacts, advancing our understanding of gene regulation. A free online prediction service is available at http://health.tsinghua.edu.cn/epigept. © The Author(s) 2024.},
	author_keywords = {3D genome; Epigenomics; Gene Regulation; Language model; Transformer},
	keywords = {Chromatin; Epigenesis, Genetic; Epigenomics; Genome, Human; Humans; Software; Transcription Factors; transcription factor; alternative RNA splicing; Article; bioinformatics; chromatin; classification algorithm; controlled study; coronavirus disease 2019; DNA methylation; DNA sequence; embryonic stem cell; epigenetics; gene control; gene expression; gene ontology; genetic transcription; genome-wide association study; genomics; glucose homeostasis; GM12878 cell line; human; human cell; human tissue; K-562 cell line; lung parenchyma; machine learning; mathematical model; mouse; nonhuman; receiver operating characteristic; single nucleotide polymorphism; total quality management; genetic epigenesis; genetics; human genome; metabolism; procedures; software},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access}
}

@ARTICLE{Sepasdar20251,
	author = {Sepasdar, Zahra and Gautam, Sushant and Midoglu, Cise and Riegler, Michael A. and Halvorsen, Pål},
	title = {Soccer-GraphRAG: Applications of GraphRAG in Soccer},
	year = {2025},
	journal = {Communications in Computer and Information Science},
	volume = {2197 CCIS},
	pages = {1 – 10},
	doi = {10.1007/978-3-031-71382-8_1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207645080&doi=10.1007%2f978-3-031-71382-8_1&partnerID=40&md5=a68e6758ee09bf3e4094bbba4eb515db},
	abstract = {In the realm of soccer analytics, the need for efficient and accurate information retrieval is crucial. In this paper, we introduce SoccerGraphRAG, a framework designed to facilitate the retrieval of soccerrelated information through natural language queries. This system leverages knowledge graphs, created from the recently released SoccerNetEchoes dataset which includes transcriptions of soccer game audio commentaries. Soccer-GraphRAG aims to streamline the retrieval, access, and analysis of soccer data, providing insights with precision and contextual relevance. This framework is ideally suited for analyzing player performance, as well as for engaging in question answering (Q&A) and summarizing tasks. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.},
	author_keywords = {Association Football; Automatic Speech Recognition (ASR); GraphRAG; Knowledge Graphs; Large Language Models (LLM)},
	keywords = {Modeling languages; Natural language processing systems; Query languages; Question answering; Speech recognition; Structured Query Language; Automatic speech recognition; Graphrag; Knowledge graphs; Language model; Large language model; Natural language queries; Performance; Question Answering; Soccer games; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{He2025,
	author = {He, Yu and Zhou, Kang and Tian, T. Lifang},
	title = {Multi-modal scene graph inspired policy for visual navigation},
	year = {2025},
	journal = {Journal of Supercomputing},
	volume = {81},
	number = {1},
	doi = {10.1007/s11227-024-06541-8},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208475744&doi=10.1007%2fs11227-024-06541-8&partnerID=40&md5=3bbf40292bbc44119c7c5a97c0757e03},
	abstract = {Visual navigation needs the agent locate the given target with visual perception. To enable robots to effectively execute tasks, combining large language models (LLMs) with multi-modal inputs in navigation is necessary. While LLMs offer rich semantic knowledge, they lack specific real-world information and real-time interaction capabilities. This paper introduces a Multi-modal Scene Graph (MMSG) navigation framework that aligns LLMs with visual perception models to predict next steps. Firstly, a multi-modal scene dataset is constructed, containing triplets of object-relations-target words. We provide target words and lists of existing objects in the scene to generate a large number of instructions and corresponding action plans for GPT-3.5. The generated data is then utilized for pre-train LLM for path planning. During inference, we discover objects in the scene by extending the DETR visual object detector to multi-view RGB image collected from different reachable positions. Experimental results show that path planning generated from MMSG outperforms state-of-the-art methods, indicating its feasibility in complex environments. We evaluate our methods on the ProTHOR dataset and show superior navigation performance. © The Author(s) 2024.},
	author_keywords = {Knowledge graph; Large language model; Task planning; Visual navigation},
	keywords = {Knowledge graph; Machine vision; Motion planning; Navigation charts; Robot programming; Vision; Visual languages; Visual servoing; Knowledge graphs; Language model; Large language model; Multi-modal; Scene-graphs; Semantics knowledge; Target words; Task planning; Visual Navigation; Visual perception; Semantics},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Durmaz2024,
	author = {Durmaz, Ali Riza and Thomas, Akhil and Mishra, Lokesh and Murthy, Rachana Niranjan and Straub, Thomas},
	title = {An ontology-based text mining dataset for extraction of process-structure-property entities},
	year = {2024},
	journal = {Scientific Data},
	volume = {11},
	number = {1},
	doi = {10.1038/s41597-024-03926-5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206056411&doi=10.1038%2fs41597-024-03926-5&partnerID=40&md5=349b6701b7220748db83c57c00880e2a},
	abstract = {While large language models learn sound statistical representations of the language and information therein, ontologies are symbolic knowledge representations that can complement the former ideally. Research at this critical intersection relies on datasets that intertwine ontologies and text corpora to enable training and comprehensive benchmarking of neurosymbolic models. We present the MaterioMiner dataset and the linked materials mechanics ontology where ontological concepts from the mechanics of materials domain are associated with textual entities within the literature corpus. Another distinctive feature of the dataset is its eminently fine-grained annotation. Specifically, 179 distinct classes are manually annotated by three raters within four publications, amounting to 2191 entities that were annotated and curated. Conceptual work is presented for the symbolic representation of causal composition-process-microstructure-property relationships. We explore the annotation consistency between the three raters and perform fine-tuning of pre-trained language models to showcase the feasibility of training named entity recognition models. Reusing the dataset can foster training and benchmarking of materials language models, automated ontology construction, and knowledge graph generation from textual data. © The Author(s) 2024.},
	keywords = {article; benchmarking; human; language model; large language model; mechanics; ontology},
	type = {Data paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access}
}

@ARTICLE{Chatterjee2024,
	author = {Chatterjee, Ayan and Gerdes, Martin W. and Prinz, Andreas and Riegler, Michael A. and Martinez, Santiago G.},
	title = {Semantic representation and comparative analysis of physical activity sensor observations using MOX2-5 sensor in real and synthetic datasets: a proof-of-concept-study},
	year = {2024},
	journal = {Scientific Reports},
	volume = {14},
	number = {1},
	doi = {10.1038/s41598-024-55183-6},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185940438&doi=10.1038%2fs41598-024-55183-6&partnerID=40&md5=34b14a3671893a2c7ef5a15847a69310},
	abstract = {The widespread use of devices like mobile phones and wearables allows for automatic monitoring of human daily activities, generating vast datasets that offer insights into long-term human behavior. A structured and controlled data collection process is essential to unlock the full potential of this information. While wearable sensors for physical activity monitoring have gained significant traction in healthcare, sports science, and fitness applications, securing diverse and comprehensive datasets for research and algorithm development poses a notable challenge. In this proof-of-concept study, we underscore the significance of semantic representation in enhancing data interoperability and facilitating advanced analytics for physical activity sensor observations. Our approach focuses on enhancing the usability of physical activity datasets by employing a medical-grade (CE certified) sensor to generate synthetic datasets. Additionally, we provide insights into ethical considerations related to synthetic datasets. The study conducts a comparative analysis between real and synthetic activity datasets, assessing their effectiveness in mitigating model bias and promoting fairness in predictive analysis. We have created an ontology for semantically representing observations from physical activity sensors and conducted predictive analysis on data collected using MOX2-5 activity sensors. Until now, there has been a lack of publicly available datasets for physical activity collected with MOX2-5 activity monitoring medical grade (CE certified) device. The MOX2-5 captures and transmits high-resolution data, including activity intensity, weight-bearing, sedentary, standing, low, moderate, and vigorous physical activity, as well as steps per minute. Our dataset consists of physical activity data collected from 16 adults (Male: 12; Female: 4) over a period of 30–45 days (approximately 1.5 months), yielding a relatively small volume of 539 records. To address this limitation, we employ various synthetic data generation methods, such as Gaussian Capula (GC), Conditional Tabular General Adversarial Network (CTGAN), and Tabular General Adversarial Network (TABGAN), to augment the dataset with synthetic data. For both the authentic and synthetic datasets, we have developed a Multilayer Perceptron (MLP) classification model for accurately classifying daily physical activity levels. The findings underscore the effectiveness of semantic ontology in semantic search, knowledge representation, data integration, reasoning, and capturing meaningful relationships between data. The analysis supports the hypothesis that the efficiency of predictive models improves as the volume of additional synthetic training data increases. Ontology and Generative AI hold the potential to expedite advancements in behavioral monitoring research. The data presented, encompassing both real MOX2-5 and its synthetic counterpart, serves as a valuable resource for developing robust methods in activity type classification. Furthermore, it opens avenues for exploration into research directions related to synthetic data, including model efficiency, detection of generated data, and considerations regarding data privacy. © The Author(s) 2024.},
	author_keywords = {Gaussian Capula; General adversarial network; MOX2-5; Multilayer perceptron; Semantic ontology; Semantic sensor network; Synthetic data in healthcare},
	keywords = {Adult; Algorithms; Exercise; Female; Human Activities; Humans; Male; Neural Networks, Computer; Semantics; adult; algorithm; article; daily life activity; data integration; data interoperability; data privacy; fairness; female; generative artificial intelligence; human; male; mobile phone; multilayer perceptron; ontology; physical activity; predictive model; proof of concept; reasoning; sensor; sports science; wearable device; wearable sensor; weight bearing},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Zhang2024198,
	author = {Zhang, Jinying and Wang, Zhefeng and Xie, Hua and Yao, Changying and Min, Yanli and Wang, XINYing},
	title = {Development and Application of a Knowledge Retrieval and Analysis System for the Power Industry Based on Knowledge Graph and Large Language Model; [基于知识图谱与大语言模型的电力行业知识检索分析系统研发与应用]},
	year = {2024},
	journal = {Zhongguo Dianli/Electric Power},
	volume = {57},
	number = {12},
	pages = {198 – 205},
	doi = {10.11930/j.issn.1004-9649.202409084},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213293929&doi=10.11930%2fj.issn.1004-9649.202409084&partnerID=40&md5=17ebe497c3bb60c37f75346ebb44d935},
	abstract = {With the rapid development of artificial intelligence technology, knowledge retrieval systems in the power industry are facing technological updates and iterations. A knowledge retrieval and analysis system for the power industry based on knowledge graph and big language model has been proposed. Firstly, using big language models to mine user needs and understand their intentions; Then, for knowledge information with different structures, structured knowledge graphs are constructed through strategies such as knowledge modeling, knowledge extraction, and knowledge fusion; Finally, utilizing a large language model based on user requests and professional knowledge obtained from knowledge subgraphs, and visualizing the generated content for display to users, provides a new approach for knowledge retrieval systems in the power industry. © 2024 Automation of Electric Power Systems Press. All rights reserved.},
	author_keywords = {knowledge extraction; knowledge graph; large language model},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Li2024573,
	author = {Li, Xiaohui Victor and Sanna Passino, Francesco},
	title = {FinDKG: Dynamic Knowledge Graphs with Large Language Models for Detecting Global Trends in Financial Markets},
	year = {2024},
	journal = {ICAIF 2024 - 5th ACM International Conference on AI in Finance},
	pages = {573 – 581},
	doi = {10.1145/3677052.3698603},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214895443&doi=10.1145%2f3677052.3698603&partnerID=40&md5=00d9af903bdb79518bada093290341e7},
	abstract = {Dynamic knowledge graphs (DKGs) are popular structures to express different types of connections between objects over time. They can also serve as an efficient mathematical tool to represent information extracted from complex unstructured data sources, such as text or images. Within financial applications, DKGs could be used to detect trends for strategic thematic investing, based on information obtained from financial news articles. In this work, we explore the properties of large language models (LLMs) as dynamic knowledge graph generators, proposing a novel open-source fine-tuned LLM for this purpose, called the Integrated Contextual Knowledge Graph Generator (ICKG). We use ICKG to produce a novel open-source DKG from a corpus of financial news articles, called FinDKG, and we propose an attention-based GNN architecture for analysing it, called KGTransformer. We test the performance of the proposed model on benchmark datasets and FinDKG, demonstrating superior performance on link prediction tasks. Additionally, we evaluate the performance of the KGTransformer on FinDKG for thematic investing, showing it can outperform existing thematic ETFs.  © 2024 ACM.},
	author_keywords = {Dynamic knowledge graphs; graph attention networks; graph neural networks; graph transformers; large language models.},
	keywords = {Distribution transformers; Financial markets; Graph neural networks; Dynamic knowledge graph; Financial news; Graph attention network; Graph neural networks; Graph transformer; Knowledge graphs; Language model; Large language model.; News articles; Performance; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Bronze Open Access, Green Open Access}
}

@ARTICLE{Wei2024,
	author = {Wei, Zihan and Iyer, Meghna R. and Zhao, Benjamin and Deng, Jennifer and Mitchell, Cassie S.},
	title = {Artificial Intelligence-Assisted Comparative Analysis of the Overlapping Molecular Pathophysiology of Alzheimer’s Disease, Amyotrophic Lateral Sclerosis, and Frontotemporal Dementia},
	year = {2024},
	journal = {International Journal of Molecular Sciences},
	volume = {25},
	number = {24},
	doi = {10.3390/ijms252413450},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213258005&doi=10.3390%2fijms252413450&partnerID=40&md5=fa5e0964fe1a59a10ac9634509a82e21},
	abstract = {The overlapping molecular pathophysiology of Alzheimer’s Disease (AD), Amyotrophic Lateral Sclerosis (ALS), and Frontotemporal Dementia (FTD) was analyzed using relationships from a knowledge graph of 33+ million biomedical journal articles. The unsupervised learning rank aggregation algorithm from SemNet 2.0 compared the most important amino acid, peptide, and protein (AAPP) nodes connected to AD, ALS, or FTD. FTD shared 99.9% of its nodes with ALS and AD; AD shared 64.2% of its nodes with FTD and ALS; and ALS shared 68.3% of its nodes with AD and FTD. The results were validated and mapped to functional biological processes using supervised human supervision and an external large language model. The overall percentages of mapped intersecting biological processes were as follows: inflammation and immune response, 19%; synapse and neurotransmission, 19%; cell cycle, 15%; protein aggregation, 12%; membrane regulation, 11%; stress response and regulation, 9%; and gene regulation, 4%. Once normalized for node count, biological mappings for cell cycle regulation and stress response were more prominent in the intersection of AD and FTD. Protein aggregation, gene regulation, and energetics were more prominent in the intersection of ALS and FTD. Synapse and neurotransmission, membrane regulation, and inflammation and immune response were greater at the intersection of AD and ALS. Given the extensive molecular pathophysiology overlap, small differences in regulation, genetic, or environmental factors likely shape the underlying expressed disease phenotype. The results help prioritize testable hypotheses for future clinical or experimental research. © 2024 by the authors.},
	author_keywords = {Alzheimer’s disease (AD); amyotrophic lateral sclerosis (ALS); frontotemporal dementia (FTD); knowledge graph; literature-based discovery; machine learning; network regulation; neuropathology; neurophysiology; pathology dynamics},
	keywords = {Algorithms; Alzheimer Disease; Amyotrophic Lateral Sclerosis; Artificial Intelligence; Frontotemporal Dementia; Humans; akap10 protein; al1 protein; amino acid; atp8a2 protein; avp protein; bradykinin B2 receptor; calr protein; charged multivesicular body protein 2B; chemical compound; chimerin; cholinergic receptor; cobatoxin 1; cobatoxin 2; conotoxin; copper zinc superoxide dismutase; cyclin dependent kinase 11B; ephrin receptor A3; fatty acid peroxidase; fibroblast growth factor binding protein 3; fibronectin 1; fibrosin; gemin8 protein; guanine nucleotide exchange C9orf72; hoxc protein; liothyronine; lymphocyte cytosolic protein 1; menchyme forkhead 1; microRNA; microRNA 150; microtubule associated protein; n (4 isothiocyano 2 nitrophenyl) 2 aminoethanesulfonate; nima related kinase 9; nuclear matrix binding protein; omega conotoxin RVIA; peptide; phosphatidylserine; phosphatidylserine decarboxylase 2; phospholipid serine base exchange enzyme; polyketide synthase; potassium channel Kv3.4; progranulin; prostaglandin E; protein; protein homer 1a; protoporphyrinogen oxidase; RNA binding protein FUS; secretory phospholipase A2; slc6a7 protein; suppressor of G2 allele of skp1 homolog 1; syntaxin 3B; TAR DNA binding protein; tau protein; TBP associated factor 15 kDa; thrombin; thyroid hormone receptor alpha 1; thyroxine; toll like receptor 5; transcription factor 4; transcription factor 7 like 2; type I interferon receptor; uga4 protein; unclassified drug; valosin containing protein; xylanase x22; Alzheimer disease; amyotrophic lateral sclerosis; Article; artificial intelligence; biological phenomena and functions concerning the entire organism; cell cycle; cell cycle regulation; cell membrane; energy transfer; environmental factor; frontotemporal dementia; gene control; human; immune response; inflammation; large language model; molecular pathology; neuropathology; neurotransmission; phenotype; physiological stress; protein aggregation; regulatory mechanism; supervised machine learning; synapse; Unified Medical Language System; unsupervised machine learning; algorithm; Alzheimer disease; amyotrophic lateral sclerosis; comparative study; frontotemporal dementia; genetics; metabolism; pathology; pathophysiology},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Mihindukulasooriya2025243,
	author = {Mihindukulasooriya, Nandana and Tiwari, Sanju and Dobriy, Daniil and Nielsen, Finn Årup and Chhetri, Tek Raj and Polleres, Axel},
	title = {Scholarly Wikidata: Population and Exploration of Conference Data in Wikidata Using LLMs},
	year = {2025},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) },
	volume = {15370 LNAI},
	pages = {243 – 259},
	doi = {10.1007/978-3-031-77792-9_15},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210802375&doi=10.1007%2f978-3-031-77792-9_15&partnerID=40&md5=2174304a5b13ed0c2f1946e6903ee33a},
	abstract = {Several initiatives have been undertaken to conceptually model the domain of scholarly data using ontologies and to create respective Knowledge Graphs. Yet, the full potential seems unleashed, as automated means for automatic population of said ontologies are lacking, and respective initiatives from the Semantic Web community are not necessarily connected: we propose to make scholarly data more sustainably accessible by leveraging Wikidata’s infrastructure and automating its population in a sustainable manner through LLMs by tapping into unstructured sources like conference Web sites and proceedings texts as well as already existing structured conference datasets. While an initial analysis shows that Semantic Web conferences are only minimally represented in Wikidata, we argue that our methodology can help to populate, evolve and maintain scholarly data as a community within Wikidata. Our main contributions include (a) an analysis of ontologies for representing scholarly data to identify gaps and relevant entities/properties in Wikidata, (b) semi-automated extraction – requiring (minimal) manual validation – of conference metadata (e.g., acceptance rates, organizer roles, programme committee members, best paper awards, keynotes, and sponsors) from websites and proceedings texts using LLMs. Finally, we discuss (c) extensions to visualization tools in the Wikidata context for data exploration of the generated scholarly data. Our study focuses on data from 105 Semantic Web-related conferences and extends/adds more than 6000 entities in Wikidata. It is important to note that the method can be more generally applicable beyond Semantic Web-related conferences for enhancing Wikidata’s utility as a comprehensive scholarly resource. Source Repository: https://github.com/scholarly-wikidata/  DOI:https://doi.org/10.5281/zenodo.10989709  License: Creative Commons CC0 (Data), MIT (Code).  © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.},
	author_keywords = {Large Language Model; Scholarly Data; Wikidata},
	keywords = {Data centers; Ontology; Semantics; Spatio-temporal data; Automatic populations; Community IS; Knowledge graphs; Language model; Large language model; Ontology's; Scholarly data; Semantic-Web; Web community; Wikidata; Data assimilation},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Li2024,
	author = {Li, Jiecheng and Luo, Xudong and Lu, Guangquan},
	title = {GS-CBR-KBQA: Graph-structured case-based reasoning for knowledge base question answering},
	year = {2024},
	journal = {Expert Systems with Applications},
	volume = {257},
	doi = {10.1016/j.eswa.2024.125090},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201422953&doi=10.1016%2fj.eswa.2024.125090&partnerID=40&md5=02bfa2bfc82ee2badc16d86ab23d192c},
	abstract = {Knowledge Base Question Answering (KBQA) task is an important research direction in natural language processing. Due to the flexibility and ambiguity of natural language, users’ questions often have more complex query types and richer semantic information. To address this issue, this paper proposes the GS-CBR-KBQA model, a Case-Based Reasoning model tailored for KBQA to improve the semantic parsing accuracy and interpretability of natural language questions. The model integrates Knowledge-oriented Programming Language (KoPL) reasoning graphs with query information, employing a Graph Auto-Encoder and the RoBERTa pretrained language model for a highly effective case retrieval. This integration leads to a more robust knowledge retrieval and application approach, particularly innovative in capturing the relationships within KoPL graphs. The model addresses explicitly complex questions such as multi-hop reasoning and questions involving intricate entity relationships. Finally, our extensive experiments show that the model performs excellently in accuracy and F1 metrics on benchmark datasets such as WebQSP and ComplexWebQuestions, particularly in complex question-answering. The code of our model is available at https://anonymous.4open.science/r/GS-CBR-KBQA. © 2024 Elsevier Ltd},
	author_keywords = {Case-based reasoning; Deep learning; Knowledge base question answering; Large language model; Natural language processing},
	keywords = {Case based reasoning; Knowledge graph; Structured Query Language; Casebased reasonings (CBR); Deep learning; Knowledge base question answering; Knowledge-oriented; Language model; Language processing; Large language model; Natural language processing; Natural languages; Question Answering; Question answering},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Wang202529,
	author = {Wang, Guan and Li, Weihua and Lai, Edmund M.-K. and Bai, Quan},
	title = {Aspect-Adaptive Knowledge-based Opinion Summarization},
	year = {2025},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) },
	volume = {15372 LNAI},
	pages = {29 – 41},
	doi = {10.1007/978-981-96-0026-7_3},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210249660&doi=10.1007%2f978-981-96-0026-7_3&partnerID=40&md5=4f294280c2acef39b6d713a0cb33f754},
	abstract = {The increase in online information has overwhelmed users with opinions and comments on various products and services, making decision-making a daunting task. Text summarization can help by distilling long or multiple documents into concise, relevant content. Recent advances in Large Language Models (LLM) have shown great potential in this area. The existing text summarization approaches often lack the “adaptive” nature required to capture diverse aspects in opinion summarization, which is particularly detrimental to users with specific preferences. In this paper, we introduce an Aspect-adaptive Knowledge-based Opinion Summarization model for product reviews. This model generates summaries that highlight specific aspects of reviews, providing users with targeted, relevant information quickly. Our extensive experiments with real-world datasets explicitly demonstrate that our model surpasses current state-of-the-art methods. It effectively adapts to user needs, producing efficient, aspect-focused summaries that help users make informed decisions based on their unique preferences. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2025.},
	author_keywords = {Aspect-adaptive Opinion Summarization; Deep Learning; Knowledge Graph; Self-supervised; Text Summarization},
	keywords = {Contrastive Learning; Knowledge graph; Aspect-adaptive opinion summarization; Decisions makings; Deep learning; Knowledge based; Knowledge graphs; Making decision; Online information; Product and services; Self-supervised; Text Summarisation; Self-supervised learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Bianchini2025145,
	author = {Bianchini, Filippo and Calamo, Marco and De Luzi, Francesca and Macrì, Mattia and Mecella, Massimo},
	title = {A Service-Based Pipeline for Complex Linguistic Tasks Adopting LLMs and Knowledge Graphs},
	year = {2025},
	journal = {Communications in Computer and Information Science},
	volume = {2221 CCIS},
	pages = {145 – 161},
	doi = {10.1007/978-3-031-72578-4_8},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207827226&doi=10.1007%2f978-3-031-72578-4_8&partnerID=40&md5=8441f5f5be2847d35e0cb06fc7be1657},
	abstract = {This paper introduces a microservices-based architecture designed for executing complex linguistic tasks using Large Language Models (LLMs) and Knowledge Graphs (KGs). It has been conceived by focusing on the legal domain, and it integrates Domain-specific KGs and Constraint KGs to address tasks such as law extraction and reasoning. We outline how the pipeline works through a running example involving the extraction of legislative references from legal documents. Furthermore, we discuss a methodology for building KGs from unstructured documents and employing zero-shot prompt engineering techniques to facilitate information extraction. Finally, we present a validation process leveraging the Constraint KG to ensure the coherence and correctness of generated outputs. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.},
	author_keywords = {complex linguistic tasks; Knowledge Graphs; Large Language Models; microservices},
	keywords = {Linguistics; Modeling languages; Complex linguistic task; Domain-specific knowledge; Knowledge constraints; Knowledge graphs; Language model; Large language model; Legal documents; Legal domains; Microservice; Service-based; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Kamatović20246,
	author = {Kamatović, Tamara},
	title = {AUGUSTINE AND THE POSTHUMAN WRITER: TOWARD AN AMBIGUOUS AUTHORSHIP IN THE AGE OF ARTIFICIAL INTELLIGENCE},
	year = {2024},
	journal = {Journal of Posthuman Studies},
	volume = {8},
	number = {1},
	pages = {6 – 22},
	doi = {10.5325/jpoststud.8.1.0006},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212755880&doi=10.5325%2fjpoststud.8.1.0006&partnerID=40&md5=a8143c14120c9aa581f6fbc44efe5a9c},
	abstract = {This article explores emerging hybrid ontologies of the posthuman in the context of generative AI technologies and their impact on writing practices. We should regard arguments mobilizing fear of AI-assisted or -generated writing as based on misguided anxieties about the potentials of human creative acts and man/machine hybrid creations (what this article refers to as a model of “weak authorship”). A reading of St. Augustine’s Confessions, a key work in the Judeo-Christian tradition, shows how an early Christian humanist text can give us a model for understanding paternalist structures that place human authorship and human creators within a hierarchy of creation, where the transcendental and divine is identified as the highest source of creation, and where the “human creator” must seek legitimation and authorization from that higher power to create in the first place. The article explores creativity through the concept of ambiguity, speculating on the extent to which AI and human authorship might be combined and to what extent such hybrid forms might impact our understanding of human creativity. As generative technologies continue to be integrated into our lifeworld, we should develop a strong account of authorship that embraces the concept of ambiguity as a means of orienting ourselves toward a nondualist ontology of becoming. Copyright © 2024.},
	author_keywords = {ambiguity; artificial intelligence; augustine; authorship; writing},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Sunil2024,
	author = {Sunil, Rohan Shawn and Lim, Shan Chun and Itharajula, Manoj and Mutwil, Marek},
	title = {The gene function prediction challenge: Large language models and knowledge graphs to the rescue},
	year = {2024},
	journal = {Current Opinion in Plant Biology},
	volume = {82},
	doi = {10.1016/j.pbi.2024.102665},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209639477&doi=10.1016%2fj.pbi.2024.102665&partnerID=40&md5=2a90ee4162685c7af9823e57bba216c6},
	abstract = {Elucidating gene function is one of the ultimate goals of plant science. Despite this, only ∼15 % of all genes in the model plant Arabidopsis thaliana have comprehensively experimentally verified functions. While bioinformatical gene function prediction approaches can guide biologists in their experimental efforts, neither the performance of the gene function prediction methods nor the number of experimental characterization of genes has increased dramatically in recent years. In this review, we will discuss the status quo and the trajectory of gene function elucidation and outline the recent advances in gene function prediction approaches. We will then discuss how recent artificial intelligence advances in large language models and knowledge graphs can be leveraged to accelerate gene function predictions and keep us updated with scientific literature. © 2024 Elsevier Ltd},
	keywords = {Arabidopsis; Artificial Intelligence; Computational Biology; Genes, Plant; Arabidopsis; artificial intelligence; bioinformatics; genetics; plant gene; procedures},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Yang2024,
	author = {Yang, Kuo and Dong, Xin and Zhang, Shuhan and Yu, Haibin and Zhong, Liqun and Zhang, Lei and Zhao, He and Hou, Yutong and Song, Xinpeng and Zhou, Xuezhong},
	title = {PresRecRF: Herbal prescription recommendation via the representation fusion of large TCM semantics and molecular knowledge: PresRecRF: HPR via the representation fusion of large TCM semantics and molecular knowledge},
	year = {2024},
	journal = {Phytomedicine},
	volume = {135},
	doi = {10.1016/j.phymed.2024.156116},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206079455&doi=10.1016%2fj.phymed.2024.156116&partnerID=40&md5=5ff106966133f78c58515e201d5b154f},
	abstract = {Background: Herbal prescription recommendation (HPR) is a hotspot in the research of clinical intelligent decision support. Recently plentiful HPR models based on deep neural networks have been proposed. Owing to insufficient data, e.g., lack of knowledge of molecular, TCM theory, and herbal dosage in HPR modeling, the existing models suffer from challenges, e.g., plain prediction precision, and are far from real-world clinics. Purpose: To address these problems, we proposed a novel herbal prescription recommendation model with the representation fusion of large TCM semantics and molecular knowledge (termed PresRecRF). Study Design and Methods: PresRecRF comprises three key modules. The representation learning module consists of two key components: a molecular knowledge representation component, integrating molecular knowledge into the herb-symptom-protein knowledge graph to enhance representations for herbs and symptoms; and a TCM knowledge representation component, leveraging BERT and ChatGPT to acquire TCM knowledge-enriched semantic representations. We introduced a representation fusion module to effectively merge molecular and TCM semantic representations. In the herb recommendation module, a multi-task objective loss is implemented to predict both herbs and dosages simultaneously. Results: The experimental results on two clinical datasets show that PresRecRF can achieve the optimal performance. Further analysis of ablation, hyper-parameters, and case studies indicate the effectiveness and reliability of the proposed model, suggesting that it can help precision medicine and treatment recommendations. Conclusion: The entire process of the proposed PresRecRF model closely mirrors the actual diagnosis and treatment procedures carried out by doctors, which are better applied in real clinical scenarios. The source codes of PresRecRF is available at https://github.com/2020MEAI/PresRecRF. © 2024},
	author_keywords = {Feature fusion; Herb dosage prediction; Herbal prescription recommendation; Large language model; Molecular knowledge; TCM semantics},
	keywords = {Decision Support Systems, Clinical; Drugs, Chinese Herbal; Humans; Medicine, Chinese Traditional; Semantics; calcined eulopnia; Chinese medicinal formula; chuan lian zi; chuanxiong; common yam rhizome; danshen root; dried tangerine peel; fried atractylodes macrocephala; fried white peony root; Glycyrrhiza glabra root; herbaceous agent; honey licorice; jujube extract; kansui; lacquer tree sap; largehead atractylodes rhizome; liquorice root; lotus seed meat; radix paeoniae alba; radix paeoniae rubra; tsaoco; turmeric; unclassified drug; vinegar; vinegar chicken gizzard skin; vinegar corydalis; vinegar curcuma; vinegar schisandra; zhike; aconite; Alisma; Allium tuberosum; Amomum; Angelica; appetite disorder; Article; Atractylodes; bean; black plum; bone; Bupleurum; cardamom; ChatGPT; chest tightness; Chinese medicine; cinnamon; clinical feature; Codonopsis; comparative study; Coptis; Costus; coughing; cuttlefish; Dioscorea polystachya; dried food; drug research; dyspnea; Eupathorium; feature learning (machine learning); fried cardamom; fried divine comedy; fried white hyacinth bean; fruit peel; gastroesophageal reflux; ginseng; heartburn; human; knowledge; Lonicera; Lotus (genus); lung disease; medical decision making; model; oyster; Pinellia; Piper betle; plant leaf; plum; Poria; prediction; prescription recommendation model; processed evodia; processed food; raw dragon bone; Salt psoralea; Salvia miltiorrhiza; Saposhnikovia; Scutellaria; Scutellaria baicalensis; semantics; Sophora flavescens; sore throat; tangerine; Terminalia chebula; toxicity; vomiting; wheezing; xerostomia; Zhe beimu; Chinese medicine; clinical decision support system; procedures},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Ayad20242611,
	author = {Ayad, Sarah and Alsayoud, Fatimah},
	title = {Prompt engineering techniques for semantic enhancement in business process models},
	year = {2024},
	journal = {Business Process Management Journal},
	volume = {30},
	number = {7},
	pages = {2611 – 2641},
	doi = {10.1108/BPMJ-02-2024-0108},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201561386&doi=10.1108%2fBPMJ-02-2024-0108&partnerID=40&md5=ed563575f69dc0e00f839106b3feab8a},
	abstract = {Purpose: The term knowledge refers to the part of the world investigated by a specific discipline and that includes a specific taxonomy, vocabulary, concepts, theories, research methods and standards of justification. Our approach uses domain knowledge to improve the quality of business process models (BPMs) by exploiting the domain knowledge provided by large language models (LLMs). Among these models, ChatGPT stands out as a notable example of an LLM capable of providing in-depth domain knowledge. The lack of coverage presents a limitation in each approach, as it hinders the ability to fully capture and represent the domain’s knowledge. To solve such limitations, we aim to exploit GPT-3.5 knowledge. Our approach does not ask GPT-3.5 to create a visual representation; instead, it needs to suggest missing concepts, thus helping the modeler improve his/her model. The GPT-3.5 may need to refine its suggestions based on feedback from the modeler. Design/methodology/approach: We initiate our semantic quality enhancement process of a BPM by first extracting crucial elements including pools, lanes, activities and artifacts, along with their corresponding relationships such as lanes being associated with pools, activities belonging to each lane and artifacts associated with each activity. These data are systematically gathered and structured into ArrayLists, a form of organized collection that allows for efficient data manipulation and retrieval. Once we have this structured data, our methodology involves creating a series of prompts based on each data element. We adopt three approaches to prompting: zero-shot, few-shot and chain of thoughts (CoT) prompts. Each type of prompting is specifically designed to interact with the OpenAI language model in a unique way, aiming to elicit a diverse array of suggestions. As we apply these prompting techniques, the OpenAI model processes each prompt and returns a list of suggestions tailored to that specific element of the BPM. Our approach operates independently of any specific notation and offers semi-automation, allowing modelers to select from a range of suggested options. Findings: This study demonstrates the significant potential of prompt engineering techniques in enhancing the semantic quality of BPMs when integrated with LLMs like ChatGPT. Our analysis of model activity richness and model artifact richness across different prompt techniques and input configurations reveals that carefully tailored prompts can lead to more complete BPMs. This research is a step forward for further exploration into the optimization of LLMs in BPM development. Research limitations/implications: The limitation is the domain ontology that we are relying on to evaluate the semantic completeness of the new BPM. In our future work, the modeler will have the option to ask for synonyms, hyponyms, hypernyms or keywords. This feature will facilitate the replacement of existing concepts to improve not only the completeness of the BPM but also the clarity and specificity of concepts in BPMs. Practical implications: To demonstrate our methodology, we take the “Hospitalization” process as an illustrative example. In the scope of our research, we have presented a select set of instructions pertinent to the “chain of thought” and “few-shot prompting.” Due to constraints in presentation and the extensive nature of the instructions, we have not included every detail within the body of this paper. However, they can be found in the previous GitHub link. Two appendices are given at the end. Appendix 1 describes the different prompt instructions. Appendix 2 presents the application of the instructions in our example. Originality/value: In our research, we rely on the domain application knowledge provided by ChatGPT-3 to enhance the semantic quality of BPMs. Typically, the semantic quality of BPMs may suffer due to the modeler's lack of domain knowledge. To address this issue, our approach employs three prompt engineering methods designed to extract accurate domain knowledge. By utilizing these methods, we can identify and propose missing concepts, such as activities and artifacts. This not only ensures a more comprehensive representation of the business process but also contributes to the overall improvement of the model's semantic quality, leading to more effective and accurate business process management. © 2024, Emerald Publishing Limited.},
	author_keywords = {Business process improvement; Business process modeling; Business process redesign; Prompt engineering; Semantic quality},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Zimmermann2024,
	author = {Zimmermann, Gero},
	title = {What makes systems intelligent},
	year = {2024},
	journal = {Discover Psychology},
	volume = {4},
	number = {1},
	doi = {10.1007/s44202-024-00245-z},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205985624&doi=10.1007%2fs44202-024-00245-z&partnerID=40&md5=947c4ca5f44f85cc53e1efe52729be10},
	abstract = {We are confronted with the concept of intelligence every day. Starting with human intelligence to artificial intelligence. Some animals are also attested to be intelligent based on specific problems they solve. We also come across terms such as swarm intelligence, emotional intelligence or even physical intelligence. But there is still a lack of a clear definition of what intelligence actually is and, in particular, how it could be measured. Intelligence tests that provide quantitative information have so far only been available from psychology and only for people. There is a lack of criteria for what makes a system an intelligent system. This became particularly clear with the question of whether generative AI, such as ChatGPT, can be considered intelligent at all. So can intelligence be derived from the cognitive abilities of a system, or is it ultimately decisive how these abilities come about? This paper suggests a definition of the term intelligence and suggests an explanation for what constitutes intelligence and to what extent intelligence is required to gain knowledge. And finally it is questioned whether artificial systems are intelligent and have any knowledge at all. © The Author(s) 2024.},
	author_keywords = {AI; Cognition; Consciousness; Intelligence; Knowledge; Ontology},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Groza2024,
	author = {Groza, Tudor and Caufield, Harry and Gration, Dylan and Baynam, Gareth and Haendel, Melissa A. and Robinson, Peter N. and Mungall, Christopher J. and Reese, Justin T.},
	title = {An evaluation of GPT models for phenotype concept recognition},
	year = {2024},
	journal = {BMC Medical Informatics and Decision Making},
	volume = {24},
	number = {1},
	doi = {10.1186/s12911-024-02439-w},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183914608&doi=10.1186%2fs12911-024-02439-w&partnerID=40&md5=b19f4ec37a3955d0406a08de5413709a},
	abstract = {Objective: Clinical deep phenotyping and phenotype annotation play a critical role in both the diagnosis of patients with rare disorders as well as in building computationally-tractable knowledge in the rare disorders field. These processes rely on using ontology concepts, often from the Human Phenotype Ontology, in conjunction with a phenotype concept recognition task (supported usually by machine learning methods) to curate patient profiles or existing scientific literature. With the significant shift in the use of large language models (LLMs) for most NLP tasks, we examine the performance of the latest Generative Pre-trained Transformer (GPT) models underpinning ChatGPT as a foundation for the tasks of clinical phenotyping and phenotype annotation. Materials and methods: The experimental setup of the study included seven prompts of various levels of specificity, two GPT models (gpt-3.5-turbo and gpt-4.0) and two established gold standard corpora for phenotype recognition, one consisting of publication abstracts and the other clinical observations. Results: The best run, using in-context learning, achieved 0.58 document-level F1 score on publication abstracts and 0.75 document-level F1 score on clinical observations, as well as a mention-level F1 score of 0.7, which surpasses the current best in class tool. Without in-context learning, however, performance is significantly below the existing approaches. Conclusion: Our experiments show that gpt-4.0 surpasses the state of the art performance if the task is constrained to a subset of the target ontology where there is prior knowledge of the terms that are expected to be matched. While the results are promising, the non-deterministic nature of the outcomes, the high cost and the lack of concordance between different runs using the same prompt and input make the use of these LLMs challenging for this particular task. © 2024, Crown.},
	author_keywords = {Artificial intelligence; Generative pretrained transformer; Human Phenotype Ontology; Large language models; Phenotype concept recognition},
	keywords = {Humans; Knowledge; Language; Machine Learning; Phenotype; Rare Diseases; human; knowledge; language; machine learning; phenotype; rare disease},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Tong2024,
	author = {Tong, Song and Mao, Kai and Huang, Zhen and Zhao, Yukun and Peng, Kaiping},
	title = {Automating psychological hypothesis generation with AI: when large language models meet causal graph},
	year = {2024},
	journal = {Humanities and Social Sciences Communications},
	volume = {11},
	number = {1},
	doi = {10.1057/s41599-024-03407-5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198141251&doi=10.1057%2fs41599-024-03407-5&partnerID=40&md5=5ea154b2733fcdfefc295609f4cd9558},
	abstract = {Leveraging the synergy between causal knowledge graphs and a large language model (LLM), our study introduces a groundbreaking approach for computational hypothesis generation in psychology. We analyzed 43,312 psychology articles using a LLM to extract causal relation pairs. This analysis produced a specialized causal graph for psychology. Applying link prediction algorithms, we generated 130 potential psychological hypotheses focusing on “well-being”, then compared them against research ideas conceived by doctoral scholars and those produced solely by the LLM. Interestingly, our combined approach of a LLM and causal graphs mirrored the expert-level insights in terms of novelty, clearly surpassing the LLM-only hypotheses (t(59) = 3.34, p = 0.007 and t(59) = 4.32, p < 0.001, respectively). This alignment was further corroborated using deep semantic analysis. Our results show that combining LLM with machine learning techniques such as causal knowledge graphs can revolutionize automated discovery in psychology, extracting novel insights from the extensive literature. This work stands at the crossroads of psychology and artificial intelligence, championing a new enriched paradigm for data-driven hypothesis generation in psychological research. © The Author(s) 2024.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{2025,
	title = {5th Workshop on Intelligent Data - From Data to Knowledge, DOING 2024, 3rd Workshop on Knowledge Graphs Analysis on a Large Scale, K-GALS 2024, 6th Workshop on Modern Approaches in Data Engineering and Information System Design, MADEISD 2024 and 3rd Workshop on Personalization and Recommender Systems, PERS 2024 held in conjunction with 28th European Conference on Advances in Databases and Information Systems, ADBIS 2024},
	year = {2025},
	journal = {Communications in Computer and Information Science},
	volume = {2186 CCIS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210157946&partnerID=40&md5=557d22e5c5a7df48ba04c689d9a3414a},
	abstract = {The proceedings contain 37 papers. The special focus in this conference is on Intelligent Data. The topics include: A Compact and Efficient Data Structure for Line-Based Processing of Series of Raster Data; fedeM: Federated Learning-Based Privacy-Preserving Record Matching; Estimating MPdist with SAX and Machine Learning; entity Matching with Large Language Models as Weak and Strong Labellers; LLMClean: Context-Aware Tabular Data Cleaning via LLM-Generated OFDs; capturing Analytical Intents from Text; the Effect of Text Normalization on Mining Portuguese Man-of-War Instagram Posts; a Preliminary Investigation: Strategies for Incorporating Logical Rules Into Knowledge Graph Embeddings; construction of Open Data Sources for Data Interoperability in Brazilian Health Information Systems; brazilian Political Study with Topics Analysis and Complex Networks; Transforming Text Into Knowledge with Graphs: Report of the GDR MADICS DOING Action; building Model-Driven Knowledge Graphs via Large Language Models; process Mining in Croatia’s Judicial Auctions; Towards the Utilization of AI-Powered Assistance for Systematic Literature Review; estimating Information Efficiency of Bitcoin Inscriptions; deep Learning-Based Cellular Nuclei Segmentation Using Transformer Model; towards a Model-Driven Approach to Enable Uniform Access to Vector Databases; employing Multiple Online Translation Services in a Multilingual Database Design Tool; development of Collaborative Business Intelligence Framework for Tourism Domain Analysis; session-Based Recommendation with Graph Neural Networks with an Examination of the Impact of Local and Global Vectors; senselife: Service Recommendation and Frailty Prevention Through Knowledge Models; evaluating Diversity in Sequential Group Recommendations; using Graph Theory for Clinical Data Management; Advancing Legal NLP: Application of Pre-trained Language Models in the Legal Domain; an Application for Scoliosis Screening and Follow-Up: A First Proposal; negation Detection in Italian: A Key Challenge in Sentiment Analysis; optimizing Federated Learning and Increasing Efficiency; integrating Pseudo-time Series Analysis Into Telemedicine: Enhancing Real-Time Disease Monitoring and Intervention; classifying Chest X-Ray Images with Deep Learning Techniques: Challenges and Explainable Analysis.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Chen202533,
	author = {Chen, Yao and Shen, Yuming},
	title = {Temporal Knowledge Graph Link Prediction Using Synergized Large Language Models and Temporal Knowledge Graphs},
	year = {2025},
	journal = {Communications in Computer and Information Science},
	volume = {2183 CCIS},
	pages = {33 – 45},
	doi = {10.1007/978-981-97-7007-6_3},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205488383&doi=10.1007%2f978-981-97-7007-6_3&partnerID=40&md5=eadc1f5b13127d96b8e2ff0c7036a6ca},
	abstract = {Although large language models and temporal knowledge graphs each have significant advantages in the field of artificial intelligence, they also face certain challenges. However, through collaboration, large language models and temporal knowledge graphs can complement each other, addressing their respective shortcomings. This collaborative approach aims to harness the potential feasibility and practical effectiveness of large language models as external knowledge bases for temporal knowledge graph reasoning tasks. In our research, we have meticulously designed a synergized model that leverages the knowledge from the graph as prompts. The answers generated by the large language model undergo careful processing before being seamlessly incorporated into the training dataset. The ultimate goal is to significantly enhance the reasoning capabilities of temporal knowledge graphs. Experimental results underscore the positive impact of this synergized model on the completion tasks of temporal knowledge graphs, showcasing its potential to address gaps in knowledge and improve overall performance. While its influence on prediction tasks is relatively weak, the collaborative synergy demonstrates promising avenues for further exploration and development in the realm of AI research. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2025.},
	author_keywords = {Completion task; Large language models; Prediction task; Synergetic pattern; Temporal knowledge graphs},
	keywords = {Prediction models; Completion task; Knowledge graphs; Language model; Large language model; Model knowledge; Prediction tasks; Synergetic pattern; Synergetics; Temporal knowledge; Temporal knowledge graph; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Shah-Mohammadi20242173,
	author = {Shah-Mohammadi, Fatemeh and Finkelstein, Joseph},
	title = {Addressing Semantic Variability in Clinical Outcome Reporting Using Large Language Models},
	year = {2024},
	journal = {BioMedInformatics},
	volume = {4},
	number = {4},
	pages = {2173 – 2185},
	doi = {10.3390/biomedinformatics4040116},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213514159&doi=10.3390%2fbiomedinformatics4040116&partnerID=40&md5=76b35d15d3cb635b2481dcbbdac42450},
	abstract = {Background/Objectives: Clinical trials frequently employ diverse terminologies and definitions to describe similar outcomes, leading to ambiguity and inconsistency in data interpretation. Addressing the variability in clinical outcome reports and integrating semantically similar outcomes is important in healthcare and clinical research. Variability in outcome reporting not only hinders the comparability of clinical trial results but also poses significant challenges in evidence synthesis, meta-analysis, and evidence-based decision-making. Methods: This study investigates variability reduction in outcome measures reporting using rule-based and large language-based models. It aims to mitigate the challenges associated with variability in outcome reporting by comparing these two models. The first approach, which is rule-based, will leverage well-known ontologies, and the second approach exploits sentence-bidirectional encoder representations from transformers (SBERT) to identify semantically similar outcomes along with Generative Pre-training Transformer (GPT) to refine the results. Results: The results show that the relatively low percentages of outcomes are linked to established rule-based ontologies. Analysis of outcomes by word count highlighted the absence of ontological linkage for three-word outcomes, which indicates potential gaps in semantic representation. Conclusions: Employing large language models (LLMs), this study demonstrates its ability to identify similar outcomes, even with more than three words, suggesting a crucial role in outcome harmonization efforts, potentially reducing redundancy and enhancing data interoperability. © 2024 by the authors.},
	author_keywords = {clinical outcome; large language model; ontology; semantic variability},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Diaz Ochoa2024,
	author = {Diaz Ochoa, Juan G. and Mustafa, Faizan E. and Weil, Felix and Wang, Yi and Kama, Kudret and Knott, Markus},
	title = {The aluminum standard: using generative Artificial Intelligence tools to synthesize and annotate non-structured patient data},
	year = {2024},
	journal = {BMC Medical Informatics and Decision Making},
	volume = {24},
	number = {1},
	doi = {10.1186/s12911-024-02825-4},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213549719&doi=10.1186%2fs12911-024-02825-4&partnerID=40&md5=eaddc8fc9e03114533b8fe17eb1225a6},
	abstract = {Background: Medical narratives are fundamental to the correct identification of a patient’s health condition. This is not only because it describes the patient’s situation. It also contains relevant information about the patient’s context and health state evolution. Narratives are usually vague and cannot be categorized easily. On the other hand, once the patient’s situation is correctly identified based on a narrative, it is then possible to map the patient’s situation into precise classification schemas and ontologies that are machine-readable. To this end, language models can be trained to read and extract elements from these narratives. However, the main problem is the lack of data for model identification and model training in languages other than English. First, gold standard annotations are usually not available due to the high level of data protection for patient data. Second, gold standard annotations (if available) are difficult to access. Alternative available data, like MIMIC (Sci Data 3:1, 2016) is written in English and for specific patient conditions like intensive care. Thus, when model training is required for other types of patients, like oncology (and not intensive care), this could lead to bias. To facilitate clinical narrative model training, a method for creating high-quality synthetic narratives is needed. Method: We devised workflows based on generative AI methods to synthesize narratives in the German language to avoid the disclosure of patient’s health data. Since we required highly realistic narratives, we generated prompts, written with high-quality medical terminology, asking for clinical narratives containing both a main and co-disease. The frequency of distribution of both the main and co-disease was extracted from the hospital’s structured data, such that the synthetic narratives reflect the disease distribution among the patient’s cohort. In order to validate the quality of the synthetic narratives, we annotated them to train a Named Entity Recognition (NER) algorithm. According to our assumptions, the validation of this system implies that the synthesized data used for its training are of acceptable quality. Result: We report precision, recall and F1 score for the NER model while also considering metrics that take into account both exact and partial entity matches. Trained models are cautious, with a precision up to 0.8 for Entity Type match metric and a F1 score of 0.3. Conclusion: Despite its inherent limitations, this technology has the potential to allow data interoperability by using encoded diseases across languages and regions without compromising data safety. Additionally, it facilitates the synthesis of unstructured patient data. In this way, the identification and training of models can be accelerated. We believe that this method may be able to generate discharge letters for any combination of main and co-diseases, which will significantly reduce the amount of time spent writing these letters by healthcare professionals. © The Author(s) 2024.},
	author_keywords = {Generative AI; Language models; Non-english Language models; Synthetic data; Synthetic narratives},
	keywords = {Artificial Intelligence; Humans; Narration; Natural Language Processing; artificial intelligence; human; natural language processing; verbal communication},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Xie2024,
	author = {Xie, Xin and Wang, Junbo and Han, Yu and Li, Wenjuan},
	title = {Knowledge Graph-Based In-Context Learning for Advanced Fault Diagnosis in Sensor Networks},
	year = {2024},
	journal = {Sensors},
	volume = {24},
	number = {24},
	doi = {10.3390/s24248086},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213217940&doi=10.3390%2fs24248086&partnerID=40&md5=f55b31a4c83a5740f49cea8754fed190},
	abstract = {This paper introduces a novel approach for enhancing fault diagnosis in industrial equipment systems through the application of sensor network-driven knowledge graph-based in-context learning (KG-ICL). By focusing on the critical role of sensor data in detecting and isolating faults, we construct a domain-specific knowledge graph (DSKG) that encapsulates expert knowledge relevant to industrial equipment. Utilizing a long-length entity similarity (LES) measure, we retrieve relevant information from the DSKG. Our method leverages large language models (LLMs) to conduct causal analysis on textual data related to equipment faults derived from sensor networks, thereby significantly enhancing the accuracy and efficiency of fault diagnosis. This paper details a series of experiments that validate the effectiveness of the KG-ICL method in accurately diagnosing fault causes and locations of industrial equipment systems. By leveraging LLMs and structured knowledge, our approach offers a robust tool for condition monitoring and fault management, thereby improving the reliability and efficiency of operations in industrial sectors. © 2024 by the authors.},
	author_keywords = {fault diagnosis; in-context learning; knowledge graph; large language models},
	keywords = {Data encapsulation; Context learning; Faults diagnosis; Graph-based; In contexts; In-context learning; Industrial equipment; Knowledge graphs; Language model; Large language model; Sensors network; article; context learning; controlled study; diagnosis; knowledge; large language model; reliability; sensor; Knowledge graph},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Ieva20243095,
	author = {Ieva, Saverio and Loconte, Davide and Loseto, Giuseppe and Ruta, Michele and Scioscia, Floriano and Marche, Davide and Notarnicola, Marianna},
	title = {A Retrieval-Augmented Generation Approach for Data-Driven Energy Infrastructure Digital Twins},
	year = {2024},
	journal = {Smart Cities},
	volume = {7},
	number = {6},
	pages = {3095 – 3120},
	doi = {10.3390/smartcities7060121},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213473949&doi=10.3390%2fsmartcities7060121&partnerID=40&md5=725f9465adfec09814548b4b9ec4f184},
	abstract = {Highlights: What are the main findings? Novel data-driven and knowledge-based energy digital-twin framework integrating a Retrieval-Augmented Generation (RAG) approach. Prototype applied to a real-world scenario involving the management of high-voltage energy infrastructures, showcasing the framework feasibility and effectiveness in operational environments. What is the implication of the main finding? Improved management of energy infrastructures enhancing the ability to predict future conditions and prescribe more informed and data-driven decisions in asset maintenance. Exploitation of a conversational virtual assistant to interact with users, improving the accessibility, interpretability, and usability of complex data for decision-makers. Digital-twin platforms are increasingly adopted in energy infrastructure management for smart grids. Novel opportunities arise from emerging artificial intelligence technologies to increase user trust by enhancing predictive and prescriptive analytics capabilities and by improving user interaction paradigms. This paper presents a novel data-driven and knowledge-based energy digital-twin framework and architecture. Data integration and mining based on machine learning are integrated into a knowledge graph annotating asset status data, prediction outcomes, and background domain knowledge in order to support a retrieval-augmented generation approach, which enhances a conversational virtual assistant based on a large language model to provide user decision support in asset management and maintenance. Components of the proposed architecture have been mapped to commercial-off-the-shelf tools to implement a prototype framework, exploited in a case study on the management of a section of the high-voltage energy infrastructure in central Italy. © 2024 by the authors.},
	author_keywords = {digital twin; energy infrastructures; energy management; natural user interface; retrieval-augmented generation},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Wang2024,
	author = {Wang, Haowen and Zhao, Ruixue},
	title = {Knowledge graph of agricultural engineering technology based on large language model},
	year = {2024},
	journal = {Displays},
	volume = {85},
	doi = {10.1016/j.displa.2024.102820},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205552112&doi=10.1016%2fj.displa.2024.102820&partnerID=40&md5=74c9df2554e59b1e5c2b7379632a095f},
	abstract = {Agriculture is an industry that has evolved alongside human evolution and has faithfully fulfilled its core mission of food supply. With the reduction of rural labor, the progress of artificial intelligence and the development of Internet of Things technology, it is hoped that the efficiency and productivity of the agricultural industry can be improved. Recently, with the development of information and intelligent technology, agricultural production and management have been significantly enhanced. However, there is still a considerable challenge in effectively integrating the vast amount of fragmented information for downstream applications. An agricultural knowledge graph (AGKG) will serve as the foundation for achieving these goals. Knowledge graphs can be general or domain-specific, and are the basis for many applications, such as search engines, online question-and-answer services, and knowledge inference. Therefore, there are many knowledge graphs, including Wikidata and DBpedia, for accessing structured knowledge. Although some general knowledge graphs contain some entities and relationships related to agriculture, there are no domain-specific knowledge graphs specifically for agricultural applications. Therefore, this paper proposes an agricultural knowledge graph (AGKG) for automatically integrating large amounts of agricultural data from the Internet. By applying natural language processing and deep learning technologies, AGKG can automatically identify agricultural entities from unstructured text and connect them to form a knowledge graph. In addition, we have described the typical scenarios of our AGKG and validated it through real-world applications such as agricultural entity retrieval and agricultural question-answering. © 2024},
	author_keywords = {Knowledge graph; LLM},
	keywords = {Agribusiness; Agricultural economics; % reductions; Agricultural industries; Human evolution; Intelligent technology; Internet of things technologies; Knowledge graphs; Language model; LLM; Rural labors; Technology-based; Knowledge graph},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Wu2024,
	author = {Wu, Jinge and Dong, Hang and Li, Zexi and Wang, Haowei and Li, Runci and Patra, Arijit and Dai, Chengliang and Ali, Waqar and Scordis, Phil and Wu, Honghan},
	title = {A hybrid framework with large language models for rare disease phenotyping},
	year = {2024},
	journal = {BMC Medical Informatics and Decision Making},
	volume = {24},
	number = {1},
	doi = {10.1186/s12911-024-02698-7},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205771843&doi=10.1186%2fs12911-024-02698-7&partnerID=40&md5=aa3309ef200ab9ba91ed64c6135f7ce8},
	abstract = {Purpose: Rare diseases pose significant challenges in diagnosis and treatment due to their low prevalence and heterogeneous clinical presentations. Unstructured clinical notes contain valuable information for identifying rare diseases, but manual curation is time-consuming and prone to subjectivity. This study aims to develop a hybrid approach combining dictionary-based natural language processing (NLP) tools with large language models (LLMs) to improve rare disease identification from unstructured clinical reports. Methods: We propose a novel hybrid framework that integrates the Orphanet Rare Disease Ontology (ORDO) and the Unified Medical Language System (UMLS) to create a comprehensive rare disease vocabulary. SemEHR, a dictionary-based NLP tool, is employed to extract rare disease mentions from clinical notes. To refine the results and improve accuracy, we leverage various LLMs, including LLaMA3, Phi3-mini, and domain-specific models like OpenBioLLM and BioMistral. Different prompting strategies, such as zero-shot, few-shot, and knowledge-augmented generation, are explored to optimize the LLMs’ performance. Results: The proposed hybrid approach demonstrates superior performance compared to traditional NLP systems and standalone LLMs. LLaMA3 and Phi3-mini achieve the highest F1 scores in rare disease identification. Few-shot prompting with 1-3 examples yields the best results, while knowledge-augmented generation shows limited improvement. Notably, the approach uncovers a significant number of potential rare disease cases not documented in structured diagnostic records, highlighting its ability to identify previously unrecognized patients. Conclusion: The hybrid approach combining dictionary-based NLP tools with LLMs shows great promise for improving rare disease identification from unstructured clinical reports. By leveraging the strengths of both techniques, the method demonstrates superior performance and the potential to uncover hidden rare disease cases. Further research is needed to address limitations related to ontology mapping and overlapping case identification, and to integrate the approach into clinical practice for early diagnosis and improved patient outcomes. © The Author(s) 2024.},
	author_keywords = {Electronic health record; Large language model; Natural language processing; Phenotyping},
	keywords = {Biological Ontologies; Electronic Health Records; Humans; Natural Language Processing; Phenotype; Rare Diseases; Unified Medical Language System; biological ontology; diagnosis; electronic health record; human; natural language processing; phenotype; rare disease; Unified Medical Language System},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access}
}

@ARTICLE{2025,
	title = {43rd International Conference on Conceptual Modeling, ER 2024},
	year = {2025},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) },
	volume = {15238 LNCS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209551458&partnerID=40&md5=8beac58109dd074a36359432bcbc8d8a},
	abstract = {The proceedings contain 22 papers. The special focus in this conference is on Conceptual Modeling. The topics include: A Universal Prompting Strategy for Extracting Process Model Information from Natural Language Text Using Large Language Models; agent System Event Data: Concepts, Dimensions, Applications; Multi-faceted Evaluation of Modeling Languages for Augmented Reality Applications The Case of ARWFML; Application of the Tree-of-Thoughts Framework to LLM-Enabled Domain Modeling; ECQL: Towards Succinct and Extensible Modeling of Multi-model Query Results; An Analysis of the Semantic Foundation of KerML and SysML v2; portions of Matter and Their Existential Events: An Ontology-Based Conceptual Model; model-Driven Design and Generation of Training Simulators for Reinforcement Learning; generating Secure Workflow Designs from Requirements Goal Models Using Patterns; modeling and Reasoning About Explanation Requirements Using Goal Models; enhancing Domain Modeling with Pre-trained Large Language Models: An Automated Assistant for Domain Modelers; How are LLMs Used for Conceptual Modeling? An Exploratory Study on Interaction Behavior and User Perception; Small, Medium, and Large Language Models for Text-to-SQL; Establishing Traceability Between Natural Language Requirements and Software Artifacts by Combining RAG and LLMs; GenACT: An Ontology-Based Temporal Web Data Generator; SAQI: An Ontology Based Knowledge Graph Platform for Social Air Quality Index; Conceptual Framework for Designing Hippocratic APIs; the Role-Artifact-Function Framework for Understanding Digital Identity Models; ontological Foundations of Resilience; conceptual Modelling Method for Digital Twins.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Desai2025160,
	author = {Desai, Vaaruni and Chi, Yinglan and Stephens, Jon and Gupta, Amarnath},
	title = {Building Model-Driven Knowledge Graphs via Large Language Models},
	year = {2025},
	journal = {Communications in Computer and Information Science},
	volume = {2186 CCIS},
	pages = {160 – 172},
	doi = {10.1007/978-3-031-70421-5_14},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210181716&doi=10.1007%2f978-3-031-70421-5_14&partnerID=40&md5=43d8e8799929dc7229dc2ce60996bb11},
	abstract = {We consider a special case of knowledge graph construction from text, where the target knowledge graph is structured as specific Directed Acyclic Graph and the input text has the form of a recipe. The intention of this paper is to present a case study that uses a large language model (LLM) for the knowledge extraction process. We formulate knowledge extraction as a model-driven structure recovery process and demonstrate that LLMs can be effectively used in the process. We demonstrate through extensive experiments that using LLMs a zero-shot process produces a wide range of errors. To remedy them, we propose two different model-driven prompting strategies by which LLMs can be used to improve the accuracy of knowledge graph construction. We demonstrate that a state memoization technique introduces an accuracy-efficiency tradeoff that demands further research.  © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.},
	author_keywords = {Graph Structure Recovery; Knowledge Graph Construction; Model-driven Construction},
	keywords = {Modeling languages; Zero-shot learning; Graph construction; Graph structure recovery; Graph structures; Knowledge extraction; Knowledge graph construction; Knowledge graphs; Language model; Model-driven; Model-driven construction; Structure recovery; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Gilbert2024,
	author = {Gilbert, Stephen and Kather, Jakob Nikolas and Hogan, Aidan},
	title = {Augmented non-hallucinating large language models as medical information curators},
	year = {2024},
	journal = {npj Digital Medicine},
	volume = {7},
	number = {1},
	doi = {10.1038/s41746-024-01081-0},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191180518&doi=10.1038%2fs41746-024-01081-0&partnerID=40&md5=79c97a04b822871a41844f8a25f0849c},
	abstract = {Reliably processing and interlinking medical information has been recognized as a critical foundation to the digital transformation of medical workflows, and despite the development of medical ontologies, the optimization of these has been a major bottleneck to digital medicine. The advent of large language models has brought great excitement, and maybe a solution to the medicines’ ‘communication problem’ is in sight, but how can the known weaknesses of these models, such as hallucination and non-determinism, be tempered? Retrieval Augmented Generation, particularly through knowledge graphs, is an automated approach that can deliver structured reasoning and a model of truth alongside LLMs, relevant to information structuring and therefore also to decision support. © The Author(s) 2024.},
	keywords = {automation; clinical decision support system; communication disorder; digital technology; human; information retrieval; knowledge base; large language model; machine learning; medical information; medical information system; Note},
	type = {Note},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Shu2024,
	author = {Shu, Xiaoling and Dang, Xiaochao and Dong, Xiaohui and Li, Fenfang},
	title = {Utilizing Large Language Models for Hyper Knowledge Graph Construction in Mine Hoist Fault Analysis},
	year = {2024},
	journal = {Symmetry},
	volume = {16},
	number = {12},
	doi = {10.3390/sym16121600},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213233403&doi=10.3390%2fsym16121600&partnerID=40&md5=d739eca0e51089e4affd22c5e9fa8a71},
	abstract = {The rapid development of artificial intelligence technology is driving the intelligentization process across various fields, particularly in knowledge graph construction, where significant achievements have been made. However, research on hyper-relational knowledge graphs in the industrial domain remains relatively weak. Traditional construction methods suffer from low automation, high cost, and poor reproducibility and portability. To address these challenges, this paper proposes an optimized construction process for a hyper-relational knowledge graph for mine hoist faults based on large language models. This process leverages the strengths of large language models and the logical connections of fault knowledge, employing GPT’s powerful reasoning abilities. A combined strategy of template-based and template-free prompts is designed to generate fault entities and relationships. To address potential data incompleteness caused by prompt engineering, link prediction is used to optimize the initial data generated by GPT o1-preview. We integrated the graph’s topological structure with domain-specific logical rules and applied the Variational EM algorithm for alternating optimization while also incorporating text embeddings to comprehensively enhance data optimization. Experimental results show that compared to the unoptimized MHSD, the optimized MHSD achieved a 0.008 improvement in MRR. Additionally, compared to the latest KICGPT, the optimized MHSD showed a 0.002 improvement in MRR. Finally, the optimized data were successfully imported into Neo4j for visualization. © 2024 by the authors.},
	author_keywords = {hyper-relational knowledge graphs; industrial intelligence; link prediction; prompt engineering design},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access}
}

@ARTICLE{Zhao2024,
	author = {Zhao, Zelong and Zhang, Nan and Yu, Bin and Duan, Zhenhua},
	title = {Generating Java code pairing with ChatGPT},
	year = {2024},
	journal = {Theoretical Computer Science},
	volume = {1021},
	doi = {10.1016/j.tcs.2024.114879},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204472636&doi=10.1016%2fj.tcs.2024.114879&partnerID=40&md5=6c54a7736f489c9a0c43c29c9d7da28a},
	abstract = {The Large Language Models (LLMs) like ChatGPT 3.5 have created a new era of automatic code generation. However, the existing research primarily focuses on generating simple code based on datasets (such as HumanEval, etc.). Most of approaches pay less attention to complex and practical code generation. Therefore, in this paper, we propose a new approach called “Xd-CodeGen” which can be used to generate large scale Java code. This approach is composed of four phases: requirement analysis, modeling, code generation, and code verification. In the requirement analysis phase, ChatGPT 3.5 is utilized to decompose and restate user requirements. To do so, a knowledge graph is developed to describe entities and their relationship in detail. Further, Propositional Projection Temporal Logic (PPTL) formulas are employed to define the properties of requirements. In the modeling phase, we use knowledge graphs to enhance prompts and generate UML class and activity diagrams for each sub-requirement using ChatGPT 3.5. In the code generation phase, based on established UML models, we make use of prompt engineering and knowledge graph to generate Java code. In the code verification phase, a runtime verification at code level approach is employed to verify generated Java code. Finally, we apply the proposed approach to develop a practical Java web project. © 2024 Elsevier B.V.},
	author_keywords = {ChatGPT; Code generation; Iterative prompting; Large language models; Prompt engineering},
	keywords = {Java programming language; Requirements engineering; Automatic code generations; ChatGPT; Codegeneration; Codes verification; Iterative prompting; Java codes; Knowledge graphs; Language model; Large language model; Prompt engineering; Knowledge graph},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Wei2024,
	author = {Wei, Zhaoquan and Chen, Xi and Sun, Youshi and Zhang, Yifei and Dong, Ruifang and Wang, Xiaojing and Chen, Shuangtao},
	title = {Exploring the molecular mechanisms and shared potential drugs between rheumatoid arthritis and arthrofibrosis based on large language model and synovial microenvironment analysis},
	year = {2024},
	journal = {Scientific Reports},
	volume = {14},
	number = {1},
	doi = {10.1038/s41598-024-69080-5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201404596&doi=10.1038%2fs41598-024-69080-5&partnerID=40&md5=200060a61832ef95ee25302b1c3aa025},
	abstract = {Rheumatoid arthritis (RA) and arthrofibrosis (AF) are both chronic synovial hyperplasia diseases that result in joint stiffness and contractures. They shared similar symptoms and many common features in pathogenesis. Our study aims to perform a comprehensive analysis between RA and AF and identify novel drugs for clinical use. Based on the text mining approaches, we performed a correlation analysis of 12 common joint diseases including arthrofibrosis, gouty arthritis, infectious arthritis, juvenile idiopathic arthritis, osteoarthritis, post infectious arthropathies, post traumatic osteoarthritis, psoriatic arthritis, reactive arthritis, rheumatoid arthritis, septic arthritis, and transient arthritis. 5 bulk sequencing datasets and 4 single-cell sequencing datasets of RA and AF were integrated and analyzed. A novel drug repositioning method was found for drug screening, and text mining approaches were used to verify the identified drugs. RA and AF performed the highest gene similarity (0.77) and functional ontology similarity (0.84) among all 12 joint diseases. We figured out that they share the same key pathogenic cell including CD34 + sublining fibroblasts (CD34-SLF) and DKK3 + sublining fibroblasts (DKK3-SLF). Potential therapeutic target database (PTTD) was established with the differential expressed genes (DEGs) of these key pathogenic cells. Based on the PTTD, 15 potential drugs for AF and 16 potential drugs for RA were identified. This work provides a new perspective on AF and RA study which enhances our understanding of their pathogenesis. It also shed light on their underlying mechanism and open new avenues for drug repositioning studies. © The Author(s) 2024.},
	author_keywords = {Arthritis; Arthrofibrosis; Rheumatoid arthritis; Sublining fibroblasts; Synovial microenvironment},
	keywords = {Arthritis, Rheumatoid; Cellular Microenvironment; Data Mining; Drug Repositioning; Fibroblasts; Fibrosis; Humans; Synovial Membrane; data mining; drug effect; drug repositioning; drug therapy; fibroblast; fibrosis; genetics; human; metabolism; pathology; rheumatoid arthritis; synovium; tumor microenvironment},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Mahboubi2024,
	author = {Mahboubi, Arash and Luong, Khanh and Aboutorab, Hamed and Bui, Hang Thanh and Jarrad, Geoff and Bahutair, Mohammed and Camtepe, Seyit and Pogrebna, Ganna and Ahmed, Ejaz and Barry, Bazara and Gately, Hannah},
	title = {Evolving techniques in cyber threat hunting: A systematic review},
	year = {2024},
	journal = {Journal of Network and Computer Applications},
	volume = {232},
	doi = {10.1016/j.jnca.2024.104004},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201883123&doi=10.1016%2fj.jnca.2024.104004&partnerID=40&md5=79853c4b19069fecf58738b1c452e197},
	abstract = {In the rapidly changing cybersecurity landscape, threat hunting has become a critical proactive defense against sophisticated cyber threats. While traditional security measures are essential, their reactive nature often falls short in countering malicious actors’ increasingly advanced tactics. This paper explores the crucial role of threat hunting, a systematic, analyst-driven process aimed at uncovering hidden threats lurking within an organization's digital infrastructure before they escalate into major incidents. Despite its importance, the cybersecurity community grapples with several challenges, including the lack of standardized methodologies, the need for specialized expertise, and the integration of cutting-edge technologies like artificial intelligence (AI) for predictive threat identification. To tackle these challenges, this survey paper offers a comprehensive overview of current threat hunting practices, emphasizing the integration of AI-driven models for proactive threat prediction. Our research explores critical questions regarding the effectiveness of various threat hunting processes and the incorporation of advanced techniques such as augmented methodologies and machine learning. Our approach involves a systematic review of existing practices, including frameworks from industry leaders like IBM and CrowdStrike. We also explore resources for intelligence ontologies and automation tools. The background section clarifies the distinction between threat hunting and anomaly detection, emphasizing systematic processes crucial for effective threat hunting. We formulate hypotheses based on hidden states and observations, examine the interplay between anomaly detection and threat hunting, and introduce iterative detection methodologies and playbooks for enhanced threat detection. Our review encompasses supervised and unsupervised machine learning approaches, reasoning techniques, graph-based and rule-based methods, as well as other innovative strategies. We identify key challenges in the field, including the scarcity of labeled data, imbalanced datasets, the need for integrating multiple data sources, the rapid evolution of adversarial techniques, and the limited availability of human expertise and data intelligence. The discussion highlights the transformative impact of artificial intelligence on both threat hunting and cybercrime, reinforcing the importance of robust hypothesis development. This paper contributes a detailed analysis of the current state and future directions of threat hunting, offering actionable insights for researchers and practitioners to enhance threat detection and mitigation strategies in the ever-evolving cybersecurity landscape. © 2024 The Author(s)},
	author_keywords = {Cyber threat intelligence; Generative AI; Hypothesis; Machine learning; OpenAI voice engine; Threat hunting},
	keywords = {Cyber attacks; Generative adversarial networks; Phishing; Cybe threat intelligence; Cyber security; Cyber threats; Generative artificial intelligence; Hypothesis; Machine-learning; Openai voice engine; Systematic Review; Threat hunting; Voice engines; Adversarial machine learning},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Hou2025111,
	author = {Hou, Zhi-Wei and Jing, Wenlong and Qin, Cheng-Zhi and Yang, Ji and Xia, Qing and Yin, Xiaoling},
	title = {Prospects on mangrove knowledge services in the smart era: From plant atlas to knowledge graphs},
	year = {2025},
	journal = {Science China Earth Sciences},
	volume = {68},
	number = {1},
	pages = {111 – 127},
	doi = {10.1007/s11430-024-1446-9},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208962831&doi=10.1007%2fs11430-024-1446-9&partnerID=40&md5=694307bc27bd56242c7610567146a46e},
	abstract = {Mangroves are crucial to the ecological security of the Earth and human well-being. Their management, conservation, and restoration are of great importance and necessitate the support of spatio-temporal information and multi-disciplinary knowledge such as biology and ecology. Traditional knowledge services such as plant atlas provide illustrated textual knowledge of mangroves. However, this kind of service is oriented to information retrieval and is incapable of effectively mining and utilizing fragmented knowledge from multi-source heterogeneous data, facing the problem of “massive data, rare knowledge”. Knowledge graphs are capable of extracting, organizing, and fusing the knowledge contained in massive data into semantic networks that can be understood and computed by computers. They provide a solution for the realization of intelligent knowledge services. Focusing on the urgent need for mangrove knowledge acquisition, formal representation, and intelligent services, this paper proposes a research prospect on mangrove knowledge graphs and knowledge services. We first analyze the similarities and differences between various domain-specific concepts of Tupu. On this basis, we define the mangrove knowledge graph as a large-scale knowledge base that integrates multi-disciplinary knowledge and spatio-temporal information with mangrove ecosystems as the core. Then, we propose a research framework for mangrove knowledge services that can realize the transformation from multi-modal data to intelligent knowledge services, including multiple research levels such as ubiquitous data sensing and aggregation, knowledge organization and graph construction, and intelligent mangrove knowledge services. Subsequently, the methods and workflow for constructing mangrove knowledge graphs are introduced. Finally, we discuss the challenges and possible future directions of mangrove knowledge services in the smart era, including the construction of a mangrove knowledge system that integrates the domain-specific characteristics and spatio-temporal features of mangroves, the exploration of knowledge extraction and fusion methods supported by large language models, and the development of intelligent knowledge applications for typical scenarios. © Science China Press 2024.},
	author_keywords = {Knowledge graph; Knowledge service; Mangrove; Multi-modal; Tupu},
	keywords = {Semantics; Domain specific; Ecological security; Knowledge graphs; Knowledge service; Mangrove; Massive data; Multi-modal; Spatiotemporal information; Tupu; Well being; atlas; data mining; ecosystem service; knowledge based system; mangrove; traditional knowledge; Knowledge graph},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Lee2024,
	author = {Lee, Jungwon and Ahn, Seungjun and Kim, Daeho and Kim, Dongkyun},
	title = {Performance comparison of retrieval-augmented generation and fine-tuned large language models for construction safety management knowledge retrieval},
	year = {2024},
	journal = {Automation in Construction},
	volume = {168},
	doi = {10.1016/j.autcon.2024.105846},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208685132&doi=10.1016%2fj.autcon.2024.105846&partnerID=40&md5=060f7e9ac92d4019bce3b3a420a536a6},
	abstract = {Construction safety standards are in unstructured formats like text and images, complicating their effective use in daily tasks. This paper compares the performance of Retrieval-Augmented Generation (RAG) and fine-tuned Large Language Model (LLM) for the construction safety knowledge retrieval. The RAG model was created by integrating GPT-4 with a knowledge graph derived from construction safety guidelines, while the fine-tuned LLM was fine-tuned using a question-answering dataset derived from the same guidelines. These models' performance is tested through case studies, using accident synopses as a query to generate preventive measurements. The responses were assessed using metrics, including cosine similarity, Euclidean distance, BLEU, and ROUGE scores. It was found that both models outperformed GPT-4, with the RAG model improving by 21.5 % and the fine-tuned LLM by 26 %. The findings highlight the relative strengths and weaknesses of the RAG and fine-tuned LLM approaches in terms of applicability and reliability for safety management. © 2024},
	author_keywords = {Construction safety; Fine-tuned LLM; Knowledge graph; Large Language Model (LLM); Retrieval-Augmented Generation (RAG)},
	keywords = {Information management; Modeling languages; Project management; Query languages; Structured Query Language; Construction safety; Fine-tuned large language model; Knowledge graphs; Knowledge retrieval; Language model; Large language model; Performance comparison; Retrieval-augmented generation; Safety management; Knowledge graph},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Carriero2025434,
	author = {Carriero, Valentina Anita and Azzini, Antonia and Baroni, Ilaria and Scrocca, Mario and Celino, Irene},
	title = {Human Evaluation of Procedural Knowledge Graph Extraction from Text with Large Language Models},
	year = {2025},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) },
	volume = {15370 LNAI},
	pages = {434 – 452},
	doi = {10.1007/978-3-031-77792-9_26},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210875567&doi=10.1007%2f978-3-031-77792-9_26&partnerID=40&md5=dea3435124d9e4028cb1079e44ebf144},
	abstract = {Procedural Knowledge is the know-how expressed in the form of sequences of steps needed to perform some tasks. Procedures are usually described by means of natural language texts, such as recipes or maintenance manuals, possibly spread across different documents and systems, and their interpretation and subsequent execution is often left to the reader. Representing such procedures in a Knowledge Graph (KG) can be the basis to build digital tools to support those users who need to apply or execute them. In this paper, we leverage Large Language Model (LLM) capabilities and propose a prompt engineering approach to extract steps, actions, objects, equipment and temporal information from a textual procedure, in order to populate a Procedural KG according to a pre-defined ontology. We evaluate the KG extraction results by means of a user study, in order to qualitatively and quantitatively assess the perceived quality and usefulness of the LLM-extracted procedural knowledge. We show that LLMs can produce outputs of acceptable quality and we assess the subjective perception of AI by human evaluators. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.},
	author_keywords = {Knowledge Engineering; Knowledge Extraction; Knowledge Graphs; Large Language Models; Ontology; Procedural Knowledge},
	keywords = {Natural language processing systems; Ontology; Graph extractions; Human evaluation; Knowledge extraction; Knowledge graphs; Language model; Large language model; Maintenance manual; Natural languages texts; Ontology's; Procedural knowledge; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Song2024,
	author = {Song, Jihwan and Yoon, Sungmin},
	title = {Ontology-assisted GPT-based building performance simulation and assessment: Implementation of multizone airflow simulation},
	year = {2024},
	journal = {Energy and Buildings},
	volume = {325},
	doi = {10.1016/j.enbuild.2024.114983},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208462359&doi=10.1016%2fj.enbuild.2024.114983&partnerID=40&md5=98ac6df98e7be3795cc8f90f424834d8},
	abstract = {Building performance simulation (BPS) is crucial for building performance assessments across its lifecycle. However, the complexity of buildings and the iterative nature of simulation poses challenges, leading to high costs and low values. Previous studies focused on simplification, but did not fully utilize advanced simulation engines. Despite recent advancements, there is a lack of research on leveraging artificial intelligence (AI), specifically generative pre-trained transformer (GPT), for BPS. Therefore, this study proposes a GPT-based BPS system, enhancing simulation efficiency and value by integrating simulation engines and advanced data analytics in the GPT environment. The ontology for GPT-based BPS is also developed to enable comprehensive, reliable, informative BPS environments. Based on this framework, case studies were conducted for GPT-based multizone airflow network simulation in a high-rise residential building using CONTAM software. They demonstrate GPT's capabilities in retrieving simulation data, visualizing results with data mining, answering questions based on building knowledge, checking compliance with design guidelines, and proposing design alternatives. Finally, this study emphasizes expert interventions with ontological engineering informatics to utilize strictly structured BPS engines. © 2024 Elsevier B.V.},
	author_keywords = {Artificial intelligence; Building performance; Building performance simulation (BPS); ChatGPT; CONTAM; Digital twins; GPT; Large language model (LLM)},
	keywords = {Ontology; Building performance; Building performance simulation; Building performance simulations; ChatGPT; CONTAM; Generative pre-trained transformer; Language model; Large language model; Ontology's; Simulation engine; Digital elevation model},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Prokop2025235,
	author = {Prokop, Dominik and Stenchlák, Štěpán and Škoda, Petr and Klímek, Jakub and Nečaský, Martin},
	title = {Enhancing Domain Modeling with Pre-trained Large Language Models: An Automated Assistant for Domain Modelers},
	year = {2025},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) },
	volume = {15238 LNCS},
	pages = {235 – 253},
	doi = {10.1007/978-3-031-75872-0_13},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209593844&doi=10.1007%2f978-3-031-75872-0_13&partnerID=40&md5=85e479015a25eb0009610122d307d4a9},
	abstract = {Domain modeling involves creating abstract representations of information within a specific domain using techniques such as conceptual modeling and ontology engineering. Traditionally, manual creation and maintenance of domain models are labor intensive and require modeling expertise. This paper explores the automation of domain modeling using pre-trained large language models (LLMs), presenting an experimental LLM-based conceptual modeling assistant that collaborates with a human expert. The assistant provides modeling suggestions based on a given textual description of the domain of interest, aiding in the design of classes, attributes, and associations. We present a generic framework for domain modeling assistants that consists of class, attribute, and association generators, and show how they can be implemented using an LLM. We demonstrate a concrete configuration of this framework and its prototype implementation. We evaluated the effectiveness of the framework configuration across various domains. Our findings indicate that the assistant significantly enhances the efficiency of modeling while maintaining reasonable quality of the outputs. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.},
	author_keywords = {Conceptual Modeling; Domain Modeling; Domain Modeling Automation; Large Language Models},
	keywords = {Abstract representation; Conceptual model; Domain model; Domain modeling automation; Language model; Large language model; Model engineering; Modeling automation; Ontology engineering; Modeling languages},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Chen2024,
	author = {Chen, Liuqing and Zuo, Haoyu and Cai, Zebin and Yin, Yuan and Zhang, Yuan and Sun, Lingyun and Childs, Peter},
	title = {Toward Controllable Generative Design: A Conceptual Design Generation Approach Leveraging the Function-Behavior-Structure Ontology and Large Language Models},
	year = {2024},
	journal = {Journal of Mechanical Design},
	volume = {146},
	number = {12},
	doi = {10.1115/1.4065562},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199391540&doi=10.1115%2f1.4065562&partnerID=40&md5=0660f8c1c6c4541acec77bfc9ad3cda1},
	abstract = {Recent research in the field of design engineering is primarily focusing on using AI technologies such as Large Language Models (LLMs) to assist early-stage design. The engineer or designer can use LLMs to explore, validate, and compare thousands of generated conceptual stimuli and make final choices. This was seen as a significant stride in advancing the status of the generative approach in computer-aided design. However, it is often difficult to instruct LLMs to obtain novel conceptual solutions and requirement-compliant in real design tasks, due to the lack of transparency and insufficient controllability of LLMs. This study presents an approach to leverage LLMs to infer Function-Behavior-Structure (FBS) ontology for high-quality design concepts. Prompting design based on the FBS model decomposes the design task into three sub-tasks including functional, behavioral, and structural reasoning. In each sub-task, prompting templates and specification signifiers are specified to guide the LLMs to generate concepts. User can determine the selected concepts by judging and evaluating the generated function-structure pairs. A comparative experiment has been conducted to evaluate the concept generation approach. According to the concept evaluation results, our approach achieves the highest scores in concept evaluation, and the generated concepts are more novel, useful, functional, and low cost compared to the baseline. Copyright © 2024 by ASME.},
	author_keywords = {conceptual design; creativity and concept generation; FBS model; generative design; large language model; machine learning},
	keywords = {Architectural design; Computational linguistics; Computer aided design; Function evaluation; Machine learning; Ontology; Structural design; Concept generation; Creativity and concept generation; Design tasks; Function-behavior-structure model; Function-Behaviour-Structure ontologies; Generative design; Language model; Large language model; Machine-learning; Subtask; Conceptual design},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Ji2024,
	author = {Ji, Shengwei and Liu, Longfei and Xi, Jizhong and Zhang, Xiaoxue and Li, Xinlu},
	title = {KLR-KGC: Knowledge-Guided LLM Reasoning for Knowledge Graph Completion},
	year = {2024},
	journal = {Electronics (Switzerland)},
	volume = {13},
	number = {24},
	doi = {10.3390/electronics13245037},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213259040&doi=10.3390%2felectronics13245037&partnerID=40&md5=fcc88d0284e1bb6c993f14700ab0ada1},
	abstract = {Knowledge graph completion (KGC) involves inferring missing entities or relationships within a knowledge graph, playing a crucial role across various domains, including intelligent question answering, recommendation systems, and dialogue systems. Traditional knowledge graph embedding (KGE) methods have proven effective in utilizing structured data and relationships. However, these methods often overlook the vast amounts of unstructured data and the complex reasoning capabilities required to handle ambiguous queries or rare entities. Recently, the rapid development of large language models (LLMs) has demonstrated exceptional potential in text comprehension and contextual reasoning, offering new prospects for KGC tasks. By using traditional KGE to capture the structural information of entities and relations to generate candidate entities and then reranking them with a generative LLM, the output of the LLM can be constrained to improve reliability. Despite this, new challenges, such as omissions and incorrect responses, arise during the ranking process. To address these issues, a knowledge-guided LLM reasoning for knowledge graph completion (KLR-KGC) framework is proposed. This model retrieves two types of knowledge from the knowledge graph—analogical knowledge and subgraph knowledge—to enhance the LLM’s logical reasoning ability for specific tasks while injecting relevant additional knowledge. By integrating a chain-of-thought (CoT) prompting strategy, the model guides the LLM to filter and rerank candidate entities, constraining its output to reduce omissions and incorrect responses. The framework aims to learn and uncover the latent correspondences between entities, guiding the LLM to make reasonable inferences based on supplementary knowledge for more accurate predictions. The experimental results demonstrate that on the FB15k-237 dataset, KLR-KGC outperformed the entity generation model (CompGCN), achieving a 4.8% improvement in MRR and a 5.8% improvement in Hits@1. © 2024 by the authors.},
	author_keywords = {knowledge graph completion; knowledge graph embedding; knowledge graphs; large language models},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Xiao202560,
	author = {Xiao, Zhengyang and Pakrasi, Himadri B. and Chen, Yixin and Tang, Yinjie J.},
	title = {Network for knowledge Organization (NEKO): An AI knowledge mining workflow for synthetic biology research},
	year = {2025},
	journal = {Metabolic Engineering},
	volume = {87},
	pages = {60 – 67},
	doi = {10.1016/j.ymben.2024.11.006},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210356580&doi=10.1016%2fj.ymben.2024.11.006&partnerID=40&md5=53f1acb45ad65309d1a50c565db15d4c},
	abstract = {Large language models (LLMs) can complete general scientific question-and-answer, yet they are constrained by their pretraining cut-off dates and lack the ability to provide specific, cited scientific knowledge. Here, we introduce Network for Knowledge Organization (NEKO), a workflow that uses LLM Qwen to extract knowledge through scientific literature text mining. When user inputs a keyword of interest, NEKO can generate knowledge graphs to link bioinformation entities and produce comprehensive summaries from PubMed search. NEKO significantly enhance LLM ability and has immediate applications in daily academic tasks such as education of young scientists, literature review, paper writing, experiment planning/troubleshooting, and new ideas/hypothesis generation. We exemplified this workflow's applicability through several case studies on yeast fermentation and cyanobacterial biorefinery. NEKO's output is more informative, specific, and actionable than GPT-4's zero-shot Q&A. NEKO offers flexible, lightweight local deployment options. NEKO democratizes artificial intelligence (AI) tools, making scientific foundation model more accessible to researchers without excessive computational power. © 2024 The Author(s)},
	author_keywords = {Foundation model; Knowledge graph; Large language model; Qwen; Retrieval augmented generation},
	keywords = {Artificial Intelligence; Data Mining; Synthetic Biology; Workflow; Knowledge organization system (KOS); Simple knowledge organization system (SKOS); beta carotene; Foundation models; Knowledge graphs; Knowledge mining; Knowledge organization; Language model; Large language model; Qwen; Retrieval augmented generation; Synthetic biology; Work-flows; Article; calculation; clinical research; data mining; distillation; exploratory research; generative artificial intelligence; hypothesis; knowledge; large language model; learning; medical literature; Medline; network for knowledge organization; nonhuman; problem solving; Rhodotorula toruloides; synthetic biology; word processing; workflow; Yarrowia lipolytica; artificial intelligence; workflow; Knowledge graph},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Mehenni2025382,
	author = {Mehenni, Gaya and Zouaq, Amal},
	title = {Ontology-Constrained Generation of Domain-Specific Clinical Summaries},
	year = {2025},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) },
	volume = {15370 LNAI},
	pages = {382 – 398},
	doi = {10.1007/978-3-031-77792-9_23},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210803481&doi=10.1007%2f978-3-031-77792-9_23&partnerID=40&md5=e64c78d443a24a6f444aa61aa3aa8215},
	abstract = {Large Language Models (LLMs) offer promising solutions for text summarization. However, some domains require specific information to be available in the summaries. Generating these domain-adapted summaries is still an open challenge. Similarly, hallucinations in generated content is a major drawback of current approaches, preventing their deployment. This study proposes a novel approach that leverages ontologies to create domain-adapted summaries both structured and unstructured. We employ an ontology-guided constrained decoding process to reduce hallucinations while improving relevance. When applied to the medical domain, our method shows potential in summarizing Electronic Health Records (EHRs) across different specialties, allowing doctors to focus on the most relevant information to their domain. Evaluation on the MIMIC-III dataset demonstrates improvements in generating domain-adapted summaries of clinical notes and hallucination reduction. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.},
	keywords = {Ontology; 'current; Constrained decoding; Decoding process; Domain specific; Electronic health; Language model; Medical domains; Ontology's; Specific information; Text Summarisation; Electronic health record},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Sufi2024,
	author = {Sufi, Fahim},
	title = {Advances in Mathematical Models for AI-Based News Analytics},
	year = {2024},
	journal = {Mathematics},
	volume = {12},
	number = {23},
	doi = {10.3390/math12233736},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211904310&doi=10.3390%2fmath12233736&partnerID=40&md5=eec349f41cec1a3497ed4657fe599f1d},
	abstract = {The exponential growth of digital news sources presents a critical challenge in efficiently processing and analyzing vast datasets to derive actionable insights. This paper introduces a GPT-based news analytics system that addresses this issue using advanced mathematical modeling and AI techniques. Over a 405-day period, the system processed 1,033,864 news articles, categorizing 90.67% into 202 subcategories across 11 main categories. The system achieved an average precision of 0.924, recall of 0.920, and F1-score of 0.921 in event correlation analysis and demonstrated a fast average execution time of 21.38 s per query, enabling near-real time analysis. The system critically analyzes semantic relationships between events, allowing for robust event correlation analysis, with precision and recall reaching up to 1.000 for specific pairs such as “UFO” and “Cyber”. Using dimensional augmentation, probabilistic feature extraction, and a semantic knowledge graph, the system provides robust event relationships for modeling unstructured news reports. Additionally, the integration of spectral residual and convolutional neural networks helps to identify anomalies in time-series news data with 85% sensitivity. Unlike existing solutions reported in the literature, the proposed system introduces a unified mathematical framework for large-scale news analytics, seamlessly integrating advanced methods such as large language models, knowledge graphs, anomaly detection, and event correlation to deliver fast and efficient performance. This scientifically novel and scalable framework offers a transformative approach to solving the pressing problem of news analytics, offering significant value to researchers, policymakers, and media analysts. © 2024 by the author.},
	author_keywords = {anomaly detection; convolutional neural network; eigenvalue decomposition; event correlation analysis; GPT-based news analytics; knowledge graph; situational awareness; spectral residual},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{2025,
	title = {13th CCF International Conference on Natural Language Processing and Chinese Computing, NLPCC 2024},
	year = {2025},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) },
	volume = {15360 LNAI},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210080314&partnerID=40&md5=9b0497eda60417dac7d323eed156341e},
	abstract = {The proceedings contain 194 papers. The special focus in this conference is on Natural Language Processing and Chinese Computing. The topics include: Hierarchical Knowledge Aggregation for Personalized Response Generation in Dialogue Systems; multi-hop Reading Comprehension Model Based on Abstract Meaning Representation and Multi-task Joint Learning; Leveraging Large Language Models for QA Dialogue Dataset Construction and Analysis in Public Services; MCFC: A Momentum-Driven Clicked Feature Compressed Pre-trained Language Model for Information Retrieval; integrating Syntax Tree and Graph Neural Network for Conversational Question Answering over Heterogeneous Sources; pqE: Zero-Shot Document Expansion for Dense Retrieval with Large Language Models; CKF: Conditional Knowledge Fusion Method for CommonSense Question Answering; MPPQA: Structure-Aware Extractive Multi-span Question Answering for Procedural Documents; GraphLLM: A General Framework for Multi-hop Question Answering over Knowledge Graphs Using Large Language Models; local or Global Optimization for Dialogue Discourse Parsing; structure and Behavior Dual-Graph Reasoning with Integrated Key-Clue Parsing for Multi-party Dialogue Reading Comprehension; enhancing Emotional Support Conversation with Cognitive Chain-of-Thought Reasoning; a Simple and Effective Span Interaction Modeling Method for Enhancing Multiple Span Question Answering; FacGPT: An Effective and Efficient Method for Evaluating Knowledge-Based Visual Question Answering; PAPER: A Persona-Aware Chain-of-Thought Learning Framework for Personalized Dialogue Response Generation; towards Building a Robust Knowledge Intensive Question Answering Model with Large Language Models; model-Agnostic Knowledge Distillation Between Heterogeneous Models; exploring Multimodal Information Fusion in Spoken Off-Topic Degree Assessment; integrating Hierarchical Key Information and Semantic Difference Features for Long Text Matching; CausalAPM: Generalizable Literal Disentanglement for NLU Debiasing; W2CL: A Multi-task Learning Approach to Improve Domain-Specific Sentence Classification Through Word Classification and Contrastive Learning; outperforming Larger Models on Text Classification Through Continued Pre-training; semantic Knowledge Enhanced and Global Pointer Optimized Method for Medical Nested Entity Recognition.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Gnatenko2025453,
	author = {Gnatenko, Anton and Kutz, Oliver and Troquard, Nicolas},
	title = {Modelling and Mining Knowledge About Computational Complexity},
	year = {2025},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) },
	volume = {15370 LNAI},
	pages = {453 – 470},
	doi = {10.1007/978-3-031-77792-9_27},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210875715&doi=10.1007%2f978-3-031-77792-9_27&partnerID=40&md5=be14aee23857cfc0e982f0f286916a0a},
	abstract = {We present an ontology of computational complexity that allows for a representation of research findings on the subject and supports query answering and reasoning tasks to help students and researchers in finding known facts and deriving new ones. The facts about decision problems and complexity classes are organised as a knowledge graph. The relationships between them are axiomatised using the FOWL framework that allows one to combine OWL 2 and first-order logic to balance between reasoning efficiency and expressive power. While the axioms were created through ontological analysis based on received ‘textbook knowledge’, the facts were extracted from the textual corpus of the ‘Complexity Zoo’ website, a human-curated ‘encyclopedia’ of complexity classes, in a human-supervised process employing large language models. We discuss, on the one hand, the modelling choices in relation to the previous work on knowledge representation in mathematics and, on the other hand, the peculiarities of using language models for the mining of complex symbolic facts. Finally, we illustrate some of the features of the hybrid reasoning system by providing a usage example. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.},
	author_keywords = {Computational Complexity; Domain Modelling; Knowledge Mining; LLM; Representation of Mathematical Knowledge},
	keywords = {Domain Knowledge; Modeling languages; Ontology; Complexity class; Domain model; Knowledge mining; Language model; LLM; Mathematical knowledge; Ontology's; Query answering; Reasoning tasks; Representation of mathematical knowledge; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{2025,
	title = {23rd International Symposium on Knowledge and Systems Sciences, KSS 2024},
	year = {2025},
	journal = {Communications in Computer and Information Science},
	volume = {2269 CCIS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210246299&partnerID=40&md5=e0cf1f558a06e9644b2942151d5ce5af},
	abstract = {The proceedings contain 23 papers. The special focus in this conference is on Knowledge and Systems Sciences. The topics include: Construction and Evaluation of a Subjects Synergistic Network for Cross-Regional Major Infectious Disease Emergency Response; evolution of Cumulative Reciprocity in Structured Populations; Simulating Social Network with LLM Agents: An Analysis of Information Propagation and Echo Chambers; How Public Opinion Risks in Social Hot Events Are Generated: A fsQCA Perspective; vulnerability Measurement of Social Media Users to Online Public Opinion in Emergency Context; analyzing Replies and Interactions Among Users with Different Stances: A Case Study of the Russia-Ukraine Conflict; explainable Machine Learning-Based Research on Key Factors in the Formation of Public Opinion on Similar Events; UMCap: User Memory Augmented Method for Personalized Image Descriptions; research on the Construction Method of Island Chain Knowledge Graph; a Knowledge and Data Driven Method for Air Combat Intention Recognition; Model-Based Systems Engineering Supporting Architecture Modeling of Air Traffic Management System and Model Verifying Based on SMT; Mission Modeling for the Perseverance Rover Based on KARMA Language; social Media Oriented Fake News Detection Based on Social Context and Cascade Graph; data Augmentation Using Large Language Model for Fake Review Identification; digital Transformation Mechanisms for Emergency Management in Chemical Enterprises: An Industrial Agglomeration Perspective; research on the Credibility Evaluation Method of Online Medical Community Answer Content Based on Domain Knowledge Graph; a Comprehensive Framework for Sentiment Analysis and Cold-Start Recommendations in Vietnam Hospitality Sector; mining Complementary Relationships of Items for Diversified Recommendation; a Novel Two-Stage Approach for Customer Satisfaction Analysis; predicting the Decision-Making Performance Based on Self-attention and Long-Short Term Memory Network.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Zhou2024,
	author = {Zhou, Jincao and Su, Xuezhong and Fu, Weiping and Lv, Yang and Liu, Bo},
	title = {Enhancing intention prediction and interpretability in service robots with LLM and KG},
	year = {2024},
	journal = {Scientific Reports},
	volume = {14},
	number = {1},
	doi = {10.1038/s41598-024-77916-3},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208688998&doi=10.1038%2fs41598-024-77916-3&partnerID=40&md5=b336082072f2be17d3a4e7c070603b11},
	abstract = {The rapid advancement of artificial intelligence has significantly expanded the role of service robots in everyday life. This expansion necessitates the accurate recognition and prediction of human intentions to provide timely and appropriate services. However, existing methods often struggle to perform effectively in complex and unstructured environments. To address this challenge, we propose the Large language model and Knowledge graph based Intention Recognition Framework (LKIRF), which combines large language model (LLM) with knowledge graphs (KG) to enhance the intention recognition capabilities of service robots. Our approach constructs an offline KG from human motion and environmental data and builds an online reasoning graph through real-time interaction, utilizing LLM for interpretation. Experimental results indicate that compared to traditional methods, LKIRF not only improves prediction accuracy across various scenarios but also enhances the transparency and interpretability of the intention reasoning process. © The Author(s) 2024.},
	author_keywords = {Intention Recognition; Knowledge Graph; Large Language Model},
	keywords = {article; artificial intelligence; human; large language model; prediction; reasoning; service robot},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Kuang2024,
	author = {Kuang, Senyun and Liu, Yang and Wang, Xin and Wu, Xinhua and Wei, Yintao},
	title = {Harnessing multimodal large language models for traffic knowledge graph generation and decision-making},
	year = {2024},
	journal = {Communications in Transportation Research},
	volume = {4},
	doi = {10.1016/j.commtr.2024.100146},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208121684&doi=10.1016%2fj.commtr.2024.100146&partnerID=40&md5=2a21be678605759ab722447d0bc5ef4a},
	type = {Editorial},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Chu2024,
	author = {Chu, Lei and Wu, Hongyan and Pan, Yi},
	title = {ChatASD: A Dialogue Framework for LLMs Enhanced by Autism Knowledge Graph Retrieval},
	year = {2024},
	journal = {ACM-BCB 2024 - 15th ACM Conference on Bioinformatics, Computational Biology, and Health Informatics},
	doi = {10.1145/3698587.3701538},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216416469&doi=10.1145%2f3698587.3701538&partnerID=40&md5=fdf180b4a122bb32cd639a8e2c085d41},
	abstract = {Autism Spectrum Disorder (ASD) is a neurodevelopmental disorder characterized by developmental delays, communication difficulties, repetitive behaviors, and restricted interests. Large Language Models (LLMs) have demonstrated exceptional capabilities in various natural language tasks, particularly in providing personalized question-and-answer(Q&A) services, making them well-suited for constructing dialogue engines for autism Q&A systems. However, general LLMs often lack integrated autism knowledge during training, limiting their professional competency in autism consultation. Additionally, the automatic evaluation of scientific accuracy in autism medical knowledge Q&A remains underexplored. To address this gap, we propose ChatASD, an autism knowledge Q&A framework based on Graph Retrieval-Augmented Generation (GraphRAG) technology. This framework leverages LLMs and retrieves relevant information from medical literature to generate an autism knowledge graph, employing a combination of global and community queries to produce reliable responses. Compared to traditional methods, ChatASD effectively addresses the sparse distribution of autism knowledge, providing more accurate and comprehensive answersAutomatic efficacy evaluations and competitive experiments on system responses indicate our approach significantly improves reliability of autism-related professional knowledge queries. © 2024 Copyright is held by the owner/author(s).},
	author_keywords = {Autism; Knowledge Graph; LLM; Question-and-Answer System; Retrieval-Augmented Generation},
	keywords = {Diseases; Autism; Autism spectrum disorders; Developmental delay; Knowledge graphs; Language model; Large language model; Natural languages; Professional competencies; Question and answer system; Retrieval-augmented generation; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Filippone2025163,
	author = {Filippone, Giuseppe and La Rosa, Gianmarco and Tabacchi, Marco Elio},
	title = {SDF-FuzzIA: A Fuzzy-Ontology Based Plug-in for the Intelligent Analysis of Geo-Thematic Data},
	year = {2025},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) },
	volume = {15350 LNAI},
	pages = {163 – 169},
	doi = {10.1007/978-3-031-76235-2_13},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210099435&doi=10.1007%2f978-3-031-76235-2_13&partnerID=40&md5=81d2ba2fe62b9c41ff0519d334f55a96},
	abstract = {This short paper presents a description of SDF-FuzzIA, a Fuzzy-Ontology LLM-based system for the intelligent analysis of geo-thematic data that serves as a plug-in to the Sustainability Decision Framework (SDF) Decision Support System (DSS). A description of the components implemented in the system is given, followed by an explanation of the interaction between the components and the main system. As this still is a work in progress, future directions and possible hurdles are explored. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2025.},
	author_keywords = {Fuzzy Logic; Fuzzy Ontology; Soft Computing},
	keywords = {Ontology; Decision framework; Decision supports; Fuzzy ontology; Fuzzy-Logic; Intelligent analysis; Ontology-based; Plug-ins; Soft-Computing; Support systems; Thematic data; Fuzzy logic},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{2025,
	title = {13th CCF International Conference on Natural Language Processing and Chinese Computing, NLPCC 2024},
	year = {2025},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) },
	volume = {15359 LNAI},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209808726&partnerID=40&md5=30859b114b562fbe49da488e1ee2fb23},
	abstract = {The proceedings contain 194 papers. The special focus in this conference is on Natural Language Processing and Chinese Computing. The topics include: Hierarchical Knowledge Aggregation for Personalized Response Generation in Dialogue Systems; multi-hop Reading Comprehension Model Based on Abstract Meaning Representation and Multi-task Joint Learning; Leveraging Large Language Models for QA Dialogue Dataset Construction and Analysis in Public Services; MCFC: A Momentum-Driven Clicked Feature Compressed Pre-trained Language Model for Information Retrieval; integrating Syntax Tree and Graph Neural Network for Conversational Question Answering over Heterogeneous Sources; pqE: Zero-Shot Document Expansion for Dense Retrieval with Large Language Models; CKF: Conditional Knowledge Fusion Method for CommonSense Question Answering; MPPQA: Structure-Aware Extractive Multi-span Question Answering for Procedural Documents; GraphLLM: A General Framework for Multi-hop Question Answering over Knowledge Graphs Using Large Language Models; local or Global Optimization for Dialogue Discourse Parsing; structure and Behavior Dual-Graph Reasoning with Integrated Key-Clue Parsing for Multi-party Dialogue Reading Comprehension; enhancing Emotional Support Conversation with Cognitive Chain-of-Thought Reasoning; a Simple and Effective Span Interaction Modeling Method for Enhancing Multiple Span Question Answering; FacGPT: An Effective and Efficient Method for Evaluating Knowledge-Based Visual Question Answering; PAPER: A Persona-Aware Chain-of-Thought Learning Framework for Personalized Dialogue Response Generation; towards Building a Robust Knowledge Intensive Question Answering Model with Large Language Models; model-Agnostic Knowledge Distillation Between Heterogeneous Models; exploring Multimodal Information Fusion in Spoken Off-Topic Degree Assessment; integrating Hierarchical Key Information and Semantic Difference Features for Long Text Matching; CausalAPM: Generalizable Literal Disentanglement for NLU Debiasing; W2CL: A Multi-task Learning Approach to Improve Domain-Specific Sentence Classification Through Word Classification and Contrastive Learning; outperforming Larger Models on Text Classification Through Continued Pre-training; semantic Knowledge Enhanced and Global Pointer Optimized Method for Medical Nested Entity Recognition.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Li202418,
	author = {Li, Chengxue and Chen, Xuyang and Ding, Min and Jin, Wei and Gao, Feng},
	title = {Research on Chinese Knowledge Base and Knowledge Q&A Technology for Power Grid Dispatching},
	year = {2024},
	journal = {ACM International Conference Proceeding Series},
	pages = {18 – 23},
	doi = {10.1145/3703187.3703192},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216103728&doi=10.1145%2f3703187.3703192&partnerID=40&md5=94a59a0eee9ffb10673281ed7869545b},
	abstract = {To support online professional knowledge query for power grid dispatchers, this article proposes a method for constructing a knowledge base based on knowledge graph, which implements systematic organization and management of knowledge resources in the field of power-grid dispatching. Moreover, a questions and answers (Q&A) service is design based on large language model and proposed knowledge base. Based on the constructed knowledge base and Q&A service, auxiliary learning functions can be provided in the domain of power grid operation. This enables accurate acquisition of professional knowledge through Chinese natural language interaction, enhancing the effectiveness and flexibility of online training for power-grid dispatchers. © 2024 Copyright held by the owner/author(s).},
	author_keywords = {Graph database; Knowledge graph; Large language model; Question answering},
	keywords = {Graph Databases; Knowledge graph; Graph database; Knowledge graphs; Knowledge resource; Language model; Large language model; Organization and management; Power grid dispatching; Power grids; Professional knowledge; Question Answering},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Xu2024,
	author = {Xu, Liang and Lu, Lu and Liu, Minglu and Song, Chengxuan and Wu, Lizhen},
	title = {Nanjing Yunjin intelligent question-answering system based on knowledge graphs and retrieval augmented generation technology},
	year = {2024},
	journal = {Heritage Science},
	volume = {12},
	number = {1},
	doi = {10.1186/s40494-024-01231-3},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189988524&doi=10.1186%2fs40494-024-01231-3&partnerID=40&md5=fa422be6944ff08e26848af12bba0f7b},
	abstract = {Nanjing Yunjin, a traditional Chinese silk weaving craft, is celebrated globally for its unique local characteristics and exquisite workmanship, forming an integral part of the world's intangible cultural heritage. However, with the advancement of information technology, the experiential knowledge of the Nanjing Yunjin production process is predominantly stored in text format. As a highly specialized and vertical domain, this information is not readily convert into usable data. Previous studies on a knowledge graph-based Nanjing Yunjin Question-Answering System have partially addressed this issue. However, knowledge graphs need to be constantly updated and rely on predefined entities and relationship types. Faced with ambiguous or complex natural language problems, knowledge graph information retrieval faces some challenges. Therefore, this study proposes a Nanjing Yunjin Question-Answering System that integrates Knowledge Graphs and Retrieval Augmented Generation techniques. In this system, the ROBERTA model is first utilized to vectorize Nanjing Yunjin textual information, delving deep into textual semantics to unveil its profound cultural connotations. Additionally, the FAISS vector database is employed for efficient storage and retrieval of Nanjing Yunjin information, achieving a deep semantic match between questions and answers. Ultimately, related retrieval results are fed into the Large Language Model for enhanced generation, aiming for more accurate text generation outcomes and improving the interpretability and logic of the Question-Answering System. This research merges technologies like text embedding, vectorized retrieval, and natural language generation, aiming to overcome the limitations of knowledge graphs-based Question-Answering System in terms of graph updating, dependency on predefined types, and semantic understanding. System implementation and testing have shown that the Nanjing Yunjin Intelligent Question-Answering System, constructed on the basis of Knowledge Graphs and Retrieval Augmented Generation, possesses a broader knowledge base that considers context, resolving issues of polysemy, vague language, and sentence ambiguity, and efficiently and accurately generates answers to natural language queries. This significantly facilitates the retrieval and utilization of Yunjin knowledge, providing a paradigm for constructing Question-Answering System for other intangible cultural heritages, and holds substantial theoretical and practical significance for the deep exploration and discovery of the knowledge structure of human intangible heritage, promoting cultural inheritance and protection. © The Author(s) 2024.},
	author_keywords = {Knowledge graphs; Nanjing Yunjin; Question-Answering System; Retrieval augmented generation; Vector retrieval},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Gold Open Access}
}

@ARTICLE{Hou2024,
	author = {Hou, Kun and Li, Jingyuan and Liu, Yingying and Sun, Shiqi and Zhang, Haoliang and Jiang, Haiyang},
	title = {KG-EGV: A Framework for Question Answering with Integrated Knowledge Graphs and Large Language Models},
	year = {2024},
	journal = {Electronics (Switzerland)},
	volume = {13},
	number = {23},
	doi = {10.3390/electronics13234835},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211914102&doi=10.3390%2felectronics13234835&partnerID=40&md5=50001a84e012492e3820f6b6cd43080f},
	abstract = {Despite the remarkable progress of large language models (LLMs) in understanding and generating unstructured text, their application in structured data domains and their multi-role capabilities remain underexplored. In particular, utilizing LLMs to perform complex reasoning tasks on knowledge graphs (KGs) is still an emerging area with limited research. To address this gap, we propose KG-EGV, a versatile framework leveraging LLMs to perform KG-based tasks. KG-EGV consists of four core steps: sentence segmentation, graph retrieval, EGV, and backward updating, each designed to segment sentences, retrieve relevant KG components, and derive logical conclusions. EGV, a novel integrated framework for LLM inference, enables comprehensive reasoning beyond retrieval by synthesizing diverse evidence, which is often unattainable via retrieval alone due to noise or hallucinations. The framework incorporates six key stages: generation expansion, expansion evaluation, document re-ranking, re-ranking evaluation, answer generation, and answer verification. Within this framework, LLMs take on various roles, such as generator, re-ranker, evaluator, and verifier, collaboratively enhancing answer precision and logical coherence. By combining the strengths of retrieval-based and generation-based evidence, KG-EGV achieves greater flexibility and accuracy in evidence gathering and answer formulation. Extensive experiments on widely used benchmarks, including FactKG, MetaQA, NQ, WebQ, and TriviaQA, demonstrate that KG-EGV achieves state-of-the-art performance in answer accuracy and evidence quality, showcasing its potential to advance QA research and applications. © 2024 by the authors.},
	author_keywords = {answer verification; evidence retrieval; graph-based inference; knowledge graph; large language model; multi-role reasoning; ODQA; question answering},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Chang2024,
	author = {Chang, Munyoung and Ahn, Junyong and Kang, Bong Gyun and Yoon, Sungroh},
	title = {Cross-modal embedding integrator for disease-gene/protein association prediction using a multi-head attention mechanism},
	year = {2024},
	journal = {Pharmacology Research and Perspectives},
	volume = {12},
	number = {6},
	doi = {10.1002/prp2.70034},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210022485&doi=10.1002%2fprp2.70034&partnerID=40&md5=96e9726be6661aef76394b92ef29e9af},
	abstract = {Knowledge graphs, powerful tools that explicitly transfer knowledge to machines, have significantly advanced new knowledge inferences. Discovering unknown relationships between diseases and genes/proteins in biomedical knowledge graphs can lead to the identification of disease development mechanisms and new treatment targets. Generating high-quality representations of biomedical entities is essential for successfully predicting disease-gene/protein associations. We developed a computational model that predicts disease-gene/protein associations using the Precision Medicine Knowledge Graph, a biomedical knowledge graph. Embeddings of biomedical entities were generated using two different methods—a large language model (LLM) and the knowledge graph embedding (KGE) algorithm. The LLM utilizes information obtained from massive amounts of text data, whereas the KGE algorithm relies on graph structures. We developed a disease-gene/protein association prediction model, “Cross-Modal Embedding Integrator (CMEI),” by integrating embeddings from different modalities using a multi-head attention mechanism. The area under the receiver operating characteristic curve of CMEI was 0.9662 (± 0.0002) in predicting disease-gene/protein associations. In conclusion, we developed a computational model that effectively predicts disease-gene/protein associations. CMEI may contribute to the identification of disease development mechanisms and new treatment targets. © 2024 The Author(s). Pharmacology Research & Perspectives published by British Pharmacological Society and American Society for Pharmacology and Experimental Therapeutics and John Wiley & Sons Ltd.},
	author_keywords = {disease; gene; knowledge graph embedding; large language model; multi-head attention; protein},
	keywords = {Algorithms; Computational Biology; Humans; Precision Medicine; Proteins; ROC Curve; protein; algorithm; article; computer model; gene; human; large language model; personalized medicine; prediction; receiver operating characteristic; algorithm; bioinformatics; genetics; procedures},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Earley2024271,
	author = {Earley, Seth and Mehta, Sanjay},
	title = {Powerful tools for personalisation: Using large language model-based agents, knowledge graphs and customer signals to connect with users},
	year = {2024},
	journal = {Applied Marketing Analytics},
	volume = {10},
	number = {3},
	pages = {271 – 288},
	doi = {10.69554/NMCE9908},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213407161&doi=10.69554%2fNMCE9908&partnerID=40&md5=3562698ec0880f9eabf715c0b776ed3a},
	abstract = {This paper discusses how large language models’ (LLMs) agentic workflows powering ChatGPT types of applications can use a combination of enterprise data sources to hyper-personalise information at scale for customers or employees. Typical use cases include marketing communications, customer support, content creation and digital assistants. The approaches described are at one level established in theory; however, practical adoption has been challenging and the combination of templated prompts with LLMs and agent call outs to external application programming interfaces and knowledge sources are new. The data sources using these approaches include knowledge, content and transactional data with near real time and real time customer signals. Customer signal data can include first, second or third party data that describes the characteristics of a customer or employee, as well as real time ‘digital body language’ — click paths, searches, responses to campaigns and chatbot dialogues. Two use cases in two industries — automotive and industrial manufacturing — will be detailed to illustrate how the same principles and approaches can be applied in situations that are very different, and how a knowledge architecture combined with retrieval augmented generation (RAG) should be developed and applied. Analytics to monitor outcomes and enable manual and automated course corrections will be discussed. The outcomes are unified and contextualised experiences realising the sometimes ambitious designs of user experience developers. It is easier to storyboard a design than it is to make it a reality. Marketing organisations are more and more responsible for the end-to-end customer journey and experience. However, the customer journey is a knowledge journey. At each step of the process, they are asking questions about the company, product or service. What product and solutions do you offer? Which ones are right for me? How do I choose a particular offering? How do I purchase or procure the product or service? How can I maintain it, and get service or support? How do I get the most from my purchase? What are the options for upgrading or enhancing my solution? These are marketing communications that consist of educating the prospect rather than selling to them. Today’s prospects are empowered with greater information and understanding of offerings and the competition than ever before. Marketing is therefore responsible for helping them make the decision based on information and references that are presented at each stage of the journey. © Henry Stewart Publications 2054-7544 (2024).},
	author_keywords = {artificial intelligence; ChatGPT; customer experience; customer journey; generative AI; hyper-personalisation; knowledge architecture; knowledge management; knowledge models; large language models; LLM challenges; LLM solutions; LLMs; marketing personalisation; metadata models; RAG; retrieval augmented generation},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}@CONFERENCE{Chen2024266,
	author = {Chen, Hao and Hou, Jun},
	title = {Intelligent data governance: Building an enterprise data management system using KG and LLM},
	year = {2024},
	journal = {ACM International Conference Proceeding Series},
	pages = {266 – 271},
	doi = {10.1145/3695080.3695127},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209119622&doi=10.1145%2f3695080.3695127&partnerID=40&md5=5afccecb2ceb06faeb1624823d0781c8},
	abstract = {In tobacco enterprises, data governance is the key to improving operational efficiency and decision-making quality. This study focuses on how to build an advanced data management system for tobacco enterprises through knowledge graph (KG) and large language model (LLM). Firstly, this paper describes the process of integrating the core resources of tobacco enterprises, such as metadata, data elements, data constraints, arithmetic, storage and network, into a KG. Subsequently, it analyses in depth how to use local LLM combined with the KG to form a 'think tank' for tobacco enterprise data governance. This think tank would not only be able to store and process the vast amount of data governance information in the tobacco industry, but also provide intelligent recommendations, predict future trends, and diagnose problems in existing data governance processes. In addition, the paper discusses the potential impact of this integrated approach on enhancing data governance strategies, improving data quality and compliance in tobacco organisations, as well as its role in fostering cross-functional collaboration and improving data governance efficiency. A series of recommendations for implementing and optimising such an integrated data governance system are also presented to address the specificities of the tobacco industry, such as the high requirements for data security and regulatory compliance. These recommendations are designed to help tobacco organisations manage their growing data assets more effectively and ensure data security and compliance to stay ahead of the game in a competitive market. With this advanced data governance system, tobacco companies can better adapt to the trend of digital transformation and maximise the use of their data assets.  © 2024 ACM.},
	author_keywords = {data governance; intelligent Q&A system; KG; LLM},
	keywords = {Efficiency; Data assets; Data governances; Enterprise data; Governance systems; Intelligent data; Intelligent Q&A system; Knowledge graphs; Language model; Large language model; Tobacco industry; Data quality},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Basu20245556,
	author = {Basu, Kinjal},
	title = {Bridging Knowledge Gaps in LLMs via Function Calls},
	year = {2024},
	journal = {International Conference on Information and Knowledge Management, Proceedings},
	pages = {5556 – 5557},
	doi = {10.1145/3627673.3679070},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209987481&doi=10.1145%2f3627673.3679070&partnerID=40&md5=6eadd08c4072ef798ccd2de627cd8197},
	abstract = {Large Language Models (LLMs) demonstrate impressive abilities across a wide range of NLP tasks. However, their underlying architecture and design come with inherent limitations, which result in issues like hallucinations and constrained reasoning capabilities. Additionally, creating an autonomous AI agent capable of handling complex real-world tasks demands access to real-time information, sensitive data, or external tools-capabilities that most LLMs currently lack. Addressing these issues may require augmenting LLMs with external knowledge through function calling. These function calls serve as an interface between LLMs and the world, enabling access to real-time data, diverse tools, reasoning systems, knowledge graphs, APIs, plugins, code interpreters, and more. The primary objective of this talk is to highlight the significance of function-calling capabilities in bridging the knowledge gap in LLMs, showcase recent research advancements in this area, and discuss existing challenges along with future directions. Also, I will present a training and benchmarking data suite for function calling - API-BLEND and a function calling model - Granite-20B-FunctionCalling.  © 2024 Owner/Author.},
	author_keywords = {function calling; knowledge-augmented llms; large language model (llm)},
	keywords = {Chatbots; Metadata; Modeling languages; Natural language processing systems; Network security; Problem oriented languages; Program interpreters; Sensitive data; Function calling; Function calls; Inherent limitations; Knowledge gaps; Knowledge-augmented llms; Language model; Large language model; Real-world task; Reasoning capabilities; Task demand; Benchmarking},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Ivanisenko2024,
	author = {Ivanisenko, Timofey V. and Demenkov, Pavel S. and Ivanisenko, Vladimir A.},
	title = {An Accurate and Efficient Approach to Knowledge Extraction from Scientific Publications Using Structured Ontology Models, Graph Neural Networks, and Large Language Models},
	year = {2024},
	journal = {International Journal of Molecular Sciences},
	volume = {25},
	number = {21},
	doi = {10.3390/ijms252111811},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208591467&doi=10.3390%2fijms252111811&partnerID=40&md5=2e16168a1f39ac8952e4a4c15a20bb26},
	abstract = {The rapid growth of biomedical literature makes it challenging for researchers to stay current. Integrating knowledge from various sources is crucial for studying complex biological systems. Traditional text-mining methods often have limited accuracy because they don’t capture semantic and contextual nuances. Deep-learning models can be computationally expensive and typically have low interpretability, though efforts in explainable AI aim to mitigate this. Furthermore, transformer-based models have a tendency to produce false or made-up information—a problem known as hallucination—which is especially prevalent in large language models (LLMs). This study proposes a hybrid approach combining text-mining techniques with graph neural networks (GNNs) and fine-tuned large language models (LLMs) to extend biomedical knowledge graphs and interpret predicted edges based on published literature. An LLM is used to validate predictions and provide explanations. Evaluated on a corpus of experimentally confirmed protein interactions, the approach achieved a Matthews correlation coefficient (MCC) of 0.772. Applied to insomnia, the approach identified 25 interactions between 32 human proteins absent in known knowledge bases, including regulatory interactions between MAOA and 5-HT2C, binding between ADAM22 and 14-3-3 proteins, which is implicated in neurological diseases, and a circadian regulatory loop involving RORB and NR1D1. The hybrid GNN-LLM method analyzes biomedical literature efficiency to uncover potential molecular interactions for complex disorders. It can accelerate therapeutic target discovery by focusing expert verification on the most relevant automatically extracted information. © 2024 by the authors.},
	author_keywords = {ANDSystem; deep learning; GNN; knowledge graph; LLM; text-mining},
	keywords = {Data Mining; Deep Learning; Humans; Knowledge Bases; Neural Networks, Computer; Publications; ADAM protein; amine oxidase (flavin containing) isoenzyme A; nuclear receptor NR1D1; protein 14 3 3; protein adam 22; retinoid related orphan receptor beta; serotonin 2C receptor; unclassified drug; accuracy; Article; binary classification; circadian rhythm; data mining; graph neural network; human; insomnia; knowledge base; large language model; medical literature; multilayer perceptron; neurologic disease; prediction; protein binding; protein protein interaction; publication; urban health; artificial neural network; deep learning; procedures; publication},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Luo20249311,
	author = {Luo, Pengfei and Xu, Tong and Liu, Che and Zhang, Suojuan and Xu, Linli and Li, Minglei and Chen, Enhong},
	title = {Bridging Gaps in Content and Knowledge for Multimodal Entity Linking},
	year = {2024},
	journal = {MM 2024 - Proceedings of the 32nd ACM International Conference on Multimedia},
	pages = {9311 – 9320},
	doi = {10.1145/3664647.3681661},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209818185&doi=10.1145%2f3664647.3681661&partnerID=40&md5=afee3049181fea4b271d3b033a715149},
	abstract = {Multimodal Entity Linking (MEL) aims to address the ambiguity in multimodal mentions and associate them with Multimodal Knowledge Graphs (MMKGs). Existing works primarily focus on designing multimodal interaction and fusion mechanisms to enhance the performance of MEL. However, these methods still overlook two crucial gaps within the MEL task. One is the content discrepancy between mentions and entities, manifested as uneven information density. The other is the knowledge gap, indicating insufficient knowledge extraction and reasoning during the linking process. To bridge these gaps, we propose a novel framework FissFuse, as well as a plug-and-play knowledge-aware re-ranking method KAR. Specifically, FissFuse collaborates with the Fission and Fusion branches, establishing dynamic features for each mention-entity pair and adaptively learning multimodal interactions to alleviate content discrepancy. Meanwhile, KAR is endowed with carefully crafted instruction for intricate knowledge reasoning, serving as re-ranking agents empowered by Large Language Models (LLMs). Extensive experiments on two well-constructed MEL datasets demonstrate outstanding performance of FissFuse compared with various baselines. Comprehensive evaluations and ablation experiments validate the effectiveness and generality of KAR. © 2024 ACM.},
	author_keywords = {content discrepancy; multimodal entity linking; multimodal fusion; multimodal knowledge graph},
	keywords = {Modeling languages; Content discrepancy; Knowledge graphs; Knowledge reasoning; Multi-modal; Multi-modal fusion; Multimodal entity linking; Multimodal Interaction; Multimodal knowledge graph; Performance; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Ji20242616,
	author = {Ji, Xiangyu and Wang, Xin and Zhang, Heyi and Meng, Zhaopeng and Zhang, Junhua and Zhuang, Pengwei and Jia, Yongzhe and Xu, Dawei},
	title = {Knowledge Augmentation on Traditional Chinese Medicine Language Model; [面向中医药大模型的知识增强方法研究]},
	year = {2024},
	journal = {Journal of Frontiers of Computer Science and Technology},
	volume = {18},
	number = {10},
	pages = {2616 – 2629},
	doi = {10.3778/j.issn.1673-9418.2407082},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206536429&doi=10.3778%2fj.issn.1673-9418.2407082&partnerID=40&md5=427400fe20f40c6fb77890db963f88c7},
	abstract = {Recently, large language models (LLM) have made significant achievements in various fields. However, due to lack of specialized knowledge and the gap between modern medicine and traditional Chinese medicine (TCM), it is still a challenge to deploy LLM in TCM. Existing methods fail to maintain the structure of TCM prescription. To address the problems, a pattern of knowledge augmentation is proposed. The method includes model training, knowledge graph construction and knowledge augmentation. In the training phase, TCM language model is trained on TCM corpus, by a two-stage method combining pre-training and fine-tuning. In the knowledge graph construction phase, prescription knowledge graph is constructed from nearly 100000 preprocessed classical TCM prescriptions and those from ancient books. In the knowledge augmentation phase, enhanced by the above pattern, outputs are generated from computation of knowledge graph, according to the schema of knowledge graph from searching result, which preserves the structure of prescriptions. A set of evaluations specific to prescription optimizations is proposed, including objective and subjective indicators, to evaluate the performance of the model for the task. Experiment shows that the model improves greatly on both subjective and objective evaluations compared with baselines. BLEU-1 is increased by up to 0.09, while ROUGE-1 is increased by up to 0.21. Ablation study shows that, it is of vital importance for the model performance to be knowledge-augmented. BLEU-1 of augmentation-free model is decreased by about 37% compared with that of the augmented model. © 2024 Journal of Computer Engineering and Applications Beijing Co., Ltd.; Science Press. All rights reserved.},
	author_keywords = {large language model (LLM); prescription optimization; retrieval augmented generation; traditional Chinese medicine},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Vassiliou2024,
	author = {Vassiliou, Giannis and Trouli, Georgia Eirini and Troullinou, Georgia and Spyridakis, Nikolaos and Bitzarakis, George and Droumalia, Fotini and Karagiannakis, Antonis and Skouteli, Georgia and Oikonomou, Nikolaos and Deka, Dimitra and Makaronas, Emmanouil and Pronoitis, Georgios and Alexandris, Konstantinos and Kostopoulos, Stamatios and Kazantzakis, Yiannis and Vlassis, Nikolaos and Sfinarolaki, Eleftheria and Daskalakis, Vardis and Giannakos, Iakovos and Stamatoukou, Argyro and Papadakis, Nikolaos and Kondylakis, Haridimos},
	title = {ULYSSES: Automated FreqUentLY ASked QueStions for KnowlEdge GraphS},
	year = {2024},
	journal = {Applied Sciences (Switzerland)},
	volume = {14},
	number = {17},
	doi = {10.3390/app14177640},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203626631&doi=10.3390%2fapp14177640&partnerID=40&md5=8793b066ffe242715e8959cf0af3164f},
	abstract = {The exponential growth of Knowledge Graphs necessitates effective and efficient methods for their exploration and understanding. Frequently Asked Questions (FAQ) is a service that typically presents a list of questions and answers related to a specific topic, and which is intended to help people understand that topic. Although FAQ has already shown its value on large websites and is widely used, to the best of our knowledge it has not yet been exploited for Knowledge Graphs. In this paper, we present ULYSSES, the first system for automatically constructing FAQ lists for large Knowledge Graphs. Our method consists of three key steps. First, we select the most frequent queries by exploiting the available query logs. Next, we answer the selected queries, using the original graph. Finally, we construct textual descriptions of both the queries and the corresponding answers, exploring state-of-the-art transformer models, i.e., ChatGPT 3.5 and Gemini 1.5 Pro. We evaluate the results of each model, using a human-constructed FAQ list, contributing a unique dataset to the domain and showing the benefits of our approach. © 2024 by the authors.},
	author_keywords = {frequently asked questions; large language models; RDF knowledge graphs},
	keywords = {Question answering; Structured Query Language; Automated frequently asked question; Exponential growth; First systems; Frequently asked questions; Knowledge graphs; Knowledge IT; Language model; Large language model; Query logs; RDF knowledge graph; Knowledge graph},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Soman2024,
	author = {Soman, Karthik and Rose, Peter W. and Morris, John H. and Akbas, Rabia E. and Smith, Brett and Peetoom, Braian and Villouta-Reyes, Catalina and Cerono, Gabriel and Shi, Yongmei and Rizk-Jackson, Angela and Israni, Sharat and Nelson, Charlotte A. and Huang, Sui and Baranzini, Sergio E.},
	title = {Biomedical knowledge graph-optimized prompt generation for large language models},
	year = {2024},
	journal = {Bioinformatics},
	volume = {40},
	number = {9},
	doi = {10.1093/bioinformatics/btae560},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205402312&doi=10.1093%2fbioinformatics%2fbtae560&partnerID=40&md5=4a86e921811e77ed9e411bb8fcd611d0},
	abstract = {Motivation: Large language models (LLMs) are being adopted at an unprecedented rate, yet still face challenges in knowledge-intensive domains such as biomedicine. Solutions such as pretraining and domain-specific fine-tuning add substantial computational overhead, requiring further domain-expertise. Here, we introduce a token-optimized and robust Knowledge Graph-based Retrieval Augmented Generation (KG-RAG) framework by leveraging a massive biomedical KG (SPOKE) with LLMs such as Llama-2-13b, GPT-3.5-Turbo, and GPT-4, to generate meaningful biomedical text rooted in established knowledge. Results: Compared to the existing RAG technique for Knowledge Graphs, the proposed method utilizes minimal graph schema for context extraction and uses embedding methods for context pruning. This optimization in context extraction results in more than 50% reduction in token consumption without compromising the accuracy, making a cost-effective and robust RAG implementation on proprietary LLMs. KG-RAG consistently enhanced the performance of LLMs across diverse biomedical prompts by generating responses rooted in established knowledge, accompanied by accurate provenance and statistical evidence (if available) to substantiate the claims. Further benchmarking on human curated datasets, such as biomedical true/false and multiple-choice questions (MCQ), showed a remarkable 71% boost in the performance of the Llama-2 model on the challenging MCQ dataset, demonstrating the framework’s capacity to empower open-source models with fewer parameters for domain-specific questions. Furthermore, KG-RAG enhanced the performance of proprietary GPT models, such as GPT-3.5 and GPT-4. In summary, the proposed framework combines explicit and implicit knowledge of KG and LLM in a token optimized fashion, thus enhancing the adaptability of general-purpose LLMs to tackle domain-specific questions in a cost-effective fashion. © The Author(s) 2024. Published by Oxford University Press.},
	keywords = {Algorithms; Computational Biology; Humans; Natural Language Processing; algorithm; bioinformatics; human; natural language processing; procedures},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Guo2024727,
	author = {Guo, Yuxiang and Shen, Shuanghong and Liu, Qi and Huang, Zhenya and Zhu, Linbo and Su, Yu and Chen, Enhong},
	title = {Mitigating Cold-Start Problems in Knowledge Tracing with Large Language Models: An Attribute-aware Approach},
	year = {2024},
	journal = {International Conference on Information and Knowledge Management, Proceedings},
	pages = {727 – 736},
	doi = {10.1145/3627673.3679664},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210014457&doi=10.1145%2f3627673.3679664&partnerID=40&md5=5d4b58397bf9e7071d2d7ada93123111},
	abstract = {Knowledge Tracing (KT) is a crucial research task for dynamically monitoring students' knowledge states, particularly in online education systems. Recently, knowledge tracing has gained significant attention and in-depth research. Most existing methods rely on students' response data for question understanding and modeling, which helps better updating students' knowledge states. Meanwhile, question ID is utilized to indicate and represent questions. However, this presents a challenge when transitioning to new, cold-start questions that few students has answered before. Also, prior work has overlooked the semantic modeling of questions, which could better assist in modeling the transfer of students' knowledge states. In this paper, we explore leveraging the power of Large Language Models (LLMs) to help understand questions for knowledge tracing, which benefits mitigating cold-start and sparse problems and modeling the transfer of students' knowledge states in a sophisticated manner. Specifically, we first design an attribute estimation module to estimate the attribute of the questions (e.g., difficulty, ability requirements, expected response time) by prompting Large Language Models. Subsequently, we have developed a question embedding module that incorporates graph attention network to effectively utilizing these attributes. Extensive experiments on various datasets demonstrate that our model outperforms existing state-of-the-art models and effectively addresses the problems of cold-start and sparsity. In addition, due to the estimation of multiple attributes of the questions, our model exhibits superior interpretability.  © 2024 ACM.},
	author_keywords = {knowledge tracing; large language model; question attributes},
	keywords = {Graph embeddings; Knowledge graph; Modeling languages; Network embeddings; Question answering; Students; Cold start problems; Cold-start; Education systems; Knowledge state; Knowledge tracings; Language model; Large language model; On-line education; Question attribute; Student knowledge; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Kondinski20242070,
	author = {Kondinski, Aleksandar and Rutkevych, Pavlo and Pascazio, Laura and Tran, Dan N. and Farazi, Feroz and Ganguly, Srishti and Kraft, Markus},
	title = {Knowledge graph representation of zeolitic crystalline materials},
	year = {2024},
	journal = {Digital Discovery},
	volume = {3},
	number = {10},
	pages = {2070 – 2084},
	doi = {10.1039/d4dd00166d},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205728208&doi=10.1039%2fd4dd00166d&partnerID=40&md5=0f495be066acbc1fa416526cf50a6397},
	abstract = {Zeolites are complex and porous crystalline inorganic materials that serve as hosts for a variety of molecular, ionic and cluster species. Formal, machine-actionable representation of this chemistry presents a challenge as a variety of concepts need to be semantically interlinked. This work demonstrates the potential of knowledge engineering in overcoming this challenge. We develop ontologies OntoCrystal and OntoZeolite, enabling the representation and instantiation of crystalline zeolite information into a dynamic, interoperable knowledge graph called The World Avatar (TWA). In TWA, crystalline zeolite instances are semantically interconnected with chemical species that act as guests in these materials. Information can be obtained via custom or templated SPARQL queries administered through a user-friendly web interface. Unstructured exploration is facilitated through natural language processing using the Marie System, showcasing promise for the blended large language model - knowledge graph approach in providing accurate responses on zeolite chemistry in natural language. © 2024 RSC.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Huang2024942,
	author = {Huang, Yubo and Zeng, Guosun},
	title = {RD-P: A Trustworthy Retrieval-Augmented Prompter with Knowledge Graphs for LLMs},
	year = {2024},
	journal = {International Conference on Information and Knowledge Management, Proceedings},
	pages = {942 – 952},
	doi = {10.1145/3627673.3679659},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210016239&doi=10.1145%2f3627673.3679659&partnerID=40&md5=7be39f98fabf42d1abfb84217cb5f1e0},
	abstract = {Large Language Models (LLMs) face challenges due to hallucination issues. Current solutions use retrieval-augmented generation (RAG), integrating LLMs with external knowledge to enhance answer accuracy. However, the misuse of irrelevant external knowledge can be misleading. In this paper, we propose a novel method called Retrieve-and-Discriminate Prompter (RD-P), which leverages knowledge graphs (KGs) for trustworthy RAG by synchronizing knowledge retrieval and discrimination in a unified model. Specifically, we train a prompter based on a pre-trained language model with shared parameters. It has two key modules: the retriever and the discriminator. The retriever identifies relevant reasoning paths in the KG, while the discriminator evaluates their credibility through "logical coverage calculation"and in turn instructs the retrieval process. Prompts are then constructed to guide LLMs in reasoning and answering questions using both retrieved and implicit knowledge. Experiments on knowledge-intensive question answering (QA) tasks demonstrate that our method significantly improves answer coverage rate while reducing the retrieval scale, achieving superior performance in complex KGQA tasks compared with state-of-the-art RAG methods at a low cost.  © 2024 ACM.},
	author_keywords = {kgqa; large language models; prompter; retrieval-augmented generation},
	keywords = {Computer simulation languages; Problem oriented languages; Unified Modeling Language; 'current; External knowledge; Kgqa; Knowledge graphs; Knowledge retrieval; Language model; Large language model; Novel methods; Prompter; Retrieval-augmented generation; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Liu20242940,
	author = {Liu, Xin and Gao, Huiquan and Shao, Changheng and Chen, Ziliang and Lu, Wenjuan and Yang, Huiru},
	title = {Construction and Application of Large Language Model for Public Complaints with Knowledge Reasoning and Similarity Retrieval; [融合知识推理与相似度检索的民众诉求大模型构建与应用]},
	year = {2024},
	journal = {Journal of Frontiers of Computer Science and Technology},
	volume = {18},
	number = {11},
	pages = {2940 – 2953},
	doi = {10.3778/j.issn.1673-9418.2406057},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209718567&doi=10.3778%2fj.issn.1673-9418.2406057&partnerID=40&md5=8d0fbbd808434c71f820111610b80d99},
	abstract = {Efficiently responding to public complaints is a necessary measure to realize intelligent management and enhance public satisfaction, and the use of intelligent question answering for public complaints can save time and human resources. However, rule-based and retrieval-based models in intelligent question answering rely on preset knowledge. Therefore, they cannot provide effective responses when complaints are out of the scope of knowledge, nor can they maintain the coherence of conversations when dealing with multiple rounds of dialogues. Existing large language models can communicate smoothly with users, but general-purpose large language models lack domain knowledge. Due to the fact that the correct answers in the training data will contain information not covered by the questions, the general large language model generates wrong responses or answers that are not the questions asked, resulting in hallucination. To address these issues, a large language model (PC-LLM) for intelligent question-and-answer in the domain of public complaints has been constructed. Firstly, an entity relationship extraction model based on BERT-BiLSTM-CRF is designed to extract entities and relationships in the complaint work order in order to construct the complaint knowledge graph. The BERT model is used to vectorize the complaint work order and construct the vector index library of the complaint work order. In the stage of reply generation, this paper extracts the entities and relationships of users’complaints, conducts knowledge reasoning through entity links in the knowledge graph of complaints, obtains potential relationship tips, and uses the knowledge graph of complaints to perform knowledge reasoning to obtain potential relationship hints. Meanwhile, this paper performs quick search of complaints within the vector index library of complaint work orders, and obtains similar complaints. Finally, a more accurate response can be generated by integrating potential relationship prompts, similar complaint prompts and complaint into a large language model. Experimental analysis shows that the performance of this large language model on the complaints dataset is significantly better than that of ChatGPT4o, ERNIE Bot, Tongyi Qianwen, and other large language models. © 2024 Journal of Computer Engineering and Applications Beijing Co., Ltd.; Science Press. All rights reserved.},
	author_keywords = {knowledge graph; knowledge reasoning; large language model; public complaints; similarity retrieval},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Wang2024,
	author = {Wang, Li-C.},
	title = {LLM-Assisted Analytics in Semiconductor Test (Invited)},
	year = {2024},
	journal = {MLCAD 2024 - Proceedings of the 2024 ACM/IEEE International Symposium on Machine Learning for CAD},
	doi = {10.1145/3670474.3685974},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205018711&doi=10.1145%2f3670474.3685974&partnerID=40&md5=64430288bfaa4b010be7fa37f18173bd},
	abstract = {The emergence of Large Language Models (LLMs) has impacted our perspective on applying Machine Learning (ML) in semiconductor test. This paper shares our experience in leveraging the power of LLMs to build an AI agent for test data analytics. We advocate for an end-to-end approach where the Knowledge Graph (KG) plays a central role. Using wafermap analytics as an example, we highlight the key ideas behind developing the LLM-assisted AI agent named IEA-Plot, and discuss its practical applications. © 2024 Owner/Author.},
	author_keywords = {Knowledge Graph; Large Language Model; Machine Learning; Test Data Analytics},
	keywords = {Adversarial machine learning; Modeling languages; Semiconductor device testing; Data analytics; End to end; Knowledge graphs; Language model; Large language model; Machine-learning; Power; Semiconductor tests; Test data; Test data analytic; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Fu2024632,
	author = {Fu, Lingyue and Guan, Hao and Du, Kounianhua and Lin, Jianghao and Xia, Wei and Zhang, Weinan and Tang, Ruiming and Wang, Yasheng and Yu, Yong},
	title = {SINKT: A Structure-Aware Inductive Knowledge Tracing Model with Large Language Model},
	year = {2024},
	journal = {International Conference on Information and Knowledge Management, Proceedings},
	pages = {632 – 642},
	doi = {10.1145/3627673.3679760},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210008063&doi=10.1145%2f3627673.3679760&partnerID=40&md5=02c478a8a9bdcffeed8003a8a7de9ad3},
	abstract = {Knowledge Tracing (KT) aims to determine whether students will respond correctly to the next question, which is a crucial task in intelligent tutoring systems (ITS). In educational KT scenarios, transductive ID-based methods often face severe data sparsity and cold start problems, where interactions between individual students and questions are sparse, and new questions and concepts consistently arrive in the database. In addition, existing KT models only implicitly consider the correlation between concepts and questions, lacking direct modeling of the more complex relationships in the heterogeneous graph of concepts and questions. In this paper, we propose a <u>S</u>tructure-aware <u>IN</u>ductive <u>K</u>nowledge <u>T</u>racing model with large language model (dubbed SINKT), which, for the first time, introduces large language models (LLMs) and realizes inductive knowledge tracing. Firstly, SINKT utilizes LLMs to introduce structural relationships between concepts and constructs a hetero- geneous graph for concepts and questions. Secondly, by encoding concepts and questions with LLMs, SINKT incorporates semantic information to aid prediction. Finally, SINKT predicts the student's response to the target question by interacting with the student's knowledge state and the question representation. Experiments on four real-world datasets demonstrate that SINKT achieves state-of-the-art performance among 12 existing transductive KT models. Additionally, we explore the performance of SINKT on the inductive KT task and provide insights into various modules.  © 2024 ACM.},
	author_keywords = {inductive learning; knowledge tracing; online education},
	keywords = {Adversarial machine learning; Contrastive Learning; Federated learning; Intelligent systems; Knowledge graph; Self-supervised learning; Semantics; Teaching; Educational knowledge; ID-based; Inductive learning; Intelligent tutoring; Knowledge tracings; Language model; On-line education; Structure-aware; Tracing model; Tutoring system; Students},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Peng20245395,
	author = {Peng, Yiwen and Bonald, Thomas and Alam, Mehwish},
	title = {Refining Wikidata Taxonomy using Large Language Models},
	year = {2024},
	journal = {International Conference on Information and Knowledge Management, Proceedings},
	pages = {5395 – 5399},
	doi = {10.1145/3627673.3679156},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209994602&doi=10.1145%2f3627673.3679156&partnerID=40&md5=57a6d49ad71bff033c361143255f3043},
	abstract = {Due to its collaborative nature, Wikidata is known to have a complex taxonomy, with recurrent issues like the ambiguity between instances and classes, the inaccuracy of some taxonomic paths, the presence of cycles, and the high level of redundancy across classes. Manual efforts to clean up this taxonomy are time-consuming and prone to errors or subjective decisions. We present WiKC, a new version of Wikidata taxonomy cleaned automatically using a combination of Large Language Models (LLMs) and graph mining techniques. Operations on the taxonomy, such as cutting links or merging classes, are performed with the help of zero-shot prompting on an open-source LLM. The quality of the refined taxonomy is evaluated from both intrinsic and extrinsic perspectives, on a task of entity typing for the latter, showing the practical interest of WiKC.  © 2024 Owner/Author.},
	author_keywords = {graph mining; knowledge graphs; large language model},
	keywords = {Modeling languages; Taxonomies; Graph mining; Knowledge graphs; Language model; Large language model; Mining techniques; Open-source; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Colombo20245443,
	author = {Colombo, Andrea},
	title = {Leveraging Knowledge Graphs and LLMs to Support and Monitor Legislative Systems},
	year = {2024},
	journal = {International Conference on Information and Knowledge Management, Proceedings},
	pages = {5443 – 5446},
	doi = {10.1145/3627673.3680268},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210034513&doi=10.1145%2f3627673.3680268&partnerID=40&md5=5c17e45613e1989344ca762a8969bf15},
	abstract = {Knowledge Graphs (KGs) have been used to organize large datasets into structured, interconnected information, enhancing data analytics across various fields. In the legislative context, one potential natural application of KGs is modeling the intricate set of interconnections that link laws and their articles with each other and the broader legislative context. At the same time, the rise of large language models (LLMs) such as GPT has opened new opportunities in legal applications, such as text generation and document drafting. Despite their potential, the use of LLMs in legislative contexts is critical since it requires the absence of hallucinations and reliance on up-to-date information, as new laws are published on a daily basis. This work investigates how Legislative Knowledge Graphs and LLMs can synergize and support legislative processes. We address three key questions: the benefits of using KGs for legislative systems, how LLM can support legislative activities by ensuring an accurate output, and how we can allow non-technical users to use such technologies in their activities. To this aim, we develop Legis AI Platform, an interactive platform focused on Italian legislation that enhances the possibility of conducting legislative analysis and that aims to support lawmaking activities.  © 2024 Owner/Author.},
	author_keywords = {graphrag; knowledge graph; large language models; laws; legislative systems},
	keywords = {Laws and legislation; Natural language processing systems; Data analytics; Graphrag; Knowledge graphs; Language model; Large datasets; Large language model; Law; Legislative systems; Link law; Text generations; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Haris2024,
	author = {Haris, Erum and Cohn, Anthony G. and Stell, John G.},
	title = {Semantic Perspectives on the Lake District Writing: Spatial Ontology Modeling and Relation Extraction for Deeper Insights},
	year = {2024},
	journal = {Leibniz International Proceedings in Informatics, LIPIcs},
	volume = {315},
	doi = {10.4230/LIPIcs.COSIT.2024.11},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205767309&doi=10.4230%2fLIPIcs.COSIT.2024.11&partnerID=40&md5=19d2f1db0c2f32ffdd5c451e9a5f78ea},
	abstract = {Extracting spatial details from historical texts can be difficult, hindering our understanding of past landscapes. The study addresses this challenge by analyzing the Corpus of the Lake District Writing, focusing on the English Lake District region. We systematically link the theoretical notions from the core concepts of spatial information to provide basis for the problem domain. The conceptual foundation is further complemented with a spatial ontology and a custom gazetteer, allowing a formal and insightful semantic exploration of the massive unstructured corpus. The other contrasting side of the framework is the usage of LLMs for spatial relation extraction. We formulate prompts leveraging understanding of the LLMs of the intended task, curate a list of spatial relations representing the most recurring proximity or vicinity relations terms and extract semantic triples for the top five place names appearing in the corpus. We compare the extraction capabilities of three benchmark LLMs for a scholarly significant historical archive, representing their potential in a challenging and interdisciplinary research problem. Finally, the network comprising the semantic triples is enhanced by incorporating a gazetteer-based classification of the objects involved thus improving their spatial profiling. © Erum Haris, Anthony G. Cohn, and John G. Stell;},
	author_keywords = {large language models; ontology; spatial humanities; spatial narratives},
	keywords = {Benchmarking; Classification (of information); Economic and social effects; Modeling languages; Semantics; Text mining; Language model; Large language model; Ontology model; Ontology relations; Ontology's; Relation extraction; Spatial humanity; Spatial narratives; Spatial ontologies; Spatial relations; Ontology},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Tupayachi20242392,
	author = {Tupayachi, Jose and Xu, Haowen and Omitaomu, Olufemi A. and Camur, Mustafa Can and Sharmin, Aliza and Li, Xueping},
	title = {Towards Next-Generation Urban Decision Support Systems through AI-Powered Construction of Scientific Ontology Using Large Language Models—A Case in Optimizing Intermodal Freight Transportation},
	year = {2024},
	journal = {Smart Cities},
	volume = {7},
	number = {5},
	pages = {2392 – 2421},
	doi = {10.3390/smartcities7050094},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207278547&doi=10.3390%2fsmartcities7050094&partnerID=40&md5=3935736d17eec06666cbac8bad15f5db},
	abstract = {Highlights: What are the main findings? We have developed an integrated and automated methodology that leverages a pre-trained Large Language Model (LLM) to generate scenario-based ontologies and knowledge graphs from research articles and technical manuals. Our methodology utilizes the ChatGPT API as the primary reasoning engine, supplemented by Natural Language Processing modules and carefully engineered prompts. This combination enables an automated tool capable of generating ontologies independently. The ontologies generated through our AI-powered method are interoperable and can significantly facilitate the design of data models and software architecture, particularly in the development of urban decision support systems. What is the implication of the main finding? We compared ontologies generated by our LLM with those created by human experts through CQ-based qualitative evaluation, assessing the reliability and feasibility of our approach. The methodology has been successfully applied to intermodal freight data and simulations. This has allowed us to generate a scenario-based ontology and knowledge graph that enhances data discovery, integration, and management, thereby supporting network optimization and multiple criteria decision analysis. Our methodology is both generalizable and adaptive, enabling the automation of ontology generation to support the development of urban and environmental decision support systems across various disciplines. The incorporation of Artificial Intelligence (AI) models into various optimization systems is on the rise. However, addressing complex urban and environmental management challenges often demands deep expertise in domain science and informatics. This expertise is essential for deriving data and simulation-driven insights that support informed decision-making. In this context, we investigate the potential of leveraging the pre-trained Large Language Models (LLMs) to create knowledge representations for supporting operations research. By adopting ChatGPT-4 API as the reasoning core, we outline an applied workflow that encompasses natural language processing, Methontology-based prompt tuning, and Generative Pre-trained Transformer (GPT), to automate the construction of scenario-based ontologies using existing research articles and technical manuals of urban datasets and simulations. From these ontologies, knowledge graphs can be derived using widely adopted formats and protocols, guiding various tasks towards data-informed decision support. The performance of our methodology is evaluated through a comparative analysis that contrasts our AI-generated ontology with the widely recognized pizza ontology, commonly used in tutorials for popular ontology software. We conclude with a real-world case study on optimizing the complex system of multi-modal freight transportation. Our approach advances urban decision support systems by enhancing data and metadata modeling, improving data integration and simulation coupling, and guiding the development of decision support strategies and essential software components. © 2024 by the authors.},
	author_keywords = {artificial intelligence; intermodal freight transportation; large language models; ontology; urban decision support system},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Zhang20243300,
	author = {Zhang, Zhiqiang and Wen, Liqiang and Zhao, Wen},
	title = {A GAIL Fine-Tuned LLM Enhanced Framework for Low-Resource Knowledge Graph Question Answering},
	year = {2024},
	journal = {International Conference on Information and Knowledge Management, Proceedings},
	pages = {3300 – 3309},
	doi = {10.1145/3627673.3679753},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210010094&doi=10.1145%2f3627673.3679753&partnerID=40&md5=e83e2edb876e2dbacc691d88aa767c55},
	abstract = {Recent studies on knowledge graph question answering (KGQA) have focused on tackling complex inquiries to enhance the applicability of models in real-life settings. Unfortunately, KGQA models encounter significant challenges due to the lack of high-quality annotated data, making it difficult to accurately answer the diverse range of complex natural language questions posed by users. Inspired by the recent success of Large Language Models (LLMs), the burden associated with manual annotation can be mitigated by utilizing LLMs. However, the data generated directly by LLMs may exhibit a potential distribution discrepancy with real user queries. In this paper, we present an enhancement framework that utilizes Generative Adversarial Imitation Learning (GAIL) to fine-tune LLMs, which can address the challenges inherent in the low-resource KGQA task. Specifically, based on GAIL, the LLMs act as the generator aiming to output samples resembling expert demonstrations. Meanwhile, we utilize a paired discriminator to assess the authenticity of generated sequences and their relevance to the input SPARQL queries. Additionally, proximal policy optimization is leveraged to stabilize the training of the generator. Furthermore, we employ an automated algorithm to controllably sample various SPARQL queries from the knowledge graph, subsequently transforming them into corresponding natural language questions using fine-tuned LLMs. The synthetic dataset can serve as supplementary data for training lightweight KGQA models in real-world scenarios. Experimental results on the WebQuestionsSP, ComplexWebQuestions, and GrailQA show that our framework achieves state-of-the-art performance in a low-resource setting, even approaching the performance of supervised models.  © 2024 ACM.},
	author_keywords = {generative adversarial imitation learning; knowledge graph; large language model; question answering},
	keywords = {Adversarial machine learning; Contrastive Learning; Generative adversarial networks; Structured Query Language; Diverse range; Generative adversarial imitation learning; High quality; Imitation learning; Knowledge graphs; Language model; Large language model; Manual annotation; Natural language questions; Question Answering; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Liu20242901,
	author = {Liu, Jun and Leng, Fangling and Wu, Wangwang and Bao, Yubin},
	title = {Construction Method of Textbook Knowledge Graph Based on Multimodal and Knowledge Distillation; [基于多模态和知识蒸馏的教材知识图谱构建方法]},
	year = {2024},
	journal = {Journal of Frontiers of Computer Science and Technology},
	volume = {18},
	number = {11},
	pages = {2901 – 2911},
	doi = {10.3778/j.issn.1673-9418.2406054},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209896889&doi=10.3778%2fj.issn.1673-9418.2406054&partnerID=40&md5=436590ec36f2a18c3ed4deba040cb691},
	abstract = {In order to efficiently construct a multimodal subject knowledge graph in the field of education, a textbook text entity relationship extraction algorithm based on large model knowledge distillation and multi-model collaborative reasoning is proposed. During the model training phase, this paper uses a closed source model with 100 billion parameters to annotate text data and achieve implicit knowledge distillation. Then, this paper fine-tunes the domain data instructions for the open-source billion scale parameter model to enhance the instruction compliance ability of the entity relationship extraction task of the open-source model. In the model inference stage, the closed source model serves as the guiding model, and the open-source billion scale parameter model serves as the execution model. Experimental results show that knowledge distillation, multi-model collaboration, and domain data instruction fine-tuning are effective, significantly improving the effectiveness of textbook text entity relationship extraction tasks based on instruction prompts. A multimodal named entity recognition algorithm for textbook diagrams with explicit and implicit knowledge enhancement has been proposed. Firstly, this paper uses techniques such as image OCR (optical character recognition) and visual language modeling to extract textual information and global content description information from textbook diagrams. Then, by using explicit knowledge base retrieval and implicit LLM hint enhancement methods, auxiliary knowledge that may be associated with image title pairs is obtained. The knowledge obtained from explicit knowledge base and implicit LLM is further fused to form the final auxiliary knowledge. Finally, the auxiliary knowledge of the schematic diagram is combined with the schematic diagram title to achieve multimodal named entity recognition of the textbook schematic diagram title. Experimental results show that the algorithm is advanced and the interpretability of the algorithm is enhanced. © 2024 Journal of Computer Engineering and Applications Beijing Co., Ltd.; Science Press. All rights reserved.},
	author_keywords = {disciplinary knowledge graph; entity relationship extraction; knowledge distillation; large language model; multimodal named entity recognition},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Zhao20243320,
	author = {Zhao, Kaichen and Song, Yaoxian and Zhao, Haiquan and Liu, Haoyu and Li, Tiefeng and Li, Zhixu},
	title = {Towards Coarse-grained Visual Language Navigation Task Planning Enhanced by Event Knowledge Graph},
	year = {2024},
	journal = {International Conference on Information and Knowledge Management, Proceedings},
	pages = {3320 – 3330},
	doi = {10.1145/3627673.3679711},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210019974&doi=10.1145%2f3627673.3679711&partnerID=40&md5=3e76287b5b065af4fcb71e1be5707e17},
	abstract = {Visual language navigation (VLN) is one of the important research in embodied AI. It aims to enable an agent to understand the surrounding environment and complete navigation tasks. VLN instructions could be categorized into coarse-grained and fine-grained commands. Fine-grained command describes a whole task with subtasks step-by-step. In contrast, coarse-grained command gives an abstract task description, which more suites human habits. Most existing work focuses on the former kind of instruction in VLN tasks, ignoring the latter abstract instructions belonging to daily life scenarios. To overcome the above challenge in abstract instruction, we attempt to consider coarse-grained instruction in VLN by event knowledge enhancement. Specifically, we first propose a prompt-based framework to extract an event knowledge graph (named VLN-EventKG =) for VLN integrally over multiple mainstream benchmark datasets. Through small and large language model collaboration, we realize knowledge-enhanced navigation planning (named EventNav) for VLN tasks with coarse-grained instruction input. Additionally, we design a novel dynamic history backtracking module to correct potential error action planning in real time. Experimental results in various public benchmarks show our knowledge-enhanced method has superiority in coarse-grained-instruction VLN using our proposed VLN-EventKG with over 5% improvement in success rate. Our project is available at https://sites.google.com/view/vln-eventkg  © 2024 ACM.},
	author_keywords = {dynamic backtracking; event knowledge graph; knowledge retrieval; task planning; visual language navigation},
	keywords = {Benchmarking; Contrastive Learning; Visual languages; Coarse-grained; Dynamic backtracking; Event knowledge graph; Fine grained; Knowledge graphs; Knowledge retrieval; Navigation tasks; Surrounding environment; Task planning; Visual language navigation; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Yang20241156,
	author = {Yang, Junwei and Xu, Hanwen and Mirzoyan, Srbuhi and Chen, Tong and Liu, Zixuan and Liu, Zequn and Ju, Wei and Liu, Luchen and Xiao, Zhiping and Zhang, Ming and Wang, Sheng},
	title = {Poisoning medical knowledge using large language models},
	year = {2024},
	journal = {Nature Machine Intelligence},
	volume = {6},
	number = {10},
	pages = {1156 – 1168},
	doi = {10.1038/s42256-024-00899-3},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204498399&doi=10.1038%2fs42256-024-00899-3&partnerID=40&md5=0b8cc3a5c2c507fcb1ef911fd31aa91c},
	abstract = {Biomedical knowledge graphs (KGs) constructed from medical literature have been widely used to validate biomedical discoveries and generate new hypotheses. Recently, large language models (LLMs) have demonstrated a strong ability to generate human-like text data. Although most of these text data have been useful, LLM might also be used to generate malicious content. Here, we investigate whether it is possible that a malicious actor can use an LLM to generate a malicious paper that poisons medical KGs and further affects downstream biomedical applications. As a proof of concept, we develop Scorpius, a conditional text-generation model that generates a malicious paper abstract conditioned on a promoted drug and a target disease. The goal is to fool the medical KG constructed from a mixture of this malicious abstract and millions of real papers so that KG consumers will misidentify this promoted drug as relevant to the target disease. We evaluated Scorpius on a KG constructed from 3,818,528 papers and found that Scorpius can increase the relevance of 71.3% drug–disease pairs from the top 1,000 to the top ten by adding only one malicious abstract. Moreover, the generation of Scorpius achieves better perplexity than ChatGPT, suggesting that such malicious abstracts cannot be efficiently detected by humans. Collectively, Scorpius demonstrates the possibility of poisoning medical KGs and manipulating downstream applications using LLMs, indicating the importance of accountable and trustworthy medical knowledge discovery in the era of LLMs. © The Author(s), under exclusive licence to Springer Nature Limited 2024.},
	keywords = {Biomedical applications; Down-stream; Human like; Knowledge graphs; Language model; Medical knowledge; Medical literatures; Proof of concept; Text data; Text generations; Knowledge graph},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5}
}

@CONFERENCE{Zhang2024233,
	author = {Zhang, Yichi and Chen, Zhuo and Guo, Lingbing and Xu, Yajing and Zhang, Wen and Chen, Huajun},
	title = {Making Large Language Models Perform Better in Knowledge Graph Completion},
	year = {2024},
	journal = {MM 2024 - Proceedings of the 32nd ACM International Conference on Multimedia},
	pages = {233 – 242},
	doi = {10.1145/3664647.3681327},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209797603&doi=10.1145%2f3664647.3681327&partnerID=40&md5=5410fe1b731f7d6e35ae51ad023f6f66},
	abstract = {Large language model (LLM) based knowledge graph completion (KGC) aims to predict the missing triples in the KGs with LLMs. However, research about LLM-based KGC fails to sufficiently harness LLMs' inference proficiencies, overlooking critical structural information integral to KGs. In this paper, we explore methods to incorporate structural information into the LLMs, with the overarching goal of facilitating structure-aware reasoning. We first discuss on the existing LLM paradigms like in-context learning and instruction tuning, proposing basic structural information injection approaches. Then we propose a Knowledge Prefix Adapter (KoPA) to fulfill this stated goal. KoPA uses a structural pre-training phase to comprehend the intricate entities and relations within KGs, representing them as structural embeddings. Then KoPA communicates such cross-modal structural information understanding to the LLMs through a knowledge prefix adapter which projects the structural embeddings into the textual space and obtains virtual knowledge tokens positioned as a prefix of the input prompt. We conduct comprehensive experiments and provide incisive analysis. Our code and data are available at https://github.com/zjukg/KoPA. © 2024 ACM.},
	author_keywords = {cross-modal adapter; graph-text fusion; knowledge graph completion; knowledge graphs; large language models},
	keywords = {Graph embeddings; Modeling languages; Cross-modal; Cross-modal adapter; Graph-text fusion; Knowledge graph completion; Knowledge graphs; Language model; Large language model; Model-based OPC; Structural information; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Green Open Access}
}

@CONFERENCE{Zhang20243227,
	author = {Zhang, Tianli and Zheng, Tongya and Xiao, Zhenbang and Chen, Zulong and Li, Liangyue and Feng, Zunlei and Zhang, Dongxiang and Song, Mingli},
	title = {Language Models-enhanced Semantic Topology Representation Learning For Temporal Knowledge Graph Extrapolation},
	year = {2024},
	journal = {International Conference on Information and Knowledge Management, Proceedings},
	pages = {3227 – 3236},
	doi = {10.1145/3627673.3679602},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210042891&doi=10.1145%2f3627673.3679602&partnerID=40&md5=6afaa606eecd06d4391d388c47fd986d},
	abstract = {Temporal Knowledge Graph (TKG) extrapolation aims to predict future missing facts based on historical information, which has exhibited both semantics and topology of events. The mainstream methods have advanced the prediction performance by exploring the potential of topology representations of TKGs based on dedicated temporal Graph Neural Networks (GNNs). Until recently, few Language Models (LM) based methods have attempted to model the semantic representations of TKGs, however, lacking specific designs for the topology information. Therefore, we propose a Semantic TOpology REpresentation learning (STORE) framework enhanced by LMs to bridge the gap between the semantics and topology of TKGs. Firstly, we tackle the challenge of long historical facts modeling by a time-aware sampling based on semantic priors to extract concise yet precise facts. Secondly, we handle the challenge of the interaction between topology and semantics by transforming graph representations into virtual tokens that are then integrated with generated prompts and fed into LMs. Finally, multi-head attention is adopted to obtain better semantic topology representations, thereby achieving joint optimization of both temporal GNNs and LMs. Extensive experiments on five datasets show that our STORE outperforms state-of-the-art GNNs- and LM-based methods.  © 2024 ACM.},
	author_keywords = {knowledge graph reasoning; large language model; temporal knowledge graph},
	keywords = {Contrastive Learning; Graph neural networks; Latent semantic analysis; Semantics; Graph neural networks; Knowledge graph reasoning; Knowledge graphs; Language model; Large language model; Model-based method; Temporal graphs; Temporal knowledge; Temporal knowledge graph; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Pan20241836,
	author = {Pan, Bo and Zhang, Zheng and Zhang, Yifei and Hu, Yuntong and Zhao, Liang},
	title = {Distilling Large Language Models for Text-Attributed Graph Learning},
	year = {2024},
	journal = {International Conference on Information and Knowledge Management, Proceedings},
	pages = {1836 – 1845},
	doi = {10.1145/3627673.3679830},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210033827&doi=10.1145%2f3627673.3679830&partnerID=40&md5=e19eec2150b0c35d8d618559abab9ee1},
	abstract = {Text-Attributed Graphs (TAGs) are graphs of connected textual documents. Graph models can efficiently learn TAGs, but their training heavily relies on human-annotated labels, which are scarce or even unavailable in many applications. Large language models (LLMs) have recently demonstrated remarkable capabilities in few-shot and zero-shot TAG learning, but they suffer from scalability, cost, and privacy issues. Therefore, in this work, we focus on synergizing LLMs and graph models with their complementary strengths by distilling the power of LLMs into a local graph model on TAG learning. To address the inherent gaps between LLMs (generative models for texts) and graph models (discriminative models for graphs), we propose first to let LLMs teach an interpreter with rich rationale and then let a student model mimic the interpreter's reasoning without LLMs' rationale. We convert LLM's textual rationales to multi-level graph rationales to train the interpreter model and align the student model with the interpreter model based on the features of TAGs. Extensive experiments validate the efficacy of our proposed framework.  © 2024 ACM.},
	author_keywords = {knowledge distillation; large language models; text-attributed graphs},
	keywords = {Adversarial machine learning; Contrastive Learning; Knowledge graph; Students; Attributed graphs; Graph model; Knowledge distillation; Language model; Large language model; Learn+; Scalability issue; Student Modeling; Text-attributed graph; Textual documents; Zero-shot learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@CONFERENCE{Zhao20243341,
	author = {Zhao, Runhao and Tang, Jiuyang and Zeng, Weixin and Chen, Ziyang and Zhao, Xiang},
	title = {Zero-shot Knowledge Graph Question Generation via Multi-agent LLMs and Small Models Synthesis},
	year = {2024},
	journal = {International Conference on Information and Knowledge Management, Proceedings},
	pages = {3341 – 3351},
	doi = {10.1145/3627673.3679805},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210034805&doi=10.1145%2f3627673.3679805&partnerID=40&md5=7cef29bd2b1257027e63710712f06c23},
	abstract = {Knowledge Graph Question Generation (KGQG) is the task of generating natural language questions based on the given knowledge graph (KG). Although extensively explored in recent years, prevailing models predominantly depend on labelled data for training deep learning models or employ large parametric frameworks, e.g., Large Language Models (LLMs), which can incur significant deployment costs and pose practical implementation challenges. To address these issues, in this work, we put forward a zero-shot, multi-agent KGQG framework. This framework integrates the capabilities of LLMs with small models to facilitate cost-effective, high-quality question generation. In specific, we develop a professional editorial team architecture accompanied by two workflow optimization tools to reduce unproductive collaboration among LLMs-based agents and enhance the robustness of the system. Extensive experiments demonstrate that our proposed framework derives the new state-of-the-art performance on the zero-shot KGQG tasks, with relative gains of 20.24% and 13.57% on two KGQG datasets, respectively, which rival fully supervised state-of-the-art models.  © 2024 ACM.},
	author_keywords = {large language models; multi-agents framework; zero-shot knowledge graph question generation},
	keywords = {Adversarial machine learning; Deep learning; Zero-shot learning; Knowledge graphs; Labeled data; Language model; Large language model; Learning models; Model synthesis; Multi agent; Multiagent framework; Natural language questions; Zero-shot knowledge graph question generation; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Cho2024591,
	author = {Cho, Nicole and Srishankar, Nishan and Cecchi, Lucas and Watson, William},
	title = {FISHNET: Financial Intelligence from Sub-querying, Harmonizing, Neural-Conditioning, Expert Swarms, and Task Planning},
	year = {2024},
	journal = {ICAIF 2024 - 5th ACM International Conference on AI in Finance},
	pages = {591 – 599},
	doi = {10.1145/3677052.3698597},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213805851&doi=10.1145%2f3677052.3698597&partnerID=40&md5=3f91ca2b30177e10434421d99ca2eb7a},
	abstract = {Financial intelligence generation from vast data sources has typically relied on traditional methods of knowledge-graph construction or database engineering. Recently, fine-tuned financial domain-specific Large Language Models (LLMs), have emerged. While these advancements are promising, limitations such as high inference costs, hallucinations, and the complexity of concurrently analyzing high-dimensional financial data, emerge. This motivates our invention FISHNET (Financial Intelligence from Sub-querying, Harmonizing, Neural-Conditioning, Expert swarming, and Task planning), an agentic architecture that accomplishes highly complex analytical tasks for more than 98,000 regulatory filings that vary immensely in terms of semantics, data hierarchy, or format. FISHNET shows remarkable performance for financial insight generation (61.8% success rate over 5.0% Routing, 45.6% RAG R-Precision). We conduct rigorous ablations to empirically prove the success of FISHNET, each agent's importance, and the optimized performance of assembling all agents. Our modular architecture can be leveraged for a myriad of use-cases, enabling scalability, flexibility, and data integrity that are critical for financial tasks.  © 2024 ACM.},
	author_keywords = {Harmonizing; LLM Agents; Planning; Sub-querying; Swarming},
	keywords = {Data integrity; Financial data processing; Knowledge graph; Metadata; Query languages; Structured Query Language; Data-source; Graph construction; Harmonizing; Knowledge graphs; Language model; Large language model agent; Model agents; Sub-querying; Swarming; Task planning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Bronze Open Access, Green Open Access}
}

@ARTICLE{Chi2024,
	author = {Chi, Te-Yu and Jang, Jyh-Shing Roger},
	title = {WC-SBERT: Zero-Shot Topic Classification Using SBERT and Light Self-Training on Wikipedia Categories},
	year = {2024},
	journal = {ACM Transactions on Intelligent Systems and Technology},
	volume = {15},
	number = {5},
	doi = {10.1145/3678183},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209937566&doi=10.1145%2f3678183&partnerID=40&md5=8ddac4e7102db7a9c47fdb583f307094},
	abstract = {In natural language processing (NLP), zero-shot topic classification requires machines to understand the contextual meanings of texts in a downstream task without using the corresponding labeled texts for training, which is highly desirable for various applications. In this article, we propose a novel approach to construct a zero-shot task-specific model called WC-SBERT with satisfactory performance. The proposed approach is highly efficient since it uses light self-training requiring target labels (target class names of downstream tasks) only, which is distinct from other research that uses both the target labels and the unlabeled texts for training. In particular, during the pre-training stage, WC-SBERT uses contrastive learning with multiple negative ranking losses to construct the pre-trained model based on the similarity between Wiki categories. For the self-training stage, online contrastive loss is utilized to reduce the distance between a target label and Wiki categories of similar Wiki pages to the label. Experimental results indicate that compared to existing self-training models, WC-SBERT achieves rapid inference on approximately 6.45 million Wiki text entries by utilizing pre-stored Wikipedia text embeddings, significantly reducing inference time per sample by a factor of 2,746 to 16,746. During the fine-tuning step, the time required for each sample is reduced by a factor of 23-67. Overall, the total training time shows a maximum reduction of 27.5 times across different datasets. Most importantly, our model has achieved state-of-the-art (SOTA) accuracy on two of the three commonly used datasets for evaluating zero-shot classification, namely the AG News (0.84) and Yahoo! Answers (0.64) datasets. The code for WC-SBERT is publicly available on GitHub,1 and the dataset can also be accessed on Hugging Face.  © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.},
	author_keywords = {Contrastive learning; Knowledge graph; LLM; SBERT; Self-training; Wikipedia; Zero-shot topic classification},
	keywords = {Classification (of information); Knowledge graph; Natural language processing systems; Text processing; Zero-shot learning; Down-stream; Knowledge graphs; LLM; Natural languages; SBERT; Self-training; Target labels; Topic Classification; Wikipedia; Zero-shot topic classification; Contrastive Learning},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Yu202416,
	author = {Yu, Yunlong and Bai, Bing and Chen, Shiji and Qiu, Junping and Ding, Jingda},
	title = {Mining Connotation of New Quality Productive Forces Based on Large Language Models; [基于大语言模型的新质生产力内涵特征挖掘研究]},
	year = {2024},
	journal = {Journal of Modern Information},
	volume = {44},
	number = {11},
	pages = {16 – 26},
	doi = {10.3969/j.issn.1008-0821.2024.11.003},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208217530&doi=10.3969%2fj.issn.1008-0821.2024.11.003&partnerID=40&md5=727ca30179d73bb6154b7423f58d4921},
	abstract = {[Purpose/ Significance] Revealing the characteristics and structure of New Quality Productivity(NQP), deeply understand the essential meaning of NQP. [Method/ Process] First, the paper summarized the core connotations of NQP from the important speeches of President Xi Jinping. Second, extracted keywords from the full texts of papers related to NQP using the large language model ERNIE-bot 4. 0. Subsequently, a stochastic block model was applied to explore the structural equivalence of NQP keyword co-occurrence network. Third, displayed connotations of NQP and their structure with knowledge graph technology. Finally, discussed the hierarchical structure of the core connotations of NQP. [Result/ Conclusion] Studies on NQP closely revolve around the core connotations of Xi Jinping NQP theory. The full-text keyword co-occurrence network shows a core-periphery structure, with keywords in the center representing the core connotations of NQP. Technology innovation and high-quality development occupy the core position of co-word network, forming the primary connotations of NQP and being the core content of academic research. Keywords such as digital technology, data elements, strategic emerging industries, future industries, talent cultivation, and green development are in the secondary core positions in the co-word network. Results of the word frequency and combination relationship networks further suggest that digital technology and data elements are crucial connotations of NQP and focal points of related studies. Strategic emerging industries and future industries represent major connotations of NQP and are key research topics. Talent resources and green development are important extensions of NQP core connotations and are significant topics in studies. Additionally, the scope of NQP studies is extensive covering areas such as governance systems and open-door policies, which are top-level design requirements for NQP high-quality development. © 2024 Editorial Board of Journal of Modern Information. All rights reserved.},
	author_keywords = {digital and intelligent technology; full-text analysis; high-level innovation; low-carbon development; talent systems},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Kong202435,
	author = {Kong, Xiangxing and Li, Yangyang and Fan, Manyi and Shi, Jiayi and Wei, Lingxiang and Qu, Shaojie},
	title = {Automated Knowledge Mining and Knowledge Graph Reasoning for Aircraft Engine Maintenance},
	year = {2024},
	journal = {ACM International Conference Proceeding Series},
	pages = {35 – 40},
	doi = {10.1145/3689218.3689221},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207088272&doi=10.1145%2f3689218.3689221&partnerID=40&md5=02b99d188124d6a3f1573bf2e2484ad5},
	abstract = {The maintenance process for aircraft engines is fraught with significant challenges due to their inherent complexity. Large Language Models excel in general Natural Language Processing tasks, yet they lack domain-specific knowledge, thereby compromising their performance in specialized areas. The varied descriptions of engine faults also render traditional text matching algorithms unsuitable for this maintenance domain. In this paper, we construct a knowledge graph integrated with fault diagnosis reasoning ability with knowledge mined from aircraft engine maintenance data. Firstly, we propose the Knowledge Mining and Knowledge Graph Reasoning framework for aircraft engine maintenance data knowledge mining and aircraft engine fault diagnosis. Secondly, we utilize prompt with in-context learning to mitigate the issue of the model lacking expertise in the field of aircraft engine maintenance. Finally, we adopt a sentence similarity calculation method based on BERT, which enables more effective processing of semantic information. We apply our method to Aircraft Engine Fault dataset which is collected from maintenance records of civil aircraft engine since 2007 to 2015, and experimental results demonstrate the effectiveness of our knowledge mining method and aircraft engine fault reasoning algorithm. © 2024 ACM.},
	author_keywords = {aircraft engine maintenance; knowledge graph reasoning; large language model},
	keywords = {Knowledge graph; Metadata; Modeling languages; Natural language processing systems; Aircraft engine maintenance; Excel; Faults diagnosis; Inherent complexity; Knowledge graph reasoning; Knowledge graphs; Knowledge mining; Language model; Large language model; Maintenance process; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Anand202456,
	author = {Anand, Avinash and Nair, Ashwin R and Prasad, Kritarth and Narayan, Vrinda and Lal, Naman and Mahata, Debanjan and Singla, Yaman K and Shah, Rajiv Ratn},
	title = {Advances in Citation Text Generation: Leveraging Multi-Source Seq2Seq Models and Large Language Models},
	year = {2024},
	journal = {International Conference on Information and Knowledge Management, Proceedings},
	pages = {56 – 64},
	doi = {10.1145/3627673.3679783},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210035453&doi=10.1145%2f3627673.3679783&partnerID=40&md5=552eb7df9db0872fdcebf2f3e9958fd7},
	abstract = {Citation Text Generation (CTG) in scientific documents often relies on standard summarization techniques, which may not fully capture the nuanced relationship between the citing and cited papers. To address this, we present a Multi-Source Citation Text Generation (M-CTG) architecture, leveraging a Seq2Seq transformer framework enhanced with keyphrase embeddings, graph embeddings, and text representations. This approach aims to produce more contextually relevant and accurate citation texts by integrating multiple sources of information. Our methodology is tested using the newly created CTG-S2ORC dataset, consisting of English-language computer science research papers. In a comparative analysis, we explore the performance of traditional Language Models (LMs) and demonstrate how Large Language Models (LLMs), particularly when integrated with various prompting techniques and Knowledge Graphs, offer superior capabilities in analyzing and generating citation texts. In addition to traditional evaluation metrics, we introduce a custom metric that emphasizes the overlap of key terms and semantic similarity, providing a more comprehensive assessment of our model's performance. Our code and data are available at https://github.com/midas-research/M-CTG/tree/main.  © 2024 ACM.},
	author_keywords = {citation text generation; graph embeddings; knowledge graphs; language models; large language models; S2ORC},
	keywords = {Knowledge graph; Semantics; Citation text generation; Graph embeddings; Knowledge graphs; Language model; Large language model; Multi-Sources; S2ORC; Scientific documents; Text generations; Graph embeddings},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Li2024,
	author = {Li, Jun and Qian, Lu and Liu, Peifeng and Liu, Taoxiong},
	title = {Construction of Legal Knowledge Graph Based on Knowledge-Enhanced Large Language Models},
	year = {2024},
	journal = {Information (Switzerland)},
	volume = {15},
	number = {11},
	doi = {10.3390/info15110666},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210243535&doi=10.3390%2finfo15110666&partnerID=40&md5=61384415bb69c1eea08d4d78bb5bde09},
	abstract = {Legal knowledge involves multidimensional heterogeneous knowledge such as legal provisions, judicial interpretations, judicial cases, and defenses, which requires extremely high relevance and accuracy of knowledge. Meanwhile, the construction of a legal knowledge reasoning system also faces challenges in obtaining, processing, and sharing multisource heterogeneous knowledge. The knowledge graph technology, which is a knowledge organization form with triples as the basic unit, is able to efficiently transform multisource heterogeneous information into a knowledge representation form close to human cognition. Taking the automated construction of the Chinese legal knowledge graph (CLKG) as a case scenario, this paper presents a joint knowledge enhancement model (JKEM), where prior knowledge is embedded into a large language model (LLM), and the LLM is fine-tuned through the prefix of the prior knowledge data. Under the condition of freezing most parameters of the LLM, this fine-tuning scheme adds continuous deep prompts as prefix tokens to the input sequences of different layers, which can significantly improve the accuracy of knowledge extraction. The results show that the knowledge extraction accuracy of the JKEM in this paper reaches (Formula presented.). Based on the superior performance of this model, the CLKG is further constructed, which contains 3480 knowledge triples composed of 9 entities and 2 relationships, providing strong support for an in-depth understanding of the complex relationships in the legal field. © 2024 by the authors.},
	author_keywords = {domain knowledge graph; knowledge engineering; knowledge extraction; large language model; legal knowledge},
	keywords = {Domain Knowledge; Domain knowledge; Domain knowledge graph; Heterogeneous Knowledge; Knowledge extraction; Knowledge graphs; Language model; Large language model; Legal knowledge; Multi-Sources; Prior-knowledge; Knowledge graph},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Ghajari2024271,
	author = {Ghajari, Adrián and Ros, Salvador and Pérez, Álvaro},
	title = {Querying the Depths: Unveiling the Strengths and Struggles of Large Language Models in SPARQL Generation; [Explorando las Profundidades: Revelando las Fortalezas y Desafíos de los Modelos de Lenguaje de Gran Escala en la Generación de SPARQL]},
	year = {2024},
	journal = {Procesamiento del Lenguaje Natural},
	number = {73},
	pages = {271 – 281},
	doi = {10.26342/2024-73-20},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206510658&doi=10.26342%2f2024-73-20&partnerID=40&md5=65474a178c3faf6cc013180b27942e98},
	abstract = {The emergence of the Semantic Web has precipitated a proliferation of structured data manifested in the form of knowledge graphs, underscoring the imperative of natural language interfaces to enhance accessibility to these repositories of information. The capacity to articulate queries in natural language and subsequently retrieve data through SPARQL queries assumes paramount importance. In the present investigation, we have scrutinized the efficacy of in-context learning based on an agent-based architecture in facilitating the construction of SPARQL queries. Contrary to initial expectations, the augmentation of in-context learning prompts through agent-based mechanisms has been found to diminish the efficacy of Language Model-based Systems (LLMS), as it is perceived as extraneous”noise,” thereby delineating the constraints inherent in this approach. The results highlight the need to delve deeper into the intricacies of model training and fine-tuning, focusing on the relational aspects of ontology schemas. © 2024 Sociedad Española para el Procesamiento del Lenguaje Natural.},
	author_keywords = {Agents; Knowledge Retrieval; Prompt Engineering; SPARQL Queries},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{2024,
	title = {32nd International Symposium on Graph Drawing and Network Visualization, GD 2024},
	year = {2024},
	journal = {Leibniz International Proceedings in Informatics, LIPIcs},
	volume = {320},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208781574&partnerID=40&md5=c165a8efba653134667a0663d0b05d3b},
	abstract = {The proceedings contain 59 papers. The topics discussed include: how can biclique covers help in matching problems; how can algorithms help in protecting our privacy; the Euclidean MST-ratio for bi-colored lattices; holes in convex and simple drawings; 1-planar unit distance graphs; the density formula: one lemma to bound them all; partitioning complete geometric graphs on dense point sets into plane subgraphs; constrained outer-string representations; monotone arc diagrams with few Biarcs; the parameterized complexity of extending stack layouts; knowledge graph builder – constructing a graph from arbitrary text using an LLM; and evolutionary algorithms for one-sided bipartite crossing minimization.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Al Shuraiqi2024,
	author = {Al Shuraiqi, Somaiya and Aal Abdulsalam, Abdulrahman and Masters, Ken and Zidoum, Hamza and AlZaabi, Adhari},
	title = {Automatic Generation of Medical Case-Based Multiple-Choice Questions (MCQs): A Review of Methodologies, Applications, Evaluation, and Future Directions},
	year = {2024},
	journal = {Big Data and Cognitive Computing},
	volume = {8},
	number = {10},
	doi = {10.3390/bdcc8100139},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207495519&doi=10.3390%2fbdcc8100139&partnerID=40&md5=aca9dbdc169459ee2a125aa481fe026a},
	abstract = {This paper offers an in-depth review of the latest advancements in the automatic generation of medical case-based multiple-choice questions (MCQs). The automatic creation of educational materials, particularly MCQs, is pivotal in enhancing teaching effectiveness and student engagement in medical education. In this review, we explore various algorithms and techniques that have been developed for generating MCQs from medical case studies. Recent innovations in natural language processing (NLP) and machine learning (ML) for automatic language generation have garnered considerable attention. Our analysis evaluates and categorizes the leading approaches, highlighting their generation capabilities and practical applications. Additionally, this paper synthesizes the existing evidence, detailing the strengths, limitations, and gaps in current practices. By contributing to the broader conversation on how technology can support medical education, this review not only assesses the present state but also suggests future directions for improvement. We advocate for the development of more advanced and adaptable mechanisms to enhance the automatic generation of MCQs, thereby supporting more effective learning experiences in medical education. © 2024 by the authors.},
	author_keywords = {automatic question generation (AQG); case-based multiple-choice questions (MCQs); deep learning (DL); large language model (LLM); machine learning (ML); natural language processing (NLP); ontology},
	keywords = {Adversarial machine learning; Contrastive Learning; Deep learning; Natural language processing systems; Question answering; Automatic question generation; Case based; Case-based multiple-choice question; Deep learning; Language model; Language processing; Large language model; Machine learning; Machine-learning; Multiple-choice questions; Natural language processing; Natural languages; Ontology's; Medical education},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@CONFERENCE{Tachioka20241142,
	author = {Tachioka, Yuuki},
	title = {User Knowledge Prompt for Sequential Recommendation},
	year = {2024},
	journal = {RecSys 2024 - Proceedings of the 18th ACM Conference on Recommender Systems},
	pages = {1142 – 1146},
	doi = {10.1145/3640457.3691714},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210512688&doi=10.1145%2f3640457.3691714&partnerID=40&md5=969e92d523198746d5f3d5b0ec4f3016},
	abstract = {The large language model (LLM) based recommendation system is effective for sequential recommendation, because general knowledge of popular items is included in the LLM. To add domain knowledge of items, the conventional method uses a knowledge prompt obtained from the item knowledge graphs and has achieved SOTA performance. However, for personalized recommendation, it is necessary to consider user knowledge, which the conventional method does not fully consider because user knowledge is not included in the item knowledge graphs; thus, we propose a user knowledge prompt, which converts a user knowledge graph into a prompt using the relationship template. The existing prompt denoising framework is extended to prevent hallucination caused by undesirable interactions between knowledge graph prompts. We propose user knowledge prompts of user traits and user preferences and associate relevant items. Experiments on three types of dataset (movie, music, and book) show the significant and consistent improvement of our proposed user knowledge prompt. © 2024 Copyright held by the owner/author(s).},
	author_keywords = {collaborative filtering; LLM; personalization; sequential recommendation; user knowledge graph},
	keywords = {Collaborative filtering; Conventional methods; General knowledge; Knowledge graphs; Language model; Large language model; Model-based OPC; Personalizations; Sequential recommendation; User knowledge; User knowledge graph; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Bronze Open Access}
}

@CONFERENCE{Göbel2024602,
	author = {Göbel, Susanne and Lämmel, Ralf},
	title = {Model-Based Trust Analysis of LLM Conversations},
	year = {2024},
	journal = {Proceedings: MODELS 2024 - ACM/IEEE 27th International Conference on Model Driven Engineering Languages and Systems: Companion Proceedings},
	pages = {602 – 610},
	doi = {10.1145/3652620.3687809},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212209635&doi=10.1145%2f3652620.3687809&partnerID=40&md5=4e0729f6af78bf731faeda3147273172},
	abstract = {LLM-based chatbots are routinely advertised as supporting the collaboration of humans and AI. We study LLM conversations from a knowledge elicitation perspective with the objective of being able to understand and assess the human’s trust in knowledge elicited from the LLM and complementary sources. Our approach is supported by the DSML KEML, the Knowledge Elicitation Modeling Language, subject to abstract and visual syntax as well as a model transformation-based model semantics for trust analysis. Conversations are modeled by a combination of sequence diagrams and enhanced argumentation graphs — the latter for the purpose of relating information pieces (facts and instructions) that are extracted from messages. The analysis of the corresponding models entails trust scores for gathered information (i.e., elicited knowledge). © 2024 Copyright held by the owner/author(s).},
	author_keywords = {DSMLs for AI usage; Knowledge representation models; MDE for AI; Model-based analysis of LLMs},
	keywords = {Knowledge graph; Semantics; Abstract syntax; Chatbots; DSML for AI usage; Knowledge representation model; Knowledge-representation; MDE for AI; Model-based analysis; Model-based analyze of LLM; Model-based OPC; Representation model; Chatbots},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Mulayim2024312,
	author = {Mulayim, Ozan Baris and Paul, Lazlo and Pritoni, Marco and Prakash, Anand Krishnan and Sudarshan, Malavikha and Fierro, Gabe},
	title = {Large Language Models for the Creation and Use of Semantic Ontologies in Buildings: Requirements and Challenges},
	year = {2024},
	journal = {BuildSys 2024 - Proceedings of the 2024 11th ACM International Conference on Systems for Energy-Efficient Buildings, Cities, and Transportation},
	pages = {312 – 317},
	doi = {10.1145/3671127.3698792},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211353946&doi=10.1145%2f3671127.3698792&partnerID=40&md5=89e1120f58e8e0a0ef8bfa96da69a369},
	abstract = {Semantic ontologies offer a formalized, machine-readable framework for representing knowledge, enabling the structured description of complex systems. In the building domain, the adoption of ontologies like the Brick schema has transformed how buildings and their systems are modeled by providing a standardized, interoperable language. However, the complexity and the steep learning curve involved in developing and querying semantic models present substantial challenges, often requiring a workforce with specialized expertise. This paper builds on our experience in investigating how Large Language Models (LLMs) can help address these challenges, focusing on their role in constructing and querying of semantic models, particularly using the Brick Schema. Our study outlines the requirements and metrics for evaluating the scalability and effectiveness of LLM-based tools, while also discussing the current challenges and limitations in developing such tools. Ultimately, this paper aims to orient research efforts as various groups experiment with diverse techniques, while enabling more effective comparison of emerging solutions and fostering collaboration across the field. © 2024 Copyright held by the owner/author(s).},
	author_keywords = {Knowledge Graphs; Large Language Models; Semantic Ontology},
	keywords = {Brick; Knowledge graph; Latent semantic analysis; Ontology; Query languages; Semantics; Building requirements; In-buildings; Knowledge graphs; Language model; Large language model; Ontology's; Querying semantics; Semantic modelling; Semantic ontology; Steep learning curve; Structured Query Language},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{2024,
	title = {Proceedings - 2024 6th International Conference on Pattern Recognition and Intelligent Systems, PRIS 2024},
	year = {2024},
	journal = {ACM International Conference Proceeding Series},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207202619&partnerID=40&md5=2026266eb77b2973636a5589be369dbe},
	abstract = {The proceedings contain 15 papers. The topics discussed include: power large language model exploration: activation, measurement and enhancement for operations and maintenance knowledge; transformer fault diagnosis based on IESOA-ELM and SMOTE; EFRAG: embedding-fine tuning retrieval augmented generation for QA in power projects; two-level data sharing method based on classification and grading watermark identification; automated knowledge mining and knowledge graph reasoning for aircraft engine maintenance; DTCNA-Net: dual temporal convolutional neural network with noise estimation and attention mechanism for intelligent fault diagnosis under the complex noise environment; study of incremental photoelectric encoder error compensation based on WSO-GRU; and challenge and practice of intelligent high continuity service for navigation satellite.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Chen2024,
	author = {Chen, Minze and Tao, Zhenxiang and Tang, Weitong and Qin, Tingxin and Yang, Rui and Zhu, Chunli},
	title = {Enhancing emergency decision-making with knowledge graphs and large language models},
	year = {2024},
	journal = {International Journal of Disaster Risk Reduction},
	volume = {113},
	doi = {10.1016/j.ijdrr.2024.104804},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205304342&doi=10.1016%2fj.ijdrr.2024.104804&partnerID=40&md5=d513611c9f2491068262b747717158cb},
	abstract = {Emergency management urgently requires comprehensive knowledge while having a high possibility to go beyond individuals’ cognitive scope. Therefore, artificial intelligence(AI) supported decision-making under that circumstance is of vital importance. Recent emerging large language models (LLM) provide a new direction for enhancing targeted machine intelligence. However, the utilization of LLM directly would inevitably introduce unreliable output for its inherent issue of hallucination and poor reasoning skills. In this work, we develop a system called Enhancing Emergency decision-making with Knowledge Graph and LLM (E-KELL), which provides evidence-based decision-making in various emergency stages. The study constructs a structured emergency knowledge graph and guides LLMs to reason over it via a prompt chain. In real-world evaluations, E-KELL demonstrates significant improvement over baseline models in various emergency response scenarios, as rated by emergency commanders and firefighters. This work introduces a novel approach to applying LLMs to enhance emergency decision-making. © 2024 Elsevier Ltd},
	author_keywords = {Decision support system; Emergency decision support; Knowledge graph; Large language model},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Green Open Access}
}

@CONFERENCE{Vakaj20245596,
	author = {Vakaj, Edlira and Mihindukulasooriya, Nandana and Gaur, Manas and Khan, Arijit},
	title = {Knowledge Graphs for Responsible AI},
	year = {2024},
	journal = {International Conference on Information and Knowledge Management, Proceedings},
	pages = {5596 – 5598},
	doi = {10.1145/3627673.3679085},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210000782&doi=10.1145%2f3627673.3679085&partnerID=40&md5=9095afe45c304210adbf021bc4a4082c},
	abstract = {Responsible AI is built upon a set of principles that prioritize fairness, transparency, accountability, and inclusivity in AI development and deployment. As AI systems become increasingly sophisticated, including the explosion of generative AI, there is a growing need to address ethical considerations and potential societal impacts of their uses. Knowledge graphs (KGs), as structured representations of information, can enhance generative AI performance by providing context, explaining outputs, and reducing biases, thereby offering a powerful framework to address the challenges of responsible AI. By leveraging semantic relationships and contextual understanding, KGs facilitate transparent decision-making, enabling stakeholders to trace and interpret the reasoning behind AI driven outcomes. Moreover, they provide a means to capture and manage diverse knowledge sources, supporting the development of fair and unbiased AI models. The workshop aims to investigate the role of knowledge graphs in promoting responsible AI principles and creating a cooperative space for researchers, practitioners, and policymakers to exchange insights and enhance their comprehension of KGs' impact on achieving responsible AI solutions. It seeks to facilitate collaboration and idea-sharing to advance the understanding of how KGs can contribute to responsible AI.  © 2024 Owner/Author.},
	author_keywords = {bias mitigation; ethical AI; fairness; interpretability; knowledge graphs; large language models; privacy; responsible AI},
	keywords = {AI systems; Bias mitigation; Ethical AI; Fairness; Interpretability; Knowledge graphs; Language model; Large language model; Privacy; Responsible AI; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Zhao20241,
	author = {Zhao, Jinxiong and Ma, Zhicheng and Zhao, Hong and Zhang, Xun and Liu, Qichuan and Peng, Xinjie and Zhang, Gefei},
	title = {Power Large Language Model Exploration: Activation, Measurement and Enhancement for Operations and Maintenance Knowledge: Activation, Measurement and Enhancement for Power O&M Knowledge},
	year = {2024},
	journal = {ACM International Conference Proceeding Series},
	pages = {1 – 7},
	doi = {10.1145/3689218.3689222},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207082118&doi=10.1145%2f3689218.3689222&partnerID=40&md5=6cfb157c89b7a2ad1b93f6b23ab32acb},
	abstract = {With the rapid advancement of Large Language Models, their applications are gradually transitioning from general to specific domains. However, the application of LLM in the electric power domain is still in its early stages, and few studies have explored power LLM. Currently, there are two main challenges against power LLMs: (1) determining how to measure the real power knowledge capacity of LLMs to facilitate targeted enhancement of specific knowledge. (2) identifying practical enhancement methods to facilitate efficient and feasible power LLM applications in real-world scenarios. In this paper, we ask three insightful questions that address the power knowledge capacity of LLMs and then draw inspiration from Reflexion and CoT to design an Activation, Measurement and Enhancement framework (AME) for power operations and maintenance (O&M) knowledge. Specifically, we ask three "HOW"questions based on the activation, measurement, and enhancement of power O&M knowledge. We introduce a Reflexion Module to discover the knowledge capacity of LLM and a Knowledge Graph Module to provide external knowledge of LLM in our proposed AME. Experiments on the real-world dataset provide strong evidence when we answer the above three insightful questions. © 2024 ACM.},
	author_keywords = {Power Large Language Model; Power Operations and Maintenance; Practical Knowledge Graph; Reflexion},
	keywords = {Activation measurements; Knowledge graphs; Language model; Operations and maintenance; Power; Power large language model; Power operation; Power operation and maintenance; Practical knowledge graph; Reflexion; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Kollegger2024,
	author = {Kollegger, Andreas Benno and Erdl, Alexander and Hunger, Michael},
	title = {Knowledge Graph Builder - Constructing a Graph from Arbitrary Text Using an LLM},
	year = {2024},
	journal = {Leibniz International Proceedings in Informatics, LIPIcs},
	volume = {320},
	doi = {10.4230/LIPIcs.GD.2024.61},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208810171&doi=10.4230%2fLIPIcs.GD.2024.61&partnerID=40&md5=da533679434804e296f324ecf27fe63f},
	abstract = {Knowledge graphs improve many information retrieval tasks over structured and unstructured data. However, knowledge graph construction can be challenging even for domain experts. The Knowledge Graph Builder is an application incorporating advanced techniques for deriving a knowledge graph from unstructured data using an LLM. © Andreas Benno Kollegger, Alexander Erdl, and Michael Hunger.},
	author_keywords = {Knowledge Graph; Lexical Graph},
	keywords = {Domain Knowledge; Domain experts; Graph construction; Knowledge graphs; Lexical graph; Structured data; Unstructured data; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Wang2024,
	author = {Wang, Yongtao and Feng, Yinhui and Xi, Chengfeng and Wang, Bochao and Tang, Bo and Geng, Yanzhao},
	title = {Development of an Intelligent Coal Production and Operation Platform Based on a Real-Time Data Warehouse and AI Model},
	year = {2024},
	journal = {Energies},
	volume = {17},
	number = {20},
	doi = {10.3390/en17205205},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207346966&doi=10.3390%2fen17205205&partnerID=40&md5=0d8a15d9bcb6c03a2603102ca435d535},
	abstract = {Smart mining solutions currently suffer from inadequate big data support and insufficient AI applications. The main reason for these limitations is the absence of a comprehensive industrial internet cloud platform tailored for the coal industry, which restricts resource integration. This paper presents the development of an innovative platform designed to enhance safety, operational efficiency, and automation in fully mechanized coal mining in China. This platform integrates cloud edge computing, real-time data processing, and AI-driven analytics to improve decision-making and maintenance strategies. Several AI models have been developed for the proactive maintenance of comprehensive mining face equipment, including early warnings for periodic weighting and the detection of common faults such as those in the shearer, hydraulic support, and conveyor. The platform leverages large-scale knowledge graph models and Graph Retrieval-Augmented Generation (GraphRAG) technology to build structured knowledge graphs. This facilitates intelligent Q&A capabilities and precise fault diagnosis, thereby enhancing system responsiveness and improving the accuracy of fault resolution. The practical process of implementing such a platform primarily based on open-source components is summarized in this paper. © 2024 by the authors.},
	author_keywords = {cloud–edge collaboration; knowledge base; large language model (LLM); massively parallel processing (MPP) database; real-time data warehouse; retrieval-augmented generation (RAG); stream processing},
	keywords = {Coal mines; Hydraulic equipment; Knowledge graph; Mine safety; Mining equipment; Cloud–edge collaboration; Knowledge base; Knowledge graphs; Language model; Large language model; Massively parallel processing; Massively parallel processing  database; Real-time data warehouse; Retrieval-augmented generation; Stream processing; Coal industry},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Ali2024929,
	author = {Ali, Zafar and Qi, Guilin and Ullah, Irfan and Mohammed, Adam A.Q. and Kefalas, Pavlos and Muhammad, Khan},
	title = {GLAMOR: Graph-based LAnguage MOdel embedding for citation Recommendation},
	year = {2024},
	journal = {RecSys 2024 - Proceedings of the 18th ACM Conference on Recommender Systems},
	pages = {929 – 933},
	doi = {10.1145/3640457.3688171},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210483033&doi=10.1145%2f3640457.3688171&partnerID=40&md5=cb84a8e8d4b961be1c97ea2fde72f548},
	abstract = {Digital publishing’s exponential growth has created vast scholarly collections. Guiding researchers to relevant resources is crucial, and knowledge graphs (KGs) are key tools for unlocking hidden knowledge. However, current methods focus on external links between concepts, ignoring the rich information within individual papers. Challenges like insufficient multi-relational data, name ambiguity, and cold-start issues further limit existing KG-based methods, failing to capture the intricate attributes of diverse entities. To solve these issues, we propose GLAMOR, a robust KG framework encompassing entities e.g., authors, papers, fields of study, and concepts, along with their semantic interconnections. GLAMOR uses a novel random walk-based KG text generation method and then fine-tunes the language model using the generated text. Subsequently, the acquired context-preserving embeddings facilitate superior top@k predictions. Evaluation results on two public benchmark datasets demonstrate our GLAMOR’s superiority against state-of-the-art methods especially in solving the cold-start problem. © 2024 Copyright held by the owner/author(s).},
	author_keywords = {Attributed Graph Embedding; Citation Recommendation; Cold-start; GLAMOR; Large Language Model; Recommender Systems},
	keywords = {Knowledge graph; Recommender systems; Semantics; Attributed graph embedding; Attributed graphs; Citation recommendation; Cold-start; GLAMOR; Graph embeddings; Graph-based languages; Knowledge graphs; Language model; Large language model; Graph embeddings},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Bronze Open Access}
}

@CONFERENCE{Anelli20241245,
	author = {Anelli, Vito Walter and Ferrara, Antonio and Musto, Cataldo and Narducci, Fedelucio and Ragone, Azzurra and Zanker, Markus},
	title = {Sixth Knowledge-aware and Conversational Recommender Systems Workshop (KaRS)},
	year = {2024},
	journal = {RecSys 2024 - Proceedings of the 18th ACM Conference on Recommender Systems},
	pages = {1245 – 1249},
	doi = {10.1145/3640457.3687114},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209379329&doi=10.1145%2f3640457.3687114&partnerID=40&md5=f73f1c4ac4beadfc92c568ad06fe1f13},
	abstract = {Recommender systems, though widely used, often struggle to engage users effectively. While deep learning methods have enhanced connections between users and items, they often neglect the user’s perspective. Knowledge-based approaches, utilizing knowledge graphs, offer semantic insights and address issues like knowledge graph embeddings, hybrid recommendation, and interpretable recommendation. More recently, neural-symbolic systems, combining data-driven and symbolic techniques, show promise in recommendation systems, especially when used with knowledge graphs. Moreover, content features become vital in conversational recommender systems, which demand multi-turn dialogues. Recent literature highlights increasing interest in this area, particularly with the emergence of Large Language Models (LLMs), which excel in understanding user queries and generating recommendations in natural language. Sixth Knowledge-aware and Conversational Recommender Systems (KaRS) Workshop aims to disseminate advancements and discuss about challenges and opportunities. © 2024 Copyright held by the owner/author(s).},
	author_keywords = {conversational agents; knowledge graphs; large language models; natural language processing; neuro-symbolic; recommender systems},
	keywords = {Chatbots; Deep learning; Graph embeddings; Natural language processing systems; Recommender systems; Semantics; Conversational agents; Conversational recommender systems; Knowledge graphs; Language model; Language processing; Large language model; Learning methods; Natural language processing; Natural languages; Neuro-symbolic; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Bronze Open Access}
}

@ARTICLE{Siddharth2024,
	author = {Siddharth, L. and Luo, Jianxi},
	title = {Retrieval augmented generation using engineering design knowledge},
	year = {2024},
	journal = {Knowledge-Based Systems},
	volume = {303},
	doi = {10.1016/j.knosys.2024.112410},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202757647&doi=10.1016%2fj.knosys.2024.112410&partnerID=40&md5=d59e39885e452cf081b410d636826cdf},
	abstract = {Aiming to support Retrieval Augmented Generation (RAG) in the design process, we present a method to identify explicit, engineering design facts – {head entity:: relationship:: tail entity} from patented artefact descriptions. Given a sentence with a pair of entities (selected from noun phrases) marked in a unique manner, our method extracts their relationship that is explicitly communicated in the sentence. For this task, we create a dataset of 375,084 examples and fine-tune language models for relation identification (token classification task) and relation elicitation (sequence-to-sequence task). The token classification approach achieves up to 99.7% accuracy. Upon applying the method to a domain of 4,870 fan system patents, we populate a knowledge base of over 2.93 million facts. Using this knowledge base, we demonstrate how Large Language Models (LLMs) are guided by explicit facts to synthesise knowledge and generate technical and cohesive responses when sought out for knowledge retrieval tasks in the design process. © 2024 Elsevier B.V.},
	author_keywords = {Engineering design knowledge; Graph neural networks; Knowledge graphs; Large-language models; Patent documents; Retrieval-augmented generation},
	keywords = {Graph neural networks; Patents and inventions; Design-process; Engineering design; Engineering design knowledge; Entity-relationship; Graph neural networks; Knowledge graphs; Language model; Large-language model; Patent documents; Retrieval-augmented generation; Knowledge graph},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Green Open Access}
}

@ARTICLE{Jiang2024,
	author = {Jiang, Mingjie and Guo, Yu and Huang, Shaohua and Pu, Jun},
	title = {Generating the assembly instructions of helicopter subassemblies using the hierarchical pruning strategy and large language model},
	year = {2024},
	journal = {Journal of Industrial Information Integration},
	volume = {42},
	doi = {10.1016/j.jii.2024.100723},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208192621&doi=10.1016%2fj.jii.2024.100723&partnerID=40&md5=fe703aec33338225cb77065ef9813d3f},
	abstract = {Assembly instructions are process documents in detail describing the operation steps, materials, tools, fixtures, and assembly sequences in assembly procedures. Due to assembly instructions including numerous contents, and the content being easy for workers to understand, process designers need to spend lots of time thinking and authoring assembly instructions to ensure that workers can complete the assembly task according to the assembly instructions. Focusing on the difficulties of the variety of assembly instructions and the process factors implicit in the standard languages of assembly instructions, a method of assembly instruction generation for helicopter subassemblies is proposed. First, a data representation model of multi-source heterogeneous knowledge and information based on knowledge graphs is designed and established. Then, a hierarchical pruning VF3 algorithm is presented to reuse assembly instructions according to hybrid similarity. Finally, a process factor revision model based on RoBERTa-BiLSTM-CRF is proposed to generate revised assembly instructions. Helicopter subassemblies, which contain 11,240 assembly procedures, are used to evaluate the performance of the method for generating assembly instructions. The proposed method greatly reduces the time cost of assembly instruction authoring and promotes the intelligent development of assembly process design. © 2024 Elsevier Inc.},
	author_keywords = {Assembly instruction generation; Helicopter subassembly assembly; Knowledge graph; Large language model; Subgraph matching},
	keywords = {Assembly; Fixtures (tooling); Modeling languages; Process design; Teaching; Assembly instruction generation; Assembly instructions; Helicopter subassembly assembly; Instruction generations; Knowledge graphs; Language model; Large language model; Process factor; Subgraph matching; Workers'; Knowledge graph},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Youn2024,
	author = {Youn, Jason and Li, Fangzhou and Simmons, Gabriel and Kim, Shanghyeon and Tagkopoulos, Ilias},
	title = {FoodAtlas: Automated knowledge extraction of food and chemicals from literature},
	year = {2024},
	journal = {Computers in Biology and Medicine},
	volume = {181},
	doi = {10.1016/j.compbiomed.2024.109072},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202569044&doi=10.1016%2fj.compbiomed.2024.109072&partnerID=40&md5=d0076382d72c090988f2b0edcbcefcbb},
	abstract = {Automated generation of knowledge graphs that accurately capture published information can help with knowledge organization and access, which have the potential to accelerate discovery and innovation. Here, we present an integrated pipeline to construct a large-scale knowledge graph using large language models in an active learning setting. We apply our pipeline to the association of raw food, ingredients, and chemicals, a domain that lacks such knowledge resources. By using an iterative active learning approach of 4120 manually curated premise-hypothesis pairs as training data for ten consecutive cycles, the entailment model extracted 230,848 food-chemical composition relationships from 155,260 scientific papers, with 106,082 (46.0 %) of them never been reported in any published database. To augment the knowledge incorporated in the knowledge graph, we further incorporated information from 5 external databases and ontology sources. We then applied a link prediction model to identify putative food-chemical relationships that were not part of the constructed knowledge graph. Validation of the 443 hypotheses generated by the link prediction model resulted in 355 new food-chemical relationships, while results show that the model score correlates well (R2 = 0.70) with the probability of a novel finding. This work demonstrates how automated learning from literature at scale can accelerate discovery and support practical applications through reproducible, evidence-based capture of latent interactions of diverse entities, such as food and chemicals. © 2024},
	author_keywords = {Data mining; Deep learning; Food chemical; Knowledge graph; Large language model; Link prediction; Nutrition; Quality control},
	keywords = {Data Mining; Databases, Factual; Food; Humans; Machine Learning; Prediction models; beta carotene; chemical agent; ergosterol; lauric acid; lumisterol; matairesinol; Active Learning; Chemical relationships; Deep learning; Food chemical; Knowledge extraction; Knowledge graphs; Language model; Large language model; Link prediction; Prediction modelling; Article; chemical composition; coconut; Cocos (genus); data mining; deep learning; evidence based practice; food; garlic; ginseng; knowledge; language model; large language model; Lupinus albus; maximum entropy model; Musa x paradisiaca; muskmelon; nutrition; ontology; prediction; probability; tomato; factual database; food; human; machine learning; procedures; Knowledge graph},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Green Open Access}
}

@ARTICLE{Wang20242770,
	author = {Wang, Runzhou and Zhang, Xinsheng},
	title = {Medical Knowledge Graph Question-Answering System Based on Hybrid Dynamic Masking and Multi-strategy Fusion; [基于混合动态掩码与多策略融合的医疗知识图谱问答]},
	year = {2024},
	journal = {Journal of Frontiers of Computer Science and Technology},
	volume = {18},
	number = {10},
	pages = {2770 – 2786},
	doi = {10.3778/j.issn.1673-9418.2401072},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206533867&doi=10.3778%2fj.issn.1673-9418.2401072&partnerID=40&md5=2dd1dbd87503c7bd3a77b509464f77d8},
	abstract = {Medical knowledge graph question-answering combines medical knowledge and natural language processing technology to provide accurate and fast question-answering services for medical practitioners and patients. However, the current Chinese medical knowledge graphs are not comprehensive enough due to the surge in data. Additionally, the complex and ambiguous nature of medical questions poses a significant challenge in accurately identifying entity information and generating answers that are both easily comprehensible and accessible to the public. This paper proposes a medical knowledge graph question-answering framework based on hybrid dynamic masking and multi-strategy fusion. Initially, a medical knowledge graph encompassing 34167 entities and 297463 relationships is constructed by integrating public datasets and disease knowledge from medical platforms, covering categories such as diseases, medications, and food. Subsequently, a BERT-MaskAttention-BiLSTM-CRF hybrid dynamic masking model is introduced to accurately identify medical entity information in the input, effectively focusing on essential content and eliminating interference from redundant information. Finally, entity alignment strategies are employed to unify and standardize medical entities, while intent recognition strategies delve into users’query intentions. This is coupled with the use of large language models to refine the output from the knowledge graph, ensuring that the responses are more readily comprehensible. Experimental results demonstrate that the model achieves a macro-average F1 score of 0.9602 in entity recognition comparative experiments and an average accuracy of 0.9656 in question-answering tests. The generated content is more easily comprehensible and interpretable. © 2024 Journal of Computer Engineering and Applications Beijing Co., Ltd.; Science Press. All rights reserved.},
	author_keywords = {hybrid dynamic masking; knowledge graph; large language model; medical question-answering; multi-strategy fusion},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Wang20244757,
	author = {Wang, Siqi and Liang, Chao and Gao, Yunfan and Liu, Yang and Li, Jing and Wang, Haofen},
	title = {Decoding Urban Industrial Complexity: Enhancing Knowledge-Driven Insights via IndustryScopeGPT},
	year = {2024},
	journal = {MM 2024 - Proceedings of the 32nd ACM International Conference on Multimedia},
	pages = {4757 – 4765},
	doi = {10.1145/3664647.3681705},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209823117&doi=10.1145%2f3664647.3681705&partnerID=40&md5=4baef5ac1725267f2c4a9fc86cd243a0},
	abstract = {Industrial parks are critical to urban economic growth. Yet, their development often encounters challenges stemming from imbalances between industrial requirements and urban services, underscoring the need for strategic planning and operations. This paper introduces IndustryScopeKG, a pioneering large-scale multi-modal, multi-level industrial park knowledge graph, which integrates diverse urban data including street views, corporate, socio-economic, and geospatial information, capturing the complex relationships and semantics within industrial parks. Alongside this, we present the IndustryScopeGPT framework, which leverages Large Language Models (LLMs) with Monte Carlo Tree Search to enhance tool-augmented reasoning and decision-making in Industrial Park Planning and Operation (IPPO). Our work significantly improves site recommendation and functional planning, demonstrating the potential of combining LLMs with structured datasets to advance industrial park management. This approach sets a new benchmark for intelligent IPPO research and lays a robust foundation for advancing urban industrial development. The dataset and related code are available at https://github.com/Tongji-KGLLM/IndustryScope. © 2024 ACM.},
	author_keywords = {industrial park planning and operation; large language model agent; urban design and planning; urban knowledge graph},
	keywords = {Benchmarking; Strategic planning; Trees (mathematics); Design and planning; Industrial park planning and operation; Industrial parks; Knowledge graphs; Language model; Large language model agent; Model agents; Urban design; Urban design and planning; Urban knowledge graph; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Hu2024,
	author = {Hu, Yuelin and Zou, Futai and Han, Jiajia and Sun, Xin and Wang, Yilei},
	title = {LLM-TIKG: Threat intelligence knowledge graph construction utilizing large language model},
	year = {2024},
	journal = {Computers and Security},
	volume = {145},
	doi = {10.1016/j.cose.2024.103999},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199251034&doi=10.1016%2fj.cose.2024.103999&partnerID=40&md5=7d5495dd2c8e159b768bb8c775c8d078},
	abstract = {Open-source threat intelligence is often unstructured and cannot be directly applied to the next detection and defense. By constructing a knowledge graph through open-source threat intelligence, we can better apply this information to intrusion detection. However, the current methods for constructing knowledge graphs face limitations due to the domain-specific attributes of entities and the analysis of lengthy texts, and they require large amounts of labeled data. Furthermore, there is a lack of authoritative open-source annotated threat intelligence datasets, which require significant manual effort. Moreover, it is noteworthy that current research often neglects the textual descriptions of attack behaviors, resulting in the loss of vital information to understand intricate cyber threats. To address these issues, we propose LLM-TIKG that applies the large language model to construct a knowledge graph from unstructured open-source threat intelligence. The few-shot learning capability of GPT is leveraged to achieve data annotation and augmentation, thereby creating the datasets for fine-tuning a smaller language model (7B). Using the fine-tuned model, we perform topic classification on the collected reports, extract entities and relationships, and extract TTPs from the attack description. This process results in the construction of a threat intelligence knowledge graph, enabling automated and universal analysis of textualized threat intelligence. The experimental results demonstrate improved performance in both named entity recognition and TTP classification, achieving the precision of 87.88% and 96.53%, respectively. © 2024 Elsevier Ltd},
	author_keywords = {Knowledge graph; Large language model; Threat intelligence; TTP classification},
	keywords = {Computational linguistics; Data mining; Intrusion detection; 'current; Domain specific; Graph construction; Intrusion-Detection; Knowledge graphs; Language model; Large language model; Open-source; Threat intelligence; TTP classification; Knowledge graph},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7}
}

@ARTICLE{Feng20242887,
	author = {Feng, Tuoyu and Li, Weiping and Guo, Qinglang and Wang, Gangliang and Zhang, Yusong and Qiao, Zijian},
	title = {Overview of Knowledge Graph Question Answering Enhanced by Large Language Models; [大语言模型增强的知识图谱问答研究进展综述]},
	year = {2024},
	journal = {Journal of Frontiers of Computer Science and Technology},
	volume = {18},
	number = {11},
	pages = {2887 – 2900},
	doi = {10.3778/j.issn.1673-9418.2407069},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209892946&doi=10.3778%2fj.issn.1673-9418.2407069&partnerID=40&md5=cca271e305c6b30af6c6ad61e89c48ff},
	abstract = {Knowledge graph question answering (KGQA) is a technology that retrieves relevant answers from a knowledge graph by processing natural language questions posed by users. Early KGQA technologies were limited by the size of knowledge graphs, computational power, and natural language processing capabilities, resulting in lower accuracy. In recent years, with advancements in artificial intelligence, particularly the development of large language models (LLMs), KGQA technology has achieved significant improvements. LLMs such as GPT- 3 have been widely applied to enhancing the performance of KGQA. To better study and learn the enhanced KGQA technologies, this paper summarizes various methods using LLMs for KGQA. Firstly, the relevant knowledge of LLMs and KGQA is summarized, including the technical principles and training methods of LLMs, as well as the basic concepts of knowledge graphs, question answering, and KGQA. Secondly, existing methods of enhancing KGQA with LLMs are reviewed from two dimensions: semantic parsing and information retrieval. The problems that these methods address and their limitations are analyzed. Additionally, related resources and evaluation methods for KGQA enhanced by LLMs are collected and organized, and the performance of existing methods is summarized. Finally, the limitations of current methods are analyzed, and future research directions are proposed. © 2024 Journal of Computer Engineering and Applications Beijing Co., Ltd.; Science Press. All rights reserved.},
	author_keywords = {information retrieval; knowledge graph question answering; large language model; semantic parsing},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Kouwenhoven20244586,
	author = {Kouwenhoven, Jonas and Lageweg, Lucas and Kruit, Benno},
	title = {Constrained LLM-Based Query Generation for Question Answering on Official Statistics},
	year = {2024},
	journal = {Frontiers in Artificial Intelligence and Applications},
	volume = {392},
	pages = {4586 – 4593},
	doi = {10.3233/FAIA241052},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216638109&doi=10.3233%2fFAIA241052&partnerID=40&md5=4bd9af90d64ca511f93320050f067b9e},
	abstract = {This research explores the development of a knowledge graph statistical question answering system for Statistics Netherlands. Aimed at efficiently retrieving single statistical values from their extensive database, which encompasses over a billion values across more than 4,000 tables, we propose a comprehensive three-component framework consisting of: (1) a data augmentation method to generate synthetic data, (2) an entity retrieval system that leverages various encoder networks along with different hard negative mining techniques for the effective retrieval of tables, measures, and dimensions, and (3) an innovative large language model-based query generator. A central innovation of our research is the introduction of a dynamic prompting technique for query generation, which creates prompts specifically for a certain phase of the token generation. This approach ensures that the model is supplied with information relevant for generating specific tokens in a symbolic query. With this approach, we propose a novel system that can help find relevant information in official statistics and similar systems, which is vital for governmental decision making and all fields of research utilising and relying on these statistics. © 2024 The Authors.},
	keywords = {Knowledge graph; Modeling languages; Query languages; Structured Query Language; Augmentation methods; Component framework; Data augmentation; Knowledge graphs; Netherlands; Official Statistics; Query generation; Question Answering; Question answering systems; Three-component; Question answering},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Zheng2024,
	author = {Zheng, Yi-Kai and Zeng, Bi and Feng, Yi-Chun and Zhou, Lu and Li, Yi-Xue},
	title = {PLRTE: Progressive learning for biomedical relation triplet extraction using large language models},
	year = {2024},
	journal = {Journal of Biomedical Informatics},
	volume = {159},
	doi = {10.1016/j.jbi.2024.104738},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207781078&doi=10.1016%2fj.jbi.2024.104738&partnerID=40&md5=e2810ffabaf6aa7dd02fa9c89d97ae82},
	abstract = {Document-level relation triplet extraction is crucial in biomedical text mining, aiding in drug discovery and the construction of biomedical knowledge graphs. Current language models face challenges in generalizing to unseen datasets and relation types in biomedical relation triplet extraction, which limits their effectiveness in these crucial tasks. To address this challenge, our study optimizes models from two critical dimensions: data-task relevance and granularity of relations, aiming to enhance their generalization capabilities significantly. We introduce a novel progressive learning strategy to obtain the PLRTE model. This strategy not only enhances the model's capability to comprehend diverse relation types in the biomedical domain but also implements a structured four-level progressive learning process through semantic relation augmentation, compositional instruction, and dual-axis level learning. Our experiments on the DDI and BC5CDR document-level biomedical relation triplet datasets demonstrate a significant performance improvement of 5% to 20% over the current state-of-the-art baselines. Furthermore, our model exhibits exceptional generalization capabilities on the unseen Chemprot and GDA datasets, further validating the effectiveness of optimizing data-task association and relation granularity for enhancing model generalizability. © 2024 Elsevier Inc.},
	author_keywords = {Biomedical text mining; Large language model; Named entity recognition; Natural language processing; Relation triplet extraction; Supervised fine-tuning},
	keywords = {Algorithms; Data Mining; Databases, Factual; Humans; Machine Learning; Natural Language Processing; Semantics; Contrastive Learning; Natural language processing systems; Self-supervised learning; Biomedical text minings; Fine tuning; Language model; Language processing; Large language model; Named entity recognition; Natural language processing; Natural languages; Relation triplet extraction; Supervised fine-tuning; article; human; language model; large language model; learning; natural language processing; triplets; algorithm; data mining; factual database; machine learning; procedures; semantics; Semantics},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Zhang20244052,
	author = {Zhang, Fan and Jin, Kebing and Zhuo, Hankz Hankui},
	title = {Planning with Logical Graph-Based Language Model for Instruction Generation},
	year = {2024},
	journal = {Frontiers in Artificial Intelligence and Applications},
	volume = {392},
	pages = {4052 – 4059},
	doi = {10.3233/FAIA240974},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216682782&doi=10.3233%2fFAIA240974&partnerID=40&md5=d3915719c91a57e3f4de937f970db8c0},
	abstract = {Despite the superior performance of large language models to generate natural language texts, it is hard to generate texts with correct logic according to a given task, due to the difficulties for neural models to capture strict logic from free-form texts. In this paper, we propose a novel graph-based language model, Logical-GLM, to extract strict logic from free-form texts and then infuse into language models. Specifically, we first capture information from natural language instructions and construct logical probability graphs that generally describe domains. Next, we generate logical skeletons to guide language model training, infusing domain knowledge into language models. At last, we alternately optimize the searching policy of graphs and language models until convergence. The experimental results show that Logical-GLM is both effective and efficient compared with traditional language models, despite using smaller-scale training data and fewer parameters. Our approach can generate instructional texts with more correct logic owing to the internalized domain knowledge. Moreover, the search of logical graphs reflects the inner mechanism of the language models, which improves the interpretability of black-box models. © 2024 The Authors.},
	keywords = {Adversarial machine learning; Context free languages; Contrastive Learning; Knowledge graph; Natural language processing systems; Domain knowledge; Freeforms; Graph-based languages; Instruction generations; Language model; Natural languages; Natural languages texts; Neural modelling; Performance; Strict logic},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Lee20245234,
	author = {Lee, Zhicheng and Huang, Zhidian and Yao, Zijun and Liu, Jinxin and Xin, Amy and Hou, Lei and Li, Juanzi},
	title = {DiaKoP: Dialogue-based Knowledge-oriented Programming for Neural-symbolic Knowledge Base Question Answering},
	year = {2024},
	journal = {International Conference on Information and Knowledge Management, Proceedings},
	pages = {5234 – 5238},
	doi = {10.1145/3627673.3679229},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209989348&doi=10.1145%2f3627673.3679229&partnerID=40&md5=570a90bc312d955e136fc48a47a78698},
	abstract = {We present Dialogue-based Knowledge-oriented Programming system (DiaKoP), a system with a chat interface designed for multi-turn knowledge base question answering (KBQA). DiaKoP enables users to decompose complex questions into multiple simpler follow-up questions and interact with the system to obtain answers. Multi-turn KBQA presents unique challenges because users may switch topics or ask incomplete questions that rely on previous interactions. To address this, we develop a Dialogue History Tracker and Dialogue Policy to manage user conversations effectively. Additionally, we enhance the knowledge from the knowledge graph by integrating parametric knowledge from a large language model (LLM) to provide more comprehensive answers. To mitigate the issue of wrongly parsed questions by semantic parser, we implement a human-in-the-loop mechanism, allowing users to correct errors. We evaluate DiaKoP both qualitatively and quantitatively, with user study indicating that our system better meets users' needs. DiaKoP is open-sourced on https://github.com/THU-KEG/DiaKoP with a guiding demo on https://youtu.be/Tq17k0OxPVg.  © 2024 Owner/Author.},
	author_keywords = {explainability; human-in-the-loop; knowledge based question answering system; multi-turn dialogue},
	keywords = {Knowledge graph; Modeling languages; Explainability; Human-in-the-loop; Knowledge based; Knowledge based question answering system; Knowledge-oriented; Multi-turn; Multi-turn dialog; Programming system; Question Answering; Question answering systems; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Sarmah2024608,
	author = {Sarmah, Bhaskarjit and Mehta, Dhagash and Hall, Benika and Rao, Rohan and Patel, Sunil and Pasquali, Stefano},
	title = {HybridRAG: Integrating Knowledge Graphs and Vector Retrieval Augmented Generation for Efficient Information Extraction},
	year = {2024},
	journal = {ICAIF 2024 - 5th ACM International Conference on AI in Finance},
	pages = {608 – 616},
	doi = {10.1145/3677052.3698671},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212671710&doi=10.1145%2f3677052.3698671&partnerID=40&md5=c04edd0fdbdde850c864f7726b8e5627},
	abstract = {Extraction and interpretation of intricate information from unstructured text data arising in financial applications, such as earnings call transcripts, present substantial challenges to large language models (LLMs) even using the current best practices to use Retrieval Augmented Generation (RAG) (referred to as VectorRAG techniques which utilize vector databases for information retrieval) due to challenges such as domain specific terminology and complex formats of the documents. We introduce a novel approach based on a combination, called HybridRAG, of the Knowledge Graphs (KGs) based RAG techniques (called GraphRAG) and VectorRAG techniques to enhance question-answer (Q&A) systems for information extraction from financial documents that is shown to be capable of generating accurate and contextually relevant answers. Using experiments on a set of financial earning call transcripts documents which come in the form of Q&A format, and hence provide a natural set of pairs of ground-truth Q&As, we show that HybridRAG which retrieves context from both vector database and KG outperforms both traditional VectorRAG and GraphRAG individually when evaluated at both the retrieval and generation stages in terms of retrieval accuracy and answer generation. The proposed technique has applications beyond the financial domain.  © 2024 ACM.},
	keywords = {Knowledge graph; 'current; Best practices; Domain-specific terminology; Financial applications; Generation techniques; Graph-based; Knowledge graphs; Language model; Text data; Unstructured texts; Vectors},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Bronze Open Access}
}

@ARTICLE{Kim20242190,
	author = {Kim, Junyoung and Wang, Kai and Weng, Chunhua and Liu, Cong},
	title = {Assessing the utility of large language models for phenotype-driven gene prioritization in the diagnosis of rare genetic disease},
	year = {2024},
	journal = {American Journal of Human Genetics},
	volume = {111},
	number = {10},
	pages = {2190 – 2202},
	doi = {10.1016/j.ajhg.2024.08.010},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206019380&doi=10.1016%2fj.ajhg.2024.08.010&partnerID=40&md5=cf928c0d61985cc2dfdeb99950724960},
	abstract = {Phenotype-driven gene prioritization is fundamental to diagnosing rare genetic disorders. While traditional approaches rely on curated knowledge graphs with phenotype-gene relations, recent advancements in large language models (LLMs) promise a streamlined text-to-gene solution. In this study, we evaluated five LLMs, including two generative pre-trained transformers (GPT) series and three Llama2 series, assessing their performance across task completeness, gene prediction accuracy, and adherence to required output structures. We conducted experiments, exploring various combinations of models, prompts, phenotypic input types, and task difficulty levels. Our findings revealed that the best-performed LLM, GPT-4, achieved an average accuracy of 17.0% in identifying diagnosed genes within the top 50 predictions, which still falls behind traditional tools. However, accuracy increased with the model size. Consistent results were observed over time, as shown in the dataset curated after 2023. Advanced techniques such as retrieval-augmented generation (RAG) and few-shot learning did not improve the accuracy. Sophisticated prompts were more likely to enhance task completeness, especially in smaller models. Conversely, complicated prompts tended to decrease output structure compliance rate. LLMs also achieved better-than-random prediction accuracy with free-text input, though performance was slightly lower than with standardized concept input. Bias analysis showed that highly cited genes, such as BRCA1, TP53, and PTEN, are more likely to be predicted. Our study provides valuable insights into integrating LLMs with genomic analysis, contributing to the ongoing discussion on their utilization in clinical workflows. © 2024 The Authors},
	author_keywords = {artificial intelligence; gene prioritization; generative pre-trained transformers; large language model; phenotypes; precision medicine; rare disease diagnosis},
	keywords = {Computational Biology; Humans; Phenotype; Rare Diseases; phosphatidylinositol 3,4,5 trisphosphate 3 phosphatase; protein p53; Article; cohort analysis; diagnostic accuracy; diagnostic test accuracy study; generative pretrained transformer; genetic analysis; genetic disorder; human; large language model; major clinical study; prediction; PTEN gene; standardization; TP53 gene; tumor suppressor gene; bioinformatics; genetics; phenotype; procedures; rare disease},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Afreen20245159,
	author = {Afreen, Neda and Balloccu, Giacomo and Boratto, Ludovico and Fenu, Gianni and Malloci, Francesca Maridina and Marras, Mirko and Martis, Andrea Giovanni},
	title = {EDGE: A Conversational Interface driven by Large Language Models for Educational Knowledge Graphs Exploration},
	year = {2024},
	journal = {International Conference on Information and Knowledge Management, Proceedings},
	pages = {5159 – 5163},
	doi = {10.1145/3627673.3679231},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210006996&doi=10.1145%2f3627673.3679231&partnerID=40&md5=571304dc188a5bda25c09eb688ef4900},
	abstract = {As education adopts digital platforms, the vast amount of information from various sources, such as learning management systems and learning object repositories, presents challenges in navigation and elaboration. Traditional interfaces involve a steep learning curve, limited user accessibility, and lack flexibility. Language models alone cannot address these issues as they do not have access to structured information specific to the educational organization. In this paper, we propose EDGE (EDucational knowledge Graph Explorer), a natural language interface that uses knowledge graphs to organize educational information. EDGE translates natural language requests into queries and converts the results back into natural language responses. We show EDGE's versatility using knowledge graphs built from public datasets, providing example interactions of different stakeholders. Demo video: https://u.garr.it/eYq63.  © 2024 ACM.},
	author_keywords = {conversational interface; graph database; information retrieval; knowledge graph; language model; learning management},
	keywords = {Adversarial machine learning; Federated learning; Graph Databases; Structured Query Language; Amount of information; Conversational interface; Digital platforms; Educational knowledge; Graph database; Graph exploration; Knowledge graphs; Language model; Learning managements; Natural languages; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Liang20242594,
	author = {Liang, Jia and Zhang, Liping and Yan, Sheng and Zhao, Yubo and Zhang, Yawen},
	title = {Research Progress of Named Entity Recognition Based on Large Language Model; [基于大语言模型的命名实体识别研究进展]},
	year = {2024},
	journal = {Journal of Frontiers of Computer Science and Technology},
	volume = {18},
	number = {10},
	pages = {2594 – 2615},
	doi = {10.3778/j.issn.1673-9418.2407038},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206545582&doi=10.3778%2fj.issn.1673-9418.2407038&partnerID=40&md5=f926c82dd68b9707cfb2050fdb14268c},
	abstract = {Named entity recognition aims to identify named entities and their types from unstructured text, which is an important basic task in natural language processing technologies such as question answering system, machine translation and knowledge graph. With the development of artificial intelligence, named entity recognition based on large language model has become a hot research topic. This paper reviews the latest research progress of named entity recognition based on large language model. Firstly, the development process of large language model and named entity recognition is summarized, and the commonly used datasets and evaluation methods for named entity recognition tasks are briefly introduced. This paper sorts out the traditional research work on named entity recognition from three aspects: rule-based and dictionary-based, statistical machine learning-based and deep learning-based. Secondly, how to apply different big language models to different fields of named entity recognition tasks is described in detail according to the model architecture, and the existing problems and improvement directions are analyzed. Finally, the challenges faced by named entity recognition tasks based on big language models are summarized, and future research directions are prospected. © 2024 Journal of Computer Engineering and Applications Beijing Co., Ltd.; Science Press. All rights reserved.},
	author_keywords = {deep learning; large language model; named entity recognition; neural network},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Yang2024,
	author = {Yang, Rui and Zhu, Jiahao and Man, Jianping and Fang, Li and Zhou, Yi},
	title = {Enhancing text-based knowledge graph completion with zero-shot large language models: A focus on semantic enhancement},
	year = {2024},
	journal = {Knowledge-Based Systems},
	volume = {300},
	doi = {10.1016/j.knosys.2024.112155},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197083343&doi=10.1016%2fj.knosys.2024.112155&partnerID=40&md5=0e7a9cc1d110f55d61257f9c5348282f},
	abstract = {The design and development of text-based knowledge graph completion (KGC) methods leveraging textual entity descriptions are at the forefront of research. These methods involve advanced optimization techniques such as soft prompts and contrastive learning to enhance KGC models. The effectiveness of text-based methods largely hinges on the quality and richness of the training data. Large language models (LLMs) can utilize straightforward prompts to alter text data, thereby enabling data augmentation for KGC. Nevertheless, LLMs typically demand substantial computational resources. To address these issues, we introduce a framework termed constrained prompts for KGC (CP-KGC). This CP-KGC framework designs prompts that adapt to different datasets to enhance semantic richness. Additionally, CP-KGC employs a context constraint strategy to effectively identify polysemous entities within KGC datasets. Through extensive experimentation, we have verified the effectiveness of this framework. Even after quantization, the LLM (Qwen-7B-Chat-int4) still enhances the performance of text-based KGC methods.1 This study extends the performance limits of existing models and promotes further integration of KGC with LLMs. © 2024 Elsevier B.V.},
	author_keywords = {Knowledge graph; Knowledge graph completion; Large language models; Semantic enhancement},
	keywords = {Computational linguistics; Knowledge management; Semantics; Zero-shot learning; Completion methods; Design and Development; Knowledge graph completion; Knowledge graphs; Language model; Large language model; Optimization techniques; Semantic enhancements; Text-based methods; Knowledge graph},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; All Open Access, Green Open Access}
}

@ARTICLE{Qi2024,
	author = {Qi, Peng and Sun, Yan and Yao, Muyan and Tao, Dan},
	title = {KEMoS: A knowledge-enhanced multi-modal summarizing framework for Chinese online meetings},
	year = {2024},
	journal = {Neural Networks},
	volume = {178},
	doi = {10.1016/j.neunet.2024.106417},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195391128&doi=10.1016%2fj.neunet.2024.106417&partnerID=40&md5=1afe5ad77efd7bb38e5ef9ce1f7b315e},
	abstract = {The demand for “online meetings” and “collaborative office work” keeps surging recently, producing an abundant amount of relevant data. How to provide participants with accurate and fast summarizing service has attracted extensive attention. Existing meeting summarizing models overlook the utilization of multi-modal information and the information offsetting during summarizing. In this paper, we develop a knowledge-enhanced multi-modal summarizing framework. Firstly, we construct a three-layer multi-modal meeting knowledge graph, including basic, knowledge, and multi-modal layer, to integrate meeting information thoroughly. Then, we raise a topic-based hierarchical clustering approach, which considers information entropy and difference simultaneously, to capture the semantic evolution of meetings. Next, we devise a multi-modal enhanced encoding strategy, including a sentence-level cross-modal encoder, a joint loss function, and a knowledge graph embedding module, to learn the meeting and topic-level presentations. Finally, when generating summaries, we design a topic-enhanced decoding strategy for the Transformer decoder which mitigates semantic offsetting with the aid of topic information. Extensive experiments show that our proposed work consistently outperforms state-of-the-art solutions on the Chinese meeting dataset, where the ROUGE-1, ROUGE-2, and ROUGE-L are 49.98%, 21.03%, and 32.03% respectively. © 2024 Elsevier Ltd},
	author_keywords = {Multi-modal enhanced encoding strategy; Multi-modal meeting knowledge graph; Topic-based hierarchical clustering approach; Topic-enhanced decoding strategy},
	keywords = {Algorithms; China; Cluster Analysis; Congresses as Topic; East Asian People; Humans; Knowledge; Neural Networks, Computer; Semantics; Decoding; Encoding (symbols); Knowledge graph; Semantics; Decoding strategy; Encoding strategy; Hierarchical clustering approach; Knowledge graphs; Multi-modal; Multi-modal enhanced encoding strategy; Multi-modal meeting knowledge graph; Topic-based hierarchical clustering approach; Topic-enhanced decoding strategy; Chinese; conference paper; controlled study; drug combination; drug therapy; entropy; hierarchical clustering; human; algorithm; artificial neural network; China; cluster analysis; East Asian; knowledge; organization; semantics; Signal encoding},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Wu2024,
	author = {Wu, Da and Yang, Jingye and Wang, Kai},
	title = {Exploring the reversal curse and other deductive logical reasoning in BERT and GPT-based large language models},
	year = {2024},
	journal = {Patterns},
	volume = {5},
	number = {9},
	doi = {10.1016/j.patter.2024.101030},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205832199&doi=10.1016%2fj.patter.2024.101030&partnerID=40&md5=4f12b27e8890757842b1cba73dfbdea1},
	abstract = {The “Reversal Curse” describes the inability of autoregressive decoder large language models (LLMs) to deduce “B is A” from “A is B,” assuming that B and A are distinct and can be uniquely identified from each other. This logical failure suggests limitations in using generative pretrained transformer (GPT) models for tasks like constructing knowledge graphs. Our study revealed that a bidirectional LLM, bidirectional encoder representations from transformers (BERT), does not suffer from this issue. To investigate further, we focused on more complex deductive reasoning by training encoder and decoder LLMs to perform union and intersection operations on sets. While both types of models managed tasks involving two sets, they struggled with operations involving three sets. Our findings underscore the differences between encoder and decoder models in handling logical reasoning. Thus, selecting BERT or GPT should depend on the task's specific needs, utilizing BERT's bidirectional context comprehension or GPT's sequence prediction strengths. © 2024 The Author(s)},
	author_keywords = {auto-regressive model; BERT; bidirectional encoder; deductive logical reasoning; GPT; large language model; LLM; reversal curse},
	keywords = {Encoding (symbols); Knowledge graph; Modeling languages; Autoregressive modelling; Bidirectional encoder; Bidirectional encoder representation from transformer; Deductive logical reasoning; Generative pretrained transformer; Language model; Large language model; Logical reasoning; Reversal curse; Decoding},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Zha20243113,
	author = {Zha, Zhiwei and Wang, Jiaan and Li, Zhixu and Zhu, Xiangru and Song, Wei and Xiao, Yanghua},
	title = {M2ConceptBase: A Fine-Grained Aligned Concept-Centric Multimodal Knowledge Base},
	year = {2024},
	journal = {International Conference on Information and Knowledge Management, Proceedings},
	pages = {3113 – 3123},
	doi = {10.1145/3627673.3679852},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210044349&doi=10.1145%2f3627673.3679852&partnerID=40&md5=900ac4edb4cd2dd522cea9347ca0451f},
	abstract = {Multimodal knowledge bases (MMKBs) provide cross-modal aligned knowledge crucial for multimodal tasks. However, the images in existing MMKBs are generally collected for entities in encyclopedia knowledge graphs. Therefore, detailed groundings of visual semantics with linguistic concepts are lacking, which are essential for the visual concept cognition ability of multimodal models. Addressing this gap, we introduce M2 ConceptBase, the first concept-centric MMKB. M2 ConceptBase models concepts as nodes with associated images and detailed textual descriptions. We propose a context-aware multimodal symbol grounding approach to align concept-image and concept-description pairs using context information from image-text datasets. Comprising 951K images and 152K concepts, M2 ConceptBase links each concept to an average of 6.27 images and a single description, ensuring comprehensive visual and textual semantics. Human studies confirm more than 95% alignment accuracy, underscoring its quality. Additionally, our experiments demonstrate that M2 ConceptBase significantly enhances VQA model performance on the OK-VQA task. M2 ConceptBase also substantially improves the fine-grained concept understanding capabilities of multimodal large language models through retrieval augmentation in two concept-related tasks, highlighting its value.  © 2024 ACM.},
	author_keywords = {knowledge base; multimodal knowledge base; multimodal symbol grounding; visual question answering},
	keywords = {Knowledge graph; Modeling languages; Question answering; Concept-base; Fine grained; Knowledge base; Multi-modal; Multimodal knowledge base; Multimodal symbol grounding; Question Answering; Symbol grounding; Visual question answering; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Bernasconi2024,
	author = {Bernasconi, Eleonora and Ceriani, Miguel and Ferilli, Stefano},
	title = {LPG Semantic Ontologies: A Tool for Interoperable Schema Creation and Management},
	year = {2024},
	journal = {Information (Switzerland)},
	volume = {15},
	number = {9},
	doi = {10.3390/info15090565},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205234457&doi=10.3390%2finfo15090565&partnerID=40&md5=ddaeb2e3390921465ac1fdf285d7d2a1},
	abstract = {Ontologies are essential for the management and integration of heterogeneous datasets. This paper presents OntoBuilder, an advanced tool that leverages the structural capabilities of semantic labeled property graphs (SLPGs) in strict alignment with semantic web standards to create a sophisticated framework for data management. We detail OntoBuilder’s architecture, core functionalities, and application scenarios, demonstrating its proficiency and adaptability in addressing complex ontological challenges. Our empirical assessment highlights OntoBuilder’s strengths in enabling seamless visualization, automated ontology generation, and robust semantic integration, thereby significantly enhancing user workflows and data management capabilities. The performance of the linked data tools across multiple metrics further underscores the effectiveness of OntoBuilder. © 2024 by the authors.},
	author_keywords = {knowledge management; large language models; ontologies; Semantic Labeled Property Graphs; semantic web},
	keywords = {Information management; Knowledge graph; Labeled data; Ontology; Heterogeneous datasets; Language model; Large language model; Ontology's; Property; Semantic labeled property graph; Semantic ontology; Semantic web standards; Semantic-Web; Structural capabilities; Semantics},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Burgueño2024578,
	author = {Burgueño, Lola and Maria Keet, C. and Kienzle, Jörg and Michael, Judith and Babur, Önder},
	title = {A Human Behavior Exploration Approach Using LLMs for Cyber-Physical Systems},
	year = {2024},
	journal = {Proceedings: MODELS 2024 - ACM/IEEE 27th International Conference on Model Driven Engineering Languages and Systems: Companion Proceedings},
	pages = {578 – 586},
	doi = {10.1145/3652620.3687806},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212228857&doi=10.1145%2f3652620.3687806&partnerID=40&md5=79620c2bce2a5ea984a95e076aed08cb},
	abstract = {In the early phases of Cyber-Physical Systems (CPS) development, scoping human behavior plays a significant role, especially when interactions extend beyond expected behavior. Here, it is especially challenging to develop cases that capture the full spectrum of human behavior. Up to now, identifying such behavior of humans remains a task for domain experts. We explore how one can use Large Languages Models (LLMs) in the design phase of systems to provide additional information about human-CPS interaction. Our approach proposes a preliminary ontology describing a hierarchy of types of behavior and relevant CPS components as input for prompt templates. It uses them to generate parts of human behavior descriptions, as well as a canned prompt with one variable about behavior. For demonstration, we take a smart building with a Home Energy System as the use case. An initial user evaluation shows that the behavior descriptions generated with standard and ontology-driven prompts complement each other and are useful when assisting humans. The discovered uncommon behaviors can be used to complete interaction scenarios that eventually result in a more robust CPS implementation. © 2024 Copyright held by the owner/author(s).},
	author_keywords = {Cyber-Physical Systems; Digital Twin; Human Behavior; Large Language Models; User Scenario},
	keywords = {Hierarchical systems; Behaviour descriptions; Cybe-physical systems; Cyber-physical systems; Human behaviors; Language model; Large language model; Ontology's; Scoping; System development; User scenario; Ontology},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Luger2024,
	author = {Luger, Jason},
	title = {‘Where #freedom and #patriotism live:’ Linking digital media to far-right geographies},
	year = {2024},
	journal = {Political Geography},
	volume = {114},
	doi = {10.1016/j.polgeo.2024.103195},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203009735&doi=10.1016%2fj.polgeo.2024.103195&partnerID=40&md5=dac0b694d3feb034fd3abc7849842aef},
	abstract = {This paper explores some ways that far-right worldviews are digitally encoded and strategically-assembled in and through built environments. The paper argues that an understanding of far-right spatiality will be limited without a more inter-scalar, relational and material framing of the various components of far-right world-building. Assemblage ontologies, seen through comparative cases, therefore hold value in making sense of the far-right today. Explorations of how digital media and the far-right are entangled with and co-producing built environments, are thus vital. As ideologies and philosophies (e.g., nationalism or conspiracism) travel across networked medias, complex hybridizations become infrastructurally-fixed-in-place. These affixations produce, and are produced by, geographical communities (e.g., urban developments). Far-right material infrastructures thereby extend from, and into, the digital, mediated by both human and nonhuman processes (such as generative AI), thus becoming co-constitutive elements of place, via land ownership, buildings, aesthetics, social encounters and practices, urban planning processes, and electoral politics; e.g., the assembled spatialities of everyday life. The paper juxtaposes two international cases, drawn from ethnography and critical discourse/visual analyses. The first is the territorialisation of circulating notions of American hyper-patriotic nationalism in the suburban South via urban developments and recreational spaces. The second case explores how far-right representations of conspiracism and debates around urban traditionalism versus modernity, are contested online and offline in Dresden, Saxony. Both cases point to the powerful entanglements of far-right ideology, digital media, and place. Conceptually, the paper juxtaposes phenomenological notions of far-right space/place with ideas of ‘strategic assemblage’ and online/offline ‘code space’, as ontological lenses to interrogate the relationships between far-right online worlds and the material configurations of physical infrastructures and materials which have troubling implications for everyday environments and democratic life. © 2024 The Author},
	keywords = {Dresden; Germany; Saxony; artificial intelligence; ethnography; mass media; nationalism; visual analysis},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Silva20241333,
	author = {Silva, Marta Contreiras and Faria, Daniel and Pesquita, Catia},
	title = {Complex Multi-Ontology Alignment Through Geometric Operations on Language Embeddings},
	year = {2024},
	journal = {Frontiers in Artificial Intelligence and Applications},
	volume = {392},
	pages = {1333 – 1340},
	doi = {10.3233/FAIA240632},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213368903&doi=10.3233%2fFAIA240632&partnerID=40&md5=f23921945e8c210d05bab0e3ffa1f87a},
	abstract = {With knowledge graphs increasing in popularity, aligning and integrating them is paramount to ensure their usefulness and reusability. A key step in this process is ontology matching, whereby the semantic models of KGs are aligned into a single cohesive semantic backbone. While finding simple pairwise equivalences between entities in two ontologies is well addressed by state-of-the-art algorithms, finding more complex mappings that can include multiple entities from different ontologies is far from solved, despite their importance in ensuring a deep and meaningful integration of KGs. We propose a novel complex ontology matching approach that explores geometric operations over the shared semantic space afforded by large language models, enabling the discovery of complex mappings that are missed by purely lexical approaches. We evaluate our approach on several biomedical ontologies using partial reference alignments and manual expert validation. Our approach improves on the performance of a purely lexical approach while also increasing the coverage of complex multi-ontology alignments by 20 to 80%, which translates to a 97% coverage of the source ontologies. Moreover, the manual evaluation of the mappings produced by LLM shows that it achieves a high level of precision. This work demonstrates that the use of LLMs can improve on the performance of traditional lexical strategies. © 2024 The Authors.},
	keywords = {Graph embeddings; Knowledge graph; Latent semantic analysis; Ontology; Reusability; Semantics; Complex mapping; Embeddings; Geometric operations; Knowledge graphs; Multi-ontologies; Ontology alignment; Ontology matching; Ontology's; Performance; Semantic modelling; Mapping},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Chen20241389,
	author = {Chen, Jieying and Dong, Hang and Chen, Jiaoyan and Horrocks, Ian},
	title = {Ontology Text Alignment: Aligning Textual Content to Terminological Axioms},
	year = {2024},
	journal = {Frontiers in Artificial Intelligence and Applications},
	volume = {392},
	pages = {1389 – 1396},
	doi = {10.3233/FAIA240639},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213316349&doi=10.3233%2fFAIA240639&partnerID=40&md5=b4da4b6fb6605365351c379a4e4cd27b},
	abstract = {Despite the impressive advancements in Large Language Models (LLMs), their ability to perform reasoning and provide explainable outcomes remains a challenge, underscoring the continued relevance of ontologies in certain areas, particularly due to the reasoning and validation capabilities of ontologies. Ontology modelling and semantic search, due to their inherent complexity, still demand considerable human effort and expertise. Addressing this gap, our paper introduces the problem of ontology text alignment, which involves finding the most relevant axioms with respect to the given reference text. We propose an advanced Retrieval Augmented Generation framework that leverages BERT models and generative LLMs, together with ontology semantic enhancement based on atomic decomposition. Additionally, we have developed benchmarks in geology and biomedical areas. Our evaluation demonstrates the positive impact of our framework. © 2024 The Authors.},
	keywords = {Benchmarking; Ontology; Language model; Model search; Ontology model; Ontology semantics; Ontology's; Reasoning capabilities; Semantic search; Text alignments; Textual content; Validation capability; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Ni20245463,
	author = {Ni, Bo},
	title = {Reliable Knowledge Graph Reasoning with Uncertainty Quantification},
	year = {2024},
	journal = {International Conference on Information and Knowledge Management, Proceedings},
	pages = {5463 – 5466},
	doi = {10.1145/3627673.3680266},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209990967&doi=10.1145%2f3627673.3680266&partnerID=40&md5=80f94c859c9a1fc4a14edf0729b0cc36},
	abstract = {Recently, Knowledge Graphs (KGs) have been successfully coupled with Large Language Models (LLMs) to mitigate their hallucinations and enhance their reasoning capability, e.g., KG-based retrieval-augmented framework for question-answering. However, current KG-LLM frameworks lack rigorous uncertainty estimation, limiting their reliable deployment in high-stake applications where the cost of errors is significant. To address this crucial gap, we propose a new trustworthy KG-LLM framework, UaG(<u>U</u>ncertainty <u>A</u>ware <u>G</u>raph Reasoning), which incorporates uncertainty quantification into the KG-LLM framework. We design an uncertainty-aware multi-step reasoning framework that leverages conformal prediction to provide a theoretical guarantee on the prediction set. To manage the error rate of the multi-step process, we additionally introduce an error rate control module to adjust the error rate within the individual components. Our preliminary results demonstrate that UaG can achieve the desired theoretical coverage while maintaining a reasonable prediction set size.  © 2024 Owner/Author.},
	author_keywords = {knowledge graph; question answering; trustworthy AI; uncertainty quantification},
	keywords = {Error rate; Knowledge graphs; Language model; Modelling framework; Multisteps; Question Answering; Reasoning capabilities; Reasoning with uncertainty; Trustworthy AI; Uncertainty quantifications; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Wu202424,
	author = {Wu, Jingzhu and Li, Lin and Wu, Zongning and Yu, Chongchong and Cheng, Junhu and Zeng, Xin'an and Zhao, Xia and Yang, Yi and Ma, Ji},
	title = {Research Progress on Digitalization and Intelligence in Food Domain Based on Knowledge Graphs; [基于知识图谱的食品领域数智化研究进展]},
	year = {2024},
	journal = {Journal of Food Science and Technology (China)},
	volume = {42},
	number = {5},
	pages = {24 – 32},
	doi = {10.12301/spxb202400610},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208097327&doi=10.12301%2fspxb202400610&partnerID=40&md5=81729ae6ba8af803d28ec895ae21c75d},
	abstract = {With the development of technologies such as big data and cloud computing, the scale of data in the food domain is growing at an astonishing rate. These data not only come from diverse sources and have complex structures, but also lack standardized terminology, which poses challenges to the effective integration and utilization of food-related data. Knowledge graphs, as fundamental cornerstone of achieving general artificial intelligence, provides support for the organization and management of food data and its higher-level applications in terms of integration and semantic understanding. By summarizing recent research achievements of knowledge graphs in the food domain, the construction methods of knowledge graphs in food domain was reviewed, covering key steps such as ontology construction, knowledge extraction, knowledge fusion, and processing. The current applications of knowledge graphs in the food domain, particularly in three areas, food nutrition and health, food innovation and research, and food safety and traceability. Based on current state of development of knowledge graphs in the food domain, incorporating multimodal data fusion technology, large language model construction, and the intelligentization of industrial equipment in the food field, the future development directions of knowledge graphs in food domain were anticipated. © 2024 Beijing Technology and Business University, Department of Science and Technology. All rights reserved.},
	author_keywords = {food research and development; food safety; food traceability; knowledge graph; nutrition analysis; ontology construction},
	keywords = {Cloud-computing; Complexes structure; Food research; Food research and development; Food traceabilitys; Food-safety; Knowledge graphs; Nutrition analyze; Ontology construction; Research and development; Knowledge graph},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Liu2024570,
	author = {Liu, Wei and Yu, Ailun and Zan, Daoguang and Shen, Bo and Zhang, Wei and Zhao, Haiyan and Jin, Zhi and Wang, Qianxiang},
	title = {GraphCoder: Enhancing Repository-Level Code Completion via Coarse-to-fine Retrieval Based on Code Context Graph},
	year = {2024},
	journal = {Proceedings - 2024 39th ACM/IEEE International Conference on Automated Software Engineering, ASE 2024},
	pages = {570 – 581},
	doi = {10.1145/3691620.3695054},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212425997&doi=10.1145%2f3691620.3695054&partnerID=40&md5=fcbf9df83ed8cded8f7950b8eabd7496},
	abstract = {The performance of repository-level code completion depends upon the effective leverage of both general and repository-specific knowledge. Despite the impressive capability of code LLMs in general code completion tasks, they often exhibit less satisfactory performance on repository-level completion due to the lack of repository-specific knowledge in these LLMs. To address this problem, we propose GraphCoder, a retrieval-augmented code completion framework that leverages LLMs' general code knowledge and the repository-specific knowledge via a graph-based retrieval-generation process. In particular, GraphCoder captures the context of completion target more accurately through code context graph (CCG) that consists of control-flow, data- and control-dependence between code statements, a more structured way to capture the completion target context than the sequence-based context used in existing retrieval-augmented approaches; based on CCG, GraphCoder further employs a coarse-to-fine retrieval process to locate context-similar code snippets with the completion target from the current repository. Experimental results demonstrate both the effectiveness and efficiency of GraphCoder: Compared to baseline retrieval-augmented methods, GraphCoder achieves higher exact match (EM) on average, with increases of +6.06 in code match and +6.23 in identifier match, while using less time and space. © 2024 Copyright is held by the owner/author(s). Publication rights licensed to ACM.},
	author_keywords = {code completion; code graphs; large language model; retrieval augmented generation},
	keywords = {Search engines; Coarse to fine; Code completions; Code graphs; Generation process; Graph-based; Language model; Large language model; Performance; Retrieval augmented generation; Specific knowledge; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Monka20244665,
	author = {Monka, Sebastian and Grangel-González, Irlan and Schmid, Stefan and Halilaj, Lavdim and Rickart, Marc and Rudolph, Oliver and Dias, Rui},
	title = {Enhancing Manufacturing Knowledge Access with LLMs and Context-Aware Prompting},
	year = {2024},
	journal = {Frontiers in Artificial Intelligence and Applications},
	volume = {392},
	pages = {4665 – 4672},
	doi = {10.3233/FAIA241062},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216677054&doi=10.3233%2fFAIA241062&partnerID=40&md5=f095c3bd278e5d1dbd29d3344c6e8b23},
	abstract = {Knowledge graphs (KGs) have transformed data management within the manufacturing industry, offering effective means for integrating disparate data sources through shared and structured conceptual schemas. However, harnessing the power of KGs can be daunting for non-experts, as it often requires formulating complex SPARQL queries to retrieve specific information. With the advent of Large Language Models (LLMs), there is a growing potential to automatically translate natural language queries into the SPARQL format, thus bridging the gap between user-friendly interfaces and the sophisticated architecture of KGs. The challenge remains in adequately informing LLMs about the relevant context and structure of domain-specific KGs, e.g., in manufacturing, to improve the accuracy of generated queries. In this paper, we evaluate multiple strategies that use LLMs as mediators to facilitate information retrieval from KGs. We focus on the manufacturing domain, particularly on the Bosch Line Information System KG and the I40 Core Information Model. In our evaluation, we compare various approaches for feeding relevant context from the KG to the LLM and analyze their proficiency in transforming real-world questions into SPARQL queries. Our findings show that LLMs can significantly improve their performance on generating correct and complete queries when provided only the adequate context of the KG schema. Such context-aware prompting techniques help LLMs to focus on the relevant parts of the ontology and reduce the risk of hallucination. We anticipate that the proposed techniques help LLMs to democratize access to complex data repositories and empower informed decision-making in manufacturing settings. © 2024 The Authors.},
	keywords = {Data integration; Information management; Knowledge graph; Manufacturing data processing; Modeling languages; Natural language processing systems; Query languages; Smart manufacturing; Translation (languages); Conceptual schemas; Context-aware prompting; Data-source; Knowledge graphs; Language model; Manufacturing industries; Manufacturing knowledge; Natural language queries; Power; Specific information; Structured Query Language},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{He202455,
	author = {He, Tingting and Zhang, Qiang},
	title = {Application status and development trend of knowledge graph in petroleum exploration and development; [知识图谱在油气勘探开发中的应用现状与发展趋势]},
	year = {2024},
	journal = {Natural Gas Industry},
	volume = {44},
	number = {9},
	pages = {55 – 67},
	doi = {10.3787/j.issn.1000-0976.2024.09.005},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204892585&doi=10.3787%2fj.issn.1000-0976.2024.09.005&partnerID=40&md5=26e152f141de996125796cafcc007a45},
	abstract = {Ⅰn the energy sector, the efficient exploration and development of petroleum resources based on the knowledge graph (KG) is favorable for promoting the high-quality development of petroleum industry. KG, as an emerging technology based on artificial intelligence and knowledge representation, has become the research hotspot and focus in petroleum exploration and development. Ⅰn this paper, such current applications of KG are summarized systematically in four major domains, i.e., geophysical exploration, drilling and completion, well logging, and reservoir engineering. Then, combined with Large Language Models (LLMs), the challenges that KG encounters in the petroleum exploration and development are dissected, and the future directions are predicted. And the following research results are obtained. First, in the field of petroleum exploration and development, KG, combined with deep learning model and expert experience, is widely used in geological data management, information interpretation, anomaly detection and analysis, intelligent decision making support, fault diagnosis, comprehensive analysis of logging data, interpretation of logging data, automatic matching of logging curves, reservoir description, numerical reservoir simulation, reservoir management, and equipment fault maintenance, and achieves the functions such as data quality improvement, data utilization rate improvement, and real-time reservoir performance monitoring, effectively improving the efficiency of exploration and development. Second, when KG is applied in petroleum exploration and development, it face challenges such as multi-source heterogeneous data, acquisition and representation of professional knowledge, knowledge updating and maintenance, demand for computing resources, and interdisciplinary collaboration and application, so it needs continuous research and innovation in terms of technology, standard and collaboration mechanism to fully leverage its potential in petroleum exploration and development. Ⅰn conclusion, the KG technology with promising prospects is applied to knowledge search, recommendation, sharing, intelligent question-answering, reasoning, and computation, as well as the integration of KG with LLMs in the context of petroleum exploration and development, and the technological research keeps on its focus on large-scale models for petroleum exploration and development, simulation models based on mechanism models and intelligent models, and multimodal technology, etc., which will propel the industry to be more intelligent, efficient and precise. © 2024 Natural Gas Industry Journal Agency. All rights reserved.},
	author_keywords = {Drilling and completion domain; Geophysical exploration domain; Knowledge graph; Large Language Models (LLMs); Logging domain; Petroleum exploration and development; Reservoir engineering domain},
	keywords = {Data quality; Deep oil well drilling; Exploratory oil well drilling; Gasoline; Intelligent well technology; Knowledge acquisition; Natural gas well logging; Oil field development; Oil wells; Petroleum geology; Petroleum reservoir evaluation; Research and development management; Seismic prospecting; Drilling and completion; Drilling and completion domain; Engineering domains; Exploration and development; Exploration domain; Geophysical exploration; Geophysical exploration domain; Knowledge graphs; Language model; Large language model; Logging domain; Petroleum development; Petroleum exploration; Reservoir engineering; Reservoir engineering domain; Knowledge representation},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{Mansourian2024,
	author = {Mansourian, Ali and Oucheikh, Rachid},
	title = {ChatGeoAI: Enabling Geospatial Analysis for Public through Natural Language, with Large Language Models},
	year = {2024},
	journal = {ISPRS International Journal of Geo-Information},
	volume = {13},
	number = {10},
	doi = {10.3390/ijgi13100348},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207678194&doi=10.3390%2fijgi13100348&partnerID=40&md5=7b68b79205cdad625330856e110fd60e},
	abstract = {Large Language Models (LLMs) such as GPT, BART, and Gemini stand at the forefront of Generative Artificial Intelligence, showcasing remarkable prowess in natural language comprehension and task execution. This paper proposes a novel framework developed on the foundation of Llama 2, aiming to bridge the gap between natural language queries and executable code for geospatial analyses within the PyQGIS environment. It empowers non-expert users to leverage GIS technology without requiring deep knowledge of geospatial programming or tools. Through cutting-edge Natural Language Processing (NLP) techniques, including tailored entity recognition and ontology mapping, the framework accurately interprets user intents and translates them into specific GIS operations. Integration of geospatial ontologies enriches semantic comprehension, ensuring precise alignment between user descriptions, geospatial datasets, and geospatial analysis tasks. A code generation module empowered by Llama 2 converts these interpretations into PyQGIS scripts, enabling the execution of geospatial analysis and results visualization. Rigorous testing across a spectrum of geospatial analysis tasks, with incremental complexity, evaluates the framework and the performance of such a system, with LLM at its core. The proposed system demonstrates proficiency in handling various geometries, spatial relationships, and attribute queries, enabling accurate and efficient analysis of spatial datasets. Moreover, it offers robust error-handling mechanisms and supports tasks related to map styling, visualization, and data manipulation. However, it has some limitations, such as occasional struggles with ambiguous attribute names and aliases, which leads to potential inaccuracies in the filtering and retrieval of features. Despite these limitations, the system presents a promising solution for applications integrating LLMs into GIS and offers a flexible and user-friendly approach to geospatial analysis. © 2024 by the authors.},
	author_keywords = {code generation; GeoAI; geospatial analysis; GIS; GIS democratization; large language model; Llama; natural language processing},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Xu20245543,
	author = {Xu, Eric and Zhang, Wenbin and Xu, Weifeng},
	title = {Transforming Digital Forensics with Large Language Models: Unlocking Automation, Insights, and Justice},
	year = {2024},
	journal = {International Conference on Information and Knowledge Management, Proceedings},
	pages = {5543 – 5546},
	doi = {10.1145/3627673.3679091},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201270292&doi=10.1145%2f3627673.3679091&partnerID=40&md5=79c50162594ebb34f26840edee0ec769},
	abstract = {In the pursuit of justice and accountability in the digital age, the integration of Large Language Models (LLMs) with digital forensics holds immense promise. This half-day tutorial provides a comprehensive exploration of the transformative potential of LLMs in automating digital investigations and uncovering hidden insights. Through a combination of real-world case studies, interactive exercises, and hands-on labs, participants will gain a deep understanding of how to harness LLMs for evidence analysis, entity identification, and knowledge graph reconstruction. By fostering a collaborative learning environment, this tutorial aims to empower professionals, researchers, and students with the skills and knowledge needed to drive innovation in digital forensics. As LLMs continue to revolutionize the field, this tutorial will have far-reaching implications for enhancing justice outcomes, promoting accountability, and shaping the future of digital investigations.  © 2024 Owner/Author.},
	author_keywords = {automation; digital forensics; evidence analysis; knowledge graph reconstruction; large language model},
	keywords = {Adversarial machine learning; Collaborative learning; Computer forensics; Contrastive Learning; Electronic crime countermeasures; Forensic engineering; Teaching; Case-studies; Digital age; Digital investigation; Evidence analysis; Interactive exercise; Knowledge graph reconstruction; Knowledge graphs; Language model; Large language model; Real-world; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Tu202419595,
	author = {Tu, Qingshi and Guo, Jing and Li, Nan and Qi, Jianchuan and Xu, Ming},
	title = {Mitigating Grand Challenges in Life Cycle Inventory Modeling through the Applications of Large Language Models},
	year = {2024},
	journal = {Environmental Science and Technology},
	volume = {58},
	number = {44},
	pages = {19595 – 19603},
	doi = {10.1021/acs.est.4c07634},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206920514&doi=10.1021%2facs.est.4c07634&partnerID=40&md5=a6c4d4d8aac9e7339c689a2c24ba9a5f},
	abstract = {The accuracy of life cycle assessment (LCA) studies is often questioned due to the two grand challenges of life cycle inventory (LCI) modeling: (1) missing foreground flow data and (2) inconsistency in background data matching. Traditional mechanistic methods (e.g., process simulation) and existing machine learning (ML) methods (e.g., similarity-based selection methods) are inadequate due to their limitations in scalability and generalizability. The large language models (LLMs) are well-positioned to address these challenges, given the massive and diverse knowledge learned through the pretraining step. Incorporating LLMs into LCI modeling can lead to the automation of inventory data curation from diverse data sources and to the implementation of a multimodal analytical capacity. In this article, we delineated the mechanisms and advantages of LLMs to addressing these two grand challenges. We also discussed the future research to enhance the use of LLMs for LCI modeling, which includes the key areas such as improving retrieval augmented generation (RAG), integration with knowledge graphs, developing prompt engineering strategies, and fine-tuning pretrained LLMs for LCI-specific tasks. The findings from our study serve as a foundation for future research on scalable and automated LCI modeling methods that can provide more appropriate data for LCA calculations. © 2024 American Chemical Society.},
	author_keywords = {automation; background data mapping; large language models; life cycle assessment; life cycle inventory; missing data; scalability},
	keywords = {Language; Life Cycle Stages; Machine Learning; Models, Theoretical; Background data mapping; Data mappings; Data matching; Flow data; Grand Challenge; Inventory modeling; Language model; Large language model; Life Cycle Inventory; Missing data; automation; foundation; inventory; life cycle analysis; machine learning; model validation; numerical model; research program; automation; human; information retrieval; large language model; life cycle; life cycle assessment; machine learning; process model; prompt engineering; review; therapy; language; life cycle stage; machine learning; theoretical model},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Song2024,
	author = {Song, Sihan and Yang, Chuncheng and Xu, Li and Shang, Haibin and Li, Zhuo and Chang, Yinghui},
	title = {TravelRAG: A Tourist Attraction Retrieval Framework Based on Multi-Layer Knowledge Graph},
	year = {2024},
	journal = {ISPRS International Journal of Geo-Information},
	volume = {13},
	number = {11},
	doi = {10.3390/ijgi13110414},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210250653&doi=10.3390%2fijgi13110414&partnerID=40&md5=5da83c7907a9e72d9b7e75473e50bbaf},
	abstract = {A novel framework called TravelRAG is introduced in this paper, which is built upon a large language model (LLM) and integrates Retrieval-Augmented Generation (RAG) with knowledge graphs to create a retrieval system framework designed for the tourism domain. This framework seeks to address the challenges LLMs face in providing precise and contextually appropriate responses to domain-specific queries in the tourism field. TravelRAG extracts information related to tourist attractions from User-Generated Content (UGC) on social media platforms and organizes it into a multi-layer knowledge graph. The travel knowledge graph serves as the core retrieval source for the LLM, enhancing the accuracy of information retrieval and significantly reducing the generation of erroneous or fabricated responses, often termed as “hallucinations”. As a result, the accuracy of the LLM’s output is enhanced. Comparative analyses with traditional RAG pipelines indicate that TravelRAG significantly boosts both the retrieval efficiency and accuracy, while also greatly reducing the computational cost of model fine-tuning. The experimental results show that TravelRAG not only outperforms traditional methods in terms of retrieval accuracy but also better meets user needs for content generation. © 2024 by the authors.},
	author_keywords = {document intelligence; explainability; GeoAI; retrieval-augmented generation; tourism knowledge graph},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Chen2024,
	author = {Chen, Lu and Xu, Jihui and Wu, Tianyu and Liu, Jie},
	title = {Information Extraction of Aviation Accident Causation Knowledge Graph: An LLM-Based Approach},
	year = {2024},
	journal = {Electronics (Switzerland)},
	volume = {13},
	number = {19},
	doi = {10.3390/electronics13193936},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208786490&doi=10.3390%2felectronics13193936&partnerID=40&md5=aedfad1f20d73c13339d249d0d1e0723},
	abstract = {Summarizing the causation of aviation accidents is conducive to enhancing aviation safety. The knowledge graph of aviation accident causation, constructed based on aviation accident reports, can assist in analyzing the causes of aviation accidents. With the continuous development of artificial intelligence technology, leveraging large language models for information extraction and knowledge graph construction has demonstrated significant advantages. This paper proposes an information extraction method for aviation accident causation based on Claude-prompt, which relies on the large-scale pre-trained language model Claude 3.5. Through prompt engineering, combined with a few-shot learning strategy and a self-judgment mechanism, this method achieves automatic extraction of accident-cause entities and their relationships. Experimental results indicate that this approach effectively improves the accuracy of information extraction, overcoming the limitations of traditional methods in terms of accuracy and efficiency in processing complex texts. It provides strong support for subsequently constructing a structured knowledge graph of aviation accident causation and conducting causation analysis of aviation accidents. © 2024 by the authors.},
	author_keywords = {accident causation; aviation safety; information extraction; knowledge graphs; large language models (LLMs)},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Gao2024,
	author = {Gao, Yan and Xiong, Guanyu and Li, Haijiang and Richards, Jarrod},
	title = {Exploring bridge maintenance knowledge graph by leveraging GrapshSAGE and text encoding},
	year = {2024},
	journal = {Automation in Construction},
	volume = {166},
	doi = {10.1016/j.autcon.2024.105634},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199297205&doi=10.1016%2fj.autcon.2024.105634&partnerID=40&md5=e57a047d034c74069b65e44c6a48e72f},
	abstract = {Knowledge graphs (KGs) are crucial in documenting bridge maintenance expertise. However, existing KG schemas lack integration of bridge design and practical inspection insights. Meanwhile, traditional methods for node feature initialization, relying on meticulous manual encoding or word embeddings, are inadequate for real-world maintenance textual data. To address these challenges, this paper introduces a bridge maintenance-oriented KG (BMKG) schema and approaches for graph data mining, including node-layer classification and link prediction. These methods leverage large language model (LLM)-based text encoding combined with GraphSAGE, demonstrating excellent performance in semantic enrichment and KG completion on deficient BMKGs. Additionally, ablation studies reveal the superiority of the pre-trained BERT text encoder and the L2 distance pairwise scoring calculator. Furthermore, a practical implementation framework integrating these approaches is developed for routine bridge maintenance, which can facilitate various practical applications, such as maintenance planning, and has the potential to enhance the efficiency of engineers' documentation work. © 2024 The Author(s)},
	author_keywords = {Bridge maintenance knowledge graph; Graph neural networks; Link prediction; Node classification; Text encoding},
	keywords = {Classification (of information); Data mining; Directed graphs; Encoding (symbols); Knowledge graph; Knowledge management; Maintenance; Network coding; Semantics; Text processing; Bridge design; Bridge maintenance knowledge graph; Bridges maintenance; Encodings; Feature initialization; Graph neural networks; Knowledge graphs; Link prediction; Node classification; Text encoding; Graph neural networks},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Wu2024,
	author = {Wu, Tianxing and Yao, Kai and Li, Wei and Qi, Guilin and Yu, Yijun and Zhao, Nengwen and Zhang, Renyou and Duan, Peibo},
	title = {Triple confidence measurement in knowledge graph with multiple heterogeneous evidences},
	year = {2024},
	journal = {World Wide Web},
	volume = {27},
	number = {6},
	doi = {10.1007/s11280-024-01307-x},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205713578&doi=10.1007%2fs11280-024-01307-x&partnerID=40&md5=8c990355b6e5b622d59b58ef708f1179},
	abstract = {Knowledge graph (KG) is a representative technique of knowledge engineering, and it is often used in various intelligence applications, which assume that all triples in knowledge graphs (KGs) are correct. However, due to the noise brought by automatic KG construction techniques and the fuzziness of knowledge in specific fields, measuring uncertainty of KGs (i.e., the confidence of each triple being true) is important to the tasks of error detection and fact verification. Existing studies on triple confidence measurement either only relies on explicit evidences or merely depends on embedding evidences, which causes the resulting confidences are not precise enough. To solve this problem, in this paper, we propose a new triple confidence measurement (TCM) method, which combines multiple heterogeneous evidences including explicit evidences (i.e., concept paths and neighbor concept subgraphs) and different embedding evidences acquired by large language model, KG embedding models, contrastive learning, and graph convolutional network. Experiments on different real-world datasets demonstrate not only the superiority of TCM in the tasks of error detection and link prediction, but also the effectiveness of all proposed explicit evidences and embedding evidences. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.},
	author_keywords = {Knowledge graph; Knowledge graph embedding; Triple confidence measurement},
	keywords = {Contrastive Learning; Graph embeddings; Network embeddings; Construction technique; Embeddings; Graph construction; Graph embeddings; Knowledge graph embedding; Knowledge graphs; Knowledge IT; Measuring uncertainty; Triple confidence measurement; Knowledge graph},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Xu20245603,
	author = {Xu, Jiejun and Tong, Hanghang and Bertozzi, Andrea},
	title = {The 8th Workshop on Graph Techniques for Adversarial Activity Analytics (GTA3 2024)},
	year = {2024},
	journal = {International Conference on Information and Knowledge Management, Proceedings},
	pages = {5603 – 5604},
	doi = {10.1145/3627673.3680119},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210006059&doi=10.1145%2f3627673.3680119&partnerID=40&md5=0c9f778f845c7c2d58d59428ae7a27ff},
	abstract = {Graphs are powerful analytic tools for modeling adversarial activities across a wide range of domains and applications. Examples include identifying and responding to cybersecurity systems' threats and vulnerabilities, strengthening critical infrastructure's resilience and robustness, and combating covert illicit activities that span various domains like finance, communication, and transportation. With the rapid development of generative AI, the lifecycle and throughput of adversarial activities, such as generating attacks or synthesizing deceptive signals, have accelerated significantly. For instance, a malicious actor can generate a large number of malware variants to flood defense systems or create agents to disseminate misleading signals, obscuring their activities. Consequently, there is a pressing need for novel and effective technology to autonomously handle these adversarial activities and keep pace with the evolving threats. The purpose of this workshop is to provide a forum to discuss emerging research problems and novel approaches in graph analysis for modeling adversarial activities in the age of generative AI.  © 2024 ACM.},
	author_keywords = {adversarial activity analytics; graph machine learning; graph mining; knowledge representation},
	keywords = {Generative adversarial networks; Knowledge graph; Malware; Adversarial activity analytic; Analytic tools; Cyber security; Graph machine; Graph machine learning; Graph mining; Graph technique; Knowledge-representation; Machine-learning; Threats and vulnerabilities; Adversarial machine learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Gubanov20244497,
	author = {Gubanov, Michael and Pyayt, Anna and Karolak, Aleksandra},
	title = {CancerKG.ORG - A Web-scale, Interactive, Verifiable Knowledge Graph-LLM Hybrid for Assisting with Optimal Cancer Treatment and Care},
	year = {2024},
	journal = {International Conference on Information and Knowledge Management, Proceedings},
	pages = {4497 – 4505},
	doi = {10.1145/3627673.3680094},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210005883&doi=10.1145%2f3627673.3680094&partnerID=40&md5=fc24074756f2ae416dce13f25a280cfd},
	abstract = {Here, we describe one of the first Web-scale hybrid Knowledge Graph (KG)-Large Language Model (LLM), populated with the latest peer-reviewed medical knowledge on colorectal Cancer. It is currently being evaluated to assist with both medical research and clinical information retrieval tasks at Moffitt Cancer Center and Research Institute, which is one of the top Cancer centers in the U.S. and in the world. Our hybrid is remarkable as it serves the user needs better than just an LLM, KG or a search-engine in isolation. LLMs as is are known to exhibit hallucinations and catastrophic forgetting as well as are trained on outdated corpora. The state of the art KGs, such as PrimeKG, cBioPortal, ChEMBL, NCBI, and other require manual curation, hence are quickly getting stale. CancerKG is unsupervised and is capable of automatically ingesting and organizing the latest medical findings. To alleviate the LLMs shortcomings, the verified KG serves as a Retrieval Augmented Generation (RAG) guardrail. CancerKG exhibits 5 different advanced user interfaces, each tailored to serve different data modalities better and more convenient for the user. We evaluated CancerKG on real user queries and report a high NDCG score on a large-scale corpora of approximately 44K publications.  © 2024 ACM.},
	author_keywords = {artificial intelligence (AI); cancer; data management; LLM},
	keywords = {Lung cancer; Artificial intelligence; Cancer; Clinical information; Hybrid knowledge; Knowledge graphs; Language model; Large language model; Medical knowledge; Medical research; Research institutes; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Kloosterman20245336,
	author = {Kloosterman, Daan J. and Erbani, Johanna and Boon, Menno and Farber, Martina and Handgraaf, Shanna M. and Ando-Kuri, Masami and Sánchez-López, Elena and Fontein, Bauke and Mertz, Marjolijn and Nieuwland, Marja and Liu, Ning Qing and Forn-Cuni, Gabriel and van der Wel, Nicole N. and Grootemaat, Anita E. and Reinalda, Luuk and van Kasteren, Sander I. and de Wit, Elzo and Ruffell, Brian and Snaar-Jagalska, Ewa and Petrecca, Kevin and Brandsma, Dieta and Kros, Alexander and Giera, Martin and Akkari, Leila},
	title = {Macrophage-mediated myelin recycling fuels brain cancer malignancy},
	year = {2024},
	journal = {Cell},
	volume = {187},
	number = {19},
	pages = {5336 – 5356.e30},
	doi = {10.1016/j.cell.2024.07.030},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201934715&doi=10.1016%2fj.cell.2024.07.030&partnerID=40&md5=8a28790fa813e12475dcb431645c161c},
	abstract = {Tumors growing in metabolically challenged environments, such as glioblastoma in the brain, are particularly reliant on crosstalk with their tumor microenvironment (TME) to satisfy their high energetic needs. To study the intricacies of this metabolic interplay, we interrogated the heterogeneity of the glioblastoma TME using single-cell and multi-omics analyses and identified metabolically rewired tumor-associated macrophage (TAM) subpopulations with pro-tumorigenic properties. These TAM subsets, termed lipid-laden macrophages (LLMs) to reflect their cholesterol accumulation, are epigenetically rewired, display immunosuppressive features, and are enriched in the aggressive mesenchymal glioblastoma subtype. Engulfment of cholesterol-rich myelin debris endows subsets of TAMs to acquire an LLM phenotype. Subsequently, LLMs directly transfer myelin-derived lipids to cancer cells in an LXR/Abca1-dependent manner, thereby fueling the heightened metabolic demands of mesenchymal glioblastoma. Our work provides an in-depth understanding of the immune-metabolic interplay during glioblastoma progression, thereby laying a framework to unveil targetable metabolic vulnerabilities in glioblastoma. © 2024 The Authors},
	author_keywords = {cancer immunity; cholesterol; glioblastoma; lipid metabolism; macrophages; myelin recycling; tumor microenvironment},
	keywords = {Animals; ATP Binding Cassette Transporter 1; Brain Neoplasms; Cell Line, Tumor; Cholesterol; Female; Glioblastoma; Humans; Liver X Receptors; Macrophages; Male; Mice; Myelin Sheath; Tumor Microenvironment; Tumor-Associated Macrophages; ABC transporter A1; cell surface marker; liver X receptor; myelin; ABC transporter A1; ABCA1 protein, human; cholesterol; liver X receptor; animal cell; animal experiment; Article; autofluorescence; bicinchoninic acid assay; bone marrow derived macrophage; brain cancer; brain interstitial fluid; bulk ATAC seq library preparation; cancer recurrence; cDNA synthesis; cell proliferation; cell proliferation assay; cell viability; cholesterol blood level; cholesterol staining; chromatin; chromatin landscape; coculture; controlled study; DNA synthesis; electron microscopy; electrospray mass spectrometry; epigenetics; ex vivo study; extracellular acidification rate; fatty acid analysis; female; flow cytometry; fluorescence activated cell sorting; fluorescence intensity; frozen section; gene expression profiling; gene library; gene ontology; gene set enrichment analysis; glioblastoma; illumina sequencing; image analysis; immunofluorescence assay; immunosuppressive treatment; in vitro study; in vivo study; interstitial fluid; KEGG; lipid analysis; lipid extraction; lipid laden macrophage; lipid storage; lipidomics; liquid chromatography-mass spectrometry; live cell imaging; macrophage; male; mass fragmentography; metabolic activity assay; metabolite; metabolomics; microglia; mitochondrial respiration; monoculture; motif enrichment analysis; mouse; mRNA expression assay; multiomics; nonhuman; nuclear magnetic resonance spectroscopy; oxygen consumption; phenotype; predictive value; real time reverse transcription polymerase chain reaction; recycling; remyelinization; RNA extraction; RNA sequence; seahorse assay; single cell RNA seq; staining; sterol analysis; survival analysis; tissue and cell imaging; tumor cell monoculture; tumor growth; tumor microenvironment; tumor-associated macrophage; ultracentrifugation; animal; brain tumor; glioblastoma; human; immunology; macrophage; metabolism; myelin sheath; pathology; tumor cell line; tumor microenvironment},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 16; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Li20242326,
	author = {Li, Yifei and Zhang, Lingling and Dong, Yuxuan and Wang, Jiaxin and Zhong, Yujie and Wei, Bifan},
	title = {Large Language Model Augmentation and Feature Alignment Method for Few-Shot Continual Relation Extraction; [基于大语言模型增强表征对齐的小样本持续关系抽取方法]},
	year = {2024},
	journal = {Journal of Frontiers of Computer Science and Technology},
	volume = {18},
	number = {9},
	pages = {2326 – 2336},
	doi = {10.3778/j.issn.1673-9418.2406056},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203294758&doi=10.3778%2fj.issn.1673-9418.2406056&partnerID=40&md5=1c15d5a970a5dca5d6e59f55d7d23ebc},
	abstract = {Relation extraction, as a key task in natural language processing, plays a significant role in deepening language understanding, constructing knowledge graphs, and optimizing information retrieval systems. However, traditional supervised learning methods are not well-suited for real-world scenarios due to the continuous emergence of new relations and the lack of large annotated datasets. Although the advent of large language models has significantly improved the performance of many natural language processing tasks, they still cannot effectively address the challenges of few-shot continual relation extraction. To fully leverage the semantic knowledge of large language models to mitigate catastrophic forgetting and overfitting issues, a novel few-shot continual relation extraction method, LAFA (large language model augmentation and feature alignment), is proposed. This method enhances representation alignment through various strategies such as relation instance rewriting, semantic expansion, and enhanced relation representation. It effectively improves the model adaptability to new relations and the retention of old knowledge while maintaining low data and computational costs. Experimental validation on two relation extraction datasets, FewRel and TACRED, demonstrates that LAFA outperforms existing methods in few- shot continual relation extraction tasks, particularly achieving the best results in incremental stages. Ablation experiments further reveal the significant contributions of each module to overall performance. Moreover, the inference efficiency and cost of LAFA are substantially lower than those of existing large language model-based methods, and it boasts strong scalability, being able to adapt to various language models. © 2024 Journal of Computer Engineering and Applications Beijing Co., Ltd.; Science Press. All rights reserved.},
	author_keywords = {continual learning; few-shot learning; large language model (LLM); relation extraction},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Konstantinidis2024,
	author = {Konstantinidis, Ioannis and Kapantai, Eleni and Michailidis, Alexios and Deligiannis, Athanasios and Berberidis, Christos and Magnisalis, Ioannis and Peristeras, Vassilios},
	title = {From document-centric to data-centric public service provision},
	year = {2024},
	journal = {Digital Government: Research and Practice},
	volume = {5},
	number = {3},
	doi = {10.1145/3676279},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207085243&doi=10.1145%2f3676279&partnerID=40&md5=1417f5b01377a1c12c787be6f9a73231},
	abstract = {The profound digitization of public administration over recent decades has not eliminated information exchange via paper or electronic documents and certificates. We argue that a paradigm shift from document-centric to data-centric public service provision is needed and is feasible today with the exploitation of emerging technologies. We explore frameworks, architectures, benefits, and challenges in transforming document-centric administration processes into integrated, granular data exchange. A conceptual architecture for public service provision is proposed to extract preconditions from legislation, map the needed evidence to the service requirements, standardize evidence types, and integrate authoritative data sources. While promoting efficiency, privacy, and innovation, this shift faces technical and organizational challenges as the analysis of the "National Registry of Administrative Public Services"in Greece reveals. Further research on aligning policies, upholding trust, and coordinating institutional processes is warranted.  © 2024 held by the owner/author(s).},
	author_keywords = {AI; data; digital transformation; Knowledge Graphs; LLMs; public service},
	keywords = {Data; Data centric; Digital transformation; Digitisation; Information exchanges; Knowledge graphs; LLM; Paper documents; Public service provisions; Public services},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Hu20241205,
	author = {Hu, Jiayuan and Qiu, Ruijin and Sun, Yang and Shang, Hongcai},
	title = {Natural language processing and its application in the medical field; [自然语言处理及其在医学领域的应用]},
	year = {2024},
	journal = {Chinese Journal of Evidence-Based Medicine},
	volume = {24},
	number = {10},
	pages = {1205 – 1211},
	doi = {10.7507/1672-2531.202311178},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210389258&doi=10.7507%2f1672-2531.202311178&partnerID=40&md5=cd19e01d1006f5280180db5ad3065053},
	abstract = {Natural language processing (NLP) is the embodiment of computer intelligence in acquiring knowledge, understanding, processing and expressing consciously and actively. It is the scientific key to promoting the informatization of medical practice and research. This paper reviews the development history and research basis of NLP, and focuses on the current application of NLP and large language models in biomedicine and traditional Chinese medicine (TCM), including the intelligent reading, information extraction and feedback of medical texts and ancient books of TCM, as well as the construction of medical knowledge graph and question-answering system. NLP is the technical support to explore the treasure house of TCM, which is of great practical significance to further promote the development of efficient and high-quality core values of TCM and to improve the service capacity. © 2024 West China University of Medical Science. All rights reserved.},
	author_keywords = {Medicine information; Natural language processing; Traditional Chinese medicine},
	keywords = {Article; biomedicine; Chinese medicine; data extraction; drug information; human; intelligence; knowledge; large language model; natural language processing; reading},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Liu2024,
	author = {Liu, Xiaona and Wang, Qing and Zhou, Minghao and Wang, Yanfei and Wang, Xuefeng and Zhou, Xiaobo and Song, Qianqian},
	title = {DrugFormer: Graph-Enhanced Language Model to Predict Drug Sensitivity},
	year = {2024},
	journal = {Advanced Science},
	volume = {11},
	number = {40},
	doi = {10.1002/advs.202405861},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202597517&doi=10.1002%2fadvs.202405861&partnerID=40&md5=75be36466cb676ea896f4738439ace47},
	abstract = {Drug resistance poses a crucial challenge in healthcare, with response rates to chemotherapy and targeted therapy remaining low. Individual patient's resistance is exacerbated by the intricate heterogeneity of tumor cells, presenting significant obstacles to effective treatment. To address this challenge, DrugFormer, a novel graph-augmented large language model designed to predict drug resistance at single-cell level is proposed. DrugFormer integrates both serialized gene tokens and gene-based knowledge graphs for the accurate predictions of drug response. After training on comprehensive single-cell data with drug response information, DrugFormer model presents outperformance, with higher F1, precision, and recall in predicting drug response. Based on the scRNA-seq data from refractory multiple myeloma (MM) and acute myeloid leukemia (AML) patients, DrugFormer demonstrates high efficacy in identifying resistant cells and uncovering underlying molecular mechanisms. Through pseudotime trajectory analysisunique drug-resistant cellular states associated with poor patient outcomes are revealed. Furthermore, DrugFormer identifies potential therapeutic targets, such as COX8A, for overcoming drug resistance across different cancer types. In conclusion, DrugFormer represents a significant advancement in the field of drug resistance prediction, offering a powerful tool for unraveling the heterogeneity of cellular response to drugs and guiding personalized treatment strategies. © 2024 The Author(s). Advanced Science published by Wiley-VCH GmbH.},
	author_keywords = {drug resistance; knowledge graph; language model; single-cell RNA sequencing},
	keywords = {Antineoplastic Agents; Drug Resistance, Neoplasm; Humans; Leukemia, Myeloid, Acute; Multiple Myeloma; Genes; Knowledge graph; antineoplastic agent; Drug response; Drug-resistance; Drug-sensitivity; Knowledge graphs; Language model; Response rate; Single cells; Single-cell level; Single-cell RNA sequencing; Tumour cells; acute myeloid leukemia; drug resistance; drug therapy; genetics; human; multiple myeloma; Chemotherapy},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Zhang20242656,
	author = {Zhang, Caike and Li, Xiaolong and Zheng, Sheng and Cai, Jiajun and Ye, Xiaozhou and Luo, Jing},
	title = {Research on Construction and Application of Knowledge Graph Based on Large Language Model; [基于大语言模型的知识图谱构建及应用研究]},
	year = {2024},
	journal = {Journal of Frontiers of Computer Science and Technology},
	volume = {18},
	number = {10},
	pages = {2656 – 2667},
	doi = {10.3778/j.issn.1673-9418.2406013},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206515503&doi=10.3778%2fj.issn.1673-9418.2406013&partnerID=40&md5=3886ca855c2305b1c60aadc184c9d9dd},
	abstract = {Massive amounts of operational and maintenance (O&M) data from nuclear power distributed control system (DCS) contain rich operational experience and expert knowledge. Effectively extracting DCS alarm response information and forming knowledge service is a current hotspot and frontier research area in rapid DCS response. Due to the lack of clear structure and standards in multi-source heterogeneous data of nuclear power DCS, previous knowledge extraction primarily relied on manual annotation and deep learning methods, which require extensive domain knowledge and information processing capabilities and are constrained by the heavy workload of data annotation. Therefore, this study proposes a knowledge extraction method using large language model (LLM) with a step-by-step prompting strategy, constructing a DCS O&M knowledge graph (KG). Based on large language model technology and secondary intent recognition methods, intelligent question and answer (Q&A) and other knowledge services are developed utilizing the knowledge graph. Using O&M data from a nuclear power plant’s DCS as a case study, the research focuses on knowledge extraction, knowledge graph construction, and intelligent Q&A. The results show that the model achieves an overall precision (P) of 91.24%, recall (R) of 85.85%, and F1- score of 88.43% . The proposed method can comprehensively capture key entities and attribute information from multi-source heterogeneous DCS O&M data, guiding domain knowledge Q&A, assisting O&M personnel in timely responding to DCS alarm anomalies, analyzing fault causes and response strategies, and providing guidance for DCS O&M training and maintenance in power plants. © 2024 Journal of Computer Engineering and Applications Beijing Co., Ltd.; Science Press. All rights reserved.},
	author_keywords = {answer (Q&A); intelligent question; knowledge extraction; knowledge graph; large language model; nuclear power distributed control system},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Buehler2024,
	author = {Buehler, Markus J},
	title = {Accelerating scientific discovery with generative knowledge extraction, graph-based representation, and multimodal intelligent graph reasoning},
	year = {2024},
	journal = {Machine Learning: Science and Technology},
	volume = {5},
	number = {3},
	doi = {10.1088/2632-2153/ad7228},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206499137&doi=10.1088%2f2632-2153%2fad7228&partnerID=40&md5=94ed91f84a18f9d1bc6639226979d627},
	abstract = {Leveraging generative Artificial Intelligence (AI), we have transformed a dataset comprising 1000 scientific papers focused on biological materials into a comprehensive ontological knowledge graph. Through an in-depth structural analysis of this graph, we have calculated node degrees, identified communities along with their connectivities, and evaluated clustering coefficients and betweenness centrality of pivotal nodes, uncovering fascinating knowledge architectures. We find that the graph has an inherently scale-free nature, shows a high level of connectedness, and can be used as a rich source for downstream graph reasoning by taking advantage of transitive and isomorphic properties to reveal insights into unprecedented interdisciplinary relationships that can be used to answer queries, identify gaps in knowledge, propose never-before-seen material designs, and predict material behaviors. Using a large language embedding model we compute deep node representations and use combinatorial node similarity ranking to develop a path sampling strategy that allows us to link dissimilar concepts that have previously not been related. One comparison revealed detailed structural parallels between biological materials and Beethoven’s 9th Symphony, highlighting shared patterns of complexity through isomorphic mapping. In another example, the algorithm proposed an innovative hierarchical mycelium-based composite based on integrating path sampling with principles extracted from Kandinsky’s ‘Composition VII’ painting. The resulting material integrates an innovative set of concepts that include a balance of chaos and order, adjustable porosity, mechanical strength, and complex patterned chemical functionalization. We uncover other isomorphisms across science, technology and art, revealing a nuanced ontology of immanence that reveal a context-dependent heterarchical interplay of constituents. Because our method transcends established disciplinary boundaries through diverse data modalities (graphs, images, text, numerical data, etc), graph-based generative AI achieves a far higher degree of novelty, explorative capacity, and technical detail, than conventional approaches and establishes a widely useful framework for innovation by revealing hidden connections. © 2024 The Author(s). Published by IOP Publishing Ltd.},
	author_keywords = {biomaterials; generative AI; Graph theory; language modeling; materials informatics; materials science; natural language processing},
	keywords = {Biological materials; Biomaterials; Chaos theory; Crystalline materials; Generative adversarial networks; Ontology; Generative artificial intelligence; Knowledge extraction; Language model; Language processing; Material Informatics; Material science; Natural language processing; Natural languages; Path sampling; Scientific discovery; Knowledge graph},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Yu2024,
	author = {Yu, Jingwen and Wang, Yaohao and Wang, Haidong and Wei, Zhi and Pei, Yonggang},
	title = {Decoding Critical Targets and Signaling Pathways in EBV-Mediated Diseases Using Large Language Models},
	year = {2024},
	journal = {Viruses},
	volume = {16},
	number = {11},
	doi = {10.3390/v16111660},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210446933&doi=10.3390%2fv16111660&partnerID=40&md5=a3614b73ddd935a00add8032264207f7},
	abstract = {Epstein–Barr virus (EBV), a member of the gamma herpesvirus, is the first identified human oncovirus and is associated with various malignancies. Understanding the intricate interactions between EBV antigens and cellular pathways is crucial to unraveling the molecular mechanisms in EBV-mediated diseases. However, fully elucidating EBV–host interactions and the associated pathogenesis remains a significant challenge. In this study, we employed large language models (LLMs) to screen 36,105 EBV-relevant scientific publications and summarize the current literature landscape on various EBV-associated diseases like Burkitt lymphoma (BL), diffuse large B-cell lymphoma (DLBCL), nasopharyngeal carcinoma (NPC), and so on. LLM-generated data indicate that the most-studied EBV-associated pathways are enriched in immune response, apoptosis, cell growth, and replication. The analyses of protein–protein interactions (PPIs) reveal three principal EBV-related protein clusters: TP53-centered apoptotic factors, EBV-associated transcription factors, and immune response elements. Utilizing our dataset and public databases, we demonstrated that BLLF3-targeted TLR2-associated factors are effective diagnostic markers for DLBCL. Next, we confirmed the co-expression of LMP1-targeted calcium pathway factors in BL. Finally, we demonstrated the correlation and co-expression of LMP1-induced PARP1, HIF1A, HK2, and key glycolysis-related factors, further suggesting that LMP1 actively regulates the glycolysis pathway. Therefore, our study presents a comprehensive functional encyclopedia of the interactions between EBV antigens and host signaling pathways across various EBV-associated diseases, providing valuable insights for the development of therapeutic strategies. © 2024 by the authors.},
	author_keywords = {EBV; EBV-mediated diseases; LLM; signaling pathways},
	keywords = {Burkitt Lymphoma; Epstein-Barr Virus Infections; Herpesvirus 4, Human; Host-Pathogen Interactions; Humans; Lymphoma, Large B-Cell, Diffuse; Nasopharyngeal Carcinoma; Protein Interaction Maps; Signal Transduction; host factor; interleukin 17; microRNA; transcription factor; apoptosis; Article; Burkitt lymphoma; carcinogenesis; cell growth; cell proliferation; cell survival; diffuse large B cell lymphoma; Epstein Barr virus; Epstein Barr virus infection; gene expression; gene mutation; gene ontology; gene silencing; immune response; innate immunity; large language model; lipid metabolism; MAPK signaling; mismatch repair; nasopharynx carcinoma; nonhuman; omics; oxidative phosphorylation; Pi3K/Akt signaling; protein homeostasis; protein misfolding; protein phosphorylation; protein protein interaction; signal transduction; transcription regulation; tumor microenvironment; ubiquitination; unfolded protein response; upregulation; host pathogen interaction; human; metabolism; physiology; virology},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Zhao20245086,
	author = {Zhao, Qian and Qian, Hao and Liu, Ziqi and Zhang, Gong-Duo and Gu, Lihong},
	title = {Breaking the Barrier: Utilizing Large Language Models for Industrial Recommendation Systems through an Inferential Knowledge Graph},
	year = {2024},
	journal = {International Conference on Information and Knowledge Management, Proceedings},
	pages = {5086 – 5093},
	doi = {10.1145/3627673.3680022},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210004162&doi=10.1145%2f3627673.3680022&partnerID=40&md5=5b3d488252ac420f183883faee368730},
	abstract = {Recommendation systems are widely used in e-commerce websites and online platforms to address information overload. However, existing systems primarily rely on historical data and user feedback, making it difficult to capture user intent transitions. Recently, Knowledge Base (KB)-based models are proposed to incorporate expert knowledge, but it struggle to adapt to new items and the evolving e-commerce environment. To address these challenges, we propose a novel Large Language Model based Complementary Knowledge Enhanced Recommendation System (LLM-KERec). It introduces an entity extractor that extracts unified concept terms from item and user information. To provide cost-effective and reliable prior knowledge, entity pairs are generated based on entity popularity and specific strategies. The large language model determines complementary relationships in each entity pair, constructing a complementary knowledge graph. Furthermore, a new complementary recall module and an Entity-Entity-Item (E-E-I) weight decision model refine the scoring of the ranking model using real complementary exposure-click samples. Extensive experiments conducted on three industry datasets demonstrate the significant performance improvement of our model compared to existing approaches. Additionally, detailed analysis shows that LLM-KERec enhances users' enthusiasm for consumption by recommending complementary items. In summary, LLM-KERec addresses the limitations of traditional recommendation systems by incorporating complementary knowledge and utilizing a large language model to capture user intent transitions, adapt to new items, and enhance recommendation efficiency in the evolving e-commerce landscape.  © 2024 ACM.},
	author_keywords = {knowledge graph; large language model; recommendation system},
	keywords = {Marketplaces; Modeling languages; Recommender systems; Address informations; Breakings; E- commerces; E-commerce websites; Existing systems; Information overloads; Knowledge graphs; Language model; Large language model; Online platforms; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@CONFERENCE{2024,
	title = {HT 2024: Creative Intelligence - 35th ACM Conference on Hypertext and Social Media},
	year = {2024},
	journal = {HT 2024: Creative Intelligence - 35th ACM Conference on Hypertext and Social Media},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204931114&partnerID=40&md5=0a90542c6c2781271567dadf637b6093},
	abstract = {The proceedings contain 58 papers. The topics discussed include: seeing through AI’s lens: enhancing human skepticism towards LLM-generated fake news; emotional hermeneutics. exploring the limits of artificial intelligence from a Diltheyan perspective; queering AI as a speculative practice: an analysis of the artistic explorations of new paradigms for developing inclusive AI; unwinding AI’s moral maze: hypertext’s ethical potential; conversational media for inclusive access to mental health interventions for schoolchildren; supporting the end-user curation of cultural heritage knowledge graphs; the handling of Vernon Lee’s words: developing scholarly editions in the age of hypertext; a new view: a hypertext view without boxes and arrows; beyond the page-break: towards better tools for remediation of born-digital documents; and authoring educational hypercomics assisted by large language models.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Wang20244331,
	author = {Wang, Jiawei and Cao, Da and Lu, Shaofei and Ma, Zhanchang and Xiao, Junbin and Chua, Tat-Seng},
	title = {Causal-driven Large Language Models with Faithful Reasoning for Knowledge Question Answering},
	year = {2024},
	journal = {MM 2024 - Proceedings of the 32nd ACM International Conference on Multimedia},
	pages = {4331 – 4340},
	doi = {10.1145/3664647.3681263},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209792418&doi=10.1145%2f3664647.3681263&partnerID=40&md5=3342921c0e0b90770723c1bd3de926ca},
	abstract = {In Large Language Models (LLMs), text generation that involves knowledge representation is often fraught with the risk of "hallucinations'', where models confidently produce erroneous or fabricated content. These inaccuracies often stem from intrinsic biases in the pre-training stage or from the incorporation of human preference biases during the fine-tuning process. To mitigate these issues, we take inspiration from Goldman's causal theory of knowledge, which asserts that knowledge is not merely about having a true belief but also involves a causal connection between the belief and the truth of the proposition. We instantiate this theory within the context of Knowledge Question Answering (KQA) by constructing a causal graph that delineates the pathways between the candidate knowledge and belief. Through the application of the do-calculus rules from structural causal models, we devise an unbiased estimation framework based on this causal graph, thereby establishing a methodology for knowledge modeling grounded in causal inference. The resulting CORE framework (short for "Causal knOwledge REasoning'') is comprised of four essential components: question answering, causal reasoning, belief scoring, and refinement. Together, they synergistically improve the KQA system by fostering faithful reasoning and introspection. Extensive experiments are conducted on ScienceQA and HotpotQA datasets, which demonstrate the effectiveness and rationality of the CORE framework. © 2024 ACM.},
	author_keywords = {causal theory of knowledge; knowledge question answering; large language models},
	keywords = {Risk assessment; Causal graph; Causal theory; Causal theory of knowledge; Knowledge question answering; Knowledge-representation; Language model; Large language model; Question Answering; Text generations; Theories of knowledge; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Burriss2024560,
	author = {Burriss, Sarah K. and Leander, Kevin},
	title = {Critical Posthumanist Literacy: Building Theory for Reading, Writing, and Living Ethically with Everyday Artificial Intelligence},
	year = {2024},
	journal = {Reading Research Quarterly},
	volume = {59},
	number = {4},
	pages = {560 – 569},
	doi = {10.1002/rrq.565},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199770323&doi=10.1002%2frrq.565&partnerID=40&md5=f5d40af6cafaf6cd77609db649eb0ab6},
	abstract = {Literacy has become inextricably bound with machine processes, especially in the age of ubiquitous, consequential artificial intelligence (AI). Despite a relatively long history of AI involvement in our everyday reading and writing practices, the public availability of generative AI tools has set off a wave of heated debate—and concern—about AI's role in our lives. We argue that critical literacy theory and tools can serve as a foundation, when combined with posthumanist ideas and some technical knowledge, for understanding, teaching, and participating in our AI-infused world. In this paper, we outline our theory of critical posthumanist literacy, which draws on posthumanist scholarship to re-imagine critical literacy with respect to concepts of ontology, agency, ethics and justice, and pedagogy. For each concept, we build on humanist, critical perspectives to show how posthumanist scholarship can help theorize for literacy in the age of AI, especially as AI presents both lingering and new challenges to conceptions of human text production and consumption. Posthumanism provides us with alternative modes of thinking about the nature of “things” (and ourselves); with an understanding of agency as not a human possession but an accomplishment among/within many human and non-human actors; with an expanded ethics that accounts more deeply for non-humans; and with pedagogy that embraces ambiguity, movement, and speculation. Using these ideas to expand critical literacy practices, we offer concepts and questions for guiding literacy practice and research, with the understanding that these are no longer separable from complex computational systems. © 2024 The Author(s). Reading Research Quarterly published by Wiley Periodicals LLC on behalf of International Literacy Association.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Zhu20243549,
	author = {Zhu, Yinghao and Ren, Changyu and Wang, Zixiang and Zheng, Xiaochen and Xie, Shiyun and Feng, Junlan and Zhu, Xi and Li, Zhoujun and Ma, Liantao and Pan, Chengwei},
	title = {EMERGE: Enhancing Multimodal Electronic Health Records Predictive Modeling with Retrieval-Augmented Generation},
	year = {2024},
	journal = {International Conference on Information and Knowledge Management, Proceedings},
	pages = {3549 – 3559},
	doi = {10.1145/3627673.3679582},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210014985&doi=10.1145%2f3627673.3679582&partnerID=40&md5=d886ef0112862d099aaf40da7f5ddcc4},
	abstract = {The integration of multimodal Electronic Health Records (EHR) data has significantly advanced clinical predictive capabilities. Existing models, which utilize clinical notes and multivariate time-series EHR data, often fall short of incorporating the necessary medical context for accurate clinical tasks, while previous approaches with knowledge graphs (KGs) primarily focus on structured knowledge extraction. In response, we propose EMERGE, a Retrieval-Augmented Generation (RAG) driven framework to enhance multimodal EHR predictive modeling. We extract entities from both time-series data and clinical notes by prompting Large Language Models (LLMs) and align them with professional PrimeKG, ensuring consistency. In addition to triplet relationships, we incorporate entities' definitions and descriptions for richer semantics. The extracted knowledge is then used to generate task-relevant summaries of patients' health statuses. Finally, we fuse the summary with other modalities using an adaptive multimodal fusion network with cross-attention. Extensive experiments on the MIMIC-III and MIMIC-IV datasets' in-hospital mortality and 30-day readmission tasks demonstrate the superior performance of the EMERGE framework over baseline models. Comprehensive ablation studies and analysis highlight the efficacy of each designed module and robustness to data sparsity. EMERGE contributes to refining the utilization of multimodal EHR data in healthcare, bridging the gap with nuanced medical contexts essential for informed clinical predictions. We have publicly released the code at https://github.com/yhzhu99/EMERGE.  © 2024 ACM.},
	author_keywords = {electronic health record; large language model; multimodal learning; retrieval-augmented generation},
	keywords = {Records management; Clinical notes; Electronic health; Health records; Language model; Large language model; Multi-modal; Multi-modal learning; Predictive capabilities; Predictive models; Retrieval-augmented generation; Electronic health record},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Diaz2024,
	author = {Diaz, Teresa Gonzalez and Lee, Xian Yeow and Zhuge, Huimin and Vidyaratne, Lasitha and Sin, Gregory and Watanabe, Tsubasa and Farahat, Ahmed and Gupta, Chetan},
	title = {AI+AR based Framework for Guided Visual Equipment Diagnosis},
	year = {2024},
	journal = {Proceedings of the Annual Conference of the Prognostics and Health Management Society, PHM },
	volume = {16},
	number = {1},
	doi = {10.36001/phmconf.2024.v16i1.3909},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210227167&doi=10.36001%2fphmconf.2024.v16i1.3909&partnerID=40&md5=897ac8045a48e2e80aa7522870c2004f},
	abstract = {Automated solutions for effective support services, such as failure diagnosis and repair, are crucial to keep customer satisfaction and loyalty. However, providing consistent, high quality, and timely support is a difficult task. In practice, customer support usually requires technicians to perform onsite diagnosis, but service quality is often adversely affected by limited expert technicians, high turnover, and minimal automated tools. To address these challenges, we present a novel solution framework for aiding technicians in performing visual equipment diagnosis. We envision a workflow where the technician reports a failure and prompts the system to automatically generate a diagnostic plan that includes parts, areas of interest, and necessary tasks. The plan is used to guide the technician with augmented reality (AR), while a perception module analyzes and tracks the technician’s actions to recommend next steps. Our framework consists of three components: planning, tracking, and guiding. The planning component automates the creation of a diagnostic plan by querying a knowledge graph (KG). We propose to leverage Large Language Models (LLMs) for the construction of the KG to accelerate the extraction process of parts, tasks, and relations from manuals. The tracking component enhances 3D detections by using perception sensors with a 2D nested object detection model. Finally, the guiding component reduces process complexity for technicians by combining 2D models and AR interactions. To validate the framework, we performed multiple studies to:1) determine an effective prompt method for the LLM to construct the KG; 2) demonstrate benefits of our 2D nested object model combined with AR model. © 2024 Prognostics and Health Management Society. All rights reserved.},
	keywords = {Augmented reality; Diagnosis; Quality of service; Query languages; Sales; Automated solutions; Customer loyalty; Customers' satisfaction; Equipment diagnosis; Failure Diagnosis; Failure repairs; High quality; Knowledge graphs; Language model; Support services; Customer satisfaction},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Guo20247063,
	author = {Guo, Tiezheng and Yang, Qingwen and Wang, Chen and Liu, Yanyi and Li, Pan and Tang, Jiawei and Li, Dapeng and Wen, Yingyou},
	title = {KnowledgeNavigator: leveraging large language models for enhanced reasoning over knowledge graph},
	year = {2024},
	journal = {Complex and Intelligent Systems},
	volume = {10},
	number = {5},
	pages = {7063 – 7076},
	doi = {10.1007/s40747-024-01527-8},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197269337&doi=10.1007%2fs40747-024-01527-8&partnerID=40&md5=97e6c8171dd93a547ec050c0fe99dfd9},
	abstract = {Large language models have achieved outstanding performance on various downstream tasks with their advanced understanding of natural language and zero-shot capability. However, they struggle with knowledge constraints, particularly in tasks requiring complex reasoning or extended logical sequences. These limitations can affect their performance in question answering by leading to inaccuracies and hallucinations. This paper proposes a novel framework called KnowledgeNavigator that leverages large language models on knowledge graphs to achieve accurate and interpretable multi-hop reasoning. Especially with an analysis-retrieval-reasoning process, KnowledgeNavigator searches the optimal path iteratively to retrieve external knowledge and guide the reasoning to reliable answers. KnowledgeNavigator treats knowledge graphs and large language models as flexible components that can be switched between different tasks without additional costs. Experiments on three benchmarks demonstrate that KnowledgeNavigator significantly improves the performance of large language models in question answering and outperforms all large language models-based baselines. © The Author(s) 2024.},
	author_keywords = {Knowledge retrieval; Large language model; Question answering; Retrieval augmented generation},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access}
}

@ARTICLE{Xiao2024,
	author = {Xiao, Yongkang and Zhang, Sinian and Zhou, Huixue and Li, Mingchen and Yang, Han and Zhang, Rui},
	title = {FuseLinker: Leveraging LLM's pre-trained text embeddings and domain knowledge to enhance GNN-based link prediction on biomedical knowledge graphs},
	year = {2024},
	journal = {Journal of Biomedical Informatics},
	volume = {158},
	doi = {10.1016/j.jbi.2024.104730},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205147730&doi=10.1016%2fj.jbi.2024.104730&partnerID=40&md5=3bcb3fd89934b927e659510cb0b3b248},
	abstract = {Objective: To develop the FuseLinker, a novel link prediction framework for biomedical knowledge graphs (BKGs), which fully exploits the graph's structural, textual and domain knowledge information. We evaluated the utility of FuseLinker in the graph-based drug repurposing task through detailed case studies. Methods: FuseLinker leverages fused pre-trained text embedding and domain knowledge embedding to enhance the graph neural network (GNN)-based link prediction model tailored for BKGs. This framework includes three parts: a) obtain text embeddings for BKGs using embedding-visible large language models (LLMs), b) learn the representations of medical ontology as domain knowledge information by employing the Poincaré graph embedding method, and c) fuse these embeddings and further learn the graph structure representations of BKGs by applying a GNN-based link prediction model. We evaluated FuseLinker against traditional knowledge graph embedding models and a conventional GNN-based link prediction model across four public BKG datasets. Additionally, we examined the impact of using different embedding-visible LLMs on FuseLinker's performance. Finally, we investigated FuseLinker's ability to generate medical hypotheses through two drug repurposing case studies for Sorafenib and Parkinson's disease. Results: By comparing FuseLinker with baseline models on four BKGs, our method demonstrates superior performance. The Mean Reciprocal Rank (MRR) and Area Under receiver operating characteristic Curve (AUROC) for KEGG50k, Hetionet, SuppKG and ADInt are 0.969 and 0.987, 0.548 and 0.903, 0.739 and 0.928, and 0.831 and 0.890, respectively. Conclusion: Our study demonstrates that FuseLinker is an effective novel link prediction framework that integrates multiple graph information and shows significant potential for practical applications in biomedical and clinical tasks. Source code and data are available at https://github.com/YKXia0/FuseLinker. © 2024 Elsevier Inc.},
	author_keywords = {Drug Repurposing; Graph Neural Network; Knowledge graph; Large Language Model; Link Prediction},
	keywords = {Algorithms; Drug Repositioning; Humans; Machine Learning; Medical Informatics; Natural Language Processing; Neural Networks, Computer; C (programming language); Graph embeddings; Graph neural networks; Network embeddings; Neurodegenerative diseases; Prediction models; artemether; cisapride; deferoxamine; delavirdine; fosphenytoin sodium; meloxicam; omeprazole; sildenafil; sorafenib; tamsulosin; Domain knowledge; Drug repurposing; Embeddings; Graph neural networks; Knowledge graphs; Language model; Large language model; Link prediction; Network-based; Repurposing; area under the curve; Article; artificial neural network; biomedical knowledge graph; biomedicine; breast cancer; coronary artery disease; drug repositioning; embedding; graph neural network; hematologic malignancy; information processing; KEGG; kidney cancer; large language model; liver cancer; lung cancer; lymphatic system malignancy; malaria; mathematical analysis; mathematical and statistical procedures; medical ontology; melanoma; multiple sclerosis; Parkinson disease; prediction; receiver operating characteristic; algorithm; human; machine learning; medical informatics; natural language processing; procedures; Knowledge graph},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Qiu20241216,
	author = {Qiu, Ming-Hui and Xie, Neng-Fu and Jiang, Li-Hua and Wu, Huan-Ping and Chen, Ying and Li, Yong-Lei},
	title = {Research on the Construction of Knowledge Graphs for Agricultural Meteorological Disasters: A Review; [农业气象灾害知识图谱构建研究进展]},
	year = {2024},
	journal = {Chinese Journal of Agrometeorology},
	volume = {45},
	number = {10},
	pages = {1216 – 1235},
	doi = {10.3969/j.issn.1000-6362.2024.10.11},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211230392&doi=10.3969%2fj.issn.1000-6362.2024.10.11&partnerID=40&md5=e054a49c0136192d755cf8ec9d38947c},
	abstract = {Efficient utilization of massive heterogeneous data is the key factor to enhance the intelligence of agricultural disaster management. Therefore, it is important to explore techniques for constructing multi-source heterogeneous agricultural meteorological disaster knowledge graphs for dynamic monitoring of agricultural meteorological disasters and intelligent management decision making. This paper analyzed the data sources, types, and characteristics required for knowledge graph construction in the agricultural meteorological disaster domain through literature studies and proposed a framework for knowledge graph construction that combined top-down and bottom-up approaches. The paper also examined key techniques and the current application status of knowledge graph construction from the perspective of schema layer construction, entity extraction, relation extraction, and knowledge fusion. In addition, it explored the applications of agricultural meteorological disaster knowledge graphs in the fields of monitoring and early warning, risk assessment, intelligent service, and decision support. It summarized the challenges of constructing agricultural meteorological disaster knowledge graphs and discussed the future development directions. Integrating information from the different modalities could make knowledge graph more comprehensive and accurate in describing and expressing the knowledge and information in the field of agricultural meteorological disasters, which could help to mitigate the losses caused by agricultural meteorological disasters and improve the accuracy and efficiency of decision-making. In the future, agricultural meteorological disaster knowledge graph will be constructed by incorporating large language models, advanced knowledge extraction methods to achieve complex entity and relationship extraction, and multi modal data. Further research is needed to advance the technical study of agricultural meteorological disaster knowledge graph. © 2024 Editorial Board of Chinese Journal of Agrometeorology. All rights reserved.},
	author_keywords = {Agricultural meteorological disasters; Knowledge extraction; Knowledge fusion; Knowledge graph},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}@ARTICLE{Remy20241844,
	author = {Remy, François and Demuynck, Kris and Demeester, Thomas},
	title = {BioLORD-2023: Semantic textual representations fusing large language models and clinical knowledge graph insights},
	year = {2024},
	journal = {Journal of the American Medical Informatics Association},
	volume = {31},
	number = {9},
	pages = {1844 – 1855},
	doi = {10.1093/jamia/ocae029},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198060632&doi=10.1093%2fjamia%2focae029&partnerID=40&md5=5b7b3f95f742c0fd02c0e259d1cef0f0},
	abstract = {Objective: In this study, we investigate the potential of large language models (LLMs) to complement biomedical knowledge graphs in the training of semantic models for the biomedical and clinical domains. Materials and Methods: Drawing on the wealth of the Unified Medical Language System knowledge graph and harnessing cutting-edge LLMs, we propose a new state-of-the-art approach for obtaining high-fidelity representations of biomedical concepts and sentences, consisting of 3 steps: an improved contrastive learning phase, a novel self-distillation phase, and a weight averaging phase. Results: Through rigorous evaluations of diverse downstream tasks, we demonstrate consistent and substantial improvements over the previous state of the art for semantic textual similarity (STS), biomedical concept representation (BCR), and clinically named entity linking, across 15+ datasets. Besides our new state-of-the-art biomedical model for English, we also distill and release a multilingual model compatible with 50+ languages and finetuned on 7 European languages. Discussion: Many clinical pipelines can benefit from our latest models. Our new multilingual model enables a range of languages to benefit from our advancements in biomedical semantic representation learning, opening a new avenue for bioinformatics researchers around the world. As a result, we hope to see BioLORD-2023 becoming a precious tool for future biomedical applications. Conclusion: In this article, we introduced BioLORD-2023, a state-of-the-art model for STS and BCR designed for the clinical domain.  © 2024 The Author(s).},
	author_keywords = {biological ontologies; knowledge bases; machine learning; natural language processing; semantics},
	keywords = {Humans; Natural Language Processing; Semantics; Unified Medical Language System; article; bioinformatics; biological ontology; distillation; feature learning (machine learning); human; knowledge; knowledge base; large language model; learning; machine learning; natural language processing; semantics; Unified Medical Language System; Unified Medical Language System},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Kang2024228,
	author = {Kang, Ruifu and Fu, Shuojin and Jin, Shuai and Wang, Yanling and Xiao, Qian},
	title = {Development of an Intelligent Health Education System Based on Large Language Model for Elderly Pulmonary Aspiration Prevention},
	year = {2024},
	journal = {Studies in Health Technology and Informatics},
	volume = {315},
	pages = {228 – 230},
	doi = {10.3233/SHTI240141},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199652189&doi=10.3233%2fSHTI240141&partnerID=40&md5=ae345e37b99e1153fd0b61038b6c4ad9},
	abstract = {As the aging process accelerates, the incidence of chronic diseases in the elderly is rising. As a result, it is crucial to optimize health education for the elderly. Pulmonary aspiration and aspiration pneumonia are significant concerns endangering the health of the elderly. The health education paradigm now in use to prevent pulmonary aspiration in the elderly has numerous flaws, including a lack of home-based health education and the digital divide. Large language model (LLM), an example of artificial intelligence technology, is anticipated to bring a chance to address these issues and offer easily comprehensible health information for the prevention of pulmonary aspiration in the elderly. Our multidisciplinary research team fully understood the needs from the perspective of physicians, nurses and patients, built a knowledge graph (KG), and developed an intelligent Health EducAtion system based on LLM for the prevention of elderly Pulmonary Aspiration (iHEAL-ePA system).  © 2024 The Authors.},
	author_keywords = {Health education; knowledge graph; large language model; pulmonary aspiration},
	keywords = {Aged; Artificial Intelligence; Health Education; Humans; Pneumonia, Aspiration; Computational linguistics; Ageing process; Aspiration pneumonia; Chronic disease; Education systems; Health education; Home-based; Knowledge graphs; Language model; Large language model; Pulmonary aspiration; aged; artificial intelligence; aspiration pneumonia; health education; human; prevention and control; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Kraft20241433,
	author = {Kraft, Angelie and Soulier, Eloïse},
	title = {Knowledge-Enhanced Language Models Are Not Bias-Proof: Situated Knowledge and Epistemic Injustice in AI},
	year = {2024},
	journal = {2024 ACM Conference on Fairness, Accountability, and Transparency, FAccT 2024},
	pages = {1433 – 1445},
	doi = {10.1145/3630106.3658981},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196640886&doi=10.1145%2f3630106.3658981&partnerID=40&md5=fb2d160d8f0820dc873cdec56a7ad30a},
	abstract = {The factual inaccuracies ("hallucinations") of large language models have recently inspired more research on knowledge-enhanced language modeling approaches. These are often assumed to enhance the overall trustworthiness and objectivity of language models. Meanwhile, the issue of bias is usually only mentioned as a limitation of statistical representations. This dissociation of knowledge-enhancement and bias is in line with previous research on AI engineers' assumptions about knowledge, which indicate that knowledge is commonly understood as objective and value-neutral by this community. We argue that claims and practices by actors of the field still reflect this underlying conception of knowledge. We contrast this assumption with literature from social and, in particular, feminist epistemology, which argues that the idea of a universal disembodied knower is blind to the reality of knowledge practices and seriously challenges claims of "objective"or "neutral"knowledge. Knowledge enhancement techniques commonly use Wikidata and Wikipedia as their sources for knowledge, due to their large scales, public accessibility, and assumed trustworthiness. In this work, they serve as a case study for the influence of the social setting and the identity of knowers on epistemic processes. Indeed, the communities behind Wikidata and Wikipedia are known to be male-dominated and many instances of hostile behavior have been reported in the past decade. In effect, the contents of these knowledge bases are highly biased. It is therefore doubtful that these knowledge bases would contribute to bias reduction. In fact, our empirical evaluations of RoBERTa, KEPLER, and CoLAKE, demonstrate that knowledge enhancement may not live up to the hopes of increased objectivity. In our study, the average probability for stereotypical associations was preserved on two out of three metrics and performance-related gender gaps on knowledge-driven task were also preserved. We build on these results and critical literature to argue that the label of "knowledge"and the commonly held beliefs about it can obscure the harm that is still done to marginalized groups. Knowledge enhancement is at risk of perpetuating epistemic injustice, and AI engineers' understanding of knowledge as objective per se conceals this injustice. Finally, to get closer to trustworthy language models, we need to rethink knowledge in AI and aim for an agenda of diversification and scrutiny from outgroup members.  © 2024 Owner/Author.},
	author_keywords = {bias; epistemology; fairness; feminism; knowledge enhancement; knowledge graphs; language models; natural language processing; representation},
	keywords = {Knowledge graph; Modeling languages; Natural language processing systems; Social aspects; Bias; Epistemology; Fairness; Feminism; Knowledge enhancement; Knowledge graphs; Language model; Language processing; Natural language processing; Natural languages; Representation; Computational linguistics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Zhang20241806,
	author = {Zhang, Qi and Zhong, Hao},
	title = {Submodular Optimization Approach for Entity Summarization in Knowledge Graph Driven by Large Language Models; [大语言模型驱动的知识图谱实体摘要的次模优化方法]},
	year = {2024},
	journal = {Journal of Frontiers of Computer Science and Technology},
	volume = {18},
	number = {7},
	pages = {1806 – 1813},
	doi = {10.3778/j.issn.1673-9418.2305086},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198665844&doi=10.3778%2fj.issn.1673-9418.2305086&partnerID=40&md5=2171d747ee94dd1560350807039b95bd},
	abstract = {The continuous expansion of the knowledge graph has made entity summarization a research hotspot. The goal of entity summarization is to obtain a brief description of an entity from large-scale triple-structured facts that describe it. The research aims to propose a submodular optimization method for entity summarization based on a large language model. Firstly, based on the descriptive information of entities, relationships, and properties in the triples, a large language model is used to embed them to vectors, effectively capturing the semantic information of the triples and generating embedding vectors containing rich semantic information. Secondly, based on the embedding vectors generated by the large language model, a method is defined to characterize the relevance between any two triples that describe the same entity. The higher the relevance between any two triples, the more similar the information contained in these two triples. Finally, based on the defined method for characterizing triple relevance, a normalized and monotonically non-decreasing submodular function is defined, modeling entity summarization as a submodular function maximization problem. Therefore, greedy algorithms with performance guarantees can be directly applied to extracting entity summaries. Testing is conducted on three public benchmark datasets, and the quality of the extracted entity summaries is evaluated using two metrics, F1 score and NDCG (normalized discounted cumulative gain). Experimental results show that the proposed approach significantly outperforms the state-of-the-art method. © 2024 Journal of Computer Engineering and Applications Beijing Co., Ltd.; Science Press. All rights reserved.},
	author_keywords = {entity summarization; greedy algorithm; large language model; submodular function},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Zhou2024,
	author = {Zhou, Yunfeng and Zhu, Cui and Zhu, Wenjun},
	title = {ProMvSD: Towards unsupervised knowledge graph anomaly detection via prior knowledge integration and multi-view semantic-driven estimation},
	year = {2024},
	journal = {Information Processing and Management},
	volume = {61},
	number = {4},
	doi = {10.1016/j.ipm.2024.103705},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187775960&doi=10.1016%2fj.ipm.2024.103705&partnerID=40&md5=2ab07f907ac33550e560fd0d25660b0d},
	abstract = {Knowledge graphs (KGs) have found extensive applications within intelligent systems, such as information retrieval. Much of the research has predominantly focused on completing missing knowledge, with little consideration given to examining errors. Unfortunately, during customizing KGs, diverse unpredictable errors are virtually unavoidable to be introduced, and these anomalies significantly impact the performance of applications. Detecting erroneous knowledge presents a formidable challenge due to the costly acquisition of ground-truth labels. In this work, we develop an unsupervised anomaly detection framework named ProMvSD, aiming to adapt KGs of varying scales via serialization components. To overcome the insufficient contextual information provided by the topological structure, we introduce the large language model as a reasoner to extract prior knowledge from extensive pre-trained textual data, thereby enhancing the understanding of KGs. Anomalous triple may result in a larger semantic gap between the head and tail neighborhoods. To uncover latent anomalies effectively, we propose a multi-view semantic-driven model (MvSD) based on the assumptions of self-consistency and information stability. MvSD jointly estimates the suspiciousness of triples from three hyperviews: node-view semantic contradiction, triple-view semantic gap, and pathway-view semantic gap. Extensive experiments on three English benchmark KGs and a Chinese medical KG demonstrate that, for the top 1% of the most suspicious triples, we can detect real anomalies with at most 99.9% accuracy. Furthermore, ProMvSD significantly outperforms state-of-the-art representation learning baselines, achieving a 29.2% improvement in detecting all anomalies. © 2024 Elsevier Ltd},
	author_keywords = {Anomaly detection; Knowledge graph; Pre-trained language models; Semantics; Unsupervised learning},
	keywords = {Anomaly detection; Computational linguistics; Intelligent systems; Knowledge graph; Search engines; Topology; Unsupervised learning; Anomaly detection; Ground truth; Knowledge graphs; Knowledge integration; Language model; Multi-views; Performance; Pre-trained language model; Prior-knowledge; Semantic gap; Semantics},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5}
}

@ARTICLE{Hou2024,
	author = {Hou, Zhi-Wei and Liu, Xulong and Zhou, Shengnan and Jing, Wenlong and Yang, Ji},
	title = {Bibliometric Analysis on the Research of Geoscience Knowledge Graph (GeoKG) from 2012 to 2023},
	year = {2024},
	journal = {ISPRS International Journal of Geo-Information},
	volume = {13},
	number = {7},
	doi = {10.3390/ijgi13070255},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199574243&doi=10.3390%2fijgi13070255&partnerID=40&md5=d692240e969fc4765979eb37662542c0},
	abstract = {The geoscience knowledge graph (GeoKG) has gained worldwide attention due to its ability in the formal representation of spatiotemporal features and relationships of geoscience knowledge. Currently, a quantitative review of the state and trends in GeoKG is still scarce. Thus, a bibliometric analysis was performed in this study to fill the gap. Specifically, based on 294 research articles published from 2012 to 2023, we conducted analyses in terms of the (1) trends in publications and citations; (2) identification of the major papers, sources, researchers, institutions, and countries; (3) scientific collaboration analysis; and (4) detection of major research topics and tendencies. The results revealed that the interest in GeoKG research has rapidly increased after 2019 and is continually expanding. China is the most productive country in this field. Co-authorship analysis shows that inter-national and inter-institutional collaboration should be reinforced. Keyword analysis indicated that geoscience knowledge representation, information extraction, GeoKG construction, and GeoKG-based multi-source data integration were current hotspots. In addition, several important but currently neglected issues, such as the integration of Large Language Models, are highlighted. The findings of this review provide a systematic overview of the development of GeoKG and provide a valuable reference for future research. © 2024 by the authors.},
	author_keywords = {bibliometric analysis; geoscience; knowledge graph; research topics; scientific collaboration; spatio-temporal knowledge; VOSviewer},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access}
}

@ARTICLE{Kwon2024488,
	author = {Kwon, Jason J. and Pan, Joshua and Gonzalez, Guadalupe and Hahn, William C. and Zitnik, Marinka},
	title = {On knowing a gene: A distributional hypothesis of gene function},
	year = {2024},
	journal = {Cell Systems},
	volume = {15},
	number = {6},
	pages = {488 – 496},
	doi = {10.1016/j.cels.2024.04.008},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195872321&doi=10.1016%2fj.cels.2024.04.008&partnerID=40&md5=a2d8bc8026f6a19d3d8c0eb5b723ea3c},
	abstract = {As words can have multiple meanings that depend on sentence context, genes can have various functions that depend on the surrounding biological system. This pleiotropic nature of gene function is limited by ontologies, which annotate gene functions without considering biological contexts. We contend that the gene function problem in genetics may be informed by recent technological leaps in natural language processing, in which representations of word semantics can be automatically learned from diverse language contexts. In contrast to efforts to model semantics as “is-a” relationships in the 1990s, modern distributional semantics represents words as vectors in a learned semantic space and fuels current advances in transformer-based models such as large language models and generative pre-trained transformers. A similar shift in thinking of gene functions as distributions over cellular contexts may enable a similar breakthrough in data-driven learning from large biological datasets to inform gene function. © 2024 The Authors},
	author_keywords = {artificial intelligence; distributed representations; gene function; large language models; lexical semantics; machine learning; transformers; word embeddings},
	keywords = {Animals; Computational Biology; Gene Ontology; Genes; Humans; Natural Language Processing; Semantics; automation; computer model; data availability; gene activity; gene expression; gene function; gene mapping; generative pretrained transformer; genetic analysis; human; hypothesis; language processing; linguistics; machine learning; molecular biology; natural language processing; pattern recognition; Review; semantics; word processing; word recognition; writing; animal; bioinformatics; gene; gene ontology; genetics; natural language processing; procedures; semantics},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Ji20242361,
	author = {Ji, Guiyang and Wang, Peiyan and Yu, Zhuo},
	title = {Research on Knowledge Injection Method for Large Language Model Oriented to Process Specification Texts; [面向工艺规范文本的大语言模型知识注入方法研究]},
	year = {2024},
	journal = {Journal of Frontiers of Computer Science and Technology},
	volume = {18},
	number = {9},
	pages = {2361 – 2369},
	doi = {10.3778/j.issn.1673-9418.2406067},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203254929&doi=10.3778%2fj.issn.1673-9418.2406067&partnerID=40&md5=cb36262de9cb69048528b091844aa797},
	abstract = {The application of large language models in process specifications is an effective approach to addressing the issue of inaccurate process knowledge queries. At present, the domain model construction methods through domain knowledge graph embedding or fine-tuning with instruction data are not effective. The difficulty lies in the fact that the process knowledge in the process specifications involves relationships between multiple process elements, which is highly complex. The data are sparse because the standards are only used through citation. The high complexity of process knowledge and sparse data limit the model’s ability to learn process domain concepts, the relationships between concepts and attributes, the relationships between concepts, the relationships between multiple concepts, and reference- based knowledge. To address this difficulty, this paper proposes a large language model knowledge injection method for process specification texts. According to the characteristics of process specification data, this paper designs knowledge injection data including auxiliary sentence identification task, concept-chapter generation task, chapter continuation task and chapter-summary generation task. The model is fine-tuned through supervised learning by combining question-answer pair data to inject domain concepts, attributes, relationships between multiple concepts, and reference knowledge into the model. Experimental results show that the model trained with knowledge injection data and question-answer pair data improves ACC (accuracy) by 7.3 percentage points, ROUGE-L by 7.4 percentage points, and BLEU-4 by 6.2 percentage points compared with the model trained only with question-answer pair data, indicating the effectiveness of the proposed knowledge injection method. © 2024 Journal of Computer Engineering and Applications Beijing Co., Ltd.; Science Press. All rights reserved.},
	author_keywords = {knowledge injection; large language model; process specification; supervised fine-tuning},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Liang2024713,
	author = {Liang, Pan and Ye, Danwei and Zhu, Zihao and Wang, Yunchao and Xia, Wang and Liang, Ronghua and Sun, Guodao},
	title = {C5: toward better conversation comprehension and contextual continuity for ChatGPT},
	year = {2024},
	journal = {Journal of Visualization},
	volume = {27},
	number = {4},
	pages = {713 – 730},
	doi = {10.1007/s12650-024-00980-4},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189615043&doi=10.1007%2fs12650-024-00980-4&partnerID=40&md5=c6ad6e6301dce0517ef30beddca4a31f},
	abstract = {Large language models (LLMs), such as ChatGPT, have demonstrated outstanding performance in various fields, particularly in natural language understanding and generation tasks. In complex application scenarios, users tend to engage in multi-turn conversations with ChatGPT to keep contextual information and obtain comprehensive responses. However, human forgetting and model contextual forgetting remain prominent issues in multi-turn conversation scenarios, which challenge the users’ conversation comprehension and contextual continuity for ChatGPT. To address these challenges, we propose an interactive conversation visualization system called C5, which includes Global View, Topic View, and Context-associated Q&A View. The Global View uses the GitLog diagram metaphor to represent the conversation structure, presenting the trend of conversation evolution and supporting the exploration of locally salient features. The Topic View is designed to display all the question and answer nodes and their relationships within a topic using the structure of a knowledge graph, thereby display the relevance and evolution of conversations. The Context-associated Q&A View consists of three linked views, which allow users to explore individual conversations deeply while providing specific contextual information when posing questions. The usefulness and effectiveness of C5 were evaluated through a case study and a user study. © The Visualization Society of Japan 2024.},
	author_keywords = {ChatGPT; Contextual continuity; Conversation comprehension; Conversation visualization; Natural language processing},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Pan20243580,
	author = {Pan, Shirui and Luo, Linhao and Wang, Yufei and Chen, Chen and Wang, Jiapu and Wu, Xindong},
	title = {Unifying Large Language Models and Knowledge Graphs: A Roadmap},
	year = {2024},
	journal = {IEEE Transactions on Knowledge and Data Engineering},
	volume = {36},
	number = {7},
	pages = {3580 – 3599},
	doi = {10.1109/TKDE.2024.3352100},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182350576&doi=10.1109%2fTKDE.2024.3352100&partnerID=40&md5=96523fd500b93b54566f08f6d7695d1b},
	abstract = {Large language models (LLMs), such as ChatGPT and GPT4, are making new waves in the field of natural language processing and artificial intelligence, due to their emergent ability and generalizability. However, LLMs are black-box models, which often fall short of capturing and accessing factual knowledge. In contrast, Knowledge Graphs (KGs), Wikipedia, and Huapu for example, are structured knowledge models that explicitly store rich factual knowledge. KGs can enhance LLMs by providing external knowledge for inference and interpretability. Meanwhile, KGs are difficult to construct and evolve by nature, which challenges the existing methods in KGs to generate new facts and represent unseen knowledge. Therefore, it is complementary to unify LLMs and KGs together and, simultaneously, leverage their advantages. In this article, we present a forward-looking roadmap for the unification of LLMs and KGs. Our roadmap consists of three general frameworks, namely: 1) KG-enhanced LLMs, which incorporate KGs during the pre-training and inference phases of LLMs, or for the purpose of enhancing understanding of the knowledge learned by LLMs; 2) LLM-augmented KGs, that leverage LLMs for different KG tasks such as embedding, completion, construction, graph-to-text generation, and question answering; and 3) Synergized LLMs + KGs, in which LLMs and KGs play equal roles and work in a mutually beneficial way to enhance both LLMs and KGs for bidirectional reasoning driven by both data and knowledge. We review and summarize existing efforts within these three frameworks in our roadmap and pinpoint their future research directions. © 1989-2012 IEEE.},
	author_keywords = {bidirectional reasoning; generative pre-training; knowledge graphs; large language models; Natural language processing; roadmap},
	keywords = {Computational linguistics; Graphic methods; Job analysis; Knowledge management; Natural language processing systems; Bidirectional reasoning; Chatbots; Cognition; Decoding; Generative pre-training; Knowledge graphs; Language model; Language processing; Large language model; Natural language processing; Natural languages; Pre-training; Predictive models; Roadmap; Task analysis; Knowledge graph},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 216; All Open Access, Green Open Access}
}

@ARTICLE{Kakalou20241018,
	author = {Kakalou, Christine and Karamanidou, Christina and Dalamagas, Theodore and Koubarakis, Manolis},
	title = {Enhancing Patient Empowerment and Health Literacy: Integrating Knowledge Graphs with Language Models for Personalized Health Content Delivery},
	year = {2024},
	journal = {Studies in Health Technology and Informatics},
	volume = {316},
	pages = {1018 – 1022},
	doi = {10.3233/SHTI240582},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202005489&doi=10.3233%2fSHTI240582&partnerID=40&md5=daf616dedaa143d3fdb973042d46fb0d},
	abstract = {Health literacy empowers people to access, understand and apply health information to effectively manage their own health and to be an active participant in healthcare decisions. In this paper we propose a conceptual model for cognitive factors affecting health literacy and related socioeconomic aspects. Then we develop the HEALIE Knowledge Graph to represent the model, drawing from various medical ontologies, resources, and insights from domain experts. Finally, we combine the Knowledge Graph with a Large Language Model to generate personalised medical content and showcase the results through an example. © 2024 The Authors.},
	author_keywords = {Health Literacy; Knowledge Graphs; Natural Language Generation; Patient Empowerment; Retrieval Augmented Generation},
	keywords = {Empowerment; Health Literacy; Humans; Natural Language Processing; Patient Participation; Precision Medicine; Electronic health record; Contents deliveries; Health informations; Health literacy; Knowledge graphs; Language model; Natural language generation; Patient empowerments; Patient health; Personalized healths; Retrieval augmented generation; empowerment; health literacy; human; natural language processing; patient participation; personalized medicine; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Zafar2024,
	author = {Zafar, Ahtsham and Parthasarathy, Venkatesh Balavadhani and Van, Chan Le and Shahid, Saad and Khan, Aafaq Iqbal and Shahid, Arsalan},
	title = {Building Trust in Conversational AI: A Review and Solution Architecture Using Large Language Models and Knowledge Graphs},
	year = {2024},
	journal = {Big Data and Cognitive Computing},
	volume = {8},
	number = {6},
	doi = {10.3390/bdcc8060070},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197155515&doi=10.3390%2fbdcc8060070&partnerID=40&md5=8cf6862dcb7db9ddcee535b8c7c9e174},
	abstract = {Conversational AI systems have emerged as key enablers of human-like interactions across diverse sectors. Nevertheless, the balance between linguistic nuance and factual accuracy has proven elusive. In this paper, we first introduce LLMXplorer, a comprehensive tool that provides an in-depth review of over 205 large language models (LLMs), elucidating their practical implications, ranging from social and ethical to regulatory, as well as their applicability across industries. Building on this foundation, we propose a novel functional architecture that seamlessly integrates the structured dynamics of knowledge graphs with the linguistic capabilities of LLMs. Validated using real-world AI news data, our architecture adeptly blends linguistic sophistication with factual rigor and further strengthens data security through role-based access control. This research provides insights into the evolving landscape of conversational AI, emphasizing the imperative for systems that are efficient, transparent, and trustworthy. © 2024 by the authors.},
	author_keywords = {knowledge graphs; large language models; LLMXplorer; Neo4j; role-based access control; trustworthiness},
	keywords = {Computational linguistics; Knowledge graph; Network security; AI systems; Human like; Knowledge graphs; Language model; Large language model; Llmxplorer; Neo4j; Role-based Access Control; Solution architectures; Trustworthiness; Access control},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Fraga2024,
	author = {Fraga, Felipe Poggi A. and Poggi, Marcus and Casanova, Marco A. and Leme, Luiz André P. Paes},
	title = {Creating Automatic Connections for Personal Knowledge Management},
	year = {2024},
	journal = {SN Computer Science},
	volume = {5},
	number = {5},
	doi = {10.1007/s42979-024-02876-4},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192723312&doi=10.1007%2fs42979-024-02876-4&partnerID=40&md5=eeff554811570ee842adf14184b7da77},
	abstract = {The field of Personal Knowledge Management (PKM) has seen a surge in popularity in recent years. Interestingly, Natural Language Processing (NLP) and Large Language Models are also becoming mainstream, but PKM has not seen much integration with NLP. With this motivation, this article first introduces a methodology to automatically interconnect isolated text collections using NLP techniques combined with Knowledge Graphs. The text connections are generated by exploring the semantic relatedness of the texts and the concepts they share. The article proceeds to describe PKM Assistants that incorporate the methodology to assist users in understanding and exploring the knowledge contained in text collections using a Knowledge Management tool called Tana. The article continues with an assessment of the methodology using a text collection composed of several books and book passages collected for each book. Finally, the article concludes with a discussion of the proposed methodology, with special attention to the potential use cases. © The Author(s), under exclusive licence to Springer Nature Singapore Pte Ltd. 2024.},
	author_keywords = {Bi-directional hyperlinks; Concept extraction; Knowledge graph; Natural language processing; Note-taking; Personal knowledge management; Semantic similarity; Text relatedness},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Mukanova2024,
	author = {Mukanova, Assel and Milosz, Marek and Dauletkaliyeva, Assem and Nazyrova, Aizhan and Yelibayeva, Gaziza and Kuzin, Dmitrii and Kussepova, Lazzat},
	title = {LLM-Powered Natural Language Text Processing for Ontology Enrichment},
	year = {2024},
	journal = {Applied Sciences (Switzerland)},
	volume = {14},
	number = {13},
	doi = {10.3390/app14135860},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198457806&doi=10.3390%2fapp14135860&partnerID=40&md5=7923304d463f1145d82907f2bbb8da56},
	abstract = {This paper describes a method and technology for processing natural language texts and extracting data from the text that correspond to the semantics of an ontological model. The proposed method is distinguished by the use of a Large Language Model algorithm for text analysis. The extracted data are stored in an intermediate format, after which individuals and properties that reflect the specified semantics are programmatically created in the ontology. The proposed technology is implemented using the example of an ontological model that describes the geographical configuration and administrative–territorial division of Kazakhstan. The proposed method and technology can be applied in any subject areas for which ontological models have been developed. The results of the study can significantly improve the efficiency of using knowledge bases based on semantic networks by converting texts in natural languages into semantically linked data. © 2024 by the authors.},
	author_keywords = {ChatGPT; geographic question answering system; Large Language Model; natural language processing; ontology; Semantic Web},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Gold Open Access}
}

@ARTICLE{Wang20242076,
	author = {Wang, Andy and Liu, Cong and Yang, Jingye and Weng, Chunhua},
	title = {Fine-tuning large language models for rare disease concept normalization},
	year = {2024},
	journal = {Journal of the American Medical Informatics Association},
	volume = {31},
	number = {9},
	pages = {2076 – 2083},
	doi = {10.1093/jamia/ocae133},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200384913&doi=10.1093%2fjamia%2focae133&partnerID=40&md5=ba78db0880e367a9996c7ee21d07f18a},
	abstract = {Objective: We aim to develop a novel method for rare disease concept normalization by fine-tuning Llama 2, an open-source large language model (LLM), using a domain-specific corpus sourced from the Human Phenotype Ontology (HPO). Methods: We developed an in-house template-based script to generate two corpora for fine-tuning. The first (NAME) contains standardized HPO names, sourced from the HPO vocabularies, along with their corresponding identifiers. The second (NAMEþSYN) includes HPO names and half of the concept’s synonyms as well as identifiers. Subsequently, we fine-tuned Llama 2 (Llama2-7B) for each sentence set and conducted an evaluation using a range of sentence prompts and various phenotype terms. Results: When the phenotype terms for normalization were included in the fine-tuning corpora, both models demonstrated nearly perfect performance, averaging over 99% accuracy. In comparison, ChatGPT-3.5 has only ∼20% accuracy in identifying HPO IDs for phenotype terms. When single-character typos were introduced in the phenotype terms, the accuracy of NAME and NAMEþSYN is 10.2% and 36.1%, respectively, but increases to 61.8% (NAMEþSYN) with additional typo-specific fine-tuning. For terms sourced from HPO vocabularies as unseen synonyms, the NAME model achieved 11.2% accuracy, while the NAMEþSYN model achieved 92.7% accuracy. Conclusion: Our fine-tuned models demonstrate ability to normalize phenotype terms unseen in the fine-tuning corpus, including misspellings, synonyms, terms from other ontologies, and laymen’s terms. Our approach provides a solution for the use of LLMs to identify named medical entities from clinical narratives, while successfully normalizing them to standard concepts in a controlled vocabulary. # The Author(s) 2024. Published by Oxford University Press on behalf of the American Medical Informatics Association. All rights reserved.},
	author_keywords = {concept normalization; fine-tuning; HPO; large language model; Llama 2},
	keywords = {Biological Ontologies; Humans; Natural Language Processing; Phenotype; Rare Diseases; Vocabulary, Controlled; Article; ChatGPT; large language model; rare disease; biological ontology; controlled vocabulary; human; natural language processing; phenotype},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8; All Open Access, Green Open Access}
}

@CONFERENCE{Tang2024491,
	author = {Tang, Jiabin and Yang, Yuhao and Wei, Wei and Shi, Lei and Su, Lixin and Cheng, Suqi and Yin, Dawei and Huang, Chao},
	title = {GraphGPT: Graph Instruction Tuning for Large Language Models},
	year = {2024},
	journal = {SIGIR 2024 - Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
	pages = {491 – 500},
	doi = {10.1145/3626772.3657775},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200589241&doi=10.1145%2f3626772.3657775&partnerID=40&md5=77ae594794be6e8d1f0e8840552af658},
	abstract = {Graph Neural Networks (GNNs) have evolved to understand graph structures through recursive exchanges and aggregations among nodes. To enhance robustness, self-supervised learning (SSL) has become a vital tool for data augmentation. Traditional methods often depend on fine-tuning with task-specific labels, limiting their effectiveness when labeled data is scarce. Our research tackles this by advancing graph model generalization in zero-shot learning environments. Inspired by the success of large language models (LLMs), we aim to create a graph-oriented LLM capable of exceptional generalization across various datasets and tasks without relying on downstream graph data. We introduce the GraphGPT framework, which integrates LLMs with graph structural knowledge through graph instruction tuning. This framework includes a text-graph grounding component to link textual and graph structures and a dual-stage instruction tuning approach with a lightweight graph-text alignment projector. These innovations allow LLMs to comprehend complex graph structures and enhance adaptability across diverse datasets and tasks. Our framework demonstrates superior generalization in both supervised and zero-shot graph learning tasks, surpassing existing benchmarks. The open-sourced model implementation of our GraphGPT is available at https://github.com/HKUDS/GraphGPT. © 2024 ACM.},
	author_keywords = {graph learning; instruction tuning; large language models},
	keywords = {Computational linguistics; Computer aided instruction; Graph neural networks; Graph structures; Graph theory; Knowledge graph; Large datasets; Learning systems; Zero-shot learning; Data augmentation; Fine tuning; Generalisation; Graph learning; Graph neural networks; Graph structures; Instruction tuning; Labeled data; Language model; Large language model; Graphic methods},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@CONFERENCE{Moore2024122,
	author = {Moore, Steven and Schmucker, Robin and Mitchell, Tom and Stamper, John},
	title = {Automated Generation and Tagging of Knowledge Components from Multiple-Choice Questions},
	year = {2024},
	journal = {L@S 2024 - Proceedings of the 11th ACM Conference on Learning @ Scale},
	pages = {122 – 133},
	doi = {10.1145/3657604.3662030},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199923750&doi=10.1145%2f3657604.3662030&partnerID=40&md5=3caa896fbdf864a920874c090df51664},
	abstract = {Knowledge Components (KCs) linked to assessments enhance the measurement of student learning, enrich analytics, and facilitate adaptivity. However, generating and linking KCs to assessment items requires significant effort and domain-specific knowledge. To streamline this process for higher-education courses, we employed GPT-4 to generate KCs for multiple-choice questions (MCQs) in Chemistry and E-Learning. We analyzed discrepancies between the KCs generated by the Large Language Model (LLM) and those made by humans through evaluation from three domain experts in each subject area. This evaluation aimed to determine whether, in instances of non-matching KCs, evaluators showed a preference for the LLM-generated KCs over their human-created counterparts. We also developed an ontology induction algorithm to cluster questions that assess similar KCs based on their content. Our most effective LLM strategy accurately matched KCs for 56% of Chemistry and 35% of E-Learning MCQs, with even higher success when considering the top five KC suggestions. Human evaluators favored LLM-generated KCs, choosing them over human-assigned ones approximately two-thirds of the time, a preference that was statistically significant across both domains. Our clustering algorithm successfully grouped questions by their underlying KCs without needing explicit labels or contextual information. This research advances the automation of KC generation and classification for assessment items, alleviating the need for student data or predefined KC labels. © 2024 ACM.},
	author_keywords = {concept labeling; knowledge component; knowledge labeling; learning engineering; multiple-choice question},
	keywords = {Clustering algorithms; Domain Knowledge; Education computing; Students; Automated generation; Concept labeling; E - learning; Knowledge components; Knowledge labeling; Labelings; Language model; Learning engineering; Multiple-choice questions; E-learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Green Open Access}
}

@CONFERENCE{2024,
	title = {Proceedings of the 7th ACM SIGMOD Joint International Workshop on Graph Data Management Experiences and Systems, (GRADES) and Network Data Analytics, (NDA), GRADES-NDA 2024},
	year = {2024},
	journal = {Proceedings of the 7th ACM SIGMOD Joint International Workshop on Graph Data Management Experiences and Systems, (GRADES) and Network Data Analytics, (NDA), GRADES-NDA 2024},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198715766&partnerID=40&md5=70a5c39ae6333a6681799ec6d39b895c},
	abstract = {The proceedings contain 6 papers. The topics discussed include: understanding high-performance subgraph pattern matching: a systems perspective; space & time efficient leapfrog Triejoin; TelarKG: a knowledge graph of Chile's constitutional process; scaling differential computation for large-scale graph processing; a benchmark to understand the role of knowledge graphs on large language model’s accuracy for question answering on enterprise SQL databases; and HomeRun: a cardinality estimation advisor for graph databases.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Xie2024128,
	author = {Xie, Yijie},
	title = {Temporal Knowledge Graph Completion based on Historical Constraints and Contemporaneous Subgraphs: TKGC with Historical Constraints and Contemporaneous Subgraphs},
	year = {2024},
	journal = {ACM International Conference Proceeding Series},
	pages = {128 – 132},
	doi = {10.1145/3677779.3677800},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205446025&doi=10.1145%2f3677779.3677800&partnerID=40&md5=4dc6966c0695b57e0cd3c31fef2f8a83},
	abstract = {Temporal knowledge graph (TKG) can model entities and relations in the real world in the time dimension. However, due to the problem of incomplete information in TKGs, research on TKG completion techniques is needed. Most TKG completion methods heavily rely on the repetitive appearance of historical entities, which poses a challenge for completing entities in the same period. Therefore, we propose a TKG completion model based on historical constraints and contemporaneous subgraphs, named HC-TKGC. HC-TKGC divides candidate entities into historical entities, non-historical entities, and contemporaneous entities, and learns distribution vectors for different types of entities. It also adjusts the final candidate entity scores by using a binary classifier based on external knowledge to determine the historical visibility of candidate entities. We evaluate our proposed model on three datasets. The results show that HC-TKGC outperforms baseline models in most metrics, demonstrating the effectiveness of the model in TKG completion tasks. © 2024 Copyright held by the owner/author(s).},
	author_keywords = {Graph completion; LLM; Representation learning; Temporal knowledge graph},
	keywords = {Graph completion; Knowledge graphs; LLM; Model entities; Modeling relations; Real-world; Representation learning; Subgraphs; Temporal knowledge; Temporal knowledge graph; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Delgadillo2024,
	author = {Delgadillo, Josiel and Kinyua, Johnson and Mutigwe, Charles},
	title = {FinSoSent: Advancing Financial Market Sentiment Analysis through Pretrained Large Language Models},
	year = {2024},
	journal = {Big Data and Cognitive Computing},
	volume = {8},
	number = {8},
	doi = {10.3390/bdcc8080087},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202346804&doi=10.3390%2fbdcc8080087&partnerID=40&md5=97a2a16417ab03bc1264ae01fd996790},
	abstract = {Predicting the directions of financial markets has been performed using a variety of approaches, and the large volume of unstructured data generated by traders and other stakeholders on social media microblog platforms provides unique opportunities for analyzing financial markets using additional perspectives. Pretrained large language models (LLMs) have demonstrated very good performance on a variety of sentiment analysis tasks in different domains. However, it is known that sentiment analysis is a very domain-dependent NLP task that requires knowledge of the domain ontology, and this is particularly the case with the financial domain, which uses its own unique vocabulary. Recent developments in NLP and deep learning including LLMs have made it possible to generate actionable financial sentiments using multiple sources including financial news, company fundamentals, technical indicators, as well social media microblogs posted on platforms such as StockTwits and X (formerly Twitter). We developed a financial social media sentiment analyzer (FinSoSent), which is a domain-specific large language model for the financial domain that was pretrained on financial news articles and fine-tuned and tested using several financial social media corpora. We conducted a large number of experiments using different learning rates, epochs, and batch sizes to yield the best performing model. Our model outperforms current state-of-the-art FSA models based on over 860 experiments, demonstrating the efficacy and effectiveness of FinSoSent. We also conducted experiments using ensemble models comprising FinSoSent and the other current state-of-the-art FSA models used in this research, and a slight performance improvement was obtained based on majority voting. Based on the results obtained across all models in these experiments, the significance of this study is that it highlights the fact that, despite the recent advances of LLMs, sentiment analysis even in domain-specific contexts remains a difficult research problem. © 2024 by the authors.},
	author_keywords = {BERT; financial markets; LLM; sentiment analysis; social media; StockTwits; Twitter/X},
	keywords = {Decentralized finance; Financial markets; Market Research; Problem oriented languages; Sentiment analysis; BERT; Financial domains; Language model; Large language model; Micro-blog; Performance; Sentiment analysis; Social media; Stocktwit; Twitter/X; Tweets},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access}
}

@CONFERENCE{Sequeda2024,
	author = {Sequeda, Juan and Allemang, Dean and Jacob, Bryon},
	title = {A Benchmark to Understand the Role of Knowledge Graphs on Large Language Model's Accuracy for Question Answering on Enterprise SQL Databases},
	year = {2024},
	journal = {Proceedings of the 7th ACM SIGMOD Joint International Workshop on Graph Data Management Experiences and Systems, (GRADES) and Network Data Analytics, (NDA), GRADES-NDA 2024},
	doi = {10.1145/3661304.3661901},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198723406&doi=10.1145%2f3661304.3661901&partnerID=40&md5=0814b4c31b222b241ad83d462f63fbe3},
	abstract = {Enterprise applications of Large Language Models (LLMs) hold promise for question answering on enterprise SQL databases. However, the extent to which LLMs can accurately respond to enterprise questions in such databases remains unclear, given the absence of suitable Text-to-SQL benchmarks tailored to enterprise settings. Additionally, the potential of Knowledge Graphs (KGs) to enhance LLM-based question answering by providing business context is not well understood. This study aims to evaluate the accuracy of LLM-powered question answering systems in the context of enterprise questions and SQL databases, while also exploring the role of knowledge graphs in improving accuracy. To achieve this, we introduce a benchmark comprising an enterprise SQL schema in the insurance domain, a range of enterprise queries encompassing reporting to metrics, and a contextual layer incorporating an ontology and mappings that define a knowledge graph. Our primary finding reveals that question answering using GPT-4, with zero-shot prompts directly on SQL databases, achieves an accuracy of 16%. Notably, this accuracy increases to 54% when questions are posed over a Knowledge Graph representation of the enterprise SQL database. Therefore, investing in Knowledge Graph provides higher accuracy for LLM powered question answering systems. Copyright © 2024 held by the owner/author(s). Publication rights licensed to ACM.},
	keywords = {Computational linguistics; Database systems; Zero-shot learning; Business contexts; Enterprise applications; Knowledge graphs; Language model; Model-based OPC; Modeling accuracy; Question Answering; Question answering systems; Question database; SQL database; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Green Open Access}
}

@CONFERENCE{2024,
	title = {Asian Internet Engineering Conference, AINTEC 2024},
	year = {2024},
	journal = {Asian Internet Engineering Conference, AINTEC 2024},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203294942&partnerID=40&md5=f89a468b6b5f9e71f70f6b1d2d04e8ad},
	abstract = {The proceedings contain 9 papers. The topics discussed include: measuring Genai usage patterns in a university campus via network traffic analysis; on the impact of heterogeneity on federated learning at the edge with DGA malware detection; systematic mapping and temporal reasoning of IoT cyber risks using structured data; TrafficGPT: an LLM approach for open-set encrypted traffic classification; examining technologies to reduce response time in hands-on exercise environment over widely distributed computer network utilizing RENs; dynamic fixed-point values in eBPF: a case for fully in-kernel anomaly detection; the quest for a resilient internet access in a constrained geopolitical environment; and detecting inconsistency between network design and current state based on network ontology bonsai.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Yu2024148,
	author = {Yu, Changlong and Liu, Xin and Maia, Jefferson and Li, Yang and Cao, Tianyu and Gao, Yifan and Song, Yangqiu and Goutam, Rahul and Zhang, Haiyang and Yin, Bing and Li, Zheng},
	title = {COSMO: A Large-Scale E-commerce Common Sense Knowledge Generation and Serving System at Amazon},
	year = {2024},
	journal = {Proceedings of the ACM SIGMOD International Conference on Management of Data},
	pages = {148 – 160},
	doi = {10.1145/3626246.3653398},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196398163&doi=10.1145%2f3626246.3653398&partnerID=40&md5=688c4d9fe3ec37966fdb679bd55591aa},
	abstract = {Applications of large-scale knowledge graphs in the e-commerce platforms can improve shopping experience for their customers. While existing e-commerce knowledge graphs (KGs) integrate a large volume of concepts or product attributes, they fail to discover user intentions, leaving the gap with how people think, behave, and interact with the surrounding world. In this work, we present COSMO, a scalable system to mine user-centric commonsense knowledge from massive behaviors and construct industry-scale knowledge graphs to empower diverse online services. In particular, we describe a pipeline for collecting high-quality seed knowledge assertions that are distilled from large language models (LLMs) and further refined by critic classifiers trained over human-in-the-loop annotated data.Since those generations may not always align with human preferences and contain noises, we then describe how we adopt instruction tuning to finetune an efficient language model∼(COSMO-LM) for faithful e-commerce commonsense knowledge generation at scale. COSMO-LM effectively expands our knowledge graph to 18 major categories at Amazon, producing millions of high-quality knowledge with only 30k annotated instructions. Finally COSMO has been deployed in Amazon search applications such as search navigation. Both offline and online A/B experiments demonstrate our proposed system achieves significant improvement. Furthermore, these experiments highlight the immense potential of commonsense knowledge extracted from instruction-finetuned large language models.  © 2024 ACM.},
	author_keywords = {commonsense knowledge; knowledge graph; large language model},
	keywords = {Computational linguistics; Electronic commerce; Commerce platforms; Commonsense knowledge; E- commerces; High quality; Knowledge generations; Knowledge graphs; Language model; Large language model; Large volumes; Large-scales; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@BOOK{Maniaci202471,
	author = {Maniaci, Antonino and Lechien, Jerome Rene and Lavalle, S. and Lentini, Mario},
	title = {Large language model (LLM) and generative pre-trained transformers (GPT) in otolaryngology: Perspectives and limitations},
	year = {2024},
	journal = {Advances in Health and Disease},
	pages = {71 – 91},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206280426&partnerID=40&md5=62d0e33c552a1ecc6e1fdc57227e10a2},
	abstract = {The diagnosis and treatment of disorders affecting the ear, nose, throat,and adjacent structures is known as otolaryngology. With the advent of large language models (LLMs) and generative pre-trained transformers (GPTs), this area has made tremendous strides. Modern natural language processing (NLP) tools have the potential to transform otolaryngology practice in a number of ways, including patient education, clinical documentation, and research. Exceptionally good at comprehending and producing language that sounds human, LLMs and GPTs can efficiently and accurately transcribing clinical notes, simplifying the documentation process, and relieving otolaryngologists of administrative obligations. These models can also help extract pertinent data from medical records, which can lead to better decision-making and individualized treatment strategies. When it comes to patient education, LLMs and GPTs can provide customized instructions and explanations that improve understanding and treatment compliance. In the field of otolaryngology, where problems frequently entail extensive treatment procedures and complex anatomical components, this can be especially helpful. Additionally, by summarizing pertinent material, pointing out possible research gaps, and even helping to generate study proposals and hypotheses, these language models can expedite otolaryngology research. This can hasten the development of novel therapies, cuttingedge procedures, and diagnostic techniques. The integration of GPTs and LLMs in otolaryngology is not without difficulties, though. It is important to carefully consider issues including model bias, privacy concerns, and the possibility of producing false or misleading information. Ensuring the responsible and reliable implementation of these technologies in clinical settings will need the establishment of regulatory frameworks and ethical guidelines. This chapter examines the advantages and disadvantages of LLMs and GPTs in otolaryngology, going into detail about their underlying training protocols, architectures, and practical uses. We look at case stories and research results that demonstrate these models' transformative power while also talking about possible hazards and ethical issues. In order to provide comprehensive and intelligent solutions for otolaryngological care, we will offer insights into future approaches. One such direction is the integration of LLMs and GPTs with other new technologies, such computer vision and knowledge graphs. © 2024 by Nova Science Publishers, Inc. All rights reserved.},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Chen2024,
	author = {Chen, Nanjiang and Lin, Xuhui and Jiang, Hai and An, Yi},
	title = {Automated Building Information Modeling Compliance Check through a Large Language Model Combined with Deep Learning and Ontology},
	year = {2024},
	journal = {Buildings},
	volume = {14},
	number = {7},
	doi = {10.3390/buildings14071983},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199602988&doi=10.3390%2fbuildings14071983&partnerID=40&md5=65427538ce181b319759b8abb9d30e3c},
	abstract = {Ensuring compliance with complex industry standards and regulations during the design and implementation phases of construction projects is a significant challenge in the building information modeling (BIM) domain. Traditional manual compliance checking methods are inefficient and error-prone, failing to meet modern engineering demands. Natural language processing (NLP) and deep learning methods have improved efficiency and accuracy in rule interpretation and compliance checking. However, these methods still require extensive manual feature engineering, large, annotated datasets, and significant computational resources. Large language models (LLMs) provide robust language understanding with minimal labeled data due to their pre-training and few-shot learning capabilities. However, their application in the AEC field is still limited by the need for fine-tuning for specific tasks, handling complex texts with nested clauses and conditional statements. This study introduces an innovative automated compliance checking framework that integrates LLM, deep learning models, and ontology knowledge models. The use of LLM is motivated by its few-shot learning capability, which significantly reduces the need for large, annotated datasets required by previous methods. Deep learning is employed to preliminarily classify regulatory texts, which further enhances the accuracy of structured information extraction by the LLM compared to directly feeding raw data into the LLM. This novel combination of deep learning and LLM significantly enhances the efficiency and accuracy of compliance checks by automating the processing of regulatory texts and reducing manual intervention. This approach is crucial for architects, engineers, project managers, and regulators, providing a scalable and adaptable solution for automated compliance in the construction industry with broad application prospects. © 2024 by the authors.},
	author_keywords = {automated compliance check; BIM; deep learning; design regulations; large language models (LLMs); ontology knowledge models},
	keywords = {Architectural design; Automation; Classification (of information); Compliance control; Computational linguistics; Construction industry; Deep learning; Efficiency; Information theory; Large datasets; Learning systems; Natural language processing systems; Ontology; Personnel training; Regulatory compliance; Structural design; Automated compliance check; Building Information Modelling; Compliance checks; Deep learning; Design regulation; Knowledge model; Language model; Large language model; Ontology knowledge model; Ontology's; Modeling languages},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access}
}

@ARTICLE{Canabal-Juanatey2024,
	author = {Canabal-Juanatey, Mariña and Alonso-Moral, Jose M. and Catala, Alejandro and Bugarín-Diz, Alberto},
	title = {Enriching interactive explanations with fuzzy temporal constraint networks},
	year = {2024},
	journal = {International Journal of Approximate Reasoning},
	volume = {171},
	doi = {10.1016/j.ijar.2024.109128},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183564390&doi=10.1016%2fj.ijar.2024.109128&partnerID=40&md5=1893a8e3ba386505acd17702ffe81fa6},
	abstract = {Humans often use expressions with vague terms which play a fundamental role for effective communication. These expressions are successfully modeled with fuzzy technology, but they are not usually integrated yet with Natural Language Processing models and techniques. Large-scale pre-trained language models yield excellent results in many language tasks, but they have some drawbacks such as their lack of transparency and thorough temporal reasoning capabilities. Therefore, the use of such models may provoke inconsistent or incorrect dialogues in the context of conversational agents which were aimed at providing users of intelligent systems with interactive explanations. In this paper, we propose a model for fuzzy temporal reasoning to overcome some inconsistencies detected in pre-trained language models in a specific application domain of a conversational agent carefully designed for providing users with explanations which are endowed with a good balance between naturalness and fidelity. More precisely, starting from a knowledge graph that provides an intuitive representation of the entities and relations in the application domain, we describe how to map the temporal information onto a fuzzy temporal constraint network. This formalism allows to represent imprecise temporal information and provides mechanisms for checking consistency in conversations. In addition, as a proof of concept, we have developed TimeVersa, a conversational agent which integrates the proposed model into an application domain (i.e., a virtual assistant for tourists) that requires handling imprecise temporal constraints. We illustrate in a use case how the agent can identify temporal inconsistencies and answer queries related to temporal information properly. Results after a user study report that users' perception of consistency is significantly higher in a conversation with TimeVersa than in a similar conversation using the well-known GPT-3 Large Language Model, when vague temporal information is involved. The proposed approach is a step forward for developing conversational agents operating in application domains that require temporal reasoning under uncertainty. © 2024 The Author(s)},
	author_keywords = {Conversational agents; Fuzzy temporal constraint networks; Fuzzy temporal reasoning; Knowledge graphs; Language models},
	keywords = {Computational linguistics; Fuzzy logic; Fuzzy neural networks; Intelligent systems; Natural language processing systems; Query processing; Applications domains; Conversational agents; Effective communication; Fuzzy technology; Fuzzy temporal constraint networks; Fuzzy temporal reasoning; Knowledge graphs; Language model; Temporal information; Temporal reasoning; Knowledge graph},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Zhang20242357,
	author = {Zhang, Rui and Su, Yixin and Trisedya, Bayu Distiawan and Zhao, Xiaoyan and Yang, Min and Cheng, Hong and Qi, Jianzhong},
	title = {AutoAlign: Fully Automatic and Effective Knowledge Graph Alignment Enabled by Large Language Models},
	year = {2024},
	journal = {IEEE Transactions on Knowledge and Data Engineering},
	volume = {36},
	number = {6},
	pages = {2357 – 2371},
	doi = {10.1109/TKDE.2023.3325484},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172203247&doi=10.1109%2fTKDE.2023.3325484&partnerID=40&md5=e4ec8d6b46cbb1cc2c9d49e7ed3bf0fa},
	abstract = {The task of entity alignment between knowledge graphs (KGs) aims to identify every pair of entities from two different KGs that represent the same entity. Many machine learning-based methods have been proposed for this task. However, to our best knowledge, existing methods all require manually crafted seed alignments, which are expensive to obtain. In this paper, we propose the first fully automatic alignment method named AutoAlign, which does not require any manually crafted seed alignments. Specifically, for predicate embeddings, AutoAlign constructs a predicate-proximity-graph with the help of large language models to automatically capture the similarity between predicates across two KGs. For entity embeddings, AutoAlign first computes the entity embeddings of each KG independently using TransE, and then shifts the two KGs' entity embeddings into the same vector space by computing the similarity between entities based on their attributes. Thus, both predicate alignment and entity alignment can be done without manually crafted seed alignments. AutoAlign is not only fully automatic, but also highly effective. Experiments using real-world KGs show that AutoAlign improves the performance of entity alignment significantly compared to state-of-the-art methods.  © 1989-2012 IEEE.},
	author_keywords = {Attribute embeddings; deep learning; entity alignment; knowledge base; knowledge graph; knowledge graph alignment; large language model; predicate proximity graph; representation learning},
	keywords = {Computational linguistics; Deep learning; Graph embeddings; Knowledge graph; Vector spaces; Attribute embedding; Deep learning; Embeddings; Entity alignment; Knowledge base; Knowledge graph alignment; Knowledge graphs; Language model; Large language model; Predicate proximity graph; Proximity graphs; Representation learning; Alignment},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; All Open Access, Green Open Access}
}

@ARTICLE{Wang2024156,
	author = {Wang, Lu and Liu, Ruilin and Huang, Jingzhong and Guo, Xuchao},
	title = {Joint model of intent detection and slot filling of knowledge question for crop diseases and pests using CNN-Transformer; [基于 CNN-Transformer 的农作物病虫害知识问答意图识别与槽位填充联合模型]},
	year = {2024},
	journal = {Nongye Gongcheng Xuebao/Transactions of the Chinese Society of Agricultural Engineering},
	volume = {40},
	number = {13},
	pages = {156 – 162},
	doi = {10.11975/j.issn.1002-6819.202403116},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202808952&doi=10.11975%2fj.issn.1002-6819.202403116&partnerID=40&md5=571d449ef28c9caa3e58f9acff634e4c},
	abstract = {Intent detection and slot filling have been two of the most vital tasks to question the crop diseases and pests using knowledge graph. Among them, intent detection is to determine the user's intention or purpose from the text entered by the user in the crop pest field. Slot filling is to identify and extract specific information from the user's text, especially for the slot, for example, "what is the control of tomato bacterial wilt?". The task identifies the semantic slot "tomato bacterial wilt" (head entity) and the intention "control " (relation) to form a triple (tomato bacterial wilt, control, -). Where"-" represents the semantic slot and the intention to find the answer from the knowledge graph. A graph convolution encoder has been proposed to capture the spatiotemporal semantic features of conversation discourse in recent years, in order to learn the co-occurrence relationship between intention detection and slot filling. The slot decoding context has improved the accuracy of intention detection. In turn, the target of intention detection can be optimized to further improve the performance of slot filling. The best performance has been achieved in the experiments on public data sets. Sub word attention adapter (SAA) has also been used to effectively extract the context features from complex tags, and then retain the overall discourse information. In addition, an intention attention adapter (IAA) has been proposed to obtain the comprehensive sentence features, in order to predict the users’ intention. In experiments, the knowledge question and answer have been focused mainly on the pipeline in the existing agricultural research. The named entity recognition has been firstly used to identify the head entity in the question. The text classification can be then used to classify the question for the intention. However, such a pipeline can be vulnerable to error propagation that caused by word segmentation errors. It is very necessary to make full use of the correlation between intent detection and slot filling in the agricultural field. In this study, a joint model of intent detection and slot filling was proposed to fully utilize the semantic information using CNN-Transformer (CDPCT-IDSF). According to the semantic complexity of crop pest text, the CNN network and multi-layer Transformer were designed to emphasize the local useful information. The semantic loss was alleviated to introduce the alignment guarantee one-to-one relationship between input and output in the Transformer decoder. As such, the model was improved to identify the correct slot labels. In addition, a question-and-answer dataset was constructed for the agricultural pest knowledge, including 20 intention categories, 12 slot categories, and 11242 labeled samples. Comparative experiments show that the slot-filling F1 value of the CDPCT-IDSF model on the corpus was 94.36%, the intent detection accuracy was 92.99%, and the overall recognition accuracy was 87.23%, which was better than other comparison models. The improved model was also performed better for the intent detection and slot filling in crop diseases and pests. The finding can provide the theoretical support to knowledge question and answer research on crop diseases and pests. Moreover, the experiments were also carried out on two public datasets. CDPCT-IDSF was also suitable for English corpus scenarios. On ATIS datasets, the slot filling F1 value was 95.43%, intent detection accuracy was 97.95%, and overall recognition accuracy was 87.68%. On SNIPS datasets, the slot filling F1 value, intent detection accuracy and overall recognition accuracy of CDPCT-IDSF were 95.70%, 98.57% and 89.96%, respectively. At the same time, the better generalization and robustness were achieved in the rest corpus. © 2024 Chinese Society of Agricultural Engineering. All rights reserved.},
	author_keywords = {CNN network; crop; diseases and pests; intent detection; slot filling; Transformer},
	keywords = {Decision trees; Emotional intelligence; Fertilizers; Image annotation; Image matching; Photomapping; Semantic Segmentation; Semantics; CNN network; Crop disease; Detection accuracy; Disease and pest; F1 values; Intent detection; Intention detection; Slot filling; Tomato bacterial wilt; Transformer; Fruits},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Maratsi2024165,
	author = {Maratsi, Maria Ioanna and Ahmed, Umair and Alexopoulos, Charalampos and Charalabidis, Yannis and Polini, Andrea},
	title = {Towards Cross-Domain Linking of Data: A Semantic Mapping of Cultural Heritage Ontologies},
	year = {2024},
	journal = {ACM International Conference Proceeding Series},
	pages = {165 – 176},
	doi = {10.1145/3657054.3657077},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195318383&doi=10.1145%2f3657054.3657077&partnerID=40&md5=a5f94d7aa2ca4ae0f1dfc65c507617be},
	abstract = {The Linked Open Vocabularies (LOV) registry, designed with the Linked Data principles at core, provides an environment suitable for research which targets domain-specific, but also potentially reusable, information representation. The main purpose of this study is to follow the recommendations pertaining to the utilisation of LOV as a basis for experimentation in order to examine how information within the Cultural Heritage (CH) domain can be improved in terms of reusability and interoperability. The present lack of cross-domain knowledge transfer forms the motivation behind this study, with the aim of facilitating the transition from conventional, domain-specific knowledge representation to reusable and semantically interoperable information. The methodology of this study involves the manual semantic mapping of elements from 12 vocabularies in the LOV registry, reinforced by a small-scale experiment using contemporary large language models (LLMs), particularly GPT, for a preliminary assessment of the mapping process. The findings revealed several key aspects to consider regarding the alignment of semantically adjacent vocabulary elements in the CH domain and beyond, emphasising the potential unveiled by linking domain-focused schemata to standardised, established ones while preserving the conceptual hierarchies inherent to each individual knowledge domain. The contribution of this research pertains to the vision of linking data across different domains by initiating the alignment among representation schemata in CH, with the ultimate aim to expand beyond the boundaries of the in-word knowledge domain, while employing combinatory methodological approaches of technological means and human expertise to facilitate this process. © 2024 Copyright held by the owner/author(s).},
	keywords = {Computational linguistics; Interoperability; Knowledge management; Knowledge representation; Linked data; Mapping; Natural language processing systems; Reusability; Semantics; Cross-domain; Cultural heritages; Domain knowledge; Domain specific; Information representation; Knowledge domains; Linked Data principles; Ontology's; Semantics mappings; Target domain; Domain Knowledge},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Bénédict20243029,
	author = {Bénédict, Gabriel and Zhang, Ruqing and Metzler, Donald and Yates, Andrew and Jiang, Ziyan},
	title = {Gen-IR @ SIGIR 2024: The Second Workshop on Generative Information Retrieval},
	year = {2024},
	journal = {SIGIR 2024 - Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
	pages = {3029 – 3032},
	doi = {10.1145/3626772.3657982},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200546347&doi=10.1145%2f3626772.3657982&partnerID=40&md5=aeb5d6416f2c6ddaf51a025b637f82bf},
	abstract = {Generative information retrieval (Gen-IR) is a fast-growing interdisciplinary research area that investigates how to leverage advances in generative Artificial Intelligence (AI) to improve information retrieval systems. Gen-IR has attracted interest from the information retrieval, natural language processing, and machine learning communities, among others. Since the dawn of Gen-IR last year, there has been an explosion of Gen-IR systems that have launched and are now widely used. Interest in this area across academia and industry is only expected to continue to grow as new research challenges and application opportunities arise. The goal of this proposed workshop, The Second Workshop on Generative Information Retrieval (Gen-IR @ SIGIR 2024) is to provide an interactive venue for exploring a broad range of foundational and applied Gen-IR research. The workshop will focus on tasks such as generative document retrieval, grounded answer generation, generative recommendation, and generative knowledge graphs, all through the lens of model training, model behavior, and broader issues. The workshop will be highly interactive, favoring panel discussions, poster sessions, and roundtable discussions over one-sided keynotes and paper talks. © 2024 Owner/Author.},
	author_keywords = {generative models; information retrieval; large language models},
	keywords = {Knowledge graph; Learning algorithms; Natural language processing systems; Recommender systems; Search engines; Generative model; Information-retrieval systems; Language model; Language processing; Large language model; Machine learning communities; Natural languages; Research applications; Research areas; Research challenges; Information retrieval systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Labala202462,
	author = {Labala, Rajendra Kumar and Khan, Zeeshan Ahmad and Mondal, Gopinath and Hazra, Subhajit and Banerjee, Bidisha and Chattoraj, Asamanja},
	title = {Transcriptome Analysis on the ALAN-Induced Zebrafish Ovary: Desynchronization of Life Processes and Initiation of Diseases},
	year = {2024},
	journal = {Chronobiology in Medicine},
	volume = {6},
	number = {2},
	pages = {62 – 76},
	doi = {10.33069/cim.2024.0009},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197454469&doi=10.33069%2fcim.2024.0009&partnerID=40&md5=9ef4628f451e8c9f1a2da971f44b18d2},
	abstract = {Objective: The effect of artificial light at night (ALAN) on "transcriptome"is prominent owing to its capacity for "desynchronization"of organismal physiology. Light influences the circadian rhythm. This study aims to explore the ALAN-induced ovarian transcriptome of zebrafish for desynchronization of life processes. Methods: Four experimental conditions were set up for female zebrafish: one normal 12-hour light and 12-hour dark (LD) cycle, and three continuous exposures to ALAN for one week (LLW), one month (LLM), and one year (LLY). The whole transcriptome data analysis of the ALAN-exposed samples was then compared with the normal sample using RNA-Seq, followed by exploratory analyses. Results: The analysis revealed two different patterns of expression of genes where LLW and LLM differ with LLY samples in comparison to LD. Compared to LD, downregulation of the predicted hub genes was observed in all treatments; ribosome and oxidative phosphorylation pathways were enriched. LLY vs. LD contrast depicts the enrichment of three more pathways-RNA polymerase, adhesion junction, and signaling. The gene ontology (GO) enrichment portrays more prevalent biological processes in LLW vs. LD and LLM vs. LD than in LLY vs. LD. Contrast-wise disease annotation represents neoplasms as the most prevalent; disease enrichment denotes the major class of neoplasm, carcinoma, coupled with intellectual disability, global developmental delay, and seizures. Conclusion: Our study displayed desynchronization of various genes and pathways leading to the initiation of diseases, for the first time in zebrafish. Even though, this data shows that ALAN is a serious threat, further research is needed to determine the intensity and the duration of ALAN which might cause potential repercussions. © 2024 Korean Academy of Sleep Medicine.},
	author_keywords = {Artificial light at night; Clock; Desynchronization; Disease; Ovary; RNASeq},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Zhao2024,
	author = {Zhao, Chenguang and Liu, Tong and Wang, Zheng},
	title = {PANDA-3D: Protein function prediction based on AlphaFold models},
	year = {2024},
	journal = {NAR Genomics and Bioinformatics},
	volume = {6},
	number = {3},
	doi = {10.1093/nargab/lqae094},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200742481&doi=10.1093%2fnargab%2flqae094&partnerID=40&md5=dbe7de01628aaf80ed816cc95509deb7},
	abstract = {Previous protein function predictors primarily make predictions from amino acid sequences instead of tertiary structures because of the limited number of experimentally determined structures and the unsatisfying qualities of predicted structures. AlphaFold recently achieved promising performances when predicting protein tertiary structures, and the AlphaFold protein structure database (AlphaFold DB) is fast-expanding. Therefore, we aimed to develop a deep-learning tool that is specifically trained with AlphaFold models and predict GO terms from AlphaFold models. We developed an advanced learning architecture by combining geometric vector perceptron graph neural networks and variant transformer decoder layers for multi-label classification. PANDA-3D predicts gene ontology (GO) terms from the predicted structures of AlphaFold and the embeddings of amino acid sequences based on a large language model. Our method significantly outperformed a state-of-the-art deep-learning method that was trained with experimentally determined tertiary structures, and either outperformed or was comparable with several other language-model-based state-of-the-art methods with amino acid sequences as input. PANDA-3D is tailored to AlphaFold models, and the AlphaFold DB currently contains over 200 million predicted protein structures (as of May 1st, 2023), making PANDA-3D a useful tool that can accurately annotate the functions of a large number of proteins. PANDA-3D can be freely accessed as a web server from http://dna.cs.miami.edu/PANDA-3D/ and as a repository from https://github.com/zwang-bioinformatics/PANDA-3D. © 2024 The Author(s).},
	keywords = {amino acid sequence; article; bioinformatics; controlled study; deep learning; gene ontology; language model; large language model; multilabel classification; nerve cell network; nonhuman; prediction; protein function; protein structure; protein tertiary structure},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Chen2024353,
	author = {Chen, Nuo and Li, Yuhan and Tang, Jianheng and Li, Jia},
	title = {GraphWiz: An Instruction-Following Language Model for Graph Computational Problems},
	year = {2024},
	journal = {Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
	pages = {353 – 364},
	doi = {10.1145/3637528.3672010},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203681916&doi=10.1145%2f3637528.3672010&partnerID=40&md5=e514a9b4a51fb879cdc2f97a5c46727e},
	abstract = {Large language models (LLMs) have achieved impressive success across various domains, but their capability in understanding and resolving complex graph problems is less explored. To bridge this gap, we introduce GraphInstruct, a novel instruction-tuning dataset aimed at enabling language models to tackle a broad spectrum of graph problems through explicit reasoning paths. Utilizing GraphInstruct, we build GraphWiz, an open-source language model capable of solving various graph computational problems while generating clear reasoning processes. To further enhance the model's performance and reliability, we integrate the Direct Preference Optimization (DPO) framework within the graph problem-solving context. The improved model, GraphWiz-DPO, achieves an average accuracy of 65% across nine tasks with different complexity levels, surpassing GPT-4 which has an average accuracy of 43.8%. Our study also investigates the relationship between training data volume and model performance, emphasizing the risk of overfitting as data volume increases. Additionally, we explore the transferability of the proposed model across different tasks and datasets, demonstrating its robust zero-shot generalization capability. GraphWiz offers a new blueprint and valuable insights for developing LLMs specialized in graph reasoning and problem-solving.  © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.},
	author_keywords = {graph algorithms; instruction tuning; large language models},
	keywords = {Adversarial machine learning; Contrastive Learning; Knowledge graph; Open source software; Computational problem; Data volume; Graph algorithms; Graph problems; Instruction tuning; Language model; Large language model; Modeling performance; Preference optimizations; Problem-solving; Graph algorithms},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Dong20242906,
	author = {Dong, Jun and Shu, Hongchun and Liu, Rui and Long, Wenzhen and Zhang, Guangbin},
	title = {Large Language Models Empowering Scenario Generation and Dual-layer Optimization for Coupled Operations of Power Supply, Irrigation, and Water Storage in Multiple Agricultural Parks; [大语言模型赋能场景生成和双层优化的多农业园区供电-灌溉-蓄水耦合运行]},
	year = {2024},
	journal = {Gaodianya Jishu/High Voltage Engineering},
	volume = {50},
	number = {7},
	pages = {2906 – 2917},
	doi = {10.13336/j.1003-6520.hve.20240871},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199695966&doi=10.13336%2fj.1003-6520.hve.20240871&partnerID=40&md5=e2f30c9b0095f00e2f105f43c040a5ed},
	abstract = {The traditional agricultural irrigation load exhibits concentration and disorder, significantly exacerbating the imbalance between supply and demand and increasing operational costs in power systems. To enhance the economic efficiency of agricultural parks and the absorption capacity of photovoltaic resources, this study proposes a multi-agricultural park optimization scheduling model based on scenario generation using a large language model (LLM) and bi-level optimization. By characterizing the agricultural irrigation load and considering the energy demands of crop growth, the model forecasts the temporal analysis capabilities of the LLM for short-term photovoltaic power generation. Additionally, the knowledge inference capabilities of the LLM are employed to construct an agricultural water use knowledge graph. The rich semantic relationships within the knowledge graph assist the LLM in reasoning and prediction, generating more realistic scenarios for agricultural power supply, irrigation, and water storage. The bi-level optimization scheduling model, based on the generated scenarios, aims to optimize the economic operation of the parks by coupling the power supply, irrigation, and water storage across multiple agricultural parks. Finally, simulations demonstrate that the proposed method can be adopted to significantly enhance the stability of the power system operations in agricultural parks and effectively reduce operational costs. © 2024 Science Press. All rights reserved.},
	author_keywords = {bi-level optimization model; characteristics of agricultural irrigation load; knowledge extraction; knowledge graphs; large language model},
	keywords = {Computational linguistics; Economic efficiency; Knowledge graph; Semantics; Solar energy; Agricultural irrigation; Agricultural parks; Bi-level optimization models; Characteristic of agricultural irrigation load; Knowledge extraction; Knowledge graphs; Language model; Large language model; Power supply; Water storage; Irrigation},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Yang20243091,
	author = {Yang, Linyao and Chen, Hongyang and Li, Zhao and Ding, Xiao and Wu, Xindong},
	title = {Give us the Facts: Enhancing Large Language Models With Knowledge Graphs for Fact-Aware Language Modeling},
	year = {2024},
	journal = {IEEE Transactions on Knowledge and Data Engineering},
	volume = {36},
	number = {7},
	pages = {3091 – 3110},
	doi = {10.1109/TKDE.2024.3360454},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184341387&doi=10.1109%2fTKDE.2024.3360454&partnerID=40&md5=c37d0dfe482955bf0fc907793183278a},
	abstract = {Recently, ChatGPT, a representative large language model (LLM), has gained considerable attention. Due to their powerful emergent abilities, recent LLMs are considered as a possible alternative to structured knowledge bases like knowledge graphs (KGs). However, while LLMs are proficient at learning probabilistic language patterns and engaging in conversations with humans, they, like previous smaller pre-trained language models (PLMs), still have difficulty in recalling facts while generating knowledge-grounded contents. To overcome these limitations, researchers have proposed enhancing data-driven PLMs with knowledge-based KGs to incorporate explicit factual knowledge into PLMs, thus improving their performance in generating texts requiring factual knowledge and providing more informed responses to user queries. This paper reviews the studies on enhancing PLMs with KGs, detailing existing knowledge graph enhanced pre-trained language models (KGPLMs) as well as their applications. Inspired by existing studies on KGPLM, this paper proposes enhancing LLMs with KGs by developing knowledge graph-enhanced large language models (KGLLMs). KGLLM provides a solution to enhance LLMs' factual reasoning ability, opening up new avenues for LLM research. © 1989-2012 IEEE.},
	author_keywords = {ChatGPT; knowledge graph; knowledge management; knowledge reasoning; Large language model},
	keywords = {Computational linguistics; Job analysis; Knowledge graph; Modeling languages; Chatbots; ChatGPT; Knowledge graphs; Knowledge reasoning; Knowledge-based systems; Language model; Large language model; Task analysis; Transformer; Knowledge management},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 28; All Open Access, Green Open Access}
}

@CONFERENCE{Xu20242905,
	author = {Xu, Zhentao and Cruz, Mark Jerome and Guevara, Matthew and Wang, Tie and Deshpande, Manasi and Wang, Xiaofeng and Li, Zheng},
	title = {Retrieval-Augmented Generation with Knowledge Graphs for Customer Service Question Answering},
	year = {2024},
	journal = {SIGIR 2024 - Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
	pages = {2905 – 2909},
	doi = {10.1145/3626772.3661370},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200563752&doi=10.1145%2f3626772.3661370&partnerID=40&md5=5f5b45dc025223e99da508241e8bc034},
	abstract = {In customer service technical support, swiftly and accurately retrieving relevant past issues is critical for efficiently resolving customer inquiries. The conventional retrieval methods in retrieval-augmented generation (RAG) for large language models (LLMs) treat a large corpus of past issue tracking tickets as plain text, ignoring the crucial intra-issue structure and inter-issue relations, which limits performance. We introduce a novel customer service question-answering method that amalgamates RAG with a knowledge graph (KG). Our method constructs a KG from historical issues for use in retrieval, retaining the intra-issue structure and inter-issue relations. During the question-answering phase, our method parses consumer queries and retrieves related sub-graphs from the KG to generate answers. This integration of a KG not only improves retrieval accuracy by preserving customer service structure information but also enhances answering quality by mitigating the effects of text segmentation. Empirical assessments on our benchmark datasets, utilizing key retrieval (MRR, Recall@K, NDCG@K) and text generation (BLEU, ROUGE, METEOR) metrics, reveal that our method outperforms the baseline by 77.6% in MRR and by 0.32 in BLEU. Our method has been deployed within LinkedIn's customer service team for approximately six months and has reduced the median per-issue resolution time by 28.6%. © 2024 ACM.},
	author_keywords = {knowledge graph; large language model; question answering; retrieval-augmented generation},
	keywords = {Computational linguistics; Information retrieval; Sales; Customer inquiry; Customer-service; Knowledge graphs; Language model; Large corpora; Large language model; Question Answering; Retrieval methods; Retrieval-augmented generation; Technical support; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6}
}

@CONFERENCE{Yang2024335,
	author = {Yang, Shenghao and Ma, Weizhi and Sun, Peijie and Ai, Qingyao and Liu, Yiqun and Cai, Mingchen and Zhang, Min},
	title = {Sequential Recommendation with Latent Relations based on Large Language Model},
	year = {2024},
	journal = {SIGIR 2024 - Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
	pages = {335 – 344},
	doi = {10.1145/3626772.3657762},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200561179&doi=10.1145%2f3626772.3657762&partnerID=40&md5=b2d195fef57c35bfd2fbfa6cb1a1adbd},
	abstract = {Sequential recommender systems predict items that may interest users by modeling their preferences based on historical interactions. Traditional sequential recommendation methods rely on capturing implicit collaborative filtering signals among items. Recent relation-aware sequential recommendation models have achieved promising performance by explicitly incorporating item relations into the modeling of user historical sequences, where most relations are extracted from knowledge graphs. However, existing methods rely on manually predefined relations and suffer the sparsity issue, limiting the generalization ability in diverse scenarios with varied item relations. In this paper, we propose a novel relation-aware sequential recommendation framework with Latent Lelation Riscovery (LRD). Different from previous relation-aware models that rely on predefined rules, we propose to leverage the Large Language Model (LLM) to provide new types of relations and connections between items. The motivation is that LLM contains abundant world knowledge, which can be adopted to mine latent relations of items for recommendation. Specifically, inspired by that humans can describe relations between items using natural language, LRD harnesses the LLM that has demonstrated human-like knowledge to obtain language knowledge representations of items. These representations are fed into a latent relation discovery module based on the discrete state variational autoencoder (DVAE). Then the self-supervised relation discovery tasks and recommendation tasks are jointly optimized. Experimental results on multiple public datasets demonstrate our proposed latent relation discovery method can be incorporated with existing relation-aware sequential recommendation models and significantly improve the performance. Further analysis experiments indicate the effectiveness and reliability of the discovered latent relations. © 2024 Owner/Author.},
	author_keywords = {large language model; latent relation; sequential recommendation},
	keywords = {Computational linguistics; Knowledge graph; Modeling languages; Recommender systems; Reliability analysis; Signal processing; User profile; Generalization ability; Knowledge graphs; Language model; Large language model; Latent relation; Performance; Preference-based; Recommendation methods; Relation-based; Sequential recommendation; Collaborative filtering},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@ARTICLE{Li2024,
	author = {Li, Yunqing and Starly, Binil},
	title = {Building a knowledge graph to enrich ChatGPT responses in manufacturing service discovery},
	year = {2024},
	journal = {Journal of Industrial Information Integration},
	volume = {40},
	doi = {10.1016/j.jii.2024.100612},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190988149&doi=10.1016%2fj.jii.2024.100612&partnerID=40&md5=5679fb733057945b3fd15fa48bcfb0c8},
	abstract = {Sourcing and identification of new manufacturing partners is crucial for manufacturing system integrators to enhance agility and reduce risk through supply chain diversification in the global economy. The advent of advanced large language models has captured significant interest, due to their ability to generate comprehensive and articulate responses across a wide range of knowledge domains. However, the system often falls short in accuracy and completeness when responding to domain-specific inquiries, particularly in areas like manufacturing service discovery. This research explores the potential of leveraging Knowledge Graphs in conjunction with ChatGPT to streamline the process for prospective clients in identifying small manufacturing enterprises. In this study, we propose a method that integrates bottom-up ontology with advanced machine learning models to develop a Manufacturing Service Knowledge Graph from an array of structured and unstructured data sources, including the digital footprints of small-scale manufacturers throughout North America. The Knowledge Graph and the learned graph embedding vectors are leveraged to tackle intricate queries within the digital supply chain network, responding with enhanced reliability and greater interpretability. The approach highlighted is scalable to millions of entities that can be distributed to form a global Manufacturing Service Knowledge Network Graph that can potentially interconnect multiple types of Knowledge Graphs that span industry sectors, geopolitical boundaries, and business domains. The dataset developed for this study, now publicly accessible, encompasses more than 13,000 manufacturers’ weblinks, manufacturing services, certifications, and location entity types. © 2024 Elsevier Inc.},
	author_keywords = {ChatGPT; Digital supply chain; Knowledge graph; Manufacturing service discovery},
	keywords = {Industrial research; Knowledge management; Supply chains; ChatGPT; Digital supply chain; Global economies; Knowledge domains; Knowledge graphs; Language model; Manufacturing service; Manufacturing service discovery; Service discovery; System integrators; Knowledge graph},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; All Open Access, Green Open Access}
}

@CONFERENCE{2024,
	title = {The Provenance of Elegance in Computation - Essays Dedicated to Val Tannen},
	year = {2024},
	journal = {OpenAccess Series in Informatics},
	volume = {119},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195646205&partnerID=40&md5=dc7c92f67df02e0bf3a66f3f46e72dc6},
	abstract = {The proceedings contain 11 papers. The topics discussed include: explaining enterprise knowledge graphs with large language models and ontological reasoning; traversal-invariant characterizations of logarithmic space; semiring provenance in the infinite; annotation and more annotation: some problems posed by (and to) Val Tannen; chasing parallelism in aggregating graph queries; fishing fort: a system for graph analytics with ML prediction and logic deduction; a note on logical pers and reducibility. logical relations strike again!; AutoML for explainable anomaly detection (XAD); on the impact of provenance semiring theory on the design of a provenance-aware database system; and different differences in semirings.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Zhao20244443,
	author = {Zhao, Haihong and Chen, Aochuan and Sun, Xiangguo and Cheng, Hong and Li, Jia},
	title = {All in One and One for All: A Simple yet Effective Method towards Cross-domain Graph Pretraining},
	year = {2024},
	journal = {Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
	pages = {4443 – 4454},
	doi = {10.1145/3637528.3671913},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197149723&doi=10.1145%2f3637528.3671913&partnerID=40&md5=0cbc1787375af4561e53dd0131d16a4d},
	abstract = {Large Language Models (LLMs) have revolutionized the fields of computer vision (CV) and natural language processing (NLP). One of the most notable advancements of LLMs is that a single model is trained on vast and diverse datasets spanning multiple domains - a paradigm we term 'All in One'. This methodology empowers LLMs with super generalization capabilities, facilitating an encompassing comprehension of varied data distributions. Leveraging these capabilities, a single LLM demonstrates remarkable versatility across a variety of domains - a paradigm we term 'One for All'. However, applying this idea to the graph field remains a formidable challenge, with cross-domain pretraining often resulting in negative transfer. This issue is particularly important in few-shot learning scenarios, where the paucity of training data necessitates the incorporation of external knowledge sources. In response to this challenge, we propose a novel approach called Graph COordinators for PrEtraining (GCOPE), that harnesses the underlying commonalities across diverse graph datasets to enhance few-shot learning. Our novel methodology involves a unification framework that amalgamates disparate graph datasets during the pretraining phase to distill and transfer meaningful knowledge to target tasks. Extensive experiments across multiple graph datasets demonstrate the superior efficacy of our approach. By successfully leveraging the synergistic potential of multiple graph datasets for pretraining, our work stands as a pioneering contribution to the realm of graph foundational model. Code available at https://github.com/cshhzhao/GCOPE.  © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.},
	author_keywords = {graph neural networks; pretraining; prompt tuning},
	keywords = {Knowledge graph; Natural language processing systems; Spatio-temporal data; Zero-shot learning; Cross-domain; Graph neural networks; Language model; Language processing; Multiple domains; Natural languages; Pre-training; Prompt tuning; Simple++; Single models; Graph neural networks},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@ARTICLE{Li20241904,
	author = {Li, Zhao and Wei, Qiang and Huang, Liang-Chin and Li, Jianfu and Hu, Yan and Chuang, Yao-Shun and He, Jianping and Das, Avisha and Keloth, Vipina Kuttichi and Yang, Yuntao and Diala, Chiamaka S and Roberts, Kirk E and Tao, Cui and Jiang, Xiaoqian and Zheng, W. Jim and Xu, Hua},
	title = {Ensemble pretrained language models to extract biomedical knowledge from literature},
	year = {2024},
	journal = {Journal of the American Medical Informatics Association},
	volume = {31},
	number = {9},
	pages = {1904 – 1911},
	doi = {10.1093/jamia/ocae061},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201788657&doi=10.1093%2fjamia%2focae061&partnerID=40&md5=293c6fc038d0965f63aeadf6f37d2e79},
	abstract = {Objectives: The rapid expansion of biomedical literature necessitates automated techniques to discern relationships between biomedical concepts from extensive free text. Such techniques facilitate the development of detailed knowledge bases and highlight research deficiencies. The LitCoin Natural Language Processing (NLP) challenge, organized by the National Center for Advancing Translational Science, aims to evaluate such potential and provides a manually annotated corpus for methodology development and benchmarking. Materials and Methods: For the named entity recognition (NER) task, we utilized ensemble learning to merge predictions from three domain-specific models, namely BioBERT, PubMedBERT, and BioM-ELECTRA, devised a rule-driven detection method for cell line and taxonomy names and annotated 70 more abstracts as additional corpus. We further finetuned the T0pp model, with 11 billion parameters, to boost the performance on relation extraction and leveraged entites' location information (eg, title, background) to enhance novelty prediction performance in relation extraction (RE). Results: Our pioneering NLP system designed for this challenge secured first place in Phase I - NER and second place in Phase II - relation extraction and novelty prediction, outpacing over 200 teams. We tested OpenAI ChatGPT 3.5 and ChatGPT 4 in a Zero-Shot setting using the same test set, revealing that our finetuned model considerably surpasses these broad-spectrum large language models. Discussion and Conclusion: Our outcomes depict a robust NLP system excelling in NER and RE across various biomedical entities, emphasizing that task-specific models remain superior to generic large ones. Such insights are valuable for endeavors like knowledge graph development and hypothesis formulation in biomedical research. © 2024 The Author(s).},
	author_keywords = {ensemble learning; knowledge base; large language model; named entity recognition; relation extraction},
	keywords = {broadly neutralizing antibody; Article; benchmarking; cell line; ChatGPT; comparative study; evaluation study; human; knowledge base; language model; large language model; learning; medical research; natural language processing; task performance; translational science},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{2024,
	title = {SIGIR 2024 - Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
	year = {2024},
	journal = {SIGIR 2024 - Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200555594&partnerID=40&md5=21ec5bfcac82ce7d40e9dc6ab102a378},
	abstract = {The proceedings contain 380 papers. The topics discussed include: TRAD: enhancing LLM agents with step-wise thought retrieval and aligned decision; CorpusLM: towards a unified language model on corpus for knowledge-intensive tasks; a setwise approach for effective and highly efficient zero-shot ranking with large language models; unsupervised large language model alignment for information retrieval via contrastive feedback; METAHKG: meta hyperbolic learning for few-shot temporal reasoning; transformer-based reasoning for learning evolutionary chain of events on temporal knowledge graph; contrast then memorize: semantic neighbor retrieval-enhanced inductive multimodal knowledge graph completion; and Amazon-KG: a knowledge graph enhanced cross-domain recommendation dataset.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Strader20244886,
	author = {Strader, Jared and Hughes, Nathan and Chen, William and Speranzon, Alberto and Carlone, Luca},
	title = {Indoor and Outdoor 3D Scene Graph Generation Via Language-Enabled Spatial Ontologies},
	year = {2024},
	journal = {IEEE Robotics and Automation Letters},
	volume = {9},
	number = {6},
	pages = {4886 – 4893},
	doi = {10.1109/LRA.2024.3384084},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189615964&doi=10.1109%2fLRA.2024.3384084&partnerID=40&md5=71c9a2838140184849867e15e79680bd},
	abstract = {This letter proposes an approach to build 3D scene graphs in arbitrary indoor and outdoor environments. Such extension is challenging; the hierarchy of concepts that describe an outdoor environment is more complex than for indoors, and manually defining such hierarchy is time-consuming and does not scale. Furthermore, the lack of training data prevents the straightforward application of learning-based tools used in indoor settings. To address these challenges, we propose two novel extensions. First, we develop methods to build a spatial ontology defining concepts and relations relevant for indoor and outdoor robot operation. In particular, we use a Large Language Model (LLM) to build such an ontology, thus largely reducing the amount of manual effort required. Second, we leverage the spatial ontology for 3D scene graph construction using Logic Tensor Networks (LTN) to add logical rules, or axioms (e.g., 'a beach contains sand'), which provide additional supervisory signals at training time thus reducing the need for labelled data, providing better predictions, and even allowing predicting concepts unseen at training time. We test our approach in a variety of datasets, including indoor, rural, and coastal environments, and show that it leads to a significant increase in the quality of the 3D scene graph generation with sparsely annotated data.  © 2016 IEEE.},
	author_keywords = {3D scene graphs; AI-based methods; semantic scene understanding; spatial ontologies},
	keywords = {Modeling languages; Ontology; Personnel training; Three dimensional computer graphics; Three dimensional displays; 3d scene graph; 3D scenes; AI-based method; Ontology's; Scene understanding; Scene-graphs; Semantic scene understanding; Solid modelling; Spatial ontologies; Three-dimensional display; Training data; Semantics},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Li2024,
	author = {Li, Hao and Yang, Rongzheng and Xu, Shuangshuang and Xiao, Yao and Zhao, Hongyu},
	title = {Intelligent Checking Method for Construction Schemes via Fusion of Knowledge Graph and Large Language Models},
	year = {2024},
	journal = {Buildings},
	volume = {14},
	number = {8},
	doi = {10.3390/buildings14082502},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202445836&doi=10.3390%2fbuildings14082502&partnerID=40&md5=580e67b113934e347a05fc380acf04b6},
	abstract = {In the construction industry, the professional evaluation of construction schemes represents a crucial link in ensuring the safety, quality and economic efficiency of the construction process. However, due to the large number and diversity of construction schemes, traditional expert review methods are limited in terms of timeliness and comprehensiveness. This leads to an increasingly urgent requirement for intelligent check of construction schemes. This paper proposes an intelligent compliance checking method for construction schemes that integrates knowledge graphs and large language model (LLM). Firstly, a method for constructing a multi-dimensional, multi-granular knowledge graph for construction standards is introduced, which serves as the foundation for domain-specific knowledge support to the LLM. Subsequently, a parsing module based on text classification and entity extraction models is proposed to automatically parse construction schemes and construct pathways for querying the knowledge graph of construction standards. Finally, an LLM is leveraged to achieve an intelligent compliance check. The experimental results demonstrate that the proposed method can effectively integrate domain knowledge to guide the LLM in checking construction schemes, with an accuracy rate of up to 72%. Concurrently, the well-designed prompt template and the comprehensiveness of the knowledge graph facilitate the stimulation of the LLM’s reasoning ability. This work contributes to exploring the application of LLMs and knowledge graphs in the vertical domain of text compliance checking. Future work will focus on optimizing the integration of LLMs and domain knowledge to further improve the accuracy and practicality of the intelligent checking system. © 2024 by the authors.},
	author_keywords = {construction scheme; intelligent check; knowledge graph; large language model; natural language processing},
	keywords = {Domain Knowledge; Economic efficiency; Modeling languages; Natural language processing systems; Structured Query Language; Compliance checking; Construction scheme; Construction standards; Intelligent check; Knowledge graphs; Language model; Language processing; Large language model; Natural language processing; Natural languages; Knowledge graph},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Cadeddu2024,
	author = {Cadeddu, Andrea and Chessa, Alessandro and De Leo, Vincenzo and Fenu, Gianni and Motta, Enrico and Osborne, Francesco and Reforgiato Recupero, Diego and Salatino, Angelo and Secchi, Luca},
	title = {A comparative analysis of knowledge injection strategies for large language models in the scholarly domain},
	year = {2024},
	journal = {Engineering Applications of Artificial Intelligence},
	volume = {133},
	doi = {10.1016/j.engappai.2024.108166},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186596688&doi=10.1016%2fj.engappai.2024.108166&partnerID=40&md5=1110bbeb81ef2b7839f225d23590ff32},
	abstract = {In recent years, transformer-based models have emerged as powerful tools for natural language processing tasks, demonstrating remarkable performance in several domains. However, they still present significant limitations. These shortcomings become more noticeable when dealing with highly specific and complex concepts, particularly within the scientific domain. For example, transformer models have particular difficulties when processing scientific articles due to the domain-specific terminologies and sophisticated ideas often encountered in scientific literature. To overcome these challenges and further enhance the effectiveness of transformers in specific fields, researchers have turned their attention to the concept of knowledge injection. Knowledge injection is the process of incorporating outside knowledge into transformer models to improve their performance on certain tasks. In this paper, we present a comprehensive study of knowledge injection strategies for transformers within the scientific domain. Specifically, we provide a detailed overview and comparative assessment of four primary methodologies, evaluating their efficacy in the task of classifying scientific articles. For this purpose, we constructed a new benchmark including both 24K labelled papers and a knowledge graph of 9.2K triples describing pertinent research topics. We also developed a full codebase to easily re-implement all knowledge injection strategies in different domains. A formal evaluation indicates that the majority of the proposed knowledge injection methodologies significantly outperform the baseline established by Bidirectional Encoder Representations from Transformers. © 2024},
	author_keywords = {BERT; Classification; Knowledge graphs; Knowledge injection; Large language models; Natural language processing; Transformers},
	keywords = {Computational linguistics; Natural language processing systems; BERT; Knowledge graphs; Knowledge injection; Language model; Language processing; Large language model; Natural language processing; Natural languages; Performance; Transformer; Knowledge graph},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Carta2024467,
	author = {Carta, Salvatore and Giuliani, Alessandro and Manca, Marco Manolo and Piano, Leonardo and Tiddia, Sandro Gabriele},
	title = {Towards Zero-shot Knowledge Graph building: Automated Schema Inference},
	year = {2024},
	journal = {UMAP 2024 - Adjunct Proceedings of the 32nd ACM Conference on User Modeling, Adaptation and Personalization},
	pages = {467 – 473},
	doi = {10.1145/3631700.3665234},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198932122&doi=10.1145%2f3631700.3665234&partnerID=40&md5=14fe30f829817c642115f9811b1ed732},
	abstract = {In the current Digital Transformation scenario, Knowledge Graphs are essential for comprehending, representing, and exploiting complex information in a structured form. The main paradigm in automatically generating proper Knowledge Graphs relies on predefined schemas or ontologies. Such schemas are typically manually constructed, requiring an intensive human effort, and are often sensitive to information loss due to negligence, incomplete analysis, or human subjectivity or inclination. Limiting human bias and the resulting information loss in creating proper Knowledge Graphs is paramount, particularly for user modeling in various sectors, such as education or healthcare. To this end, we propose a novel approach to automatically generating a proper entity schema. The devised methodology combines the language understanding capabilities of LLM with classical machine learning methods such as clustering to properly build an entity schema from a set of documents. This solution eliminates the need for human intervention and fosters a more efficient and comprehensive knowledge representation. The assessment of our proposal concerns adopting a state-of-the-art entity extraction model (UniNER) to estimate the relevance of the extracted entities based on the generated schema. Results confirm the potential of our approach, as we observed a negligible difference between the topic similarity score obtained with the ground truth and with the automatically generated schema (less than 1% on average on three different datasets). Such an outcome confirms that the proposed approach may be valuable in automatically creating an entity schema from a set of documents. © 2024 Owner/Author.},
	author_keywords = {Large Language Models; Named Entity Recognition; Ontology Learning},
	keywords = {Learning systems; Ontology; Semantics; User profile; Zero-shot learning; 'current; Complex information; Digital transformation; Information loss; Knowledge graphs; Language model; Large language model; Named entity recognition; Ontology learning; Schema inference; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Zhu2024907,
	author = {Zhu, Peide and Li, Na and Zhao, Zhiming},
	title = {Retrieval-augmented Query Reformulation for Heterogeneous Research Asset Retrieval in Virtual Research Environment},
	year = {2024},
	journal = {WWW 2024 Companion - Companion Proceedings of the ACM Web Conference},
	pages = {907 – 910},
	doi = {10.1145/3589335.3651553},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194502055&doi=10.1145%2f3589335.3651553&partnerID=40&md5=e7b2a2e58ba70a14853155c7aae3888d},
	abstract = {Discovering and reusing research assets such as datasets and computational notebooks is crucial for building research workflows in data-centric studies. The rapid growth of research assets in scientific communities provides scientists with great opportunities to enhance research efficacy but also poses significant challenges in finding suitable materials for specific tasks. Scientists, especially those focusing on cross-disciplinary research, often find it difficult to formulate effective queries to retrieve desired resources. Previous work has proposed query reformulation methods to increase the efficiency of research asset search. However, it relies on existent knowledge graphs and is constrained to computational notebooks only. As research assets utilized by data analytic workflows are in essence heterogeneous, i.e., of distinct kinds and from diversified sources, query reformulation methods in this regard should consider the relationship between different types of research assets. To address the above challenges, we propose a retrieval-augmented query reformulation method for heterogeneous research asset retrieval. It is developed in the context of a Notebook-based virtual research environment (VRE) and offers query reformulation services to other VRE components. We demonstrate the effectiveness of the proposed query reformulation service with experiments on dataset and notebook retrieval. Up till now, we have indexed 8,954 datasets and 18,158 notebooks. The experimental results show that the proposed service can create useful query suggestions. © 2024 Copyright held by the owner/author(s).},
	author_keywords = {Heterogeneous Research Asset Retrieval; Large Language Models; Query Reformulation},
	keywords = {Data centric; Heterogeneous research asset retrieval; Language model; Large language model; Query reformulation; Rapid growth; Scientific community; Specific tasks; Virtual research environment; Work-flows; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Alotaibi2024,
	author = {Alotaibi, Obaid and Tomy, Sarath and Pardede, Eric},
	title = {A Framework for Cleaning Streaming Data in Healthcare: A Context and User-Supported Approach},
	year = {2024},
	journal = {Computers},
	volume = {13},
	number = {7},
	doi = {10.3390/computers13070175},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199651452&doi=10.3390%2fcomputers13070175&partnerID=40&md5=7297b9bbadf01d58d626cc217c541556},
	abstract = {Nowadays, ubiquitous technology makes life easier, especially devices that use the internet (IoT). IoT devices have been used to generate data in various domains, including healthcare, industry, and education. However, there are often problems with this generated data such as missing values, duplication, and data errors, which can significantly affect data analysis results and lead to inaccurate decision making. Enhancing the quality of real-time data streams has become a challenging task as it is crucial for better decisions. In this paper, we propose a framework to improve the quality of a real-time data stream by considering different aspects, including context-awareness. The proposed framework tackles several issues in the data stream, including duplicated data, missing values, and outliers to improve data quality. The proposed framework also provides recommendations on appropriate data cleaning techniques to the user to help improve data quality in real time. Also, the data quality assessment is included in the proposed framework to provide insight to the user about the data stream quality for better decisions. We present a prototype to examine the concept of the proposed framework. We use a dataset that is collected in healthcare and process these data using a case study. The effectiveness of the proposed framework is verified by the ability to detect and repair stream data quality issues in selected context and to provide a recommended context and data cleaning techniques to the expert for better decision making in providing healthcare advice to the patient. We evaluate our proposed framework by comparing the proposed framework against previous works. © 2024 by the authors.},
	author_keywords = {context-awareness; data analysis; data cleaning; data detection; data repairing; generative AI; healthcare; machine learning; ontology; real-time data stream},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Liu20248160,
	author = {Liu, Peifeng and Qian, Lu and Zhao, Xingwei and Tao, Bo},
	title = {Joint Knowledge Graph and Large Language Model for Fault Diagnosis and Its Application in Aviation Assembly},
	year = {2024},
	journal = {IEEE Transactions on Industrial Informatics},
	volume = {20},
	number = {6},
	pages = {8160 – 8169},
	doi = {10.1109/TII.2024.3366977},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187338038&doi=10.1109%2fTII.2024.3366977&partnerID=40&md5=3e88eeceee9b7572d5f557f75c5e066b},
	abstract = {In complex assembly industry settings, fault localization involves rapidly and accurately identifying the source of a fault and obtaining a troubleshooting solution based on fault symptoms. This study proposes a knowledge-enhanced joint model that incorporates aviation assembly knowledge graph (KG) embedding into large language models (LLMs). This model utilizes graph-structured Big Data within KGs to conduct prefix-tuning of the LLMs. The KGs for prefix-tuning enable an online reconfiguration of the LLMs, which avoids a massive computational load. Through the subgraph embedding learning process, the specialized knowledge of the joint model within the aviation assembly domain, especially in fault localization, is strengthened. In the context of aviation assembly functional testing, the joint model can generate knowledge subgraphs, fuse knowledge through retrieval augmentation, and ultimately provide knowledge-based reasoning responses. In practical industrial scenario experiments, the joint enhancement model demonstrates an accuracy of 98.5% for fault diagnosis and troubleshooting schemes.  © 2005-2012 IEEE.},
	author_keywords = {Data-driven; fault localization; intelligent fault diagnosis; knowledge graph (KG); large language model (LLM)},
	keywords = {Big data; Computational linguistics; Fault detection; Hidden Markov models; Job analysis; Knowledge graph; Cognition; Data driven; Fault localization; Faults diagnosis; Hidden-Markov models; Intelligent fault diagnosis; Knowledge graph; Knowledge graphs; Language model; Large language model; Task analysis; Failure analysis},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 19}
}

@CONFERENCE{Alam20246704,
	author = {Alam, Mehwish and Buscaldi, Davide and Reforgiato Recupero, Diego and Cochez, Michael and Gesese, Genet Asefa and Osborne, Francesco},
	title = {Workshop on Deep Learning and Large Language Models for Knowledge Graphs (DL4KG)},
	year = {2024},
	journal = {Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
	pages = {6704 – 6705},
	doi = {10.1145/3637528.3671491},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203705907&doi=10.1145%2f3637528.3671491&partnerID=40&md5=88066b739a59db74fb5a01310e88497b},
	abstract = {The use of Knowledge Graphs (KGs) which constitute large networks of real-world entities and their interrelationships, has grown rapidly. A substantial body of research has emerged, exploring the integration of deep learning (DL) and large language models (LLMs) with KGs. This workshop aims to bring together leading researchers in the field to discuss and foster collaborations on the intersection of KG and DL/LLMs.  © 2024 Copyright held by the owner/author(s).},
	author_keywords = {artificial intelligence; deep learning; knowledge graphs; large language models},
	keywords = {Adversarial machine learning; Contrastive Learning; Deep learning; Deep learning; Knowledge graphs; Language model; Large language model; Larger networks; Real-world entities; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Li20246545,
	author = {Li, Jia and Sun, Xiangguo and Li, Yuhan and Li, Zhixun and Cheng, Hong and Yu, Jeffrey Xu},
	title = {Graph Intelligence with Large Language Models and Prompt Learning},
	year = {2024},
	journal = {Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
	pages = {6545 – 6554},
	doi = {10.1145/3637528.3671456},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203684562&doi=10.1145%2f3637528.3671456&partnerID=40&md5=4d3d77229b4589563881abe68c817181},
	abstract = {Graph plays a significant role in representing and analyzing complex relationships in real-world applications such as citation networks, social networks, and biological data. Graph intelligence is rapidly becoming a crucial aspect of understanding and exploiting the intricate interconnections within graph data. Recently, large language models (LLMs) and prompt learning techniques have pushed graph intelligence forward, outperforming traditional Graph Neural Network (GNN) pre-training methods and setting new benchmarks for performance. In this tutorial, we begin by offering a comprehensive review and analysis of existing methods that integrate LLMs with graphs. We introduce existing works based on a novel taxonomy that classifies them into three distinct categories according to the roles of LLMs in graph tasks: as enhancers, predictors, or alignment components. Secondly, we introduce a new learning method that utilizes prompting on graphs, offering substantial potential to enhance graph transfer capabilities across diverse tasks and domains. We discuss existing works on graph prompting within a unified framework and introduce our developed tool for executing a variety of graph prompting tasks. Additionally, we discuss the applications of combining Graphs, LLMs, and prompt learning across various tasks, such as urban computing, recommendation systems, and anomaly detection. This lecture-style tutorial is an extension of our original work published in IJCAI 2024[44] and arXiv[77] with the invitation of KDD24.  © 2024 Copyright held by the owner/author(s).},
	author_keywords = {graph learning; graph prompting; large language model},
	keywords = {Adversarial machine learning; Graph algorithms; Graph neural networks; Knowledge graph; Network theory (graphs); Biological data; Citation networks; Complex relationships; Graph data; Graph learning; Graph prompting; Language model; Large language model; Network data; Real-world; Contrastive Learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Carta2024460,
	author = {Carta, Salvatore and Giuliani, Alessandro and Manca, Marco Manolo and Piano, Leonardo and Pompianu, Livio and Tiddia, Sandro Gabriele},
	title = {Towards Knowledge Graph Refinement: Misdirected Triple Identification},
	year = {2024},
	journal = {UMAP 2024 - Adjunct Proceedings of the 32nd ACM Conference on User Modeling, Adaptation and Personalization},
	pages = {460 – 466},
	doi = {10.1145/3631700.3665235},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198908197&doi=10.1145%2f3631700.3665235&partnerID=40&md5=ecba8820fb08e9aba5e3ac12a442e981},
	abstract = {In the current digital transformation scenario, Knowledge Graphs (KGs) represent an across-the-board instrument for representing knowledge in a structured form. Such tools allow to effectively enhance the performance of Artificial Intelligence models in manifold contexts, such as reasoning or information retrieval. Nevertheless, the effectiveness of KGs is often affected by the incorrect directionality of some of their edges, due in most cases to human error or the inefficiency of automatic and semi-automatic graph creation methods. This paper proposes a classification-based approach to identify misdirected triples within a KG, aiming to support and assist humans in creating graph refinement. Triples are the main component of KGs, and they model the connection between nodes with a <subject, predicate, object> form. Our proposal allows us to refine a KG by devising a classification-based approach for recognizing whether the subjects and objects are not compliant with the logic directionality of the corresponding predicate, meaning that they should be switched (e.g., the triple <U.S.A., is capital, Washington> should be inverted as <Washington, is capital, U.S.A.>). We compare traditional machine learning techniques with cutting-edge advanced methods, including pre-trained language models and large language models. Extensive experiments have been performed across several datasets, confirming the effectiveness of our proposal. © 2024 Owner/Author.},
	author_keywords = {Artificial Intelligence; Digital Transformation; Large Language Models},
	keywords = {Computational linguistics; Learning systems; 'current; Board instruments; Digital transformation; Effectiveness of knowledge; Intelligence models; Knowledge graphs; Language model; Large language model; Performance; Washington; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Wang202491,
	author = {Wang, Cangqing and Yang, Yutian and Li, Ruisi and Sun, Dan and Cai, Ruicong and Zhang, Yuzhu and Fu, Chengqian and Floyd, Lillian},
	title = {Adapting LLMs for Efficient Context Processing through Soft Prompt Compression},
	year = {2024},
	journal = {ACM International Conference Proceeding Series},
	pages = {91 – 97},
	doi = {10.1145/3677779.3677794},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205445640&doi=10.1145%2f3677779.3677794&partnerID=40&md5=f9925ddb3612567af3c901ec7eaa77c1},
	abstract = {The rapid advancement of Large Language Models (LLMs) has inaugurated a transformative epoch in natural language processing, fostering unprecedented proficiency in text generation, comprehension, and contextual scrutiny. Nevertheless, effectively handling extensive contexts, crucial for myriad applications, poses a formidable obstacle owing to the intrinsic constraints of the models’ context window sizes and the computational burdens entailed by their operations. This investigation presents an innovative framework that strategically tailors LLMs for streamlined context processing by harnessing the synergies among natural language summarization, soft prompt com- pression, and augmented utility preservation mechanisms. Our methodology, dubbed SoftPromptComp, amalgamates natural language prompts extracted from summarization methodologies with dynamically generated soft prompts to forge a concise yet semantically robust depiction of protracted contexts. This depiction undergoes further refinement via a weighting mechanism optimizing information retention and utility for subsequent tasks. We substantiate that our framework markedly diminishes computational overhead and enhances LLMs’ efficacy across various benchmarks, while upholding or even augmenting the caliber of the produced content. By amalgamating soft prompt compression with sophisticated summarization, SoftPromptComp confronts the dual challenges of managing lengthy contexts and ensuring model scalability. Our findings point towards a propitious trajectory for augmenting LLMs’ applicability and efficiency, rendering them more versatile and pragmatic for real- world applications. This research enriches the ongoing discourse on optimizing language models, providing insights into the potency of soft prompts and summarization techniques as pivotal instruments for the forthcoming generation of NLP solutions. © 2024 Copyright held by the owner/author(s).},
	author_keywords = {Knowledge Graph Reasoning; Reinforcement Learning; Reward Shaping; Transfer Learning},
	keywords = {Benchmarking; Contrastive Learning; Gluing; Knowledge graph; Natural language processing systems; Reinforcement learning; Transfer learning; Context processing; Knowledge graph reasoning; Knowledge graphs; Language model; Language processing; Natural languages; Reinforcement learnings; Reward shaping; Text generations; Transfer learning; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@ARTICLE{Matsumoto2024,
	author = {Matsumoto, Nicholas and Moran, Jay and Choi, Hyunjun and Hernandez, Miguel E. and Venkatesan, Mythreye and Wang, Paul and Moore, Jason H.},
	title = {KRAGEN: a knowledge graph-enhanced RAG framework for biomedical problem solving using large language models},
	year = {2024},
	journal = {Bioinformatics},
	volume = {40},
	number = {6},
	doi = {10.1093/bioinformatics/btae353},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195708984&doi=10.1093%2fbioinformatics%2fbtae353&partnerID=40&md5=49772a06afcf45f4ba0772adca738910},
	abstract = {Motivation: Answering and solving complex problems using a large language model (LLM) given a certain domain such as biomedicine is a challenging task that requires both factual consistency and logic, and LLMs often suffer from some major limitations, such as hallucinating false or irrelevant information, or being influenced by noisy data. These issues can compromise the trustworthiness, accuracy, and compliance of LLM-generated text and insights. Results: Knowledge Retrieval Augmented Generation ENgine (KRAGEN) is a new tool that combines knowledge graphs, Retrieval Augmented Generation (RAG), and advanced prompting techniques to solve complex problems with natural language. KRAGEN converts knowledge graphs into a vector database and uses RAG to retrieve relevant facts from it. KRAGEN uses advanced prompting techniques: namely graph-of-thoughts (GoT), to dynamically break down a complex problem into smaller subproblems, and proceeds to solve each subproblem by using the relevant knowledge through the RAG framework, which limits the hallucinations, and finally, consolidates the subproblems and provides a solution. KRAGEN’s graph visualization allows the user to interact with and evaluate the quality of the solution’s GoT structure and logic. © The Author(s) 2024. Published by Oxford University Press.},
	keywords = {Algorithms; Computational Biology; Databases, Factual; Humans; Information Storage and Retrieval; Natural Language Processing; Problem Solving; Software; algorithm; bioinformatics; factual database; human; information retrieval; natural language processing; problem solving; procedures; software},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Santos2024230,
	author = {Santos, Ricardo L. and Cruz-Correia, Ricardo},
	title = {Improving Healthcare Quality with a LHS: From Patient-Generated Health Data to Evidence-Based Recommendations},
	year = {2024},
	journal = {Studies in Health Technology and Informatics},
	volume = {316},
	pages = {230 – 234},
	doi = {10.3233/SHTI240387},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202002694&doi=10.3233%2fSHTI240387&partnerID=40&md5=e5c2a498bbfa588d6526a0d0cde83c17},
	abstract = {One approach to enriching the Learning Health System (LHS) is leveraging vital signs and data from wearable technologies. Blood oxygen, heart rate, respiration rates, and other data collected by wearables (like sleep and exercise patterns) can be used to monitor and predict health conditions. This data is already being collected and could be used to improve healthcare in several ways. Our approach will be health data interoperability with HL7 FHIR (for data exchange between different systems), openEHR (to store researchable data separated from software but connected to ontologies, external terminologies and code sets) and maintain the semantics of data. OpenEHR is a standard that has an important role in modelling processes and clinical decisions. The six pillars of Lifestyle Medicine can be a first attempt to change how patients see their daily decisions, affecting the mid to long-term evolution of their health. Our objective is to develop the first stage of the LHS based on a co-produced personal health recording (CoPHR) built on top of a local LLM that interoperates health data through HL7 FHIR, openEHR, OHDSI and terminologies that can ingest external evidence and produces clinical and personal decision support and, when combined with many other patients, can produce or confirm evidence. © 2024 The Authors.},
	author_keywords = {clinical decision; Health data interoperability; HL7 FHIR; Learning Health System; openEHR; patient-generated health data; personal health recording},
	keywords = {Electronic Health Records; Evidence-Based Medicine; Health Information Interoperability; Humans; Learning Health System; Patient Generated Health Data; Quality Improvement; Wearable Electronic Devices; Clinical research; Clinical decision; Data interoperability; Health data; Health data interoperability; Health systems; HL7 FHIR; Learning health system; Openehr; Patient-generated health data; Personal health; Personal health recording; data interoperability; electronic health record; evidence based medicine; human; learning health system; medical record; total quality management; wearable computer; Electronic health record},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Gonzalez-Garcia2024443,
	author = {Gonzalez-Garcia, Lino and González-Carreño, Gema and Rivas Machota, Ana María and Padilla Fernández-Vega, Juan},
	title = {Enhancing knowledge graphs with microdata and LLMs: the case of Schema.org and Wikidata in touristic information},
	year = {2024},
	journal = {Electronic Library},
	volume = {42},
	number = {3},
	pages = {443 – 454},
	doi = {10.1108/EL-06-2023-0160},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194469507&doi=10.1108%2fEL-06-2023-0160&partnerID=40&md5=701a87b9969895acf6159ebfb06facba},
	abstract = {Purpose: Knowledge graphs (KGs) are structured knowledge bases that represent real-world entities and are used in a variety of applications. Many of them are created and curated from a combination of automated and manual processes. Microdata embedded in Web pages for purposes of facilitating indexing and search engine optimization are a potential source to augment KGs under some assumptions of complementarity and quality that have not been thoroughly explored to date. In that direction, this paper aims to report results on a study that evaluates the potential of using microdata extracted from the Web to augment the large, open and manually curated Wikidata KG for the domain of touristic information. As large corpora of Web text is currently being leveraged via large language models (LLMs), these are used to compare the effectiveness of the microdata enhancement method. Design/methodology/approach: The Schema.org taxonomy was used as the source to determine the annotation types to be collected. Here, the authors focused on tourism-related pages as a case study, selecting the relevant Schema.org concepts as point of departure. The large CommonCrawl resource was used to select those annotations from a large recent sample of the World Wide Web. The extracted annotations were processed and matched with Wikidata to estimate the degree to which microdata produced for SEO might become a valuable resource to complement KGs or vice versa. The Web pages themselves can also serve as a context to produce additional metadata elements using them as context in pipelines of an existing LLMs. That way, both the annotations and the contents itself can be used as sources. Findings: The samples extracted revealed a concentration of metadata annotations in only a few of the relevant Schema.org attributes and also revealed the possible influence of authoring tools in a significant fraction of microdata produced. The analysis of the overlapping of attributes in the sample with those of Wikidata showed the potential of the technique, limited by the disbalance of the presence of attributes. The combination of those with the use of LLMs to produce additional annotations demonstrates the feasibility of the approach in the population of existing Wikidata locations. However, in both cases, the effectiveness appears to be lower in the cases of less content in the KG, which are arguably the most relevant when considering the scenario of an automated population approach. Originality/value: The research reports novel empirical findings on the way touristic annotations with a SEO orientation are being produced in the wild and provides an assessment of their potential to complement KGs, or reuse information from those graphs. It also provides insights on the potential of using LLMs for the task. © 2024, Emerald Publishing Limited.},
	author_keywords = {CommonCrawl; Knowledge graphs; Large language models; Microdata; Schema.org; Wikidata},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Shao2024,
	author = {Shao, Wujun and Zhang, Rui and Ji, Pengli and Fan, Dongwei and Hu, Yaohua and Yan, Xiaoran and Cui, Chenzhou and Tao, Yihan and Mi, Linying and Chen, Lang},
	title = {Astronomical Knowledge Entity Extraction in Astrophysics Journal Articles via Large Language Models},
	year = {2024},
	journal = {Research in Astronomy and Astrophysics},
	volume = {24},
	number = {6},
	doi = {10.1088/1674-4527/ad3d15},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194364602&doi=10.1088%2f1674-4527%2fad3d15&partnerID=40&md5=20da62147fb5b66d7d6167f57ece5f20},
	abstract = {Astronomical knowledge entities, such as celestial object identifiers, are crucial for literature retrieval and knowledge graph construction, and other research and applications in the field of astronomy. Traditional methods of extracting knowledge entities from texts face numerous challenging obstacles that are difficult to overcome. Consequently, there is a pressing need for improved methods to efficiently extract them. This study explores the potential of pre-trained Large Language Models (LLMs) to perform astronomical knowledge entity extraction (KEE) task from astrophysical journal articles using prompts. We propose a prompting strategy called Prompt-KEE, which includes five prompt elements, and design eight combination prompts based on them. We select four representative LLMs (Llama-2-70B, GPT-3.5, GPT-4, and Claude 2) and attempt to extract the most typical astronomical knowledge entities, celestial object identifiers and telescope names, from astronomical journal articles using these eight combination prompts. To accommodate their token limitations, we construct two data sets: the full texts and paragraph collections of 30 articles. Leveraging the eight prompts, we test on full texts with GPT-4 and Claude 2, on paragraph collections with all LLMs. The experimental results demonstrate that pre-trained LLMs show significant potential in performing KEE tasks, but their performance varies on the two data sets. Furthermore, we analyze some important factors that influence the performance of LLMs in entity extraction and provide insights for future KEE tasks in astrophysical articles using LLMs. Finally, compared to other methods of KEE, LLMs exhibit strong competitiveness in multiple aspects. © 2024. National Astronomical Observatories, CAS and IOP Publishing Ltd.},
	author_keywords = {astronomical databases: miscellaneous; methods: data analysis; virtual observatory tools},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Green Open Access}
}

@ARTICLE{Yuan2024W248,
	author = {Yuan, Qianmu and Tian, Chong and Song, Yidong and Ou, Peihua and Zhu, Mingming and Zhao, Huiying and Yang, Yuedong},
	title = {GPSFun: Geometry-aware protein sequence function predictions with language models},
	year = {2024},
	journal = {Nucleic Acids Research},
	volume = {52},
	number = {W1},
	pages = {W248 – W255},
	doi = {10.1093/nar/gkae381},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197753062&doi=10.1093%2fnar%2fgkae381&partnerID=40&md5=f9a737dc86c1b417ab1d4c04556940e6},
	abstract = {Knowledge of protein function is essential for elucidating disease mechanisms and discovering new drug targets. However, there is a widening gap between the exponential growth of protein sequences and their limited function annotations. In our prior studies, we have developed a series of methods including GraphPPIS, GraphSite, LMetalSite and SPROF-GO for protein function annotations at residue or protein level. To further enhance their applicability and performance, we now present GPSFun, a versatile web server for Geometry-aware Protein Sequence Function annotations, which equips our previous tools with language models and geometric deep learning. Specifically, GPSFun employs large language models to efficiently predict 3D conformations of the input protein sequences and extract informative sequence embeddings. Subsequently, geometric graph neural networks are utilized to capture the sequence and structure patterns in the protein graphs, facilitating various downstream predictions including protein-ligand binding sites, gene ontologies, subcellular locations and protein solubility. Notably, GPSFun achieves superior performance to state-of-the-art methods across diverse tasks without requiring multiple sequence alignments or experimental protein structures. GPSFun is freely available to all users at https://bio-web1.nscc-gz.cn/app/GPSFun with user-friendly interfaces and rich visualizations.  © 2024 The Author(s). Published by Oxford University Press on behalf of Nucleic Acids Research.},
	keywords = {Amino Acid Sequence; Binding Sites; Deep Learning; Humans; Internet; Molecular Sequence Annotation; Neural Networks, Computer; Protein Conformation; Proteins; Sequence Analysis, Protein; Software; protein; algorithm; amino acid sequence; Article; base pairing; binding site; computer model; deep learning; entropy; gene mapping; gene ontology; geometry; language model; large language model; ligand binding; machine learning; metagenome; nerve cell network; nonhuman; prediction; protein function; protein phosphorylation; protein secondary structure; protein structure; receiver operating characteristic; sequence alignment; sequence homology; three-dimensional imaging; training; transcriptomics; amino acid sequence; artificial neural network; chemistry; human; Internet; metabolism; molecular genetics; protein conformation; sequence analysis; software},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; All Open Access, Gold Open Access}
}

@ARTICLE{Buchmann2024,
	author = {Buchmann, Robert and Eder, Johann and Fill, Hans-Georg and Frank, Ulrich and Karagiannis, Dimitris and Laurenzi, Emanuele and Mylopoulos, John and Plexousakis, Dimitris and Santos, Maribel Yasmina},
	title = {Large language models: Expectations for semantics-driven systems engineering},
	year = {2024},
	journal = {Data and Knowledge Engineering},
	volume = {152},
	doi = {10.1016/j.datak.2024.102324},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194927581&doi=10.1016%2fj.datak.2024.102324&partnerID=40&md5=d881b1ee0c638ec4d3d573b514dbb69f},
	abstract = {The hype of Large Language Models manifests in disruptions, expectations or concerns in scientific communities that have focused for a long time on design-oriented research. The current experiences with Large Language Models and associated products (e.g. ChatGPT) lead to diverse positions regarding the foreseeable evolution of such products from the point of view of scholars who have been working with designed abstractions for most of their careers - typically relying on deterministic design decisions to ensure systems and automation reliability. Such expectations are collected in this paper in relation to a flavor of systems engineering that relies on explicit knowledge structures, introduced here as “semantics-driven systems engineering”. The paper was motivated by the panel discussion that took place at CAiSE 2023 in Zaragoza, Spain, during the workshop on Knowledge Graphs for Semantics-driven Systems Engineering (KG4SDSE). The workshop brought together Conceptual Modeling researchers with an interest in specific applications of Knowledge Graphs and the semantic enrichment benefits they can bring to systems engineering. The panel context and consensus are summarized at the end of the paper, preceded by a proposed research agenda considering the expressed positions. © 2024},
	author_keywords = {Conceptual modeling; Knowledge engineering; Large language models; Systems engineering},
	keywords = {Computational linguistics; Knowledge graph; Modeling languages; Product design; Professional aspects; 'current; Conceptual model; Design decisions; Design-oriented researches; Deterministic design; Driven system; Knowledge graphs; Language model; Large language model; Scientific community; Semantics},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5}
}

@CONFERENCE{Zhang20246214,
	author = {Zhang, Fanjin and Shi, Shijie and Zhu, Yifan and Chen, Bo and Cen, Yukuo and Yu, Jifan and Chen, Yelin and Wang, Lulu and Zhao, Qingfei and Cheng, Yuqing and Han, Tianyi and An, Yuwei and Zhang, Dan and Tam, Weng Lam and Cao, Kun and Pang, Yunhe and Guan, Xinyu and Yuan, Huihui and Song, Jian and Li, Xiaoyan and Dong, Yuxiao and Tang, Jie},
	title = {OAG-Bench: A Human-Curated Benchmark for Academic Graph Mining},
	year = {2024},
	journal = {Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
	pages = {6214 – 6225},
	doi = {10.1145/3637528.3672354},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201166879&doi=10.1145%2f3637528.3672354&partnerID=40&md5=78375d6d3b2aa8b837daf7f355b0b584},
	abstract = {With the rapid proliferation of scientific literature, versatile academic knowledge services increasingly rely on comprehensive academic graph mining. Despite the availability of public academic graphs, benchmarks, and datasets, these resources often fall short in multi-aspect and fine-grained annotations, are constrained to specific task types and domains, or lack underlying real academic graphs. In this paper, we present OAG-Bench, a comprehensive, multi-aspect, and fine-grained human-curated benchmark based on the Open Academic Graph (OAG). OAG-Bench covers 10 tasks, 20 datasets, 70+ baselines, and 120+ experimental results to date. We propose new data annotation strategies for certain tasks and offer a suite of data pre-processing codes, algorithm implementations, and standardized evaluation protocols to facilitate academic graph mining. Extensive experiments reveal that even advanced algorithms like large language models (LLMs) encounter difficulties in addressing key challenges in certain tasks, such as paper source tracing and scholar profiling. We also introduce the Open Academic Graph Challenge (OAG-Challenge) to encourage community input and sharing. We envisage that OAG-Bench can serve as a common ground for the community to evaluate and compare algorithms in academic graph mining, thereby accelerating algorithm development and advancement in this field. OAG-Bench is accessible at https://www.aminer.cn/data/.  © 2024 Copyright held by the owner/author(s).},
	author_keywords = {academic graph mining; academic knowledge graph; benchmark},
	keywords = {Data mining; Academic graph mining; Academic knowledge graph; Benchmark; Fine grained; Graph mining; Knowledge graphs; Knowledge service; Multi aspects; Scientific literature; Specific tasks; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Bolaños2024,
	author = {Bolaños, Francisco and Salatino, Angelo and Osborne, Francesco and Motta, Enrico},
	title = {Artificial intelligence for literature reviews: opportunities and challenges},
	year = {2024},
	journal = {Artificial Intelligence Review},
	volume = {57},
	number = {9},
	doi = {10.1007/s10462-024-10902-3},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201532020&doi=10.1007%2fs10462-024-10902-3&partnerID=40&md5=fd6b6b994750b2fd47749d4192cddffe},
	abstract = {This paper presents a comprehensive review of the use of Artificial Intelligence (AI) in Systematic Literature Reviews (SLRs). A SLR is a rigorous and organised methodology that assesses and integrates prior research on a given topic. Numerous tools have been developed to assist and partially automate the SLR process. The increasing role of AI in this field shows great potential in providing more effective support for researchers, moving towards the semi-automatic creation of literature reviews. Our study focuses on how AI techniques are applied in the semi-automation of SLRs, specifically in the screening and extraction phases. We examine 21 leading SLR tools using a framework that combines 23 traditional features with 11 AI features. We also analyse 11 recent tools that leverage large language models for searching the literature and assisting academic writing. Finally, the paper discusses current trends in the field, outlines key research challenges, and suggests directions for future research. We highlight three primary research challenges: integrating advanced AI solutions, such as large language models and knowledge graphs, improving usability, and developing a standardised evaluation framework. We also propose best practices to ensure more robust evaluations in terms of performance, usability, and transparency. Overall, this review offers a detailed overview of AI-enhanced SLR tools for researchers and practitioners, providing a foundation for the development of next-generation AI solutions in this field. © The Author(s) 2024.},
	author_keywords = {Artificial intelligence; Evaluation framework; Large language models; Literature review; Natural anguage processing; Systematic literature reviews; Usability},
	keywords = {Knowledge graph; Evaluation framework; Language model; Large language model; Literature reviews; Natural anguage processing; Research challenges; Review process; Semi-automatics; Systematic literature review; Usability; Usability engineering},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6}
}

@ARTICLE{Cadeddu2024,
	author = {Cadeddu, Andrea and Chessa, Alessandro and De Leo, Vincenzo and Fenu, Gianni and Motta, Enrico and Osborne, Francesco and Reforgiato Recupero, Diego and Salatino, Angelo and Secchi, Luca},
	title = {Optimizing Tourism Accommodation Offers by Integrating Language Models and Knowledge Graph Technologies},
	year = {2024},
	journal = {Information (Switzerland)},
	volume = {15},
	number = {7},
	doi = {10.3390/info15070398},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199856907&doi=10.3390%2finfo15070398&partnerID=40&md5=082e5fa7b93a6b1c209eec6201e94d4f},
	abstract = {Online platforms have become the primary means for travellers to search, compare, and book accommodations for their trips. Consequently, online platforms and revenue managers must acquire a comprehensive comprehension of these dynamics to formulate a competitive and appealing offerings. Recent advancements in natural language processing, specifically through the development of large language models, have demonstrated significant progress in capturing the intricate nuances of human language. On the other hand, knowledge graphs have emerged as potent instruments for representing and organizing structured information. Nevertheless, effectively integrating these two powerful technologies remains an ongoing challenge. This paper presents an innovative deep learning methodology that combines large language models with domain-specific knowledge graphs for classification of tourism offers. The main objective of our system is to assist revenue managers in the following two fundamental dimensions: (i) comprehending the market positioning of their accommodation offerings, taking into consideration factors such as accommodation price and availability, together with user reviews and demand, and (ii) optimizing presentations and characteristics of the offerings themselves, with the intention of improving their overall appeal. For this purpose, we developed a domain knowledge graph covering a variety of information about accommodations and implemented targeted feature engineering techniques to enhance the information representation within a large language model. To evaluate the effectiveness of our approach, we conducted a comparative analysis against alternative methods on four datasets about accommodation offers in London. The proposed solution obtained excellent results, significantly outperforming alternative methods. © 2024 by the authors.},
	author_keywords = {BERT; classification tasks; feature engineering; hospitality; knowledge graphs; natural language processing; tourism},
	keywords = {Computational linguistics; Domain Knowledge; Knowledge graph; Natural language processing systems; BERT; Classification tasks; Feature engineerings; Hospitality; Knowledge graphs; Language model; Language processing; Natural language processing; Natural languages; Online platforms; Deep learning},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Nechakhin2024,
	author = {Nechakhin, Vladyslav and D’Souza, Jennifer and Eger, Steffen},
	title = {Evaluating Large Language Models for Structured Science Summarization in the Open Research Knowledge Graph},
	year = {2024},
	journal = {Information (Switzerland)},
	volume = {15},
	number = {6},
	doi = {10.3390/info15060328},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197313646&doi=10.3390%2finfo15060328&partnerID=40&md5=e7f908dd60c2647cc43877a04c5ffa0e},
	abstract = {Structured science summaries or research contributions using properties or dimensions beyond traditional keywords enhance science findability. Current methods, such as those used by the Open Research Knowledge Graph (ORKG), involve manually curating properties to describe research papers’ contributions in a structured manner, but this is labor-intensive and inconsistent among human domain-expert curators. We propose using Large Language Models (LLMs) to automatically suggest these properties. However, it is essential to assess the readiness of LLMs like GPT-3.5, Llama 2, and Mistral for this task before their application. Our study performs a comprehensive comparative analysis between the ORKG’s manually curated properties and those generated by the aforementioned state-of-the-art LLMs. We evaluate LLM performance from four unique perspectives: semantic alignment with and deviation from ORKG properties, fine-grained property mapping accuracy, SciNCL embedding-based cosine similarity, and expert surveys comparing manual annotations with LLM outputs. These evaluations occur within a multidisciplinary science setting. Overall, LLMs show potential as recommendation systems for structuring science, but further fine-tuning is recommended to improve their alignment with scientific tasks and mimicry of human expertise. © 2024 by the authors.},
	author_keywords = {large language models; Open Research Knowledge Graph; structured summarization},
	keywords = {Computational linguistics; Semantics; 'current; Human domain; Knowledge graphs; Labour-intensive; Language model; Large language model; Open research knowledge graph; Property; Research papers; Structured summarization; Knowledge graph},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Jamil2024,
	author = {Jamil, Hasan M. and Oduro-Afriyie, Joel},
	title = {Knowledge Graph Enhancement for Improved Natural Language Health Question Answering using Large Language Models},
	year = {2024},
	journal = {ACM International Conference Proceeding Series},
	doi = {10.1145/3676288.3676289},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204967827&doi=10.1145%2f3676288.3676289&partnerID=40&md5=4e6bcea15e159e2ec2b88a7749ee4a70},
	abstract = {In this paper we present a method for enhancing Question Answering (QA) systems by iteratively improving Knowledge Graphs (KGs) with a focus on maintaining monotonicity in the enhancement process. We introduce a mathematical framework employing functions τ and ϕ, where τ transforms text T into a KG K, and ϕ generates an answer fromT for a given question. We propose that augmenting K with domain-specific information, denoted as ΔK, leads to a more accurate approximation of the expected answer, adhering to the principle that each enhancement either maintains or improves answer quality. This concept is formalized as ϕ−1(ϕ(T)∪ΔK) yielding better results than ϕ−1(ϕ(T)). The paper elaborates on this process with practical examples, demonstrating how KG enhancements, under the constraints of monotonicity, lead to successive improvements in the Question Answering (QA) system. © 2024 Copyright held by the owner/author(s)},
	author_keywords = {graph augmentation; knowledge graphs; monotonic answer improvement; natural language processing},
	keywords = {Graph augmentation; Knowledge graphs; Language processing; Monotonic answer improvement; Monotonicity; Monotonics; Natural language processing; Natural languages; Question Answering; Question answering systems; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Tang20242842,
	author = {Tang, Jiabin and Yang, Yuhao and Wei, Wei and Shi, Lei and Xia, Long and Yin, Dawei and Huang, Chao},
	title = {HiGPT: Heterogeneous Graph Language Model},
	year = {2024},
	journal = {Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
	pages = {2842 – 2853},
	doi = {10.1145/3637528.3671987},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203166311&doi=10.1145%2f3637528.3671987&partnerID=40&md5=acfde3f80fc3260d7ab0020283ad9e9f},
	abstract = {Heterogeneous graph learning aims to capture complex relationships and diverse relational semantics among entities in a heterogeneous graph to obtain meaningful representations for nodes and edges. Recent advancements in heterogeneous graph neural networks (HGNNs) have achieved state-of-the-art performance by considering relation heterogeneity and using specialized message functions and aggregation rules. However, existing frameworks for heterogeneous graph learning have limitations in generalizing across diverse heterogeneous graph datasets. Most of these frameworks follow the "pre-train"and "fine-tune"paradigm on the same dataset, which restricts their capacity to adapt to new and unseen data. This raises the question: "Can we generalize heterogeneous graph models to be well-adapted to diverse downstream learning tasks with distribution shifts in both node token sets and relation type heterogeneity?"To tackle those challenges, we propose HiGPT, a general large graph model with <u>Heterogeneous graph <u>instruction-tuning paradigm. Our framework enables learning from arbitrary heterogeneous graphs without the need for any fine-tuning process from downstream datasets. To handle distribution shifts in heterogeneity, we introduce an in-context heterogeneous graph tokenizer that captures semantic relationships in different heterogeneous graphs, facilitating model adaptation. We incorporate a large corpus of heterogeneity-aware graph instructions into our HiGPT, enabling the model to effectively comprehend complex relation heterogeneity and distinguish between various types of graph tokens. Furthermore, we introduce the Mixture-of-Thought (MoT) instruction augmentation paradigm to mitigate data scarcity by generating diverse and informative instructions. Through comprehensive evaluations conducted in various settings, our proposed framework demonstrates exceptional performance in terms of generalization performance, surpassing current leading benchmarks. We make our model implementation openly available, along with comprehensive details at: https://github.com/HKUDS/HiGPT.  © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.},
	author_keywords = {graph learning; large language models},
	keywords = {Benchmarking; Contrastive Learning; Graph neural networks; Knowledge graph; Complex relationships; Down-stream; Graph languages; Graph learning; Graph model; Graph neural networks; Heterogeneous graph; Language model; Large language model; Relational semantics; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Wang20241984,
	author = {Wang, Duokang and Hu, Linmei and Hao, Rui and Shao, Yingxia and Lv, Xin and Nie, Liqiang and Li, Juanzi},
	title = {Let Me Show You Step by Step: An Interpretable Graph Routing Network for Knowledge-based Visual Question Answering},
	year = {2024},
	journal = {SIGIR 2024 - Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
	pages = {1984 – 1994},
	doi = {10.1145/3626772.3657790},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200559256&doi=10.1145%2f3626772.3657790&partnerID=40&md5=a73168b5b4a6f7f8fbba15e8f65c700c},
	abstract = {Visual Question Answering based on external Knowledge Bases (KB-VQA) requires a model to incorporate knowledge beyond the content of given image and question for answer prediction. Most existing works made efforts on using graph neural networks or Multi-modal Large Language Models to incorporate external knowledge for answer generation. Despite the promising results, they have limited interpretability and exhibit a deficiency in handling questions with unseen answers. In this paper, we propose a novel interpretable graph routing network (GRN) which explicitly conducts entity routing over a constructed scene knowledge graph step by step for KB-VQA. At each step, GRN keeps an entity score vector representing how likely of each entity to be activated as the answer, and a transition matrix representing the transition probability from one entity to another. To answer the given question, GRN will focus on certain keywords of the question at each step and correspondingly conduct entity routing by transiting the entity scores according to the transition matrix computed referring to the focused question keywords. In this way, it clearly provides the reasoning process of KB-VQA and can handle the questions with unseen answers without distinction. Experiments on the benchmark dataset KRVQA have demonstrated that GRN improves the performance of KB-VQA by a large margin, surpassing existing state-of-the art KB-VQA methods and Multi-modal Large Language Models, as well as shows competent capability in handling unseen answers and good interpretability in KB-VQA. © 2024 ACM.},
	author_keywords = {graph routing network; knowledge-based visual question answering; scene knowledge graph},
	keywords = {Computational linguistics; Graph neural networks; Knowledge graph; Large datasets; Network routing; External knowledge; Graph routing network; Knowledge based; Knowledge graphs; Knowledge-based visual question answering; Language model; Multi-modal; Question Answering; Routing networks; Scene knowledge graph; Benchmarking},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Zong2024,
	author = {Zong, Hui and Wu, Rongrong and Cha, Jiaxue and Feng, Weizhe and Wu, Erman and Li, Jiakun and Shao, Aibin and Tao, Liang and Li, Zuofeng and Tang, Buzhou and Shen, Bairong},
	title = {Advancing Chinese biomedical text mining with community challenges},
	year = {2024},
	journal = {Journal of Biomedical Informatics},
	volume = {157},
	doi = {10.1016/j.jbi.2024.104716},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202344787&doi=10.1016%2fj.jbi.2024.104716&partnerID=40&md5=d244032f6ecc73dee5bdaa016948ec3a},
	abstract = {Objective: This study aims to review the recent advances in community challenges for biomedical text mining in China. Methods: We collected information of evaluation tasks released in community challenges of biomedical text mining, including task description, dataset description, data source, task type and related links. A systematic summary and comparative analysis were conducted on various biomedical natural language processing tasks, such as named entity recognition, entity normalization, attribute extraction, relation extraction, event extraction, text classification, text similarity, knowledge graph construction, question answering, text generation, and large language model evaluation. Results: We identified 39 evaluation tasks from 6 community challenges that spanned from 2017 to 2023. Our analysis revealed the diverse range of evaluation task types and data sources in biomedical text mining. We explored the potential clinical applications of these community challenge tasks from a translational biomedical informatics perspective. We compared with their English counterparts, and discussed the contributions, limitations, lessons and guidelines of these community challenges, while highlighting future directions in the era of large language models. Conclusion: Community challenge evaluation competitions have played a crucial role in promoting technology innovation and fostering interdisciplinary collaboration in the field of biomedical text mining. These challenges provide valuable platforms for researchers to develop state-of-the-art solutions. © 2024 The Authors},
	author_keywords = {Artificial intelligence; Biomedical text mining; Health information processing; Large language model; Natural language processing},
	keywords = {China; Data Mining; Medical Informatics; Natural Language Processing; Modeling languages; Question answering; Biomedical text minings; Data-source; Health information processing; Health informations; Language model; Language processing; Large language model; Natural language processing; Natural languages; Task type; artificial intelligence; classification; clinical practice guideline; community; competition; human; information processing; large language model; medical information; natural language processing; practice guideline; review; translational bioinformatics; China; data mining; medical informatics; procedures; Data description},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Doan202443,
	author = {Doan, Anhai},
	title = {Technical Perspective: Unicorn: A Unified Multi-Tasking Matching Model},
	year = {2024},
	journal = {SIGMOD Record},
	volume = {53},
	number = {1},
	pages = {43},
	doi = {10.1145/3665252.3665262},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193454396&doi=10.1145%2f3665252.3665262&partnerID=40&md5=8c76dd5c6316b7dea760dbe7956774a1},
	abstract = {Data integration has been a long-standing challenge for data management. It has recently received significant attention due to at least three main reasons. First, many data science projects require integrating data from disparate sources before analysis can be carried out to extract insights. Second, many organizations want to build knowledge graphs, such as Customer 360s, Product 360s, and Supplier 360s, which capture all available information about the customers, products, and suppliers of an organization. Building such knowledge graphs often requires integrating data from multiple sources. Finally, there is also an increasing need to integrate a massive amount of data to create training data for AI models, such as large language models.  © 2024 Copyright is held by the owner/author(s).},
	type = {Note},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Sojitra20242657,
	author = {Sojitra, Daivik and Jain, Raghav and Saha, Sriparna and Jatowt, Adam and Gupta, Manish},
	title = {Timeline Summarization in the Era of LLMs},
	year = {2024},
	journal = {SIGIR 2024 - Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
	pages = {2657 – 2661},
	doi = {10.1145/3626772.3657899},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200547390&doi=10.1145%2f3626772.3657899&partnerID=40&md5=5fc99efe0f7ddafc7bac685975f99989},
	abstract = {Timeline summarization is the task of automatically generating concise overviews of documents that capture the key events and their progression on timelines. While this capability is useful for quickly comprehending event sequences without reading lengthy descriptions, timeline summarization remains a relatively underexplored area in recent years when compared to traditional document summarization task and their evolution. The advent of large language models (LLMs) has led some to presume summarization as a solved problem. However, timeline summarization poses unique challenges for LLMs. Our investigation is centered on evaluating the performance of LLMs, against state-of-the-art models in this field. We employed three different approaches: chunking, knowledge graph-based summarization, and TimeRanker. Each of these methods was systematically tested on three benchmark datasets for timeline summarization to assess their effectiveness in capturing and condensing key events and their evolution within timelines. Our findings reveal that while LLMs show promise, timeline summarization remains a complex task that is not yet fully resolved. © 2024 ACM.},
	author_keywords = {benchmarking; knowledge graphs; llms; timeline summarization},
	keywords = {Graphic methods; ART model; Document summarization; Event sequence; Graph-based; Knowledge graphs; Language model; Llms; Performance; State of the art; Timeline summarization; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Goel2024417,
	author = {Goel, Drishti and Husain, Fiza and Singh, Aditya and Ghosh, Supriyo and Parayil, Anjaly and Bansal, Chetan and Zhang, Xuchao and Rajmohan, Saravan},
	title = {X-Lifecycle Learning for Cloud Incident Management using LLMs},
	year = {2024},
	journal = {FSE Companion - Companion Proceedings of the 32nd ACM International Conference on the Foundations of Software Engineering},
	pages = {417 – 428},
	doi = {10.1145/3663529.3663861},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198654519&doi=10.1145%2f3663529.3663861&partnerID=40&md5=10425cdfe461f881a386a15e22de81db},
	abstract = {Incident management for large cloud services is a complex and tedious process that requires a significant amount of manual effort from on-call engineers (OCEs). OCEs typically leverage data from different stages of the software development lifecycle [SDLC] (e.g., codes, configuration, monitor data, service properties, service dependencies, trouble-shooting documents, etc.) to generate insights for detection, root cause analysis and mitigation of incidents. Recent advancements in large language models [LLMs] (e.g., ChatGPT, GPT-4, Gemini) have created opportunities to automatically generate contextual recommendations for the OCEs, assisting them in quickly identifying and mitigating critical issues. However, existing research typically takes a silo-ed view of solving a certain task in incident management by leveraging data from a single stage of the SDLC. In this paper, we demonstrate that augmenting additional contextual data from different stages of the SDLC improves the performance of two critically important and practically challenging tasks: (1) automatically generating root cause recommendations for dependency failure related incidents, and (2) identifying the ontology of service monitors used for automatically detecting incidents. By leveraging a dataset of 353 incidents and 260 monitors from Microsoft, we demonstrate that augmenting contextual information from different stages of the SDLC improves the performance over state-of-the-art methods. © 2024 Copyright held by the owner/author(s).},
	author_keywords = {Cloud Services; Large language models; Monitor management; Reliability; Root-cause analysis},
	keywords = {Computational linguistics; Distributed database systems; Life cycle; Reliability analysis; Software design; Cloud services; Code configuration; Different stages; Incident Management; Language model; Large language model; Monitor management; Performance; Root cause analysis; Software development life-cycle; Web services},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@CONFERENCE{2024,
	title = {Scientific and Statistical Database Management: 36th International Conference, SSDBM 2024 - Proceedings},
	year = {2024},
	journal = {ACM International Conference Proceeding Series},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205024881&partnerID=40&md5=0c0a15ff9d77763526081c04072c4342},
	abstract = {The proceedings contain 19 papers. The topics discussed include: model reuse in learned spatial indexes; the intersection of compliance, databases, and it operations; similarity measures recommendation for mixed data clustering; CURD: context-aware relevance and urgency determination; imbalanced graph-level anomaly detection via counterfactual augmentation and feature learning; a compact and efficient neural data structure for mutual information estimation in large timeseries; AI data readiness inspector (AIDRIN) for quantitative assessment of data readiness for AI; statistical privacy and consent in data aggregation; how do users design scientific workflows? the case of Snakemake and Nextflow; a model and query language for multi-modal hybrid query; and knowledge graph enhancement for improved natural language health question answering using large language models.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Obuchi202446,
	author = {Obuchi, Kiichi and Funaya, Koichi and Toyama, Kiyohiko and Tanaka, Shukichi and Onoro Rubio, Daniel and Min, Martin Renqiang and Melvin, Iain},
	title = {LLMs and MI Bring Innovation to Material Development Platforms},
	year = {2024},
	journal = {NEC Technical Journal},
	volume = {17},
	number = {2},
	pages = {46 – 50},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198045683&partnerID=40&md5=d61ec7193698a4188e5cdfbff961a6e7},
	abstract = {In this paper, we introduce efforts to apply large language models (LLMs) to the field of material development. NEC is advancing the development of a material development platform. By applying core technologies corresponding to two material development steps, namely investigation activities (Read paper/patent) and experimental planning (Design Experiment Plan), the platform organizes documents such as papers and reports as well as data such as experimental results and then presents in an interactive way to users. In addition, with techniques that reflect physical and chemical principles into machine learning models, AI can learn even with limited data and accurately predict material properties. Through this platform, we aim to achieve the seamless integration of materials informatics (MI) with a vast body of industry literature and knowledge, thereby bringing innovation to the material development process. © 2024 NEC Mediaproducts. All rights reserved.},
	author_keywords = {AI model for generating molecular structures; information extraction technology; knowledge graph; material area-specific LLM; Materials Informatics (MI); ontology; PIML (Physics-Informed Machine Learning)},
	keywords = {Machine learning; AI model for generating molecular structure; Information extraction technology; Knowledge graphs; Language model; Machine-learning; Material area-specific large language model; Material informatic; Material Informatics; Ontology's; Physic-informed machine learning; Knowledge graph},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Zhao2024,
	author = {Zhao, Xinyan and Chen, Baiyan and Ji, Mengxue and Wang, Xinyue and Yan, Yuhan and Zhang, Jinming and Liu, Shiyingjie and Ye, Muyang and Lv, Chunli},
	title = {Implementation of Large Language Models and Agricultural Knowledge Graphs for Efficient Plant Disease Detection},
	year = {2024},
	journal = {Agriculture (Switzerland)},
	volume = {14},
	number = {8},
	doi = {10.3390/agriculture14081359},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202663351&doi=10.3390%2fagriculture14081359&partnerID=40&md5=279e5716a88641a449316f2f2c10ff03},
	abstract = {This study addresses the challenges of elaeagnus angustifolia disease detection in smart agriculture by developing a detection system that integrates advanced deep learning technologies, including Large Language Models (LLMs), Agricultural Knowledge Graphs (KGs), Graph Neural Networks (GNNs), representation learning, and neural-symbolic reasoning techniques. The system significantly enhances the accuracy and efficiency of disease detection through an innovative graph attention mechanism and optimized loss functions. Experimental results demonstrate that this system significantly outperforms traditional methods across key metrics such as precision, recall, and accuracy, with the graph attention mechanism excelling in all aspects, particularly achieving a precision of 0.94, a recall of 0.92, and an accuracy of 0.93. Furthermore, comparative experiments with various loss functions further validate the effectiveness of the graph attention loss mechanism in enhancing model performance. This research not only advances the application of deep learning in agricultural disease detection theoretically but also provides robust technological tools for disease management and decision support in actual agricultural production, showcasing broad application prospects and profound practical value. © 2024 by the authors.},
	author_keywords = {agricultural knowledge graphs; agricultural large model; deep learning; plant disease detection; smart agriculture},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Gaur20246712,
	author = {Gaur, Manas and Tsamoura, Efthymia and Raff, Edward and Vedula, Nikhita and Parthasarathy, Srinivasan},
	title = {KiL 2024: 4th International Workshop on Knowledge-infused Learning (Towards Consistent, Reliable, Explainable, and Safe LLMs)},
	year = {2024},
	journal = {Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
	pages = {6712 – 6713},
	doi = {10.1145/3637528.3671495},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203688220&doi=10.1145%2f3637528.3671495&partnerID=40&md5=24e6dedb2435e3f85c9a00613ef06bb3},
	abstract = {The Knowledge-infused Learning Workshop is a recurring event in ACM's KDD Conference that gathers the research community on knowledge graphs and knowledge-enabled learning, grounded neurosymbolic AI, explainable and safe AI, and applications in high-stakes decision-making problems. This year, the workshop aligned with Biden's vision of Responsible AI Development.  © 2024 Copyright held by the owner/author(s).},
	author_keywords = {evaluation metrics; knowledge-infused learning; large language models; neurosymbolic ai; safe ai; social good; trustworthy ai},
	keywords = {Contrastive Learning; Federated learning; Knowledge graph; Evaluation metrics; International workshops; Knowledge-infused learning; Language model; Large language model; Learning workshops; Neurosymbolic ai; Safe ai; Social good; Trustworthy ai; Adversarial machine learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Ying20241912,
	author = {Ying, Huaiyuan and Zhao, Zhengyun and Zhao, Yang and Zeng, Sihang and Yu, Sheng},
	title = {CoRTEx: Contrastive learning for representing terms via explanations with applications on constructing biomedical knowledge graphs},
	year = {2024},
	journal = {Journal of the American Medical Informatics Association},
	volume = {31},
	number = {9},
	pages = {1912 – 1920},
	doi = {10.1093/jamia/ocae115},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201754632&doi=10.1093%2fjamia%2focae115&partnerID=40&md5=70634c8b45a96460f1c7b8cee222f292},
	abstract = {Objectives: Biomedical Knowledge Graphs play a pivotal role in various biomedical research domains. Concurrently, term clustering emerges as a crucial step in constructing these knowledge graphs, aiming to identify synonymous terms. Due to a lack of knowledge, previous contrastive learning models trained with Unified Medical Language System (UMLS) synonyms struggle at clustering difficult terms and do not generalize well beyond UMLS terms. In this work, we leverage the world knowledge from large language models (LLMs) and propose Contrastive Learning for Representing Terms via Explanations (CoRTEx) to enhance term representation and significantly improves term clustering. Materials and Methods: The model training involves generating explanations for a cleaned subset of UMLS terms using ChatGPT. We employ contrastive learning, considering term and explanation embeddings simultaneously, and progressively introduce hard negative samples. Additionally, a ChatGPT-assisted BIRCH algorithm is designed for efficient clustering of a new ontology. Results: We established a clustering test set and a hard negative test set, where our model consistently achieves the highest F1 score. With CoRTEx embeddings and the modified BIRCH algorithm, we grouped 35 580 932 terms from the Biomedical Informatics Ontology System (BIOS) into 22 104 559 clusters with O(N) queries to ChatGPT. Case studies highlight the model's efficacy in handling challenging samples, aided by information from explanations. Conclusion: By aligning terms to their explanations, CoRTEx demonstrates superior accuracy over benchmark models and robustness beyond its training set, and it is suitable for clustering terms for large-scale biomedical ontologies. © 2024 The Author(s). Published by Oxford University Press on behalf of the American Medical Informatics Association. All rights reserved.},
	author_keywords = {contrastive learning; knowledge injection; large language models; term clustering},
	keywords = {algorithm; Article; biomedical knowledge graph; case study; ChatGPT; contrastive learning for representing terms via explanation; language model; large language model; medical informatics; sample; scoring system; Unified Medical Language System},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Green Open Access}
}

@CONFERENCE{Zhang20246644,
	author = {Zhang, Yunyi and Zhong, Ming and Ouyang, Siru and Jiao, Yizhu and Zhou, Sizhe and Ding, Linyi and Han, Jiawei},
	title = {Automated Mining of Structured Knowledge from Text in the Era of Large Language Models},
	year = {2024},
	journal = {Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
	pages = {6644 – 6654},
	doi = {10.1145/3637528.3671469},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203709209&doi=10.1145%2f3637528.3671469&partnerID=40&md5=7d0aca518d9e51a57b476998ec9c7cfa},
	abstract = {Massive amount of unstructured text data are generated daily, ranging from news articles to scientific papers. How to mine structured knowledge from the text data remains a crucial research question. Recently, large language models (LLMs) have shed light on the text mining field with their superior text understanding and instruction-following ability. There are typically two ways of utilizing LLMs: fine-tune the LLMs with human-annotated training data, which is labor intensive and hard to scale; prompt the LLMs in a zero-shot or few-shot way, which cannot take advantage of the useful information in the massive text data. Therefore, it remains a challenge on automated mining of structured knowledge from massive text data in the era of large language models. In this tutorial, we cover the recent advancements in mining structured knowledge using language models with very weak supervision. We will introduce the following topics in this tutorial: (1) introduction to large language models, which serves as the foundation for recent text mining tasks, (2) ontology construction, which automatically enriches an ontology from a massive corpus, (3) weakly-supervised text classification in flat and hierarchical label space, (4) weakly-supervised information extraction, which extracts entity and relation structures.  © 2024 Copyright held by the owner/author(s).},
	author_keywords = {large language models; text mining; weak supervision},
	keywords = {Self-supervised learning; Zero-shot learning; Automated mining; Language model; Large language model; News articles; Scientific papers; Structured knowledge; Text data; Text-mining; Unstructured texts; Weak supervision; Ontology},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Tsitsulin20246424,
	author = {Tsitsulin, Anton and Perozzi, Bryan and Fatemi, Bahare and Halcrow, Jonathan J.},
	title = {Graph Reasoning with LLMs (GReaL)},
	year = {2024},
	journal = {Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
	pages = {6424 – 6425},
	doi = {10.1145/3637528.3671448},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203720447&doi=10.1145%2f3637528.3671448&partnerID=40&md5=613cb3144dfbc5307a3b6c4337cf3cb9},
	abstract = {Graphs are a powerful tool for representing and analyzing complex relationships in real-world applications. Large Language Models (LLMs) have demonstrated impressive capabilities by advancing state-of-the-art on many language-based benchmarks. Their ability to process and understand natural language open exciting possibilities in various domains. Despite the remarkable progress in automated reasoning with natural text, reasoning on graphs with LLMs remains an understudied problem that has recently gained more attention. This tutorial builds upon recent advances in expressing reasoning problems through the lens of tasks on graph data. The first part of the tutorial will provide an in-depth discussion of techniques for representing graphs as inputs to LLMs. The second, hands-on, portion will demonstrate these techniques in a practical setting. As a learning outcome of participating in the tutorial, participants will be able to analyze graphs either on free-tier Colab or their local machines with the help of LLMs.  © 2024 Copyright held by the owner/author(s).},
	author_keywords = {graph neural networks; graphs; large language models},
	keywords = {Adversarial machine learning; Benchmarking; Contrastive Learning; Knowledge graph; Modeling languages; Natural language processing systems; Automated reasoning; Complex relationships; Graph; Graph neural networks; Language model; Large language model; Natural languages; Real-world; Reasoning problems; State of the art; Graph neural networks},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Xiong20243963,
	author = {Xiong, Hao-Shu and Wang, Bei-Xuan and Hou, Jian and Zhao, Cheng and Wang, Ya-Wen and Zhang, Shun-Nan and Yan, Kai-Jing},
	title = {Application scenario design and prospect of generative artificial intelligence (AI) in intelligent manufacturing and supply chain of traditional Chinese medicine; [生成式人工智能(AI) 在中药智能制造及供应链中的应用场景设计与展望]},
	year = {2024},
	journal = {Zhongguo Zhongyao Zazhi},
	volume = {49},
	number = {14},
	pages = {3963 – 3970},
	doi = {10.19540/j.cnki.cjcmm.20240402.301},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199706675&doi=10.19540%2fj.cnki.cjcmm.20240402.301&partnerID=40&md5=76dfdb792c440f402a8b0a5c6aa9f4bc},
	abstract = {Intelligent manufacturing technologies, including databases, mathematical modeling, and information systems have played a significant role in process control, production management, and supply chain management in traditional Chinese medicine (TCM) industry. However, their ability to process and utilize unstructured data, such as research and development reports, batch production records, quality inspection records, and supplier documents, is relatively weak. For text, images, language, and other unstructured data, generative artificial intelligence (AI) technology has shown strong potential for development in extracting information, extracting knowledge, semantic retrieval, and content generation. Generative AI is expected to provide a feasible set of tools for the utilization of unstructured data resources in the TCM industry. Based on years of research and industrial application experience in TCM intelligent manufacturing technology, this study reviewed the current situation of intelligent manufacturing in TCM and the utilization of unstructured data, analyzed the application value of generative AI in the TCM manufacturing process and supply chain, summarized four typical application scenarios, including intelligent pharmaceutical knowledge base / knowledge graph, intelligent on-the-job training, intelligent production quality control, and intelligent supply chain. Furthermore, this study also explained the data collection and processing, business process design, application potential, and value of each scenario based on industry demands. Finally, based on the integration of generative AI and TCM industrial models, the study proposed a preliminary concept of a smart industrial brain for TCM, aiming to provide a reference for the application of AI technology in the field of TCM manufacturing. © 2024 Zhongguo Zhongyi Yanjiuyuan. All rights reserved.},
	author_keywords = {artificial intelligence; generative artificial intelligence (AI); intelligent manufacturing; large model; supply chain; traditional Chinese medicine(TCM)},
	keywords = {Artificial Intelligence; Drugs, Chinese Herbal; Humans; Medicine, Chinese Traditional; Quality Control; herbaceous agent; article; artificial intelligence; Chinese medicine; commercial phenomena; data base; generative artificial intelligence; human; information processing; information retrieval; information system; knowledge base; process control; process design; quality control; chemistry},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Bhattacharya202462,
	author = {Bhattacharya, Ranjeeta},
	title = {Strategies to mitigate hallucinations in large language models},
	year = {2024},
	journal = {Applied Marketing Analytics},
	volume = {10},
	number = {1},
	pages = {62 – 67},
	doi = {10.69554/nxxb8234},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202886920&doi=10.69554%2fnxxb8234&partnerID=40&md5=ca872300412c68c70deb81a8e0219b2b},
	abstract = {In the world of enterprise-level applications, the construction and utilisation of large language models (LLMs) carry a paramount significance, accompanied by the crucial task of mitigating hallucinations. These instances of generating factually inaccurate information pose challenges during both the initial development phase of LLMs and the subsequent refinement process through prompt engineering. This paper delves into a variety of approaches such as retrieval augmented generation, advanced prompting methodologies, harnessing the power of knowledge graphs, construction of entirely new LLMs from scratch etc, aimed at alleviating these challenges. The paper also underscores the indispensable role of human oversight and user education in addressing this evolving issue. As the field continues to evolve, the importance of continuous vigilance and adaptation cannot be overstated, with a focus on refining strategies to effectively combat hallucinations within LLMs. © Henry Stewart Publications 2054-7544 (2024)},
	author_keywords = {hallucination; large language model; LLM; prompt engineering; RAG},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Hu20241108,
	author = {Hu, Qi and Li, Haoran and Bai, Jiaxin and Wang, Zihao and Song, Yangqiu},
	title = {Privacy-Preserved Neural Graph Databases},
	year = {2024},
	journal = {Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
	pages = {1108 – 1118},
	doi = {10.1145/3637528.3671678},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203717627&doi=10.1145%2f3637528.3671678&partnerID=40&md5=e1389fbd76b5f8550448c59ad07b38d3},
	abstract = {In the era of large language models (LLMs), efficient and accurate data retrieval has become increasingly crucial for the use of domain-specific or private data in the retrieval augmented generation (RAG). Neural graph databases (NGDBs) have emerged as a powerful paradigm that combines the strengths of graph databases (GDBs) and neural networks to enable efficient storage, retrieval, and analysis of graph-structured data which can be adaptively trained with LLMs. The usage of neural embedding storage and Complex neural logical Query Answering (CQA) provides NGDBs with generalization ability. When the graph is incomplete, by extracting latent patterns and representations, neural graph databases can fill gaps in the graph structure, revealing hidden relationships and enabling accurate query answering. Nevertheless, this capability comes with inherent trade-offs, as it introduces additional privacy risks to the domain-specific or private databases. Malicious attackers can infer more sensitive information in the database using well-designed queries such as from the answer sets of where Turing Award winners born before 1950 and after 1940 lived, the living places of Turing Award winner Hinton are probably exposed, although the living places may have been deleted in the training stage due to the privacy concerns. In this work, we propose a privacy-preserved neural graph database (P-NGDB) framework to alleviate the risks of privacy leakage in NGDBs. We introduce adversarial training techniques in the training stage to enforce the NGDBs to generate indistinguishable answers when queried with private information, enhancing the difficulty of inferring sensitive information through combinations of multiple innocuous queries. Extensive experimental results on three datasets show that our framework can effectively protect private information in the graph database while delivering high-quality public answers responses to queries. The code is available at https://github.com/HKUST-KnowComp/PrivateNGDB.  © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.},
	author_keywords = {complex query answering (cqa); knowledge graphs (kgs); neural graph databases (ngdbs); privacy preserving},
	keywords = {Database systems; Graph neural networks; Information leakage; Question answering; Structured Query Language; Complex queries; Complex query answering; Domain specific; Graph database; Knowledge graph; Knowledge graphs; Language model; Neural graph database; Privacy preserving; Query answering; Differential privacy},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@CONFERENCE{2024,
	title = {Proceedings of the 2024 International Conference on Computer and Multimedia Technology, ICCMT 2024},
	year = {2024},
	journal = {ACM International Conference Proceeding Series},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201254831&partnerID=40&md5=037a7b972d5c3de27a7f0e2d3cf369f6},
	abstract = {The proceedings contain 100 papers. The topics discussed include: research on following model based on K-nearest neighbor and information entropy; temporal knowledge graph completion based on entity multi-encoding and temporal awareness; a novel method based on large language model for MBTI classification: a novel MBTI classification method; a method for fusion of customer caller appeal information based on a consistent clustering model; program design of big data technology combined with artificial intelligence algorithm to assist civics teaching to cultivate Chinese national community consciousness; construction of meteorological disasters knowledge graph based on deep learning; and research on automatic calibration method of microwave radiometer on offshore floating platform.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Groza2024,
	author = {Groza, Tudor and Gration, Dylan and Baynam, Gareth and Robinson, Peter N.},
	title = {FastHPOCR: pragmatic, fast, and accurate concept recognition using the human phenotype ontology},
	year = {2024},
	journal = {Bioinformatics},
	volume = {40},
	number = {7},
	doi = {10.1093/bioinformatics/btae406},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197975714&doi=10.1093%2fbioinformatics%2fbtae406&partnerID=40&md5=63e22c0dca51a6992de3c31ddc854d35},
	abstract = {Motivation: Human Phenotype Ontology (HPO)-based phenotype concept recognition (CR) underpins a faster and more effective mechanism to create patient phenotype profiles or to document novel phenotype-centred knowledge statements. While the increasing adoption of large language models (LLMs) for natural language understanding has led to several LLM-based solutions, we argue that their intrinsic resource-intensive nature is not suitable for realistic management of the phenotype CR lifecycle. Consequently, we propose to go back to the basics and adopt a dictionary-based approach that enables both an immediate refresh of the ontological concepts as well as efficient re-analysis of past data. Results: We developed a dictionary-based approach using a pre-built large collection of clusters of morphologically equivalent tokens-to address lexical variability and a more effective CR step by reducing the entity boundary detection strictly to candidates consisting of tokens belonging to ontology concepts. Our method achieves state-of-the-art results (0.76 F1 on the GSCþ corpus) and a processing efficiency of 10 000 publication abstracts in 5 s. Availability and implementation: FastHPOCR is available as a Python package installable via pip. The source code is available at https://github.com/tudorgroza/fast_hpo_cr. A Java implementation of FastHPOCR will be made available as part of the Fenominal Java library available at https://github.com/monarch-initiative/fenominal. The up-to-date GCS-2024 corpus is available at https://github.com/tudorgroza/code-forpapers/tree/main/gsc-2024. © The Author(s) 2024.},
	keywords = {Algorithms; Biological Ontologies; Humans; Natural Language Processing; Phenotype; Software; algorithm; biological ontology; human; natural language processing; phenotype; software},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Huang2024552,
	author = {Huang, Xiaobin and Ku, Chin Soon},
	title = {Designing an Interpretable Question Answering System for Vertical Domains Based on Large Language Model and Knowledge Graph},
	year = {2024},
	journal = {Advances in Transdisciplinary Engineering},
	volume = {57},
	pages = {552 – 561},
	doi = {10.3233/ATDE240503},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198548015&doi=10.3233%2fATDE240503&partnerID=40&md5=f5d9d3267f1c55ebe15bf6d81a6e6ada},
	abstract = {Given the low interpretability of large language models (LLMs) due to their extensive parameters and intricate features, this study aims to enhance the understandability and interpretability of automatic QA systems powered by LLMs, thereby addressing a critical gap in the field. To achieve this, we introduce an interpretable architecture for a domain-specific LLM-based question-answering (QA) system. The research decomposes the QA system into six modules: operation recognition, intent recognition, normalization, triplet structured data conversion, knowledge graph querying, and query result processing. Through this approach, the input and output of each module in the QA system are human-readable text data, enhancing the interpretability of the QA system's processing. The use of knowledge graph data increases the credibility of the answers provided by the QA system. The QA system architecture proposed in this study attempts to integrate the powerful natural language understanding capabilities of large language models with the data querying capacity of knowledge graphs, offering a reference for addressing the issue of low interpretability in automatic QA systems based on large language models (LLMs). © 2024 The Authors.},
	author_keywords = {interpretable; knowledge graph; Large language model; question answering system},
	keywords = {Computational linguistics; Computer architecture; Data handling; Natural language processing systems; Search engines; Automatic question answering; Domain specific; Interpretability; Interpretable; Knowledge graphs; Language model; Large language model; Model-based OPC; Question answering systems; Understandability; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Peng2024,
	author = {Peng, Huang and Zhang, Pengfei and Tang, Jiuyang and Xu, Hao and Zeng, Weixin},
	title = {Detect-Then-Resolve: Enhancing Knowledge Graph Conflict Resolution with Large Language Model},
	year = {2024},
	journal = {Mathematics},
	volume = {12},
	number = {15},
	doi = {10.3390/math12152318},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200779132&doi=10.3390%2fmath12152318&partnerID=40&md5=218c45feddceafa443029fadbd763d1f},
	abstract = {Conflict resolution for knowledge graphs (KGs) is a critical technique in knowledge fusion, ensuring the resolution of conflicts between existing KGs and external knowledge while maintaining post-fusion accuracy. However, current approaches often encounter difficulties with external triples involving unseen entities due to limited knowledge. Moreover, current methodologies typically overlook conflict detection prior to resolution, a crucial step for accurate truth inference. This paper introduces CRDL, an innovative approach that leverages conflict detection and large language models (LLMs) to identify truths. By employing conflict detection, we implement precise filtering strategies tailored to various types of relations and attributes. By designing prompts and injecting relevant information into an LLM, we identify triples with unseen entities. Experimental results demonstrate the superiority of CRDL over baseline methods. Specifically, our method surpasses the state-of-the-art by achieving a 56.4% improvement in recall and a 68.2% increase in F1-score. These results clearly illustrate the enhanced performance and effectiveness of our approach. Additionally, ablation studies and further analyses underscore the importance of the components within CRDL. © 2024 by the authors.},
	author_keywords = {conflict resolution; knowledge graph; large language model},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Feng2024920,
	author = {Feng, Jun and Lu, Zhipeng and Fan, Zhendong and Kong, Xu and Lu, Jiamin and Zhou, Siyuan},
	title = {Label design method for flood control scheduling rules assisted by LLM; [基于大语言模型辅助的防洪调度规则标签设计方法]},
	year = {2024},
	journal = {Shuili Xuebao/Journal of Hydraulic Engineering},
	volume = {55},
	number = {8},
	pages = {920 – 930},
	doi = {10.13243/j.cnki.slxb.20230643},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205973586&doi=10.13243%2fj.cnki.slxb.20230643&partnerID=40&md5=cc99f77a9ac89862b4f5575b3ed0e4b2},
	abstract = {The information extraction of flood control dispatching rules is of great significance for flood control dispatching automation, and the design of labeling systems is pivotal for information extraction. Traditional designs often have comprehension biases and omissions, leading to issues like overgeneralization and incompleteness. Addressing these imperfections, this research emphasizes the extraction of rules in flood scheduling texts, proposing an enhanced approach for labeling optimization.Large Language Models(LLM) are utilized for tasks like label refinement and generation, boosting label precision and clarity, and a technique for extracting entity relationship triplets is also presented for datasets with many labels. Grouping these triplets enhances extraction performance in label-rich datasets. A visual knowledge graph for flood control scheduling using Neo4j is also developed. This research offers foundational insights for future work in flood control scheduling knowledge extraction. © 2024 International Research and Training Center on Erosion and Sedimentation and China Water and Power Press. All rights reserved.},
	author_keywords = {flood control scheduling; knowledge extraction; knowledge graph; label design; natural language processing},
	keywords = {Knowledge graph; Natural language processing systems; Risk management; Design method; Flood control scheduling; Knowledge extraction; Knowledge graphs; Label design; Language model; Language processing; Natural language processing; Natural languages; Scheduling rules; Flood control},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Osman2024,
	author = {Osman, Inès and Pileggi, Salvatore Flavio and Yahia, Sadok Ben},
	title = {Uncertainty in Automated Ontology Matching: Lessons from an Empirical Evaluation},
	year = {2024},
	journal = {Applied Sciences (Switzerland)},
	volume = {14},
	number = {11},
	doi = {10.3390/app14114679},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195951776&doi=10.3390%2fapp14114679&partnerID=40&md5=c28a5c8ce24eae075ce281bef3da4c11},
	abstract = {Data integration is considered a classic research field and a pressing need within the information science community. Ontologies play a critical role in such processes by providing well-consolidated support to link and semantically integrate datasets via interoperability. This paper approaches data integration from an application perspective by looking at ontology matching techniques. As the manual matching of different sources of information becomes unrealistic once the system scales up, the automation of the matching process becomes a compelling need. Therefore, we have conducted experiments on actual non-semantically enriched relational data with the support of existing tools (pre-LLM technology) for automatic ontology matching from the scientific community. Even considering a relatively simple case study—i.e., the spatio–temporal alignment of macro indicators—outcomes clearly show significant uncertainty resulting from errors and inaccuracies along the automated matching process. More concretely, this paper aims to test on real-world data a bottom-up knowledge-building approach, discuss the lessons learned from the experimental results of the case study, and draw conclusions about uncertainty and uncertainty management in an automated ontology matching process. While the most common evaluation metrics clearly demonstrate the unreliability of fully automated matching solutions, properly designed semi-supervised approaches seem to be mature for more generalized application. © 2024 by the authors.},
	author_keywords = {data integration; ontology matching; uncertainty},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Chen20244850,
	author = {Chen, Xuanzhong and Mao, Xiaohao and Guo, Qihan and Wang, Lun and Zhang, Shuyang and Chen, Ting},
	title = {RareBench: Can LLMs Serve as Rare Diseases Specialists?},
	year = {2024},
	journal = {Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
	pages = {4850 – 4861},
	doi = {10.1145/3637528.3671576},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203668742&doi=10.1145%2f3637528.3671576&partnerID=40&md5=61f1822d9e1bd70fdb78c6e9109af16d},
	abstract = {Generalist Large Language Models (LLMs), such as GPT-4, have shown considerable promise in various domains, including medical diagnosis. Rare diseases, affecting approximately 300 million people worldwide, often have unsatisfactory clinical diagnosis rates primarily due to a lack of experienced physicians and the complexity of differentiating among many rare diseases. In this context, recent news such as "ChatGPT correctly diagnosed a 4-year-old's rare disease after 17 doctors failed"underscore LLMs' potential, yet underexplored, role in clinically diagnosing rare diseases. To bridge this research gap, we introduce RareBench, a pioneering benchmark designed to systematically evaluate the capabilities of LLMs on 4 critical dimensions within the realm of rare diseases. Meanwhile, we have compiled the largest open-source dataset on rare disease patients, establishing a benchmark for future studies in this domain. To facilitate differential diagnosis of rare diseases, we develop a dynamic few-shot prompt methodology, leveraging a comprehensive rare disease knowledge graph synthesized from multiple knowledge bases, significantly enhancing LLMs' diagnostic performance. Moreover, we present an exhaustive comparative study of GPT-4's diagnostic capabilities against those of specialist physicians. Our experimental findings underscore the promising potential of integrating LLMs into the clinical diagnostic process for rare diseases. This paves the way for exciting possibilities in future advancements in this field.  © 2024 Copyright held by the owner/author(s).},
	author_keywords = {benchmark for llms; evaluation; rare disease diagnosis},
	keywords = {Clinical research; Diagnosis; Knowledge graph; Benchmark for llms; Clinical diagnosis; Critical dimension; Disease diagnosis; Evaluation; Language model; Model potential; Rare disease; Rare disease diagnose; Research gaps; Diseases},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Park2024,
	author = {Park, Chaelim and Lee, Hayoung and Jeong, Ok-Ran},
	title = {Leveraging Medical Knowledge Graphs and Large Language Models for Enhanced Mental Disorder Information Extraction},
	year = {2024},
	journal = {Future Internet},
	volume = {16},
	number = {8},
	doi = {10.3390/fi16080260},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202302320&doi=10.3390%2ffi16080260&partnerID=40&md5=b59d38f1f4cefb66efb4a48066e2a07e},
	abstract = {The accurate diagnosis and effective treatment of mental health disorders such as depression remain challenging owing to the complex underlying causes and varied symptomatology. Traditional information extraction methods struggle to adapt to evolving diagnostic criteria such as the Diagnostic and Statistical Manual of Mental Disorders fifth edition (DSM-5) and to contextualize rich patient data effectively. This study proposes a novel approach for enhancing information extraction from mental health data by integrating medical knowledge graphs and large language models (LLMs). Our method leverages the structured organization of knowledge graphs specifically designed for the rich domain of mental health, combined with the powerful predictive capabilities and zero-shot learning abilities of LLMs. This research enhances the quality of knowledge graphs through entity linking and demonstrates superiority over traditional information extraction techniques, making a significant contribution to the field of mental health. It enables a more fine-grained analysis of the data and the development of new applications. Our approach redefines the manner in which mental health data are extracted and utilized. By integrating these insights with existing healthcare applications, the groundwork is laid for the development of real-time patient monitoring systems. The performance evaluation of this knowledge graph highlights its effectiveness and reliability, indicating significant advancements in automating medical data processing and depression management. © 2024 by the authors.},
	author_keywords = {depression; DSM-5; entity linking; knowledge graph; large language models; mental health; zero-shot information extraction},
	keywords = {Hospital data processing; Depression; DSM-5; Entity linking; Knowledge graphs; Language model; Large language model; Medical knowledge; Mental disorders; Mental health; Zero-shot information extraction; Electronic health record},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Li20246872,
	author = {Li, Xiaodong and Tian, Guohui and Cui, Yongcheng},
	title = {Fine-Grained Task Planning for Service Robots Based on Object Ontology Knowledge via Large Language Models},
	year = {2024},
	journal = {IEEE Robotics and Automation Letters},
	volume = {9},
	number = {8},
	pages = {6872 – 6879},
	doi = {10.1109/LRA.2024.3412593},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196082646&doi=10.1109%2fLRA.2024.3412593&partnerID=40&md5=ecd1a11006e44107c03a532063bab7a3},
	abstract = {In domestic environment, the successful execution of service tasks heavily relies on the robot's capability to identify and understand objects within its surrounding. This crucial process predominantly takes place during task planning, prior to the actual performance of service tasks. Therefore, it is vital that the robot is capable of formulating object-specific action sequences through task planning. In this letter, we propose the Fine-Grained Task Planning (FGTP) framework, an innovative method that combines object ontology knowledge with Large Language Models (LLMs) to create detailed action sequences. The FGTP framework is uniquely designed to process both text descriptions of service tasks and images of relevant objects, enabling a thorough comprehension of object attributes essential for task execution. Moreover, we have developed a set of rules based on these attributes to assist in the robot's decision-making process. In scenarios where service tasks fail because the object is in an unsuitable state, our framework deploys a logic-based reasoning method, concentrating on object attributes to identify suitable substitutes. This process leverages a pre-established semantic map to locate these alternatives, thus enabling a transition back to standard task planning. Our evaluations, conducted in both the VirtualHome simulation environment and with the TIAGo real robot, demonstrate the efficacy of our approach. This confirms our framework's capability to generate practical and implementable plans for various service tasks. © 2016 IEEE.},
	author_keywords = {service robotics; Task planning},
	keywords = {Computational linguistics; Decision making; Job analysis; Ontology; Robot programming; Semantics; Fine grained; Language model; Object ontology; Objects recognition; Ontology's; Robot kinematics; Service robotics; Service robots; Task analysis; Task planning; Object recognition},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Jiang20241301,
	author = {Jiang, Wenyuan and Wu, Wenwei and Zhang, Le and Yuan, Zixuan and Xiang, Jian and Zhou, Jingbo and Xiong, Hui},
	title = {Killing Two Birds with One Stone: Cross-modal Reinforced Prompting for Graph and Language Tasks},
	year = {2024},
	journal = {Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
	pages = {1301 – 1312},
	doi = {10.1145/3637528.3671742},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203676005&doi=10.1145%2f3637528.3671742&partnerID=40&md5=a283b841d3131b3a6dc9ccc74150f3b5},
	abstract = {In recent years, Graph Neural Networks (GNNs) and Large Language Models (LLMs) have exhibited remarkable capability in addressing different graph learning and natural language tasks, respectively. Motivated by this, integrating LLMs with GNNs has been increasingly studied to acquire transferable knowledge across modalities, which leads to improved empirical performance in language and graph domains. However, existing studies mainly focused on a single-domain scenario by designing complicated integration techniques to manage multimodal data effectively. Therefore, a concise and generic learning framework for multi-domain tasks, i.e., graph and language domains, is highly desired yet remains under-exploited due to two major challenges. First, the language corpus of downstream tasks differs significantly from graph data, making it hard to bridge the knowledge gap between modalities. Second, not all knowledge demonstrates immediate benefits for downstream tasks, potentially introducing disruptive noise to context-sensitive models like LLMs. To tackle these challenges, we propose a novel plug-and-play framework for incorporating a lightweight cross-domain prompting method into both language and graph learning tasks. Specifically, we first convert the textual input into a domain-scalable prompt, which not only preserves the semantic and logical contents of the textual input, but also highlights related graph information as external knowledge for different domains. Then, we develop a reinforcement learning-based method to learn the optimal edge selection strategy for useful knowledge extraction, which profoundly sharpens the multi-domain model capabilities. In addition, we introduce a joint multi-view optimization module to regularize agent-level collaborative learning across two domains. Finally, extensive empirical justifications over 23 public and synthetic datasets demonstrate that our approach can be applied to diverse multi-domain tasks more accurately, robustly, and reasonably, and improve the performances of the state-of-the-art graph and language models in different learning paradigms.  © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.},
	author_keywords = {graph neural networks; large language models; prompt learning; reinforcement learning},
	keywords = {Adversarial machine learning; Collaborative learning; Contrastive Learning; Domain Knowledge; Federated learning; Knowledge graph; Multi-task learning; Network theory (graphs); Reinforcement learning; Semantics; Cross-modal; Down-stream; Graph neural networks; Language model; Large language model; Learning languages; Multi-domain tasks; Natural languages; Prompt learning; Reinforcement learnings; Graph neural networks},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Wanna2024,
	author = {Wanna, Selma and Solovyev, Nicholas and Barron, Ryan and Eren, Maksim E. and Bhattarai, Manish and Rasmussen, Kim Ø. and Alexandrov, Boian S.},
	title = {TopicTag: Automatic Annotation of NMF Topic Models Using Chain of Thought and Prompt Tuning with LLMs},
	year = {2024},
	journal = {DocEng 2024 - Proceedings of the 2024 ACM Symposium on Document Engineering},
	doi = {10.1145/3685650.3685667},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206102336&doi=10.1145%2f3685650.3685667&partnerID=40&md5=f2d872b0fe3a70ef9b3732f3848c8c62},
	abstract = {Topic modeling is a technique for organizing and extracting themes from large collections of unstructured text. Non-negative matrix factorization (NMF) is a common unsupervised approach that decomposes a term frequency-inverse document frequency (TF-IDF) matrix to uncover latent topics and segment the dataset accordingly. While useful for highlighting patterns and clustering documents, NMF does not provide explicit topic labels, necessitating subject matter experts (SMEs) to assign labels manually. We present a methodology for automating topic labeling in documents clustered via NMF with automatic model determination (NMFk). By leveraging the output of NMFk and employing prompt engineering, we utilize large language models (LLMs) to generate accurate topic labels. Our case study on over 34,000 scientific abstracts on Knowledge Graphs demonstrates the effectiveness of our method in enhancing knowledge management and document organization. © 2024 Copyright held by the owner/author(s).},
	author_keywords = {chain of thought; llm; nmf; prompt tuning; topic labeling},
	keywords = {Covariance matrix; Information management; Inverse problems; Knowledge graph; Labeled data; Automatic annotation; Chain of thought; Labelings; Language model; Llm; Matrix factorizations; Nmf; Prompt tuning; Topic labeling; Topic Modeling; Non-negative matrix factorization},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@ARTICLE{Liu2024,
	author = {Liu, Yao and Liu, Ye},
	title = {Integration of Semantic and Topological Structural Similarity Comparison for Entity Alignment without Pre-Training},
	year = {2024},
	journal = {Electronics (Switzerland)},
	volume = {13},
	number = {11},
	doi = {10.3390/electronics13112036},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195823563&doi=10.3390%2felectronics13112036&partnerID=40&md5=8d18914b898bcfb823eae4de5a0d8e71},
	abstract = {Entity alignment (EA) is a critical task in integrating diverse knowledge graph (KG) data and plays a central role in data-driven AI applications. Traditional EA approaches rely on entity embeddings, but their effectiveness is limited by scarce KG input data and representation learning techniques. Large language models have shown promise, but face challenges such as high hardware requirements, large model sizes and computational inefficiency, which limit their applicability. To overcome these limitations, we propose an entity-alignment model that compares the similarity between entities by capturing both semantic and topological information to enable the alignment of entities with high similarity. First, we analyze descriptive information to quantify semantic similarity, including individual features such as types and attributes. Then, for topological analysis, we introduce four conditions based on graph connectivity and structural patterns to determine subgraph similarity within three hops of the entity’s neighborhood, thereby improving accuracy. Finally, we integrate semantic and topological similarity using a weighted approach that considers dataset features. Our model requires no pre-training and is designed to be compact and generalizable to different datasets. Experimental results on four standard EA datasets validate the effectiveness of our proposed model. © 2024 by the authors.},
	author_keywords = {description information; entity alignment; knowledge graph; topological structure},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Malakhov2024,
	author = {Malakhov, Kyrylo S.},
	title = {Innovative Hybrid Cloud Solutions for Physical Medicine and Telerehabilitation Research},
	year = {2024},
	journal = {International Journal of Telerehabilitation},
	volume = {16},
	number = {1},
	doi = {10.5195/ijt.2024.6635},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197791828&doi=10.5195%2fijt.2024.6635&partnerID=40&md5=624087c1c6f29134bbba3d26031fddda},
	abstract = {Purpose: The primary objective of this study was to develop and implement a Hybrid Cloud Environment for Telerehabilitation (HCET) to enhance patient care and research in the Physical Medicine and Rehabilitation (PM&R) domain. This environment aims to integrate advanced information and communication technologies to support both traditional in-person therapy and digital health solutions. Background: Telerehabilitation is emerging as a core component of modern healthcare, especially within the PM&R field. By applying digital health technologies, telerehabilitation provides continuous, comprehensive support for patient rehabilitation, bridging the gap between traditional therapy, and remote healthcare delivery. This study focuses on the design, and implementation of a hybrid HCET system tailored for the PM&R domain. Methods: The study involved the development of a comprehensive architectural and structural organization for the HCET, including a three-layer model (infrastructure, platform, service layers). Core components of the HCET were designed and implemented, such as the Hospital Information System (HIS) for PM&R, the MedRehabBot system, and the MedLocalGPT project. These components were integrated using advanced technologies like large language models (LLMs), word embeddings, and ontology-related approaches, along with APIs for enhanced functionality and interaction. Findings: The HCET system was successfully implemented and is operational, providing a robust platform for telerehabilitation. Key features include the MVP of the HIS for PM&R, supporting patient profile management, and rehabilitation goal tracking; the MedRehabBot and WhiteBookBot systems; and the MedLocalGPT project, which offers sophisticated querying capabilities, and access to extensive domain-specific knowledge. The system supports both Ukrainian and English languages, ensuring broad accessibility and usability. Interpretation: The practical implementation, and operation of the HCET system demonstrate its potential to transform telerehabilitation within the PM&R domain. By integrating advanced technologies, and providing comprehensive digital health solutions, the HCET enhances patient care, supports ongoing rehabilitation, and facilitates advanced research. Future work will focus on optimizing services and expanding language support to further improve the system's functionality and impact. © 2024, University Library System, University of Pittsburgh. All rights reserved.},
	author_keywords = {Cloud computing; Digital health; Hybrid cloud environment; MedLocalGPT; MedRehabBot; Telerehabilitation},
	type = {Note},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Haghighi202470,
	author = {Haghighi, Nava},
	title = {Ontological Breakdown: Toward a World of Many Worlds},
	year = {2024},
	journal = {DIS 2024 - Proceedings of the 2024 ACM Designing Interactive Systems Conference},
	pages = {70 – 73},
	doi = {10.1145/3656156.3665133},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198901569&doi=10.1145%2f3656156.3665133&partnerID=40&md5=90a043134444f711fb849e42955e631f},
	abstract = {Examining the taken-for-granted assumptions and views of the world underlying the design of technological artifacts, this work posits that a lack of ontological self-reflection can constrain imagination, impeding movement toward a world of many worlds. I propose ontological breakdown as an analytic lens for interrogating the default assumptions underlying the design of technology, using LLMs as a case-study and drawing parallels to the discourse on values in design. Then, I share three ways in which I have used ontological breakdowns generatively to (1) surface ontological difference and create spaces for experiencing ontological alternatives to our defaults, (2) explore ontological alternatives in the design of artifacts and enable the end-users to notice their own ontological defaults, and (3) expand ontological diversity by empowering the end-users to move beyond the prescribed defaults. I demonstrate the generative potential of ontological breakdowns by providing examples of my work in personal informatics.  © 2024 Owner/Author.},
	author_keywords = {generative AI; LLM; ontological breakdown; ontological design; ontologies; personal informatics},
	keywords = {Case-studies; End-users; Generative AI; LLM; Ontological breakdown; Ontological design; Ontology's; Personal informatics; Self reflection; Value in designs; Ontology},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Babaiha2024,
	author = {Babaiha, Negin Sadat and Rao, Sathvik Guru and Klein, Jürgen and Schultz, Bruce and Jacobs, Marc and Hofmann-Apitius, Martin},
	title = {Rationalism in the face of GPT hypes: Benchmarking the output of large language models against human expert-curated biomedical knowledge graphs},
	year = {2024},
	journal = {Artificial Intelligence in the Life Sciences},
	volume = {5},
	doi = {10.1016/j.ailsci.2024.100095},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185528314&doi=10.1016%2fj.ailsci.2024.100095&partnerID=40&md5=2975ed8da60610738a8a1a0b71f7e1ea},
	abstract = {Biomedical knowledge graphs (KGs) hold valuable information regarding biomedical entities such as genes, diseases, biological processes, and drugs. KGs have been successfully employed in challenging biomedical areas such as the identification of pathophysiology mechanisms or drug repurposing. The creation of high-quality KGs typically requires labor-intensive multi-database integration or substantial human expert curation, both of which take time and contribute to the workload of data processing and annotation. Therefore, the use of automatic systems for KG building and maintenance is a prerequisite for the wide uptake and utilization of KGs. Technologies supporting the automated generation and updating of KGs typically make use of Natural Language Processing (NLP), which is optimized for extracting implicit triples described in relevant biomedical text sources. At the core of this challenge is how to improve the accuracy and coverage of the information extraction module by utilizing different models and tools. The emergence of pre-trained large language models (LLMs), such as ChatGPT which has grown in popularity dramatically, has revolutionized the field of NLP, making them a potential candidate to be used in text-based graph creation as well. So far, no previous work has investigated the power of LLMs on the generation of cause-and-effect networks and KGs encoded in Biological Expression Language (BEL). In this paper, we present initial studies towards one-shot BEL relation extraction using two different versions of the Generative Pre-trained Transformer (GPT) models and evaluate its performance by comparing the extracted results to a highly accurate, manually curated BEL KG curated by domain experts. © 2024},
	author_keywords = {Biological expression language (BEL); Biomedical knowledge graphs; Biomedical text mining; Large language models (LLMs); Natural language processing (NLP)},
	keywords = {phosphoprotein; phosphorylated Tau; tau protein; unclassified drug; accuracy; Article; artificial intelligence; benchmarking; bioinformatics; biological expression language; biomedical knowledge graph; biomedical text mining; controlled study; data extraction; data mining; generative pretrained transformer; human; knowledge graph; large language model; natural language processing},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access}
}

@CONFERENCE{Barbon2024,
	author = {Barbon, Sylvio and Ceravolo, Paolo and Groppe, Sven and Jarrar, Mustafa and Maghool, Samira and Sèdes, Florence and Sahri, Soror and Van Keulen, Maurice},
	title = {Are Large Language Models the New Interface for Data Pipelines?},
	year = {2024},
	journal = {Proceedings of the International Workshop on Big Data in Emergent Distributed Environments, BIDEDE 2024, in conjunction with the 2024 ACM SIGMOD/PODS Conference},
	doi = {10.1145/3663741.3664785},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198707764&doi=10.1145%2f3663741.3664785&partnerID=40&md5=e5a1739732fb11f7ad571dc74dbd27d4},
	abstract = {A Language Model is a term that encompasses various types of models designed to understand and generate human communication. Large Language Models (LLMs) have gained significant attention due to their ability to process text with human-like fluency and coherence, making them valuable for a wide range of data-related tasks fashioned as pipelines. The capabilities of LLMs in natural language understanding and generation, combined with their scalability, versatility, and state-of-the-art performance, enable innovative applications across various AI-related fields, including eXplainable Artificial Intelligence (XAI), Automated Machine Learning (AutoML), and Knowledge Graphs (KG). Furthermore, we believe these models can extract valuable insights and make data-driven decisions at scale, a practice commonly referred to as Big Data Analytics (BDA). In this position paper, we provide some discussions in the direction of unlocking synergies among these technologies, which can lead to more powerful and intelligent AI solutions, driving improvements in data pipelines across a wide range of applications and domains integrating humans, computers, and knowledge. Copyright © 2024 held by the owner/author(s). Publication rights licensed to ACM.},
	author_keywords = {Automated Machine Learning; Big Data Analytic; eXplainable Artificial Intelligence; Human-Computer Interaction; Knowledge Graphs; Natural Language Understanding},
	keywords = {Big data; Computational linguistics; Human computer interaction; Knowledge graph; Machine learning; Pipelines; Automated machine learning; Automated machines; Big data analytic; Data analytics; Data pipelines; Explainable artificial intelligence; Knowledge graphs; Language model; Machine-learning; Natural language understanding; Data Analytics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@CONFERENCE{Baldazzi2024,
	author = {Baldazzi, Teodoro and Bellomarini, Luigi and Ceri, Stefano and Colombo, Andrea and Gentili, Andrea and Sallinger, Emanuel and Atzeni, Paolo},
	title = {Explaining Enterprise Knowledge Graphs with Large Language Models and Ontological Reasoning},
	year = {2024},
	journal = {OpenAccess Series in Informatics},
	volume = {119},
	doi = {10.4230/OASIcs.Tannen.2024.1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195697101&doi=10.4230%2fOASIcs.Tannen.2024.1&partnerID=40&md5=a4d99eafb23b2b36530ee3467dcab429},
	abstract = {In recent times, the demand for transparency and accountability in AI-driven decisions has intensified, particularly in high-stakes domains like finance and bio-medicine. This focus on the provenance of AI-generated conclusions underscores the need for decision-making processes that are not only transparent but also readily interpretable by humans, to built trust of both users and stakeholders. In this context, the integration of state-of-the-art Large Language Models (LLMs) with logic-oriented Enterprise Knowledge Graphs (EKGs) and the broader scope of Knowledge Representation and Reasoning (KRR) methodologies is currently at the cutting edge of industrial and academic research across numerous data-intensive areas. Indeed, such a synergy is paramount as LLMs bring a layer of adaptability and human-centric understanding that complements the structured insights of EKGs. Conversely, the central role of ontological reasoning is to capture the domain knowledge, accurately handling complex tasks over a given realm of interest, and to infuse the process with transparency and a clear provenance-based explanation of the conclusions drawn, addressing the fundamental challenge of LLMs' inherent opacity and fostering trust and accountability in AI applications. In this paper, we propose a novel neuro-symbolic framework that leverages the underpinnings of provenance in ontological reasoning to enhance state-of-the-art LLMs with domain awareness and explainability, enabling them to act as natural language interfaces to EKGs. © Teodoro Baldazzi, Luigi Bellomarini, Stefano Ceri, Andrea Colombo, Andrea Gentili, Emanuel Sallinger, and Paolo Atzeni; licensed under Creative Commons License CC-BY 4.0.},
	author_keywords = {knowledge graphs; language models; ontological reasoning; provenance},
	keywords = {Computational linguistics; Decision making; Industrial research; Interface states; Knowledge graph; Natural language processing systems; Academic research; Cutting edges; Decision-making process; Knowledge graphs; Knowledge representation and reasoning; Language model; Model reasonings; Ontological reasoning; Provenance; State of the art; Transparency},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Zhu2024,
	author = {Zhu, Yuqi and Wang, Xiaohan and Chen, Jing and Qiao, Shuofei and Ou, Yixin and Yao, Yunzhi and Deng, Shumin and Chen, Huajun and Zhang, Ningyu},
	title = {LLMs for knowledge graph construction and reasoning: recent capabilities and future opportunities},
	year = {2024},
	journal = {World Wide Web},
	volume = {27},
	number = {5},
	doi = {10.1007/s11280-024-01297-w},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201575403&doi=10.1007%2fs11280-024-01297-w&partnerID=40&md5=c50c95f2d077e8f5629cdcf69a2d95a6},
	abstract = {This paper presents an exhaustive quantitative and qualitative evaluation of Large Language Models (LLMs) for Knowledge Graph (KG) construction and reasoning. We engage in experiments across eight diverse datasets, focusing on four representative tasks encompassing entity and relation extraction, event extraction, link prediction, and question-answering, thereby thoroughly exploring LLMs’ performance in the domain of construction and inference. Empirically, our findings suggest that LLMs, represented by GPT-4, are more suited as inference assistants rather than few-shot information extractors. Specifically, while GPT-4 exhibits good performance in tasks related to KG construction, it excels further in reasoning tasks, surpassing fine-tuned models in certain cases. Moreover, our investigation extends to the potential generalization ability of LLMs for information extraction, leading to the proposition of a Virtual Knowledge Extraction task and the development of the corresponding VINE dataset. Based on these empirical findings, we further propose AutoKG, a multi-agent-based approach employing LLMs and external sources for KG construction and reasoning. We anticipate that this research can provide invaluable insights for future undertakings in the field of knowledge graphs. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.},
	author_keywords = {GPT-4; Information extraction; Knowledge graph; Large language model},
	keywords = {Case based reasoning; Modeling languages; Question answering; Entity extractions; GPT-4; Graph construction; Information extraction; Knowledge graphs; Language model; Large language model; Qualitative evaluations; Quantitative evaluation; Relation extraction; Knowledge graph},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7}
}

@ARTICLE{Chen2024715,
	author = {Chen, Juan and Zhao, Xinchao and Sui, Jingyan and Qi, Lin and Tian, Chen and Pang, Liang and Fang, Jinyun},
	title = {Narrative-Driven Large Language Model for Temporal Knowledge Graph Prediction; [故事启发大语言模型的时序知识图谱预测]},
	year = {2024},
	journal = {Moshi Shibie yu Rengong Zhineng/Pattern Recognition and Artificial Intelligence},
	volume = {37},
	number = {8},
	pages = {715 – 728},
	doi = {10.16451/j.cnki.issn1003-6059.202408005},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206485249&doi=10.16451%2fj.cnki.issn1003-6059.202408005&partnerID=40&md5=ea2ad3447d29fa714d7daa8f5732f1dc},
	abstract = {The temporal knowledge graph(TKG) is characterized by vast sparsity, and the long-tail distribution of entities leads to poor generalization in reasoning for out-of-distribution entities. Additionally, the low infrequency of historical interactions results in biased predictions for future events. Therefore, a narrative-driven large language model for TKG Prediction is proposed. The world knowledge and complex semantic reasoning capabilities of large language models are leveraged to enhance the understanding of out-of-distribution entities and the association of sparse interaction events. Firstly, a key event tree is selected based on the temporal and structural characteristics of TKG, and the most representative events are extracted through a historical event filtering strategy. Relevant historical information is summarized to reduce input data while the most important information is retained. Then, the large language model generator is fine-tuned to produce logically coherent "key event tree" narratives as unstructured input. During the generation process, special attention is paid to the causal relationships and temporal sequences of events to ensure the coherence and rationality of the generated stories. Finally, the large language model is utilized as a reasoner to infer the missing temporal entities. Experiments on three public datasets demonstrate that the proposed method effectively leverages the capabilities of large models to achieve more accurate temporal entity reasoning. © 2024 Science Press. All rights reserved.},
	author_keywords = {Event Inference; Key Event Tree; Large Language Model; Temporal Knowledge Graph(TKG); Temporal Story},
	keywords = {Information filtering; Knowledge graph; Modeling languages; Semantics; Trees (mathematics); Event inference; Event-trees; Key event tree; Knowledge graphs; Language model; Large language model; Long-tail distribution; Temporal knowledge; Temporal knowledge graph; Temporal story; Spatio-temporal data},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Komarlu20241407,
	author = {Komarlu, Tanay and Jiang, Minhao and Wang, Xuan and Han, Jiawei},
	title = {OntoType: Ontology-Guided and Pre-Trained Language Model Assisted Fine-Grained Entity Typing},
	year = {2024},
	journal = {Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
	pages = {1407 – 1417},
	doi = {10.1145/3637528.3671745},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203677734&doi=10.1145%2f3637528.3671745&partnerID=40&md5=a7ea18e01f03660f1cca5e8f52854c0a},
	abstract = {Fine-grained entity typing (FET), which assigns entities in text with context-sensitive, fine-grained semantic types, is a basic but important task for knowledge extraction from unstructured text. FET has been studied extensively in natural language processing and typically relies on human-annotated corpora for training, which is costly and difficult to scale. Recent studies explore the utilization of pre-trained language models (PLMs) as a knowledge base to generate rich and context-aware weak supervision for FET. However, a PLM still requires direction and guidance to serve as a knowledge base as they often generate a mixture of rough and fine-grained types, or tokens unsuitable for typing. In this study, we vision that an ontology provides a semantics-rich, hierarchical structure, which will help select the best results generated by multiple PLM models and head words. Specifically, we propose a novel annotation-free, ontology-guided FET method, OntoType, which follows a type ontological structure, from coarse to fine, ensembles multiple PLM prompting results to generate a set of type candidates, and refines its type resolution, under the local context with a natural language inference model. Our experiments on the Ontonotes, FIGER, and NYT datasets using their associated ontological structures demonstrate that our method outperforms the state-of-the-art zero-shot fine-grained entity typing methods as well as a typical LLM method, ChatGPT. Our error analysis shows that refinement of the existing ontology structures will further improve fine-grained entity typing.  © 2024 Copyright held by the owner/author(s).},
	author_keywords = {fine-grained entity typing; masked language model prompting; natural language understanding; zero-shot entity typing},
	keywords = {Context sensitive languages; Economic and social effects; Inference engines; Modeling languages; Natural language processing systems; Ontology; Context-sensitive; Fine grained; Fine-grained entity typing; Language model; Masked language model prompting; Natural language understanding; Natural languages; Ontological structures; Ontology's; Zero-shot entity typing; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Hybrid Gold Open Access}
}@CONFERENCE{Brown2024,
	author = {Brown, Eric L. and Talbert, Douglas A.},
	title = {Intelligent Infrastructure Facilitating Sequence Recommendation for Cybersecurity Education Systems},
	year = {2024},
	journal = {Proceedings of the International Florida Artificial Intelligence Research Society Conference, FLAIRS},
	volume = {37},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200435982&partnerID=40&md5=3711a961eb3333d6a1b177912c06f68d},
	abstract = {The ability to incorporate original and adapted data into query-based storage structures to provide dynamic and timely service to sequence recommendation systems is a continuous goal of learning management systems. This can be a challenging goal when data integrity and student privacy are paramount. We are developing a hybrid machine learning-assisted system (CyberTaliesin) for cybersecurity educational support. In this poster, we present the early building blocks of the system involving the use of federated knowledge graphs as a trusted knowledge source capable of learning from “less restricted” models such as large language models. How can integrating these tools yield a flexible system that improves sequence recommendations, facilitates concepts such as adaptive and personalized learning, and achieves improved competency-based educational outcomes? Copyright © 2024 by the authors.},
	keywords = {Digital storage; Information management; Knowledge graph; Learning systems; Recommender systems; Building blockes; Cyber security; Cyber-security educations; Data integrity; Education systems; Hybrid machine learning; Intelligent infrastructures; Learning management system; Learning-assisted system; Storage structures; Search engines},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Quintero-Narvaez20241198,
	author = {Quintero-Narvaez, Carlos Efrain and Monroy, Raul},
	title = {Integrating Knowledge Graph Data with Large Language Models for Explainable Inference},
	year = {2024},
	journal = {WSDM 2024 - Proceedings of the 17th ACM International Conference on Web Search and Data Mining},
	pages = {1198 – 1199},
	doi = {10.1145/3616855.3636507},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191738394&doi=10.1145%2f3616855.3636507&partnerID=40&md5=5fbb18c468268347292d8093ad4d52be},
	abstract = {We propose a method to enable Large Language Models to access Knowledge Graph (KG) data and justify their text generation by showing the specific graph data the model accessed during inference. For this, we combine Language Models with methods from Neurosymbolic Artificial Intelligence designed to answer queries on Knowledge Graphs. This is done by modifying the model so that at different stages of inference it outputs an Existential Positive First-Order (EPFO) query, which is then processed by an additional query appendix. In turn, the query appendix uses neural link predictors along with description aware embeddings to resolve these queries. After that, the queries are logged and used as an explanation of the inference process of the complete model. Lastly, we train the model using a Linear Temporal Logic (LTL) constraint-based loss function to measure the consistency of the queries among each other and with the final model output. © 2024 Owner/Author.},
	author_keywords = {advanced artificial intelligence; existential positive first order query; explainable; knowledge graph; language model; linear temporal logic; query},
	keywords = {Computational linguistics; Computer circuits; Query processing; Temporal logic; Advanced artificial intelligence; Existential positive first order query; Explainable; First order; Graph data; Knowledge graphs; Language model; Linear temporal logic; Query; Text generations; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Anuyah2024,
	author = {Anuyah, Sydney and Chakraborty, Sunandan},
	title = {Can Deep Learning Large Language Models be Used to Unravel Knowledge Graph Creation?},
	year = {2024},
	journal = {ACM International Conference Proceeding Series},
	doi = {10.1145/3661725.3661733},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197284923&doi=10.1145%2f3661725.3661733&partnerID=40&md5=d360e31459f07277e20f69654dd5e066},
	abstract = {This research focuses on advancing RE methodologies by employing and comparing various NLP models for analyzing medical relationships, particularly concerning Gastroesophageal Reflux Disease (GERD). Leveraging a comprehensive dataset of GERD-related articles from PubMed, the study explores the effectiveness of SpaCy for Named Entity Recognition (NER) and BERT-based models (including Bio-BERT and ELECTRA) for tokenization and deep learning classification tasks. Unique to this study is the extensive comparison across multiple advanced models, providing an insightful evaluation of their performance in terms of precision, recall, F1-score, and accuracy in the context of biomedical text analysis. Significantly, Bio-BERT emerged as the most effective model for this dataset, excelling across all metrics compared to BERT-BASE and ELECTRA. This performance underscores Bio-BERT's specialized pre-training on biomedical literature. The analysis includes the application of these models in constructing a comprehensive knowledge graph, which consolidates diverse information about GERD. Additionally, the paper presents a critical comparison between SpaCy's automated annotation and human annotators, utilizing the F-1 score for assessing the reliability of BERT's RE capabilities. © 2024 ACM.},
	author_keywords = {BERT; Bio-BERT; biomedical NLP.; deep learning; knowledge graph; medical text analysis; NER; RE; transformer models},
	keywords = {Classification (of information); Deep learning; Learning systems; Natural language processing systems; BERT; Bio-BERT; Biomedical NLP; Biomedical NLP.; Deep learning; Knowledge graphs; Medical text analyse; Named entity recognition; RE; Text analysis; Transformer modeling; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Chow2024353,
	author = {Chow, Sabrina and Guo, Lilian and Chow, Jonathan and Chia, Chelsea and Li, Sarah and Huang, Dong-Yan},
	title = {Semantic Search Using LLM-aided Topic Generation on Knowledge Graphs for Paper Discovery},
	year = {2024},
	journal = {2024 14th International Symposium on Chinese Spoken Language Processing, ISCSLP 2024},
	pages = {353 – 357},
	doi = {10.1109/ISCSLP63861.2024.10800417},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216395750&doi=10.1109%2fISCSLP63861.2024.10800417&partnerID=40&md5=e5e1ffd43629b46d64c9921470eed4c4},
	abstract = {The exponential growth of academic papers presents a huge challenge for researchers, exacerbating the already tedious literature review process. Current tools like Google Scholar and Connected Papers offer solutions for text-based and citation-based searches but fail to address the need for finding semantically similar yet terminologically different papers efficiently. This paper proposes an innovative approach to paper discovery using semantic search to create a knowledge graph of topics and papers. By generating a tree of topics using ChatGPT 4o and calculating semantic similarity with SciBERT, this method aims to uncover relevant papers overlooked by traditional citation-based searches. The solution, validated through quantitative evaluation, demonstrates the potential to improve the efficiency and comprehensiveness of paper discovery. ©2024 IEEE.},
	author_keywords = {Knowledge Graphs; Literature Review; Natural Language Processing (NLP); SciBERT; Semantic Search},
	keywords = {Academic paper; Exponential growth; Knowledge graphs; Language processing; Literature reviews; Natural language processing; Natural languages; Review process; SciBERT; Semantic search; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Yang2024,
	author = {Yang, Jingye and Liu, Cong and Deng, Wendy and Wu, Da and Weng, Chunhua and Zhou, Yunyun and Wang, Kai},
	title = {Enhancing phenotype recognition in clinical notes using large language models: PhenoBCBERT and PhenoGPT},
	year = {2024},
	journal = {Patterns},
	volume = {5},
	number = {1},
	doi = {10.1016/j.patter.2023.100887},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182025246&doi=10.1016%2fj.patter.2023.100887&partnerID=40&md5=43f00f9992e9e949c371fc199d7dc6c4},
	abstract = {To enhance phenotype recognition in clinical notes of genetic diseases, we developed two models—PhenoBCBERT and PhenoGPT—for expanding the vocabularies of Human Phenotype Ontology (HPO) terms. While HPO offers a standardized vocabulary for phenotypes, existing tools often fail to capture the full scope of phenotypes due to limitations from traditional heuristic or rule-based approaches. Our models leverage large language models to automate the detection of phenotype terms, including those not in the current HPO. We compare these models with PhenoTagger, another HPO recognition tool, and found that our models identify a wider range of phenotype concepts, including previously uncharacterized ones. Our models also show strong performance in case studies on biomedical literature. We evaluate the strengths and weaknesses of BERT- and GPT-based models in aspects such as architecture and accuracy. Overall, our models enhance automated phenotype detection from clinical texts, improving downstream analyses on human diseases. © 2023 The Authors},
	author_keywords = {BERT; clinical notes; DSML 3: Development/Pre-production: Data science output has been rolled out/validated across multiple domains/problems; electronic health records; GPT; Human Phenotype Ontology; named entity recognition; transformer},
	keywords = {Computational linguistics; BERT; Clinical notes; Domain problems; DSML 3: development/pre-production: data science output have been rolled out/validated across multiple domain/problem; Electronic health; Electronic health record; GPT; Health records; Human phenotype ontology; Multiple domains; Named entity recognition; Ontology's; Pre-production; Production data; Transformer; Ontology},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 16; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Oelen2024,
	author = {Oelen, Allard and Auer, Sören},
	title = {Leveraging Large Language Models for Realizing Truly Intelligent User Interfaces},
	year = {2024},
	journal = {Conference on Human Factors in Computing Systems - Proceedings},
	doi = {10.1145/3613905.3650949},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194189020&doi=10.1145%2f3613905.3650949&partnerID=40&md5=b89fbf4146f1e50f46f851e35a2f2fbe},
	abstract = {The number of published scholarly articles is growing at a significant rate, making scholarly knowledge organization increasingly important. Various approaches have been proposed to organize scholarly information, including describing scholarly knowledge semantically leveraging knowledge graphs. Transforming unstructured knowledge, presented within articles, to structured and semantically represented knowledge generally requires human intelligence and labor since natural language processing methods alone typically do not render sufficient precision and recall for many applications. With the recent developments of Large Language Models (LLMs), it becomes increasingly possible to provide truly intelligent user interfaces guiding humans in the transformation process. We present an approach to integrate non-intrusive LLMs guidance into existing user interfaces. More specifically, we integrate LLM-supported user interface components into an existing scholarly knowledge infrastructure. Additionally, we provide our experiences with LLM integration, detailing best practices and obstacles. Finally, we evaluate the approach using a small-scale user evaluation with domain experts. © 2024 Association for Computing Machinery. All rights reserved.},
	author_keywords = {Intelligent User Interface; LLM Interface; Scholarly Knowledge Graphs},
	keywords = {Air navigation; Computational linguistics; Knowledge graph; Knowledge management; Natural language processing systems; Human labor; Intelligent User Interfaces; Knowledge graphs; Knowledge organization; Language model; Large language model interface; Model interface; Rate makings; Scholarly articles; Scholarly knowledge graph; User interfaces},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Bronze Open Access}
}

@CONFERENCE{Chen20241207,
	author = {Chen, Yuemin and Wu, Feifan and Wang, Jingwei and Qian, Hao and Liu, Ziqi and Zhang, Zhiqiang and Zhou, Jun and Wang, Meng},
	title = {Knowledge-augmented Financial Market Analysis and Report Generation},
	year = {2024},
	journal = {EMNLP 2024 - 2024 Conference on Empirical Methods in Natural Language Processing, Proceedings of the Industry Track},
	pages = {1207 – 1217},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216766011&partnerID=40&md5=82c25fdb828df87b485cd7566f2a87cd},
	abstract = {Crafting a convincing financial market analysis report necessitates a wealth of market information and the expertise of financial analysts, posing a highly challenging task. While large language models (LLMs) have enabled the automated generation of financial market analysis text, they still face issues such as hallucinations, errors in financial knowledge, and insufficient capability to reason about complex financial problems, which limits the quality of the generation. To tackle these shortcomings, we propose a novel task and a retrieval-augmented framework grounded in a financial knowledge graph (FKG). The proposed framework is compatible with commonly used instruction-tuning methods. Experiments demonstrate that our framework, coupled with a small-scale language model fine-tuned with instructions, can significantly enhance the logical consistency and quality of the generated analysis texts, outperforming both large-scale language models and other retrieval-augmented baselines. © 2024 Association for Computational Linguistics.},
	keywords = {Financial markets; Knowledge graph; Automated generation; Financial analysts; Financial problems; Knowledge graphs; Language model; Market analysis; Market information; Novel task; Report generation; Tuning method; Decentralized finance},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Jiang2024100,
	author = {Jiang, Yingdi and Yao, Jiarui and Li, Fangfei and Zhang, Yan},
	title = {Research on Engineering Management Question-answering System in the Communication Industry Based on Large Language Models and Knowledge Graphs},
	year = {2024},
	journal = {ACM International Conference Proceeding Series},
	pages = {100 – 105},
	doi = {10.1145/3653946.3653961},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197427510&doi=10.1145%2f3653946.3653961&partnerID=40&md5=f1aa55c834b132990980f10eaf188267},
	abstract = {In the engineering management of the communication industry, there are many issues, including low efficiency in information acquisition and limitations in the level of intelligence.Large language models, with their powerful text comprehension and generation capabilities, offer new perspectives for the development of this field.This study constructed a question-answering system using a combined approach of large language models and text knowledge bases. The system dynamically leverages abundant external knowledge and enhances the model's reasoning ability and interpretability through knowledge graphs. In response to five categories of issues in engineering management, experiments and in-depth analysis revealed that although large language models may lack granularity in addressing some complex problems, the question-answering system overall achieved intelligent assistance, improving the efficiency of collaborative engineering management. © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.},
	author_keywords = {Engineering management; Keywords •Large language models; Knowledge graphs; Question-answering},
	keywords = {Computational linguistics; Efficiency; Knowledge management; Communications industry; Engineering management; Industry based; Information acquisitions; Keyword •large language model; Knowledge graphs; Language model; Question Answering; Question answering systems; Text generations; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{2024,
	title = {Sustainable Production through Advanced Manufacturing, Intelligent Automation and Work Integrated Learning - Proceedings of the 11th Swedish Production Symposium, SPS2024},
	year = {2024},
	journal = {Advances in Transdisciplinary Engineering},
	volume = {52},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191318908&partnerID=40&md5=4bce1e86d2198af59b5a3ee703261d09},
	abstract = {The proceedings contain 59 papers. The topics discussed include: towards in-line measurements of sawn wood surfaces; combining ontology and large language models to identify recurring machine failures in free-text fields; study of pulsed laser beam welding of nickel-based superalloy G27; strategies for effective chip management in machining of ductile cast iron; drop detachment under intense laser irradiation; relationship between tool temperature distribution and stagnation point behavior for different process factors in machining operations; process parameter impact on axial plasma sprayed ytterbium disilicate coatings for environment barrier coating applications; effect of laser power on the deposition of alloy 718 powder on alumina substrate using laser directed energy deposition: a single-track study; and ultrasonic signal response from internal manufactured defects in PBF-LB manufactured superalloys.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Wu2024280,
	author = {Wu, Shun and Wu, Di and Luo, Kun and Zhang, XueYou and Zhao, Jun and Liu, Kang},
	title = {KMatrix: A Flexible Heterogeneous Knowledge Enhancement Toolkit for Large Language Model},
	year = {2024},
	journal = {EMNLP 2024 - 2024 Conference on Empirical Methods in Natural Language Processing, Proceedings of System Demonstrations},
	pages = {280 – 290},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216518178&partnerID=40&md5=f43e827e7592b4f92b0a35795efc5410},
	abstract = {Knowledge-Enhanced Large Language Models (K-LLMs) system enhances Large Language Models (LLMs) abilities using external knowledge. Existing K-LLMs toolkits mainly focus on free-textual knowledge, lacking support for heterogeneous knowledge like tables and knowledge graphs, and fall short in comprehensive datasets, models, and user-friendly experience. To address this gap, we introduce KMatrix: a flexible heterogeneous knowledge enhancement toolkit for LLMs including verbalizing-retrieval and parsing-query methods. Our modularity and control-logic flow diagram design flexibly supports the entire lifecycle of various complex K-LLMs systems, including training, evaluation, and deployment. To assist K-LLMs system research, a series of related knowledge, datasets, and models are integrated into our toolkit, along with performance analyses of K-LLMs systems enhanced by different types of knowledge. Using our toolkit, developers can rapidly build, evaluate, and deploy their own K-LLMs systems. Our toolkit and resources are available at here. © 2024 Association for Computational Linguistics.},
	keywords = {Data flow graphs; Knowledge graph; Query languages; Query processing; Structured Query Language; Control logic; External knowledge; Heterogeneous Knowledge; K-matrix; Knowledge graphs; Language model; Modeling abilities; Modelling systems; Query methods; User friendly; Computational linguistics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Chen20244383,
	author = {Chen, Long and Li, Yuchen and Silamu, Wushour and Li, Qingquan and Ge, Shirong and Wang, Fei-Yue},
	title = {Smart Mining With Autonomous Driving in Industry 5.0: Architectures, Platforms, Operating Systems, Foundation Models, and Applications},
	year = {2024},
	journal = {IEEE Transactions on Intelligent Vehicles},
	volume = {9},
	number = {3},
	pages = {4383 – 4393},
	doi = {10.1109/TIV.2024.3365997},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186065598&doi=10.1109%2fTIV.2024.3365997&partnerID=40&md5=1ac2a40f349bc0907c70101d47424e5d},
	abstract = {The increasing importance of mineral resources in contemporary society is becoming more prominent, playing an indispensable and crucial role in the global economy. These resources not only provide essential raw materials for the global economic system but also play an irreplaceable role in supporting the development of modern industry, technology, and infrastructure. With the rapid development of intelligent technologies such as Industry 5.0 and advanced Large Language Models (LLMs), the mining industry is facing unprecedented opportunities and challenges. The development of smart mines has become a crucial direction for industry progress. This article aims to explore the strategic requirements for the development of smart mines by combining advanced products or technologies such as Chat-GPT (one of the successful applications of LLMs), digital twins, and scenario engineering. We propose a comprehensive architecture consisting of three different levels, the mining industrial Internet of Things (IoT) platform, mining operating systems, and foundation models. The systems and models empower the mining equipment for transportation. The architecture delivers a comprehensive solution that aligns perfectly with the demands of Industry 5.0. The application and validation outcomes of this intelligent solution showcase a noteworthy enhancement in mining efficiency and a reduction in safety risks, thereby laying a sturdy groundwork for the advent of Mining 5.0.  © 2016 IEEE.},
	author_keywords = {architectures; autonomous driving; industry 5.0; Mining 5.0; mining transportation trucks; smart mining},
	keywords = {Architecture; Autonomous vehicles; Computer architecture; Internet of things; Job analysis; Mineral resources; Mining industry; Autonomous driving; Biological system modeling; Fifth industrial revolution; Industrial revolutions; Industry 5.0; Mining 5.0; Mining transportation truck; Mining transportations; Ontology's; Smart mining; Task analysis; Mining},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9}
}

@CONFERENCE{Agrawal202423164,
	author = {Agrawal, Garima and Pal, Kuntal and Deng, Yuli and Liu, Huan and Chen, Ying-Chih},
	title = {CyberQ: Generating Questions and Answers for Cybersecurity Education Using Knowledge Graph-Augmented LLMs},
	year = {2024},
	journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
	volume = {38},
	number = {21},
	pages = {23164 – 23172},
	doi = {10.1609/aaai.v38i21.30362},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189648091&doi=10.1609%2faaai.v38i21.30362&partnerID=40&md5=f4f95a6cc7ce9b687a924c14f3a0734f},
	abstract = {Building a skilled cybersecurity workforce is paramount to building a safer digital world. However, the diverse skill set, constantly emerging vulnerabilities, and deployment of new cyber threats make learning cybersecurity challenging. Traditional education methods struggle to cope with cybersecurity's rapidly evolving landscape and keep students engaged and motivated. Different studies on students' behaviors show that an interactive mode of education by engaging through a question-answering system or dialoguing is one of the most effective learning methodologies. There is a strong need to create advanced AI-enabled education tools to promote interactive learning in cybersecurity. Unfortunately, there are no publicly available standard question-answer datasets to build such systems for students and novice learners to learn cybersecurity concepts, tools, and techniques. The education course material and online question banks are unstructured and need to be validated and updated by domain experts, which is tedious when done manually. In this paper, we propose CyberGen, a novel unification of large language models (LLMs) and knowledge graphs (KG) to generate the questions and answers for cybersecurity automatically. Augmenting the structured knowledge from knowledge graphs in prompts improves factual reasoning and reduces hallucinations in LLMs. We used the knowledge triples from cybersecurity knowledge graphs (AISecKG) to design prompts for ChatGPT and generate questions and answers using different prompting techniques. Our question-answer dataset, CyberQ, contains around 4k pairs of questions and answers. The domain expert manually evaluated the random samples for consistency and correctness. We train the generative model using the CyberQ dataset for question answering task. Copyright © 2024, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.},
	keywords = {Cybersecurity; Education computing; Learning systems; Students; Cyber security; Cyber threats; Cyber-security educations; Digital world; Domain experts; Education methods; Knowledge graphs; Language model; Skill sets; Traditional educations; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; All Open Access, Gold Open Access}
}

@ARTICLE{Tian2024,
	author = {Tian, Xin and Meng, Yuan},
	title = {PDEC: A Framework for Improving Knowledge Graph Reasoning Performance through Predicate Decomposition},
	year = {2024},
	journal = {Algorithms},
	volume = {17},
	number = {3},
	doi = {10.3390/a17030129},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188790361&doi=10.3390%2fa17030129&partnerID=40&md5=c0ddaa22e07004433ccb9ca2ce6597f8},
	abstract = {The judicious configuration of predicates is a crucial but often overlooked aspect in the field of knowledge graphs. While previous research has primarily focused on the precision of triples in assessing knowledge graph quality, the rationality of predicates has been largely ignored. This paper introduces an innovative approach aimed at enhancing knowledge graph reasoning by addressing the issue of predicate polysemy. Predicate polysemy refers to instances where a predicate possesses multiple meanings, introducing ambiguity into the knowledge graph. We present an adaptable optimization framework that effectively addresses predicate polysemy, thereby enhancing reasoning capabilities within knowledge graphs. Our approach serves as a versatile and generalized framework applicable to any reasoning model, offering a scalable and flexible solution to enhance performance across various domains and applications. Through rigorous experimental evaluations, we demonstrate the effectiveness and adaptability of our methodology, showing significant improvements in knowledge graph reasoning accuracy. Our findings underscore that discerning predicate polysemy is a crucial step towards achieving a more dependable and efficient knowledge graph reasoning process. Even in the age of large language models, the optimization and induction of predicates remain relevant in ensuring interpretable reasoning. © 2024 by the authors.},
	author_keywords = {embedding; knowledge graph; predicates; reasoning},
	keywords = {Semantics; Assessing knowledge; Embeddings; Innovative approaches; Knowledge graphs; Optimization framework; Predicate; Reasoning; Reasoning capabilities; Reasoning models; Reasoning performance; Knowledge graph},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Yang2024,
	author = {Yang, Jian and Shu, Liqi and Han, Mingyu and Pan, Jiarong and Chen, Lihua and Yuan, Tianming and Tan, Linhua and Shu, Qiang and Duan, Huilong and Li, Haomin},
	title = {RDmaster: A novel phenotype-oriented dialogue system supporting differential diagnosis of rare disease},
	year = {2024},
	journal = {Computers in Biology and Medicine},
	volume = {169},
	doi = {10.1016/j.compbiomed.2024.107924},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181539226&doi=10.1016%2fj.compbiomed.2024.107924&partnerID=40&md5=45e022a072ece5aa501b256dabe3f108},
	abstract = {Background: Clinicians often lack the necessary expertise to differentially diagnose multiple underlying rare diseases (RDs) due to their complex and overlapping clinical features, leading to misdiagnoses and delayed treatments. The aim of this study is to develop a novel electronic differential diagnostic support system for RDs. Method: Through integrating two Bayesian diagnostic methods, a candidate list was generated with enhance clinical interpretability for the further Q&A based differential diagnosis (DDX). To achieve an efficient Q&A dialogue strategy, we introduce a novel metric named the adaptive information gain and Gini index (AIGGI) to evaluate the expected gain of interrogated phenotypes within real-time diagnostic states. Results: This DDX tool called RDmaster has been implemented as a web-based platform (http://rdmaster.nbscn.org/). A diagnostic trial involving 238 published RD patients revealed that RDmaster outperformed existing RD diagnostic tools, as well as ChatGPT, and was shown to enhance the diagnostic accuracy through its Q&A system. Conclusions: The RDmaster offers an effective multi-omics differential diagnostic technique and outperforms existing tools and popular large language models, particularly enhancing differential diagnosis in collecting diagnostically beneficial phenotypes. © 2024 The Authors},
	author_keywords = {Differential diagnosis; Electronic differential diagnostic support system; Human phenotype ontology; Phenomic and genomic diagnostics; Rare disease},
	keywords = {Bayes Theorem; Diagnosis, Differential; Dichlorodiphenyl Dichloroethylene; Humans; Phenotype; Rare Diseases; Diagnosis; Diseases; Genes; Speech processing; 1,1 dichloro 2,2 bis(4 chlorophenyl)ethylene; Diagnostic support systems; Dialogue systems; Differential diagnosis; Electronic differential; Electronic differential diagnostic support system; Genomics; Human phenotype ontology; Ontology's; Phenomic and genomic diagnostic; Rare disease; Article; ChatGPT; diagnostic accuracy; diagnostic procedure; diagnostic test accuracy study; differential diagnosis; female; Gini coefficient; human; human computer interaction; knowledge base; major clinical study; male; multiomics; phenotype; rare disease; retrospective study; whole exome sequencing; workflow; Bayes theorem; differential diagnosis; genetics; phenotype; rare disease; Genome},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Gautam2024297,
	author = {Gautam, Sushant and Pop, Roxana},
	title = {FactGenius: Combining Zero-Shot Prompting and Fuzzy Relation Mining to Improve Fact Verification with Knowledge Graphs},
	year = {2024},
	journal = {FEVER 2024 - 7th Fact Extraction and VERification Workshop, Proceedings of the Workshop},
	pages = {297 – 306},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216925185&partnerID=40&md5=18aba31c79dd5706fe64e61c8f776286},
	abstract = {Fact-checking is a crucial natural language processing (NLP) task that verifies the truthfulness of claims by considering reliable evidence. Traditional methods are labour-intensive, and most automatic approaches focus on using documents as evidence. In this paper, we focus on the relatively understudied fact-checking with Knowledge Graph data as evidence and experiment on the recently introduced FactKG benchmark. We present FactGenius, a novel method that enhances fact-checking by combining zero-shot prompting of large language models (LLMs) with fuzzy text matching on knowledge graphs (KGs). Our method employs LLMs for filtering relevant connections from the graph and validates these connections via distance-based matching. The evaluation of FactGenius on an existing benchmark demonstrates its effectiveness, as we show it significantly outperforms state-of-the-art methods. The code and materials are available at https://github.com/SushantGautam/FactGenius. © 2024 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Modeling languages; Natural language processing systems; Zero-shot learning; Automatic approaches; Fuzzy relations; Graph data; Knowledge graphs; Labour-intensive; Language model; Language processing; Natural languages; Novel methods; Relation mining; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Tripathi2024493,
	author = {Tripathi, Sandhya and King, Christopher Ryan},
	title = {Contrastive learning: Big Data Foundations and Applications},
	year = {2024},
	journal = {ACM International Conference Proceeding Series},
	pages = {493 – 497},
	doi = {10.1145/3632410.3633291},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183582823&doi=10.1145%2f3632410.3633291&partnerID=40&md5=fd70b939c2fce6299457dbad51789493},
	abstract = {Contrastive learning (CL) has exploded in popularity due to its ability to learn effective representations using vast quantities of unlabelled data across multiple domains. CL underlies some of the most impressive applications of generative AI for the general public. We will review the fundamentals and applied work on contrastive learning representations focusing on three main topics: 1) CL in supervised, unsupervised and self-supervised setup and its revival in AI research as an instance discriminator. In this part, we will focus on learning about the nuts and bolts, such as different augmentation techniques, loss functions, performance evaluation metrics, and some theoretical understanding of contrastive loss. We will also present the methods supporting DALL · E 2, a popular generative AI. 2) Learning contrastive representations across vision, text, time series, tabular data and knowledge graph modalities. Specifically, we will present the literature representative of solution approaches regarding new augmentation techniques, modification in the loss function, and additional information. The first two parts will also have small hands-on session on the application shown and some of the methods learned. 3) Discussing the various theoretical and empirical claims for CL's success, including the role of negative examples. We will also present some work that challenges the shared information assumption of CL and propose alternative explanations. Finally, we will conclude with some future directions and applications for CL.  © 2024 Owner/Author.},
	author_keywords = {augmentations; clustering; contrastive learning; distillation; graphs; multi-modal; multi-view; noise estimation loss; tabular datasets; time-series},
	keywords = {Big data; Distillation; Knowledge graph; Augmentation; Clusterings; Contrastive learning; Graph; Multi-modal; Multi-views; Noise estimation; Noise estimation loss; Tabular dataset; Times series; Time series},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Sousa202443,
	author = {Sousa, Guilherme and Lima, Rinaldo and Trojahn, Cassia},
	title = {Towards Generating Complex Alignments with Large Language Models via Prompt Engineering},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3897},
	pages = {43 – 56},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216423330&partnerID=40&md5=0a2afeab7c303ab8425938365e9b4ee6},
	abstract = {Still few ontology matching approaches focus on generating alignments by a Large Language Model (LLM), especially in the complex matching task. This paper proposes an approach that leverages the capabilities of LLMs to perform complex ontology matching. The method integrates subsets of both source and target ontologies into the prompt and, as a response, the LLM generates alignments in the structured EDOAL format, rather than natural language descriptions. This reduction technique, based on the automatic generation of SPARQL queries, tackles the challenge of large prompt sizes, reduces the search space, and enables efficient processing on consumer-grade hardware. This approach is evaluated on the Conference and Geolink datasets from the OAEI complex track, demonstrating improved scalability and the ability to produce well-formed EDOAL. Key contributions include the development of a SPARQL-based prompt engineering strategy and the application of few-shot learning techniques to complex alignment generation. © 2024 Copyright for this paper by its authors.},
	author_keywords = {complex matching; LLM; SPARQL},
	keywords = {Modeling languages; Natural language processing systems; Complex matching; Language description; Language model; Large language model; Matchings; Natural languages; Ontology matching; Ontology's; Reduction techniques; SPARQL; Ontology},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Das20241163,
	author = {Das, Sudeep and Saboo, Raghav and Vadrevu, Chaitanya S. K. and Wang, Bruce and Xu, Steven},
	title = {Applications of LLMs in E-Commerce Search and Product Knowledge Graph: The DoorDash Case Study},
	year = {2024},
	journal = {WSDM 2024 - Proceedings of the 17th ACM International Conference on Web Search and Data Mining},
	pages = {1163 – 1164},
	doi = {10.1145/3616855.3635738},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191732046&doi=10.1145%2f3616855.3635738&partnerID=40&md5=f439a4a72e32b33bd4399b896a7338cf},
	abstract = {Extracting knowledge from unstructured or semi-structured textual information is essential for the machine learning applications that power DoorDash's search experience, and the development and maintenance of its product knowledge graph. Large language models (LLMs) have opened up new possibilities for utilizing their power in these areas, replacing or complementing traditional natural language processing methods. LLMs are also proving to be useful in the label and annotation generation process, which is critical for these use cases. In this talk, we will provide a high-level overview of how we incorporated LLMs for search relevance and product understanding use cases, as well as the key lessons learned and challenges faced during their practical implementation. © 2024 Owner/Author.},
	author_keywords = {large language model; natural language processing; product knowledge graph; search},
	keywords = {Computational linguistics; Natural language processing systems; Knowledge graphs; Language model; Language processing; Large language model; Natural language processing; Natural languages; Power; Product knowledge; Product knowledge graph; Search; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@BOOK{Eybers2024197,
	author = {Eybers, Oscar Oliver},
	title = {A GenAI Ontology for Academic Literacies Teaching and Learning Practices},
	year = {2024},
	journal = {AI Approaches to Literacy in Higher Education},
	pages = {197 – 218},
	doi = {10.4018/979-8-3693-1054-0.ch009},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193678449&doi=10.4018%2f979-8-3693-1054-0.ch009&partnerID=40&md5=f9e0754490989ea09f246f49f74055f4},
	abstract = {In the ever-evolving higher education landscape, the integration of AI, particularly Generative AI (GenAI), is causing a profound shift. This chapter explores how GenAI is reshaping teaching, learning, and academic literacies. Academic literacies facilitators now navigate a diverse terrain, bridging traditional materials, digital resources, and AI-enhanced texts. They cultivate scholars' proficiency in GenAI tools and pioneer innovative teaching methods. This chapter introduces a GenAI ontology to support this transformative journey. It equips facilitators and students to use GenAI effectively, fostering tailored teaching methods and personalised literacies assessments. In summary, this chapter presents GenAI's potential to innovate, enhance accessibility, and elevate academic prowess in higher education. © 2024, IGI Global.},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Luan2024313,
	author = {Luan, Qiushi},
	title = {A Methodology for Generating and Optimizing Chain-of-Thought Based on Knowledge Graphs},
	year = {2024},
	journal = {Advances in Transdisciplinary Engineering},
	volume = {47},
	pages = {313 – 324},
	doi = {10.3233/ATDE231203},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189518486&doi=10.3233%2fATDE231203&partnerID=40&md5=3e1d4c01e750c505a65c0a42114fa0b3},
	abstract = {One of the critical indicators for assessing the practical applicability of large language models is their competency in vertical domain question-answering tasks. However, in real-world applications, fine-tuning these large models often compromises their inherent capabilities. Moreover, fine-tuning does not offer precise control over the model's generated outputs.Consequently, enhancing the question-answering performance of large models in specialized domains has become a focal concern in the field. To address these challenges, this paper introduces a novel approach for generating and optimizing a 'Chain-of-Thought'(CoT), leveraging domain-specific knowledge graphs. Specifically, we propose a Knowledge Graph-generated Chain of Thought (KGCoT) method that utilizes graph search algorithms to generate a chain of thought. This chain guides the injection of specialized knowledge into large language models and adapts the weightings based on user feedback, thereby optimizing subsequent graph searches.Heuristic searches are performed on the knowledge graph based on edge weights, culminating in the amalgamation of discovered entities and knowledge into a chain of thought. This KGCoT serves as a prompt to stimulate the large language model's contemplation of domain-specific knowledge. Additionally, an adaptive weight optimization formula refines the chain's weights in response to output feedback, thereby continually enhancing the quality of future search results and ensuring real-time optimization capabilities for the model.Through empirical evaluations conducted on publicly available datasets, the large language model ChatGLM, when prompted with a KGCoT, exhibited a 72.8% improvement in its BLEU score compared to its baseline performance. This outperformed other models like LLaMA and RWKV, unequivocally substantiating the efficacy of the proposed KGCoT method. © 2024 The Authors.},
	author_keywords = {Chain-of-Thought; Knowledge Graph; Large Language Model; Optimize Search; Prompt},
	keywords = {Computational linguistics; Domain Knowledge; Feedback; Graphic methods; Knowledge management; Large datasets; Optimization; Chain-of-thought; Domain-specific knowledge; Fine tuning; Knowledge graphs; Language model; Large language model; Large models; Optimize search; Prompt; Question Answering Task; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Buehler2024,
	author = {Buehler, Markus J.},
	title = {MechGPT, a Language-Based Strategy for Mechanics and Materials Modeling That Connects Knowledge Across Scales, Disciplines, and Modalities},
	year = {2024},
	journal = {Applied Mechanics Reviews},
	volume = {76},
	number = {2},
	doi = {10.1115/1.4063843},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184374431&doi=10.1115%2f1.4063843&partnerID=40&md5=084eb60d2696016fb425056f373995e0},
	abstract = {For centuries, researchers have sought out ways to connect disparate areas of knowledge. While early scholars (Galileo, da Vinci, etc.) were experts across fields, specialization took hold later. With the advent of Artificial Intelligence, we can now explore relationships across areas (e.g., mechanics-biology) or disparate domains (e.g., failure mechanics-art). To achieve this, we use a fine-tuned large language model (LLM), here for a subset of knowledge in multiscale materials failure. The approach includes the use of a general-purpose LLM to distill question-answer pairs from raw sources followed by LLM fine-tuning. The resulting MechGPTLLMfoundation model is used in a series of computational experiments to explore its capacity for knowledge retrieval, various language tasks, hypothesis generation, and connecting knowledge across disparate areas. While the model has some ability to recall knowledge from training, we find that LLMs are particularly useful for extracting structural insights through Ontological Knowledge Graphs. These interpretable graph structures provide explanatory insights, frameworks for new research questions, and visual representations of knowledge that also can be used in retrieval-augmented generation. Three versions of MechGPT are discussed, featuring different sizes from 13×109 to 70×109 parameters, and reaching context lengths of more than 10,000 tokens. This provides ample capacity for sophisticated retrieval augmented strategies, as well as agentbased modeling where multiple LLMs interact collaboratively and/or adversarially, the incorporation of new data from the literature or web searches, as well as multimodality.  Copyright © 2024 by ASME.},
	author_keywords = {AI; attention; failure; GPT; human-machine; language model; materials; mechanics; scientific ML; transformer},
	keywords = {Computational linguistics; Graphic methods; Knowledge graph; Modeling languages; Attention; GALILEO; GPT; Human-machine; Language model; Material modeling; Mechanic model; Scientific ML; Specialisation; Transformer; Failure (mechanical)},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 28; All Open Access, Green Open Access}
}

@CONFERENCE{2024,
	title = {OM 2024 - Proceedings of the 19th International Workshop on Ontology Matching, co-located with the 23rd International Semantic Web Conference, ISWC 2024},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3897},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216413567&partnerID=40&md5=4793bb35261c18fa0ff4878bd40dbd4d},
	abstract = {The proceedings contain 17 papers. The topics discussed include: a gold standard benchmark dataset for digital humanities; a scalable method for large-scale entity alignment via multi-channel retrieval and fusion; MDMapper: a framework for aligning master data models using ontology matching techniques; towards generating complex alignments with large language models via prompt engineering; towards tailoring ontology embeddings for ontology matching tasks; enhancing entity matching through systematic association of matchers to linking problem types; results of the ontology alignment evaluation initiative 2024; and TOMATO: results of the 2024 OAEI evaluation campaign.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Bellan20241634,
	author = {Bellan, Patrizio and Dragoni, Mauro and Ghidini, Chiara},
	title = {Process Knowledge Extraction and Knowledge Graph Construction Through Prompting: A Quantitative Analysis},
	year = {2024},
	journal = {Proceedings of the ACM Symposium on Applied Computing},
	pages = {1634 – 1641},
	doi = {10.1145/3605098.3635957},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197704747&doi=10.1145%2f3605098.3635957&partnerID=40&md5=90b6bbfd440e3543d0f51021122b261b},
	abstract = {The automated construction of process knowledge graphs from process description documents is a challenging research area. Here, the lack of massive annotated data, as well as raw text repositories describing real-world process documents, makes it extremely difficult to adopt deep learning approaches to perform this transformation. Indeed, the main challenge is to extract conceptual elements representing the actual entities or relations of the process model described within its corresponding natural language document. Large Language Models (LLMs) have shown promising results in supporting the extraction of structured knowledge from unstructured texts. Although several works explored this strategy to build or complete knowledge graphs, the exploitation of LLMs toward domain-specific knowledge base construction from scratch has not yet been investigated deeply. Our aim is to exploit the LLM capabilities to extract process knowledge from unseen natural language descriptions. In this work, we present a prompt-based in-context learning strategy to extract, from process descriptions, conceptual information that can be converted into their equivalent knowledge graphs. Such a strategy is performed in a multi-turn dialog fashion. We validate the accuracy of the proposed approach from a quantitative perspective. The results highlight the feasibility of the proposed approach within our low-resource scenarios and open interesting perspectives for future activities. © 2024 Copyright is held by the owner/author(s). Publication rights licensed to ACM.},
	author_keywords = {business process management; in-context learning; knowledge graph; large language model; process extraction from text},
	keywords = {Administrative data processing; Computational linguistics; Data mining; Domain Knowledge; Enterprise resource management; Extraction; Learning systems; Metadata; Natural language processing systems; Business Process; Business process management; Context learning; In contexts; In-context learning; Knowledge graphs; Language model; Large language model; Process extraction from text; Process management; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Putman2024D938,
	author = {Putman, Tim E. and Schaper, Kevin and Matentzoglu, Nicolas and Rubinetti, Vincent P. and Alquaddoomi, Faisal S. and Cox, Corey and Caufield, J. Harry and Elsarboukh, Glass and Gehrke, Sarah and Hegde, Harshad and Reese, Justin T. and Braun, Ian and Bruskiewich, Richard M. and Cappelletti, Luca and Carbon, Seth and Caron, Anita R. and Chan, Lauren E. and Chute, Christopher G. and Cortes, Katherina G. and De Souza, Vinícius and Fontana, Tommaso and Harris, Nomi L. and Hartley, Emily L. and Hurwitz, Eric and Jacobsen, Julius O.B. and Krishnamurthy, Madan and Laraway, Bryan J. and McLaughlin, James A. and McMurry, Julie A. and Moxon, Sierra A.T. and Mullen, Kathleen R. and O'Neil, Shawn T. and Shefchek, Kent A. and Stefancsik, Ray and Toro, Sabrina and Vasilevsky, Nicole A. and Walls, Ramona L. and Whetzel, Patricia L. and Osumi-Sutherland, David and Smedley, Damian and Robinson, Peter N. and Mungall, Christopher J. and Haendel, Melissa A. and Munoz-Torres, Monica C.},
	title = {The Monarch Initiative in 2024:ãnãnalytic platform integrating phenotypes, g enesãnd diseasesãcross species},
	year = {2024},
	journal = {Nucleic Acids Research},
	volume = {52},
	number = {D1},
	pages = {D938 – D949},
	doi = {10.1093/nar/gkad1082},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181766041&doi=10.1093%2fnar%2fgkad1082&partnerID=40&md5=e3b5ed710656ea8ba17bb9255692b77a},
	abstract = {Bridging the gap between genetic vãriations, en vironmentãl determinants,ãnd phenot ypic outcomes is critical for supporting clinical diagnosisãnd understanding mechanisms of diseases. It requires integrating open dataãtã global scale. The Monarch Initiativeãdvances these goals b y de v eloping open ontologies, semantic data models,ãnd kno wledge graphs f or translational research. T he Monarch App isãn integrated platform combining dataãbout genes, phenotypes,ãnd diseasesãcross species. Monarch's APIs enableãccess to carefully curated datasetsãndãdvãncedãnaly sis tools that support the understandingãnd diagnosis of disease for diverseãpplications suchãs variant prioritization, deep phenot yping ,ãnd patient profile-matching . We ha v e migrated our sy stem intoã scalable, cloud-based infrastr uct ure; simplified Monarch's data ingestionãnd knowledge graph integration systems; enhanced data mappingãnd integration standards;ãnd de v elopedã ne w user interfãce with no v el searchãnd graph navigation features. Furthermore, weãdvanced Monarch'sãnalytic tools by developingã customized plugin for OpenAI's ChatGPT to increase the reliability of its responsesãbout phenot ypic datã,ãllowing us to interrogate the knowledge in the Monarch graph using state-of-the-art Large Language Models. The resources of the Monarch Initiative can be foundãt monarchinitiative.orgãnd its corresponding code repositoryãt github.com / monarc h-initiative / monarc h-app.  © The Author ( s ) 2023.},
	keywords = {Humans; Phenotype; Reproducibility of Results; Article; ChatGPT; diseases; Ehlers Danlos syndrome; gene; gene ontology; generative pretrained transformer; genetic background; genetic variation; large language model; machine learning; natural language processing; nonhuman; phenotype; quality control; retinitis pigmentosa; translational research; Usher syndrome; written communication; human; phenotype; reproducibility},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 10; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{2024,
	title = {KiL 2024 - Proceedings of the 4th International Workshop on Knowledge-Infused Learning: Towards Consistent, Reliable, Explainable, and Safe LLMs, co-located with 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, KDD 2024},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3894},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216428382&partnerID=40&md5=557b0d16e7b3753501280f2c81cd4391},
	abstract = {The proceedings contain 13 papers. The topics discussed include: towards optimizing with large language model; enhancing the reliability of LLMs-based systems for survey generation through distributional drift detection; GraphEval: a knowledge-graph based LLM hallucination evaluation framework; enhancing semantic understanding in vision language models using meaning representation negative generation; can LLMs solve reading comprehension tests as second language learners?; Infodeslib: Python library for dynamic ensemble learning using late fusion of multimodal data; design and optimization of heat exchangers using large language models; and encoding medical ontologies with holographic reduced representations for transformers.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Alharbi20241650,
	author = {Alharbi, Reham and Tamma, Valentina and Grasso, Floriana and Payne, Terry},
	title = {An Experiment in Retrofitting Competency Questions for Existing Ontologies},
	year = {2024},
	journal = {Proceedings of the ACM Symposium on Applied Computing},
	pages = {1650 – 1658},
	doi = {10.1145/3605098.3636053},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195594103&doi=10.1145%2f3605098.3636053&partnerID=40&md5=53f9a5de78bb9f406e56b7d96ba294e8},
	abstract = {Competency Questions (CQs) are a form of ontology functional requirements expressed as natural language questions. Inspecting CQs together with the axioms in an ontology provides critical insights into the intended scope and applicability of the ontology. CQs also underpin a number of tasks in the development of ontologies e.g. ontology reuse, ontology testing, requirement specification, and the definition of patterns that implement such requirements. Although CQs are integral to the majority of ontology engineering methodologies, the practice of publishing CQs alongside the ontological artefacts is not widely observed by the community.In this context, we present an experiment in retrofitting CQs from existing ontologies. We propose RETROFIT-CQs, a method to extract candidate CQs directly from ontologies using Generative AI. In the paper we present the pipeline that facilitates the extraction of CQs by leveraging Large Language Models (LLMs) and we discuss its application to a number of existing ontologies. © 2024 Copyright held by the owner/author(s).},
	author_keywords = {competency questions; large language models; ontology engineering},
	keywords = {Computational linguistics; Natural language processing systems; Retrofitting; Competency question; Functional requirement; Language model; Large language model; Natural language questions; Ontology engineering; Ontology reuse; Ontology's; Requirements specifications; Testing requirements; Ontology},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Wu2024141,
	author = {Wu, Shenghan and Hsu, Wynne and Lee, Mong Li},
	title = {EHDChat: A Knowledge-Grounded, Empathy-Enhanced Language Model for Healthcare Interactions},
	year = {2024},
	journal = {SICon 2024 - 2nd Workshop on Social Influence in Conversations, Proceedings of the Workshop},
	pages = {141 – 151},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216934377&partnerID=40&md5=a6d3aa9e8470ff0a5b7a6da2514f633c},
	abstract = {Large Language Models (LLMs) excel at a range of tasks but often struggle with issues like hallucination and inadequate empathy support. To address hallucinations, we ground our dialogues in medical knowledge sourced from external repositories such as Disease Ontology and DrugBank. To improve empathy support, we develop the Empathetic Healthcare Dialogues dataset, which utilizes multiple dialogue strategies in each response. This dataset is then used to fine-tune an LLM, and we introduce a lightweight, adaptable method called Strategy Combination Guidance to enhance the emotional support capabilities of the fine-tuned model, named EHDChat. Our evaluations show that EHDChat significantly outperforms existing models in providing emotional support and medical accuracy, demonstrating the effectiveness of our approach in enhancing empathetic and informed AI interactions in healthcare. © 2024 Association for Computational Linguistics.},
	keywords = {Ontology; Dialogue strategy; Drugbank; Emotional supports; Excel; Language model; Medical knowledge; Ontology's; Support capability; Computational linguistics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{2024,
	title = {CMLDS 2024 - 2024 International Conference on Computing, Machine Learning and Data Science, Conference Proceedings},
	year = {2024},
	journal = {ACM International Conference Proceeding Series},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197294704&partnerID=40&md5=1ca007832b6aecbd6023e5b43c54a0cd},
	abstract = {The proceedings contain 60 papers. The topics discussed include: privacy-preservation robust federated learning with blockchain-based hierarchical framework; spatio-temporal hypergraph convolutional network based network traffic prediction; hash function based on quantum walks with two-step memory; adversarial analysis and methods for math word problems; object tracking based on adaptive multi-template fusing; analysis of spatial-temporal variability and heterogeneity of soil moisture; can deep learning large language models be used to unravel knowledge graph creation?; binary and multi-label machine learning models for discrete-time survival analysis: a case study to predict complications and mortality in Thai diabetic patients; power factor anomaly detection using data stream summaries; and consensus filter for distributed sensor networks with unknown colored noise.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Cornelio202412435,
	author = {Cornelio, Cristina and Diab, Mohammed},
	title = {Recover: A Neuro-Symbolic Framework for Failure Detection and Recovery},
	year = {2024},
	journal = {IEEE International Conference on Intelligent Robots and Systems},
	pages = {12435 – 12442},
	doi = {10.1109/IROS58592.2024.10801853},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216491450&doi=10.1109%2fIROS58592.2024.10801853&partnerID=40&md5=e4dbf9c7992d1978996059ff61c6d732},
	abstract = {Recognizing failures during task execution and implementing recovery procedures is challenging in robotics. Traditional approaches rely on the availability of extensive data or a tight set of constraints, while more recent approaches leverage large language models (LLMs) to verify task steps and replan accordingly. However, these methods often operate offline, necessitating scene resets and incurring in high costs. This paper introduces Recover, a neuro-symbolic framework for online failure identification and recovery. By integrating ontologies, logical rules, and LLM-based planners, Recover exploits symbolic information to enhance the ability of LLMs to generate recovery plans and also to decrease the associated costs. In order to demonstrate the capabilities of our method in a simulated kitchen environment, we introduce OntoThor, an ontology describing the AI2Thor simulator setting. Empirical evaluation shows that OntoThor's logical rules accurately detect all failures in the analyzed tasks, and that Recover considerably outperforms, for both failure detection and recovery, a baseline method reliant solely on LLMs. Supplementary material, including the OntoThor ontology, is available at: https://recover-ontothor.github.io. © 2024 IEEE.},
	keywords = {Robotics; Failure detection and recoveries; High costs; Language model; Logical rules; Offline; Ontology's; Recovery procedure; Task executions; Traditional approaches; Traditional approachs; Ontology},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@ARTICLE{Kulin2024588,
	author = {Kulin, Nikita I. and Muravyov, Sergey B.},
	title = {Advanced methods for knowledge injection in large language models; [Продвинутые методы внедрения знаний в больших языковых моделях]},
	year = {2024},
	journal = {Scientific and Technical Journal of Information Technologies, Mechanics and Optics},
	volume = {24},
	number = {4},
	pages = {588 – 593},
	doi = {10.17586/2226-1494-2024-24-4-588-593},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203181792&doi=10.17586%2f2226-1494-2024-24-4-588-593&partnerID=40&md5=f833c14533fe392de79abff17b094652},
	abstract = {Transformer-based language models have revolutionized Natural Language Processing tasks, with advancements in language modeling techniques. Current transformer architectures utilize attention mechanisms to model text dependencies effectively. Studies have shown that these models embed syntactic structures and knowledge, explaining their performance in tasks involving syntactic and semantic elements. However, transformer-based models are prone to hallucination where incorporated knowledge is not utilized effectively. To address this, methods are emerging to mitigate hallucination and integrate external knowledge sources like knowledge graphs (e.g., Freebase, WordNet, ConceptNet, ATOMIC). Knowledge graphs represent real-world knowledge through entities and relationships offering a potential injection point to enhance model performance in inference tasks. Various injection approaches, including input, architectural, and output injections, aim to incorporate knowledge from graphs into transformer models. Input injections modify data preprocessing, architectural injections add layers for knowledge integration, and output injections adjust error functions to correct knowledge incorporation during training. Despite ongoing research, a universal solution to hallucination remains elusive, and a standardized benchmark for comparing injection methods is lacking. This study investigates knowledge graphs as one of the methods to mitigate hallucination and their possible integration into Large Language Models. Comparative experiments across General Language Understanding Evaluation benchmark tasks demonstrated that ERNIE 3.0 and XLNet outperform other injection methods with the average scores of 91.1 % and 90.1 %. © Kulin N.I., Muravyov S.B., 2024.},
	author_keywords = {BERT; hallucination problem; knowledge graphs; knowledge injection methods; LLM},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@CONFERENCE{Walker2024,
	author = {Walker, Johanna and Koutsiana, Elisavet and Nwachukwu, Michelle and Meroño-Peñuela, Albert and Simperl, Elena},
	title = {The Promise and Challenge of Large Language Models for Knowledge Engineering: Insights from a Hackathon},
	year = {2024},
	journal = {Conference on Human Factors in Computing Systems - Proceedings},
	doi = {10.1145/3613905.3650844},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194154569&doi=10.1145%2f3613905.3650844&partnerID=40&md5=3d045b25fd6003f5ae1f983a63f0fcaa},
	abstract = {Knowledge engineering (KE) is the process of building, maintaining and using knowledge-based systems. This recently takes the form of knowledge graphs (KGs). The advent of new technologies like Large Language Models (LLMs) has the potential to improve automation in KE work due to the richness of their training data and their performance at solving natural language processing tasks.We conducted a multiple-methods study exploring user opinions and needs regarding the use of LLMs in KE.We used ethnographic techniques to observe KE workers using LLMs to solve KE tasks during a hackathon, followed by interviews with some of the participants. This interim study found that despite LLMs' promising capabilities for efficient knowledge acquisition and requirements elicitation, their effective deployment requires an extended set of capabilities and training, particularly in prompting and understanding data. LLMs can be useful for simple quality assessment tasks, but in complex scenarios, the output is hard to control and evaluation may require novel approaches. With this study, we aim to evidence the interaction of KE stakeholders with LLMs, identify areas of potential, and understand the barriers to their effective use.We find copilot approaches may be valuable in developing processes where the human or a team of humans is assisted by generative AI. © 2024 Association for Computing Machinery. All rights reserved.},
	author_keywords = {Interviews; Knowledge Engineering; Knowledge Graph; Large Language Models},
	keywords = {Computational linguistics; Natural language processing systems; Quality control; Engineering works; Interview; Knowledge graphs; Knowledge-based systems; Language model; Language processing; Large language model; Natural languages; Performance; Training data; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Bronze Open Access, Green Open Access}
}

@CONFERENCE{Ge202413318,
	author = {Ge, Wenqi and Tang, Chao and Zhang, Hong},
	title = {Commonsense Scene Graph-based Target Localization for Object Search},
	year = {2024},
	journal = {IEEE International Conference on Intelligent Robots and Systems},
	pages = {13318 – 13325},
	doi = {10.1109/IROS58592.2024.10801656},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216461562&doi=10.1109%2fIROS58592.2024.10801656&partnerID=40&md5=4dcdd42952975ee504d41c99885c1be4},
	abstract = {Object search is a fundamental skill for household robots, yet the core problem lies in the robot's ability to locate the target object accurately. The dynamic nature of household environments, characterized by the arbitrary placement of daily objects by users, makes it challenging to perform target localization. To efficiently locate the target object, the robot needs to be equipped with knowledge at both the object and room level. However, existing approaches rely solely on one type of knowledge, leading to unsatisfactory object localization performance and, consequently, inefficient object search processes. To address this problem, we propose a commonsense scene graph-based target localization, CSG-TL, to enhance target object search in the household environment. Given the pre-built map with stationary items, the robot models the room-level spatial knowledge with object-level commonsense knowledge generated by a large language model (LLM) to a commonsense scene graph (CSG), supporting both types of knowledge for CSG-TL. To demonstrate the superiority of CSG-TL on target localization, extensive experiments are performed on the real-world ScanNet dataset and the AI2THOR simulator. Moreover, we have extended CSG-TL to an object search framework, CSG-OS, validated in both simulated and real-world environments. Code and videos are available at https://sites.google.com/view/csg-os. © 2024 IEEE.},
	keywords = {Knowledge graph; Core problems; Daily object; Dynamic nature; Graph-based; Household robots; Object localization; Objects search; Scene-graphs; Target localization; Target object; Robots},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@CONFERENCE{Zhang2024,
	author = {Zhang, Haoran and Nagesh, Supriya and Shyani, Milind and Mishra, Nina},
	title = {Dossier: Fact Checking in Electronic Health Records while Preserving Patient Privacy},
	year = {2024},
	journal = {Proceedings of Machine Learning Research},
	volume = {252},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216676545&partnerID=40&md5=010c9dad52f85acea7ccba2257b9a3a3},
	abstract = {Given a particular claim about a specific document, the fact checking problem is to determine if the claim is true and, if so, provide corroborating evidence. The problem is motivated by contexts where a document is too lengthy to quickly read and find an answer. This paper focuses on electronic health records, or a medical dossier, where a physician has a pointed claim to make about the record. Prior methods that rely on directly prompting an LLM may suffer from hallucinations and violate privacy constraints. We present a system, Dossier, that verifies claims related to the tabular data within a document. For a clinical record, the tables include timestamped vital signs, medications, and labs. Dossier weaves together methods for tagging medical entities within a claim, converting natural language to SQL, and utilizing biomedical knowledge graphs, in order to identify rows across multiple tables that prove the answer. A distinguishing and desirable characteristic of Dossier is that no private medical records are shared with an LLM. An extensive experimental evaluation is conducted over a large corpus of medical records demonstrating improved accuracy over five baselines. Our methods provide hope that physicians can privately, quickly, and accurately fact check a claim in an evidence-based fashion. © 2024 H. Zhang, S. Nagesh, M. Shyani & N. Mishra.},
	keywords = {Differential privacy; Clinical records; Electronic health; Health records; Knowledge graphs; Medical record; Natural languages; Patient privacies; Privacy constraints; Tabular data; Vital sign; Electronic health record},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Von Der Assen2024,
	author = {Von Der Assen, Jan and Huertas, Alberto and Sharif, Jamo and Feng, Chao and Bovet, Gérôme and Stiller, Burkhard},
	title = {ThreatFinderAI: Automated Threat Modeling Applied to LLM System Integration},
	year = {2024},
	journal = {Proceedings of the 2024 20th International Conference on Network and Service Management: AI-Powered Network and Service Management for Tomorrow's Digital World, CNSM 2024},
	doi = {10.23919/CNSM62983.2024.10814632},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216521822&doi=10.23919%2fCNSM62983.2024.10814632&partnerID=40&md5=c57c6f90e15945d0269acc10943b6cec},
	abstract = {Artificial Intelligence (AI) is a rapidly integrated technology, significantly contributing to advancements like 6G. However, its swift adoption raises considerable security concerns. Large Language Models (LLMs) pose risks such as spear phishing, code injections, and remote code execution. Conventional threat modeling, used in secure software development, faces challenges when applied to AI systems, as existing methodologies are designed for traditional software. Furthermore, AI-specific threat modeling research is sparse and lacks approaches providing practical support or automation. Thus, this demo paper presents ThreatFinderAI, an asset-centric threat modeling and risk assessment framework. ThreatFinderAI fulfills seven steps aligned with AI system design and transforms AI threat and control knowledge bases into a queryable knowledge graph for automated asset identification and threat elicitation. It also proposes business impact analysis and expert estimates for AI threat impact quantification. In the demonstration, ThreatFinderAI is illustrated by securing a customer care application relying on LLMs. Through this, it is demonstrated how the proposed framework can be used to identify relevant threats and practical countermeasures and communicate strategic risk.  © 2024 IFIP.},
	author_keywords = {AI Security; AI Systems; Large Language Models; Threat Modeling},
	keywords = {Risk assessment; Artificial intelligence security; Artificial intelligence systems; Code injection; Integrated technologies; Language model; Large language model; Modelling systems; Spear phishing; System integration; Threat modeling; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Jokinen2024578,
	author = {Jokinen, Kristiina and Wilcock, Graham},
	title = {Exploring a Japanese Cooking Database A robot uses GenAI and a knowledge graph to chat about culinary delights},
	year = {2024},
	journal = {ACM/IEEE International Conference on Human-Robot Interaction},
	pages = {578 – 582},
	doi = {10.1145/3610978.3640622},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188145575&doi=10.1145%2f3610978.3640622&partnerID=40&md5=0ccf9d796d5978baf041e64afed529dd},
	abstract = {The paper describes ongoing work applying Generative AI to a real world application. We use Retrieval Augmented Generation and other GenAI tools that combine large language models with Neo4j knowledge graphs. These tools help a robot to chat in English about Japanese cooking using a knowledge base that is in Japanese. © 2024 Copyright held by the owner/author(s)},
	author_keywords = {Cypher query language; Generative AI; graph databases; Japanese cooking; knowledge graphs; large language models; retrieval augmented generation; semantic search; social robots},
	keywords = {Computational linguistics; Query languages; Query processing; Robots; Semantics; Cipher query language; Generative AI; Graph database; Japanese cooking; Knowledge graphs; Language model; Large language model; Retrieval augmented generation; Semantic search; Social robots; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Tan2024151,
	author = {Tan, Fiona Anting and Desai, Jay and Sengamedu, Srinivasan H.},
	title = {Enhancing Fact Verification with Causal Knowledge Graphs and Transformer-Based Retrieval for Deductive Reasoning},
	year = {2024},
	journal = {FEVER 2024 - 7th Fact Extraction and VERification Workshop, Proceedings of the Workshop},
	pages = {151 – 169},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216918360&partnerID=40&md5=d3715640b6666ec872f408625898e078},
	abstract = {The ability to extract and verify factual information from free-form text is critical in an era where vast amounts of unstructured data are available, yet unreliable sources abound. This paper focuses on enhancing causal deductive reasoning, a key component of factual verification, through the lens of accident investigation, where determining the probable causes of events is paramount. Deductive reasoning refers to the task of drawing conclusions based on a premise. While some deductive reasoning benchmarks exist, none focus on causal deductive reasoning and are from real-world applications. Recently, large language models (LLMs) used with prompt engineering techniques like retrieval-augmented generation (RAG) have demonstrated remarkable performance across various natural language processing benchmarks. However, adapting these techniques to handle scenarios with no knowledge bases and to different data structures, such as graphs, remains an ongoing challenge. In our study, we introduce a novel framework leveraging LLMs’ decent ability to detect and infer causal relations to construct a causal Knowledge Graph (KG) which represents knowledge that the LLM recognizes. Additionally, we propose a RoBERTa-based Transformer Graph Neural Network (RoTG) specifically designed to select relevant nodes within this KG. Integrating RoTG-retrieved causal chains into prompts effectively enhances LLM performance, demonstrating usefulness of our approach in advancing LLMs’ causal deductive reasoning capabilities. © 2024 Association for Computational Linguistics.},
	keywords = {Benchmarking; Case based reasoning; Graph neural networks; Modeling languages; Natural language processing systems; Accident investigation; Deductive reasoning; Factual information; Freeforms; Knowledge graphs; Knowledge transformers; Language model; Real-world; Through the lens; Unstructured data; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Ni202413765,
	author = {Ni, Zhe and Deng, Xiaoxin and Tai, Cong and Zhu, Xinyue and Xie, Qinghongbing and Huang, Weihang and Wu, Xiang and Zeng, Long},
	title = {GRID: Scene-Graph-based Instruction-driven Robotic Task Planning},
	year = {2024},
	journal = {IEEE International Conference on Intelligent Robots and Systems},
	pages = {13765 – 13772},
	doi = {10.1109/IROS58592.2024.10801291},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216457296&doi=10.1109%2fIROS58592.2024.10801291&partnerID=40&md5=9c8a1c397bda2ac36a1e1977c54436ce},
	abstract = {Recent works have shown that Large Language Models (LLMs) can facilitate the grounding of instructions for robotic task planning. Despite this progress, most existing works have primarily focused on utilizing raw images to aid LLMs in understanding environmental information. However, this approach not only limits the scope of observation but also typically necessitates extensive multimodal data collection and large-scale models. In this paper, we propose a novel approach called Graph-based Robotic Instruction Decomposer (GRID), which leverages scene graphs instead of images to perceive global scene information and iteratively plan subtasks for a given instruction. Our method encodes object attributes and relationships in graphs through an LLM and Graph Attention Networks, integrating instruction features to predict subtasks consisting of pre-defined robot actions and target objects in the scene graph. This strategy enables robots to acquire semantic knowledge widely observed in the environment from the scene graph. To train and evaluate GRID, we establish a dataset construction pipeline to generate synthetic datasets for graph-based robotic task planning. Experiments have shown that our method outperforms GPT-4 by over 25.4% in subtask accuracy and 43.6% in task accuracy. Moreover, our method achieves a real-time speed of 0.11s per inference. Experiments conducted on datasets of unseen scenes and scenes with varying numbers of objects demonstrate that the task accuracy of GRID declined by at most 3.8%, showcasing its robust cross-scene generalization ability. We validate our method in both physical simulation and the real world. More details can be found on the project page https://jackyzengl.github.io/GRID.github.io/. © 2024 IEEE.},
	keywords = {Adversarial machine learning; Digital elevation model; Knowledge graph; Problem oriented languages; Robot applications; Robot learning; Robot programming; Semantics; Decomposers; Environmental information; Graph-based; Language model; Multi-modal; Raw images; Robotic tasks; Scene-graphs; Subtask; Task planning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@ARTICLE{Feng2024105,
	author = {Feng, Shichu and Shi, Bin and Zheng, Yalong},
	title = {Construction of Gem Knowledge Graph Based on Large Language Model; [基于大语言模型 (LLM) 的宝石知识图谱的构建]},
	year = {2024},
	journal = {Journal of Gems and Gemmology},
	volume = {26},
	number = {3},
	pages = {105 – 112},
	doi = {10.15964/j.cnki.027jgg.2024.03.012},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205486942&doi=10.15964%2fj.cnki.027jgg.2024.03.012&partnerID=40&md5=c9b0bc6bdb33da08bca61ed30ce1ddfc},
	abstract = {The sources of gemmological knowledge include books, journals, courses, markets and related disciplines. A complete gemmological knowledge system is of great significance to the jewelry industry. Gem knowledge points are numerous and relatively isolated in storage, which is not conducive to practitioners and researchers to retrieve knowledge. This problem can be solved by constructing a gem knowledge base system. The graph can deal with the complex association between knowledge points, which is impossible for widely used structured database, therefore, a knowledge base in the form of a knowledge graph is selected. This paper introduces the traditional knowledge graph construction method and points out the difficulties: high cost, heavy workload, difficult technology and slightly low accuracy. It is proposed to use LLM (Large language model) to complete some tasks in knowledge graph construction to improve the cost and workload. A new knowledge graph construction idea based on LLM is conceived. Its steps include data cleaning, knowledge acquisition and knowledge refinement. According to the above ideas, a gemstone knowledge graph that can cover the gemstone knowledge of the bachelor stage is constructed, and some query scenarios are displayed. The feasibility and high efficiency of the new method are proved by our test e-valuation, and the possible application direction of the graph is prospected. © 2024 Editorial Department of Journal of Gems and Gemmology, China University of Geosciences. All rights reserved.},
	author_keywords = {gemmology; knowledge extraction; knowledge graph; large language model; prompt engineering},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Wang202419135,
	author = {Wang, Jiaan and Qu, Jianfeng and Wang, Kexin and Li, Zhixu and Hua, Wen and Li, Ximing and Liu, An},
	title = {Improving the Robustness of Knowledge-Grounded Dialogue via Contrastive Learning},
	year = {2024},
	journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
	volume = {38},
	number = {17},
	pages = {19135 – 19143},
	doi = {10.1609/aaai.v38i17.29881},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189647385&doi=10.1609%2faaai.v38i17.29881&partnerID=40&md5=45da5296ecbfe9490fbeb1848fdf2dcd},
	abstract = {Knowledge-grounded dialogue (KGD) learns to generate an informative response based on a given dialogue context and external knowledge (e.g., knowledge graphs; KGs). Recently, the emergence of large language models (LLMs) and pre-training techniques has brought great success to knowledge-grounded dialogue. However, when building KGD systems in real applications, there are various real-world noises that are inevitable to face. For example, the dialogue context might involve perturbations such as misspellings and abbreviations. In addition, KGs typically suffer from incompletion and also might contain erroneous and outdated facts. Such real-world noises pose a challenge to the robustness of KGD systems and hinder their applications in the real world. In this paper, we propose an entity-based contrastive learning framework for improving the robustness of KGD. Specifically, we make use of the entity information in a KGD sample to create both its positive and negative samples which involve semantic-irrelevant and semantic-relevant perturbations, respectively. The contrastive learning framework ensures the KGD model is aware of these two types of perturbations, thus generating informative responses with the potentially noisy inputs in real applications. Experimental results on three benchmark datasets show that our method achieves new state-of-the-art performance in terms of automatic evaluation scores, verifying its effectiveness and potentiality. Furthermore, we show that our method can generate better responses than comparison models in both the noisy and the few-shot settings. © 2024, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.},
	keywords = {Benchmarking; Knowledge graph; Learning systems; Dialogue systems; External knowledge; Knowledge graphs; Language model; Learn+; Learning frameworks; Model training; Pre-training; Real applications; Real-world noise; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Valiev2024470,
	author = {Valiev, Airat and Tutubalina, Elena},
	title = {HSE NLP Team at MEDIQA-CORR 2024 Task: In-Prompt Ensemble with Entities and Knowledge Graph for Medical Error Correction},
	year = {2024},
	journal = {ClinicalNLP 2024 - 6th Workshop on Clinical Natural Language Processing, Proceedings of the Workshop},
	pages = {470 – 482},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216814902&partnerID=40&md5=a691111b1ee7baf39ea2397b63de9ef7},
	abstract = {This paper presents our LLM-based system designed for the MEDIQA-CORR @ NAACLClinicalNLP 2024 Shared Task 3, focusing on medical error detection and correction in medical records. Our approach consists of three key components: entity extraction, prompt engineering, and ensemble. First, we automatically extract biomedical entities such as therapies, diagnoses, and biological species. Next, we explore few-shot learning techniques and incorporate graph information from the MeSH database for the identified entities. Finally, we investigate two methods for ensembling: (i) combining the predictions of three previous LLMs using an AND strategy within a prompt and (ii) integrating the previous predictions into the prompt as separate ‘expert’ solutions, accompanied by trust scores representing their performance. The latter system ranked second with a BERTScore score of 0.8059 and third with an aggregated score of 0.7806 out of the 15 teams’ solutions in the shared task. © 2024 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Error correction; Error detection; Expert systems; Zero-shot learning; Biological species; Entity extractions; Error detection and correction; Errors correction; Graph information; Knowledge graphs; Learning techniques; Medical errors; Medical record; Trust scores; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Zhao2024201,
	author = {Zhao, Lu and Jiang, Xin and Tao, Feng and Liu, Wen and Wang, Xue and Wu, Yu Hao},
	title = {Research on Large Model Text-to-SQL Optimization Method for Intelligent Interaction in the Field of Construction Safety},
	year = {2024},
	journal = {2024 5th International Symposium on Computer Engineering and Intelligent Communications, ISCEIC 2024},
	pages = {201 – 209},
	doi = {10.1109/ISCEIC63613.2024.10810146},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216631866&doi=10.1109%2fISCEIC63613.2024.10810146&partnerID=40&md5=627fd5e8f87c09ba9d6818c312ceacc6},
	abstract = {With the increasing amount of information and data in construction safety management, traditional business query and analysis methods are no longer sufficient to meet the demands for flexibility and complexity in on-site management. This study addresses the information query needs in the construction safety domain by proposing a graph-structured retrieval-enhanced large model Text-to-SQL optimization method. By standardizing database table information, addressing few-shot problems with example-based and enterprise safety domain knowledge prompt templates, and utilizing graph data-based knowledge retrieval enhancement techniques, the method enhances the large model's business understanding capability in the construction safety field and reduces computational resource consumption. Furthermore, by employing reasoning strategies such as chain-of-thought prompting, easy-to-hard progression, self-consistency, and self-correction, the accuracy of the large model in responding to complex construction safety business questions is significantly improved. Experimental results on the open-source model llama-3-sqlcoder-8b and the closed-source model GLM-4-Plus demonstrate that this method achieves substantial improvements in execution accuracy and syntactic accuracy, proving its universality and effectiveness. © 2024 IEEE.},
	author_keywords = {GraphRAG; LLM; Prompt engineering; Reasoning Strategies; Text-to-SQL},
	keywords = {Data accuracy; Enterprise resource management; Information management; Knowledge graph; Project management; Amount of information; Construction safety; Graphrag; Intelligent interactions; Large models; LLM; Optimization method; Prompt engineering; Reasoning strategy; Text-to-SQL; Structured Query Language},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Chowdhury2024194,
	author = {Chowdhury, Saurav and Joshi, Suyog and Dey, Lipika},
	title = {Cross Examine: An Ensemble-based approach to leverage Large Language Models for Legal Text Analytics},
	year = {2024},
	journal = {NLLP 2024 - Natural Legal Language Processing Workshop 2024, Proceedings of the Workshop},
	pages = {194 – 204},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216927826&partnerID=40&md5=b3aabe5a7b1fbf37b80d701a5e10fe40},
	abstract = {Legal documents are complex in nature, describing a course of argumentative reasoning that is followed to settle a case. Churning through large volumes of legal documents is a daily requirement for a large number of professionals who need access to the information embedded in them. Natural Language Processing(NLP) methods that help in document summarization with key information components, insight extraction and question answering play a crucial role in legal text processing. Most of the existing document analysis systems use supervised machine learning, which require large volumes of annotated training data for every different application and are expensive to build. In this paper we propose a legal text analytics pipeline using Large Language Models (LLMs), which can work with little or no training data. For document summarization, we propose an iterative pipeline using retrieval augmented generation to ensure that the generated text remains contextually relevant. For question answering, we propose a novel ontology-driven ensemble approach similar to cross-examination that exploits questioning and verification principles. A knowledge graph, created with the extracted information, stores the key entities and relationships reflecting the repository content structure. A new dataset is created with Indian court documents related to bail applications for cases filed under POCSO1 Act. Analysis of insights extracted from the answers reveal patterns of crime and social conditions leading to those crimes, which are important inputs for social scientists as well as legal system.  ©2024 Association for Computational Linguistics.},
	keywords = {Crime; Data Analytics; Knowledge graph; Modeling languages; Natural language processing systems; Personnel training; Semi-supervised learning; Document summarization; Language model; Language processing; Large volumes; Legal documents; Legal texts; Natural languages; Processing method; Question Answering; Text analytics; Question answering},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{You202419431,
	author = {You, Weihao and Wang, Pengcheng and Li, Changlong and Ji, Zhilong and Bai, Jinfeng},
	title = {CK12: A Rounded K12 Knowledge Graph Based Benchmark for Chinese Holistic Cognition Evaluation},
	year = {2024},
	journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
	volume = {38},
	number = {17},
	pages = {19431 – 19439},
	doi = {10.1609/aaai.v38i17.29914},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189609115&doi=10.1609%2faaai.v38i17.29914&partnerID=40&md5=130a5dc19cffa295f428471689a7b5b1},
	abstract = {New NLP benchmarks are urgently needed to align with the rapid development of large language models (LLMs). We present a meticulously designed evaluation benchmark that leverages the knowledge graph. This evaluation comprises 584 level-1 knowledge points and 1,989 level-2 knowledge points, thereby encompassing a comprehensive spectrum of the K12 education domain knowledge. The primary objective is to comprehensively assess the high-level comprehension aptitude and reasoning capabilities of LLMs operating within the Chinese context. Our evaluation incorporates five distinct question types with 39,452 questions. We test the current mainstream LLMs by three distinct modes. Firstly, four prompt evaluation modes were employed to assess the fundamental capacity. Additionally, for choice questions, a result-oriented evaluation approach was designed through data augmentation to assess the model’s proficiency in advanced knowledge and reasoning. Moreover, a subset with reasoning process is derived, and the process-oriented testing method is used to test the model’s interpretability and higher-order reasoning capacity. We further show models’ capability in our knowledge points, and anticipate the evaluation can assist in the assessment of the strengths and deficiencies of LLMs on knowledge points, thus fostering their development within the Chinese context. Our Dataset will be publicly available in https://github.com/tal-tech/chinese-k12-evaluation. © 2024, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.},
	keywords = {Domain Knowledge; Graphic methods; Chinese context; Domain knowledge; Education domain; Graph-based; K-12 education; Knowledge graphs; Language model; Level 2; Level-1; Spectra's; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Matthews2024,
	author = {Matthews, Blair},
	title = {Finding the Human in an Era of Machine Intelligence: A Flat Ontological Analysis of Generative AI and Language Learning},
	year = {2024},
	journal = {Technology in Language Teaching and Learning},
	volume = {6},
	number = {3},
	doi = {10.29140/tltl.v6n3.1612},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216431170&doi=10.29140%2ftltl.v6n3.1612&partnerID=40&md5=8e66bae8bcf4c1a9be1086b8af2cdb31},
	abstract = {Amid the optimism of generative Artificial Intelligence (gen-AI) in language education, there remains a weak connection to learning practices. The emergence of gen-AI has preceded considerations of how it should be applied in teaching and learning. However, while gen-AI has been justified in terms of the possibilities to enhance learner agency by expanding opportunities to engage with language, such as through the generation of content or the translation of texts, it can also take power away from learners. How can learners be self-determining in light of how choices become increasingly guided by Artificial Intelligence? In this paper, I conceive the arrangements of humans and software as an assemblage of complex and dynamic social, and technical processes. Drawing on a flat ontology, where all agents (human and non-human, material and subjective) have equal ontological status, I argue that learner agency has its origins in the messy and lively interactions between heterogenous actors. In particular, I consider active and passive affects as being part of the same process: active when we bring something into effect ourselves, passive when our self-determination is changed not by our own power, but through external forces acting on it (such as gen-AI). From this, I explore the constraining and enabling potential of artificial intelligence. Finally, I extend this discussion to the emergence of learner agency. © 2024 Blair Matthews.},
	author_keywords = {artificial intelligence; flat ontology; language education; language learning; learner agency; socio-materialism},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Zhang2024,
	author = {Zhang, Wenbo and Wang, Mengxuan and Han, Guangjie and Feng, Yongxin and Tan, Xiaobo},
	title = {A Knowledge Graph Completion Algorithm Based on the Fusion of Neighborhood Features and vBiLSTM Encoding for Network Security},
	year = {2024},
	journal = {Electronics (Switzerland)},
	volume = {13},
	number = {9},
	doi = {10.3390/electronics13091661},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192525471&doi=10.3390%2felectronics13091661&partnerID=40&md5=b0ca1b20190e386cabc7ee94f22da33d},
	abstract = {Knowledge graphs in the field of network security can integrate diverse, heterogeneous, and fragmented network security data, further explore the relationships between data, and provide support for deep analysis. Currently, there is sparse security information in the field of network security knowledge graphs. The limited information provided by traditional text encoding models leads to insufficient reasoning ability, greatly restricting the development of this field. Starting from text encoding, this paper first addresses the issue of the inadequate capabilities of traditional models using a deep learning model for assistance. It designs a vBiLSTM model based on a word2vec and BiLSTM combination to process network security texts. By utilizing word vector models to retain semantic information in entities and extract key features to input processed data into BiLSTM networks for extracting higher-level features that better capture and express their deeper meanings, this design significantly enhances understanding and expression capabilities toward complex semantics in long sentences before inputting final feature vectors into the KGC-N model. The KGC-N model uses feature vectors combined with graph structure information to fuse forward and reverse domain features and then utilizes a Transformer decoder to decode predictions and complete missing information within the network security knowledge map. Compared with other models using evaluation metrics such as MR, MRR demonstrates that employing our proposed method effectively improves performance on completion tasks and increases comprehension abilities toward complex relations, thereby enhancing accuracy and efficiency when completing knowledge graphs. © 2024 by the authors.},
	author_keywords = {cybersecurity; KGC-N; knowledge graph completion; text encoding; vBiLSTM},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access}
}

@CONFERENCE{Chaitra20241,
	author = {Chaitra, C.R. and Kulkarni, Sankalp and Sagi, Sai Rama Akash Varma and Pandey, Shashank and Yalavarthy, Rohit and Chakraborty, Dipanjan and Upadhyay, Prajna},
	title = {LeGen: Complex Information Extraction from Legal sentences using Generative Models},
	year = {2024},
	journal = {NLLP 2024 - Natural Legal Language Processing Workshop 2024, Proceedings of the Workshop},
	pages = {1 – 17},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216918796&partnerID=40&md5=9f24fba50a85b492a347144933affef0},
	abstract = {Constructing legal knowledge graphs from unstructured legal texts is a complex challenge due to the intricate nature of legal language. While open information extraction (OIE) techniques can convert text into triples of the form (subject, relation, object), they often fall short of capturing the nuanced relationships within lengthy legal sentences, necessitating more sophisticated approaches known as complex information extraction. This paper proposes LeGen - an end-to-end approach leveraging pre-trained large language models (GPT-4o, T5, BART) to perform complex information extraction from legal sentences. LeGen learns and represents the discourse structure of legal sentences, capturing both their complexity and semantics. It minimizes error propagation typical in multi-step pipelines and achieves up to a 32.2% gain on the Indian Legal benchmark. Additionally, it demonstrates competitive performance on open information extraction benchmarks. A promising application of the resulting legal knowledge graphs is in developing question-answering systems for government schemes, tailored to the Next Billion Users who struggle with the complexity of legal language. Our code and data are available at https://github.com/prajnaupadhyay/LegalIE.  ©2024 Association for Computational Linguistics.},
	keywords = {Benchmarking; Computational linguistics; Knowledge graph; Open Data; Complex information; Discourse structure; End to end; Generative model; Information extraction techniques; Knowledge graphs; Language model; Learn+; Legal knowledge; Legal texts; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Nakajima20244755,
	author = {Nakajima, Haru and Miura, Jun},
	title = {Combining Ontological Knowledge and Large Language Model for User-Friendly Service Robots},
	year = {2024},
	journal = {IEEE International Conference on Intelligent Robots and Systems},
	pages = {4755 – 4762},
	doi = {10.1109/IROS58592.2024.10802273},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216487892&doi=10.1109%2fIROS58592.2024.10802273&partnerID=40&md5=053174d1fb6270842ef219b68e258816},
	abstract = {Lifestyle support through robotics is an increasingly promising field, with expectations for robots to take over or assist with chores like floor cleaning, table setting and clearing, and fetching items. The growth of AI, particularly foundation models, such as large language models (LLMs) and visual language models (VLMs), is significantly shaping this sector. LLMs, by facilitating natural interactions and providing vast general knowledge, are proving invaluable for robotic tasks. This paper focuses on the benefits of LLMs for "bring-me"tasks, where robots fetch specific items for users, often based on ambiguous instructions. Our previous efforts utilized an ontology extended to handle environmental data to resolve such ambiguities, but faced limitations when unresolvable ambiguities required user intervention for clarity. Here, we enhance our approach by integrating LLMs for providing additional commonsense knowledge, pairing it with ontological data to mitigate the issue of hallucinations and reduce the need for user queries, thus improving system usability. We present a system that merges these knowledge bases and assess its efficacy on "bring-me"tasks, aiming to provide a more seamless and efficient robotic assistance experience. © 2024 IEEE.},
	keywords = {Microrobots; Modeling languages; Ontology; Floor cleaning; Foundation models; General knowledge; Language model; Natural interactions; Ontology's; Robotic tasks; Service robots; User friendly; Visual language model; Visual languages},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@CONFERENCE{Wu202419234,
	author = {Wu, Chenxiao and Ke, Wenjun and Wang, Peng and Luo, Zhizhao and Li, Guozheng and Chen, Wanyi},
	title = {ConsistNER: Towards Instructive NER Demonstrations for LLMs with the Consistency of Ontology and Context},
	year = {2024},
	journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
	volume = {38},
	number = {17},
	pages = {19234 – 19242},
	doi = {10.1609/aaai.v38i17.29892},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186365966&doi=10.1609%2faaai.v38i17.29892&partnerID=40&md5=ecc266eaa733bf42d21af3eca5bc82a3},
	abstract = {Named entity recognition (NER) aims to identify and classify specific entities mentioned in textual sentences. Most existing superior NER models employ the standard fully supervised paradigm, which requires a large amount of annotated data during training. In order to maintain performance with insufficient annotation resources (i.e., low resources), in-context learning (ICL) has drawn a lot of attention, due to its plug-and-play nature compared to other methods (e.g., meta-learning and prompt learning). In this manner, how to retrieve high-correlated demonstrations for target sentences serves as the key to emerging ICL ability. For the NER task, the correlation implies the consistency of both ontology (i.e., generalized entity type) and context (i.e., sentence semantic), which is ignored by previous NER demonstration retrieval techniques. To address this issue, we propose ConsistNER, a novel three-stage framework that incorporates ontological and contextual information for low-resource NER. Firstly, ConsistNER employs large language models (LLMs) to pre-recognize potential entities in a zero-shot manner. Secondly, ConsistNER retrieves the sentence-specific demonstrations for each target sentence based on the two following considerations: (1) Regarding ontological consistency, demonstrations are filtered into a candidate set based on ontology distribution. (2) Regarding contextual consistency, an entity-aware self-attention mechanism is introduced to focus more on the potential entities and semantic-correlated tokens. Finally, ConsistNER feeds the retrieved demonstrations for all target sentences into LLMs for prediction. We conduct experiments on four widely-adopted NER datasets, including both general and specific domains. Experimental results show that ConsistNER achieves a 6.01%-26.37% and 3.07%-21.18% improvement over the state-of-the-art baselines on Micro-F1 scores under 1- and 5-shot settings, respectively. © 2024, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.},
	keywords = {Ontology; Semantics; Zero-shot learning; Context learning; In contexts; Language model; Large amounts; Metalearning; Named entity recognition; Ontology's; Performance; Plug-and-play; Recognition models; Demonstrations},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access}
}

@CONFERENCE{Ringwald202423411,
	author = {Ringwald, Célian},
	title = {Learning Pattern-Based Extractors from Natural Language and Knowledge Graphs: Applying Large Language Models to Wikipedia and Linked Open Data},
	year = {2024},
	journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
	volume = {38},
	number = {21},
	pages = {23411 – 23412},
	doi = {10.1609/aaai.v38i21.30406},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189624509&doi=10.1609%2faaai.v38i21.30406&partnerID=40&md5=bc139ed8b357b6daae7bedd02f2c24f0},
	abstract = {Seq-to-seq transformer models have recently been successfully used for relation extraction, showing their flexibility, effectiveness and scalability on that task. In this context, knowledge graphs aligned with Wikipedia such as DBpedia and Wikidata give us the opportunity to leverage existing texts and corresponding RDF graphs in order to extract, from these texts, the knowledge that is missing in the corresponding graphs and meanwhile improve their coverage. The goal of my thesis is to learn efficient extractors targeting specific RDF patterns and to do so by leveraging the latest language models and the dual base formed by Wikipedia on the one hand, and DBpedia & Wikidata on the other hand. Copyright © 2024, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.},
	keywords = {Computational linguistics; Graphic methods; Knowledge management; Linked data; Open Data; Resource Description Framework (RDF); Dbpedia; Knowledge graphs; Language model; Learning patterns; Linked open datum; Natural languages; RDF graph; Relation extraction; Transformer modeling; Wikipedia; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access}
}

@CONFERENCE{Bengtsson202427,
	author = {Bengtsson, Marcus and D’Cruze, Ricky Stanley and Ahmed, Mobyen Uddin and Sakao, Tomohiko and Funk, Peter and Sohlberg, Rickard},
	title = {Combining Ontology and Large Language Models to Identify Recurring Machine Failures in Free-Text Fields},
	year = {2024},
	journal = {Advances in Transdisciplinary Engineering},
	volume = {52},
	pages = {27 – 38},
	doi = {10.3233/ATDE240151},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191305248&doi=10.3233%2fATDE240151&partnerID=40&md5=5342fb3fe7b813f7974bb523918e5bea},
	abstract = {Companies must enhance total maintenance effectiveness to stay competitive, focusing on both digitalization and basic maintenance procedures. Digitalization offers technologies for data-driven decision-making, but many maintenance decisions still lack a factual basis. Prioritizing efficiency and effectiveness require analyzing equipment history, facilitated by using Computerized Maintenance Management Systems (CMMS). However, CMMS data often contains unstructured free-text, leading to manual analysis, which is resource-intensive and reactive, focusing on short time periods and specific equipment. Two approaches are available to solve the issue: minimizing free-text entries or using advanced methods for processing them. Free-text allows detailed descriptions but may lack completeness, while structured reporting aids automated analysis but may limit fault description richness. As knowledge and experience are vital assets for companies this research uses a hybrid approach by combining Natural Language Processing with domain specific ontology and Large Language Models to extract information from free-text entries, enabling the possibility of real-time analysis e.g., identifying recurring failure and knowledge sharing across global sites. © 2024 The Authors.},
	author_keywords = {Artificial Intelligence; Experience Reuse; Industrial Maintenance; Large Language Models; Natural Language Processing},
	keywords = {Computational linguistics; Decision making; Failure (mechanical); Natural language processing systems; Ontology; Computerized maintenance management system; Experience reuse; Free texts; Industrial maintenance; Language model; Language processing; Large language model; Natural language processing; Natural languages; Text entry; Maintenance},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@CONFERENCE{Mou20242603,
	author = {Mou, Xinyi and Li, Zejun and Lyu, Hanjia and Luo, Jiebo and Wei, Zhongyu},
	title = {Unifying Local and Global Knowledge: Empowering Large Language Models as Political Experts with Knowledge Graphs},
	year = {2024},
	journal = {WWW 2024 - Proceedings of the ACM Web Conference},
	pages = {2603 – 2614},
	doi = {10.1145/3589334.3645616},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186254656&doi=10.1145%2f3589334.3645616&partnerID=40&md5=e67e2e64852f65367fa154e3d318ee1e},
	abstract = {Large Language Models (LLMs) have revolutionized solutions for general natural language processing (NLP) tasks. However, deploying these models in specific domains still faces challenges like hallucination. While existing knowledge graph retrieval-based approaches offer partial solutions, they cannot be well adapted to the political domain. On one hand, existing generic knowledge graphs lack vital political context, hindering deductions for practical tasks. On the other hand, the nature of political questions often renders the direct facts elusive, necessitating deeper aggregation and comprehension of retrieved evidence. To address these challenges, we propose a Political Experts through Knowledge Graph Integration (PEG) framework. PEG entails the creation and utilization of a multi-view political knowledge graph (MVPKG), which integrates U.S. legislative, election, and diplomatic data, as well as conceptual knowledge from Wikidata. With MVPKG as its foundation, PEG enhances existing methods through knowledge acquisition, aggregation, and injection. This process begins with refining evidence through semantic filtering, followed by its aggregation into global knowledge via implicit or explicit methods. The integrated knowledge is then utilized by LLMs through prompts. Experiments on three real-world datasets across diverse LLMs confirm PEG's superiority in tackling political modeling tasks. © 2024 ACM.},
	author_keywords = {knowledge graph; large language models; political science},
	keywords = {Computational linguistics; Natural language processing systems; Semantics; Global knowledge; Knowledge graphs; Language model; Language processing; Large language model; Local knowledge; Multi-views; Natural languages; Political context; Political science; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@ARTICLE{Fenggui2024353,
	author = {Fenggui, Niu and Bei, Zhang and Shi, Chen},
	title = {Review and perspective of Earth Science Knowledge Graph in Big Data Era; [大数据时代的地球科学知识图谱研究现状与展望]},
	year = {2024},
	journal = {Acta Seismologica Sinica},
	volume = {46},
	number = {3},
	pages = {353 – 376},
	doi = {10.11939/jass.20230157},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196662469&doi=10.11939%2fjass.20230157&partnerID=40&md5=37ee0272bddfdc4ccd9205412c38dac6},
	abstract = {Earth Science is a discipline that heavily relies on data,yet it is not fully harnessing the advantages of Earth data with existing technological means though covers many subject areas,Knowledge Graphs (KGs) is widely recognized as an effective approach to fully harness and utilize the extensive data in this field. Earth Science Knowledge Graphs can integrate geoscience knowledge,enhance research efficiency,and facilitate interdisciplinary collaboration. By analyzing network connections and semantic relationships,they uncover knowledge associations and patterns,andaid researchers in identifying new domains and posing novel research questions. Unlike conventional advancements in large-scale modeling technologies, Knowledge Graph offers precise knowledge that enhances both the intelligence and dependability of generated outcomes from such models. Firstly,this study provides a detailed exposition of Knowledge Graph concepts and construction methods. Knowledge Graphs,as a form of data graph,are designed to collect and convey knowledge from the real world. Their universal expression is in the form of triples,consisting of head entities,tail entities,and the relationships between them. Knowledge Graphs have emerged as a significant approach for organizing structured knowledge and integrating information from multiple data sources in the organizational world. Their architectural framework primarily encompasses four components:source data acquisition,knowledge fusion, knowledge computation,and knowledge application. Source data acquisition stands as the primary step in building Knowledge Graphs,focusing on extracting useful information from various types of data. Knowledge fusion is pivotal in addressing the heterogeneity of different Knowledge Graphs,with the aim of enhancing their quality through integration. Knowledge computation represents the primary output capability of Knowledge Graphs,currently applied in fields such as semantic search,question answering,and visualization analysis. Knowledge Graph construction technology enables the extraction of information from structured,unstructured,and semi-structured data sources,organizing this information into knowledge and presenting it in graphical form. Presently,the construction of Knowledge Graphs in the field of Earth Sciences primarily employs two methods:Top-down and bottom-up approaches,with the overarching principle being the synthesis of both methods while allowing flexibility in their specific sequencing. Secondly,this study offers a comprehensive introduction to the widely applied top-level ontology,the Basic Formal Ontology (BFO) model,in the scientific domain. The paper briefly summarizes existing Knowledge Graph in the geoscience field,emphasizing the GeoCore Ontology and Geoscience ontology (GSO) in the Earth Science domain,highlighting their similarities and differences. BFO,comprising 38 classes,is designed to facilitate information integration,retrieval,and analysis in scientific research. Presently,BFO has been successfully employed in over 350 ontology projects worldwide. The GeoCore Ontology,built upon BFO, serves as a specialized framework to describe the core concepts within the domain of Earth Science,rigorously defining a set of universal geological concepts during its development. Conversely,GSO provides a systematic framework for representing crucial geological science knowledge,encompassing three hierarchical layers:foundational,geological,and detailed modules. GeoCore can be viewed as an intermediary layer within GSO,which can be further expanded,while detailed modules have already been constructed within GSO. Additionally, researchers worldwide employ various methods such as literature mining,domain expert interviews,and data mining techniques to extract Earth Science knowledge from relevant literature, databases,and open data,subsequently to construct Knowledge Graphs. These Knowledge Graphs are found in applications across various domains including geological exploration,natural disaster prediction,and environmental conservation,and are utilized in practical projects such as oil and gas exploration,water resource management,and climate change research. In summary,the application scope of Earth Science Knowledge Graphs is extensive,providing a crucial foundation of data and knowledge for scientific research,decision support,and sustainable development. Finally,the study introduces international Earth Science data science initiatives such as the Deep-time Digital Earth (DDE) project related to constructing Earth Science Knowledge Graph,and the challenges and application prospects for the future development of Earth Science Knowledge Graph,with a focus on seismic science. The DDE aims to connect and coordinate global deep-earth data,promoting the sharing of geoscientific knowledge worldwide and facilitating research on Earth's evolution in a data-driven manner. Apart from the DDE,numerous domestic and international organizations and initiatives are driving the development of Knowledge Graph in Earth Science,such as OneGeology,EarthCube,and LinkedGeoData projects. Despite facing various challenges,Knowledge Graph is gradually overcoming these hurdles with advancements in technology and tools. These challenges are not exclusive to the field of Earth Science but are prevalent across all Knowledge Graph construction endeavors. However,due to the complexity and diversity of Earth Science,Knowledge Graph construction in this field encounters unique difficulties. Nevertheless,there is ample room for the creation and application of Knowledge Graph in Earth Science,with the introduction of Large Language Models (LLMs) bringing forth new opportunities. Earthquake Science,as a crucial branch of Earth Science,encompasses intersections of multiple primary disciplines such as geology,geophysics,and engineering seismology. However,the application of Knowledge Graphs in the field of Earthquake Science still faces significant gaps and urgently requires further research building upon existing models. In conclusion,the future development of Earth Science Knowledge Graphs will be an ongoing process of evolution and refinement,bringing more opportunities and benefits for fields such as Earth Science research,decision-making,and public education through sustained technological innovation and interdisciplinary collaboration. © 2024 Acta Seismologica Sinica Press. All rights reserved.},
	author_keywords = {Earth science; geological ontology; Knowledge Graph; ontology construction},
	keywords = {data acquisition; data mining; data set; Earth science; knowledge; seismic data},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Abdul2024,
	author = {Abdul, Ashu and Chen, Binghong and Phani, Siginamsetty and Chen, Jenhui},
	title = {Improving preliminary clinical diagnosis accuracy through knowledge filtering techniques in consultation dialogues},
	year = {2024},
	journal = {Computer Methods and Programs in Biomedicine},
	volume = {246},
	doi = {10.1016/j.cmpb.2024.108051},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185166949&doi=10.1016%2fj.cmpb.2024.108051&partnerID=40&md5=c2fe5526e2c702a4f27b12156edb1f1f},
	abstract = {Background and Objective: Symptom descriptions by ordinary people are often inaccurate or vague when seeking medical advice, which often leads to inaccurate preliminary clinical diagnoses. To address this issue, we propose a deep learning model named the knowledgeable diagnostic transformer (KDT) for the natural language processing (NLP)-based preliminary clinical diagnoses. Methods: The KDT extracts symptom-disease relation triples (h,r,t) from patient symptom descriptions by using a proposed bipartite medical knowledge graph (bMKG). To avoid too many relation triples causing the knowledge noise issue, we propose a knowledge inclusion-exclusion approach (KIA) to eliminate undesirable triples (a knowledge filtering layer). Next, we combine token embedding techniques with the transformer model to predict the diseases that patients may encounter. Results: To train the KDT, a medical diagnosis question-answering dataset (named MDQA dataset) containing large-scale, high-quality questions (patient syndrome description) and answering (diagnosis) corpora with 2.6M entries (1.07GB in size) in Mandarin was built. We also train the KDT with the National Institutes of Health (NIH) English dataset (MedQuAD). The KDT marks a transformative approach by achieving a remarkable accuracy of 99% for different evaluation metrics when compared with the baseline transformers used for the NLP-based preliminary clinical diagnoses approaches. Conclusions: In essence, our study not only demonstrates the effectiveness of the KDT in enhancing diagnostic precision but also underscores its potential to revolutionize the field of preliminary clinical diagnoses. By harnessing the power of knowledge-based approaches and advanced NLP techniques, we have paved the way for more accurate and reliable diagnoses, ultimately benefiting both healthcare providers and patients. The KDT has the potential to significantly reduce misdiagnoses and improve patient outcomes, marking a pivotal advancement in the realm of medical diagnostics. © 2024 Elsevier B.V.},
	author_keywords = {Disease; Knowledge graph; Natural language processing; Patient syndrome; Preliminary clinical diagnosis; Transformers},
	keywords = {Benchmarking; Electric Power Supplies; Humans; Knowledge Bases; Language; Natural Language Processing; Referral and Consultation; United States; Deep learning; Knowledge graph; Large datasets; Natural language processing systems; Clinical diagnosis; Filtering technique; Knowledge graphs; Language processing; Natural language processing; Natural languages; Ordinary people; Patient syndrome; Preliminary clinical diagnose; Transformer; Article; clinical evaluation; consultation; deep learning; diagnostic accuracy; diagnostic test accuracy study; digital filtering; diseases; embedding; feature extraction; human; intermethod comparison; knowledge discovery; knowledgeable diagnostic transformer; large language model; Mandarin (language); national health organization; natural language processing; noise; performance indicator; prediction; preliminary data; quality control; symptom; total quality management; benchmarking; knowledge base; language; patient referral; power supply; United States; Diagnosis},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Wang202419206,
	author = {Wang, Yu and Lipka, Nedim and Rossi, Ryan A. and Siu, Alexa and Zhang, Ruiyi and Derr, Tyler},
	title = {Knowledge Graph Prompting for Multi-Document Question Answering},
	year = {2024},
	journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
	volume = {38},
	number = {17},
	pages = {19206 – 19214},
	doi = {10.1609/aaai.v38i17.29889},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188263953&doi=10.1609%2faaai.v38i17.29889&partnerID=40&md5=e78bdeb37abd7b343bbf4a79ceda6a83},
	abstract = {The ‘pre-train, prompt, predict’ paradigm of large language models (LLMs) has achieved remarkable success in open-domain question answering (OD-QA). However, few works explore this paradigm in multi-document question answering (MD-QA), a task demanding a thorough understanding of the logical associations among the contents and structures of documents. To fill this crucial gap, we propose a Knowledge Graph Prompting (KGP) method to formulate the right context in prompting LLMs for MD-QA, which consists of a graph construction module and a graph traversal module. For graph construction, we create a knowledge graph (KG) over multiple documents with nodes symbolizing passages or document structures (e.g., pages/tables), and edges denoting the semantic/lexical similarity between passages or document structural relations. For graph traversal, we design an LLM-based graph traversal agent that navigates across nodes and gathers supporting passages assisting LLMs in MD-QA. The constructed graph serves as the global ruler that regulates the transitional space among passages and reduces retrieval latency. Concurrently, the graph traversal agent acts as a local navigator that gathers pertinent context to progressively approach the question and guarantee retrieval quality. Extensive experiments underscore the efficacy of KGP for MD-QA, signifying the potential of leveraging graphs in enhancing the prompt design and retrieval augmented generation for LLMs. Our code: https://github.com/YuWVandy/KG-LLM-MDQA. © 2024, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.},
	keywords = {Air navigation; Graph theory; Semantics; Structural design; Content and structure; Document structure; Graph construction; Graph traversals; Knowledge graphs; Language model; Multidocuments; Multiple documents; Open domain question answering; Question Answering; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 23; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Sampels2024124,
	author = {Sampels, Julian},
	title = {OntoMatch Results for OAEI 2024},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3897},
	pages = {124 – 131},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216387360&partnerID=40&md5=f3574fe259d893ec448d7aeae809d538},
	abstract = {This paper presents the results of OntoMatch in the OAEI 2024 competition. OntoMatch is an ontology matching system that combines graph search algorithms with zero-shot prompting of Large Language Models (LLMs) to produce class correspondences. The system follows an iterative approach involving neighbourhood candidate selection, context extraction using graph search techniques, verbalising of context and zero-shot LLM prompting with templates. Each iteration concludes with a cardinality filter to refine the alignments. OntoMatch was evaluated on the OAEI conference benchmark dataset. The results demonstrate the impact of incorporating graph-based contextual information alongside carefully crafted prompt templates, achieving competitive scores and highlighting the effectiveness of LLM-driven approaches for ontology alignment. © 2024 Copyright for this paper by its authors.},
	author_keywords = {Graph Search; Knowledge Graphs; Large Language Model; Ontology Matching; Prompt Generation},
	keywords = {Modeling languages; Ontology; Zero-shot learning; Graph search; Graph-search algorithms; Iterative approach; Knowledge graphs; Language model; Large language model; Matching system; Neighbourhood; Ontology matching; Prompt generation; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Pradeep20241176,
	author = {Pradeep, Ronak and Lee, Daniel and Mousavi, Ali and Pound, Jeff and Sang, Yisi and Lin, Jimmy and Ilyas, Ihab and Potdar, Saloni and Arefiyan, Mostafa and Li, Yunyao},
	title = {ConvKGYarn: Spinning Configurable and Scalable Conversational Knowledge Graph QA Datasets with Large Language Models},
	year = {2024},
	journal = {EMNLP 2024 - 2024 Conference on Empirical Methods in Natural Language Processing, Proceedings of the Industry Track},
	pages = {1176 – 1206},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216757590&partnerID=40&md5=def5e576fcbc06a2c67d101cdfb7cab2},
	abstract = {The rapid evolution of Large Language Models (LLMs) and conversational assistants necessitates dynamic, scalable, and configurable conversational datasets for training and evaluation. These datasets must accommodate diverse user interaction modes, including text and voice, each presenting unique modeling challenges. Knowledge Graphs (KGs), with their structured and evolving nature, offer an ideal foundation for current and precise knowledge. Although human-curated KG-based conversational datasets exist, they struggle to keep pace with the rapidly changing user information needs. We present ConvKGYarn, a scalable method for generating up-to-date and configurable conversational KGQA datasets. Qualitative psychometric analyses demonstrate ConvKGYarn’s effectiveness in producing high-quality data comparable to popular conversational KGQA datasets across various metrics. ConvKGYarn excels in adhering to human interaction configurations and operating at a significantly larger scale. We showcase ConvKGYarn’s utility by testing LLMs on diverse conversations — exploring model behavior on conversational KGQA sets with different configurations grounded in the same KG fact set. Our results highlight the ability of ConvKGYarn to improve KGQA foundations and evaluate parametric knowledge of LLMs, thus offering a robust solution to the constantly evolving landscape of conversational assistants. © 2024 Association for Computational Linguistics.},
	keywords = {Ability testing; Computational linguistics; 'current; Graph-based; High quality data; Interaction modes; Knowledge graphs; Language model; Psychometric analysis; Scalable methods; User information need; User interaction; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Rajjoub2024998,
	author = {Rajjoub, Rami and Arroyave, Juan Sebastian and Zaidat, Bashar and Ahmed, Wasil and Mejia, Mateo Restrepo and Tang, Justin and Kim, Jun S. and Cho, Samuel K.},
	title = {ChatGPT and its Role in the Decision-Making for the Diagnosis and Treatment of Lumbar Spinal Stenosis: A Comparative Analysis and Narrative Review},
	year = {2024},
	journal = {Global Spine Journal},
	volume = {14},
	number = {3},
	pages = {998 – 1017},
	doi = {10.1177/21925682231195783},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167623905&doi=10.1177%2f21925682231195783&partnerID=40&md5=6ad5ffca712170a9ca64415faa05cd2b},
	abstract = {Study Design: Comparative Analysis and Narrative Review. Objective: To assess and compare ChatGPT’s responses to the clinical questions and recommendations proposed by The 2011 North American Spine Society (NASS) Clinical Guideline for the Diagnosis and Treatment of Degenerative Lumbar Spinal Stenosis (LSS). We explore the advantages and disadvantages of ChatGPT’s responses through an updated literature review on spinal stenosis. Methods: We prompted ChatGPT with questions from the NASS Evidence-based Clinical Guidelines for LSS and compared its generated responses with the recommendations provided by the guidelines. A review of the literature was performed via PubMed, OVID, and Cochrane on the diagnosis and treatment of lumbar spinal stenosis between January 2012 and April 2023. Results: 14 questions proposed by the NASS guidelines for LSS were uploaded into ChatGPT and directly compared to the responses offered by NASS. Three questions were on the definition and history of LSS, one on diagnostic tests, seven on non-surgical interventions and three on surgical interventions. The review process found 40 articles that were selected for inclusion that helped corroborate or contradict the responses that were generated by ChatGPT. Conclusions: ChatGPT’s responses were similar to findings in the current literature on LSS. These results demonstrate the potential for implementing ChatGPT into the spine surgeon’s workplace as a means of supporting the decision-making process for LSS diagnosis and treatment. However, our narrative summary only provides a limited literature review and additional research is needed to standardize our findings as means of validating ChatGPT’s use in the clinical space. © The Author(s) 2023.},
	author_keywords = {artificial intelligence; clinical guidelines; decision-making; large language models; lumbar stenosis; spine},
	keywords = {acetylsalicylic acid; anticonvulsive agent; antidepressant agent; corticosteroid; duloxetine; endorphin; gabapentin; ibuprofen; naproxen; nonsteroid antiinflammatory agent; paracetamol; adult; aerobic exercise; analgesia; artificial intelligence; atrophy; claudication; Cochrane Library; decision making; decompression; diagnostic imaging; electromyography; electrostimulation; functional electrical stimulation; human; large language model; lumbar puncture; lumbar spinal stenosis; manipulative medicine; medical ontology; Medline; myelography; nerve root; neurogenic claudication; neuromuscular electrical stimulation; neuropathic pain; nuclear magnetic resonance imaging; paresthesia; practice guideline; prognosis; questionnaire; radicular pain; range of motion; Review; spinal cord disease; spine; spine fusion; spine manipulation; spine surgery; spondylolisthesis; surgeon; systematic review; transcutaneous electrical nerve stimulation; vertebral canal stenosis; weakness; X ray; x-ray computed tomography},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 36; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Roy202423823,
	author = {Roy, Kaushik and Khandelwal, Vedant and Vera, Valerie and Surana, Harshul and Heckman, Heather and Sheth, Amit},
	title = {GEAR-Up: Generative AI and External Knowledge-based Retrieval Upgrading Scholarly Article Searches for Systematic Reviews},
	year = {2024},
	journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
	volume = {38},
	number = {21},
	pages = {23823 – 23825},
	doi = {10.1609/aaai.v38i21.30577},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189626120&doi=10.1609%2faaai.v38i21.30577&partnerID=40&md5=7c8e42f66d07c80e96d052afa996c4ac},
	abstract = {This paper addresses the time-intensive nature of systematic reviews (SRs) and proposes a solution leveraging advancements in Generative AI (e.g., ChatGPT) and external knowledge augmentation (e.g., Retrieval-Augmented Generation). The proposed system, GEAR-Up, automates query development and translation in SRs, enhancing efficiency by enriching user queries with context from language models and knowledge graphs. Collaborating with librarians, qualitative evaluations demonstrate improved reproducibility and search strategy quality. Access the demo at https://youtu.be/zMdP56GJ9mU. Copyright © 2024, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.},
	keywords = {Knowledge management; External knowledge; Knowledge based; Knowledge graphs; Language model; Qualitative evaluations; Reproducibilities; Scholarly articles; Search strategies; Systematic Review; User query; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Caufield2024,
	author = {Caufield, J. Harry and Hegde, Harshad and Emonet, Vincent and Harris, Nomi L. and Joachimiak, Marcin P. and Matentzoglu, Nicolas and Kim, HyeongSik and Moxon, Sierra and Reese, Justin T. and Haendel, Melissa A. and Robinson, Peter N. and Mungall, Christopher J.},
	title = {Structured Prompt Interrogation and Recursive Extraction of Semantics (SPIRES): a method for populating knowledge bases using zero-shot learning},
	year = {2024},
	journal = {Bioinformatics},
	volume = {40},
	number = {3},
	doi = {10.1093/bioinformatics/btae104},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187509853&doi=10.1093%2fbioinformatics%2fbtae104&partnerID=40&md5=3b73e6f32cdb9ac1da5db4715f565f4a},
	abstract = {Motivation: Creating knowledge bases and ontologies is a time consuming task that relies on manual curation. AI/NLP approaches can assist expert curators in populating these knowledge bases, but current approaches rely on extensive training data, and are not able to populate arbitrarily complex nested knowledge schemas. Results: Here we present Structured Prompt Interrogation and Recursive Extraction of Semantics (SPIRES), a Knowledge Extraction approach that relies on the ability of Large Language Models (LLMs) to perform zero-shot learning and general-purpose query answering from flexible prompts and return information conforming to a specified schema. Given a detailed, user-defined knowledge schema and an input text, SPIRES recursively performs prompt interrogation against an LLM to obtain a set of responses matching the provided schema. SPIRES uses existing ontologies and vocabularies to provide identifiers for matched elements. We present examples of applying SPIRES in different domains, including extraction of food recipes, multispecies cellular signaling pathways, disease treatments, multi-step drug mechanisms, and chemical to disease relationships. Current SPIRES accuracy is comparable to the mid-range of existing Relation Extraction methods, but greatly surpasses an LLM’s native capability of grounding entities with unique identifiers. SPIRES has the advantage of easy customization, flexibility, and, crucially, the ability to perform new tasks in the absence of any new training data. This method supports a general strategy of leveraging the language interpreting capabilities of LLMs to assemble knowledge bases, assisting manual knowledge curation and acquisition while supporting validation with publicly-available databases and ontologies external to the LLM. Availability and implementation: SPIRES is available as part of the open source OntoGPT package: https://github.com/monarch-initiative/ontogpt. © The Author(s) 2024.},
	keywords = {Databases, Factual; Knowledge Bases; Semantics; factual database; knowledge base; semantics},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 16; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Baek20243355,
	author = {Baek, Jinheon and Chandrasekaran, Nirupama and Cucerzan, Silviu and Herring, Allen and Jauhar, Sujay Kumar},
	title = {Knowledge-Augmented Large Language Models for Personalized Contextual Query Suggestion},
	year = {2024},
	journal = {WWW 2024 - Proceedings of the ACM Web Conference},
	pages = {3355 – 3366},
	doi = {10.1145/3589334.3645404},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192838064&doi=10.1145%2f3589334.3645404&partnerID=40&md5=bf52f9a81d67b22aba4d4eb9a4533795},
	abstract = {Large Language Models (LLMs) excel at tackling various natural language tasks. However, due to the significant costs involved in re-training or fine-tuning them, they remain largely static and difficult to personalize. Nevertheless, a variety of applications could benefit from generations that are tailored to users' preferences, goals, and knowledge. Among them is web search, where knowing what a user is trying to accomplish, what they care about, and what they know can lead to improved search experiences. In this work, we propose a novel and general approach that augments an LLM with relevant context from users' interaction histories with a search engine in order to personalize its outputs. Specifically, we construct an entity-centric knowledge store for each user based on their search and browsing activities on the web, which is then leveraged to provide contextually relevant LLM prompt augmentations. This knowledge store is light-weight, since it only produces user-specific aggregate projections of interests and knowledge onto public knowledge graphs, and leverages existing search log infrastructure, thereby mitigating the privacy, compliance, and scalability concerns associated with building deep user profiles for personalization. We validate our approach on the task of contextual query suggestion, which requires understanding not only the user's current search context but also what they historically know and care about. Through a number of experiments based on human evaluation, we show that our approach is significantly better than several other LLM-powered baselines, generating query suggestions that are contextually more relevant, personalized, and useful. © 2024 Owner/Author.},
	author_keywords = {contextual query suggestion; entity-centric knowledge; large language models; personalization},
	keywords = {Computational linguistics; Information retrieval; Knowledge graph; Knowledge management; Search engines; Contextual query suggestion; Entity-centric knowledge; Excel; Fine tuning; Knowledge stores; Language model; Large language model; Natural languages; Personalizations; Query suggestion; User profile},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Green Open Access}
}

@ARTICLE{Dey2024,
	author = {Dey, Lipika},
	title = {Knowledge graph-driven data processing for business intelligence},
	year = {2024},
	journal = {Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery},
	volume = {14},
	number = {3},
	doi = {10.1002/widm.1529},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184903765&doi=10.1002%2fwidm.1529&partnerID=40&md5=35eb9731511f94275d66ae595543417d},
	abstract = {With proliferation of Big Data, organizational decision making has also become more complex. Business Intelligence (BI) is no longer restricted to querying about marketing and sales data only. It is more about linking data from disparate applications and also churning through large volumes of unstructured data like emails, call logs, social media, News, and so on in an attempt to derive insights that can also provide actionable intelligence and better inputs for future strategy making. Semantic technologies like knowledge graphs have proved to be useful tools that help in linking disparate data sources intelligently and also enable reasoning through complex networks that are created as a result of this linking. Over the last decade the process of creation, storage, and maintenance of knowledge graphs have sufficiently matured, and they are now making inroads into business decision making also. Very recently, these graphs are also seen as a potential way to reduce hallucinations of large language models, by including these during pre-training as well as generation of output. There are a number of challenges also. These include building and maintaining the graphs, reasoning with missing links, and so on. While these remain as open research problems, we present in this article a survey of how knowledge graphs are currently used for deriving business intelligence with use-cases from various domains. This article is categorized under: Algorithmic Development > Text Mining Application Areas > Business and Industry. © 2024 Wiley Periodicals LLC.},
	author_keywords = {business intelligence; business text processing; knowledge graphs; natural language QA},
	keywords = {Complex networks; Data handling; Decision making; Digital storage; Graphic methods; Information analysis; Knowledge graph; Semantics; Business text processing; Business-intelligence; Knowledge graphs; Large volumes; Natural language QA; Natural languages; Organizational decision making; Social media; Text-processing; Unstructured data; Text processing},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Han2024631,
	author = {Han, Dongrui and Cui, Mingyu and Kang, Jiawen and Wu, Xixin and Liu, Xunying and Meng, Helen},
	title = {Improving Grapheme-to-Phoneme Conversion through In-Context Knowledge Retrieval with Large Language Models},
	year = {2024},
	journal = {2024 14th International Symposium on Chinese Spoken Language Processing, ISCSLP 2024},
	pages = {631 – 635},
	doi = {10.1109/ISCSLP63861.2024.10800392},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216431620&doi=10.1109%2fISCSLP63861.2024.10800392&partnerID=40&md5=e60cd917ebbd19fb01524fa672a42704},
	abstract = {Grapheme-to-phoneme (G2P) conversion is a crucial step in Text-to-Speech (TTS) systems, responsible for mapping grapheme to corresponding phonetic representations. However, it faces ambiguities problems where the same grapheme can represent multiple phonemes depending on contexts, posing a challenge for G2P conversion. Inspired by the remarkable success of Large Language Models (LLMs) in handling context-aware scenarios, contextual G2P conversion systems with LLMs’ in-context knowledge retrieval (ICKR) capabilities are proposed to promote disambiguation capability. The efficacy of incorporating ICKR into G2P conversion systems is demonstrated thoroughly on the Librig2p dataset. In particular, the best contextual G2P conversion system using ICKR outperforms the baseline with weighted average phoneme error rate (PER) reductions of 2.0% absolute (28.9% relative). Using GPT-4 in the ICKR system can increase of 3.5% absolute (3.8% relative) on the Librig2p dataset. ©2024 IEEE.},
	author_keywords = {Grapheme-to-Phoneme; In-context; Large Language Model; Text-to-Speech},
	keywords = {Linguistics; Modeling languages; Conversion systems; Grapheme to phonemes; Grapheme-to-phoneme conversion; In contexts; Knowledge retrieval; Language model; Large language model; Phonetic representation; Text to speech; Text-to-speech system; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@CONFERENCE{Chan2024991,
	author = {Chan, Robin and Mirylenka, Katsiaryna and Gschwind, Thomas and Miksovic-Czasch, Christoph and Scotton, Paolo and Toniato, Enrico and Labbi, Abdel},
	title = {Adapting LLMs for Structured Natural Language API Integration},
	year = {2024},
	journal = {EMNLP 2024 - 2024 Conference on Empirical Methods in Natural Language Processing, Proceedings of the Industry Track},
	pages = {991 – 1000},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216736999&partnerID=40&md5=f86f8dfe679525f9764a561783d8c19b},
	abstract = {API integration is crucial for enterprise systems, as it enables seamless interaction between applications within workflows. However, the diversity and complexity of the API landscape present significant challenges in combining API calls based on user intent. Existing methods rely on named entity recognition (NER) and knowledge graphs, but struggle to generate more complex control flow structures, such as conditionals and loops. We propose a novel framework that leverages the success of large language models (LLMs) in code generation to integrate APIs based on natural language input. Our approach involves fine-tuning an LLM using automatically generated API flows derived from OpenAPI specifications. We further evaluate the effectiveness of enforcing the syntax and schema adherence through constrained decoding. To enable systematic comparison, we introduce targeted test suites to assess the generalization capabilities of these approaches and their ability to retain structured knowledge. Our findings show that LLMs fine-tuned on OpenAPI specifications can (a) learn structural API constraints implicitly during training, and (b) achieve significant improvements in both in-distribution and out-of-distribution performance over NER and retrieval-augmented generation (RAG)-based approaches. © 2024 Association for Computational Linguistics.},
	keywords = {Application programming interfaces (API); Flow graphs; Knowledge graph; Modeling languages; Natural language processing systems; API calls; Codegeneration; Complex control flow; Control-flow structures; Enterprise system; Knowledge graphs; Language model; Named entity recognition; Natural languages; Work-flows; Computational linguistics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Zhang2024,
	author = {Zhang, Yichong and Hao, Yongtao},
	title = {Traditional Chinese Medicine Knowledge Graph Construction Based on Large Language Models},
	year = {2024},
	journal = {Electronics (Switzerland)},
	volume = {13},
	number = {7},
	doi = {10.3390/electronics13071395},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190297966&doi=10.3390%2felectronics13071395&partnerID=40&md5=a355efd9b59e912d3ee75ec3fbab3352},
	abstract = {This study explores the use of large language models in constructing a knowledge graph for Traditional Chinese Medicine (TCM) to improve the representation, storage, and application of TCM knowledge. The knowledge graph, based on a graph structure, effectively organizes entities, attributes, and relationships within the TCM domain. By leveraging large language models, we collected and embedded substantial TCM–related data, generating precise representations transformed into a knowledge graph format. Experimental evaluations confirmed the accuracy and effectiveness of the constructed graph, extracting various entities and their relationships, providing a solid foundation for TCM learning, research, and application. The knowledge graph has significant potential in TCM, aiding in teaching, disease diagnosis, treatment decisions, and contributing to TCM modernization. In conclusion, this paper utilizes large language models to construct a knowledge graph for TCM, offering a vital foundation for knowledge representation and application in the field, with potential for future expansion and refinement. © 2024 by the authors.},
	author_keywords = {interdisciplinary research; knowledge graph; large language modeling; traditional Chinese medicine},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; All Open Access, Gold Open Access}
}

@ARTICLE{Yang2024,
	author = {Yang, Tian and Mei, Yupeng and Xu, Ling and Yu, Huihui and Chen, Yingyi},
	title = {Application of question answering systems for intelligent agriculture production and sustainable management: A review},
	year = {2024},
	journal = {Resources, Conservation and Recycling},
	volume = {204},
	doi = {10.1016/j.resconrec.2024.107497},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185550710&doi=10.1016%2fj.resconrec.2024.107497&partnerID=40&md5=dfafd31e61cbb849ff97cf0d5062e5bd},
	abstract = {The increasing application of artificial intelligence in agriculture production and management has generated a large amount of data, leading to a demand for processing this data. This review focuses on the knowledge storage approaches in agricultural question answering systems, namely corpora, knowledge graphs, and large language models. These systems are built on massive amounts of data and aim to process and retrieve information effectively in the context of sustainable agriculture. Corpora refer to large collections of diverse documents that serve as foundational resources for training and fine-tuning question answering systems. Knowledge graphs capture structured and interconnected knowledge by representing entities, relationships, and attributes, enabling efficient organization and querying of information. Large language models, such as GPT-4, enhance the capacity of question answering systems to provide accurate and relevant responses. By exploring these three prominent knowledge storage approaches, this review analyses the methodology and impact of agricultural question answering systems, highlighting their applications in the production process. The findings provide important implications for future research in agriculture, and potential directions for further exploration. © 2024},
	author_keywords = {Intelligent agriculture; Knowledge graphs; Large language models; Question answering system},
	keywords = {Agriculture; Computational linguistics; Data handling; Digital storage; Information management; Agriculture management; Agriculture productions; Intelligent agriculture; Knowledge graphs; Knowledge storage; Language model; Large language model; Production management; Question answering systems; Sustainable management; accuracy assessment; agricultural management; agricultural production; agricultural research; agricultural technology; alternative agriculture; artificial intelligence; data processing; demand analysis; information and communication technology; machine learning; technology adoption; training; agriculture; Article; data analysis; decision making; diagnosis; information processing; knowledge; large language model; methodology; pest control; prediction; sustainable agriculture; Knowledge graph},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9}
}

@CONFERENCE{Venkatakrishnan2024605,
	author = {Venkatakrishnan, Radhakrishnan and Tanyildizi, Emrah and Canbaz, M. Abdullah},
	title = {Semantic interlinking of Immigration Data using LLMs for Knowledge Graph Construction},
	year = {2024},
	journal = {WWW 2024 Companion - Companion Proceedings of the ACM Web Conference},
	pages = {605 – 608},
	doi = {10.1145/3589335.3651557},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194462152&doi=10.1145%2f3589335.3651557&partnerID=40&md5=8fa4c8869a1051976b14b398ec6a7002},
	abstract = {The challenge of managing immigration data is exacerbated by its reliance on paper-based, evidence-driven records maintained by legal professionals, creating obstacles for efficient processing and analysis due to inherent trust issues with AI-based systems. This paper introduces a cutting-edge framework to surmount these hurdles by synergizing Large Language Models (LLMs) with Knowledge Graphs (KGs), revolutionizing traditional data handling methods. Our method transforms archaic, paper-based immigration records into a structured, interconnected knowledge network that intricately mirrors the legal and procedural nuances of immigration, ensuring a dynamic and trustworthy platform for data analysis. Utilizing LLMs, we extract vital entities and relationships from diverse legal documents to forge a comprehensive knowledge graph, encapsulating the complex legalities and procedural disparities in immigration processes and mapping the multifaceted interactions among stakeholders like applicants, sponsors, and legal experts. This graph not only facilitates a deep dive into the legal stipulations but also incorporates them, significantly boosting the system’s reliability and precision. With the integration of Retrieval Augmented Generation (RAG) for exact, context-aware data retrieval and Augmented Knowledge Creation for developing a conversational interface via LLMs, our framework offers a scalable, adaptable solution to immigration data management. This innovative amalgamation of LLMs, KGs, and RAG techniques marks a paradigm shift towards more informed, efficient, and trustworthy decision-making in the sphere of global migration, setting a new benchmark for legal technology and data source management. © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.},
	author_keywords = {Data Restructuring; Document Processing; Information Retrieval; Knowledge Graphs; Large Language Models; Legal Tech},
	keywords = {Computational linguistics; Data handling; Information management; Knowledge graph; Semantics; Cutting edges; Data restructuring; Document-processing; Graph construction; Knowledge graphs; Knowledge networks; Language model; Large language model; Legal documents; Legal tech; Decision making},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Bronze Open Access}
}

@CONFERENCE{Jayawardena2024196,
	author = {Jayawardena, Lasal and Yapa, Prasan},
	title = {Improving Quality and Domain-Relevancy of Paraphrase Generation with Graph-Based Retrieval Augmented Generation},
	year = {2024},
	journal = {ACM International Conference Proceeding Series},
	pages = {196 – 208},
	doi = {10.1145/3669754.3669784},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203793959&doi=10.1145%2f3669754.3669784&partnerID=40&md5=0a8f9a984baf094f886cbdd36d160bcb},
	abstract = {Paraphrase generation is a fundamental area of research in Natural Language Processing (NLP) and Natural Language Generation (NLG), due to its sequence-to-sequence (Seq2Seq) nature. Paraphrasing, spanning across various domains, poses challenges for simpler model architectures due to the extensive knowledge required to generate paraphrases. The added constraint of generating diverse paraphrases further complicates the task for models trained on existing datasets. We present a methodology that leverages Graph-Based Retrieval Augmented Generation (G-RAG), capable of utilizing both entity and phrasal knowledge to address this issue. We demonstrate through experiments that this approach enables both complex models like Large Language models (LLMs) and smaller Seq2Seq models to generate more diverse paraphrases without compromising semantic similarity. Furthermore, this approach's capacity to integrate domain-specific knowledge makes it particularly effective across different domains, enhancing its applicability in varied contexts. The results are further corroborated by human evaluation and extensive quantitative analysis focusing on semantic similarity, lexical diversity, syntactic diversity, and grammatical correctness to gauge high-quality paraphrases. © 2024 ACM.},
	author_keywords = {Graph-based Knowledge; Large Language Models; Natural Language Processing; Paraphrase Generation; Sequence-to-Sequence Models},
	keywords = {Domain Knowledge; Knowledge graph; Natural language processing systems; Graph-based; Graph-based knowledge; Language model; Language processing; Large language model; Natural language processing; Natural languages; Paraphrase generation; Sequence models; Sequence-to-sequence model; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{He2024,
	author = {He, Lianlian and Li, Hao and Zhang, Rui},
	title = {A Semantic-Spatial Aware Data Conflation Approach for Place Knowledge Graphs},
	year = {2024},
	journal = {ISPRS International Journal of Geo-Information},
	volume = {13},
	number = {4},
	doi = {10.3390/ijgi13040106},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191751182&doi=10.3390%2fijgi13040106&partnerID=40&md5=908acbefda9dee0ebe2195cc878aeaa7},
	abstract = {Recent advances in knowledge graphs show great promise to link various data together to provide a semantic network. Place is an important part in the big picture of the knowledge graph since it serves as a powerful glue to link any data to its georeference. A key technical challenge in constructing knowledge graphs with location nodes as geographical references is the matching of place entities. Traditional methods typically rely on rule-based matching or machine-learning techniques to determine if two place names refer to the same location. However, these approaches are often limited in the feature selection of places for matching criteria, resulting in imbalanced consideration of spatial and semantic features. Deep feature-based methods such as deep learning methods show great promise for improved place data conflation. This paper introduces a Semantic-Spatial Aware Representation Learning Model (SSARLM) for Place Matching. SSARLM liberates the tedious manual feature extraction step inherent in traditional methods, enabling an end-to-end place entity matching pipeline. Furthermore, we introduce an embedding fusion module designed for the unified encoding of semantic and spatial information. In the experiment, we evaluate the approach to named places from Guangzhou and Shanghai cities in GeoNames, OpenStreetMap (OSM), and Baidu Map. The SSARLM is compared with several classical and commonly used binary classification machine learning models, and the state-of-the-art large language model, GPT-4. The results demonstrate the benefit of pre-trained models in data conflation of named places. © 2024 by the authors.},
	author_keywords = {conflation; knowledge graph; location-based service; place data; place entity matching},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access}
}

@CONFERENCE{Guan202418126,
	author = {Guan, Xinyan and Liu, Yanjiang and Lin, Hongyu and Lu, Yaojie and He, Ben and Han, Xianpei and Sun, Le},
	title = {Mitigating Large Language Model Hallucinations via Autonomous Knowledge Graph-Based Retrofitting},
	year = {2024},
	journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
	volume = {38},
	number = {16},
	pages = {18126 – 18134},
	doi = {10.1609/aaai.v38i16.29770},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185659420&doi=10.1609%2faaai.v38i16.29770&partnerID=40&md5=8b12d5b5710ae43301461a9f67a41d65},
	abstract = {Incorporating factual knowledge in knowledge graph is regarded as a promising approach for mitigating the hallucination of large language models (LLMs). Existing methods usually only use the user’s input to query the knowledge graph, thus failing to address the factual hallucination generated by LLMs during its reasoning process. To address this problem, this paper proposes Knowledge Graph-based Retrofitting (KGR), a new framework that incorporates LLMs with KGs to mitigate factual hallucination during the reasoning process by retrofitting the initial draft responses of LLMs based on the factual knowledge stored in KGs. Specifically, KGR leverages LLMs to extract, select, validate, and retrofit factual statements within the model-generated responses, which enables an autonomous knowledge verifying and refining procedure without any additional manual efforts. Experiments show that KGR can significantly improve the performance of LLMs on factual QA benchmarks especially when involving complex reasoning processes, which demonstrates the necessity and effectiveness of KGR in mitigating hallucination and enhancing the reliability of LLMs. Copyright © 2024, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.},
	keywords = {Benchmarking; Computational linguistics; Graphic methods; Retrofitting; Effectiveness of knowledge; Factual knowledge; Graph-based; Knowledge graphs; Language model; Model-based OPC; Performance; Reasoning process; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Tian202419080,
	author = {Tian, Yijun and Song, Huan and Wang, Zichen and Wang, Haozhu and Hu, Ziqing and Wang, Fang and Chawla, Nitesh V. and Xu, Panpan},
	title = {Graph Neural Prompting with Large Language Models},
	year = {2024},
	journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
	volume = {38},
	number = {17},
	pages = {19080 – 19088},
	doi = {10.1609/aaai.v38i17.29875},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185803457&doi=10.1609%2faaai.v38i17.29875&partnerID=40&md5=7db44360ec0406f99fd74f888e6343ff},
	abstract = {Large language models (LLMs) have shown remarkable generalization capability with exceptional performance in various language modeling tasks. However, they still exhibit inherent limitations in precisely capturing and returning grounded knowledge. While existing work has explored utilizing knowledge graphs (KGs) to enhance language modeling via joint training and customized model architectures, applying this to LLMs is problematic owing to their large number of parameters and high computational cost. Therefore, how to enhance pre-trained LLMs using grounded knowledge, e.g., retrieval-augmented generation, remains an open question. In this work, we propose Graph Neural Prompting (GNP), a novel plug-and-play method to assist pre-trained LLMs in learning beneficial knowledge from KGs. GNP encompasses various designs, including a standard graph neural network encoder, a cross-modality pooling module, a domain projector, and a self-supervised link prediction objective. Extensive experiments on multiple datasets demonstrate the superiority of GNP on both commonsense and biomedical reasoning tasks across different LLM sizes and settings. Code is available at https://github.com/meettyj/GNP. © 2024, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.},
	keywords = {Computational linguistics; Knowledge graph; Modeling languages; Computational costs; Generalization capability; Graph neural networks; Inherent limitations; Knowledge graphs; Language model; Modeling architecture; Modeling task; Performance; Plug-and-play; Graph neural networks},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Derin20241890,
	author = {Derin, Mehmet Oguz and Uçar, Erdem and Yergesh, Banu and Shimada, Yuki and Hong, Youjin and Lin, Xin-Yu},
	title = {Evaluating the Impact of Model Size on Multilingual JSON Structuring for Knowledge Graphs with Recent LLMs},
	year = {2024},
	journal = {Proceedings of the IEEE 3rd International Conference on Problems of Informatics, Electronics and Radio Engineering, PIERE 2024},
	pages = {1890 – 1895},
	doi = {10.1109/PIERE62470.2024.10805070},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216536851&doi=10.1109%2fPIERE62470.2024.10805070&partnerID=40&md5=c77cdc2bfab828b77eb5803be518b3bf},
	abstract = {This study investigates the impact of model size on the multilingual JSON structuring capabilities of commercial Large Language Models (LLMs) for Knowledge Graph creation, emphasizing the integration of expert feedback and in-context learning. Focusing on Old Uyghur and Old Turkic as the subject language and various study or work languages, including Japanese and Kazakh, we evaluated the performance of the latest generation LLMs of two sizes within the same family in structuring complex philological plain text. Our methodology involved a comparative analysis of LLM performance across different model sizes and languages, incorporating expert feedback and in-context learning techniques through a custom-built annotation tool to anonymize the specific LLM size for fair evaluation and integrate structurization and structure translation. Our findings indicate that smaller models can perform comparably to larger, more costly models in JSON structuring tasks when leveraging expert feedback and in-context learning despite struggling with the quality of initial structurization. This trend was consistent across the evaluated work languages, albeit with some performance variations. The study underscores the significant potential of in-context learning and expert feedback in enhancing LLMs' structuring capabilities, particularly for under-resourced languages with unstructured yet comprehensive publications. These results have important implications for efficient and cost-effective Knowledge Graph creation in multilingual contexts, offering new avenues for processing and integrating complex philological data into structured, machine-readable formats. © 2024 IEEE.},
	author_keywords = {GPT-4o; In-Context Learning; Knowledge Graphs; Large Language Models (LLMs); Multilingual Structuring},
	keywords = {Adversarial machine learning; Contrastive Learning; Economic and social effects; Modeling languages; Translation (languages); Context learning; Expert feedback; GPT-4o; In contexts; In-context learning; Knowledge graphs; Language model; Large language model; Model size; Multilingual structuring; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Baldazzi2024834,
	author = {Baldazzi, Teodoro and Bellomarini, Luigi and Ceri, Stefano and Colombo, Andrea and Gentili, Andrea and Sallinger, Emanuel},
	title = {“Please, Vadalog, tell me why”: Interactive Explanation of Datalog-based Reasoning},
	year = {2024},
	journal = {Advances in Database Technology - EDBT},
	volume = {27},
	number = {3},
	pages = {834 – 837},
	doi = {10.48786/edbt.2024.82},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191027240&doi=10.48786%2fedbt.2024.82&partnerID=40&md5=223927d70e94f058453dc38376d1a403},
	abstract = {Integrating Large Language Models (LLMs) with logic-based Enterprise Knowledge Graphs (EKGs) and more generally with Knowledge Representation and Reasoning (KRR) approaches is currently at the forefront of research in many data-intensive areas, as language models may complement EKGs and ontological reasoning with flexibility and human orientation. Conversely, EKGs provide transparency and explainability on the conclusions drawn, a typical weak point of LLMs, which operate opaquely. In this demo, we integrate Llama 2 with our reasoning system Vadalog and use it to turn a chase graph, i.e., the trace of an ontological reasoning process, into a human-readable business report. In other words, we show the amazing capabilities of state-of-the-art LLMs in combination with a principled exploitation of the theoretical underpinnings of logic-based reasoning. We walk the audience through a visual environment, unfolding real-world reasoning settings from the Central Bank of Italy. © 2024 Copyright held by the owner/author(s).},
	keywords = {Computer circuits; Knowledge graph; Ontology; Based reasonings; Data intensive; Datalog; Human orientation; Knowledge graphs; Knowledge representation and reasoning; Language model; Ontological reasoning; Reasoning approach; Weak points; Computational linguistics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@BOOK{Cupitt2024214,
	author = {Cupitt, Rebekah},
	title = {Sympoietics: The Co-mingling of Creative Agents},
	year = {2024},
	journal = {Queer and Trans Life: Anthropological Futures},
	pages = {214 – 246},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216651803&partnerID=40&md5=4a68323b4b01a149596f4d685ccff91e},
	abstract = {While the hype and the real harms of generative artificial intelligence (generative AI) make headlines (Coleman 2023; Gedeon and Miller 2024; Shtaya 2022) and occupy important scholarly debate (Dhar 2020; Gonzalez 2024; Tamburrini 2022), this chapter examines how the mundane use of generative AI can nevertheless be useful in reformulating anthropocentric epistemologies and ontologies. The gambit is that a close reading of human-AI relationalities allows us to rethink the bounds of the human as well as the non-humanness of AI. This in turn opens up for a way of seeing technology and its harms as originating in the human without oversimplifying the complex, sociotechnical processes of human–non-human interactions that are the (re-) producers of ‘bias’. While illustrating instances of bias, violence and exclusion enacted through technologies is a critical first step, it leads to battles about responsibility, origination, and creates spaces where identifying accountability is difficult (Padovan et al. 2023; Widder and Nafus 2023). Legal battles about responsibility demonstrate how adept humans and our legal systems are at escaping culpability (Hacker 2023). The current discourse on generative AI as bias is one part of a sociocultural reality of AI which focuses on the all-important steps of increasing visibility of discrimination and awareness of a problem. Another part is making sure we understand the dynamic range of human–non-human intra-actions so we can redress bias in all contexts – in the labs as well as in everyday lives. As Suchman (2023) puts it, we need tools to revise the ‘uncontroversial “thingness”’ to do this, and queer anthropology makes a critical contribute to this debate. © 2025 Silvia Posocco, EJ Gonzalez-Polledo, Lars Aaberg and Tunay Altay. All rights reserved.},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Liu20241294,
	author = {Liu, Lihui and Wang, Zihao and Bai, Jiaxin and Song, Yangqiu and Tong, Hanghang},
	title = {New Frontiers of Knowledge Graph Reasoning: Recent Advances and Future Trends},
	year = {2024},
	journal = {WWW 2024 Companion - Companion Proceedings of the ACM Web Conference},
	pages = {1294 – 1297},
	doi = {10.1145/3589335.3641254},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194466071&doi=10.1145%2f3589335.3641254&partnerID=40&md5=f943a936e07b629871aebe8e983041ce},
	abstract = {Knowledge graph reasoning plays an important role in data mining, AI, Web, and social science. These knowledge graphs serve as intuitive repositories of human knowledge, allowing for the inference of new information. However, traditional symbolic reasoning, while powerful in its own right, faces challenges posed by incomplete and noisy data in the knowledge graphs. In contrast, recent years have witnessed the emergence of Neural Symbolic AI, an exciting development that fuses the capabilities of deep learning and symbolic reasoning. It aims to create AI systems that are not only highly interpretable and explainable but also incredibly versatile, effectively bridging the gap between symbolic and neural approaches. Furthermore, with the advent of large language models, the integration of LLMs with knowledge graph reasoning has emerged as a prominent frontier, offering the potential to unlock unprecedented capabilities. This tutorial aims to comprehensively review different aspects of knowledge graph reasoning applications and also introduce the recent advances about Neural Symbolic reasoning and combining knowledge graph reasoning with large language models. It is intended to benefit researchers and practitioners in the fields of data mining, AI, Web, and social science. © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.},
	author_keywords = {Knowledge graph reasoning},
	keywords = {Behavioral research; Computational linguistics; Data mining; Deep learning; AI systems; Future trends; Human knowledge; Incomplete data; Knowledge graph reasoning; Knowledge graphs; Language model; Noisy data; Symbolic reasoning; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Sophaken2024606,
	author = {Sophaken, Chotanansub and Vongpanich, Kantapong and Intaphan, Wachirawit and Utasri, Tharathon and Deepho, Chutamas and Takhom, Akkharawoot},
	title = {Leveraging Graph-RAG for Enhanced Diagnostic and Treatment Strategies in Dentistry},
	year = {2024},
	journal = {8th International Conference on Information Technology 2024, InCIT 2024},
	pages = {606 – 611},
	doi = {10.1109/InCIT63192.2024.10810521},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216814042&doi=10.1109%2fInCIT63192.2024.10810521&partnerID=40&md5=94f8a62c0975a5f6462b137f1309a1a7},
	abstract = {This paper presents a method for extracting and interpreting information from diverse, unstructured dental literature using advanced AI techniques. By integrating information extraction, ontologies, and knowledge graphs, the approach enhances the efficiency and accuracy of dental data analysis. Named Entity Recognition (NER) and a Large Language Model (LLM) are employed to extract relevant entities and relationships, which are then structured into triples and integrated with a dental ontology to ensure contextual relevance. This enriched ontology supports Retrieval-Augmented Generation (RAG) applications, enabling advanced querying and analysis. The methodology improves the identification and categorization of dental conditions, treatments, and anatomical terms, providing a structured representation of dental knowledge. Knowledge graphs facilitate the representation and analysis of relationships between entities, fostering insightful interpretations and supporting hypothesis generation, thereby enhancing the accessibility and usability of dental knowledge. Experimental results demonstrate the effectiveness of this approach in managing complex dental information, showcasing the benefits of combining Knowledge Representation (KR) with Machine Learning (ML). This research contributes to dental studies by offering a robust framework for extracting and utilizing knowledge from diverse and extensive datasets.  © 2024 IEEE.},
	author_keywords = {Dental Literature; Dentistry; Information Extraction; Knowledge Graphs; Large Language Models; Ontologies; Oral Health},
	keywords = {Dentistry; Diagnosis; Ontology; Structured Query Language; AI techniques; Dental literature; Extraction ontologies; Information extraction; Integrating information; Knowledge graphs; Language model; Large language model; Ontology's; Oral healths; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Shi20242159,
	author = {Shi, Jingchuan and Dong, Hang and Chen, Jiaoyan and Wu, Zhe and Horrocks, Ian},
	title = {Taxonomy Completion via Implicit Concept Insertion},
	year = {2024},
	journal = {WWW 2024 - Proceedings of the ACM Web Conference},
	pages = {2159 – 2169},
	doi = {10.1145/3589334.3645584},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194098825&doi=10.1145%2f3589334.3645584&partnerID=40&md5=2869630674e67c7ce0e36468a9d76d26},
	abstract = {\beginabstract High quality taxonomies play a critical role in various domains such as e-commerce, web search and ontology engineering. While there has been extensive work on expanding taxonomies from externally mined data, there has been less attention paid to enriching taxonomies by exploiting existing concepts and structure within the taxonomy. In this work, we show the usefulness of this kind of enrichment, and explore its viability with a new taxonomy completion system ICON (I mplicit CON cept Insertion). ICON generates new concepts by identifying implicit concepts based on the existing concept structure, generating names for such concepts and inserting them in appropriate positions within the taxonomy. ICON integrates techniques from entity retrieval, text summary, and subsumption prediction; this modular architecture offers high flexibility while achieving state-of-the-art performance. We have evaluated ICON on two e-commerce taxonomies, and the results show that it offers significant advantages over strong baselines including recent taxonomy completion models and the large language model, ChatGPT. © 2024 Owner/Author.},
	author_keywords = {ontology engineering; pre-trained language model; taxonomy completion; taxonomy enrichment; text summarisation},
	keywords = {Computational linguistics; Electronic commerce; Ontology; E- commerces; High quality; Language model; Ontology engineering; Pre-trained language model; Taxonomy completion; Taxonomy enrichment; Text Summarisation; Web ontology; Web searches; Taxonomies},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@ARTICLE{Zafar2024,
	author = {Zafar, Aizan and Sahoo, Sovan Kumar and Bhardawaj, Harsh and Das, Amitava and Ekbal, Asif},
	title = {KI-MAG: A knowledge-infused abstractive question answering system in medical domain},
	year = {2024},
	journal = {Neurocomputing},
	volume = {571},
	doi = {10.1016/j.neucom.2023.127141},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181014592&doi=10.1016%2fj.neucom.2023.127141&partnerID=40&md5=176e9e04431a6574787ad71dc2e87e4c},
	abstract = {Abstractive question-answering (QA) has emerged as a prominent area in Natural Language Processing (NLP) due to its ability to produce concise and human-like responses, particularly with the advancement of Large Language Models. Despite its potential, abstractive QA suffers from challenges like the need for extensive training data and the generation of incorrect entities and out-of-context words in the responses. In safety–critical domains like medical and clinical settings, such issues are unacceptable and may compromise the accuracy and reliability of generated answers. We proposed KI-MAG (Knowledge-Infused Medical Abstractive Generator) model, a novel Knowledge-Infused Abstractive Question Answering System specifically designed for the medical domain. KI-MAG aims to address the aforementioned limitations and enhance the correctness of generated responses while mitigating data sparsity concerns. The KI-MAG system produces more precise and informative answers by incorporating relevant medical entities into the model's generation process. Furthermore, we adopt a synthetic data generation approach using question–answer pairs to overcome the challenge of limited training data in the medical domain. These synthetic pairs augment the original dataset, resulting in better model generalization and improved performance. Our extensive experimental evaluations demonstrate the effectiveness of the KI-MAG system. Compared to traditional abstractive QA models, our approach exhibits a substantial increase of approximately 15% in Blue-1, Blue-2, Blue-3, and Blue-4 scores, indicating a remarkable improvement in answer accuracy and overall quality of responses. Overall, our Knowledge-Infused Abstractive Question Answering System in the Medical Domain (KI-MAG) presents a promising solution to enhance the performance and reliability of abstractive QA models in safety–critical medical applications where precision and correctness of answers are of utmost importance. © 2023 Elsevier B.V.},
	author_keywords = {Answer generation; Knowledge filtering; Knowledge graphs; Knowledge infusion; Medical question answering; Pre-trained language models},
	keywords = {Computational linguistics; Knowledge graph; Natural language processing systems; Answer generation; Knowledge filtering; Knowledge graphs; Knowledge infusion; Language model; Medical domains; Medical question answering; Pre-trained language model; Question Answering; Question answering systems; abstractive question answering; Article; ChatGPT; comparative study; controlled study; data accuracy; data error; data processing; data quality; human; information processing; knowledge filtering; knowledge graph; knowledge infused medical abstractive generator; knowledge infusion; language model; medical information; natural language processing; performance; reliability; statistical analysis; validation study; Medical applications},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8}
}

@CONFERENCE{Anaguchi202411,
	author = {Anaguchi, Fumikatsu and Chakraborty, Sudesna and Morita, Takeshi and Egami, Shusaku and Ugai, Takanori and Fukuda, Ken},
	title = {Reasoning and Justification System for Domestic Hazardous Behaviors Based on Knowledge Graph of Daily Activities and Retrieval-Augmented Generation},
	year = {2024},
	journal = {Proceedings - 2024 12th International Symposium on Computing and Networking, CANDAR 2024},
	pages = {11 – 20},
	doi = {10.1109/CANDAR64496.2024.00010},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216925907&doi=10.1109%2fCANDAR64496.2024.00010&partnerID=40&md5=fa0732c1466a26154b582e1c7d8e07e4},
	abstract = {Accidents among people over 65 years of age predominantly occur within residential settings, making the maintenance of a safe home environment a crucial social issue. To address this issue, previous research has developed systems that construct Knowledge Graphs (KG) based on simulations of daily household activities, and studies have been conducted on detecting hazardous behaviors using such KG analysis. In this current study, we propose a system capable of presenting the reason and justification for the detected domestic hazardous behaviors. Our system will first generates the reason for the detected behavior using a Large Language Model (LLM). To ensure the accuracy, reliability and reproducibility of the LLM output, the system will provides reliable sources to support the output. We employed Retrieval-Augmented Generation (RAG) to search for sentences similar to the reason generated by the LLM within reliable, authoritative documents describing domestic accident cases and their causes and these will be presented as the evidence alongside the search engine results to the users. Consequently, a knowledge graph (KG) of domestic hazardous behavior is developed based on evidence ontology. Finally, to evaluate the ability of our proposed system in appropriately generating reasons for domestic hazardous behaviors and the adequacy of the justifications provided, the output was rated using LLMs and human volunteers. The rating results showed a significant correlation between LLMs and human evaluation, indicating that the proposed system can provide sufficient reasons and justifications for domestic hazardous behaviors at residential setting. © 2024 IEEE.},
	author_keywords = {Explainable AI; Knowledge Graph; Large Language Model; Retrieval-Augmented Generation},
	keywords = {Behavior-based; Daily activity; Explainable AI; Graph-based; Home environment; Knowledge graphs; Language model; Large language model; Retrieval-augmented generation; Social issues; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Shang202418934,
	author = {Shang, Ziyu and Ke, Wenjun and Xiu, Nana and Wang, Peng and Liu, Jiajun and Li, Yanhui and Luo, Zhizhao and Ji, Ke},
	title = {OntoFact: Unveiling Fantastic Fact-Skeleton of LLMs via Ontology-Driven Reinforcement Learning},
	year = {2024},
	journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
	volume = {38},
	number = {17},
	pages = {18934 – 18943},
	doi = {10.1609/aaai.v38i17.29859},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186379985&doi=10.1609%2faaai.v38i17.29859&partnerID=40&md5=9ce4e14d6554f47fd26d5dbde1b10668},
	abstract = {Large language models (LLMs) have demonstrated impressive proficiency in information retrieval, while they are prone to generating incorrect responses that conflict with reality, a phenomenon known as intrinsic hallucination. The critical challenge lies in the unclear and unreliable fact distribution within LLMs trained on vast amounts of data. The prevalent approach frames the factual detection task as a question-answering paradigm, where the LLMs are asked about factual knowledge and examined for correctness. However, existing studies primarily focused on deriving test cases only from several specific domains, such as movies and sports, limiting the comprehensive observation of missing knowledge and the analysis of unexpected hallucinations. To address this issue, we propose OntoFact, an adaptive framework for detecting unknown facts of LLMs, devoted to mining the ontology-level skeleton of the missing knowledge. Specifically, we argue that LLMs could expose the ontology-based similarity among missing facts and introduce five representative knowledge graphs (KGs) as benchmarks. We further devise a sophisticated ontology-driven reinforcement learning (ORL) mechanism to produce error-prone test cases with specific entities and relations automatically. The ORL mechanism rewards the KGs for navigating toward a feasible direction for unveiling factual errors. Moreover, empirical efforts demonstrate that dominant LLMs are biased towards answering Yes rather than No, regardless of whether this knowledge is included. To mitigate the overconfidence of LLMs, we leverage a hallucination-free detection (HFD) strategy to tackle unfair comparisons between baselines, thereby boosting the result robustness. Experimental results on 5 datasets, using 32 representative LLMs, reveal a general lack of fact in current LLMs. Notably, ChatGPT exhibits fact error rates of 51.6% on DBpedia and 64.7% on YAGO, respectively. Additionally, the ORL mechanism demonstrates promising error prediction scores, with F1 scores ranging from 70% to 90% across most LLMs. Compared to the exhaustive testing, ORL achieves an average recall of 80% while reducing evaluation time by 35.29% to 63.12%. © 2024, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.},
	keywords = {Errors; Knowledge graph; Musculoskeletal system; Ontology; Critical challenges; Detection tasks; Factual knowledge; Knowledge graphs; Language model; Learning mechanism; Ontology's; Question Answering; Reinforcement learnings; Test case; Reinforcement learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; All Open Access, Gold Open Access}
}

@ARTICLE{Kulmanov2024220,
	author = {Kulmanov, Maxat and Guzmán-Vega, Francisco J. and Duek Roggli, Paula and Lane, Lydie and Arold, Stefan T. and Hoehndorf, Robert},
	title = {Protein function prediction as approximate semantic entailment},
	year = {2024},
	journal = {Nature Machine Intelligence},
	volume = {6},
	number = {2},
	pages = {220 – 228},
	doi = {10.1038/s42256-024-00795-w},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185149701&doi=10.1038%2fs42256-024-00795-w&partnerID=40&md5=dfc454adc1c3d58b5660d449da45f138},
	abstract = {The Gene Ontology (GO) is a formal, axiomatic theory with over 100,000 axioms that describe the molecular functions, biological processes and cellular locations of proteins in three subontologies. Predicting the functions of proteins using the GO requires both learning and reasoning capabilities in order to maintain consistency and exploit the background knowledge in the GO. Many methods have been developed to automatically predict protein functions, but effectively exploiting all the axioms in the GO for knowledge-enhanced learning has remained a challenge. We have developed DeepGO-SE, a method that predicts GO functions from protein sequences using a pretrained large language model. DeepGO-SE generates multiple approximate models of GO, and a neural network predicts the truth values of statements about protein functions in these approximate models. We aggregate the truth values over multiple models so that DeepGO-SE approximates semantic entailment when predicting protein functions. We show, using several benchmarks, that the approach effectively exploits background knowledge in the GO and improves protein function prediction compared to state-of-the-art methods. © The Author(s) 2024.},
	keywords = {Forecasting; Proteins; Semantics; Approximate modeling; Axiomatic theory; Background knowledge; Biological process; Gene ontology; Molecular function; Protein function prediction; Protein functions; Semantic entailment; Truth values; Gene Ontology},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 11; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Mitsuji2024144,
	author = {Mitsuji, Fumiya and Chakraborty, Sudesna and Morita, Takeshi and Egami, Shusaku and Ugai, Takanori and Fukuda, Ken},
	title = {Entity Linking for Wikidata using Large Language Models and Wikipedia Links},
	year = {2024},
	journal = {Proceedings - 2024 12th International Symposium on Computing and Networking Workshops, CANDARW 2024},
	pages = {144 – 149},
	doi = {10.1109/CANDARW64572.2024.00030},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216878267&doi=10.1109%2fCANDARW64572.2024.00030&partnerID=40&md5=6b766bc94b4da8f9306164263dc9fc0d},
	abstract = {Entity Linking (EL), a task that maps named entities in text to corresponding entities in a knowledge base, has gained attention as a fundamental technology in knowledge processing and natural language processing. Conventional EL methods typically tokenize input text and utilize multiple features such as word embeddings and knowledge graph embeddings. Adapting these conventional EL methods to specific languages requires modifying language-dependent modules like tokenizers and word embedding models for the target language. In this study, we propose an EL method targeting Wikidata, based on Large Language Models (LLMs) and links from Wikidata to Wikipedia. Our method prompts LLMs to extract entity names from the input text and generate the corresponding Wikipedia URLs. Furthermore, it queries the Wikidata SPARQL endpoint to obtain Wikidata IDs from the Wikipedia URLs, outputting the entity names and their Wikidata IDs. This method can be applied to various languages by modifying the prompts. To evaluate, we compared the proposed method with conventional EL methods (PNEL and Japanese PNEL) on Japanese and English datasets from LC-QuAD2.0, SimpleQuestions, and WebQSP; using GPT-3.5, GPT-4, and Llama 2 as LLMs. The results showed that our method using GPT-4 outperformed conventional EL methods in recall and F-scores on datasets except for Japanese SimpleQuestions.  © 2024 IEEE.},
	author_keywords = {Entity Linking; Knowledge Graph; Large Language Model; Wiki-data; Wikipedia},
	keywords = {Graph embeddings; Natural language processing systems; Structured Query Language; Embeddings; Entity linking; Knowledge graphs; Knowledge processing; Language model; Large language model; Named entities; Natural languages; Wiki-data; Wikipedia; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Yáñez-Romero2024137,
	author = {Yáñez-Romero, Fabio and Montoyo, Andres and Muñoz, Rafael and Gutiérrez, Yoan and Suárez, Armando},
	title = {OntoLM: Integrating Knowledge Bases and Language Models for classification in the medical domain; [OntoLM: Integrando bases de conocimiento y modelos de lenguaje para clasificación en dominio médico]},
	year = {2024},
	journal = {Procesamiento del Lenguaje Natural},
	volume = {72},
	pages = {137 – 148},
	doi = {10.26342/2024-72-10},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200508113&doi=10.26342%2f2024-72-10&partnerID=40&md5=0a76b4e6fc395c03d434703e933d9273},
	abstract = {Large language models have shown impressive performance in Natural Language Processing tasks, but their black box characteristics render the explainability of the model's decision difficult to achieve and the integration of semantic knowledge. There has been a growing interest in combining external knowledge sources with language models to address these drawbacks. This paper, OntoLM, proposes a novel architecture combining an ontology with a pre-trained language model to classify biomedical entities in text. This approach involves constructing and processing graphs from ontologies and then using a graph neural network to contextualize each entity. Next, the language model and the graph neural network output are combined into a final classifier. Results show that OntoLM improves the classification of entities in medical texts using a set of categories obtained from the Unified Medical Language System. We can create more traceable natural language processing architectures using ontology graphs and graph neural networks. © 2024 Sociedad Española para el Procesamiento del Lenguaje Natural.},
	author_keywords = {External Knowledge; Graph Neural Networks; Large Language Models; Ontologies},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Todorov20241418,
	author = {Todorov, Konstantin and Fafalios, Pavlos and Dietze, Stefan and Dimitrov, Dimitar},
	title = {Beyond Facts: 4th International Workshop on Computational Methods for Online Discourse Analysis},
	year = {2024},
	journal = {WWW 2024 Companion - Companion Proceedings of the ACM Web Conference},
	pages = {1418 – 1421},
	doi = {10.1145/3589335.3641296},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194478678&doi=10.1145%2f3589335.3641296&partnerID=40&md5=7747869ba3240087ad3367e065a82ed7},
	abstract = {Expressing opinions and interacting with others on the Web has led to the production of an abundance of online discourse data, such as claims and viewpoints on controversial topics, their sources and contexts (events, entities). This data constitutes a valuable source of insights for studies into misinformation spread, bias reinforcement, echo chambers or political agenda setting. Computational methods, mostly from the field of NLP, have emerged that tackle a wide range of tasks in this context, including argument and opinion mining, claim detection, checkworthiness detection, stance detection or fact verification. However, computational models require robust definitions of classes and concepts under investigation. Thus, these computational tasks require a strong interdisciplinary and epistemological foundation, specifically with respect to the underlying definitions of key concepts such as claims, arguments, stances, check-worthiness or veracity. This requires a highly interdisciplinary approach combining expertise from fields such as communication studies, computational linguistics and computer science. As opposed to facts, claims are inherently more complex. Their interpretation strongly depends on the context and a variety of intentional or unintended meanings, where terminology and conceptual understandings strongly diverge across communities. From a computational perspective, in order to address this complexity, the synergy of multiple approaches, coming both from symbolic (knowledge representation) and statistical AI seem to be promising to tackle such challenges. This workshop aims at strengthening the relations between these communities, providing a forum for shared works on the modeling, extraction and analysis of discourse on the Web. It will address the need for a shared understanding and structured knowledge about discourse data in order to enable machine-interpretation, discoverability and reuse, in support of scientific or journalistic studies into the analysis of societal debates on the Web. Beyond research into information and knowledge extraction, data consolidation and modeling for knowledge graphs building, the workshop targets communities focusing on the analysis of online discourse, relying on methods from machine learning, natural language processing, large language models and Web data mining. © 2024 Copyright held by the owner/author(s).},
	author_keywords = {Computational fact-checking; computational journalism; intent detection; Knowledge graphs; Language models; Mis- and disinformation spread and detection; Online discourse analysis; Social web mining; Stance / viewpoint discovery},
	keywords = {Computational linguistics; Computational methods; Data mining; Extraction; Knowledge graph; Modeling languages; Computational fact-checking; Computational journalism; Discourse analysis; Intent detection; Knowledge graphs; Language model; Mis- and disinformation spread and detection; Online discourse analyse; Social web minings; Stance / viewpoint discovery; Sentiment analysis},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Bronze Open Access}
}

@ARTICLE{Shafqat2024,
	author = {Shafqat, Wafa and Na, Seung-Hoon},
	title = {Evaluating Complex Entity Knowledge Propagation for Knowledge Editing in LLMs},
	year = {2024},
	journal = {Applied Sciences (Switzerland)},
	volume = {14},
	number = {4},
	doi = {10.3390/app14041508},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192466886&doi=10.3390%2fapp14041508&partnerID=40&md5=d76cdb3a7f8b04e18636c1c2e8c1ced1},
	abstract = {In today’s world, where information keeps growing rapidly and changing constantly, language models play a crucial role in making our lives easier across different fields. However, it is tough to keep these models updated with all the new data while making sure they stay accurate and relevant. To tackle this challenge, our study proposes an innovative approach to facilitate the propagation of complex entity knowledge within language models through extensive triplet representation. Using a specially curated dataset (CTR-KE) derived from reliable sources like Wikipedia and Wikidata, the research assesses the efficacy of editing methods in handling intricate relationships between entities across multiple tiers of information. By employing a comprehensive triplet representation strategy, the study aims to enrich contextual understanding while mitigating the risks associated with distorting or forgetting critical information. The study evaluates its proposed methodology using various evaluation metrics and four distinct editing methods across three diverse language models (GPT2-XL, GPT-J, and Llama-2-7b). The results indicate the superiority of mass-editing memory in a transformer (MEMIT) and in-context learning for knowledge editing (IKE) in efficiently executing multiple updates within the triplet representation framework. This research signifies a promising pathway for deeper exploration of data representation for knowledge editing within large language models, and improved understanding of contexts to facilitate continual learning. © 2024 by the authors.},
	author_keywords = {comprehensive knowledge representation; entity knowledge propagation (EKP); knowledge editing; knowledge graph; large language models (LLMs)},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access}
}

@ARTICLE{Mumuni2024,
	author = {Mumuni, Fuseini and Mumuni, Alhassan},
	title = {Improving deep learning with prior knowledge and cognitive models: A survey on enhancing explainability, adversarial robustness and zero-shot learning},
	year = {2024},
	journal = {Cognitive Systems Research},
	volume = {84},
	doi = {10.1016/j.cogsys.2023.101188},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183716435&doi=10.1016%2fj.cogsys.2023.101188&partnerID=40&md5=61aafc6a003c4a9da8d4eef3b24d62b0},
	abstract = {We review current and emerging knowledge-informed and brain-inspired cognitive systems for realizing adversarial defenses, eXplainable Artificial Intelligence (XAI), and zero-shot or few-shot learning. Data-driven machine learning models have achieved remarkable performance and demonstrated capabilities surpassing humans in many applications. Yet, their inability to exploit domain knowledge leads to serious performance limitations in practical applications. In particular, deep learning systems are exposed to adversarial attacks, which can trick them into making glaringly incorrect decisions. Moreover, complex data-driven models typically lack interpretability or explainability, i.e., their decisions cannot be understood by human subjects. Furthermore, models are usually trained on standard datasets with a closed-world assumption. Hence, they struggle to generalize to unseen cases during inference in practical open-world environments, thus, raising the zero- or few-shot generalization problem. Although many conventional solutions exist, explicit domain knowledge, brain-inspired neural networks and cognitive architectures offer powerful new dimensions towards alleviating these problems. Prior knowledge is represented in appropriate forms like mathematical relations, logic rules, knowledge graphs, and large language models (LLMs). and incorporated in deep learning frameworks to improve performance. Brain-inspired cognition methods use computational models that mimic the human brain to enhance intelligent behavior in artificial agents and autonomous robots. Ultimately, these models achieve better explainability, higher adversarial robustness and data-efficient learning, and can, in turn, provide insights for cognitive science and neuroscience—that is, to deepen human understanding on how the brain works in general, and how it handles these problems. © 2023 Elsevier B.V.},
	author_keywords = {Adversarial attack; Brain-inspired neural network; Cognitive architecture; Domain knowledge; Explainable AI; Zero-shot generalization},
	keywords = {Brain; Cognitive systems; Computation theory; Deep learning; Intelligent robots; Learning systems; Network architecture; Zero-shot learning; Adversarial attack; Brain-inspired; Brain-inspired neural network; Cognitive architectures; Domain knowledge; Explainable AI; Generalisation; Learning with prior knowledge; Neural-networks; Zero-shot generalization; Article; artificial intelligence; artificial neural network; back propagation; cognitive model; coronavirus disease 2019; deep learning; deep neural network; few shot learning; functional magnetic resonance imaging; human; image reconstruction; knowledge; large language model; machine learning; man machine interaction; mathematics; measurement accuracy; prediction; thorax radiography; zero shot learning; Domain Knowledge},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; All Open Access, Green Open Access}
}

@CONFERENCE{Kalra2024237,
	author = {Kalra, Rishi and Wu, Zekun and Gulley, Ayesha and Hilliard, Airlie and Guan, Xin and Koshiyama, Adriano and Treleaven, Philip},
	title = {HyPA-RAG: A Hybrid Parameter Adaptive Retrieval-Augmented Generation System for AI Legal and Policy Applications},
	year = {2024},
	journal = {1st Workshop on Customizable NLP: Progress and Challenges in Customizing NLP for a Domain, Application, Group, or Individual, CustomNLP4U 2024 - Proceedings of the Workshop},
	pages = {237 – 256},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216564032&partnerID=40&md5=3da5d6954cf104b3d9a661f21f7d5ccd},
	abstract = {While Large Language Models (LLMs) excel in text generation and question-answering, their effectiveness in AI legal and policy applications is limited by outdated knowledge, hallucinations, and inadequate reasoning in complex contexts. Retrieval-Augmented Generation (RAG) systems improve response accuracy by integrating external knowledge but struggle with retrieval errors, poor context integration, and high costs, particularly in interpreting AI legal texts. This paper introduces a Hybrid Parameter-Adaptive RAG (HyPA-RAG) system tailored for AI legal and policy, exemplified by NYC Local Law 144 (LL144). HyPARAG uses a query complexity classifier for adaptive parameter tuning, a hybrid retrieval strategy combining dense, sparse, and knowledge graph methods, and an evaluation framework with specific question types and metrics. By dynamically adjusting parameters, HyPARAG significantly improves retrieval accuracy and response fidelity. Testing on LL144 shows enhanced correctness, faithfulness, and contextual precision, addressing the need for adaptable NLP systems in complex, high-stakes AI legal and policy applications.  ©2024 Association for Computational Linguistics.},
	keywords = {Knowledge graph; Laws and legislation; Query languages; Question answering; Excel; External knowledge; Generation systems; Hybrid parameters; Language model; Local laws; Parameter adaptive; Question Answering; Retrieval errors; Text generations; Computational linguistics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Hsu2024537,
	author = {Hsu, Chi-Yang and Cox, Kyle and Xu, Jiawei and Tan, Zhen and Zhai, Tianhua and Hu, Mengzhou and Pratt, Dexter and Chen, Tianlong and Hu, Ziniu and Ding, Ying},
	title = {Thought Graph: Generating Thought Process for Biological Reasoning},
	year = {2024},
	journal = {WWW 2024 Companion - Companion Proceedings of the ACM Web Conference},
	pages = {537 – 540},
	doi = {10.1145/3589335.3651572},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194487248&doi=10.1145%2f3589335.3651572&partnerID=40&md5=175a7deacbd6790e5563bf634866e336},
	abstract = {We present the Thought Graph as a novel framework to support complex reasoning and use gene set analysis as an example to uncover semantic relationships between biological processes. Our framework stands out for its ability to provide a deeper understanding of gene sets, significantly surpassing GSEA by 40.28% and LLM baselines by 5.38% based on cosine similarity to human annotations. Our analysis further provides insights into future directions of biological processes naming, and implications for bioinformatics and precision medicine. Here’s our Github Code. © 2024 Copyright held by the owner/author(s). Publication rights licensed to ACM.},
	author_keywords = {bioinformatics; gene ontology; large language model; natural language processing; semantic web biological process},
	keywords = {Bioinformatics; Gene Ontology; Genes; Natural language processing systems; Biological process; Gene ontology; Gene sets; Language model; Language processing; Large language model; Natural language processing; Natural languages; Semantic web biological process; Semantic-Web; Semantic Web},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Yuan20241963,
	author = {Yuan, Chenhan and Xie, Qianqian and Huang, Jimin and Ananiadou, Sophia},
	title = {Back to the Future: Towards Explainable Temporal Reasoning with Large Language Models},
	year = {2024},
	journal = {WWW 2024 - Proceedings of the ACM Web Conference},
	pages = {1963 – 1974},
	doi = {10.1145/3589334.3645376},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194101474&doi=10.1145%2f3589334.3645376&partnerID=40&md5=84100eedda5b297b4f0f8356803ff867},
	abstract = {Temporal reasoning is a crucial natural language processing (NLP) task, providing a nuanced understanding of time-sensitive contexts within textual data. Although recent advancements in Large Language Models (LLMs) have demonstrated their potential in temporal reasoning, the predominant focus has been on tasks such as temporal expression detection, normalization, and temporal relation extraction. These tasks are primarily designed for the extraction of direct and past temporal cues from given contexts and to engage in simple reasoning processes. A significant gap remains when considering complex reasoning tasks such as event forecasting, which requires multi-step temporal reasoning on events and prediction on the future timestamp. Another notable limitation of existing methods is their incapability to illustrate their reasoning process for explaining their prediction, hindering explainability. In this paper, we introduce the first task of explainable temporal reasoning, to predict an event's occurrence at a future timestamp based on context which requires multiple reasoning over multiple events, and subsequently provide a clear explanation for their prediction. Our task offers a comprehensive evaluation of both the LLMs' complex temporal reasoning ability, the future event prediction ability, and explainability-a critical attribute for AI applications. To support this task, we present the first instruction-tuning dataset of explainable temporal reasoning (ExpTime) with 26k derived from the temporal knowledge graph datasets, using a novel knowledge-graph-instructed-generation strategy. Based on the dataset, we propose the first open-source LLM series TimeLlaMA based on the foundation LLM LlaMA2, with the ability of instruction following for explainable temporal reasoning. We compare the performance of our method and a variety of LLMs, where our method achieves the state-of-the-art performance of temporal prediction and explanation generation. We also explore the impact of instruction tuning and different training sizes of instruction-tuning data, highlighting LLM's capabilities and limitations in complex temporal prediction and explanation generation. © 2024 ACM.},
	author_keywords = {event forecasting; explainable AI; large language models; temporal reasoning},
	keywords = {Computational linguistics; Extraction; Knowledge graph; Natural language processing systems; Event forecasting; Explainable AI; Knowledge graphs; Language model; Large language model; Natural languages; Reasoning process; Temporal prediction; Temporal reasoning; Time-stamp; Forecasting},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Green Open Access}
}

@ARTICLE{Cao2024,
	author = {Cao, Xiangang and Xu, Wangtao and Zhao, Jiangbin and Duan, Yong and Yang, Xin},
	title = {Research on Large Language Model for Coal Mine Equipment Maintenance Based on Multi-Source Text},
	year = {2024},
	journal = {Applied Sciences (Switzerland)},
	volume = {14},
	number = {7},
	doi = {10.3390/app14072946},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192549054&doi=10.3390%2fapp14072946&partnerID=40&md5=20184244ff72bcc75d2cd51b2a53720b},
	abstract = {The efficient management and utilization of coal mine equipment maintenance knowledge is an indispensable foundation for advancing the establishment of intelligent mines. This knowledge has problems such as scattered, low sharing, and insufficient management, which restricts the development of coal mine intelligence. For the above-mentioned problems, a large language model for the maintenance of coal mine equipment based on multi-source text (XCoalChat) was proposed to better manage and utilize the existing massive knowledge of coal mine equipment maintenance. The dataset of coal mine equipment maintenance based on ReliableCEMK-Self-Instruction was constructed to obtain a wide and diverse amount of knowledge through sample generation. Aiming at the illusory problem of the large language model, a knowledge graph enhancement method based on the “Coal Mine Equipment Maintenance System—Full Life Cycle—Specification” was proposed to improve the knowledge density. A triple-LoRA fine-tuning mechanism and DPO direct preference optimization method were introduced into the top of the baseline model, which guarantees that XCoalChat can handle multiple Q&A and maintenance decision analysis tasks with limited computing power. Compared with ChatGLM, Bloom, and LLama, the comprehensive assessment of XCoalChat was performed by experiments including coal mine dialog consulting, coal mine professional consulting, and maintenance decision analysis. The results showed that XCoalChat achieved the best response accuracy in professional consulting and maintenance decision analysis; XCoalChat also took the least reasoning time on average. XCoalChat outperformed other mainstream large language models, which verify that XCoalChat is an effective large language model in the field of coal mine equipment maintenance. © 2024 by the authors.},
	author_keywords = {coal mine intelligence; equipment maintenance; knowledge graph; knowledge management; large language model},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Gold Open Access}
}

@BOOK{Krause202471,
	author = {Krause, Franz and Kurniawan, Kabul and Kiesling, Elmar and Martinez-Gil, Jorge and Hoch, Thomas and Pichler, Mario and Heinzl, Bernhard and Moser, Bernhard},
	title = {Leveraging semantic representations via knowledge graph embeddings},
	year = {2024},
	journal = {Artificial Intelligence in Manufacturing: Enabling Intelligent, Flexible and Cost-Effective Production Through AI},
	pages = {71 – 85},
	doi = {10.1007/978-3-031-46452-2_5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201910361&doi=10.1007%2f978-3-031-46452-2_5&partnerID=40&md5=d5687685f5ae14875d72b64e0bad7071},
	abstract = {The representation and exploitation of semantics has been gaining popularity in recent research, as exemplified by the uptake of large language models in the field of Natural Language Processing (NLP) and knowledge graphs (KGs) in the Semantic Web. Although KGs are already employed in manufacturing to integrate and standardize domain knowledge, the generation and application of corresponding KG embeddings as lean feature representations of graph elements have yet to be extensively explored in this domain. Existing KGs in manufacturing often focus on top-level domain knowledge and thus ignore domain dynamics, or they lack interconnectedness, i.e., nodes primarily represent non-contextual data values with single adjacent edges, such as sensor measurements. Consequently, context-dependent KG embedding algorithms are either restricted to non-dynamic use cases or cannot be applied at all due to the given KG characteristics. Therefore, this work provides an overview of state-of-the-art KG embedding methods and their functionalities, identifying the lack of dynamic embedding formalisms and application scenarios as the key obstacles that hinder their implementation in manufacturing. Accordingly, we introduce an approach for dynamizing existing KG embeddings based on local embedding reconstructions. Furthermore, we address the utilization of KG embeddings in the Horizon2020 project Teaming.AI (www.teamingai-project.eu.) focusing on their respective benefits. © The Author(s) 2024. All rights reserved.},
	author_keywords = {Dynamic knowledge graph embedding; Industry 5.0; Knowledge graph; Knowledge graph embedding; Manufacturing; Representation learning},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Li2024588,
	author = {Li, Haotian and Xia, Congmin and Hou, Youjuan and Hu, Sile and Quan, Jiang and Liu, Yanjun},
	title = {TCMRD-KG: Design and Development of a Rheumatism Knowledge Graph Based on Ancient Chinese Literature},
	year = {2024},
	journal = {Proceedings - 2024 IEEE International Conference on Medical Artificial Intelligence, MedAI 2024},
	pages = {588 – 593},
	doi = {10.1109/MedAI62885.2024.00083},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216679297&doi=10.1109%2fMedAI62885.2024.00083&partnerID=40&md5=24d742f32999a4f240b42ff9abe7b5f6},
	abstract = {The use of Traditional Chinese medicineTCM in rheumatic diseases dates back to thousands of years ago. Compared with standardized treatment, TCM has the advantages of low cost, low side effects, and flexible medication. Ancient books of traditional Chinese medicine play an important role in clinical and scientific research. This study takes the content related to rheumatism in ancient books of traditional Chinese medicine as the research object, integrates the ontology theory and technology in the knowledge graph, realizes the reconstruction of traditional Chinese medicine information knowledge, and provides basic data structure for data mining and knowledge discovery. This study is the first rheumatism-specific knowledge graph constructed based on ancient books of traditional Chinese medicine; it has tried the construction method of knowledge graph of ancient books of traditional Chinese medicine by combining automatic labeling of mainstream large language models with manual review; and according to the knowledge characteristics of ancient books of traditional Chinese medicine, the existing word segmentation technology is difficult to accurately reproduce the accurate meaning of the original text of ancient books, a new type of entity extraction method is given.  © 2024 IEEE.},
	author_keywords = {Knowledge Graph; Rheumatic Diseases; Traditional Chinese Medicine},
	keywords = {Knowledge graph; Chinese literature; Clinical research; Design and Development; Graph-based; Knowledge graphs; Low-costs; Rheumatic disease; Scientific researches; Side effect; Traditional Chinese Medicine},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Sousa2024156,
	author = {Sousa, Guilherme and Lima, Rinaldo and Trojahn, Cassia},
	title = {Results of CANARD in OAEI 2024},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3897},
	pages = {156 – 160},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216401149&partnerID=40&md5=03702571a288fcfb0c99cf667c644ee8},
	abstract = {This paper presents the 2024 results of an enhanced version of the CANARD system, which integrates Large Language Models (LLMs) to address the challenges of complex alignments. By leveraging LLM-based embeddings, the system better captures semantic and contextual relationships, improving both precision and coverage. Four architectural settings - Label Embedding Similarity (LES), Embeddings of SPARQL Query (ESQ), Subgraph Embeddings (SE) and Instance Embeddings (IE) - were explored to improve the alignment quality. Experiments on the Populated Conference dataset from the OAEI Complex Track demonstrate improvements over baseline approaches, with an increase in F-measure up to 45% in some cases. However, challenges such as runtime overhead in IE and noise in SE components were identified, where future work can explore better aggregation techniques or fine-tuned LLMs. © 2024 Copyright for this paper by its authors.},
	author_keywords = {Complex Ontology Matching; Embeddings; LLM},
	keywords = {Modeling languages; Ontology; Semantics; Structured Query Language; Complex ontology matching; Contextual relationships; Embeddings; Language model; Large language model; Model-based OPC; Ontology matching; Semantic relationships; Similarity embedding; Subgraphs; Embeddings},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Totoian2024138,
	author = {Totoian, Marius-Horatiu and Marginean, Anca and Blohm, Philipp and Hussain, Mir Nawab},
	title = {HybridOM: Ontology Matching using Hybrid Search},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3897},
	pages = {138 – 145},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216388200&partnerID=40&md5=6c536aafb8b92a07ed02734fedb6f96c},
	abstract = {Ontology matching targets identical concepts from different ontologies with the final purpose of interoperability and ontologies merging. The matching task is not restricted to ontologies, it is also relevant for knowledge graphs. Ontology matching solutions based on transformer-based embeddings, textual similarity, logical mapping, or Large Language Models (LLMs) are still facing problems, mainly due to the lack of uniform information about the concepts and lack of homogeneous semantic granularity along different ontologies. In this work, we present a framework that combines vector-based similarity and string-based similarity through hybrid searches. LLMs are used to generate descriptions for ontology concepts, hence the concepts' representation is enriched and the alignment process can benefit from both the knowledge captured by the initial ontologies and the extended LLM-generated textual descriptions. The proposed system, HybridOM, is an unsupervised approach independent of the ontologies' domain. HybridOM is evaluated within Bio-ML 2024 track for the task of concept matching. It achieves the highest values for F1-score and Recall for most of the ontology pairs while maintaining a balance between precision and recall. The proposed method has been adapted for industrial usage in a human capital management product called msg.ProfileMap. © 2024 Copyright for this paper by its authors.},
	author_keywords = {hybrid search; Large Language Model; Ontology matching; vector database; verbalization},
	keywords = {Knowledge graph; Ontology; Semantics; Hybrid search; Knowledge graphs; Language model; Large language model; Ontology matching; Ontology merging; Ontology's; Vector database; Verbalization; Human resource management},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Maninger2024112,
	author = {Maninger, Daniel and Narasimhan, Krishna and Mezini, Mira},
	title = {Towards Trustworthy AI Software Development Assistance},
	year = {2024},
	journal = {Proceedings - International Conference on Software Engineering},
	pages = {112 – 116},
	doi = {10.1145/3639476.3639770},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195151909&doi=10.1145%2f3639476.3639770&partnerID=40&md5=02eaafc0892d7308dc0fab12e9777b02},
	abstract = {It is expected that in the near future, AI software development assistants will play an important role in the software industry. However, current software development assistants tend to be unreliable, often producing incorrect, unsafe, or low-quality code. We seek to resolve these issues by introducing a holistic architecture for constructing, training, and using trustworthy AI software development assistants. In the center of the architecture, there is a foundational LLM trained on datasets representative of real-world coding scenarios and complex software architectures, and fine-tuned on code quality criteria beyond correctness. The LLM will make use of graph-based code representations for advanced semantic comprehension. We envision a knowledge graph integrated into the system to provide up-to-date background knowledge and to enable the assistant to provide appropriate explanations. Finally, a modular framework for constrained decoding will ensure that certain guarantees (e.g., for correctness and security) hold for the generated code.  © 2024 Copyright held by the owner/author(s).},
	keywords = {Graphic methods; Knowledge graph; Software design; 'current; Code quality; Complex software; Development assistance; Graph-based; Low qualities; Quality codes; Quality criteria; Real-world; Software industry; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Sansford202420,
	author = {Sansford, Hannah and Richardson, Nicholas and Maretic, Hermina Petric and Saada, Juba Nait},
	title = {GraphEval: A Knowledge-Graph Based LLM Hallucination Evaluation Framework},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3894},
	pages = {20 – 31},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216407923&partnerID=40&md5=70c8845e88270b15f5988c061b576675},
	abstract = {Methods to evaluate Large Language Model (LLM) responses and detect inconsistencies, also known as hallucinations, with respect to the provided knowledge, are becoming increasingly important for LLM applications. Current metrics fall short in their ability to provide explainable decisions, systematically check all pieces of information in the response, and are often too computationally expensive to be used in practice. We present GraphEval: a hallucination evaluation framework based on representing information in Knowledge Graph (KG) structures. Our method identifies the specific triples in the KG that are prone to hallucinations and hence provides more insight into where in the response a hallucination has occurred, if at all, than previous methods. Furthermore, using our approach in conjunction with state-of-the-art natural language inference (NLI) models leads to an improvement in balanced accuracy on various hallucination benchmarks, compared to using the raw NLI models. Lastly, we explore the use of GraphEval for hallucination correction by leveraging the structure of the KG, a method we name GraphCorrect, and demonstrate that the majority of hallucinations can indeed be rectified. © 2024 Copyright for this paper by its authors.},
	author_keywords = {Hallucination Correction; Hallucination Detection; Knowledge Graphs; Large Language Models},
	keywords = {Benchmarking; Graph algorithms; Evaluation framework; Graph-based; Hallucination correction; Hallucination detection; Inference models; Knowledge graphs; Language inference; Language model; Large language model; Natural languages; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Gu2024,
	author = {Gu, Zhanzhong and He, Xiangjian and Yu, Ping and Jia, Wenjing and Yang, Xiguang and Peng, Gang and Hu, Penghui and Chen, Shiyan and Chen, Hongjie and Lin, Yiguang},
	title = {Automatic quantitative stroke severity assessment based on Chinese clinical named entity recognition with domain-adaptive pre-trained large language model},
	year = {2024},
	journal = {Artificial Intelligence in Medicine},
	volume = {150},
	doi = {10.1016/j.artmed.2024.102822},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186860362&doi=10.1016%2fj.artmed.2024.102822&partnerID=40&md5=f1d91f559e3adc410f26b360c795d235},
	abstract = {Background: Stroke is a prevalent disease with a significant global impact. Effective assessment of stroke severity is vital for an accurate diagnosis, appropriate treatment, and optimal clinical outcomes. The National Institutes of Health Stroke Scale (NIHSS) is a widely used scale for quantitatively assessing stroke severity. However, the current manual scoring of NIHSS is labor-intensive, time-consuming, and sometimes unreliable. Applying artificial intelligence (AI) techniques to automate the quantitative assessment of stroke on vast amounts of electronic health records (EHRs) has attracted much interest. Objective: This study aims to develop an automatic, quantitative stroke severity assessment framework through automating the entire NIHSS scoring process on Chinese clinical EHRs. Methods: Our approach consists of two major parts: Chinese clinical named entity recognition (CNER) with a domain-adaptive pre-trained large language model (LLM) and automated NIHSS scoring. To build a high-performing CNER model, we first construct a stroke-specific, densely annotated dataset “Chinese Stroke Clinical Records” (CSCR) from EHRs provided by our partner hospital, based on a stroke ontology that defines semantically related entities for stroke assessment. We then pre-train a Chinese clinical LLM coined “CliRoberta” through domain-adaptive transfer learning and construct a deep learning-based CNER model that can accurately extract entities directly from Chinese EHRs. Finally, an automated, end-to-end NIHSS scoring pipeline is proposed by mapping the extracted entities to relevant NIHSS items and values, to quantitatively assess the stroke severity. Results: Results obtained on a benchmark dataset CCKS2019 and our newly created CSCR dataset demonstrate the superior performance of our domain-adaptive pre-trained LLM and the CNER model, compared with the existing benchmark LLMs and CNER models. The high F1 score of 0.990 ensures the reliability of our model in accurately extracting the entities for the subsequent automatic NIHSS scoring. Subsequently, our automated, end-to-end NIHSS scoring approach achieved excellent inter-rater agreement (0.823) and intraclass consistency (0.986) with the ground truth and significantly reduced the processing time from minutes to a few seconds. Conclusion: Our proposed automatic and quantitative framework for assessing stroke severity demonstrates exceptional performance and reliability through directly scoring the NIHSS from diagnostic notes in Chinese clinical EHRs. Moreover, this study also contributes a new clinical dataset, a pre-trained clinical LLM, and an effective deep learning-based CNER model. The deployment of these advanced algorithms can improve the accuracy and efficiency of clinical assessment, and help improve the quality, affordability and productivity of healthcare services. © 2024 The Author(s)},
	author_keywords = {Automatic stroke severity assessment; Chinese electronic health records; Clinical named entity recognition; Domain-adaptive pre-training; Large language model},
	keywords = {Artificial Intelligence; China; Electronic Health Records; Humans; Language; Natural Language Processing; Reproducibility of Results; Stroke; Benchmarking; Computational linguistics; Deep learning; Diagnosis; E-learning; Natural language processing systems; Records management; Automatic stroke severity assessment; Chinese electronic health record; Clinical named entity recognition; Domain-adaptive pre-training; Electronic health; Health records; Language model; Large language model; Named entity recognition; Pre-training; Article; artificial intelligence; automation; cerebrovascular accident; Chinese; Chinese clinical named entity recognition; clinical assessment; clinical evaluation; clinical outcome; comparative study; conceptual framework; deep learning; disease severity; electronic health record; health service; hospital care; human; interrater reliability; laboratory test; large language model; National Institutes of Health Stroke Scale; ontology; outcome assessment; quantitative analysis; recognition; reliability; transfer of learning; cerebrovascular accident; China; language; natural language processing; reproducibility; Automation},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Koudouridis202498,
	author = {Koudouridis, Georgios P. and Shalmashi, Serveh and Moosavi, Reza},
	title = {An Evaluation Survey of Knowledge-Based Approaches in Telecommunication Applications},
	year = {2024},
	journal = {Telecom},
	volume = {5},
	number = {1},
	pages = {98 – 121},
	doi = {10.3390/telecom5010006},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188895250&doi=10.3390%2ftelecom5010006&partnerID=40&md5=b515a98300a0c6eed4982ca1a60728e7},
	abstract = {The purpose of this survey study is to shed light on the importance of knowledge usage and knowledge-driven applications in telecommunication systems and businesses. To this end, we first define a classification of the different knowledge-based approaches in terms of knowledge representations and reasoning formalisms. Further, we define a set of qualitative criteria and evaluate the different categories for their suitability and usefulness in telecommunications. From the evaluation results, we could conclude that different use cases are better served by different knowledge-based approaches. Further, we elaborate and showcase our findings on three different knowledge-based approaches and their applicability to three operational aspects of telecommunication networks. More specifically, we study the utilization of large language models in network operation and management, the automation of the network based on knowledge-graphs and intent-based networking, and the optimization of the network based on machine learning-based distributed intelligence. The article concludes with challenges, limitations, and future steps toward knowledge-driven telecommunications. © 2024 by the authors.},
	author_keywords = {generative AI; intent-based networking; knowledge representation; knowledge-based systems; large language models; machine learning; machine reasoning; network automation},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@CONFERENCE{Çöplü2024144,
	author = {Çöplü, Tolga and Bendiken, Arto and Skomorokhov, Andrii and Bateiko, Eduard and Cobb, Stephen},
	title = {Prompt-Time Ontology-Driven Symbolic Knowledge Capture with Large Language Models},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3894},
	pages = {144 – 149},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216389497&partnerID=40&md5=deecd7ac298892018293f0ff1524b524},
	abstract = {In applications such as personal assistants, large language models (LLMs) must consider the user’s personal information and preferences. However, LLMs lack the inherent ability to learn from user interactions. This paper explores capturing personal information from user prompts using ontology and knowledge-graph approaches. We use a subset of the KNOW ontology, which models personal information, to train the language model on these concepts. We then evaluate the success of knowledge capture using a specially constructed dataset. Our code and datasets are publicly available at https://github.com/HaltiaAI/paper-PTODSKC. © 2024 Copyright for this paper by its authors.},
	author_keywords = {fine-tuning; KNOW ontology; knowledge graphs; large language models; ontology-driven symbolic knowledge capture; symbolic representation},
	keywords = {Ontology; Fine tuning; KNOW ontology; Knowledge capture; Knowledge graphs; Language model; Large language model; Ontology's; Ontology-driven symbolic knowledge capture; Symbolic knowledge; Symbolic representation; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Mondal202418798,
	author = {Mondal, Debjyoti and Modi, Suraj and Panda, Subhadarshi and Singh, Rituraj and Rao, Godawari Sudhakar},
	title = {KAM-CoT: Knowledge Augmented Multimodal Chain-of-Thoughts Reasoning},
	year = {2024},
	journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
	volume = {38},
	number = {17},
	pages = {18798 – 18806},
	doi = {10.1609/aaai.v38i17.29844},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189627509&doi=10.1609%2faaai.v38i17.29844&partnerID=40&md5=7c09bf63c9da0bffb7478bbec6b22347},
	abstract = {Large Language Models (LLMs) have demonstrated impressive performance in natural language processing tasks by leveraging chain of thought (CoT) that enables step-by-step thinking. Extending LLMs with multimodal capabilities is the recent interest, but incurs computational cost and requires substantial hardware resources. To address these challenges, we propose KAM-CoT a framework that integrates CoT reasoning, Knowledge Graphs (KGs), and multiple modalities for a comprehensive understanding of multimodal tasks. KAM-CoT adopts a two-stage training process with KG grounding to generate effective rationales and answers. By incorporating external knowledge from KGs during reasoning, the model gains a deeper contextual understanding reducing hallucinations and enhancing the quality of answers. This knowledge-augmented CoT reasoning empowers the model to handle questions requiring external context, providing more informed answers. Experimental findings show KAM-CoT outperforms the state-of-the-art methods. On the ScienceQA dataset, we achieve an average accuracy of 93.87%, surpassing GPT-3.5 (75.17%) by 18% and GPT-4 (83.99%) by 10%. Remarkably, KAM-CoT achieves these results with only 280M trainable parameters at a time, demonstrating its cost-efficiency and effectiveness. © 2024, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.},
	keywords = {Natural language processing systems; Computational costs; Hardware resources; Knowledge graphs; Language model; Language processing; Multi-modal; Multimodal chains; Multiple modalities; Natural languages; Performance; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Lian2024214,
	author = {Lian, Huijun and Chen, Keqi and Sun, Zekai and Gao, Yingming and Li, Ya},
	title = {G2DiaR: Enhancing Commonsense Reasoning of LLMs with Graph-to-Dialogue & Reasoning},
	year = {2024},
	journal = {2024 14th International Symposium on Chinese Spoken Language Processing, ISCSLP 2024},
	pages = {214 – 218},
	doi = {10.1109/ISCSLP63861.2024.10800655},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216408214&doi=10.1109%2fISCSLP63861.2024.10800655&partnerID=40&md5=eb9b64563da9fa661f03c998cd4b9856},
	abstract = {Knowledge-rich dialogues are crucial for assessing and enhancing the reasoning capabilities of Large Language Models (LLMs). Detailed knowledge hints are incorporated in prompts to generate knowledge-rich dialogues. However, the intricate interplay among dialogue, context, and diverse knowledge facets is often overlooked. This causes LLMs to exhibit basic commonsense understanding but struggle with commonsense reasoning. To tackle these challenges, we proposed a graph-to-dialogue & reasoning generation method G2DiaR. G2DiaR can controllably convert the knowledge path in the graph into a dialogue, and can also generate reasoning that is faithful to the dialogue based on the neighbor nodes of the path nodes. We leverage G2DiaR to create G2DiaD, a challenging dataset for dialogue-based reasoning in multiple-choice question-answering (MCQA), derived from the ATOMIC commonsense graph. G2DiaD comprises 6,492 QA pairs, each offering inference-based answers supported by or conflicting with reasoning. Experimental results demonstrate that training on G2DiaD leads to an average performance improvement of 6.08% across various commonsense reasoning benchmarks, surpassing retrieval methods (0.60% improvement) and training on the CICERO dataset (-4.78% decline). G2DiaR can generate dialogue data rich in commonsense, relation and reasoning, enhancing the reasoning and generalization capabilities of LLMs. ©2024 IEEE.},
	author_keywords = {commonsense reasoning; dialogue generation; large language models},
	keywords = {Speech enhancement; Based reasonings; Commonsense reasoning; Dialogue generations; Generation method; Language model; Large language model; Multiple-choice questions; Neighbour nodes; Question Answering; Reasoning capabilities; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}@CONFERENCE{Lopes2024,
	author = {Lopes, Alcides and Carbonera, Joel and Rodrigues, Fabricio and Garcia, Luan and Abel, Mara},
	title = {How to classify domain entities into top-level ontology concepts using large language models: A study across multiple labels, resources, and languages},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3882},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214572340&partnerID=40&md5=2a7cc600567dd009cf3ccec08907c7c4},
	abstract = {Classifying domain entities into their respective top-level ontology concepts is a complex problem that typically demands manual analysis and deep expertise in the domain of interest and ontology engineering. Using an efficient approach to classify domain entities enhances data integration, interoperability, and the semantic clarity of ontologies, which are crucial for structured knowledge representation and modeling. Based on this, our main motivation is to help an ontology engineer with an automated approach to classify domain entities into top-level ontology concepts using informal definitions of these domain entities during the ontology development process. In this context, we hypothesize that the informal definitions encapsulate semantic information crucial for associating domain entities with specific top-level ontology concepts. Our approach leverages state-of-the-art language models to explore our hypothesis across multiple languages and informal definitions from different knowledge resources. In order to evaluate our proposal, we extracted multi-label datasets from the alignment of the OntoWordNet ontology and the BabelNet semantic network, covering the entire structure of the Dolce-Lite-Plus top-level ontology from most generic to most specific concepts. These datasets contain several different textual representation approaches of domain entities, including terms, example sentences, and informal definitions. Our experiments conducted 3 study cases, investigating the effectiveness of our proposal across different textual representation approaches, languages, and knowledge resources. We demonstrate that the best results are achieved using a classification pipeline with a K-Nearest Neighbor (KNN) method to classify the embedding representation of informal definitions from the Mistral large language model. The findings underscore the potential of informal definitions in reflecting top-level ontology concepts and point towards developing automated tools that could significantly aid ontology engineers during the ontology development process. © 2024 Copyright for this paper by its authors.},
	author_keywords = {Informal definition; Language Model; Ontology learning; Top-level ontology classification},
	keywords = {Classification (of information); Data encapsulation; Domain Knowledge; Knowledge representation; Modeling languages; Ontology; Development process; Domain entities; Informal definition; Language model; Multiple languages; Ontology concepts; Ontology development; Ontology learning; Ontology's; Top-level ontology classification; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{2024,
	title = {2024 Sensor Data Fusion: Trends, Solutions, Applications, SDF 2024},
	year = {2024},
	journal = {2024 Sensor Data Fusion: Trends, Solutions, Applications, SDF 2024},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215135182&partnerID=40&md5=c53ab4998d9086b78b694fcdcea0c77f},
	abstract = {The proceedings contain 18 papers. The topics discussed include: computational complexity reduction for the track-to-track association problem; modeling contour measurements of elliptical extended objects via gaussian spatial distributions; advanced sensor fusion for railway security - a hierarchical graph-based approach; performance evaluation of deep learning-based state estimation: a comparative study of KalmanNet; a hybrid AI framework integrating ontology learning, knowledge graphs, and large language models for improved data model translation in smart manufacturing and transportation; multi-sensor simulation from target tracking to a recognized air picture; and Voronoi trust regions for local calibration testing in supervised machine learning models.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Prabhong2024,
	author = {Prabhong, Thin and Kertkeidkachorn, Natthawut and Trongratsameethong, Areerat},
	title = {KGC-RAG: Knowledge Graph Construction from Large Language Model Using Retrieval-Augmented Generation},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3853},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212706822&partnerID=40&md5=224f1ec196ac04865f29d3d42e30f731},
	abstract = {The construction of Knowledge Graphs (KGs) has become increasingly important due to their ability to integrate and represent complex relationships across various domains, making them essential for applications like information retrieval and semantic search. Recently, Large Language Models (LLMs) have been utilized to enhance KGs creation by leveraging their advanced capabilities in understanding and generating human-like text. The Large Language Models for Knowledge Engineering (LLMKE) pipeline was introduced to combine knowledge probing with Wikidata entity mapping for knowledge engineering. Nevertheless, this approach has a limitation: it primarily relies on retrieval-augmented context drawn from the first paragraph and Wikipedia Infobox of the subject entity's page. This narrow focus can lead to incomplete knowledge representations, as relevant information is often spread throughout the text and linked pages. To address this issue, we propose the Knowledge Graph Construction from Large Language Model using Retrieval-Augmented Generation method (KGC-RAG). This method leverages web scraping to retrieve documents from the subject entity's Wikipedia page and to extend the search to include linked pages, thereby increasing the likelihood of capturing comprehensive and contextually rich information. We further enhance this approach by using LLMs in conjunction with cosine similarity to filter out irrelevant content, ensuring that only the most pertinent data are included in the relevant contexts. We conducted an experiment on datasets from ISWC 2024 LM-KBC Challenge and applied the meta-llama/Meta-Llama-3-8B-Instruct model as our pre-trained large language model along with the all-MiniLM-L6-v2 as our vector embedding model. We set a relevant score threshold of 0.5 to filter Wikipedia URLs. Our approach achieved macro average F1-scores of 0.695 and 0.698 on the validation and test sets, respectively. The implementation is available at https://github.com/jaejeajay/LM-KBC2024. © 2024 Copyright for this paper by its authors.},
	keywords = {Graph embeddings; Hypertext systems; Information retrieval; Modeling languages; Semantics; Complex relationships; Generation method; Graph construction; Human like; Incomplete knowledge; Knowledge graphs; Knowledge-representation; Language model; Semantic search; Wikipedia; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Fang2024238,
	author = {Fang, Yunfei and Chen, Yong and Jiang, Zhonglin and Xiao, Jun and Ge, Yanli},
	title = {Effective and Reliable Domain-Specific Knowledge Question Answering},
	year = {2024},
	journal = {Proceedings - 2024 IEEE International Conference on e-Business Engineering, ICEBE 2024},
	pages = {238 – 243},
	doi = {10.1109/ICEBE62490.2024.00044},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215575544&doi=10.1109%2fICEBE62490.2024.00044&partnerID=40&md5=cbe87b16d6a328f4c497fd1f3b1c52b6},
	abstract = {Large language models (LLMs) serve as powerful knowledge bases, capable of embedding knowledge from text into model parameters. However, the widespread issue of hallucination and opaque black-box processes restrict their broader application in professional sectors that place high demands on safety and predictability. Conversely, knowledge graphs provide inherent superiority in the authenticity and interpretability in question answering sessions. However, building a knowledge graph in specialized fields and conduct question answering over the knowledge graph are both nontrivial problems. This paper introduces an efficient knowledge graph question answering (KGQA) approach tailored to customized domain-specific knowledge graphs. Our 'extract-then-bind' KGQA method leverages the in-context learning capabilities of the LLM to extract mention and relation proposals from the query, which are then matched with nodes and edges in the knowledge graph. Experimental results demonstrate the effectiveness of our approach in a question answering task using automotive user manuals. Notably, the knowledge graph was created through an automated process. By combining this innovative KGQA technique with its corresponding knowledge graph construction method, this paper proposes an effective and reliable system for addressing domain-specific knowledge question answering. This integrated solution guarantees authenticity and traceability in question answering while significantly reducing the need for manual labour. © 2024 IEEE.},
	author_keywords = {domain-specific; knowledge graph; Large language models; question answering},
	keywords = {Domain Knowledge; Black-box process; Broad application; Domain specific; Domain-specific knowledge; Embeddings; Knowledge graphs; Language model; Large language model; Modeling parameters; Question Answering; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Bouquet2024,
	author = {Bouquet, Paolo and Molinari, Andrea and Sandri, Simone},
	title = {Challenges in Working with Unstructured Data in the LLM Era: NER Processes Using Graph Neural Networks},
	year = {2024},
	journal = {International Conference on Electrical, Computer, Communications and Mechatronics Engineering, ICECCME 2024},
	doi = {10.1109/ICECCME62383.2024.10796004},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216029704&doi=10.1109%2fICECCME62383.2024.10796004&partnerID=40&md5=360af576b47a5b86b6b79ee7dcc74568},
	abstract = {The application of neural networks and large language models (LLMs) in the financial technology (fintech) sector has significantly enhanced capabilities of providing better services based on unstructured documents, mainly thanks to the astonishing interactive capabilities of large language models (LLMs). However, in these contexts, precisely recognizing named entities (for example, the beneficiary of an insurance policy) and creating reliable, domain-dependent, private knowledge graphs is more crucial than conversational capabilities. Moreover, optimizing these models for dynamic data environments and ensuring Explainability presents notable challenges. This paper aims to present our approach for the creation of a knowledge graph that uses graph neural nets (GNN) to provide a better named-entity recognition (NER) process, to identify entities in the text precisely and to solve other issues in knowledge graph management, like the co-ference resolution problem or focusing on dynamic data environments and the critical need for Explainability of modern AI-based solutions. The paper presents our preliminary results on one of the various pipeline steps that creates the navigable knowledge graph. © 2024 IEEE.},
	author_keywords = {Artificial Intelligence; Graph Neural Nets; Knolwedge Graph; Named entity resolution},
	keywords = {Decentralized finance; Fintech; Graph neural networks; Information management; Insurance; Investments; Neural network models; Dynamic data; Entity resolutions; Graph neural net; Knolwedge graph; Knowledge graphs; Language model; Named entities; Named entity recognition; Named entity resolution; Recognition process; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Schmidt2024,
	author = {Schmidt, David M. and Cimiano, Philipp},
	title = {Grammar-constrained decoding for structured information extraction with fine-tuned generative models applied to clinical trial abstracts},
	year = {2024},
	journal = {Frontiers in Artificial Intelligence},
	volume = {7},
	doi = {10.3389/frai.2024.1406857},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215524351&doi=10.3389%2ffrai.2024.1406857&partnerID=40&md5=b9d122cc21dc6f6d382cba1ca26a2469},
	abstract = {Background: In the field of structured information extraction, there are typically semantic and syntactic constraints on the output of information extraction (IE) systems. These constraints, however, can typically not be guaranteed using standard (fine-tuned) encoder-decoder architectures. This has led to the development of constrained decoding approaches which allow, e.g., to specify constraints in form of context-free grammars. An open question is in how far an IE system can be effectively guided by a domain-specific grammar to ensure that the output structures follow the requirements of a certain domain data model. Methods: In this work we experimentally investigate the influence of grammar-constrained decoding as well as pointer generators on the performance of a domain-specific information extraction system. For this, we consider fine-tuned encoder-decoder models, Longformer and Flan-T5 in particular, and experimentally investigate whether the addition of grammar-constrained decoding and pointer generators improve information extraction results. Toward this goal, we consider the task of inducing structured representations from abstracts describing clinical trials, relying on the C-TrO ontology to semantically describe the clinical trials and their results. We frame the task as a slot filling problem where certain slots of templates need to be filled with token sequences occurring in the input text. We use a dataset comprising 211 annotated clinical trial abstracts about type 2 diabetes and glaucoma for training and evaluation. Our focus is on settings in which the available training data is in the order of a few hundred training examples, which we consider as a low-resource setting. Results: In all our experiments we could demonstrate the positive impact of grammar-constrained decoding, with an increase in F1 score of pp 0.351 (absolute score 0.413) and pp 0.425 (absolute score 0.47) for the best-performing models on type 2 diabetes and glaucoma datasets, respectively. The addition of the pointer generators had a detrimental impact on the results, decreasing F1 scores by pp 0.15 (absolute score 0.263) and pp 0.198 (absolute score 0.272) for the best-performing pointer generator models on type 2 diabetes and glaucoma datasets, respectively. Conclusion: The experimental results indicate that encoder-decoder models used for structure prediction for information extraction tasks in low-resource settings clearly benefit from grammar-constrained decoding guiding the output generation. In contrast, the evaluated pointer generator models decreased the performance drastically in some cases. Moreover, the performance of the pointer models appears to depend both on the used base model as well as the function used for aggregating the attention values. How the size of large language models affects the performance benefit of grammar-constrained decoding remains to be more structurally investigated in future work. Copyright © 2025 Schmidt and Cimiano.},
	author_keywords = {clinical trials; deep learning; evidence-based medicine; generative large language models; grammar-constrained decoding; PICO; structured information extraction},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Li2024410,
	author = {Li, Yi and Tian, Liwei and Yi, Chengyi and Li, Jingjing and Qin, Xiaodong and He, Yuxuan and Su, Huai},
	title = {A Large Language Model Based Knowledge Mining Method for Improving the Reliability of Fire Water Systems},
	year = {2024},
	journal = {2024 6th International Conference on System Reliability and Safety Engineering, SRSE 2024},
	pages = {410 – 413},
	doi = {10.1109/SRSE63568.2024.10772514},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215273182&doi=10.1109%2fSRSE63568.2024.10772514&partnerID=40&md5=354478f18fa1fe58344a5fcc13c34c7c},
	abstract = {The fire water system plays a critical role in protecting both infrastructure and human lives. An essential aspect of enhancing the reliability of this system is fault diagnosis. However, the current fault diagnosis methods primarily rely on data-driven approaches, which often result in a high threshold for application due to their lack of interpretability. To tackle this challenge, this paper introduces a novel approach based on large language models for knowledge mining from textual data to extract fault information related to the fire water system, thereby enhancing the interpretability of data-driven fault diagnosis methods. The methodology followed in this paper consists of two main steps: firstly, analyzing the characteristics and principles of fire water system faults to develop a fault ontology, and secondly, creating a knowledge mining model using a large language model guided by the established fault ontology. Experimental findings indicate that the proposed model achieves an F1 score of 0.944, meeting the necessary criteria for effective knowledge mining in fire water system fault analysis. Furthermore, a comparative experiment was conducted to evaluate the performance of various encoder models, including GRU, BiGRU, LSTM, BiLSTM, and pre-trained large language model BERT. The results revealed a significant improvement in performance with the BERT encoder, showing increases in F1 scores of 22.12 %, 2.27 %, 17.41 %, and 3.16 % compared to the other models, respectively. This study provides valuable interpretative insights that can enhance the engineering applicability and reliability of data-driven fault diagnosis methods in fire water system.  © 2024 IEEE.},
	author_keywords = {fire water system; knowledge mining; large language model; safety engineering; system reliability},
	keywords = {Fire protection; Intelligent systems; Knowledge based systems; Systems analysis; Data-driven fault diagnosis; Fault diagnosis method; Fire water system; Interpretability; Knowledge mining; Language model; Large language model; System faults; System reliability; Water system; Mine fires},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Ho2024,
	author = {Ho, Huu-Tuong and Ly, Duc-Tin and Nguyen, Luong Vuong},
	title = {Mitigating Hallucinations in Large Language Models for Educational Application},
	year = {2024},
	journal = {2024 IEEE International Conference on Consumer Electronics-Asia, ICCE-Asia 2024},
	doi = {10.1109/ICCE-Asia63397.2024.10773965},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214942280&doi=10.1109%2fICCE-Asia63397.2024.10773965&partnerID=40&md5=79e91fcbc2b0b7295806ca982c34ca8d},
	abstract = {Large Language Models (LLMs) have transformed various fields, including education, by providing intelligent and automated text generation. However, the tendency of these models to generate hallucinated or factually incorrect information poses significant challenges, especially in educational contexts where ac-curacy is paramount. This paper explores various methodologies to mitigate hallucinations in LLMs, focusing on their application in educational settings. We review current approaches, propose a multi-stage framework for reducing hallucinations, and evaluate its effectiveness through empirical studies. © 2024 IEEE.},
	author_keywords = {Educational; Empirical Evaluation; Hallucination; Hybrid Retrieval; Knowledge Graphs; Large Language Models (LLMs); Prompt Engineering},
	keywords = {Computer simulation languages; Educational; Educational Applications; Empirical evaluations; Hallucination; Hybrid retrieval; Knowledge graphs; Language model; Large language model; Prompt engineering; Text generations; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Carta20242235,
	author = {Carta, Salvatore and Giuliani, Alessandro and Manca, Marco Manolo and Piano, Leonardo and Podda, Alessandro Sebastian and Pompianu, Livio and Tiddia, Sandro Gabriele},
	title = {A Zero-Shot Strategy for Knowledge Graph Engineering Using GPT-3.5},
	year = {2024},
	journal = {Procedia Computer Science},
	volume = {246},
	number = {C},
	pages = {2235 – 2243},
	doi = {10.1016/j.procs.2024.09.573},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213342420&doi=10.1016%2fj.procs.2024.09.573&partnerID=40&md5=22d5e4e1e59e27bf7e3fb6cfc94f57e5},
	abstract = {In the recent digitization era, capturing, representing, and understanding knowledge is essential in countless real-world scenarios. Knowledge graphs emerged as a powerful tool for representing information through an adequately interconnected and interpretable structure in such a context. Nevertheless, generating proper knowledge graphs usually requires significant manual effort and domain expertise, resulting in graphs often affected by human subjectivity, limited scalability, or inability to capture implicit knowledge or handle heterogeneity. This paper proposes an innovative zero-shot strategy tailored to uncover reliable knowledge from text leveraging the recent highly effective generative large language models, with a particular focus on the GPT-3.5 model. Our proposal aims to create a suitable knowledge graph or improve existing ones by discovering missing qualitative triples. To assess the effectiveness of our methodology, we performed experiments on domain-specific datasets, confirming its potential for scalable and versatile knowledge discovery. © 2024 The Authors.},
	author_keywords = {Knowledge Engineering; Knowledge Graphs; Large Language Models},
	keywords = {Graphic methods; Zero-shot learning; Digitisation; Domain expertise; Domain specific; Implicit knowledge; Knowledge graphs; Language model; Large language model; Real-world scenario; Shot strategy; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@CONFERENCE{Ta2024,
	author = {Ta, Pralaypati and Gupta, Bhumika and Jain, Arihant and Sneha Sree, C. and Ram, Keerthi and Sivaprakasam, Mohanasankar},
	title = {Knowledge Models for Cancer Clinical Practice Guidelines: Construction, Management and Usage in Question Answering},
	year = {2024},
	journal = {Proceedings of the Annual International Conference of the IEEE Engineering in Medicine and Biology Society, EMBS},
	doi = {10.1109/EMBC53108.2024.10782807},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214974829&doi=10.1109%2fEMBC53108.2024.10782807&partnerID=40&md5=30a6c3ef8db3b964b40f33a0e8c16b9d},
	abstract = {An automated knowledge modeling algorithm for Cancer Clinical Practice Guidelines (CPGs) extracts the knowledge contained in the CPG documents and transforms it into a programmatically interactable, easy-to-update structured model with minimal human intervention. The existing automated algorithms have minimal scope and cannot handle the varying complexity of the knowledge content in the CPGs for different cancer types. This work proposes an improved automated knowledge modeling algorithm to create knowledge models from the National Comprehensive Cancer Network (NCCN) CPGs in Oncology for different cancer types. The proposed algorithm has been evaluated with NCCN CPGs for four different cancer types. We also proposed an algorithm to compare the knowledge models for different versions of a guideline to discover the specific changes introduced in the treatment protocol of a new version. We created a question-answering (Q&A) framework with the guideline knowledge models as the augmented knowledge base to study our ability to query the knowledge models. We compiled a set of 32 question-answer pairs derived from two reliable data sources for the treatment of Non-Small Cell Lung Cancer (NSCLC) to evaluate the Q&A framework. The framework was evaluated against the question-answer pairs from one data source, and it can generate the answers with 54.5% accuracy from the treatment algorithm and 81.8% accuracy from the discussion part of the NCCN NSCLC guideline knowledge model. © 2024 IEEE.},
	author_keywords = {Cancer CPGs; Knowledge Modeling; LLM; NCCN; question-answering; RAG},
	keywords = {Diseases; Knowledge graph; Lung cancer; Cancer clinical practice guideline; Clinical practice guidelines; Data-source; Knowledge model; LLM; Model algorithms; National comprehensive cancer network; Question Answering; Question-answer pairs; RAG; Question answering},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@CONFERENCE{2024,
	title = {AIxEDU 2024 - Proceedings of the 2nd International Workshop on Artificial INtelligent Systems in Education, co-located with 23rd International Conference of the Italian Association for Artificial Intelligence, AIxIA 2024},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3879},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214242226&partnerID=40&md5=9e46d795ec69e5b966dee3bc3682d29f},
	abstract = {The proceedings contain 16 papers. The topics discussed include: enhancing instructional design: the impact of CONALI ontology and ChatGPT in primary education training; generative AI for teaching Latin and Greek in high school; fostering metacognitive skills in programming: leveraging AI to reflect on code; speeding up design and making to reduce time-to-project and time-to-market: an AI-enhanced approach in engineering education; enhancing educational outcomes and well-being through technology-supported object-based learning: the RESTART Project at the University of Tor Vergata; EULER: fine-tuning a large language model for Socratic interactions; large language models for the assessment of students’ authentic tasks: a replication study in higher education; and uninvited generative ai has joined our students: tackling disinformation and creating content with the help of AI apps.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Vandemoortele202454,
	author = {Vandemoortele, Nathan and Steenwinckel, Bram and Van Hoecke, Sofie and Ongenae, Femke},
	title = {Scalable Table-to-Knowledge Graph Matching from Metadata using LLMs},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3889},
	pages = {54 – 68},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214864616&partnerID=40&md5=73067eb5dcc1a79f668fbec7ee463d8a},
	abstract = {Addressing the challenge of interoperability when integrating and interpreting large datasets from diverse sources is essential for businesses aiming to make informed, data-driven decisions. Therefore, the 2024 Semantic Web Challenge on Tabular Data to Knowledge Graph Matching (SemTab) focuses on using metadata, such as column names, to map tables to semantic concepts within standardized vocabularies or Knowledge Graphs (KGs). The challenge involves mapping two datasets, one to the DBpedia ontology and the other to a custom vocabulary. Our approach begins with applying Retrieval-Augmented Generation (RAG) for a broad search of relevant matches, ensuring scalability. We then refine these matches using a Large Language Model (LLM) with Chain-of-Thought (CoT) prompting and Self-Consistency (SC). Finally, we combine the results using Reciprocal Rank Fusion (RRF) to obtain a final ranking of the matches. This method achieves hit rates of 62% (top 1) and 82% (top 5) for the first dataset, and 84% (top 1) and 98% (top 5) for the second. The LLM’s strong semantic understanding and extensive knowledge base provide significant advantages over traditional human labeling, which is often laborious and time-consuming. Furthermore, the LLM’s zero-shot capability removes the need for additional task-specific training data, making this solution applicable across various domains. Despite limitations like computational costs and the need for well-defined concepts in the ontology or vocabulary, our approach remains cost-effective compared to extensive human labeling. Moreover, we leave room to trade performance for scalability if needed, pending further research. © 2024 Copyright for this paper by its authors.},
	author_keywords = {data linkage; knowledge graphs; large language models; metadata; retrieval augmented generation; zero-shot learning},
	keywords = {Data consistency; Large datasets; Metadata; Ontology; Scalability; Semantics; Spatio-temporal data; Zero-shot learning; Data driven decision; Data linkage; Graph matchings; Human labelling; Knowledge graphs; Language model; Large datasets; Large language model; Ontology's; Retrieval augmented generation; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Maathuis2024252,
	author = {Maathuis, Clara and Kerkhof, Iddo},
	title = {Navigating Online Narratives on Israel-Hamas War with LLMs},
	year = {2024},
	journal = {Proceedings of the 4th International Conference on AI Research, ICAIR 2024},
	pages = {252 – 259},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215702850&partnerID=40&md5=675551d0929fd0dd4f0a46764be647db},
	abstract = {In recent years, international conflicts have seen a steady rise, accompanied by the increased use of technological advancements to achieve strategic and military objectives. One such conflict, the ongoing hostilities between Israel and Hamas, exemplifies the complex interplay of political, ideological, social, and technological factors shaping contemporary warfare. While extensive analysis is devoted to analysing strategic, historical, and economic dimensions, still limited attention is directed through research efforts towards the vast troves of information available on global social media platforms such as YouTube. These platforms serve as conduits for a wide range of narratives, opinions, and representations related to this war, by providing valuable insights into public discourse and sentiments. Given the capability of automatically and systematically analysing vast amount of content, this research tackles the above stated knowledge gap by developing a novel explorative LLMs (Large Language Models)-based modelling approach to efficiently extract, categorize, and interpret nuanced discussions surrounding the Israel-Palestinian war. It does that following the Data Science methodological approach and focusing on YouTube data aiming at not only contributing to enriching understanding of contemporary conflicts through social media platforms, but also to reflect on the evolving role that state-of-the-art AI technological developments play in shaping the global security landscape. © Proceedings of the 4th International Conference on AI Research, ICAIR 2024.},
	author_keywords = {Generative AI; Israel-Hamas war; Israel-Palestine War; Knowledge graphs; Large language models; LLMs},
	keywords = {Generative AI; Israel-hamas war; Israel-palestine war; Knowledge graphs; Language model; Large language model; Palestine; Social media platforms; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Melhem2024235,
	author = {Melhem, Wasen and Abdi, Asad and Meziane, Farid},
	title = {Traffic Detection and Forecasting from Social Media Data Using a Deep Learning-Based Model, Linguistic Knowledge, Large Language Models, and Knowledge Graphs},
	year = {2024},
	journal = {International Joint Conference on Knowledge Discovery, Knowledge Engineering and Knowledge Management, IC3K - Proceedings},
	volume = {2},
	pages = {235 – 242},
	doi = {10.5220/0013066900003838},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215287189&doi=10.5220%2f0013066900003838&partnerID=40&md5=a9556fd77d61292987212895f5ccce7c},
	abstract = {Traffic data analysis and forecasting is a multidimensional challenge that extracts details from sources such as social media and vehicle sensor data. This study proposes a three-stage framework using Deep Learning (DL) and natural language processing (NLP) techniques to enhance the end-to-end pipeline for traffic event identification and forecasting. The framework first identifies relevant traffic data from social media using NLP, context, and word-level embeddings. The second phase extracts events and locations to dynamically construct a knowledge graph using deep learning and slot filling. A domain-specific large language model (LLM), enriched with this graph, improves traffic information relevancy. The final phase integrates Allen's interval algebra and region connection calculus to forecast traffic events based on temporal and spatial logic. This framework’s goal is to improve the accuracy and semantic quality of traffic event detection, bridging the gap between academic research and real-world systems, and enabling advancements in intelligent transport systems (ITS). © 2024 by SCITEPRESS – Science and Technology Publications, Lda.},
	author_keywords = {Allen’s Interval Algebra; Deep Learning; Fine Tuning; Instruction Tuning; Knowledge Graphs; Large Language Models; Natural Language Processing; Region Connection Calculus; Retrieval Augmented Generation},
	keywords = {Deep learning; Graph embeddings; Natural language processing systems; Pipeline processing systems; Semantics; Allen’s interval algebra; Deep learning; Fine tuning; Instruction tuning; Interval algebra; Knowledge graphs; Language model; Language processing; Large language model; Natural language processing; Natural languages; Region connection calculus; Retrieval augmented generation; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Lee2024,
	author = {Lee, Chang-Shing and Wang, Mei-Hui and Tseng, Guan-Ying and Yue, Chao-Cyuan and Hsieh, Hao-Chun and Reformat, Marek},
	title = {Cao Robot for Taiwanese/English Knowledge Graph Application},
	year = {2024},
	journal = {2024 27th Conference on the Oriental COCOSDA International Committee for the Co-Ordination and Standardisation of Speech Databases and Assessment Techniques, O-COCOSDA 2024 - Proceedings},
	doi = {10.1109/O-COCOSDA64382.2024.10800729},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215670709&doi=10.1109%2fO-COCOSDA64382.2024.10800729&partnerID=40&md5=4fc834e567c41c21cba26bf8f0bd6d34},
	abstract = {This paper proposes a Content Attention Ontology (CAO) robot for constructing Taiwanese/English Knowledge Graphs (KGs) by prompting audio or texts to Large Language Models (LLMs), including TAIDE, Zephyr, and Llama 3.1. The collected data includes lecture videos from the IEEE WCCI 2024 in Japan and the 2024 National Language Development Forum in Taiwan, along with students' learning data from the 2024 Summer School on Taiwanese/English Human and Robot Co-Learning at Rende Elementary School (RDES). In addition, the fundamental concepts of Computational Intelligence (CI) and Quantum CI (QCI) learning were incorporated into the study. The generative KGs highlight important concepts, relations, and communities within the collected teaching and learning data. Additionally, we utilized data from subjects wearing braincomputer interface (BCI) devices while speaking Taiwanese/English to generate KGs. We also compared the differences in these KGs and analyzed the similarities between the transcribed texts of lectures and learners. In the future, we plan to expand the CAO robot to more validation fields across Taiwan, aiming to engage young students in speaking Taiwanese while concurrently enhancing their English language skills through interaction with the robot.  © 2024 IEEE.},
	author_keywords = {CAO Robot; Knowledge Graph; Large Language Model; Llama 3.1; TAIDE; Taiwanese/English Language Co-learning},
	keywords = {Adversarial machine learning; Contrastive Learning; Federated learning; Robot learning; Robots; Students; Co-learning; Content attention ontology robot; English languages; Knowledge graphs; Language model; Large language model; Llama 3.1; Ontology's; TAIDE; Taiwanese/english language co-learning; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@BOOK{Ni202487,
	author = {Ni, Fei and Wang, Bingyan and Li, Rongpeng and Zhao, Zhifeng and Zhang, Honggang},
	title = {Interplay of Semantic Communication and Knowledge Learning},
	year = {2024},
	journal = {Wireless Semantic Communications: Concepts, Principles, and Challenges},
	pages = {87 – 108},
	doi = {10.1002/9781394223336-5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216011573&doi=10.1002%2f9781394223336-5&partnerID=40&md5=efc94bfe7be4a3f551b9f250913e4139},
	abstract = {In the swiftly advancing realm of communication technologies, semantic communication (SemCom), which emphasizes knowledge understanding and processing, has emerged as a hot topic. By integrating artificial intelligence technologies, SemCom facilitates a profound understanding, analysis, and transmission of communication content. In this chapter, we clarify the means of knowledge learning in SemCom with a particular focus on the utilization of knowledge graphs (KGs). Specifically, we first review existing efforts that combine SemCom with knowledge learning. Subsequently, we introduce a KG‐enhanced SemCom system, wherein the receiver is carefully calibrated to leverage knowledge from its static knowledge base for ameliorating the decoding performance. Contingent upon this framework, we further explore potential approaches that can empower the system to operate in an evolving knowledge base more effectively. Furthermore, we investigate the possibility of integration with large language models (LLMs) for data augmentation, offering additional perspective on the potential implementation means of SemCom. Extensive numerical results demonstrate that the proposed framework yields superior performance on top of the KG‐enhanced decoding and manifests its versatility under different scenarios. © 2025 John Wiley and Sons, Ltd. All rights reserved.},
	author_keywords = {deep learning; knowledge graph; large language model; semantic communication; semantic extraction},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Kurteva2024,
	author = {Kurteva, Anelia and Domingue, John},
	title = {Towards Cultivating Decentralised Data Privacy, Interoperability and Trust with Semantic PETs and Visualisations},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3891},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215982706&partnerID=40&md5=725e21c7adf993258815a33f4f252770},
	abstract = {Recent artificial intelligence (AI) advancements in the fields of generative AI and hyper-automation in the Internet of Things (IoT) have turned data into a valuable highly sought-after asset and an economical resource for the ever-growing service digitization. Fields such as smart cities, e-commerce and finance now often integrate AI to improve and optimise online services, which requires large volumes of diverse high-quality data. Most of the data that is generated, related and used by humans for AI in any of these domains can be categorised as personal. The access to it, its processing and sharing for different purposes between different software agents, humans and organisations, if not governed and legally compliant, can jeopardise individuals' privacy and sovereignty both online and offline. Through the years, several eminent data misuse cases have shown that the current centralised digital data ecosystem is easily exploitable and that there is a lack of transparency and accountability along the data supply chain. Individuals have long ago lost control over their data due to vendor lock-ins and their privacy is often violated. The growing number of fines issued to numerous organisations in response to violating the General Data Protection Regulation (GDPR) by misusing individual's personal data, further confirm this. A new paradigm shift towards decentralisation of the Web has emerged as a solution. However, implementing data and privacy governance in a decentralised setting poses new technical and organisational challenges that are currently being investigated and a standard solution is yet to be established. Further, there is a lack of tools aimed at assisting and guiding individuals in managing their decentralised data. In this paper, we propose the development of a more human-centered approach for building trusted self-sovereign decentralised spaces for personal data governance based on combining semantics with privacy enhancing technologies (PETs) and the utilisation of graphical visualisations. We present the main building blocks of the proposed approach with the main goal to foster further discussion and collaboration between the Semantic Web, Privacy, Decentralisation, Human-Computer Interaction and Legal communities.  © 2024 Copyright for this paper by its authors.},
	author_keywords = {Data Visualisation; Decentralisation; Knowledge Graphs; Legal Compliance; Ontologies; Privacy Enhancing Technologies; Trust},
	keywords = {Differential privacy; Decentralisation; Decentralised; Digitisation; E finances; E- commerces; Knowledge graphs; Legal compliance; Ontology's; Privacy enhancing technologies; Trust; Decentralized finance},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Yang2024,
	author = {Yang, Weijie and Zhang, Chunyu and Zhang, Min and Jiang, Xunjie and Fan, Yanlin and Bi, Zhongbo and Xiong, Jiansheng and Wang, Danshi},
	title = {Multi-Modal Knowledge Graph with Large Language Model for Intelligent Fault Management in Optical Networks},
	year = {2024},
	journal = {Asia Communications and Photonics Conference, ACP},
	doi = {10.1109/ACP/IPOC63121.2024.10809842},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214978344&doi=10.1109%2fACP%2fIPOC63121.2024.10809842&partnerID=40&md5=9b276d122a411ae9c74103ee0e6ac9a3},
	abstract = {We propose a multi-modal knowledge graph with large language model for intelligent fault management in optical networks. Demonstrations of two real-world cases validate its capability to utilize multi-modal data and facilitate intelligent reasoning. © 2024 IEEE.},
	author_keywords = {Intelligent fault management; Large language models; Multi-modal knowledge graph; Optical networks},
	keywords = {Knowledge graph; Fault management; Intelligent fault management; Knowledge graphs; Language model; Large language model; Multi-modal; Multi-modal data; Multi-modal knowledge graph; Optical-; Real-world},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Dominic2024340,
	author = {Dominic, Nicholas and Pardamean, Bens},
	title = {Knowledge Graph-Enhanced Semantic Cache for Low-Latency and Cost-Effective Inference in Large Language Models},
	year = {2024},
	journal = {Proceedings of 2024 International Conference on Information Management and Technology, ICIMTech 2024},
	pages = {340 – 344},
	doi = {10.1109/ICIMTech63123.2024.10780864},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216034299&doi=10.1109%2fICIMTech63123.2024.10780864&partnerID=40&md5=6b42abe47931562259eccdb59173e741},
	abstract = {In organizational knowledge management, Large Language Model (LLM) caches act as a semantic repository gathered from previous LLM responses. Due to intensive calls from multiple users, LLM may suffer from high inference latency. While there are many prior available approaches to solve this problem, most of them are inherently complex. This paper introduced a Knowledge Graph-enhanced Semantic Cache mechanism as an alternative, lightweight technique to boost retrieval for similar prompts. The latest state-of-the-art open-source LLM, named Google's Gemma-2B-it, was used to generate sample prompts and responses as a draft, while a knowledge graph (KG) was built from Wikipedia sentences. To create embeddings of prompts and KG, all-MiniLM-L6-v2 from SentenceTransformer was used. This new cache system resulted in up to 28% improvement over a standard model. In particular, reinforcement with KG cache embeddings yielded more than 85% semantic cache accuracy. To map the next trajectory of this pilot study, an overview of the extended framework for LLM knowledge management was also presented in this paper. The framework includes the new KG- enhanced cache system equipped with scalable security and fallback mechanisms that can promote green technology through substantial improvements in latency, throughput, and overall LLM costs. © 2024 IEEE.},
	author_keywords = {green technology; knowledge graph; large language models; semantic cache; symmetric similarity search},
	keywords = {Cache memory; Embeddings; Semantics; Embeddings; Enhanced semantics; Green technology; Knowledge graphs; Language model; Large language model; Semantic cache; Similarity search; Symmetric similarity search; Symmetrics; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Vakaj2024,
	author = {Vakaj, Edlira and Stamatia, Rizou and Mihindukulasooriya, Nandana and Tiwari, Sanju and Ortiz-Rodríguez, Fernando and McGranaghan, Ryan},
	title = {3rd InternationalWorkshop on Natural Language Processing for Knowledge Graph Creation (NLP4KGC 2024)},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3874},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214253632&partnerID=40&md5=876fe9d55cf79c76113d3f1ebf323178},
	abstract = {Knowledge Graphs (KG) are emerging and becoming increasingly popular. Building a domain knowledge graph from a large amount of text is a challenging task which requires a tremendous amount of work, including entity recognition, entity disambiguation, and relationship extraction. In this context, the 3rd NLP4KGC workshop brings together academics, industry experts, and enthusiasts from the natural language processing (NLP) and knowledge graph (KG) creation fields in a common forum. The objective is to foster collaboration and knowledge sharing among researchers, developers, and practitioners working at the cutting edge of NLP and KG creation. After two successful previous editions, the 3rd NLP4KGc is co-located with the 20th International Conference on Semantic Systems (SEMANTiCS 2024). After a rigorous review process, 10 papers were accepted for oral presentations at the event. Workshop Website: https://sites.google.com/view/3rdnlp4kgc/ Previous Proceedings: https://ceur-ws.org/Vol-3510/, https://doi.org/10.1145/3543873.3589746.  © 2024 Copyright for this paper by its authors.},
	author_keywords = {graph neural networks; knowledge graphs; large language models; natural language processing; responsible AI; semantics},
	keywords = {Graph neural networks; Natural language processing systems; Semantics; Domain knowledge; Graph neural networks; Knowledge graphs; Language model; Language processing; Large language model; Natural language processing; Natural languages; Processing graphs; Responsible AI; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Bara2024,
	author = {Bara, Davide Mario Ricardo},
	title = {Prompt engineering for tail prediction in domain-specific knowledge graph completion tasks},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3853},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212709925&partnerID=40&md5=c9122b4f64d0bae7bd6e351bd1579971},
	abstract = {In this paper we propose a system architecture for tackling the LM-KBC Challenge 2024 [1] task as a tail prediction problem in a knowledge graph completion setup. We experiment with several prompting techniques as suggested in the TELER taxonomy [2]. We notice that under the few-shot paradigm, using In-Context-Learning by supplying the LLM with valuable public information about the query subject and expert knowledge about the relation under study, we can improve the tail prediction performance. © 2024 Copyright for this paper by its authors.},
	keywords = {Prediction models; Context learning; Domain-specific knowledge; Expert knowledge; In contexts; Knowledge graphs; Prediction performance; Prediction problem; Public information; Systems architecture; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Rangel202436,
	author = {Rangel, Julio C. and Mendes de Farias, Tarcisio and Sima, Ana Claudia and Kobayashi, Norio},
	title = {SPARQL Generation: an analysis on fine-tuning OpenLLaMA for Question Answering over a Life Science Knowledge Graph},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3890},
	pages = {36 – 45},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214895238&partnerID=40&md5=eff3a35e1b7573c2785409cde4fb76f8},
	abstract = {The recent success of Large Language Models (LLM) in a wide range of Natural Language Processing applications opens the path towards novel Question Answering Systems over Knowledge Graphs leveraging LLMs. However, one of the main obstacles preventing their implementation is the scarcity of training data for the task of translating questions into corresponding SPARQL queries, particularly in the case of domain-specific KGs. To overcome this challenge, in this study, we evaluate several strategies for fine-tuning the OpenLlama LLM for question answering over life science knowledge graphs. In particular, we propose an end-to-end data augmentation approach for extending a set of existing queries over a given knowledge graph towards a larger dataset of semantically enriched question-to-SPARQL query pairs, enabling fine-tuning even for datasets where these pairs are scarce. In this context, we also investigate the role of semantic”clues” in the queries, such as meaningful variable names and inline comments. Finally, we evaluate our approach over the real-world Bgee gene expression knowledge graph and we show that semantic clues can improve model performance by up to 33% compared to a baseline with random variable names and no comments included. © 2024 Copyright for this paper by its authors.},
	author_keywords = {Knowledge Graphs; Large Language Models; Question Answering; SPARQL},
	keywords = {Gene expression; Knowledge graph; Structured Query Language; Fine tuning; Knowledge graphs; Language model; Large language model; Life-sciences; Natural language processing applications; Question Answering; Question answering systems; SPARQL; Training data; Question answering},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Kömeçoǧlu2024187,
	author = {Kömeçoǧlu, Başak Buluz and Yilmaz, B Urcu},
	title = {Knowledge-Augmented Large Language Model Prompting for Cypher Query Construction},
	year = {2024},
	journal = {UBMK 2024 - Proceedings: 9th International Conference on Computer Science and Engineering},
	pages = {187 – 192},
	doi = {10.1109/UBMK63289.2024.10773450},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215532421&doi=10.1109%2fUBMK63289.2024.10773450&partnerID=40&md5=616e4017e2b00779476f7ab5127b5f55},
	abstract = {While existing large language models demonstrate remarkable proficiency inn a turall a nguage processing tasks, their capacity for knowledge graph structuring remains a potential avenue for enhancement, particularly in the context of knowledge graph question answering. This paper presents a novel method for knowledge-enriched LLM routing for the construction of Cypher queries utilising knowledge graphs. It is proposed that the prompts of LLMs be enriched with knowledge by the addition of relevant triples taken from the knowledge graph. The proposed method facilitates the generation of more precise and pertinent Cypher queries by LLMs, thereby enhancing their question-answering capabilities. The method is evaluated using a story-based knowledge graph question answering dataset, which is introduced in this paper as a new contribution to the literature. The results demonstrate that the incorporation of knowledge enhances the performance of knowledge graph question answering (KGQA), particularly in the context of complex and temporal inquiries. Furthermore, the utilisation of a story graph structure for the modelling of events in news texts facilitates the effective resolution of complex questions by following the paths on the graph. Finally, it is demonstrated that the extraction of temporal labels and their incorporation into the knowledge graph is of paramount importance in answering temporal questions. © 2024 IEEE.},
	author_keywords = {knowledge graph; language model; natural language processing; prompt engineering; question answering},
	keywords = {Modeling languages; Natural language processing systems; Query languages; Query processing; Question answering; Structured Query Language; Knowledge graphs; Language model; Language processing; Natural language processing; Natural languages; Novel methods; Prompt engineering; Query construction; Question Answering; Routings; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Abbasian2024,
	author = {Abbasian, Mahyar and Yang, Zhongqi and Khatibi, Elahe and Zhang, Pengfei and Nagesh, Nitish and Azimi, Iman and Jain, Ramesh and Rahmani, Amir M.},
	title = {Knowledge-Infused LLM-Powered Conversational Health Agent: A Case Study for Diabetes Patients},
	year = {2024},
	journal = {Proceedings of the Annual International Conference of the IEEE Engineering in Medicine and Biology Society, EMBS},
	doi = {10.1109/EMBC53108.2024.10781547},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214971664&doi=10.1109%2fEMBC53108.2024.10781547&partnerID=40&md5=c924f7befaaa79221ba2220686c64ce6},
	abstract = {Effective diabetes management is crucial for maintaining health in diabetic patients. Large Language Models (LLMs) have opened new avenues for diabetes management, facilitating their efficacy. However, current LLM-based approaches are limited by their dependence on general sources and lack of integration with domain-specific knowledge, leading to inaccurate responses. In this paper, we propose a knowledge-infused LLM-powered conversational health agent (CHA) for diabetic patients. We customize and leverage the open-source openCHA framework, enhancing our CHA with external knowledge and analytical capabilities. This integration involves two key components: 1) incorporating the American Diabetes Association dietary guidelines and the Nutritionix information and 2) deploying analytical tools that enable nutritional intake calculation and comparison with the guidelines. We compare the proposed CHA with GPT4. Our evaluation includes 100 diabetes-related questions on daily meal choices and assessing the potential risks associated with the suggested diet. Our findings show that the proposed agent demonstrates superior performance in generating responses to manage essential nutrients. © 2024 IEEE.},
	author_keywords = {Diabetes; Health Agents; Knowledge Graph; LLMs; Nutrition Therapy},
	keywords = {Knowledge graph; Case-studies; Diabetes management; Diabetes patients; Diabetics patients; Health agent; Knowledge graphs; Language model; Large language model; Management IS; Nutrition therapy},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Green Open Access}
}

@CONFERENCE{Gan2024514,
	author = {Gan, Lu and Wang, Peng and Zhang, Di and Cao, Yiqun and Zhou, Liwan and Zhang, Yongjun},
	title = {Application Analysis and Prospect of GPT-enabled Digital Transformation of Power Systems},
	year = {2024},
	journal = {2024 IEEE IAS Industrial and Commercial Power System Asia, I and CPS Asia 2024},
	pages = {514 – 519},
	doi = {10.1109/ICPSAsia61913.2024.10761764},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214495066&doi=10.1109%2fICPSAsia61913.2024.10761764&partnerID=40&md5=e71a135dba6a5ed943e2496f466d3dea},
	abstract = {The rapid development of Generative Pre-trained Transformer (GPT) models brings both opportunities and challenges to power system digital and intelligence transformation. Starting with the summarization of the concept and technical architecture of GPT models, four kinds of potential application scenarios in new power systems related to GPT models are presented. Then, the integration of GPT models with several typical digital technologies in new power systems are reviewed, such as computer vision, human-computer interaction, knowledge graph, Internet of Things, and Blockchain. Finally, the challenge and development direction of GPT models for new power systems are prospected. The comprehensive analysis could provide theoretical and application guidance for the development of GPT-enabled models in new power systems. © 2024 IEEE.},
	author_keywords = {application scenarios; digital transformation; GPT model; large language model; new power system},
	keywords = {Power systems computer aided design; Application analysis; Application prospect; Application scenario; Digital transformation; Generative pre-trained transformer model; Language model; Large language model; New power system; Power; Transformer modeling; Power system analysis},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Mo2024215,
	author = {Mo, Fan and Chaplin, Jack C. and Sanderson, David and Ratchev, Svetan},
	title = {Advancing Capability Matching in Manufacturing Reconfiguration with Large Language Models},
	year = {2024},
	journal = {Lecture Notes in Mechanical Engineering},
	pages = {215 – 222},
	doi = {10.1007/978-3-031-74485-3_24},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213309666&doi=10.1007%2f978-3-031-74485-3_24&partnerID=40&md5=b63acd27234c11a1084b9ec409124454},
	abstract = {This paper introduces an approach that integrates Natural Language Processing (NLP) and knowledge graphs with Reconfigurable Manufacturing Systems (RMS) to enhance flexibility and adaptability. We utilize a chatbot interface powered by GPT-4 and a structured knowledge base to simplify the complexities of manufacturing reconfiguration. This system not only boosts reconfiguration efficiency but also broadens accessibility to advanced manufacturing technologies. We demonstrate our methodology through an application in capability matching, showcasing how it facilitates the identification of assets for new product requirements. Our results indicate that this integrated solution offers a scalable and user-friendly approach to overcoming adaptability challenges in modern manufacturing environments. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {chatbot; knowledge graph; large language model; manufacturing reconfiguration; natural language processing},
	keywords = {Smart manufacturing; Capability matching; Chatbots; Knowledge graphs; Language model; Language processing; Large language model; Manufacturing reconfiguration; Natural language processing; Natural languages; Processing graphs; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Di Nuzzo2024128,
	author = {Di Nuzzo, Dario and Vakaj, Edlira and Saadany, Hadeel and Grishti, Eglantina and Mihindukulasooriya, Nandana},
	title = {Automated Generation of Competency Questions Using Large Language Models and Knowledge Graphs},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3874},
	pages = {128 – 153},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214252305&partnerID=40&md5=2e515c25d50189663298029bd1f0cbd0},
	abstract = {This research presents a novel approach to automated competency question generation by integrating Large Language Models (LLMs) with Knowledge Graphs (KGs), particularly within the context of sustainability assessment standards like BREEAM. The study develops a comprehensive methodology combining natural language processing and knowledge representation to address the challenges of manual question generation in competency-based assessments. The methodology begins with text extraction from BREEAM standards, followed by preprocessing, transformation into graph documents, and the construction of a structured KG. Advanced LLMs, including GPT-4o and Mistral, are employed to generate competency questions based on entity-specific and community-focused retrieval methods. The system is rigorously evaluated using quantitative metrics such as cosine similarity scores and qualitative assessments using the "LLM-as-a-Judge"method. Results demonstrate that GPT-4 and Mistral models generate highly relevant, clear, and complex questions, highlighting the potential for scalable, domainspecific competency assessments. This research opens avenues for improving AI-driven educational technologies and personalised learning through automated, adaptive assessment tools.  © 2024 Copyright for this paper by its authors.},
	author_keywords = {Artificial Intelligence; Competency Question; Large Language Models; Natural Language Processing},
	keywords = {Natural language processing systems; Automated generation; Competency question; Knowledge graphs; Knowledge-representation; Language model; Language processing; Large language model; Natural language processing; Natural languages; Sustainability assessment; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Kabal20242617,
	author = {Kabal, Othmane and Harzallah, Mounira and Guillet, Fabrice and Ichise, Ryutaro},
	title = {Enhancing Domain-Independent Knowledge Graph Construction through OpenIE Cleaning and LLMs Validation},
	year = {2024},
	journal = {Procedia Computer Science},
	volume = {246},
	number = {C},
	pages = {2617 – 2626},
	doi = {10.1016/j.procs.2024.09.436},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213339134&doi=10.1016%2fj.procs.2024.09.436&partnerID=40&md5=2055d155a77810cedf773e0f34e2426e},
	abstract = {In the challenging context of Knowledge Graph (KG) construction from text, traditional approaches often rely on Open Information Extraction (OpenIE) pipelines. However, they are prone to generating many incorrect triplets. While domain specific Named Entity Recognition (NER) is commonly used to enhance the results, it compromises the domain independence and misses crucial triplets. To address these limitations, we introduce G-T2KG, a novel pipeline for KG construction that aims to preserve the domain independence while reducing incorrect triplets, thus offering a cost-effective solution without the need for domain-specific adaptations. Our pipeline utilizes state-of-the-art OpenIE combined with both a noun phrase-based cleaning and a LLMs based validation. It is evaluated using gold standards in two distinct domains (i.e., computer science and music) that we have constructed in the context of this study. On computer science corpus, the experimental results demonstrate a higher recall as compared to state-of-the-art approaches, and a higher precision notably increased by the integration of LLMs. Experiments on the music corpus show good performance, underscoring the versatility and effectiveness of G-T2KG in domain-independent KG construction. © 2024 The Authors.},
	author_keywords = {Domain-independent building; From raw text; Information Extraction; Knowledge graph; Knowledge graph construction pipeline; LLMs based validation; LLMs for KG},
	keywords = {Knowledge graph; Natural language processing systems; Domain independents; Domain-independent building; From raw text; Graph construction; Information extraction; Knowledge graph construction pipeline; Knowledge graphs; LLM based validation; LLM for knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Sun2024548,
	author = {Sun, Jiawei and Zhang, Quan and Zhi, Yongqi and Ling, Weiqing},
	title = {Knowledge Graph Indexing Enhanced Q&A System Based on Large Language Model},
	year = {2024},
	journal = {2024 4th International Conference on Electronic Information Engineering and Computer Science, EIECS 2024},
	pages = {548 – 553},
	doi = {10.1109/EIECS63941.2024.10800696},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216319745&doi=10.1109%2fEIECS63941.2024.10800696&partnerID=40&md5=78da955438a5d364f1add119210a4a03},
	abstract = {With the advent of the digital age, the explosive growth of data has brought unprecedented opportunities and challenges to societal development. The rapid evolution of data science is driving innovation and progress across various industries. Both the business and academic communities recognize the immense potential hidden within vast amounts of data. Extracting truly valuable information from this data has become a critical issue that needs to be addressed. As technology advances swiftly and data accumulates rapidly, traditional processing and analysis methods can no longer keep up with the current volume and velocity of data. This has prompted data professionals to seek innovative solutions to handle increasingly complex and massive data relationships and quantities. Against this backdrop, two key technologies have emerged due to their exceptional performance-knowledge graphs and large language models  © 2024 IEEE.},
	author_keywords = {Knowledge graph; knowledge question answering; lapping process knowledge; large language model},
	keywords = {Digital age; Graph indexing; Knowledge graphs; Knowledge question answering; Language model; Lapping process; Lapping process knowledge; Large language model; Process knowledge; Question Answering; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Cao2024,
	author = {Cao, Lang and Sun, Jimeng and Cross, Adam},
	title = {An Automatic and End-to-End System for Rare Disease Knowledge Graph Construction Based on Ontology-Enhanced Large Language Models: Development Study},
	year = {2024},
	journal = {JMIR Medical Informatics},
	volume = {12},
	doi = {10.2196/60665},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214677383&doi=10.2196%2f60665&partnerID=40&md5=c6b40494479e4384a9f116b6833e56f3},
	abstract = {Background: Rare diseases affect millions worldwide but sometimes face limited research focus individually due to low prevalence. Many rare diseases do not have specific International Classification of Diseases, Ninth Edition (ICD-9) and Tenth Edition (ICD-10), codes and therefore cannot be reliably extracted from granular fields like “Diagnosis” and “Problem List” entries, which complicates tasks that require identification of patients with these conditions, including clinical trial recruitment and research efforts. Recent advancements in large language models (LLMs) have shown promise in automating the extraction of medical information, offering the potential to improve medical research, diagnosis, and management. However, most LLMs lack professional medical knowledge, especially concerning specific rare diseases, and cannot effectively manage rare disease data in its various ontological forms, making it unsuitable for these tasks. Objective: Our aim is to create an end-to-end system called automated rare disease mining (AutoRD), which automates the extraction of rare disease–related information from medical text, focusing on entities and their relations to other medical concepts, such as signs and symptoms. AutoRD integrates up-to-date ontologies with other structured knowledge and demonstrates superior performance in rare disease extraction tasks. We conducted various experiments to evaluate AutoRD’s performance, aiming to surpass common LLMs and traditional methods. Methods: AutoRD is a pipeline system that involves data preprocessing, entity extraction, relation extraction, entity calibration, and knowledge graph construction. We implemented this system using GPT-4 and medical knowledge graphs developed from the open-source Human Phenotype and Orphanet ontologies, using techniques such as chain-of-thought reasoning and prompt engineering. We quantitatively evaluated our system’s performance in entity extraction, relation extraction, and knowledge graph construction. The experiment used the well-curated dataset RareDis2023, which contains medical literature focused on rare disease entities and their relations, making it an ideal dataset for training and testing our methodology. Results: On the RareDis2023 dataset, AutoRD achieved an overall entity extraction F1-score of 56.1% and a relation extraction F1-score of 38.6%, marking a 14.4% improvement over the baseline LLM. Notably, the F1-score for rare disease entity extraction reached 83.5%, indicating high precision and recall in identifying rare disease mentions. These results demonstrate the effectiveness of integrating LLMs with medical ontologies in extracting complex rare disease information. Conclusions: AutoRD is an automated end-to-end system for extracting rare disease information from text to build knowledge graphs, addressing critical limitations of existing LLMs by improving identification of these diseases and connecting them to related clinical features. This work underscores the significant potential of LLMs in transforming health care, particularly in the rare disease domain. By leveraging ontology-enhanced LLMs, AutoRD constructs a robust medical knowledge base that incorporates up-to-date rare disease information, facilitating improved identification of patients and resulting in more inclusive research and trial candidacy efforts. © Lang Cao, Jimeng Sun, Adam Cross. Originally published in JMIR Medical Informatics.},
	author_keywords = {artificial intelligence; clinical informatics; data extraction; knowledge graphs; large language models; LLM; machine learning; natural language processing; ontologies; rare disease; text mining},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Kosten2024,
	author = {Kosten, Catherine and Nooralahzadeh, Farhad and Stockinger, Kurt},
	title = {Evaluating the effectiveness of prompt engineering for knowledge graph question answering},
	year = {2024},
	journal = {Frontiers in Artificial Intelligence},
	volume = {7},
	doi = {10.3389/frai.2024.1454258},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216184385&doi=10.3389%2ffrai.2024.1454258&partnerID=40&md5=82d845d42d3892877d5b41766adddecb},
	abstract = {Many different methods for prompting large language models have been developed since the emergence of OpenAI's ChatGPT in November 2022. In this work, we evaluate six different few-shot prompting methods. The first set of experiments evaluates three frameworks that focus on the quantity or type of shots in a prompt: a baseline method with a simple prompt and a small number of shots, random few-shot prompting with 10, 20, and 30 shots, and similarity-based few-shot prompting. The second set of experiments target optimizing the prompt or enhancing shots through Large Language Model (LLM)-generated explanations, using three prompting frameworks: Explain then Translate, Question Decomposition Meaning Representation, and Optimization by Prompting. We evaluate these six prompting methods on the newly created Spider4SPARQL benchmark, as it is the most complex SPARQL-based Knowledge Graph Question Answering (KGQA) benchmark to date. Across the various prompting frameworks used, the commercial model is unable to achieve a score over 51%, indicating that KGQA, especially for complex queries, with multiple hops, set operations and filters remains a challenging task for LLMs. Our experiments find that the most successful prompting framework for KGQA is a simple prompt combined with an ontology and five random shots. Copyright © 2025 Kosten, Nooralahzadeh and Stockinger.},
	author_keywords = {knowledge graph question answering; LLMs; prompt engineering; RDF; SPARQL},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@CONFERENCE{Kommineni202419,
	author = {Kommineni, Vamsi Krishna and König-Ries, Birgitta and Samuel, Sheeba},
	title = {Towards the Automation of Knowledge Graph Construction Using Large Language Models},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3874},
	pages = {19 – 34},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214197878&partnerID=40&md5=c4ce0ae9c8b2f8c98f2364b50cb3c716},
	abstract = {The conventional process of building Ontologies and Knowledge Graphs (KGs) heavily relies on human domain experts to define entities and relationship types, establish hierarchies, maintain relevance to the domain, fill the ABox (i.e., populate with instances), and ensure data quality (including amongst others accuracy and completeness). On the other hand, Large Language Models (LLMs) have recently gained popularity for their ability to understand and generate human-like natural language, offering promising ways to automate aspects of this process. This work explores the (semi-)automatic construction of KGs facilitated by different state-of-the-art LLMs: Mixtral 8x22B Instruct v0.1, GPT-4o, GPT-3.5, and Gemini. Our pipeline involves formulating competency questions (CQs), developing an ontology (TBox) based on these CQs, constructing KGs using the developed ontology, and evaluating the resultant KG with minimal to no involvement of human experts. We showcase the feasibility of our semi-automated pipeline by creating a KG on deep learning methodologies by exploiting scholarly publications. The answers generated via Retrieval-Augmented-Generation (RAG) were evaluated by a domain expert manually, and the KG was evaluated by matching the KG individuals to RAG-generated answers. Our findings suggest that employing LLMs could potentially reduce the human effort involved in the construction of KGs, although a human-in-the-loop approach is recommended to evaluate automatically generated KGs.  © 2024 Copyright for this paper by its authors.},
	author_keywords = {Competency Questions; Knowledge Graphs; Large Language Models; Ontology; Retrieval-augmented generation},
	keywords = {Deep learning; Domain Knowledge; Modeling languages; Natural language processing systems; Ontology; Search engines; Competency question; Domain experts; Graph construction; Human domain; Knowledge graphs; Language model; Large language model; Ontology graphs; Ontology's; Retrieval-augmented generation; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Naji20243694,
	author = {Naji, Mouncef and Masmoudi, Maroua and Zghal, Hajer Baazaoui},
	title = {Towards an LLM based approach for medical e-consent},
	year = {2024},
	journal = {Procedia Computer Science},
	volume = {246},
	number = {C},
	pages = {3694 – 3701},
	doi = {10.1016/j.procs.2024.09.187},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213312032&doi=10.1016%2fj.procs.2024.09.187&partnerID=40&md5=ed9f395475324623c88ef349c86f4587},
	abstract = {The question of informed and voluntary consent emerges as a matter of significance in healthcare. Obtaining informed consent, encounters many obstacles coupled with systemic, clinician-related, and patient-related factors, demanding interventions at different levels. This paper introduces a novel approach to present personalized consent based on Large Language Models (LLMs). The personalization of information is displayed through the combination of the LLM with a knowledge graph. We focus in our approach on how the knowledge graph enhances and personalize content generation, allowing therefore the acquisition of informed consent. The paper focuses as well on aspects related to hyper-parameters of information retrieval that help giving better prompt to the LLM. Experiments have showcased intresting results in terms of personalization and information retrieval using metrics of Rouge, Faithfulness and Relevance. © 2024 The Authors.},
	author_keywords = {E-consent; Healthcare Information Systems; knowledge graph; Large Language Model},
	keywords = {Electronic health record; Information retrieval; E-consent; Healthcare information system; Help giving; Hyper-parameter; Knowledge graphs; Language model; Large language model; Model based approach; Personalizations; Related factors; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@CONFERENCE{Barua2024,
	author = {Barua, Adrita},
	title = {Concept Induction Using LLMs},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3884},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214839760&partnerID=40&md5=a4f4be096d70304877c43b60b93d8ecf},
	abstract = {In this study, the capability of Large Language Models (LLMs) is explored to automate Concept Induction, a process traditionally reliant on formal logical reasoning using description logic ontologies, within the context of explainable AI (XAI). Initially, a pre-trained LLM like GPT-4 is employed to assess its ability to generate high-level concepts describing data differentials for a scene classification task via prompting. A human assessment study was conducted which revealed that concepts produced by GPT-4 are preferred over those from logical concept induction systems in terms of human understandability, despite some limitations in neuron activation analysis. Building on these insights, further research aims to automate the concept induction system using LLMs, potentially addressing the shortcomings of traditional logical reasoners. This approach has the potential to scale and provide a significant avenue for concept discovery in complex AI models. © 2024 Copyright for this paper by its authors.},
	author_keywords = {Concept Induction; Explainable AI; GPT-4; LLM},
	keywords = {Formal languages; Modeling languages; Problem oriented languages; Concept induction; Description logic; Explainable AI; GPT-4; Induction system; Language model; Large language model; Logical reasoning; Ontology's; Scene classification; Ontology},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Gupta2024,
	author = {Gupta, Saransh Kumar and Dey, Lipika and Das, Partha Pratim and Jain, Ramesh},
	title = {Building FKG.in: A knowledge graph for Indian food},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3882},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214574186&partnerID=40&md5=dc26c9218389b466f21493d4043457f6},
	abstract = {This paper presents an ontology design along with knowledge engineering and multilingual semantic reasoning techniques to build an automated system for assimilating culinary information for Indian food in the form of a knowledge graph. The main focus is on designing intelligent methods to derive ontology designs and capture all-encompassing knowledge about food, recipes, ingredients, cooking characteristics, and most importantly, nutrition, at scale. We present our ongoing work in this workshop paper, describe in some detail the relevant challenges in curating knowledge of Indian food, and propose our high-level ontology design. We also present a novel workflow that uses AI, LLM, and language technology to curate information from recipe blog sites in the public domain to build knowledge graphs for Indian food. The methods for knowledge curation proposed in this paper are generic and can be replicated for any domain. The design is application-agnostic and can be used for AI-driven smart analysis, building recommendation systems for Personalized Digital Health, and complementing the knowledge graph for Indian food with contextual information such as user information, food biochemistry, geographic information, agricultural information, etc. © 2024 Copyright for this paper by its authors.},
	author_keywords = {Food Computing; Knowledge Engineering; Large Language Models; Nutrition Informatics; Ontology Design; Semantic Reasoning},
	keywords = {Food ingredients; Ontology; Automated systems; Food computing; Informatics; Knowledge graphs; Language model; Large language model; Nutrition informatic; Ontology design; Reasoning techniques; Semantic reasoning; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Pires2024343,
	author = {Pires, Catarina and Correia, Pedro Gonçalo and Silva, Pedro and Ferreira, Liliana},
	title = {Enhancing LLMs with Knowledge Graphs for Academic Literature Retrieval},
	year = {2024},
	journal = {International Joint Conference on Knowledge Discovery, Knowledge Engineering and Knowledge Management, IC3K - Proceedings},
	volume = {1},
	pages = {343 – 347},
	doi = {10.5220/0012990500003838},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215303708&doi=10.5220%2f0012990500003838&partnerID=40&md5=1b3a17d5e0e9e5c1e49b18dd7010d820},
	abstract = {While Large Language Models have demonstrated significant advancements in Natural Language Generation, they frequently produce erroneous or nonsensical texts. This phenomenon, known as hallucination, raises concerns about the reliability of Large Language Models, particularly when users seek accurate information, such as in academic literature retrieval. This paper addresses the challenge of hallucination in Large Language Models by integrating them with Knowledge Graphs using prompt engineering. We introduce GPTscholar, an initial study designed to enhance Large Language Models responses in the field of computer science academic literature retrieval. The authors manually evaluated the quality of responses and frequency of hallucinations on 40 prompts across 4 different use cases. We conclude that the approach is promising, as the system outperforms the results we obtained with gpt-3.5-turbo without Knowledge Graphs. © 2024 by SCITEPRESS – Science and Technology Publications, Lda.},
	author_keywords = {Academic Literature Retrieval; Hallucination; Knowledge Graph Augmented LLMs; Knowledge Graphs; Large Language Models; Natural Language Generation; Prompt Engineering},
	keywords = {Graphic methods; Natural language processing systems; Academic literature; Academic literature retrieval; Hallucination; Knowledge graph augmented LLM; Knowledge graphs; Language model; Large language model; Literature retrieval; Natural language generation; Prompt engineering; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Duan2024,
	author = {Duan, Yuchen and Zhou, Qingqing and Li, Yu and Qin, Chi and Wang, Ziyang and Kan, Hongxing and Hu, Jili},
	title = {Research on a traditional Chinese medicine case-based question-answering system integrating large language models and knowledge graphs},
	year = {2024},
	journal = {Frontiers in Medicine},
	volume = {11},
	doi = {10.3389/fmed.2024.1512329},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215534738&doi=10.3389%2ffmed.2024.1512329&partnerID=40&md5=413bf55c13bcf623ce56e4eb1bbdbf40},
	abstract = {Introduction: Traditional Chinese Medicine (TCM) case records encapsulate vast clinical experiences and theoretical insights, holding significant research and practical value. However, traditional case studies face challenges such as large data volumes, complex information, and difficulties in efficient retrieval and analysis. This study aimed to address these issues by leveraging modern data techniques to improve access and analysis of TCM case records. Methods: A total of 679 case records from Wang Zhongqi, a renowned physician of Xin’an Medicine, a branch of TCM, covering 41 diseases, were selected. The study involved four stages: pattern layer construction, knowledge extraction, integration, and data storage and visualization. A large language model (LLM) was employed to automatically extract key entities, including symptoms, pathogenesis, treatment principles, and prescriptions. These were structured into a TCM case knowledge graph. Results: The LLM successfully identified and extracted relevant entities, which were then organized into relational triples. A TCM case query system based on natural language input was developed. The system’s performance, evaluated using the RAGAS framework, achieved high scores: 0.9375 in faithfulness, 0.9686 in answer relevancy, and 0.9500 in context recall; In human evaluations, the levels of safety and usability are significantly higher than those of LLMs without using RAG. Discussion: The results demonstrate that integrating LLMs with a knowledge graph significantly enhances the efficiency and accuracy of retrieving TCM case information. This approach could play a crucial role in modernizing TCM research and improving access to clinical insights. Future research may explore expanding the dataset and refining the query system for broader applications. Copyright © 2025 Duan, Zhou, Li, Qin, Wang, Kan and Hu.},
	author_keywords = {interdisciplinary research; knowledge graph; large language model; question answering system; traditional Chinese medicine},
	keywords = {Article; Chinese medicine; clinical article; human; information retrieval; information storage; interdisciplinary research; knowledge; large language model; physician; prescription},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Du202432,
	author = {Du, Jin},
	title = {A Rule-Based Multidimensional Axiomatic Fuzzy Set Knowledge Graph Question-Answering Model},
	year = {2024},
	journal = {Communications in Computer and Information Science},
	volume = {2274 CCIS},
	pages = {32 – 52},
	doi = {10.1007/978-981-97-9671-7_3},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215676271&doi=10.1007%2f978-981-97-9671-7_3&partnerID=40&md5=3e2dc509c655d0f2a7a8e82229097736},
	abstract = {The pretrained large language model has made significant progress in intelligent question-answering, reading comprehension, and other aspects. This paper refers to a rule-based mathematical model-the multidimensional axiomatic fuzzy set (AFS) model and extends it by using logic inverse and fuzzy implication operations to increase the interpretability of this model. For open-book question answering (QA), AFS theory can generate a knowledge graph of passages, and retrieve the context most closely related to the question on the basis of the graph retrieval algorithm. We utilize the reading comprehension ability of the large language model to analyze the retrieved context on the basis of the question and obtain the final answer. The experimental results show that the proposed model can perform better on several datasets. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2024.},
	author_keywords = {Axiomatic fuzzy set; interpretability; large language model; logical inverse; question answering;  fuzzy implication},
	keywords = {Fuzzy logic; Fuzzy set theory; Fuzzy sets; Inverse problems; Knowledge graph; Axiomatic fuzzy sets; Fuzzy implications; Interpretability; Knowledge graphs; Language model; Large language model; Logical inverse; Question Answering; Reading comprehension; Rule based; Question answering},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Ji2024491,
	author = {Ji, Lintian and Du, Shuxin and Qiu, Yi and Xu, Hongyi and Guo, Xiaorui},
	title = {Constructing a Medical Domain Functional Knowledge Graph with Large Language Models},
	year = {2024},
	journal = {2024 IEEE 6th International Conference on Power, Intelligent Computing and Systems, ICPICS 2024},
	pages = {491 – 496},
	doi = {10.1109/ICPICS62053.2024.10796042},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216237791&doi=10.1109%2fICPICS62053.2024.10796042&partnerID=40&md5=dfa683cc1a1ad881482e37f2f34a6b0a},
	abstract = {The integration of medicine and artificial intelligence is creating novel opportunities to gather, analyze, and generate groundbreaking medical insights from the vast expanse of medical literature. Although these advancements hold great promise, difficulties including manual annotation and precise data retrieval, and transparency persist. Advanced natural language processing (NLP) techniques and large language models (LLMs) have shown potential in addressing these issues. This paper introduces the Medical Knowledge Graph (MedKG), a comprehensive and multidisciplinary medical knowledge graph. By utilizing advanced NLP algorithms, MedKG extracts millions of entities and converts them into triples from a corpus of superior medical research papers published over the last decade. It categorizes unstructured medical information into nine distinct tags, including disease names, treatments, diagnoses, symptoms, genetics, cellular structures of diseases, patient data, medical procedures, and treatment applications, while seamlessly integrating the digital object identifier (DOI) of each paper. As the latest structured database of medical knowledge, MedKG serves as a powerful tool for accelerating medical research and lays the groundwork for constructing a more extensive medical knowledge graph using full-text medical articles. Moreover, our research establishes a foundation for practical knowledge management systems based on text mining, applicable not only to complex medical systems but also to other professional domains.  © 2024 IEEE.},
	author_keywords = {Database; Knowledge graph; Large language model; Medical engineering; NLP},
	keywords = {Diagnosis; Disease control; Diseases; Hospital data processing; Medical information systems; Metadata; Natural language processing systems; Functionals; Knowledge graphs; Language model; Language processing; Large language model; Medical domains; Medical engineering; Medical knowledge; Natural language processing; Natural languages; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Li2024128,
	author = {Li, Jinghong and Siritanawan, Prarinya and Gu, Wen and Hasegawa, Shinobu},
	title = {Multi-Agent Approach for Dynamic Research Insight Path Generation},
	year = {2024},
	journal = {Proceedings - 2024 IEEE International Conference on Agents, ICA 2024},
	pages = {128 – 129},
	doi = {10.1109/ICA63002.2024.00035},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215625741&doi=10.1109%2fICA63002.2024.00035&partnerID=40&md5=79519a9b6d1141288d38683d1ae8b6cb},
	abstract = {In recent years, researchers have witnessed rapid advancements in conducting paper surveys using generative AI, enhancing survey efficiency to some extent. However, today's generative AI lacks deep research training to analyze logical threads woven across multiple papers. A concise visualization method is also expected to present logical connections among various papers. These logical threads are often implicit in the issue ontology authors commonly employ when writing papers. Building on this issue ontology, our method utilizes Dynamic Programming with multiple agents to generate an insight path. The key feature of this approach is the collaboration of multiple agents to adapt to a complex environment and make optimized decisions on issue ontology selection. This path aims to succinctly express longitudinal logical connections among multiple papers, including commonality, difference, and inheritance. © 2024 IEEE.},
	author_keywords = {Agent; Dynamic programming; Insight path; Issue ontology; Longitudinal},
	keywords = {Ontology; Dynamic researches; Insight path; Issue ontology; Logical connections; Longitudinal; Multi-agent approach; Multiple agents; Ontology's; Paper surveys; Path-generation},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Lin202427,
	author = {Lin, Yichen and Potikas, Petros and Potika, Katerina},
	title = {Opinion Graphs Construction for Reviews Using Transfer Learning and Large Language Models},
	year = {2024},
	journal = {Proceedings - 2024 Conference on AI, Science, Engineering, and Technology, AIxSET 2024},
	pages = {27 – 34},
	doi = {10.1109/AIxSET62544.2024.00010},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215115223&doi=10.1109%2fAIxSET62544.2024.00010&partnerID=40&md5=c83e8bed1ab07b1a4be3f4ff0cffdf89},
	abstract = {We propose a new method OpinionGraphGenerator that aims to create opinion graphs from hotel reviews to reduce the high volume of text in reviews while preserving essential insights. In an opinion graph, vertices are semantically similar opinions, where each opinion consists of an opinion term (a description of an aspect, e.g., tasty) and an aspect term (an entity, e.g., food). Edges represent the explanatory relationships between vertices. The current method of constructing opinion graphs requires a human-annotated hotel dataset, where the label is the existence of a directed edge. With transfer learning, we can reduce the need for labeled data while training a model, thus significantly reducing labor costs for labeling our dataset. Additionally, transfer learning with large language models is used for identifying sentences, extracting opinions, and mining explanatory relationships from reviews. Next, natural language processing methods are utilized to generate word embeddings for the reviews, further clustered to identify semantically similar opinions. Finally, with the extracted edges and semantically similar opinions as vertices, multiple opinion graphs are generated. We focus our attention on hotel reviews to create opinion graphs. © 2024 IEEE.},
	author_keywords = {Clustering; Hotel Reviews; Large Language Models; Opinion Graphs; Transfer Learning},
	keywords = {Graph embeddings; Knowledge graph; Motels; Natural language processing systems; Transfer learning; Wages; 'current; Clusterings; Graph construction; Graph's vertices; High volumes; Hotel review; Language model; Large language model; Opinion graph; Transfer learning; Hotels},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Lombardi2024,
	author = {Lombardi, Dario and Traetta, Luigi and Maffei, Antonio and Podržaj, Primož},
	title = {Enhancing Instructional Design: The Impact of CONALI Ontology and ChatGPT in Primary Education Training},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3879},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214202421&partnerID=40&md5=d5fc423c2218e3740b3c62560afd4915},
	abstract = {The integration of Artificial Intelligence (AI) in education is becoming increasingly crucial [1], especially for the preparation of future educators. Despite these requirements, there is a paucity of training courses for educators in the use of AI systems [2]. AI-driven tools play a crucial role in personalizing, simplifying, and innovating educational pathways at all levels [3]. his study examines the combined application of the CONALI Ontology [4][5] and ChatGPT in supporting the instructional design process among 110 students enrolled in the Primary Education Sciences Laboratory at the University of Foggia. The goal was to evaluate how AI can enhance the creation of Learning Units (LUs) by streamlining design processes and promoting educational innovation. Participants received training in using the CONALI framework, which emphasizes the identification of learning objectives, activities, and assessment methods through constructive alignment [5]. After this initial instruction, students engaged in the design of their own LUs, integrating ChatGPT as a support tool. At the conclusion of the exercises, validated questionnaires were administered to assess participants' perceptions of the implementation of the CONALI ontological framework in combination with generative AI systems ChatGPT. The goal was to explore the advantages, disadvantages, and emerging challenges that must be addressed in the training of future educators, specifically regarding the integration of AI in the design of Learning Units and its implications for both their current and future educational practices. Results demonstrated that the CONALI Ontology was instrumental in helping students articulate SMART objectives, resulting in clearer, more focused instructional design. Moreover, the integration of ChatGPT was perceived as significantly improving the efficiency and creativity of the design process, enabling students to quickly generate ideas and refine their projects. This study highlights the transformative potential of AI in conjunction with structured ontological frameworks to enrich instructional design, ultimately enhancing the skills and competencies of future educators in a technology-enhanced learning environment. © 2024 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).},
	author_keywords = {AIEd; Instructional Design; Teacher Training},
	keywords = {Adversarial machine learning; Contrastive Learning; Curricula; Educational technology; Federated learning; Ontology; Personnel training; Teaching; AIEd; Artificial intelligence in education; Artificial intelligence systems; Design-process; Education training; Instructional designs; Ontological frameworks; Ontology's; Primary education; Teacher training; Students},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Babichenko202489,
	author = {Babichenko, Dmitriy and Swanson, Tod},
	title = {HeritageRoots: Developing Interconnected Immersive Experiences for Cultural Preservation and Education},
	year = {2024},
	journal = {Proceedings of the European Conference on Games-based Learning},
	volume = {18},
	number = {1},
	pages = {89 – 98},
	doi = {10.34190/ecgbl.18.1.3057},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212971904&doi=10.34190%2fecgbl.18.1.3057&partnerID=40&md5=15beb07a43c803236e03d36a3e735509},
	abstract = {In this paper, we present technical implementation details, describe the virtual world procedural generation pipeline, and discuss potential uses in cultural preservation, museum exhibits, and education of HeritageRoots, an innovative software infrastructure designed for preserving indigenous narratives and oral histories. HeritageRoots consists of two interconnected systems - (1) a web-based knowledge graph (KG) data collection and management system which stores, connects, and presents indigenous traditional knowledge (ITK) in the form of narratives, myths, and testimonies from multiple cultures and languages; (2) a virtual environment rendering pipeline which utilizes large language models (LLM), Unity3D, and Meta Quest software development kit (SDK) to procedurally generate virtual worlds from the KG data. Preliminary system evaluation with Ecuadorian Kichwa narratives showed promising results in (1) academic community interest and support, (2) the possibility of developing an infrastructure capable of connecting indigenous narratives with modern scientific knowledge via KGs and (3) procedurally generating virtual worlds from KG. © 2024 Dechema e.V.. All rights reserved.},
	keywords = {Economic and social effects; Historic preservation; Knowledge graph; Cultural education; Cultural preservation; Graph data; Immersive; Knowledge graphs; Museum exhibits; Oral history; Software infrastructure; Technical implementation; Virtual worlds; Virtual environments},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Bronze Open Access}
}

@ARTICLE{Wu2024,
	author = {Wu, Yanting and Sun, Yicheng and Wen, Xiaojian and Liu, Xiaoqiang and Bao, Jinsong and Wang, Sen},
	title = {A Generative Modeling Method for Digital Twin Shop Floor},
	year = {2024},
	journal = {IEEE Internet Computing},
	doi = {10.1109/MIC.2024.3522301},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214434272&doi=10.1109%2fMIC.2024.3522301&partnerID=40&md5=37d23dd3c8a4a835461855cec5c37dc0},
	abstract = {Digital Twin(DT) as a key enabling technology for achieving digitization, flexibility, and customization in shop floor, has attracted significant attention. However, the shop floor involves diverse assets across multiple dimensions, scales, and interdisciplinary fields, making the modeling process complex. To address this issue, this paper analyzes the construction process of ontology-based information models, and proposes a generative modeling method for digital twin shop floor driven by Large Language Models(LLMs). Firstly, LLMs are utilized to analyze user intentions, acquiring the hierarchical object structure of DT models. Secondly, by combining an analysis-retrieval method to extract domain knowledge and generate dynamic prompts, LLMs are guided to realize the creation and fusion of objects, and construct structured and semantically enriched DT models. Finally, the effectiveness of the proposed method is validated through examples of shop floor resource scheduling.  © 1997-2012 IEEE.},
	keywords = {Machine shops; Customisation; Digitisation; Enabling technologies; Generative model; Interdisciplinary fields; Language model; Model method; Modeling process; Multiple dimensions; Shopfloors; Semantics},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Procko2024166,
	author = {Procko, Tyler Thomas and Ochoa, Omar},
	title = {Graph Retrieval-Augmented Generation for Large Language Models: A Survey},
	year = {2024},
	journal = {Proceedings - 2024 Conference on AI, Science, Engineering, and Technology, AIxSET 2024},
	pages = {166 – 169},
	doi = {10.1109/AIxSET62544.2024.00030},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215110171&doi=10.1109%2fAIxSET62544.2024.00030&partnerID=40&md5=6f4b0ae223e8c33d47be0530e5591e87},
	abstract = {Large Language Models (LLMs) demonstrate general knowledge, but they suffer when specifically needed knowledge is not present in their training set. Two approaches to ameliorating this, without retraining, are 1) prompt engineering and 2) Retrieval-Augmented Generation (RAG). RAG is a form of prompt engineering, insofar as relevant lexical snippets retrieved from RAG corpora are vectorized and aggregated with prompts. However, RAG documents are often noisy, i.e., while relevant to a given prompt, they can contain much other information that obfuscates the desired snippet. If the purpose of pretraining a LLM on massive and general corpora is to engender a generally applicable model, RAG is not: it is a means of LLM optimization, and as such, RAG document selection must be precise, not general. For expert tasks, it is imperative that a RAG corpus be as noise-free as possible, in much the same way a good prompt should be free of irrelevant text. Knowledge Graphs (KGs) provide a concise means of representing domain knowledge free of noisy information. This paper surveys work incorporating KGs with LLM RAG, intending to equip scientists with a better understanding of this novel research area for future work. © 2024 IEEE.},
	author_keywords = {fine-tuning; GPT; knowledge graphs; LLM; RAG},
	keywords = {Distributed computer systems; Geological surveys; Modeling languages; Fine tuning; General knowledge; GPT; Knowledge graphs; Language model; Large language model; Model optimization; Pre-training; Retrieval-augmented generation; Training sets; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{2024,
	title = {JOWO 2024 - Proceedings of the Joint Ontology Workshops - Episode X: The Tukker Zomer of Ontology, and Satellite Events, co-located with the 14th International Conference on Formal Ontology in Information Systems, FOIS 2024},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3882},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214581548&partnerID=40&md5=bcd59a2efd31d875f72a80342c127c68},
	abstract = {The proceedings contain 88 papers. The topics discussed include: understanding ASD: design and development of a domain ontology to assist professionals in understanding autistic children based on DSM-5; TAO: a document- and person-centric ontology for storing rich metadata of manuscripts; the geography of temperature space; from human cognitive expertise to ontological formalization: bridging the knowledge gap for nanophotonic calculator design and simulation; ontologies, arguments, and large-language models; what is abstraction in biomimetics?; rewriting SPARQL queries using an authorization ontology; and ontology pattern substitution: toward their use for domain ontologies.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Alharbi20241,
	author = {Alharbi, Reham and Ahmed, Umair and Dobriy, Daniil and Łajewska, Weronika and Menotti, Laura and Saeedizade, Mohammad Javad and Dumontier, Michel},
	title = {Exploring the Role of Generative AI in Constructing Knowledge Graphs for Drug Indications with Medical Context},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3890},
	pages = {1 – 10},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214896866&partnerID=40&md5=92194969cad015f54812f2354abcd8f4},
	abstract = {The medical context for a drug indication provides crucial information on how the drug can be used in practice. However, the extraction of medical context from drug indications remains poorly explored, as most research concentrates on the recognition of medications and associated diseases. Indeed, most databases cataloging drug indications do not contain their medical context in a machine-readable format. This paper proposes the use of a large language model for constructing DIAMOND-KG, a knowledge graph of drug indications and their medical context. The study 1) examines the change in accuracy and precision in providing additional instruction to the language model, 2) estimates the prevalence of medical context in drug indications, and 3) assesses the quality of DIAMOND-KG against NeuroDKG, a small manually curated knowledge graph. The results reveal that more elaborated prompts improve the quality of extraction of medical context; 71% of indications had at least one medical context; 63.52% of extracted medical contexts correspond to those identified in NeuroDKG. This paper demonstrates the utility of using large language models for specialized knowledge extraction, with a particular focus on extracting drug indications and their medical context. We provide DIAMOND-KG as a FAIR RDF graph supported with an ontology. Openly accessible, DIAMOND-KG may be useful for downstream tasks such as semantic query answering, recommendation engines, and drug repositioning research. © 2024 Copyright for this paper by its authors.},
	author_keywords = {Knowledge Graph Construction; LLMs in KGC; Medical Knowledge Graph},
	keywords = {Query languages; Semantics; Accuracy and precision; Graph construction; Knowledge graph construction; Knowledge graphs; Language model; LLM in KGC; Machine-readable format; Medical knowledge; Medical knowledge graph; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Crum2024,
	author = {Crum, Elias and De Santis, Antonio and Ovide, Manon and Pan, Jiaxin and Pisu, Alessia and Lazzari, Nicolas and Rudolph, Sebastian},
	title = {Enriching Ontologies with Disjointness Axioms using Large Language Models},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3853},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212711225&partnerID=40&md5=8e4efddbdf745c0480df90e78e4b6d2b},
	abstract = {Ontologies often lack explicit disjointness declarations between classes, despite their usefulness for sophisticated reasoning and consistency checking in Knowledge Graphs. In this study, we explore the potential of Large Language Models (LLMs) to enrich ontologies by identifying and asserting class disjointness axioms. Our approach aims at leveraging the implicit knowledge embedded in LLMs, using prompt engineering to elicit this knowledge for classifying ontological disjointness. We validate our methodology on the DBpedia ontology, focusing on open-source LLMs. Our findings suggest that LLMs, when guided by effective prompt strategies, can reliably identify disjoint class relationships, thus streamlining the process of ontology completion without extensive manual input. For comprehensive disjointness enrichment, we propose a process that takes logical relationships between disjointness and subclass statements into account in order to maintain satisfiability and reduce the number of calls to the LLM. This work provides a foundation for future applications of LLMs in automated ontology enhancement and offers insights into optimizing LLM performance through strategic prompt design. Our code is publicly available on GitHub at https://github.com/n28div/llm-disjointness. © 2024 Copyright for this paper by its authors.},
	author_keywords = {Disjointness Learning; Large Language Models; Ontology Enrichment},
	keywords = {Contrastive Learning; Knowledge graph; Consistency checking; Dbpedia; Disjointness; Disjointness learning; Implicit knowledge; Knowledge graphs; Language model; Large language model; Ontology enrichment; Ontology's; Ontology},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Gribova202470,
	author = {Gribova, Valeriya and Shalfeeva, Elena},
	title = {SMART Standards for Industry},
	year = {2024},
	journal = {Lecture Notes in Networks and Systems},
	volume = {1209 LNNS},
	pages = {70 – 82},
	doi = {10.1007/978-3-031-77688-5_8},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214201578&doi=10.1007%2f978-3-031-77688-5_8&partnerID=40&md5=d7d110868d9cb5cefcf827bcb8534e1c},
	abstract = {An urgent task for all areas of industry is to create documents with machine-readable content (SMART-standards) that can be analyzed not only by domain specialists, but also software services for solving various professional tasks in the Industry. Such documents should be equally understandable to both experts and software systems, which is generally a contradiction. The presence of a textual, i.e. human-readable document with its subsequent translation into a machine-understandable representation is quite a difficult task due to the presence of complex semantic connections in the domain. Modern methods of natural language analysis, including Large Language Models (LLM), are not able to accurately solve this problem. Therefore, an critical task is to develop new methods and approaches to ensure human and machine comprehension while minimizing possible errors when translating from one representation to another. The purpose of this work is to describe an approach for creating and translating into a machine-understandable representation of regulatory documents of the Industry for their further use in software services and systems. The authors propose a new approach for representing normative documents as two-level graphs of knowledge. LLM models, supplemented by a specialized adapter obtained as a result of additional training, serve as the basis for ensuring the transformation of one form into another form. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {automatic extraction and transfer; knowledge graph; knowledge representation; LLM; normative document; SMART Standards; two-level representation},
	keywords = {Semantics; Automatic extraction; Automatic extraction and transfer; Knowledge graphs; Knowledge-representation; Language model; Large language model; Normative documents; SMART standard; Software services; Two-level representation; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Coutinho2024,
	author = {Coutinho, Matheus L.},
	title = {Leveraging LLMs in text-based ontology-driven conceptual modeling},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3882},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214559880&partnerID=40&md5=7787bbb654a022118ddc4e18f807e705},
	abstract = {This research introduces the use of a Large Language Models (LLM) assistant into the modeling tool proposed for Tonto, a text-based language for ontologies based on the Unified Foundational Ontology (UFO). By integrating Tonto with LLMs, we aim to improve conceptual modeling by employing LLMs in assisting tasks such as summarizing models, inferring meta properties of classes and the ontological nature of their instances, and creating elements based on context. This project investigates how this integration can improve modeling efficiency, accuracy, and the overall user experience with an LLM-powered assistant. © 2024 Copyright for this paper by its authors.},
	author_keywords = {AI; Large Language Models (LLM); Machine learning (ML); Ontology Development; OntoUML; Textual Language; UFO},
	keywords = {Adversarial machine learning; Computational linguistics; Digital elevation model; Machine learning; Unified Modeling Language; Foundational ontologies; Language model; Large language model; Machine learning; Machine-learning; Ontology development; Ontology-Driven Conceptual Modeling; OntoUML; Textual language; Unified foundational ontology; Ontology},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Macilenti20241289,
	author = {Macilenti, Giulio and Stellato, Armando and Fiorelli, Manuel},
	title = {Prompting is not all you need Evaluating GPT-4 performance on a real-world ontology alignment use case},
	year = {2024},
	journal = {Procedia Computer Science},
	volume = {246},
	number = {C},
	pages = {1289 – 1298},
	doi = {10.1016/j.procs.2024.09.557},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213321670&doi=10.1016%2fj.procs.2024.09.557&partnerID=40&md5=f53255441e72ba20c9f73ed85769f5fa},
	abstract = {Ontology Alignment (OA) is a complex, demanding and error-prone task, requiring the intervention of domain and Semantic Web experts. Automating the alignment process thus becomes a must-do, especially when involving large datasets, to at least produce a first input for human experts. Automated ontology alignment could benefit from the outstanding language ability of Large Language Models (LLMs), which could implicitly provide the background knowledge that has been the Achilles' heel of traditional alignment systems. However, this requires a correct evaluation of the performance of LLMs and understanding the best way to incorporate them into more specific tools. In this paper, we show that a naive prompting approach on the popular GPT-4 model could face several problems when transferred to real-world use cases. To this end, we replicated the methods of Norouzi et al. (2023), applied to the OAEI 2022 conference track, on a reference alignment between a pair of datasets (reduced versions of two popular thesauri: European Commission's EuroVoc and TESEO, from the Italian Senate of the Republic), which has never been tested in OAEI evaluation campaigns. This reference alignment has several features common to real-world use cases: it is has a larger size than those considered in the study we replicated, it is not published online and is therefore not subject to data contamination and it involves relations between concepts that are more complex than simple equivalence. The replicated methods achieved a significantly lower performance on our reference alignment than on the OAEI 2022 conference track, suggesting that size, data contamination, and semantic complexity need to be considered when using LLMs for the alignment task. © 2024 The Authors.},
	author_keywords = {Large language models; Ontology alignment; Semantic technologies},
	keywords = {Latent semantic analysis; Ontology; Error prone tasks; Human expert; Language model; Large datasets; Large language model; Ontology alignment; Performance; Real-world; Semantic technologies; Semantic-Web; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@CONFERENCE{2024,
	title = {IAI4CH 2024 - Proceedings of the 3rd Workshop on Artificial Intelligence for Cultural Heritage, co-located with the 23rd International Conference of the Italian Association for Artificial Intelligence, AIxIA 2024},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3865},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213708974&partnerID=40&md5=77724c8f72714ba8af197480368c1b16},
	abstract = {The proceedings contain 15 papers. The topics discussed include: new frontiers in digital libraries: the trajectory of digital humanities through a computational lens; how BERT speaks Shakespearean English? evaluating historical bias in masked language models; constructing a knowledge graph for Italian cinema divas’ autobiographies; transfer learning for renaissance illuminated manuscripts: starting a journey from classification to interpretation; saliency-driven 3D reconstruction and printing for accessible museums; using ontologies for LLM applications in cultural heritage; intelligent human-computer interaction in innovative ai solutions in travel and its impact on the e-society; digital augmented reality app for historic architecture; ontological representation of narrative places for cinema archives; and developing a comprehensive dataset for enhancing social inclusion and cohesion through citizen curation in cultural heritage.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{2024,
	title = {Proceedings of the 21st International Conference on Cognition and Exploratory Learning in the Digital Age, CELDA 2024},
	year = {2024},
	journal = {Proceedings of the 21st International Conference on Cognition and Exploratory Learning in the Digital Age, CELDA 2024},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214024252&partnerID=40&md5=f215ec2fcabe81b0a5fd5a2bfa358fc2},
	abstract = {The proceedings contain 55 papers. The topics discussed include: using large language models for academic writing instruction: conceptual design and evaluation of the SOCRAT project; large language model detuning in learning content understanding; evidence-based content design and validation for cybersecurity games; integrating gaze data and digital textbook reading logs for enhanced analysis of learning activities; exploring student perception and interaction using ChatGPT in programming education; unpacking the three spheres of interest in a blended intensive program: collaborative learning, blended learning and internationalization; a three-step knowledge graph approach using LLMs in collaborative problem solving-based stem education; and enhancing learning and skills in the digital age: digital bloom and platforms in music education.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Yang2024381,
	author = {Yang, Shenghao and Ma, Weizhi and Sun, Peijie and Zhang, Min and Ai, Qingyao and Liu, Yiqun and Cai, Mingchen},
	title = {Common Sense Enhanced Knowledge-based Recommendation with Large Language Model},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) },
	volume = {14854 LNCS},
	pages = {381 – 390},
	doi = {10.1007/978-981-97-5569-1_25},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213376187&doi=10.1007%2f978-981-97-5569-1_25&partnerID=40&md5=9d9ca1caabb8b9fe63f2049fc490c576},
	abstract = {Knowledge-based recommendation models effectively alleviate the data sparsity issue leveraging the side information in the knowledge graph, and have achieved considerable performance. Nevertheless, the knowledge graphs used in previous work, namely metadata-based knowledge graphs, are usually constructed based on the item attributes and co-occurring relations (e.g., also buy), in which the former provides limited information and the latter relies on sufficient interaction data and still suffers from data sparsity issue. Common sense, as a knowledge form with generality and universality, can be used as a supplement to the metadata-based knowledge graph and provides a new perspective for modeling users’ preferences. Recently, benefiting from the emergent knowledge of the Large Language Model, efficient acquisition of common sense has become possible. This paper proposes a novel knowledge-based recommendation framework incorporating common sense, namely CSRec, which can be flexibly coupled with existing knowledge-based methods. Considering the challenge of the knowledge gap between the common sense- and metadata-based knowledge graph, we propose a knowledge fusion approach based on mutual information maximization theory. Experimental results on public datasets demonstrate that our approach significantly improves the performance of existing knowledge-based recommendation models. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2024.},
	author_keywords = {Knowledge Graph; Knowledge-based Recommendation; Large Language Model},
	keywords = {Common sense; Data sparsity; Knowledge graphs; Knowledge-based recommendations; Language model; Large language model; Limited information; Performance; Side information; User's preferences; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Beverley2024,
	author = {Beverley, John and Franda, Francesco and Karray, Mohamed Hedi and Maxwell, Dan and Benson, Carter and Smith, Barry},
	title = {Ontologies, Arguments, and Large-Language Models},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3882},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214573075&partnerID=40&md5=77206ea24fc3ee16e1e50095b26c08b4},
	abstract = {The explosion of interest in large language models (LLMs) has been accompanied by concerns over the extent to which generated outputs can be trusted, owing to the prevalence of bias, hallucinations, and so forth. Accordingly, there is a growing interest in the use of ontologies and knowledge graphs to make LLMs more trustworthy. This rests on the long history of ontologies and knowledge graphs in constructing human-comprehensible justification for model outputs as well as traceability concerning the impact of evidence on other evidence. Understanding the nature of arguments and argumentation is critical to each, especially when LLM output conflicts with what is expected by users. The central contribution of this article is to extend the Arguments Ontology (ARGO) - an ontology specific to the domain of argumentation and evidence broadly construed - into the space of LLM fact-checking in the interest of promoting justification and traceability research through the use of ARGO-based ‘blueprints’. © 2024 Copyright for this paper by its authors.},
	author_keywords = {Arguments; Large Language Models; Ontology; Semantic Reasoning},
	keywords = {Modeling languages; Ontology; Semantics; Argument; Knowledge graphs; Language model; Large language model; Model outputs; Ontology graphs; Ontology's; Ontology-based; Semantic reasoning; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Tharaniya Sairaj2024,
	author = {Tharaniya Sairaj, R. and Balasundaram, S.R.},
	title = {Exploring SPARQL query types to improve Ontology Mapping and Retrieval Augmented Modelling for auto-generated questions},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3882},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214557306&partnerID=40&md5=d2de42da80fa9d707bb8fc4602b53c74},
	abstract = {The use of SPARQL is evergreen for querying, extracting and expanding named entities from RDF datasets, significantly enhancing text processing applications such as Automatic Question Generation (AQG). Recent research employs pretrained Large Language Models (LLMs) for AQG to reduce manual costs, but these models are limited by their dependence on training data. This in turn makes LLMs to conterfeit the answer-revealingness challenge in automatic Multi-hop Question Generation. This challenge occurs in the process of Multi-hop Question Generation as it requires integration of named entities from multiple sources and deep comprehension of these interconnected concepts, which is quite challenging. In this context, Retrieval Augmented Models (RAM) have gained attention in NLP for improving text processing through enhanced information extraction, yet their application in AQG is limited. This research addresses this gap by RAM's workflow with attention to its first phase - Input Text Enrichment via Named Entity Expansion—is crucial for generating diverse, comprehensive questions. But, Effective named entity expansion is facilitated by ontology mapping to align entities to various ontologies, which is more demanding. To address this requirement, SPARQL querying techniques such as multi-querying, step-back querying, and sub-querying are examined to enhance named entity expansion accuracy, thereby improving RAM's efficacy, leading to well-formed auto-generated questions. © 2024 Copyright for this paper by its authors.},
	author_keywords = {Automatic Question Generation; Named Entity Set Expansion; Ontology Mapping; Retrieval Augmented Model; Semantic Similarity},
	keywords = {Ontology; Query languages; Query processing; Question answering; Semantics; Automatic question generation; Language model; Multi-hops; Named entities; Named entity set expansion; Ontology mapping; Retrieval augmented model; Semantic similarity; Set expansions; Text-processing; Structured Query Language},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Chen202451,
	author = {Chen, Li and Li, Gen and Ma, Boxuan and Tang, Cheng and Yamada, Masanori},
	title = {A THREE-STEP KNOWLEDGE GRAPH APPROACH USING LLMS IN COLLABORATIVE PROBLEM SOLVING-BASED STEM EDUCATION},
	year = {2024},
	journal = {Proceedings of the 21st International Conference on Cognition and Exploratory Learning in the Digital Age, CELDA 2024},
	pages = {51 – 58},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214012325&partnerID=40&md5=db8bfaac4791e376e35e957928634436},
	abstract = {This paper proposes a three-step approach to develop knowledge graphs that integrate textbook-based target knowledge graph with student dialogue-based knowledge graphs. The study was conducted in seventh-grade STEM classes, following a collaborative problem solving process. First, the proposed approach generates a comprehensive target knowledge graph from learning material contents, establishing a reference framework that represents the target knowledge structure of the course. Second, customized knowledge graphs were generated by analyzing the scientific concepts and knowledge based on the discussion dialogues, showing students' activated knowledge structures. Finally, the dialogue-based knowledge graphs were integrated into textbook-based target knowledge, to identify the activated and non-activated knowledge nodes and connections, as well as the related activated knowledge nodes and connections from other previous lectures or experiences. This three-step approach visualizes students' knowledge activation, and the learning gaps remain. This paper presented three examples of integrated knowledge graphs based on the different group formations. The findings of three different groups were discussed, and some educational implications were provided. © 2024 Proceedings of the 21st International Conference on Cognition and Exploratory Learning in the Digital Age, CELDA 2024. All rights reserved.},
	author_keywords = {Collaborative Problem Solving; Knowledge Graph; Large Language Model; STEM Education},
	keywords = {Collaborative learning; Collaborative problem solving; Knowledge graphs; Knowledge nodes; Knowledge structures; Language model; Large language model; Learning materials; Problem solving process; STEM education; Three-step approach; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Langer2024,
	author = {Langer, Stefan and Neuhaus, Fabian and Nürnberger, Andreas},
	title = {CEAR: Automatic construction of a knowledge graph of chemical entities and roles from scientific literature},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3882},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214555647&partnerID=40&md5=04edc0d3b18355b78d45472177627d17},
	abstract = {Ontologies are formal representations of knowledge in specific domains that provide a structured framework for organizing and understanding complex information. Creating ontologies, however, is a complex and time-consuming endeavor. ChEBI is a well-known ontology in the field of chemistry, which provides a comprehensive resource for defining chemical entities and their properties. However, it covers only a small fraction of the rapidly growing knowledge in chemistry and does not provide references to the scientific literature. To address this, we propose a methodology that involves augmenting existing annotated text corpora with knowledge from Chebi and fine-tuning a large language model (LLM) to recognize chemical entities and their roles in scientific text. Our experiments demonstrate the effectiveness of our approach. By combining ontological knowledge and the language understanding capabilities of LLMs, we achieve high precision and recall rates in identifying both the chemical entities and roles in scientific literature. Furthermore, we extract them from a set of 8,000 ChemRxiv articles, and apply a second LLM to create a knowledge graph (KG) of chemical entities and roles (CEAR), which provides complementary information to ChEBI, and can help to extend it. © 2024 Copyright for this paper by its authors.},
	author_keywords = {ChEBI; knowledge graphs; large language models; named entity recognition; ontologies},
	keywords = {Ontology; Automatic construction; ChEBI; Chemical entity; Formal representations; Knowledge graphs; Language model; Large language model; Named entity recognition; Ontology's; Scientific literature; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Munzir2024,
	author = {Munzir, Syed I. and Hier, Daniel B. and Carrithers, Michael D.},
	title = {High Throughput Phenotyping of Physician Notes with Large Language and Hybrid NLP Models},
	year = {2024},
	journal = {Proceedings of the Annual International Conference of the IEEE Engineering in Medicine and Biology Society, EMBS},
	doi = {10.1109/EMBC53108.2024.10782119},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214971917&doi=10.1109%2fEMBC53108.2024.10782119&partnerID=40&md5=d7855bf94e96874ded3dd2ce84462eec},
	abstract = {Deep phenotyping is the detailed description of patient signs and symptoms using concepts from an ontology. The deep phenotyping of the numerous physician notes in electronic health records requires high throughput methods. Over the past 30 years, progress toward making high-throughput phenotyping feasible. In this study, we demonstrate that a large language model and a hybrid NLP model (combining word vectors with a machine learning classifier) can perform high throughput phenotyping on physician notes with high accuracy. Large language models will likely emerge as the preferred method for high throughput deep phenotyping physician notes.Clinical relevance: Large language models will likely emerge as the dominant method for the high throughput phenotyping of signs and symptoms in physician notes © 2024 IEEE.},
	keywords = {Electronic health; Health records; High-throughput method; High-throughput phenotyping; Language model; Learning classifiers; Machine-learning; Ontology's; Phenotyping; Word vectors; Electronic health record},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@CONFERENCE{Hull2024,
	author = {Hull, Richard and Bishop, Matt and Gendreau, Joseph and Levitt, Karl and Sadoghi, Mohammad and Lange, Matthew},
	title = {Conceptual modeling to advance agrifood cybersecurity ontologies},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3882},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214557424&partnerID=40&md5=288e11c6576c3b60f67e19de433f2f85},
	abstract = {Agriculture is central to the survival and comfort of the human race. In recent decades tremendous advances in the application of digital technologies increasingly enable significant efficiency, productivity, environmental sustainability and climate change resilience gains across the continuum of agrifood systems, including agricultural processes and the inputs they use, processing, product distribution, purveyance, knowledge and practice. Digital technologies now underpin new methods, practices, and equipment, altering the way we define and manage issues and indicators, meaningful metrics ranging across topics stretching from soil quality and agricultural practices, to food processing, to wholesaling/retailing, and transportation and warehousing logistics. The increasing ubiquity of digital agrifood technologies has brought a substantial expansion in the cybersecurity attack surface, in the range and kinds of cybersecurity vulnerabilities, and the magnitude of their potential consequences, which will continue to grow in the foreseeable future. As a step towards reducing the cyber risks to modern agrifood systems, this paper describes work to develop a conceptual model that will underpin a comprehensive agrifood cybersecurity ontology. This ontology would enable much smoother, structured information sharing between the agrifood and cybersecurity communities, and specifically support efficient data and knowledge sharing about cyber threats and defenses for the agrifood industries. This ontology will include systems actors/agents, the types of technologies they use and their prevalence across food systems, the cyber and social vulnerabilities associated with these actors and technologies, known and previously unseen attacks on the technologies, and best practices for preventing, detecting, mitigating and deterring cyber attacks. The approach for building this ontology includes bringing together cybersecurity and agriculture experts, applying Large Language Models, and integrating relevant existing ontologies and other structured vocabularies in the cybersecurity and agricultural spaces. At this point the team has constructed a preliminary conceptual model that can act as an initial guide for developing a formal ontology across digital local-to-global food systems. © 2024 Copyright for this paper by its authors.},
	author_keywords = {agrifood systems; cybersecurity; ontologies},
	keywords = {Energy security; Fertilizers; Knowledge acquisition; Ontology; Agri-food system; Agricultural process; Agrifood; Conceptual model; Cyber security; Digital technologies; Environmental sustainability; Food system; Human races; Ontology's; Cyber attacks},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Daluwatte2024,
	author = {Daluwatte, Chathuri and Khromava, Alena and Chen, Yuning and Serradell, Laurence and Chabanon, Anne-Laure and Chan-Ou-Teung, Anthony and Molony, Cliona and Juhaeri, Juhaeri},
	title = {Application of a Language Model Tool for COVID-19 Vaccine Adverse Event Monitoring Using Web and Social Media Content: Algorithm Development and Validation Study},
	year = {2024},
	journal = {JMIR Infodemiology},
	volume = {4},
	doi = {10.2196/53424},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214488720&doi=10.2196%2f53424&partnerID=40&md5=d4dd8de02b7fe0e296f1e4609f64cbfe},
	abstract = {Background: Spontaneous pharmacovigilance reporting systems are the main data source for signal detection for vaccines. However, there is a large time lag between the occurrence of an adverse event (AE) and the availability for analysis. With global mass COVID-19 vaccination campaigns, social media, and web content, there is an opportunity for real-time, faster monitoring of AEs potentially related to COVID-19 vaccine use. Our work aims to detect AEs from social media to augment those from spontaneous reporting systems. Objective: This study aims to monitor AEs shared in social media and online support groups using medical context-aware natural language processing language models. Methods: We developed a language model–based web app to analyze social media, patient blogs, and forums (from 190 countries in 61 languages) around COVID-19 vaccine–related keywords. Following machine translation to English, lay language safety terms (ie, AEs) were observed using the PubmedBERT-based named-entity recognition model (precision=0.76 and recall=0.82) and mapped to Medical Dictionary for Regulatory Activities (MedDRA) terms using knowledge graphs (MedDRA terminology is an internationally used set of terms relating to medical conditions, medicines, and medical devices that are developed and registered under the auspices of the International Council for Harmonization of Technical Requirements for Pharmaceuticals for Human Use). Weekly and cumulative aggregated AE counts, proportions, and ratios were displayed via visual analytics, such as word clouds. Results: Most AEs were identified in 2021, with fewer in 2022. AEs observed using the web app were consistent with AEs communicated by health authorities shortly before or within the same period. Conclusions: Monitoring the web and social media provides opportunities to observe AEs that may be related to the use of COVID-19 vaccines. The presented analysis demonstrates the ability to use web content and social media as a data source that could contribute to the early observation of AEs and enhance postmarketing surveillance. It could help to adjust signal detection strategies and communication with external stakeholders, contributing to increased confidence in vaccine safety monitoring. ©Chathuri Daluwatte, Alena Khromava, Yuning Chen, Laurence Serradell, Anne-Laure Chabanon, Anthony Chan-Ou-Teung, Cliona Molony, Juhaeri Juhaeri.},
	author_keywords = {adverse event; COVID-19; detection; large language model; mass vaccination; natural language processing; pharmacovigilance; safety; social media; vaccine},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@CONFERENCE{Wallace2024118,
	author = {Wallace, Richard and Bajracharya, Ravi and Aasman, Jans and Norvell, Craig},
	title = {Pruning Cycles in UMLS Metathesaurus: A Neuro Symbolic AI Approach},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3874},
	pages = {118 – 127},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214221614&partnerID=40&md5=7afe34058666ac6ee99c5e31c0d110d2},
	abstract = {The Unified Medical Language System (UMLS) is a set of files and software tools that brings together many health and biomedical vocabularies and standards to enable interoperability between computer systems. Maintained by the National Library of Medicine, UMLS includes over 3 million concepts and 11 million unique terms from over 200 vocabularies, including SNOMED CT, ICD-10, LOINC, MeSH, and RxNorm. The UMLS aims to facilitate the development of computer-based systems that can effectively understand and use biomedical information from various sources. However, several authors have diagnosed significant problems with the predicate relationships in UMLS, including inconsistencies, ambiguities, redundancies and, in the case of transitive relationships, cycles. This last issue, cycles, became our concern when we attempted to search for clinical codes in transitive closures of narrower UMLS concepts in an NQF (National Quality Forum) 1 query for early-onset diabetes quality metrics. To address the challenges within UMLS, the study leverages a neuro-symbolic knowledge graph framework. This innovative approach integrates logic-based semantic reasoning and Large Language Models (LLMs) to clean the UMLS graph and eliminate cycles effectively. By validating existing hierarchical and equivalence relations through this framework, the project successfully prunes a significant number of cycles (66 %) from UMLS. This outcome demonstrates the potential of Neuro-symbolic AI in enhancing the reliability and precision of biomedical information systems. A cleaned up UMLS saves time for data scientists that can have more trust in the outcome of their queries and might even save lives by being more precise in analytics underlying treatments.  © 2024 Copyright for this paper by its authors.},
	author_keywords = {Knowledge Graph; LLM; Neuro-Symbolic AI; UMLS},
	keywords = {Diagnosis; Flow visualization; Knowledge graph; Medical informatics; Neurology; Problem oriented languages; Query languages; Query processing; Redundancy; Software reliability; Unified Modeling Language; Biomedical information; Biomedical vocabularies; Knowledge graphs; Language model; Large language model; Metathesaurus; National library of medicines; Neuro-symbolic AI; Software-tools; Unified medical language systems; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Cui202484,
	author = {Cui, Xiao and Gao, Yan},
	title = {Analysis on the Explainable of Generative Artificial Intelligence in Military Contexts},
	year = {2024},
	journal = {Lecture Notes in Electrical Engineering},
	volume = {1267 LNEE},
	pages = {84 – 94},
	doi = {10.1007/978-981-97-7774-7_8},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215587603&doi=10.1007%2f978-981-97-7774-7_8&partnerID=40&md5=515d4e8697f98827950ca35fce5e8ef4},
	abstract = {The “black box” characteristics of generative artificial intelligence (generative AI), which is based on large language models(LLMs), contradict the need for decision certainty in military contexts. This paper explores the technical application and potential development of explainable generative AI in military contexts. It starts by introducing the technology development and military application field of generative artificial intelligence, followed by presenting a framework with three main components—input, interpretation, and feedback—to achieve explainability in generative AI. Finally, the paper demonstrates the application of explainable generative AI in the military field using two examples: target strike selection and a visual language search model based on the knowledge graph. © Chinese Institute of Command and Control 2024.},
	author_keywords = {Explainable Generative AI; Large Language Models; Military Contexts},
	keywords = {Knowledge graph; Visual languages; Application fields; Black boxes; Explainable generative AI; Language model; Large language model; Military context; Military fields; Technical applications; Technical potential; Technology development; Generative adversarial networks},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Wang2024,
	author = {Wang, Changlong and Sang, Xiujuan and Wang, Xijie and Gao, Yuan and Liu, Yi},
	title = {Research on Knowledge Graph Extraction Methods for Chinese STEM Curriculum},
	year = {2024},
	journal = {MLNLP 2024 - 2024 International Conference on Machine Learning and Natural Language Processing},
	doi = {10.1109/MLNLP63328.2024.10800180},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215598070&doi=10.1109%2fMLNLP63328.2024.10800180&partnerID=40&md5=fe10103d37d1ac54dd4568f9edd242ee},
	abstract = {STEM education, as an innovative teaching model, has gained widespread attention in recent years. However, the lack of relevant textbooks and learning resources has made its implementation challenging. Developing interdisciplinary knowledge graphs tailored for STEM education has become an urgent issue. To address this, a knowledge extraction framework named Llms4edu is proposed, which utilizes a series of effective prompts to guide large language models in knowledge extraction. Specifically, the knowledge extraction task is transformed into multiple rounds of question-and-answer interactions with the LLM, gradually identifying entity-relation triplets from subject data. Through experiments, an F1-score of 89.4% was achieved on the named entity recognition task in the chemistry subject, and an F1-score of 66.7% on the relation extraction task. Finally, a subject ontology model was built for subject text, and a subject data set was constructed using Llms4edu, which includes three subjects of junior high school mathematics, physics, and chemistry, a total of 2,511 entities, 2,010 relationship triples, and cross-disciplinary knowledge is linked to construct a cross-disciplinary knowledge graph. © 2024 IEEE.},
	author_keywords = {interdisciplinary knowledge graph; large language model; prompt engineering},
	keywords = {Adversarial machine learning; Contrastive Learning; Federated learning; Cross-disciplinary; F1 scores; Graph extractions; Interdisciplinary knowledge graph; Knowledge extraction; Knowledge graphs; Language model; Large language model; Prompt engineering; STEM education; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Bikim202443,
	author = {Bikim, Jean Petit and Atezong, Carick and Jiomekong, Azanzi and Oelen, Allard and Rabby, Gollam and D’Souza, Jennifer and Auer, Sören},
	title = {Leveraging GPT Models For Semantic Table Annotation},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3889},
	pages = {43 – 53},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214946158&partnerID=40&md5=8bd02f4582d21a46723ae870193e438c},
	abstract = {This paper outlines our contribution to the Accuracy Track and the Semantic Table Interpretation (STI) & Large Language Models (LLMs) track of the Semantic Web Challenge on Tabular Data to Knowledge Graph Matching (SemTab). Our approach involves using LLMs to address the various tasks presented in the challenge. Specifically, we employed zero-shot and few-shot prompting techniques for most of the tasks, which facilitated the LLMs ability to interpret and annotate tabular data with minimal prior training. For the Column Property Annotation (CPA) task, we took a different approach by applying a set of predefined rules, tailored to the structure of each dataset. Our method achieved notable results, with an f1-score exceeding 0.92, demonstrating the effectiveness of LLMs in tackling the SemTab challenge. These results suggest that LLMs hold significant capabilities as a robust solution for semantic table annotation and knowledge graph matching, highlighting their potential to advance the field of semantic web technologies. © 2024 Copyright for this paper by its authors.},
	author_keywords = {Knowledge Graph; Large Language Models; Prompt Engineering; Semantic Table Annotation; Semantic Table Interpretation; SemTab; Tabular Data},
	keywords = {Semantics; Zero-shot learning; Knowledge graphs; Language model; Large language model; Prompt engineering; Semantic table annotation; Semantic table interpretation; Semantic tables; Semtab; Tabular data; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Zhou202488,
	author = {Zhou, Yuchen and Gu, Xin and Ding, Junsheng and Chen, Sirou and Perzylo, Alexander},
	title = {Accessing the Capabilities of KGs and LLMs in Mapping Indicators within Sustainability Reporting Standards},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3874},
	pages = {88 – 96},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214209575&partnerID=40&md5=ad0a0fb95f8f40bfc2ad09dff8dd0139},
	abstract = {Sustainability reporting is gaining importance in response to climate change and the pursuit of social sustainable development. In preparing these reports, sustainability managers are tasked with identifying sustainability indicators across multiple reporting standards. However, the challenge arises to locate the corresponding indicators in another standard through keyword searches due to the inconsistency of the naming conventions and classifications across different standards. Knowledge graphs(KGs) offer a promising solution for mapping the concepts of sustainability reporting from diverse standards. Nonetheless, traditional approaches to construct KGs are often time and resource intensive. In this context, the advanced natural language understanding capabilities of the Large Language Models (LLMs) could be explored to comprehend the reporting standards. Additionally, the rich knowledge structure of KGs could be leveraged to enhance the retrieval of relevant document snippets that describe the indicators within these standards. Accordingly, we propose a framework aimed at accessing the capabilities of KGs and LLMs in mapping indicators within sustainability reporting standards. This paper presents our framework, details two exploratory experiments, and discuses the preliminary results.  © 2024 Copyright for this paper by its authors.},
	author_keywords = {Indicators; Knowledge Graphs; Large Language Models; Sustainability Reporting Standards},
	keywords = {Climate change; Sustainable development goals; Keyword search; Knowledge graphs; Language model; Large language model; Mapping indicators; Reporting standards; Sustainability indicators; Sustainability reporting; Sustainability reporting standard; Traditional approachs; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Zhao2024114,
	author = {Zhao, Xinke and Yilahun, Hankiz and Hamdulla, Askar},
	title = {Text-to-CQL Based on Large Language Model and Graph Pattern Enhancement},
	year = {2024},
	journal = {2024 IEEE 5th International Conference on Pattern Recognition and Machine Learning, PRML 2024},
	pages = {114 – 119},
	doi = {10.1109/PRML62565.2024.10779814},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215514587&doi=10.1109%2fPRML62565.2024.10779814&partnerID=40&md5=8cc78e9ff0dc7a92f4a9be26c5ade3d6},
	abstract = {With the wide application of knowledge graphs in various scenarios and Neo4j graph databases becoming excellent knowledge graph carriers, Cypher (CQL for short) has become the most popular graph database query language. However, when performing graph database retrieval, the complex pattern and syntax make constructing CQL statements a complicated and time-consuming task. Therefore, similar to Text-to-SQL, it is necessary and urgent to study an effective method for end-to-end transformation of natural languages into CQL. There have been many advances in Text-to-SQL for traditional relational databases, but these methods cannot be well applied to Text-to-CQL, so there is still a lack of effective work on Text-to-CQL for graph databases. In recent years, as large language models have been widely applied to different tasks with good results, and considering that the fundamental difference between CQL and SQL is the representation of graph patterns. We propose in this paper PA-LLM, a Text-to-CQL method that utilizes large language models combined with graph patterns enhancement, which combines large language models and subdivides the graph patterns into three categories according to their respective characteristics. They are simple query patterns, multi-hop query patterns, and function query patterns. For different graph patterns, the method optimizes the process of generating CQL for the model, which can be subdivided into four sub-methods, simple pattern enhancement method, multi-hop pattern enhancement method, function pattern enhancement method, and entity-relationship enhancement method. The experimental results show that the method improves the quality of the CQL statements generated by the model, including the logical accuracy ACCLX and the execution result accuracy ACCEX, and achieves better results on the SpCQL dataset proposed by the National Defense University of Science and Technology (NDUST). It provides an effective solution for the task of converting CQL to natural language end-to-end. © 2024 IEEE.},
	author_keywords = {ChatGLM; Graph patterns enhancement; Knowledge graph; Neo4j; Text-to-CQL},
	keywords = {C (programming language); Graph Databases; Query languages; Relational database systems; Structured Query Language; ChatGLM; Graph database; Graph pattern enhancement; Graph patterns; Knowledge graphs; Language model; Neo4j; Pattern enhancements; Query patterns; Text-to-CQL; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Rai2024,
	author = {Rai, P. and Jain, A. and Anand, A.},
	title = {Generative AI and Large Language Model Assisted Causal Discovery and Inference for Driving Process Improvements},
	year = {2024},
	journal = {Society of Petroleum Engineers - ADIPEC 2024},
	doi = {10.2118/221872-MS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215082880&doi=10.2118%2f221872-MS&partnerID=40&md5=e1ed69c6b23684ab0b31205ede33c66b},
	abstract = {Data-driven process management coupled with machine learning have been successful in driving commercial value to oil and gas operators by offering insights into process disruptions and their root causes. One frequently used approach is to analyze causes of process disruptions exclusively from historical data. In general, specific insights in the form of high correlation between certain process performance indicators and a well-defined measure of production inefficiency is often confounded as responsible causal factors. While this may yield some insights, the complexity of processes, measured in terms of number of entities involved and their interrelationships, requires a more nuanced approach that must include the context of the specific process. Thus, data analysis must be augmented with significant inputs from experts. Causal Inference provides a conceptual framework and tools for doing such analysis. In causal analysis, we embed this specific knowledge of subject matter experts using causal graphs consisting of process features (nodes) and their dependency (directed edges). For complex processes however, constructing causal graphs could be non-trivial due to ambiguity over which nodes to include and the plausible direction of their relationships. With the advent of foundational Large Language Models (LLM), there is an opportunity to mitigate this problem by utilizing the enormous information it encodes. Tools and technologies now exist to customize the response of LLM using retrieval of information from a corpus of specific high-quality knowledge in the form of related literature and data. It can therefore be used to assist the domain expert in building and finetuning the causal graph, and in simpler cases, can completely automate this step. In this work, we propose a two-step approach to combine the power of LLMs and Causal Analysis for analyzing inefficiencies in production processes. In the first step, we implement a Retrieval Augmented Generation (RAG) enhanced LLM prompting on a curated dataset designed to answer specific questions on relationship between process performance indicators. The outcome of this step is a directed acyclic graph encoding dependency of process performance indicators. Domain experts can validate or potentially refine the LLM-generated causal graph based on their domain knowledge for eliminating spurious hallucinations. In the second step, we use an appropriate causal inference method on the refined causal diagram and historical production data to estimate the causal effect of process variable contributing to disruptions or inefficiencies. Thus, by combining human expertise with machine learning, this framework offers a comprehensive approach for optimizing production processes. Copyright 2024, Society of Petroleum Engineers.},
	keywords = {Automobile drivers; Benchmarking; Decision trees; Enterprise resource management; Enterprise resource planning; Flow visualization; Gasoline refining; Inference engines; Knowledge graph; Photomapping; Problem oriented languages; Tachometers; Causal analysis; Causal graph; Causal inferences; Data driven; Domain experts; Language model; Machine-learning; Process Improvement; Process performance indicators; Production process; Gasoline},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Gao2024,
	author = {Gao, Ting and Zhai, Xue and Yang, Chuan and Lv, Linlin and Wang, Han},
	title = {Joint extraction of entity and relation based on fine-tuning BERT for long biomedical literatures},
	year = {2024},
	journal = {Bioinformatics Advances},
	volume = {4},
	number = {1},
	doi = {10.1093/bioadv/vbae194},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213827033&doi=10.1093%2fbioadv%2fvbae194&partnerID=40&md5=24a13aba74d7b0f9178c8e6a41a180f4},
	abstract = {Motivation: Joint extraction of entity and relation is an important research direction in Information Extraction. The number of scientific and technological biomedical literature is rapidly increasing, so automatically extracting entities and their relations from these literatures are key tasks to promote the progress of biomedical research. Results: The joint extraction of entity and relation model achieves both intra-sentence extraction and cross-sentence extraction, alleviating the problem of long-distance information dependence in long literature. Joint extraction of entity and relation model incorporates a variety of advanced deep learning techniques in this paper: (i) a fine-tuning BERT text classification pre-training model, (ii) Graph Convolutional Network learning method, (iii) Robust Learning Against Textual Label Noise with Self-Mixup Training, (iv) Local regularization Conditional Random Fields. The model implements the following functions: identifying entities from complex biomedical literature effectively, extracting triples within and across sentences, reducing the effect of noisy data during training, and improving the robustness and accuracy of the model. The experiment results prove that the model performs well on the self-built BM_GBD dataset and public datasets, enabling precise large language model enhanced knowledge graph construction for biomedical tasks. © The Author(s) 2024.Published by Oxford University Press.},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@CONFERENCE{Heim20241347,
	author = {Heim, Desiree and Jilek, Christian and Ulges, Adrian and Dengel, Andreas},
	title = {Using Large Language Models to Generate Authentic Multi-agent Knowledge Work Datasets},
	year = {2024},
	journal = {Lecture Notes in Informatics (LNI), Proceedings - Series of the Gesellschaft fur Informatik (GI)},
	volume = {352},
	pages = {1347 – 1357},
	doi = {10.18420/inf2024_118},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216075196&doi=10.18420%2finf2024_118&partnerID=40&md5=8176dd5eca955ccb1036900ecba05aac},
	abstract = {Current publicly available knowledge work data collections lack diversity, extensive annotations, and contextual information about the users and their documents. These issues hinder objective and comparable data-driven evaluations and optimizations of knowledge work assistance systems. Due to the considerable resources needed to collect such data in real-life settings and the necessity of data censorship, collecting such a dataset appears nearly impossible. For this reason, we propose a configurable, multi-agent knowledge work dataset generator. This system simulates collaborative knowledge work among agents producing Large Language Model-generated documents and accompanying data traces. Additionally, the generator captures all background information, given in its configuration or created during the simulation process, in a knowledge graph. Finally, the resulting dataset can be utilized and shared without privacy or confidentiality concerns. This paper introduces our approach’s design and vision and focuses on generating authentic knowledge work documents using Large Language Models. Our study involving human raters who assessed 53% of the generated and 74% of the real documents as realistic demonstrates the potential of our approach. Furthermore, we analyze the authenticity criteria mentioned in the participants’ comments and elaborate on potential improvements for identified common issues. © 2024 Gesellschaft fur Informatik (GI). All rights reserved.},
	author_keywords = {Knowledge Work Dataset Generator; Large Language Models; Multi-agent Simulation},
	keywords = {Knowledge graph; Multi agent systems; 'current; Agent knowledge; Contextual information; Data collection; Knowledge work; Knowledge work dataset generator; Language model; Large language model; Multi agent; Multi-agents simulations; Digital elevation model},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{2024,
	title = {NLP4KGC 2024 - Proceedings of the 3rd International Workshop on Natural Language Processing for Knowledge Graph Creation, co-located with 20th International Conference on Semantic Systems, SEMANTiCS 2024},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3874},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214203615&partnerID=40&md5=dd68a799fc0ffdd80b02ba49c9de8999},
	abstract = {The proceedings contain 11 papers. The topics discussed include: on the pertinence of LLMs for ontology learning; towards the automation of knowledge graph construction using large language models; assessing SPARQL capabilities of large language models; breaking down financial news impact: a novel ai approach with geometric hypergraphs; ontology learning from text: an analysis on LLM performance; accessing the capabilities of KGs and LLMs in mapping indicators within sustainability reporting standards; converting fire safety regulations to SHACL shapes using natural language processing; ontology-based dataset discovery in the BUILDSPACE data management platform; pruning cycles in UMLS Metathesaurus: a neuro symbolic ai approach; and automated generation of competency questions using large language models and knowledge graphs.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Li2024116,
	author = {Li, Harry and Appleby, Gabriel and Suh, Ashley},
	title = {LinkQ: An LLM-Assisted Visual Interface for Knowledge Graph Question-Answering},
	year = {2024},
	journal = {Proceedings - 2024 IEEE Visualization Conference - Short Papers, VIS 2024},
	pages = {116 – 120},
	doi = {10.1109/VIS55277.2024.00031},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215265596&doi=10.1109%2fVIS55277.2024.00031&partnerID=40&md5=77dcbc0be5a981a87dc5784ddaa2f734},
	abstract = {We present LinkQ, a system that leverages a large language model (LLM) to facilitate knowledge graph (KG) query construction through natural language question-answering. Traditional approaches often require detailed knowledge of a graph querying language, limiting the ability for users - even experts - to acquire valuable insights from KGs. LinkQ simplifies this process by implementing a multistep protocol in which the LLM interprets a user's question, then systematically converts it into a well-formed query. LinkQ helps users iteratively refine any open-ended questions into precise ones, supporting both targeted and exploratory analysis. Further, LinkQ guards against the LLM hallucinating outputs by ensuring users' questions are only ever answered from ground truth KG data. We demonstrate the efficacy of LinkQ through a qualitative study with five KG practitioners. Our results indicate that practitioners find LinkQ effective for KG question-answering, and desire future LLM-assisted exploratory data analysis systems.  © 2024 IEEE.},
	author_keywords = {Knowledge graphs; large language models; natural language interfaces; query construction; question-answering},
	keywords = {Knowledge graph; Modeling languages; Query languages; Structured Query Language; Graph queries; Knowledge graphs; Language model; Large language model; Natural language interfaces; Natural language questions; Query construction; Question Answering; Traditional approachs; Visual Interface; Question answering},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@CONFERENCE{Mohsenzadegan2024,
	author = {Mohsenzadegan, Kabeh and Tavakkoli, Vahid and Kambale, Witesyavwirwa Vianney and Kyamakya, Kyandoghere},
	title = {A Hybrid AI Framework Integrating Ontology Learning, Knowledge Graphs, and Large Language Models for Improved Data Model Translation in Smart Manufacturing and Transportation},
	year = {2024},
	journal = {2024 Sensor Data Fusion: Trends, Solutions, Applications, SDF 2024},
	doi = {10.1109/SDF63218.2024.10773919},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215099473&doi=10.1109%2fSDF63218.2024.10773919&partnerID=40&md5=5fcbe67dc46387c032139870a3a72aa2},
	abstract = {Interoperability among diverse data standards is crucial for advancing digital technologies in smart manufacturing and transportation. This paper studies and presents a hybrid AI framework that integrates Ontology Learning (OL), Knowledge Graphs (KGs), and Large Language Models (LLMs) to enhance data translation across different standards. Focusing on IEEE 1451, ISO 15926, and IEC 61499, which exemplify the challenges of translating between distinct data models, we evaluate the performance of OL, KGs, and LLMs in terms of accuracy, scalability, efficiency, robustness, and flexibility. The findings indicate that the hybrid framework effectively leverages OL for semantic structuring, KGs for relational modeling, and LLMs for linguistic and contextual processing. This integration significantly improves the accuracy and adaptability of data translations, offering a comprehensive solution tailored to the complex environments of smart manufacturing and transportation, thereby advancing cross-standard data interoperability.  © 2024 IEEE.},
	author_keywords = {AI in Transportation; Cross-Standard Data Integration; Data Interoperability; Data Model Translation; Hybrid AI Framework; Knowledge Graphs (KGs); Large Language Models (LLMs); Ontology Learning (OL); Semantic Mapping; Smart Manufacturing},
	keywords = {Data accuracy; Data assimilation; Knowledge graph; AI in transportation; Cross-standard data integration; Data interoperability; Data model translation; Hybrid AI framework; Knowledge graph; Knowledge graphs; Language model; Large language model; Model translation; Ontology learning; Semantics mappings; Smart manufacturing; Smart manufacturing},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{De Giorgis2024,
	author = {De Giorgis, Stefano},
	title = {May the FORCE be with Semantics: exploiting LLMs to Image Schematic Knowledge Enrichment},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3888},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214838665&partnerID=40&md5=847a65a611064741707a6db0c189f376},
	abstract = {This paper addresses the underspecification of the FORCE image schema. We present a novel hybrid pipeline that combines large language model interactions, linguistic analysis, and knowledge extraction techniques to expand upon Johnson’s initial categorization of FORCE types. Our methodology employs Claude 3.5 Sonnet for domain exploration, generates a dataset of 100 force-expressing verbs with contextual sentences, and integrates findings into ImageSchemaNet through AMR2FRED processing and SPARQL querying. Key contributions include: (1) a more nuanced understanding of the FORCE image schema, (2) a validated dataset of force-related linguistic expressions, and (3) an enhanced ontology with empirically derived FORCE concepts. This work bridges the gap between abstract image schema theory and specific linguistic realizations of FORCE, offering practical tools for natural language processing, knowledge representation, and cognitive computing. © 2024 Copyright for this paper by its authors.},
	keywords = {Knowledge representation; Large datasets; Modeling languages; Natural language processing systems; Ontology; Domain exploration; Extraction techniques; Image schemata; Knowledge extraction; Language model; Linguistic analysis; Linguistic expressions; Linguistic knowledge; Model interaction; Underspecification; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Meyer202435,
	author = {Meyer, Lars-Peter and Frey, Johannes and Brei, Felix and Arndt, Natanael},
	title = {Assessing SPARQL Capabilities of Large Language Models},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3874},
	pages = {35 – 53},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214238211&partnerID=40&md5=a095b424bdc2ffe8fbeee2f16006d42e},
	abstract = {The integration of Large Language Models (LLMs) with Knowledge Graphs (KGs) offers significant synergistic potential for knowledge-driven applications. One possible integration is the interpretation and generation of formal languages, such as those used in the Semantic Web, with SPARQL being a core technology for accessing KGs. In this paper, we focus on measuring out-of-the box capabilities of LLMs to work with SPARQL and more specifically with SPARQL SELECT queries applying a quantitative approach. We implemented various benchmarking tasks in the LLM-KG-Bench framework for automated execution and evaluation with several LLMs. The tasks assess capabilities along the dimensions of syntax, semantic read, semantic create, and the role of knowledge graph prompt inclusion. With this new benchmarking tasks, we evaluated a selection of GPT, Gemini, and Claude models. Our findings indicate that working with SPARQL SELECT queries is still challenging for LLMs and heavily depends on the specific LLM as well as the complexity of the task. While fixing basic syntax errors seems to pose no problems for the best of the current LLMs evaluated, creating semantically correct SPARQL SELECT queries is difficult in several cases.  © 2024 Copyright for this paper by its authors.},
	author_keywords = {Knowledge Graph; LLM; LLM benchmarking; LLMs for Knowledge Graphs; RDF; SPARQL},
	keywords = {Benchmarking; Query languages; Semantics; Structured Query Language; Syntactics; Knowledge graphs; Language model; Large language model; Large language model benchmarking; Large language model for knowledge graph; Model benchmarking; RDF; SPARQL; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Thornton2024,
	author = {Thornton, Katherine and Seals-Nutt, Kenneth and Matsuzaki, Mika},
	title = {Nutritional Data Integrity in Complex Language Model Applications: Harnessing the WikiFCD Knowledge Graph for AI Self-Verification Across Multilingual International Food Composition Tables to Enrich Accuracy within Software Systems and AI-Enabled Interfaces},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3882},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214587582&partnerID=40&md5=3a0b9af17d2749d890c0b1cff10df42f},
	abstract = {Estimation of nutritional intake, a key determinant of our health, requires reliable and accurate food and nutrient information. As the convenience of chat-style interactions appeals to many people, can we trust agents powered by large language models (LLMs) to answer questions about nutrition accurately? We introduce the Wikidata and WikiFCD AI Food Composition Chat Bot (ChatWikiFCD), a chat bot for food composition information powered by structured data from WikiFCD and Wikidata and enhanced by LLMs. This approach combines referenced statements from human-curated knowledge bases, which include mappings to FoodOn, with generative artificial intelligence (AI). The system includes a chat-based application that provides explainable responses linked back to published sources. The system supports multilingual input and will respond in the human language in which a question is posed. This system leverages the benefits of LLMs while also reducing the risk of hallucination and provides fine-tuned data for the food domain sourced from published food composition tables. © 2024 Copyright for this paper by its authors.},
	author_keywords = {artificial intelligence; chat automation; Food Composition; hallucination detection; knowledge graphs; linked data; model augmentation; Nutri-informatics; Wikibase; Wikidata},
	keywords = {Knowledge graph; Chat automation; Food compositions; Hallucination detection; Informatics; Knowledge graphs; Language model; Model augmentation; Nutri-informatic; Wikibase; Wikidata; Chatbots},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Longo2024,
	author = {Longo, Carmelo Fabio and Santamaria, Daniele Francesco and Mongiovì, Misael and Bulla, Luana and Sanfilippo, Emilio M.},
	title = {Leveraging Knowledge Graphs inference for Semi-Explainable Systems based on Large Language Models},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3882},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214569139&partnerID=40&md5=825ad4c881d7d9dcade59aed9d11a5b4},
	abstract = {Recent advances in applying Large Language Models (LLMs) to natural language processing raise the challenge of integrating them with ontological models, to harness the features of Knowledge Graphs (KG) alongside the expressive abilities of LLMs. This paper introduces QuLIO-XR, a framework designed to integrate LLMs and ontologies, proposing an approach combining reasoning capabilities of OWL 2 with the expressive power of an LLM. Natural language text is structurally and semantically represented through the foundational ontology called LODO, which combines straightforward notation with human-like reasoning capabilities to address the issues derived from the expressive arbitrariness of natural languages. Experiments demonstrate also promising translation performances from RDF triples to the natural language, establishing QuLIO-XR as a valuable tool in the realm of LLMs explainability once fine-tuned with the same knowledge employed to build LODO KGs. © 2024 Copyright for this paper by its authors.},
	author_keywords = {Knowledge Graph; Large Language Models; Natural Language Processing; Semantic Web},
	keywords = {Latent semantic analysis; Natural language processing systems; Ontology; Semantics; Translation (languages); Knowledge graphs; Language model; Language processing; Large language model; Natural language processing; Natural languages; Ontological modeling; Ontology's; Reasoning capabilities; Semantic-Web; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Rascanu2024,
	author = {Rascanu, G. and Dzhusupova, R. and Guo, Z.},
	title = {Enhancing Engineering Document Analysis Through Structured Data Mapping},
	year = {2024},
	journal = {Society of Petroleum Engineers - ADIPEC 2024},
	doi = {10.2118/221950-MS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215069497&doi=10.2118%2f221950-MS&partnerID=40&md5=5f77ef7652ff44280afb0d92dcb1b235},
	abstract = {This paper presents an innovative approach for mapping engineering documents, particularly unstructured PDF files, to knowledge graphs, offering significant benefits for both engineering processes (i.e. such as 'review-check-approve' process) and AI-powered development. The method aims at improving efficiency, enhancing decision-making capabilities, reducing document turn-around duration, and thus decreasing costs while increasing productivity. Specific advantages include: • Quick overview for reviewers to prioritize tasks - more weight can be given to identified main topics with less time on the side topics. • Improved quality: interrupted relationships and isolated entities may indicate inconsistency that is usually overlooked in the traditional review process. • A faster review process achieved through common understanding between reviewers, resulting in a subjective time reduction (average 10% improvement) while enhancing quality. Our method leverages advanced natural language processing (NLP) techniques, sentence transformers and large language models (LLMs) to transform complex document content into structured knowledge visual representations. This approach addresses the challenge of efficiently extracting information from unstructured engineering documents by first identifying relevant keywords, that align with the main topics of the document, through a robust initial process. The extracted keywords define the framework upon which the entire knowledge graph is built, ensuring its relevance and utility. Central to our methodology are novel techniques in LLM-based prompt engineering that enhance entity and relationship extraction in complex engineering contexts. These techniques incorporate chain-of-thought reasoning for improved accuracy. Furthermore, we introduce a robust process of relevant keyword extraction as an initial step, which sets the foundation for all subsequent stages from entity extraction to final graph presentation. The resulting knowledge graphs serve as a method of enhanced visual understanding of documents that are often complex and difficult to comprehend through human analysis alone. By extracting patterns and connections that would otherwise be challenging to identify or understand, these graphs facilitate simplified document comprehension and improved data integration. Our proof-of-concept results demonstrate the effectiveness of this method in supporting decision-making processes in the energy sector. Using this methodology as the ground base we outline directions for future AI development applications such as generating contextually relevant responses of the interrogated documents, summary creation and integration with other AI technologies. Copyright 2024, Society of Petroleum Engineers.},
	keywords = {Cost engineering; Decision making; Mapping; Metadata; Natural language processing systems; Visual languages; Data mappings; Documents analysis; Engineering document; Entity extractions; Innovative approaches; Knowledge graphs; Language model; PDF files; Review process; Structured data; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Dong2024136,
	author = {Dong, Haomin and Wang, Wenbin and Sun, Zhenjiang and Kang, Ziyi and Ge, Xiaojun},
	title = {Iterative LLM Prompting for Intelligent Cockpit Knowledge Graph Construction},
	year = {2024},
	journal = {2024 4th International Conference on Computer Systems, ICCS 2024},
	pages = {136 – 145},
	doi = {10.1109/ICCS62594.2024.10795847},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215817926&doi=10.1109%2fICCS62594.2024.10795847&partnerID=40&md5=092d1f5689175d482c83555e32268b8f},
	abstract = {With the development of digital and intelligent cockpits, the data within these environments exhibit complexity and diversity, leading to issues such as inefficient data processing and difficulty in information extraction. Consequently, effectively capturing and representing the hidden associative knowledge in cockpits is crucial. Against this backdrop, knowledge graphs serve as an effective tool capable of retrieving and organizing a vast amount of information within a connected and interpretable structure. By systematically representing complex data relationships in the cockpit, they help enhance the prediction of precise interaction intentions and provide richer and more relevant knowledge support for personalized recommendations. However, rapidly and flexibly generating domain-specific knowledge graphs still poses certain challenges. This paper introduces an innovative method of knowledge graph construction using generative large language models, implementing a novel iterative zero-shot and domain-agnostic strategy. We propose an innovative strategy of iteratively prompting large language models to extract relevant triples for constructing knowledge graphs, effectively addressing key challenges such as entity recognition ambiguity and relationship extraction complexity in cockpit data. Experiments conducted in a domain-specific dataset demonstrate the feasibility of this method.  © 2024 IEEE.},
	author_keywords = {intelligent cockpit; knowledge graphs; LLMs; prompting engineering; triples},
	keywords = {Data handling; Modeling languages; Amount of information; Complex data; Effective tool; Graph construction; Intelligent cockpit; Knowledge graphs; Language model; LLM; Prompting engineering; Triple; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Loffredo202437,
	author = {Loffredo, Rocco and De Santo, Massimo},
	title = {Using Ontologies for LLM Applications in Cultural Heritage},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3865},
	pages = {37 – 43},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213724566&partnerID=40&md5=f016cf214de3b6a96a88252565f5c838},
	abstract = {Applying Large Language models (LLMs) offers the potential for transformative change in cultural heritage. This short paper is based on ongoing doctoral research. It examines innovative methodologies for enhancing the accessibility, comprehension, and preservation of cultural heritage by utilizing AI technologies such as LLM. This research aims to improve AI-generated responses' contextual precision and dependability by employing sophisticated knowledge representations, such as ontologies. The approach promises to overcome the challenges associated with data complexity and information retrieval, thereby creating new avenues for heritage documentation, education, and public engagement. © 2024 Copyright for this paper by its authors.},
	author_keywords = {cultural heritage; large language model; ontology; retrieval augmented generation},
	keywords = {Knowledge representation; AI Technologies; Cultural heritages; Doctoral research; Innovative methodologies; Knowledge-representation; Language model; Large language model; Model application; Ontology's; Retrieval augmented generation; Ontology},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{2024,
	title = {SWAT4HCLS 2024 - 15th International Conference on Semantic Web Applications and Tools for Health Care and Life Sciences},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3890},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214923143&partnerID=40&md5=1f129e8d697d5964595812d914592544},
	abstract = {The proceedings contain 44 papers. The topics discussed include: exploring the role of generative AI in constructing knowledge graphs for drug indications with medical context; SPHN strategy to unravel the semantic drift between versions of standard terminologies; representation and comparison of chemotherapy protocols with ChemoKG and graph embeddings; SPARQL generation: an analysis on fine-tuning OpenLLaMA for question answering over a life science knowledge graph; explaining graph neural network predictions for drug repurposing; refining SemOpenAlex concept ontology: a constraint-aware approach via knowledge graph embeddings and SKOS constraints; and unlocking semantics as a FAIR implementation profile. Reflections and lessons learned building user-centric semantic authoring applications.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Trappey2024,
	author = {Trappey, Amy J.C. and Chou, Shao-Chien and Li, Gi-Kuen J.},
	title = {Patent litigation mining using a large language model—Taking unmanned aerial vehicle development as the case domain},
	year = {2024},
	journal = {World Patent Information},
	doi = {10.1016/j.wpi.2024.102332},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213274311&doi=10.1016%2fj.wpi.2024.102332&partnerID=40&md5=22e593b7c14d2cc870616723f0357760},
	abstract = {As unmanned aerial vehicle (UAV), also called “drone”, swiftly advances with innovative functions and applications, the surge in patent applications has profoundly reshaped the intellectual property (IP) landscape in the UAV industry, leading to a growing number of litigations. This study is structured in two phases, aiming to develop an intelligent approach to analyzing the trend and evolution of patent litigations. The first phase involves macro- and micro-patent analyses of the related technology domain. Macro patent analysis elucidates the fundamental patent information in the drone industry, while micro patent analysis leverages the technology function matrix (TFM) to identify R&D hotspots and potentials. The second phase involves litigation (judgement) mining based on large language model (LLM). Beginning with the construction of a knowledge ontology, the domain infringement landscape can be detected through TFMs. A comparative analysis of the two-phase TFMs (i.e., both TFMs of patent and infringement allocations) is then conducted to pinpoint the key legal actions and the relevant technology. To drill deeper in infringement mining, dynamic topic modeling (DTM) is applied to analyze trends and dynamics in drone controller technology over time. This study aims to strengthen IP protection by developing an intelligent litigation mining approach that adopts large language model (LLM) and uses UAV/drone litigation studies as examples to show how the approach being applied in the industry. © 2024 Elsevier Ltd},
	author_keywords = {Drone; Dynamic topic modeling; Large language model; Patent analysis; Patent litigation mining; Technology function matrix; Unmanned aerial vehicle (UAV)},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{2024,
	title = {39th CCF National Conference on Computer Applications, CCF NCCA 2024},
	year = {2024},
	journal = {Communications in Computer and Information Science},
	volume = {2274 CCIS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215696514&partnerID=40&md5=916245f4226031ca18b3052e2fd8e3a9},
	abstract = {The proceedings contain 48 papers. The special focus in this conference is on Computer Applications. The topics include: A Rule-Based Multidimensional Axiomatic Fuzzy Set Knowledge Graph Question-Answering Model; multi-population Evolutionary Computation Based on Lethal Chromosome and Its Application in Path Planning; few-Shot Knowledge Graph Completion Based on Selective Attention and the Transformer; node Embedding of the Abstract Syntax Tree for Source Code Representation; end-to-End Deep Reinforcement Learning for Inclined Ladder Steps Grasping in Humanoid Robots; cooperative Coverage Path Planning for Air-Ground Heterogeneous Robots in Aircraft Skin Inspection Tasks; a Redis Cache-Based Approach to High Concurrency Response in Applications of Large Language Models; research and Application Status of a Tendency-Based Gas Source Localization Strategy via the Active Olfaction Method: A Review; exploring Named Entity Recognition in Medical Knowledge Graphs with Pre-trained Language Models and Attention Mechanism; a Text-Oriented Transformer with an Image Aesthetics Assessment Fusion Network for Visual-Textual Sentiment Analysis; Coverage Path Planning for Aircraft Skin Inspection UGV under Curvature Constraints; less Hallucination and More Factuality: Human Values Alignment in Text Summarization; chinese‒Korean Cross-Language Transfer Method That is Based on Language Features; a Knowledge–Enhanced Text Clustering Based Adversarial Learning for Text Generation; dialogue Understanding and Generation of Sequence Template and Path Retrieval Based on Knowledge Enhancement; DGCBA: A Novel Medical Point Cloud Segmentation Network Based on Dilated Graph Convolution and Boundary Awareness; question-Guided Hybrid Learning and Knowledge Embedding for Visual Question-Answering; integrating Image Super-Resolution Network and Semantic Segmentation for 3D Reconstruction of Medical Sequence Image; data Sources and Fast Preprocessing of Shoreline and Bathymetric Data from the Coastal Ocean Numerical Model: Examples of the Pearl River Estuary.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Fill202456,
	author = {Fill, Hans-Georg and Härer, Felix and Vasic, Iva and Borcard, Daniel and Reitemeyer, Benedikt and Muff, Fabian and Curty, Simon and Bühlmann, Marcel},
	title = {CMAG: A Framework for Conceptual Model Augmented Generative Artificial Intelligence},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3849},
	pages = {56 – 69},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212846551&partnerID=40&md5=6e50923447d851c128b4f071f00c7deb},
	abstract = {The advent of generative artificial intelligence, and in particular large language models, has opened up new possibilities for information processing in a multitude of domains. Nevertheless, it is essential to validate their output in order to ensure its validity within the specified context. This is due to their nature as probabilistic models of language, which may lead to the generation of inaccuracies or nonexistent facts commonly known as hallucinations. As a solution, we propose a framework and a prompt structure for the validation of the results of generative artificial intelligence in formats that are more human-comprehensible through the use of conceptual models. We denote this as conceptual model augmented generative artificial intelligence (CMAG). We illustrate the approach through application examples in the domains of data management, knowledge graphs and cultural heritage, and software engineering. © 2024 Copyright for this paper by its authors.},
	author_keywords = {Conceptual Model; Generative Artificial Intelligence; Large Language Model; Prompt Structure},
	keywords = {Application examples; Conceptual model; Cultural heritages; Generative artificial intelligence; Knowledge graphs; Language model; Large language model; Probabilistic models; Prompt structure; Generative adversarial networks},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Li20241043,
	author = {Li, Zehao and Zhong, Ling and Han, Xinyi},
	title = {Research on the Entity Relationship Extraction Method of Large Model Chinese Electronic Medical Record With Low-Moment Features},
	year = {2024},
	journal = {2024 4th International Conference on Electronic Information Engineering and Computer Science, EIECS 2024},
	pages = {1043 – 1046},
	doi = {10.1109/EIECS63941.2024.10800474},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216385288&doi=10.1109%2fEIECS63941.2024.10800474&partnerID=40&md5=eaf47ebcbb725a12507cd7f5d92495f0},
	abstract = {The entity relationship extraction of Chinese electronic medical records is used to construct the knowledge graph in the medical field, and it plays an important role in serving downstream tasks. However, due to the fuzzy boundary of Chinese electronic medical records, the complex relationship between medical texts, and the high density of entities, the task of extracting the physical relationships of medical texts is not accurate enough. To solve this problem, this paper adopts a large language model ChatGLM2-6B based on (Generative Language Model) architecture and Quantized Low-rank Adaptation of Large Language Models (QLoRA) for Chinese electronic medical record entity relationship extraction. By leveraging the powerful language understanding capabilities of ChatGLM2-6B and the efficient fine-tuning characteristics of QLoRA, the low-moment features are integrated to achieve accurate and efficient Chinese electronic medical record entity relationship extraction, which provides strong support for medical data analysis and clinical decision-making.  © 2024 IEEE.},
	author_keywords = {knowledge graph; large language models; low-moment features; relationship extraction},
	keywords = {Knowledge graph; Entity-relationship; Extraction method; Knowledge graphs; Language model; Large language model; Large models; Low-moment feature; Medical record; Moment features; Relationship extraction; Electronic health record},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Yue202484,
	author = {Yue, Dylan Li Tin and Jimenez-Ruiz, Ernesto},
	title = {CitySTI 2024 System: Tabular Data to KG Matching using LLMs},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3889},
	pages = {84 – 89},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214919840&partnerID=40&md5=0604860e7f8fbae0a9bf36eefd404d72},
	abstract = {This paper investigates the use of a Large Language Model (LLM) to match tabular data with knowledge graphs. The system participated in the STI vs. LLMs 2024 SemTab Track, which prompts a model to perform the cell entity annotation (CEA) task. The study covers the processes from data cleaning and matching to its execution in the cloud, while relying on a Lookup API to generate a list of candidates. This project not only contributes to the understanding of the applications of Large Language Models in tabular data annotations but also lays the groundwork for future research in the field. © 2024 Copyright for this paper by its authors.},
	author_keywords = {Entity Matching; Knowledge Graphs; Large Language Model; SemTab Challenge; Tabular Data Annotation},
	keywords = {Data annotation; Data cleaning; Entity matching; Knowledge graphs; Language model; Large language model; Matchings; Semtab challenge; Tabular data; Tabular data annotation; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Ahmad2024266,
	author = {Ahmad, Asiyah},
	title = {Knowledge Graphs in AI-Driven Biomedical and Chemical Engineering: A Survey of Construction, Applications, and Future Directions},
	year = {2024},
	journal = {Proceedings - 2024 Conference on AI, Science, Engineering, and Technology, AIxSET 2024},
	pages = {266 – 275},
	doi = {10.1109/AIxSET62544.2024.00050},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215095823&doi=10.1109%2fAIxSET62544.2024.00050&partnerID=40&md5=6cec5182ac05ea898b951315810e2654},
	abstract = {Knowledge graphs have become a popular means of storing and exploring complex data across multiple disci-plines. This survey paper explores the foundational concepts and methodologies for constructing and utilizing knowledge graphs, with a particular focus on AI-driven applications in biomedical and chemical engineering. We discuss the essential tools and frameworks commonly used in the field, followed by a detailed examination of inference algorithms tailored for these knowledge graphs. We highlight various applications, including large language models, illustrating the transformative potential of knowledge graphs in identifying drug targets, optimizing material properties, and enhancing personalized medicine. We address the challenges and limitations inherent in developing and deploying knowledge graphs, including data quality, scalability, and interoperability issues. Finally, we outline future research directions and opportunities, emphasizing the integration of advanced AI techniques and the expansion of knowledge graphs to new scientific domains. © 2024 IEEE.},
	author_keywords = {Biomedical Engineering; Chemical Engineering; Disease Modeling; Drug Discovery; Knowledge Extraction; Knowledge Graphs; Large Language Models; Materials Optimization; Personalized Medicine; Survey Paper},
	keywords = {Biomedical materials; Inference engines; Personalized medicine; Construction applications; Disease models; Drug discovery; Knowledge extraction; Knowledge graphs; Language model; Large language model; Material optimization; Personalized medicines; Survey paper; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Wang2024,
	author = {Wang, Zihan and Huo, Hong and Xu, Renxin and Yang, Shijie and Fang, Tao},
	title = {Ophthalmic Disease Zero-Shot Question Answering Through Knowledge Triple Augmented Language Model Prompting},
	year = {2024},
	journal = {MLNLP 2024 - 2024 International Conference on Machine Learning and Natural Language Processing},
	doi = {10.1109/MLNLP63328.2024.10800230},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215608264&doi=10.1109%2fMLNLP63328.2024.10800230&partnerID=40&md5=2eecf509550555073e72e5e8bc64f435},
	abstract = {Ophthalmic disease zero-shot question answering aims to answer questions about ophthalmic disease in natural language without any model training. Although the pretrained large language models (LLMs) have stored quantities of general knowledge of the real-world and made zero-shot question answering come true, they ususally have insufficient ophthalmic knowledge, and fine-tuning LLMs to update their internal ophthalmic knowledge is very compute-intensive and expensive. By utilizing the specialized knowledge in the self-built ophthalmic disease knowledge graph (ODKG) to augment LLMs, the proposed Knowledge Triple Augmented language model Prompting (KTAP) has well implemented ophthalmic disease zero-shot question answering. Our KTAP is primarily divided into three modules: entity linking, knowledge retriever and knowledge injection. The entity linking module extracts ophthalmic disease entities from the question by a prompt-based zero-shot entity linking method, and a subgraph related to these ophthalmic disease entities is obtained from ODKG. The knowledge retriever module consists of two submodules, the text embedding and the similarity matching. The former is responsible for calculating embeddings of both each triple in the subgraph and entities in the question, while the latter calculates the semantic similarity between each triple embedding and the question embedding to obtain the top K triples most relevant to the question. In the knowledge injection module, a prompt template based on the top K triples and the question is designed to guide LLMs to perform ophthalmic disease zero-shot question answering. The experiments have shown that in the zero-shot question answering task of ophthalmic disease, the proposed KTAP has outperformed other language model prompting baselines by an average of 16% in the precision of generated answers. © 2024 IEEE.},
	author_keywords = {Knowledge Graph; Language Model Prompting; Ophthalmic Disease; Zero-shot Question Answering},
	keywords = {Graph embeddings; Modeling languages; Semantics; Zero-shot learning; Embeddings; Knowledge graphs; Language model; Language model prompting; Model training; Natural languages; Ophthalmic disease; Question Answering; Subgraphs; Zero-shot question answering; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Díaz2024,
	author = {Díaz, Camila and Dunstan, Jocelyn and Etcheverry, Lorena and Fonck, Antonia and Grez, Alejandro and Mery, Domingo and Reutter, Juan and Rojas, Hugo},
	title = {Automatic knowledge-graph creation from historical documents: The Chilean dictatorship as a case study},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3853},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212705684&partnerID=40&md5=d0fcc6d861c72eaca0134114f37b278e},
	abstract = {We present our results regarding the construction of a knowledge graph from historical documents related to the Chilean dictatorship period (1973-1990). Our approach uses LLMs to automatically recognize entities and relations between them and resolve conflicts between these values. To prevent hallucination, the interaction with the LLM is grounded in a simple ontology with four types of entities and seven types of relations. To evaluate our architecture, we use a gold standard graph constructed using a small subset of the documents, and compare this to the graph obtained from our approach when processing the same set of documents. Results show that the automatic construction manages to recognize a good portion of all the entities in the gold standard and that those not recognized are explained mainly by the level of granularity in which the information is structured in the graph and not because the automatic approach misses an important entity in the graph. Looking forward, we expect this report to encourage work on other similar projects focused on enhancing research in humanities and social science. However, we remark that better evaluation metrics are needed to accurately fine-tune these types of architectures. © 2024 Copyright for this paper by its authors.},
	keywords = {History; Ontology; Automatic approaches; Automatic construction; Case-studies; Gold standards; Historical documents; Humanities and social science; Knowledge graphs; Ontology's; Simple++; Types of relations; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Parmar2024,
	author = {Parmar, Darshna and Nagrani, Tanish and Babre, Rushabh and Mazumdar, Pramit},
	title = {From Conversations to Knowledge: Enriching Movie Datasets with Knowledge Graph},
	year = {2024},
	journal = {2024 15th International Conference on Computing Communication and Networking Technologies, ICCCNT 2024},
	doi = {10.1109/ICCCNT61001.2024.10723870},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212837445&doi=10.1109%2fICCCNT61001.2024.10723870&partnerID=40&md5=ba8ba5e2327e5203b1edd5550af29c03},
	abstract = {Knowledge graphs are invaluable assets for facilitating the dissemination of structured and semantically enriched data to both humans and machines while ensuring its accuracy and reliability. However, it has been observed that a direct approach of generating knowledge graph from existing benchmark data sources such as ReDial, DBPedia, etc. fails to highlight many crucial relationships between entities. In this work we proposed a strategy to enrich a knowledge graph by resolving multiple entity relationships generated from the ReDial movie dataset. First the missing entities and their corresponding relationships were identified. Subsequently, the publicly available large TMDb dataset is leveraged to align additional information such as genre, director, actor, writer, and year as nodes. Bidirectional links are then introduced to semantically enrich the knowledge graph. Validating a knowledge graph is considered as another important step. In this direction, we extract triplets in (movie, relationship, genre) format from the knowledge graph. The triplets are validated using IMDb which is a vast repository of movie details, and the Gemini Generative AI model. We compute accuracy of the extracted triplets and the results indicate improvement in the knowledge graph generation strategy and the IMDb as an efficient validator for our approach. © 2024 IEEE.},
	author_keywords = {Fact Validation; Gemini; IMDb; Knowledge Graph; Named Entity Recognition; ReDial; TMDb},
	keywords = {Benchmark data; Data-source; Direct approach; Fact validation; Geminus; IMDb; Knowledge graphs; Named entity recognition; Redial; TMDb; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Schaeffer20241,
	author = {Schaeffer, Marion and Sesboüé, Matthias and Charbonnier, Léa and Delestre, Nicolas and Kotowicz, Jean-Philippe and Zanni-Merk, Cecilia},
	title = {On the Pertinence of LLMs for Ontology Learning},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3874},
	pages = {1 – 18},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214247692&partnerID=40&md5=a817900503c26a5320cf55725e593f4d},
	abstract = {Ontology learning from text is traditionally approached as sub-tasks tackled with linguistic, statistical or logic-based methods. Large language models and their generation capabilities have recently caught much interest. We investigate the pertinence of such generative models for ontology learning. We evaluate the created ontologies on two different use cases by aligning with a reference ontology and compare components for each sub-task using the OLAF ontology learning framework. In addition to demonstrating the relevance of large language models for ontology learning, we discuss component combinations, LLM size, and environmental impact in creating efficient pipelines while limiting resource consumption.  © 2024 Copyright for this paper by its authors.},
	author_keywords = {Knowledge Graph Construction; LLM; Ontology Learning},
	keywords = {Adversarial machine learning; Federated learning; Knowledge graph; Ontology; Generative model; Graph construction; Knowledge graph construction; Knowledge graphs; Language model; Learning from texts; LLM; Ontology learning; Ontology's; Subtask; Contrastive Learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Molinari2024,
	author = {Molinari, Andrea and Sandri, Simone},
	title = {Evolution of LMS Design and Implementation in the Age of AI and Large Language Models},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3879},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214206144&partnerID=40&md5=d001822ff7fa4fe9baea5f9da4905800},
	abstract = {The integration of generative AI and large language models (LLMs) into Learning Management Systems (LMSs) offers significant potential but remains underutilized. Current implementations typically involve the LMS requesting services from an AI engine, such as responses, suggestions, and content summaries, reflecting a superficial interaction between two distinct systems. This limited integration arises from the architecture of most major LMS platforms (e.g., Moodle, Docebo, Sakai), which were designed in the early 2000s. These systems are structured around relational databases and multi-layered logic, which separates business logic from the user interface. While they offer extensive multimedia resources for education, their content is generally organized into folders based on modules or lessons, limiting their adaptability to modern AI functionalities. Additionally, while some platforms support text-based interactions (forums, FAQs, blogs), their overall design remains outdated. This paper proposes a new software architecture for LMSs, designed to natively support AI functionalities. It advocates for a shift from relational to graph-based models for content storage, allowing the creation of a knowledge graph that integrates ontological frameworks. This transformation would enable more advanced AI-driven functionalities, such as content recommendations, semantic searches, and personalized learning experiences. We also address the challenges inherent in such a transformation, including a) the need for a complete redesign of the platform's persistence and business logic layers; b) the complexity of integrating multi-domain ontologies within educational institutions; and c) the technological hurdles in training large, adaptive language models that can evolve in real-time, especially during periods of high content generation. © 2024 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0)},
	author_keywords = {Knowledge Graphs; Learning Management Systems; Named-entity recognition},
	keywords = {C (programming language); Ontology; Relational database systems; Semantics; 'current; Creative Commons; Design and implementations; Knowledge graphs; Language model; Learning management system; Multi-layered; Named entity recognition; Relational Database; System platforms; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Piazza2024,
	author = {Piazza, Nancirose and Upadhayay, Bibek and Scarpa, Ronald and Behzadan, Vahid},
	title = {Large Language Models for Automatic Standardization of Cyber Deception Plans based on the Adversary Engagement Ontology},
	year = {2024},
	journal = {Proceedings - IEEE Military Communications Conference MILCOM},
	doi = {10.1109/MILCOM61039.2024.10773797},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214561637&doi=10.1109%2fMILCOM61039.2024.10773797&partnerID=40&md5=3680db5b3589df21dca84df6396a7615},
	abstract = {Adversary Engagement Ontology (AEO) is a candidate ontology for the Unified Cyber Ontology (UCO), a community effort aimed at ontological standardization of cyber domain concepts and objects under a unifying framework. It forms a part of the Cyber Domain Ontology (CDO). In the past, community efforts and development have always been labor-intensive with regards to changes in ontology, example generation for adopters, and documentation generation. Large Language Models (LLMs), such as Claude-3.5-Sonnet and GPT4, have been proven capable of automating many tasks and aiding in human expert decision-making. Additionally, LLMs have been used in code interpretation, generation, and evaluation with efficiency and accuracy comparable to that of humans. This emergent capability of LLMs has led to the advantage of using LLMs to streamline the process of ontology development. Motivated by the aforementioned-approaches, we aim to demonstrate how these foundational LLMs can assist in ontology example generation and development, as well as be utilized to automate structured, albeit tedious tasks. © 2024 IEEE.},
	author_keywords = {Adversary Engagement; Ontology},
	keywords = {Decision making; Adversary engagement; Decisions makings; Domain concepts; Domain ontologies; Human expert; Labour-intensive; Language model; Ontology development; Ontology's; Plan-based; Ontology},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Rekik2024,
	author = {Rekik, Karim and Zhou, Zengpeng and Ouzineb, Sohaib and Zened, Olfa and Amour, Myriam},
	title = {Accelerating Wellbore Domain Interpretations Using Generative AI and Knowledge Graphs},
	year = {2024},
	journal = {Society of Petroleum Engineers - ADIPEC 2024},
	doi = {10.2118/222164-MS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85215077442&doi=10.2118%2f222164-MS&partnerID=40&md5=15c218a1028c3b40b9f5c2a29a91cef2},
	abstract = {The petroleum industry relies heavily on accurate wellbore domain interpretation for effective resource management and extraction. Traditionally, this process involves numerous complex and time-consuming steps, such as data normalization, unit harmonization, and depth matching, often requiring extensive expertise. This paper presents an AI-powered solution designed to automate the creation of wellbore interpretation workflows, significantly enhancing efficiency and accuracy. Our solution integrates generative AI, large language models (LLM), and graph-based methods to streamline the workflow creation process. The methodology involves three key steps: knowledge gathering from extensive documentation, automatic workflow generation through natural language interactions with a chatbot, and execution of quality-checked workflows. By leveraging a comprehensive knowledge base built from training manuals, API references, and historical interpretation data, our system can intelligently suggest optimal workflows in response to user queries. Tests conducted using data from the Groningen field demonstrate the effectiveness of this approach. The time required to create a lithology computation workflow was reduced from the typical 15-30 minutes to just 10 seconds using our AI-powered workflow advisor. This represents a time reduction factor of up to 180 for junior petrophysicists. The knowledge graph employed in this process showed a 93% accuracy in building workflows, ensuring reliability and precision. This innovative solution not only saves time but also minimizes errors, enabling non-experts to perform accurate data interpretation. The AI-powered workflow advisor represents a significant advancement in the automation of wellbore interpretation tasks, demonstrating the potential of machine learning to revolutionize the petroleum industry. By automating tedious and complex processes, our solution contributes to faster, more reliable wellbore analysis, ultimately improving decision-making and operational efficiency. Copyright 2024, Society of Petroleum Engineers.},
	keywords = {Gasoline; Oil well flooding; Petroleum engineering; Resource valuation; Unit operations (oil wells); Data normalization; Depth matching; Harmonisation; Knowledge graphs; Language model; Model-based method; Resource extraction; Resource management; Wellbore; Work-flows; Petroleum industry},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Hamann20241407,
	author = {Hamann, Felix and Falk, Maurice and Walker, Lukas},
	title = {Expanding Knowledge Graphs Through Text: Leveraging Large Language Models for Inductive Link Prediction},
	year = {2024},
	journal = {Lecture Notes in Informatics (LNI), Proceedings - Series of the Gesellschaft fur Informatik (GI)},
	volume = {352},
	pages = {1407 – 1417},
	doi = {10.18420/inf2024_123},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216084920&doi=10.18420%2finf2024_123&partnerID=40&md5=91c481a85ed92bbf89da2c27b5af10dd},
	abstract = {Knowledge graphs (KG) play a crucial role for knowledge modelling in various domains such as web search, medical applications, or technical support, yet they are often incomplete. To mitigate this problem, knowledge graph completion (KGC) may be used to infer missing links of the graph. Taking it a step further, in an automated knowledge acquisition process, links for entirely new, unseen entities may be incorporated. This process is known as inductive link prediction (I-LP). Optionally, text as an external source of information is leveraged to infer the correct linkage of such entities. Depending on the context, this text either provides a comprehensive singular description of the entity or includes numerous incidental references to it. This paper presents a study that explores the application of LLAMA3 as a representative of the current generation of large language models (LLM) to I-LP. Through experimentation on popular benchmark datasets such as Wikidata5m, FB15k-237, WN18-RR, and IRT2, we evaluate the performance of LLMs for inserting new facts into a knowledge base, given textual references to the target object. These benchmarks, by design, exhibit significant variations in the quality of the associated text, as well as in the number of entities and links included. This paper explores several prompt formulations and studies whether pre-emptive retrieval of text helps. For automated link prediction, we implement the full cycle of prompt generation, answer processing, entity candidate lookup and finally link prediction. Our results show that LLM-based inductive link-prediction is outperformed by previously suggested models which fine-tune task-specific LM encoders. © 2024 Gesellschaft fur Informatik (GI). All rights reserved.},
	author_keywords = {Inductive Link Prediction; Knowledge Graph Completion; Large Language Models; Prompting},
	keywords = {Economic and social effects; Knowledge acquisition; Modeling languages; Prediction models; Inductive link; Inductive link prediction; Knowledge graph completion; Knowledge graphs; Knowledge model; Language model; Large language model; Link prediction; Prompting; Web searches; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{2024,
	title = {39th CCF National Conference on Computer Applications, CCF NCCA 2024},
	year = {2024},
	journal = {Communications in Computer and Information Science},
	volume = {2275 CCIS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85216084404&partnerID=40&md5=59b37dfba282805c33aa109dce895dde},
	abstract = {The proceedings contain 48 papers. The special focus in this conference is on Computer Applications. The topics include: A Rule-Based Multidimensional Axiomatic Fuzzy Set Knowledge Graph Question-Answering Model; multi-population Evolutionary Computation Based on Lethal Chromosome and Its Application in Path Planning; few-Shot Knowledge Graph Completion Based on Selective Attention and the Transformer; node Embedding of the Abstract Syntax Tree for Source Code Representation; end-to-End Deep Reinforcement Learning for Inclined Ladder Steps Grasping in Humanoid Robots; cooperative Coverage Path Planning for Air-Ground Heterogeneous Robots in Aircraft Skin Inspection Tasks; a Redis Cache-Based Approach to High Concurrency Response in Applications of Large Language Models; research and Application Status of a Tendency-Based Gas Source Localization Strategy via the Active Olfaction Method: A Review; exploring Named Entity Recognition in Medical Knowledge Graphs with Pre-trained Language Models and Attention Mechanism; a Text-Oriented Transformer with an Image Aesthetics Assessment Fusion Network for Visual-Textual Sentiment Analysis; Coverage Path Planning for Aircraft Skin Inspection UGV under Curvature Constraints; less Hallucination and More Factuality: Human Values Alignment in Text Summarization; chinese‒Korean Cross-Language Transfer Method That is Based on Language Features; a Knowledge–Enhanced Text Clustering Based Adversarial Learning for Text Generation; dialogue Understanding and Generation of Sequence Template and Path Retrieval Based on Knowledge Enhancement; DGCBA: A Novel Medical Point Cloud Segmentation Network Based on Dilated Graph Convolution and Boundary Awareness; question-Guided Hybrid Learning and Knowledge Embedding for Visual Question-Answering; integrating Image Super-Resolution Network and Semantic Segmentation for 3D Reconstruction of Medical Sequence Image; data Sources and Fast Preprocessing of Shoreline and Bathymetric Data from the Coastal Ocean Numerical Model: Examples of the Pearl River Estuary.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Bernasconi202477,
	author = {Bernasconi, Eleonora and Ferilli, Stefano},
	title = {Semantic Label Property Graph Ontologies: A Methodology for Enhanced Data Management in Digital Libraries},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3865},
	pages = {77 – 84},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85213708014&partnerID=40&md5=e08f9a45847ec1264c35ec62d1820708},
	abstract = {Ontologies are crucial for managing and integrating diverse datasets in digital libraries, where data heterogeneity poses ongoing challenges. This paper presents a novel framework specifically designed to address the unique needs of digital libraries using Semantic Label Property Graphs. Our methodology aligns with semantic web standards, offering a sophisticated approach to data management that enhances integration, querying, and visualization of complex datasets. The proposed framework supports automated ontology generation, advanced semantic integration, and seamless visualization, leveraging the structural efficiency of Property Graphs with semantic annotations to optimize resource discovery, management, and retrieval. We detail the architecture and core functionalities of the framework, demonstrating its adaptability in managing complex ontologies and improving workflows for researchers and practitioners. Empirical evaluations reveal significant performance improvements in data management and linked data integration, underscoring the framework's potential to streamline workflows and enhance semantic interoperability. This innovative approach addresses the evolving challenges of large-scale data management, positioning the framework as a valuable tool for the future of digital libraries. © 2024 Copyright for this paper by its authors.},
	author_keywords = {Artificial Intelligence; Digital Libraries; Label Property Graph; Large Language Models; Schema Management; Semantic Ontologies; Semantic Web},
	keywords = {Label property graph; Language model; Large language model; Ontology's; Property; Schema management; Semantic labels; Semantic ontology; Semantic-Web; Work-flows; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Bakker202470,
	author = {Bakker, Roos M. and Di Scala, Daan L. and De Boer, Maaike H. T.},
	title = {Ontology Learning from Text: an Analysis on LLM Performance},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3874},
	pages = {70 – 87},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214243423&partnerID=40&md5=8356243bab75422799ef66c7e3d26eff},
	abstract = {Ontologies provide a structured framework to represent and integrate domain knowledge. Developing them is a complex and time-consuming task, requiring domain expertise to ensure accuracy and consistency. Ontology learning aims to automate this process by learning full ontologies, or parts of them, from sources such as textual data. In this paper, we research the potential of Large Language Models (LLMs), specifically GPT-4o, in ontology learning, using a real-world use case. We introduce a manually constructed ontology based on knowledge in a news article, and compare it to ontologies extracted using three different prompting approaches over multiple runs. The resulting ontologies are evaluated both quantitatively and qualitatively, to ensure that differences in performance due to modelling choices are also considered. The results show that, while the LLM effectively identifies important classes and individuals, it often does not include properties between classes, and adds inconsistent and incorrect properties between individuals. Prompting on a sentence level leads to more correct individuals and properties, however, quantitative evaluation shows more hallucinations and incorrect triples. Despite these issues, LLMs advance previous ontology learning methods by considering classes, individuals, and properties as a whole, creating a more complete ontology rather than isolated elements. This provides a new perspective on ontology learning and highlights the potential of LLMs to offer a first version of an ontology or an extension to an existing one based on new information.  © 2024 Copyright for this paper by its authors.},
	author_keywords = {information extraction; knowledge graph extraction; large language models; ontology learning},
	keywords = {Adversarial machine learning; Federated learning; Knowledge graph; Graph extractions; Information extraction; Knowledge graph extraction; Knowledge graphs; Language model; Large language model; Learning from texts; Ontology learning; Ontology's; Property; Contrastive Learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Xia2024,
	author = {Xia, Liqiao and Fan, Junming and Parlikad, Ajith and Huang, Xiao and Zheng, Pai},
	title = {Unlocking Large Language Model Power in Industry: Privacy-Preserving Collaborative Creation of Knowledge Graph},
	year = {2024},
	journal = {IEEE Transactions on Big Data},
	doi = {10.1109/TBDATA.2024.3522814},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214128747&doi=10.1109%2fTBDATA.2024.3522814&partnerID=40&md5=58301953dfc874972cb801a0451f1f88},
	abstract = {Semantic expertise remains a reliable foundation for industrial decision-making, while Large Language Models (LLMs) can augment the often limited empirical knowledge by generating domain-specific insights, though the quality of this generative knowledge is uncertain. Integrating LLMs with the collective wisdom of multiple stakeholders could enhance the quality and scale of knowledge, yet this integration might inadvertently raise privacy concerns for stakeholders. In response to this challenge, Federated Learning (FL) is harnessed to improve the knowledge base quality by cryptically leveraging other stakeholders' knowledge, where knowledge base is represented in Knowledge Graph (KG) form. Initially, a multi-field hyperbolic (MFH) graph embedding method vectorizes entities, furnishing mathematical representations in lieu of solely semantic meanings. The FL framework subsequently encrypted identifies and fuses common entities, whereby the updated entities' embedding can refine other private entities' embedding locally, thus enhancing the overall KG quality. Finally, the KG complement method refines and clarifies triplets to improve the overall quality of the KG. An experiment assesses the proposed approach across different industrial KGs, confirming its effectiveness as a viable solution for collaborative KG creation, all while maintaining data security.  © 2015 IEEE.},
	author_keywords = {Federated Learning; Graph Embedding; Industrial 4.0; Knowledge Graph; Large Language Models},
	keywords = {Collaborative learning; Differential privacy; Graph embeddings; Decisions makings; Embeddings; Empirical knowledge; Graph embeddings; Industrial 4.0; Knowledge graphs; Language model; Large language model; Modeling power; Privacy preserving; Knowledge graph},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Schiese2024267,
	author = {Schiese, Dennis and Perevalov, Aleksandr and Both, Andreas},
	title = {TOWARDS LLM-GENERATED EXPLANATIONS FOR COMPONENT-BASED KNOWLEDGE GRAPH QUESTION ANSWERING SYSTEMS},
	year = {2024},
	journal = {Proceedings of the International Conferences on Applied Computing and WWW/Internet 2024},
	pages = {267 – 276},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85214139110&partnerID=40&md5=30e9ddf31d473f9d2fb153d7d1c4839e},
	abstract = {Over time, software systems have reached a level of complexity that makes it difficult for their developers and users to explain particular decisions made by them. In this paper, we focus on the explainability of component-based systems for Question Answering (QA). These components often conduct processes driven by AI methods, in which behavior and decisions cannot be clearly explained or justified, s.t., even for QA experts interpreting the executed process and its results is hard. To address this challenge, we present an approach that considers the components’ input and output data flows as a source for representing the behavior and provide explanations for the components, enabling users to comprehend what happened. In the QA framework used here, the data flows of the components are represented as SPARQL queries (inputs) and RDF triples (outputs). Hence, we are also providing valuable insights on verbalization regarding these data types. In our experiments, the approach generates explanations while following template-based settings (baseline) or via the use of Large Language Models (LLMs) with different configurations (automatic generation). Our evaluation shows that the explanations generated via LLMs achieve high quality and mostly outperform template-based approaches according to the users’ ratings. Therefore, it enables us to automatically explain the behavior and decisions of QA components to humans while using RDF and SPARQL as a context for explanations. © 2024 Proceedings of the International Conferences on Applied Computing and WWW/Internet 2024. All rights reserved.},
	author_keywords = {Explainable AI; Knowledge Graphs; Large Language Models; Question Answering; RDF; SPARQL},
	keywords = {Data flow graphs; Knowledge graph; Component based; Dataflow; Explainable AI; Knowledge graphs; Language model; Large language model; Question Answering; Question answering systems; RDF; SPARQL; Question answering},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}@CONFERENCE{Yoo202483,
	author = {Yoo, Taewoo and Cheong, Yun-Gyung},
	title = {Leveraging LLM-Constructed Graphs for Effective Goal-Driven Storytelling},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3818},
	pages = {83 – 95},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209668701&partnerID=40&md5=db3aeb1d0b9508c2262eaa37ac0ef368},
	abstract = {While advanced language models, such as Large Language Models (LLMs), have demonstrated potential in generating various types of text, including narratives, they often struggle to maintain semantic consistency. In narrative theory, skeleton selection refers to deriving a story’s backbone by choosing only the pivotal events, or nucleus, from the comprehensive story world (fabula), ensuring a focused and coherent narrative structure. To address the challenges faced by LLMs, we utilize Story Plan Graphs (SPGs)—a form of Knowledge Graphs—to ensure logical soundness for skeleton construction. When evaluated against GPT-3.5 using the ROCStories dataset, our approach demonstrates enhanced skeleton selection capabilities, offering an efficient solution for storytelling. © 2024 Copyright for this paper by its authors.},
	author_keywords = {Goal-driven storytelling; KGs (Knowledge Graphs); LLMs (Large Language Models); Narrative generation; SPGs (Story Plan Graphs)},
	keywords = {Musculoskeletal system; Semantics; Goal-driven; Goal-driven storytelling; Knowledge graph; Knowledge graphs; Language model; Large language model; Narrative generation; Narrative theory; Semantic consistency; Story plan graph; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Şeker2024,
	author = {Şeker, Şadi Evren},
	title = {Editorial: Large language models in work and business},
	year = {2024},
	journal = {Frontiers in Artificial Intelligence},
	volume = {7},
	doi = {10.3389/frai.2024.1516832},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212121340&doi=10.3389%2ffrai.2024.1516832&partnerID=40&md5=01f441b8d32e0af895cd15f42109b50b},
	author_keywords = {AI in business; data driven decision making; knowledge graph; LLM; XAI},
	type = {Editorial},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Hao2024,
	author = {Hao, Xubing and Cui, Licong and Tao, Cui and Roberts, Kirk and Amith, Muhammad},
	title = {Analyzing Llama 3-based Approach for Axiom Translation from Ontologies},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3853},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212688634&partnerID=40&md5=2bb61c3b90845531b2a9b19696705ec7},
	abstract = {Ontology development involves a top-down approach where ontology engineers and domain experts collaboratively define and evaluate ontological elements and axioms. Translating ontology axioms into natural language can significantly aid in ontology evaluation by making the content more understandable to subject matter experts who may lack a background in knowledge engineering. In this preliminary study, we investigate the potential of large language models (LLMs) in axiom translation from ontologies to facilitate ontology evaluation. We utilize Llama 3 to translate 1,192 ontology axioms across 19 distinct axiom types from five published ontologies. Results show that 163 (13.67%) of the Llama 3 translation of the axiom are accurately represented, 268 (22.48%) are not accurately represented, and 761 (63.84%) are partially accurate. Our manual evaluation of the Llama 3 translation indicates some competency in producing hierarchical natural language equivalents while revealing some limitations when translating complex axioms. Nonetheless, there are opportunities to improve the results with few-shot training or using LLMs to provide support in knowledge engineering for ontologies. © 2024 Copyright for this paper by its authors.},
	keywords = {Ontology; Translation (languages); Domain experts; Language model; Natural languages; Ontological elements; Ontology axioms; Ontology development; Ontology evaluations; Ontology's; Subject matter experts; Top down approaches; Knowledge engineering},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Zhang2024,
	author = {Zhang, Yingbo and Ren, Shumin and Wang, Jiao and Lu, Junyu and Wu, Cong and He, Mengqiao and Liu, Xingyun and Wu, Rongrong and Zhao, Jing and Zhan, Chaoying and Du, Dan and Zhan, Zhajun and Singla, Rajeev K. and Shen, Bairong},
	title = {Aligning Large Language Models with Humans: A Comprehensive Survey of ChatGPT’s Aptitude in Pharmacology},
	year = {2024},
	journal = {Drugs},
	doi = {10.1007/s40265-024-02124-2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212522060&doi=10.1007%2fs40265-024-02124-2&partnerID=40&md5=01e8526b5436c5e190ef5299366f370d},
	abstract = {Background: Due to the lack of a comprehensive pharmacology test set, evaluating the potential and value of large language models (LLMs) in pharmacology is complex and challenging. Aims: This study aims to provide a test set reference for assessing the application potential of both general-purpose and specialized LLMs in pharmacology. Methods: We constructed a pharmacology test set consisting of three tasks: drug information retrieval, lead compound structure optimization, and research trend summarization and analysis. Subsequently, we compared the performance of general-purpose LLMs GPT-3.5 and GPT-4 on this test set. Results: The results indicate that GPT-3.5 and GPT-4 can better understand instructions for information retrieval, scheme optimization, and trend summarization in pharmacology, showing significant potential in basic pharmacology tasks, especially in areas such as drug pharmacological properties, pharmacokinetics, mode of action, and toxicity prediction. These general LLMs also effectively summarize the current challenges and future trends in this field, proving their valuable resource for interdisciplinary pharmacology researchers. However, the limitations of ChatGPT become evident when handling tasks such as drug identification queries, drug interaction information retrieval, and drug structure simulation optimization. It struggles to provide accurate interaction information for individual or specific drugs and cannot optimize specific drugs. This lack of depth in knowledge integration and analysis limits its application in scientific research and clinical exploration. Conclusion: Therefore, exploring retrieval-augmented generation (RAG) or integrating proprietary knowledge bases and knowledge graphs into pharmacology-oriented ChatGPT systems would yield favorable results. This integration will further optimize the potential of LLMs in pharmacology. © The Author(s) 2024.},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Monti2024,
	author = {Monti, Marco and Kutz, Oliver and Righetti, Guendalina and Troquard, Nicolas},
	title = {Improving the Accuracy of Black-Box Language Models with Ontologies: A Preliminary Roadmap},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3882},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210825174&partnerID=40&md5=60d777f52ba7a7467274422944bdb59d},
	abstract = {Large Language Models (LLMs) have revolutionised natural language generation. But their statistical and auto-regressive nature makes them unreliable. It has become clear to the research community that in order to produce reliably correct answers, LLMs need to be enriched in some way with ‘world models’ reflecting the semantics of the domains being queried. We here propose a simple workflow to address this problem through a neuro-symbolic interaction protocol with the LLM treated as a blackbox. Answers given by an LLM are checked against accepted knowledge provided by a domain ontology. The approach aims to combine conflict detection with explanation extraction and formal repairs presented to the LLM in the form of specific artificial speech acts. The goal is to build constraining, incremental prompts that improve repeatability and veracity in the LLM’s output. © 2024 Copyright for this paper by its authors.},
	author_keywords = {LLM; neuro-symbolic reasoning; ontologies},
	keywords = {Latent semantic analysis; Natural language processing systems; Ontology; Speech enhancement; Auto-regressive; Black boxes; Language model; Large language model; Natural language generation; Neuro-symbolic reasoning; Ontology's; Research communities; Roadmap; Symbolic reasoning; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{2024,
	title = {SICSA-REALLM 2024 - Proceedings of the SICSA Workshop on Reasoning, Evaluation and Application of Large Language Models},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3822},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210021824&partnerID=40&md5=a37311d16502cece39ea494853bb34f1},
	abstract = {The proceedings contain 8 papers. The topics discussed include: towards improving open-box hallucination detection in large language models (LLMs); extended results for enhancing abstract screening classification in evidence-based medicine: incorporating domain knowledge into pre-trained models; towards LLM-driven automated verification of best practices in digital public infrastructures; formal dialogue and large language models; evaluating large language models on qualitative reasoning tasks: a case study using OpenAI GPT models; dual-task dialogue understanding; SCaLe-QA: Sri Lankan case law embeddings for legal QA; and integrating KGs and ontologies with RAG for personalized summarization in regulatory compliance.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Wen2024460,
	author = {Wen, Sijie and Chen, Yongming and Pan, Xinyu and Zhuang, Weibin and Li, Xinyu},
	title = {Enhancing Fault Troubleshooting through Human-Machine Collaboration: A Multi-Stage Reasoning Approach},
	year = {2024},
	journal = {IEEE International Conference on Automation Science and Engineering},
	pages = {460 – 467},
	doi = {10.1109/CASE59546.2024.10711734},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208228009&doi=10.1109%2fCASE59546.2024.10711734&partnerID=40&md5=61b5e65aaabc34b5eb6518666b1a1101},
	abstract = {Ensuring the stable operation of critical industrial equipment is pivotal for maintaining production efficiency and economic gains. The complexity of modern industrial machinery, however, places a substantial cognitive load on maintenance personnel. To alleviate this, a Diagnostic Semantic-Enhanced Fault Causality Knowledge Graph (DSFCKG) is proposed to formalize fault information for computational analysis. Additionally, a Large Language Model (LLM)-based Knowledge Graph Construction (KGC) method is introduced for the automated assembly of DSFCKG. Building upon this, a multi-stage reasoning approach is designed for human-machine collaborative fault Troubleshooting. Experiments on real-world fault tickets demonstrate that our proposed method significantly enhances fault diagnosis and troubleshooting accuracy, especially in complex scenarios with long fault causal chains, which bring insights into futuristic smart maintenance. © 2024 IEEE.},
	keywords = {Problem oriented languages; Economic gains; Efficiency gain; Human-machine collaboration; Industrial equipment; Knowledge graphs; Multi-stages; Production economics; Production efficiency; Reasoning approach; Stable operation; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Fortuna20248,
	author = {Fortuna, Carolina and Hanzel, Vid and Bertalanic, Blaz},
	title = {Natural Language Interaction with a Household Electricity Knowledge-based Digital Twin},
	year = {2024},
	journal = {2024 IEEE International Conference on Communications, Control, and Computing Technologies for Smart Grids, SmartGridComm 2024},
	pages = {8 – 14},
	doi = {10.1109/SmartGridComm60555.2024.10738062},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210826784&doi=10.1109%2fSmartGridComm60555.2024.10738062&partnerID=40&md5=20d9cb95094ee3a5803d18fdb119e728},
	abstract = {Domain specific digital twins, representing a digital replica of various segments of the smart grid, are foreseen as able to model, simulate, and control the respective segments. At the same time, knowledge-based digital twins, coupled with AI, may also empower humans to understand aspects of the system through natural language interaction in view of planning and policy making. This paper is the first to assess and report on the potential of Retrieval Augmented Generation (RAG) question answers related to household electrical energy measurement aspects leveraging a knowledge-based energy digital twin. Relying on the recently published electricity consumption knowledge graph that actually represents a knowledge-based digital twin, we study the capabilities of ChatGPT, Gemini and Llama in answering electricity related questions. Furthermore, we compare the answers with the ones generated through a RAG techniques that leverages an existing electricity knowledge-based digital twin. Our findings illustrate that the RAG approach not only reduces the incidence of incorrect information typically generated by LLMs but also significantly improves the quality of the output by grounding responses in verifiable data. This paper details our methodology, presents a comparative analysis of responses with and without RAG, and discusses the implications of our findings for future applications of AI in specialized sectors like energy data analysis.  © 2024 IEEE.},
	author_keywords = {house-holds; knowledge graph; knowledge-based digital twin; large language models; retrieval augmented generation},
	keywords = {Digital replicas; Domain specific; House-hold; Knowledge based; Knowledge graphs; Knowledge-based digital twin; Language model; Large language model; Natural language interaction; Retrieval augmented generation; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@ARTICLE{Tavakkoli202449,
	author = {Tavakkoli, Vahid and Mohsenzadegan, Kabeh and Kyamakya, Kyandoghere},
	title = {Leveraging Context-Aware Emotion and Fatigue Recognition Through Large Language Models for Enhanced Advanced Driver Assistance Systems (ADAS)},
	year = {2024},
	journal = {Studies in Computational Intelligence},
	volume = {1175},
	pages = {49 – 85},
	doi = {10.1007/978-3-031-71821-2_2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208981614&doi=10.1007%2f978-3-031-71821-2_2&partnerID=40&md5=f50bab35b3b04801f03fa49abb6e64db},
	abstract = {The automotive sector is swiftly advancing, focusing on driving experiences that prioritize safety and integrate with human emotions and well-being. This chapter explores the transformative potential of combining large language models (LLMs) with context-aware emotion and fatigue recognition techniques in Advanced Driver Assistance Systems (ADAS). The primary objective is to enhance driving experiences and overall well-being through real-time emotional and fatigue assessments. Grounded in Active and Assisted Living (AAL) principles, this chapter emphasizes the practical implementation of bio-signal-based emotion and fatigue estimation techniques within the ADAS framework. Utilizing formal knowledge representation techniques, such as ontologies, demonstrates how contextual modeling can facilitate optimal support services in dynamic driving contexts. Central to this approach is the integration of LLMs with emotion and fatigue recognition methodologies. The chapter details using non-intrusive bio-signal sensors to analyze facial expressions through video, EEG measurements, and voice analysis. This synergy between language comprehension and bio-signal insights enables real-time emotional assessments and fatigue estimations, empowering safer and more responsive driving experiences. LLMs act as the cognitive bridge, enhancing human driver assistance with context-aware emotion and fatigue recognition. The chapter reveals the potential of language models to decode emotional cues and detect fatigue levels, which are crucial for shaping proactive and adaptive driver assistance strategies. Integrating LLMs within ADAS showcases their ability to anticipate driver needs, provide timely alerts, and improve decision-making processes. Importantly, this chapter offers a roadmap for integrating LLMs with context-aware emotion and fatigue recognition into ADAS. Leveraging the capabilities of LLMs presents a scalable method for embedding bio-signal-based emotion and fatigue estimation techniques into ADAS, highlighting the AAL principles while demonstrating the transformative potential of LLMs. This work envisions an advanced iteration of ADAS, fostering a safer, more intuitive, and supportive driving experience. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {Advanced Driver Assistance Systems (ADAS); Bio-signal processing; Context-aware systems; Emotion and fatigue detection; Human-centered design; Large Language Models (LLMs); Real-time assessments},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Chellagurki202460,
	author = {Chellagurki, Pranav and Kumaru, Sai Prasanna Kumar and Peela, Rahul Raghava and Yeluri, Neeharika and Rojas, Carlos and Jetcheva, Jorjeta},
	title = {Biomedical Relation Extraction Using LLMs and Knowledge Graphs},
	year = {2024},
	journal = {Proceedings - IEEE 10th International Conference on Big Data Computing Service and Applications, BigDataService 2024},
	pages = {60 – 69},
	doi = {10.1109/BigDataService62917.2024.00015},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209652074&doi=10.1109%2fBigDataService62917.2024.00015&partnerID=40&md5=5bb124504d11a97254e0bb7d74ab67be},
	abstract = {Due to the rapid growth of research papers on biomedical topics, it has become increasingly important to make advancements in biomedical Natural Language Processing (NLP). Biomedical NLP enables us to extract important information from text, such as new insights into the role of different genes in disease susceptibility, or the potential for drug therapies that are effective against one disease to work effectively against another. In this paper, we present a comparative evaluation of the binary relation classification capabilities of the current state-of-the-art binary relation classifier, BioBERT, against recently released open-source large language models, Gemma-2b, Gemma-7b, and Llama2-7b, which we fine-tune with the benchmark GAD and EU-ADR datasets. In addition, we quantify the potential of discovering new relationships by utilizing knowledge graphs built out of known binary relations.  © 2024 IEEE.},
	author_keywords = {biomedical natural language processing; LLMs; relation extraction},
	keywords = {Disease control; Natural language processing systems; Targeted drug delivery; Binary relation; Biomedical natural language processing; Disease susceptibility; Knowledge graphs; Language processing; LLM; Natural languages; Rapid growth; Relation extraction; Research papers; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Zhang2024,
	author = {Zhang, Jinrui and Han, Linyi and Zhang, Xiaowang},
	title = {KFC-QR: A Knowledge Fusion Constraint Method Based on Query Retrieval for CPE prediction},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3828},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210253958&partnerID=40&md5=cd4c35a61ddcb10e61a2cf0de2fe7963},
	abstract = {Textual vulnerability description (TVD) is the record of software vulnerability by software engineers. Software engineers use the common platform enumerations (CPE) in TVDs to find software related to the vulnerability record. However, CPE is always incomplete, which makes it difficult to comprehensively identify the software affected by the vulnerability. Existing work focuses on completing CPE through CPE prediction based on the Knowledge Graph Embedding (KGE) model. However, the KGE model cannot capture the potential connections between softwares in TVD. In this poster, we propose a knowledge fusion constraint method based on query retrieval. Firstly, we extract the subgraph related to TVDs from the graph, which contains known CPEs and vulnerability types. Then, we use a large language model (LLM) combined with the subgraph to rerank the candidate CPEs predicted by the KGE model. Experiments show that our framework improves the accuracy of TVD-CPE link prediction, providing valuable support for software developers in product security assessment. © 2024 Copyright for this paper by its authors.},
	author_keywords = {CPE Prediction; Large Language Model; Vulnerability Knowledge Graph},
	keywords = {Graph embeddings; Prediction models; Query languages; Structured Query Language; Common platform; Common platform enumeration prediction; Constraints method; Graph embeddings; Knowledge fusion; Knowledge graphs; Language model; Large language model; Vulnerability description; Vulnerability knowledge graph; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Baddour2024,
	author = {Baddour, Moussa and Paquelet, Stephane and Rollier, Paul and De Tayrac, Marie and Dameron, Olivier and Labbe, Thomas},
	title = {Phenotypes Extraction from Text: Analysis and Perspective in the LLM Era},
	year = {2024},
	journal = {International IEEE Conference  proceedings, IS},
	number = {2024},
	doi = {10.1109/IS61756.2024.10705235},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208419027&doi=10.1109%2fIS61756.2024.10705235&partnerID=40&md5=100c2cd1ee6520fb0c6d6608a1d89e92},
	abstract = {Collecting the relevant list of patient phenotypes, known as deep phenotyping, can significantly improve the final diagnosis. As textual clinical reports are the richest source of phenotypes information, their automatic extraction is a critical task. The main challenges of this Information Extraction (IE) task are to identify precisely the text spans related to a phenotype and to link them unequivocally to referenced entities from a source such as the Human Phenotype Ontology (HPO). Recently, Language Models (LMs) have been the most suc-cessful approach for extracting phenotypes from clinical reports. Solutions such as PhenoBERT, relying on BERT or GPT, have shown promising results when applied to datasets built on the hypothesis that most phenotypes are explicitly mentioned in the text. However, this assumption is not always true in medical genetics. Hence, although the LMs carry powerful semantic abilities, their contributions are not clear compared to syntactic string-matching steps that are used within the current pipelines. The goal of this study is to improve phenotype extraction from clinical notes related to genetic diseases. Our contributions are threefold: First, we provide a clear definition of the phenotype extraction task from free text, along with a high-level overview of the involved functions. Second, we conduct an in-depth analysis of PhenoBERT, one of the best existing solutions, to evaluate the proportion of phenotypes predicted with simple string-matching. Third, we demonstrate how utilizing and incorporating large language models (LLMs) for span detection step can improve performance especially with implicit phenotypes. In addition, this experiment revealed that the annotations of existing dataset are not exhaustive, and that LLM can identify relevant spans missed by human labelers.  © 2024 IEEE.},
	author_keywords = {embed dings; entity linking; genetic; LLM; phenoBERT; phenotype},
	keywords = {Embed ding; Entity linking; Genetic; Language model; Large language model; Phenobert; Phenotype; Phenotyping; String matching; Text analysis; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@CONFERENCE{Lecu2024443,
	author = {Lecu, Alexandru and Groza, Adrian and Hawizy, Lezan},
	title = {Using LLMs and ontologies to extract causal relationships from medical abstracts},
	year = {2024},
	journal = {Procedia Computer Science},
	volume = {244},
	pages = {443 – 452},
	doi = {10.1016/j.procs.2024.10.219},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211237678&doi=10.1016%2fj.procs.2024.10.219&partnerID=40&md5=5af066d1d718d6ad0fc655edfada9bd1},
	abstract = {The substantiation of the causal relationships behind its development is very important in identifying possible interventions and early treatment. Knowledge Graphs (KG) play a crucial role in the medical research domain by organizing data into interconnected structures that represent relationships between entities such as disease, treatments, and progressions. This paper shows a complete workflow that demonstrates the extraction of causal relationships from medical abstracts using a fine-tuned GPT-based model and the integration of these relationships into a KG. © 2024 The Authors. Published by Elsevier B.V.},
	author_keywords = {Age-Related Macular Degeneration; Causal Relation Extraction; Knowledge Graphs; Large Language Models},
	keywords = {Medical informatics; Age-related macular degeneration; Causal relation extractions; Causal relationships; Interconnected structures; Knowledge graphs; Language model; Large language model; Medical research; Ontology's; Research domains; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Bhat20241,
	author = {Bhat, Vani and Cheerla, Sree Divya and Mathew, Jinu Rose and Pathak, Nupur and Liu, Guannan and Gao, Jerry},
	title = {Retrieval Augmented Generation (RAG) Based Restaurant Chatbot with AI Testability},
	year = {2024},
	journal = {Proceedings - IEEE 10th International Conference on Big Data Computing Service and Applications, BigDataService 2024},
	pages = {1 – 10},
	doi = {10.1109/BigDataService62917.2024.00008},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209684760&doi=10.1109%2fBigDataService62917.2024.00008&partnerID=40&md5=a1325212c3e31e2614bebaf5285669d8},
	abstract = {Post-COVID the restaurant industry is experiencing a surge in demand, presenting a unique challenge of efficiently managing increased customer flow while ensuring seamless interactions. Chatbots have emerged as an innovative solution to meet the demand increase. The paper addresses the enhancement of AI chatbots through the integration of Retrieval-Augmented Generation (RAG) with the Large Language Model (LLM). This paper focuses on the development of a restaurant chatbot that not only engages in natural-language conversations but also addresses context optimization and LLM optimization for restaurant context learning. The approach uses a Neo4j Knowledge graph built using the restaurant data as an external source of knowledge. The graph is traversed to match the user question with appropriate answer tokens using Term Frequency - Inverse Document Frequency (TF-IDF) embeddings. The relevant tokens along with user questions are used to provide additional context to the T5 language model to provide nuanced responses to the users. This improvement is quantitatively evidenced by a Bilingual Evaluation Understudy (BLEU) score of 0.60, indicating a high level of precision in language understanding and generation. An extensive evaluation of the chatbot includes assessing AI testability on the level of words, sentences, and information. These evaluations include simulated dialogue assessments and performance analyses, with a focus on the chatbot's ability to retrieve and integrate information. Based on the AI testability evaluation, the models consistently produce more knowledgeable, diverse, and relevant answers as compared with state-of-the-art models with an average information score in the range of 0.6-0.8.  © 2024 IEEE.},
	author_keywords = {AI Testability; Information Retrieval (IR); Knowledge Graph; Large Language Model (LLM); Natural Language Processing (NLP); Retrieval Augmented Generation (RAG)},
	keywords = {Inverse problems; Knowledge graph; Metadata; Natural language processing systems; AI testability; Information retrieval; Knowledge graphs; Language model; Language processing; Large language model; Natural language processing; Natural languages; Retrieval augmented generation; Testability},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Çöplü2024,
	author = {Çöplü, Tolga and Bendiken, Arto and Skomorokhov, Andrii and Bateiko, Eduard and Cobb, Stephen},
	title = {Ontology-Guided On-Device Conversational Knowledge Capture with Large Language Models},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3853},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212670794&partnerID=40&md5=ed0f3bd8cee345316a2d76349d063d84},
	abstract = {Generative AI applications must integrate users' personal information into the response generation process to offer an advanced user experience. One of the most effective methods for obtaining accurate and current user information is by capturing this data from AI interactions. This paper examines conversational knowledge capture using ontology and knowledge-graph approaches. We propose enhancing the large language model's (LLM) ability to capture precise and relevant information by training it with a subset of the KNOW ontology, which models personal knowledge. Our paper details the ontology-guided training process and evaluates the success of knowledge capture using a specially constructed dataset. Additionally, we emphasize the importance of privacy in handling personal information and investigate the implementation of knowledge capture with on-device language models. Our findings highlight the potential of on-device solutions to effectively capture personal knowledge while preserving user privacy. © 2024 Copyright for this paper by its authors.},
	keywords = {Knowledge graph; 'current; AI applications; Generation process; Knowledge capture; Language model; Ontology's; Personal information; Response generation; User information; Users' experiences; Differential privacy},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{2024,
	title = {ISWC-Posters-Demos-Industry 2024 - Proceedings of the ISWC 2024 Posters, Demos and Industry Tracks: From Novel Ideas to Industrial Practice, co-located with 23rd International Semantic Web Conference, ISWC 2024},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3828},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210246992&partnerID=40&md5=9784b0ea71874b0f83def5d49169ea44},
	abstract = {The proceedings contain 51 papers. The topics discussed include: compressing multi-modal temporal knowledge graphs of videos; towards a heliophysics knowledge commons; extracting graphs from tables via conceptual models; MG-GNN: enhancing GNNs for anomaly detection via minority class sample generation; optimizing traversal queries of sensor data using a rule-based reachability approach; decompositional semantic analysis for LLM-based code quality evaluation; collaborative system synergizing human expertise and large-scale language models for legal knowledge graph construction; towards a knowledge graph for teaching knowledge graphs; scalable database-driven kgs can help text-to-SQL; supporting next-generation science with a semantic ecosystem; and KFC-QR: a knowledge fusion constraint method based on query retrieval for CPE prediction.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Schmidt2024,
	author = {Schmidt, Michael and Bebee, Brad and Broekema, Willem and Elzarei, Mohamed and Lopez Enriquez, Carlos Manuel and Neyman, Marcin and Schmedding, Florian and Steigmiller, Andreas and Thompson, Bryan and Varkey, Geo and Williams, Gregory Todd and Xiang, Amanda},
	title = {openCypher over RDF: Connecting Two Worlds},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3828},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210268884&partnerID=40&md5=c91608c3233ff9b73a511f78dd2bb71c},
	abstract = {Today’s graph database space is divided into two – for the most part, separated – technology stacks: Labeled Property Graphs (LPGs) and RDF. As the team working on Amazon Neptune, a graph database that supports both technologies, we aim to give our customers the choice and flexibility they need to address their graph use cases. What we learned when working with them on their graph applications – from social networks, recommendations, fraud detection, to Knowledge Graphs and LLM grounding – is that the two technology stacks each have their unique strengths. RDF, with its standardized serialization formats, global identifiers, and the availability of Linked Open Data sets, is of particular value for data architects who seek to build, integrate, and interchange graph data. Application development teams, on the other hand, often prefer LPG query languages to interact with graphs, due to their intuitive syntax, the maturity of developer ecosystems (client drivers, programming language integration, etc.), and graph-specific features such as built-in support for path extraction and algorithms. In this demo we will present our recent work on openCypher over RDF, which aims to combine the strengths of the two worlds by (a) allowing our customers to load LPG and RDF data into a single, connected graph and (b) querying this single graph using the openCypher query language. From a conceptual perspective, this functionally is achieved by an overarching graph metamodel called OneGraph, which encompasses both data models and provides LPG and RDF specific views that implicitly define query semantics. We will utilize open data sets to showcase how we combine LPG and RDF data into a single data graph, demonstrate how this unified graph can be queried and modified using openCypher, and discuss concepts, design decisions, as well as remaining challenges in aligning the LPG and RDF stacks. © 2024 Copyright for this paper by Amazon Web Services.},
	keywords = {Graph Databases; Knowledge graph; Labeled data; Metadata; Problem oriented languages; Sales; Structured Query Language; Data set; Fraud detection; Graph data; Graph database; Knowledge graphs; Neptune; Property; RDF data; S-graph; Team working; Query languages},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Pan20243155,
	author = {Pan, Xinyu and Gong, Jie and Wen, Sijie and Zhuang, Weibin and Li, Xinyu},
	title = {Mining User Requirement Scenarios and Generating Design Solutions for Rehabilitation Aids Based on Large Language Models},
	year = {2024},
	journal = {IEEE International Conference on Automation Science and Engineering},
	pages = {3155 – 3161},
	doi = {10.1109/CASE59546.2024.10711793},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208237892&doi=10.1109%2fCASE59546.2024.10711793&partnerID=40&md5=56cdd8042c4609ad8c0072fbdad0a7f7},
	abstract = {The development of the rehabilitation aids industry for the disabled has been pivotal in recent years, particularly in the personalized design of lower limb rehabilitation aids. Facing challenges in meeting individualized demands in design practice and the information gap between medical professionals and users, we propose a design Knowledge Graph (KG) method based on the Function-Behavior-Structure (FBS) model. This approach utilizes open-source large language models (LLMs) and fine-tunes them with instruction data generated by self-instructions to improve the accuracy of user requirements mining. The method aims to enhance the personalization and innovation of rehabilitation aids design through the integration of KG and LLM, effectively narrowing the cognitive gap between service providers and users. The anticipated results of the study are expected to promote efficient innovation in rehabilitation aids design, better meeting the needs of the disabled community. © 2024 IEEE.},
	keywords = {Design for manufacturability; Disabled persons; Neuromuscular rehabilitation; Reconstruction (structural); Design practice; Design solutions; Information-gap; Knowledge graphs; Language model; Limb rehabilitation; Lower limb; Rehabilitation aids; Requirements scenarios; User requirements; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Jia2024,
	author = {Jia, Runsong and Zhang, Bowen and Rodríguez-Méndez, Sergio J. and Omran, Pouya G.},
	title = {Towards Building an RDF-based Deep Document Model and Retrieval Augmented Generation System for Enhanced Question Answering with Large Language Models},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3828},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210259392&partnerID=40&md5=f1941cf74434d556a7f2f27fa9a238d9},
	abstract = {Knowledge Graphs (KGs) are crucial for Retrieval-Augmented Generation (RAG), but traditional methods have limitations in capturing details and querying academic KGs. The challenges lie in identifying the appropriate KG type for RAG, such as a Metadata KG, and optimizing the integration of Large Language Models (LLMs) with KGs to enhance retrieval and generation. This paper introduces a novel framework combining the Deep Document Model (DDM) concept and a KG-enhanced Query Processing (KGQP) mechanism. DDM provides a comprehensive, hierarchical representation of academic papers using advanced Natural Language Processing (NLP) techniques, while KGQP optimizes complex queries using the KG’s structural information and semantic relationships. The framework also integrates KGs with state-of-the-art LLMs to improve knowledge utilization and downstream task performance. Evaluations show that the KG-based approach surpasses vector-based methods in relevance, accuracy, completeness, and readability. This research demonstrates the potential of combining KGs and LLMs for effective academic knowledge management and discovery. § Submission type: Poster §. © 2024 Copyright for this paper by its authors.},
	author_keywords = {Deep Document Model; Information Extraction; Knowledge Graph; Knowledge Graph Construction; Large Language Model},
	keywords = {Information retrieval; Natural language processing systems; Query languages; Query processing; Question answering; Semantics; Structured Query Language; Deep document model; Document modeling; Document Retrieval; Graph construction; Information extraction; Knowledge graph construction; Knowledge graphs; Language model; Large language model; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Villegas-Ch2024191994,
	author = {Villegas-Ch, William and Govea, Jaime and Gutierrez, Rommel},
	title = {Optimizing Language Model-Based Educational Assistants Using Knowledge Graphs: Integration with Moodle LMS},
	year = {2024},
	journal = {IEEE Access},
	volume = {12},
	pages = {191994 – 192012},
	doi = {10.1109/ACCESS.2024.3518952},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212600030&doi=10.1109%2fACCESS.2024.3518952&partnerID=40&md5=37c166ada51b9c45fc451d231692b637},
	abstract = {Chatbots in educational settings have grown significantly, facilitating interaction between students and learning platforms. However, current systems, such as Rasa, Moodle Integrated Chatbots, and ChatterBot, present significant limitations in precision, adaptability, and response time, affecting their effectiveness in resolving academic queries and personalizing learning. To address these shortcomings, this work proposes the development of an advanced educational chatbot that combines large language models (LLMs) with knowledge graphs, allowing for more accurate and contextualized responses and offering valuable suggestions to enrich the learning process. The system is evaluated based on its ability to adjust to different student profiles and offer fast and accurate responses. The results show that the proposed chatbot achieves a precision of 85%, outperforming Rasa and ChatterBot, which achieved accuracies of 83% and 81%, respectively. Furthermore, the chatbot reduces response times to 0.41 seconds, improving efficiency compared to other solutions. The system also demonstrates adaptability, effectively adjusting to students' learning styles and academic levels. This work indicates that knowledge graph integration and hyperparameter optimization are crucial to improving educational chatbots' precision, speed, and adaptability, presenting an innovative solution that overcomes the limitations of current systems.  © 2013 IEEE.},
	author_keywords = {Educational chatbots; knowledge graphs; large language models; learning personalization},
	keywords = {Chatbots; Chatterbots; Current system; Educational chatbot; Knowledge graphs; Language model; Large language model; Learning personalization; Model-based OPC; Personalizations; Knowledge graph},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@CONFERENCE{2024,
	title = {Proceedings - 2024 International Conference on Embedded Software, EMSOFT 2024},
	year = {2024},
	journal = {Proceedings - 2024 International Conference on Embedded Software, EMSOFT 2024},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212255519&partnerID=40&md5=9340af7159250406ff5d044d10c069fd},
	abstract = {The proceedings contain 4 papers. The topics discussed include: work-in-progress: real-time vehicular traffic-based crowd density estimation for reducing epidemiological risks; work-in-progress: development of margin-shared system-level logical execution time simulator to support scheduling design of automotive ECUs; work-in-progress: on-device retrieval augmented generation with knowledge graphs for personalized large language models; and work-in-progress: ESOps - an agile pipeline for next-generation embedded systems development.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Haque2024,
	author = {Haque, Mohd Ariful and Kamal, Marufa and George, Roy and Gupta, Kishor Datta},
	title = {Utilizing Structural Metrics from Knowledge Graphs to Enhance the Robustness Quantification of Large Language Models (Extended Abstract)},
	year = {2024},
	journal = {2024 IEEE 11th International Conference on Data Science and Advanced Analytics, DSAA 2024},
	doi = {10.1109/DSAA61799.2024.10722791},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209373283&doi=10.1109%2fDSAA61799.2024.10722791&partnerID=40&md5=709780d2b95a924779cc562c9bae25b1},
	abstract = {The goal of this study is to determine whether large language models (LLMs) like CodeLlama, Mistral, and Vicuna can be used to build knowledge graphs (KGs) from textual data. We create class descriptions for well-known KGs such as DBpedia, YAGO, and Google Knowledge Graph, from which we extract RDF triples and enhance these graphs using different preprocessing methods. Six structural quality measures are used in the study to compare the constructed and existing KGs. Our results demonstrate how important LLMs are to improving KG construction and provide insightful information for KG construction researchers. Moreover, an in-depth analysis of popular open-source LLM models enables researchers to identify the most efficient model for various tasks, ensuring optimal performance in specific applications. © 2024 IEEE.},
	keywords = {Dbpedia; Extended abstracts; Google+; Graph construction; Knowledge graphs; Language model; RDF triples; Robustness quantifications; Structural metrics; Textual data; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{2024,
	title = {HI-AI 2024 - Proceedings of the KDD Workshop on Human-Interpretable AI 2024, co-located with 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining, KDD 2024},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3841},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210869022&partnerID=40&md5=6bde3d13a771845bffd6dcb76dfe19a3},
	abstract = {The proceedings contain 12 papers. The topics discussed include: towards fast visual explanations of local path planning with LIME and GAN; using longitudinal data for plausible counterfactual explanations; generative models for counterfactual explanations; logically explainable malware detection; MASALA: model-agnostic surrogate explanations by locality adaptation; GLEAMS: bridging the gap between local and global explanations; from must to may: enabling test-time feature imputation and interventions; evaluating the reliability of Shapley value estimates: an interval-based approach; enhancing interpretability in multivariate time series classification through dimension and feature selection; sparse oblique decision trees: a tool to understand and manipulate neural net features; and ontology-grounded automatic knowledge graph construction by LLM under Wikidata schema.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Hu2024,
	author = {Hu, Mengzhou and Alkhairy, Sahar and Lee, Ingoo and Pillich, Rudolf T. and Fong, Dylan and Smith, Kevin and Bachelder, Robin and Ideker, Trey and Pratt, Dexter},
	title = {Evaluation of large language models for discovery of gene set function},
	year = {2024},
	journal = {Nature Methods},
	doi = {10.1038/s41592-024-02525-x},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210471684&doi=10.1038%2fs41592-024-02525-x&partnerID=40&md5=816f4d1888c37db18e5cbbb7ed322c64},
	abstract = {Gene set enrichment is a mainstay of functional genomics, but it relies on gene function databases that are incomplete. Here we evaluate five large language models (LLMs) for their ability to discover the common functions represented by a gene set, supported by molecular rationale and a self-confidence assessment. For curated gene sets from Gene Ontology, GPT-4 suggests functions similar to the curated name in 73% of cases, with higher self-confidence predicting higher similarity. Conversely, random gene sets correctly yield zero confidence in 87% of cases. Other LLMs (GPT-3.5, Gemini Pro, Mixtral Instruct and Llama2 70b) vary in function recovery but are falsely confident for random sets. In gene clusters from omics data, GPT-4 identifies common functions for 45% of cases, fewer than functional enrichment but with higher specificity and gene coverage. Manual review of supporting rationale and citations finds these functions are largely verifiable. These results position LLMs as valuable omics assistants. © The Author(s), under exclusive licence to Springer Nature America, Inc. 2024.; Large language models show potential in suggesting common functions for a gene set. © The Author(s), under exclusive licence to Springer Nature America, Inc. 2024..},
	keywords = {Computational Biology; Databases, Genetic; Gene Ontology; Genomics; Humans; bioinformatics; gene ontology; genetic database; genomics; human; procedures},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Song2024,
	author = {Song, Zelin and Xue, Tao and Li, Pinjie and Zhang, Ming and Zhang, Tao},
	title = {GuKang, a Reliable Dataset for Multi-source Chinese Orthopedic Rehabilitation},
	year = {2024},
	journal = {ICAC 2024 - 29th International Conference on Automation and Computing},
	doi = {10.1109/ICAC61394.2024.10718741},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208618777&doi=10.1109%2fICAC61394.2024.10718741&partnerID=40&md5=6748fcd41b355e32b90eb56d98b6711c},
	abstract = {The treatment of orthopaedic diseases commonly faces challenges such as prolonged hospital stays, a shortage of physician resources, and high medical costs. Large language models offer a novel solution for remote home rehabilitation by simulating doctor-patient interactions, report interpretations, professional diagnoses, and prescription issuances. The development of these consultative models relies heavily on special-ized knowledge datasets. To this end, our research team has constructed a medical consultation dataset named "GuKang"(GuKang Medical Consultation DataSet, GKMCD), which stands as the most comprehensive repository of orthopaedic rehabilitation medical consultation resources to date. It comprises four main components: a medical Q&A database, a medical knowledge base, knowledge graphs, and a medical knowledge question bank. The Q&A database contains 401,568 entries covering over 95% of orthopaedic diseases. Ensuring the accuracy and professionalism of our data involved thorough collection, cleaning, and filtering of information, as well as manual reviews and intelligent evaluations. Furthermore, the diversity of data sources not only provides the model with a wealth of learning resources but also enhances the model's adaptability and flexibility in addressing real-world problems. This study establishes new research directions and practical foundations for the application of large language models in specialized medical fields. © 2024 IEEE.},
	author_keywords = {Knowledge Base; Knowledge Graph; Medical Consultation; Orthopaedic Rehabilitation; Question Bank},
	keywords = {Disease control; Diseases; Orthopedics; Patient rehabilitation; Knowledge base; Knowledge graphs; Language model; Medical consultation; Medical knowledge; Multi-Sources; Novel solutions; Orthopedic disease; Orthopedic rehabilitation; Question banks; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Nasiri202459,
	author = {Nasiri, Yeganeh and Fulda, Nancy},
	title = {Designing a Language-Model-Based Chatbot that Considers User’s Personality Profile and Emotions To Support Caregivers of People With Dementia},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3818},
	pages = {59 – 70},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209689341&partnerID=40&md5=89cad04e359d8d2dbd9fc8e0997d1435},
	abstract = {Chatbots driven by Artificial Intelligence (AI) systems are gaining widespread traction in industry, research, and education; however, many chatbot architectures operate only in the generalized case, without a personalized understanding of the specific user and contextual situation involved. This becomes particularly problematic in the domain of emotional support, which requires both understanding emotions, and the ability to properly respond to those emotions by considering the needs of the user. This work presents a conversational agent that uses a probabilistic model to localize the user’s personality type on the popular Myers-Briggs Type Indicator (MBTI) self-report inventory and create customized responses for different personalities. Results from the personality classifier are injected into an associated Knowledge Graph and are considered during text generation in order to create more personalized responses, and emotion detection is used to identify and react to the user’s current emotional state. We apply this model in a hypothetical scenario supporting caregivers of people with dementia, and augment a response generator trained on a custom dataset of scraped conversations among such caregivers with a dynamic knowledge graph that stores user information extracted from the conversation. We explore the efficacy of this system in a user study with N=24 participants and show that the MBTI personality classification and emotion modules were both noticeable to users and improved the user’s sense that the AI system was getting to know them as a person. Long-term, we hope this research will help create chatbots that provide emotional support for persons in socially isolated situations, including caregivers of people with dementia. © 2024 Copyright for this paper by its authors.},
	author_keywords = {Chatbot; Knowledge graphs; Large language models; Personality classifier},
	keywords = {Emotion Recognition; Knowledge graph; Neurodegenerative diseases; Artificial intelligence systems; Chatbots; Emotional supports; Industry research; Knowledge graphs; Language model; Large language model; Model-based OPC; Myers-Briggs Type Indicators; Personality classifier; Chatbots},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Sun2024,
	author = {Sun, Tianda and Carr, Jamie and Kazakov, Dimitar},
	title = {A Hybrid Question Answering Model with Ontological Integration for Environmental Information},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3833},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211099694&partnerID=40&md5=6e9cddb1f471d558dd4b193383d41387},
	abstract = {This paper presents a novel approach to constructing a Question Answering model for analysing Nationally Determined Contributions (NDC) reports within the environmental sector. The approach is based on Large Language Models (LLMs) equipped with Retrieval Augmented Generation (RAG) and enhanced by ontology integration. Acknowledging the challenges inherent in directly applying RAG, our approach begins with the development of a specialised ontology framework for NDC reports. This framework supports the construction of a knowledge graph that provides essential, verifiable information for a Question Answering (QA) model. In the next step, the model combines RAG embeddings with ontology-based queries, aiming to enhance the reliability of answers across various NDC reports. We evaluate the performance of our hybrid model through testing with a set of questions and human/AI evaluation across different LLMs. While the results indicate improvements in the efficiency of climate change-related QA models, they also underscore the complexity of achieving significant enhancements in this domain. Our findings contribute to ongoing discussions about the potential and limitations of integrating ontological methods with LLM for environmental information retrieval. © 2024 Copyright for this paper by its authors.},
	author_keywords = {Knowledge Graph Construction; Relation Extraction; Retrieval Augmentation Generation},
	keywords = {Knowledge graph; Ontology; Environmental information; Environmental sector; Graph construction; Knowledge graph construction; Knowledge graphs; Language model; Ontology: Integration; Question Answering; Relation extraction; Retrieval augmentation generation; Question answering},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Chen2024,
	author = {Chen, Fuqiang and Jiang, Yan and Xu, Jie and Liu, Zheng and Sheng, Zhiqiang and Song, Xueying and Li, Bochu and Meng, Zibing},
	title = {A knowledge graph and large language model based approach to security measure},
	year = {2024},
	journal = {Proceedings of SPIE - The International Society for Optical Engineering},
	volume = {13403},
	doi = {10.1117/12.3051842},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210834584&doi=10.1117%2f12.3051842&partnerID=40&md5=54c192a1112879b18c5f20bd3a825947},
	abstract = {Power work ticket is an indispensable working document in the electric power industry, the current safety measures in the power work ticket are mainly filled out manually by the practitioners based on their experience, which lacks consistency and has the risk of omission, in order to reduce the dependence on the front-line practitioners, this paper proposes a model based on the knowledge graph and the large language model of the safety measures generation. Firstly, based on the knowledge graph of work tickets, similar work tickets are found and preliminary safety measures are generated according to the rules, and then relevant safety specifications are queried based on the semantic similarity, and the model inputs, preliminary safety measures, and relevant safety specifications are inputted into the large language model together to get the complete safety measures. From the experimental results, it can be seen that this method outperforms other models in terms of expert assessment and the accuracy of security measure generation, and the security measures generated by the model can meet the needs of invoicing, ensuring the accuracy and efficiency of filling out work tickets. © 2024 SPIE.},
	author_keywords = {Electricity work ticket; Knowledge graph; Large language model; Natural language processing; Security measure},
	keywords = {Electricity work ticket; Knowledge graphs; Language model; Language processing; Large language model; Natural language processing; Natural languages; Power; Safety measures; Security measure; Electric industry},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Kaverinskiy2024253,
	author = {Kaverinskiy, Vladislav and Palagin, Oleksandr and Litvin, Anna},
	title = {Development and Testing of a Large Language Models Prompt for Natural Language Phrases Synthesis from Ontological Semantic Structures},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3806},
	pages = {253 – 264},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209356688&partnerID=40&md5=9b710c00d303747e430b3cd53683b2e6},
	abstract = {The article introduces an innovative approach that leverages a specially designed structured prompt for Chat GPT, a large language model. This approach was tested through a series of experiments aimed at generating natural language phrases from their underlying ontological representations. These representations were automatically derived from sentences in scientific and technical texts using advanced software tools. They encapsulate the entities identified in the text and the semantic relationships between them, which can be expressed in the sentences of the analyzed text. In more detail, the system identifies relationships between concepts and links them to entities within a sentence. These entities can be either simple sentences or parts of complex ones. The structured prompt provided to the language model includes detailed explanations of these semantic relationships and a set of concept pairs connected by these relationships, serving as the building blocks for sentence creation. The generated sentences were then compared to the original ones using the cosine similarity measure across various vectorization methods. The similarity scores, calculated using the xx_ent_wiki_sm model, ranged from 0.8193 to 0.9722. Despite these high similarity scores, some stylistic differences were noted in the generated sentences. This research holds significant practical value for the development of dialogue systems that integrate ontological methods with advanced language models, paving the way for more accurate and contextually aware information systems. © 2024 Copyright for this paper by its authors.},
	author_keywords = {cosine similarity; large language model; natural language text analysis; natural language text synthesis; ontology; text vectorization},
	keywords = {Natural language processing systems; Ontology; Semantics; Software testing; Cosine similarity; Language model; Large language model; Natural language text analyze; Natural language text synthesis; Natural languages texts; Ontology's; Text analysis; Text vectorization; Vectorization; Latent semantic analysis},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{2024,
	title = {RuleML+RR-Companion 2024 - Companion Proceedings of the 8th International Joint Conference on Rules and Reasoning, co-located with 20th Reasoning Web Summer School, RW 2024 and 16th DecisionCAMP 2024 as part of Declarative AI 2024},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3816},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209395083&partnerID=40&md5=c7b259ed974b03d907c4e0fa7f8153e1},
	abstract = {The proceedings contain 30 papers. The topics discussed include: RuleMiner: an interactive web tool for rule-based data analysis; rule-aware datalog fact explanation using Group-SAT Solver; PolyCoP: a connection prover for (possibly) any logical language; query optimization of backward-chaining reasoning with learned heuristics; softening ontological reasoning with large language models; distributed component interoperation and execution for norm-based real-time compliance; explanatory dialogues with active learning for rule-based expertise; integrating symbolic knowledge and machine learning in healthcare; fair shifts by the rule: a rule-based compliance methodology for medical rosters; and towards optimizing ontology-based data federation: performance insights from experimental studies.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{2024,
	title = {Fifth International Conference on Control, Robotics, and Intelligent System, CCRIS 2024},
	year = {2024},
	journal = {Proceedings of SPIE - The International Society for Optical Engineering},
	volume = {13404},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208932699&partnerID=40&md5=2e6faad2d60cf3adc66e3339e53fd116},
	abstract = {The proceedings contain 39 papers. The topics discussed include: adaptive optimal output regulation: a parametric Lyapunov equation approach; evaluation on parameter-efficient continual instruction tuning of large language models; research on enhancing forecast accuracy of gold futures using LSTM neural networks across various time periods; FedGKD: personalized federated learning through grouping and distillation; the development of a question-answering system for learning article using natural language processing; KG-CQAM: knowledge graph and mind mapping-based complex question answering for large language models; and PCEM-SQL: enhancing text-to-SQL capabilities by large language models and prompt engineering with self-consistency and self-evaluation mechanism.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Haque2024,
	author = {Haque, Mohd Ariful and Kamal, Marufa and George, Roy and Gupta, Kishor Datta},
	title = {Utilizing structural metrics from knowledge graphs to enhance the robustness quantification of large language models},
	year = {2024},
	journal = {International Journal of Data Science and Analytics},
	doi = {10.1007/s41060-024-00643-5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211953282&doi=10.1007%2fs41060-024-00643-5&partnerID=40&md5=58d0f1a8d0e439638e4b17e6abaeaaff},
	abstract = {Knowledge graphs (KGs) play a critical role in organizing large stores of unstructured information into structured formats. This structured information is then accessible through SPARQL queries or graph libraries based on their structure. KGs enhance search, power AI systems, and facilitate knowledge discovery across domains. In this research, we explore the capabilities of different large language models (LLMs) like CodeLlama, Mistral, and Vicuna, which are recognized for text generation, in handling textual information tasks for constructing knowledge graphs with structured data. Utilizing these LLMs, we generate class descriptions for all the classes of well-known KGs like DBpedia, YAGO, and Google Knowledge Graph. Using these class descriptions, we have extracted RDF triples and used different preprocessing techniques for better refinement and extraction of the graph triples from the generated result. These extracted triples are used for the graph ontology creation. Highlighting the contribution of LLMs to structured graph formation, our study includes a comparison of the constructed KGs using the three LLMs with the existing Knowledge Graphs. Later, these KGs are evaluated using six structural quality metrics encompassing both class and property-related information crucial for KG formation. Our insights prove valuable for researchers exploring these domains, offering guidance on overcoming challenges and maximizing the potential of large language models in knowledge graph construction, text generation, and text extraction. © The Author(s), under exclusive licence to Springer Nature Switzerland AG 2024.},
	author_keywords = {CodeLlama; Knowledge graph; LLM; Mistral; Structural metrics; Vicuna},
	keywords = {Domain Knowledge; Structured Query Language; Codellama; Knowledge graphs; Language model; Large language model; Mistral; Robustness quantifications; Structural metrics; Structured information; Text generations; Vicuna; Knowledge graph},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Barthelmess2024,
	author = {Barthelmess, Paulo and Blais, Curtis L.},
	title = {Exploring Large Language Models for Scenario Generation in Support of C2SIM Autonomous Systems Ontology Extension Development},
	year = {2024},
	journal = {Simulation Innovation Workshop 2024, SIW 2024},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211637924&partnerID=40&md5=0d9c47332bd152f084c3b161bf4e9d74},
	abstract = {The C2SIM Autonomous Systems sub-group has embarked on an explorative study employing GPT-4, a Large Language Model (LLM), to facilitate scenario development foundational to extending ontologies. This paper outlines the initial findings of GPT-4's application in generating context-specific scenarios, highlighting both its utility and limitations. We detail the methods adopted for directing GPT-4's output, including 0-shot learning and prompt engineering, which serve as techniques for curating scenario content in line with C2SIM requirements. These methods offer a novel approach to not only summarizing existing knowledge in the literature but also in extracting embedded domain knowledge from the model, contributing to a dynamic, user-guided refinement process for scenarios. The insights from this investigation reveal the practical implications of deploying LLMs in scenario generation, thereby informing subsequent research trajectories focused on synthetic data contributions to ontology development. The paper concludes by mapping out potential avenues for future inquiry, tempered by lessons learned from the current application of LLMs in this domain. © Simulation Innovation Workshop 2024, SIW 2024.},
	author_keywords = {ASX; Autonomous Systems; C2SIM; GPT-4; Large Language Models; LLM; Ontology; Scenario Generation},
	keywords = {Computer simulation languages; Digital elevation model; Modeling languages; Ontology; ASX; Autonomous system; C2SIM; GPT-4; Language model; Large language model; Ontology's; Scenarios generation; Zero-shot learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Li2024157,
	author = {Li, Daifeng and Xu, Fan},
	title = {The Deep Integration of Knowledge Graphs and Large Language Models: Advancements, Challenges, and Future Directions},
	year = {2024},
	journal = {2024 IEEE 2nd International Conference on Sensors, Electronics and Computer Engineering, ICSECE 2024},
	pages = {157 – 162},
	doi = {10.1109/ICSECE61636.2024.10729340},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209656174&doi=10.1109%2fICSECE61636.2024.10729340&partnerID=40&md5=82718fb143e89463b3cc77630b7bf05f},
	abstract = {In recent years, large language models have emerged with amazing capabilities, but they also have limitations such as hallucinations and black boxes, while knowledge graphs have accurate knowledge and symbolic reasoning capabilities. Therefore, the integration of knowledge graph and large language model becomes necessary. The paper systematically conducts the recent research pertaining to the integration of knowledge graph with large language mode. By analyzing the methods and locations of their confluence, we propose a unifying framework that aims to facilitate comprehension and inspiration for fellow researchers in related fields. This framework not only consolidates existing knowledge but also enhances the translational potential of research by delineating innovative pathways for practical implementation.  © 2024 IEEE.},
	author_keywords = {deep integration; knowledge graphs; large language models; system review},
	keywords = {Black boxes; Deep integrations; Integration of knowledge; Knowledge graphs; Knowledge reasoning; Language model; Large language model; Reasoning capabilities; Symbolic reasoning; System review; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Wang2024,
	author = {Wang, FeiLong and Shi, Donghui and Aguilar, Jose and Cui, Xinyi},
	title = {A few-shot learning method based on knowledge graph in large language models},
	year = {2024},
	journal = {International Journal of Data Science and Analytics},
	doi = {10.1007/s41060-024-00699-3},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212425230&doi=10.1007%2fs41060-024-00699-3&partnerID=40&md5=0dfe60467188cbde598e64b4abe3d267},
	abstract = {The emergence of large language models has significantly transformed natural language processing and text generation. Fine-tuning these models for specific domains enables them to generate answers tailored to the unique requirements of those fields, such as in legal or medical domains. However, these models often perform poorly in few-shot scenarios. Herein, the challenges of data scarcity in fine-tuning large language models in low-sample scenarios were addressed by proposing three different KDGI (Knowledge-Driven Dialog Generation Instances) generation strategies, including entity-based KDGI generation, relation-based KDGI generation, and semantic-based multi-level KDGI generation. These strategies aimed to enhance few-shot datasets to address the issue of low fine-tuning metrics caused by insufficient data. Specifically, knowledge graphs were utilized to define the distinct KDGI generation strategies for enhancing few-shot data. Subsequently, these KDGI data were employed to fine-tune the large language model using the P-tuning v2 approach. Through multiple experiments, the effectiveness of the three KDGI generation strategies was validated using BLEU and ROUGE metrics, and the fine-tuning benefits of few-shot learning on large language models were confirmed. To further evaluate the effectiveness of KDGI, additional experiments were conducted, including LoRA-based fine-tuning in the medical domain and comparative studies leveraging Mask Language Model augmentation, back-translation, and noise injection methods. Consequently, the paper proposes a reference method for leveraging knowledge graphs in prompt data engineering, which shows potential in facilitating few-shot learning for fine-tuning large language models. © The Author(s), under exclusive licence to Springer Nature Switzerland AG 2024.},
	author_keywords = {Few-shot learning; Fine-tuning; Knowledge graph; Knowledge-driven dialog generation; Large language model},
	keywords = {Contrastive Learning; Natural language processing systems; Semantics; Translation (languages); Zero-shot learning; Dialogue generations; Few-shot learning; Fine tuning; Knowledge graphs; Knowledge-driven dialog generation; Language model; Large language model; Learning methods; Medical domains; Natural languages texts; Knowledge graph},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Amrani2024340,
	author = {Amrani, Mohamed Chakib and Hamouda Sidhoum, Abdellah and Mataoui, M’hamed and Baghdad Bey, Kadda},
	title = {Leveraging Large Language Models and Knowledge Graphs for Advanced Biomedical Question Answering Systems},
	year = {2024},
	journal = {Lecture Notes in Networks and Systems},
	volume = {1145 LNNS},
	pages = {340 – 349},
	doi = {10.1007/978-3-031-71848-9_31},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211810137&doi=10.1007%2f978-3-031-71848-9_31&partnerID=40&md5=d99b15c2a018f6bc4973f66091e3a8ad},
	abstract = {This study introduces a Knowledge Base Question Answering (KBQA) system augmented with Large Language Models (LLMs) to address the complexities of biomedical data exploration and knowledge extraction. The proposed system leverages LLMs to translate natural language questions into structured graph queries, tailored for Knowledge Graph (KG) databases. This enables medical professionals to efficiently explore stored data with no need to master any graph query language syntax. The responses retrieved are then processed through the LLMs, which rephrase and refine this information to generate human-like answers. We evaluated our system using the BioASQ benchmark dataset, employing different knowledge sources, namely, PrimeKG and Hetionet. For the LLMs, LLAMA2-70B and GPT-4 were used. Cypher, adapted for Neo4j databases, served as the graph query language for our experiments. Initial results show that our system obtains good performance in the case of List-type questions. The presented comparative experiments indicate that the success of our proposed approach depends significantly on the quality of both the KGs and the LLMs used for generating queries. This underscores the necessity for more comprehensive KGs covering a wider range of biomedical knowledge. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {Biomedical Data; Cypher Queries; Knowledge Graphs; Large Language Models; Question Answering},
	keywords = {Knowledge graph; Natural language processing systems; Query languages; Structured Query Language; Biomedical data; Biomedical question answering; Cipher query; Data exploration; Graph query language; Knowledge graphs; Language model; Large language model; Question Answering; Question answering systems; Question answering},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Govindharajan2024431,
	author = {Govindharajan, Hariharan and Vijayakumar, Senthilkumar},
	title = {A Framework for automated selective Fine-Tuning of Domain-Specific Large Language Models Using Graph-Based Retrieval Augmented Generation},
	year = {2024},
	journal = {2024 IEEE 15th Annual Ubiquitous Computing, Electronics and Mobile Communication Conference, UEMCON 2024},
	pages = {431 – 439},
	doi = {10.1109/UEMCON62879.2024.10754778},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212695933&doi=10.1109%2fUEMCON62879.2024.10754778&partnerID=40&md5=3286393728297847814df6bbade053d6},
	abstract = {Graph based retrieval augmented generation technique in Large Language Model (LLM) brings in major advantages by providing deep context to LLMs through relational knowledge graph for text generation, classification, question and answering use cases. However, maintaining vast data volume of domain specific data in a knowledge graph with complex relationships and querying from it every time a prompt is being posted to LLM, is a time consuming and expensive process. This paper presents a novel framework for selectively fine-tuning domain-specific large language models (LLMs) using a multi-stage Knowledge Graph (KG) based Retrieval Augmented Generation (RAG) pipeline and an Automated Incremental Fine-tuning System (AIFS). The proposed system aims to enhance the accuracy and relevance of LLM responses for text generation and Question Answering use cases by finetuning the LLM incrementally based on highly sought and highly relevant information in knowledge graph identified by leveraging page rank algorithm in KG. The framework comprises three major subsystems: Knowledge Graph Generation, Automated Incremental fine-tuning system (AIFS), and Domain Based Information Retrieval (DBIR). The effectiveness of the system is demonstrated through its ability to incrementally fine-tune LLMs based on selected highly relevant nodes within the KG, thereby improving the model's domain-specific knowledge, response accuracy by 90% and reduce cost by 71.8%. © 2024 IEEE.},
	author_keywords = {Artificial Intelligence(AI); Contextual Information Extraction &Retrieval Systems; Knowledge Graph(KG); Large Language Models(LLM); LLM Fine-tuning},
	keywords = {Content based retrieval; Domain Knowledge; Metadata; Modeling languages; Question answering; Search engines; Structured Query Language; Contextual information; Contextual information extraction &retrieval system; Fine tuning; Information extraction systems; Information-retrieval systems; Knowledge graphs; Language model; Large language model; Large language model fine-tuning; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Gu2024,
	author = {Gu, Shijia and Qi, Yujia},
	title = {Knowledge graph construction method for business process instructed by prompts},
	year = {2024},
	journal = {Proceedings of SPIE - The International Society for Optical Engineering},
	volume = {13395},
	doi = {10.1117/12.3049117},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210242730&doi=10.1117%2f12.3049117&partnerID=40&md5=8d6a8654006a8f342e0a0a25e03cfaf5},
	abstract = {The technology of generative general artificial intelligence not only revolutionizes machine intelligence but also plays a significant role in enterprise digitalization. Given that natural gas sales companies offer conventional human-centered services, cost and efficiency have emerged as a set of irreconcilable contradictions. The automated intelligent customer service model, based on the new generation of artificial intelligence technology, is like an open key to high-quality development. We propose a method to create a knowledge graph of customer service business processes by guiding a multi-modal large language model to generate the knowledge graph with prompt words. Based on the open-source multi-modal large language model, the general ability of the large model was applied to identify, analyze, and extract the business process table in the “Natural Gas Customer Standardized Service Business Process Guidebook” through customized task prompt design. Ultimately, we successfully constructed a business process knowledge graph, confirming the feasibility and effectiveness of this method. This method aims to optimize intelligent customer service by providing high-quality answers. The method enhances automation, intelligence, and standardization of customer service, which improves work efficiency and controls costs simultaneously. © 2024 SPIE.},
	author_keywords = {business process; downstream task; knowledge graph; Multi-modal large language model; prompt engineering},
	keywords = {Commerce; Gas industry; Modula (programming language); Problem oriented languages; Process control; Sales; Service industry; Business Process; Customer-service; Down-stream; Downstream task; High quality; Knowledge graphs; Language model; Multi-modal; Multi-modal large language model; Prompt engineering; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Liang2024870,
	author = {Liang, Xinxin and Wang, Zuoxu and Li, Mingrui and Yan, Zhijie},
	title = {A survey of LLM-augmented knowledge graph construction and application in complex product design},
	year = {2024},
	journal = {Procedia CIRP},
	volume = {128},
	pages = {870 – 875},
	doi = {10.1016/j.procir.2024.07.069},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208784617&doi=10.1016%2fj.procir.2024.07.069&partnerID=40&md5=1a8d8ed01d3382cf4f1d3f6ca729be15},
	abstract = {In the field of complex product design, deploying knowledge graphs (KGs) has become a promising trend due to its strength on exploiting and applying the large-scale, complex, and specialized domain knowledge. In recent years, large language models (LLMs) have also attracted much attention due to their outstanding performance in natural language understanding and generation. However, in the research of complex product design dominated by domain knowledge, few studies involve LLMS and KG at the same time. To fill this gap, we survey 42 articles published in the last four years, focusing on three key questions. The combination of LLM and KG in specific applications in complex product design is deeply discussed. The analysis reveals how these techniques facilitate data collection, design concept formation and design process optimization and proposes a technical framework combining LLM and KG for complex product design domain. In addition, we identify key challenges and propose directions for future research. As an explorative survey paper, this paper provides insightful ideas for implementing more specialized domain knowledge graph in complex product design field. © 2024 The Authors. Published by Elsevier B.V.},
	author_keywords = {Design: challenges & Innovation; Knowledge Graph; Large Language Model},
	keywords = {Complex products; Design challenges; Design innovations; Domain knowledge; Graph construction; Knowledge graphs; Language model; Large language model; Large-scales; Performance; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access}
}

@CONFERENCE{Hertling2024,
	author = {Hertling, Sven and Sack, Harald},
	title = {Towards Large Language Models Interacting with Knowledge Graphs Via Function Calling},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3853},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212704419&partnerID=40&md5=0f837f0ab24f9d2027035b1f583f7ebe},
	abstract = {This position paper introduces a new way for large language models (LLMs) to interact with Knowledge Graphs (KGs), especially for information extraction. Most relation extraction approaches focus on finding the corresponding textual spans for subject, relation, and object in a text but ignore the actual state of the KG and the schema defined therein. In this work, the function-calling possibility of LLMs is explored to search for already defined entities in the KG and add information in the form of triples to the KG. A huge improvement over previous techniques is that it can also deal with various large ontologies/KGs and that the added information fits to a provided KG on a schema and instance level. Further validation checks can be added to increase the quality of the extracted statements. A small playground is provided to analyze the effectiveness of the approach. © 2024 Copyright for this paper by its authors.},
	keywords = {Data mining; Information retrieval; Modeling languages; Knowledge graphs; Language model; Ontology's; Position papers; Relation extraction; Validation checks; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Cheng2024,
	author = {Cheng, Xiyao and Edara, Lakshmi Srinivas and Zhang, Yuanxun and Kejriwal, Mayank and Calyam, Prasad},
	title = {Influence Role Recognition and LLM-Based Scholar Recommendation in Academic Social Networks},
	year = {2024},
	journal = {2024 IEEE 11th International Conference on Data Science and Advanced Analytics, DSAA 2024},
	doi = {10.1109/DSAA61799.2024.10722780},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209391430&doi=10.1109%2fDSAA61799.2024.10722780&partnerID=40&md5=b127a24ac9d51f7a69196bb8f3512162},
	abstract = {Identifying scholars and their relevant publications in interdisciplinary collaborations within an academic social network (ASN) can help drive new scientific knowledge discovery. This involves a challenging and time-consuming process, which requires scholar's influence role recognition in a scholar team for a given research task. In this paper, we propose a novel 'ScholarInfluencer' recommendation system that: (a) uses a classification model combined with network analysis on a heterogeneous knowledge graph to recognize the scholar influencers within interdisciplinary teams of collaborators, and (b) features a large language model (LLM) to use influence role recognition results to support user queries to produce pertinent scholar and their publication recommendations. Our novel approach involves building a heterogeneous knowledge graph using diverse ASN datasets involving entities such as scholars, publications, research grants, and the relationship among these entities. We perform an evaluation of ScholarInfluencer using four widely-used ASN datasets (i.e., NSF, DBLP, Cora and CA-HepTh). Our experiment results show that our influence role recognition model outperforms the state-of-the-art models across the different datasets; especially in the case of the NSF dataset, our model outperforms by up to 13.6%. Further, we show how our recommendation model with role recognition outperforms the model without role recognition across the different datasets; especially in the case of the NSF dataset, our model outperforms by 7%. © 2024 IEEE.},
	author_keywords = {academic social network; heterogeneous knowledge graph; large language model; recommender system},
	keywords = {Economic and social effects; Recommender systems; Academic social network; Classification models; Heterogeneous Knowledge; Heterogeneous knowledge graph; Interdisciplinary collaborations; Knowledge graphs; Language model; Large language model; Model-based OPC; Scientific knowledge; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Lee20241,
	author = {Lee, Chanhee and Prahlad, Deeksha and Kim, Dongha and Kim, Hokeun},
	title = {Work-in-Progress: On-device Retrieval Augmented Generation with Knowledge Graphs for Personalized Large Language Models},
	year = {2024},
	journal = {Proceedings - 2024 International Conference on Embedded Software, EMSOFT 2024},
	pages = {1},
	doi = {10.1109/EMSOFT60242.2024.00006},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212308770&doi=10.1109%2fEMSOFT60242.2024.00006&partnerID=40&md5=c160722a5a5cbe40093f04a9098a7072},
	abstract = {On-device large language models (LLMs) have promising benefits, including personalization, enhanced user privacy, and offline operations. We present our work-in-progress approach to on-device LLMs leveraging retrieval augmented generation (RAG) based on personalized on-device knowledge graphs (KGs). We aim to enhance the personalized experience of LLMs while preserving privacy by keeping sensitive data locally.  © 2024 IEEE.},
	keywords = {Differential privacy; Knowledge graphs; Language model; Offline; Personalizations; User privacy; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Maldonado-Sifuentes20241401,
	author = {Maldonado-Sifuentes, Christian E. and Vargas-Santiago, Mariano and Solis-Gamboa, Samuel and Sidorov, Grigori and Lechuga-Gutierrez, Luis and González-Andrade, Francisco and del Carmen Heras-Sánchez, María},
	title = {Towards a Proto Artificial General Intelligence: The Role of Large Language Model Ontologies in its Development},
	year = {2024},
	journal = {Computacion y Sistemas},
	volume = {28},
	number = {3},
	pages = {1401 – 1415},
	doi = {10.13053/CyS-28-3-5200},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210772833&doi=10.13053%2fCyS-28-3-5200&partnerID=40&md5=9d08b2800f3cb8440fac2f3f2be08adb},
	abstract = {Proto Artificial General Intelligence (ProtoAGI) aims to create a versatile artificial intelligence system capable of autonomously performing diverse tasks. A foundational element of ProtoAGI is the Large Language Model (LLM) ontology, which plays a crucial role in organizing and retrieving information about different LLMs, enabling the selection of the most appropriate model for specific tasks. This ontology, the first of several designed to support ProtoAGI, addresses key challenges in managing and accessing information regarding LLM capabilities, performance, and task suitability. We present the methodology for constructing this ontology, covering data extraction, enrichment, and model recommendation using a generalized LLM API. The initial version of this ontology involved processing over a million tokens, underscoring the system’s complexity and the scale of information integrated. This ontology is designed for continuous updates, ensuring that ProtoAGI remains current with the latest advancements in LLMs. The ongoing development of this ontology marks a significant step in ProtoAGI’s evolution, following an initial proof-of-concept demonstrated during the 2024 eclipse, where the feasibility of integrating such a comprehensive LLM ontology into a general-purpose AI system was shown. By making this ontology accessible to the broader AI community, we aim to accelerate further advancements in AGI research and applications. © 2024 Instituto Politecnico Nacional. All rights reserved.},
	author_keywords = {Artificial general intelligence; hybrid intelligent systems; large language models; multi-agent systems; ontology},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Santini2024,
	author = {Santini, Cristian},
	title = {Combining language models for knowledge extraction from Italian TEI editions},
	year = {2024},
	journal = {Frontiers in Computer Science},
	volume = {6},
	doi = {10.3389/fcomp.2024.1472512},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209410230&doi=10.3389%2ffcomp.2024.1472512&partnerID=40&md5=286257feb0a7c80699f0a954c45e5fbc},
	abstract = {This study investigates the integration of language models for knowledge extraction (KE) from Italian TEI/XML encoded texts, focusing on Giacomo Leopardi's works. The objective is to create structured, machine-readable knowledge graphs (KGs) from unstructured texts for better exploration and linkage to external resources. The research introduces a methodology that combines large language models (LLMs) with traditional relation extraction (RE) algorithms to overcome the limitations of current models with Italian literary documents. The process adopts a multilingual LLM, that is, ChatGPT, to extract natural language triples from the text. These are then converted into RDF/XML format using the REBEL model, which maps natural language relations to Wikidata properties. A similarity-based filtering mechanism using SBERT is applied to keep semantic consistency. The final RDF graph integrates these filtered triples with document metadata, utilizing established ontologies and controlled vocabularies. The research uses a dataset of 41 TEI/XML files from a semi-diplomatic edition of Leopardi's letters as case study. The proposed KE pipeline significantly outperformed the baseline model, that is, mREBEL, with remarkable improvements in semantic accuracy and consistency. An ablation study demonstrated that combining LLMs with traditional RE models enhances the quality of KGs extracted from complex texts. The resulting KG had fewer, but semantically richer, relations, predominantly related to Leopardi's literary activities and health, highlighting the extracted knowledge's relevance to understanding his life and work. Copyright © 2024 Santini.},
	author_keywords = {entity linking; Giacomo Leopardi; knowledge extraction; large language models (LLMs); relation extraction; Semantic Web; TEI/XML; Wikidata},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@CONFERENCE{Huo202452,
	author = {Huo, Hongying and Fu, Zetong and Yu, Haochen and Yang, Shengguang and Tang, Gongbo},
	title = {Chinese Text Simplification Based on Large Language Models},
	year = {2024},
	journal = {Proceedings - 2024 International Conference on Computational Linguistics and Natural Language Processing, CLNLP 2024},
	pages = {52 – 56},
	doi = {10.1109/CLNLP64123.2024.00018},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211362659&doi=10.1109%2fCLNLP64123.2024.00018&partnerID=40&md5=ac4c720a5ca4f96acd438fbdf6a3688a},
	abstract = {Chinese is a complex language, creating a demand for text simplification in various contexts. Traditional text simplification models have primarily relied on pre-trained models. With the advancement of large language models (LLMs), researchers have begun leveraging their robust text comprehension and generation capabilities for text simplification tasks. However, these implementations are often simplistic, merely instructing the LLM to simplify text without addressing inherent challenges. One notable issue is the hallucination phenomenon where LLMs introduce inaccuracies, especially in fine-grained knowledge. This paper proposes an approach to interact with LLMs by embedding the text's underlying knowledge through carefully designed prompts. These prompts provide clearer guidance to the LLMs, thereby improving the quality of text simplification. In addition, LLMs may be further improved on specific tasks after instruction fine-tuning. Thus, we constructed a text simplification training dataset with semantic knowledge from Chinese Parataxis graph, and fine-tuned existing large models specifically for the text simplification task. Experimental results demonstrate that fine-tuning LLMs can significantly enhance the quality of text simplification. Finally, we provide the proposed methods as a service via a web interface and a browser extension. © 2024 IEEE.},
	author_keywords = {Chinese parataxis graph; Large Language Models; prompt engineering; text simplification},
	keywords = {Knowledge graph; Web browsers; Chinese parataxi graph; Chinese text; Fine tuning; Language model; Large language model; Prompt engineering; Simplification models; Text comprehensions; Text generations; Text simplification; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Hatem2024327,
	author = {Hatem, Shahenda and Khoriba, Ghada and Gad-Elrab, Mohamed H. and Elhelw, Mohamed},
	title = {Up to Date: Automatic Updating Knowledge Graphs Using LLMs},
	year = {2024},
	journal = {Procedia Computer Science},
	volume = {244},
	pages = {327 – 334},
	doi = {10.1016/j.procs.2024.10.206},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211224752&doi=10.1016%2fj.procs.2024.10.206&partnerID=40&md5=dea124469dc4de5ccf0b2ccf8c78197d},
	abstract = {Maintaining up-to-date knowledge graphs (KGs) is essential for enhancing the accuracy and relevance of artificial intelligence (AI) applications, especially with sensitive domains. Yet, major KGs are either manually maintained (e.g., Wikidata) or infrequently rebuilt (e.g., DBpedia & YAGO). Thus, they contain many outdated facts. The rise of Large Language Models (LLMs) reasoning and Augmented Retrieval Generation approaches (RAG) gives KGs an interface to other trusted sources. This paper introduces a methodology utilizing Large Language Models (LLMs) to validate and update KG facts automatically. In particular, we utilize LLM reasoning capabilities to determine potentially outdated facts. After that, we use RAG techniques to generate an accurate fix for the fact. Experimental results on several LLMs and real-world datasets demonstrate the ability of our approach to propose accurate fixes. In addition, our experiments highlight the efficacy of few-shot prompts over zero-shot prompts. © 2024 The Authors. Published by Elsevier B.V.},
	author_keywords = {Knowledge Graphs; Large Language Models; Retrieval augmented generation},
	keywords = {Domain Knowledge; Automatic updating; Dbpedia; Knowledge graphs; Language model; Large language model; Model reasonings; Real-world datasets; Reasoning capabilities; Retrieval augmented generation; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Ghafarollahi2024,
	author = {Ghafarollahi, Alireza and Buehler, Markus J.},
	title = {SciAgents: Automating Scientific Discovery Through Bioinspired Multi-Agent Intelligent Graph Reasoning},
	year = {2024},
	journal = {Advanced Materials},
	doi = {10.1002/adma.202413523},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212471317&doi=10.1002%2fadma.202413523&partnerID=40&md5=29992e89f43933617b6672fb56e44263},
	abstract = {A key challenge in artificial intelligence (AI) is the creation of systems capable of autonomously advancing scientific understanding by exploring novel domains, identifying complex patterns, and uncovering previously unseen connections in vast scientific data. In this work, SciAgents, an approach that leverages three core concepts is presented: (1) large-scale ontological knowledge graphs to organize and interconnect diverse scientific concepts, (2) a suite of large language models (LLMs) and data retrieval tools, and (3) multi-agent systems with in-situ learning capabilities. Applied to biologically inspired materials, SciAgents reveals hidden interdisciplinary relationships that were previously considered unrelated, achieving a scale, precision, and exploratory power that surpasses human research methods. The framework autonomously generates and refines research hypotheses, elucidating underlying mechanisms, design principles, and unexpected material properties. By integrating these capabilities in a modular fashion, the system yields material discoveries, critiques and improves existing hypotheses, retrieves up-to-date data about existing research, and highlights strengths and limitations. This is achieved by harnessing a “swarm of intelligence” similar to biological systems, providing new avenues for discovery. How this model accelerates the development of advanced materials by unlocking Nature's design principles, resulting in a new biocomposite with enhanced mechanical properties and improved sustainability through energy-efficient production is shown. © 2024 The Author(s). Advanced Materials published by Wiley-VCH GmbH.},
	author_keywords = {bio-inspired materials; biological design; knowledge graph; large language model; materials design; multi-agent system; natural language processing; scientific AI},
	keywords = {Bio-inspired materials; Biological design; Knowledge graphs; Language model; Language processing; Large language model; Materials design; Multiagent systems (MASs); Natural language processing; Natural languages; Scientific artificial intelligence; Knowledge graph},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{2024,
	title = {12th AAAI Conference on Human Computation and Crowdsourcing, HCOMP 2024},
	year = {2024},
	journal = {Proceedings of the AAAI Conference on Human Computation and Crowdsourcing, HCOMP},
	volume = {12},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208446927&partnerID=40&md5=6e159413661911a917a1c287626816c5},
	abstract = {The proceedings contain 18 papers. The special focus in this conference is on Human Computation and Crowdsourcing. The topics include: Atlas of AI Risks: Enhancing Public Understanding of AI Risks; toward Context-Aware Privacy Enhancing Technologies for Online Self-Disclosure; unveiling the Inter-Related Preferences of Crowdworkers: Implications for Personalized and Flexible Platform Design; estimating Contribution Quality in Online Deliberations Using a Large Language Model; investigating What Factors Influence Users’ Rating of Harmful Algorithmic Bias and Discrimination; Combining Human and AI Strengths in Object Counting under Information Asymmetry; Mix and Match: Characterizing Heterogeneous Human Behavior in AI-assisted Decision Making; Utility-Oriented Knowledge Graph Accuracy Estimation with Limited Annotations: A Case Study on DBpedia; Assessing Educational Quality: Comparative Analysis of Crowdsourced, Expert, and AI-Driven Rubric Applications; predicting and Understanding Human Action Decisions: Insights from Large Language Models and Cognitive Instance-Based Learning; User Profiling in Human-AI Design: An Empirical Case Study of Anchoring Bias, Individual Differences, and AI Attitudes; Responsible Crowdsourcing for Responsible Generative AI:Engaging Crowds in AI Auditing and Evaluation; PACE: Participatory AI for Community Engagement; Human Computation, Equitable and Innovative Future of Work AI Tools.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Haag2024,
	author = {Haag, Aaron and Argatu, Vlad and Lohse, Oliver},
	title = {Joint Embeddings for Graph Instruction Tuning},
	year = {2024},
	journal = {6th International Conference on Intelligent Computing in Data Sciences, ICDS 2024},
	doi = {10.1109/ICDS62089.2024.10756351},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211924970&doi=10.1109%2fICDS62089.2024.10756351&partnerID=40&md5=81b92d361ac758763378c442ddfc0e83},
	abstract = {Large Language Models (LLMs) have achieved impressive performance in text understanding and have become an essential tool for building smart assistants. Originally focusing on text, they have been enhanced with multimodal capabilities in recent works that successfully built visual instruction following assistants. As far as the graph modality goes, however, no such assistants have yet been developed. Graph structures are complex in that they represent relation between different features and are permutation invariant. Moreover, representing them in purely textual form does not always lead to good LLM performance even for finetuned models. As a result, there is a need to develop a new method to integrate graphs in LLMs for general graph understanding. This work explores the integration of the graph modality in LLM for general graph instruction following tasks. It aims at producing a deep learning model that enhances an underlying LLM with graph embeddings and trains it to understand them and to produce, given an instruction, an answer grounded in the graph representation. The approach performs significantly better than a graph to text approach and remains consistent even for larger graphs. © 2024 IEEE.},
	keywords = {Adversarial machine learning; Contrastive Learning; Deep learning; Graphic methods; Knowledge graph; Embeddings; General graph; Graph embeddings; Graph representation; Graph structures; Language model; Learning models; Modeling performance; Multi-modal; Performance; Graph embeddings},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@CONFERENCE{2024,
	title = {KaRS 2024 - Proceedings of the 6th Knowledge-Aware and Conversational Recommender Systems Workshop, co-located with 18th ACM Conference on Recommender Systems, RecSys2024},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3817},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209346783&partnerID=40&md5=1d399ec68556eeee9b7e9362771f667d},
	abstract = {The proceedings contain 8 papers. The topics discussed include: Sixth Knowledge-aware and Conversational Recommender Systems Workshop (KaRS 2024); the effect of semantic knowledge graph richness on embedding based recommender systems; empowering shilling attacks with Katz and exclusivity-based relatedness; using semantic-based adaptive relevance prediction to enhance entity recommendation for personal knowledge assistance; can we integrate items into models? knowledge editing to align LLMs with product catalogs; adapting sequential recommender models to content recommendation in chat data using non-item page-models; conversational recommender systems based on extracting implicit preferences with large language models; and a social robot as a meal-time companion for elderly people.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Li2024,
	author = {Li, Zhongqiu and Wu, Zhenhe and Li, Mengxiang and He, Zhongjiang and Fang, Ruiyu and Zhang, Jie and Zhao, Yu and Li, Yongxiang and Li, Zhoujun and Song, Shuangyong},
	title = {Scalable Database-Driven KGs can help Text-to-SQL},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3828},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210231219&partnerID=40&md5=dd6f7f07bf72e0afc5783acc7edbeb5e},
	abstract = {The text-to-SQL task aims to covert natural language questions into SQL queries. Large Language Models (LLMs) have demonstrated remarkable performance on this task, which relied on in-context learing or Supervised Fine-Tuning (SFT). However, the heterogeneity of database and the complexity of the knowledge acquisition process pose significant challenges in previous works. To address these, we propose a novel text-to-SQL framework that enhances the performance of LLMs through Knowledge Graphs (KGs). We construct the KGs based on schemas, which are structured representations of the relationships and attributes within the databases. Then, we utilize LLMs to extract descriptions and dependencies from historical queries, which are used to complete contextual knowledge in KGs. We leverage retrieval model to recall benefit nodes and edges from KGs and then employ LLMs to generate task-specific evidence. Based on the evidence and retrieved information, we define a unified KGs-based schema for LLMs to generate SQL queries. Our paper conducts experiments on public datasets BIRD and Spider, and the results indicate that our framework significantly improves the text-to-SQL performance. © 2024 Copyright for this paper by its authors.},
	author_keywords = {Knowledge Generation; Knowledge Graph; Large Language Models; Text-to-SQL},
	keywords = {Database systems; Knowledge acquisition; Knowledge graph; Graph-based; Help texts; Knowledge generations; Knowledge graphs; Language model; Large language model; Natural language questions; Performance; SQL query; Text-to-SQL; Structured Query Language},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Toma2024,
	author = {Toma, Ioan and Serles, Umutcan},
	title = {PERKS: Eliciting and Exploiting Procedural Knowledge in Industry 5.0},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3816},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209369008&partnerID=40&md5=6d2160102cf34e9b8070d06db4d89a11},
	abstract = {Procedural Knowledge (PK) is essential for industrial operations but often challenging to manage. The PERKS project addresses this by developing AI-based tools and methodologies to capture, manage, and deliver PK throughout its lifecycle. By focusing on human-centric solutions and testing in diverse industrial settings, PERKS aims to improve operational efficiency and worker performance while enabling knowledge transfer across industries. The PERKS results are applied and tested in three industrial scenarios (white goods production plant, computer numerical control machines, microgrid testbed) providing different use cases in terms of PK complexity and industrial requirements. © 2024 Copyright for this paper by its authors.},
	author_keywords = {Hybrid AI; Knowledge Graphs; LLMs; Procedural Knowledge},
	keywords = {Human-centric; Hybrid AI; Industrial operations; Industrial settings; Knowledge graphs; LLM; Operational efficiencies; Performance; Procedural knowledge; Workers'},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Diaz202417,
	author = {Diaz, Dany and Moreno-Vera, Felipe and Heredia, Juanpablo and Venturim, Fabricio and Poco, Jorge},
	title = {FishBiasLens: Integrating Large Language Models and Visual Analytics for Bias Detection},
	year = {2024},
	journal = {Proceedings - 2024 IEEE Visual Analytics Science and Technology VAST Challenge, Vast-Challenge 2024},
	pages = {17 – 18},
	doi = {10.1109/VASTChallenge64683.2024.00013},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212291938&doi=10.1109%2fVASTChallenge64683.2024.00013&partnerID=40&md5=dd321cff219dd639b530e768c6c3916b},
	abstract = {Identifying unreliable sources is crucial for preventing misinformation and making informed decisions. CatchNet, the Oceanus Knowledge Graph, contains biased perspectives that threaten its credibility. We use Large Language Models (LLMs) and interactive visualization systems to identify these biases. By analyzing police reports and using GPT-3.5 to extract information from articles, we establish the ground truth for our analysis. Our visual analytics system detects anomalies, revealing unreliable news sources such as The News Buoy and biased analysts such as Harvey Janus and Junior Shurdlu. © 2024 IEEE.},
	author_keywords = {Bias detection; GPT; Knowledge Graph; LLM; Visualization},
	keywords = {Economic and social effects; Knowledge graph; Modeling languages; Visual languages; Visualization; Bias detection; GPT; Informed decision; Interactive visualization systems; Knowledge graphs; Language model; Large language model; Model visualization; Police reports; Visual analytics; Visual analytics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Zhang2024177012,
	author = {Zhang, Ying and Shen, Yangpeng and Xiao, Gang and Peng, Jinghui},
	title = {Leveraging Non-Parametric Reasoning with Large Language Models for Enhanced Knowledge Graph Completion},
	year = {2024},
	journal = {IEEE Access},
	volume = {12},
	pages = {177012 – 177027},
	doi = {10.1109/ACCESS.2024.3505433},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210900991&doi=10.1109%2fACCESS.2024.3505433&partnerID=40&md5=2edb4bc74ef43b6a9290446ec9a6725e},
	abstract = {The completeness of knowledge graphs is critical to their effectiveness across various applications. However, existing knowledge graph completion methods face challenges such as difficulty in adapting to new entity information, parameter explosion, and limited generalization capability. To address these issues, this paper proposes a knowledge graph completion framework that integrates large language models with case-based reasoning (CBR-LLM). By combining non-parametric reasoning with the semantic understanding capabilities of large language models, the framework not only improves completion accuracy but also significantly enhances generalization under various data-missing scenarios. Experimental results demonstrate that CBR-LLM excels in handling complex reasoning tasks and large-scale data-missing scenarios, providing an efficient and scalable solution for knowledge graph completion.  © 2013 IEEE.},
	author_keywords = {Case-based reasoning; information entropy; knowledge graph completion; large language model},
	keywords = {Case based reasoning; Semantics; Application scenario; Casebased reasonings (CBR); Information entropy; Iterative enhancement; Knowledge graph completion; Knowledge graphs; Language model; Large language model; Modeling parameters; Nonparametrics; Knowledge graph},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Chen2024,
	author = {Chen, Long and Zhou, Yan and Wei, Qiang and Sun, Baoxin and Zhao, Ranran and Zhang, Chaolin and Wang, Xiaobing},
	title = {ELPGPT: Large Language Models Enhancing Link Prediction in Electrical Knowledge Graph},
	year = {2024},
	journal = {International Journal of High Speed Electronics and Systems},
	doi = {10.1142/S0129156425401159},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209066528&doi=10.1142%2fS0129156425401159&partnerID=40&md5=e8f6a80eb71241305946513b0aef0c34},
	abstract = {Graphs provide essential means for organizing and analyzing complex equipment data. Although link prediction techniques have been widely applied to enhance knowledge graphs, existing methods still show room for improvement in accuracy, especially when dealing with sparse data. To address this, we introduce ELPGPT (Large Language Models Enhancing Link Prediction in Electrical Equipment Knowledge Graph), a novel approach that integrates large language models into link prediction to enhance the accuracy of relation prediction within electrical equipment knowledge graphs. The core of the ELPGPT method lies in the combination of large language models with traditional knowledge graph link prediction techniques. By leveraging the deep semantic understanding capabilities of large language models, this method effectively extracts relational features and enhances the handling of sparse data. Additionally, we employ a Retrieval-Augmented Generation (RAG) approach, which, by integrating external data sources, further enhances the precision and relevance of predictions. Experiments on the Electrical Equipment Knowledge Graph (EEKG) demonstrate that ELPGPT significantly improves performance across several metrics, including Hit@k, Mean Rank (MR), and Mean Reciprocal Rank (MRR). These results validate the effectiveness and potential applications of this method in the domain of link prediction for electrical equipment knowledge graphs. © World Scientific Publishing Company.},
	author_keywords = {electrical equipment; knowledge graph; Link prediction; retrieval-augmented generation},
	keywords = {Data accuracy; Prediction models; Complex equipment; Electrical equipment; Knowledge graphs; Language model; Link prediction; Prediction techniques; Retrieval-augmented generation; Semantics understanding; Sparse data; Traditional knowledge; Knowledge graph},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Marchesin2024105,
	author = {Marchesin, Stefano and Silvello, Gianmaria and Alonso, Omar},
	title = {Utility-Oriented Knowledge Graph Accuracy Estimation with Limited Annotations: A Case Study on DBpedia},
	year = {2024},
	journal = {Proceedings of the AAAI Conference on Human Computation and Crowdsourcing, HCOMP},
	volume = {12},
	pages = {105 – 114},
	doi = {10.1609/hcomp.v12i1.31605},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208443980&doi=10.1609%2fhcomp.v12i1.31605&partnerID=40&md5=a74a00ec45fe93b71aabf6f8e75e8a81},
	abstract = {Knowledge Graphs (KGs) are essential for applications like search, recommendation, and virtual assistants, where their accuracy directly impacts effectiveness. However, due to their large-scale and ever-evolving nature, it is impractical to manually evaluate all KG contents. We propose a framework that employs sampling, estimation, and active learning to audit KG accuracy in a cost-effective manner. The framework prioritizes KG facts based on their utility to downstream tasks. We applied the framework to DBpedia and gathered annotations from both expert and layman annotators. We also explored the potential of Large Language Models (LLMs) as KG evaluators, showing that while they can perform comparably to low-quality human annotators, they tend to overestimate KG accuracy. As such, LLMs are currently insufficient to replace human crowdworkers in the evaluation process. The results also provide insights into the scalability of methods for auditing KGs. © 2024, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.},
	keywords = {Active learning; Accuracy estimation; Active Learning; Case-studies; Cost effective; Dbpedia; Knowledge graphs; Language model; Large-scales; Sampling estimation; Virtual assistants; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Bronze Open Access}
}

@ARTICLE{Zhou2024,
	author = {Zhou, Yan and Chen, Long and Wei, Qiang and Su, Yan and Qiao, Binrui and Guo, Ying and Geng, Wei},
	title = {Improving the Classification of Defect Levels in Main Electrical Equipment Through Advanced Prompting on a Large Language Model},
	year = {2024},
	journal = {International Journal of High Speed Electronics and Systems},
	doi = {10.1142/S0129156425401160},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209237092&doi=10.1142%2fS0129156425401160&partnerID=40&md5=f19a4bd2d6aba2287abf522d8a5573b3},
	abstract = {The stable operation of the power system is closely related to the national economy and people’s livelihoods. Therefore, the timely detection, qualitative assessment, and handling of major equipment defects are crucial. The classification of defect levels in main electrical equipment is a fundamental task in this process, which is often manually completed, supplemented by knowledge bases or expert systems. However, this approach is time-consuming, labor-intensive, involves challenging human–machine interaction, and relies on expert experience. Conversational large language models, such as ChatGPT, ERNIE Bot, ChatGLM, have garnered widespread recognition in various domains. However, these models may have errors in the reasoning process, resulting in biased or even erroneous outputs, which is referred to as the “hallucinations”. The hallucinations’ problem of large language models poses challenges in specific fields. To mitigate the hallucinations in large language models, researchers often seek to incorporate domain-specific knowledge into these models through methods like fine-tuning or prompt learning. In order to enhance model performance while minimizing computational costs, this study adopts the prompt learning approach. Specifically, we propose a large language model prompt learning framework based on knowledge graphs, aiming to provide the large language model with reasoning support by leveraging specific information stored within the knowledge graph and receive explainable reasoning result. Experimental results demonstrate that our module achieved superior results on the power defect dataset compared to the non-prompt method. © World Scientific Publishing Company.},
	author_keywords = {Classification of defect levels; knowledge graph; large language model; prompt engineering},
	keywords = {Knowledge graph; Modeling languages; Problem oriented languages; Classification of defect level; Classification of defects; Defect levels; Electrical equipment; Knowledge graphs; Language model; Large language model; Power; Prompt engineering; Stable operation; Expert systems},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Zhu2024262,
	author = {Zhu, Zhui and Qi, Guangpeng and Shang, Guangyong and He, Qingfeng and Zhang, Weichen and Li, Ningbo and Chen, Yunzhi and Hu, Lijun and Zhang, Wenqiang and Dang, Fan},
	title = {Enhancing Large Language Models with Knowledge Graphs for Robust Question Answering},
	year = {2024},
	journal = {Proceedings of the International Conference on Parallel and Distributed Systems - ICPADS},
	pages = {262 – 269},
	doi = {10.1109/ICPADS63350.2024.00042},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212492528&doi=10.1109%2fICPADS63350.2024.00042&partnerID=40&md5=4270eedef575882697fdb1552ef32907},
	abstract = {In recent years, large language models (LLMs) have shown rapid development, becoming one of the most popular topics in the field of artificial intelligence. LLMs have demonstrated powerful generalization and learning capabilities, and their performance on various language tasks has been remarkable. Despite their successes, LLMs face significant challenges, particularly in domain-specific tasks that require structured knowledge, often leading to issues such as hallucinations. To mitigate these challenges, we propose a novel system, SynaptiQA, which integrates LLMs with Knowledge Graphs (KGs) to answer more questions about knowledge. Our approach leverages the generative capabilities of LLMs to create and optimize KG queries, thereby improving the accuracy and contextual relevance of responses. Experimental results in an industrial data set demonstrate that SynaptiQA outperforms baseline models and naive retrieval-augmented generation (RAG) systems, demonstrating improved accuracy and reduced hallucinations. This integration of KGs with LLMs paves the way for more reliable and interpretable domain-specific question answering systems. © 2024 IEEE.},
	author_keywords = {Artificial Intelligence; Knowledge Graph; Large Language Model},
	keywords = {Knowledge graph; Structured Query Language; Domain specific; Generalization capability; Knowledge graphs; Language model; Large language model; Learning capabilities; Performance; Question Answering; Specific tasks; Structured knowledge; Question answering},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Kwan2024,
	author = {Kwan, Linda and Omran, Pouya G. and Taylor, Kerry},
	title = {Using Knowledge Graphs and Agentic LLMs for Factuality Text Assessment and Improvement},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3828},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210233104&partnerID=40&md5=a134f5024d6241cd6a8d147c8e785b17},
	abstract = {This paper addresses the challenge of assessing and enhancing the factual accuracy of texts generated by large language models (LLMs). Existing methods often rely on self-reflection or external knowledge sources, validating statements individually and rigidly, thus missing a holistic view. We propose a novel approach utilizing a comprehensive knowledge graph (KG), such as Wikidata, to assess and improve the factuality of generated texts. Our method dynamically retrieves and integrates relevant facts during the assessment process, providing a more interconnected and accurate evaluation. Integrating KG with LLM capabilities enhances the overall factual integrity, leading to more reliable AI-generated content. Our results demonstrate improvements in factual accuracy, highlighting the effectiveness of our approach. Submission type: Poster © 2024 Copyright for this paper by its authors.},
	author_keywords = {Agentic LLM; Knowledge Graph; Large Language Model; LLM Evaluation},
	keywords = {Agentic large language model; Assessment and improvement; Knowledge graphs; Language model; Large language model; Large language model evaluation; Model evaluation; Self reflection; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Dai2024292,
	author = {Dai, Yun and Lin, Ziyan and Liu, Ang},
	title = {Facilitating Students' Adaptive Help-seeking and Peer Interactions through an Analytics-enhanced Forum in Engineering Design Education},
	year = {2024},
	journal = {Procedia CIRP},
	volume = {128},
	pages = {292 – 297},
	doi = {10.1016/j.procir.2024.06.024},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208785034&doi=10.1016%2fj.procir.2024.06.024&partnerID=40&md5=cff388df496ce39f0f8c63aa37eb6d71},
	abstract = {Design often takes place in collective and collaborative settings, and interactions and mutual support among peers have been a critical component of design education. However, in most of the existing design courses, students often work in small groups and peer interactions are limited to group members, which limits the range and depth of knowledge exchange. To complement the group-based activities, this study designs and assesses an analytics-enhanced discussion forum for whole-class interactions. The forum adopts ontology-based recommender systems and anomaly detection techniques to tailor the threads and contents for individual students in a personalized way. This analytics-enhanced forum was implemented in a large-size undergraduate design course (n = 313), and data about student responses to this forum was compared with data from the previous year's course that adopted a conventional forum (n = 280). From the statistical analysis, students learning with the analytics-enhanced forum demonstrated significantly higher degrees of design practices (specifically, empathize, define, ideate, and test), collaborative learning, and course satisfaction. Qualitative analysis of students' focus-group interviews shows their perceived benefits and concerns of the analytics-enhanced forum. The study also suggests integrating generative artificial intelligence and large language models to support students' design thinking and collaborative design. © 2024 Elsevier B.V.. All rights reserved.},
	author_keywords = {design thinking; engineering education; help-seeking; learning analytics; peer support},
	keywords = {Adversarial machine learning; Contrastive Learning; Collaborative interaction; Collaborative settings; Critical component; Design course; Design thinking; Engineering design education; Help seeking; Learning analytic; Peer interactions; Peer support; Collaborative learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Zhang20242443,
	author = {Zhang, Yuan and Fu, Lin and Guo, Xingyu and Li, Mengkun},
	title = {Dynamic Insights: Unraveling Public Demand Evolution in Health Emergencies Through Integrated Language Models and Spatial-Temporal Analysis},
	year = {2024},
	journal = {Risk Management and Healthcare Policy},
	volume = {17},
	pages = {2443 – 2455},
	doi = {10.2147/RMHP.S472247},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208142632&doi=10.2147%2fRMHP.S472247&partnerID=40&md5=47cb42715627ba591dcea5c583569773},
	abstract = {Background and Purpose: In public health emergencies, rapid perception and analysis of public demands are essential prerequisites for effective crisis communication. Public demands serve as the most instinctive response to the current state of a public health crisis. Therefore, the government must promptly grasp and leverage public demands information to enhance the effectiveness and efficiency of health emergency management, that is planned to better deal with the outbreak and meet the medical demands of the public. Methods: This study employs dynamic topic mining and knowledge graph construction to analyze public demands, presenting a spatial-temporal evolution analysis method for emergencies based on EBU models. EBU models are three large language models, including ERNIE, BERTopic, and UIE. Results: The data analysis of Shanghai’s city closure and control during the COVID-19 epidemic has verified that this method can simplify the labeling and training process, and can use massive social media data to quickly, comprehensively, and accurately analyze public demands from both time and space dimensions. From the visual analysis, geographic information on public demands can be quickly obtained and areas with serious problems can be located. The classification of geographical information can help guide the formulation and implementation of government policies at different levels, and provide a basis for health emergency material dispatch. Conclusion: This study extends the scope and depth of research on health emergency management, enriching subject categories and research methods in the context of public health emergencies. The use of social media data underscores its potential as a valuable tool for analyzing public demands. The method can provide rapid decision supports for decision-making for public services such as government departments, centers for disease control, medical emergency centers and transport authorities. © 2024 Zhang et al.},
	author_keywords = {dynamic topic mining; health emergency management; public demands; public health emergencies; spatial-temporal evolution},
	keywords = {algorithm; Article; coronavirus disease 2019; data clustering; data visualization; decision making; decision support system; disease control; emergency health service; emergency management; geographic information system; governmental organization; health care delivery; language model; machine learning; social media; spatiotemporal analysis; training},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Lan20241157,
	author = {Lan, Mingjing and Xia, Yi and Zhou, Gang and Huang, Ningbo and Li, Zhufeng and Wu, Hao},
	title = {LLM4QA: Leveraging Large Language Model for Efficient Knowledge Graph Reasoning with SPARQL Query},
	year = {2024},
	journal = {Journal of Advances in Information Technology},
	volume = {15},
	number = {10},
	pages = {1157 – 1162},
	doi = {10.12720/jait.15.10.1157-1162},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208203144&doi=10.12720%2fjait.15.10.1157-1162&partnerID=40&md5=7ac7cd17d1e8c71864f18a8799a45c8e},
	abstract = {As one of the core technologies of general artificial intelligence, knowledge graph reasoning aims to infer new knowledge from existing knowledge in the knowledge base, providing decision support for knowledge-driven intelligent information services such as information retrieval, question answering, and recommendation systems. However, there are still some issues, such as poor interpretability and low reasoning efficiency, always decrease the current knowledge reasoning performance. To tackle the challenges, this paper proposes a knowledge graph reasoning method LLM4QA, which leverages fine-tuned large language models with chain-of-thought to generate graph query languages SPARQL (i.e., SPARQL Protocol and RDF Query Language) for reasoning. Firstly, an efficient instruction fine-tuning method is applied to fine-tune open-source large language models with chain-of-thought. Then, the fine-tuned open-source large model is used to convert natural language questions into logical forms. Finally, we utilize unsupervised entity relationship retrieval to generate graph database query languages, real-izing a natural language knowledge graph question-answering framework. Experimental results demonstrate that this method achieves well performance in terms of inference accuracy and significantly improves model retrieval efficiency. © 2024 by the authors.},
	author_keywords = {chain of thought; knowledge graph; Large Language Model (LLM); question answering system},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@CONFERENCE{Momcilovic2024121,
	author = {Momcilovic, Tomas Bueno and Buesser, Beat and Zizzo, Giulio and Purcell, Mark and Balta, Dian},
	title = {Towards Assurance of LLM Adversarial Robustness using Ontology-Driven Argumentation},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3793},
	pages = {121 – 128},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208283226&partnerID=40&md5=2be6d1e85223a03b9147402cf6dfd07f},
	abstract = {Despite the impressive adaptability of large language models (LLMs), challenges remain in ensuring their security, transparency, and interpretability. Given their susceptibility to adversarial attacks, LLMs need to be defended with an evolving combination of adversarial training and guardrails. However, managing the implicit and heterogeneous knowledge for continuously assuring robustness is difficult. We introduce a novel approach for assurance of the adversarial robustness of LLMs based on formal argumentation. Using ontologies for formalization, we structure state-of-the-art attacks and defenses, facilitating the creation of a human-readable assurance case, and a machine-readable representation. We demonstrate its application with examples in English language and code translation tasks, and provide implications for theory and practice, by targeting engineers, data scientists, users, and auditors. © 2024 Copyright for this paper by its authors.},
	author_keywords = {adversarial robustness; argumentation; assurance; LLM; ontologies},
	keywords = {Generative adversarial networks; Guard rails; Ontology; Translation (languages); Adversarial robustness; Argumentation; Assurance; Heterogeneous Knowledge; Implicit knowledge; Interpretability; Language model; Large language model; Model-based OPC; Ontology's; Adversarial machine learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Fan2024,
	author = {Fan, Yi and Sun, Yu and Mi, Baigang},
	title = {FLIGHT CONTROL SYSTEM KNOWLEDGE GRAPH CONSTRUCTION BASED ON AERONAUTICAL DOMAIN KNOWLEDGE AUGMENTED LARGE LANGUAGE MODEL},
	year = {2024},
	journal = {ICAS Proceedings},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208787293&partnerID=40&md5=b8d0e22d4fc368b6768afd0a6d270dbb},
	abstract = {In the complex competitive aerospace environment, the continuous intelligent assurance of the Flight Control System (FCS) is essential for the successful execution of aerospace missions. Monitoring and maintaining the FCS under dynamic and complex conditions rely heavily on empirical expert knowledge. Domain Knowledge Graphs (KG) serve as an efficient mechanism for FCS status management within expert systems, enabling effective value extraction. This paper outlines the construction of an FCS KG through large language model (LLM) fine-tuning, enriched with aeronautical domain knowledge derived from multi-source heterogeneous FCS texts. The process begins with the creation of an FCS ontology, integrating aeronautical domain knowledge and defining entity-relationship types. Subsequently, the Llama3-8B LLM was fine-tuned using methods such as LoRA, QLoRA, and AdaLoRA for parameter-efficient tuning, and prior aeronautical knowledge was incorporated via a chain of thought (COT) prompt template to facilitate intelligent discovery from a common FCS dataset. Experimental results indicate that the aeronautical domain knowledgeaugmented LLM method achieved an F1 score of 97.86%, representing a 6.48% improvement over traditional methods. Finally, the FCS KG was visualized using the graph database Neo4j, demonstrating the effectiveness and superiority of this approach in constructing FCS KG. © 2024, International Council of the Aeronautical Sciences. All rights reserved.},
	author_keywords = {Flight control system (FCS), Knowledge graph (KG); knowledge discovery (KD); Large language model (LLM); Parameter-efficient fine-tuning (PEFT)},
	keywords = {Domain knowledge; Fine tuning; Flight control system , knowledge graph; Flight-control systems; Knowledge discovery; Knowledge graphs; Language model; Large language model; Parameter-efficient fine-tuning; System knowledge; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Hu2024326,
	author = {Hu, Xuejun and Li, Jie and Zheng, Hangbin and Zhang, Gaohua},
	title = {Intelligent Sorting Method for Smartphones Based on Agents},
	year = {2024},
	journal = {2024 6th International Conference on Robotics and Computer Vision, ICRCV 2024},
	pages = {326 – 332},
	doi = {10.1109/ICRCV62709.2024.10758583},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212262933&doi=10.1109%2fICRCV62709.2024.10758583&partnerID=40&md5=c0c612de14bd04b574888ed3ed3e8e4f},
	abstract = {Automated disassembly of discarded smartphones is a critical step in electronic waste processing, yet existing automated systems often lack adaptability when handling various types of discarded smartphones. To address the issue of poor adaptability in sorting processes, this study proposes an agent-based sorting method for discarded smartphones. This method leverages large language model(LLM) for natural language understanding and generation, enhancing user-friendliness. It integrates information from knowledge graphs and historical sorting records to build a comprehensive knowledge base. By combining intelligent agents that track historical data and utilize external knowledge bases, the proposed method improves adaptability for sorting multiple phone types. This allows the system to dynamically formulate sorting strategies based on the specific characteristics of discarded smartphones, significantly enhancing the adaptability of disassembly lines. Furthermore, the mobile phone classification module draws inspiration from facial recognition model architectures. A deep learning-based classification method for discarded smartphones is proposed, achieving highly adaptable classification functionality for various phone types. Experimental results demonstrate that the proposed classification algorithm maintains high accuracy in recognizing phone models not included in the training set. © 2024 IEEE.},
	author_keywords = {Agent; Automated disassembly; End-of-life management; Image classification; LLM},
	keywords = {Chatbots; Deep learning; Electronic Waste; Knowledge graph; Automated disassembly; Critical steps; Electronics wastes; End of life managements; End-of-life managements; Images classification; Language model; Large language model; Smart phones; Sorting method; Smartphones},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{2024,
	title = {SEPLN-P 2024 - Poster Proceedings of the 40th Annual Conference of the Spanish Association for Natural Language Processing 2024, co-located with the 40th International Conference of the Spanish Society for Natural Language Processing, SEPLN 2024},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3846},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211943049&partnerID=40&md5=c32c2e859b8cdf5afd99fbeca5aef2f1},
	abstract = {The proceedings contain 17 papers. The topics discussed include: on the relationship of social gender equality and grammatical gender in pre-trained large language models; the difficulty of misinformation labelling: a case study for radon gas-related searches; findings of a machine translation shared task focused on Covid-19 related documents; COCOTEROS: a Spanish corpus with contextual knowledge for natural language generation; emotions and news structure: an analysis of the language of fake news in Spanish; towards multi-class smishing detection: a novel feature vector approach and the Smishing-4C Dataset; synthetic annotated data for named entity recognition in computed tomography scan reports; Spanish FatPhoCorpus 2023: combating fatphobia in social media in Spanish using transformers; Spanish-language platform for drug-disease evidence search based on scientific articles; and automatic pathology detection in Spanish clinical notes combining language models and medical ontologies.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Aasman2024,
	author = {Aasman, Jans},
	title = {Knowledge Graph-Driven Neuro-Symbolic System for Intelligent Document Matching},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3828},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210261010&partnerID=40&md5=d1e5fde5d9ad8636ca163c7c94267c5d},
	abstract = {This paper presents a novel Neuro-Symbolic framework for intelligent document matching that integrates Knowledge Graphs with Large Language Models (LLMs) to address challenges in various domains, including healthcare, aircraft maintenance, and legal documentation. Traditional methods relying solely on taxonomies face limitations due to diverse document authorship and the complexity of semantic searches. The proposed approach leverages the reasoning capabilities of Knowledge Graphs, the semantic richness of taxonomies, and the adaptive retrieval strengths of LLMs. This combination enhances precision, reduces costs, and facilitates the automated matching of documents by efficiently managing embeddings within a vector database. The framework demonstrates significant improvements in data management and insight generation, with potential applications across multiple industries. © 2024 Copyright for this paper by its authors.},
	author_keywords = {Knowledge Graph; LLM; Neuro-Symbolic AI; UMLS},
	keywords = {Graph neural networks; Information management; Modeling languages; Semantics; Taxonomies; Aircraft maintenance; Document matching; Intelligent documents; Knowledge graphs; Language model; Large language model; Legal documentation; Neuro-symbolic AI; Neuro-symbolic system; UMLS; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Duan2024,
	author = {Duan, Runlin and Karthik, Nachiketh and Shi, Jingyu and Jain, Rahul and Yang, Maria C. and Ramani, Karthik},
	title = {CONCEPTVIS: GENERATING AND EXPLORING DESIGN CONCEPTS FOR EARLY-STAGE IDEATION USING LARGE LANGUAGE MODEL},
	year = {2024},
	journal = {Proceedings of the ASME Design Engineering Technical Conference},
	volume = {3B-2024},
	doi = {10.1115/DETC2024-146409},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210097393&doi=10.1115%2fDETC2024-146409&partnerID=40&md5=fa2863a5c060b7832e4cd894aec237d0},
	abstract = {Large language models (LLMs) are capable of generating cross-domain design knowledge, opening up new possibilities for creating a myriad of design concepts for early-stage design ideation. The current interfaces and interaction capabilities of LLMs, however, pose challenges in controlling the ideation process in terms of its diversity and quality. To enhance human guidance over the LLM-driven ideation process, we have developed ConceptVis, a system that organizes and symbiotically coordinates the LLM-generated design space through an interactive knowledge graph. In ConceptVis, designers can easily control the breadth and depth of the design space by intuitively prompting the LLM from the graph nodes. Natural Language Processing (NLP) algorithms extract concept keywords and related design knowledge from LLM responses, which are then added to the knowledge graph for visualization. We conducted a user study with 24 novice designers and compared the performance of ConceptVis with that of a chat-based LLM interface for concept generation. With ConceptVis, designers can explore the design space with a balance of breadth and depth. This approach prevents them from merely prompting the LLM to generate random concepts, struggling to keep track of what has been generated in long linear lists, or fixating on early ideas. Supporting users to interact with LLMs through an interactive visual interface significantly improves both the efficiency and quality of concept generation. This result highlights the importance of developing user-centered design systems to facilitate human-LLM collaboration during the early stages of design. Copyright © 2024 by ASME.},
	author_keywords = {Collaborative Design; Design Visualization; Generative Design},
	keywords = {Design for manufacturability; Graphical user interfaces; Human engineering; Integrated circuit design; User centered design; Visual languages; Visualization; Collaborative design; Concept generation; Cross-domain; Design concept; Design knowledge; Design spaces; Design visualization; Generative design; Knowledge graphs; Language model; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Buchmuller20249,
	author = {Buchmuller, Raphael and Furst, Daniel and Frings, Alexander and Schlegel, Udo and Keim, Daniel},
	title = {Visual Bias Detection for Addressing Illegal Fishing Activities},
	year = {2024},
	journal = {Proceedings - 2024 IEEE Visual Analytics Science and Technology VAST Challenge, Vast-Challenge 2024},
	pages = {9 – 10},
	doi = {10.1109/VASTChallenge64683.2024.00009},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212302884&doi=10.1109%2fVASTChallenge64683.2024.00009&partnerID=40&md5=54cf3d0f750107cd9403c748614d103c},
	abstract = {In this work, we present a visual analytics approach designed to address the 2024 VAST Challenge Mini-Challenge 1, which focuses on detecting bias in a knowledge graph. Our solution utilizes pixel-based visualizations to explore patterns within the knowledge graph, CatchNet, which is employed to identify potential illegal fishing activities. CatchNet is constructed by FishEye analysts who aggregate open-source data, including news articles and public reports. They have recently begun incorporating knowledge extracted from these sources using advanced language models. Our method combines pixel-based visualizations with ordering techniques and sentiment analysis to uncover hidden patterns in both the news articles and the knowledge graph. Notably, our analysis reveals that news articles covering critiques and convictions of companies are subject to elevated levels of bias. © 2024 IEEE.},
	author_keywords = {LLM; Mini-Challenge 1; Pixel Visualization; VAST Challenge; Visual Analytics},
	keywords = {Crime; Fisheries; Pixels; Sentiment analysis; Visualization; Analytic approach; Fish-eye; Fishing activities; Knowledge graphs; LLM; Mini-challenge 1; News articles; Pixel visualization; VAST challenge; Visual analytics; Visual analytics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Kondo2024,
	author = {Kondo, Ryoma and Watanabe, Tomohiro and Yoshida, Takahiro and Yamasawa, Kazuyuki and Hisano, Ryohei},
	title = {Collaborative System Synergizing Human Expertise and Large-scale Language Models for Legal Knowledge Graph Construction},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3828},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210257570&partnerID=40&md5=d29fbf341f952385411b05d9839047f0},
	abstract = {Court judgments are rich with information that details the combination of facts and legal norms to arrive at judicial decisions. This intricate process can be conceptualized as a hierarchical tree structure, wherein facts are aggregated in a bottom-up manner to highlight pivotal facts. These critical facts are subsequently linked to legal norms, facilitating the derivation of specific decisions. Despite the intrinsic value of this information, there is no legal knowledge graph(KG) that can represent this, and even if there were, the task of text-mining or text-annotation of such legal structures from court judgments presents considerable challenges. We show a legal ontology that links facts and norms and a new collaborative framework that harnesses the capabilities of both LLMs and legal experts for extracting these intricate relationships. Our approach is underpinned by a carefully designed LLM, tailored through prompt engineering, that can capture such structures. The results from this are then refined by legal experts through a graphic user interface, also providing us with an overall score of the annotation. We believe that a synergistic integration of machine efficiency and human expertise will lead to the improvement of future legal KGs and legal search engines. © 2024 Copyright for this paper by its authors.},
	author_keywords = {annotation tools; artificial intelligence and law; court judgments; large-scale language models; legal knowledge graph; Semantic web},
	keywords = {Semantics; Trees (mathematics); Annotation tool; Artificial intelligence and laws; Court judgement; Knowledge graphs; Language model; Large-scale language model; Large-scales; Legal knowledge; Legal knowledge graph; Semantic-Web; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{2024,
	title = {KBC-LM-LM-KBC 2024 - Joint Proceedings of the 2nd Workshop on Knowledge Base Construction from Pre-Trained Language Models and the 3rd Challenge on Language Models for Knowledge Base Construction, co-located with the 23nd International Semantic Web Conference, ISWC 2024},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3853},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212674154&partnerID=40&md5=f6e6e461a5f87fb9df6a460a10e2ac8a},
	abstract = {The proceedings contain 14 papers. The topics discussed include: enriching ontologies with disjointness axioms using large language models; ontology learning for ESCO: leveraging LLMs to navigate labor dynamics; ontology-guided on-device conversational knowledge capture with large language models; the effects of hallucinations in synthetic training data for relation extraction; analyzing Llama 3-based approach for axiom translation from ontologies; LLM store: leveraging large language models as sources of Wikidata-structured knowledge; towards large language models interacting with knowledge graphs via function calling; automatic knowledge-graph creation from historical documents: the Chilean dictatorship as a case study; and HybridContextQA: a hybrid approach for complex question answering using knowledge graph construction and context retrieval with LLMs.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Al Khatib2024,
	author = {Al Khatib, Hassan S. and Neupane, Subash and Kumar Manchukonda, Harish and Golilarz, Noorbakhsh Amiri and Mittal, Sudip and Amirlatifi, Amin and Rahimi, Shahram},
	title = {Patient-centric knowledge graphs: a survey of current methods, challenges, and applications},
	year = {2024},
	journal = {Frontiers in Artificial Intelligence},
	volume = {7},
	doi = {10.3389/frai.2024.1388479},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208957427&doi=10.3389%2ffrai.2024.1388479&partnerID=40&md5=ad5069dcdf6825f741cf50f628b4844c},
	abstract = {Patient-Centric Knowledge Graphs (PCKGs) represent an important shift in healthcare that focuses on individualized patient care by mapping the patient’s health information holistically and multi-dimensionally. PCKGs integrate various types of health data to provide healthcare professionals with a comprehensive understanding of a patient’s health, enabling more personalized and effective care. This literature review explores the methodologies, challenges, and opportunities associated with PCKGs, focusing on their role in integrating disparate healthcare data and enhancing patient care through a unified health perspective. In addition, this review also discusses the complexities of PCKG development, including ontology design, data integration techniques, knowledge extraction, and structured representation of knowledge. It highlights advanced techniques such as reasoning, semantic search, and inference mechanisms essential in constructing and evaluating PCKGs for actionable healthcare insights. We further explore the practical applications of PCKGs in personalized medicine, emphasizing their significance in improving disease prediction and formulating effective treatment plans. Overall, this review provides a foundational perspective on the current state-of-the-art and best practices of PCKGs, guiding future research and applications in this dynamic field. Copyright © 2024 Al Khatib, Neupane, Kumar Manchukonda, Golilarz, Mittal, Amirlatifi and Rahimi.},
	author_keywords = {generative AI; knowledge graph; natural language processing; patient-centric; personalized healthcare},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Massafra2024685,
	author = {Massafra, Angelo and Coraglia, Ugo Maria and Predari, Giorgia and Gulli, Riccardo},
	title = {Building Information Model Analysis Through Large Language Models and Knowledge Graphs},
	year = {2024},
	journal = {Proceedings of the International Conference on Education and Research in Computer Aided Architectural Design in Europe},
	volume = {1},
	pages = {685 – 694},
	doi = {10.52842/conf.ecaade.2024.1.685},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209786049&doi=10.52842%2fconf.ecaade.2024.1.685&partnerID=40&md5=a38af2630a327bac8963f7d09fadb905},
	abstract = {The advent of Large Language Models (LLMs) seems to mark a break between past and present in the methods of structuring knowledge, making it possible today to transfer this capability to machines e^ve^n in a sector like AECO，always been information-intensive but resistant to technological transition. In terms of knowledge, the most established paradigm has been BuildinglnformationModelling (BIM), with IFC functioning as the main schema for standardizing the industry’s information.Ädded to this are knowledge graphs that, emerging with semantic web technologies, allow storing knowledge in structures consisting of nodes and edges with semantic meanings· Nevertheless, a barrier to the widespread adoption of BIM is its accessibility. Querying BIM models is often Umitedfor stakeholders without digital skills, who ^ay struggle to access the vast amount of information stored in these complex informative models. In an attempt to outhne one of thepossible uses of LLMs in BIM’ this research proposes a methodfor querying BIM models through textual prompts aimed at anafyzing a selected case study. In the workflow, a BIM model isfirst realized. Then, data is integrated into a knowledge graph. Next, ChatGPT ‘s LLMs are used to activate query functions for the analysis of the graph. The results of the queries are displayed in a user-friendly graphical user interface· The study’s outcomes offer insights for researchers and industry professionals, highlighting emerging research potentialsfor LLMs in the field. © 2024, Education and research in Computer Aided Architectural Design in Europe. All rights reserved.},
	author_keywords = {Building Information Modeling; Knowledge Graphs; Large Language Models; Natural Language Processing},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Congès2024,
	author = {Congès, Aurélie and Fertier, Audrey and Salatgé, Nicolas and Rebière, Sébastien and Benaben, Frederick},
	title = {R-IO SUITE: integration of LLM-based AI into a knowledge management and model-driven based platform dedicated to crisis management},
	year = {2024},
	journal = {Software and Systems Modeling},
	doi = {10.1007/s10270-024-01237-2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211435891&doi=10.1007%2fs10270-024-01237-2&partnerID=40&md5=18b98e8a4d9f00569586662654ce8d7f},
	abstract = {This article presents how the R-IO SUITE software platform, a decision support system for crisis management entirely based on model-driven engineering principles, considerably benefits from large language model (LLM)-based artificial intelligence (AI). The different components of the R-IO SUITE platform are used to climb the four abstraction layers: data, information, decision and action through interpretation (from data to information), exploitation (from information to decision) and implementation (from decision to action). These transitions between layers are supported by a knowledge base embedding knowledge instances structured according to a crisis management metamodel. From a functional perspective, this platform is fully operational, however, to be able to cover any type of crisis situation, the knowledge base should be enriched, first, from a “resource perspective” (to embed the various available means to deal with any faced situation), and second, from an “issue perspective” (to understand all risks and damage that can appear on a crisis situation). It is not reasonable to consider creating and maintaining such an exhaustive knowledge base. However, the connection of the R-IO SUITE platform with LLM software such as ChatGPT© makes it possible, by generating appropriate prompts, to update on-the-fly the knowledge base according to the faced context. This article shows how the LLM AI can provide complementary knowledge to formally fulfil the knowledge base to make it relevant to the faced crisis situation. This article presents the R-IO SUITE as a LLM-empowered model-driven platform to become an extended crisis management supporting system. © The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature 2024.},
	author_keywords = {Artificial intelligence; Business process management; Complex event processing; Decision support system; Knowledge base; Large language model; Metamodel; Model-driven engineering; Ontologies},
	keywords = {Enterprise resource management; Enterprise resource planning; Information management; Metadata; Modeling languages; Ontology; Public administration; Risk management; Business Process; Business process management; Complex event processing; Complex events; Decision supports; Event Processing; Knowledge base; Language model; Large language model; Meta model; Model-driven Engineering; Ontology's; Process management; Support systems; Decision support systems},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Erickson2024,
	author = {Erickson, John S. and Santos, Henrique and McCusker, Jamie and Shirai, Sola and McGuinness, Deborah L. and Hendler, James},
	title = {ChatBS: An Exploratory Sandbox for Bridging Large Language Models with the Open Web},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3828},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210250493&partnerID=40&md5=520f4d1cb82ed6c3ca7e915af56180ac},
	abstract = {The recent widespread public availability of generative large language models (LLMs) has drawn much attention from the academic community to run experiments in order to learn more about their strengths and drawbacks. From prompt engineering and fine-tuning to fact-checking and task-solving, researchers have pursued several approaches to try to take advantage of these tools. As some of the most powerful LLMs are “closed” and only accessible through web APIs with prior authorization, combining LLMs with the open web is still a challenge. In this evolving landscape, tools that can facilitate the exploration of the capabilities and limitations of LLMs are desirable, especially when connecting with traditional web features such as search and structured data. This article presents ChatBS, a web-based exploratory sandbox for LLMs, working as a front-end for prompting LLMs with user inputs. It provides features such as entity resolution from open knowledge graphs, web search using LLM outputs, as well as popular prompting techniques (e.g. multiple submissions, “step-by-step”). ChatBS has been extensively used in Rensselaer Polytechnic Institute’s Data INCITE courses and research, serving as key tool for utilizing LLMs outputs at scale in these contexts. © 2024 Copyright for this paper by its authors.},
	keywords = {Academic community; Fine tuning; Front end; Language model; Learn+; Model outputs; Structured data; User input; Web based; Web features},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{2024,
	title = {Simulation Innovation Workshop 2024, SIW 2024},
	year = {2024},
	journal = {Simulation Innovation Workshop 2024, SIW 2024},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211635519&partnerID=40&md5=7ac3142c63aaca7cde2e0d72feeac0a0},
	abstract = {The proceedings contain 11 papers. The topics discussed include: aptitude for command evaluations: implementation opportunities for cognitive science; incorporating ethics in defense M & S: new frontiers in standards; weapon simulation as a service for the entire tactical cycle; standards for ChatGPT-enhanced technical writing: objectives, obstacles, options, and opportunities; advancing modelling and simulation in NATO federated mission networking; a helper framework for simplifying HLA interfaces; initial comparison of network loading under HLA and dis standards; C2SIM as a mission planning tool standard; exploring large language models for scenario generation in support of C2SIM autonomous systems ontology extension development; and live-virtual interoperability in large flag exercises.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Lee20241191,
	author = {Lee, Woo-Sung and Kim, Tae-Yeon and Choi, Woen-Sug},
	title = {Autonomous Navigation Command Generation System for Underwater Robots Using LLM},
	year = {2024},
	journal = {Journal of Institute of Control, Robotics and Systems},
	volume = {30},
	number = {10},
	pages = {1191 – 1196},
	doi = {10.5302/J.ICROS.2024.24.0142},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208623885&doi=10.5302%2fJ.ICROS.2024.24.0142&partnerID=40&md5=2c3267b179f4b2b111add9ad4f3248aa},
	abstract = {Recent advances in artificial intelligence, particularly in natural language processing with large language models (LLMs), enable robots to perform complex tasks. Integration with ROS to simulate control room conversation enhances robot autonomy, allowing them to automatically navigate and determine optimal paths. This study demonstrates the feasibility of implementing a system where robots can generate their own navigation commands by integrating ROS and LLMs. To achieve this, a simulation environment was constructed, data processing and command generation processes were designed, and three methodologies were experimented with by applying ontology and prompt engineering. The experimental results showed that using a single GPT model with information filtering provided high efficiency and success rates in command generation, and higher versions of the GPT model delivered improved performance. These findings present a preliminary methodology that improves robot autonomy and efficiency in autonomous controls and establishes a foundation for further enhancing the performance of robot control systems. © 2024, Institute of Control, Robotics and Systems. All rights reserved.},
	author_keywords = {autonomous surface vehicle; autonomous underwater vehicle; large-scale language model; marine robots; prompt engineering; ROS-Gazebo framework},
	keywords = {Modeling languages; Robots; Unmanned surface vehicles; Autonomous surface vehicles; Autonomous underwater vehicles]; Command generation; Language model; Large-scale language model; Large-scales; Marine robots; Navigation commands; Prompt engineering; ROS-gazebo framework; Natural language processing systems},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Kandula2024,
	author = {Kandula, Rakesh and Hannah, Lee and Shimizu, Cogan},
	title = {Lexico-syntatic Patterns for Fine-tuning an LLM},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3828},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210249798&partnerID=40&md5=771ac8fea63eda5f7e36896a139b1f29},
	abstract = {Large Language Models (LLMs) are expensive to train. However, there are techniques that can adapt LLMs more quickly and efficiently, such as fine-tuning with domain specific data. This allows foundational models to be applied to more niche use-cases in a cost efficient manner. Knowledge graphs (KGs) are excellent sources of curated data, making them an ideal source of knowledge for fine-tuning. Further, lexico-syntactic patterns (LSPs) can play an important role in representing data captured in semantic relationships in KGs as natural language text. In this paper, we discuss the use of LSPs to represent knowledge graphs (KGs) in natural language for the purposes of fine tuning. We demonstrate in our question answering use-case that fine-tuning helps in this case, but does not exceed retrieval-augmented generation approaches. We posit with larger KGs and and additional LSPs, we can achieve parity. Poster Submission. © 2024 Copyright for this paper by its authors.},
	author_keywords = {Fine-tuning; Large Language Models(LLMs); Lexico Syntactic Patterns (LSPs)},
	keywords = {Natural language processing systems; Question answering; Semantics; Syntactics; Cost-efficient; Domain specific; Fine tuning; Knowledge graphs; Language model; Large language model; Lexico syntactic pattern; Lexico-syntactic patterns; Natural languages texts; Semantic relationships; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Xie2024,
	author = {Xie, Bingbing and Ma, Xiaoxiao and Shan, Xue and Beheshti, Amin and Yang, Jian and Fan, Hao and Wu, Jia},
	title = {Multiknowledge and LLM-Inspired Heterogeneous Graph Neural Network for Fake News Detection},
	year = {2024},
	journal = {IEEE Transactions on Computational Social Systems},
	doi = {10.1109/TCSS.2024.3488191},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209878746&doi=10.1109%2fTCSS.2024.3488191&partnerID=40&md5=f2dd87a053d477c1360712825ded5ed4},
	abstract = {The widespread diffusion of fake news has become a critical problem on dynamic social media worldwide, which requires effective strategies for fake news detection to alleviate its hazardous consequences for society. However, most recent efforts only focus on the features of news content and social context without realizing the benefits of large language models (LLMs) and multiple knowledge graphs (KGs), thus failing to improve detection capabilities further. To tackle this issue, we present a multiknowledge and LLM-inspired heterogeneous graph neural network for fake news detection (MiLk-FD), by combining KGs, LLMs, and graph neural networks (GNNs). Specifically, we first model news content as a heterogeneous graph (HG) containing news, entity, and topic nodes and then fuse the knowledge from three KGs to augment the factual basis of news articles. Meanwhile, we leverage TransE to initialize the knowledge features and employ LLaMa2-7B to obtain the initial feature vectors of news articles. After that, we utilize the devised HG transformer to learn news embeddings with specific feature distribution in high-dimensional spaces by aggregating neighborhood information according to metapaths. Finally, a classifier based on multilayer perceptron (MLP) is trained to predict each news article as fake or true. Through experiments, we demonstrate that our proposed framework surpasses ten baselines according to accuracy, precision, F1-score, recall, and ROC in four public real-world benchmarks (i.e., COVID-19, FakeNewsNet, PAN2020, Liar).  © 2014 IEEE.},
	author_keywords = {Deep learning; fake news detection; graph anomaly detection; knowledge graph (KG); large language model (LLM)},
	keywords = {Deep learning; Graph neural networks; Multilayer neural networks; Network theory (graphs); Anomaly detection; Deep learning; Fake news detection; Graph anomaly detection; Graph neural networks; Heterogeneous graph; Knowledge graph; Knowledge graphs; Language model; Large language model; Knowledge graph},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Lai2024,
	author = {Lai, Xuan and Tang, Lianggui and Zhu, Xiuling and Xiao, Liyong and Chen, Zhuo and Yang, Jiajun},
	title = {KG-CQAM: Knowledge Graph and Mind Mapping-based Complex Question Answering for Large Language Models},
	year = {2024},
	journal = {Proceedings of SPIE - The International Society for Optical Engineering},
	volume = {13404},
	doi = {10.1117/12.3050113},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208826329&doi=10.1117%2f12.3050113&partnerID=40&md5=f52b8199003ef5bb23c69acd2446a90d},
	abstract = {Large Language Models (LLMs) have achieved significant advancements in the field of natural language processing. However, they still face challenges related to integrity, timeliness, fidelity, and adaptability, often encountering hallucination issues. To address these challenges, knowledge graphs, as structured data structures storing vast knowledge in a clear manner, can be employed to augment LLMs’ knowledge. However, simple retrieval methods are insufficient for complex multi-hop reasoning tasks. Therefore, this paper proposes a novel approach, utilizing the chain of thought, employing mind maps as key prompts, aimed at dynamically reasoning over knowledge graphs by invoking LLMs while preserving graph structure information. Experimental results demonstrate that KG-CQAM not only significantly enhances LLMs’ reasoning capabilities for multi-hop complex questions but also obviates the need for any model training. © 2024 SPIE.},
	author_keywords = {Knowledge graph reasoning; LLM; Mind mapping; Multi-hop problems; Prompt engineering},
	keywords = {Mapping; Natural language processing systems; Structured Query Language; Complex questions; Knowledge graph reasoning; Knowledge graphs; Language model; Large language model; Mind-mapping; Multi-hop problem; Multi-hops; Prompt engineering; Question Answering; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Xu2024162638,
	author = {Xu, Jun and Zhang, Hao and Zhang, Haijing and Lu, Jiawei and Xiao, Gang},
	title = {ChatTf: A Knowledge Graph-Enhanced Intelligent Q&A System for Mitigating Factuality Hallucinations in Traditional Folklore},
	year = {2024},
	journal = {IEEE Access},
	volume = {12},
	pages = {162638 – 162650},
	doi = {10.1109/ACCESS.2024.3485877},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209217304&doi=10.1109%2fACCESS.2024.3485877&partnerID=40&md5=26725e7ac94810608245a6c7bad52b84},
	abstract = {Large language models are rapidly advancing the field of artificial intelligence, with current research focusing primarily on traditional natural language understanding tasks, such as question answering and information extraction. However, in knowledge-intensive domains, such as intangible cultural heritage, hallucination problems due to insufficient domain knowledge persist. To address this, we present ChatTf, a knowledge graph-enhanced intelligent Q&A system, exemplified by Chinese traditional folklore, aimed at reducing factuality hallucinations in this domain. Specifically, we constructed the Traditional Folklore Ontology (TFOnto) and proposed the Zero-shot Traditional Folklore Triplet Extraction (ZFTE) framework. Driven by TFOnto, ZFTE builds a Traditional Folklore Knowledge Graph (TFKG). We then proposed a dual-stage Retrieval-Augmented Generation framework (TFKG-RAG) based on TFKG to provide traditional folklore knowledge to large language models, mitigating factuality hallucinations in folklore Q&A tasks. In the experimental phase, ChatTf achieved an accuracy of 96.7% on a self-built TFCQD test set, outperforming several state-of-the-art baseline methods. This demonstrates the accuracy and reliability of folklore domain question answering.  © 2024 The Authors.},
	author_keywords = {Knowledge graph; large language model; question answering; retrieval-augmented generation; traditional folklore},
	keywords = {Domain Knowledge; Knowledge graph; 'current; Intangible cultural heritages; Knowledge graphs; Language model; Large language model; Natural language understanding; Ontology's; Question Answering; Retrieval-augmented generation; Traditional folklore; Question answering},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@CONFERENCE{Armant2024,
	author = {Armant, Vincent and Mouakher, Amira and Vargas-Rojas, Felipe and Symeonidou, Danai and Guérin, Joris and Mougenot, Isabelle and Desconnets, Jean-Christophe},
	title = {Can Knowledge Graphs and Retrieval-Augmented Generation be combined to Explain Query/Answer Relationships Truthfully?},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3833},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211180646&partnerID=40&md5=5406aeb192f487bae497d1a983229118},
	abstract = {In recent years, there has been a significant increase in the adoption of Large Language Models (LLMs) by users in both academic and industrial fields. These powerful tools are progressively challenging the dominance of traditional keyword-based search engines in various fields. While advancements like Retrieval-Augmented Generation (RAG) are enabling LLMs to provide provenance and explanations, their widespread adoption remains hindered by some well-known limitations, including hallucinations (factual inconsistencies), outdated knowledge, and answer precision. In contrast, classical search engines do not suffer from these issues, thanks to recent progress that has made them both efficient and accurate. However, their output may lack interpretability compared to LLMs. This vision paper proposes a novel explanation system that bridges this gap. By integrating Knowledge Graphs with RAG, we aim to elucidate the semantic relationships between retrieved resources and user queries. Addressing this research question has the potential to enhance user trust and confidence in the utilization of explainable search engines. © 2024 Copyright for this paper by its authors.},
	author_keywords = {Explanation; Knowledge Graph; Large Language Model; Resource Discovery; Retrieval-Augmented Generation; XAI},
	keywords = {Content based retrieval; Query languages; Search engines; Semantics; Structured Query Language; Academic fields; Explanation; Industrial fields; Knowledge graphs; Knowledge retrieval; Language model; Large language model; Resource discovery; Retrieval-augmented generation; XAI; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Wahid2024,
	author = {Wahid, Abdul and Yahya, Muhammad and Zaman, Farooq and Zhou, Baifan and Breslin, John G. and Intizar, Muhammad Ali and Kharlamov, Evgeny},
	title = {Integrating I4.0 Knowledge Graphs with Large Language Models Beyond SPARQL Endpoints},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3830},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210885367&partnerID=40&md5=84f44fce68aee092a8964af6520465d5},
	abstract = {Industry 4.0 (I4.0) knowledge graphs are a common way to represent industrial information models. Conventional SPARQL querying systems require the users to be familiar with the data schema and SPARQL syntax. However, this is often very difficult for many users in industrial production, who have mostly an engineering background, instead of a semantic web. Recent developments in large language models (LLMs) make it possible for non-semantic experts to use natural language to query knowledge graphs (KG). In this work, we present a framework and preliminary results of integrating Industry 4.0 KGs with LLMs to improve how data is represented, reasoned, and processed in manufacturing contexts, facilitating user interaction with KGs and contributing to operational efficiency. Our technique enhances Language Models (LLMs) by utilising the semantic complexity and interdependence of Knowledge Graphs (KGs). This allows us to incorporate domain-specific knowledge. We used the FAISS library and LLaMA2 to optimise the storage and retrieval of vectors, which improved the system’s performance and scalability. This integration allows for advanced fault detection, proactive maintenance, and process optimisation, resulting in decreased periods of inactivity and improved productivity. We introduce the framework’s architecture, implementation strategy, and possible advantages while also discussing the difficulties associated with data integration and scalability. The results of our study show that the integration of KG-LLM surpasses traditional approaches in terms of operational efficiency, as evidenced by enhanced fault detection, proactive maintenance, and process optimisation, thereby opening up possibilities for the advancement of more intelligent and resilient production systems. © 2022 Copyright for this paper by its authors.},
	author_keywords = {Deep Learning; Knowledge Graphs; Large Language Model (LLM); LLaMa; SPARQL},
	keywords = {Query languages; Scalability; Semantics; Structured Query Language; Deep learning; Faults detection; Knowledge graphs; Language model; Large language model; LLaMa; Operational efficiencies; Proactive maintenance; Proactive process; SPARQL; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{2024,
	title = {Proceedings - 2024 IEEE Visual Analytics Science and Technology VAST Challenge, Vast-Challenge 2024},
	year = {2024},
	journal = {Proceedings - 2024 IEEE Visual Analytics Science and Technology VAST Challenge, Vast-Challenge 2024},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212276195&partnerID=40&md5=0e8cdfcebe48cbc0d3c2c61870d2f19a},
	abstract = {The proceedings contain 13 papers. The topics discussed include: bubbles behind Oceanus' fishing market; VADITA: visual analytics for detecting illegal transport activities; utilizing TimeArcs and PageRank to solve the 2024 VAST Challenge Mini Challenge 3; visual bias detection for addressing illegal fishing activities; tracking overfishing: visual analytics of suspicious behaviors in commercial fishing vessels; FishEye watcher: a visual analytics system for knowledge graph bias detection; exploratory analysis of multi-edge knowledge graphs with paired clustered grids; FishBiasLens: integrating large language models and visual analytics for bias detection; project SunSpot: fishing cycle analysis and detection for tackling the 2024 VAST Challenge; visual anomaly detection in temporal knowledge graphs; and visual analysis of complex temporal networks supported by analytic provenance.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{2024,
	title = {LKM 2024 - Proceedings of the 1st International OpenKG Workshop: Large Knowledge-Enhanced Models, co-locacted with the International Joint Conference on Artificial Intelligence, IJCAI 2024},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3818},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209660233&partnerID=40&md5=8ea4da82cc015fadd9257149c738811c},
	abstract = {The proceedings contain 7 papers. The topics discussed include: augmenting patent summarization using large language model with knowledge graph; cognitive mirage: a review of hallucinations in large language models; InLegalLLaMA: Indian legal knowledge enhanced large language model; knowledge base-enhanced multilingual relation extraction with large language models; designing a language-model-based chatbot that considers user’s personality profile and emotions to support caregivers of people with dementia; LLM-driven knowledge enhancement for securities index prediction; and leveraging LLM-constructed graphs for effective goal-driven storytelling.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Baldazzi2024,
	author = {Baldazzi, Teodoro and Benedetto, Davide and Bellomarini, Luigi and Sallinger, Emanuel and Vlad, Adriano},
	title = {Softening Ontological Reasoning with Large Language Models},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3816},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209387015&partnerID=40&md5=60a46323ab00b3fd9d2fcdd038e7e6ae},
	abstract = {Logic-based Knowledge Graphs (KGs) and Knowledge Representation and Reasoning (KRR) have emerged as fundamental methodologies in many data-intensive areas, fostering trust and accountability for effective decision-making. However, the knowledge captured by such approaches is often restricted by the rigidity of their structured rule-based formalisms. More recently, the rising adoption of Large Language Models (LLMs) has introduced a new layer of semantic understanding and flexibility in human-data interaction. Yet, these models are inherently limited in reasoning capabilities and lack systematic and explainable outcomes due to their opaque nature. To address today’s challenge of combining the strengths of both technologies, we propose a novel neurosymbolic solution that leverages the power of LLMs to “soften” rule activations, enhancing adaptability in ontological reasoning while preserving robustness and transparency of KRR systems. © 2024 Copyright for this paper by its authors.},
	author_keywords = {Knowledge graphs; Language models; Ontological reasoning},
	keywords = {Semantics; Data intensive; Decisions makings; Graph representation; Human data; Knowledge graphs; Knowledge representation and reasoning; Language model; Ontological reasoning; Rule based; Semantics understanding; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Verma2024,
	author = {Verma, Ghanshyam and Sarkar, Simanta and Pillai, Devishree and Shiokawa, Hotaka and Shahbazi, Hamed and Veazey, Fiona and Hubbert, Peter and Su, Hui and Buitelaar, Paul},
	title = {HybridContextQA: A Hybrid Approach for Complex Question Answering using Knowledge Graph Construction and Context Retrieval with LLMs},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3853},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212695574&partnerID=40&md5=f8c5ff0672238492773a2b803d401c80},
	abstract = {Augmenting domain-specific knowledge with Large Language Models (LLMs) to answer complex conditional questions is an important area of research. LLMs are good at answering general domain questions, however, their performance decreases when applied to a specific domain with complex conditional questions. We hypothesize that extracting context from relevant documents and Knowledge Graphs (KGs), and then feeding this combined knowledge to the LLM prompts, can provide better context to answer the complex conditional questions. To test our hypothesis, we propose a hybrid approach called Hybrid Context for Complex Question-Answering (HybridContextQA) that can extract relevant context from documents as well as from a KG. To implement this, we create a Retrieval-Augmented Generation (RAG)-based hybrid context retrieval pipeline. This pipeline creates a KG from the provided documents and stores it in a Neo4j graph store. An LLM is used to automatically create a KG from the provided documents. The pipeline also stores the context extracted from the documents in vector form in a vector database. This combined context from KG and vector store can then be used for answering the complex conditional questions of that domain using an LLM. We perform our experiments on a complex question-answering (QA) dataset called ConditionalQA. This dataset contains complex questions with conditional answers. We also compare the proposed approach with other approaches such as Code Prompt, Text Prompt, and Think-on-Graph. We find that the HybridContextQA approach performs better than the existing approaches for multiple LLMs, including Mistral and Mixtral. We also conduct comprehensive experiments to analyze the contribution of the context from KG and vector form. We release the code implementing the HybridContextQA approach and the end-to-end pipeline with LLM prompts. © 2024 Copyright for this paper by its authors.},
	keywords = {Knowledge graph; Pipeline codes; Vectors; Complex questions; Context retrieval; Domain-specific knowledge; Graph construction; Hybrid approach; Knowledge graphs; Language model; Performance; Question Answering; Relevant documents; Question answering},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Phyu20241,
	author = {Phyu, Shoon Lei and Uchkempirov, Murataly and Proma, Mayesha Maliha and Kulkarni, Parag},
	title = {Augmenting Patent Summarization using Large Language Model with Knowledge Graph},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3818},
	pages = {1 – 13},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209631890&partnerID=40&md5=ee498a28a2165c271e02540cffc5ede1},
	abstract = {The increasing quantity and intricacy of patent papers need the creation of effective and precise summary techniques. The scientific and comprehensive nature of patents is often excessive for traditional summary techniques and machine learning-based approaches. This paper explores the integration of large language models (LLMs) with knowledge graphs (KGs) to improve patent document summarization. LLMs such as GPT-4 provide advanced language understanding and generation capabilities, but can cause problems with domain-specific content. Knowledge graphs offer a structured representation of knowledge that allows domain-specific information to be included in the summarization process. The goal of this integration is to enhance the readability and informativeness of patent summaries. We then propose a framework for combining LLM with KG and evaluate its performance compared to traditional baseline summarization technique using both ROUGE scores and human evaluations. The results demonstrate a significant improvement in the quality of patent summary, highlighting the potential of this approach to produce more informative and accurate reviews of complex technical documents. This research contributes to the development of more robust artificial intelligence summarization system capable of performing complex data interpretation and decision making in specialized areas. © 2024 Copyright for this paper by its authors.},
	author_keywords = {Knowledge Graph; Knowledge Graph Summarization; Natural Language Processing; Patent Summarization},
	keywords = {Decision making; Patents and inventions; Knowledge graph summarization; Knowledge graphs; Language model; Language processing; Learning-based approach; Machine-learning; Natural language processing; Natural languages; Patent summarization; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Hong202441,
	author = {Hong, Bin and Wu, Jinze and Liu, Jiayu and Ding, Liang and Sha, Jing and Zhang, Kai and Wang, Shijin and Huang, Zhenya},
	title = {End-to-End Graph Flattening Method for Large Language Models},
	year = {2024},
	journal = {Proceedings - 2024 International Conference on Computational Linguistics and Natural Language Processing, CLNLP 2024},
	pages = {41 – 45},
	doi = {10.1109/CLNLP64123.2024.00016},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211382848&doi=10.1109%2fCLNLP64123.2024.00016&partnerID=40&md5=f418fa3803fafa1ee6e96ef0218371fa},
	abstract = {In recent years, the breakthrough of Large Language Models (LLMs) offers new ideas for achieving universal methods on graph data. The common practice of converting graphs into natural language for LLMs, which refers to graph flattening, exhibits good generalizability and interpretability. However, the poor organization of the textual format results in poor performance in long-distance scenario understanding. Inspired by human cognitive reasoning habits, we propose a novel method for graph flattening to fit LLMs, termed as End-to-End DAG-Path prompting (EEDP). Experiments on real-world datasets show that EEDP enhances the reasoning performance of LLMs in long-distance scenarios while maintaining excellent performance in short-distance scenarios, demonstrating good robustness in the face of distance variations. © 2024 IEEE.},
	author_keywords = {graph flattening; graph representation; Large Language Model},
	keywords = {Modeling languages; End to end; Graph data; Graph flattening; Graph representation; Interpretability; Language model; Large language model; Natural languages; Textual format; Universal method; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Feng2024117,
	author = {Feng, Xiaohan and Wu, Xixin and Meng, Helen},
	title = {Ontology-grounded Automatic Knowledge Graph Construction by LLM under Wikidata schema},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3841},
	pages = {117 – 135},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210894055&partnerID=40&md5=42721ceb91e4dca1bd023f200ae069d5},
	abstract = {We propose an ontology-grounded approach to Knowledge Graph (KG) construction using Large Language Models (LLMs) on a knowledge base. An ontology is authored by generating Competency Questions (CQ) on knowledge base to discover knowledge scope, extracting relations from CQs, and attempt to replace equivalent relations by their counterpart in Wikidata. To ensure consistency and interpretability in the resulting KG, we ground generation of KG with the authored ontology based on extracted relations. Evaluation on benchmark datasets demonstrates competitive performance in knowledge graph construction task. Our work presents a promising direction for scalable KG construction pipeline with minimal human intervention, that yields high quality and human-interpretable KGs, which are interoperable with Wikidata semantics for potential knowledge base expansion. © 2024 Copyright for this paper by its authors.},
	author_keywords = {Interpretable AI; Knowledge Graph; Large Language Model; Relation Extraction; Wikidata},
	keywords = {Ontology; Semantics; Equivalent relation; Graph construction; Interpretability; Interpretable AI; Knowledge graphs; Language model; Large language model; Ontology's; Relation extraction; Wikidata; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Hassanzadeh2024,
	author = {Hassanzadeh, Oktie},
	title = {WikiCausal: Corpus and Evaluation Framework for Causal Knowledge Graph Construction},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3828},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210228643&partnerID=40&md5=e7bf5f97a94b086cd98d6fd03a81d7d6},
	abstract = {Recently, there has been an increasing interest in the construction of general-domain and domain-specific causal knowledge graphs. Such knowledge graphs enable reasoning for causal analysis and event prediction, and so have a range of applications across different domains. While great progress has been made toward automated construction of causal knowledge graphs, the evaluation of such solutions has either focused on low-level tasks (e.g., cause-effect phrase extraction) or on ad hoc evaluation data and small manual evaluations. In this work, we present a corpus, task, and evaluation framework for causal knowledge graph construction. Our corpus consists of Wikipedia articles for a collection of event-related concepts in Wikidata. The task is to extract causal relations between event concepts from the corpus. The evaluation is performed in part using existing causal relations in Wikidata to measure recall, and in part using Large Language Models to avoid the need for manual or crowd-sourced evaluation. We evaluate a pipeline for causal knowledge graph construction that relies on neural models for question answering and concept linking, and show how the corpus and the evaluation framework allow us to effectively find the right model for each task. © 2024 Copyright for this paper by its authors.},
	author_keywords = {Causal Knowledge; Knowledge Extraction from Text; Knowledge Graph Construction},
	keywords = {Domain Knowledge; Causal analysis; Causal knowledge; Causal relations; Domain specific; Evaluation framework; Graph construction; Knowledge extraction; Knowledge extraction from text; Knowledge graph construction; Knowledge graphs; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Sukhwal2024,
	author = {Sukhwal, Prakash C. and Rajan, Vaibhav and Kankanhalli, Atreyi},
	title = {A Joint LLM-KG System for Disease Q&A},
	year = {2024},
	journal = {IEEE Journal of Biomedical and Health Informatics},
	doi = {10.1109/JBHI.2024.3514659},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212298632&doi=10.1109%2fJBHI.2024.3514659&partnerID=40&md5=b569074c4e539f032a2c9f903b38c992},
	abstract = {Medical question answer (QA) assistants respond to lay users' health-related queries by synthesizing information from multiple sources using natural language processing and related techniques. They can serve as vital tools to alleviate issues of misinformation, information overload, and complexity of medical language, thus addressing lay users' information needs while reducing the burden on healthcare professionals. QA systems, the engines of such assistants, have often used large language models (LLMs) or knowledge graphs (KG), though the approaches could be complementary. LLM-based QA systems excel at understanding complex questions and providing well-formed answers but are prone to factual mistakes. KG-based QA systems, which represent facts well, are mostly limited to answering short-answer questions with pre-created templates. While a few studies have used both LLM and KG for text-based QA, the approaches are still prone to incomplete or inaccurate answers. Extant QA systems also have limitations in terms of automation and performance. We address these challenges by designing a novel, automated disease QA system named Disease Guru - Long-Form Question Answer (DG-LFQA), which effectively utilizes both LLM and KG techniques through a joint reasoning approach to answer disease-related questions appropriate for lay users. Our evaluation of the system using a range of quality metrics demonstrates its efficacy over related baseline systems.  © 2013 IEEE.},
	author_keywords = {Healthcare; Information extraction; Knowledge graph; Large language model; Question answering},
	keywords = {Diseases; Natural language processing systems; Healthcare; Information extraction; Knowledge graphs; Language model; Large language model; Model knowledge; Multiple source; Natural languages; Question answer systems; Question Answering; article; automation; benchmarking; health care personnel; information overload; large language model; misinformation; natural language processing; reasoning; Knowledge graph},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Saito2024,
	author = {Saito, Yuki and Egami, Shusaku and Sei, Yuichi and Tahara, Yasuyuki and Ohsuga, Akihiko},
	title = {Empirical Analysis of Knowledge Representation for Anime Recommendation Using Graph Neural Networks},
	year = {2024},
	journal = {Transactions of the Japanese Society for Artificial Intelligence},
	volume = {39},
	number = {6},
	doi = {10.1527/tjsai.39-6_AG24-D},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85209113142&doi=10.1527%2ftjsai.39-6_AG24-D&partnerID=40&md5=c951f2b93861648097edfb12c2b08c9c},
	abstract = {In recent years, entertainment content, such as movies, music, and anime, has been gaining attention due to the stay-at-home demand caused by the expansion of COVID-19. In the content domain, research in the field of knowledge representation is primarily concerned with accurately describing metadata. Therefore, different knowledge representations are required for applications in downstream tasks. In this study, we aim to clarify effective knowledge representation for predicting users’ latent preferences through a case study of an anime recommendation task. We developed hypotheses from both quantitative and qualitative aspects on how to represent work knowledge to improve recommendation performance, and verified them by changing the structure of knowledge representation according to the hypothesis. Initially, we constructed a Knowledge Graph (KG) by integrating domain-specific and general-purpose data sources through the process of entity matching and imposing constraints on the properties. Subsequently, we constructed multiple KGs by varying the knowledge configuration. Specifically, we changed the composition of the data sources considered in the KG construction or excluded a triplet associated with an arbitrary property. After that, we fed the constructed KGs into the graph neural network recommender model and compared the recommendation performance. As a result, it was shown that the recommendation performance based on the KG composed of multiple data sources was the best, thus supporting the hypothesis from a quantitative aspect. Next, an ablation study on the properties revealed that knowledge characterizing the work itself contributed to the recommendation performance, thus supporting the hypothesis from a qualitative aspect. Furthermore, we constructed a text-based KG by generating a new vocabulary from the “synopsis” text. It can describe the work’s storyline and worldview in more detail. We take it as an input to a Large Language Model (LLM) and extend the existing metadatabased KG. The results showed that the KG considering both metadata and text had the best overall recommendation performance, again confirming the hypothesis. © 2024, Japanese Society for Artificial Intelligence. All rights reserved.},
	author_keywords = {data integration; graph neural networks; knowledge graph; recommender system},
	keywords = {Graph neural networks; Metadata; Recommender systems; Case-studies; Data-source; Down-stream; Empirical analysis; Graph neural networks; Knowledge graphs; Knowledge-representation; Property; Qualitative aspects; Recommendation performance; Knowledge graph},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@CONFERENCE{2024,
	title = {SOFLIM2KG-SEMIIM 2024 - Joint Proceedings of the 1st Software Lifecycle Management for Knowledge Graphs Workshop and the 3rd International Workshop on Semantic Industrial Information Modelling, co-located with 23th International Semantic Web Conference, ISWC 2024},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3830},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85210832346&partnerID=40&md5=9d6432eea269e88e41d16c348919b682},
	abstract = {The proceedings contain 7 papers. The topics discussed include: RDF-Connect: A declarative framework for streaming and cross-environment data processing pipelines; generating transparent and query-based RDF layers; vision of knowledge graph lifecycle management within hybrid artificial intelligence solutions; knowledge representation and engineering for smart diagnosis of cyber physical systems; SPARQL-based relaxed rules for learning over knowledge graphs; Integrating I4.0 knowledge graphs with large language models beyond SPARQL endpoints; and towards an ontology for procedural knowledge in Industry 5.0.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Elchafei2024229,
	author = {Elchafei, Passant and Fashwan, Amany},
	title = {Arabic NER Evaluation: Pre-Trained Models via Contrastive Learning vs. LLM Few-Shot Prompting},
	year = {2024},
	journal = {Procedia Computer Science},
	volume = {244},
	pages = {229 – 237},
	doi = {10.1016/j.procs.2024.10.196},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211217191&doi=10.1016%2fj.procs.2024.10.196&partnerID=40&md5=0c07df0a7a6cbaed2b737a7252a4d888},
	abstract = {Developing Natural Language Processing (NLP) tools for the Arabic language and its dialects is very challenging. Named Entity Recognition (NER) is one of these challenges, which serves as the core component in many NLP systems such as information extraction, question answering, machine translation and knowledge graph building. This paper sheds light on applying diferent approaches for Arabic NER (Flat and Nested) using a large and rich Arabic NER corpus, Wojood dataset, which consists of about 550K tokens annotated with 21 entity types. First, we apply the Wojood base model, AraBERTv2, along with various other Arabic BERT models such as MARBERTv2, CaMelBert, mBert,.etc. Next, we utilize the Bi-Encoder Contrastive Learning (CL) approach, a framework developed by Microsoft, which maps candidate text spans and entity types into the same vector representation space. The primary challenge in this approach is distinguishing non-entity spans from entity mentions. This approach could achieve F1 score 91.25% for Flat and 91.40% for Nested NER. Additionally, for evaluating the predicted NER, we employ Few-Shot prompting on LLaMA, and GPT-3.5 using refined prompt-based strategy. Our findings reveal that LLaMA outperforms GPT3.5. © 2024 Elsevier B.V.. All rights reserved.},
	author_keywords = {Arabic NER; BERT; Contrastive Learning; Few-Shot; GPT3.5; LLaMA; LLM; Named Entity Recognition; Prompt Engineering},
	keywords = {Adversarial machine learning; Knowledge graph; Natural language processing systems; Translation (languages); Vector spaces; Zero-shot learning; Arabic named entity recognition; BERT; Entity-types; Few-shot; Gpt3.5; LLaMA; LLM; Named entity recognition; Prompt engineering; Contrastive Learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@CONFERENCE{Ye202412,
	author = {Ye, Weiqi and Zhang, Qiang and Zhou, Xian and Hu, Wenpeng and Tian, Changhai and Cheng, Jiajun},
	title = {Correcting Factual Errors in LLMs via Inference Paths Based on Knowledge Graph},
	year = {2024},
	journal = {Proceedings - 2024 International Conference on Computational Linguistics and Natural Language Processing, CLNLP 2024},
	pages = {12 – 16},
	doi = {10.1109/CLNLP64123.2024.00011},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211336467&doi=10.1109%2fCLNLP64123.2024.00011&partnerID=40&md5=a6cea544b79e551003f9e981984e5453},
	abstract = {Large language models (LLMs) have been observed to occasionally exhibit hallucination, a phenomenon where they generate statements unsupported by factual evidence, thereby compromising the trustworthiness of their output. Current approaches to mitigating this problem largely rely on extracting a single triplet from a knowledge graph, which fails to adequately capture the complex and interlinked nature of factual reasoning. In an effort to address this critical challenge, this paper delves into the utilization of inference paths based on knowledge graph for factual error correction of LLMs. At the heart of our approach lies the deployment of deep reinforcement learning algorithms, which traverse the knowledge graph to retrieve inference paths. These paths, replete with contextual depth and logical coherence, thereby amending the content and diminishing the incidence of factual discrepancies in the reasoning process of LLMs. Experimental results demonstrate that our approach markedly enhances the factual QA performance of LLMs. Furthermore, it shows great potential in improving the reliability of LLMs in complex reasoning scenarios, highlighting the effectiveness of inference path derived from knowledge graph. © 2024 IEEE.},
	author_keywords = {factual error correction; inference path; knowledge graph; reinforcement learning},
	keywords = {Adversarial machine learning; Contrastive Learning; Deep reinforcement learning; Reinforcement learning; Undirected graphs; 'current; Critical challenges; Errors correction; Factual error correction; Inference path; Knowledge graphs; Language model; Path-based; Reinforcement learning algorithms; Reinforcement learnings; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Sahbi20243083,
	author = {Sahbi, Aya and Alec, Céline and Beust, Pierre},
	title = {Automatic Ontology Population from Textual Advertisements: LLM vs. Semantic Approach},
	year = {2024},
	journal = {Procedia Computer Science},
	volume = {246},
	number = {C},
	pages = {3083 – 3092},
	doi = {10.1016/j.procs.2024.09.364},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211219376&doi=10.1016%2fj.procs.2024.09.364&partnerID=40&md5=1ad9dd0944ca08c2e6a21f355a331796},
	abstract = {Automatic ontology population involves identifying, extracting and integrating information from various sources to instantiate the classes and properties of an ontology, thereby building a domain Knowledge Graph (KG). In this paper, we compare two text-based ontology population techniques: KOnPoTe, a semantic approach based on textual and domain knowledge analysis, and a generative AI approach utilizing Claude, a Large Language Model (LLM). We present experiments conducted on two French sales advertisement domains: real estate and boats, and discuss the strengths and limitations of both approaches. © 2024 The Authors.},
	author_keywords = {LLM; Ontology Population; Textual Advertisement},
	keywords = {Domain Knowledge; Generative adversarial networks; Knowledge graph; Modeling languages; Ontology; Semantics; Automatic ontology; Domain knowledge; Extracting information; Integrating information; Language model; Large language model; Ontology Population; Property; Semantic approach; Textual advertisement; Marketing},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access}
}

@CONFERENCE{Lotfy2024437,
	author = {Lotfy, Abdelrahman and Ashraf, Ahmed and Barakat, Mariam and Saleh, Kirollos and Ahmed, Eslam and Sherif, Bassel and Badawy, Ali Nasser and Khoriba, Ghada},
	title = {A Comparative Analysis of Large Language Models for Automated Course Content Generation from Books},
	year = {2024},
	journal = {NILES 2024 - 6th Novel Intelligent and Leading Emerging Sciences Conference, Proceedings},
	pages = {437 – 442},
	doi = {10.1109/NILES63360.2024.10753166},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85212582615&doi=10.1109%2fNILES63360.2024.10753166&partnerID=40&md5=efdfe31a473c3c61778f6f5aedef2837},
	abstract = {Large Language Models (LLMs) have emerged as powerful tools for extracting course topics from textbooks in today's fast-paced educational landscape. Additionally, harnessing the potential of Knowledge Graphs to visualize the mutuality among topics enhances the informativeness of the extracted content. This paper presents a comprehensive comparative study that explores and assesses the effectiveness of different LLMs in extracting, identifying, and summarizing course topics within textbooks and generating knowledge graphs to visualize topic interdependencies. Moreover, we present a comprehensive methodology for knowledge graph development, incorporating specialized models, GPT2, Falcon 7B, and Llama-2-7b-chat-hf, fine-tuned with eight book tables of contents. Also, we have used Llama3, Llama3.1, Gemma, and Mistral-Nemo as a zero-shot model. Our findings show that llama3 has achieved the best performance among the zero-shot models in the following constraints: quality of content, correctness, clarity, and overall rating. Also, GPT2- Large excels in generating meaningful content, while GPT2-Base performs efficiently. In addition, challenges in knowledge graph integration were addressed by representing table of content data as knowledge graphs, providing more meaningful insights. This research enhances knowledge representation, demonstrating LLMs' value in knowledge graphs and data balance optimization. © 2024 IEEE.},
	author_keywords = {Knowledge Graphs & Finetuning; Large Language Models (LLMs)},
	keywords = {Curricula; Comparative analyzes; Comparatives studies; Course contents; Informativeness; Knowledge graph & finetuning; Knowledge graphs; Language model; Large language model; Performance; Table of contents; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Tian2024137,
	author = {Tian, Xiaoyun and Liu, Bin and Yang, Jianzhong and Ai, Bo and Zhao, Huailiang and Zhang, Shaoyang},
	title = {Knowledge Graph Enhanced Interactive Fault Diagnosis O&M Approach Based on Large Models of Electrical Power},
	year = {2024},
	journal = {Proceedings - 2024 4th Power System and Green Energy Conference, PSGEC 2024},
	pages = {137 – 142},
	doi = {10.1109/PSGEC62376.2024.10721152},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85208991766&doi=10.1109%2fPSGEC62376.2024.10721152&partnerID=40&md5=f7b30899a63616b8fa583617acb4dd6f},
	abstract = {Power equipment operation and maintenance has accumulated a large amount of knowledge recorded in the form of text, which provides the basis for power equipment diagnosis and operation and maintenance. However, the huge amount of redundant knowledge makes it difficult for the relevant personnel to quickly access the information, and it is also impossible to integrate it into the existing diagnostic algorithms. For this reason, this paper proposes an interactive equipment diagnosis and operation and maintenance method based on knowledge graph and big model. First, the unstructured knowledge is transformed and constitutes the O&M (Operation and Maintenance) knowledge graph using entity extraction method; second, the conditional probability of the equipment feature quantity to the failure mode is fitted using graph convolution to realize the equipment failure diagnosis; subsequently, an intention recognition algorithm based on self-attention network is proposed and retrieval is realized; finally, the results are generated into natural language using the big language model. It is verified that the proposed diagnosis and intent recognition F1 values are improved by 9.77% and 17.48%, respectively, confirming the effectiveness of the system.  © 2024 IEEE.},
	author_keywords = {fault diagnosis; interactive system; knowledge graph; large language model},
	keywords = {Equipment diagnosis; Faults diagnosis; Interactive system; Knowledge graphs; Language model; Large language model; Large models; Maintenance approaches; Operations and maintenance; Power equipment; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Schaub-Torre202499,
	author = {Schaub-Torre, León-Paul and Quirós, Pelayo and García-Mieres, Helena},
	title = {Automatic Pathology Detection in Spanish Clinical Notes Combining Language Models and Medical Ontologies; [Detección Automática de Patologías en Notas Clínicas en Español Combinando Modelos de Lenguaje y Ontologías Médicos]},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3846},
	pages = {99 – 120},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85211928611&partnerID=40&md5=613c3536921986de8d515c03015d719e},
	abstract = {In this paper we present a hybrid method for the automatic detection of dermatological pathologies in medical reports. We use a large language model combined with medical ontologies to predict, given a first appointment or follow-up medical report, the pathology a person may suffer from. The results show that teaching the model to learn the type, severity and location on the body of a dermatological pathology as well as in which order it has to learn these three features significantly increases its accuracy. The article presents the demonstration of state-of-the-art results for classification of medical texts with a precision of 0.84, micro and macro F1-score of 0.82 and 0.75, and makes both the method and the dataset used available to the community. © 2024 Copyright for this paper by its authors.},
	author_keywords = {biomedical; hybrid method; language model; ontology},
	keywords = {Contrastive Learning; Oncology; Ontology; Automatic Detection; Biomedical; Clinical notes; Follow up; Hybrid method; Language model; Learn+; Medical ontology; Ontology's; Pathologies detections; Dermatology},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}@CONFERENCE{Luo20242039,
	author = {Luo, Haoran and Haihong, E. and Tang, Zichen and Peng, Shiyao and Guo, Yikai and Zhang, Wentai and Ma, Chenghao and Dong, Guanting and Song, Meina and Lin, Wei and Zhu, Yifan and Tuan, Luu Anh},
	title = {ChatKBQA: A Generate-then-Retrieve Framework for Knowledge Base Question Answering with Fine-tuned Large Language Models},
	year = {2024},
	journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
	pages = {2039 – 2056},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205293195&partnerID=40&md5=b7f86a2bbcb13881fc97f0a6f6a4ea7a},
	abstract = {Knowledge Base Question Answering (KBQA) aims to answer natural language questions over large-scale knowledge bases (KBs), which can be summarized into two crucial steps: knowledge retrieval and semantic parsing. However, three core challenges remain: inefficient knowledge retrieval, mistakes of retrieval adversely impacting semantic parsing, and the complexity of previous KBQA methods. To tackle these challenges, we introduce ChatKBQA, a novel and simple generate-then-retrieve KBQA framework, which proposes first generating the logical form with fine-tuned LLMs, then retrieving and replacing entities and relations with an unsupervised retrieval method, to improve both generation and retrieval more directly. Experimental results show that ChatKBQA achieves new state-of-the-art performance on standard KBQA datasets, WebQSP, and CWQ. This work can also be regarded as a new paradigm for combining LLMs with knowledge graphs (KGs) for interpretable and knowledge-required question answering. Our code is publicly available. © 2024 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Knowledge graph; Semantics; Knowledge retrieval; Language model; Large-scales; Logical forms; Natural language questions; Question Answering; Retrieval methods; Semantic parsing; Simple++; State-of-the-art performance; Question answering},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Yang2024,
	author = {Yang, Yangrui and Chen, Sisi and Zhu, Yaping and Liu, Xuemei and Pan, Shifeng and Wang, Xin},
	title = {Intelligent question answering for water conservancy project inspection driven by knowledge graph and large language model collaboration; [Réponses intelligentes aux questions pour l'inspection des projets de conservation de l'eau, basées sur un graphique de connaissances et une collaboration sur un grand modèle de langage]},
	year = {2024},
	journal = {LHB: Hydroscience Journal},
	volume = {110},
	number = {1},
	doi = {10.1080/27678490.2024.2397337},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206669084&doi=10.1080%2f27678490.2024.2397337&partnerID=40&md5=b0b5a79136d8477da6f9f631dc473dbf},
	abstract = {Engineering inspection is of great significance to ensure the safe operation of the project. However, the unclear query statements of the detectors pose a challenge to the intelligent question answering task. Existing knowledge graph-based question-answering systems face issues of vocabulary limitations and reliance on fixed templates. Solely relying on Large Language Models (LLMs) for questioning introduces noise and randomness due to their extensive knowledge base. Therefore, this paper proposes a novel approach that synergistically employs both knowledge graphs and LLMs for intelligent question-answering in hydroengineering inspection. The method divides the overall task into five units, progressively clarifying query statements for accurate answers. Leveraging LLM’s vast prior knowledge, robust semantic understanding, and contextual learning mitigates issues related to vocabulary limitations and template dependence. Simultaneously, the knowledge contained in the graph is integrated into an optimal clarification path and transferred to LLM to address noise and randomness, thereby enhancing the efficiency of the clarification process. Benchmark experiments demonstrate that the proposed method achieves Mean Reciprocal Rank (MRR), Mean Average Precision (MAP), Precision, and Recall metrics all above 0.73. The results affirm the method’s effectiveness in improving the accuracy of intelligent question-answering in hydroengineering inspection, with potential implications for similar applications in other domains of hydraulic engineering. © 2024 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.},
	author_keywords = {clarification process; Engineering inspection; intelligent question answering; knowledge graph; large language models},
	keywords = {experimental study; hydraulic property; model validation; planning method; questionnaire survey; water management},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{2024,
	title = {28th International Conference on Theory and Practice of Digital Libraries, TPDL 2024},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {15178 LNCS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206271537&partnerID=40&md5=e4bc400ed0beb9c91fdc300a3068b3f2},
	abstract = {The proceedings contain 43 papers. The special focus in this conference is on Theory and Practice of Digital Libraries. The topics include: A Reputation System for Scientific Contributions Based on a Token Economy; bibliotheca Eugeniana Digital—Unveiling and Visualizing the Treasures of Prince Eugene of Savoy’s Library; comparative Analysis of Evaluation Measures for Scientific Text Simplification; promoting Interoperability on the Datasets of the Arrowheads Findings of the Chalcolithic and the Early/Middle Bronze Age; tracing the Retraction Cascade: Identifying Non-retracted but Potentially Retractable Articles; mapping Techniques for an Automated Library Classification: The Case Study of Library Loans at Bibliotheca Hertziana; LIT: Label-Informed Transformers on Token-Based Classification; Improving Retrieval and Expression of Iconographical and Iconological Semantic Statements: An Extension of the ICON Ontology; scholarly Quality Measurements: A Systematic Literature Review; assessing the Accessibility and Usability of Web Archives for Blind Users; leveraging Transfer Learning for Article Segmentation in Historical Newspapers; Multi-dimensional Edge-Embedded GCNs for Arabic Text Classification; LIAS: Layout Information-Based Article Separation in Historical Newspapers; CALM: Context Augmentation with Large Language Model for Named Entity Recognition; database Approaches to the Modelling and Querying of Musical Scores: A Survey; Content-Based Dataset Retrieval Methods: Reproducibility of the ACORDAR Test Collection; enhancing Identification of Scholarly Reference on YouTube: Method Development and Analysis of External Link Characteristics; mining Literary Trends: A Tool for Digital Library Analysis; PRET19: Automatic Recognition and Indexing of Handwritten Loan Registers from 19th Century Parisian Universities; leveraging Open Large Language Models for Historical Named Entity Recognition; Enriching Archival Linked Data Descriptions with Information from Wikidata and DBpedia; OpenPSS: An Open Page Stream Segmentation Benchmark.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Zhang2024,
	author = {Zhang, Mingtao and Yang, Guoli and Liu, Yi and Shi, Jing and Bai, Xiaoying},
	title = {Knowledge graph accuracy evaluation: an LLM-enhanced embedding approach},
	year = {2024},
	journal = {International Journal of Data Science and Analytics},
	doi = {10.1007/s41060-024-00661-3},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205842003&doi=10.1007%2fs41060-024-00661-3&partnerID=40&md5=640899f9692c8e600b2bed076720ae99},
	abstract = {As an effective way for knowledge representation and knowledge storage, knowledge graph has been widely used in various fields. However, with the rapid increase of scale and volume of various knowledge graphs, there will inevitably be some knowledge quality matters. To evaluate the accuracy of knowledge graph effectively and efficiently, a common paradigm is to match the facts in knowledge graph with specific external knowledge. In this study, an LLM-enhanced (large language model enhanced) embedding framework is designed, integrating the verification ability of large language models to further evaluate the embedding results. First an optimized embedding model is proposed to make use of knowledge graph’s internal structural information to measure whether the relation of a given triplet is probably founded. Then, the triplets which have less paths to support themselves are selected as the questionable ones, as their correctness cannot be determined confidently. Finally, the questionable triplets are filtered, and LLMs are adopted for further fact verification as external knowledge. The above three parts are aggregated to achieve the automated, accurate and efficient evaluation for knowledge graphs. © The Author(s), under exclusive licence to Springer Nature Switzerland AG 2024.},
	author_keywords = {Embedding learning; Knowledge graph accuracy; Large language models},
	keywords = {Data accuracy; Graph embeddings; Accuracy evaluation; Embedding learning; Embeddings; External knowledge; Knowledge graph accuracy; Knowledge graphs; Knowledge storage; Knowledge-representation; Language model; Large language model; Knowledge graph},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Chang2024,
	author = {Chang, Eunsuk and Sung, Sumi},
	title = {Use of SNOMED CT in Large Language Models: Scoping Review},
	year = {2024},
	journal = {JMIR Medical Informatics},
	volume = {12},
	doi = {10.2196/62924},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207323832&doi=10.2196%2f62924&partnerID=40&md5=dcc96bceeff813d856038f8d12fe4fec},
	abstract = {Background: Large language models (LLMs) have substantially advanced natural language processing (NLP) capabilities but often struggle with knowledge-driven tasks in specialized domains such as biomedicine. Integrating biomedical knowledge sources such as SNOMED CT into LLMs may enhance their performance on biomedical tasks. However, the methodologies and effectiveness of incorporating SNOMED CT into LLMs have not been systematically reviewed. Objective: This scoping review aims to examine how SNOMED CT is integrated into LLMs, focusing on (1) the types and components of LLMs being integrated with SNOMED CT, (2) which contents of SNOMED CT are being integrated, and (3) whether this integration improves LLM performance on NLP tasks. Methods: Following the PRISMA-ScR (Preferred Reporting Items for Systematic Reviews and Meta-Analyses extension for Scoping Reviews) guidelines, we searched ACM Digital Library, ACL Anthology, IEEE Xplore, PubMed, and Embase for relevant studies published from 2018 to 2023. Studies were included if they incorporated SNOMED CT into LLM pipelines for natural language understanding or generation tasks. Data on LLM types, SNOMED CT integration methods, end tasks, and performance metrics were extracted and synthesized. Results: The review included 37 studies. Bidirectional Encoder Representations from Transformers and its biomedical variants were the most commonly used LLMs. Three main approaches for integrating SNOMED CT were identified: (1) incorporating SNOMED CT into LLM inputs (28/37, 76%), primarily using concept descriptions to expand training corpora; (2) integrating SNOMED CT into additional fusion modules (5/37, 14%); and (3) using SNOMED CT as an external knowledge retriever during inference (5/37, 14%). The most frequent end task was medical concept normalization (15/37, 41%), followed by entity extraction or typing and classification. While most studies (17/19, 89%) reported performance improvements after SNOMED CT integration, only a small fraction (19/37, 51%) provided direct comparisons. The reported gains varied widely across different metrics and tasks, ranging from 0.87% to 131.66%. However, some studies showed either no improvement or a decline in certain performance metrics. Conclusions: This review demonstrates diverse approaches for integrating SNOMED CT into LLMs, with a focus on using concept descriptions to enhance biomedical language understanding and generation. While the results suggest potential benefits of SNOMED CT integration, the lack of standardized evaluation methods and comprehensive performance reporting hinders definitive conclusions about its effectiveness. Future research should prioritize consistent reporting of performance comparisons and explore more sophisticated methods for incorporating SNOMED CT’s relational structure into LLMs. In addition, the biomedical NLP community should develop standardized evaluation frameworks to better assess the impact of ontology integration on LLM performance. ©Eunsuk Chang, Sumi Sung.},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{2024,
	title = {17th International Conference on Knowledge Science, Engineering and Management, KSEM 2024},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14887 LNAI},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206256538&partnerID=40&md5=4e94b76f37f5d17bc2cec8d45b938c71},
	abstract = {The proceedings contain 160 papers. The special focus in this conference is on Knowledge Science, Engineering and Management. The topics include: EE-LCE: An Event Extraction Framework Based on LLM-Generated CoT Explanation; attention and Learning Features-Enhanced Knowledge Tracing; An MLM Decoding Space Enhancement for Legal Document Proofreading; meta-pruning: Learning to Prune on Few-Shot Learning; knowledge-Informed Molecular Learning: A Survey on Paradigm Transfer; GenFlowchart: Parsing and Understanding Flowchart Using Generative AI; DSCVSR: A Lightweight Video Super-Resolution for Arbitrary Magnification; programming Knowledge Tracing with Context and Structure Integration; an Konwledge-Based Semi-supervised Active Learning Method for Precision Pest Disease Diagnostic; multi-label Feature Selection with Adaptive Subspace Learning; User Story Classification with Machine Learning and LLMs; PTMA: Pre-trained Model Adaptation for Transfer Learning; optimization Strategies for Knowledge Graph Based Distractor Generation; reinforced Subject-Aware Graph Neural Network for Related Work Generation; EFCC-IeT: Cross-Modal Electronic File Content Correlation via Image-Enhanced Text; multi-relation Neural Network Recommendation Model Based on Knowledge Graph Embedding Algorithm; link Prediction Based on Deep Global Information in Heterogeneous Graph; subject Knowledge Entity Relationship Extraction Based on Multi-feature Fusion and Relation Specific Horns Tagging; a Human-Computer Negotiation Model Based on Q-Learning; affine Transformation-Based Knowledge Graph Embedding; integrating Prior Scenario Knowledge for Composition Review Generation; distant Supervised Relation Extraction on Pre-train Model with Improved Multi-label Attention Mechanism; sEMG-Based Multi-view Feature-Constrained Representation Learning; vicinal Data Augmentation for Classification Model via Feature Weaken; STM: An Improved Peak Price Tracking-Based Online Portfolio Selection Algorithm; spatiotemporal Dependence Learning with Meteorological Context for Transportation Demand Prediction; automatic Meter Pointer Reading Based on Knowledge Distillation; multi-table Question Answering Method Based on Correlation Evaluation and Precomputed Cube; a Joint Multi-task Learning Model for Web Table-to-Knowledge Graph Matching; an In-Context Schema Understanding Method for Knowledge Base Question Answering.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Wu2024,
	author = {Wu, Guanchen and Ling, Chen and Graetz, Ilana and Zhao, Liang},
	title = {Ontology extension by online clustering with large language model agents},
	year = {2024},
	journal = {Frontiers in Big Data},
	volume = {7},
	doi = {10.3389/fdata.2024.1463543},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206991474&doi=10.3389%2ffdata.2024.1463543&partnerID=40&md5=c6e9195c8845a4d66d81ebb4578116b4},
	abstract = {An ontology is a structured framework that categorizes entities, concepts, and relationships within a domain to facilitate shared understanding, and it is important in computational linguistics and knowledge representation. In this paper, we propose a novel framework to automatically extend an existing ontology from streaming data in a zero-shot manner. Specifically, the zero-shot ontology extension framework uses online and hierarchical clustering to integrate new knowledge into existing ontologies without substantial annotated data or domain-specific expertise. Focusing on the medical field, this approach leverages Large Language Models (LLMs) for two key tasks: Symptom Typing and Symptom Taxonomy among breast and bladder cancer survivors. Symptom Typing involves identifying and classifying medical symptoms from unstructured online patient forum data, while Symptom Taxonomy organizes and integrates these symptoms into an existing ontology. The combined use of online and hierarchical clustering enables real-time and structured categorization and integration of symptoms. The dual-phase model employs multiple LLMs to ensure accurate classification and seamless integration of new symptoms with minimal human oversight. The paper details the framework's development, experiments, quantitative analyses, and data visualizations, demonstrating its effectiveness in enhancing medical ontologies and advancing knowledge-based systems in healthcare. Copyright © 2024 Wu, Ling, Graetz and Zhao.},
	author_keywords = {large language model; medical ontology; online hierarchical clustering; ontology extension; zero-shot classification},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@CONFERENCE{Zhou202484,
	author = {Zhou, Jiehan and Shao, Kai and Yu, Changrong and Hao, Yixue and Hu, Long and Chen, Min and Zhu, Haibin},
	title = {MDEA: Modeling Depressive Emotions Aligned with Knowledge Graphs and Large Language Models},
	year = {2024},
	journal = {Canadian Conference on Electrical and Computer Engineering},
	pages = {84 – 85},
	doi = {10.1109/CCECE59415.2024.10667092},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204982733&doi=10.1109%2fCCECE59415.2024.10667092&partnerID=40&md5=5238935c9bd79c3b91ffd59c2d8eb145},
	abstract = {This paper introduces a novel framework for Modeling Depressive Emotions Aligned with knowledge graphs and Large Language Models (MDEA), aiming at enhancing the accuracy and interpretability of diagnosing and predicting depressive emotions. Experimental results demonstrate the outstanding performance of graph neural networks based on knowledge graphs in emotion analysis and depression detection.  © 2024 IEEE.},
	author_keywords = {Depression Diagnosis; Knowledge Graphs; Large Language Models},
	keywords = {Graph neural networks; Modeling languages; Depression diagnose; Emotion analysis; Graph neural networks; Interpretability; Knowledge graphs; Language model; Large language model; Network-based; Performance; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@BOOK{Würsch2024153,
	author = {Würsch, Maxime and David, Dimitri Percia and Mermoud, Alain},
	title = {Monitoring Emerging Trends in LLM Research},
	year = {2024},
	journal = {Large Language Models in Cybersecurity: Threats, Exposure and Mitigation},
	pages = {153 – 161},
	doi = {10.1007/978-3-031-54827-7_17},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207186959&doi=10.1007%2f978-3-031-54827-7_17&partnerID=40&md5=6db4195d846eadbe913c81daea1e8856},
	abstract = {Established methodologies for monitoring and forecasting trends in technological development fall short of capturing advancements in Large Language Models (LLMs). This chapter suggests a complementary and alternative approach to mitigate this concern. Traditional indicators, such as search volumes and citation frequencies, are demonstrated to inadequately reflect the rapid evolution of LLMrelated technologies due to biases, semantic drifts, and inherent lags in data documentation. Our presented methodology analyzes the proximity of technological terms related to LLMs, leveraging the OpenAlex and arXiv databases, and focuses on extracting nouns from scientific papers to provide a nuanced portrayal of advancements in LLM technologies. The approach aims to counteract the inherent lags in data, accommodate semantic drift, and distinctly differentiate between various topics, offering both retrospective and prospective insights in their analytical purview. The insights derived underline the need for refined, robust, adaptable, and precise forecasting models as LLMs intersect with domains like cyber defense. At the same time, they are considering the limitations of singular ontologies and integrating advanced anticipatory measures for a nuanced understanding of evolving LLM technologies. © The Editor(s) (if applicable) and The Author(s) 2024.},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Siwi202450,
	author = {Siwi, Satria and Wiharja, Kemas and Hafizh, Raihan},
	title = {Transforming Indonesian Geography Education Books into Knowledge Graphs Using ChatGPT LLMs},
	year = {2024},
	journal = {2024 12th International Conference on Information and Communication Technology, ICoICT 2024},
	pages = {50 – 56},
	doi = {10.1109/ICoICT61617.2024.10698487},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207420962&doi=10.1109%2fICoICT61617.2024.10698487&partnerID=40&md5=37a21432b53be2277871817ae0f4dc63},
	abstract = {This study demonstrates the construction of knowledge graphs from Indonesian geography education books using ChatGPT Large Language Models (LLMs) and Neo4j for visualization. The primary objective is to convert unstructured PDF text into structured, interactive knowledge representations to enhance learning experiences. The methodology involves extracting entities, relationships, and triples from the text, and organizing them into coherent knowledge graphs. Evaluations on four individual datasets and a combined dataset used Mean Reciprocal Rank (MRR) and HITS@10 metrics to assess performance. The results showed strong performance, with MRR values between 0.7087 and 0.8592 and HITS@10 values between 0.9274 and 1.0. The combined dataset achieved an MRR of 0.7695 and HITS@10 of 0.9570. These findings underscore the effectiveness of ChatGPT LLMs in converting unstructured text into dynamic, interactive knowledge representations, thereby enhancing the accessibility and utility of educational content. Confidence in using ChatGPT is supported by its high accuracy in data extraction, with minimal inappropriate references generated, which were easily manageable. ChatGPT was chosen over other AI tools due to its superior text generation and entity recognition capabilities. Future work will focus on optimizing the extraction processes, expanding the dataset scope, and further validating and improving the approach to ensure broader applicability and effectiveness in educational settings. © 2024 IEEE.},
	author_keywords = {ChatGPT; HITS@10; Knowledge Graphs; Large Language Models (LLMs); Mean Reciprocal Rank (MRR); NLP},
	keywords = {Contrastive Learning; ChatGPT; Geography educations; HITS@10; Knowledge graphs; Knowledge-representation; Language model; Large language model; Mean reciprocal rank; Mean reciprocal ranks; Performance; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Arikkat2024348,
	author = {Arikkat, Dincy R. and Vinod, P. and K. A., Rafidha Rehiman and Nicolazzo, Serena and Nocera, Antonino and Conti, Mauro},
	title = {Relation Extraction Techniques in Cyber Threat Intelligence},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14762 LNCS},
	pages = {348 – 363},
	doi = {10.1007/978-3-031-70239-6_24},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205348424&doi=10.1007%2f978-3-031-70239-6_24&partnerID=40&md5=18066e24e82a217d1272c0a3ba676677},
	abstract = {Cyber Threat Intelligence (CTI) provides a structured and interconnected model for threat information through Cybersecurity Knowledge Graphs. This allows researchers and practitioners to represent and organize complex relationships and entities in a more coherent form. Above all, the discovery of hidden relationships between different CTI entities, such as threat actors, malware, infrastructure, and attacks, is becoming a crucial task in this domain, facilitating proactive defense measures and helping to identify Tactics, Techniques, and Procedures (TTPs) employed by malicious parties. In this paper, we provide a Systematization of Knowledge (SoK) to analyze the existing literature and give insights into the important CTI task of Relation Extraction. In particular, we design a categorization of the relations used in CTI; we analyze the techniques employed for their extraction, the emerging trends and open issues in this context, and the main future directions. This work provides a novel and fresh perspective that can help the reader understand how relationships among entities can be schematized to provide a better view of the cyber threat landscape. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {Cyber Threat Intelligence; Dependancy Parsing; Entities; Large Language Model; Relation Extraction},
	keywords = {Network intrusion; Phishing; Cybe threat intelligence; Cyber threats; Dependancy; Dependancy parsing; Entity; Extraction techniques; Language model; Large language model; Relation extraction; Structured modeling; Cyber attacks},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Paz-Argaman20242259,
	author = {Paz-Argaman, Tzuf and Palowitch, John and Kulkarni, Sayali and Tsarfaty, Reut and Baldridge, Jason},
	title = {Into the Unknown: Generating Geospatial Descriptions for New Environments},
	year = {2024},
	journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
	pages = {2259 – 2273},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205282331&partnerID=40&md5=658cf906628447a087a745f5f7f0501d},
	abstract = {Similar to vision-and-language navigation (VLN) tasks that focus on bridging the gap between vision and language for embodied navigation, the new Rendezvous (RVS) task requires reasoning over allocentric spatial relationships (independent of the observer's viewpoint) using non-sequential navigation instructions and maps. However, performance substantially drops in new environments with no training data. Using opensource descriptions paired with coordinates (e.g., Wikipedia) provides training data but suffers from limited spatially-oriented text resulting in low geolocation resolution. We propose a large-scale augmentation method for generating high-quality synthetic data for new environments using readily available geospatial data. Our method constructs a grounded knowledge-graph, capturing entity relationships. Sampled entities and relations (“shop north of school”) generate navigation instructions via (i) generating numerous templates using context-free grammar (CFG) to embed specific entities and relations; (ii) feeding the entities and relation into a large language model (LLM) for instruction generation. A comprehensive evaluation on RVS, showed that our approach improves the 100-meter accuracy by 45.83% on unseen environments. Furthermore, we demonstrate that models trained with CFG-based augmentation achieve superior performance compared with those trained with LLM-based augmentation, both in unseen and seen environments. These findings suggest that the potential advantages of explicitly structuring spatial information for text-based geospatial reasoning in previously unknown, can unlock data-scarce scenarios. © 2024 Association for Computational Linguistics.},
	keywords = {Context sensitive grammars; Knowledge graph; Context-free grammars; Geo-spatial; Geolocations; Language model; Navigation tasks; Open-source; Performance; Spatial relationships; Training data; Wikipedia; Context free grammars},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Hwang20241928,
	author = {Hwang, EunJeong and Shwartz, Vered and Gutfreund, Dan and Thost, Veronika},
	title = {A Graph per Persona: Reasoning about Subjective Natural Language Descriptions},
	year = {2024},
	journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
	pages = {1928 – 1942},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205287221&partnerID=40&md5=50a47467512867b66da4497ae751f1e3},
	abstract = {Reasoning about subjective natural language descriptions, such as opinions and preferences, is a challenging topic that largely remains unsolved to date. In particular, state-of-the-art large language models (LLMs) perform disappointingly in this task, show strong biases, and do not meet the interpretability requirements often needed in these kinds of applications. We propose a novel approach for reasoning about subjective knowledge that integrates potential and implicit meanings and explicitly models the relational nature of the information. We apply supervised graph learning, offer explanations for the model's reasoning, and show that our model performs well across all 15 topics of OpinionQA, outperforming several prominent LLMs. Our detailed analysis further shows its unique advantages and the complementary nature it offers in comparison to LLMs. © 2024 Association for Computational Linguistics.},
	keywords = {Adversarial machine learning; Computational linguistics; Knowledge graph; Self-supervised learning; Translation (languages); Interpretability; Language description; Language model; Model reasonings; Natural languages; State of the art; Contrastive Learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Li2024382,
	author = {Li, Yingshu and Wang, Zhanyu and Liu, Yunyi and Wang, Lei and Liu, Lingqiao and Zhou, Luping},
	title = {KARGEN: Knowledge-Enhanced Automated Radiology Report Generation Using Large Language Models},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) },
	volume = {15005 LNCS},
	pages = {382 – 392},
	doi = {10.1007/978-3-031-72086-4_36},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206578625&doi=10.1007%2f978-3-031-72086-4_36&partnerID=40&md5=f24ba568e623824b2cb4466b5c62dd91},
	abstract = {Harnessing the robust capabilities of Large Language Models (LLMs) for narrative generation, logical reasoning, and common-sense knowledge integration, this study delves into utilizing LLMs to enhance automated radiology report generation (R2Gen). Despite the wealth of knowledge within LLMs, efficiently triggering relevant knowledge within these large models for specific tasks like R2Gen poses a critical research challenge. This paper presents KARGEN, a Knowledge-enhanced Automated radiology Report GENeration framework based on LLMs. Utilizing a frozen LLM to generate reports, the framework integrates a knowledge graph to unlock chest disease-related knowledge within the LLM to enhance the clinical utility of generated reports. This is achieved by leveraging the knowledge graph to distill disease-related features in a designed way. Since a radiology report encompasses both normal and disease-related findings, the extracted graph-enhanced disease-related features are integrated with regional image features, attending to both aspects. We explore two fusion methods to automatically prioritize and select the most relevant features. The fused features are employed by LLM to generate reports that are more sensitive to diseases and of improved quality. Our approach demonstrates promising results on the MIMIC-CXR and IU-Xray datasets. Our code will be available on GitHub. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {Large Language Models; Medical Domain Knowledge Graph; Radiology Report Generation},
	keywords = {C (programming language); Domain knowledge; Knowledge graphs; Language model; Large language model; Medical domain knowledge graph; Medical domains; Radiology report generation; Radiology reports; Report generation; Robust capability; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Yang2024,
	author = {Yang, Jiaxin and Zhuang, Xinhao and Li, Zhenqi and Xiong, Gang and Xu, Ping and Ling, Yunchao and Zhang, Guoqing},
	title = {CPMKG: a condition-based knowledge graph for precision medicine},
	year = {2024},
	journal = {Database},
	volume = {2024},
	doi = {10.1093/database/baae102},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205275926&doi=10.1093%2fdatabase%2fbaae102&partnerID=40&md5=1c5dcc56b63879d0e71e8b4a48c2f9a5},
	abstract = {Personalized medicine tailors treatments and dosages based on a patient's unique characteristics, particularly its genetic profile. Over the decades, stratified research and clinical trials have uncovered crucial drug-related information - such as dosage, effectiveness, and side effects - affecting specific individuals with particular genetic backgrounds. This genetic-specific knowledge, characterized by complex multirelationships and conditions, cannot be adequately represented or stored in conventional knowledge systems. To address these challenges, we developed CPMKG, a condition-based platform that enables comprehensive knowledge representation. Through information extraction and meticulous curation, we compiled 307 614 knowledge entries, encompassing thousands of drugs, diseases, phenotypes (complications/side effects), genes, and genomic variations across four key categories: drug side effects, drug sensitivity, drug mechanisms, and drug indications. CPMKG facilitates drug-centric exploration and enables condition-based multiknowledge inference, accelerating knowledge discovery through three pivotal applications. To enhance user experience, we seamlessly integrated a sophisticated large language model that provides textual interpretations for each subgraph, bridging the gap between structured graphs and language expressions. With its comprehensive knowledge graph and user-centric applications, CPMKG serves as a valuable resource for clinical research, offering drug information tailored to personalized genetic profiles, syndromes, and phenotypes. Database URL: https://www.biosino.org/cpmkg/  © 2024 The Author(s). Published by Oxford University Press.},
	keywords = {Humans; Knowledge Bases; Precision Medicine; human; knowledge base; personalized medicine; procedures},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Hello2024876,
	author = {Hello, Nour and Di Lorenzo, Paolo and Strinati, Emilio Calvanese},
	title = {Semantic Communication Enhanced by Knowledge Graph Representation Learning},
	year = {2024},
	journal = {IEEE Workshop on Signal Processing Advances in Wireless Communications, SPAWC},
	pages = {876 – 880},
	doi = {10.1109/SPAWC60668.2024.10694291},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207074283&doi=10.1109%2fSPAWC60668.2024.10694291&partnerID=40&md5=119640d2c28fd4d59d40fa1ee919a682},
	abstract = {This paper investigates the advantages of representing and processing semantic knowledge extracted into graphs within the emerging paradigm of semantic communications. The proposed approach leverages semantic and pragmatic aspects, incorporating recent advances on large language models (LLMs) to achieve compact representations of knowledge to be processed and exchanged between intelligent agents. This is accomplished by using the cascade of LLMs and graph neural networks (GNNs) as semantic encoders, where information to be shared is selected to be meaningful at the receiver. The embedding vectors produced by the proposed semantic encoder represent information in the form of triplets: nodes (semantic concepts entities), edges(relations between concepts), nodes. Thus, semantic information is associated with the representation of relationships among elements in the space of semantic concept abstractions. In this paper, we investigate the potential of achieving high compression rates in communication by incorporating relations that link elements within graph embeddings. We propose sending semantic symbols solely equivalent to node embeddings through the wireless channel and inferring the complete knowledge graph at the receiver. Numerical simulations illustrate the effectiveness of leveraging knowledge graphs to semantically compress and transmit information. © 2024 IEEE.},
	author_keywords = {graph neural network; knowledge graph; large language models; Semantic communication},
	keywords = {Chatbots; Graph embeddings; Graph neural networks; Semantics; Compact representation; Embeddings; Graph neural networks; Graph representation; Knowledge graphs; Language model; Large language model; Semantic communication; Semantic concept; Semantics knowledge; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@CONFERENCE{Zia2024101,
	author = {Zia, Ghezal Ahmad Jan and Valdestilhas, Andre and Torres, Benjamí Moreno and Kruschwitz, Sabine},
	title = {Leveraging large language models for automated knowledge graphs generation in non-destructive testing},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3760},
	pages = {101 – 110},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204975994&partnerID=40&md5=3a0c5b49d90a7df3acf65d870ce8b225},
	abstract = {This paper presents an innovative approach for the automatic generation of Knowledge Graphs (KGs) from heterogeneous scientific articles in the domain of Non-Destructive Testing (NDT) applied to building materials. Our methodology leverages large language models (LLMs) to extract and semantically relate concepts from diverse sources. We developed material-specific agents for concrete, wood, steel, and bricks, each equipped with a curated glossary of terms to ensure domain accuracy. These agents process PDF documents, extracting relevant information on deterioration mechanisms, physical changes, and applicable NDT methods. The extracted data is then normalized, validated, and structured into a Neo4j graph database, forming a comprehensive KG. Our results demonstrate the system's ability to automatically discover and represent intricate relationships between materials, deterioration mechanisms, physical changes, and NDT techniques. The generated KG successfully captures complex interactions, such as the applicability of specific NDT methods to various materials under different deterioration conditions. This work not only highlights the potential of KGs in enhancing knowledge discovery and representation in NDT research but also provides a scalable framework for extending this approach to other scientific domains. © 2024 CEUR-WS. All rights reserved.},
	author_keywords = {Data Interoperability; Large Language Model; Linked Open Data; Materials Science and Engineering; RDF; Semantic Web},
	keywords = {Automatic test pattern generation; Concrete testing; Deterioration; Metadata; Network security; Semantics; Data interoperability; Deterioration mechanism; Knowledge graphs; Language model; Large language model; Linked open data; Materials science and engineering; Non destructive testing; RDF; Semantic-Web; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Iga202440,
	author = {Iga, Vasile-Ionut-Remus},
	title = {Integrating LLMs with Knowledge Graphs-enhanced Task-Oriented Dialogue Systems},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3767},
	pages = {40 – 51},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207046142&partnerID=40&md5=818570425f217889185ca2e4d117817c},
	abstract = {Large Language Models (LLM) have become the state-of-the-art natural language processing systems. Their emergent abilities paved the way for dialogue systems capable of understanding and solving users’ specific tasks, ranging from arithmetic problems to simple chatting, all expressed in natural language. However, for specific domains, research has shown that LLMs cannot directly substitute Task-Oriented Dialogue Systems (TOD). TOD Systems aims to master a specific domain or company, enabling communication by natural language. Thus, this research project focuses on building personalized TODS with the help of artificial intelligence, using LLMs grounded with Temporal Knowledge Graphs. We assess the temporal validity of facts in the KG through temporal timestamps. To capture the dynamics of a company or domain, business processes are modeled with BPMN, offering the possibility of converting them to KGs. Finally, the TOD System will be able to grow a domain-specific KG and reason over it, leveraging LLMs capabilities of solving KG-related tasks. © 2023 Copyright for this paper by its authors.},
	author_keywords = {Business Process Modeling; Knowledge Graph; Large Language Model; Task-Oriented Dialogue System},
	keywords = {Administrative data processing; Modeling languages; Natural language processing systems; Problem oriented languages; Speech enhancement; Business process modeling; Dialogue systems; Knowledge graphs; Language model; Language processing systems; Large language model; Natural languages; State of the art; Task-oriented; Task-oriented dialog system; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Nguyen20242862,
	author = {Nguyen, Minh-Vuong and Luo, Linhao and Shiri, Fatemeh and Phung, Dinh and Li, Yuan-Fang and Vu, Thuy-Trang and Haffari, Gholamreza},
	title = {Direct Evaluation of Chain-of-Thought in Multi-hop Reasoning with Knowledge Graphs},
	year = {2024},
	journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
	pages = {2862 – 2883},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205305010&partnerID=40&md5=e1eccf2609eaf09b038701789e9a2aed},
	abstract = {Large language models (LLMs) have demonstrated strong reasoning abilities when prompted to generate chain-of-thought (CoT) explanations alongside answers. However, previous research on evaluating LLMs has solely focused on answer accuracy, neglecting the correctness of the generated CoT. In this paper, we delve deeper into the CoT reasoning capabilities of LLMs in multi-hop question answering by utilizing knowledge graphs (KGs). We propose a novel discriminative and generative CoT evaluation paradigm to assess LLMs' knowledge of reasoning and the accuracy of the generated CoT. Through experiments conducted on 5 different families of LLMs across 2 multi-hop question-answering datasets, we find that LLMs possess sufficient knowledge to perform reasoning. However, there exists a significant disparity between answer accuracy and faithfulness of the CoT generated by LLMs, indicating that they often arrive at correct answers through incorrect reasoning. © 2024 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Question answering; Direct evaluations; Knowledge graphs; Language model; Model knowledge; Multi-hops; Question Answering; Reasoning ability; Reasoning capabilities; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Amato202429,
	author = {Amato, Flora and Benfenati, Domenico and Cirillo, Egidia and De Filippis, Giovanni Maria and Fonisto, Mattia and Galli, Antonio and Marrone, Stefano and Marassi, Lidia and Moscato, Vincenzo and Patwardhan, Narendra and Moccardi, Alberto and Pascarella, Antonio Elia and Rinaldi, Antonio M. and Russo, Cristiano and Sansone, Carlo and Tommasino, Cristian},
	title = {Advancements and Challenges in Generative AI: Architectures, Applications, and Ethical Implications},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3762},
	pages = {29 – 34},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205529917&partnerID=40&md5=c3888d89f543ce8a6c97585da8113641},
	abstract = {Architecture, classification, and major applications of Generative AI interfaces, specifically chatbots, are presented in this paper. Research paper details how the Generative AI interfaces work with various Generative AI approaches and show the architecture and their working. On the other hand, the generative model is built using advanced machine learning techniques to build dynamic, contextually relevant responses automatically. On the other hand, the retrieval-based model builds up with dependency on a predefined response library. The paper also discusses the use of Generative AI to populate Multimedia Knowledge Graphs (KGs), presenting technologies based on the semantic analysis of deep learning and NoSQL to more effectively integrate and retrieve data. The social and ethical challenges that come with the deployment of generative models are critically reviewed. These dialogues bring forward the balance that has to be maintained between progress and necessity in technological advancements, for which the call for ethical responsibility in developing AI is made. The paper presents a comprehensive review of state-of-the-art Generative AI with special focus on the promises and pitfalls in Generative AI research related to both natural language processing and knowledge management. © 2024 Copyright for this paper by its authors.},
	author_keywords = {artificial intelligence; Generative AI},
	keywords = {Adversarial machine learning; Contrastive Learning; Chatbots; Ethical implications; Generative AI; Generative model; Knowledge graphs; Machine learning techniques; Research papers; Semantic analysis; Technological advancement; Technology-based; Generative adversarial networks},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Gao20246719,
	author = {Gao, Yifu and Qiao, Linbo and Kan, Zhigang and Wen, Zhihua and He, Yongquan and Li, Dongsheng},
	title = {Two-stage Generative Question Answering on Temporal Knowledge Graph Using Large Language Models},
	year = {2024},
	journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
	pages = {6719 – 6734},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205285579&partnerID=40&md5=9de6c3e1f0adffa1656cd4ae8c7faecd},
	abstract = {Temporal knowledge graph question answering (TKGQA) poses a significant challenge task, due to the temporal constraints hidden in questions and the answers sought from dynamic structured knowledge. Although large language models (LLMs) have made considerable progress in their reasoning ability over structured data, their application to the TKGQA task is a relatively unexplored area. This paper first proposes a novel generative temporal knowledge graph question answering framework, GenTKGQA, which guides LLMs to answer temporal questions through two phases: Subgraph Retrieval and Answer Generation. First, we exploit LLM's intrinsic knowledge to mine temporal constraints and structural links in the questions without extra training, thus narrowing down the subgraph search space in both temporal and structural dimensions. Next, we design virtual knowledge indicators to fuse the graph neural network signals of the subgraph and the text representations of the LLM in a non-shallow way, which helps the open-source LLM deeply understand the temporal order and structural dependencies among the retrieved facts through instruction tuning. Experimental results on two widely used datasets demonstrate the superiority of our model. © 2024 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Generative adversarial networks; Graph neural networks; Knowledge graph; Structured Query Language; Knowledge graphs; Language model; Question Answering; Question Answering Task; Reasoning ability; Structured data; Structured knowledge; Subgraphs; Temporal constraints; Temporal knowledge; Question answering},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Penkov2024272,
	author = {Penkov, Stanislav},
	title = {Mitigating Hallucinations in Large Language Models via Semantic Enrichment of Prompts: Insights from BioBERT and Ontological Integration},
	year = {2024},
	journal = {Proceedings of the International Conference Computational Linguistics in Bulgaria},
	pages = {272 – 276},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206264551&partnerID=40&md5=0831974af08e95cba6ebb47261f40da5},
	abstract = {The advent of Large Language Models (LLMs) has been transformative for natural language processing, yet their tendency to produce “hallucinations”-outputs that are factually incorrect or entirely fabricated-remains a significant hurdle. This paper introduces a proactive methodology for reducing hallucinations by strategically enriching LLM prompts. This involves identifying key entities and contextual cues from varied domains and integrating this information into the LLM prompts to guide the model towards more accurate and relevant responses. Leveraging examples from BioBERT for biomedical entity recognition and ChEBI for chemical ontology, we illustrate a broader approach that encompasses semantic prompt enrichment as a versatile tool for enhancing LLM output accuracy. By examining the potential of semantic and ontological enrichment in diverse contexts, we aim to present a scalable strategy for improving the reliability of AI-generated content, thereby contributing to the ongoing efforts to refine LLMs for a wide range of applications. © 2024, Institute for Bulgarian Language. All rights reserved.},
	author_keywords = {BioBERT Entity Recognition; Domain-Specific Ontologies; Hallucination Mitigation; Large Language Models (LLMs); Semantic Prompt Enrichment},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Tsaneva2024,
	author = {Tsaneva, Stefani and Dessì, Danilo and Osborne, Francesco and Sabou, Marta},
	title = {Enhancing Scientific Knowledge Graph Generation Pipelines with LLMs and Human-in-the-Loop},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3780},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207087893&partnerID=40&md5=37614b2efe50a57ed17ed8a264e581a1},
	abstract = {Scientific Knowledge Graphs have recently become a powerful tool for exploring the research landscape and assisting scientific inquiry. It is crucial to generate and validate these resources to ensure they offer a comprehensive and accurate representation of specific research fields. However, manual approaches are not scalable, while automated methods often result in lower-quality resources. In this paper, we investigate novel validation techniques to improve the accuracy of automated KG generation methodologies, leveraging both a human-in-the-loop (HiL) and a large language model (LLM)-in-the-loop. Using the automated generation pipeline of the Computer Science Knowledge Graph as a case study, we demonstrate that precision can be increased by 12% (from 75% to 87%) using only LLMs. Moreover, a hybrid approach incorporating both LLMs and HiL significantly enhances both precision and recall, resulting in a 4% increase in the F1 score (from 77% to 81%). © 2022 Copyright for this paper by its authors.},
	author_keywords = {Hybrid Human-AI Workflows; Knowledge Graph Evaluation; Large Language Models; Scientific Knowledge Graph},
	keywords = {Human-in-the-loop; Hybrid human-AI workflow; Knowledge graph evaluation; Knowledge graphs; Language model; Large language model; Scientific knowledge; Scientific knowledge graph; Work-flows; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Blanchard2024,
	author = {Blanchard, Marc and Venerito, Vincenzo and Ming Azevedo, Pedro and Hügle, Thomas},
	title = {Generative AI-based knowledge graphs for the illustration and development of mHealth self-management content},
	year = {2024},
	journal = {Frontiers in Digital Health},
	volume = {6},
	doi = {10.3389/fdgth.2024.1466211},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206974687&doi=10.3389%2ffdgth.2024.1466211&partnerID=40&md5=b88140544b248947fbf46bbf5aa7bbec},
	abstract = {Background: Digital therapeutics (DTx) in the form of mobile health (mHealth) self-management programs have demonstrated effectiveness in reducing disease activity across various diseases, including fibromyalgia and arthritis. However, the content of online self-management programs varies widely, making them difficult to compare. Aim: This study aims to employ generative artificial intelligence (AI)-based knowledge graphs and network analysis to categorize and structure mHealth content at the example of a fibromyalgia self-management program. Methods: A multimodal mHealth online self-management program targeting fibromyalgia and post-viral fibromyalgia-like syndromes was developed. In addition to general content, the program was customized to address specific features and digital personas identified through hierarchical agglomerative clustering applied to a cohort of 202 patients with chronic musculoskeletal pain syndromes undergoing multimodal assessment. Text files consisting of 22,150 words divided into 24 modules were used as the input data. Two generative AI web applications, ChatGPT-4 (OpenAI) and Infranodus (Nodus Labs), were used to create knowledge graphs and perform text network analysis, including 3D visualization. A sentiment analysis of 129 patient feedback entries was performed. Results: The ChatGPT-generated knowledge graph model provided a simple visual overview with five primary edges: “Mental health challenges”, “Stress and its impact”, “Immune system function”, “Long COVID and fibromyalgia” and “Pain management and therapeutic approaches”. The 3D visualization provided a more complex knowledge graph, with the term “pain” appearing as the central edge, closely connecting with “sleep”, “body”, and “stress”. Topical cluster analysis identified categories such as “chronic pain management”, “sleep hygiene”, “immune system function”, “cognitive therapy”, “healthy eating”, “emotional development”, “fibromyalgia causes”, and “deep relaxation”. Gap analysis highlighted missing links, such as between “negative behavior” and “systemic inflammation”. Retro-engineering of the self-management program showed significant conceptual similarities between the knowledge graph and the original text analysis. Sentiment analysis of free text patient comments revealed that most relevant topics were addressed by the online program, with the exception of social contacts. Conclusion: Generative AI tools for text network analysis can effectively structure and illustrate DTx content. Knowledge graphs are valuable for increasing the transparency of self-management programs, developing new conceptual frameworks, and incorporating feedback loops. 2024 Blanchard, Venerito, Ming Azevedo and Hügle.},
	author_keywords = {artificial intelligence; ChatGPT; chronic musculoskeletal pain syndromes; fibromyalgia; knowledge graph; large language model; mHealth (mobile health)},
	keywords = {Article; artificial intelligence; Brief Pain Inventory; ChatGPT; chronic pain; cognitive behavioral therapy; cohort analysis; depression; emotional development; endometriosis; Fear-Avoidance Beliefs Questionnaire; fibromyalgia; generative artificial intelligence-based knowledge graph; genetic predisposition; health care delivery; hierarchical clustering; Hospital Anxiety and Depression Scale; human; large language model; loneliness; long COVID; machine learning; mental health; mobile health; musculoskeletal pain; network analysis; obesity; Oswestry Disability Index; Pain Catastrophizing scale; posttraumatic stress disorder; proof of concept; self care; sentiment analysis; storytelling; stress management; Tampa scale for kinesiophobia; Toronto Alexithymia scale},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access}
}

@CONFERENCE{Xu202415496,
	author = {Xu, Ran and Cui, Hejie and Yu, Yue and Kan, Xuan and Shi, Wenqi and Zhuang, Yuchen and Wang, May D. and Jin, Wei and Ho, Joyce C. and Yang, Carl},
	title = {Knowledge-Infused Prompting: Assessing and Advancing Clinical Text Data Generation with Large Language Models},
	year = {2024},
	journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
	pages = {15496 – 15523},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205322427&partnerID=40&md5=1082b39f199b0991afedde3e7a55fb81},
	abstract = {Clinical natural language processing faces challenges like complex medical terminology and clinical contexts. Recently, large language models (LLMs) have shown promise in this domain. Yet, their direct deployment can lead to privacy issues and are constrained by resources. To address this challenge, we delve into synthetic clinical text generation with LLMs for clinical NLP tasks. We propose an innovative, resource-efficient approach, CLINGEN, which infuses knowledge into the process. Our model involves clinical knowledge extraction and context-informed LLM prompting. Both clinical topics and writing styles are drawn from external domain-specific knowledge graphs and LLMs to guide data generation. Our extensive empirical study across 8 clinical NLP tasks and 18 datasets reveals that CLINGEN consistently enhances performance across various tasks by 7.7%-8.7% on average, effectively aligning the distribution of real datasets and enriching the diversity of generated training instances. Our code is available at https://github.com/ritaranx/ClinGen. © 2024 Association for Computational Linguistics.},
	keywords = {Knowledge graph; Modeling languages; Natural language processing systems; Clinical knowledge; Data generation; Language model; Language processing; Medical terminologies; Natural languages; Privacy issue; Resource-efficient; Text data; Text generations; Computational linguistics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Bo2024169,
	author = {Bo, Lili and He, Yuting and Sun, Xiaobing and Ji, Wangjie and Wu, Xiaohan},
	title = {A Software Bug Fixing Approach Based on Knowledge-Enhanced Large Language Models},
	year = {2024},
	journal = {IEEE International Conference on Software Quality, Reliability and Security, QRS},
	pages = {169 – 179},
	doi = {10.1109/QRS62785.2024.00026},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206389176&doi=10.1109%2fQRS62785.2024.00026&partnerID=40&md5=36f5e62ff58fda7114f54d49fbc1bec5},
	abstract = {Software Bug Fixing is a time-consuming task in software development and maintenance. Despite the success of Large Language Models (LLMs) using in Automatic Program Repair (APR), they still have the limitations of generating patches with low accuracy and explainability. In this paper, we propose a software bug-fixing approach based on knowledge-enhanced large language models. First, we collect bugs as well as their fix information from bug tracking systems, such as Github and Stack Overflow. Then, we extract bug entities and inter-entity relationships using Named Entity Recognition (NER) to construct a Bug Knowledge Graph (BKG). Finally, we utilize LLMs (e.g., GPT-4) which is enhanced by the knowledge of the similar historical bugs as well as fix information from BKG to generate patches for new bugs. The experimental results show that the our approach can fix 28.52% (85\298) bugs correctly, which is significantly better than the state-of-the-art approaches. Furthermore, the generated patches are explainable and more credible. © 2024 IEEE.},
	author_keywords = {Bug fixing; Explainable; Generative AI; Knowledge Graph},
	keywords = {Computer software maintenance; Software design; Automatic programs; Bug tracking system; Bug-fixing; Explainable; Generative AI; Knowledge graphs; Language model; Software bug; Software development and maintenances; Time-consuming tasks; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Jiang20242986,
	author = {Jiang, Zhouyu and Zhong, Ling and Sun, Mengshu and Xu, Jun and Sun, Rui and Cai, Hui and Luo, Shuhan and Zhang, Zhiqiang},
	title = {Efficient Knowledge Infusion via KG-LLM Alignment},
	year = {2024},
	journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
	pages = {2986 – 2999},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205306891&partnerID=40&md5=c2e37010474d93f5adf758bbda753258},
	abstract = {To tackle the problem of domain-specific knowledge scarcity within large language models (LLMs), knowledge graph-retrieval-augmented method has been proven to be an effective and efficient technique for knowledge infusion. However, existing approaches face two primary challenges: knowledge mismatch between public available knowledge graphs and the specific domain of the task at hand, and poor information compliance of LLMs with knowledge graphs. In this paper, we leverage a small set of labeled samples and a large-scale corpus to efficiently construct domain-specific knowledge graphs by an LLM, addressing the issue of knowledge mismatch. Additionally, we propose a three-stage KG-LLM alignment strategy to enhance the LLM's capability to utilize information from knowledge graphs. We conduct experiments with a limited-sample setting on two biomedical question-answering datasets, and the results demonstrate that our approach outperforms existing baselines. © 2024 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Domain Knowledge; Question answering; Biomedical question answering; Domain-specific knowledge; Knowledge graphs; Language model; Large-scales; Model knowledge; Poor information; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{2024,
	title = {Sci-K 2024 - Proceedings of the 4th International Workshop on Scientific Knowledge: Representation, Discovery, and Assessment, co-located with 23rd International Semantic Web Conference, ISWC 2024},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3780},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207259002&partnerID=40&md5=663c9c0b51161d4788f2a6b9caa3bbd7},
	abstract = {The proceedings contain 9 papers. The topics discussed include: enhancing scientific knowledge graph generation pipelines with LLMs and human-in-the-loop; knowledge graph enabled scientific data repositories; identifying semantic relationships between research topics using large language models in a zero-shot learning setting; enhancing scientific discovery and decision-making: a knowledge graph-based research support system; DiTraRe: AI on a spider’s web. Interweaving disciplines for digitalization; federated querying of scholarly communication infrastructures; assessing the reliability and scientific rigor of references in Wikidata; ensuring fairness in machine learning projects; and skills and expertise in large organizations.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Yan20245378,
	author = {Yan, Quan and Duan, Junwen and Wang, Jianxin},
	title = {Multi-modal Concept Alignment Pre-training for Generative Medical Visual Question Answering},
	year = {2024},
	journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
	pages = {5378 – 5389},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205306777&partnerID=40&md5=970782d2ab4ade9dda77cb613b65b810},
	abstract = {Medical Visual Question Answering (Med-VQA) seeks to accurately respond to queries regarding medical images, a task particularly challenging for open-ended questions. This study unveils the Multi-modal Concept Alignment Pre-training (MMCAP) approach for generative Med-VQA, leveraging a knowledge graph sourced from medical image-caption datasets and the Unified Medical Language System. MMCAP advances the fusion of visual and textual medical knowledge via a graph attention network and a transformer decoder. Additionally, it incorporates a Type Conditional Prompt in the fine-tuning phase, markedly boosting the accuracy and relevance of answers to open-ended questions. Our tests on benchmark datasets illustrate MMCAP's superiority over existing methods, demonstrating its high efficiency in data-limited settings and effective knowledge-image alignment capability. © 2024 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Medical imaging; Visual languages; Concept alignments; Fine tuning; Image caption; Knowledge graphs; Medical knowledge; Multi-modal; Open-ended questions; Pre-training; Question Answering; Unified medical language systems; Question answering},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Gui2024485,
	author = {Gui, Zhou and Kuty, Layla and Harth, Andreas},
	title = {Design and Implementation of a Natural Language Interface for Controlling the Web of Things Devices},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14762 LNCS},
	pages = {485 – 499},
	doi = {10.1007/978-3-031-70239-6_33},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205337592&doi=10.1007%2f978-3-031-70239-6_33&partnerID=40&md5=f3da057c79d0e848a9661ea8eebdee51},
	abstract = {We present a systematic workflow for developing a Natural Language Interface (NLI) using Knowledge Graphs (KGs) and the Web of Things (WoT) specification as an abstraction layer. We first synthesize a data corpus from a given device interface description using manually created templates and parameter sheets. Then we paraphrase the synthesized data corpus with pre-trained Large Language Models (LLMs). The resulting corpus serves as training data for a text-to-code encoder-decoder neural network model, enabling the mapping of diverse natural language commands into an executable code format. To the best of our knowledge, no existing data corpus or NLI system has been tailored for WoT device interactions. Our work provides a baseline and can be extended to a broader range of real world WoT use cases. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {Knowledge Graphs; Large Language Models; Natural Language Interface; Web of Things},
	keywords = {Encoding (symbols); EXAPT (programming language); Natural language processing systems; Network coding; Specification languages; Web Design; Abstraction layer; Design and implementations; Device interfaces; Interface descriptions; Knowledge graphs; Language model; Large language model; Natural language interfaces; Synthesised; Work-flows; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Yang2024,
	author = {Yang, Chengrong and Jin, Qiwen and Wang, Yaowei and Zhou, Yujue and Lan, Dapeng and Yang, Yun},
	title = {EHAPZero: Ensemble Hierarchical Attribute Prompting Based Zero-Shot Learning for Pest Recognition},
	year = {2024},
	journal = {IEEE Internet of Things Journal},
	doi = {10.1109/JIOT.2024.3472079},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207136194&doi=10.1109%2fJIOT.2024.3472079&partnerID=40&md5=c524ef6ac3b36d1908c5fb7f83932814},
	abstract = {Pest recognition is of great significance for achieving sustainable development in agriculture. Nevertheless, due to the wide variety of pest species, subtle inter-species differences, and significant intra-species variations, existing artificial intelligence and Internet of Things (IoT) technologies can only recognize a small number of known pests effectively. In this paper, we propose a zero-shot learning pest recognition framework based on ensemble hierarchical attribute prompting, termed EHAPZero. EHAPZero can identify pest images collected by IoT devices, and then transmit the recognition results to the IoT platform for terminal display. Specifically, the image recognition function is implemented by an attribute generation module (AGM), a hierarchical prompting module (HPM), and a semantic-visual interaction module (SVIM). AGM utilizes large language models to construct a knowledge graph of pests. It employs both node importance evaluation algorithms and manual methods to perform dual filtering on attribute nodes within the graph. Inspired by human knowledge reasoning, HPM dynamically predicts different hierarchical attributes of input images within the Transformer intermediate blocks. These predicted attributes are subsequently injected into the intermediate layer features of the Transformer as prompts. To achieve semantic disambiguation and knowledge transfer, SVIM employs a visual-guided semantic representation method and a semantic-guided visual representation method to strengthen cross-domain interaction between semantics and vision. Finally, the final prediction score is derived through ensemble of prediction results across different levels. Extensive experiments show that EHAPZero achieves the new state-of-theart results on the real-word pest recognition benchmark. The codes are available at: https://github.com/jinqiwen/EHAPZero.  © 2014 IEEE.},
	author_keywords = {Attribute generation; Ensemble hierarchical attribute; Hierarchical attribute prompting; Semantic-visual interaction; Zero-shot learning},
	keywords = {Attribute generation; Ensemble hierarchical attribute; Hierarchical attribute prompting; Hierarchical attributes; Interaction modules; Internet of things technologies; Representation method; Semantic-visual interaction; Visual interaction; Zero-shot learning},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Bi20243615,
	author = {Bi, Baolong and Liu, Shenghua and Wang, Yiwei and Mei, Lingrui and Cheng, Xueqi},
	title = {LPNL: Scalable Link Prediction with Large Language Models},
	year = {2024},
	journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
	pages = {3615 – 3625},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205302735&partnerID=40&md5=5849b32c0770685a631edcda0f711c8c},
	abstract = {Exploring the application of large language models (LLMs) to graph learning is an emerging endeavor. However, the vast amount of information inherent in large graphs poses significant challenges to graph learning with LLMs. This work focuses on the link prediction task and introduces LPNL (Link Prediction via Natural Language), a framework based on large language models designed for scalable link prediction on large-scale heterogeneous graphs. We design novel prompts for link prediction that articulate graph details in natural language. We propose a two-stage sampling pipeline to extract crucial information from the graphs, and a divide-and-conquer strategy to control the input tokens within predefined limits, addressing the challenge of overwhelming information. We fine-tune a T5 model based on our self-supervised learning designed for link prediction. Extensive experimental results demonstrate that LPNL outperforms multiple advanced baselines in link prediction tasks on large-scale graphs. © 2024 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Contrastive Learning; Knowledge graph; Self-supervised learning; Supervised learning; Amount of information; Divide-and-conquer; Heterogeneous graph; Language model; Large graphs; Large-scales; Link prediction; Natural languages; Prediction tasks; Two stage samplings; Prediction models},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Reif2024,
	author = {Reif, Jonathan and Jeleniewski, Tom and Gill, Milapji Singh and Gehlhoff, Felix and Fay, Alexander},
	title = {Chatbot-Based Ontology Interaction Using Large Language Models and Domain-Specific Standards},
	year = {2024},
	journal = {IEEE International Conference on Emerging Technologies and Factory Automation, ETFA},
	doi = {10.1109/ETFA61755.2024.10711065},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207845394&doi=10.1109%2fETFA61755.2024.10711065&partnerID=40&md5=66f23aeac5d26075622bf58bda10afb2},
	abstract = {The following contribution introduces a concept that employs Large Language Models (LLMs) and a chatbot interface to enhance SPARQL query generation for ontologies, thereby facilitating intuitive access to formalized knowledge. Utilizing natural language inputs, the system converts user inquiries into accurate SPARQL queries that strictly query the factual content of the ontology, effectively preventing misinformation or fabrication by the LLM. To enhance the quality and precision of outcomes, additional textual information from established domain-specific standards is integrated into the ontology for precise descriptions of its concepts and relationships. An experimental study assesses the accuracy of generated SPARQL queries, revealing significant benefits of using LLMs for querying ontologies and highlighting areas for future research. © 2024 IEEE.},
	author_keywords = {Cyber-Physical Systems; Industry 4.0; Large Language Models; Ontologies; Semantic Web},
	keywords = {Ontology; Query languages; Semantics; Chatbots; Cybe-physical systems; Cyber-physical systems; Domain specific; Language model; Large language model; Natural languages; Ontology's; Query generation; Semantic-Web; Structured Query Language},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Wang20248055,
	author = {Wang, Zhunheng and Liu, Xiaoyi and Hu, Mengting and Ying, Rui and Jiang, Ming and Wu, Jianfeng and Xie, Yalan and Gao, Hang and Cheng, Renhong},
	title = {ECoK: Emotional Commonsense Knowledge Graph for Mining Emotional Gold},
	year = {2024},
	journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
	pages = {8055 – 8074},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205303429&partnerID=40&md5=2bee577c5b9ecb704979798bca506e7d},
	abstract = {The demand for understanding and expressing emotions in the field of natural language processing is growing rapidly. Knowledge graphs, as an important form of knowledge representation, have been widely utilized in various emotion-related tasks. However, existing knowledge graphs mainly focus on the representation and reasoning of general factual knowledge, while there are still significant deficiencies in the understanding and reasoning of emotional knowledge. In this work, we construct a comprehensive and accurate emotional commonsense knowledge graph, ECoK. We integrate cutting-edge theories from multiple disciplines such as psychology, cognitive science, and linguistics, and combine techniques such as large language models and natural language processing. By mining a large amount of text, dialogue, and sentiment analysis data, we construct rich emotional knowledge and establish the knowledge generation model COMET-ECoK. Experimental results show that ECoK contains high-quality emotional reasoning triples, and the performance of our knowledge generation model surpasses GPT-4-Turbo, which can help downstream tasks better understand and reason about emotions. Our data and code is available from https://github.com/ZornWang/ECoK. © 2024 Association for Computational Linguistics.},
	keywords = {Linguistics; Natural language processing systems; Cognitive linguistics; Commonsense knowledge; Cutting edges; Factual knowledge; Knowledge generations; Knowledge graphs; Knowledge-representation; Language processing; Multiple disciplines; Natural languages; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{2024,
	title = {2024 14th International Conference on Pattern Recognition Systems, ICPRS 2024},
	year = {2024},
	journal = {2024 14th International Conference on Pattern Recognition Systems, ICPRS 2024},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206489490&partnerID=40&md5=e4f6e292726e3775edb1fd67a5d23dc8},
	abstract = {The proceedings contain 42 papers. The topics discussed include: LLM-aided knowledge graph construction for zero-shot visual object state classification; enhancing Apple’s defect classification: insights from visible spectrum and narrow spectral band imaging; analyzing emotional and topical patterns in conspiracy theory narratives: a discourse comparative study on the 2023 Hawaii wildfires; non-invasive estimation of moisture content in mushrooms using hyperspectral imaging and machine learning-based stacking regressor model; a concept drift based approach to evaluating model performance and theoretical lifespan; autism spectrum disorder prediction using machine learning classifiers; adversarial contrastive representation learning for passive Wi-Fi fingerprinting of individuals; and SAI-ChileanDiet: a multi-label food dataset with self-acquired images of the Chilean diet.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Gupta2024,
	author = {Gupta, Pranav and Sharma, Raunak and Kumari, Rashmi and Aditya, Sri Krishna and Choudhary, Shwetank and Kumar, Sumit and Kanchana, M. and Thilagavathy, R.},
	title = {ECHO: Environmental Sound Classification with Hierarchical Ontology-guided Semi-Supervised Learning},
	year = {2024},
	journal = {Proceedings of CONECCT 2024 - 10th IEEE International Conference on Electronics, Computing and Communication Technologies},
	doi = {10.1109/CONECCT62155.2024.10677303},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205825848&doi=10.1109%2fCONECCT62155.2024.10677303&partnerID=40&md5=eeb2bd4266c03684cb11dd385621e1ae},
	abstract = {Environment Sound Classification has been a well-studied research problem in the field of signal processing and till now more focus has been laid on fully supervised approaches. Recently, the focus has moved towards semi-supervised methods which concentrate on utilizing unlabeled data, and self-supervised methods which learn the intermediate representation through pretext tasks or contrastive learning. However, both approaches require a vast amount of unlabelled data to improve performance. In this work, we propose a novel framework called Environmental Sound Classification with Hierarchical Ontology-guided semi-supervised Learning (ECHO) that utilizes label ontology-based hierarchy to learn semantic representation by defining a novel pretext task. The model tries to predict coarse labels represented by the Large Language Model (LLM) based on ground truth label ontology, then further fine-tuned in a supervised way to predict the actual task. ECHO achieves a 1% to 8% accuracy improvement over baseline systems across UrbanSound8K, ESC-10, and ESC-50 datasets.  © 2024 IEEE.},
	author_keywords = {Environment Sound Classification; Label ontology; semi-supervised learning},
	keywords = {Adversarial machine learning; Contrastive Learning; Federated learning; Ontology; Semantics; Semi-supervised learning; Environment sound classification; Environmental sound classifications; Label ontology; Learn+; Ontology's; Research problems; Semi-supervised learning; Signal-processing; Sound classification; Unlabeled data; Self-supervised learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Zhang2024356,
	author = {Zhang, Xuan and Wei, Chunyu and Yan, Ruyu and Fan, Yushun and Jia, Zhixuan},
	title = {Large Language Model Ranker with Graph Reasoning for Zero-Shot Recommendation},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {15020 LNCS},
	pages = {356 – 370},
	doi = {10.1007/978-3-031-72344-5_24},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205320434&doi=10.1007%2f978-3-031-72344-5_24&partnerID=40&md5=90dc78044ffa223941ee9fb080bc214a},
	abstract = {Large Language Models (LLMs), with their powerful reasoning abilities and extensive open-world knowledge, have substantially improved recommender systems by utilizing user interactions to provide personalized suggestions, particularly in zero-shot scenarios where prior training data is absent. However, existing approaches frequently fail to capture complex, higher-order information. In response to this limitation, we integrate user-item bipartite graph information into LLMs. This integration is challenging due to the inherent gaps between graph data and sequential text, as well as the input token limitations of LLMs. We propose a novel Graph Reasoning LLM Ranker framework for Zero-Shot Recommendation (G-LLMRanker) to overcome these challenges. Specifically, G-LLMRanker constructs a semantic tree enriched with higher-order information for each node in the graph and develops an instruction template to generate text sequences that LLMs can comprehend. Additionally, to address the input token limitations of LLMs, G-LLMRanker redefines the recommendation task as a conditional sorting task, where text sequences augmented by graph information serve as conditions, and the items selected through a Mixture of Experts approach act as candidates. Experiments on public datasets demonstrate that G-LLMRanker significantly outperforms zero-shot baselines in recommendation tasks. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {Graph Reasoning; Higher-order Information; Large Language Model; Recommender Systems},
	keywords = {Knowledge graph; Modeling languages; Open systems; Recommender systems; Semantics; Trees (mathematics); Graph information; Graph reasoning; High-order; High-order information; Higher-order; Language model; Large language model; Open world; Reasoning ability; World knowledge; Zero-shot learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{2024,
	title = {Proceedings of the 31st International Workshop on Intelligent Computing in Engineering, EG-ICE 2024},
	year = {2024},
	journal = {Proceedings of the 31st International Workshop on Intelligent Computing in Engineering, EG-ICE 2024},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207207232&partnerID=40&md5=f491ca64175e0e36f6072e1116ccf016},
	abstract = {The proceedings contain 68 papers. The topics discussed include: LLM-informed drone control for visual inspection of infrastructure; accurate rail track detection from high-resolution photogrammetric flights: photogrammetry, computer vision, and AI; accurate detection of road markings from high-resolution photogrammetric flights: photogrammetry, computer vision, and AI; digital rules in infrastructure planning: presentation of an ontology- based approach; extension of accessibility ontologies by requirements for inclusive indoor navigation; evaluating topological and geometric requirements for enhanced spatial data management: review and proposals within the context of level of information need; and towards a comprehensive digital twin of a road infrastructure system – requirements analysis and system architecture.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Da Silva2024,
	author = {Da Silva, Luis Miguel Vieira and Köcher, Aljosha and Gehlhoff, Felix and Fay, Alexander},
	title = {Toward a Method to Generate Capability Ontologies from Natural Language Descriptions},
	year = {2024},
	journal = {IEEE International Conference on Emerging Technologies and Factory Automation, ETFA},
	doi = {10.1109/ETFA61755.2024.10710783},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207822437&doi=10.1109%2fETFA61755.2024.10710783&partnerID=40&md5=2fab4d7473209dad1eaf190210ea1908},
	abstract = {To achieve a flexible and adaptable system, capabil-ity ontologies are increasingly leveraged to describe functions in a machine-interpretable way. However, modeling such complex ontological descriptions is still a manual and error-prone task that requires a significant amount of effort and ontology expertise. This contribution presents an innovative method to automate capability ontology modeling using Large Language Models (LLMs), which have proven to be well suited for such tasks. Our approach requires only a natural language description of a capability, which is then automatically inserted into a predefined prompt using a few-shot prompting technique. After prompting an LLM, the resulting capability ontology is automatically verified through various steps in a loop with the LLM to check the overall correctness of the capability ontology. First, a syntax check is performed, then a check for contradictions, and finally a check for hallucinations and missing ontology elements. Our method greatly reduces manual effort, as only the initial natural language description and a final human review and possible correction are necessary, thereby streamlining the capability ontology generation process. © 2024 IEEE.},
	author_keywords = {Capabilities; Large Language Models; LLMs; Model-Generation; Ontologies; Semantic Web; Skills},
	keywords = {Natural language processing systems; Ontology; Semantics; Capability; Language model; Large language model; Model generation; Natural languages; Ontology's; Semantic-Web; Skill; Modeling languages},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@CONFERENCE{Knollmeyer2024,
	author = {Knollmeyer, Simon and Akmal, Muhammad Uzair and Koval, Leonid and Asif, Saara and Mathias, Selvine G. and Großmann, Daniel},
	title = {Document Knowledge Graph to Enhance Question Answering with Retrieval Augmented Generation},
	year = {2024},
	journal = {IEEE International Conference on Emerging Technologies and Factory Automation, ETFA},
	doi = {10.1109/ETFA61755.2024.10711054},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207838978&doi=10.1109%2fETFA61755.2024.10711054&partnerID=40&md5=3e735d8b14fc68f874577ac01e4c1092},
	abstract = {Reusing and managing existing knowledge from available documents is crucial for success in the factory planning domain. By leveraging Artificial Intelligence (AI) and Question Answering (QA) systems, users can query a document corpus through a chat-based application and receive precise answers. The recent advancements in Large Language Models (LLMs) and their linguistic capabilities present new opportunities for such applications. Utilizing the methodology of Retrieval Augmented Generation (RAG), document sections are provided to the LLM based on user queries. However, existing RAG implementations that use vector databases as document repositories face limitations when answering questions that extend beyond the text content of the documents. To address this issue, this paper proposes a concept to enhance RAG systems by integrating a Knowledge Graph (KG) constructed from the document structures. © 2024 IEEE.},
	author_keywords = {Information management; Knowledge Graph; Large Language Models; Retrieval Augmented Generation},
	keywords = {Information management; Knowledge graph; Query languages; Structured Query Language; Factory planning; Knowledge graphs; Language model; Large language model; Model-based OPC; Planning domains; Question Answering; Question answering systems; Retrieval augmented generation; User query; Question answering},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Li2024251,
	author = {Li, Yihao and Zhang, Ru and Liu, Jianyi},
	title = {An Enhanced Prompt-Based LLM Reasoning Scheme via Knowledge Graph-Integrated Collaboration},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {15020 LNCS},
	pages = {251 – 265},
	doi = {10.1007/978-3-031-72344-5_17},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205323657&doi=10.1007%2f978-3-031-72344-5_17&partnerID=40&md5=93169cab1f7ffd47f5645485fed85c13},
	abstract = {While Large Language Models (LLMs) demonstrate exceptional performance in a multitude of Natural Language Processing (NLP) tasks, they encounter challenges in practical applications, including issues with hallucinations, inadequate knowledge updating, and limited transparency in the reasoning process. To overcome these limitations, this study innovatively proposes a collaborative training-free reasoning scheme involving tight cooperation between Knowledge Graph (KG) and LLMs. This scheme first involves using LLMs to iteratively explore KG, selectively retrieving a task-relevant knowledge subgraph to support reasoning. The LLMs are then guided to further combine inherent implicit knowledge to reason on the subgraph while explicitly elucidating the reasoning process. Through such a cooperative approach, our scheme achieves more reliable knowledge-based reasoning and facilitates the tracing of the reasoning results. Experimental results show that our scheme significantly progressed across multiple datasets, notably achieving an improvement of over 10% on the QALD10 dataset compared to both the best baseline and the fine-tuned state-of-the-art (SOTA) models. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {Collaborative reasoning; Knowledge Graph; Large Language Models; Prompt-based},
	keywords = {Collaborative reasonings; Knowledge graphs; Language model; Large language model; Model reasonings; Performance; Prompt-based; Reasoning process; Reasoning schemes; Subgraphs; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Jin2024163,
	author = {Jin, Bowen and Xie, Chulin and Zhang, Jiawei and Roy, Kashob Kumar and Zhang, Yu and Li, Zheng and Li, Ruirui and Tang, Xianfeng and Wang, Suhang and Meng, Yu and Han, Jiawei},
	title = {Graph Chain-of-Thought: Augmenting Large Language Models by Reasoning on Graphs},
	year = {2024},
	journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
	pages = {163 – 184},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205324902&partnerID=40&md5=f5bcca04c226950e9e18fae86a3b4442},
	abstract = {Large language models (LLMs), while exhibiting exceptional performance, suffer from hallucinations, especially on knowledge-intensive tasks. Existing works propose to augment LLMs with individual text units retrieved from external knowledge corpora to alleviate the issue. However, in many domains, texts are interconnected (e.g., academic papers in a bibliographic graph are linked by citations and co-authorships) which form a (text-attributed) graph. The knowledge in such graphs is encoded not only in single texts/nodes but also in their associated connections. To facilitate the research of augmenting LLMs with graphs, we manually construct a Graph Reasoning Benchmark dataset called GRBENCH, containing 1,740 questions that can be answered with the knowledge from 10 domain graphs. Then, we propose a simple and effective framework called Graph Chain-of-thought (GRAPH-COT) to augment LLMs with graphs by encouraging LLMs to reason on the graph iteratively. Each GRAPH-COT iteration consists of three sub-steps: LLM reasoning, LLM-graph interaction, and graph execution. We conduct systematic experiments with three LLM backbones on GRBENCH, where GRAPH-COT outperforms the baselines consistently. The code is available at https://github.com/PeterGriffinJin/Graph-CoT. © 2024 Association for Computational Linguistics.},
	keywords = {Bibliographic retrieval systems; Bibliographies; Computational linguistics; Graph algorithms; Academic paper; Attributed graphs; Benchmark datasets; Co-authorships; External knowledge; Knowledge intensive tasks; Language model; Model reasonings; Performance; Simple++; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Carta2024396,
	author = {Carta, Salvatore and Giuliani, Alessandro and Manca, Marco Manolo and Piano, Leonardo and Pisu, Alessia and Tiddia, Sandro Gabriele},
	title = {Instruct Large Language Models for Public Administration Document Information Extraction},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3762},
	pages = {396 – 401},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205580023&partnerID=40&md5=dc5035afabc75dd414fc210deae4e3b4},
	abstract = {With the rapid digitization of institutions, there is an ever-increasing problem of effectively organizing and accessing information. Public Administrations (PAs) manage large volumes of disparate data from a variety of sources. Thus, these organizations would greatly benefit from AI, particularly Natural Language Processing solutions that help organize, structure, and search for information effectively. In the context of Italian PA, which we address in this paper, there are two main challenges: the lack of ontologies and the limited tools available for Italian information extraction. In this paper, we attempt to advance Information Extraction for Italian PAs by instructing a Large Language Model on a set of automatically labeled triplets of public tenders. © 2024 Copyright for this paper by its authors.},
	author_keywords = {Italian Open Information Extraction; Large Language Models; Public Administration; Tenders},
	keywords = {Natural language processing systems; Open Data; Digitisation; Italian open information extraction; Language model; Language processing; Large language model; Large volumes; Natural languages; Ontology's; Processing solutions; Tender},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Liu2024839,
	author = {Liu, Lihui and Hill, Blaine and Du, Boxin and Wang, Fei and Tong, Hanghang},
	title = {Conversational Question Answering with Language Models Generated Reformulations over Knowledge Graph},
	year = {2024},
	journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
	pages = {839 – 850},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205321877&partnerID=40&md5=ff5d46383e97e878f73c7f1c2a6e7d20},
	abstract = {Conversational question answering (ConvQA) over knowledge graphs (KGs) involves answering multi-turn natural language questions about information contained in a KG. State-of-the-art methods of ConvQA often struggle with inexplicit question-answer pairs. These inputs are easy for human beings to understand given a conversation history, but hard for a machine to interpret, which can degrade ConvQA performance. To address this issue, we propose a reinforcement learning (RL) based model, CORNNET, which utilizes question reformulations generated by large language models (LLMs) to improve ConvQA performance. CORNNET adopts a teacher-student architecture where a teacher model learns question representations using human writing reformulations, and a student model to mimic the teacher model's output via reformulations generated by LLMs. The learned question representation is then used by a RL model to locate the correct answer in a KG. Extensive experimental results show that CORNNET outperforms state-of-the-art ConvQA models. © 2024 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Knowledge graph; Reinforcement learning; Students; Teaching; Human being; Knowledge graphs; Language model; Multi-turn; Natural language questions; Performance; Question Answering; Question-answer pairs; State-of-the-art methods; Teacher models},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Pardo-Ferrera2024178,
	author = {Pardo-Ferrera, Joel},
	title = {Automatic Medical Knowledge Graph Construction},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3797},
	pages = {178 – 186},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207927035&partnerID=40&md5=31607c7152cc7f36715e1f533e37df82},
	abstract = {Knowledge Graphs are crucial for structuring and integrating large amounts of data, improving decision-making and data interoperability, especially in the healthcare domain. This PhD thesis aims to implement a unified end-to-end framework for building a cross-lingual KG for English and Spanish in the healthcare sector using NLP techniques. Addressing the reliance on traditional methods in KG construction and the limited non-English language resources, this work seeks to refine the information extraction process within unstructured medical texts and facilitate the (re)use of existent ontologies (schema to represent the real-world). © 2024 Copyright for this paper by its authors.},
	author_keywords = {Electronic Health Records; Information Extraction; Knowledge Graph Construction; Large Language Models},
	keywords = {Knowledge graph; Medical informatics; Electronic health; Graph construction; Health records; Information extraction; Knowledge graph construction; Knowledge graphs; Language model; Large amounts of data; Large language model; Medical knowledge; Electronic health record},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Gouidis2024,
	author = {Gouidis, Filippos and Papantoniou, Katerina and Papoutsakis, Konstantinos and Patkos, Theodore and Argyros, Antonis and Plexousakis, Dimitris},
	title = {LLM-aided Knowledge Graph construction for Zero-Shot Visual Object State Classification},
	year = {2024},
	journal = {2024 14th International Conference on Pattern Recognition Systems, ICPRS 2024},
	doi = {10.1109/ICPRS62101.2024.10677802},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206449143&doi=10.1109%2fICPRS62101.2024.10677802&partnerID=40&md5=f4ed3522828b92141201378f2299d333},
	abstract = {The problem of classifying the states of objects using visual information holds great importance in both applied and theoretical contexts. This work focuses on the special case of Zero-shot Object-Agnostic State Classification (ZS-OaSC). To tackle this problem, we introduce an innovative strategy that capitalizes on the capabilities of Graph Neural Networks to learn to project semantic embeddings into visual space and on the potential of Large Language Models (LLMs) to provide rich content for constructing Knowledge Graphs (KGs). Through a comprehensive ablation study, we explore the synergies between LLMs and KGs, uncovering critical insights about their integration in the context of the ZS-OSC problem. Our proposed methodology is rigorously evaluated against current state-of-the-art (SoA) methods, demonstrating superior performance in various image datasets. ©2024 IEEE.},
	keywords = {Graph embeddings; Graph neural networks; Semantics; Visual languages; Zero-shot learning; Graph construction; Graph neural networks; Innovative strategies; Knowledge graphs; Language model; Learn+; Semantic embedding; State classification; Visual information; Visual objects; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Shamsabadi2024218,
	author = {Shamsabadi, Mahsa and D’Souza, Jennifer},
	title = {A FAIR and Free Prompt-Based Research Assistant},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14763 LNCS},
	pages = {218 – 224},
	doi = {10.1007/978-3-031-70242-6_21},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205493076&doi=10.1007%2f978-3-031-70242-6_21&partnerID=40&md5=09d6aff698cf251064c807ac74296eef},
	abstract = {This demo will present the Research Assistant (RA) tool developed to assist with six main types of research tasks defined as standardized instruction templates, instantiated with user input, applied finally as prompts to well-known—for their sophisticated natural language processing abilities—AI tools, such as ChatGPT and Gemini. The six research tasks addressed by RA are: creating FAIR research comparisons, ideating research topics, drafting grant applications, writing scientific blogs, aiding preliminary peer reviews, and formulating enhanced literature search queries. RA’s reliance on generative AI tools like ChatGPT or Gemini means the same research task assistance can be offered in any scientific discipline. We demonstrate its versatility by sharing RA outputs in Computer Science, Virology, and Climate Science, where the output with the RA tool assistance mirrored that from a domain expert who performed the same research task. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {ChatGPT; Gemini; Knowledge Graphs; Large Language Models; Research Assistants;  Open Research Knowledge Graph},
	keywords = {ChatGPT; Geminus; Knowledge graphs; Language model; Large language model; Natural languages; Open research knowledge graph; Research assistant; User input; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Xie2024,
	author = {Xie, Yijie and Luo, Xiangfeng and Wang, Xinzhi},
	title = {Combing formalized temporal knowledge and generative background knowledge for temporal knowledge graph reasoning},
	year = {2024},
	journal = {Proceedings of SPIE - The International Society for Optical Engineering},
	volume = {13286},
	doi = {10.1117/12.3045266},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207073311&doi=10.1117%2f12.3045266&partnerID=40&md5=475b4a50fcbe89f5cee88538ba5d11d4},
	abstract = {Temporal knowledge graph (TKG) can abstract the temporal information of entities and relations in the real world. If we can infer unknown temporal quadruples, we can predict the developmental trends of events in the long run. However, current TKG reasoning methods are difficult to model the relative temporal relations between quadruples well, and there is also an issue of insufficient reasoning information. Therefore, we propose a TKG reasoning model named TKBK, which combines formalized temporal knowledge and generative background knowledge. TKBK retrieves temporal knowledge from TKG and generates background knowledge from large language models (LLM). It uses a masking strategy to train a pre-trained language model and transforms the complex reasoning task into a masked token prediction task. We evaluated our proposed model on two datasets. The results show that TKBK outperforms the baseline model on most metrics, proving the effectiveness of this model in TKG reasoning tasks. © 2024 SPIE.},
	author_keywords = {graph reasoning; large language model; prompt engineering; temporal knowledge graph},
	keywords = {Generative adversarial networks; Background knowledge; Graph reasoning; Knowledge graphs; Language model; Large language model; Prompt engineering; Reasoning tasks; Temporal information; Temporal knowledge; Temporal knowledge graph; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Gerasimov2024,
	author = {Gerasimov, Irina and Mehrabian, Armin and Kc, Binita and Alfred, Jerome and Mcguire, Michael P.},
	title = {Discovering Research Areas in Dataset Applications through Knowledge Graphs and Large Language Models},
	year = {2024},
	journal = {Proceedings - 2024 IEEE 20th International Conference on e-Science, e-Science 2024},
	doi = {10.1109/e-Science62913.2024.10678676},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205948791&doi=10.1109%2fe-Science62913.2024.10678676&partnerID=40&md5=f68c90c757e2da97d44024ceb1e0eb88},
	abstract = {Scientific datasets are increasingly cited in peer-reviewed journal publications, facilitating easy access to research utilizing those datasets. Datasets undergo a life cycle where older versions of datasets are replaced by newer versions often due to improvements in data resolution, algorithms, and other factors. Unlike peer reviewed documents registered with a single Digital Unique Identifier (DOI), datasets can be updated over time and the newer version of the datasets are registered with a new DOI which is not necessarily linked to the previous version of the dataset. It is challenging when publications citing a dataset need to be traced over the entire life cycle of that dataset. We provide an innovative approach to link the dataset versions and publications using a knowledge graph (KG). KG can help to trace the dataset cited in publications over the entire dataset life cycle and shed light into dataset usage in various applied research areas. We fine-tuned the pretrained NASA IMPACT INDUS Large Language Model (LLM) on a set of labeled publications abstracts. Our results showed that 87% of the publications were classified into one of twenty applied research areas, while the remaining 13% were classified into non-applied research areas. By linking datasets to applied research areas through the KG and employing Global Change Master Directory (GCMD), a well-established controlled vocabulary of scientific keywords describing Earth science datasets, we contribute to a transparent and advanced search and discovery mechanism for datasets across the Earth data ecosystem. The integrated KG and LLM approach is now incorporated and operational in dataset publication management at one of NASA's Earth science data archival centers.  © 2024 IEEE.},
	author_keywords = {data citation; Knowledge Graph; LLM},
	keywords = {NASA; Access to research; Applied research; Classifieds; Data citation; Data resolutions; Journal publication; Knowledge graphs; Language model; Large language model; Research areas; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Bhargava2024290,
	author = {Bhargava, Urvashi and Teresha, Y. and Koul, Nishank and Chavan, Chandrashekhar Pomu},
	title = {Overcoming the Challenges of Large Language Models: Introducing a Novel Proposition for Synthetic Data Validation},
	year = {2024},
	journal = {2024 IEEE 7th International Conference on Big Data and Artificial Intelligence, BDAI 2024},
	pages = {290 – 295},
	doi = {10.1109/BDAI62182.2024.10692968},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206888653&doi=10.1109%2fBDAI62182.2024.10692968&partnerID=40&md5=07dfedde32b46539a05c83e3fa62c87c},
	abstract = {The market debut of ChatGPT gave rise to the development and deployment of various other Large Language Models (LLMs) that achieve state-of-the-art performance across various tasks. The growing popularity of these models has captivated some to attempt to construct or enhance their own LLM. We must be aware of the significant problems that already exist and that we might face along the way. This paper aims to identify and investigate the main challenges in this field, provide existing solutions, and propose novel approaches to mitigate them. A unique Truth-Table proposition for validating synthetic data is presented examining two models, along with a bidirectional knowledge graph-based solution for curing the reverse curse problem, data generation strategies, domain adaptation methods, and the use of a custom dataset to address model hallucinations. The methodology and findings of this study provide valuable insights for users, researchers, and industry experts who are interested in LLMs. It serves as a reference for future research on current models, refining models or developing domain-specific ones. © 2024 IEEE.},
	author_keywords = {Challenges; Data Scarcity; Knowledge Graph; Large Language Models; Model Hallucinations; Reversal Curse; Strategies; Synthetic Data Validation},
	keywords = {Spatio-temporal data; Challenge; Data scarcity; Data validation; Knowledge graphs; Language model; Large language model; Model hallucination; Reversal curse; Strategy; Synthetic data; Synthetic data validation; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Sun20242919,
	author = {Sun, Yushi and Xin, Hao and Sun, Kai and Ethan Xu, Yifan and Yang, Xiao and Luna Dong, Xin and Tang, Nan and Chen, Lei},
	title = {Are Large Language Models a Good Replacement of Taxonomies?},
	year = {2024},
	journal = {Proceedings of the VLDB Endowment},
	volume = {17},
	number = {11},
	pages = {2919 – 2932},
	doi = {10.14778/3681954.3681973},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205361962&doi=10.14778%2f3681954.3681973&partnerID=40&md5=170d3896c9374a7073dc033aec00ca38},
	abstract = {Large language models (LLMs) demonstrate an impressive ability to internalize knowledge and answer natural language questions. Although previous studies validate that LLMs perform well on general knowledge while presenting poor performance on long-tail nuanced knowledge, the community is still doubtful about whether the traditional knowledge graphs should be replaced by LLMs. In this paper, we ask if the schema of knowledge graph (i.e., taxonomy) is made obsolete by LLMs. Intuitively, LLMs should perform well on common taxonomies and at taxonomy levels that are common to people. Unfortunately, there lacks a comprehensive benchmark that evaluates the LLMs over a wide range of taxonomies from common to specialized domains and at levels from root to leaf so that we can draw a confident conclusion. To narrow the research gap, we constructed a novel taxonomy hierarchical structure discovery benchmark named TaxoGlimpse to evaluate the performance of LLMs over taxonomies. TaxoGlimpse covers ten representative taxonomies from common to specialized domains with in-depth experiments of different levels of entities in this taxonomy from root to leaf. Our comprehensive experiments of eighteen LLMs under three prompting settings validate that LLMs perform miserably poorly in handling specialized taxonomies and leaf-level entities. Specifically, the QA accuracy of the best LLM drops by up to 30% as we go from common to specialized domains and from root to leaf levels of taxonomies. © 2024, VLDB Endowment. All rights reserved.},
	keywords = {Benchmarking; Natural language processing systems; Plants (botany); Taxonomies; Community IS; General knowledge; Knowledge graphs; Language model; Leaf level; Long tail; Natural language questions; Poor performance; Research gaps; Traditional knowledge; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@ARTICLE{Lysyuk2024107,
	author = {Lysyuk, Maria and Salnikov, Mikhail and Braslavski, Pavel and Panchenko, Alexander},
	title = {Konstruktor: A Strong Baseline for Simple Knowledge Graph Question Answering},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14763 LNCS},
	pages = {107 – 118},
	doi = {10.1007/978-3-031-70242-6_11},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205453422&doi=10.1007%2f978-3-031-70242-6_11&partnerID=40&md5=4f290b1a4bb3c78d275b33a68bef2a43},
	abstract = {While being one of the most popular question types, simple questions such as “Who is the author of Cinderella?”, are still not completely solved. Surprisingly, even most powerful modern Large Language Models (LLMs) are prone to errors when dealing with such questions, especially when dealing with rare entities. At the same time, as an answer may be one hop away from the question entity, one can try to develop a method that uses structured knowledge graphs (KGs) to answer such questions. In this paper, we introduce Konstruktor -- an efficient and robust approach that breaks down the problem into three steps: (i) entity extraction and entity linking, (ii) relation prediction, and (iii) querying the knowledge graph. Our approach integrates language models and knowledge graphs, exploiting the power of the former and the interpretability of the latter. We experiment with two named entity recognition and entity linking methods and several relation detection techniques. We show that for relation detection, the most challenging step of the workflow, a combination of relation classification/generation and ranking outperforms other methods. On four datasets, we report the strong performance of Konstruktor. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {KG; KGQA; knowledge graphs; question answering},
	keywords = {Question answering; Structured Query Language; Break down; KGQA; Knowledge graphs; Language model; Question Answering; Question type; Robust approaches; Simple++; Structured knowledge; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Jian2024,
	author = {Jian, Zhaorui and Liu, Shengquan and Gao, Wei and Cheng, Jianming},
	title = {Distantly Supervised Relation Extraction based on Non-taxonomic Relation and Self-Optimization},
	year = {2024},
	journal = {Proceedings of the International Joint Conference on Neural Networks},
	doi = {10.1109/IJCNN60899.2024.10650745},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205022179&doi=10.1109%2fIJCNN60899.2024.10650745&partnerID=40&md5=cd7ce697f1952b520c74e2e00e6dccdd},
	abstract = {Distantly supervised relation extraction (DS-RE) leverages existing knowledge bases to generate annotated data for relation extraction (RE), addressing the issue of scarce labeled data. However, distant supervision (DS) is often limited by coarse annotations and insufficient contextual awareness, leading to relational ambiguity and introducing noise in the labeled results. Moreover, although one can optimize the classifiers in DS-RE models through weight updates, the static nature of the guiding rules for such adjustments often falls short when addressing the challenges posed by diverse non-taxonomic relations and complex noise patterns in datasets. In this paper, we propose a DS-RE framework that capitalizes on non-taxonomic relations and a self-optimizing mechanism. We define a set of consistent DS relation candidates and combine DS with a LLM to enhance the perception of entities' contextual states during the DS process. Then, we design a Self-Optimizing Ontology-Enhanced Non-taxonomic Relation Extraction Model (SO-NRE). The model incorporates additional entity-relation knowledge to enhance the semantic depth of Non-taxonomic relation ontologies and uses an adaptive dynamic scheduling mechanism to refine the classification strategy through iterations informed by self-perception outcomes. The experimental results show that the improved DS annotation workflow has enhanced accuracy, and SO-NRE outperforms mainstream baselines in RE performance. © 2024 IEEE.},
	author_keywords = {Distantly Supervised Relation Extraction; LLM; Non-taxonomic Relation; Self-Optimization},
	keywords = {Ontology; Self-supervised learning; Distantly supervised relation extraction; Extraction modeling; Labeled data; LLM; Non-taxonomic relation; Ontology's; Relation extraction; Self-optimization; Self-optimizing; Weight update; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Ding20242609,
	author = {Ding, Wenxuan and Feng, Shangbin and Liu, Yuhan and Tan, Zhaoxuan and Balachandran, Vidhisha and He, Tianxing and Tsvetkov, Yulia},
	title = {KNOWLEDGE CROSSWORDS: Geometric Knowledge Reasoning with Large Language Models},
	year = {2024},
	journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
	pages = {2609 – 2636},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205288479&partnerID=40&md5=59c8f8bad6342e8d4d95b099729479c0},
	abstract = {We propose KNOWLEDGE CROSSWORDS, a geometric knowledge reasoning benchmark consisting of incomplete knowledge networks bounded by structured factual constraints, where LLMs are tasked with inferring the missing facts to meet all constraints. The novel setting of geometric knowledge reasoning necessitates new LM abilities beyond existing atomic/linear multi-hop QA, such as backtracking, verifying facts and constraints, reasoning with uncertainty, and more. KNOWLEDGE CROSSWORDS contains 2,101 individual problems, covering diverse knowledge domains, and is further divided into three difficulty levels. We conduct extensive experiments to evaluate existing LLMs and approaches on KNOWLEDGE CROSSWORDS. Results demonstrate that baseline approaches struggle with larger knowledge networks and semantically-equivalent entity distractors. In light of their limitations, we propose two new approaches, STAGED PROMPTING and VERIFY-ALL, to augment LLMs' abilities for error-aware backtracking and constraint verification. Our VERIFY-ALL significantly outperforms prior methods and is more robust towards problems in the hard subset. Further analysis shows that geometric knowledge reasoning poses new challenges to LLMs' knowledge abilities, particularly in robustness towards varying option orders, complex structural constraints in knowledge networks, “none of the above” scenarios, and more. © 2024 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Domain Knowledge; Knowledge graph; Modeling languages; Constraint reasoning; Geometric knowledge; Incomplete knowledge; Knowledge domains; Knowledge networks; Knowledge reasoning; Language model; Multi-hops; New approaches; Reasoning with uncertainty; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Xia202416144,
	author = {Xia, Yuwei and Wang, Ding and Liu, Qiang and Wang, Liang and Wu, Shu and Zhang, Xiaoyu},
	title = {Chain-of-History Reasoning for Temporal Knowledge Graph Forecasting},
	year = {2024},
	journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
	pages = {16144 – 16159},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205285087&partnerID=40&md5=d186a40f39605ca29f2e73d302587482},
	abstract = {Temporal Knowledge Graph (TKG) forecasting aims to predict future facts based on given histories. Most recent graph-based models excel at capturing structural information within TKGs but lack semantic comprehension abilities. Nowadays, with the surge of LLMs, the LLM-based TKG prediction model has emerged. However, the existing LLM-based model exhibits three shortcomings: (1) It only focuses on the first-order history for prediction while ignoring high-order historical information, resulting in the provided information for LLMs being extremely limited. (2) LLMs struggle with optimal reasoning performance under heavy historical information loads. (3) For TKG prediction, the temporal reasoning capability of LLM alone is limited. To address the first two challenges, we propose Chain-of-History (CoH) reasoning which explores high-order histories step-by-step, achieving effective utilization of high-order historical information for LLMs on TKG prediction. To address the third issue, we design CoH as a plug-and-play module to enhance the performance of graph-based models for TKG prediction. Extensive experiments on three datasets and backbones demonstrate the effectiveness of CoH. © 2024 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Knowledge graph; Excel; Graph-based models; High-order; Higher-order; Historical information; Knowledge graphs; Prediction modelling; Semantic comprehension; Structural information; Temporal knowledge; Prediction models},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Wang202410242,
	author = {Wang, Huimin and Zhao, Yutian and Wu, Xian and Zheng, Yefeng},
	title = {imapScore: Medical Fact Evaluation Made Easy},
	year = {2024},
	journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
	pages = {10242 – 10257},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205322873&partnerID=40&md5=9545f6284c7765145b19b2566154811b},
	abstract = {Automatic evaluation of natural language generation (NLG) tasks has gained extensive research interests, since it can rapidly assess the performance of large language models (LLMs). However, automatic NLG evaluation struggles with medical QA because it fails to focus on the crucial correctness of medical facts throughout the generated text. To address this, this paper introduces a new data structure, imap, designed to capture key information in questions and answers, enabling evaluators to focus on essential details. The imap comprises three components: Query, Constraint, and Inform, each of which is in the form of term-value pairs to represent medical facts in a structural manner. We then introduce imapScore, which compares the corresponding medical term-value pairs in the imap to score generated texts. We utilize GPT-4 to extract imap from questions, human-annotated answers, and generated responses. To mitigate the diversity in medical terminology for fair term-value pairs comparison, we use a medical knowledge graph to assist GPT-4 in determining matches. To compare imapScore with existing NLG metrics, we establish a new benchmark dataset. The experimental results show that imapScore consistently outperforms state-of-the-art metrics, demonstrating an average improvement of 79.8% in correlation with human scores. Furthermore, incorporating imap into n-gram, embedding, and LLM metrics boosts the base versions, increasing correlation with human scores by averages of 89.9%, 81.7%, and 32.6%, respectively. © 2024 Association for Computational Linguistics.},
	keywords = {Knowledge graph; Natural language processing systems; Structured Query Language; Terminology; Automatic evaluation; Component queries; Language model; Medical terms; Natural language generation; Performance; Query constraints; Research interests; Term value; Three-component; Computational linguistics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Tian20243813,
	author = {Tian, Shiyu and Luo, Yangyang and Xu, Tianze and Yuan, Caixia and Jiang, Huixing and Chen, Wei and Wang, Xiaojie},
	title = {KG-Adapter: Enabling Knowledge Graph Integration in Large Language Models through Parameter-Efficient Fine-Tuning},
	year = {2024},
	journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
	pages = {3813 – 3828},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205321028&partnerID=40&md5=ff6bc38f0418481b217d9b25bf7203c6},
	abstract = {Although large language models (LLMs) show remarkable capabilities and generalizability across various tasks, they are criticized for lack of expertise. One promising solution is to combine knowledge graphs (KGs) with LLMs, and recent studies focus on integrating KGs into LLMs through prompt-based methods. However, these approaches fail to use the structural information of the KGs, suffer from the problem of knowledge conflict, and over-reliance on super LLMs. To address these challenges, we propose KG-Adapter, a parameter-level KG integration method based on parameter-efficient fine-tuning (PEFT). Specifically, we introduce a novel adapter structure designed for decoder-only LLMs, which can encode KGs from both node-centered and relation-centered perspectives, and then perform joint reasoning with LLMs to generate responses end-to-end. Experiments with diverse models on four datasets for two different tasks all demonstrate significant improvements. With only 28M parameters trained, we make the 7B-parameter LLM outperform the previous full-parameter fine-tuned state-of-the-art method and comparable to the prompt-based ChatGPT methods. © 2024 Association for Computational Linguistics.},
	keywords = {Computational linguistics; End to end; Fine tuning; Full parameters; Integration method; Knowledge graphs; Language model; Over reliance; Parameter levels; State-of-the-art methods; Structural information; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Shen2024,
	author = {Shen, Qianru and Lin, Hailun and Liu, Huan and Lin, Zheng and Wang, Weiping},
	title = {Exploiting Visual Relation and Multi-Grained Knowledge for Multimodal Relation Extraction},
	year = {2024},
	journal = {Proceedings of the International Joint Conference on Neural Networks},
	doi = {10.1109/IJCNN60899.2024.10650770},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205020395&doi=10.1109%2fIJCNN60899.2024.10650770&partnerID=40&md5=b05a077819e41c0d58104655150ee415},
	abstract = {Given a text and its related image, the multimodal relation extraction (MRE) task aims at predicting the correct semantic relation between two entities in the input text. Though certain advances have been made by recent MRE approaches, they still suffer from two drawbacks. First, they ignore fine-grained visual relations between image objects which can serve as important clues for inferring the correct relation. Second, they are unable to utilize useful external knowledge about entities and the input sentence, leading to a sub-optimal performance when processing examples that demand related background or commonsense knowledge. To alleviate above limitations, we propose a novel method, named VRMK, which exploits both Visual Relations and Multi-grained Knowledge for the MRE task. Specifically, the input image-text pair is converted into a unified multimodal graph. Then, the relation-aware transformer is adopted to update node representations while explicitly encoding diverse relations among visual and textual nodes. Based on the input text, the powerful large language model (LLM) is used to generate entity-level and sentence-level knowledge with the in-context learning. The most relevant knowledge information is captured by a cross-attention mechanism and is further combined with the representations of entity nodes and original text to predict the final relation label. On the MNRE dataset, VRMK outperforms recent state-of-the-art baselines including LLM-based methods by 2.71% (82.55%→85.26% in F1 score). We also conduct extensive ablation experiments to reveal contributions of different modules and provide useful insights for future research. © 2024 IEEE.},
	author_keywords = {multi-grained knowledge; multimodal relation extraction; relation-aware Transformer; scene graph generation},
	keywords = {Knowledge graph; Modeling languages; Visual languages; Graph generation; Language model; Multi-grained knowledge; Multi-modal; Multimodal relation extraction; Relation extraction; Relation-aware transformer; Scene graph generation; Scene-graphs; Semantic relations; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Sun20246855,
	author = {Sun, Qi and Li, Yahui and Zhou, Chunjie and Tian, Yu-Chu},
	title = {Root Cause Analysis for Industrial Process Anomalies through the Integration of Knowledge Graph and Large Language Model},
	year = {2024},
	journal = {Chinese Control Conference, CCC},
	pages = {6855 – 6860},
	doi = {10.23919/CCC63176.2024.10662704},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205460404&doi=10.23919%2fCCC63176.2024.10662704&partnerID=40&md5=a95d2f111489f2550a8d0cc91fa75fd1},
	abstract = {Root cause analysis for industrial process anomalies is critical for manufacturing activities. Industrial process alarms can provide crucial information to enable root cause analysis. However, the complex system structure causes a large number of alarms to emerge at the same time. To address this issue, we proposed an approach that utilizes knowledge graphs and large language models to provide comprehensible root cause analysis. Firstly, we extract knowledge such as historical anomalies from catalytic cracking operation manuals to construct an industrial process safety knowledge graph. Then, named entities in each alarm are extracted as keywords to retrieve factual knowledge from the knowledge graph. Finally, factual knowledge will be provided to the large language model as prior knowledge to infer the root cause of anomalies. Experimental results show that the proposed approach can accurately identify the root cause, thereby ensuring the safety of industrial processes. © 2024 Technical Committee on Control Theory, Chinese Association of Automation.},
	author_keywords = {Knowledge graph; Large language model; Named entity recognition; Root cause analysis},
	keywords = {Factual knowledge; Industrial processs; Integration of knowledge; Knowledge graphs; Language model; Large language model; Manufacturing activities; Named entity recognition; Root cause; Root cause analysis; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Wang202474,
	author = {Wang, Ruobing and He, Xin and Gu, Hengrui and Wang, Xin},
	title = {LGCRS: LLM-Guided Representation-Enhancing for Conversational Recommender System},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {15024 LNCS},
	pages = {74 – 88},
	doi = {10.1007/978-3-031-72356-8_6},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205300163&doi=10.1007%2f978-3-031-72356-8_6&partnerID=40&md5=fb874be78cfdca6b380951c0e77350c7},
	abstract = {Conversational recommender systems primarily focus on acquiring user preferences through real-time interactions. However, their effectiveness in modeling user preferences is constrained by the amount of conversational information. Existing conversational recommendation methods typically leverage external knowledge graph to enhance recommendation performance, potentially overlooking valuable textual information related to users and items. With significant natural language understanding capabilities, large language models (LLMs) have the potential to improve the performance of conversational recommendation task by improving the quality of text representations. However, the incorporation of raw textual information may inadvertently introduce noise to recommendations. Additionally, the semantic gap between the textual information and the collaborative signals could potentially degrade the performance of the conversational recommender system. To tackle the aforementioned challenges, we propose a LLM-guided representation-enhancing method for conversational recommender system, which fuses collaborative signals and semantic information to improve recommendation performance and generate high-quality responses. Specifically, we leverage LLMs to refine item profiles while reducing noise in text information, construct fused item representations across multiple aspects, and align the LLMs-enhanced semantic representation with the CF-side rational representation through regularization terms in the training stage. Experiments on two publicly available conversational recommendation datasets show that our method exhibits better performance in both recommendation and conversation tasks. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {Conversational Recommender System; Large Language Models; Representation Learning},
	keywords = {Contrastive Learning; Modeling languages; Natural language processing systems; Real time systems; Recommender systems; Collaborative signal; Conversational recommendations; Conversational recommender systems; Language model; Large language model; Recommendation performance; Representation learning; Textual information; User's preferences; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Soysal2024,
	author = {Soysal, Ekin and Roberts, Kirk},
	title = {PheNormGPT: a framework for extraction and normalization of key medical findings},
	year = {2024},
	journal = {Database},
	volume = {2024},
	doi = {10.1093/database/baae103},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207727058&doi=10.1093%2fdatabase%2fbaae103&partnerID=40&md5=15184811c1b4ef679eef97159ff813a9},
	abstract = {This manuscript presents PheNormGPT, a framework for extraction and normalization of key findings in clinical text. PheNormGPT relies on an innovative approach, leveraging large language models to extract key findings and phenotypic data in unstructured clinical text and map them to Human Phenotype Ontology concepts. It utilizes OpenAI's GPT-3.5 Turbo and GPT-4 models with fine-tuning and few-shot learning strategies, including a novel few-shot learning strategy for custom-tailored few-shot example selection per request. PheNormGPT was evaluated in the BioCreative VIII Track 3: Genetic Phenotype Extraction from Dysmorphology Physical Examination Entries shared task. PheNormGPT achieved an F1 score of 0.82 for standard matching and 0.72 for exact matching, securing first place for this shared task.  © 2024 The Author(s).},
	keywords = {Data Mining; Humans; Natural Language Processing; Phenotype; data mining; human; natural language processing; phenotype; procedures},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Jiao2024185,
	author = {Jiao, Yizhu and Li, Sha and Zhou, Sizhe and Ji, Heng and Han, Jiawei},
	title = {TEXT2DB: Integration-Aware Information Extraction with Large Language Model Agents},
	year = {2024},
	journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
	pages = {185 – 205},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205299812&partnerID=40&md5=9309afbf3d0f20f6ffc53f227b8ce7a4},
	abstract = {The task of information extraction (IE) is to extract structured knowledge from text. However, it is often not straightforward to utilize IE output due to the mismatch between the IE ontology and the downstream application needs. We propose a new formulation of IE TEXT2DB that emphasizes the integration of IE output and the target database (or knowledge base). Given a user instruction, a document set, and a database, our task requires the model to update the database with values from the document set to satisfy the user instruction. This task requires understanding user instructions for what to extract and adapting to the given DB/KB schema for how to extract on the fly. To evaluate this new task, we introduce a new benchmark featuring common demands such as data infilling, row population, and column addition. In addition, we propose an LLM agent framework OPAL (Observe-Plan-Analyze LLM) which includes an Observer component that interacts with the database, the Planner component that generates a code-based plan with calls to IE models, and the Analyzer component that provides feedback regarding code quality before execution. Experiments show that OPAL can successfully adapt to diverse database schemas by generating different code plans and calling the required IE models. We also highlight difficult cases such as dealing with large databases with complex dependencies and extraction hallucination, which we believe deserve further investigation. © 2024 Association for Computational Linguistics.},
	keywords = {Database systems; Document sets; Downstream applications; Extraction modeling; Extraction ontologies; Infilling; Language model; Model agents; On-the-fly; Structured knowledge; Target database; Computational linguistics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Banerjee2024137,
	author = {Banerjee, Shubhanker and Chakravarthi, Bharathi Raja and McCrae, John Philip},
	title = {Large Language Models for Few-Shot Automatic Term Extraction},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14762 LNCS},
	pages = {137 – 150},
	doi = {10.1007/978-3-031-70239-6_10},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205377483&doi=10.1007%2f978-3-031-70239-6_10&partnerID=40&md5=7d5c980965b9fb26a9c7a6939f55e31a},
	abstract = {Automatic term extraction is the process of identifying domain-specific terms in a text using automated algorithms and is a key first step in ontology learning and knowledge graph creation. Large language models have shown good few-shot capabilities, thus, in this paper, we present a study to evaluate the few-shot in-context learning performance of GPT-3.5-Turbo on automatic term extraction. To benchmark the performance we compare the results with fine-tuning of a BERT-sized model. We also carry out experiments with count-based term extractors to assess their applicability to few-shot scenarios. We quantify prompt sensitivity with experiments to analyze the variation in performance of large language models across different prompt templates. Our results show that in-context learning with GPT-3.5-Turbo outperforms the BERT-based model and unsupervised count-based methods in few-shot scenarios. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {automatic term extraction; few-shot; large language models},
	keywords = {Contrastive Learning; Knowledge graph; Ontology; Automated algorithms; Automatic term extraction; Context learning; Domain specific; Few-shot; In contexts; Language model; Large language model; Ontology learning; Performance; Zero-shot learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Kuai202447,
	author = {Kuai, Ssu-Chi and Liu, Yao-Yu and Lin, Ching-Tzu and Liao, Wen-Hwa},
	title = {Research of Image Generation Based on Knowledge Graph},
	year = {2024},
	journal = {11th IEEE International Conference on Consumer Electronics - Taiwan, ICCE-Taiwan 2024},
	pages = {47 – 48},
	doi = {10.1109/ICCE-Taiwan62264.2024.10674576},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205791716&doi=10.1109%2fICCE-Taiwan62264.2024.10674576&partnerID=40&md5=6647662ee2e6e2c52d5bdc407a9bc636},
	abstract = {In recent years, text-to-image generation technology has achieved significant breakthroughs, especially with the advancement of Diffusion models. Sometimes the model's lack of knowledge or insufficient understanding of the text prompts to generate some unreasonable images. This paper aims to explore how combining knowledge graphs with text prompts can enhance the image generation process by providing additional relevant knowledge about the text prompts, thereby improving the capability of image generation without retraining the diffusion model. © 2024 IEEE.},
	author_keywords = {Diffusion Model; Generative AI; Knowledge Graph; Multimodal Model},
	keywords = {Diffusion model; Generation process; Generation technologies; Generative AI; Image generations; Knowledge graphs; Multimodal models; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{2024,
	title = {EvalLAC 2024 - Proceedings of the 1st Workshop on Automated Evaluation of Learning and Assessment Content, co-located with the 25th International Conference on Artificial Intelligence in Education, AIED 2024},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3772},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207219495&partnerID=40&md5=528768a3557797326bfc5c4f4170683d},
	abstract = {The proceedings contain 10 papers. The topics discussed include: question difficulty prediction based on virtual test-takers and item response theory; can LLMs evaluate items measuring collaborative problem-solving?; enhancing cross-prompt automated essay scoring by selecting training data based on reinforcement learning; exploring large language models for evaluating automatically generated questions; conceptual map assessment through structure classification; evaluation with language models in non-formal education: understanding student’s persuasion style in competitive debating; towards automatic evaluation of questions generated from ontologies; difficulty of items – predictions on linguistic features; and evaluating LLMs’ performance at automatic short-answer grading.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{2024,
	title = {17th International Conference on Knowledge Science, Engineering and Management, KSEM 2024},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14888 LNAI},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206262850&partnerID=40&md5=c3375b18ef8bbfe89e46472703680fa5},
	abstract = {The proceedings contain 160 papers. The special focus in this conference is on Knowledge Science, Engineering and Management. The topics include: EE-LCE: An Event Extraction Framework Based on LLM-Generated CoT Explanation; attention and Learning Features-Enhanced Knowledge Tracing; An MLM Decoding Space Enhancement for Legal Document Proofreading; meta-pruning: Learning to Prune on Few-Shot Learning; knowledge-Informed Molecular Learning: A Survey on Paradigm Transfer; GenFlowchart: Parsing and Understanding Flowchart Using Generative AI; DSCVSR: A Lightweight Video Super-Resolution for Arbitrary Magnification; programming Knowledge Tracing with Context and Structure Integration; an Konwledge-Based Semi-supervised Active Learning Method for Precision Pest Disease Diagnostic; multi-label Feature Selection with Adaptive Subspace Learning; User Story Classification with Machine Learning and LLMs; PTMA: Pre-trained Model Adaptation for Transfer Learning; optimization Strategies for Knowledge Graph Based Distractor Generation; reinforced Subject-Aware Graph Neural Network for Related Work Generation; EFCC-IeT: Cross-Modal Electronic File Content Correlation via Image-Enhanced Text; multi-relation Neural Network Recommendation Model Based on Knowledge Graph Embedding Algorithm; link Prediction Based on Deep Global Information in Heterogeneous Graph; subject Knowledge Entity Relationship Extraction Based on Multi-feature Fusion and Relation Specific Horns Tagging; a Human-Computer Negotiation Model Based on Q-Learning; affine Transformation-Based Knowledge Graph Embedding; integrating Prior Scenario Knowledge for Composition Review Generation; distant Supervised Relation Extraction on Pre-train Model with Improved Multi-label Attention Mechanism; sEMG-Based Multi-view Feature-Constrained Representation Learning; vicinal Data Augmentation for Classification Model via Feature Weaken; STM: An Improved Peak Price Tracking-Based Online Portfolio Selection Algorithm; spatiotemporal Dependence Learning with Meteorological Context for Transportation Demand Prediction; automatic Meter Pointer Reading Based on Knowledge Distillation; multi-table Question Answering Method Based on Correlation Evaluation and Precomputed Cube; a Joint Multi-task Learning Model for Web Table-to-Knowledge Graph Matching; an In-Context Schema Understanding Method for Knowledge Base Question Answering.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Rafalia2024775,
	author = {Rafalia, Najat and Moumen, Idriss and Ziyad, Mouhssine and Abouchabaka, Jaafar},
	title = {Strategic Intelligence: Navigating Hallucinations with Knowledge Graphs and Multi-Agent Systems in Chatbots},
	year = {2024},
	journal = {Lecture Notes in Networks and Systems},
	volume = {1089 LNNS},
	pages = {775 – 782},
	doi = {10.1007/978-3-031-67195-1_85},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206990232&doi=10.1007%2f978-3-031-67195-1_85&partnerID=40&md5=da91dc85986e124f7c9f2c74079bad3d},
	abstract = {The pervasive influence of ChatGPT and similar chatbots on information retrieval and creative tasks is undeniable. However, their susceptibility to hallucinations and inaccuracies, inherent in large language models (LLMs), presents a significant challenge for critical applications. To address this, our paper proposes a novel approach that leverages a structured knowledge graph or knowledge vector as a repository for chatbot responses. This method enables explicit control over the information conveyed, thereby reducing instances of errors and hallucinations. Our primary objective is to engineer a chatbot adept at navigating and comprehending vast amounts of textual data, while providing responses exclusively from a predefined knowledge base for enhanced reliability. Beyond knowledge management, our approach introduces a Multi-Agent System (MAS) to optimize process execution time, significantly improving operational efficiency and overall performance. The combination of knowledge control and a MultiAgent System not only tackles LLM limitations but also amplifies chatbot responsiveness and optimizes processes. Our proposed framework not only safeguards against inaccuracies but also significantly elevates the practical utility of chatbots across diverse applications. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {Chatbots; Hallucination Mitigation; Information Retrieval; Knowledge Graphs; Large Language Models; Multi-Agent Systems; Operational Efficiency},
	keywords = {Information management; Knowledge graph; Modeling languages; Chatbots; Creatives; Critical applications; Hallucination mitigation; Knowledge graphs; Language model; Large language model; Multiagent systems (MASs); Operational efficiencies; Strategic intelligence; Chatbots},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Sumanathilaka2024204,
	author = {Sumanathilaka, Deshan and Micallef, Nicholas and Hough, Julian},
	title = {Assessing GPT's Potential for Word Sense Disambiguation: A Quantitative Evaluation on Prompt Engineering Techniques},
	year = {2024},
	journal = {2024 IEEE 15th Control and System Graduate Research Colloquium, ICSGRC 2024 - Conference Proceeding},
	pages = {204 – 209},
	doi = {10.1109/ICSGRC62081.2024.10691283},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206616975&doi=10.1109%2fICSGRC62081.2024.10691283&partnerID=40&md5=8d948d3ba5ecb3a9bbc150c44fb41485},
	abstract = {Modern digital communications (including social media content) often contain ambiguous words due to their potential for multiple related interpretations (polysemy). This ambiguity poses challenges for traditional Word Sense Disambiguation (WSD) methods, which struggle with limited data and lack of contextual understanding. These limitations hinder efficient translation, information retrieval, and question-answering systems, thereby restricting the benefits of computational linguistics techniques when applied to digital communication technologies. Our research investigates the use of Large Language Models (LLMs) to improve WSD using various prompt engineering techniques. We propose and evaluate a novel method that combines a knowledge graph, together with Part-of-Speech (POS) tagging and few-shot prompting to guide LLMs. By utilizing prompt augmentation with human-in-loop on few-shot prompt approaches, this work demonstrates a substantial improvement in WSD. This research advances accurate word interpretation in digital communications, leading to important implications for improved translation systems, better search results, and more intelligent question-answering technology.  © 2024 IEEE.},
	author_keywords = {Few Shot Prompting; FEWS sense tags; Knowledge Graph; Large Language Models; Word Sense Disambiguation},
	keywords = {Computational linguistics; Digital communication systems; Information retrieval; Modeling languages; Question answering; Search engines; Translation (languages); WSDL; Digital communications; Engineering techniques; Few shot prompting; FEWS sense tag; Knowledge graphs; Language model; Large language model; Quantitative evaluation; Social media; Word Sense Disambiguation; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Sun2024269,
	author = {Sun, Jianing and Zhang, Zhichao and He, Xueli},
	title = {LLM4EduKG: LLM for Automatic Construction of Educational Knowledge Graph},
	year = {2024},
	journal = {Proceedings - 2024 International Conference on Networking and Network Applications, NaNA 2024},
	pages = {269 – 275},
	doi = {10.1109/NaNA63151.2024.00051},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205987881&doi=10.1109%2fNaNA63151.2024.00051&partnerID=40&md5=d9f4729cf8242d0c88edff0c4bead619},
	abstract = {The field of education is undergoing a significant transformation towards digital and intelligent education, driven by advancements in artificial intelligence. Knowledge graphs (KGs), as a structured representation of knowledge and information, offering a powerful way to integrate diverse and multi-sourced heterogeneous data from across the Internet. The current methodologies for constructing educational knowledge graphs, however, are confronted with challenges including labor-intensive, time-consuming, and the necessity for substantial computational resources, which severely limit their practical application, especially in resource-constrained environments. In this paper, we proposed an LLM-based automatic construction method to alleviate the labor and time consumption in existing methods, and further explored LLM's capabilities in Chinese-speaking context. Specifically, we designed a structured prompt framework to automatically extract and evaluate educational triples generated from original text. The prompt encompasses both task and model dimensions, allowing for flexible adjustments to different tasks and models, thus significantly improved the transferability of our method. Comparative experimental results from two real-world Chinese-datasets, across four advanced LLMs, demonstrate the effectiveness of the proposed method. We believe that our work represents a significant attempt by the LLM in the field of education. © 2024 IEEE.},
	author_keywords = {Intelligent Education; Knowledge graph; Large Language Model; Prompt tuning},
	keywords = {'current; Automatic construction; Educational knowledge; Heterogeneous data; Intelligent educations; Knowledge graphs; Labour-intensive; Language model; Large language model; Prompt tuning; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Sun20247417,
	author = {Sun, Lei and Tao, Zhengwei and Li, Youdi and Arakawa, Hiroshi},
	title = {ODA: Observation-Driven Agent for integrating LLMs and Knowledge Graphs},
	year = {2024},
	journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
	pages = {7417 – 7431},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205323036&partnerID=40&md5=04e47ad69c6bc3dbea77538a15ead618},
	abstract = {The integration of Large Language Models (LLMs) and knowledge graphs (KGs) has achieved remarkable success in various natural language processing tasks. However, existing methodologies that integrate LLMs and KGs often navigate the task-solving process solely based on the LLM's analysis of the question, overlooking the rich cognitive potential inherent in the vast knowledge encapsulated in KGs. To address this, we introduce Observation-Driven Agent (ODA), a novel AI agent framework tailored for tasks involving KGs. ODA incorporates KG reasoning abilities via global observation, which enhances reasoning capabilities through a cyclical paradigm of observation, action, and reflection. Confronting the exponential explosion of knowledge during observation, we innovatively design a recursive observation mechanism. Subsequently, we integrate the observed knowledge into the action and reflection modules. Through extensive experiments, ODA demonstrates state-of-the-art performance on several datasets, notably achieving accuracy improvements of 12.87% and 8.9%. Our code and data are available on https://github.com/lanjiuqing64/KGdata. © 2024 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Modeling languages; Natural language processing systems; Agent Framework; Exponential explosion; Global observation; Knowledge graphs; Language model; Language processing; Natural languages; Reasoning ability; Reasoning capabilities; State-of-the-art performance; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Huang2024,
	author = {Huang, Yuxin and Zhao, Zhiyong and Xiang, Yan},
	title = {Relational semantic-enhanced logic rule learning for knowledge graph completion},
	year = {2024},
	journal = {International Journal of Machine Learning and Cybernetics},
	doi = {10.1007/s13042-024-02434-7},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207914784&doi=10.1007%2fs13042-024-02434-7&partnerID=40&md5=916434ab253257116fd3150bad4fdd8e},
	abstract = {Knowledge graph completion (KGC) aims to automatically infer missing information in a knowledge graph (KG). Logical rule learning-based KGC has garnered significant attention due to its ability to provide logical reasoning and strong interpretability. In these models, the input paths are crucial for training the models to learn logical rules. However, topology-based methods like random walk path sampling often ignore the semantic information of relationships in the KG, which can lead to insufficient sampling, thereby affecting the quality of rules and the performance of KGC. To address this issue, we propose a path sampling method enhanced by relational semantics. First, building on random walk sampling, we prompt a large language model (LLM) to infer additional paths by understanding semantic logical connections between relationships in the KG. Second, to address unreasonable paths that may arise from potential hallucinations of the LLM, we propose a path filtering method based on a statistically analyzed relation set. Through this process, we obtain richer and more reasonable paths for logical rule learning, ultimately generating high-quality logical rules to improve the performance of KGC. Experimental results demonstrate that our model outperforms other baseline methods on three public datasets. © The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature 2024.},
	author_keywords = {Knowledge graph completion; Logical rule learning; Path expansion; Relational semantic information},
	keywords = {Adversarial machine learning; Contrastive Learning; Federated learning; Semantics; Knowledge graph completion; Knowledge graphs; Logical rule learning; Logical rules; Path expansion; Random Walk; Relational semantic information; Relational semantics; Rule learning; Semantics Information; Knowledge graph},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Efeoğlu2024,
	author = {Efeoğlu, Şefika and Chen, Zongxiong and Schimmler, Sonja},
	title = {Ensuring FAIRness in Machine Learning Projects},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3780},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207042709&partnerID=40&md5=6ba090d3e012e3bf12816486f5fc0b09},
	abstract = {Subsymbolic approaches like machine learning (ML), deep learning, and Large Language Models (LLMs) have significantly advanced Artificial Intelligence, excelling in tasks such as question answering and ontology matching. Despite their success, the lack of openness in LLMs’ training datasets and source codes poses challenges. For instance, some ML-based models do not share training data, limiting transparency. Current standards like schema.org provide a framework for dataset and software metadata but lack ML-specific guidelines. This position paper addresses this gap by proposing a comprehensive schema for ML model metadata aligned with the FAIR (Findability, Accessibility, Interoperability, Reusability) principles. We aim to provide insights into the necessity of an essential metadata format for ML models, demonstrate its integration into ML repository platforms, and show how this schema, combined with dataset metadata, can evaluate an ML model’s adherence to the FAIR principles, fostering FAIRness in ML development. © 2024 Copyright for this paper by its authors.},
	author_keywords = {FAIR ML; Machine Learning; ML metadata},
	keywords = {Contrastive Learning; Federated learning; Reusability; Findability, accessibility, interoperability, reusability machine learning; Language model; Learning projects; Machine learning metadata; Machine learning models; Machine-learning; Question Answering; Sub-symbolic approach; Adversarial machine learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{2024,
	title = {21st CCF Conference on Web Information Systems and Applications in China, WISA 2024},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14883 LNCS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205103413&partnerID=40&md5=5e079713ccc5adc06247525ded95a554},
	abstract = {The proceedings contain 50 papers. The special focus in this conference is on Web Information Systems and Applications in China. The topics include: GTGNN: Global Graph and Taxonomy Tree for Graph Neural Network Session-Based Recommendation; dual Learning Model of Code Summary and Generation Based on Transformer; relation-Oriented Temporal Knowledge Graphs Completion Based on Recurrent Neural Network; MMPDRec: A Denoising Model for Knowledge Concepts Recommendation Using Metapaths; SPR: A Similar Projection Revisor for Complex Logical Reasoning over Knowledge Graphs; An Generative Entity Relation Extraction Model Based on UIE for Legal Text; uncertain Knowledge Graph Completion with Rule Mining; MAGAN: Mode Information and Attention-Based GAN for Realistic Time Series Data Synthesis; a Study on Context-Matching-Based Joint Training for Chinese Coreference Resolution; DFCDR: Domain-Aware Feature Decoupling and Fusion for Cross-Domain Recommendation; two-Stage Enhancement for Recommendation Systems Based on Contrastive Learning; popularity-Aware Graph Neural Network with Global Context for Session-Based Recommendation; Enhancing Sentiment Analysis for Chinese Texts Using a BERT-Based Model with a Custom Attention Mechanism; contrastive Learning-Based Cross-Domain Data Augmentation for Aspect-Based Sentiment Analysis; a Dynamic Convergence Criterion for Fast K-means Computations; efficient p-Biclique Query on Large Bipartite Networks; high-Dimensional Nearest Neighbor Search-Based Blocking in Entity Resolution; top-k Collective Spatial Keyword Approximate Query; SMSRD: A Streaming Graph Data Management System Based on Relational Database; PLIS: Persistent Learned Index for Strings; dataset Construction for Fine-Grained Emotion Analysis in Catering Review Data; database Parameters Tuning via Bayesian Optimization with Domain Knowledge; attribute Multiplex Network Graph Clustering: Joint Contrastive And High-Order Proximity; reliable Community Search over Dynamic Bipartite Graphs; a Hierarchical Structure Explanation Method for Complex Tables; low-Parameter Federated Learning with Large Language Models; the Journey of Language Models in Understanding Natural Language; Instruction Tuning Large Language Models for Multimodal Relation Extraction Using LoRA.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Ezzabady2024455,
	author = {Ezzabady, Morteza Kamaladdini and Ieng, Frederic and Khorashadizadeh, Hanieh and Benamara, Farah and Groppe, Sven and Sahri, Soror},
	title = {Towards Generating High-Quality Knowledge Graphs by Leveraging Large Language Models},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14762 LNCS},
	pages = {455 – 469},
	doi = {10.1007/978-3-031-70239-6_31},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205363177&doi=10.1007%2f978-3-031-70239-6_31&partnerID=40&md5=d7f8be970043486ed3afeee920af10f6},
	abstract = {Knowledge graph creation requires relation extraction (RE) tools often trained on annotated data either manually or by distant supervision. Recent approaches operate at the model level to handle new domains with unseen relations, relying on transfer learning or generative approaches in few/zero-shot learning scenarios. In this paper, we adopt a different strategy by operating instead at the level of dataset creation. We, for the first time to the best of our knowledge, investigate the ability of prompt-based models to build high-quality RE datasets relying on GPT4 to extract triples from sentences. Our approach is further enhanced by linking our knowledge graph to Wikidata, a step that enriches our dataset and ensures its interoperability. This strategy has been successfully employed in two use cases: COVID and health relation extraction. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {Data Quality; Knowledge Graph; Relation Extraction},
	keywords = {Adversarial machine learning; Contrastive Learning; Self-supervised learning; Zero-shot learning; Data quality; High quality; Knowledge graphs; Language model; Learning scenarios; Quality knowledge; Relation extraction; Transfer learning; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{2024,
	title = {SeMatS 2024 - Proceedings of the 1st International Workshop on Semantic Materials Science: Harnessing the Power of Semantic Web Technologies in Materials Science, co-located with the 20th International Conference on Semantic Systems, SEMANTiCS 2024},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3760},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205014978&partnerID=40&md5=5ec6a2830248aac190d3634934914798},
	abstract = {The proceedings contain 10 papers. The topics discussed include: PBF-AMP-onto: an ontology for powder bed fusion additive manufacturing processes; an ontology for units of measures across history, standards, and scientific and technology domains; top level ontologies: desirable characteristics in the context of materials science; PolyMat - bringing semantics to polymer membrane research; implementing semantic technologies in materials science and engineering; enhancing semantic interoperability across materials science with HIVE4MAT; the landscape of ontologies in materials science and engineering: a survey and evaluation; leveraging large language models for automated knowledge graphs generation in non-destructive testing; and battery manufacturing knowledge infrastructure requirements for multicriteria optimization based decision support in design of simulation.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Sawczyn202410978,
	author = {Sawczyn, Albert and Viarenich, Katsiaryna and Wojtasik, Konrad and Domogala, Aleksandra and Oleksy, Marcin and Piasecki, Maciej and Kajdanowicz, Tomasz},
	title = {Developing PUGG for Polish: A Modern Approach to KBQA, MRC, and IR Dataset Construction},
	year = {2024},
	journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
	pages = {10978 – 10996},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205314119&partnerID=40&md5=e538fd5b1f303b9e316abe118cdc3d57},
	abstract = {Advancements in AI and natural language processing have revolutionized machine-human language interactions, with question answering (QA) systems playing a pivotal role. The knowledge base question answering (KBQA) task, utilizing structured knowledge graphs (KG), allows for handling extensive knowledge-intensive questions. However, a significant gap exists in KBQA datasets, especially for low-resource languages. Many existing construction pipelines for these datasets are outdated and inefficient in human labor, and modern assisting tools like Large Language Models (LLM) are not utilized to reduce the workload. To address this, we have designed and implemented a modern, semi-automated approach for creating datasets, encompassing tasks such as KBQA, Machine Reading Comprehension (MRC), and Information Retrieval (IR), tailored explicitly for low-resource environments. We executed this pipeline and introduced the PUGG dataset, the first Polish KBQA dataset, and novel datasets for MRC and IR. Additionally, we provide a comprehensive implementation, insightful findings, detailed statistics, and evaluation of baseline models. © 2024 Association for Computational Linguistics.},
	keywords = {Knowledge graph; Large datasets; Natural language processing systems; Answering machines; Human language; Language processing; Languages interactions; Natural languages; Question Answering; Question answering systems; Question Answering Task; Reading comprehension; Structured knowledge; Computational linguistics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Wang2024,
	author = {Wang, Zhenyu and Wu, Yifei},
	title = {Enhance Large Language Models for Multilingual Sentence Embedding with Knowledge Graph},
	year = {2024},
	journal = {Proceedings of the International Joint Conference on Neural Networks},
	doi = {10.1109/IJCNN60899.2024.10650221},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204964647&doi=10.1109%2fIJCNN60899.2024.10650221&partnerID=40&md5=05eb081fbedb4b03bde8b49ae967eac5},
	abstract = {Sentence representation is a major challenge in natural language processing, especially in multilingual environments. Current approaches to sentence representation using Large Language Models (LLMs) often require large amounts of data for fine-tuning, and research has focused on English content. In addition, comparative datasets translated directly from English can contain many semantic and syntactic errors. To address these issues, we propose a new approach to enhance multilingual sentence embeddings using LLMs and knowledge graphs. We first present a dedicated designed prompt that exploits in-context learning of LLMs for sentence embedding without fine-tuning. We further introduce an innovative method that utilizes knowledge graphs, such as Wikidata, for generating diverse multilingual training data for contrastive finetuning. This approach significantly reduces the reliance on translated sentences and mitigates issues related to translation accuracy. Furthermore, we develop a unique multilingual contrastive learning loss function, which, when combined with QLora's efficient fine-tuning technique, enables LLMs to achieve state-of-the-art performance in Sentence Text Similarity (STS) tasks, even with limited computational resources. © 2024 IEEE.},
	author_keywords = {contrastive learning; data argumentation; large language model; sentence embedding},
	keywords = {Graph embeddings; Knowledge graph; Natural language processing systems; Semantics; Translation (languages); Data argumentation; Embeddings; Fine tuning; Knowledge graphs; Language model; Language processing; Large language model; Multilingual sentences; Natural languages; Sentence embedding; Contrastive Learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Wang20243742,
	author = {Wang, Kai and Xu, Yuwei and Wu, Zhiyong and Luo, Siqiang},
	title = {LLM as Prompter: Low-resource Inductive Reasoning on Arbitrary Knowledge Graphs},
	year = {2024},
	journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
	pages = {3742 – 3759},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205298421&partnerID=40&md5=5fc862d04c842e5d667456530109dad6},
	abstract = {Knowledge Graph (KG) inductive reasoning, which aims to infer missing facts from new KGs that are not seen during training, has been widely adopted in various applications. One critical challenge of KG inductive reasoning is handling low-resource scenarios with scarcity in both textual and structural aspects. In this paper, we attempt to address this challenge with Large Language Models (LLMs). Particularly, we utilize the state-of-the-art LLMs to generate a graph-structural prompt to enhance the pre-trained Graph Neural Networks (GNNs), which brings us new methodological insights into the KG inductive reasoning methods, as well as high generalizability in practice. On the methodological side, we introduce a novel pretraining and prompting framework PROLINK, designed for low-resource inductive reasoning across arbitrary KGs without requiring additional training. On the practical side, we experimentally evaluate our approach on 36 low-resource KG datasets and find that PROLINK outperforms previous methods in three-shot, one-shot, and zero-shot reasoning tasks, exhibiting average performance improvements by 20%, 45%, and 147%, respectively. Furthermore, PROLINK demonstrates strong robustness for various LLM promptings as well as full-shot scenarios. Our source code is available on https://github.com/KyneWang/ProLINK. © 2024 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Graph neural networks; Network theory (graphs); Critical challenges; Graph neural networks; Inductive reasoning; Knowledge graphs; Language model; Pre-training; Reasoning methods; Reasoning tasks; State of the art; Structural aspects; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Aggarwal2024,
	author = {Aggarwal, Tanay and Salatino, Angelo and Osborne, Francesco and Motta, Enrico},
	title = {Identifying Semantic Relationships Between Research Topics Using Large Language Models in a Zero-Shot Learning Setting},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3780},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207042155&partnerID=40&md5=595559c5582ddfa5a9fb95c64b924450},
	abstract = {Knowledge Organization Systems (KOS), such as ontologies, taxonomies, and thesauri, play a crucial role in organising scientific knowledge. They help scientists navigate the vast landscape of research literature and are essential for building intelligent systems such as smart search engines, recommendation systems, conversational agents, and advanced analytics tools. However, the manual creation of these KOSs is costly, time-consuming, and often leads to outdated and overly broad representations. As a result, researchers have been exploring automated or semi-automated methods for generating ontologies of research topics. This paper analyses the use of large language models (LLMs) to identify semantic relationships between research topics. We specifically focus on six open and lightweight LLMs (up to 10.7 billion parameters) and use two zero-shot reasoning strategies to identify four types of relationships: broader, narrower, same-as, and other. Our preliminary analysis indicates that Dolphin2.1-OpenOrca-7B performs strongly in this task, achieving a 0.853 F1-score against a gold standard of 1,000 relationships derived from the IEEE Thesaurus. These promising results bring us one step closer to the next generation of tools for automatically curating KOSs, ultimately making the scientific literature easier to explore. © 2024 Copyright for this paper by its authors.},
	author_keywords = {Large Language Models; Ontology Generation; Research Topics; Scholarly Knowledge; Scientific Knowledge Graphs; Zero-Shot Learning},
	keywords = {Adversarial machine learning; Contrastive Learning; Federated learning; Knowledge graph; Knowledge organization system (KOS); Latent semantic analysis; Ontology; Recommender systems; Semantics; Taxonomies; Knowledge graphs; Language model; Large language model; Ontology generation; Ontology's; Research topics; Scholarly knowledge; Scientific knowledge; Scientific knowledge graph; Semantic relationships; Zero-shot learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Von Der Assen2024437,
	author = {Von Der Assen, Jan and Sharif, Jamo and Feng, Chao and Killer, Christian and Bovet, Gerome and Stiller, Burkhard},
	title = {Asset-Centric Threat Modeling for AI-Based Systems},
	year = {2024},
	journal = {Proceedings of the 2024 IEEE International Conference on Cyber Security and Resilience, CSR 2024},
	pages = {437 – 444},
	doi = {10.1109/CSR61664.2024.10679445},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206187492&doi=10.1109%2fCSR61664.2024.10679445&partnerID=40&md5=b7c16f456139eb9029c8a48d3f9fb1f7},
	abstract = {Threat modeling for systems relying on Artificial In-telligence is not well explored. While conventional threat modeling methods and tools do not address AI-related threats, research on this amalgamation still lacks solutions capable of guiding and automating the process, as well as providing evidence that the methods hold up in practice. Consequently, this paper presents ThreatFinderAI, an approach and tool providing guidance and automation to model AI-related assets, threats, countermeasures, and quantify residual risks. To do so, ThreatFinderAI presents a novel AI-based stencil library for automated asset extraction, a threat knowledge graph spanning several community initiatives, and a novel method to identify business impacts of AI threats and an approach to quantify them. To evaluate the practicality of the approach, participants were tasked to recreate a threat model developed by cybersecurity experts of an AI-based healthcare platform. Secondly, the approach was used to identify and discuss strategic risks in an LLM-based application through a case study. Overall, the solution's usability was well-perceived and effectively supports threat identification and risk discussion. © 2024 IEEE.},
	author_keywords = {AI Security; Risk Analysis; Threat Modeling},
	keywords = {AI security; Business impact; Hold up; Knowledge graphs; Model method; Modelling tools; Novel methods; Residual risk; Risk analyze; Threat modeling},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@CONFERENCE{Gupta2024,
	author = {Gupta, Bhumika and Ta, Pralaypati and Ram, Keerthi and Sivaprakasam, Mohanasankar},
	title = {Comprehensive Modeling and Question Answering of Cancer Clinical Practice Guidelines using LLMs},
	year = {2024},
	journal = {21st IEEE Conference on Computational Intelligence in Bioinformatics and Computational Biology, CIBCB 2024},
	doi = {10.1109/CIBCB58642.2024.10702112},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207512735&doi=10.1109%2fCIBCB58642.2024.10702112&partnerID=40&md5=e6467da12d9ec3352551e318d7a0d061},
	abstract = {The updated recommendations on diagnostic procedures and treatment pathways for a medical condition are documented as graphical flows in Clinical Practice Guidelines (CPGs). For effective use of the CPGs in helping medical professionals in the treatment decision process, it is necessary to fully capture the guideline knowledge, particularly the contexts and their relationships in the graph. While several existing works have utilized these guidelines to create a rule base for Clinical Decision Support Systems, limited work has been done toward directly capturing the full medical knowledge contained in CPGs. This work proposes an approach to create a contextually enriched, faithful digital representation of National Comprehensive Cancer Network (NCCN) Cancer CPGs in the form of graphs using automated extraction and node & relationship classification. We also implement semantic enrichment of the model by using Large Language Models (LLMs) for node classification, achieving an accuracy of 80.86% and 88.47% with zero-shot learning and few-shot learning, respectively. Additionally, we introduce a methodology for answering natural language questions with constraints based on guideline text by leveraging LLMs to extract the relevant subgraph from the guideline knowledge base. By generating natural language answers based on subgraph paths and semantic information, we mitigate the risk of incorrect answers and hallucinations associated with LLMs, ensuring factual accuracy in medical domain question answering. © 2024 IEEE.},
	author_keywords = {Cancer CPGs; Knowledge Model Enrichment; Knowledge Representation; Large Language Models (LLMs); NCCN; question-answering},
	keywords = {Diagnosis; Diseases; Knowledge graph; Semantics; Cancer clinical practice guideline; Clinical practice guidelines; Knowledge model; Knowledge model enrichment; Knowledge-representation; Language model; Large language model; National comprehensive cancer network; Question Answering; Subgraphs; Zero-shot learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Yang2024,
	author = {Yang, Rui and Zeng, Qingcheng and You, Keen and Qiao, Yujie and Huang, Lucas and Hsieh, Chia-Chun and Rosand, Benjamin and Goldwasser, Jeremy and Dave, Amisha and Keenan, Tiarnan and Ke, Yuhe and Hong, Chuan and Liu, Nan and Chew, Emily and Radev, Dragomir and Lu, Zhiyong and Xu, Hua and Chen, Qingyu and Li, Irene},
	title = {Ascle—A Python Natural Language Processing Toolkit for Medical Text Generation: Development and Evaluation Study},
	year = {2024},
	journal = {Journal of Medical Internet Research},
	volume = {26},
	doi = {10.2196/60601},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205605906&doi=10.2196%2f60601&partnerID=40&md5=98fff69cc9aa11e2d597bb127d0a9e03},
	abstract = {Background: Medical texts present significant domain-specific challenges, and manually curating these texts is a time-consuming and labor-intensive process. To address this, natural language processing (NLP) algorithms have been developed to automate text processing. In the biomedical field, various toolkits for text processing exist, which have greatly improved the efficiency of handling unstructured text. However, these existing toolkits tend to emphasize different perspectives, and none of them offer generation capabilities, leaving a significant gap in the current offerings. Objective: This study aims to describe the development and preliminary evaluation of Ascle. Ascle is tailored for biomedical researchers and clinical staff with an easy-to-use, all-in-one solution that requires minimal programming expertise. For the first time, Ascle provides 4 advanced and challenging generative functions: question-answering, text summarization, text simplification, and machine translation. In addition, Ascle integrates 12 essential NLP functions, along with query and search capabilities for clinical databases. Methods: We fine-tuned 32 domain-specific language models and evaluated them thoroughly on 27 established benchmarks. In addition, for the question-answering task, we developed a retrieval-augmented generation (RAG) framework for large language models that incorporated a medical knowledge graph with ranking techniques to enhance the reliability of generated answers. Additionally, we conducted a physician validation to assess the quality of generated content beyond automated metrics. Results: The fine-tuned models and RAG framework consistently enhanced text generation tasks. For example, the fine-tuned models improved the machine translation task by 20.27 in terms of BLEU score. In the question-answering task, the RAG framework raised the ROUGE-L score by 18% over the vanilla models. Physician validation of generated answers showed high scores for readability (4.95/5) and relevancy (4.43/5), with a lower score for accuracy (3.90/5) and completeness (3.31/5). Conclusions: This study introduces the development and evaluation of Ascle, a user-friendly NLP toolkit designed for medical text generation. All code is publicly available through the Ascle GitHub repository. All fine-tuned language models can be accessed through Hugging Face. ©Rui Yang, Qingcheng Zeng, Keen You, Yujie Qiao, Lucas Huang, Chia-Chun Hsieh, Benjamin Rosand, Jeremy Goldwasser, Amisha Dave, Tiarnan Keenan, Yuhe Ke, Chuan Hong, Nan Liu, Emily Chew, Dragomir Radev, Zhiyong Lu, Hua Xu, Qingyu Chen, Irene Li. Originally published in the Journal of Medical Internet Research (https://www.jmir.org), 03.10.2024.},
	author_keywords = {deep learning; generative artificial intelligence; healthcare; large language models; machine learning; natural language processing; retrieval-augmented generation},
	keywords = {Algorithms; Humans; Natural Language Processing; Software; algorithm; article; benchmarking; data base; deep learning; generative artificial intelligence; human; information retrieval; Internet; language model; large language model; machine learning; natural language processing; reliability; Vanilla; word processing; software},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Kang2024,
	author = {Kang, Jiaju and Pan, Weichao and Zhang, Tian and Wang, Ziming and Yang, Shuqin and Wang, Zhiqin and Wang, Jian and Niu, Xiaofei},
	title = {Correcting Factuality Hallucination in Complaint Large Language Model via Entity-Augmented},
	year = {2024},
	journal = {Proceedings of the International Joint Conference on Neural Networks},
	doi = {10.1109/IJCNN60899.2024.10650208},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204971855&doi=10.1109%2fIJCNN60899.2024.10650208&partnerID=40&md5=11b6ea8ac0cecf98f5ba4b5a43bbd904},
	abstract = {Complaint Large Language Model (Complaint-LLM) is designed as a "customer service"tool to address the scenario of handling a massive volume of public complaints, effectively leveraging the "common sense"possessed by Large Language Models (LLMs) to solve issues. Unfortunately, pre-trained LLMs often exhibit significant Factual Hallucination and Causal Errors in knowledge domains with sparse experience distribution, greatly affecting the accuracy of user interactions with LLMs. We propose an architecture that utilizes external data to support pre-trained models, aiming to avoid the expensive cost of retraining LLMs. The core concept involves leveraging prompts to inject strongly correlated additional information into LLMs and adjusting the initialized alternative outputs along the inference pathway of the LLM. To achieve this, we construct a rich knowledge graph as a knowledge base for algorithm retrieval and learning. Each input text is decomposed into subgraphs corresponding to nodes on the knowledge graph, and a graph neural network classifier is trained to obtain classification results and additional knowledge. Numerous experiments demonstrate that the Complaint-LLMs shows a significant improvement in the question-answering evaluation of various subclass scenarios in the complaint domain. Moreover, the graph neural network trained with complaint text data exhibits good transferability in classification tests for open scenarios. © 2024 IEEE.},
	keywords = {Domain Knowledge; Graph neural networks; Inference engines; Metadata; Modeling languages; Classification results; Common sense; Customer service tools; Graph neural networks; Knowledge domains; Knowledge graphs; Language model; Neural networks classifiers; Subgraphs; User interaction; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Yadav2024,
	author = {Yadav, Divyanshi and Para, Hitesh and Sandhu, Komal and Selvakumar, Prakash},
	title = {Enhancing Response Generation Systems: Knowledge Graph & Generative AI Synergy for Business Communication and Strategic Decision Making},
	year = {2024},
	journal = {International Conference on Electrical, Computer, and Energy Technologies, ICECET 2024},
	doi = {10.1109/ICECET61485.2024.10698632},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207473006&doi=10.1109%2fICECET61485.2024.10698632&partnerID=40&md5=4d8572df88288401220f48bb78a2c249},
	abstract = {In the contemporary business environment, it is crucial to have an efficient and precise response generation system to build client trust, optimize operations, and provide customized solutions. Current response management systems often face challenges such as insufficient depth, scalability issues, and inconsistencies. There is an urgent requirement for a comprehensive system that can retrieve information for generating high-quality insights and convert it to a reply. To address these needs, an approach has been explored that integrates a domain-oriented Knowledge Graph (KG), vector embeddings, Large Language Model (LLM) and utilize the pathway parsing technique that allows for in-depth multi-hop analysis within the KG, resulting in detailed and contextually rich data retrieval. This combination enhances the performance and precision of handling inquiries, streamlines entity extraction and step identification, leverages KG for Standard Operating Procedure (SOP) guidance, and offers superior recommendations or strategies for informed decision making. The concept will be illustrated through a business study focusing on the collections department use case, which involves customer correspondence. This approach ensures a more efficient, and accurate responses, leading to reduced human intervention and latency, along with that customer satisfaction is improved and business processes are streamlined. By adopting this method, businesses can enhance their communication, make data-driven decisions, and ultimately achieve better results in the competitive market. The efficacy is evident in the practical instances, owing to its profound grasp of context. © 2024 IEEE.},
	author_keywords = {Decision Making; Email Handling; Information Retrieval; Knowledge Graphs; Large Language Model; Natural Language Processing; Natural Language Understanding; Pathways parsing; Response Generation; Retrieval Augmented Generation; Word Embeddings},
	keywords = {Decision making; Graph embeddings; Knowledge graph; Modeling languages; Natural language processing systems; Network security; Sales; Word processing; Decisions makings; Email handlings; Embeddings; Knowledge graphs; Language model; Language processing; Large language model; Natural language processing; Natural language understanding; Natural languages; Pathway parsing; Response generation; Retrieval augmented generation; Word embedding; Customer satisfaction},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Li2024793,
	author = {Li, Yuexin and Huang, Chengyu and Deng, Shumin and Lock, Mei Lin and Cao, Tri and Oo, Nay and Lim, Hoon Wei and Hooi, Bryan},
	title = {KnowPhish: Large Language Models Meet Multimodal Knowledge Graphs for Enhancing Reference-Based Phishing Detection},
	year = {2024},
	journal = {Proceedings of the 33rd USENIX Security Symposium},
	pages = {793 – 810},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205030545&partnerID=40&md5=3540f4da4fc1f8a35f2fb1a5501f15dc},
	abstract = {Phishing attacks have inflicted substantial losses on individuals and businesses alike, necessitating the development of robust and efficient automated phishing detection approaches. Reference-based phishing detectors (RBPDs), which compare the logos on a target webpage to a known set of logos, have emerged as the state-of-the-art approach. However, a major limitation of existing RBPDs is that they rely on a manually constructed brand knowledge base, making it infeasible to scale to a large number of brands, which results in false negative errors due to the insufficient brand coverage of the knowledge base. To address this issue, we propose an automated knowledge collection pipeline, using which we collect a large-scale multimodal brand knowledge base, KnowPhish, containing 20k brands with rich information about each brand. KnowPhish can be used to boost the performance of existing RBPDs in a plug-and-play manner. A second limitation of existing RBPDs is that they solely rely on the image modality, ignoring useful textual information present in the webpage HTML. To utilize this textual information, we propose a Large Language Model (LLM)-based approach to extract brand information of webpages from text. Our resulting multimodal phishing detection approach, KnowPhish Detector (KPD), can detect phishing webpages with or without logos. We evaluate KnowPhish and KPD on a manually validated dataset, and a field study under Singapore's local context, showing substantial improvements in effectiveness and efficiency compared to state-of-the-art baselines. © USENIX Security Symposium 2024.All rights reserved.},
	keywords = {Knowledge acquisition; Knowledge graph; Detection approach; Knowledge graphs; Language model; Multi-modal; Phishing; Phishing attacks; Phishing detections; State-of-the-art approach; Textual information; Web-page; Phishing},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{2024,
	title = {5th International Conference on Higher Education Learning Methodologies and Technologies Online, HELMeTO 2023},
	year = {2024},
	journal = {Communications in Computer and Information Science},
	volume = {2076 CCIS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205388146&partnerID=40&md5=56b41c5891711234ed5a42db9e4f6bc0},
	abstract = {The proceedings contain 52 papers. The special focus in this conference is on Higher Education Learning Methodologies and Technologies Online. The topics include: Get in (Multi)touch with the Tangent; internationalisation Experience on a Digital Platform and Its Impact on Self-efficacy: The Results on a Sample of Initial Teacher Education Students; digital Multisensory Storytelling as Educational-Didactic Methodology for Emotional Literacy; automated Online Assessment and Cloud-Based Programming: Advancing Computer Engineering Education; Leveraging Explainable AI Methods and Tools for Educational Data; botBid - From Botany to Big Data: Combining Citizen Science and Innovative Teaching Methodologies; detecting the Usage of Large Language Models Exploiting Generative Adversarial Networks; ontology for Constructively Aligned, Collaborative, and Evolving Engineer Knowledge-Management Platforms; augmented Didactic: The Potential of Gesture in Mobile Learning to Enhance Learning; digital Twins and E-Learning: Navigating Challenges and Opportunities; emotions in Practice: Studying Lectures and Seminars in On-Line and Offline Education; performing Art-Based Methodology for Empathetic Transposition into Online Learning Experiences; improving Student Online Interactions and Teacher’s Ability to Manage Them with the Quick Chat Moodle Plugin; promoting Meaningful Learning in Topology Supported by Undergraduate Students’ Video Creations; the Feedback in a Formative Assessment Path: Development of Communicative Skills in a Workshop Online; online Resources for Training Pre-service Primary School Teachers in Mathematics; mathematics Interpretative Tasks and Formative Assessment: A Digital Device for Teachers Training; Cybersecurity for Teens (CS4T) – A Project by Ludoteca of Registro .it; Learning CyberSecurity with Story-Driven CTF Challenges: CyberTrials 2023; superCyberKids: Enhancing Cybersecurity Education in K-12 Through Digital Game-Based Learning; Empowering Higher Education with ChatGPT: Innovating University Instructional Design.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Perera2024299,
	author = {Perera, Olga and Liu, Jun},
	title = {Exploring large language models for ontology learning},
	year = {2024},
	journal = {Issues in Information Systems},
	volume = {25},
	number = {4},
	pages = {299 – 310},
	doi = {10.48009/4_iis_2024_124},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205759289&doi=10.48009%2f4_iis_2024_124&partnerID=40&md5=1f455018fe83b87516b8e774e780952b},
	abstract = {Ontology Learning aims to facilitate automatic or semi-automatic ontology development based on machine learning techniques in context of big data. Recent evolution of technology has introduced Generative Artificial Intelligence (AI) capable of creating new data, extracting insights from the existing data, and generating coherent texts from various inputs. This ability supports analysis of text data, providing insights and annotations that reduce human effort. This study explores the emerging field of Generative AI, specifically, Large Language Models for ontology learning. We conducted a survey of the current state of Generative AI research with focus on applicability and efficacy for ontology development tasks, and assessment of evaluation techniques. We discussed challenges related to explainability and interpretability of Generative AI and outlined directions for future research. © 2024 International Association for Computer Information Systems. All rights reserved.},
	author_keywords = {deep learning; Generative AI; large language models; LLM; ontology learning},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@CONFERENCE{Park20245815,
	author = {Park, Jun-Hyung and Lee, Mingyu and Kim, Junho and Lee, SangKeun},
	title = {COCONUT: Contextualized Commonsense Unified Transformers for Graph-Based Commonsense Augmentation of Language Models},
	year = {2024},
	journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
	pages = {5815 – 5830},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205290269&partnerID=40&md5=87c1ca72103da6f3873be09aa03ecc7a},
	abstract = {In this paper, we introduce COCONUT to effectively guide the contextualization of structured commonsense knowledge based on large language models. COCONUT employs a contextualized knowledge prompting scheme to gather high-quality contextualization examples from a large language model. These examples are subsequently distilled into small language models to enhance their contextualization capability. Extensive evaluations show that COCONUT considerably improves commonsense reasoning performance across diverse benchmarks, models, and settings, exhibiting its flexibility and universality in generating contextualized commonsense knowledge. Notably, COCONUT consistently outperforms the state-of-the-art technique by an average of 5.8%. © 2024 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Knowledge graph; Benchmark models; Commonsense knowledge; Commonsense reasoning; Contextualization; Contextualized knowledge; Graph-based; High quality; Knowledge based; Language model; Reasoning performance; Distribution transformers},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Canal-Esteve202424,
	author = {Canal-Esteve, Miquel},
	title = {Educational Material to Knowledge Graph Conversion: A Methodology to Enhance Digital Education},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3797},
	pages = {24 – 32},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207918417&partnerID=40&md5=31f09c29b4a650f5c1123b8bfdfac259},
	abstract = {This paper aims to present a line of research focused on the automatization of structuring digital educational content as knowledge graphs (KGs) to enhance natural language processing tasks. Unlike traditional repositories like Moodle, KGs offer a more flexible representation of relationships between concepts, facilitating intuitive navigation and discovery of connections. By integrating effectively with Large Language Models, KGs can improve personalized explanations, answers, and recommendations. This research will explore and develop technologies for creating and editing educational data (both text and multimedia) and technologies that enable students and teachers to utilize this structured knowledge effectively. © 2024 Copyright for this paper by its authors.},
	author_keywords = {Automated Knowledge Graph Generation; Educational Material to Knowledge Graph Conversion; Intelligent Educational Technologies; Large Language Models; Personalized Learning},
	keywords = {Educational technology; Automated knowledge graph generation; Educational material to knowledge graph conversion; Educational materials; Graph generation; Intelligent educational technology; Knowledge graphs; Language model; Large language model; Personalized learning; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Peng2024,
	author = {Peng, Bohua and Chen, Bin and He, Wei and Thorne, William and Kadirkamanathan, Visakan},
	title = {Efficient Token Sparsification Through the Lens of Infused Knowledge},
	year = {2024},
	journal = {FUSION 2024 - 27th International Conference on Information Fusion},
	doi = {10.23919/FUSION59988.2024.10706518},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207694759&doi=10.23919%2fFUSION59988.2024.10706518&partnerID=40&md5=051125486b29b6809dd94d423654304a},
	abstract = {Leveraging large language models (LLMs) to fuse heterogeneous knowledge is an exciting emerging field. However, with billions of parameters, these pretrained language models are prohibitively computationally expensive at inference time. Token sparsification methods can proactively accelerate inference by selecting important features from the sequence but often require task-dependent retraining. To address this, we propose Bilevel Token prUniNg wiTh Infused kNowledGe (Bunting), an interpretable token pruning method that leverages task-level knowledge encoded in prefixes to guide token sparsification, eliminating the need for task-specific retraining. Bunting performs Bayesian Token Sparsification, where the inner loop learns a joint representation to perform the task, and the outer loop learns adaptive attention masks for sparse representations, thus pruning redundant tokens layer-by-layer without compromising the pretrained abilities of LLMs. Additionally, we introduce an innovative antiphrasis evaluation protocol to test model adaptivity on rhetorical relations. Furthermore, we demonstrate that precomputed prefixes can effectively guide token sparsification in different knowledge-intensive tasks, maintaining task-level knowledge to identify important tokens and reduce the finetuning burden. Experimental results demonstrate that our method achieves over 0.3x wall-clock speed-up with only 0.14 × learnable parameters in knowledge-intensive tasks. Our findings suggest that token pruning can improve out-of-distribution detection, with sarcasm being more challenging to detect than immorality. © 2024 ISIF.},
	author_keywords = {Knowledge graphs; large language models; out-of-distribution detection},
	keywords = {Heterogeneous Knowledge; Knowledge graphs; Knowledge intensive tasks; Language model; Large language model; Learn+; Out-of-distribution detection; Sparsification; Task levels; Through the lens; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Kougioumtzidou2024247,
	author = {Kougioumtzidou, Anna and Papoutsis, Angelos and Kavallieros, Dimitrios and Mavropoulos, Thanassis and Tsikrika, Theodora and Vrochidis, Stefanos and Kompatsiaris, Ioannis},
	title = {An End-to-End Framework for Cybersecurity Taxonomy and Ontology Generation and Updating},
	year = {2024},
	journal = {Proceedings of the 2024 IEEE International Conference on Cyber Security and Resilience, CSR 2024},
	pages = {247 – 254},
	doi = {10.1109/CSR61664.2024.10679346},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206170969&doi=10.1109%2fCSR61664.2024.10679346&partnerID=40&md5=80cea9ee0478d6ecace4a95d870fa4a7},
	abstract = {Effective cyber-defense practices often require the use of structured knowledge representations, such as taxonomies and ontologies, to organise vast amounts of data and facili-tate knowledge representation and reasoning. To this end, we present an Artificial Intelligence (AI)-assisted framework for the construction and update of cybersecurity taxonomies and ontologies. The proposed framework can be divided into three main phases: Taxonomy Construction, Ontology Construction, and Taxonomy/Ontology Update, each phase consisting of both information extraction and semantic knowledge representation components. For information extraction, we employ a variety of techniques originating from Natural Language Processing (NLP), particularly Transformer Neural Networks. For constructing ontologies, we propose a conceptual ontology schema based on the STIX 2.1 standard for modeling information related to attacks, threats, and vulnerabilities, and use the Owlready2 Python library. Overall, our framework effectively builds cybersecurity taxonomies and ontologies and updates existing knowledge of both the generated and open-source taxonomies and ontologies. © 2024 IEEE.},
	author_keywords = {artificial intelligence; attacks; cybersecurity; dynamic update; large language models; natural language processing; ontologies; taxonomies; vulnerabilities},
	keywords = {Knowledge representation; Phishing; Semantics; Attack; Cyber security; Dynamic update; Language model; Language processing; Large language model; Natural language processing; Natural languages; Ontology's; Vulnerability; Cyber attacks},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Kovriguina2024,
	author = {Kovriguina, Liubov and Aung, Linn and Haase, Peter and Heiß, Simon and Heist, Nicolas and Lamprecht, David},
	title = {Enhancing Scientific Discovery and Decision-Making: A Knowledge Graph-based Research Support System},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3780},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207054543&partnerID=40&md5=38d076fbe3a7f367baed43e61c410a0f},
	abstract = {This work presents a neurosymbolic AI system for support of research and discovery activities. The system is powered by metaphactory and builds on the open scholarly knowledge graphs SemOpenAlex, LPWC and CS-KG. Researchers are supported through a range of AI methods (generative natural language interface to KGs, retrieval with semantic templates, neighborhood exploration with KG embeddings) offering convenient means to solve research tasks like scientific artifacts overview, publication search and getting recommendations. This work gives an overview of the system design, architecture, data landscape and supported functionalities. A concrete implementation of this system is used in a research project exploring the application of AI methods for electric traction drives design. © 2022 Author.},
	author_keywords = {AI for scientific discovery; KG-based systems for scientific discovery; LLM interfaces to knowledge graphs; neurosymbolic AI methods for research support; scholarly knowledge graphs},
	keywords = {Graph embeddings; Semantics; AI for scientific discovery; KG-based system for scientific discovery; Knowledge graphs; LLM interface to knowledge graph; Neurosymbolic AI method for research support; Research support; Scholarly knowledge graph; Scientific discovery; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Rong2024631,
	author = {Rong, Shiqiang and Li, Rili and Sun, Xiaocui and Yi, Faling},
	title = {Research on Named Entity Recognition Algorithm for Diabetes Intelligent Question and Answer System},
	year = {2024},
	journal = {2024 6th International Conference on Internet of Things, Automation and Artificial Intelligence, IoTAAI 2024},
	pages = {631 – 637},
	doi = {10.1109/IoTAAI62601.2024.10692530},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207047578&doi=10.1109%2fIoTAAI62601.2024.10692530&partnerID=40&md5=486a1d90b5024406a4a757ae30ace0d6},
	abstract = {Named Entity Recognition (NER) is an important basis for constructing knowledge graph. Combining knowledge graph with pre-trained large language model is an important research direction of current intelligent question and answer system. Based on the knowledge system of daily prevention and management of diabetes and the corresponding answers, the corresponding named entity recognition method is studied, and the recognition method of dictionary rules and Bert + BiLSTM + CRF model fusion is proposed. Firstly, the dictionary rules using AC automaton character matching and context analysis method to effectively identify the disease, symptoms, indicators and other fixed types of entities and classification are built; then, the Bert + BiLSTM + CRF model is constructed to achieve good performances in the identification of extensible entities such as inspections, drugs, treatment methods, and food. In the process of training Bert + BiLSTM + CRF model, various strategies such as entity replacement, entity masking and entity splicing are adopted, which effectively improves the accuracy of recognition. The experimental results show that the recognition accuracy of the fusion algorithm reaches 93 %. © 2024 IEEE.},
	author_keywords = {Bert + BiLSTM + CRF; Diabetes; Dictionary Rules; Entity Recognition; Knowledge Graph},
	keywords = {Question answering; 'current; Bert + BiLSTM + CRF; Dictionary rule; Entity recognition; Knowledge graphs; Language model; Named entity recognition; Question and answer system; Recognition algorithm; Recognition methods; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Schoch2024,
	author = {Schoch, Nicolai and Hoernicke, Mario and Strem, Nika and Stark, Katharina},
	title = {Engineering Data Funnel (WIP) - An Ontology-Enhanced LLM-Based Agent and MoE System for Engineering Data Processing},
	year = {2024},
	journal = {IEEE International Conference on Emerging Technologies and Factory Automation, ETFA},
	doi = {10.1109/ETFA61755.2024.10710789},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207839628&doi=10.1109%2fETFA61755.2024.10710789&partnerID=40&md5=9ee77acb989eba3ccc35ef3517c24570},
	abstract = {Automation Engineering of a process automation system is still a very manual effort due to limited support for the interpretation and processing of process design specification documents. Even though standards for digital data exchange between process and automation engineering do exist, those formats are rarely used and consequently the immense automation potential in automation engineering cannot be lifted. This contribution presents an AI -based approach and prototype - using an ontology-enhanced LLM -based agent and a mixture-of-experts system - to structure and formalize multimodal unstructured process design information as in PDF, Excel, and Word formats and make it available for state-of-the-art engineering tools for the long-known 'Automation of Automation'. © 2024 IEEE.},
	author_keywords = {automation of automation; engineering data processing; engineering design specification; LLM-based agent; mixture of experts; ontology-driven information processing},
	keywords = {Network security; Ontology; Automation of automation; Design specification; Engineering data; Engineering data processing; Engineering design; Engineering design specification; LLM-based agent; Mixture of experts; Ontology's; Ontology-driven information processing; Specifications},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Yu20246335,
	author = {Yu, Xuanqing and Sun, Wangtao and Li, Jingwei and Liu, Kang and Liu, Chengbao and Tan, Jie},
	title = {ONSEP: A Novel Online Neural-Symbolic Framework for Event Prediction Based on Large Language Model},
	year = {2024},
	journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
	pages = {6335 – 6350},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205281317&partnerID=40&md5=e4d66f63e94c196e8280d6a1d4d04e71},
	abstract = {In the realm of event prediction, temporal knowledge graph forecasting (TKGF) stands as a pivotal technique. Previous approaches face the challenges of not utilizing experience during testing and relying on a single short-term history, which limits adaptation to evolving data. In this paper, we introduce the Online Neural-Symbolic Event Prediction (ONSEP) framework, which innovates by integrating dynamic causal rule mining (DCRM) and dual history augmented generation (DHAG). DCRM dynamically constructs causal rules from real-time data, allowing for swift adaptation to new causal relationships. In parallel, DHAG merges short-term and long-term historical contexts, leveraging a bi-branch approach to enrich event prediction. Our framework demonstrates notable performance enhancements across diverse datasets, with significant Hit@k (k=1,3,10) improvements, showcasing its ability to augment large language models (LLMs) for event prediction without necessitating extensive retraining. The ONSEP framework not only advances the field of TKGF but also underscores the potential of neural-symbolic approaches in adapting to dynamic data environments. © 2024 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Knowledge graph; Causal relationships; Event prediction; Knowledge graphs; Language model; Performance enhancements; Prediction-based; Real-time data; Rule mining; Short-term history; Temporal knowledge; Prediction models},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Cheng20244275,
	author = {Cheng, Sitao and Zhuang, Ziyuan and Xu, Yong and Yang, Fangkai and Zhang, Chaoyun and Qin, Xiaoting and Huang, Xiang and Chen, Ling and Lin, Qingwei and Zhang, Dongmei and Rajmohan, Saravan and Zhang, Qi},
	title = {Call Me When Necessary: LLMs can Efficiently and Faithfully Reason over Structured Environments},
	year = {2024},
	journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
	pages = {4275 – 4295},
	doi = {10.18653/v1/2024.findings-acl.254},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205316001&doi=10.18653%2fv1%2f2024.findings-acl.254&partnerID=40&md5=2eae1733c834abc6aa75005b3e95f28c},
	abstract = {Large Language Models (LLMs) have shown potential in reasoning over structured environments, e.g., knowledge graphs and tables. Such tasks typically require multi-hop reasoning, i.e., match natural language utterance with instances in the environment. Previous works adopt LLMs to incrementally build a reasoning path, where LLMs either invoke tools or pick up items by step-by-step interacting with the environment. We propose Reasoning-Path-Editing (Readi), a novel framework where LLMs can efficiently and faithfully reason over structured environments. In Readi, LLMs initially generate a reasoning path given a query, and edit the path only when necessary. We instantiate the path on structured environments and provide feedback to edit the path if anything goes wrong. Experimental results on three KGQA and two TableQA datasets show the effectiveness of Readi, significantly surpassing previous LLM-based methods (by 9.1% Hit@1 on WebQSP, 12.4% on MQA-3H and 9.5% on WTQ), comparable with state-of-the-art fine-tuned methods (67% on CWQ and 74.7% on WebQSP) and substantially boosting the vanilla LLMs (by 14.9% on CWQ). Our code will be available on https://aka.ms/readi. © 2024 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Knowledge graph; Natural language processing systems; Knowledge graphs; Language model; Model-based method; Multi-hops; Natural languages; State of the art; Structured environment; Structured Query Language},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@ARTICLE{2024,
	title = {28th International Conference on Theory and Practice of Digital Libraries, TPDL 2024},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {15177 LNCS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85206100277&partnerID=40&md5=ef6d5dce8949de2e3e90ad5b8e4391cc},
	abstract = {The proceedings contain 43 papers. The special focus in this conference is on Theory and Practice of Digital Libraries. The topics include: A Reputation System for Scientific Contributions Based on a Token Economy; bibliotheca Eugeniana Digital—Unveiling and Visualizing the Treasures of Prince Eugene of Savoy’s Library; comparative Analysis of Evaluation Measures for Scientific Text Simplification; promoting Interoperability on the Datasets of the Arrowheads Findings of the Chalcolithic and the Early/Middle Bronze Age; tracing the Retraction Cascade: Identifying Non-retracted but Potentially Retractable Articles; mapping Techniques for an Automated Library Classification: The Case Study of Library Loans at Bibliotheca Hertziana; LIT: Label-Informed Transformers on Token-Based Classification; Improving Retrieval and Expression of Iconographical and Iconological Semantic Statements: An Extension of the ICON Ontology; scholarly Quality Measurements: A Systematic Literature Review; assessing the Accessibility and Usability of Web Archives for Blind Users; leveraging Transfer Learning for Article Segmentation in Historical Newspapers; Multi-dimensional Edge-Embedded GCNs for Arabic Text Classification; LIAS: Layout Information-Based Article Separation in Historical Newspapers; CALM: Context Augmentation with Large Language Model for Named Entity Recognition; database Approaches to the Modelling and Querying of Musical Scores: A Survey; Content-Based Dataset Retrieval Methods: Reproducibility of the ACORDAR Test Collection; enhancing Identification of Scholarly Reference on YouTube: Method Development and Analysis of External Link Characteristics; mining Literary Trends: A Tool for Digital Library Analysis; PRET19: Automatic Recognition and Indexing of Handwritten Loan Registers from 19th Century Parisian Universities; leveraging Open Large Language Models for Historical Named Entity Recognition; Enriching Archival Linked Data Descriptions with Information from Wikidata and DBpedia; OpenPSS: An Open Page Stream Segmentation Benchmark.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Wang2024234,
	author = {Wang, Ya and Barta, Dainel and Hesse, Julian and Buchwald, Philip and Paschke, Adrian},
	title = {Legally-Guided Automated Decision-Making System Using Language Model Agents for Autonomous Driving},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {15183 LNCS},
	pages = {234 – 248},
	doi = {10.1007/978-3-031-72407-7_17},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205093338&doi=10.1007%2f978-3-031-72407-7_17&partnerID=40&md5=9f70f38a4ad04053a6d86588b6bb31a3},
	abstract = {Recent advances in language models have facilitated the development of agent-based systems. Despite their encouraging results in various reasoning tasks, these systems often operate as “black boxes”, raising concerns about potential illegal behavior due to opaque decision-making processes. This concern is particularly critical in autonomous driving, where precise decision-making requires a thorough understanding of traffic scenes and strict adherence to established norms. In this paper, we propose a legally-guided automated decision making system (LAD) that employs language models to dynamically retrieve facts for related rules through context-based query generation while delegating decision-making to a symbolic solver. In our experiments, we demonstrate that this neuro-symbolic system, with a limited number of formalized traffic rules, provides a more accurate, interpretable, and traceable solution for rule-compliant decision-making compared to pure language models. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {Autonomous Driving; Large Language Model Agent; Neurosymbolic System; Ontological Reasoning; Rule Compliance},
	keywords = {Crime; Modeling languages; Ontology; Query languages; Structured Query Language; Agent-based systems; Automated decision making systems; Autonomous driving; Decisions makings; Language model; Large language model agent; Model agents; Neuro-symbolic system; Ontological reasoning; Rule compliance},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Incitti2024,
	author = {Incitti, Francesca and Salfinger, Andrea and Snidaro, Lauro and Challapalli, Sri},
	title = {Leveraging LLMs for Knowledge Engineering from Technical Manuals: A Case Study in the Medical Prosthesis Manufacturing Domain},
	year = {2024},
	journal = {FUSION 2024 - 27th International Conference on Information Fusion},
	doi = {10.23919/FUSION59988.2024.10706469},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85207690564&doi=10.23919%2fFUSION59988.2024.10706469&partnerID=40&md5=665b1dd19a898c7b691e8997f84a8f41},
	abstract = {Ontologies are nowadays widely used to organize information across specific domains, being effective due to their hierarchical structure and the ability to explicitly represent relationships between concepts. Knowledge engineering, like compiling companies' vast bodies of knowledge into these structures, however, still represents a time-consuming, largely manually performed process, esp. with significant amounts of knowledge often only recorded within unstructured text documents. Since the recently introduced Large Language Models (LLMs) excel on text summarization, this raises the question whether these could be exploited within dedicated knowledge fusion architectures to assist human knowledge engineers by automatically suggesting relevant classes, instances and relations extracted from textual corpora. We therefore propose a novel approach that leverages the taxonomic structure of a partially defined ontology to prompt LLMs for hierarchical knowledge organization. Unlike conventional methods that rely solely on static ontologies, our methodology dynamically generates prompts based on the ontology's existing class taxonomy, prompting the LLM to generate responses that extract supplementary information from unstructured documents. It thus introduces the concept of using ontologies as scaffolds for guiding LLMs, in order to realize a mutual interplay between structured ontological knowledge and the soft fusion capabilities of LLMs. We evaluate our proposed algorithm on a real-world case study, performing a knowledge fusion task on heterogeneous technical documentation from a medical prosthesis manufacturer. © 2024 ISIF.},
	author_keywords = {Knowledge Engineering; Large Language Models; Natural Language Processing; Ontology Population; Soft Fusion},
	keywords = {Natural language processing systems; Ontology; Prosthetics; Scaffolds; Scaffolds (biology); Case-studies; Language model; Language processing; Large language model; Medical prosthesis; Natural language processing; Natural languages; Ontology Population; Ontology's; Soft fusions; Taxonomies},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{D’Aragona2024430,
	author = {D’Aragona, Paolo Tagliolato Acquaviva and Babbini, Lorenza and Bordogna, Gloria and Lotti, Alessandro and Minelli, Annalisa and Oggioni, Alessandro},
	title = {Design of a Knowledge Hub of Heterogeneous Multisource Documents to support Public Authorities},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3762},
	pages = {430 – 435},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205573818&partnerID=40&md5=427ec656edd9ac75a1320dd73ffed1b5},
	abstract = {This contribution outlines the design of a Knowledge Hub of heterogeneous documents related to the Mediterranean Action Plan UNEP-MAP of the United Nations Environment Program [1]. The Knowledge Hub is intended to serve as a resource to assist public authorities and users with different backgrounds and needs in accessing information efficiently. Users can either formulate natural language queries or navigate a knowledge graph automatically generated to find relevant documents. The Knowledge Hub is designed based on state-of-the-art Large Language Models. (LLMs) A user-evaluation experiment was conducted, testing publicly available models on a subset of documents using distinct LLMs settings. This step was aimed to identify the best-performing model for further using it to classify the documents with respect to the topics of interest. © 2024 Copyright for this paper by its authors.},
	author_keywords = {Knowledge graph; Knowledge Hub; Large Language Models; Natural Language Queries},
	keywords = {Natural language processing systems; Query languages; Structured Query Language; Action plan; Heterogeneous documents; Knowledge graphs; Knowledge hub; Language model; Large language model; Multi-Sources; Natural language queries; Public authorities; United Nations Environment Programs; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}@CONFERENCE{Canal-Esteve202485,
	author = {Canal-Esteve, Miquel and Gutiérrez, Yoan},
	title = {Educational Material to Knowledge Graph Conversion: A Methodology to Enhance Digital Education},
	year = {2024},
	journal = {KaLLM 2024 - 1st Workshop on Knowledge Graphs and Large Language Models, Proceedings of the Workshop},
	pages = {85 – 91},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204495458&partnerID=40&md5=a4830fb1476152ac64a0c575c8c52de2},
	abstract = {This article argues that digital educational content should be structured as knowledge graphs (KGs). Unlike traditional repositories such as Moodle, a KG offers a more flexible representation of the relationships between concepts, facilitating intuitive navigation and discovery of connections. In addition, it integrates effectively with Large Language Models, enhancing personalized explanations, answers, and recommendations. This article studies different proposals based on semantics and knowledge modelling to determine the most appropriate ways to strengthen intelligent educational technologies. ©2024 Association for Computational Linguistics.},
	keywords = {Contrastive Learning; Educational contents; Educational materials; Knowledge graphs; Knowledge model; Language model; Relationship between concepts; Semantic modelling; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Eells202451,
	author = {Eells, Andrew and Dave, Brandon and Hitzler, Pascal and Shimizu, Cogan},
	title = {Commonsense Ontology Micropatterns},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14980 LNAI},
	pages = {51 – 59},
	doi = {10.1007/978-3-031-71170-1_6},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204924291&doi=10.1007%2f978-3-031-71170-1_6&partnerID=40&md5=b2e043ed4a5b9e63829b6a39249dfa9a},
	abstract = {The previously introduced Modular Ontology Modeling methodology (MOMo) attempts to mimic the human analogical process by using modular patterns to assemble more complex concepts. To support this, MOMo organizes ontology design patterns (ODPs) into design libraries, which are programmatically queryable. However, a major bottleneck to large-scale deployment of MOMo is the (to-date) limited availability of ready-to-use ODPs. At the same time, Large Language Models (LLMs) have quickly become a source of common knowledge and, in some cases, replacing search engines for questions. In this paper, we thus present a collection of 104 ODPs representing often occurring nouns, curated from the common-sense knowledge available in LLMs, organized into a fully-annotated modular ontology design library ready for use with MOMo. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	keywords = {Human form models; Structured Query Language; Design library; Design Patterns; Language model; Micro pattern; Modeling methodology; Modular ontologies; Modulars; Ontology design; Ontology model; Ontology's; Ontology},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Jia2024466,
	author = {Jia, Yongzhe and Wei, Jianguo and Wang, Xin and Xu, Dawei and Zuo, Xintian and Yang, Yuxuan and Xiao, Xuan},
	title = {Graphologue: Bridging RDBMS and Graph Databases with Natural Language Interfaces},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14856 LNCS},
	pages = {466 – 470},
	doi = {10.1007/978-981-97-5575-2_40},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203882516&doi=10.1007%2f978-981-97-5575-2_40&partnerID=40&md5=632b3501a44792cc62395a3dc0d72b46},
	abstract = {We propose a novel graph database system that overcomes existing limitations by integrating relational databases, unifying RDF and property graph data models, and incorporating large language models and natural language processing. Graphologue, our system, leveraging openGauss, enhances scalability and performance compared to traditional graph databases. The integration of RDF and property graph models enables flexible data modeling, combining expressiveness and flexibility. We introduce large language models to simplify query generation using natural language, reducing complexity. Additionally, we employ natural language processing to generate graphs from unstructured data, enhancing inclusiveness. Our research aims to advance graph database technology, offering a unified and user-friendly solution for efficient data analysis and querying in interconnected environments. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2024.},
	author_keywords = {Graph Database; Large language Model; Property Graph; RDF; Relational Database},
	keywords = {Data assimilation; Knowledge graph; Modeling languages; Query languages; Relational database systems; Graph database; Language model; Language processing; Large language model; Natural languages; Property; Property graph; RDBMS's; RDF; Relational Database; Structured Query Language},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{2024,
	title = {ESWC-JP 2024 - Joint Proceedings of the ESWC 2024 Workshops and Tutorials, co-located with 21st European Semantic Web Conference, ESWC 2024},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3749},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203581764&partnerID=40&md5=9712f25f3551d5bfc25d246cfad1c3a8},
	abstract = {The proceedings contain 18 papers. The topics discussed include: towards seamless human-robot dialogue through a robot action ontology; the SPA ontology: towards a web of things ready for robotic agents; KB4RL: towards a knowledge base for automatic creation of state and action spaces for reinforcement learning; towards a knowledge engineering methodology for flexible robot manipulation in everyday tasks; steps towards generalized manipulation action plans tackling mixing task; towards improving large language models’ planning capabilities on WoT thing descriptions by generating python objects as intermediary representations; transforming web knowledge into actionable knowledge graphs for robot manipulation tasks; and NeSy is alive and well: a LLM-driven symbolic approach for better code comment data generation and classification.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Panda202413263,
	author = {Panda, Pranoy and Agarwal, Ankush and Devaguptapu, Chaitanya and Kaul, Manohar and Prathosh, A.P.},
	title = {HOLMES: Hyper-Relational Knowledge Graphs for Multi-hop Question Answering using LLMs},
	year = {2024},
	journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
	volume = {1},
	pages = {13263 – 13282},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204493550&partnerID=40&md5=312196fa1dcf5cba63eabb9df978db39},
	abstract = {Given unstructured text, Large Language Models (LLMs) are adept at answering simple (single-hop) questions. However, as the complexity of the questions increase, the performance of LLMs degrade. We believe this is due to the overhead associated with understanding the complex question followed by filtering and aggregating unstructured information in the raw text. Recent methods try to reduce this burden by integrating structured knowledge triples into the raw text, aiming to provide a structured overview that simplifies information processing. However, this simplistic approach is query-agnostic and the extracted facts are ambiguous as they lack context. To address these drawbacks and to enable LLMs to answer complex (multi-hop) questions with ease, we propose to use a knowledge graph (KG) that is context-aware and is distilled to contain query-relevant information. The use of our compressed distilled KG as input to the LLM results in our method utilizing up to 67% fewer tokens to represent the query relevant information present in the supporting documents, compared to the state-of-the-art (SoTA) method. Our experiments show consistent improvements over the SoTA across several metrics (EM, F1, BERTScore, and Human Eval) on two popular benchmark datasets (HotpotQA and MuSiQue). © 2024 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Information filtering; Knowledge graph; Query languages; Query processing; Structured Query Language; Complex questions; Knowledge graphs; Language model; Multi-hops; Performance; Question Answering; Simple++; Single hop; Structured knowledge; Unstructured texts; Question answering},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Khettari2024457,
	author = {Khettari, Oumaima El and Nishida, Noriki and Liu, Shanshan and Munne, Rumana Ferdous and Yamagata, Yuki and Quiniou, Solen and Chaffron, Samuel and Matsumoto, Yuji},
	title = {Mention-Agnostic Information Extraction for Ontological Annotation of Biomedical Articles},
	year = {2024},
	journal = {BioNLP 2024 - 23rd Meeting of the ACL Special Interest Group on Biomedical Natural Language Processing, Proceedings of the Workshop and Shared Tasks},
	pages = {457 – 473},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204491490&partnerID=40&md5=ac874f0f7c93237fe46b2d479e87994e},
	abstract = {Biomedical information extraction is crucial for advancing research, enhancing healthcare, and discovering treatments by efficiently analyzing extensive data. Given the extensive amount of biomedical data available, automated information extraction methods are necessary due to manual extraction’s labor-intensive, expertise-dependent, and costly nature. In this paper, we propose a novel two-stage system for information extraction where we annotate biomedical articles based on a specific ontology (HOIP). The major challenge is annotating relation between biomedical processes often not explicitly mentioned in text articles. Here, we first predict the candidate processes and then determine the relationships between these processes without relying on mentions. The experimental results show promising outcomes in mention-agnostic process identification using Large Language Models (LLMs). In relation classification, our proposed BERT-based models outperform LLMs significantly. The end-to-end evaluation results suggest the difficulty of this task and room for improvement in both process identification and relation classification.. ©2024 Association for Computational Linguistics.},
	keywords = {Classification (of information); Computational linguistics; Ontology; Automated information; Biomedical data; Biomedical information extractions; Information extraction methods; Labour-intensive; Language model; Ontology's; Process identification; Relation classifications; Two stage system; Information retrieval},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Kumichev2024215,
	author = {Kumichev, Gleb and Blinov, Pavel and Kuzkina, Yulia and Goncharov, Vasily and Zubkova, Galina and Zenovkin, Nikolai and Goncharov, Aleksei and Savchenko, Andrey},
	title = {MedSyn: LLM-Based Synthetic Medical Text Generation Framework},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14950 LNAI},
	pages = {215 – 230},
	doi = {10.1007/978-3-031-70381-2_14},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203865186&doi=10.1007%2f978-3-031-70381-2_14&partnerID=40&md5=189c6a3826fe74f535e80148c5c64404},
	abstract = {Generating synthetic text addresses the challenge of data availability in privacy-sensitive domains such as healthcare. This study explores the applicability of synthetic data in real-world medical settings. We introduce MedSyn, a novel medical text generation framework that integrates large language models with a Medical Knowledge Graph (MKG). We use MKG to sample prior medical information for the prompt and generate synthetic clinical notes with GPT-4 and fine-tuned LLaMA models. We assess the benefit of synthetic data through application in the ICD code prediction task. Our research indicates that synthetic data can increase the classification accuracy of vital and challenging codes by up to 17.8% compared to settings without synthetic data. Furthermore, to provide new data for further research in the healthcare domain, we present the largest open-source synthetic dataset of clinical notes for the Russian language, comprising over 41k samples covering 219 ICD-10 codes. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {Clinical note generation; ICD code prediction; Synthetic data},
	keywords = {Clinical note generation; Clinical notes; Code predictions; Data availability; ICD code prediction; Knowledge graphs; Medical knowledge; Real-world; Synthetic data; Text generations; Electronic health record},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Jiang202465,
	author = {Jiang, Meng and Lin, Bill Yuchen and Wang, Shuohang and Xu, Yichong and Yu, Wenhao and Zhu, Chenguang},
	title = {Augmenting NLP Models with Commonsense Knowledge},
	year = {2024},
	journal = {SpringerBriefs in Computer Science},
	volume = {Part F2530},
	pages = {65 – 89},
	doi = {10.1007/978-981-97-0747-8_5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204295728&doi=10.1007%2f978-981-97-0747-8_5&partnerID=40&md5=f7e833f16612b0ee93726329966baff4},
	abstract = {This chapter focuses on augmenting NLP models with commonsense knowledge to enhance their performance in natural language understanding and generation tasks. We begin by discussing the importance of commonsense knowledge in NLP and the challenges faced by NLP models in reasoning with commonsense. We explore different types of commonsense knowledge and reasoning tasks, including multiple-choice tasks, open-ended QA, constrained NLG, and commonsense probing of language models. We then introduce the various techniques for augmenting NLP models with commonsense knowledge. We discuss the use of structured knowledge bases, such as ConceptNet, and the incorporation of graph networks for encoding structured knowledge. We also examine the augmentation of NLP models with un/semi-structured knowledge sources, such as text corpora and the use of dense passage retrieval for open-ended QA. Furthermore, we explore differentiable reasoning methods, such as DrFact, for reasoning with semi-structured knowledge. Finally, we discuss the use of neural knowledge models, such as COMET and LLMs, for incorporating commonsense knowledge. We explore the generation of commonsense knowledge graphs using LLMs and knowledge distillation techniques to create smaller, specialized commonsense models. We also examine the use of large language models for extracting relevant commonsense knowledge for reasoning. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2024.},
	author_keywords = {Commonsense knowledge; Commonsense reasoning; Knowledge graphs; Neural knowledge models},
	keywords = {Graph neural networks; Structured Query Language; Commonsense knowledge; Commonsense reasoning; Knowledge graphs; Knowledge model; Language model; Natural language generation; Neural knowledge model; Performance; Semi-structured; Structured knowledge; Knowledge graph},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Zhou2024365,
	author = {Zhou, Tong and Chen, Yubo and Liu, Kang and Zhao, Jun},
	title = {CogMG: Collaborative Augmentation Between Large Language Model and Knowledge Graph},
	year = {2024},
	journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
	volume = {3},
	pages = {365 – 373},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203844359&partnerID=40&md5=e307df193dd6faecd4cdcf0e098a99c7},
	abstract = {Large language models have become integral to question-answering applications despite their propensity for generating hallucinations and factually inaccurate content. Querying knowledge graphs to reduce hallucinations in LLM meets the challenge of incomplete knowledge coverage in knowledge graphs. On the other hand, updating knowledge graphs by information extraction and knowledge graph completion faces the knowledge update misalignment issue. In this work, we introduce a collaborative augmentation framework, CogMG, leveraging knowledge graphs to address the limitations of LLMs in QA scenarios, explicitly targeting the problems of incomplete knowledge coverage and knowledge update misalignment. The LLMs identify and decompose required knowledge triples that are not present in the KG, enriching them and aligning updates with real-world demands. We demonstrate the efficacy of this approach through a supervised fine-tuned LLM within an agent framework, showing significant improvements in reducing hallucinations and enhancing factual accuracy in QA responses. Our code1 and video2 are publicly available. © 2024 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Question answering; Agent Framework; Incomplete knowledge; Knowledge graphs; Knowledge update; Language model; Question Answering; Real-world; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{2024,
	title = {Lang + Mol 2024 - 1st Workshop on Language + Molecules, Proceedings of the Workshop},
	year = {2024},
	journal = {Lang + Mol 2024 - 1st Workshop on Language + Molecules, Proceedings of the Workshop},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204885030&partnerID=40&md5=c5da0d1f7ed7709ccf13a33059bd3006},
	abstract = {The proceedings contain 15 papers. The topics discussed include: could chemical language models benefit from message passing; ALMol: aligned language-molecule translation LLMs through offline preference contrastive optimization; evaluating extrapolation ability of large language model in chemical domain; design proteins using large language models: enhancements and comparative analyses; enhanced biot5+ for molecule-text translation: a three-stage approach with data distillation, di verse training, and voting ensemble; SciMind: a multimodal mixture-of-experts model for advancing pharmaceutical sciences; knowledge graph extraction from total synthesis documents; and Knowlab’s submission to L+M shared task: all you need is continued pretraining of chemistry texts even for molecule captioning.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Wang20241114,
	author = {Wang, Zeyuan and Zhang, Qiang and Ding, Keyan and Qin, Ming and Zhuang, Xiang and Li, Xiaotong and Chen, Huajun},
	title = {InstructProtein: Aligning Human and Protein Language via Knowledge Instruction},
	year = {2024},
	journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
	volume = {1},
	pages = {1114 – 1136},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204460638&partnerID=40&md5=2e9324d70ef80e960e961a76abb537ce},
	abstract = {Large Language Models (LLMs) have revolutionized the field of natural language processing, but they fall short in comprehending biological sequences such as proteins. To address this challenge, we propose InstructProtein, an innovative LLM that possesses bidirectional generation capabilities in both human and protein languages: (i) taking a protein sequence as input to predict its textual function description and (ii) using natural language to prompt protein sequence generation. To achieve this, we first pre-train an LLM on both protein and natural language corpora, enabling it to comprehend individual languages. Then supervised instruction tuning is employed to facilitate the alignment of these two distinct languages. Herein, we introduce a knowledge graph-based instruction generation framework to construct a high-quality instruction dataset, addressing the annotation imbalance and the absence of instructional signals in the existing protein-text corpus. In particular, the instructions inherit the structural relations between proteins and annotations in knowledge graphs, which empowers our model to engage in the causal modeling of protein functions, akin to the chain-of-thought processes in natural languages. Extensive experiments on bidirectional protein-text generation tasks show that InstructProtein outperforms state-of-the-art LLMs by a large margin. Our code is publicly available at https://github.com/HICAIZJU/InstructProtein. © 2024 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Natural language processing systems; Supervised learning; Biological sequences; Graph-based; High quality; Instruction generations; Knowledge graphs; Language model; Language processing; Natural languages; Protein sequences; Sequence generation; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Perevalov202414,
	author = {Perevalov, Aleksandr and Both, Andreas},
	title = {Towards LLM-driven Natural Language Generation based on SPARQL Queries and RDF Knowledge Graphs},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3747},
	pages = {14},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203316381&partnerID=40&md5=61ac7b9397feeb9b0e5729c12ad4c604},
	abstract = {Generating natural language based on structured data has been utilized in many use cases such as data augmentation, explainability, and education. In particular, when speaking about Knowledge Graphs, one may generate natural language representation of triples (i.e., facts) or “verbalize” SPARQL queries. The latter can be treated as a reverse semantic parsing task and, for instance, can be used by non-experts to better understand the meaning of SPARQL queries, and conduct data augmentation for question answering benchmarking datasets. In this paper, we make a first attempt to utilize Large Language Models for verbalizing SPARQL queries, i.e., converting them to natural language. The experimental setup uses both commercial and open-source models and benefits from multiple prompting techniques. We evaluate our approach on the well-known question answering datasets QALD-9-plus and QALD-10 while working with three languages: English, German, and Russian. For measuring the quality, we use machine translation metrics and human evaluation (survey) together. Even though we have observed such error classes as question overspecification, language and semantic mismatch, the results of this work suggest that Large Language Models (LLMs) are a good fit for the task of converting SPARQL queries to natural language. © 2024 Copyright for this paper by its authors.},
	author_keywords = {Large Language Models; RDF2NL; SPARQL to Natural Language; SPARQL verbalization; Text Generation},
	keywords = {Benchmarking; Large datasets; Natural language processing systems; Query languages; Semantics; Structured Query Language; Translation (languages); Data augmentation; Knowledge graphs; Language model; Large language model; Natural languages; Question Answering; RDF2NL; SPARQL to natural language; SPARQL verbalization; Text generations; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Mariotti2024,
	author = {Mariotti, Luca and Guidetti, Veronica and Mandreoli, Federica and Belli, Andrea and Lombardi, Paolo},
	title = {Combining large language models with enterprise knowledge graphs: a perspective on enhanced natural language understanding},
	year = {2024},
	journal = {Frontiers in Artificial Intelligence},
	volume = {7},
	doi = {10.3389/frai.2024.1460065},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203840711&doi=10.3389%2ffrai.2024.1460065&partnerID=40&md5=2a4ec89ec43b9c348aace003d8139b73},
	abstract = {Knowledge Graphs (KGs) have revolutionized knowledge representation, enabling a graph-structured framework where entities and their interrelations are systematically organized. Since their inception, KGs have significantly enhanced various knowledge-aware applications, including recommendation systems and question-answering systems. Sensigrafo, an enterprise KG developed by Expert.AI, exemplifies this advancement by focusing on Natural Language Understanding through a machine-oriented lexicon representation. Despite the progress, maintaining and enriching KGs remains a challenge, often requiring manual efforts. Recent developments in Large Language Models (LLMs) offer promising solutions for KG enrichment (KGE) by leveraging their ability to understand natural language. In this article, we discuss the state-of-the-art LLM-based techniques for KGE and show the challenges associated with automating and deploying these processes in an industrial setup. We then propose our perspective on overcoming problems associated with data quality and scarcity, economic viability, privacy issues, language evolution, and the need to automate the KGE process while maintaining high accuracy. Copyright © 2024 Mariotti, Guidetti, Mandreoli, Belli and Lombardi.},
	author_keywords = {AI; carbon footprint; enterprise AI; human in the loop; knowledge graph; knowledge graph enrichment; LLMS; relation extraction},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Piao2024,
	author = {Piao, Guangyuan and Mountantonakis, Mike and Papadakos, Panagiotis and Sonawane, Pournima and OMahony, Aidan},
	title = {Toward Exploring Knowledge Graphs with LLMs},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3759},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204692476&partnerID=40&md5=4367f805d3a6eeb92ce9a1c69435a842},
	abstract = {Interacting with knowledge graphs (KGs) is challenging for non-technical users with information needs who are unfamiliar with KG-specific query languages such as SPARQL and the underlying KG schema.Previous KG question answering systems require ground-truth pairs of questions and queries or fine tuning (Large) Language Models (LLMs) for a specific KG, which is time-consuming and demands deep expertise.In this poster, we present a framework for exploring KGs for question answering using LLMs in a zero-shot setting for non-technical end users, without the need for ground-truth pairs of questions and queries or fine-tuning LLMs.Additionally, we evaluate an example implementation in a simple yet challenging setting using LLMs exclusively based on the framework, without the extra effort of maintaining the embeddings or indexes of entities from KG for retrieving relevant ones to a given question.We share preliminary experimental results indicating that exploring a KG using LLM-generated SPARQL queries with reasonable complexity is possible in such a challenging setting. © 2022 Copyright for this paper by its authors.},
	keywords = {Modeling languages; Query languages; Question answering; Structured Query Language; End-users; Fine tuning; Ground truth; Knowledge graphs; Language model; Non-technical users; Question Answering; Question answering systems; Simple++; Specific knowledge; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{2024,
	title = {23rd International Conference on Business Informatics Research, BIR 2024},
	year = {2024},
	journal = {Lecture Notes in Business Information Processing},
	volume = {529 LNBIP},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204518939&partnerID=40&md5=54ae1a595341f7a2927f6f9fc58f9481},
	abstract = {The proceedings contain 16 papers. The special focus in this conference is on Business Informatics Research. The topics include: LLM-Assistance for Quality Control of LLM Output; unlocking Viewer Insights in Linear Television: A Machine Learning Approach; Comparison of AI-Based Document Classification Platforms; towards Model-driven Enhancement of Safety in Healthcare Robot Interactions; modelling of Organisational Rules in Complex Adaptive Systems: a Systematic Mapping Study; towards Method Support for Variability Modelling in Enterprise Architecture Management; cross-section of Business Intelligence Projects: Information Systems Success Perspective; incorporating Ethical Aspects in Information Systems Requirements Engineering; suitability of Business Process Modeling Methods for Requirements Elicitation; software Architectures and the Use of Knowledge Graphs to Support Their Design; Technical Debt – Insights Into a Manufacturing SME Case Study; discovery Rules for Depicting Tacit Knowledge Usage and Management in Fractal Enterprise Models; DDIs-Graph: an Approach to Identify Drug-Drug Interactions and Recommend Alternative Drugs; exploring the Information Flow and the Grounding of Digital Product Passports Using the Work-Oriented Approach, an Industrial Case Study.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{van Cauter202475,
	author = {van Cauter, Zeno and Yakovets, Nikolay},
	title = {Ontology-guided Knowledge Graph Construction from Maintenance Short Texts},
	year = {2024},
	journal = {KaLLM 2024 - 1st Workshop on Knowledge Graphs and Large Language Models, Proceedings of the Workshop},
	pages = {75 – 84},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204424427&partnerID=40&md5=603dc56e6e13fbfd87205e48724e6583},
	abstract = {Large-scale knowledge graph construction remains infeasible since it requires significant human-expert involvement. Further complications arise when building graphs from domain-specific data due to their unique vocabularies and associated contexts. In this work, we demonstrate the ability of open-source large language models (LLMs), such as Llama-2 and Llama-3, to extract facts from domain-specific Maintenance Short Texts (MSTs). We employ an approach which combines ontology-guided triplet extraction and in-context learning. By using only 20 semantically similar examples with the Llama-3-70B-Instruct model, we achieve performance comparable to previous methods that relied on fine-tuning techniques like SpERT and REBEL. This indicates that domain-specific fact extraction can be accomplished through inference alone, requiring minimal labeled data. This opens up possibilities for effective and efficient semi-automated knowledge graph construction for domain-specific data. ©2024 Association for Computational Linguistics.},
	keywords = {Adversarial machine learning; Computational linguistics; Contrastive Learning; Domain Knowledge; Ontology; Semantics; Domain specific; Graph construction; Human expert; In contexts; Knowledge graphs; Language model; Large-scales; Ontology's; Open-source; Short texts; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Dong20242417,
	author = {Dong, Junnan and Zhang, Qinggang and Zhou, Huachi and Zha, Daochen and Zheng, Pai and Huang, Xiao},
	title = {Modality-Aware Integration with Large Language Models for Knowledge-based Visual Question Answering},
	year = {2024},
	journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
	volume = {1},
	pages = {2417 – 2429},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204453809&partnerID=40&md5=80862e046ab2996412d51d5bfc20680c},
	abstract = {Knowledge-based visual question answering (KVQA) has been extensively studied to answer visual questions with external knowledge, e.g., knowledge graphs (KGs). While several attempts have been proposed to leverage large language models (LLMs) as an implicit knowledge source, it remains challenging since LLMs may generate hallucinations. Moreover, multiple knowledge sources, e.g., images, KGs and LLMs, cannot be readily aligned for complex scenarios. To tackle these, we present a novel modality-aware integration with LLMs for KVQA (MAIL). It carefully leverages multimodal knowledge for both image understanding and knowledge reasoning. Specifically, (i) we propose a two-stage prompting strategy with LLMs to densely embody the image into a scene graph with detailed visual features; (ii) We construct a coupled concept graph by linking the mentioned entities with external facts. (iii) A tailored pseudo-siamese graph medium fusion is designed for sufficient multimodal fusion. We utilize the shared mentioned entities in two graphs as mediums to bridge a tight inter-modal exchange, while maximally preserving insightful intra-modal learning by constraining the fusion within mediums. Extensive experiments show the superiority of MAIL. © 2024 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Knowledge graph; External knowledge; Implicit knowledge; Knowledge based; Knowledge graphs; Knowledge reasoning; Knowledge sources; Language model; Multi-modal; Question Answering; Scene-graphs; Question answering},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Bertolini202412,
	author = {Bertolini, Lorenzo and Hulsman, Roel and Consoli, Sergio and Puertas-Gallardo, Antonio and Ceresa, Mario},
	title = {On Constructing Biomedical Text-to-Graph Systems with Large Language Models},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3747},
	pages = {12},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203342156&partnerID=40&md5=0c711da8e40443cb507f91dbd2c34fb2},
	abstract = {Knowledge graphs and ontologies represent symbolic and factual information that can offer structured and interpretable knowledge. Extracting and manipulating this type of information is a crucial step in complex processes such as human reasoning. While Large Language Models (LLMs) are known to be useful for extracting and enriching knowledge graphs and ontologies, previous work has largely focused on comparing architecture-specific models (e.g. encoder-decoder only) across benchmarks from similar domains. In this work, we provide a large-scale comparison of the performance of certain LLM features (e.g. model architecture and size) and task learning methods (fine-tuning vs. in-context learning (iCL)) on text-to-graph benchmarks in the biomedical domain. Our experiment suggests that, while a simple truncation-based heuristic can notably boost the performance of decoder-only models used with iCL, small fine-tuned encoder-decoder models produce the most stable and strong performance. Moreover, we found that a massive out-of-domain text-graph pre-training has a positive impact on fine-tuned models, while we observed only a marginal impact of pre-training and size for decoder-only iCL models. © 2024 Copyright © 2024 for this paper by its authors.},
	author_keywords = {In-Context Learning; Information Extraction; Knowledge Graphs; Large Language Models; Word Embeddings},
	keywords = {Benchmarking; Contrastive Learning; Decoding; Graph embeddings; Ontology; Context learning; Embeddings; In contexts; In-context learning; Information extraction; Knowledge graphs; Language model; Large language model; Performance; Word embedding; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{2024,
	title = {27th International Conference on Text, Speech, and Dialogue, TSD 2024},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {15049 LNAI},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204388862&partnerID=40&md5=d3a3e79df673cf847d0dd48562101c9b},
	abstract = {The proceedings contain 50 papers. The special focus in this conference is on Text, Speech, and Dialogue. The topics include: Bilingual Lexicon Induction From Comparable and Parallel Data: A Comparative Analysis; explaining Metaphors in the French Language by Solving Analogies Using a Knowledge Graph; the Aranea Corpora Family: Ten+ Years of Processing Web-Crawled Data; continual Learning Under Language Shift; neural Spell-Checker: Beyond Words with Synthetic Data Generation; coastTerm: A Corpus for Multidisciplinary Term Extraction in Coastal Scientific Literature; new Human-Annotated Dataset of Czech Health Records for Training Medical Concept Recognition Models; Analyzing Biases in Popular Answer Selection Datasets on Neural-Based QA Models; using Neural Coherence Models to Assess Discourse Coherence; named Entity Linking in English-Czech Parallel Corpus; tamSiPara: A Tamil – Sinhala Parallel Corpus; automatic Ellipsis Reconstruction in Coordinated German Sentences Based on Text-to-Text Transfer Transformers; better Low-Resource Machine Translation with Smaller Vocabularies; bella Turca: A Large-Scale Dataset of Diverse Text Sources for Turkish Language Modeling; Evaluation Metrics in LLM Code Generation; kernel Least Squares Transformations for Cross-Lingual Semantic Spaces; unsupervised Extraction of Morphological Categories for Morphemes; Introducing LCC’s NavProc 1.0 Corpus: Annotated Procedural Texts in the Naval Domain; models and Strategies for Russian Word Sense Disambiguation: A Comparative Analysis; open-Source Web Service with Morphological Dictionary–Supplemented Deep Learning for Morphosyntactic Analysis of Czech; mistrík’s Readability Metric – an Online Library.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Arsenyan2024295,
	author = {Arsenyan, Vahan and Bughdaryan, Spartak and Shaya, Fadi and Small, Kent and Shahnazaryan, Davit},
	title = {Large Language Models for Biomedical Knowledge Graph Construction: Information extraction from EMR notes},
	year = {2024},
	journal = {BioNLP 2024 - 23rd Meeting of the ACL Special Interest Group on Biomedical Natural Language Processing, Proceedings of the Workshop and Shared Tasks},
	pages = {295 – 317},
	doi = {10.18653/v1/2024.bionlp-1.23},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204502586&doi=10.18653%2fv1%2f2024.bionlp-1.23&partnerID=40&md5=e5a1dd52b88476f18d8a601564d5186d},
	abstract = {The automatic construction of knowledge graphs (KGs) is an important research area in medicine, with far-reaching applications spanning drug discovery and clinical trial design. These applications hinge on the accurate identification of interactions among medical and biological entities. In this study, we propose an end-to-end machine learning solution based on large language models (LLMs) that utilize electronic medical record notes to construct KGs. The entities used in the KG construction process are diseases, factors, treatments, as well as manifestations that coexist with the patient while experiencing the disease. Given the critical need for high-quality performance in medical applications, we embark on a comprehensive assessment of 12 LLMs of various architectures, evaluating their performance and safety attributes. To gauge the quantitative efficacy of our approach by assessing both precision and recall, we manually annotate a dataset provided by the Macula and Retina Institute. We also assess the qualitative performance of LLMs, such as the ability to generate structured outputs or the tendency to hallucinate. The results illustrate that in contrast to encoder-only and encoder-decoder, decoder-only LLMs require further investigation. Additionally, we provide guided prompt design to utilize such LLMs. The application of the proposed methodology is demonstrated on age-related macular degeneration.. ©2024 Association for Computational Linguistics.},
	keywords = {Diseases; Drug interactions; Electronic health record; Medical computing; Medical informatics; Ophthalmology; Automatic construction; Biological entities; Clinical trial designs; Construction information; Drug discovery; Graph construction; Knowledge graphs; Language model; Performance; Research areas; Clinical research},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Green Open Access}
}

@CONFERENCE{2024,
	title = {BioNLP 2024 - 23rd Meeting of the ACL Special Interest Group on Biomedical Natural Language Processing, Proceedings of the Workshop and Shared Tasks},
	year = {2024},
	journal = {BioNLP 2024 - 23rd Meeting of the ACL Special Interest Group on Biomedical Natural Language Processing, Proceedings of the Workshop and Shared Tasks},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204496132&partnerID=40&md5=e117b9afd9940ce7fe682701e7da843d},
	abstract = {The proceedings contain 79 papers. The topics discussed include: improving self-training with prototypical learning for source-free domain adaptation on clinical text; generation and evaluation of synthetic endoscopy free-text reports with differential privacy; evaluating the robustness of adverse drug event classification models using templates; advancing healthcare automation: multi-agent system for medical necessity justification; open (clinical) LLMs are sensitive to instruction phrasings; analyzing zero-shot temporal relation extraction on clinical notes using temporal consistency; overview of the BioLaySumm 2024 shared task on the lay summarization of biomedical research articles; end-to-end relation extraction of pharmacokinetic estimates from the scientific literature; and KG-Rank: enhancing large language models for medical QA with knowledge graphs and ranking techniques..},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Oelen2024,
	author = {Oelen, Allard and Jaradeh, Mohamad Yaser and Auer, Sören},
	title = {ORKG ASK: a Neuro-symbolic Scholarly Search and Exploration System},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3759},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204701963&partnerID=40&md5=ac0e18e0e7643ce1a111b369eeb451de},
	abstract = {Purpose: Finding scholarly articles is a time-consuming and cumbersome activity, yet crucial for conducting science.Due to the growing number of scholarly articles, new scholarly search systems are needed to effectively assist researchers in finding relevant literature.Methodology: We take a neuro-symbolic approach to scholarly search and exploration by leveraging state-of-the-art components, including semantic search, Large Language Models (LLMs), and Knowledge Graphs (KGs).The semantic search component composes a set of relevant articles.From this set of articles, information is extracted and presented to the user.Findings: The presented system, called ORKG ASK (Assistant for Scientific Knowledge), provides a production-ready search and exploration system.Our preliminary evaluation indicates that our proposed approach is indeed suitable for the task of scholarly information retrieval.Value: With ORKG ASK, we present a next-generation scholarly search and exploration system and make it available online.Additionally, the system components are open source with a permissive license. © 2024 Copyright for this paper by its authors.},
	author_keywords = {Large Language Models; Neuro-symbolic AI; Scholarly Knowledge Graphs; Scholarly Search System},
	keywords = {Search engines; Semantics; Exploration systems; Knowledge graphs; Language model; Large language model; Neuro-symbolic AI; Scholarly articles; Scholarly knowledge graph; Scholarly search system; Scientific knowledge; Search system; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{2024,
	title = {SEMANTiCS-PDWT 2024 - Joint Proceedings of Posters, Demos, Workshops, and Tutorials of the 20th International Conference on Semantic Systems, co-located with 20th International Conference on Semantic Systems, SEMANTiCS 2024},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3759},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204683099&partnerID=40&md5=966a950f145c2afc591f922a8de34ec7},
	abstract = {The proceedings contain 31 papers. The topics discussed include: facilitating learning analytics in histology courses with knowledge graphs; 8-star linked open data model: extending the 5-star model for better reuse, quality, and trust of data; continuous knowledge graph quality assessment through comparison using ABECTO; ORKG ASK: a neuro-symbolic scholarly search and exploration system; towards pattern-based complex ontology matching using SPARQL and LLM; data-sovereign enterprise collaboration using the solid protocol; the Helmholtz digitization ontology: representing digital assets in the Helmholtz digital ecosystem; and facilitating search of the virtual record treasury of Ireland knowledge graph using ChatGPT.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{2024,
	title = {TEXT2KG 2024 and DQMLKG 2024 - Joint Proceedings of the 3rd International Workshop One Knowledge Graph Generation from Text and Data Quality Meets Machine Learning and Knowledge Graphs, co-located with the Extended Semantic Web Conference, ESWC 2024},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3747},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203398354&partnerID=40&md5=7821ee35299e62f9deb0f39558ddc0bf},
	abstract = {The proceedings contain 17 papers. The topics discussed include: open knowledge base canonicalization: techniques and challenges; incorporating type information into zero-shot relation extraction; generating e-commerce related knowledge graph from text: open challenges and early results using LLMs; towards dataset for extracting relations in the climate-change domain; on constructing biomedical text-to-graph systems with large language models; fine-tuning vs. prompting: evaluating the knowledge graph construction with LLMs; Battalogy: empowering battery data management through ontology-driven knowledge graph; leveraging language models for generating ontologies of research topics; towards harnessing large language models as autonomous agents for semantic triple extraction from unstructured text; knowledge graphs for digital transformation monitoring in social media; and moving from tabular knowledge graph quality assessment to RDF triples leveraging ChatGPT.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Tao2024418,
	author = {Tao, Wenbiao and Zhu, Hanlun and Tan, Keren and Wang, Jiani and Liang, Yuanyuan and Jiang, Huihui and Yuan, Pengcheng and Lan, Yunshi},
	title = {FinQA: A Training-Free Dynamic Knowledge Graph Question Answering System in Finance with LLM-Based Revision},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14948 LNAI},
	pages = {418 – 423},
	doi = {10.1007/978-3-031-70371-3_32},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203865203&doi=10.1007%2f978-3-031-70371-3_32&partnerID=40&md5=ab4e3a4fdf11b332a734eadc7fe4ce9f},
	abstract = {Knowledge graph question answering (KGQA) in the finance domain aims to answer questions based on a dynamic knowledge graph (KG), which suffers from frequent updates. Moreover, the lack of high-quality annotated data renders data-driven and training-dependent approaches ineffective. To bridge the gap, we develop FinQA, which is a training-free dynamic knowledge graph question answering system in finance with large language model based (LLM-based) revision. Specifically, FinQA gives considerations to the following aspects: (1) constructing a dynamic finance knowledge graph partitioned based on data update frequencies; (2) proposing a training-free question-answering (QA) system to parse natural language to graph query language (NL2GQL) and achieving high-efficient coordination with the dynamic KG; (3) integrating the QA system with an open-source LLM to further boost the accuracy. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {Finance Knowledge Graph; Large Language Model Revision; Question Answering; Training-free},
	keywords = {Knowledge graph; Query languages; Structured Query Language; Finance knowledge graph; Free dynamics; High quality; Knowledge graphs; Language model; Large language model revision; Model revisions; Question Answering; Question answering systems; Training-free; Question answering},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Palma2024,
	author = {Palma, Cosimo},
	title = {Modelling Interestingness: AWorkflow for Surprisal-based Knowledge Mining in Narrative Semantic Networks},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3749},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203605888&partnerID=40&md5=620e83cb14caf5b791523544a1c5b22d},
	abstract = {This working paper outlines ongoing and planned efforts aimed at achieving an objective modelling of interestingness in cross-domain knowledge bases. In pursuit of this objective, clickstream data serves as a primary component for developing a novel measure of entity-related popularity. This measure is then integrated with two couple-related similarity measures, culminating in the formulation of a new interestingness law. This principled formalization is designed to undergo human validation, ultimately enhancing its reliability and comprehensiveness. The present contribution is intended to be propaedeutic to the development of a pipeline having a Knowledge Graph as input, and an expanded version of the same as output, whereby every link is labelled by an interestingness score, thus highlighting the most interesting paths, determined according to the proposed domain-specific heuristics for interestingness detection. This work is expected to yield significant benefits for Automatic Story Generation. Although this discipline, aided by Machine Learning, has made remarkable progress in surface-level text realization, it still grapples with producing qualitatively rich outputs that offer substantive informativeness. To address this challenge, a Knowledge Graph (particularly its most compelling paths identified through the proposed methodology) is anticipated to integrate the Large Language Model, thus harnessing the final output with the contextual information selected by users throughout the entire workflow- a scenario which is particularly valuable in educational settings, where generated stories frequently serve pedagogical purposes.  © 2024 Copyright for this paper by its authors.},
	author_keywords = {Automatic Story Generation; Computational Creativity; Interestingness measures; Knowledge Mining},
	keywords = {Latent semantic analysis; Semantics; Automatic story generations; Computational creativities; Cross-domain; Interestingness; Interestingness measures; Knowledge graphs; Knowledge mining; Objective models; Semantics networks; Working papers; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Xie2024,
	author = {Xie, Qinhua and Liu, Weicong and Yuan, Fan and Shi, Jifan and Liu, Ziyu and Zhang, Yanbing},
	title = {VidBot: Intelligent Video Learning Tool for Content Mining and Playback Traffic Statistics},
	year = {2024},
	journal = {2024 IEEE International Conference on Multimedia and Expo Workshops, ICMEW 2024},
	doi = {10.1109/ICMEW63481.2024.10645449},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203835266&doi=10.1109%2fICMEW63481.2024.10645449&partnerID=40&md5=c22eeaebfbcf2e94d5d1a75130b7df81},
	abstract = {With the rapid development of online education, video-based learning has become a significant mode of learning. However, existing video learning tools often fail to fully meet learners' needs for in-depth learning and interactive communication, thereby hindering learning outcomes. To address this challenge, this study proposes and implements an innovative intel-ligent video learning tool named VidBot, which is based on large language models for deep content mining and playback traffic analysis of videos. VidBot integrates Whisper and ChatGLM3-6B language models as well as the Pyltp library to build seven major functional modules, including Video Playback Visualization, Mind Mapping, Knowledge Graph, Cross-referencing of Knowledge Points, Automatic Video Segmentation, Intelligent Tutor, and Shared Notes. These modules aim to provide learners with deeper and more interactive learning experiences. The client of VidBot is released in the form of a plugin, and the server is integrated into the online education platform developed independently by our university.  © 2024 IEEE.},
	author_keywords = {interactive learning; large language model; Online education; text summarization; video analysis},
	keywords = {Adversarial machine learning; Contrastive Learning; Federated learning; Content mining; Intelligent video; Interactive learning; Language model; Large language model; Learning tool; On-line education; Text Summarisation; Traffic statistics; Video analysis; Video analysis},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Ananya202413,
	author = {Ananya, Ananya and Tiwari, Sanju and Mihindukulasooriya, Nandana and Soru, Tommaso and Xu, Ziwei and Moussallem, Diego},
	title = {Towards Harnessing Large Language Models as Autonomous Agents for Semantic Triple Extraction from Unstructured Text},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3747},
	pages = {13},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203352071&partnerID=40&md5=77f87f46cf4502eb0be82453c2362fdb},
	abstract = {The use of Large Language Models as autonomous agents interacting with tools has shown to improve the performance of several tasks from code generation to API calling and sequencing. This paper proposes a framework for using Large Language Models as autonomous agents for the task of Knowledge Graph construction from unstructured text. Specifically, it focuses on triple extraction, which involves identifying entities and their relationships from text to construct a Knowledge Graph. Our novel framework “Auto-KG agent” incorporates two relation extraction tools, REBEL and KnowGL, in conjunction with Large Language Models. Experimental results on the CONLL04 dataset demonstrate that while multi-tool approaches face challenges like hallucination, LLM-based agents are promising in mitigating biases, major event identification, handling negations and modalities thus enhancing extraction accuracy, particularly for complex linguistic structures. The impetus for this research is to overcome the current limitations of existing systems for Knowledge Graph construction and propose a roadmap for developing a robust framework capable of handling the intricacies of natural language with minimal human interference. The paper also discusses future directions, such as emulating Large Language Model training using reinforcement learning with human feedback, incorporating query decomposition, and integrating a re-ranking module. Through this research, the authors aim to set a new direction for future endeavours in building advanced, reliable systems for knowledge extraction. Overall, this work highlights the potential of LLM-based agents for knowledge graph construction and proposes a framework for harnessing their capabilities. © 2024 Copyright for this paper by its authors.},
	author_keywords = {Handling modalities and negations; Knowledge Graph; Knowledge Graph Construction; LLM Agents; Mitigating biases; Reasoning; Triple extraction},
	keywords = {Gluing; Knowledge graph; Large datasets; Natural language processing systems; Network security; Problem oriented languages; Query languages; Reinforcement learning; Graph construction; Handling modality and negation; Knowledge graph construction; Knowledge graphs; Language model; LLM agent; Mitigating bias; Reasoning; Triple extraction; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Kurdiukov2024126,
	author = {Kurdiukov, Nikita and Zinkovich, Viktoriia and Karpukhin, Sergey and Tikhomirov, Pavel},
	title = {nlp_enjoyers at TextGraphs-17 Shared Task: Text-Graph Representations for Knowledge Graph Question Answering using all-MPNet},
	year = {2024},
	journal = {TextGraphs at ACL 2024 - Proceedings of TextGraphs-17: Graph-Based Methods for Natural Language Processing, 62nd Annual Meeting of the Association of Computational Linguistics},
	pages = {126 – 130},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204883406&partnerID=40&md5=e7c13ef57dc3edd52f54a17c6f227b7f},
	abstract = {This paper presents a model for solving the Multiple Choice Question Answering (MCQA) problem, focusing on the impact of subgraph extraction from a Knowledge Graph on model performance. The proposed method combines textual and graph information by adding linearized subgraphs directly into the main question prompt with separate tokens, enhancing the performance of models working with each modality separately. The study also includes an examination of Large Language Model (LLM) backbones and the benefits of linearized subgraphs and sequence length, with efficient training achieved through fine-tuning with LoRA. The top benchmark, using subgraphs and MPNet, achieved an F1 score of 0.3887. The main limitation of the experiments is the reliance on pre-generated subgraphs/triplets from the graph, and the lack of exploration of in-context learning and prompting strategies with decoder-based architectures. © 2024 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Linearization; Graph information; Graph representation; Knowledge graphs; Modeling performance; Multiple-choice questions; Question Answering; Question prompts; Subgraph extraction; Subgraphs; Textual information; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Dehghan202414169,
	author = {Dehghan, Mohammad and Alomrani, Mohammad Ali and Bagga, Sunyam and Alfonso-Hermelo, David and Bibi, Khalil and Ghaddar, Abbas and Zhang, Yingxue and Li, Xiaoguang and Hao, Jianye and Liu, Qun and Lin, Jimmy and Chen, Boxing and Parthasarathi, Prasanna and Biparva, Mahdi and Rezagholizadeh, Mehdi},
	title = {EWEK-QA: Enhanced Web and Efficient Knowledge Graph Retrieval for Citation-based Question Answering Systems},
	year = {2024},
	journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
	volume = {1},
	pages = {14169 – 14187},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204470168&partnerID=40&md5=7cb5a9ce204dced377f4c81206aa5dff},
	abstract = {The emerging citation-based QA systems are gaining more attention especially in generative AI search applications. The importance of extracted knowledge provided to these systems is vital from both accuracy (completeness of information) and efficiency (extracting the information in a timely manner). In this regard, citation-based QA systems are suffering from two shortcomings. First, they usually rely only on web as a source of extracted knowledge and adding other external knowledge sources can hamper the efficiency of the system. Second, web-retrieved contents are usually obtained by some simple heuristics such as fixed length or breakpoints which might lead to splitting information into pieces. To mitigate these issues, we propose our enhanced web and efficient knowledge graph (KG) retrieval solution (EWEK-QA) to enrich the content of the extracted knowledge fed to the system. This has been done through designing an adaptive web retriever and incorporating KGs triples in an efficient manner. We demonstrate the effectiveness of EWEK-QA over the open-source state-of-the-art (SoTA) web-based and KG baseline models using a comprehensive set of quantitative and human evaluation experiments. Our model is able to: first, improve the web-retriever baseline in terms of extracting more relevant passages (>20%), the coverage of answer span (>25%) and self containment (>35%); second, obtain and integrate KG triples into its pipeline very efficiently (by avoiding any LLM calls) to outperform the web-only and KG-only SoTA baselines significantly in 7 quantitative QA tasks and our human evaluation. © 2024 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Open systems; Question answering; Breakpoint; External knowledge; Human evaluation; Knowledge graphs; Knowledge sources; QA system; Question answering systems; Search application; Simple heuristics; State of the art; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Kim2024346,
	author = {Kim, Yunsoo},
	title = {Foundation Model for Biomedical Graphs: Integrating Knowledge Graphs and Protein Structures to Large Language Models},
	year = {2024},
	journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
	volume = {4},
	pages = {346 – 355},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204046637&partnerID=40&md5=708cbd849841b3f34bdebeca53329e3c},
	abstract = {Transformer model has been a de-facto standard in natural language processing. Its adaptations in other fields such as computer vision showed promising results that this architecture is a powerful neural network in representation learning regardless of the data type. This recent success has led to research in multimodal Large Language Model (LLM), which enabled us to new types of tasks and applications with multiple data types. However, multimodal LLM in the biomedical domain is primarily limited to images, text, and/or sequence data. Here I propose to work on multimodal LLM architecture for biomedical graphs such as protein structure and chemical molecules. The research hypothesis is based on the fact that clinicians and researchers in computational biology and clinical research take advantage of various information for their decision-making process. Therefore, an AI model being able to handle multiple data types should boost its ability to use diverse knowledge for improved performances in clinical applications. ©2024 Association for Computational Linguistics.},
	keywords = {De facto standard; Foundation models; Graph structures; Knowledge graphs; Language model; Multi-modal; Multiple data types; Natural languages; Proteins structures; Transformer modeling; Natural language processing systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Fang202411365,
	author = {Fang, Tianqing and Chen, Zeming and Song, Yangqiu and Bosselut, Antoine},
	title = {Complex Reasoning over Logical Queries on Commonsense Knowledge Graphs},
	year = {2024},
	journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
	volume = {1},
	pages = {11365 – 11384},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204465345&partnerID=40&md5=089e0dd144d153af810d75a4c712ddeb},
	abstract = {Event commonsense reasoning requires the ability to reason about the relationship between events, as well as infer implicit context underlying that relationship. However, data scarcity makes it challenging for language models to learn to generate commonsense inferences for contexts and questions involving interactions between complex events. To address this demand, we present COM2 (COMplex COMmonsense), a new dataset created by sampling multi-hop logical queries (e.g., the joint effect or cause of both event A and B, or the effect of the effect of event C) from an existing commonsense knowledge graph (CSKG), and verbalizing them using handcrafted rules and large language models into multiple-choice and text generation questions. Our experiments show that language models trained on COM2 exhibit significant improvements in complex reasoning ability, resulting in enhanced zero-shot performance in both in-domain and out-of-domain tasks for question answering and generative commonsense reasoning, without expensive human annotations. © 2024 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Modeling languages; Structured Query Language; Commonsense knowledge; Commonsense reasoning; Complex events; Data scarcity; Handcrafted rules; Joint effect; Knowledge graphs; Language model; Learn+; Multi-hops; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Agarwal202410119,
	author = {Agarwal, Prerna and Kumar, Nishant and Bedathur, Srikanta},
	title = {SymKGQA: Few-Shot Knowledge Graph Question Answering via Symbolic Program Generation and Execution},
	year = {2024},
	journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
	volume = {1},
	pages = {10119 – 10140},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204481424&partnerID=40&md5=c2703f774177c78033468922328cbab1},
	abstract = {Semantic Parsing of natural language questions into their executable logical form (LF) has shown state-of-the-art (SOTA) performance for Knowledge Graph Question Answering (KGQA). However, these methods are not applicable for real-world applications, due to lack of KG-specific training data. Recent advances in the capabilities of Large Language Models (LLMs) has led towards generating low-level LFs such as SPARQL and S-Expression in a few-shot setting. Unfortunately, these methods: (1) are limited to the knowledge of underlying LLM about the LF, (2) performs inferior for the harder complex benchmarks such as KQA Pro, (3) suffers while grounding the generated LF to a specific Knowledge Graph. Recently, a new LF called KoPL (Cao et al., 2022a) has been introduced that explicitly models complex reasoning process step-by-step in a symbolic manner and has shown SOTA on KQA Pro in fully-supervised setting. Inspired by this, we propose SymKGQA framework that generates step-by-step Symbolic LF i.e., KoPL in a few-shot in-context learning setting using LLM. Our framework is not dependent on pre-trained knowledge of LLM about KoPL. We further build a Retrieval-Augmented Generation based Question-Aware Contextual KoPL (QUACK) resolver to ground the generated LF. Our experiments with different LLMs and few-shot settings demonstrate that SymKGQA outperforms all other few-shot and even many of the fully-supervised KGQA approaches. © 2024 Association for Computational Linguistics.},
	keywords = {Benchmarking; Computational linguistics; Natural language processing systems; Semantics; Zero-shot learning; Executables; Knowledge graphs; Language model; Logical forms; Natural language questions; Program execution; Program generation; Question Answering; Semantic parsing; State-of-the-art performance; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Gupta202465,
	author = {Gupta, Tanay Kumar and Goel, Tushar and Verma, Ishan and Dey, Lipika and Bhardwaj, Sachit},
	title = {Knowledge Graph aided LLM based ESG Question-Answering from News},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3753},
	pages = {65 – 78},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204312367&partnerID=40&md5=36a503e3640f5272a3c77763a15a6fe1},
	abstract = {Organizations around the globe have acknowledged the importance of sustainability. Sustainability performance has gained traction in investing and risk management and is now an integral part of business planning. The volume and velocity of information being published on the web have made use of natural language processing evident for insight generation. With the recent advancements in language modelling and the availability of Large Language Models (LLM), conversational insight generation is increasingly becoming popular. LLM combined with advanced retrieval techniques has eased the task of question-answering over large natural language datasets. In this work, we present a novel approach that leverages Knowledge Graph-based Retrieval Augmented Generation (KG-RAG) to facilitate question-answering in the context of sustainability news articles and corporate Environmental, Social, and Governance (ESG) performance. Our methodology encompasses the creation of an ESG Knowledge Graph, retrieval techniques that identify contextually relevant information, and an LLM-based answer-generation framework. We have experimented with multiple LLM models and have shown a comparative study of their performances against several baseline algorithms. © 2024 Copyright for this paper by its authors.},
	author_keywords = {ESG; Knowledge Graph; Large Language Models; Question Answering; Sustainability},
	keywords = {Enterprise resource planning; Modeling languages; Risk management; Environmental, social, and governance; Knowledge graphs; Language model; Large language model; Model-based OPC; Natural languages; Performance; Question Answering; Retrieval techniques; Sustainability performance; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{2024,
	title = {Proceedings - 2024 Ivannikov Memorial Workshop, IVMEM 2024},
	year = {2024},
	journal = {Proceedings - 2024 Ivannikov Memorial Workshop, IVMEM 2024},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204376426&partnerID=40&md5=abd7a0c5847f2b0580190962a4968a07},
	abstract = {The proceedings contain 12 papers. The topics discussed include: automatic verification of the text layer correctness in PDF documents; enhancing user-centric information retrieval: a unified dual-DBMS strategy for integrating full-text and knowledge graph searches; crash report accumulation during continuous fuzzing; SSSD-ECG-nle: new label embeddings with structured state-space models for ECG generation; how to classify document segments using graph based representation and neural networks; classification of static analyzer warnings using machine learning methods; user defined checkers for static analysis with symbolic execution; data modeling for consistent access control in heterogeneous big data systems; and large language models in source code static analysis.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Holtz2024,
	author = {Holtz, Niklas and Wittfoth, Sven and Gómez, Jorge Marx},
	title = {The New Era of Knowledge Retrieval: Multi-Agent Systems Meet Generative AI},
	year = {2024},
	journal = {PICMET 2024 - 2024 Portland International Conference on Management of Engineering and Technology: Technology Management in the Artificial Intelligence Era, Proceedings},
	doi = {10.23919/PICMET64035.2024.10653018},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204375214&doi=10.23919%2fPICMET64035.2024.10653018&partnerID=40&md5=369a84be2057e96a2d7b4a68dd79d06b},
	abstract = {In the realm of interactive chat systems, the fusion of Multi-Agent Systems (MAS) with Generative Artificial Intelligence (GAl) presents a promising approach to dynamic information retrieval and personalized user experiences. Handling diverse data sources with distinct modalities, especially in real-time, poses challenges. This paper provides a comprehensive overview of MAS and GAl, emphasizing their synergistic potential in complex real-time searches. A notable contribution is an experimental prototype adept at navigating real-time data sources beyond the AI's training data, enhancing the user's information-seeking experience. By integrating MAS adaptability with GAl's data-processing capabilities, our approach delivers valuable real-time insights. The exploration of knowledge graphs based on acquired data further enriches the system. However, inherent limitations include scalability challenges, data integrity maintenance, and the refinement of the user experience. Addressing these challenges lays the foundation for future research in the exciting intersection of MAS and GAl, offering insights into the potential of this combined approach in advancing interactive chat systems.  © 2024 PICMET.},
	keywords = {Data assimilation; Data handling; Chat system; Data-source; Dynamic information retrieval; Experimental prototype; Knowledge retrieval; Multiagent systems (MASs); Real- time; Real-time data; Real-time searches; Users' experiences; Chatbots},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Yang2024155,
	author = {Yang, Rui and Liu, Haoran and Marrese-Taylor, Edison and Zeng, Qingcheng and Ke, Yu He and Li, Wanxin and Cheng, Lechao and Chen, Qingyu and Caverlee, James and Matsuo, Yutaka and Li, Irene},
	title = {KG-Rank: Enhancing Large Language Models for Medical QA with Knowledge Graphs and Ranking Techniques},
	year = {2024},
	journal = {BioNLP 2024 - 23rd Meeting of the ACL Special Interest Group on Biomedical Natural Language Processing, Proceedings of the Workshop and Shared Tasks},
	pages = {155 – 166},
	doi = {10.18653/v1/2024.bionlp-1.13},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204459936&doi=10.18653%2fv1%2f2024.bionlp-1.13&partnerID=40&md5=a7cc7fcf11e76615bd8964888651e4b1},
	abstract = {Large language models (LLMs) have demonstrated impressive generative capabilities with the potential to innovate in medicine. However, the application of LLMs in real clinical settings remains challenging due to the lack of factual consistency in the generated content. In this work, we develop an augmented LLM framework, KG-Rank, which leverages a medical knowledge graph (KG) along with ranking and re-ranking techniques, to improve the factuality of long-form question answering (QA) in the medical domain. Specifically, when receiving a question, KG-Rank automatically identifies medical entities within the question and retrieves the related triples from the medical KG to gather factual information. Subsequently, KG-Rank innovatively applies multiple ranking techniques to refine the ordering of these triples, providing more relevant and precise information for LLM inference. To the best of our knowledge, KG-Rank is the first application of KG combined with ranking models in medical QA specifically for generating long answers. Evaluation on four selected medical QA datasets demonstrates that KG-Rank achieves an improvement of over 18% in ROUGE-L score. Additionally, we extend KG-Rank to open domains, including law, business, music, and history, where it realizes a 14% improvement in ROUGE-L score, indicating the effectiveness and great potential of KG-Rank.. ©2024 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Question answering; Clinical settings; Graph technique; Knowledge graphs; Language model; Medical knowledge; Medical question answering; Modelling framework; Question Answering; Ranking technique; Re-ranking techniques; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@CONFERENCE{Usmanova2024168,
	author = {Usmanova, Aida and Usbeck, Ricardo},
	title = {Structuring Sustainability Reports for Environmental Standards with LLMs guided by Ontology},
	year = {2024},
	journal = {ClimateNLP 2024 - 1st Workshop on Natural Language Processing Meets Climate Change, Proceedings of the Workshop},
	pages = {168 – 177},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204423193&partnerID=40&md5=37d7cf082d5590cc536fab064c9a9cd2},
	abstract = {Following the introduction of the European Sustainability Reporting Standard (ESRS), companies will have to adapt to a new policy and provide mandatory sustainability reports. However, implementing such reports entails a challenge, such as the comprehension of a large number of textual information from various sources. This task can be accelerated by employing Large Language Models (LLMs) and ontologies to effectively model the domain knowledge. In this study, we extended an existing ontology to model ESRS Topical Standard for disclosure. The developed ontology would enable automated reasoning over the data and assist in constructing Knowledge Graphs (KGs). Moreover, the proposed ontology extension would also help to identify gaps in companies’ sustainability reports with regard to the ESRS requirements. Additionally, we extracted knowledge from corporate sustainability reports via LLMs guided with a proposed ontology and developed their KG representation. ©2024 Association for Computational Linguistics.},
	keywords = {Automated reasoning; Domain knowledge; Environmental standards; Knowledge graphs; Language model; Ontology's; Reporting standards; Sustainability report; Sustainability reporting; Textual information; Sustainable development goals},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{2024,
	title = {TextGraphs at ACL 2024 - Proceedings of TextGraphs-17: Graph-Based Methods for Natural Language Processing, 62nd Annual Meeting of the Association of Computational Linguistics},
	year = {2024},
	journal = {TextGraphs at ACL 2024 - Proceedings of TextGraphs-17: Graph-Based Methods for Natural Language Processing, 62nd Annual Meeting of the Association of Computational Linguistics},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204880560&partnerID=40&md5=68ee36dcb78c4c5c0712c8bf46814866},
	abstract = {The proceedings contain 15 papers. The topics discussed include: learning human action representations from temporal context in lifestyle vlogs; a pipeline approach for parsing documents into uniform meaning representation graphs; financial product ontology population with large language models; prompt me one more time: a two-step knowledge extraction pipeline with ontology-based verification; towards understanding attention-based reasoning through graph structures in medical codes classification; leveraging graph structures to detect hallucinations in large language models; semantic graphs for syntactic simplification: a revisit from the age of LLM; Skoltech at TextGraphs-17 Shared Task: finding GPT-4 prompting strategies for multiple choice que stions; and JellyBell at TextGraphs-17 Shared Task: fusing large language models with external knowledge for enhanced question answering.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Belikova2024154,
	author = {Belikova, Julia and Beliakin, Evegeniy and Konovalov, Vasily},
	title = {JellyBell at TextGraphs-17 Shared Task: Fusing Large Language Models with External Knowledge for Enhanced Question Answering},
	year = {2024},
	journal = {TextGraphs at ACL 2024 - Proceedings of TextGraphs-17: Graph-Based Methods for Natural Language Processing, 62nd Annual Meeting of the Association of Computational Linguistics},
	pages = {154 – 160},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204924501&partnerID=40&md5=0b8dd41365b1ff2a3865e250302497f6},
	abstract = {This work describes an approach to develop Knowledge Graph Question Answering (KGQA) system for TextGraphs-17 shared task. The task focuses on the fusion of Large Language Models (LLMs) with Knowledge Graphs (KGs). The goal is to select a KG entity (out of several candidates) which corresponds to an answer given a textual question. Our approach applies LLM to identify the correct answer among the list of possible candidates. We confirm that integrating external information is particularly beneficial when the subject entities are not well-known, and using RAG can negatively impact the performance of LLM on questions related to popular entities, as the retrieved context might be misleading. With our result, we achieved 2nd place in the post-evaluation phase. © 2024 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Knowledge graph; Evaluation phase; External informations; External knowledge; Knowledge graphs; Language model; Performance; Post evaluations; Question Answering; Question answering systems; Question answering},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Jiang20247566,
	author = {Jiang, Xuhui and Shen, Yinghan and Shi, Zhichao and Xu, Chengjin and Li, Wei and Li, Zixuan and Guo, Jian and Shen, Huawei and Wang, Yuanzhuo},
	title = {Unlocking the Power of Large Language Models for Entity Alignment},
	year = {2024},
	journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
	volume = {1},
	pages = {7566 – 7583},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204450323&partnerID=40&md5=79599ff1cef99ee6f826f908ec7e51e2},
	abstract = {Entity Alignment (EA) is vital for integrating diverse knowledge graph (KG) data, playing a crucial role in data-driven AI applications. Traditional EA methods primarily rely on comparing entity embeddings, but their effectiveness is constrained by the limited input KG data and the capabilities of the representation learning techniques. Against this backdrop, we introduce ChatEA, an innovative framework that incorporates large language models (LLMs) to improve EA. To address the constraints of limited input KG data, ChatEA introduces a KG-code translation module that translates KG structures into a format understandable by LLMs, thereby allowing LLMs to utilize their extensive background knowledge to improve EA accuracy. To overcome the over-reliance on entity embedding comparisons, ChatEA implements a two-stage EA strategy that capitalizes on LLMs' capability for multi-step reasoning in a dialogue format, thereby enhancing accuracy while preserving efficiency. Our experimental results verify ChatEA's superior performance, highlighting LLMs' potential in facilitating EA tasks. The source code is available at https://github.com/jxh4945777/ChatEA/. © 2024 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Computer aided language translation; Contrastive Learning; Knowledge graph; AI applications; Alignment methods; Data driven; Data playing; Embeddings; Graph data; Knowledge graphs; Language model; Learning techniques; Power; Embeddings},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Merkle2024,
	author = {Merkle, Nicole},
	title = {AutoGenHR: Automated Generation of Health Reports for Patients at Home},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3759},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204721979&partnerID=40&md5=bf5c8d0e61132bd120ca1bf8dacb92d5},
	abstract = {European countries have the highest proportion of people over the age of 50.This implies that age-related diseases, such as cardiovascular diseases, diabetes, cholesterol and dementia, are becoming increasingly common in our aging societies.Additionally, it can be observed that health systems are overburdened due to a lack of medical specialists, resources and capacities.To get an appointment with a medical specialist, patients have to wait up to several months.These circumstances imply that necessary health checks and detection of health risks cannot be carried out in a sufficient manner.Furthermore, the personalisation of medical treatments can hardly be guaranteed.To tackle these problems and enable preventive measures and interventions, a round-the-clock health monitoring, prediction of health risks, and personalised treatment would be necessary.This paper presents Auto Generative Health Reports (AutoGenHR), a work in progress that allows the automated generation of health reports based on acquired context data from round-the-clock monitoring of patients in their domestic environment.In the proposed approach health reports are generated by means of dynamically created knowledge graphs representing patients and context information, and a language model fine-tuned for generating health reports.In this way an early detection of health risks and prevention of avoidable deaths is to be achieved, while patients can stay in their domestic environments without overstretching the capacities of the health system. © 2024 Copyright for this paper by its authors.},
	author_keywords = {Digital Twins; Knowledge Graphs; Large Language Models; Transformer Neural Networks; Virtual Agents; Wearables},
	keywords = {Cardiology; Medical problems; Neurodegenerative diseases; Patient treatment; Personalized medicine; Problem oriented languages; Automated generation; Domestic environments; Health systems; Knowledge graphs; Language model; Large language model; Neural-networks; Transformer neural network; Virtual agent; Wearable; Electronic health record},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Dobriy202418,
	author = {Dobriy, Daniil},
	title = {Employing RAG to Create a Conference Knowledge Graph from Text},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3747},
	pages = {18},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203317673&partnerID=40&md5=16e9ffb1be06509864b372b91808c489},
	abstract = {In this paper, we present Semantic Observer, a platform that 1) defines a FAIR Conference Ontology for describing academic conferences, 2) presents an RAG architecture that constructs a Conference Knowledge Graph based on this ontology, 3) evaluates the architecture on a corpus of latest available CORE conference websites. The Conference Ontology models key entities such as conferences, workshops and challenges, organizer and programme committees, calls for papers and proposals as well as major deadlines and relevant topics. In the evaluation, we compare the performance of three leading Large Language Models: GPT-4 Turbo and Claude 3 Opus - in supporting the Knowledge Graph construction from text. The best-performing RAG architecture is then implemented in Semantic Observer and available in a SPARQL endpoint to make up-to-date conference information FAIR: findable, accessible, interoperable and reusable. © 2024 Copyright for this paper by its authors.},
	author_keywords = {Knowledge Graph; Ontology Engineering; Research Ecosystem; Retrieval-Augmented Generation; Semantic Web; Web Crawling},
	keywords = {Engineering research; Interoperability; Latent semantic analysis; Ontology; Reusability; Semantics; Web crawler; Academic conferences; Graph-based; Knowledge graphs; Ontology engineering; Ontology model; Ontology's; Research ecosystem; Retrieval-augmented generation; Semantic-Web; Web Crawling; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Gurgurov202463,
	author = {Gurgurov, Daniil and Hartmann, Mareike and Ostermann, Simon},
	title = {Adapting Multilingual LLMs to Low-Resource Languages with Knowledge Graphs via Adapters},
	year = {2024},
	journal = {KaLLM 2024 - 1st Workshop on Knowledge Graphs and Large Language Models, Proceedings of the Workshop},
	pages = {63 – 74},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204422426&partnerID=40&md5=c5a4754d9c368a6b48bc5247ac4e71a4},
	abstract = {This paper explores the integration of graph knowledge from linguistic ontologies into multilingual Large Language Models (LLMs) using adapters to improve performance for low-resource languages (LRLs) in sentiment analysis (SA) and named entity recognition (NER). Building upon successful parameter-efficient fine-tuning techniques, such as K-ADAPTER (Wang et al., 2021) and MAD-X (Pfeiffer et al., 2020), we propose a similar approach for incorporating knowledge from multilingual graphs, connecting concepts in various languages with each other through linguistic relationships, into multilingual LLMs for LRLs. Specifically, we focus on eight LRLs —Maltese, Bulgarian, Indonesian, Nepali, Javanese, Uyghur, Tibetan, and Sinhala — and employ language-specific adapters fine-tuned on data extracted from the language-specific section of ConceptNet, aiming to enable knowledge transfer across the languages covered by the knowledge graph. We compare various fine-tuning objectives, including standard Masked Language Modeling (MLM), MLM with full-word masking, and MLM with targeted masking, to analyze their effectiveness in learning and integrating the extracted graph data. Through empirical evaluation on language-specific tasks, we assess how structured graph knowledge affects the performance of multilingual LLMs for LRLs in SA and NER, providing insights into the potential benefits of adapting language models for low-resource scenarios. ©2024 Association for Computational Linguistics.},
	keywords = {Computational linguistics; ConceptNet; Fine tuning; Improve performance; Knowledge graphs; Language model; Linguistic ontology; Low resource languages; Named entity recognition; Sentiment analysis; Tibetans; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Markowitz202412302,
	author = {Markowitz, Elan and Ramakrishna, Anil and Dhamala, Jwala and Mehrabi, Ninareh and Peris, Charith and Gupta, Rahul and Chang, Kai-Wei and Galstyan, Aram},
	title = {Tree-of-Traversals: A Zero-Shot Reasoning Algorithm for Augmenting Black-box Language Models with Knowledge Graphs},
	year = {2024},
	journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
	volume = {1},
	pages = {12302 – 12319},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204484373&partnerID=40&md5=0aac9e9bef5572c5a86c848b63101aad},
	abstract = {Knowledge graphs (KGs) complement Large Language Models (LLMs) by providing reliable, structured, domain-specific, and up-to-date external knowledge. However, KGs and LLMs are often developed separately and must be integrated after training. We introduce Tree-of-Traversals, a novel zero-shot reasoning algorithm that enables augmentation of black-box LLMs with one or more KGs. The algorithm equips a LLM with actions for interfacing a KG and enables the LLM to perform tree search over possible thoughts and actions to find high confidence reasoning paths. We evaluate on two popular benchmark datasets. Our results show that Tree-of-Traversals significantly improves performance on question answering and KG question answering tasks. Code is available at https://github.com/amazon-science/tree-of-traversals. © 2024 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Structured Query Language; Trees (mathematics); Zero-shot learning; Benchmark datasets; Black boxes; Domain specific; External knowledge; Graph complement; High confidence; Knowledge graphs; Language model; Reasoning algorithms; Tree-search; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{2024,
	title = {KnowLLM 2024 - 1st Workshop on Towards Knowledgeable Language Models, Proceedings of the Workshop},
	year = {2024},
	journal = {KnowLLM 2024 - 1st Workshop on Towards Knowledgeable Language Models, Proceedings of the Workshop},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204904251&partnerID=40&md5=dfebedd156b2fd9e9827b3c0f7da4388},
	abstract = {The proceedings contain 16 papers. The topics discussed include: PhonologyBench: evaluating phonological skills of large language models; is your large language model knowledgeable or a choices-only cheater?; reassess summary factual inconsistency detection with large language model; retrieval-augmented knowledge integration into language models: a survey; modeling uncertainty and using post-fusion as fallback improves retrieval augmented generation with LLMs; AcKnowledge: acquired knowledge representation by small language model without pre-training; beyond probabilities: unveiling the misalignment in evaluating large language models; patent response system optimized for faithfulness: procedural knowledge embodiment with knowledge graph and retrieval augmented generation; and retrieve, generate, evaluate: a case study for medical paraphrases generation with small language models.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Li20242610,
	author = {Li, Yihao and Zhang, Ru and Liu, Jianyi and Lei, Qi},
	title = {A Semantic Controllable Long Text Steganography Framework Based on LLM Prompt Engineering and Knowledge Graph},
	year = {2024},
	journal = {IEEE Signal Processing Letters},
	volume = {31},
	pages = {2610 – 2614},
	doi = {10.1109/LSP.2024.3456636},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204149563&doi=10.1109%2fLSP.2024.3456636&partnerID=40&md5=4887ab804a00eeaff449b2fc3b09c892},
	abstract = {With ongoing advancements in natural language technology, text steganography has achieved notable progress. However, existing methods primarily concentrate on the probability distribution between words, often overlooking comprehensive control over text semantics. Particularly in the case of longer texts, these methods struggle to preserve coherence and contextual consistency, thereby increasing the risk of detection in practical applications. To effectively improve steganography security, we propose a semantic controllable long-text steganography framework based on prompt engineering and knowledge graph (KG) integration, obviating supplementary training. This framework leverages triplets from the KG and task descriptions to construct prompts, directing the large language model (LLM) to generate text that aligns with the triplet content. Subsequently, the model effectively embeds secret information by encoding the candidate pools established around the sampled target words. The experimental results demonstrate that our framework ensures the concealment of steganographic text while maintaining the relevance and consistency of the content as expected. Moreover, it can be flexibly adapted to various application scenarios, showcasing its potential and advantages in practical implementations.  © 1994-2012 IEEE.},
	author_keywords = {knowledge graph; LLM prompt engineering; semantic controllable; Text steganography},
	keywords = {Semantics; Steganography; Comprehensive controls; Contextual consistency; Knowledge graphs; Language model; Language technology; Large language model prompt engineering; Natural languages; Probability: distributions; Semantic controllable; Text steganography; Knowledge graph},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Lageweg2024,
	author = {Lageweg, Lucas and Kouwenhoven, Jonas and Kruit, Benno},
	title = {GECKO: A Question Answering System for Official Statistics},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3759},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204727283&partnerID=40&md5=cc222640295fbdb5a2eda10908d44baa},
	abstract = {This paper presents GECKO, a knowledge graph-based statistical question answering system currently in beta deployment.GECKO aims to facilitate the retrieval of single statistical values from an extensive database containing over a billion values across more than 4,000 tables.The system integrates a comprehensive framework including data augmentation, entity retrieval, and large language model (LLM)-based query generation.A key feature of the beta deployment is the collection of user feedback, which is critical for improving system performance and accuracy.This feedback mechanism allows users to report issues directly, ensuring continuous improvement based on real-world use. © 2024 Copyright for this paper by its authors.},
	keywords = {Knowledge graph; Modeling languages; Query languages; Structured Query Language; Data augmentation; Entity retrieval; Graph-based; Key feature; Knowledge graphs; Language model; Model-based OPC; Official Statistics; Query generation; Question answering systems; Question answering},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{2024,
	title = {KaLLM 2024 - 1st Workshop on Knowledge Graphs and Large Language Models, Proceedings of the Workshop},
	year = {2024},
	journal = {KaLLM 2024 - 1st Workshop on Knowledge Graphs and Large Language Models, Proceedings of the Workshop},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204424171&partnerID=40&md5=d776a5cc59adeb65a48bc011547363b2},
	abstract = {The proceedings contain 13 papers. The topics discussed include: multi-hop database reasoning with virtual knowledge graph; zero- and few-shots knowledge graph triplet extraction with large language models; analysis of LLM’s ‘spurious’ correct answers using evidence information of multi-hop QA datasets; KGAST: from knowledge graphs to annotated synthetic texts; HRGraph: leveraging LLMs for HR data knowledge graphs with information propagation-based job recommendation; adapting multilingual LLMs to low-resource languages with knowledge graphs via adapters; ontology-guided knowledge graph construction from maintenance short texts; educational material to knowledge graph conversion: a methodology to enhance digital education; and zero-shot fact-checking with semantic triples and knowledge graphs.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Zamazal2024,
	author = {Zamazal, Ondřej},
	title = {Towards Pattern-based Complex Ontology Matching using SPARQL and LLM},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3759},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204733796&partnerID=40&md5=5f38b3109696be1d51c0bc9e2ef0d2c3},
	abstract = {Complex ontology matching is a process to match complex structures in ontologies.While many matching tools tackle simple ontology matching, complex ontology matching is still rare.However, one entity in one ontology can be similar to a complex structure (1-to-n) or even complex structures can be on both sides (m-to-n).Therefore, the application, e.g., data integration, must consider complex correspondences within ontology alignment.Our poster paper presents a pattern-based approach where particular SPARQL queries correspond to a specific pattern, e.g., Class by Attribute Type (CAT), for its detection.SPARQL queries are anchored to entities from simple correspondences on input.Detected complex correspondence candidates are verbalized to be validated by the Large Language Model (LLM).Further, we provide a zero-shot prompting preliminary experiment and evaluation.The poster paper is equipped with the Jupyter notebook for automation of the pipeline and the full report of the experiment at: https://github.com/OndrejZamazal/ComplexOntologyMatching-SEMANTiCS2024. © 2024 Copyright for this paper by its authors.},
	author_keywords = {Complex Ontology Matching; Knowledge Graph; Large Language Model; Ontology; Ontology Matching},
	keywords = {Knowledge graph; Modeling languages; Ontology; Structured Query Language; Complex correspondences; Complex ontology matching; Complexes structure; Knowledge graphs; Language model; Large language model; Ontology matching; Ontology's; Simple++; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Maushagen2024,
	author = {Maushagen, Jan and Sepehri, Sara and Sanctorum, Audrey and Vanhaecke, Tamara and De Troyer, Olga and Debruyne, Christophe},
	title = {Populating CSV Files from Unstructured Text with LLMs for KG Generation with RML},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3759},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204674099&partnerID=40&md5=5af2f0f3be9963d2e7024164bf1377d3},
	abstract = {We report on an exploratory study using Large Language Models (LLMs) to generate Comma-Separated Values (CSV) files, which are subsequently transformed into Resource Description Framework (RDF) using the RDF Mapping Language (RML).Prior studies have shown that LLMs sometimes have problems generating valid and well-formed RDF from unstructured texts, i.e., issues with RDF, not the contents.We wanted to test whether the generation of CSV led to fewer issues and whether this would be a viable option for allowing domain experts to be actively part of the Knowledge Graph (KG) population process by allowing them to use familiar tools.We have built a prototype illustrating this idea, and the results seem promising for further study.The initial prototype uses zero-shot training and is built on GPT-4.The prototype takes the unstructured text and the CSV file's structure as input and uses the latter to generate prompts to fill in the cells' values.Future work includes analyzing the effect of different prompting strategies.The limitation, however, is that such an approach only works for projects where domain experts work with spreadsheets for pre-existing mappings. © 2024 Copyright for this paper by its authors.},
	author_keywords = {End-user Involvement; KG Construction; LLMs},
	keywords = {Computer hardware description languages; Knowledge graph; Domain experts; End user involvement; Graph construction; Knowledge graph construction; Knowledge graphs; Language model; Large language model; Mapping Language; Resources description frameworks; Unstructured texts; Mapping},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Saetia202453,
	author = {Saetia, Chanatip and Phruetthiset, Jiratha and Chalothorn, Tawunrat and Lertsutthiwong, Monchai and Taerungruang, Supawat and Buabthong, Pakpoom},
	title = {Financial Product Ontology Population with Large Language Models},
	year = {2024},
	journal = {TextGraphs at ACL 2024 - Proceedings of TextGraphs-17: Graph-Based Methods for Natural Language Processing, 62nd Annual Meeting of the Association of Computational Linguistics},
	pages = {53 – 60},
	doi = {10.18653/v1/2024.textgraphs-1.4},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204898551&doi=10.18653%2fv1%2f2024.textgraphs-1.4&partnerID=40&md5=3d59c1294d062d382ee3ca7ace0368c1},
	abstract = {Ontology population, which aims to extract structured data to enrich domain-specific ontologies from unstructured text, typically faces challenges in terms of data scarcity and linguistic complexity, particularly in specialized fields such as retail banking. In this study, we investigate the application of large language models (LLMs) to populate domain-specific ontologies of retail banking products from Thai corporate documents. We compare traditional span-based approaches to LLMs-based generative methods, with different prompting techniques. Our findings reveal that while span-based methods struggle with data scarcity and the complex linguistic structure, LLMs-based generative approaches substantially outperform, achieving a 61.05% F1 score, with the most improvement coming from providing examples in the prompts. This improvement highlights the potential of LLMs for ontology population tasks, offering a scalable and efficient solution for structured information extraction, especially in low-resource language settings. © 2024 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Data scarcity; Domain-specific ontologies; Financial products; Language model; Model-based OPC; Ontology Population; Product Ontologies; Retail banking; Structured data; Unstructured texts; Ontology},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{2024,
	title = {27th International Conference on Text, Speech, and Dialogue, TSD 2024},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {15048 LNAI},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203580874&partnerID=40&md5=2b15e97c0db88200d96e91fd67cdccc0},
	abstract = {The proceedings contain 50 papers. The special focus in this conference is on Text, Speech, and Dialogue. The topics include: Bilingual Lexicon Induction From Comparable and Parallel Data: A Comparative Analysis; explaining Metaphors in the French Language by Solving Analogies Using a Knowledge Graph; the Aranea Corpora Family: Ten+ Years of Processing Web-Crawled Data; continual Learning Under Language Shift; neural Spell-Checker: Beyond Words with Synthetic Data Generation; coastTerm: A Corpus for Multidisciplinary Term Extraction in Coastal Scientific Literature; new Human-Annotated Dataset of Czech Health Records for Training Medical Concept Recognition Models; Analyzing Biases in Popular Answer Selection Datasets on Neural-Based QA Models; using Neural Coherence Models to Assess Discourse Coherence; named Entity Linking in English-Czech Parallel Corpus; tamSiPara: A Tamil – Sinhala Parallel Corpus; automatic Ellipsis Reconstruction in Coordinated German Sentences Based on Text-to-Text Transfer Transformers; better Low-Resource Machine Translation with Smaller Vocabularies; bella Turca: A Large-Scale Dataset of Diverse Text Sources for Turkish Language Modeling; Evaluation Metrics in LLM Code Generation; kernel Least Squares Transformations for Cross-Lingual Semantic Spaces; unsupervised Extraction of Morphological Categories for Morphemes; Introducing LCC’s NavProc 1.0 Corpus: Annotated Procedural Texts in the Naval Domain; models and Strategies for Russian Word Sense Disambiguation: A Comparative Analysis; open-Source Web Service with Morphological Dictionary–Supplemented Deep Learning for Morphosyntactic Analysis of Czech; mistrík’s Readability Metric – an Online Library.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Choi20248702,
	author = {Choi, Wonje and Kim, Woo Kyung and Yoo, Minjong and Woo, Honguk},
	title = {Embodied CoT Distillation From LLM To Off-the-shelf Agents},
	year = {2024},
	journal = {Proceedings of Machine Learning Research},
	volume = {235},
	pages = {8702 – 8721},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203796831&partnerID=40&md5=fb95859299a3ae13d282c03c79b2b690},
	abstract = {We address the challenge of utilizing large language models (LLMs) for complex embodied tasks, in the environment where decision-making systems operate timely on capacity-limited, off-the-shelf devices. We present DEDER, a framework for decomposing and distilling the embodied reasoning capabilities from LLMs to efficient, small language model (sLM)-based policies. In DEDER, the decision-making process of LLM-based strategies is restructured into a hierarchy with a reasoning-policy and planning-policy. The reasoning-policy is distilled from the data that is generated through the embodied in-context learning and self-verification of an LLM, so it can produce effective rationales. The planning-policy, guided by the rationales, can render optimized plans efficiently. In turn, DEDER allows for adopting sLMs for both policies, deployed on off-the-shelf devices. Furthermore, to enhance the quality of intermediate rationales, specific to embodied tasks, we devise the embodied knowledge graph, and to generate multiple rationales timely through a single inference, we also use the contrastively prompted attention model. Our experiments with the ALFRED benchmark demonstrate that DEDER surpasses leading language planning and distillation approaches, indicating the applicability and efficiency of sLM-based embodied policies derived through DEDER. Copyright 2024 by the author(s)},
	keywords = {Benchmarking; Decision making; Inference engines; Knowledge graph; Context learning; Decision-making process; Decision-making systems; In contexts; Language model; Model-based OPC; Model-based strategy; Off-the-shelf devices; Planning policies; Reasoning capabilities; Distillation},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Regino202418,
	author = {Regino, André Gomes and Cesar dos Reis, Julio},
	title = {Generating E-commerce Related Knowledge Graph from Text: Open Challenges and Early Results using LLMs},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3747},
	pages = {18},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203334838&partnerID=40&md5=ac53dff8d619e6e1d33d20a00efdd161},
	abstract = {E-commerce systems need to use and manage vast amounts of unstructured textual data. This poses significant challenges for knowledge representation, information retrieval, and recommendation tasks. This study investigates the generation of E-commerce-related Knowledge Graphs (KGs) from text. In particular, we explore using Large Language Models (LLMs). Our approach integrates ontology with text-based examples from existing KGs via prompts to create structured RDF triples. We outline a four-step method encompassing text classification, extracting relevant characteristics, generating RDF triples, and assessing the generated triples. Each step leverages LLM instructions to process unstructured text. We discuss the insights, challenges, and potential future directions, highlighting the significance of integrating ontology elements with unstructured text for generating semantically enriched KGs. Through case experimentations, we demonstrate the effectiveness and applicability of our solution in the E-commerce domain. © 2024 Copyright for this paper by its authors.},
	author_keywords = {KG enhancement; Knowledge Graphs; Large Language Models; text-to-triple},
	keywords = {Marketplaces; Ontology; Structured Query Language; E-commerce systems; Knowledge graph enhancement; Knowledge graphs; Language model; Large language model; Ontology's; RDF triples; Text-to-triple; Unstructured texts; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Cai20242842,
	author = {Cai, Zefan and Kung, Po-Nien and Suvarna, Ashima and Ma, Mingyu Derek and Bansal, Hritik and Chang, Baobao and Brantingham, P. Jeffrey and Wang, Wei and Peng, Nanyun},
	title = {Improving Event Definition Following For Zero-Shot Event Detection},
	year = {2024},
	journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
	volume = {1},
	pages = {2842 – 2863},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204456047&partnerID=40&md5=9c8d3ffe4b8dc622d4c50b563d970b57},
	abstract = {Existing approaches on zero-shot event detection usually train models on datasets annotated with known event types, and prompt them with unseen event definitions. These approaches yield sporadic successes, yet generally fall short of expectations. In this work, we aim to improve zero-shot event detection by training models to better follow event definitions. We hypothesize that a diverse set of event types and definitions are the key for models to learn to follow event definitions while existing event extraction datasets focus on annotating many high-quality examples for a few event types. To verify our hypothesis, we construct an automatically generated Diverse Event Definition (DivED) dataset and conduct comparative studies. Our experiments reveal that a large number of event types (200) and diverse event definitions can significantly boost event extraction performance; on the other hand, the performance does not scale with over ten examples per event type. Beyond scaling, we incorporate event ontology information and hard-negative samples during training, further boosting the performance. Based on these findings, we fine-tuned a LLaMA-2-7B model on our DivED dataset, yielding performance that surpasses SOTA large language models like GPT-3.5 across three open benchmarks on zero-shot event detection. Our code and data can be found at https://github.com/PlusLabNLP/ZeroED. © 2024 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Large datasets; Modeling languages; Event Types; Events detection; Events extractions; High quality; Learn+; Performance; Set of events; Sporadics; Train model; Training model; Zero-shot learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Mohler2024252,
	author = {Mohler, Michael and Lee, Sandra and Brunson, Mary and Bracewell, David},
	title = {Introducing LCC’s NavProc 1.0 Corpus: Annotated Procedural Texts in the Naval Domain},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {15048 LNAI},
	pages = {252 – 266},
	doi = {10.1007/978-3-031-70563-2_20},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203585092&doi=10.1007%2f978-3-031-70563-2_20&partnerID=40&md5=81a6122842e87facdbdd05673525431f},
	abstract = {In this work, we introduce the NavProc 1.0 Corpus – a medium-scale, annotated corpus of procedural texts within the naval domain – for use as a first step in modeling procedural structures derived from real-world data sources. In particular, we have rigorously produced annotations of frame semantics (i.e., PropBank-inspired trigger/role links) across verbal, nominal, and adjectival frames. Furthermore, we have annotated 21 distinct types of semantic markers and structural links between textual elements (e.g., frame triggers, entities, modifiers) which, taken together, result in a text-focused graph of semantic elements. Such a graph can be used to derive a more complex procedure structure for use in personnel training, simulation, or collaborative procedure execution. Altogether, this annotation effort has encompassed 158 procedural units composed of 2,316 sentences, 44,459 tokens, and 48,137 distinct span annotations. Furthermore, we describe and report LLM-based extraction scores for use as a baseline in future research using this dataset. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {dataset; frame semantics; knowledge graph; procedures; textual structure},
	keywords = {Knowledge graph; Data-source; Dataset; Frame semantics; Knowledge graphs; Medium-scale; Procedure; Real-world; Semantic element; Structural links; Textual structure; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Shlyk2024380,
	author = {Shlyk, Darya and Groza, Tudor and Montanelli, Stefano and Cavalleri, Emanuele and Mesiti, Marco},
	title = {REAL: A Retrieval-Augmented Entity Linking Approach for Biomedical Concept Recognition},
	year = {2024},
	journal = {BioNLP 2024 - 23rd Meeting of the ACL Special Interest Group on Biomedical Natural Language Processing, Proceedings of the Workshop and Shared Tasks},
	pages = {380 – 389},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204426361&partnerID=40&md5=add561ad3e2397b0ec15ef41855d1983},
	abstract = {Large Language Models (LLMs) offer an appealing alternative to training dedicated models for many Natural Language Processing (NLP) tasks. However, outdated knowledge and hallucination issues can be major obstacles in their application in knowledge-intensive biomedical scenarios. In this study, we consider the task of biomedical concept recognition (CR) from unstructured scientific literature and explore the use of Retrieval Augmented Generation (RAG) to improve accuracy and reliability of the LLM-based biomedical CR. Our approach, named REAL (Retrieval Augmented Entity Linking), combines the generative capabilities of LLMs with curated knowledge bases to automatically annotate natural language texts with concepts from bio-ontologies. By applying REAL to benchmark corpora on phenotype concept recognition, we show its effectiveness in improving LLM-based CR performance. This research highlights the potential of combining LLMs with external knowledge sources to advance biomedical text processing. Source code is available at: https://github.com/dash-ka/REAL-BioCR.. ©2024 Association for Computational Linguistics.},
	keywords = {Benchmarking; Natural language processing systems; Bio-ontologies; Concept recognition; External knowledge; Language model; Language processing; Model-based OPC; Natural languages; Natural languages texts; Performance; Scientific literature; Computational linguistics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Boscariol2024404,
	author = {Boscariol, Marta and Meschini, Silvia and Tagliabue, Lavinia Chiara},
	title = {A METHODOLOGICAL APPROACH TO ASSET INFORMATION MANAGEMENT VIA KNOWLEDGE GRAPHS AND LARGE LANGUAGE MODELS},
	year = {2024},
	journal = {Proceedings of the European Conference on Computing in Construction},
	volume = {2024},
	pages = {404 – 411},
	doi = {10.35490/EC3.2024.286},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203450817&doi=10.35490%2fEC3.2024.286&partnerID=40&md5=3429fbf9c7bd8dd08578d49d29af671f},
	abstract = {Tackling the need of large organizations for a proactive Asset Information Management (AIM) System, a methodological approach to knowledge management applied to built assets portfolios is proposed. It aims at synergically leveraging Knowledge Graphs (KGs) and Artificial Intelligence (AI) technologies to enable analytics on input data. In the theorized pipeline Large Language Models (LLMs) are meant to be used both in the graph creation phase, extracting data from unstructured sources and organizing them according to domain ontologies, as tested on a use-case sample, and in the knowledge extraction phase via queries. © 2024 European Council on Computing in Construction.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Son20241,
	author = {Son, Juhee and Seonwoo, Yeon and Yoon, Seunghyun and Thorne, James and Oh, Alice},
	title = {Multi-hop Database Reasoning with Virtual Knowledge Graph},
	year = {2024},
	journal = {KaLLM 2024 - 1st Workshop on Knowledge Graphs and Large Language Models, Proceedings of the Workshop},
	pages = {1 – 11},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204452885&partnerID=40&md5=0e6a91c40687c48f446fee28785c8036},
	abstract = {Application of LLM to database queries on natural language sentences has demonstrated impressive results in both single and multi-hop scenarios. In the existing methodologies, the requirement to re-encode query vectors at each stage for processing multi-hop queries presents a significant bottleneck to the inference speed. This paper proposes VKGFR (Virtual Knowledge Graph based Fact Retriever) that leverages large language models to extract representations corresponding to a sentence’s knowledge graph, significantly enhancing inference speed for multi-hop reasoning without performance loss. Given that both the queries and natural language database sentences can be structured as a knowledge graph, we suggest extracting a Virtual Knowledge Graph (VKG) representation from sentences with LLM. Over the preconstructed VKG, our VKGFR conducts retrieval with a tiny model structure, showing performance improvements with higher computational efficiency. We evaluate VKGFR on the WikiNLDB and MetaQA dataset, designed for multi-hop database reasoning over text. The results indicate 13x faster inference speed on the WikiNLDB dataset without performance loss. ©2024 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Graph Databases; Natural language processing systems; Query languages; Query processing; Structured Query Language; Database queries; Graph-based; Knowledge graphs; Language model; Multi-hops; Natural languages; Performance loss; Query vectors; Single hop; Virtual knowledge; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Liu2024248,
	author = {Liu, Hao and Zhou, Shuxin and Chen, Zhehuan and Perl, Yehoshua and Wang, Jiayin},
	title = {Using Generative Large Language Models for Hierarchical Relationship Prediction in Medical Ontologies},
	year = {2024},
	journal = {Proceedings - 2024 IEEE 12th International Conference on Healthcare Informatics, ICHI 2024},
	pages = {248 – 256},
	doi = {10.1109/ICHI61247.2024.00040},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203690166&doi=10.1109%2fICHI61247.2024.00040&partnerID=40&md5=b9db9ae4076f591095a33e57521a95cd},
	abstract = {This study extends the exploration of ontology enrichment by evaluating the performance of various open-sourced Large Language Models (LLMs) on the task of predicting hierarchical relationships (IS-A) in medical ontologies including SNOMED CT Clinical Finding and Procedure hierarchies and the human Disease Ontology. With the previous finetuned BERT models for hierarchical relationship prediction as the baseline, we assessed eight open-source generative LLMs for the same task. We observed only three models, without finetuning, demonstrated comparable or superior performance compared to the baseline BERT -based models. The best performance model OpenChat achieved a macro average F1 score of 0.96 (0.95) on SNOMED CT Clinical Finding (Procedure) hierarchy, an increase over 7% from the baseline 0.89 (0.85). On human Disease Ontology, OpenChat excels with an F1 score of 0.91, outperforming the second-best performance model Vicuna (0.84). Notably, some LLMs prove unsuitable for hierarchical relationship prediction tasks or appliable for concept placement of medical ontologies. We also explored various prompt templates and ensemble techniques to uncover potential confounding factors in applying LLMs for IS-A relation predictions for medical ontologies. © 2024 IEEE.},
	author_keywords = {Hieratical Relation Prediction; Large Language Models; Medical Ontology; Prompts Design; SNOMED CT},
	keywords = {Generative adversarial networks; Hieratical relation prediction; Human disease; Language model; Large language model; Medical ontology; Performance; Performance Modeling; Prompt design; SNOMED-CT; Prediction models},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Schmidt2024,
	author = {Schmidt, Wilma Johanna and Rincon-Yanez, Diego and Kharlamov, Evgeny and Paschke, Adrian},
	title = {Scaling Scientific Knowledge Discovery with Neuro-Symbolic AI and Large Language Models},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3759},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204727190&partnerID=40&md5=996a09e6a534d56571251a2a78ee1213},
	abstract = {The increasing amount of available research data leads to the need to scale scientific knowledge discovery, e.g., the conduction of systematic literature reviews (SLRs), to keep up with fast developments in research and further support decision-making in the industry.AI-based methods are gaining importance in these tasks and have been integrated into many SLR tools.Yet, several challenges are still open on applying especially neural methods on scientific knowledge discovery tasks.To address this, we evaluate various neural and neuro-symbolic scenarios on a specific generative writing task.While confirming existing concerns on pure Large Language Model (LLM) approaches for these tasks, we obtain a heterogeneous picture of Retrieval-Augmented Generation (RAG) approaches.The most promising candidate is a Knowledge Graph (KG) based context-enhanced LLM approach for Knowledge Discovery. © 2022 Copyright for this paper by its authors.},
	author_keywords = {Knowledge Graph; Large Language Model; Neuro-Symbolic AI; Retrieval-Augmented Generation (RAG); Systematic Literature Review},
	keywords = {Knowledge graphs; Language model; Large language model; Modeling approach; Neuro-symbolic AI; Research data; Retrieval-augmented generation; Scalings; Scientific knowledge; Systematic literature review; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Zolnai-Lucas202492,
	author = {Zolnai-Lucas, Aaron and Boylan, Jack and Hokamp, Chris and Ghaffari, Parsa},
	title = {STAGE: Simplified Text-Attributed Graph Embeddings Using Pre-trained LLMs},
	year = {2024},
	journal = {KaLLM 2024 - 1st Workshop on Knowledge Graphs and Large Language Models, Proceedings of the Workshop},
	pages = {92 – 104},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204491215&partnerID=40&md5=cabda3847dc80631d8c6723d60ec1680},
	abstract = {We present Simplified Text-Attributed Graph Embeddings (STAGE), a straightforward yet effective method for enhancing node features in Graph Neural Network (GNN) models that encode Text-Attributed Graphs (TAGs). Our approach leverages Large-Language Models (LLMs) to generate embeddings for textual attributes. STAGE achieves competitive results on various node classification benchmarks while also maintaining a simplicity in implementation relative to current state-of-the-art (SoTA) techniques. We show that utilizing pre-trained LLMs as embedding generators provides robust features for ensemble GNN training, enabling pipelines that are simpler than current SoTA approaches which require multiple expensive training and prompting stages. We also implement diffusion-pattern GNNs in an effort to make this pipeline scalable to graphs beyond academic benchmarks. ©2024 Association for Computational Linguistics.},
	keywords = {Benchmarking; Computational linguistics; Graph algorithms; Graph neural networks; Knowledge graph; Network embeddings; 'current; Attributed graphs; Embeddings; Graph embeddings; Graph neural networks; Language model; Neural network model; Neural networks trainings; Simple++; State-of-the-art techniques; Graph embeddings},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Jiang20241,
	author = {Jiang, Meng and Lin, Bill Yuchen and Wang, Shuohang and Xu, Yichong and Yu, Wenhao and Zhu, Chenguang},
	title = {Introduction to Knowledge-augmented NLP},
	year = {2024},
	journal = {SpringerBriefs in Computer Science},
	volume = {Part F2530},
	pages = {1 – 5},
	doi = {10.1007/978-981-97-0747-8_1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204307302&doi=10.1007%2f978-981-97-0747-8_1&partnerID=40&md5=617faca57524b02d2f62b89605b79ebd},
	abstract = {There has been tremendous progress on the research of Natural Language Processing since more than half a century ago. While the latest development of Large Language Models (LLMs) has brought unprecedented enthusiasm about achieving human-level language understanding and generation, there still exist considerable limitations of these language models, such as the lack of world knowledge, explainability and generalization. To solve these issues, it is important to augment NLP models with external knowledge sources, including both unstructured knowledge, e.g., free-form text, and structured knowledge, e.g., knowledge graphs. The integration of these knowledge sources consists of three steps: (1) Grounding language into related knowledge; (2) Representing knowledge; and (3) Fusing knowledge representation into language models. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2024.},
	author_keywords = {External knowledge; Fusing; Grounding; Natural language processing; Representation; Structured knowledge; Unstructured knowledge},
	keywords = {Context free languages; Human form models; External knowledge; Fusing; Knowledge sources; Language model; Language processing; Natural language processing; Natural languages; Representation; Structured knowledge; Unstructured knowledge; Knowledge graph},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Sakhovskiy2024116,
	author = {Sakhovskiy, Andrey and Salnikov, Mikhail and Nikishina, Irina and Usmanova, Aida and Kraft, Angelie and Möller, Cedric and Banerjee, Debayan and Huang, Junbo and Jiang, Longquan and Abdullah, Rana and Yan, Xi and Ustalov, Dmitry and Tutubalina, Elena and Usbeck, Ricardo and Panchenko, Alexander},
	title = {TextGraphs 2024 Shared Task on Text-Graph Representations for Knowledge Graph Question Answering},
	year = {2024},
	journal = {TextGraphs at ACL 2024 - Proceedings of TextGraphs-17: Graph-Based Methods for Natural Language Processing, 62nd Annual Meeting of the Association of Computational Linguistics},
	pages = {116 – 125},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204909366&partnerID=40&md5=9bd4f475ca0c6dc3c958697950328b04},
	abstract = {This paper describes the results of the Knowledge Graph Question Answering (KGQA) shared task that was co-located with the TextGraphs 2024 workshop.1 In this task, given a textual question and a list of entities with the corresponding KG subgraphs, the participating system should choose the entity that correctly answers the question. Our competition attracted thirty teams, four of which outperformed our strong ChatGPT-based zero-shot baseline. In this paper, we overview the participating systems and analyze their performance according to a large-scale automatic evaluation. To the best of our knowledge, this is the first competition aimed at the KGQA problem using the interaction between large language models (LLMs) and knowledge graphs. © 2024 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Graph algorithms; Knowledge graph; Automatic evaluation; Co-located; Graph representation; Knowledge graphs; Language model; Large-scales; Participating systems; Performance; Question Answering; Subgraphs; Question answering},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5}
}

@ARTICLE{Wang2024,
	author = {Wang, Shu and Qiu, Peiyuan and Zhu, Yunqiang and Yang, Jie and Peng, Peng and Bai, Yan and Li, Gengze and Dai, Xiaoliang and Qi, Yanmin},
	title = {Review, framework, and future perspectives of Geographic Knowledge Graph (GeoKG) quality assessment},
	year = {2024},
	journal = {Geo-Spatial Information Science},
	doi = {10.1080/10095020.2024.2403785},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204530510&doi=10.1080%2f10095020.2024.2403785&partnerID=40&md5=b3de2bcbfaf6b71717575d4916ad358a},
	abstract = {High-quality Geographic Knowledge Graphs (GeoKGs) are highly anticipated for their potential to provide reliable semantic support in geographical knowledge reasoning, training Geographic Large Language Models (Geo-LLMs), enabling geographical recommendation, and facilitating various geospatial knowledge-driven tasks. However, there is a lack of a standardized quality assessment methodology and clearly defined evaluative indicators in the field of GeoKGs research. This research uses the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA) methodology to conduct a systematic review of literature and standards in the field of GeoKG in an effort to fill the gap. First, using the lifecycle theory as a guide, we outline and propose five groups including twenty assessment criteria and their accompanying calculation techniques for evaluating GeoKG quality. Then, expanding on this foundation, we present a streamlined evaluation scheme for GeoKGs that relies on just seven key measures, discussing their applicability, utility, and weight scheme in greater detail. After applying the GeoKG quality framework, we stated three key tasks emerge as priorities: the creation of specialized assessment tools, the formation of worldwide standards, and the building of large-scale, high-quality GeoKGs. We believe this thorough and systematic GeoKG quality assessment technique will help construct high-quality GeoKGs and promote GeoKGs as an engine for geo-intelligence applications including Geospatial Artificial Intelligence (GeoAI) systems, Sustainable Development Goals (SDGs) analyzers, and Virtual Geographic Environments (VGEs) models. © 2024 Wuhan University. Published by Informa UK Limited, trading as Taylor & Francis Group.},
	author_keywords = {assessment indicators; Geographic Knowledge Graph (GeoKG); Geospatial Artificial Intelligence (GeoAI); metrics; Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA); Quality Assessment; quality evaluation},
	keywords = {Data quality; Life cycle assessment; Semantics; Assessment indicator; Geo-spatial; Geographic knowledge graph; Geographics; Geospatial artificial intelligence; Knowledge graphs; Meta-analysis; Metric; Preferred reporting item for systematic review and meta-analyze; Quality assessment; Quality evaluation; Systematic Review; Knowledge graph},
	type = {Review},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access}
}

@ARTICLE{Arrigo2024325,
	author = {Arrigo, Marco and Farella, Mariella and Fulantelli, Giovanni and Schicchi, Daniele and Taibi, Davide},
	title = {A Task-Interaction Framework to Monitor Mobile Learning Activities Based on Artificial Intelligence and Augmented Reality},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {15027 LNCS},
	pages = {325 – 333},
	doi = {10.1007/978-3-031-71707-9_26},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204618733&doi=10.1007%2f978-3-031-71707-9_26&partnerID=40&md5=8969f18ab0f10dcddf37e54265d10518},
	abstract = {The complexity behind the analysis of mobile learning activities has requested the development of specifically designed frameworks. When students are involved in mobile learning experiences, they interact with the context in which the activities occur, the content they have access to, with peers and their teachers. The wider adoption of generative artificial intelligence introduces new interactions that researchers have to look at when learning analytics techniques are applied to monitor learning patterns. The task interaction framework proposed in this paper explores how AI-based tools affect student-content and student-context interactions during mobile learning activities, thus focusing on the interplay of Learning Analytics and Artificial Intelligence advances in the educational domain. A use case scenario that explores the framework’s application in a real educational context is also presented. Finally, we describe the architectural design of an environment that leverages the task interaction framework to analyze enhanced mobile learning experiences in which structured content extracted from a Knowledge Graph is elaborated by a large language model to provide students with personalized content. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {Augmented Reality; Generative AI; Learning Analytics Framework; Mobile Learning},
	keywords = {Adversarial machine learning; Contrastive Learning; Activity-based; Analytic technique; Generative AI; Interaction framework; Learning Activity; Learning analytic framework; Learning experiences; Learning patterns; Mobile Learning; Teachers'; Federated learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Tang2024131,
	author = {Tang, Wei and Qiao, Xiaosong and Zhao, Xiaofeng and Zhang, Min and Su, Chang and Li, Yuang and Li, Yinglu and Liu, Yilun and Yao, Feiyu and Tao, Shimin and Yang, Hao and He, Xianghui},
	title = {HW-TSC at TextGraphs-17 Shared Task: Enhancing Inference Capabilities of LLMs with Knowledge Graphs},
	year = {2024},
	journal = {TextGraphs at ACL 2024 - Proceedings of TextGraphs-17: Graph-Based Methods for Natural Language Processing, 62nd Annual Meeting of the Association of Computational Linguistics},
	pages = {131 – 136},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204871189&partnerID=40&md5=553e7bf1ed02fc1e9e1e59b398bea067},
	abstract = {In this paper, we present an effective method for TextGraphs-17 Shared Task. This task requires selecting an entity from the candidate entities that is relevant to the given question and answer. The selection process is aided by utilizing the shortest path graph in the knowledge graph, connecting entities in the query to the candidate entity. This task aims to explore how to enhance LLMs output with KGs, although current LLMs have certain logical reasoning capabilities, they may not be certain about their own outputs, and the answers they produce may be correct by chance through incorrect paths. In this case, we have introduced a LLM prompt design strategy based on self-ranking and emotion. Specifically, we let the large model score its own answer choices to reflect its confidence in the answer. Additionally, we add emotional incentives to the prompts to encourage the model to carefully examine the questions. Our submissions was conducted under zero-resource setting, and we achieved the second place in the task with an F1-score of 0.8321. © 2024 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Graph theory; Structured Query Language; 'current; Design strategies; F1 scores; Knowledge graphs; Large models; Logical reasoning; Reasoning capabilities; Shortest path graphs; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Yuan2024105,
	author = {Yuan, Zhangdie and Vlachos, Andreas},
	title = {Zero-Shot Fact-Checking with Semantic Triples and Knowledge Graphs},
	year = {2024},
	journal = {KaLLM 2024 - 1st Workshop on Knowledge Graphs and Large Language Models, Proceedings of the Workshop},
	pages = {105 – 115},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204428387&partnerID=40&md5=fa799058ed8b6e0e65367ceab0c49788},
	abstract = {Despite progress in automated fact-checking, most systems require a significant amount of labeled training data, which is expensive. In this paper, we propose a novel zero-shot method, which instead of operating directly on the claim and evidence sentences, decomposes them into semantic triples augmented using external knowledge graphs, and uses large language models trained for natural language inference. This allows it to generalize to adversarial datasets and domains that supervised models require specific training data for. Our empirical results show that our approach outperforms previous zero-shot approaches on FEVER, FEVER-Symmetric, FEVER 2.0, and Climate-FEVER, while being comparable or better than supervised models on the adversarial and the out-of-domain datasets. ©2024 Association for Computational Linguistics.},
	keywords = {Adversarial machine learning; Computational linguistics; Semantics; Zero-shot learning; External knowledge; Knowledge graphs; Knowledge use; Labeled training data; Language inference; Language model; Natural languages; Symmetrics; Training data; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Papaluca202412,
	author = {Papaluca, Andrea and Krefl, Daniel and Rodríguez Méndez, Sergio J. and Lensky, Artem and Suominen, Hanna},
	title = {Zero- and Few-Shots Knowledge Graph Triplet Extraction with Large Language Models},
	year = {2024},
	journal = {KaLLM 2024 - 1st Workshop on Knowledge Graphs and Large Language Models, Proceedings of the Workshop},
	pages = {12 – 23},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204482864&partnerID=40&md5=71e032000cb30e245881ae268172e0d1},
	abstract = {In this work, we tested the Triplet Extraction (TE) capabilities of a variety of Large Language Models (LLMs) of different sizes in the Zero- and Few-Shots settings. In detail, we proposed a pipeline that dynamically gathers contextual information from a Knowledge Base (KB), both in the form of context triplets and of (sentence, triplets) pairs as examples, and provides it to the LLM through a prompt. The additional context allowed the LLMs to be competitive with all the older fully trained baselines based on the Bidirectional Long Short-Term Memory (BiLSTM) Network architecture. We further conducted a detailed analysis of the quality of the gathered KB context, finding it to be strongly correlated with the final TE performance of the model. In contrast, the size of the model appeared to only logarithmically improve the TE capabilities of the LLMs. We release the code on GitHub 1 for reproducibility. ©2024 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Knowledge graph; Memory architecture; Zero-shot learning; Contextual information; Different sizes; Extraction capability; Knowledge graphs; Language model; Memory network architecture; Performance; Reproducibilities; Short term memory; Long short-term memory},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Lv202433594,
	author = {Lv, Qitan and Wang, Jie and Chen, Hanzhu and Li, Bin and Zhang, Yongdong and Wu, Feng},
	title = {Coarse-to-Fine Highlighting: Reducing Knowledge Hallucination in Large Language Models},
	year = {2024},
	journal = {Proceedings of Machine Learning Research},
	volume = {235},
	pages = {33594 – 33623},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203842300&partnerID=40&md5=f92b546fdd0759297c19814d978aa5ba},
	abstract = {Generation of plausible but incorrect factual information, often termed hallucination, has attracted significant research interest. Retrieval-augmented language model (RALM)-which enhances models with up-to-date knowledge-emerges as a promising method to reduce hallucination. However, existing RALMs may instead exacerbate hallucination when retrieving lengthy contexts. To address this challenge, we propose COFT, a novel COarse-to-Fine highlighTing method to focus on different granularity-level key texts, thereby avoiding getting lost in lengthy contexts. Specifically, COFT consists of three components: recaller, scorer, and selector. First, recaller applies a knowledge graph to extract potential key entities in a given context. Second, scorer measures the importance of each entity by calculating its contextual weight. Finally, selector selects high contextual weight entities with a dynamic threshold algorithm and highlights the corresponding paragraphs, sentences, or words in a coarse-to-fine manner. Extensive experiments on the knowledge hallucination benchmark demonstrate the effectiveness of COFT, leading to a superior performance over 30% in the F1 score metric. Moreover, COFT also exhibits remarkable versatility across various long-form tasks, such as reading comprehension and question answering. Copyright 2024 by the author(s)},
	keywords = {Benchmarking; Modeling languages; Coarse to fine; Different granularities; Dynamic threshold; Factual information; Granularity levels; Key entity; Knowledge graphs; Language model; Research interests; Three-component; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Chen20244345,
	author = {Chen, Hanzhu and Shen, Xu and Lv, Qitan and Wang, Jie and Ni, Xiaoqi and Ye, Jieping},
	title = {SAC-KG: Exploiting Large Language Models as Skilled Automatic Constructors for Domain Knowledge Graphs},
	year = {2024},
	journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
	volume = {1},
	pages = {4345 – 4360},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204481093&partnerID=40&md5=49d29db92bfcb093f37f46bb7736067e},
	abstract = {Knowledge graphs (KGs) play a pivotal role in knowledge-intensive tasks across specialized domains, where the acquisition of precise and dependable knowledge is crucial. However, existing KG construction methods heavily rely on human intervention to attain qualified KGs, which severely hinders the practical applicability in real-world scenarios. To address this challenge, we propose a general KG construction framework, named SAC-KG, to exploit large language models (LLMs) as Skilled Automatic Constructors for domain Knowledge Graph. SAC-KG effectively involves LLMs as domain experts to generate specialized and precise multi-level KGs. Specifically, SAC-KG consists of three components: Generator, Verifier, and Pruner. For a given entity, Generator produces its relations and tails from raw domain corpora, to construct a specialized single-level KG. Verifier and Pruner then work together to ensure precision by correcting generation errors and determining whether newly produced tails require further iteration for the next-level KG. Experiments demonstrate that SAC-KG automatically constructs a domain KG at the scale of over one million nodes and achieves a precision of 89.32%, leading to a superior performance with over 20% increase in precision rate compared to existing state-of-the-art methods for the KG construction task. © 2024 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Domain Knowledge; Graphic methods; Modeling languages; Domain experts; Domain knowledge; General knowledge; Graph construction; Graph-construction method; Human intervention; Knowledge graphs; Knowledge intensive tasks; Language model; Real-world scenario; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Wasi202456,
	author = {Wasi, Azmine Toushik},
	title = {HRGraph: Leveraging LLMs for HR Data Knowledge Graphs with Information Propagation-based Job Recommendation},
	year = {2024},
	journal = {KaLLM 2024 - 1st Workshop on Knowledge Graphs and Large Language Models, Proceedings of the Workshop},
	pages = {56 – 62},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204434142&partnerID=40&md5=e79e65e24f533748b5db57839105731a},
	abstract = {Knowledge Graphs (KGs) serving as semantic networks, prove highly effective in managing complex interconnected data in different domains, by offering a unified, contextualized, and structured representation with flexibility that allows for easy adaptation to evolving knowledge. Processing complex Human Resources (HR) data, KGs can help in different HR functions like recruitment, job matching, identifying learning gaps, and enhancing employee retention. Despite their potential, limited efforts have been made to implement practical HR knowledge graphs. This study addresses this gap by presenting a framework for effectively developing HR knowledge graphs from documents using Large Language Models. The resulting KG can be used for a variety of downstream tasks, including job matching, identifying employee skill gaps, and many more. In this work, we showcase instances where HR KGs prove instrumental in precise job matching, yielding advantages for both employers and employees. Empirical evidence from experiments with information propagation in KGs and Graph Neural Nets, along with case studies underscores the effectiveness of KGs in tasks such as job and employee recommendations and job area classification. ©2024 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Semantics; Different domains; Down-stream; Employee retention; Employee skills; Human resource functions; Information propagation; Job matching; Knowledge graphs; Language model; Semantics networks; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Zhao20246642,
	author = {Zhao, Ruilin and Zhao, Feng and Wang, Long and Wang, Xianzhi and Xu, Guandong},
	title = {KG-CoT: Chain-of-Thought Prompting of Large Language Models over Knowledge Graphs for Knowledge-Aware Question Answering},
	year = {2024},
	journal = {IJCAI International Joint Conference on Artificial Intelligence},
	pages = {6642 – 6650},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204280645&partnerID=40&md5=cedf2dd171ceca7eb93f0941d8c72b61},
	abstract = {Large language models (LLMs) encounter challenges such as hallucination and factual errors in knowledge-intensive tasks. One the one hand, LLMs sometimes struggle to generate reliable answers based on the black-box parametric knowledge, due to the lack of responsible knowledge. Moreover, fragmented knowledge facts extracted by knowledge retrievers fail to provide explicit and coherent reasoning paths for improving LLM reasoning. To address these challenges, we propose KG-CoT, a novel knowledge-augmented paradigm that leverages a small-scale step-by-step graph reasoning model to reason over knowledge graphs (KGs) and utilizes a reasoning path generation method to generate chains of knowledge with high confidence for large-scale LLMs. Extensive experiments demonstrate that our KG-CoT significantly improves the performance of LLMs on knowledge-intensive question answering tasks, such as multi-hop, single-hop, and open-domain question answering benchmarks, without fine-tuning LLMs. Moreover, KG-CoT can reduce the number of API calls and cost and can generalize to various LLMs in a lightweight plug-and-play manner. © 2024 International Joint Conferences on Artificial Intelligence. All rights reserved.},
	keywords = {Benchmarking; Domain Knowledge; Black boxes; High confidence; Knowledge graphs; Knowledge intensive tasks; Language model; Model reasonings; Path generation methods; Question Answering; Reasoning models; Small scale; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Du2024147,
	author = {Du, Haowei and Li, Chen and Zhang, Dinghao and Zhao, Dongyan},
	title = {Bi-Directional Multi-Granularity Generation Framework for Knowledge Graph-to-Text with Large Language Model},
	year = {2024},
	journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
	volume = {2},
	pages = {147 – 152},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203816906&partnerID=40&md5=a5f140cc9a5c8da6a814abea5c3ceef1},
	abstract = {The knowledge graph-to-text (KG-to-text) generation task aims to synthesize coherent and engaging sentences that accurately convey the complex information derived from an input knowledge graph. Existing methods generate the whole target text based on all KG triples at once and may incorporate incorrect KG triples for each sentence. To this end, we propose the bi-directional multi-granularity generation framework. Instead of generating the whole text at a time, we construct the sentence-level generation based on the corresponding triples and generate the graph-level text as a result. Moreover, we design a backward relation-extraction task to enhance the correctness of relational information. Our method achieves the new state-of-the-art in benchmark dataset WebNLG and further analysis shows the efficiency of different modules. © 2024 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Benchmark datasets; Bi-directional; Complex information; Knowledge graphs; Language model; Multi-granularity; Relation extraction; Sentence level; State of the art; Text generations; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Shah2024125,
	author = {Shah, Mili and Cahoon, Joyce and Milletari, Mirco and Tian, Jing and Psallidas, Fotis and Mueller, Andreas and Litombe, Nick},
	title = {Improving LLM-based KGQA for multi-hop Question Answering with implicit reasoning in few-shot examples},
	year = {2024},
	journal = {KaLLM 2024 - 1st Workshop on Knowledge Graphs and Large Language Models, Proceedings of the Workshop},
	pages = {125 – 135},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204490189&partnerID=40&md5=97b2ea49f05c354246701e26d8c61462},
	abstract = {Large language models (LLMs) have shown remarkable capabilities in generating natural language texts for various tasks. However, using LLMs for question answering on knowledge graphs still remains a challenge, especially for questions requiring multi-hop reasoning. In this paper, we present a novel planned query guidance approach that improves large language model (LLM) performance in multi-hop question answering on knowledge graphs (KGQA). We do this by designing few-shot examples that implicitly demonstrate a systematic reasoning methodology to answer multi-hop questions. We evaluate our approach for two graph query languages, Cypher and SPARQL, and show that the queries generated using our strategy outperform the queries generated using a baseline LLM and typical few-shot examples by up to 24.66% and 7.7% in execution match accuracy for the MetaQA and the Spider benchmarks respectively. We also conduct an ablation study to analyze the incremental effects of the different techniques of designing few-shot examples. Our results suggest that our approach enables the LLM to effectively leverage the few-shot examples to generate queries for multi-hop KGQA. ©2024 Association for Computational Linguistics.},
	keywords = {Benchmarking; Computational linguistics; Knowledge graph; Modeling languages; Natural language processing systems; Query languages; Query processing; Structured Query Language; Graph query language; Knowledge graphs; Language model; Model-based OPC; Modeling performance; Multi-hops; Natural languages texts; Question Answering; Two-graphs; Question answering},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Tanaka20248815,
	author = {Tanaka, Shinnosuke and Barry, James and Kuruvanthodi, Vishnudev and Moses, Movina and Giammona, Maxwell J. and Herr, Nathan and Elkaref, Mohab and De Mel, Geeth},
	title = {KnowledgeHub: An End-to-End Tool for Assisted Scientific Discovery},
	year = {2024},
	journal = {IJCAI International Joint Conference on Artificial Intelligence},
	pages = {8815 – 8819},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204305030&partnerID=40&md5=05345ad9d182604337998f8d0f327d26},
	abstract = {This paper describes the KnowledgeHub tool, a scientific literature Information Extraction (IE) and Question Answering (QA) pipeline. This is achieved by supporting the ingestion of PDF documents that are converted to text and structured representations. An ontology can then be constructed where a user defines the types of entities and relationships they want to capture. A browser-based annotation tool enables annotating the contents of the PDF documents according to the ontology. Named Entity Recognition (NER) and Relation Classification (RC) models can be trained on the resulting annotations and can be used to annotate the unannotated portion of the documents. A knowledge graph is constructed from these entity and relation triples which can be queried to obtain insights from the data. Furthermore, we integrate a suite of Large Language Models (LLMs) that can be used for QA and summarisation that is grounded in the included documents via a retrieval component. KnowledgeHub is a unique tool that supports annotation, IE and QA, which gives the user full insight into the knowledge discovery pipeline. © 2024 International Joint Conferences on Artificial Intelligence. All rights reserved.},
	keywords = {Knowledge graph; Modeling languages; Question answering; Annotation tool; Classification models; End to end; Named entity recognition; Ontology's; PDF document; Question Answering; Relation classifications; Scientific discovery; Scientific literature; Ontology},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Yan2024,
	author = {Yan, Youfu and Hou, Yu and Xiao, Yongkang and Zhang, Rui and Wang, Qianwen},
	title = {KNOWNET: Guided Health Information Seeking from LLMs via Knowledge Graph Integration},
	year = {2024},
	journal = {IEEE Transactions on Visualization and Computer Graphics},
	doi = {10.1109/TVCG.2024.3456364},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203958674&doi=10.1109%2fTVCG.2024.3456364&partnerID=40&md5=3998281fad4e6004e347f2290ce62a81},
	abstract = {The increasing reliance on Large Language Models (LLMs) for health information seeking can pose severe risks due to the potential for misinformation and the complexity of these topics. This paper introduces KNOWNET a visualization system that integrates LLMs with Knowledge Graphs (KG) to provide enhanced accuracy and structured exploration. Specifically, for enhanced accuracy, KNOWNET extracts triples (e.g., entities and their relations) from LLM outputs and maps them into the validated information and supported evidence in external KGs. For structured exploration, KNOWNET provides next-step recommendations based on the neighborhood of the currently explored entities in KGs, aiming to guide a comprehensive understanding without overlooking critical aspects. To enable reasoning with both the structured data in KGs and the unstructured outputs from LLMs, KNOWNET conceptualizes the understanding of a subject as the gradual construction of graph visualization. A progressive graph visualization is introduced to monitor past inquiries, and bridge the current query with the exploration history and next-step recommendations. We demonstrate the effectiveness of our system via use cases and expert interviews.  © 2024 IEEE.},
	author_keywords = {conversational agent; Human-AI interactions; knowledge graph; large language model; progressive visualization},
	keywords = {Chatbots; Structured Query Language; Visualization; Conversational agents; Graph visualization; Health informations; Human-AI interaction; Information seeking; Knowledge graphs; Language model; Large language model; Progressive visualization; Visualization system; Knowledge graph},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Vuth202443,
	author = {Vuth, Nakanyseth and Sérasset, Gilles and Schwab, Didier},
	title = {KGAST: From Knowledge Graphs to Annotated Synthetic Texts},
	year = {2024},
	journal = {KaLLM 2024 - 1st Workshop on Knowledge Graphs and Large Language Models, Proceedings of the Workshop},
	pages = {43 – 55},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204487578&partnerID=40&md5=2a27da5c0d0f42b2e351b5fc549d7f68},
	abstract = {In recent years, the use of synthetic data, either as a complement or a substitute for original data, has emerged as a solution to challenges such as data scarcity and security risks. This paper is an initial attempt to automatically generate such data for Information Extraction tasks. We accomplished this by developing a novel synthetic data generation framework called KGAST, which leverages Knowledge Graphs and Large Language Models. In our preliminary study, we conducted simple experiments to generate synthetic versions of two datasets—a French security defense dataset and an English general domain dataset, after which we evaluated them both intrinsically and extrinsically. The results indicated that synthetic data can effectively complement original data, improving the performance of models on classes with limited training samples. This highlights KGAST’s potential as a tool for generating synthetic data for Information Extraction tasks. ©2024 Association for Computational Linguistics.},
	keywords = {Data generation framework; Data scarcity; Knowledge graphs; Language model; Performance; Security defense; Security risks; Simple++; Synthetic data; Synthetic data generations; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Tsaneva202415,
	author = {Tsaneva, Stefani and Vasic, Stefan and Sabou, Marta},
	title = {LLM-driven Ontology Evaluation: Verifying Ontology Restrictions with ChatGPT},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3747},
	pages = {15},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203385177&partnerID=40&md5=7ab507fcd01da145dd09b126148403a6},
	abstract = {Recent advancements in artificial intelligence, particularly in large language models (LLMs), have sparked interest in their application to knowledge engineering (KE) tasks. While existing research has primarily explored the utilisation of LLMs for constructing and completing semantic resources such as ontologies and knowledge graphs, the evaluation of these resources-addressing quality issues- has not yet been thoroughly investigated. To address this gap, we propose an LLM-driven approach for the verification of ontology restrictions. We replicate our previously conducted human-in-the-loop experiment using ChatGPT-4 instead of human contributors to assess whether comparable ontology verification results can be obtained. We find that (1) ChatGPT-4 achieves intermediate-to-expert scores on an ontology modelling qualification test; (2) the model performs ontology restriction verification with accuracy of 92.22%; (3) combining model answers on the same ontology axiom represented in different formalisms improves the accuracy to 96.67%; and (4) higher accuracy is observed in identifying defects related to the incompleteness of ontology axioms compared to errors due to restrictions misuse. Our results highlight the potential of LLMs in supporting knowledge engineering tasks and outline future research directions in the area. © 2024 Copyright for this paper by its authors.},
	author_keywords = {defect detection; large language models; ontology evaluation},
	keywords = {Engineering research; Errors; Knowledge graph; Modeling languages; Ontology; Defect detection; Engineering tasks; Language model; Large language model; Model-driven; Ontology axioms; Ontology evaluations; Ontology graphs; Ontology's; Semantic resources; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Randles2024,
	author = {Randles, Alex and McKenna, Lucy and Kilgallon, Lynn and Yaman, Beyza and Crooks, Peter and O'Sullivan, Declan},
	title = {Facilitating Search of the Virtual Record Treasury of Ireland Knowledge Graph using ChatGPT},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3759},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204700288&partnerID=40&md5=52346a971cb5adb0a6a1ba6f69563b58},
	abstract = {The Virtual Record Treasury of Ireland (VRTI) is an initiative to digitally recreate the contents of the Irish central archive which was destroyed during the Civil War.The project has created a Knowledge Graph (KG) to facilitate information discovery and reasoning over the recovered items.However, complex queries must be created to retrieve data in the KG, which require a high level of technical expertise.In this paper, we explore the application of Large Language Models (LLMs) to facilitate searching of the VRTI-KG by users who lack this technical expertise and to decrease workload for those who do not.The VRTI-ChatGPT framework is proposed which uses ChatGPT to interpret requests from users and to facilitate the creation of queries which can be executed on the KG. © 2024 Copyright for this paper by its authors.},
	author_keywords = {ChatGPT; KG Search; User Interface},
	keywords = {Structured Query Language; ChatGPT; Complex queries; Graph search; Information discovery; Ireland; Knowledge graph search; Knowledge graphs; Language model; Technical expertise; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Chen2024587,
	author = {Chen, Huajun},
	title = {Large Knowledge Model: Perspectives and Challenges},
	year = {2024},
	journal = {Data Intelligence},
	volume = {6},
	number = {3},
	pages = {587 – 620},
	doi = {10.3724/2096-7004.di.2024.0001},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204110127&doi=10.3724%2f2096-7004.di.2024.0001&partnerID=40&md5=f4b2b27da1dbb0854c84d654d258d704},
	abstract = {Humankind’s understanding of the world is fundamentally linked to our perception and cognition, with human languages serving as one of the major carriers of world knowledge. In this vein, Large Language Models (LLMs) like ChatGPT epitomize the pre-training of extensive, sequence-based world knowledge into neural networks, facilitating the processing and manipulation of this knowledge in a parametric space. This article explores large models through the lens of “knowledge”. We initially investigate the role of symbolic knowledge such as Knowledge Graphs (KGs) in enhancing LLMs, covering aspects like knowledge-augmented language model, structure-inducing pretraining, knowledgeable prompts, structured CoT, knowledge editing, semantic tools for LLM and knowledgeable AI agents. Subsequently, we examine how LLMs can boost traditional symbolic knowledge bases, encompassing aspects like using LLM as KG builder and controller, structured knowledge pretraining, and LLM-enhanced symbolic reasoning. Considering the intricate nature of human knowledge, we advocate for the creation of Large Knowledge Models (LKM), specifically engineered to manage diversified spectrum of knowledge structures. This promising undertaking would entail several key challenges, such as disentangling knowledge base from language models, cognitive alignment with human knowledge, integration of perception and cognition, and building large commonsense models for interacting with physical world, among others. We finally propose a five-“A” principle to distinguish the concept of LKM. © 2024 Chinese Academy of Sciences.},
	author_keywords = {Knowledge Augmentation; Knowledge Graph; Knowledge Representation; Large Knowledge Model; Large Language Model},
	keywords = {Semantics; Knowledge augmentation; Knowledge graphs; Knowledge model; Knowledge-representation; Language model; Large knowledge model; Large language model; Perception and cognition; Pre-training; World knowledge; Knowledge graph},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Li20242135,
	author = {Li, Qian and Chen, Zhuo and Ji, Cheng and Jiang, Shiqi and Li, Jianxin},
	title = {LLM-based Multi-Level Knowledge Generation for Few-shot Knowledge Graph Completion},
	year = {2024},
	journal = {IJCAI International Joint Conference on Artificial Intelligence},
	pages = {2135 – 2143},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204310706&partnerID=40&md5=64032b3df65de36e4c3add0e51772523},
	abstract = {Knowledge Graphs (KGs) are pivotal in various NLP applications but often grapple with incompleteness, especially due to the long-tail problem where infrequent, unpopular relationships drastically reduce the KG completion performance.In this paper, we focus on Few-shot Knowledge Graph Completion (FKGC), a task addressing these gaps in long-tail scenarios.Amidst the rapid evolution of Large Language Models, we propose a generation-based FKGC paradigm facilitated by LLM distillation.Our MuKDC framework employs multi-level knowledge distillation for few-shot KG completion, generating supplementary knowledge to mitigate data scarcity in few-shot environments.MuKDC comprises two primary components: Multi-level Knowledge Generation, which enriches the KG at various levels, and Consistency Assessment, to ensure the coherence and reliability of the generated knowledge.Most notably, our method achieves SOTA results in both FKGC and multi-modal FKGC benchmarks, significantly advancing KG completion and enhancing the understanding and application of LLMs in structured knowledge generation and assessment. © 2024 International Joint Conferences on Artificial Intelligence. All rights reserved.},
	keywords = {Benchmarking; Zero-shot learning; Data scarcity; Knowledge assessment; Knowledge generations; Knowledge graphs; Language model; Long tail; Multi-modal; Multilevels; Performance; Structured knowledge; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Recupero2024,
	author = {Recupero, Diego Reforgiato and Boi, Lorenzo},
	title = {Towards Seamless Human-Robot Dialogue through a Robot Action Ontology},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3749},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203599306&partnerID=40&md5=0024f1635504dfd41e02758f4eb2d9a5},
	abstract = {This research paper introduces a novel methodology enabling the Zora humanoid robot to effectively engage in dynamic interactions by responding to user queries and complementing its responses with appropriate gestures. Notably, these inquiries may extend beyond mere questions to encompass action commands articulated by the user, which the robot proficiently recognizes and executes. The integration of a Large Language Model enhances the system's capabilities, particularly in the domain of questionanswering. To bolster the recognition and execution of action commands, we have employed a robot action ontology established in previous research endeavors. This ontology defines relevant classes and individuals, forming the basis for a nuanced understanding of user-inputted action commands. Further refinement involves the generation of succinct three-word strings for each action, ensuring semantic alignment with the user's verbal instructions. Importantly, our system operates in two distinctive modes: STATELESS and STATEFUL. In STATEFUL mode, the robot possesses awareness of its present posture, allowing it to execute action commands only when they align with its current state. This adaptive feature enhances the overall effectiveness of the system, catering to the dynamic nature of human-robot interactions and promoting a seamless and contextually aware dialogue between the NAO humanoid robot and its users.  © 2024 Copyright for this paper by its authors.},
	author_keywords = {Action Robot Ontology; Human-Robot Interaction; Large Language Models; Natural Language Processing},
	keywords = {Anthropomorphic robots; Human robot interaction; Microrobots; Modeling languages; Natural language processing systems; Ontology; Action robot ontology; Humanoid robot; Humans-robot interactions; Language model; Language processing; Large language model; Natural language processing; Natural languages; Ontology's; Robot actions; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Yuan20241249,
	author = {Yuan, Siyu and Chen, Jiangjie and Sun, Changzhi and Liang, Jiaqing and Xiao, Yanghua and Yang, Deqing},
	title = {ANALOGYKB: Unlocking Analogical Reasoning of Language Models with A Million-scale Knowledge Base},
	year = {2024},
	journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
	volume = {1},
	pages = {1249 – 1265},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204446393&partnerID=40&md5=3d0e905ab36b1b841fdb7d067e3f4a24},
	abstract = {Analogical reasoning is a fundamental cognitive ability of humans. However, current language models (LMs) still struggle to achieve human-like performance in analogical reasoning tasks due to a lack of resources for model training. In this work, we address this gap by proposing ANALOGYKB, a million-scale analogy knowledge base (KB) derived from existing knowledge graphs (KGs). ANALOGYKB identifies two types of analogies from the KGs: 1) analogies of the same relations, which can be directly extracted from the KGs, and 2) analogies of analogous relations, which are identified with a selection and filtering pipeline enabled by large language models (LLMs), followed by minor human efforts for data quality control. Evaluations on a series of datasets of two analogical reasoning tasks (analogy recognition and generation) demonstrate that ANALOGYKB successfully enables both smaller LMs and LLMs to gain better analogical reasoning capabilities. Resources of this paper can be found at https://github.com/siyuyuan/analogykb. © 2024 Association for Computational Linguistics.},
	keywords = {Case based reasoning; Knowledge graph; Modeling languages; 'current; Analogical reasoning; Cognitive ability; Data quality control; Human like; Knowledge graphs; Language model; Model training; Performance; Reasoning tasks; Computational linguistics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Lee202410767,
	author = {Lee, Junlin and Wang, Yequan and Li, Jing and Zhang, Min},
	title = {Multimodal Reasoning with Multimodal Knowledge Graph},
	year = {2024},
	journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
	volume = {1},
	pages = {10767 – 10782},
	doi = {10.18653/v1/2024.acl-long.579},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204446708&doi=10.18653%2fv1%2f2024.acl-long.579&partnerID=40&md5=cdf101db867aaab2525a6666f25cd69a},
	abstract = {Multimodal reasoning with large language models (LLMs) often suffers from hallucinations and the presence of deficient or outdated knowledge within LLMs. Some approaches have sought to mitigate these issues by employing textual knowledge graphs, but their singular modality of knowledge limits comprehensive cross-modal understanding. In this paper, we propose the Multimodal Reasoning with Multimodal Knowledge Graph (MR-MKG) method, which leverages multimodal knowledge graphs (MMKGs) to learn rich and semantic knowledge across modalities, significantly enhancing the multimodal reasoning capabilities of LLMs. In particular, a relation graph attention network is utilized for encoding MMKGs and a cross-modal alignment module is designed for optimizing image-text alignment. A MMKG-grounded dataset is constructed to equip LLMs with initial expertise in multimodal reasoning through pretraining. Remarkably, MR-MKG achieves superior performance while training on only a small fraction of parameters, approximately 2.25% of the LLM's parameter size. Experimental results on multimodal question answering and multimodal analogy reasoning tasks demonstrate that our MR-MKG method outperforms previous state-of-the-art models. © 2024 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Semantics; Cross-modal; Encodings; Graph methods; Image texts; Knowledge graphs; Language model; Learn+; Multi-modal; Reasoning capabilities; Semantics knowledge; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@CONFERENCE{Li2024493,
	author = {Li, Xinze and Cao, Yixin and Pan, Liangming and Ma, Yubo and Sun, Aixin},
	title = {Towards Verifiable Generation: A Benchmark for Knowledge-aware Language Model Attribution},
	year = {2024},
	journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
	pages = {493 – 516},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203323006&partnerID=40&md5=839da3db5f0c5d6d666c4f3a05212d4a},
	abstract = {Although achieving great success, Large Language Models (LLMs) usually suffer from unreliable hallucinations. Although language attribution can be a potential solution, there are no suitable benchmarks and evaluation metrics to attribute LLMs to structured knowledge. In this paper, we define a new task of Knowledge-aware Language Model Attribution (KaLMA) that improves upon three core concerns with conventional attributed LMs. First, we extend attribution source from unstructured texts to Knowledge Graph (KG), whose rich structures benefit both the attribution performance and working scenarios. Second, we propose a new “Conscious Incompetence" setting considering the incomplete knowledge repository, where the model identifies the need for supporting knowledge beyond the provided KG. Third, we propose a comprehensive automatic evaluation metric encompassing text quality, citation quality, and text citation alignment. To implement the above innovations, we build a dataset in biography domain BioKaLMA via evolutionary question generation strategy, to control the question complexity and necessary knowledge to the answer. For evaluation, we develop a baseline solution and demonstrate the room for improvement in LLMs' citation generation, emphasizing the importance of incorporating the "Conscious Incompetence" setting, and the critical role of retrieval accuracy. © 2024 Association for Computational Linguistics.},
	keywords = {Benchmarking; Computational linguistics; Modeling languages; Structured Query Language; Benchmark metrics; Evaluation metrics; Incomplete knowledge; Knowledge graphs; Knowledge repository; Language model; Performance; Rich structure; Structured knowledge; Unstructured texts; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Boylan202423,
	author = {Boylan, Jack and Mangla, Shashank and Thorn, Dominic and Ghalandari, Demian Gholipour and Ghaffari, Parsa and Hokamp, Chris},
	title = {KGValidator: A Framework for Automatic Validation of Knowledge Graph Construction},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3747},
	pages = {23},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203374235&partnerID=40&md5=ff881bb9555d4fd36fe330a69bfb34eb},
	abstract = {This study explores the use of Large Language Models (LLMs) for automatic evaluation of knowledge graph (KG) completion models. Historically, validating information in KGs has been a challenging task, requiring large-scale human annotation at prohibitive cost. With the emergence of general-purpose generative AI and LLMs, it is now plausible that human-in-the-loop validation could be replaced by a generative agent. We introduce a framework for consistency and validation when using generative models to validate knowledge graphs. Our framework is based upon recent open-source developments for structural and semantic validation of LLM outputs, and upon flexible approaches to fact checking and verification, supported by the capacity to reference external knowledge sources of any kind. The design is easy to adapt and extend, and can be used to verify any kind of graph-structured data through a combination of model-intrinsic knowledge, user-supplied context, and agents capable of external knowledge retrieval. © 2024 Copyright for this paper by its authors.},
	author_keywords = {Knowledge Graph Completion; Knowledge Graph Evaluation; Large Language Models; Text2KG},
	keywords = {Semantics; Automatic validation; External knowledge; Graph construction; Knowledge graph completion; Knowledge graph evaluation; Knowledge graphs; Language model; Large language model; Text2kg; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Luo20245766,
	author = {Luo, Jian and Chen, Xuanang and He, Ben and Sun, Le},
	title = {PRP-Graph: Pairwise Ranking Prompting to LLMs with Graph Aggregation for Effective Text Re-ranking},
	year = {2024},
	journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
	volume = {1},
	pages = {5766 – 5776},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204423316&partnerID=40&md5=ca9d0aae3313aebaaaeb431ba73e472b},
	abstract = {Pairwise Ranking Prompting (PRP) demonstrates impressive effectiveness in zero-shot document re-ranking tasks with large language models (LLMs). However, in the existing methods, PRP only outputs the same label for the comparison results of different confidence intervals without considering the uncertainty of pairwise comparison, which implies an underutilization of the generation probability information of LLMs. To bridge this gap, we propose PRP-Graph, a novel pairwise re-ranking approach, based on a refined scoring PRP unit that exploits the output probabilities of target labels to capture the degree of certainty of the comparison results. Specifically, the PRP-Graph consists of two stages, namely ranking graph construction and ranking graph aggregation. Extensive experiments conducted on the BEIR benchmark demonstrate the superiority of our approach over existing PRP-based methods. Comprehensive analysis reveals that the PRP-Graph displays strong robustness towards the initial ranking order and delivers exceptional re-ranking results with acceptable efficiency. Our code and data are available at https://github.com/Memelank/PRP-Graph. © 2024 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Contrastive Learning; Knowledge graph; Comparison result; Confidence interval; Degree of certainty; Language model; Pair-wise comparison; Probability informations; Ranking approach; Re-ranking; Target labels; Uncertainty; Zero-shot learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Wen202410370,
	author = {Wen, Yilin and Wang, Zifeng and Sun, Jimeng},
	title = {MindMap: Knowledge Graph Prompting Sparks Graph of Thoughts in Large Language Models},
	year = {2024},
	journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
	volume = {1},
	pages = {10370 – 10388},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204489189&partnerID=40&md5=9d581fa8758147b1a95b0488331528d1},
	abstract = {Large language models (LLMs) have achieved remarkable performance in natural language understanding and generation tasks. However, they often suffer from limitations such as difficulty in incorporating new knowledge, generating hallucinations, and explaining their reasoning process. To address these challenges, we propose a novel prompting pipeline, named MindMap, that leverages knowledge graphs (KGs) to enhance LLMs' inference and transparency. Our method enables LLMs to comprehend KG inputs and infer with a combination of implicit and external knowledge. Moreover, our method elicits the mind map of LLMs, which reveals their reasoning pathways based on the ontology of knowledge. We evaluate our method on diverse question & answering tasks, especially in medical domains, and show significant improvements over baselines. We also introduce a new hallucination evaluation benchmark and analyze the effects of different components of our method. Our results demonstrate the effectiveness and robustness of our method in merging knowledge from LLMs and KGs for combined inference. To reproduce our results and extend the framework further, we make our codebase available at https://github.com/wylwilling/MindMap. © 2024 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Natural language processing systems; Implicit knowledge; Knowledge graphs; Language model; Mind maps; Model inference; Model transparency; Natural language generation; Natural language understanding; Performance; Reasoning process; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5}
}

@CONFERENCE{2024,
	title = {KG4S 2024 - Proceedings of the 2nd International Workshop on Knowledge Graphs for Sustainability, colocated with the 21st Extended Semantic Web Conference, ESWC 2024},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3753},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204298667&partnerID=40&md5=11dd58466e8a3a00e5b8f94d5b3c511d},
	abstract = {The proceedings contain 8 papers. The topics discussed include: semantic asset administration shell for circular economy; modelling digital product passports for the circular economy; supporting companion planting with the CoPla ontology; the open circularity platform: a decentralized data sharing platform for circular value networks; an ontology for the reuse and tracking of prefabricated building components; knowledge graph aided LLM based ESG question-answering from news; initial and experimental ontology alignment results in the circular economy domain; and communication in design-for-circularity: requirements to a knowledge graph.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Zheng2024260,
	author = {Zheng, Chunmo and Tang, Yinqiu and Su, Xing},
	title = {A KNOWLEDGE GRAPH MODELING APPROACH FOR AUGMENTING LANGUAGE MODEL-BASED CONTRACT RISK IDENTIFICATION},
	year = {2024},
	journal = {Proceedings of the European Conference on Computing in Construction},
	volume = {2024},
	pages = {260 – 267},
	doi = {10.35490/EC3.2024.178},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203442465&doi=10.35490%2fEC3.2024.178&partnerID=40&md5=3896289aef7d0471aa7c402c1dd3f0d7},
	abstract = {Contract risk identification is essential for preventing disputes and losses in construction industry. Large language models (LLMs) have impacted various natural language processing tasks, offering a promising avenue for automating contract review without extensive data processing and feature engineering. However, LLMs still has difficulty in recalling facts while generating knowledge-grounded analysis, especially when related to complex domain knowledge. This paper introduces a Knowledge Graph (KG) modeling approach to enhance the LLM-based automated contract risk identification. A case study demonstrates that our approach exhibits enhanced performance on risk identification tasks compared to non-augmentation scenario. © 2024 European Council on Computing in Construction.},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Zhang2024116,
	author = {Zhang, Yujia and Sadler, Tyler and Taesiri, Mohammad Reza and Xu, Wenjie and Reformat, Marek Z.},
	title = {Fine-tuning Language Models for Triple Extraction with Data Augmentation},
	year = {2024},
	journal = {KaLLM 2024 - 1st Workshop on Knowledge Graphs and Large Language Models, Proceedings of the Workshop},
	pages = {116 – 124},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204440673&partnerID=40&md5=d6c7f41bafa5514b3f8c450ebec3f27a},
	abstract = {Advanced language models with impressive capabilities to process textual information can more effectively extract high-quality triples, which are the building blocks of knowledge graphs. Our work examines language models’ abilities to extract entities and the relationships between them. We use a diverse data augmentation process to fine-tune large language models to extract triples from the text. Fine-tuning is performed using a mix of trainers from HuggingFace and five public datasets, such as different variations of the WebNLG, SKE, DocRed, FewRel, and KELM. Evaluation involves comparing model output with test set triples based on several criteria, such as type, partial, exact, and strict accuracy. The obtained results outperform ChatGPT and even match or exceed the performance of GPT-4. ©2024 Association for Computational Linguistics.},
	keywords = {Knowledge graph; Modeling languages; Text mining; Building blockes; Data augmentation; Fine tuning; High quality; Knowledge graphs; Language model; Model outputs; Modeling abilities; Public dataset; Textual information; Computational linguistics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Iga2024277,
	author = {Iga, Vasile Ionut Remus and Silaghi, Gheorghe Cosmin},
	title = {Assessing LLMs Suitability for Knowledge Graph Completion},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14980 LNAI},
	pages = {277 – 290},
	doi = {10.1007/978-3-031-71170-1_22},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204902548&doi=10.1007%2f978-3-031-71170-1_22&partnerID=40&md5=58ef4bf4663def0739634115d29b838e},
	abstract = {Recent work has shown the capability of Large Language Models (LLMs) to solve tasks related to Knowledge Graphs, such as Knowledge Graph Completion, even in Zero- or Few-Shot paradigms. However, they are known to hallucinate answers, or output results in a non-deterministic manner, thus leading to wrongly reasoned responses, even if they satisfy the user’s demands. To highlight opportunities and challenges in knowledge graphs-related tasks, we experiment with three distinguished LLMs, namely Mixtral-8x7b-Instruct-v0.1, GPT-3.5-Turbo-0125 and GPT-4o, on Knowledge Graph Completion for static knowledge graphs, using prompts constructed following the TELeR taxonomy, in Zero- and One-Shot contexts, on a Task-Oriented Dialogue system use case. When evaluated using both strict and flexible metrics measurement manners, our results show that LLMs could be fit for such a task if prompts encapsulate sufficient information and relevant examples. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {Knowledge Graph; Knowledge Graph Completion; Large Language Models; Prompt engineering; Task-Oriented Dialogue System},
	keywords = {Modeling languages; Dialogue systems; Knowledge graph completion; Knowledge graphs; Language model; Large language model; Model suitability; Prompt engineering; Task-oriented; Task-oriented dialog system; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{de Ávila Mendes202435,
	author = {de Ávila Mendes, Renê and de Oliveira, Dimas Jackson and Garcia, Victor Hugo Fiuza},
	title = {Application of Generative AI as an Enterprise Wikibase Knowledge Graph Q&A System},
	year = {2024},
	journal = {KaLLM 2024 - 1st Workshop on Knowledge Graphs and Large Language Models, Proceedings of the Workshop},
	pages = {35 – 42},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204484735&partnerID=40&md5=c5abca15a59d1cb520b70b36e4fac48c},
	abstract = {Generative AI and Large Language Models are increasingly used in business contexts. One application involves natural language conversations contextualized by company data, which can be accomplished by Enterprise Knowledge Graphs, standardized representations of data. This paper outlines an architecture for implementation of an Enterprise Knowledge Graph using open-source Wikibase software. Additionally, it is presented a Knowledge Graph Q&A System powered by Generative AI. ©2024 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Generative adversarial networks; Business contexts; Knowledge graphs; Language model; Natural languages; Open-source; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Chu2024146,
	author = {Chu, Jung-Mei and Lo, Hao-Cheng and Hsiang, Jieh and Cho, Chun-Chieh},
	title = {Patent Response System Optimised for Faithfulness: Procedural Knowledge Embodiment with Knowledge Graph and Retrieval Augmented Generation},
	year = {2024},
	journal = {KnowLLM 2024 - 1st Workshop on Towards Knowledgeable Language Models, Proceedings of the Workshop},
	pages = {146 – 155},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204918162&partnerID=40&md5=0ee730886a4380a0c00ae2074002599c},
	abstract = {A successful response to Office Action is crucial for an invention to obtain a patent. While previous attempts have applied generalised LLMs, such as GPT-4, in the response process, there remains significant room for improvement in generating faithful, unbiased, and practically valuable responses. To address this issue, we propose the Patent Response System Optimised for Faithfulness (PRO). PRO explicitly incorporates procedural knowledge used by patent agents during drafting arguments in response. This framework comprises several key components: (1) Our proposed PRLLM is a LLM tailored for patent responses, designed to have comprehensive patent domain-specific knowledge. (2) Our proposed PPNet encodes legal interpretations and relationships between technical components from judicial sources through a knowledge graph. (3) The augmented generation processes retrieve relevant information from both the patent text and PPNet to augment the PRLLM's input and generate faithful responses. Results show that PRO significantly reduces unfaithfulness across six error types compared to several settings. For instance, PRO outperforms GPT-4 by an average of 39% in terms of faithfulness. This demonstrates the effectiveness of our domain-specific approach in improving the quality of automated patent responses. © 2024 Association for Computational Linguistics.},
	keywords = {Patents and inventions; Domain specific; Domain-specific knowledge; Error types; Generation process; Knowledge graphs; Knowledge retrieval; Procedural knowledge; Response process; Response systems; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Bouchouras2024,
	author = {Bouchouras, Georgios and Bitilis, Pavlos and Kotis, Konstantinos and Vouros, George A.},
	title = {LLMs for the Engineering of a Parkinson Disease Monitoring and Alerting Ontology},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3749},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203587310&partnerID=40&md5=6cf0a5bc51abfa68aafd9a5fe1f9d3ea},
	abstract = {This paper investigates the integration of Large Language Models (LLMs) in the engineering of a Parkinson's Disease (PD) monitoring and alerting ontology. The focus is on the ontology engineering methodology which combines the capabilities of LLMs and human expertise to develop more robust and comprehensive domain ontologies, faster than humans do alone. Evaluating models like ChatGPT-3.5, ChatGPT4, Gemini, and Llama2, this study explores various LLM based ontology engineering methods. The findings reveal that the proposed hybrid approach (both LLM and human involvement), namely X-HCOME, consistently excelled in class generation and F-1 score, indicating its efficiency in creating valid and comprehensive ontologies faster than humans do alone. The study underscores the potential of the combined LLMs and human intelligence to enrich PD domain knowledge and enhance expert-generated PD ontologies. In overall, the presented approach exemplifies a promising collaboration between machine capabilities and human expertise in developing ontologies for complex domains.  Copyright © 2024 for this paper by its authors.},
	author_keywords = {Human-LLM teaming; LLMs; Ontology Engineering; Parkinson Disease},
	keywords = {Disease control; Human engineering; Ontology; Disease monitoring; Human expertise; Human-large language model teaming; Language model; Large language model; Ontology engineering; Ontology Engineering Methodologies; Ontology's; Parkinson's disease; Neurodegenerative diseases},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Chen20243415,
	author = {Chen, Jianhao and Ouyang, Haoyuan and Ren, Junyang and Ding, Wentao and Hu, Wei and Qu, Yuzhong},
	title = {Timeline-based Sentence Decomposition with In-Context Learning for Temporal Fact Extraction},
	year = {2024},
	journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
	volume = {1},
	pages = {3415 – 3432},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204437553&partnerID=40&md5=ba8ee3474bd7bd2bd8ff874b4099eef4},
	abstract = {Facts extraction is pivotal for constructing knowledge graphs. Recently, the increasing demand for temporal facts in downstream tasks has led to the emergence of the task of temporal fact extraction. In this paper, we specifically address the extraction of temporal facts from natural language text. Previous studies fail to handle the challenge of establishing time-to-fact correspondences in complex sentences. To overcome this hurdle, we propose a timeline-based sentence decomposition strategy using large language models (LLMs) with in-context learning, ensuring a fine-grained understanding of the timeline associated with various facts. In addition, we evaluate the performance of LLMs for direct temporal fact extraction and get unsatisfactory results. To this end, we introduce TSDRE, a method that incorporates the decomposition capabilities of LLMs into the traditional fine-tuning of smaller pre-trained language models (PLMs). To support the evaluation, we construct ComplexTRED, a complex temporal fact extraction dataset. Our experiments show that TSDRE achieves state-of-the-art results on both HyperRED-Temporal and ComplexTRED datasets. © 2024 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Contrastive Learning; Knowledge graph; Complex sentences; Context learning; Decomposition strategy; Down-stream; Fact extraction; In contexts; Knowledge graphs; Language model; Natural languages texts; Timeline-based; Spatio-temporal data},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Dembska202456,
	author = {Dembska, Marta and Helle, Oliver and Yadav, Itisha and Peters, Diana},
	title = {Implementing semantic technologies in materials science and engineering},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3760},
	pages = {56 – 66},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85204950662&partnerID=40&md5=5374b3393dbd66ed5168538c1b61ed01},
	abstract = {The Materials Science and Engineering (MSE) field is an interdisciplinary branch of engineering characterized by high volumes of heterogeneous data, which also serve as inputs for other fields reliant on materials. While semantic technologies are already utilized in various research areas to address data management challenges, their adoption in MSE is still in its early stages. This paper provides an overview of data management issues in MSE, existing semantic technologies, and the potential application of these technologies to address those issues. This leads to a roadmap for the implementation of semantic technologies in MSE. © 2024 CEUR-WS. All rights reserved.},
	author_keywords = {Data Management; Interoperability; Large Language Models; Materials Science and Engineering; Ontologies; Semantic Technologies},
	keywords = {Data management challenges; Engineering fields; Heterogeneous data; High volumes; Language model; Large language model; Materials science and engineering; Ontology's; Research areas; Semantic technologies},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Buongiorno2024,
	author = {Buongiorno, Steph and Clark, Corey},
	title = {Leveraging Gaming to Enhance Knowledge Graphs for Explainable Generative AI Applications},
	year = {2024},
	journal = {IEEE Conference on Computatonal Intelligence and Games, CIG},
	doi = {10.1109/CoG60054.2024.10645673},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203491959&doi=10.1109%2fCoG60054.2024.10645673&partnerID=40&md5=b5ba7f2e0c5a8cee51d6116f2f096811},
	abstract = {External knowledge graphs (KGs) can be used to augment large language models (LLMs), while simultaneously providing an explainable knowledge base of facts that can be inspected by a human. This approach may be particularly valuable in domains where explainability is critical, like human trafficking data analysis. However, creating KGs can pose challenges. KGs parsed from documents may comprise explicit connections (those directly stated by a document) but miss implicit connections (those obvious to a human although not directly stated). To address these challenges, this preliminary research introduces the GAME-KG framework, standing for 'Gaming for Augmenting Metadata and Enhancing Knowledge Graphs.' GAME-KG is a federated approach to modifying explicit as well as implicit connections in KGs by using crowdsourced feedback collected through video games. GAME-KG is shown through two demonstrations: a Unity test scenario from Dark Shadows, a video game that collects feedback on KGs parsed from US Department of Justice (DOJ) Press Releases on human trafficking, and a following experiment where OpenAI's GPT-4 is prompted to answer questions based on a modified and unmodified KG. Initial results suggest that GAME-KG can be an effective framework for enhancing KGs while simultaneously providing an explainable set of structured facts verified by humans. © 2024 IEEE.},
	author_keywords = {Crowdsourcing; Generative AI; Human Computation Gaming; Knowledge Graphs},
	keywords = {Crime; Crowdsourcing; Economic and social effects; Metadata; AI applications; Explicit connections; External knowledge; Generative AI; Human computation; Human computation gaming; Human trafficking; Knowledge graphs; Language model; Video-games; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}@ARTICLE{Kahlawi20249,
	author = {Kahlawi, Adham and Martelli, Cristina},
	title = {Enhancing Administrative Source Registers for the Development of a Robust Large Language Model: A Novel Methodological Approach},
	year = {2024},
	journal = {International Journal of Advanced Computer Science and Applications},
	volume = {15},
	number = {7},
	pages = {9 – 17},
	doi = {10.14569/IJACSA.2024.0150702},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200333718&doi=10.14569%2fIJACSA.2024.0150702&partnerID=40&md5=e765d1379b802f329b8479439fc96935},
	abstract = {Accurate statistical information is critical for understanding, describing, and managing socio-economic systems. While data availability has increased, often it does not meet the quality requirements for effective governance. Administrative registers are crucial for statistical information production, but their potential is hampered by quality issues stemming from administrative inconsistencies. This paper explores the integration of semantic technologies, including ontologies and knowledge graphs, with administrative databases to improve data quality. We discuss the development of large language models (LLMs) that enable a robust, queryable framework, facilitating the integration of disparate data sources. This approach ensures high-quality administrative data, essential for statistical reuse and the development of comprehensive, dynamic knowledge graphs and LLMs tailored for administrative applications. © (2024), (Science and Information Organization). All rights reserved.},
	author_keywords = {administrative data reuse; database; knowledge graph; LLM; ontology; semantic web; Statistical information systems},
	keywords = {Computational linguistics; Data integration; Knowledge graph; Ontology; Statistics; Administrative data reuse; Data reuse; Knowledge graphs; Language model; Large language model; Methodological approach; Ontology's; Semantic-Web; Statistical information; Statistical information system; Semantic Web},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{2024,
	title = {17th International Conference on Knowledge Science, Engineering and Management, KSEM 2024},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14885 LNAI},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200745202&partnerID=40&md5=37bd88d27eb56fb1aa57a043755c22bb},
	abstract = {The proceedings contain 160 papers. The special focus in this conference is on Knowledge Science, Engineering and Management. The topics include: EE-LCE: An Event Extraction Framework Based on LLM-Generated CoT Explanation; attention and Learning Features-Enhanced Knowledge Tracing; An MLM Decoding Space Enhancement for Legal Document Proofreading; meta-pruning: Learning to Prune on Few-Shot Learning; knowledge-Informed Molecular Learning: A Survey on Paradigm Transfer; GenFlowchart: Parsing and Understanding Flowchart Using Generative AI; DSCVSR: A Lightweight Video Super-Resolution for Arbitrary Magnification; programming Knowledge Tracing with Context and Structure Integration; an Konwledge-Based Semi-supervised Active Learning Method for Precision Pest Disease Diagnostic; multi-label Feature Selection with Adaptive Subspace Learning; User Story Classification with Machine Learning and LLMs; PTMA: Pre-trained Model Adaptation for Transfer Learning; optimization Strategies for Knowledge Graph Based Distractor Generation; reinforced Subject-Aware Graph Neural Network for Related Work Generation; EFCC-IeT: Cross-Modal Electronic File Content Correlation via Image-Enhanced Text; multi-relation Neural Network Recommendation Model Based on Knowledge Graph Embedding Algorithm; link Prediction Based on Deep Global Information in Heterogeneous Graph; subject Knowledge Entity Relationship Extraction Based on Multi-feature Fusion and Relation Specific Horns Tagging; a Human-Computer Negotiation Model Based on Q-Learning; affine Transformation-Based Knowledge Graph Embedding; integrating Prior Scenario Knowledge for Composition Review Generation; distant Supervised Relation Extraction on Pre-train Model with Improved Multi-label Attention Mechanism; sEMG-Based Multi-view Feature-Constrained Representation Learning; vicinal Data Augmentation for Classification Model via Feature Weaken; STM: An Improved Peak Price Tracking-Based Online Portfolio Selection Algorithm; spatiotemporal Dependence Learning with Meteorological Context for Transportation Demand Prediction; automatic Meter Pointer Reading Based on Knowledge Distillation; multi-table Question Answering Method Based on Correlation Evaluation and Precomputed Cube; a Joint Multi-task Learning Model for Web Table-to-Knowledge Graph Matching; an In-Context Schema Understanding Method for Knowledge Base Question Answering.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Koohborfardhaghighi2024156,
	author = {Koohborfardhaghighi, Somayeh and De Geyter, Gert and Kaliner, Evan},
	title = {Unlocking the Power of LLM-Based Question Answering Systems: Enhancing Reasoning, Insight, and Automation with Knowledge Graphs},
	year = {2024},
	journal = {Lecture Notes in Networks and Systems},
	volume = {1052 LNNS},
	pages = {156 – 171},
	doi = {10.1007/978-3-031-64776-5_16},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200688445&doi=10.1007%2f978-3-031-64776-5_16&partnerID=40&md5=0b93dd0678676f7e42b6ad95441db93e},
	abstract = {In today’s data-driven business landscape, Knowledge Graphs can be effectively layered on top of relational databases and ontologies, a powerful combination for transforming how businesses tackle complex queries and decision-making processes. In this paper, we present a series of experiments that demonstrate the opportunities and advantages of blending knowledge graphs with Large Language Models (LLMs) through a practical use case. Our experimental results provide insights into the reasoning capabilities of LLMs when utilizing Knowledge Graph-Prompting. Furthermore, we observed the significance of maintaining uniformity in the language employed during knowledge graph construction to ensure precise responses from LLMs when querying the knowledge graph. This consistency also resonates in the embedding space of the model, where elements like relationship types are reflected in the resulting embeddings. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {Intelligent Systems; Knowledge Graphs; Large Language Models (LLMs); Ontologies},
	keywords = {Blending; Computational linguistics; Decision making; Graph embeddings; Graphic methods; Knowledge graph; Metadata; Ontology; Data driven; Embeddings; Knowledge graphs; Language model; Large language model; Model-based OPC; Ontology's; Power; Question answering systems; Relational Database; Intelligent systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{2024,
	title = {11th International Work-Conference on Bioinformatics and Biomedical Engineering, IWBBIO 2024},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14849 LNBI},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203158031&partnerID=40&md5=5a886dd08535efc80d1e727ca508d604},
	abstract = {The proceedings contain 54 papers. The special focus in this conference is on Bioinformatics and Biomedical Engineering. The topics include: GPACDA – circRNA-Disease Association Prediction with Generating Polynomials; Bioinformatics Analysis Provides Insight into the Identification of miRNAs as Transcriptional Regulators in Respiratory Syncytial Virus Infection; risk Factors of Recurrence and Metastasis of Breast Cancer Sub-types Based on Magnetic Resonance Imaging Techniques; Analysis of a Parallel and Distributed BPSO Algorithm for EEG Classification: Impact on Energy, Time and Accuracy; Naïve Bayes for Health-Status Predictive Monitoring in COVID-19: Leveraging Drugs and Diagnoses; speech Analysis for Autism Spectrum Disorder Detection for Children; SiMHOMer: Siamese Models for Health Ontologies Merging and Validation Through Large Language Models; lossless Compression of Nanopore Sequencing Raw Signals; medical Equipment Real-Time Locating System in Hospitals Based on Bluetooth Low Energy; Validation of WHO Charts Mobile Applications for Body Length and Weight Assessment in Healthy Newborns; Predicting Atherosclerotic Plaque Onset and Growth in Carotid Arteries: A CFD-Driven Approach; hemispherical Directional Reflectance as a Screening Tool to Distinguish Effervescent Tablets with Acetylsalicylic Acid and Vitamin C Stored Under Stress Conditions from Those Stored in Ambient Conditions; enhanced Ergonomics in Laryngoscopic Surgery. Exploring Innovative Solutions; maximal Deadlift Strength and Bone Mass in a Group of Healthy Elderly Men; multilayer Networks: A Survey on Models, Analysis of Algorithms and Database; bone Mineral Density in Middle-Aged Former Sprinters and Middle-Aged Active Men; spectrum Filtering to Extract Pulse Rate Variability from Signals Recorded by Wearable Devices; machine Learning Model for Anxiety Disorder Diagnosis Based on Sensory Time-Series Data; analysis of the Relationship Between Electrodermal Activity and Blood Glucose Level in Diabetics.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Chepurova202461,
	author = {Chepurova, Alla and Kuratov, Yuri and Bulatov, Aydar and Burtsev, Mikhail},
	title = {Prompt Me One More Time: A Two-Step Knowledge Extraction Pipeline with Ontology-Based Verification},
	year = {2024},
	journal = {TextGraphs at ACL 2024 - Proceedings of TextGraphs-17: Graph-Based Methods for Natural Language Processing, 62nd Annual Meeting of the Association of Computational Linguistics},
	pages = {61 – 77},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200615475&partnerID=40&md5=0c13b89310c5035073d1803f66af5f52},
	abstract = {This study explores a method for extending real-world knowledge graphs (specifically, Wikidata) by extracting triplets from texts with the aid of Large Language Models (LLMs). We propose a two-step pipeline that includes the initial extraction of entity candidates, followed by their refinement and linkage to the canonical entities and relations of the knowledge graph. Finally, we utilize Wikidata relation constraints to select only verified triplets. We compare our approach to a model that was fine-tuned on a machine-generated dataset and demonstrate that it performs better on natural data. Our results suggest that LLM-based triplet extraction from texts, with subsequent verification, is a viable method for real-world applications. © 2024 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Ontology; Knowledge extraction; Knowledge graphs; Language model; Model-based OPC; Ontology-based; Real-world; World knowledge; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Xia2024453,
	author = {Xia, Long and Shen, Wenqi and Fan, Weiguo and Wang, G. Alan},
	title = {Knowledge-Aware Learning Framework Based on Schema Theory to Complement Large Learning Models},
	year = {2024},
	journal = {Journal of Management Information Systems},
	volume = {41},
	number = {2},
	pages = {453 – 486},
	doi = {10.1080/07421222.2024.2340827},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197458407&doi=10.1080%2f07421222.2024.2340827&partnerID=40&md5=2c1ae1b0b2f5e2acf6931321413dd186},
	abstract = {Despite tremendous recent progress, extant artificial intelligence (AI) still falls short of matching human learning in effectiveness and efficiency. One fundamental disparity is that humans possess a wealth of prior knowledge, while AI lacks the essential commonsense knowledge required for learning tasks. Guided by schema theory, we employ the design science research methodology to introduce a novel knowledge-aware learning framework to harness the knowledge-based processes in human learning. Unlike existing pre-trained large language models (LLMs) and knowledge-aware approaches that treat knowledge in considerably different ways from humans, our theoretically grounded framework closely mimics how humans acquire, represent, activate, and utilize knowledge. The extensive evaluations in the context of text analytics tasks demonstrate that our design achieves comparable performance to the state-of-the-art LLMs and enhances model generalizability and learning efficiency. This study takes a step forward by bringing cognitive science into building cognitively plausible AI and human-AI collaboration research. © 2024 Taylor & Francis Group, LLC.},
	author_keywords = {artificial intelligence; deep learning; design science; knowledge graph; Knowledge-aware models; schema theory; text analytics},
	keywords = {Deep learning; Design; Efficiency; Learning systems; Deep learning; Design science; Human learning; Knowledge graphs; Knowledge-aware model; Language model; Learning frameworks; Learning models; Schema theory; Text analytics; Knowledge graph},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Ramchand202431,
	author = {Ramchand, Suraj and Xie, Xianghua},
	title = {Augmenting Infrequent Relationships in Clinical Language Models with Graph-Encoded Hierarchical Ontologies},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14975 LNCS},
	pages = {31 – 44},
	doi = {10.1007/978-3-031-67278-1_3},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201980956&doi=10.1007%2f978-3-031-67278-1_3&partnerID=40&md5=6fbef54ecfd8984505f33985f6e514b5},
	abstract = {Harnessing primary-care data can facilitate earlier clinical interventions via predictive modelling. Nonetheless, the intricacy of medical terminology and the breadth of ontological data often obscure the inner workings of such models. Despite the growing complexity of artificial intelligence methodologies and the pressing demand for medical tools that seamlessly integrate into clinical workflows, this opacity persists. We propose enhancing clinical Bidirectional Encoder Representations from Transformers (BERT) models with graph attention networks that encode diagnosis and medication concept hierarchies derived from primary care data. In 10-fold cross-validation on cardiovascular and respiratory detection tasks, our graph-enhanced model marginally improves F1 performance over baseline BERT. More importantly, our approach surfaces clinically deterministic patterns in patient groups, provides modular visualisations of influential terminal and ancestral medical concepts, and improves clustering of related conditions. Additionally, the hierarchical encoding allows quantitative analysis of edge relevance within and across diagnosis and medical ontologies. Our research shows that injecting structured knowledge graphs into language model architectures can improve performance through domain-specific regularisation. Additionally, the use of class activation maps throughout the approach allows for richer interpretations of predictions by following activation flows along concept relationships. The dual utility of precise ontology encoding and Large Language Models makes our graph-injected clinical language model more accurate and trustworthy, propelling preventive precision medicine forward. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {Electronic Health Records; Graph Neural Networks; Large Language Models; Medical Ontology},
	keywords = {Clinical research; Diagnosis; Electronic health record; Ontology; Clinical interventions; Electronic health; Graph neural networks; Health records; Language model; Large language model; Medical ontology; Ontology's; Predictive models; Primary care; Graph neural networks},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Huang2024180,
	author = {Huang, Junbo},
	title = {SSNF: Optimizing Entity Alignment with a Novel Structural and Semantic Neighbor Filtering},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14885 LNAI},
	pages = {180 – 191},
	doi = {10.1007/978-981-97-5495-3_13},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200750595&doi=10.1007%2f978-981-97-5495-3_13&partnerID=40&md5=446c6099547dc1ee4512d7d835d78355},
	abstract = {In the domain of Knowledge Graphs (KGs), the alignment of entities is pivotal, aiming to identify and match equivalent entities across distinct KGs. Existing methodologies primarily aggregate information from direct neighbors via graph neural networks, a process which can inadvertently introduce noise. To address this challenge, we introduce SSNF, an innovative neighbor filtering mechanism that optimally balances structural and semantic information, crucial for accurate entity alignment. By employing motifs for structural assessment and leveraging Large Language Models (LLMs) for semantic analysis with ’Reasoning-Challenging (Re-Cha)’ strategy to query LLMs to determine important neighbors. This dual-focus strategy mitigates the inclusion of less informative neighbors. When integrated with existing Entity Alignment (EA) frameworks, our approach demonstrates superior efficacy, significantly outperforming conventional methods through meticulous neighbor selection. The extensive experiments, conducted on the most widely used benchmark datasets (i.e., DBP15K), exhibit a significant improvement in EA performance, demonstrating its potential to advance the field of KG entity alignment by synergizing structural insights and semantic precision. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2024.},
	author_keywords = {Entity alignment; Knowledge Graphs; Large language models; Motif; Re-Cha strategy},
	keywords = {Alignment; Benchmarking; Computational linguistics; Graph neural networks; Information filtering; Semantics; Domain of knowledge; Entity alignment; Filtering mechanism; Graph neural networks; Knowledge graphs; Language model; Large language model; Motif; Reasoning-challenging strategy; Semantic neighbor; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Rezayi20241,
	author = {Rezayi, Saed and Liu, Zhengliang and Wu, Zihao and Dhakal, Chandra and Ge, Bao and Dai, Haixing and Mai, Gengchen and Liu, Ninghao and Zhen, Chen and Liu, Tianming and Li, Sheng},
	title = {Exploring New Frontiers in Agricultural NLP: Investigating the Potential of Large Language Models for Food Applications},
	year = {2024},
	journal = {IEEE Transactions on Big Data},
	pages = {1–12},
	doi = {10.1109/TBDATA.2024.3442542},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201463745&doi=10.1109%2fTBDATA.2024.3442542&partnerID=40&md5=f956c592ec44b749f90f6155572cd6d4},
	abstract = {This paper explores new frontiers in agricultural natural language processing (NLP) by investigating the effectiveness of food-related text corpora for pretraining transformer-based language models. Specifically, we focus on semantic matching, establishing mappings between food descriptions and nutrition data through fine-tuning AgriBERT with the FoodOn ontology. Our work introduces an expanded comparison with state-of-the-art language models such as GPT-4, Mistral-large, Claude 3 Sonnet, and Gemini 1.0 Ultra. This exploratory investigation, rather than a direct comparison, aims to understand how AgriBERT, a domain-specific, fine-tuned, open-source model, complements the broad knowledge and generative abilities of these advanced LLMs in addressing the unique challenges of the agricultural sector. We also experiment with other applications, such as cuisine prediction from ingredients, expanding our research to include various NLP tasks beyond semantic matching. Overall, this paper underscores the potential of integrating domain-specific models like AgriBERT with advanced LLMs to enhance the performance and applicability of agricultural NLP applications. IEEE},
	author_keywords = {Biological system modeling; ChatGPT; Context modeling; Data models; Food Applications; Language Models; Natural Language Processing; Natural language processing; Semantic Matching; Semantics; Task analysis; Training},
	keywords = {Semantics; Biological system modeling; ChatGPT; Context models; Food applications; Language model; Language processing; Natural language processing; Natural languages; Semantic matching; Task analysis; Modeling languages},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Green Open Access}
}

@CONFERENCE{Fieblinger2024100,
	author = {Fieblinger, Romy and Alam, Md Tanvirul and Rastogi, Nidhi},
	title = {Actionable Cyber Threat Intelligence Using Knowledge Graphs and Large Language Models},
	year = {2024},
	journal = {Proceedings - 9th IEEE European Symposium on Security and Privacy Workshops, Euro S and PW 2024},
	pages = {100 – 111},
	doi = {10.1109/EuroSPW61312.2024.00018},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203015552&doi=10.1109%2fEuroSPW61312.2024.00018&partnerID=40&md5=3a3ff13a2accca59ac279066d88a361b},
	abstract = {Cyber threats are constantly evolving. Extracting actionable insights from unstructured Cyber Threat Intelligence (CTI) data is essential to guide cybersecurity decisions. Increasingly, organizations like Microsoft, Trend Micro, and CrowdS trike are using generative AI to facilitate CTI extraction. This paper addresses the challenge of automating the extraction of actionable CTI using advancements in Large Language Models (LLMs) and Knowledge Graphs (KGs). We explore the application of state-of-the-art open-source LLMs, including the Llama 2 series, Mistral 7B Instruct, and Zephyr for extracting meaningful triples from CTI texts. Our methodology evaluates techniques such as prompt engineering, the guidance framework, and fine-tuning to optimize information extraction and structuring. The extracted data is then utilized to construct a KG, offering a structured and queryable representation of threat intelligence. Experimental results demonstrate the effectiveness of our approach in extracting relevant information, with guidance and fine-tuning showing superior performance over prompt engineering. However, while our methods prove effective in small-scale tests, applying LLMs to large-scale data for KG construction and Link Prediction presents ongoing challenges.  © 2024 IEEE.},
	author_keywords = {Cyber Threat Intelligence; Knowledge Graphs; Large Language Models; Threat Prediction},
	keywords = {Cyber attacks; Phishing; Structured Query Language; Cybe threat intelligence; Cyber security; Cyber threats; Fine tuning; Knowledge graphs; Language model; Large language model; MicroSoft; Threat prediction; Trend micros; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@CONFERENCE{Agarwal2024896,
	author = {Agarwal, Dhruv and Das, Rajarshi and Khosla, Sopan and Gangadharaiah, Rashmi},
	title = {BRING YOUR OWN KG: Self-Supervised Program Synthesis for Zero-Shot KGQA},
	year = {2024},
	journal = {Findings of the Association for Computational Linguistics: NAACL 2024 - Findings},
	pages = {896 – 919},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197850544&partnerID=40&md5=0a44e5254f5e0b8af23b69f95dd44972},
	abstract = {We present BYOKG, a universal question-answering (QA) system that can operate on any knowledge graph (KG), requires no human-annotated training data, and can be ready to use within a day-attributes that are out-of-scope for current KGQA systems. BYOKG draws inspiration from the remarkable ability of humans to comprehend information present in an unseen KG through exploration-starting at random nodes, inspecting the labels of adjacent nodes and edges, and combining them with their prior world knowledge. Exploration in BYOKG leverages an LLM-backed symbolic agent that generates a diverse set of query-program exemplars, which are then used to ground a retrieval-augmented reasoning procedure to synthesize programs for arbitrary questions. BYOKG is effective over both small- and large-scale graphs, showing dramatic gains in zero-shot QA accuracy of 27.89 and 59.88 F1 on GrailQA and MetaQA, respectively. We further find that performance of BYOKG reliably improves with continued exploration as well as improvements in the base LLM, notably outperforming a state-of-the-art fine-tuned model by 7.08 F1 on a sub-sampled zero-shot split of GrailQA. Lastly, we verify our universality claim by evaluating BYOKG on a domain-specific materials science KG and show that it improves zero-shot performance by 46.33 F1. © 2024 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Natural language processing systems; Zero-shot learning; 'current; Adjacent nodes; Annotated training data; Knowledge graphs; Performance; Program synthesis; Question answering systems; Ready to use; Symbolic agents; World knowledge; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Hadar2024328,
	author = {Hadar, Ethan and Heursch, Sven T.},
	title = {Scattered Requirements Dust in the Era of Web3 - A Vision Keynote},
	year = {2024},
	journal = {Proceedings - 32nd IEEE International Requirements Engineering Conference Workshops, REW 2024},
	pages = {328 – 329},
	doi = {10.1109/REW61692.2024.00050},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203106829&doi=10.1109%2fREW61692.2024.00050&partnerID=40&md5=aee6d1260f34659f3a5384b7fd82857f},
	abstract = {This extended abstract paper presents a vision for data and AI requirements governance in distributed System-of-Systems (SoS) that involve multiple parties and dynamic alliances, such as in the defense domain (e.g. different weapon systems on the battlefield). The paper proposes to use web3 technologies, such as distributed ledger and secure multi-party computation, to enable collaborative analytics and data interoperability among the SoS members, while preserving their sovereignty and privacy. The paper also suggests a model-driven approach that can generate executable code and workflows from a common ontology and a semantic mapping tool, which can facilitate the alignment and verification of the data and AI requirements among the coalition members. The paper demonstrates the feasibility and effectiveness of the approach through a prototype implementation in the defense domain and a case study involving a multi-party coalition of the willing to detect a SA-8 anti-aircraft battery that in essence is a sensor-Data Fusion with different sensors on different weapon systems.  © 2024 IEEE.},
	author_keywords = {DataGPT; Distributed Requirements Integrity; Generative AI; Ontology driven integration},
	keywords = {Artificial intelligence; Fighter aircraft; Information fusion; Interoperability; Metadata; Sensor data fusion; DataGPT; Distributed requirement integrity; Distributed systems; Dynamic alliance; Extended abstracts; Generative AI; Ontology driven integration; Ontology's; System-of-systems; Weapon system; Ontology},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Zhao202451,
	author = {Zhao, Wenting and Liu, Ye and Niu, Tong and Wan, Yao and Yu, Philip S. and Joty, Shafiq and Zhou, Yingbo and Yavuz, Semih},
	title = {DIVKNOWQA: Assessing the Reasoning Ability of LLMs via Open-Domain Question Answering over Knowledge Base and Text},
	year = {2024},
	journal = {Findings of the Association for Computational Linguistics: NAACL 2024 - Findings},
	pages = {51 – 68},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197851513&partnerID=40&md5=21c44971b094c06d3ecabfce30b75a6d},
	abstract = {Large Language Models (LLMs) excel in generating text but struggle with hallucinations, particularly for uncommon queries, due to reliance on internal knowledge. Retrieval-augmented models address this by integrating external knowledge, enhancing accuracy. Nonetheless, recent approaches have primarily emphasized retrieval from unstructured text corpora, owing to its seamless integration into prompts. When using structured data such as knowledge graphs, most methods simplify it into natural text, neglecting the underlying structures. Moreover, a significant gap in the current landscape is the absence of a realistic benchmark for evaluating the effectiveness of grounding LLMs on heterogeneous knowledge sources (e.g., knowledge base and text). To fill this gap, we have curated a comprehensive dataset that poses two unique challenges: (1) Two-hop multi-source questions that require retrieving information from both open-domain structured and unstructured knowledge sources; retrieving information from structured knowledge sources is a critical component in correctly answering the questions. (2) Generation of symbolic queries (e.g., SPARQL for Wikidata) is a key requirement, which adds another layer of challenge. Our dataset is created using a combination of automatic generation through predefined reasoning chains and human annotation. We also introduce a novel approach that leverages multiple retrieval tools, including text passage retrieval and symbolic language-assisted retrieval. Our model outperforms previous approaches by a significant margin, demonstrating its effectiveness in addressing the above-mentioned reasoning challenges. © 2024 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Natural language processing systems; Excel; External knowledge; Knowledge graphs; Knowledge sources; Language model; Open domain question answering; Reasoning ability; Seamless integration; Structured data; Unstructured text corpus; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{2024,
	title = {1st International Conference on Robust Argumentation Machines, RATIO 2024},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14638 LNAI},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200679567&partnerID=40&md5=1ac6344f9172726e0a3fbe78a5812402},
	abstract = {The proceedings contain 21 papers. The special focus in this conference is on Robust Argumentation Machines. The topics include: Argument Mining of Attack and Support Patterns in Dialogical Conversations with Sequential Pattern Mining; cluster-Specific Rule Mining for Argumentation-Based Classification; automatic Analysis of Political Debates and Manifestos: Successes and Challenges; PAKT: Perspectivized Argumentation Knowledge Graph and Tool for Deliberation Analysis  ; polArg: Unsupervised Polarity Prediction of Arguments in Real-Time Online Conversations; are Large Language Models Reliable Argument Quality Annotators?; the Impact of Argument Arrangement on Essay Scoring; Finding Argument Fragments on Social Media with Corpus Queries and LLMs; enhancing Abstract Argumentation Solvers with Machine Learning-Guided Heuristics: A Feasibility Study; ranking Transition-Based Medical Recommendations Using Assumption-Based Argumentation; argumentation-Based Probabilistic Causal Reasoning; from Networks to Narratives: Bayes Nets and the Problems of Argumentation; enhancing Argument Generation Using Bayesian Networks; “Do Not Disturb My Circles!” Identifying the Type of Counterfactual at Hand (Short Paper); BEA: Building Engaging Argumentation; deciphering Personal Argument Styles – A Comprehensive Approach to Analyzing Linguistic Properties of Argument Preferences; extending the Comparative Argumentative Machine: Multilingualism and Stance Detection; objective Argument Summarization in Search; argServices: A Microservice-Based Architecture for Argumentation Machines.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{2024,
	title = {Findings of the Association for Computational Linguistics: NAACL 2024 - Findings},
	year = {2024},
	journal = {Findings of the Association for Computational Linguistics: NAACL 2024 - Findings},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197905248&partnerID=40&md5=ba701abed2b9e6b58952577e0c320d16},
	abstract = {The proceedings contain 296 papers. The topics discussed include: structured pruning for large language models using coupled components elimination and minor fine-tuning; ignore me but don’t replace me: utilizing non-linguistic elements for pretraining on the cybersecurity domain; extremely efficient online query encoding for dense retrieval; attention alignment and flexible positional embeddings improve transformer length extrapolation; automatic pair construction for contrastive post-training; self-checker: plug-and-play modules for fact-checking with large language models; low-resource neural machine translation with morphological modeling; self-cleaning: improving a named entity recognizer trained on noisy data with a few clean instances; bilateral masking with prompt for knowledge graph completion; and examining modularity in multilingual LMS via language-specialized subnetworks.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{2024,
	title = {17th International Conference on Knowledge Science, Engineering and Management, KSEM 2024},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14886 LNAI},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200765585&partnerID=40&md5=7ad8ea40a27dc4f0e9147d9df352eb5b},
	abstract = {The proceedings contain 160 papers. The special focus in this conference is on Knowledge Science, Engineering and Management. The topics include: EE-LCE: An Event Extraction Framework Based on LLM-Generated CoT Explanation; attention and Learning Features-Enhanced Knowledge Tracing; An MLM Decoding Space Enhancement for Legal Document Proofreading; meta-pruning: Learning to Prune on Few-Shot Learning; knowledge-Informed Molecular Learning: A Survey on Paradigm Transfer; GenFlowchart: Parsing and Understanding Flowchart Using Generative AI; DSCVSR: A Lightweight Video Super-Resolution for Arbitrary Magnification; programming Knowledge Tracing with Context and Structure Integration; an Konwledge-Based Semi-supervised Active Learning Method for Precision Pest Disease Diagnostic; multi-label Feature Selection with Adaptive Subspace Learning; User Story Classification with Machine Learning and LLMs; PTMA: Pre-trained Model Adaptation for Transfer Learning; optimization Strategies for Knowledge Graph Based Distractor Generation; reinforced Subject-Aware Graph Neural Network for Related Work Generation; EFCC-IeT: Cross-Modal Electronic File Content Correlation via Image-Enhanced Text; multi-relation Neural Network Recommendation Model Based on Knowledge Graph Embedding Algorithm; link Prediction Based on Deep Global Information in Heterogeneous Graph; subject Knowledge Entity Relationship Extraction Based on Multi-feature Fusion and Relation Specific Horns Tagging; a Human-Computer Negotiation Model Based on Q-Learning; affine Transformation-Based Knowledge Graph Embedding; integrating Prior Scenario Knowledge for Composition Review Generation; distant Supervised Relation Extraction on Pre-train Model with Improved Multi-label Attention Mechanism; sEMG-Based Multi-view Feature-Constrained Representation Learning; vicinal Data Augmentation for Classification Model via Feature Weaken; STM: An Improved Peak Price Tracking-Based Online Portfolio Selection Algorithm; spatiotemporal Dependence Learning with Meteorological Context for Transportation Demand Prediction; automatic Meter Pointer Reading Based on Knowledge Distillation; multi-table Question Answering Method Based on Correlation Evaluation and Precomputed Cube; a Joint Multi-task Learning Model for Web Table-to-Knowledge Graph Matching; an In-Context Schema Understanding Method for Knowledge Base Question Answering.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Utrilla Guerrero2024114,
	author = {Utrilla Guerrero, Carlos and Corcho, Oscar and Garijo, Daniel},
	title = {Automated Extraction of Research Software Installation Instructions from README Files: An Initial Analysis},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14770 LNAI},
	pages = {114 – 133},
	doi = {10.1007/978-3-031-65794-8_8},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202178188&doi=10.1007%2f978-3-031-65794-8_8&partnerID=40&md5=a3d4ef580e12e6d40075896c971f1b8e},
	abstract = {Research Software code projects are typically described with a README files, which often contains the steps to set up, test and run the code contained in them. Installation instructions are written in a human-readable manner and therefore are difficult to interpret by intelligent assistants designed to help other researchers setting up a code repository. In this paper we explore this gap by assessing whether Large Language Models (LLMs) are able to extract installation instruction plans from README files. In particular, we define a methodology to extract alternate installation plans, an evaluation framework to assess the effectiveness of each result and an initial quantitative evaluation based on state of the art LLM models (llama-2-70b-chat and Mixtral-8x7b-Instruct-v0.1). Our results show that while LLMs are a promising approach for finding installation instructions, they present important limitations when these instructions are not sequential or mandatory. © The Author(s) 2024.},
	author_keywords = {Information Extraction; Natural Scientific Language Processing; Research/Scientific Knowledge Graphs},
	keywords = {Computer software selection and evaluation; Data mining; Information retrieval; Input output programs; Knowledge graph; Modeling languages; Natural language processing systems; Software testing; Automated extraction; Information extraction; Knowledge graphs; Language model; Language processing; Natural scientific language processing; Research/scientific knowledge graph; Scientific knowledge; Scientific language; Software installations; Codes (symbols)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{2024,
	title = {17th International Conference on Knowledge Science, Engineering and Management, KSEM 2024},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14884 LNAI},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200771862&partnerID=40&md5=ab7c37d60f50ade4b1f8f80c682e37ce},
	abstract = {The proceedings contain 160 papers. The special focus in this conference is on Knowledge Science, Engineering and Management. The topics include: EE-LCE: An Event Extraction Framework Based on LLM-Generated CoT Explanation; attention and Learning Features-Enhanced Knowledge Tracing; An MLM Decoding Space Enhancement for Legal Document Proofreading; meta-pruning: Learning to Prune on Few-Shot Learning; knowledge-Informed Molecular Learning: A Survey on Paradigm Transfer; GenFlowchart: Parsing and Understanding Flowchart Using Generative AI; DSCVSR: A Lightweight Video Super-Resolution for Arbitrary Magnification; programming Knowledge Tracing with Context and Structure Integration; an Konwledge-Based Semi-supervised Active Learning Method for Precision Pest Disease Diagnostic; multi-label Feature Selection with Adaptive Subspace Learning; User Story Classification with Machine Learning and LLMs; PTMA: Pre-trained Model Adaptation for Transfer Learning; optimization Strategies for Knowledge Graph Based Distractor Generation; reinforced Subject-Aware Graph Neural Network for Related Work Generation; EFCC-IeT: Cross-Modal Electronic File Content Correlation via Image-Enhanced Text; multi-relation Neural Network Recommendation Model Based on Knowledge Graph Embedding Algorithm; link Prediction Based on Deep Global Information in Heterogeneous Graph; subject Knowledge Entity Relationship Extraction Based on Multi-feature Fusion and Relation Specific Horns Tagging; a Human-Computer Negotiation Model Based on Q-Learning; affine Transformation-Based Knowledge Graph Embedding; integrating Prior Scenario Knowledge for Composition Review Generation; distant Supervised Relation Extraction on Pre-train Model with Improved Multi-label Attention Mechanism; sEMG-Based Multi-view Feature-Constrained Representation Learning; vicinal Data Augmentation for Classification Model via Feature Weaken; STM: An Improved Peak Price Tracking-Based Online Portfolio Selection Algorithm; spatiotemporal Dependence Learning with Meteorological Context for Transportation Demand Prediction; automatic Meter Pointer Reading Based on Knowledge Distillation; multi-table Question Answering Method Based on Correlation Evaluation and Precomputed Cube; a Joint Multi-task Learning Model for Web Table-to-Knowledge Graph Matching; an In-Context Schema Understanding Method for Knowledge Base Question Answering.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Obionwu2024180,
	author = {Obionwu, Chukwuka Victor and Valappil, Bhavya Baburaj Chovatta and Genty, Minu and Jomy, Maria and Padmanabhan, Visakh and Suresh, Aishwarya and Bedi, Sumat Singh and Broneske, David and Saake, Gunter},
	title = {Expert Agent Guided Learning with Transformers and Knowledge Graphs},
	year = {2024},
	journal = {Proceedings of the 13th International Conference on Data Science, Technology and Applications, DATA 2024},
	pages = {180 – 189},
	doi = {10.5220/0012860700003756},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203056911&doi=10.5220%2f0012860700003756&partnerID=40&md5=b46b1d450a12df662bd403f1f3caaa30},
	abstract = {The interaction between students and instructors can be likened to an interaction with a conversational agent model that understands the context of the interaction and the questions the student poses. Large language models have exhibited remarkable aptitude for facilitating learning and educational procedures. However, they occasionally exhibit hallucinations, which can result in the spread of inaccurate or false information. This issue is problematic and requires attention in order to ensure the general reliability of the information system. Knowledge graphs provide a methodical technique for describing entities and their interconnections. This facilitates a comprehensive and interconnected understanding of the knowledge in a specific field. Therefore, in order to make the interactions with our conversational agent more human-like and to deal with hallucinations, we employ a retrieval-focused generation strategy that utilizes existing knowledge and creates responses based on contextually relevant information. Our system relies on a knowledge graph, an intent classifier, and a response generator that compares and evaluates question embeddings to ensure accurate and contextually appropriate replies. We further evaluate our implementation based on relevant metrics and compare it to state-of-the-art task-specific retrieve-and-extract architectures. For language generation tasks, we find that the RCG models generate more specific, diverse, and factual information than state-of-the-art baseline models. © 2024 by SCITEPRESS – Science and Technology Publications, Lda.},
	author_keywords = {Conversational Agents; Generative AI; Information Retrieval; Instructional Feedback; Intent Classification; Knowledge Graphs},
	keywords = {Adversarial machine learning; Chatbots; Classification (of information); Contrastive Learning; Federated learning; Graph embeddings; Students; Agent modeling; Conversational agents; Expert agents; General reliabilities; Generative AI; Instructional feedback; Intent classification; Knowledge graphs; Language model; State of the art; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Sullutrone2024717,
	author = {Sullutrone, Giovanni},
	title = {Large Language Models integration in Digital Humanities},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3741},
	pages = {717 – 723},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202055073&partnerID=40&md5=7966f3a86075ad3f000029e6c913c20c},
	abstract = {The exponential growth of available data to Digital Humanities (DH) has created an impending need for tools capable of analyzing and extracting information from multi-lingual historical documents. This paper explores the research directions of my PhD project: providing DH scholars with effective, efficient, and explainable tools based on recent advancements in Large Language Models (LLMs). Two are the main directions of investigation: Self-Improving LLMs applied to Text-to-SQL and Topic Modeling, with a focus on interacting with and augmenting existing DBMS; Knowledge Graph (KG) creation and integration to mitigate hallucination, improve transparency and reasoning in question-answering systems. At the heart of my research lies the Digital Maktaba (DM) project which seeks to create a digital library for assisting in the preservation and analysis of multicultural non-latin heritage documents using, among others, cutting edge techniques for Natural Language Processing (NLP) and Data Science. The DM objectives and ideals align with the ultimate goal of the PhD project: the creation of instruments capable of aiding human-data interaction and information extraction while keeping the user at the center of an ever-evolving system. These tools have the potential to revolutionize the way DH scholars interact with historical documents, leading to new insights and discoveries for the field at large. © 2024 Copyright for this paper by its authors.},
	author_keywords = {Cross-Language Document Analysis; Knowledge Graph Integration; Large Language Models; Self-Improving Large Language Models},
	keywords = {Data mining; Economic and social effects; Historic preservation; Humanities computing; Information retrieval; Metadata; Modeling languages; Natural language processing systems; Question answering; Cross languages; Cross-language document analyze; Digital humanities; Documents analysis; Knowledge graph integration; Knowledge graphs; Language model; Large language model; Self-improving large language model; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Le20245477,
	author = {Le, Duy and Zhao, Kris and Wang, Mengying and Wu, Yinghui},
	title = {GraphLingo: Domain Knowledge Exploration by Synchronizing Knowledge Graphs and Large Language Models},
	year = {2024},
	journal = {Proceedings - International Conference on Data Engineering},
	pages = {5477 – 5480},
	doi = {10.1109/ICDE60146.2024.00432},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200456328&doi=10.1109%2fICDE60146.2024.00432&partnerID=40&md5=0fa1c4ea7da37818fcddc02ac5be052f},
	abstract = {Knowledge graphs (KGs) are routinely curated to provide factual data for various domain-specific analyses. Nevertheless, it remains nontrivial to explore domain knowledge with standard query languages. We demonstrate GraphLingo, a natural language (NL)-based knowledge exploration system designed for exploring domain-specific knowledge graphs. It differs from conventional knowledge graph search tools in that it enables an interactive exploratory NL query over domain-specific knowledge graphs. GraphLingo seamlessly integrates graph query processing and large language models with a graph pattern-based prompt generation approach to guide users in exploring relevant factual knowledge. It streamlines NL-based question & answer, graph query optimization & refining, and automatic prompt generation. A unique feature of GraphLingo is its capability to enable users to explore by seamlessly switching between a more 'open' approach and a more relevant yet 'conservative' one, facilitated by diversified query suggestions. We show cases of GraphLingo in curriculum suggestion, and materials scientific data search.  © 2024 IEEE.},
	author_keywords = {Exploratory search; Graph query; Knowledge graphs; Large Language Models},
	keywords = {Computational linguistics; Domain Knowledge; Graphic methods; Natural language processing systems; Query languages; Query processing; Refining; Domain knowledge; Domain specific; Domain-specific knowledge; Exploratory search; Graph queries; Knowledge exploration; Knowledge graphs; Language model; Large language model; Natural languages; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Xu2024,
	author = {Xu, Tianhan and Gu, Yixun and Xue, Mantian and Gu, Renjie and Li, Bin and Gu, Xiang},
	title = {Knowledge graph construction for heart failure using large language models with prompt engineering},
	year = {2024},
	journal = {Frontiers in Computational Neuroscience },
	volume = {18},
	doi = {10.3389/fncom.2024.1389475},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198538199&doi=10.3389%2ffncom.2024.1389475&partnerID=40&md5=c84044d6c96d2d68064573de91595e54},
	abstract = {Introduction: Constructing an accurate and comprehensive knowledge graph of specific diseases is critical for practical clinical disease diagnosis and treatment, reasoning and decision support, rehabilitation, and health management. For knowledge graph construction tasks (such as named entity recognition, relation extraction), classical BERT-based methods require a large amount of training data to ensure model performance. However, real-world medical annotation data, especially disease-specific annotation samples, are very limited. In addition, existing models do not perform well in recognizing out-of-distribution entities and relations that are not seen in the training phase. Method: In this study, we present a novel and practical pipeline for constructing a heart failure knowledge graph using large language models and medical expert refinement. We apply prompt engineering to the three phases of schema design: schema design, information extraction, and knowledge completion. The best performance is achieved by designing task-specific prompt templates combined with the TwoStepChat approach. Results: Experiments on two datasets show that the TwoStepChat method outperforms the Vanillia prompt and outperforms the fine-tuned BERT-based baselines. Moreover, our method saves 65% of the time compared to manual annotation and is better suited to extract the out-of-distribution information in the real world. Copyright © 2024 Xu, Gu, Xue, Gu, Li and Gu.},
	author_keywords = {heart failure; knowledge graph; large language models; prompt engineering; TwoStepChat},
	keywords = {Cardiology; Computational linguistics; Decision support systems; Diagnosis; Failure (mechanical); Knowledge graph; Clinical disease; Graph construction; Heart failure; Knowledge graphs; Language model; Large language model; Prompt engineering; Real-world; Schema design; Twostepchat; accuracy; algorithm; Article; artificial intelligence chatbot; cardiac imaging; ChatGPT; data extraction; decision making; decision support system; engineering; heart disease risk factor; heart failure; heart surgery; human; hypertension; knowledge; laboratory test; large language model; medical expert; medical guideline; prediction; prognosis; quality control; symptom; training; Diseases},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access}
}

@ARTICLE{Kalisz2024447,
	author = {Kalisz, Vít and Kalisz, Adam},
	title = {Prompt Engineering for Domain-Oriented AI Support Tools: Ontologies, Mind Maps, Namespaces, Source Code Fragments},
	year = {2024},
	journal = {Lecture Notes in Electrical Engineering},
	volume = {1198 LNEE},
	pages = {447 – 482},
	doi = {10.1007/978-3-031-61221-3_22},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201017640&doi=10.1007%2f978-3-031-61221-3_22&partnerID=40&md5=41dba76f744541011c44f1f76fd90f3d},
	abstract = {Chat AI systems, recently popularised by ChatGPT, allow interactions by exchanging linear text messages. Graph-like structures introduced by Z.Hedrlín represent and transfer information better than the classical linear form. We examine the possibility of using these structures to improve communication with these AI systems. We show that it is possible to create a simple graph-like structure about a topic that better captures and transfers understanding of the AI system. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {chat AI; ChatGPT; Concept Maps; diagrams; free structuring; Google Bard; graph-like structures; graphs; knowledge trees; LLM; mind maps; Mind Maps; non-linear form; non-linear structuring; OrgPad; Tony Buzan; web application},
	keywords = {Chat AI; ChatGPT; Concept maps; Diagram; Free structuring; Google bard; Google+; Graph; Graph-like structures; Knowledge tree; LLM; Mind maps; Non linear; Non-linear form; Non-linear structuring; Orgpad; Tony buzan; WEB application; Web applications; Trees (mathematics)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Tian20247731,
	author = {Tian, Yuan and Xu, Nan and Mao, Wenji},
	title = {A Theory Guided Scaffolding Instruction Framework for LLM-Enabled Metaphor Reasoning},
	year = {2024},
	journal = {Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL 2024},
	volume = {1},
	pages = {7731 – 7748},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200053762&partnerID=40&md5=8bea9ef8d49d3febc6863939072efbc0},
	abstract = {Metaphor detection is a challenging task in figurative language processing, which aims to distinguish between metaphorical and literal expressions in text. Existing methods tackle metaphor detection via training or fine-tuning discriminative models on labeled data. However, these approaches struggle to explain the underlying reasoning process behind the metaphorical/literal judgment. Recently, large language models (LLMs) have shown promise in language reasoning tasks. Although promising, LLM-based methods for metaphor detection and reasoning are still faced with the challenging issue of bringing the explainable concepts for metaphor reasoning and their linguistic manifestation. To fill this gap, we propose a novel Theory guided Scaffolding Instruction (TSI) framework that instructs an LLM to infer the underlying reasoning process of metaphor detection guided by metaphor theories for the first time. Our work is inspired by a pedagogical strategy called scaffolding instruction, which encourages educators to provide questioning and support as scaffolding so as to assist learners in constructing the understanding of pedagogical goals step by step. We first construct a metaphor knowledge graph grounded in metaphor theory, which serves as the instructional structure to obtain a series of scaffolding questions, directing the LLM to incrementally generate the reasoning process for metaphor understanding through dialogue interactions. During this theory guided instruction process, we explore the LLM’s mastery boundary and provide the relevant knowledge as scaffolding support when the question is beyond the LLM’s capability. Experimental results verify that our method significantly outperforms both the LLM-based reasoning methods and the SOTA methods in metaphor detection, indicating the facilitation of metaphor and instruction theories in guiding LLM-enabled reasoning process. © 2024 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Scaffolds; Discriminative models; Fine tuning; Labeled data; Language model; Language processing; Literals; Model-based method; Pedagogical strategies; Reasoning process; Reasoning tasks; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Hu2024843,
	author = {Hu, Zhongjian and Yang, Peng and Liu, Fengyuan and Meng, Yuan and Liu, Xingyu},
	title = {Prompting Large Language Models with Knowledge-Injection for Knowledge-Based Visual Question Answering},
	year = {2024},
	journal = {Big Data Mining and Analytics},
	volume = {7},
	number = {3},
	pages = {843 – 857},
	doi = {10.26599/BDMA.2024.9020026},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202865988&doi=10.26599%2fBDMA.2024.9020026&partnerID=40&md5=a9657f8c8dc54dc53e11b3ea009d9caf},
	abstract = {Previous works employ the Large Language Model (LLM) like GPT-3 for knowledge-based Visual Question Answering (VQA). We argue that the inferential capacity of LLM can be enhanced through knowledge injection. Although methods that utilize knowledge graphs to enhance LLM have been explored in various tasks, they may have some limitations, such as the possibility of not being able to retrieve the required knowledge. In this paper, we introduce a novel framework for knowledge-based VQA titled 'Prompting Large Language Models with Knowledge-Injection' (PLLMKI). We use vanilla VQA model to inspire the LLM and further enhance the LLM with knowledge injection. Unlike earlier approaches, we adopt the LLM for knowledge enhancement instead of relying on knowledge graphs. Furthermore, we leverage open LLMs, incurring no additional costs. In comparison to existing baselines, our approach exhibits the accuracy improvement of over 1.3 and 1.7 on two knowledge-based VQA datasets, namely OK-VQA and A-OKVQA, respectively.  © 2018 Tsinghua University Press.},
	author_keywords = {knowledge injection; knowledge-based visual question answering; large language model; visual question answering},
	keywords = {Knowledge graph; Visual languages; Additional costs; Knowledge based; Knowledge graphs; Knowledge injection; Knowledge-based visual question answering; Language model; Large language model; Question Answering; Visual question answering; Question answering},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{2024,
	title = {SEBD 2024 - Proceedings of the 32nd Symposium on Advanced Database Systems},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3741},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202050754&partnerID=40&md5=09bdfeefe89077efeb78e1a9a7b454f4},
	abstract = {The proceedings contain 73 papers. The topics discussed include: enhancing data precision with large language models: analyzing failures and innovating database curation; detecting and fixing unfairness in data-driven decision making; scalable vector analytics: a story of twists and turns; building taxonomies with triplet queries; mining validating shape for large knowledge graphs via dynamic reservoir sampling; initial achievements in relation extraction from RNA-focused scientific papers; towards a standard for triggers in property graphs; assessing speech model performance: a subgroup perspective; an innovative big temporal data analytics technique over real-life healthcare datasets: the F-TBDA approach; colossal trajectory mining: semantic co-movement pattern mining; and bootstrapping gene expression-cancer knowledge bases with limited human annotations.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Xu2024129,
	author = {Xu, Ziwei and Ichise, Ryutaro},
	title = {Exploring Causal Chain Identification: Comprehensive Insights from Text and Knowledge Graphs},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14912 LNCS},
	pages = {129 – 146},
	doi = {10.1007/978-3-031-68323-7_11},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202155976&doi=10.1007%2f978-3-031-68323-7_11&partnerID=40&md5=a31bdd49c27b904d3a1becebce47af19},
	abstract = {During real-world reasoning, the logic path is generally not explicitly articulated. An appropriate causal chain can offer abundant informative details to depict a logical pathway, which is also beneficial in preventing ambiguity problems during text generation. However, most causal chains tend to lose their causal meaning after multiple hops, also this phenomenon occurs in other chains of relations. To discriminate the broken linkage in chain detection task, we introduce the CK-CEVAE model, Chained domain Knowledge in Cause Effect Variational AutoEncoder, which integrates knowledge into the representation of causal assumptions within chains, employing sequential probabilistic distributions for cause-effect estimation. Our model demonstrates an improvement of around 4% in F1-score over LLM-based and neural-based models in identifying causal chains originating from text. Furthermore, to investigate the semantic continuity of chains within established knowledge graphs, we curate a chain-structured dataset, highlighting both causal relations and multiple non-causal relations, i.e. used for, synonym and similar to, termed ConceptNet-CC dataset. We noticed that the longer the chains, the fewer instances of existence. However, contrary to our intuitions, models perform better at identifying longer chains than shorter ones in uni-directional relations like causes and used for. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {Causal Chain; Knowledge Graph; VAE},
	keywords = {Semantics; Causal chains; Causal relations; Cause-effect; Detection tasks; Knowledge graphs; Logic path; Multiple hops; Real-world; Text generations; VAE; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Hu2024399,
	author = {Hu, Silan and Wang, Xiaoning},
	title = {FOKE: A Personalized and Explainable Education Framework Integrating Foundation Models, Knowledge Graphs, and Prompt Engineering},
	year = {2024},
	journal = {Communications in Computer and Information Science},
	volume = {2161 CCIS},
	pages = {399 – 411},
	doi = {10.1007/978-981-97-5803-6_24},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201097678&doi=10.1007%2f978-981-97-5803-6_24&partnerID=40&md5=076b57a4b8752f21a7be46662a0295e4},
	abstract = {Integrating large language models (LLMs) and knowledge graphs (KGs) holds great promise for revolutionizing intelligent education, but challenges remain in achieving personalization, interactivity, and explainability. We propose FOKE, a Forest Of Knowledge and Education framework that synergizes foundation models, knowledge graphs, and prompt engineering to address these challenges. FOKE introduces key innovations: a hierarchical knowledge forest for structured domain knowledge representation, a multi-dimensional user profiling mechanism for comprehensive learner modeling, and an interactive prompt engineering scheme for generating precise and tailored learning guidance. We implement Scholar Hero, a real-world instantiation of FOKE, showcasing its capabilities in delivering personalized, interactive, and explainable educational services. Our research highlights the potential of integrating foundation models, knowledge graphs, and prompt engineering to revolutionize intelligent education practices, ultimately benefiting learners worldwide. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2024.},
	author_keywords = {Intelligent education; Knowledge Representation; Large Language Models; Personalization; Prompt Engineering},
	keywords = {Computational linguistics; Domain Knowledge; Engineering education; Graphic methods; User profile; Foundation models; Intelligent educations; Interactivity; Knowledge graphs; Knowledge-representation; Language model; Large language model; Model knowledge; Personalizations; Prompt engineering; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Nahed2024325,
	author = {Nahed, Pouyan and Kambar, Mina Esmail Zadeh Nojoo and Taghva, Kazem},
	title = {Enhancing Clinical Trial Summarization: Leveraging Large Language Models and Knowledge Graphs for Entity Preservation},
	year = {2024},
	journal = {Lecture Notes in Networks and Systems},
	volume = {1003 LNNS},
	pages = {325 – 336},
	doi = {10.1007/978-981-97-3302-6_26},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201098360&doi=10.1007%2f978-981-97-3302-6_26&partnerID=40&md5=1ca02a3ecc28fcf59cb132be0bf243f2},
	abstract = {ClinicalTrials.gov is an accessible online medical resource for researchers, healthcare professionals, and policy designers seeking detailed information on clinical trials. Summarizing these long clinical records can significantly reduce the time needed for the database users as the process transforms comprehensive information into concise synopses, preserving the essential meaning and facilitating understanding. In this paper, we employ the Bidirectional and Auto-Regressive Transformers model to generate the trials’ brief summaries. Our contributions provide new preprocessing techniques for model training, which leads to a robust summarization model. The fine-tuned model significantly enhanced ROUGE-1, ROUGE-2, and ROUGE-L F1-scores by 14%, 23%, and 20%, respectively, compared to previous studies. Additionally, we present an innovative knowledge graph based on entity classes to assess the generated summaries. This graph not only quantifies the essential entities transformed from the original text to the summaries but also provides insights into their specific order and arrangement in sentences. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2024.},
	author_keywords = {Clinical data; Knowledge graph; Large language models; Named entity preservation; Summarization},
	keywords = {Computational linguistics; Graphic methods; Knowledge management; Medical applications; Clinical data; Clinical records; Clinical trial; Health care professionals; Knowledge graphs; Language model; Large language model; Named entities; Named entity preservation; Summarization; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Soltani2024370,
	author = {Soltani, Arian and Nkashama, DJeff Kanda and Masakuna, Jordan Felicien and Frappier, Marc and Tardif, Pierre-Martin and Kabanza, Froduald},
	title = {Extended Abstract: Assessing Language Models for Semantic Textual Similarity in Cybersecurity},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14828 LNCS},
	pages = {370 – 380},
	doi = {10.1007/978-3-031-64171-8_19},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200653407&doi=10.1007%2f978-3-031-64171-8_19&partnerID=40&md5=bc7ae1254d17f722078500a6e243a618},
	abstract = {In light of the significant strides made by large language models (LLMs) in the field of natural language processing (NLP) [5], our research seeks to evaluate and contrast their proficiency in establishing associations within the realm of cybersecurity. Our experimental framework involves juxtaposing actual connections from various cybersecurity knowledge graphs (including MITRE CAPEC, D3FEND, and CVE connections to ATT &CK) against predictions made by LLMs using semantic textual similarity (STS). These connections span a broad spectrum, encapsulating diverse abstractions of threat descriptions, attack patterns, defense strategies, and vulnerabilities. The language models chosen for this study are varied, comprising state-of-the-art models from STS leaderboards, LLMs (GPT3.5 and PaLM), and ATTACK BERT [1], a cybersecurity domain-specific language model. Our experiments provide valuable insights into the differentiation between language models and data sources, thereby facilitating the broader application of STS in cybersecurity. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {Cybersecurity; Intrusion Detection Systems (IDS); Language Models; MITRE ATT&CK},
	keywords = {Computational linguistics; Cybersecurity; Intrusion detection; Natural language processing systems; Network security; Problem oriented languages; Actual connections; Cyber security; Extended abstracts; Intrusion detection system; Intrusion Detection Systems; Language model; Language processing; MITRE ATT&CK; Natural languages; Textual similarities; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Ren20246916,
	author = {Ren, Jie and Guo, Qipeng and Yan, Hang and Liu, Dongrui and Zhang, Quanshi and Qiu, Xipeng and Lin, Dahua},
	title = {Identifying Semantic Induction Heads to Understand In-Context Learning},
	year = {2024},
	journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
	pages = {6916 – 6932},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198643484&partnerID=40&md5=c49814e64f18b914fea8f1f4087cf78a},
	abstract = {Although large language models (LLMs) have demonstrated remarkable performance, the lack of transparency in their inference logic raises concerns about their trustworthiness. To gain a better understanding of LLMs, we conduct a detailed analysis of the operations of attention heads and aim to better understand the in-context learning of LLMs. Specifically, we investigate whether attention heads encode two types of relationships between tokens in natural languages: the syntactic dependency parsed from sentences and the relation within knowledge graphs. We find that certain attention heads exhibit a pattern where, when attending to head tokens, they recall tail tokens and increase the output logits of those tail tokens. More crucially, the formulation of such semantic induction heads has a close correlation with the emergence of the in-context learning ability of language models. The study of semantic attention heads advances our understanding of the intricate operations of attention heads in transformers, and further provides new insights into the in-context learning of LLMs. © 2024 Association for Computational Linguistics.},
	keywords = {Adversarial machine learning; Computational linguistics; Contrastive Learning; Knowledge graph; Natural language processing systems; Context learning; In contexts; Knowledge graphs; Language model; Learning abilities; Natural languages; Performance; Syntactic dependencies; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Ghanem202418,
	author = {Ghanem, Hussam and Cruz, Christophe},
	title = {Fine-Tuning vs. Prompting: Evaluating the Knowledge Graph Construction with LLMs},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3747},
	pages = {18},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203305182&partnerID=40&md5=85bf591b42d98ea8d51b5aad7beccac6},
	abstract = {This paper explores Text-to-Knowledge Graph (T2KG) construction„ assessing Zero-Shot Prompting (ZSP), Few-Shot Prompting (FSP), and Fine-Tuning (FT) methods with Large Language Models (LLMs). Through comprehensive experimentation with Llama2, Mistral, and Starling, we highlight the strengths of FT, emphasize dataset size’s role, and introduce nuanced evaluation metrics. Promising perspectives include synonym-aware metric refinement, and data augmentation with LLMs. The study contributes valuable insights to KG construction methodologies, setting the stage for further advancements. © 2024 Copyright for this paper by its authors.},
	author_keywords = {Few-Shot Prompting; Fine-Tuning; Large Language Models; Text-to-Knowledge Graph; Zero-Shot Prompting},
	keywords = {Graphic methods; Zero-shot learning; Data set size; Few-shot prompting; Fine tuning; Fine-tuning methods; Graph construction; Knowledge graphs; Language model; Large language model; Text-to-knowledge graph; Zero-shot prompting; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Çiftçi2024516,
	author = {Çiftçi, Okan and Soygazi, Fatih and Tekir, Selma},
	title = {Enrichment of Turkish question answering systems using knowledge graphs},
	year = {2024},
	journal = {Turkish Journal of Electrical Engineering and Computer Sciences},
	volume = {32},
	number = {4},
	pages = {516 – 533},
	doi = {10.55730/1300-0632.4085},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200201498&doi=10.55730%2f1300-0632.4085&partnerID=40&md5=60a589bec86a607ca4412451b3ad875a},
	abstract = {Recent capabilities of large language models (LLMs) have transformed many tasks in Natural Language Processing (NLP), including question answering. The state-of-the-art systems do an excellent job of responding in a relevant, persuasive way but cannot guarantee factuality. Knowledge graphs, representing facts as triplets, can be valuable for avoiding errors and inconsistencies with real-world facts. This work introduces a knowledge graph-based approach to Turkish question answering. The proposed approach aims to develop a methodology capable of drawing inferences from a knowledge graph to answer complex multihop questions. We construct the Beyazperde Movie Knowledge Graph (BPMovieKG) and the Turkish Movie Question Answering dataset (TRMQA) to answer questions in the movie domain. We evaluate our proposed question answering pipeline against a baseline study. Furthermore, we compare it with a question answering system built upon GPT-3.5 Turbo to answer the 1-hop questions from TRMQA. The experimental results confirm that link prediction on a knowledge graph is quite effective in answering questions that require reasoning paths. Finally, we provide insights into the pros and cons of the provided solution through a qualitative study. © TÜBİTAK.},
	author_keywords = {deep learning; graph embeddings; Knowledge representation and reasoning; natural language processing; question answering systems},
	keywords = {Deep learning; Graph embeddings; Graphic methods; Motion pictures; Natural language processing systems; Deep learning; Graph embeddings; Knowledge graphs; Knowledge representation and reasoning; Language processing; Natural language processing; Natural languages; Question Answering; Question answering systems; Turkishs; Knowledge graph},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Hamed2024130,
	author = {Hamed, Ahmed Abdeen and Crimi, Alessandro and Lee, Byung Suk and Misiak, Magdalena M.},
	title = {Fact-Checking Generative AI: Ontology-Driven Biological Graphs for Disease-Gene Link Verification},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14835 LNCS},
	pages = {130 – 137},
	doi = {10.1007/978-3-031-63772-8_12},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198850505&doi=10.1007%2f978-3-031-63772-8_12&partnerID=40&md5=16b8d012cec5a85acc267cdf2ad0a465},
	abstract = {Since the launch of various generative AI tools, scientists have been striving to evaluate their capabilities and contents, in the hope of establishing trust in their generative abilities. Regulations and guidelines are emerging to verify generated contents and identify novel uses. we aspire to demonstrate how ChatGPT claims are checked computationally using the rigor of network models. We aim to achieve fact-checking of the knowledge embedded in biological graphs that were contrived from ChatGPT contents at the aggregate level. We adopted a biological networks approach that enables the systematic interrogation of ChatGPT’s linked entities. We designed an ontology-driven fact-checking algorithm that compares biological graphs constructed from approximately 200,000 PubMed abstracts with counterparts constructed from a dataset generated using the ChatGPT-3.5 Turbo model. In 10-samples of 250 randomly selected records a ChatGPT dataset of 1000 “simulated” articles, the fact-checking link accuracy ranged from 70% to 86%. This study demonstrated high accuracy of aggregate disease-gene links relationships found in ChatGPT-generated texts. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {biological graphs; biological ontology; ChatGPT; fact-checking; generative AI; network medicine},
	keywords = {Bioinformatics; Gene Ontology; Genes; Graphic methods; Biological graph; Biological networks; Biological ontologies; ChatGPT; Disease genes; Fact-checking; Generative AI; Network medicines; Network models; Ontology's; Aggregates},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Lan2024419,
	author = {Lan, Richeng and Fan, Guangwei and Tian, Maochun and Yang, Yue and Wang, Gaodan and Wang, Qingzheng and Wang, Jingteng},
	title = {Research on the framework of low-cost wide-domain Question-Answering system based on knowledge graph},
	year = {2024},
	journal = {2024 5th International Conference on Computer Engineering and Application, ICCEA 2024},
	pages = {419 – 424},
	doi = {10.1109/ICCEA62105.2024.10603818},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201142560&doi=10.1109%2fICCEA62105.2024.10603818&partnerID=40&md5=783c174ea38f1a482e16afbb649380db},
	abstract = {Knowledge graph-based question-answering (KBQA) systems suffer from problems such as low-quality datasets and limited categories of candidate entities, which lead to difficulties in system construction and limited applications. To address this problem, a low-cost wide-domain KBQA system construction framework called LCWD-QA is proposed by combining deep learning, knowledge graphs, and large language models. First, an entity span prediction model was designed to recognize potential entity mentions in sentences. Then, the concept of entity popularity is introduced, and an entity-linking algorithm is designed to link entity mentions to specific entities in the knowledge graph. Finally, the Bert style of text classification models was used for intent recognition, and then different methods were used to generate the answer to that question. In addition, large language models were used to enhance the experimental dataset and generate supplementary answers to the knowledge graph to improve the generalization of the system. The experimental results show that the LCWD-QA system presented in this paper exhibits good performance on both entity span prediction and intent recognition subtasks, with an accuracy of 99.5%, which is better than that of the prevalent benchmark models. The system avoids the high dependence of traditional named entity recognition schemes on manually labeled datasets and has high accuracy and interpretability, which has high application and reference value.  © 2024 IEEE.},
	author_keywords = {Entity linking; Entity Span Prediction; KBQA; Knowledge Graph; Large Language Model},
	keywords = {Benchmarking; Classification (of information); Computational linguistics; Costs; Deep learning; Forecasting; Graphic methods; Large datasets; Natural language processing systems; Text processing; Entity linking; Entity span prediction; Graph-based; Knowledge graph-based question-answering; Knowledge graphs; Language model; Large language model; Question Answering; Question answering systems; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Zimina202419,
	author = {Zimina, Elizaveta and Järvelin, Kalervo and Peltonen, Jaakko and Ranta, Aarne and Nummenmaa, Jyrki},
	title = {TraQuLA: Transparent Question Answering Over RDF Through Linguistic Analysis},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14629 LNCS},
	pages = {19 – 33},
	doi = {10.1007/978-3-031-62362-2_2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197756950&doi=10.1007%2f978-3-031-62362-2_2&partnerID=40&md5=6b84ae1c699e7107c719c21655a3f0eb},
	abstract = {Answering complex questions over knowledge graphs has gained popularity recently. Systems based on large language models seem to achieve top performance. However, these models may generate content that looks reasonable but is incorrect. They also lack transparency, making it impossible to exactly explain why a particular answer was generated. To tackle these problems we present the TraQuLA (Transparent QUestion-answering through Linguistic Analysis) system – a rule-based system developed through linguistic analysis of datasets of complex questions over DBpedia and Wikidata. TraQuLA defines a question’s type and extracts its semantic component candidates (named entities, properties and class names). For the extraction of properties, whose natural language verbalisations are most diverse, we built an extensive database which matches DBpedia/Wikidata properties to natural language expressions, allowing linguistic variation. TraQuLA generates semantic parses for the components and ranks them by each question’s structure and morphological features. The ranked parses are then analysed top down according to their patterns, also noting linguistic aspects, until a solution is found and a SPARQL query is produced. TraQuLA outperforms the existing baseline systems on the LC-QuAD 1.0 and competes with ChatGPT-based systems on LC-QuAD 2.0. For the LC-QuAD 1.0 test set, we developed an evaluation approach that accepts multiple ways to answer the questions (some ignored by the dataset) and curated some errors. TraQuLa contains no “black boxes” of neural networks or machine learning and makes its answer construction traceable. Users can therefore better rely on them and assess their correctness. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {Linguistic analysis; Question-answering; RDF; Rule-based},
	keywords = {Complex networks; Knowledge graph; Natural language processing systems; Query processing; Resource Description Framework (RDF); Statistical tests; Complex questions; Dbpedia; Knowledge graphs; Language model; Linguistic analysis; Performance; Property; Question Answering; RDF; Rule based; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Payumo2024,
	author = {Payumo, Kevin and Subramanian, Inimai and Lu, Thomas and Chow, Edward},
	title = {Intelligent Knowledge Base Search Tool using Large Language Model and Graph Neural Network},
	year = {2024},
	journal = {Proceedings of SPIE - The International Society for Optical Engineering},
	volume = {13040},
	doi = {10.1117/12.3014075},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197539004&doi=10.1117%2f12.3014075&partnerID=40&md5=ed518a4640a4277c8fcedb0f6bb6bbbc},
	abstract = {Within many organizations, a vast number of communications, memos, reports and documents have been accumulated in internal servers. Efficiently discovering relevant entries can reduce time spent addressing organizational needs such as personnel skills matching or anomaly resolution. However, per organization, information retrieval on these disparate data types can be challenging, as systems must be designed for their domain while accounting for unstructured and inconsistent datasets. Traditional querying via search terms often requires relevancy tuning by subject matter experts which makes it difficult to build retrieval systems. We argue that development of retrieval systems can be simplified and enhanced by embedding data with Large Language Models (LLMs), organizing information in a Knowledge Graph (KG) structure, and further encoding their relational features through a Graph Neural Network (GNN). One of the major challenges of using GNNs for information retrieval is optimizing negative edge selection. Training GNNs requires a balanced ratio between positive and negative edges however the space of negative edges is exponentially larger than positive edges. In this work, we extend the LLM-GNN hybrid architecture by applying ensemble voting on a set of trained LLM-GNNs. Preliminary results have shown modest improvement on our personnel-document matching tasks. This work contributes to a developmental effort that aims to help engineers and scientists find new research opportunities, learn from past mistakes, and quickly address future needs. © 2024 SPIE.},
	author_keywords = {BERT; GNN; GPT; graph neural network; Knowledge graph; Large Language Model; LLM; Neural document retrieval; Search tool},
	keywords = {Computational linguistics; Graph neural networks; Knowledge graph; Personnel; Search engines; BERT; Document Retrieval; GPT; Graph neural networks; Knowledge graphs; Language model; Large language model; Neural document retrieval; Search tools; Information retrieval},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{2024,
	title = {35th International Conference on Database and Expert Systems Applications, DEXA 2024},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14910 LNCS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202163358&partnerID=40&md5=7fd53dc4cc0c88f7d17789d397b1b672},
	abstract = {The proceedings contain 47 papers. The special focus in this conference is on Database and Expert Systems Applications. The topics include: TCMIDP: A Comprehensive Database of Traditional Chinese Medicine for Network Pharmacology Research; fast Subgraph Search with Graph Code Indices; completing Predicates Based on Alignment Rules from Knowledge Graphs; enriching Hierarchical Navigable Small World Searches with Result Diversification; An Efficient Indexing Method for Dynamic Graph kNN; Improving the Accuracy of Text-to-SQL Tools Based on Large Language Models for Real-World Relational Databases; QPSEncoder: A Database Workload Encoder with Deep Learning; efficient Random Sampling from Very Large Databases; SQL-to-Schema Enhances Schema Linking in Text-to-SQL; efficient Algorithms for Top-k Stabbing Queries on Weighted Interval Data; a Hierarchical Storage Mechanism for Hot and Cold Data Based on Temperature Model; a Pre-trained Knowledge Tracing Model with Limited Data; chorus: More Efficient Machine Learning on Serverless Platform; Evaluating Performance of LLaMA2 Large Language Model Enhanced by QLoRA Fine-Tuning for English Grammatical Error Correction; a Label Embedding Algorithm Based on Maximizing Normalized Cross-Covariance Operator; analyzing the Efficacy of Large Language Models: A Comparative Study; leveraging Large Language Models for Flexible and Robust Table-to-Text Generation; collaborative Filtering for the Imputation of Patient Reported Outcomes; category-Aware Sequential Recommendation with Time Intervals of Purchases; a Soft Actor-Critic Algorithm for Sequential Recommendation; an Approach for Social-Distance Preserving Location-Aware Recommender Systems: A Use Case in a Hospital Environment.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Shao2024131,
	author = {Shao, Yutong and Nakashole, Ndapa},
	title = {On Linearizing Structured Data in Encoder-Decoder Language Models: Insights from Text-to-SQL},
	year = {2024},
	journal = {Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL 2024},
	volume = {1},
	pages = {131 – 156},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200211738&partnerID=40&md5=f30472393dfc2f8c7cefb8e1154a4bf0},
	abstract = {Structured data, prevalent in tables, databases, and knowledge graphs, poses a significant challenge in its representation. With the advent of large language models (LLMs), there has been a shift towards linearization-based methods, which process structured data as sequential token streams, diverging from approaches that explicitly model structure, often as a graph. Crucially, there remains a gap in our understanding of how these linearization-based methods handle structured data, which is inherently non-linear. This work investigates the linear handling of structured data in encoder-decoder language models, specifically T5. Our findings reveal the model’s ability to mimic human-designed processes such as schema linking and syntax prediction, indicating a deep, meaningful learning of structure beyond simple token sequencing. We also uncover insights into the model’s internal mechanisms, including the ego-centric nature of structure node encodings and the potential for model compression due to modality fusion redundancy. Overall, this work sheds light on the inner workings of linearization-based methods and could potentially provide guidance for future research. © 2024 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Computer hardware description languages; Decoding; Deep learning; Linearization; Encoder-decoder; Knowledge graphs; Language model; Linearisation; Modality Fusion; Model compression; Node encoding; Non linear; Simple++; Structured data; Data handling},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Zhang202437,
	author = {Zhang, Jialei and Cai, Shubin and Jiang, Zhiwei and Xiao, Jian and Ming, Zhong},
	title = {FireRobBrain: Planning for a Firefighting Robot using Knowledge Graph and Large Language Model},
	year = {2024},
	journal = {Proceedings - 2024 IEEE 10th International Conference on Intelligent Data and Security, IDS 2024},
	pages = {37 – 41},
	doi = {10.1109/IDS62739.2024.00014},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199879265&doi=10.1109%2fIDS62739.2024.00014&partnerID=40&md5=2a354ed11ec6fb0241b442d03e0fd683},
	abstract = {Firefighting robots play a crucial role in improving fire safety. However, these robots have limitations in understanding their surroundings and adapting to changing situations. In this paper, we propose the 'FireRobBrain', a combination of a knowledge graph and a large language model, to act as the 'brain' of firefighting robots. This approach aims to tackle challenges related to planning robots in dynamic environments. The FireRobBrain consists of a KG with a dynamic information base and a relatively static knowledge base. It also includes a prompting module that helps the language model generate suggestions for the robot's reactions. We evaluated the framework using a dataset of 864 samples and discovered that the combination of LLM and KG, facilitated by a well-designed prompt module, significantly improves the quality of answers, particularly for tasks involving specific contexts and structured information. Furthermore, we noted that providing a task scope in the input prefix contributes to a better understanding of the robot's task, resulting in enhanced performance.  © 2024 IEEE.},
	author_keywords = {Knowledge Graph; Large Language Model; Planning; Robot},
	keywords = {Computational linguistics; Knowledge graph; Robot programming; Context information; Dynamic environments; Dynamic information; Fire fighting robots; Fire safety; Information basis; Knowledge graphs; Language model; Large language model; Static knowledge; Fires},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Schoch2024997,
	author = {Schoch, Nicolai and Hoernicke, Mario},
	title = {NL2IBE - Ontology-controlled Transformation of Natural Language into Formalized Engineering Artefacts},
	year = {2024},
	journal = {Proceedings - 2024 IEEE Conference on Artificial Intelligence, CAI 2024},
	pages = {997 – 1004},
	doi = {10.1109/CAI59869.2024.00182},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201234664&doi=10.1109%2fCAI59869.2024.00182&partnerID=40&md5=39174d241f94e8cd3d135d9027c10360},
	abstract = {Looking at Process and Automation Engineering (P&AE) today, for the technically adept engineer, there are many different tools available to support the engineering work from translation of engineering intentions into module and plant descriptions, to definition and parametrization of entire process plant setups, for export to a control system. However, still today, in the very early engineering phases, engineering intentions either need to be entered already in a structured and controlled expert language or require a human expert's manual efforts for translation from unstructured language into formalized representations, in order for thereon-based consistent further processing in the existing tools. This process is time-consuming, fuzzy, and error-prone due to potential misconceptions and ambiguities, even for domain experts. In this work, we therefore present our NL2IBE Tool, which makes use of modern Natural Language Processing in combination with Ontology Mining, and which, based on and controlled by an underlying ontology, allows for the deterministic transformation of natural language intentions into structured and consistent engineering artefacts. We describe the overall tool architecture as well as crucial functionalities and implementation features, followed by an evaluation by the example of a hydrogen generation and CCSU use case. We conclude with a discussion of the proposed tool and give an outlook on future research. (Abstract) © 2024 IEEE.},
	author_keywords = {generative AI; intend-based engineering; natural language processing; NLP; ontological domain representation; process & automation engineering},
	keywords = {Hydrogen production; Natural language processing systems; Petroleum reservoir evaluation; Translation (languages); Automation engineering; Domain representations; Generative AI; Intend-based engineering; Language processing; Natural language processing; Natural languages; Ontological domain representation; Process & automation engineering; Process automation; Ontology},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Bertini2024,
	author = {Bertini, Flavio and Dal Palù, Alessandro and Fabiano, Francesco and Formisano, Andrea and Zaglio, Federica},
	title = {Concept2Text: an explainable multilingual rewriting of concepts into natural language},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3733},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200126703&partnerID=40&md5=e09884c42ba89e9a77cf5bd1e91aab98},
	abstract = {Automated and explainable data interpretation hinges on two critical steps: (i) identifying emerging properties from data and representing them into abstract concepts, and (ii) translating such concepts into natural language. While Large Language Models have recently demonstrated impressive capabilities in generating natural language, their trustworthiness remains difficult to ascertain. The deployment of an explainable pipeline enables its application in high-risk activities, such as decision making. Addressing this demanding requirement is facilitated by the fertile ground of knowledge representation and automated reasoning research. Building upon previous work that explored the first step, we focus on the second step, named Concept2Text. The design of an explainable translation naturally lends itself to a logic-based model, once again highlighting the contribution of declarative programming to achieving explainability in AI. This paper explores a Prolog/CLP-based rewriting system designed to interpret concepts expressed in terms of classes and relations derived from a generic ontology, generating text in natural language. Its key features encompass hierarchical tree rewritings, modular multilingual generation, support for equivalent variants across semantic, grammar, and lexical levels, and a transparent rule-based system. We present the architecture and illustrate a simple working example that allows the generation of hundreds of different and equivalent rewritings relative to the input concept. © 2024 Copyright for this paper by its authors.},
	author_keywords = {Concept-to-text; Explainable AI; Natural Language; Prolog},
	keywords = {Abstracting; Decision making; Logic programming; Program translators; PROLOG (programming language); Semantics; Translation (languages); Abstract concept; Concept-to-text; Critical steps; Data interpretation; Explainable AI; ITS applications; Language model; Natural languages; Prolog; Property; Knowledge representation},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Xu2024398,
	author = {Xu, Sheng and Chen, Mike and Chen, Shuwen},
	title = {Enhancing Retrieval-Augmented Generation Models with Knowledge Graphs: Innovative Practices Through a Dual-Pathway Approach},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14880 LNAI},
	pages = {398 – 409},
	doi = {10.1007/978-981-97-5678-0_34},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201184058&doi=10.1007%2f978-981-97-5678-0_34&partnerID=40&md5=e67ee41eb47c1f53ceebb2f7242a8ad6},
	abstract = {This manuscript delves into the augmentation of Retrieval-Augmented Generation (RAG) through Knowledge Graphs (KG), aimed at elevating the performance of Natural Language Processing (NLP) tasks. Despite the remarkable strides made by Large Language Models (LLMs) in the domain of language comprehension and generation, challenges persist in handling tasks requiring granular or specialized domain knowledge. To address this issue, researchers have proposed the RAG system, which enhances task performance and interpretability by amalgamating retrieval modules with LLMs. However, current RAG systems still face deficiencies in managing retrieval noise and hallucination issues. The article proposes a novel dual-pathway approach, integrating structured Knowledge Graph data into the retrieval module of RAG, to refine retrieval quality and yield more accurate and coherent outputs. Experimental validation demonstrates the efficacy of this approach in enhancing the accuracy and reliability of generated content, particularly in controlling hallucinations and bolstering the output's reliability when processing lengthy text inputs. Moreover, this methodology offers significant flexibility and customizability, facilitating adjustments in retrieval patterns and output formats according to the diverse requirements of different tasks, heralding widespread applicability in artificial intelligence-powered question-answering systems and text comprehension tasks. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2024.},
	author_keywords = {Hallucination Problem; Knowledge Graph (KG); Retrieval-Augmented Generation (RAG)},
	keywords = {Domain Knowledge; Information retrieval; Natural language processing systems; Generation systems; Hallucination problem; Innovative practices; Knowledge graph; Knowledge graphs; Language model; Natural languages; Pathway approach; Performance; Retrieval-augmented generation; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Su20248589,
	author = {Su, Xin and Le, Tiep and Bethard, Steven and Howard, Phillip},
	title = {Semi-Structured Chain-of-Thought: Integrating Multiple Sources of Knowledge for Improved Language Model Reasoning},
	year = {2024},
	journal = {Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL 2024},
	volume = {1},
	pages = {8589 – 8605},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199666458&partnerID=40&md5=a1d2e956bc8acdd7f5978a9eb5e8e4fb},
	abstract = {An important open question in the use of large language models for knowledge-intensive tasks is how to effectively integrate knowledge from three sources: the model’s parametric memory, external structured knowledge, and external unstructured knowledge. Most existing prompting methods either rely on one or two of these sources, or require repeatedly invoking large language models to generate similar or identical content. In this work, we overcome these limitations by introducing a novel semi-structured prompting approach that seamlessly integrates the model’s parametric memory with unstructured knowledge from text documents and structured knowledge from knowledge graphs. Experimental results on open-domain multi-hop question answering datasets demonstrate that our prompting method significantly surpasses existing techniques, even exceeding those that require fine-tuning. ©2024 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Integrating multiple sources; Knowledge graphs; Knowledge intensive tasks; Language model; Model reasonings; Multi-hops; Question Answering; Semi-structured; Structured knowledge; Text document; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Fang20243406,
	author = {Fang, Haishuo and Zhu, Xiaodan and Gurevych, Iryna},
	title = {DARA: Decomposition-Alignment-Reasoning Autonomous Language Agent for Question Answering over Knowledge Graphs},
	year = {2024},
	journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
	pages = {3406 – 3432},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200124413&partnerID=40&md5=0b9021b295ab97f182bc60a7f9ed94dc},
	abstract = {Answering Questions over Knowledge Graphs (KGQA) is key to well-functioning autonomous language agents in various real-life applications. To improve the neural-symbolic reasoning capabilities of language agents powered by Large Language Models (LLMs) in KGQA, we propose the Decomposition-Alignment-Reasoning Agent (DARA) framework. DARA effectively parses questions into formal queries through a dual mechanism: high-level iterative task decomposition and low-level task grounding. Importantly, DARA can be efficiently trained with a small number of high-quality reasoning trajectories. Our experimental results demonstrate that DARA fine-tuned on LLMs (e.g. Llama-2-7B, Mistral) outperforms both in-context learning-based agents with GPT-4 and alternative fine-tuned agents, across different benchmarks in zero-shot evaluation. This makes such models more accessible for real-life applications. We also show that DARA attains performance comparable to state-of-the-art enumerating-and-ranking-based methods for KGQA. © 2024 Association for Computational Linguistics.},
	keywords = {Benchmarking; Computational linguistics; Zero-shot learning; Agent Framework; Dual mechanisms; High quality; Knowledge graphs; Language model; Question Answering; Real-life applications; Reasoning capabilities; Symbolic reasoning; Task decomposition; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Xu20241671,
	author = {Xu, Chenchen},
	title = {Construction of library subject information intelligent perception system integrating large language model},
	year = {2024},
	journal = {IMCEC 2024 - IEEE 6th Advanced Information Management, Communicates, Electronic and Automation Control Conference},
	pages = {1671 – 1675},
	doi = {10.1109/IMCEC59810.2024.10575069},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198650333&doi=10.1109%2fIMCEC59810.2024.10575069&partnerID=40&md5=e3577835f989cd12bff7326475e8c5ff},
	abstract = {Large language model (LLM) provides technical support for the intelligent development of library subject services. By understanding the technical principle of LLM and combining with the specific needs of library subject service field, this paper carries out the research of library subject information intelligent perception system integrating LLM. The system is constructed and designed from four dimensions: data source layer, data processing layer, large language model layer and application layer, aiming to achieve efficient integration of multi-source subject data, intelligent perception and monitoring of subject dynamics, automatic generation of subject knowledge graphs, and provision of interactive Q&A and personalized recommendations, etc., so as to provide comprehensive and in-depth subject services for institutions and researchers. It shows good application prospects in enhancing the efficiency of library subject services, improving user experience, promoting knowledge discovery and innovation, and supporting discipline analysis and decision-making.  © 2024 IEEE.},
	author_keywords = {artificial intelligence; intelligent perception; large language model; library subject service},
	keywords = {Computational linguistics; Data integration; Knowledge graph; Dimension Data; Four dimensions; Intelligent perception; Language model; Large language model; Library subject service; Perception systems; Subject services; Technical principle; Technical support; Decision making},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Liu2024104663,
	author = {Liu, Shuang and Ao, Zhizhuo and Chen, Peng and Kolmanic, Simon},
	title = {CollRec: Pre-Trained Language Models and Knowledge Graphs Collaborate to Enhance Conversational Recommendation System},
	year = {2024},
	journal = {IEEE Access},
	volume = {12},
	pages = {104663 – 104675},
	doi = {10.1109/ACCESS.2024.3434720},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200271816&doi=10.1109%2fACCESS.2024.3434720&partnerID=40&md5=1a50ab3c9a56e95ced193b953a5276ee},
	abstract = {Existing conversational recommender systems (CRS) use insufficient generality in incorporating external information using knowledge graphs. The recommendation module and generation module are loosely connected during model training and shallowly integrated during inference. A simple switching or copying mechanism is used to merge recommended items into generated responses. These problems significantly degrade the recommendation performance. To alleviate this problem, we propose a novel unified framework for collaboratively enhancing conversational recommendations using pre-trained language models and knowledge graphs (CollRec). We use a fine-tuned pre-trained language model to efficiently extract knowledge graphs from conversational text descriptions, perform entity-based recommendations based on the generated graph nodes and edges, and fine-tune a large-scale pre-trained language model to generate fluent and diverse responses. Experimental results on the WebNLG 2020 Challenge dataset, ReDial dataset, and Reddit-Movie dataset show that our CollRec model significantly outperforms the state-of-the-art methods.  © 2013 IEEE.},
	author_keywords = {Conversational recommendation system; end-to-end generation; fine-tuning; knowledge graph; large language model; ReDial; WebNLG 2020 challenge},
	keywords = {Computational linguistics; Graphic methods; Job analysis; Knowledge graph; Accuracy; Conversational recommendation system; Conversational recommendations; End to end; End-to-end generation; Fine tuning; Knowledge graphs; Language model; Large language model; Oral communication; Redial; Task analysis; WebNLG 2020 challenge; Recommender systems},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@CONFERENCE{Lehmann2024,
	author = {Lehmann, Alexander and Landes, Dieter},
	title = {Extracting Metadata from Learning Videos for Ontology-Based Recommender Systems Using Whisper & GPT},
	year = {2024},
	journal = {IEEE Global Engineering Education Conference, EDUCON},
	doi = {10.1109/EDUCON60312.2024.10578858},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199069048&doi=10.1109%2fEDUCON60312.2024.10578858&partnerID=40&md5=5d489cc473a2882fb50a8be1ced3cb83},
	abstract = {In modern education, individualized learning environments play a vital role by allowing learners to tailor their learning paths based on personal needs, interests, and abilities. Achieving effective individualization relies on dynamic adaptation of the learning path, typically facilitated by recommender systems. These systems offer personalized suggestions, commonly employing content-based or collaborative filtering approaches. However, traditional recommender systems often lack consideration of the semantics of learning elements. To address this limitation, ontology-based recommender systems integrate semantic modeling, establishing additional connections within a domain to enhance precision and context in recommendations. Notably, these systems mitigate the cold start problem and are particularly advantageous in learning environments with limited data. While videos are prevalent in learning platforms, their unstructured nature poses challenges for processing. This paper introduces an innovative approach, leveraging Large Language Models, specifically GPT, to extract metadata from learning videos. The proposed method intelligently augments videos and links them to a domain ontology, enabling the integration of videos into ontology-based recommender systems. The application of this approach is demonstrated through a case study in software engineering education, showcasing its potential to enhance individualized learning experiences in specific domains. The presented method offers an automated alternative to manual video processing, aligning with the evolving landscape of education technology.  © 2024 IEEE.},
	author_keywords = {adaptive learning environments; generative AI; large language models; learning analytics; learning videos; ontology-based recommender systems},
	keywords = {Collaborative filtering; Computational linguistics; Computer aided instruction; Engineering education; Learning systems; Metadata; Ontology; Semantics; Video signal processing; Adaptive learning environment; Generative AI; Individualized learning; Language model; Large language model; Learning analytic; Learning environments; Learning video; Ontology-based; Ontology-based recommende system; Recommender systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Lyu20241714,
	author = {Lyu, Yang},
	title = {Research on the Construction of Knowledge Platform for Pumped Storage Power Station},
	year = {2024},
	journal = {2024 5th International Conference on Computer Engineering and Application, ICCEA 2024},
	pages = {1714 – 1718},
	doi = {10.1109/ICCEA62105.2024.10603963},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201140432&doi=10.1109%2fICCEA62105.2024.10603963&partnerID=40&md5=8d98ec353793e0fd4c7e256a57644ebb},
	abstract = {The purpose of introducing the knowledge platform for pumped storage power station is to make full use of the experiential knowledge accumulated over a long period of time to provide a more effective organization, management and decision support ability. Firstly, this paper elaborates the definition, development, and architecture of the knowledge platform, then the key technologies and overall workflow of the knowledge platform are described in detail. Finally, some practical application scenarios are introduced and analyzed which has a certain reference value for the construction and application of knowledge platform for pumped storage power station.  © 2024 IEEE.},
	author_keywords = {knowledge graph; knowledge platform; large language model; pumped storage power station},
	keywords = {Knowledge graph; Pumped storage power plants; Decision supports; Experiential knowledge; Knowledge graphs; Knowledge platform; Language model; Large language model; Management support; Organization decisions; Organization management; Pumped-storage power stations; Decision support systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Croitoru2024327,
	author = {Croitoru, Madalina and Blanc, Nathalie and Anders, Royce},
	title = {Symbolic Artificial Intelligence for Schema Therapy Using Knowledge Graphs},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14914 LNAI},
	pages = {327 – 333},
	doi = {10.1007/978-3-031-67868-4_22},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201098984&doi=10.1007%2f978-3-031-67868-4_22&partnerID=40&md5=f84265b5d9750d62953bf6895d95d073},
	abstract = {In this paper we place ourselves in the broader context of Artificial Intelligence (AI)-powered mental health apps and, more precisely, in the context of semi-automated, schema-based therapy. Our contribution is two-fold. First, we provide the first Knowledge Graph in the literature for Schema Therapy and demonstrate how it can be practically used by mental health professionals in supporting their clients. Second, we pave the way for explainable, symbolic-based AI approaches in mental health that are yet to be investigated alongside the more prominent approaches (currently in fashion) based on large language models. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {AI; Mental Health Apps; Schema Therapy},
	keywords = {Health professionals; Knowledge graphs; Language model; Mental health; Mental health app; Schema therapy; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Liao20244303,
	author = {Liao, Ruotong and Jia, Xu and Li, Yangzhe and Ma, Yunpu and Tresp, Volker},
	title = {GenTKG: Generative Forecasting on Temporal Knowledge Graph with Large Language Models},
	year = {2024},
	journal = {Findings of the Association for Computational Linguistics: NAACL 2024 - Findings},
	pages = {4303 – 4317},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197880327&partnerID=40&md5=52a37ef070b0c5dc4e1de6a823271050},
	abstract = {The rapid advancements in large language models (LLMs) have ignited interest in the temporal knowledge graph (tKG) domain, where conventional embedding-based and rule-based methods dominate. The question remains open of whether pre-trained LLMs can understand structured temporal relational data and replace them as the foundation model for temporal relational forecasting. Therefore, we bring temporal knowledge forecasting into the generative setting. However, challenges occur in the huge chasms between complex temporal graph data structure and sequential natural expressions LLMs can handle, and between the enormous data sizes of tKGs and heavy computation costs of finetuning LLMs. To address these challenges, we propose a novel retrieval-augmented generation framework named GenTKG combining a temporal logical rule-based retrieval strategy and few-shot parameter-efficient instruction tuning to solve the above challenges, respectively. Extensive experiments have shown that GenTKG outperforms conventional methods of temporal relational forecasting with low computation resources using extremely limited training data as few as 16 samples. GenTKG also highlights remarkable cross-domain generalizability with outperforming performance on unseen datasets without re-training, and in-domain generalizability regardless of time split in the same dataset. Our work reveals the huge potential of LLMs in the tKG domain and opens a new frontier for generative forecasting on tKGs. The code and data are released here: https://github.com/mayhugotong/GenTKG. © 2024 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Forecasting; Computation costs; Data size; Embeddings; Foundation models; Knowledge graphs; Language model; Relational data; Rule-based method; Temporal graphs; Temporal knowledge; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7}
}

@CONFERENCE{Karmakar2024863,
	author = {Karmakar, Ankan and Patel, Chintan and Kumar Delhi, Venkata Santosh},
	title = {From Unstructured Data to Knowledge Graphs: An Application for Compliance Checking Problem},
	year = {2024},
	journal = {Proceedings of the International Symposium on Automation and Robotics in Construction},
	pages = {863 – 871},
	doi = {10.22260/ISARC2024/0112},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199652264&doi=10.22260%2fISARC2024%2f0112&partnerID=40&md5=7feaa09bffdd81b1709a4cf4d3cd9b08},
	abstract = {The rule requirements of a building code are frequently violated to create financially viable designs. These deviations are subjected to condonation by the municipal commissioner if recognizable hardships are faced. The historical concession applications for similar cases are stored in an unstructured manner, creating a barrier to knowledge transfer. The subjective statements given by applicants are composed of logical structure, language, and embedded knowledge that requires years of experience from the domain expert to decipher. A knowledge graph (KG) representation of the problem can capture concepts and represent them visually, which is easy for novice stakeholders to understand. A Large Language Model (LLM)-based method is used in this study for ontology extraction in the form of concepts and relationships. Also, unstructured input preprocessing and entity disambiguation were performed to evaluate the applicability of KG in this domain. The performance of the proposed method was checked qualitatively in a case study from real-life project examples. The limitations and scopes for improvements were also highlighted. The outcome of this study indicates KG as a potential candidate for knowledge generation from the unstructured archival data of compliance checking. The target audience for this application can be the new architects, reviewers, and programmers working on developing the end-to-end automated compliance checking systems. Finally, applying these Artificial Intelligence (AI)-based knowledge transfer mechanisms can ignite future research on automated concession applications and approvals, laying a path to the digital transformation of the industry. © 2024 ISARC. All Rights Reserved.},
	author_keywords = {Artificial Intelligence; Code Compliance Checking; Knowledge Graphs},
	keywords = {Compliance control; Knowledge management; Code compliance; Code compliance checking; Compliance checking; Domain experts; Graph representation; Knowledge graphs; Knowledge transfer; Logical structure; Similar case; Unstructured data; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Arrotta202455,
	author = {Arrotta, Luca and Bettini, Claudio and Civitarese, Gabriele and Fiori, Michele},
	title = {ContextGPT: Infusing LLMs Knowledge into Neuro-Symbolic Activity Recognition Models},
	year = {2024},
	journal = {Proceedings - 2024 IEEE International Conference on Smart Computing, SMARTCOMP 2024},
	pages = {55 – 62},
	doi = {10.1109/SMARTCOMP61445.2024.00029},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199931500&doi=10.1109%2fSMARTCOMP61445.2024.00029&partnerID=40&md5=61f9d3524e57d14e5b6829ff6c0b2591},
	abstract = {Context-aware Human Activity Recognition (HAR) is a hot research area in mobile computing, and the most effective solutions in the literature are based on supervised deep learning models. However, the actual deployment of these systems is limited by the scarcity of labeled data that is required for training. Neuro-Symbolic AI (NeSy) provides an interesting research direction to mitigate this issue, by infusing common-sense knowledge about human activities and the contexts in which they can be performed into HAR deep learning classifiers. Existing NeSy methods for context-aware HAR rely on knowledge encoded in logic-based models (e.g., ontologies) whose design, implementation, and maintenance to capture new activities and contexts require significant human engineering efforts, technical knowledge, and domain expertise. Recent works show that pre-trained Large Language Models (LLMs) effectively encode common-sense knowledge about human activities. In this work, we propose ContextGPT: a novel prompt engineering approach to retrieve from LLMs common-sense knowledge about the relationship between human activities and the context in which they are performed. Unlike ontologies, ContextGPT requires limited human effort and expertise, while sharing similar privacy concerns if the reasoning is performed in the cloud. An extensive evaluation using two public datasets shows how a NeSy model obtained by infusing common-sense knowledge from ContextGPT is effective in data scarcity scenarios, leading to similar (and sometimes better) recognition rates than logic-based approaches with a fraction of the effort.  © 2024 IEEE.},
	author_keywords = {context-awareness; human activity recognition; large language models},
	keywords = {Computational linguistics; Learning systems; Ontology; Pattern recognition; Professional aspects; Activity recognition; Commonsense knowledge; Context- awareness; Context-Aware; Human activities; Human activity recognition; Language model; Large language model; Model knowledge; Ontology's; Deep learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{2024,
	title = {SemDH 2024 - Proceedings of the 1st International Workshop of Semantic Digital Humanities, co-located with the European Semantic Web Conference 2024, ESWC 2024},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3724},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199168653&partnerID=40&md5=f65a681ae3d940d0ae0fec4e7c6d943a},
	abstract = {The proceedings contain 13 papers. The topics discussed include: exploring prosopographical information in the virtual record treasury of Ireland’s knowledge graph for Irish history; publishing numismatic public finds on the semantic web for digital humanities research – CoinSampo linked open data service and semantic portal; towards a semantic representation of Egyptian demonology: requirements and benchmark study; eXtreme design for ontological engineering in the digital humanities with Viewsari, a knowledge graph of Giorgio Vasari’s The Lives; a corpus of biblical names in the Greek new testament to study the additions, omissions, and variations across different manuscripts; PaleOrdia: semantically describing (Cuneiform) paleography using paleographic linked open data; towards LLM-based semantic analysis of historical legal documents; and sustainable semantics for sustainable research data.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Shi2024175,
	author = {Shi, Juanming and Guo, Qinglang and Liao, Yong and Wang, Yuxing and Chen, Shijia and Liang, Shenglin},
	title = {Legal-LM: Knowledge Graph Enhanced Large Language Models for Law Consulting},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14878 LNAI},
	pages = {175 – 186},
	doi = {10.1007/978-981-97-5672-8_15},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201191314&doi=10.1007%2f978-981-97-5672-8_15&partnerID=40&md5=8bc4f7ad0c8194a4e69792645b13da91},
	abstract = {This paper introduces Legal-LM, an advanced Large Language Model (LLM) enhanced with a Knowledge Graph, specifically designed for legal consulting in the Chinese legal domain. Addressing the challenges of domain-specific adaptation, data veracity, and consultations with non-professional users in legal AI, Legal-LM incorporates extensive legal corpora and a knowledge graph for effective legal knowledge acquisition. The model utilizes techniques such as external legal knowledge basis, soft prompts, and Direct Preference Optimization (DPO) to ensure accurate and diverse legal advice. Our experimental results demonstrate that Legal-LM exhibits superior performance over existing models in legal question answering, case analysis, and legal recommendations, these show its potential to facilitate legal consulting and education. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2024.},
	author_keywords = {Knowledge Graph; Large Language Models; Law Consulting; Legal AI Applications; Legal-LM},
	keywords = {Computational linguistics; AI applications; Domain specific; Knowledge graphs; Language model; Large language model; Law consulting; Legal AI application; Legal domains; Legal knowledge; Legal-LM; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Elena2024969,
	author = {Elena, Shalfeeva and Valeria, Gribova},
	title = {THE ISSUES OF CREATION OF MACHINE-UNDERSTANDABLE SMART STANDARDS BASED ON KNOWLEDGE GRAPHS; [ВОПРОСЫ СОЗДАНИЯ МАШИНОПОНИМАЕМЫХ SMARTСТАНДАРТОВ НА ОСНОВЕ ГРАФОВ ЗНАНИЙ]},
	year = {2024},
	journal = {Informatics and Automation},
	volume = {23},
	number = {4},
	pages = {969 – 988},
	doi = {10.15622/ia.23.4.2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198854645&doi=10.15622%2fia.23.4.2&partnerID=40&md5=cf8f61555ca9be73888c2a88a07f0ee8},
	abstract = {The development of digital transformation requires the widespread use of digital technologies in standardization documents. One of the goals is to create standards with machine-understandable content that will allow the use of digital documents at various stages of development and production without the need for a human operator. The purpose of this work is to describe an approach for creating and translating industry normative documents into a machine-understandable representation for their further use in software services and systems. There are three types of SMART standard content: machine-readable, machine-interpretable, and machine-understandable. Knowledge graphs are actively used to formalize data and knowledge when solving various problems. The new two-level approach is proposed for the creation and translation into a machine-understandable representation of regulatory documents as knowledge graphs. The approach defines two types of interpretation of a smart document (human readability and machine understandability) through two related formats: a graph, each semantic node of which represents text in a natural language, and a network of concepts and strict connections. Each node of a human-readable graph corresponds (in general) to a subtree of a machine-readable knowledge graph. As the basis for ensuring the transformation of one form of smart standard representation into another form, LLM models are used, supplemented by a specialized adapter obtained as a result of additional training using the Parameter-Efficient Fine-Tuning approach. Requirements have been established for a set of problem- and subject-oriented tools for generating knowledge graphs. The conceptual architecture of the system for supporting the solution of a set of problems based on knowledge graphs is shown, and the principles for implementing software components that work with smart knowledge for intelligent software services are established. © 2024 St. Petersburg Federal Research Center of the Russian Academy of Sciences. All rights reserved.},
	author_keywords = {knowledge graph; LLM models; machine-understandable representation; regulatory document; smart standard; two-level representation},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{2024,
	title = {11th International Work-Conference on Bioinformatics and Biomedical Engineering, IWBBIO 2024},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14848 LNBI},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202600199&partnerID=40&md5=951b4755d4f8a5f78d8c21ce116d34a2},
	abstract = {The proceedings contain 54 papers. The special focus in this conference is on Bioinformatics and Biomedical Engineering. The topics include: GPACDA – circRNA-Disease Association Prediction with Generating Polynomials; Bioinformatics Analysis Provides Insight into the Identification of miRNAs as Transcriptional Regulators in Respiratory Syncytial Virus Infection; risk Factors of Recurrence and Metastasis of Breast Cancer Sub-types Based on Magnetic Resonance Imaging Techniques; Analysis of a Parallel and Distributed BPSO Algorithm for EEG Classification: Impact on Energy, Time and Accuracy; Naïve Bayes for Health-Status Predictive Monitoring in COVID-19: Leveraging Drugs and Diagnoses; speech Analysis for Autism Spectrum Disorder Detection for Children; SiMHOMer: Siamese Models for Health Ontologies Merging and Validation Through Large Language Models; lossless Compression of Nanopore Sequencing Raw Signals; medical Equipment Real-Time Locating System in Hospitals Based on Bluetooth Low Energy; Validation of WHO Charts Mobile Applications for Body Length and Weight Assessment in Healthy Newborns; Predicting Atherosclerotic Plaque Onset and Growth in Carotid Arteries: A CFD-Driven Approach; hemispherical Directional Reflectance as a Screening Tool to Distinguish Effervescent Tablets with Acetylsalicylic Acid and Vitamin C Stored Under Stress Conditions from Those Stored in Ambient Conditions; enhanced Ergonomics in Laryngoscopic Surgery. Exploring Innovative Solutions; maximal Deadlift Strength and Bone Mass in a Group of Healthy Elderly Men; multilayer Networks: A Survey on Models, Analysis of Algorithms and Database; bone Mineral Density in Middle-Aged Former Sprinters and Middle-Aged Active Men; spectrum Filtering to Extract Pulse Rate Variability from Signals Recorded by Wearable Devices; machine Learning Model for Anxiety Disorder Diagnosis Based on Sensory Time-Series Data; analysis of the Relationship Between Electrodermal Activity and Blood Glucose Level in Diabetics.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Abane2024,
	author = {Abane, Amar and Battou, Abdella and Merzouki, Mheni},
	title = {An Adaptable AI Assistant for Network Management},
	year = {2024},
	journal = {Proceedings of IEEE/IFIP Network Operations and Management Symposium 2024, NOMS 2024},
	doi = {10.1109/NOMS59830.2024.10574957},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198367006&doi=10.1109%2fNOMS59830.2024.10574957&partnerID=40&md5=45777b7aecc8cdfb942c1460e4f9ce71},
	abstract = {This paper presents a network management AI assistant built with Large Language Models. It adapts at runtime to the network state and specific platform, leveraging techniques like prompt engineering, document retrieval, and Knowledge Graph integration. The AI assistant aims to simplify management tasks and is easily reproducible with available source code. © 2024 IEEE.},
	author_keywords = {graph database; knowledge graph; LLMs; Neo4j; network management; RAG; text embeddings},
	keywords = {Graph Databases; Information retrieval; Knowledge management; Network management; Embeddings; Graph database; Knowledge graphs; Language model; LLM; Neo4j; Networks management; RAG; Runtimes; Text embedding; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Sun2024311,
	author = {Sun, Kai and Xu, Yifan Ethan and Zha, Hanwen and Liu, Yue and Dong, Xin Luna},
	title = {Head-to-Tail: How Knowledgeable are Large Language Models (LLMs)? A.K.A. Will LLMs Replace Knowledge Graphs?},
	year = {2024},
	journal = {Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL 2024},
	volume = {1},
	pages = {311 – 325},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200212800&partnerID=40&md5=13cdef224fc1428ed20ad9b00364bb96},
	abstract = {Since the recent prosperity of Large Language Models (LLMs), there have been interleaved discussions regarding how to reduce hallucinations from LLM responses, how to increase the factuality of LLMs, and whether Knowledge Graphs (KGs), which store the world knowledge in a symbolic form, will be replaced with LLMs. In this paper, we try to answer these questions from a new angle: How knowledgeable are LLMs? To answer this question, we constructed Head-to-Tail, a benchmark that consists of 18K question-answer (QA) pairs regarding head, torso, and tail facts in terms of popularity. We designed an automated evaluation method and a set of metrics that closely approximate the knowledge an LLM confidently internalizes. Through a comprehensive evaluation of 16 publicly available LLMs, we show that existing LLMs are still far from being perfect in terms of their grasp of factual knowledge, especially for facts of torso-to-tail entities. ©2024 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Automated evaluation; Comprehensive evaluation; Evaluation methods; Factual knowledge; Knowledge graphs; Language model; Model response; Question-answer pairs; World knowledge; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@ARTICLE{Liu2024444,
	author = {Liu, Bingqian and Wu, Xinxin and Pan, Deng and Chen, Yanyu and Huang, Jianye and Liao, Feilong and Lin, Shuang},
	title = {Enhancing Large Language Models with Graph-Based Node Sampling for Fault Attribution in Power Distribution Networks},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14874 LNCS},
	pages = {444 – 455},
	doi = {10.1007/978-981-97-5618-6_37},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201126619&doi=10.1007%2f978-981-97-5618-6_37&partnerID=40&md5=bf7fb5083df7dbd3d0b34aeec0c3bb46},
	abstract = {The increasing complexity of power distribution networks necessitates advanced methods for fault attribution analysis to uphold system reliability and stability. This paper introduces a novel approach that integrates large language models (LLMs) with domain-specific knowledge graphs to tackle the challenges posed by high-dimensional and intricate fault data in power distribution networks. A multi-dimensional fault ontology [13] is proposed to efficiently structure the fault data, facilitating the creation of a comprehensive fault knowledge graph. To enhance the diagnostic predictions of the LLM, a reinforcement learning-based node selection algorithm is implemented, strategically choosing pertinent nodes from the fault graph to enhance the model’s reasoning abilities. Experimental findings illustrate that this approach surpasses traditional statistical methods and direct LLM reasoning, achieving superior accuracy and efficiency in fault diagnosis. By incorporating selective knowledge graph node sampling, irrelevant noise is filtered out from the fault data, sharpening the LLM’s focus and eradicating “AI hallucinations,” thereby improving analytical precision. Validation on a real-world dataset from a power company confirms the method’s efficacy, promising swift and accurate fault analysis while reducing the time required for power grid fault diagnosis. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2024.},
	author_keywords = {Fault Attribution Analysis; Knowledge Graph; Large Language Models},
	keywords = {Computational linguistics; Domain Knowledge; Electric fault currents; Electric network analysis; Electric power distribution; Electric utilities; Fault detection; Graph theory; Graphic methods; Knowledge graph; Reinforcement learning; Reliability analysis; Sentiment analysis; Fault attribution analyse; Fault data; Faults diagnosis; Graph-based; Knowledge graphs; Language model; Large language model; Node sampling; Power distribution network; System's stabilities; Failure analysis},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Karacapilidis2024,
	author = {Karacapilidis, Nikos and Kalampokis, Evangelos and Giarelis, Nikolaos and Mastrokostas, Charalampos},
	title = {Generative AI and Public Deliberation: A Framework for LLM-augmented Digital Democracy},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3737},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200754235&partnerID=40&md5=43116d486585ccc4bf3f74d9c5678da5},
	abstract = {Aiming to augment the effectiveness and scalability of existing digital deliberation platforms, while also facilitating evidence-based collective decision making and increasing citizen participation and trust, this article (i) reviews state-of-the-art applications of LLMs in diverse public deliberation issues; (ii) proposes a novel digital deliberation framework that meaningfully incorporates Knowledge Graphs and neuro-symbolic reasoning approaches to improve the factual accuracy and reasoning capabilities of LLMs, and (iii) demonstrates the potential of the proposed solution through two key deliberation tasks, namely fact checking and argument building. The article provides insights about how modern AI technology should be used to address the equity perspective, helping citizens to construct robust and informed arguments, refine their prose, and contribute comprehensible feedback; and aiding policy makers in obtaining a deep understanding of the evolution and outcome of a deliberation. © 2024 Copyright for this paper by its authors.},
	author_keywords = {Digital Democracy; Large Language Models; Neuro-symbolic AI; Public Deliberation},
	keywords = {Knowledge graph; Public policy; Citizen's participations; Collective decision making; Digital democracy; Evidence-based; Knowledge graphs; Language model; Large language model; Neuro-symbolic AI; Public deliberation; State of the art; Decision making},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Ding20241877,
	author = {Ding, Zifeng and Cai, Heling and Wu, Jingpei and Ma, Yunpu and Liao, Ruotong and Xiong, Bo and Tresp, Volker},
	title = {zrLLM: Zero-Shot Relational Learning on Temporal Knowledge Graphs with Large Language Models},
	year = {2024},
	journal = {Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL 2024},
	volume = {1},
	pages = {1877 – 1895},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198155406&partnerID=40&md5=0cdd5fc125e03cf77013b0299cf243a3},
	abstract = {Modeling evolving knowledge over temporal knowledge graphs (TKGs) has become a heated topic. Various methods have been proposed to forecast links on TKGs. Most of them are embedding-based, where hidden representations are learned to represent knowledge graph (KG) entities and relations based on the observed graph contexts. Although these methods show strong performance on traditional TKG forecasting (TKGF) benchmarks, they face a strong challenge in modeling the unseen zero-shot relations that have no prior graph context. In this paper, we try to mitigate this problem as follows. We first input the text descriptions of KG relations into large language models (LLMs) for generating relation representations, and then introduce them into embedding-based TKGF methods. LLM-empowered representations can capture the semantic information in the relation descriptions. This makes the relations, whether seen or unseen, with similar semantic meanings stay close in the embedding space, enabling TKGF models to recognize zero-shot relations even without any observed graph context. Experimental results show that our approach helps TKGF models to achieve much better performance in forecasting the facts with previously unseen relations, while still maintaining their ability in link forecasting regarding seen relations. © 2024 Association for Computational Linguistics.},
	keywords = {Benchmarking; Computational linguistics; Forecasting; Graph embeddings; Natural language processing systems; Semantics; Zero-shot learning; Embeddings; Forecasting methods; Forecasting models; Generating relations; Knowledge graphs; Language model; Performance; Relation-based; Relational learning; Temporal knowledge; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@CONFERENCE{Chi2024,
	author = {Chi, Yuanfang and Zhang, Qiyue and Sun, Jiaxiang and Cai, Wei and Wang, Z. Jane and Leung, Victor C.M.},
	title = {Maximizing the Social Welfare of Decentralized Knowledge Inference Through Evolutionary Game},
	year = {2024},
	journal = {IEEE INFOCOM 2024 - IEEE Conference on Computer Communications Workshops, INFOCOM WKSHPS 2024},
	doi = {10.1109/INFOCOMWKSHPS61880.2024.10620663},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202355962&doi=10.1109%2fINFOCOMWKSHPS61880.2024.10620663&partnerID=40&md5=e143d221da9cc578b9ef60dcfdca6398},
	abstract = {To broaden their domain knowledge coverage, large language models (LLMs) increasingly incorporate extensive cor-pus data from various industries. These heterogeneous datasets are often maintained by different stakeholders, where issues of data heterogeneity, privacy, and the network cost of data transmission have attracted much attention. To address these challenges, researchers have studied the integration of LLMs with knowledge graphs to manage data heterogeneity and with edge computing to ensure data privacy and transmission efficiency. In this work, we introduce a reputation system and a spot-check mechanism for a decentralized knowledge inference system in which edge nodes can collaborate with others for knowledge sharing while preserving their data privacy. We then use an evolutionary game model to study the dynamic decision-making between requestors and workers. Moreover, we show that higher reward values and higher model quality accelerate the maximization of social welfare. © 2024 IEEE.},
	author_keywords = {decentralized computing; evolutionary game theory; reputation system},
	keywords = {Decentralized systems; Data heterogeneity; Decentralised; Decentralized computing; Domain knowledge; Evolutionary game theory; Evolutionary games; Heterogeneous datasets; Language model; Reputation systems; Social welfare; Differential privacy},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{2024,
	title = {21st International Conference on Software and Systems Reuse, ICSR 2024},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14614 LNCS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200604821&partnerID=40&md5=ed21570e17339bcf8c49cf8b0b303aeb},
	abstract = {The proceedings contain 11 papers. The special focus in this conference is on Software and Systems Reuse. The topics include: Generative AI for Code Generation: Software Reuse Implications; complexity of In-Code Variability: Emergence of Detachable Decorators; design Pattern Representation and Detection Based on Heterogeneous Information Network; an Ontology-Based Representation for Shaping Product Evolution in Regulated Industries; assessing Reflection Usage with Mutation Testing Augmented Analysis; using Energy Consumption for Self-adaptation in FaaS; Using Code from ChatGPT: Finding Patterns in the Developers’ Interaction with ChatGPT; evaluating the Reusability of Android Static Analysis Tools; The Current Status of Open Source ERP Systems: A GitHub Analysis.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Randles2024,
	author = {Randles, Alex and O’Sullivan, Declan},
	title = {R2[RML]-ChatGPT Framework},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3718},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198658702&partnerID=40&md5=23af8057dbc804d39edd64b7c161265b},
	abstract = {The purpose of this paper is to explore the potential of applying Large Language Models (LLMs) in the processes involved in linked data publication, which require a high level of domain knowledge. In particular, we are interested in the semantic and syntactic correctness of data provided by LLMs, which could be used during the development of declarative uplift mappings. The R2[RML]-ChatGPT Framework is proposed, which integrates ChatGPT to gather useful quality insights on uplift mappings required in the publication of linked data. Two system experiments were conducted, which involved inputting mappings to test the correctness of returned knowledge. The semantic correctness of key ontology terms related to 50 distinct concepts were measured. Furthermore, 150 files of relevant code were automatically generated using the framework and measured for syntactic correctness. Moreover, the framework attempted to resolve invalid syntactics, which were then reassessed. © 2024 Copyright for this paper by its authors.},
	author_keywords = {ChatGPT; Linked data Generation; Mapping Quality; Semantic Web},
	keywords = {Data handling; Domain Knowledge; High level languages; Linked data; Mapping; Ontology; Syntactics; ChatGPT; Data generation; Data publications; Domain knowledge; Language model; Linked data generation; Linked datum; Mapping quality; Semantic-Web; Useful qualities; Semantic Web},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Bruns2024,
	author = {Bruns, Oleksandra and Poltronieri, Andrea and Stork, Lise and Tietz, Tabea},
	title = {Proceedings of the First International Workshop of Semantic Digital Humanities co-located with the Extended Semantic Web Conference 2024},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3724},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199140076&partnerID=40&md5=1c99cf6179ec26474aa0ce4f45292901},
	abstract = {Exploration, analysis, and preservation of the rich cultural and historical tapestry of the world are essential for our understanding of humanity’s past and shaping our future. In recent years, there has been increased interest in the creation and application of Ontologies, Knowledge Graphs, and other Semantic Web Technologies within cultural heritage (CH) and digital humanities (DH). However, to date, the distinct areas of expertise, methodologies and traditions across the fields have led to a noticeable gap between tech solutions and humanities’ needs. The aim of the International Workshop of Semantic Digital Humanities (SemDH) was to bridge this division and encourage closer collaboration and networking across diverse fields. © 2024 Copyright for this paper by its authors.},
	author_keywords = {Cultural Heritage; Digital Humanities; FAIR; Knowledge Graphs; Large Language Models; Ontologies; Semantic Representation},
	keywords = {Historic preservation; Knowledge graph; Semantic Web; Co-located; Cultural heritages; Digital humanities; FAIR; International workshops; Knowledge graphs; Language model; Large language model; Ontology's; Semantic representation; Ontology},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Rula2024368,
	author = {Rula, Anisa and D'Souza, Jennifer},
	title = {Exploring Large Language Models for Procedural Extraction from Documents},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3741},
	pages = {368 – 376},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202037828&partnerID=40&md5=fdeabcbd1e2576ec5ecb063814560000},
	abstract = {Recent advancements in Natural Language Processing (NLP), notably the emergence of extensive language models pre-trained on vast datasets, are opening new avenues in Knowledge Engineering. This study delves into the utilization of these large language models (LLMs) in two learning scenarios - zero-shot and in-context learning - to address the extraction of procedures from unstructured PDF texts through incremental question-answering techniques. Specifically, we employ the cutting-edge GPT-4 (Generative Pre-trained Transformer 4) model, alongside two variations of in-context learning methodologies. These methods incorporate an ontology with definitions of procedures and steps, as well as a limited set of samples for few-shot learning. Our investigation underscores the potential of this approach and underscores the significance of tailored in-context learning adaptations. These adjustments hold promise in mitigating the challenge of acquiring adequate training data, a common obstacle in deep learning-based NLP methods for procedure extraction. © 2024 Copyright for this paper by its authors.},
	author_keywords = {knowledge capture; knowledge graphs; large language models; Procedural knowledge},
	keywords = {Adversarial machine learning; Contrastive Learning; Deep learning; Knowledge graph; Large datasets; Natural language processing systems; Question answering; Context learning; In contexts; Knowledge capture; Knowledge graphs; Language model; Language processing; Large language model; Learning scenarios; Natural languages; Procedural knowledge; Zero-shot learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Hofer2024,
	author = {Hofer, Marvin and Frey, Johannes and Rahm, Erhard},
	title = {Towards self-configuring Knowledge Graph Construction Pipelines using LLMs - A Case Study with RML},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3718},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85198642897&partnerID=40&md5=371a1c9b734a0892d1b084ed8ffefc48},
	abstract = {This paper explores using large language models (LLMs) to generate RDF mapping language (RML) files in the RDF turtle format as a key step towards self-configuring RDF knowledge graph construction pipelines. Our case study involves mapping a subset of the Internet Movie Database (IMDB) in JSON format given a target Movie ontology (selection of DBpedia Ontology OWL statements). We define and compute several scores to assess both the generated mapping files and the resulting graph using a manually created reference. Our findings demonstrate the promising potential of the state-of-the-art commercial LLMs in a zero-shot scenario. © 2024 Copyright for this paper by its authors.},
	author_keywords = {Automated RML Mapping Generation; Knowledge Graph Construction; LLM-KG-Engineering},
	keywords = {Knowledge graph; Ontology; Pipelines; Resource Description Framework (RDF); Semantics; Zero-shot learning; Automated RDF mapping language mapping generation; Graph construction; Knowledge graph construction; Knowledge graphs; Language mapping; Language model; Large language model-KG-engineering; Mapping generations; Mapping Language; RDF mapping; Mapping},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@CONFERENCE{Prapty20241450,
	author = {Prapty, Renascence Tarafder and Kundu, Ashish and Iyengar, Arun},
	title = {Poster: CrystalBall - Attack Graphs Using Large Language Models and RAGs},
	year = {2024},
	journal = {Proceedings - International Conference on Distributed Computing Systems},
	pages = {1450 – 1451},
	doi = {10.1109/ICDCS60910.2024.00146},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203164625&doi=10.1109%2fICDCS60910.2024.00146&partnerID=40&md5=ae9155d2a0da19dc215e8f16d8ff9e95},
	abstract = {Attack graphs provide a way to model multiple attack vectors and multi-step attacks in a holistic manner that a malicious actor could use to compromise a system. Traditional methods of generating attack graphs involve expert knowledge, manual curation, and computational algorithms that might not cover the entire threat landscape due to the ever-evolving nature of vulnerabilities and exploits. This paper explores the approach of leveraging large language models (LLMs), such as GPT4, to automate the generation of attack graphs by intelligently chaining CVEs based on their preconditions and effects. It also shows how to utilize LLMs to create attack graphs from threat reports.  © 2024 IEEE.},
	author_keywords = {Attack Graph; CVE; Large Language Model; Threat Report},
	keywords = {Attack graph; Attack vector; Curation; CVE; Expert knowledge; Holistic manner; Language model; Large language model; Multi-step attacks; Threat report; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Menad2024117,
	author = {Menad, Safaa and Abdeddaïm, Saïd and Soualmia, Lina F.},
	title = {SiMHOMer: Siamese Models for Health Ontologies Merging and Validation Through Large Language Models},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14848 LNBI},
	pages = {117 – 129},
	doi = {10.1007/978-3-031-64629-4_9},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202640943&doi=10.1007%2f978-3-031-64629-4_9&partnerID=40&md5=f6185c8cfd967e0028f8676f93a4c194},
	abstract = {Ontologies play a key role in representing and structuring domain knowledge. In the biomedical domain, the need for this type of representation is crucial for structuring, coding, and retrieving data. However, available ontologies do not encompass all the relevant concepts and relationships. In this paper, we propose the framework SiMHOMer (Siamese Modela for Health Ontologies Merging), to semantically merge and integrate the most relevant ontologies in the healthcare domain, including diseases, symptoms, drugs, and adverse events. We propose to rely on the siamese neural models we developed and trained on biomedical data, BioSTransformers, to identify new relevant relations between different concepts and to create new semantic relations, the objective being to build a new consistent merging ontology that specialists could use as a new resource for various health-related use cases. To validate the new relations, we have leveraged existing relations in the UMLS Metathesaurus and the Semantic Network. To evaluate our findings, a large language model is also used. Our first results show promising improvements for future research. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {Biomedical Ontologies; Large Language Models; Ontology Merging; Siamese Neural Models; UMLS},
	keywords = {Electronic health record; Biomedical ontologies; Domain knowledge; Language model; Large language model; Neural modelling; Ontology merging; Ontology validations; Ontology's; Siamese neural model; UMLS; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Zhao2024493,
	author = {Zhao, Jinxiong and Ma, Zhicheng and Zhao, Hong and Zhang, Xun and Liu, Qichuan and Zhang, Chentao},
	title = {Self-consistency, Extract and Rectify: Knowledge Graph Enhance Large Language Model for Electric Power Question Answering},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14873 LNCS},
	pages = {493 – 504},
	doi = {10.1007/978-981-97-5615-5_40},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201068914&doi=10.1007%2f978-981-97-5615-5_40&partnerID=40&md5=19df4f1b9eee2459ee06ecea14d713c6},
	abstract = {Electric power artificial intelligence has rapidly advanced in recent years, encompassing safety detection, assistant decision-making, and optimal scheduling. With the rise of Large Language Models (LLMs), knowledge-based AI is becoming increasingly prevalent across various domains. However, in the field of electric power, most of the knowledge-based AI is centered on Knowledge Graph (KG) techniques, while less research has been done on power LLMs. In this paper, we are inspired by Self-Consistency (SC) and propose a Self-Consistency, Extraction and Rectify framework—SCER, for the usage of KG-enhanced LLM in power operations and maintenance (O&M) question answering scenarios. Specifically, we transfer the SC from the general-purpose domain into the power domain and replace the original model with a Chinese sentence representation model to make it more localized. We design an Extract Mechanism to generate evidence chains through multiple random walks on the POMKG and a Rectify Mechanism to correct the score of the generated rationales. Extensive experiments and specific case studies on the POMQA dataset demonstrate the effectiveness of our proposed SCER for SC transfer and improvement in the power field. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2024.},
	author_keywords = {Knowledge Graph; Large Language Model; Power Operations and Maintenance; Question Answering; Self-consistency},
	keywords = {Computational linguistics; Data mining; Decision making; Electric power; Knowledge based; Knowledge graphs; Language model; Large language model; Operations and maintenance; Power operation; Power operation and maintenance; Question Answering; Self-consistency; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Wu2024163,
	author = {Wu, Minxin and Gong, Yufei and Lu, Heping and Li, Baofeng and Wang, Kai and Zhou, Yanquan and li, Lei},
	title = {Large Models and Multimodal: A Survey of Cutting-Edge Approaches to Knowledge Graph Completion},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14878 LNAI},
	pages = {163 – 174},
	doi = {10.1007/978-981-97-5672-8_14},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201193465&doi=10.1007%2f978-981-97-5672-8_14&partnerID=40&md5=d8d2440ed001acc0ca906d3c3d755497},
	abstract = {The critical task of knowledge graph completion (KGC) cannot be overlooked when it comes to the evolution and application of new-generation knowledge graphs. With the advancement of multimodal learning and the rise of large models, knowledge graphs have experienced unprecedented development. Researchers have significantly enhanced KGC by integrating these emerging technologies with knowledge graphs. Within this context, this paper systematically reviews the evolutionary process of KGC methods, ranging from traditional representation learning approaches to those based on pre-training models, large language models (LLMs), and multimodal techniques. Specifically, we outline the application and efficacy of these emerging methods in addressing KGC problems, emphasizing their strengths and limitations in understanding knowledge associations and handling complex semantic information. Finally, we outline future developmental directions, aiming to portray a comprehensive and in-depth perspective of KGC from the latest vantage point for researchers, offering valuable insights for future research and applications. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2024.},
	author_keywords = {Knowledge Graph Completion; Large Language Models; Multimodal; Pre-training Models; Representation Learning},
	keywords = {Computational linguistics; Learning systems; Semantics; Knowledge graph completion; Knowledge graphs; Language model; Large language model; Large models; Multi-modal; Pre-training; Pre-training model; Representation learning; Training model; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Karim20245576,
	author = {Karim, Md. Rezaul and Comet, Lina Molinas and Shajalal, Md and Beyan, Oya Deniz and Rebholz-Schuhmann, Dietrich and Decker, Stefan},
	title = {From Large Language Models to Knowledge Graphs for Biomarker Discovery},
	year = {2024},
	journal = {Proceedings of the Annual Hawaii International Conference on System Sciences},
	pages = {5576 – 5586},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199807340&partnerID=40&md5=ca150bc53d799919a51139e308fb8bb6},
	abstract = {Domain experts often rely on most recent knowledge for apprehending and disseminating specific biological processes that help them design strategies for developing prevention and therapeutic decision-making in various disease scenarios. A challenging scenarios for artificial intelligence (AI) is using biomedical data (e.g., texts, imaging, omics, and clinical) to provide diagnosis and treatment recommendations for cancerous conditions. Data and knowledge about biomedical entities like cancer, drugs, genes, proteins, and their mechanism is spread across structured (knowledge bases (KBs)) and unstructured (e.g., scientific articles) sources. A knowledge graph (KG) can be constructed by integrating and extracting facts about semantically interrelated entities and relations. Such a KG not only allows exploration and question answering (QA) but also enables domain experts to deduce new knowledge. However, exploring and querying large-scale KGs is tedious for non-domain users due to their lack of understanding of the data assets and semantic technologies. In this paper1, we develop a domain KG to leverage cancer-specific biomarker discovery and interactive QA. We constructed a domain ontology called OncoNet Ontology (ONO), which enables semantic reasoning for validating gene-disease (different types of cancer) relations. The KG is further enriched by harmonizing the ONO, controlled vocabularies, and biomedical concepts from scientific articles by employing BioBERT- and SciBERT-based information extractors. Further, since the medical domain is evolving, where new findings often replace old ones, without having access to up-to-date scientific findings, there is a high chance an AI system exhibits concept drift while providing diagnosis and treatment. Therefore, we finetune the KG using large language models (LLMs) based on more recent articles and KBs. © 2024 IEEE Computer Society. All rights reserved.},
	author_keywords = {Bioinformatics; Knowledge graphs; Large language models; Machine learning; Ontology},
	keywords = {Bioinformatics; Biomarkers; Computational linguistics; Data mining; Decision making; Diagnosis; Diseases; Gene Ontology; Genes; Machine learning; Semantics; Bio-marker discovery; Biological process; Domain experts; Knowledge graphs; Language model; Large language model; Machine-learning; Ontology's; Question Answering; Scientific articles; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Li202457,
	author = {Li, Gen and Tang, Cheng and Chen, Li and Deguchi, Daisuke and Yamashita, Takayoshi and Shimada, Atsushi},
	title = {LLM-Driven Ontology Learning to Augment Student Performance Analysis in Higher Education},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14886 LNAI},
	pages = {57 – 68},
	doi = {10.1007/978-981-97-5498-4_5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200754108&doi=10.1007%2f978-981-97-5498-4_5&partnerID=40&md5=44255fb3e9ef7d24e56c1ebc11b8ccac},
	abstract = {In educational settings, a challenge is the lack of linked and labeled data, hindering effective analysis. The integration of ontology facilitates the formulation of educational knowledge concepts, student behaviors, and their relations. Traditional ontology creation requires deep domain knowledge and significant manual effort. However, advancements in Large Language Models (LLMs) have offered a novel opportunity to automate and refine this process. In this paper, we propose an LLMs-driven educational ontology learning approach aimed to enhance student performance predictions. We leverage LLMs to process lecture slide texts to identify knowledge concepts and their interrelations, while question texts are used to associate them with the concepts they assess. This process facilitates the generation of the educational ontology that links knowledge concepts and maps to student interactions. Additionally, we deploy a dual-branch Graph Neural Network (GNN) with distance-weighted pooling to analyze both global and local graph information for student performance prediction. Our empirical results demonstrate the effectiveness of using LLMs for ontology-based enhancements in educational settings. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2024.},
	author_keywords = {educational data mining; GNN; knowledge graph; LLM; ontology; student performance prediction},
	keywords = {Domain Knowledge; Education computing; Forecasting; Graph neural networks; Knowledge graph; Knowledge management; Ontology; Students; Educational data mining; Graph neural networks; Knowledge graphs; Language model; Large language model; Model-driven; Ontology's; Performance prediction; Student performance; Student performance prediction; Data mining},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Meijer2024,
	author = {Meijer, David and Beniddir, Mehdi A. and Coley, Connor W. and Mejri, Yassine M. and Ozturk, Meltem and van der Hooft, Justin J. J. and Medema, Marnix H. and Skiredj, Adam},
	title = {Empowering natural product science with AI: leveraging multimodal data and knowledge graphs},
	year = {2024},
	journal = {Natural Product Reports},
	doi = {10.1039/d4np00008k},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201596625&doi=10.1039%2fd4np00008k&partnerID=40&md5=69080d5d7eee020fb2de45a589eca99f},
	abstract = {Artificial intelligence (AI) is accelerating how we conduct science, from folding proteins with AlphaFold and summarizing literature findings with large language models, to annotating genomes and prioritizing newly generated molecules for screening using specialized software. However, the application of AI to emulate human cognition in natural product research and its subsequent impact has so far been limited. One reason for this limited impact is that available natural product data is multimodal, unbalanced, unstandardized, and scattered across many data repositories. This makes natural product data challenging to use with existing deep learning architectures that consume fairly standardized, often non-relational, data. It also prevents models from learning overarching patterns in natural product science. In this Viewpoint, we address this challenge and support ongoing initiatives aimed at democratizing natural product data by collating our collective knowledge into a knowledge graph. By doing so, we believe there will be an opportunity to use such a knowledge graph to develop AI models that can truly mimic natural product scientists' decision-making. © 2024 The Royal Society of Chemistry.},
	type = {Review},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Liu20246311,
	author = {Liu, Haochen and Wang, Song and Zhu, Yaochen and Dong, Yushun and Li, Jundong},
	title = {Knowledge Graph-Enhanced Large Language Models via Path Selection},
	year = {2024},
	journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
	pages = {6311 – 6321},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202595246&partnerID=40&md5=5a6be328d40f005265c89f1c8844e201},
	abstract = {Large Language Models (LLMs) have shown unprecedented performance in various real-world applications. However, they are known to generate factually inaccurate outputs, a.k.a. the hallucination problem. In recent years, incorporating external knowledge extracted from Knowledge Graphs (KGs) has become a promising strategy to improve the factual accuracy of LLM-generated outputs. Nevertheless, most existing explorations rely on LLMs themselves to perform KG knowledge extraction, which is highly inflexible as LLMs can only provide binary judgment on whether a certain knowledge (e.g., a knowledge path in KG) should be used. In addition, LLMs tend to pick only knowledge with direct semantic relationship with the input text, while potentially useful knowledge with indirect semantics can be ignored. In this work, we propose a principled framework KELP with three stages to handle the above problems. Specifically, KELP is able to achieve finer granularity of flexible knowledge extraction by generating scores for knowledge paths with input texts via latent semantic matching. Meanwhile, knowledge paths with indirect semantic relationships with the input text can also be considered via trained encoding between the selected paths in KG and the input text. Experiments on real-world datasets validate the effectiveness of KELP. © 2024 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Digital elevation model; Semantics; External knowledge; Fine granularity; Knowledge extraction; Knowledge graphs; Language model; Latent semantics; Path selection; Performance; Real-world; Semantic relationships; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{Meditskos2024139,
	author = {Meditskos, Georgios and Tegos, Stergios and Bouas, Christos and Tassios, Alexandros and Manousaridis, Konstantinos and Papoutsoglou, Maria and Mavropoulos, Thanassis and Vrochidis, Stefanos},
	title = {Towards Semantically Conscious, Conversation-Based Chatbot Services for Migrants},
	year = {2024},
	journal = {IFIP Advances in Information and Communication Technology},
	volume = {713 IFIPAICT},
	pages = {139 – 148},
	doi = {10.1007/978-3-031-63219-8_11},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199141729&doi=10.1007%2f978-3-031-63219-8_11&partnerID=40&md5=f701af989a9dedd1ee30d8d8c3d852d2},
	abstract = {Many EU countries continue to face significant societal challenges related to the acceptance and integration of Third Country Nationals (TCNs). On one hand, hosting countries need to develop efficient and transparent processes to ensure quick registration, health assistance, integration, and support of TCNs. On the other hand, TCNs often face difficulties finding information about the hosting countries, e.g. about public services, reception centers, migration policies and asylum procedures. This paper presents ongoing work towards the development of SALLY, an intelligent chatbot to assist the information seeking process for migrants, supporting their reception and social integration in Greece. The framework aims to combine a multitude of state-of-the-art technologies on Large Language Models, Dialogue Management, Knowledge Graphs, Sentiment Analysis, and Information Retrieval, to achieve personalized conversational awareness and assist migrants in acquiring information relevant to their needs. The support of the Greek language, which is a low-resource language, and the interaction with the users through smart dialogues, beyond simple question-answering, constitute two key objectives of the framework.  © IFIP International Federation for Information Processing 2024.},
	author_keywords = {Chatbot; Conversational Awareness; Knowledge Graphs; Large Language Models; Migrants},
	keywords = {Computational linguistics; Information management; Integration; Knowledge graph; Chatbots; Conversational awareness; Efficient process; EU countries; Knowledge graphs; Language model; Large language model; Migrant; Public services; Transparent process; Sentiment analysis},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{An202418,
	author = {An, Yuan and Greenberg, Jane and Uribe-Romo, Fernando J. and Gómez-Gualdrón, Diego A. and Langlois, Kyle and Furst, Jacob and Kalinowski, Alex and Zhao, Xintong and Hu, Xiaohua},
	title = {Knowledge Graph Question Answering for Materials Science (KGQA4MAT)},
	year = {2024},
	journal = {Communications in Computer and Information Science},
	volume = {2048 CCIS},
	pages = {18 – 29},
	doi = {10.1007/978-3-031-65990-4_2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200974884&doi=10.1007%2f978-3-031-65990-4_2&partnerID=40&md5=c707d66edb84b126f2442fe4dea67447},
	abstract = {We present a study on Knowledge Graph Question Answering in Materials Science (KGQA4MAT), with a focus on metal-organic frameworks (MOFs). A knowledge graph for metal-organic frameworks (MOF-KG) has been constructed by integrating structured data, metadata, and knowledge extracted from the literature. We aim to develop a natural language (NL) interface for domain expert to query the MOF-KG. A first step is our benchmark, which consists of 161 complex questions involving comparison, aggregation, and intricate graph structures. Each question has been rephrased into three additional variations, totaling 644 questions and 161 KG queries. We then developed a systematic approach for utilizing ChatGPT to translate natural language questions into formal KG queries. We experimented with different prompt strategies. The research indicated that using an ontology, providing a few-shot examples, and offering a chain-of-thought explanation resulted in the top F1-score of 0.89. We also applied this method to the well-known QALD-9 dataset, achieving performance on par with the state-of-the-art techniques. The results indicate applicability of this model for MOF research and potentially other scientific foci. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {knowledge graph question answering; metal-organic frameworks; natural language interface; pre-trained large language models},
	keywords = {Graphic methods; Natural language processing systems; Organometallics; Query processing; Knowledge graph question answering; Knowledge graphs; Language model; Material science; Metalorganic frameworks (MOFs); Natural language interfaces; Pre-trained large language model; Question Answering; Structured data; Structured knowledge; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{You20241687,
	author = {You, Yizhe and Jiang, Zhengwei and Zhang, Kai and Feng, Huamin and Jiang, Jun and Yang, Peian},
	title = {TiGNet: Joint entity and relation triplets extraction for APT campaign threat intelligence},
	year = {2024},
	journal = {Proceedings of the 2024 27th International Conference on Computer Supported Cooperative Work in Design, CSCWD 2024},
	pages = {1687 – 1694},
	doi = {10.1109/CSCWD61410.2024.10580395},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199032313&doi=10.1109%2fCSCWD61410.2024.10580395&partnerID=40&md5=fc077909b8833c70e0a3cacfc48623eb},
	abstract = {Contemporary cybersecurity faces escalating challenges from sophisticated threats, notably Advanced Persistent Threats (APTs). Addressing these challenges necessitates a collaborative, multidisciplinary approach that transcends traditional boundaries. Gathering cyber threat intelligence (CTI) on APT campaigns and constructing a comprehensive knowledge graph empowers defenders to track the latest trends in these campaigns, update defense strategies, and attain crucial advantages in defense measures. Previous works used relation extraction techniques to obtain entity-relation triplets for constructing threat intelligence knowledge graphs. However, these works either rely on pipeline workflow, are susceptible to exposure errors and error propagation, or use sequence annotation method, which combines entity and relation labels but lacks the ability to extract single entity overlaps (SEO) or subject-object overlaps (SOO) triplets. This paper introduces TiGNet, a novel method that transforms the entity-relation triplet's extraction task into multiple token-span recognition tasks utilizing token-pair matrices. Additionally, we integrate GlobalPointer to incorporate token position information into the token-pair matrix, significantly enhancing extraction performance. To facilitate method evaluation, we annotated a Chinese entity-relation triplets dataset about APT campaigns, named APT-Triplets, comprising 9711 triplets encompassing seven triplet types. Our evaluation demonstrates that TiGNet improves the F1 score of 3.79-5.59 compared to previous joint extraction methods. Furthermore, it outperforms methods based on large language models (LLMs) in terms of both extraction performance and inference time. These results underscore TiGNet's capacity to accurately and swiftly extract threat intelligence, facilitating the construction of the APT campaign knowledge graphs, empowering defenders to track evolving trends and fortify defense strategies collaboratively.  © 2024 IEEE.},
	author_keywords = {Advanced Persistent Threat; Cyber Threat Intelligence; Knowledge Graph; Relation Extraction},
	keywords = {Cybersecurity; Extraction; Network security; Advanced persistent threat; Cybe threat intelligence; Cyber security; Cyber threats; Defense strategy; Knowledge graphs; matrix; Multi-disciplinary approach; Performance; Relation extraction; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Perevalov20243,
	author = {Perevalov, Aleksandr and Gashkov, Aleksandr and Eltsova, Maria and Both, Andreas},
	title = {Language Models as SPARQL Query Filtering for Improving the Quality of Multilingual Question Answering over Knowledge Graphs},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14629 LNCS},
	pages = {3 – 18},
	doi = {10.1007/978-3-031-62362-2_1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197764253&doi=10.1007%2f978-3-031-62362-2_1&partnerID=40&md5=14439fdf96615d56d8511f933d9a6140},
	abstract = {Question Answering systems working over Knowledge Graphs (KGQA) generate a ranked list of SPARQL query candidates for a given natural-language question. In this paper, we follow our long-term research agenda of providing trustworthy KGQA systems – here – by presenting a query filtering approach that utilizes (large) language models (LMs/LLMs), s.t., correct and incorrect queries can be distinguished. In contrast to the previous work, we address here multilingual questions represented in major languages (English, German, French, Spanish, and Russian), and confirm the generalizability of our approach by also evaluating it on low-resource languages (Ukrainian, Armenian, Lithuanian, Belarusian, and Bashkir). For our experiments, we used the following LMs: BERT, DistilBERT, Mistral, Zephyr, GPT-3.5, and GPT-4. The LMs were applied to the KGQA systems – QAnswer and MemQA – as SPARQL query filters. The approach was evaluated on the multilingual Wikidata-based dataset QALD-9-plus. The experimental results suggest that the KGQA systems achieve quality improvements for all languages when using our query-filtering approach. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {Query Candidate Filtering; Query Validation; Question Answering over Knowledge Graphs; Trustworthiness},
	keywords = {Computational linguistics; Natural language processing systems; Query processing; Knowledge graphs; Language model; Natural language questions; Query candidate filtering; Query validation; Question Answering; Question answering over knowledge graph; Question answering systems; Research agenda; Trustworthiness; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Abu-Rasheed2024,
	author = {Abu-Rasheed, Hasan and Weber, Christian and Fathi, Madjid},
	title = {Knowledge Graphs as Context Sources for LLM-Based Explanations of Learning Recommendations},
	year = {2024},
	journal = {IEEE Global Engineering Education Conference, EDUCON},
	doi = {10.1109/EDUCON60312.2024.10578654},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199039505&doi=10.1109%2fEDUCON60312.2024.10578654&partnerID=40&md5=6aaa9d4eba76eafed5fcb5807a19dcd2},
	abstract = {In the era of personalized education, the provision of comprehensible explanations for learning recommendations is of great value to enhance the learner's understanding and engagement with the recommended learning content. Large language models (LLMs) and generative AI have recently opened new doors for generating human-like explanations, for and along learning recommendations. However, their precision is still far away from acceptable in a sensitive field like education. To harness the abilities of LLMs, while still ensuring a high level of precision towards the intent of the learners, this paper proposes an approach to utilize knowledge graphs (KG) as a source of factual context for LLM prompts, reducing the risk of model hallucinations, and safeguarding against wrong or imprecise information, while maintaining an application-intended learning context. We utilize the semantic relations in the knowledge graph to offer curated knowledge about learning recommendations. With domain-experts in the loop, we design the explanation as a textual template, which is filled and completed by the LLM. Domain experts were integrated in the prompt engineering phase as part of a study, to ensure that explanations include information that is relevant to the learner. We evaluate our approach quantitatively using Rouge-N and Rouge-L measures, as well as qualitatively with experts and learners. Our results show an enhanced recall and precision of the generated explanations compared to those generated solely by the GPT model, with a greatly reduced risk of generating imprecise information in the final learning explanation.  © 2024 IEEE.},
	author_keywords = {ChatGPT; explainable AI (XAI); Generative AI (GenAI) Learning recommendations; Knowledge graphs; Large language models (LLMs)},
	keywords = {Computational linguistics; High level languages; Learning systems; Semantics; ChatGPT; Domain experts; Explainable AI (XAI); Generative AI  learning recommendation; Imprecise information; Knowledge graphs; Language model; Large language model; Learning contents; Model-based OPC; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Green Open Access}
}

@CONFERENCE{Luo20247146,
	author = {Luo, Xindi and Sun, Zequn and Zhao, Jing and Zhao, Zhe and Hu, Wei},
	title = {KnowLA: Enhancing Parameter-efficient Finetuning with Knowledgeable Adaptation},
	year = {2024},
	journal = {Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL 2024},
	volume = {1},
	pages = {7146 – 7159},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200272097&partnerID=40&md5=1201c8583175bc69b30c636286694e51},
	abstract = {Parameter-efficient finetuning (PEFT) is a key technique for adapting large language models (LLMs) to downstream tasks. In this paper, we study leveraging knowledge graph embeddings to improve the effectiveness of PEFT. We propose a knowledgeable adaptation method called KnowLA. It inserts an adaptation layer into an LLM to integrate the embeddings of entities appearing in the input text. The adaptation layer is trained in combination with LoRA on instruction data. Experiments on six benchmarks with two popular LLMs and three knowledge graphs demonstrate the effectiveness and robustness of KnowLA. We show that KnowLA can help activate the relevant parameterized knowledge in an LLM to answer a question without changing its parameters or input prompts. © 2024 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Graph embeddings; Knowledge management; Adaptation layers; Adaptation methods; Down-stream; Graph embeddings; Knowledge graphs; Language model; Parameterized; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Cui20242030,
	author = {Cui, Yuanning and Sun, Zequn and Hu, Wei},
	title = {A Pre-trained Universal Knowledge Graph Reasoning Model Based on Rule Prompts; [基于规则提示的知识图谱通用推理预训练模型]},
	year = {2024},
	journal = {Jisuanji Yanjiu yu Fazhan/Computer Research and Development},
	volume = {61},
	number = {8},
	pages = {2030 – 2044},
	doi = {10.7544/issn1000-1239.202440133},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201412576&doi=10.7544%2fissn1000-1239.202440133&partnerID=40&md5=899db54f9d274e45b98a3132eba8136b},
	abstract = {A knowledge graph (KG) is a structured knowledge base that stores a massive amount of real-world knowledge, providing data support for numerous knowledge-driven downstream tasks. KGs often suffer from incompleteness, with many missing facts. Therefore, the KG reasoning task aims to infer new conclusions based on known facts to complete the KG. With the research and development of knowledge engineering and its commercial applications, numerous general and domain-specific KGs have been constructed. Existing KG reasoning models mostly focus on completing a single KG but lack general reasoning capabilities. Inspired by the general capabilities of pre-trained large language models in recent years, some pre-trained universal KG reasoning models have been proposed. Addressing the issue of existing pre-trained model being unable to identify high-quality reasoning patterns, we introduce a rule-based pre-trained universal KG reasoning model called RulePreM. It discovers and filters high-quality reasoning rules to enhance the reasoning abilities. The proposed model first constructs a relational IO graph based on reasoning rules and uses an encoder, RuleGNN, to encode the relations. The encoded relations are then used as prompts to encode entities in the KG. Finally, candidate entities are scored for prediction. Additionally, an attention mechanism that combines rule confidence is introduced to further reduce the impact of low-quality reasoning patterns. Experimental results demonstrate that the proposed model exhibits universal reasoning abilities on 43 different KGs, with average performance surpassing existing supervised and pre-trained models. © 2024 Science Press. All rights reserved.},
	author_keywords = {knowledge graph; pre-training; prompt learning; relational IO graph; rules; universal reasoning},
	keywords = {Encoding (symbols); High quality; Knowledge graphs; Pre-training; Prompt learning; Reasoning models; Reasoning patterns; Reasoning rules; Relational IO graph; Rule; Universal reasoning; Knowledge graph},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Li2024441,
	author = {Li, Zhidong and Wang, Licai and Luo, Qibin and Qiao, Silong},
	title = {Large Language Model Based on Full-Text Retrieval for Temporal Knowledge Q&A Approach},
	year = {2024},
	journal = {2024 5th International Seminar on Artificial Intelligence, Networking and Information Technology, AINIT 2024},
	pages = {441 – 446},
	doi = {10.1109/AINIT61980.2024.10581693},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199176137&doi=10.1109%2fAINIT61980.2024.10581693&partnerID=40&md5=b1c01878548b02076061fb3d67d3432b},
	abstract = {Knowledge Q&A is one of the hot research topics in the field of natural language processing, and temporal knowledge Q&A is a difficult area of Q&A reasoning because it also needs to consider the temporal relationship of knowledge. Today's research usually focuses on the word vector similarity between knowledge and questions as an important basis for answering, while ignoring the sentence granularity semantic information embedded in the knowledge. In this paper, we propose a method of temporal knowledge Q&A for large language models based on full-text retrieval, firstly, the sentence granularity knowledge recall is performed by Elasticsearch so that large language models can learn the knowledge that is highly relevant to the problem, and then verify the temporal knowledge Q&A ability of large language models under Zero-shot, One-shot and Few-shot. The experiments were conducted on the ICEWS05-15 dataset, and the accuracy of answers was significantly improved, demonstrating the effectiveness of the temporal knowledge Q&A method for large language models based on Elasticsearch. © 2024 IEEE.},
	author_keywords = {large language models; natural language processing; prompt learning; temporal knowledge graph question-answering},
	keywords = {Computational linguistics; Information retrieval; Knowledge graph; Large datasets; Natural language processing systems; Zero-shot learning; Knowledge graphs; Language model; Language processing; Large language model; Natural language processing; Natural languages; Prompt learning; Question Answering; Temporal knowledge; Temporal knowledge graph question-answering; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Wu202417007,
	author = {Wu, Jiayang and Gan, Wensheng and Chao, Han-Chieh and Yu, Philip S.},
	title = {Geospatial Big Data: Survey and Challenges},
	year = {2024},
	journal = {IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing},
	volume = {17},
	pages = {17007 – 17020},
	doi = {10.1109/JSTARS.2024.3438376},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200804056&doi=10.1109%2fJSTARS.2024.3438376&partnerID=40&md5=53ee1c9695b3f2e78d6b565ed47f7585},
	abstract = {In recent years, geospatial big data (GBD) has obtained attention across various disciplines, categorized into big Earth observation data and big human behavior data. Identifying geospatial patterns from GBD has been a vital research focus in the fields of urban management and environmental sustainability. This article reviews the evolution of GBD mining and its integration with advanced artificial intelligence techniques. GBD consists of data generated by satellites, sensors, mobile devices, and geographical information systems, and we categorize geospatial data based on different perspectives. We outline the process of GBD mining and demonstrate how it can be incorporated into a unified framework. In addition, we explore new technologies, such as large language models, the metaverse, and knowledge graphs, and how they could make GBD even more useful. We also share examples of GBD helping with city management and protecting the environment. Finally, we discuss the real challenges that come up when working with GBD, such as issues with data retrieval and security. Our goal is to give readers a clear view of where GBD mining stands today and where it might go next.  © 2024 The Authors. This work is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 License.},
	author_keywords = {Artificial intelligence (AI); big data; geospatial big data (GBD); geospatial data},
	keywords = {Behavioral research; Data mining; Data visualization; Environmental management; Knowledge graph; Sustainable development; Data challenges; Data surveys; Earth observation data; Geo-spatial; Geo-spatial analysis; Geo-spatial data; Geospatial big data; Green products; Human behaviors; Knowledge graphs; artificial intelligence; data mining; environmental protection; GIS; satellite; sensor; spatial data; urban planning; Big data},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Chen20244283,
	author = {Chen, Hao and Xie, Runfeng and Cui, Xiangyang and Yan, Zhou and Wang, Xin and Xuan, Zhanwei and Zhang, Kai},
	title = {LKPNR: Large Language Models and Knowledge Graph for Personalized News Recommendation Framework},
	year = {2024},
	journal = {Computers, Materials and Continua},
	volume = {79},
	number = {3},
	pages = {4283 – 4296},
	doi = {10.32604/cmc.2024.049129},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199159839&doi=10.32604%2fcmc.2024.049129&partnerID=40&md5=1bc68f38ff3daf88fd522f047b22ad5a},
	abstract = {Accurately recommending candidate news to users is a basic challenge of personalized news recommendation systems. Traditional methods are usually difficult to learn and acquire complex semantic information in news texts, resulting in unsatisfactory recommendation results. Besides, these traditional methods are more friendly to active users with rich historical behaviors. However, they can not effectively solve the long tail problem of inactive users. To address these issues, this research presents a novel general framework that combines Large Language Models (LLM) and Knowledge Graphs (KG) into traditional methods. To learn the contextual information of news text, we use LLMs’ powerful text understanding ability to generate news representations with rich semantic information, and then, the generated news representations are used to enhance the news encoding in traditional methods. In addition, multi-hops relationship of news entities is mined and the structural information of news is encoded using KG, thus alleviating the challenge of long-tail distribution. Experimental results demonstrate that compared with various traditional models, on evaluation indicators such as AUC, MRR, nDCG@5 and nDCG@10, the framework significantly improves the recommendation performance. The successful integration of LLM and KG in our framework has established a feasible way for achieving more accurate personalized news recommendation. Our code is available at https://github.com/Xuan-ZW/LKPNR. © 2024 Tech Science Press. All rights reserved.},
	author_keywords = {knowledge graphs (KG); Large language models; news recommendation},
	keywords = {Computational linguistics; Recommender systems; Semantics; Contextual information; Knowledge graph; Knowledge graphs; Language model; Large language model; Learn+; Long tail; News recommendation; Personalized news; Semantics Information; Knowledge graph},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access}
}

@CONFERENCE{Du2024194,
	author = {Du, Pengfan and Liang, Sirui and Zhang, Baoli and Cao, Pengfei and Chen, Yubo and Liu, Kang and Zhao, Jun},
	title = {ZhuJiu-Knowledge: A Fairer Platform for Evaluating Multiple Knowledge Types in Large Language Models},
	year = {2024},
	journal = {Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL 2024},
	volume = {3},
	pages = {194 – 206},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199547130&partnerID=40&md5=cf1a5e603500a7cf7f3bc3090383f9c7},
	abstract = {The swift advancement in large language models (LLMs) has heightened the importance of model evaluations. LLMs have acquired a substantial amount of knowledge, and evaluating the knowledge of these LLMs is crucial. To address this, we introduce the ZhuJiu-Knowledge benchmark which carefully considers the following factors: (1) For knowledge scope, we concentrate on three domains: commonsense knowledge, world knowledge, language knowledge, which comes from ATOMIC, Conceptnet, Wikidata, and Wordnet. (2) For data construction, to prevent data contamination, we utilize knowledge derived from corpora and knowledge graphs to formulate novel questions that are ensured not to appear in the training corpus. A multitude of prompts is purposefully devised to mitigate the impact of prompt design on evaluation and to further analyze the LLMs’ sensitivity to various prompts. (3) For evaluation criteria, we propose a novel voting methodology for assessing generative text, aligning the model’s evaluation with human preferences to reduce biases inherent in individual model assessments. We evaluate 14 current mainstream LLMs and conduct a comprehensive discussion and analysis of their results. The ZhuJiu-Knowledge benchmark and open-participation leaderboard are publicly released at http://zhujiu-knowledge.top/ and we also provide a demo video at https://youtu.be/QJp4qlEHVH8. © 2024 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Commonsense knowledge; ConceptNet; Data construction; Knowledge graphs; Knowledge types; Language model; Model evaluation; Training corpus; Wordnet; World knowledge; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{2024,
	title = {Proceedings - 9th IEEE European Symposium on Security and Privacy Workshops, Euro S and PW 2024},
	year = {2024},
	journal = {Proceedings - 9th IEEE European Symposium on Security and Privacy Workshops, Euro S and PW 2024},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203002845&partnerID=40&md5=50e6554b036d8b7c0e44483979c078b1},
	abstract = {The proceedings contain 85 papers. The topics discussed include: differentially private multi-label learning is harder than you’d think; attacking operational technology without specialized knowledge: the unspecialized OT threat actor profile; towards an integrated provenance framework - a scenario for marine data; better left shift security! framework for secure software development; are you sure you want to do coordinated vulnerability disclosure?; actionable cyber threat intelligence using knowledge graphs and large language models; optimal flow collector placement in experimental networks; and a methodology to measure the ‘cost’ of cps attacks: not all CPS networks are created equal.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{2024,
	title = {35th International Conference on Database and Expert Systems Applications, DEXA 2024},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14911 LNCS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202464304&partnerID=40&md5=ad103f4d4733c5e774b35d06ffb4c906},
	abstract = {The proceedings contain 47 papers. The special focus in this conference is on Database and Expert Systems Applications. The topics include: TCMIDP: A Comprehensive Database of Traditional Chinese Medicine for Network Pharmacology Research; fast Subgraph Search with Graph Code Indices; completing Predicates Based on Alignment Rules from Knowledge Graphs; enriching Hierarchical Navigable Small World Searches with Result Diversification; An Efficient Indexing Method for Dynamic Graph kNN; Improving the Accuracy of Text-to-SQL Tools Based on Large Language Models for Real-World Relational Databases; QPSEncoder: A Database Workload Encoder with Deep Learning; efficient Random Sampling from Very Large Databases; SQL-to-Schema Enhances Schema Linking in Text-to-SQL; efficient Algorithms for Top-k Stabbing Queries on Weighted Interval Data; a Hierarchical Storage Mechanism for Hot and Cold Data Based on Temperature Model; a Pre-trained Knowledge Tracing Model with Limited Data; chorus: More Efficient Machine Learning on Serverless Platform; Evaluating Performance of LLaMA2 Large Language Model Enhanced by QLoRA Fine-Tuning for English Grammatical Error Correction; a Label Embedding Algorithm Based on Maximizing Normalized Cross-Covariance Operator; analyzing the Efficacy of Large Language Models: A Comparative Study; leveraging Large Language Models for Flexible and Robust Table-to-Text Generation; collaborative Filtering for the Imputation of Patient Reported Outcomes; category-Aware Sequential Recommendation with Time Intervals of Purchases; a Soft Actor-Critic Algorithm for Sequential Recommendation; an Approach for Social-Distance Preserving Location-Aware Recommender Systems: A Use Case in a Hospital Environment.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Lyu2024,
	author = {Lyu, Pin and Yue, Yongyong and Yu, Wengbing and Xiao, Liqiao and Liu, Chao and Zheng, Pai},
	title = {An adaptive multi-neural network model for named entity recognition of Chinese mechanical equipment corpus},
	year = {2024},
	journal = {Journal of Engineering Design},
	doi = {10.1080/09544828.2024.2340392},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197570154&doi=10.1080%2f09544828.2024.2340392&partnerID=40&md5=8cb05746979611f3765a6fa832f55a56},
	abstract = {Mining entities from open Chinese mechanical equipment texts have become prevailing in the intelligent manufacturing field. However, compared to named entities in other domains, it is very hard to determine entity boundaries in mining Chinese mechanical equipment texts because there is no unified standard for entity simplification, and digits and units are mixed in the text. To address the issue, this paper presents an entity boundary-define strategy and constructs a mechanical equipment-oriented corpus called MECorpus using open Chinese mechanical equipment texts by combining domain knowledge. A multi-neural network collaboration model Adaptive-BERT-BiLSTM-CRF-Rating (ABBCR) is then proposed for mechanical equipment named entity recognition. The novelty of ABBCR is characterised by its adaptive input mechanism and rating score ability for identified entities. Various experiments about ABBCR model selection, evaluation and application are conducted on MECorpus. Experimental results show that the ABBCR model provides high-quality mechanical equipment entities for constructing the mechanical equipment knowledge graph. ABBCR combined with the large language model has proved to be a promising method to manage complex mechanical equipment expertise. © 2024 Informa UK Limited, trading as Taylor & Francis Group.},
	author_keywords = {adaptive mechanism; bidirectional encoder representations from transformers; fuzzy boundary; multi-neural network collaboration; Named entity recognition},
	keywords = {Knowledge graph; Mining; Natural language processing systems; Adaptive mechanism; Bidirectional encoder representation from transformer; Fuzzy boundary; Mechanical equipment; Multi-neural network collaboration; Multi-neural networks; Named entity recognition; Network collaboration; Neural network model; Rating model; Network coding},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{2024,
	title = {Proceedings - 2024 IEEE 40th International Conference on Data Engineering, ICDE 2024},
	year = {2024},
	journal = {Proceedings - International Conference on Data Engineering},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200483970&partnerID=40&md5=b6b53ef43276db37d96cd7daf1e6e17f},
	abstract = {The proceedings contain 497 papers. The topics discussed include: V2V: efficiently synthesizing video results for video queries; an interactive dive into time-series anomaly detection; hit: solving partial index tracking via hierarchical reinforcement learning; online detection of outstanding quantiles with QuantileFilter; a robust prioritized anomaly detection when not all anomalies are of primary interest; CheckMate: evaluating checkpointing protocols for streaming dataflows; F-TADOC: FPGA-based text analytics directly on compression with HLS; KGLink: a column type annotation method that combines knowledge graph and pre-trained language model; boosting write performance of KV stores: an NVM-enabled storage collaboration approach; and Chat2Query: a zero-shot automatic exploratory data analysis system with large language models.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Cavalleri202461,
	author = {Cavalleri, Emanuele and Soto-Gomez, Mauricio and Pashaeibarough, Ali and Malchiodi, Dario and Caufield, Harry and Reese, Justin and Mungall, Christopher J. and Robinson, Peter N. and Casiraghi, Elena and Valentini, Giorgio and Mesiti, Marco},
	title = {Initial achievements in relation extraction from RNA-focused scientific papers},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3741},
	pages = {61 – 69},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202018471&partnerID=40&md5=903a15b130d3508fdc1210b503158de3},
	abstract = {Relation extraction from the scientific literature to comply with a domain ontology is a well-known problem in natural language processing and is particularly critical in precision medicine. The advent of large language models (LLMs) has paved the way for the development of new effective approaches to this problem, but the extracted relations can be affected by issues such as hallucination, which must be minimized. In this paper, we present the initial design and preliminary experimental validation of SPIREX, an extension of the SPIRES-based system for the extraction of RDF triples from scientific literature involving RNA molecules. Our system exploits schema constraints in the formulations of LLM prompts along with our RNA-based KG, RNA-KG, for evaluating the plausibility of the extracted triples. RNA-KG contains more than 9M edges representing different kinds of relationships in which RNA molecules can be involved. Initial experimental results on a controlled data set are quite encouraging. © 2024 Copyright for this paper by its authors.},
	author_keywords = {Link Prediction; LLM; Prompt Engineering; relation discovery; RNA-based Knowledge Graphs},
	keywords = {Natural language processing systems; Ontology; Knowledge graphs; Language model; Large language model; Link prediction; Prompt engineering; Relation discovery; Relation extraction; RNA molecules; RNA-based knowledge graph; Scientific literature; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Nguyen20241327,
	author = {Nguyen, Dang-Anh-Khoa and Kha, Sang and Le, Thanh-Van},
	title = {HybridGCN: An Integrative Model for Scalable Recommender Systems with Knowledge Graph and Graph Neural Networks},
	year = {2024},
	journal = {International Journal of Advanced Computer Science and Applications},
	volume = {15},
	number = {5},
	pages = {1327 – 1337},
	doi = {10.14569/IJACSA.2024.01505134},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197897355&doi=10.14569%2fIJACSA.2024.01505134&partnerID=40&md5=7fdcec6ada4ee7de41c0e287fdb804b8},
	abstract = {Graph Neural Networks (GNNs) have emerged as a state-of-the-art approach in building modern Recommender Systems (RS). By leveraging the complex relationships among items, users, and their attributes, which can be represented as a Knowledge Graph (KG), these models can explore implicit semantic sub-structures within graphs, thereby enhancing the learning of user and item representations. In this paper, we propose an end-to-end architectural framework for developing recommendation models based on GNNs and KGs, namely HybridGCN. Our proposed methodologies aim to address three main challenges: (1) making graph-based RS scalable on large-scale datasets, (2) constructing domain-specific KGs from unstructured data sources, and (3) tackling the issue of incomplete knowledge in constructed KGs. To achieve these goals, we design a multistage integrated procedure, ranging from user segmentation and LLM-supported KG construction process to interconnectedly propagating between the KG and the Interaction Graph (IG). Our experimental results on a telecom e-commerce domain dataset demonstrate that our approach not only makes existing GNN-based recommender baselines feasible on large-scale data but also achieves comparative performance with the HybridGCN core. © (2024), (Science and Information Organization). All rights reserved.},
	author_keywords = {data segmentation; graph neural network; knowledge graph construction; Large-scale dataset processing; recommender systems},
	keywords = {Electronic commerce; Graph neural networks; Graphic methods; Knowledge graph; Knowledge management; Large datasets; Semantics; Data segmentation; Graph construction; Graph neural networks; In-buildings; Integrative modeling; Knowledge graph construction; Knowledge graphs; Large-scale dataset processing; Large-scale datasets; State-of-the-art approach; Recommender systems},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@CONFERENCE{Cavalleri20245639,
	author = {Cavalleri, Emanuele and Mesiti, Marco},
	title = {Construction and Enhancement of an RNA-Based Knowledge Graph for Discovering New RNA Drugs},
	year = {2024},
	journal = {Proceedings - International Conference on Data Engineering},
	pages = {5639 – 5643},
	doi = {10.1109/ICDE60146.2024.00453},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200506979&doi=10.1109%2fICDE60146.2024.00453&partnerID=40&md5=c83542641f53fe76ba87ddb4919a4884},
	abstract = {Cutting-edge technologies in RNA biology are pushing the study of fundamental biological processes and human diseases and accelerate the development of new drugs tailored to the patient's biomolecular characteristics. Even if many structured and unstructured data sources report the interaction among different RNA molecules and some other biomedical entities (e.g., drugs, diseases, genes), we still lack a comprehensive and well-described RNA-centered Knowledge Graph (KG) that contains such information and sophisticated services that support the user in its creation, maintenance, and enhancement. This PhD project aims to create a biomedical KG (named RNA-KG) to represent, and eventually infer, biological, experimentally validated interactions between different RNA molecules. We also wish to enhance the KG content and develop sophisticated services designed ad-hoc to support the user in predicting uncovered relationships and identifying new RNA-based drugs. Services will rely on deep learning methods that consider the heterogeneity of the graph and the presence of an ontology that describes the possible relationships existing among the involved entities. Moreover, we will consider Large Language Models (LLMs) in combination with RNA-KG for interacting with the user with the ground truth information contained in our KG for extracting relationships from unstructured data sources.  © 2024 IEEE.},
	author_keywords = {Biomedical knowledge graphs; Graph representation learning; LLMs; RNA therapeutics},
	keywords = {Bioinformatics; Deep learning; Drug interactions; Knowledge graph; Learning systems; Biomedical knowledge graph; Data-source; Graph representation; Graph representation learning; Knowledge graphs; Language model; Large language model; RNA molecules; RNA therapeutics; Unstructured data; RNA},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Anderson202414,
	author = {Anderson, Paul and Lin, Damon and Davidson, Jean and Migler, Theresa and Ho, Iris and Koenig, Cooper and Bittner, Madeline and Kaplan, Samuel and Paraiso, Mayumi and Buhn, Nasreen and Stokes, Emily and Anthony Hunt, C. and Ropella, Glen and Lotz, Jeffrey},
	title = {Bridging Domains in Chronic Lower Back Pain: Large Language Models and Ontology-Driven Strategies for Knowledge Graph Construction},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14849 LNBI},
	pages = {14 – 30},
	doi = {10.1007/978-3-031-64636-2_2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85203121027&doi=10.1007%2f978-3-031-64636-2_2&partnerID=40&md5=7bca64b45f3619f3541460ea7f8b3bb3},
	abstract = {Link prediction and entity resolution play pivotal roles in uncovering hidden relationships within networks and ensuring data quality in the era of heterogeneous data integration. This paper explores the utilization of large language models to enhance link prediction, particularly through knowledge graphs derived from transdisciplinary literature. Investigating zero-shot entity resolution techniques, we examine the impact of ontology-based and large language model approaches on the stability of link prediction results. Through a case study focusing on chronic lower back pain research, we analyze workflow decisions and their influence on prediction outcomes. Our research underscores the importance of robust methodologies in improving predictive accuracy and data integration across diverse domains. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {chronic lower back pain; entity resolution; Knowledge graphs; link prediction},
	keywords = {Data accuracy; Knowledge graph; Prediction models; Bridging domains; Chronic low back pain; Data quality; Entity resolutions; Graph construction; Heterogeneous data integrations; Knowledge graphs; Language model; Link prediction; Ontology's},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Azim2024,
	author = {Azim, Anee and Clark, Leon and Lau, Caleb and Cobb, Miles and Jenner, Kendall},
	title = {Grounding Ontologies with Pre-Trained Large Language Models for Activity Based Intelligence},
	year = {2024},
	journal = {Proceedings of SPIE - The International Society for Optical Engineering},
	volume = {13057},
	doi = {10.1117/12.3013332},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197783254&doi=10.1117%2f12.3013332&partnerID=40&md5=232985e878116a9d278f9c72140da966},
	abstract = {The development of Activity Based Intelligence (ABI) requires an understanding of individual actors’ intents, their interactions with other entities in the environment, and how these interactions facilitate accomplishment of their goals. Statistical modelling alone is insufficient for such analyses, mandating higher-level representations such as ontology to capture important relationships. However, constructing ontologies for ABI, ensuring they remain grounded to real-world entities, and maintaining their applicability to downstream tasks requires substantial hand-tooling by domain experts. In this paper, we propose the use of a Large Language Model (LLM) to bootstrap a grounding for such an ontology. Subsequently, we demonstrate that the experience encoded within the weights of a pre-trained LLM can be used in a zero-shot manner to provide a model of normalcy, enabling ABI analysis at the semantics level, agnostic to the precise coordinate data. This is accomplished through a sequence of two transformations, made upon a kinematic track, toward natural language narratives suitable for LLM input. The first transformation generates an abstraction of the low-level kinematic track, embedding it within a knowledge graph using a domain-specific ABI ontology. Secondly, we employ a template-driven narrative generation process to form natural language descriptions of behavior. Computation of the LLM perplexity score upon these narratives achieves grounding of the ontology. This use does not rely on any prompt engineering. In characterizing the perplexity score for any given track, we observe significant variability given chosen parameters such as sentence verbosity, attribute count, clause ordering, and so on. Consequently, we propose an approach that considers multiple generated narratives for an individual track and the distribution of perplexity scores for downstream applications. We demonstrate the successful application of this methodology against a semantic track association task. Our subsequent analysis establishes how such an approach can be used to augment existing kinematics-based association algorithms. © 2024 SPIE.},
	author_keywords = {Activity Based Intelligence; Large Language Model; Ontology; Track Association},
	keywords = {Computational linguistics; Kinematics; Knowledge graph; Semantics; Zero-shot learning; Activity based intelligences; Down-stream; Kinematics tracks; Language model; Large language model; Natural languages; Ontology's; Real-world entities; Statistic modeling; Track association; Ontology},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{2024,
	title = {1st International Workshop on Natural Scientific Language Processing and Research Knowledge Graphs, NSLP 2024},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14770 LNAI},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85202188206&partnerID=40&md5=0f16469eca8772bed7e9a6fb4dfdf8d5},
	abstract = {The proceedings contain 21 papers. The special focus in this conference is on Natural Scientific Language Processing and Research Knowledge Graphs. The topics include: Towards a Novel Classification of Table Types in Scholarly Publications; OCR Cleaning of Scientific Texts with LLMs; RTaC: A Generalized Framework for Tooling; scientific Software Citation Intent Classification Using Large Language Models; repoFromPaper: An Approach to Extract Software Code Implementations from Scientific Publications; Automated Extraction of Research Software Installation Instructions from README Files: An Initial Analysis; a Technical/Scientific Document Management Platform; the Effect of Knowledge Graph Schema on Classifying Future Research Suggestions; assessing the Overlap of Science Knowledge Graphs: A Quantitative Analysis; FoRC@NSLP2024: Overview and Insights from the Field of Research Classification Shared Task; NRK at FoRC 2024 Subtask I: Exploiting BERT-Based Models for Multi-class Classification of Scholarly Papers; advancing Automatic Subject Indexing: Combining Weak Supervision with Extreme Multi-label Classification; single-Label Multi-modal Field of Research Classification; Enriched BERT Embeddings for Scholarly Publication Classification; SOMD@NSLP2024: Overview and Insights from the Software Mention Detection Shared Task; Software Mention Recognition with a Three-Stage Framework Based on BERTology Models at SOMD 2024; ABCD Team at SOMD 2024: Software Mention Detection in Scholarly Publications with Large Language Models; falcon 7b for Software Mention Detection in Scholarly Documents; enhancing Software-Related Information Extraction via Single-Choice Question Answering with Large Language Models.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{2024,
	title = {20th International Conference on Intelligent Computing , ICIC 2024},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) },
	volume = {14881 LNBI},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85200957386&partnerID=40&md5=3e07b1a138184ff48429ecdfb0f57e5b},
	abstract = {The proceedings contain 80 papers. The special focus in this conference is on Intelligent Computing. The topics include: An Optimization Method for Drug Design Based on Molecular Features; application of Machine Learning and Large Language Model Module for Analyzing Gut Microbiota Data; CVAE-Based Hybrid Sampling Data Augmentation Method and Interpretation for Imbalanced Classification of Gout Disease; DepthParkNet: A 3D Convolutional Neural Network with Depth-Aware Coordinate Attention for PET-Based Parkinson's Disease Diagnosis; Gene Selection and Classification Method Based on SNR and Multi-loops BPSO; graph Convolutional Networks Based Multi-modal Data Integration for Breast Cancer Survival Prediction; IDHPre: Intradialytic Hypotension Prediction Model Based on Fully Observed Features; machine Learning Models for Improved Cell Screening; prediction of Bladder Cancer Prognosis by Deep Cox Proportional Hazards Model Based on Adversarial Autoencoder; SGEGCAE: A Sparse Gating Enhanced Graph Convolutional Autoencoder for Multi-omics Data Integration and Classification; short-Term Blood Glucose Prediction Method Based on Signal Decomposition and Bidirectional Networks; SLGNNCT: Synthetic Lethality Prediction Based on Knowledge Graph for Different Cancers Types; TransPBMIL: Transformer-Based Weakly Supervised Prognostic Prediction in Ovarian Cancer with Pseudo-Bag Strategy; a Heterogeneous Cross Contrastive Learning Method for Drug-Target Interaction Prediction; a Retrieval-Based Molecular Style Transformation Optimization Model; aggregation Strategy with Gradient Projection for Federated Learning in Diagnosis; coronary Artery 3D/2D Registration Based on Particle Swarm Optimization of Contextual Morphological Features; enhancing Drug-Drug Interaction Predictions in Biomedical Knowledge Graphs Through Integration of Householder Projections and Capsule Network Techniques; Feature Extraction Approach for Predicting Protein-DNA Binding Residues Using Transformer Encoder-Decoder Architecture.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{D'Souza20243163,
	author = {D'Souza, Jennifer and Kabongo, Salomon and Giglou, Hamed Babaei and Zhang, Yue},
	title = {Overview of the CLEF 2024 SimpleText Task 4: SOTA? Tracking the State-of-the-Art in Scholarly Publications},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3740},
	pages = {3163 – 3173},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201594943&partnerID=40&md5=77366eb6b336d5b6cff952fecde195bb},
	abstract = {This paper presents an overview of the CLEF 2024 SimpleText Task 4 on SOTA? Tracking the State-of-the-Art in Scholarly Publications, asking systems to perform two tasks: 1) classification - given the full text of an AI scientific paper, classify whether the paper indeed reports model scores on benchmark datasets, and if so, 2) information extraction - extract all pertinent (Task, Dataset, Metric, Score) tuples from the content of the scientific paper to automatically populate leaderboards used to keep track on the latest and greatest AI models. We discuss the details of the task set-up. First, the “SOTA?” task corpus comprising over 14K AI scientific papers, their corresponding annotations, and detailed corpus statistics. Second, the Evaluation Metrics used and the online Codalab Evaluation Platform to accept participant submissions. Third, the Results of the runs submitted by our participants. © 2024 Copyright for this paper by its authors.},
	author_keywords = {artificial intelligence; benchmarks; information extraction; large language models; leaderboards; natural language processing; open research knowledge graph; text mining},
	keywords = {Benchmarking; Classification (of information); Knowledge graph; Modeling languages; Natural language processing systems; Benchmark; Information extraction; Knowledge graphs; Language model; Language processing; Large language model; Leaderboard; Natural language processing; Natural languages; Open research knowledge graph; Text-mining; Information retrieval},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@ARTICLE{Naji2024100,
	author = {Naji, Mouncef and Masmoudi, Maroua and Baazaoui Zghal, Hajer},
	title = {A Novel Approach for Medical E-Consent: Leveraging Language Models for Informed Consent Management},
	year = {2024},
	journal = {Communications in Computer and Information Science},
	volume = {2144 CCIS},
	pages = {100 – 112},
	doi = {10.1007/978-981-97-5937-8_9},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85201949912&doi=10.1007%2f978-981-97-5937-8_9&partnerID=40&md5=f418724f51be41efbfc4a2e6aee85073},
	abstract = {In the context of healthcare, the issue of informed and voluntary consent stands a matter of paramount concern. Despite its stringent regulation within the medical field, the process of obtaining informed consent is frequently hindered by systemic, clinician-related, and patient-related factors, necessitating interventions at various levels. Notably, studies have shown that these factors often result in uninformed decisions, particularly in the context of hospitalization or intervention. This paper introduces a novel approach for enhancing the medical e-consent process by leveraging Large Language Models (LLMs) and knowledge graphs. The objective is to provide support during the consent process. Our proposal deal with 1) legal validation of consent documents for content clarity and comprehension verification; 2) personalization of content and interactions based on patient preferences and medical history; and 3) semantic reasoning integration into healthcare system information using knowledge graphs and ontologies. The overarching architectural objective of our proposal is to ensure a well-informed, adaptable, and legally valid consent process. Scenarios explaining the process based on data provided by our collaborators, is also detailed. The results show an improvement in the process and confirm the interest of the proposed LLM for informed consent management. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2024.},
	author_keywords = {E-consent; Healthcare Information Systems; knowledge graphs; Large Language Models},
	keywords = {Electronic health record; Modeling languages; Consent managements; E-consent; Healthcare information system; Knowledge graphs; Language model; Large language model; Medical fields; Personalizations; Related factors; Stringent regulations; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}@ARTICLE{Chen20249090,
	author = {Chen, Xingyu and Liu, Jiaxu and Liu, Zeyang and Wan, Lipeng and Lan, Xuguang and Zheng, Nanning},
	title = {Knowledge Graph Enhancement for Fine-Grained Zero-Shot Learning on ImageNet21K},
	year = {2024},
	journal = {IEEE Transactions on Circuits and Systems for Video Technology},
	volume = {34},
	number = {10},
	pages = {9090 – 9101},
	doi = {10.1109/TCSVT.2024.3396215},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192183890&doi=10.1109%2fTCSVT.2024.3396215&partnerID=40&md5=8843239ee7388d52ddc28716638c25cb},
	abstract = {Fine-grained Zero-shot Learning on the large-scale dataset ImageNet21K is an important task that has promising perspectives in many real-world scenarios. One typical solution is to explicitly model the knowledge passing using a Knowledge Graph (KG) to transfer knowledge from seen to unseen instances. By analyzing the hierarchical structure and the word descriptions on ImageNet21K, we find that the noisy semantic information, the sparseness of seen classes, and the lack of supervision of unseen classes make the knowledge passing insufficient, which limits the KG-based fine-grained ZSL. To resolve this problem, in this paper, we enhance the knowledge passing from three aspects. First, we use more powerful models such as the Large Language Model and Vision-Language Model to get more reliable semantic embeddings. Then we propose a strategy that globally enhances the knowledge graph based on the convex combination relationship of the semantic embeddings. It effectively connects the edges between the non-kinship seen and unseen classes that have strong correlations while assigning an importance score to each edge. Based on the enhanced knowledge graph, we further present a novel regularizer that locally enhances the knowledge passing during training. We extensively conducted comparative evaluations to demonstrate the advantages of our method over state-of-the-art approaches. © 1991-2012 IEEE.},
	author_keywords = {Fine-grained zero-shot learning; graph convolutional neural network; knowledge graph},
	keywords = {Computational linguistics; Computer vision; Graphic methods; Image enhancement; Job analysis; Knowledge graph; Neural networks; Timing circuits; Zero-shot learning; Circuits and systems; Convolutional neural network; Fine grained; Fine-grained zero-shot learning; Graph convolutional neural network; Graph-based; Knowledge graphs; Language model; Task analysis; Semantics},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Amorim202415761,
	author = {Amorim, Evelin and Campos, Ricardo and Jorge, Alípio and Mota, Pedro and Almeida, Rúben},
	title = {text2story: A Python Toolkit to Extract and Visualize Story Components of Narrative Text},
	year = {2024},
	journal = {2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation, LREC-COLING 2024 - Main Conference Proceedings},
	pages = {15761 – 15772},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195938411&partnerID=40&md5=835365614b9921f32c8e7c8977c650d4},
	abstract = {Story components, namely, events, time, participants, and their relations are present in narrative texts from different domains such as journalism, medicine, finance, and law. The automatic extraction of narrative elements encompasses several NLP tasks such as Named Entity Recognition, Semantic Role Labeling, Event Extraction, and Temporal Inference. The text2story Python, an easy-to-use modular library, supports the narrative extraction and visualization pipeline. The package contains an array of narrative extraction tools that can be used separately or in sequence. With this toolkit, end users can process free text in English or Portuguese and obtain formal representations, like standard annotation files or a formal logical representation. The toolkit also enables narrative visualization as Message Sequence Charts (MSC), Knowledge Graphs, and Bubble Diagrams, making it useful to visualize and transform human-annotated narratives. The package combines the use of off-the-shelf and custom tools and is easily patched (replacing existing components) and extended (e.g. with new visualizations). It includes an experimental module for narrative element effectiveness assessment and being is therefore also a valuable asset for researchers developing solutions for narrative extraction. To evaluate the baseline components, we present some results of the main annotators embedded in our package for datasets in English and Portuguese. We also compare the results with the extraction of narrative elements by GPT-3, a robust LLM model. © 2024 ELRA Language Resource Association: CC BY-NC 4.0.},
	author_keywords = {framework; information retrieval; narrative extraction; python; text annotation; toolkit},
	keywords = {Extraction; High level languages; Knowledge graph; Semantics; Visualization; Automatic extraction; Different domains; Events extractions; Framework; Named entity recognition; Narrative extraction; Semantic role labeling; Story components; Text annotations; Toolkit; Python},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Meem202413129,
	author = {Meem, Jannat Ara and Rashid, Muhammad Shihab and Dong, Yue and Hristidis, Vagelis},
	title = {PAT-Questions: A Self-Updating Benchmark for Present-Anchored Temporal Question-Answering},
	year = {2024},
	journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
	pages = {13129 – 13148},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196959448&partnerID=40&md5=6d56b08e5ab6a2717f95944799055323},
	abstract = {Existing work on Temporal Question Answering (TQA) has predominantly focused on questions anchored to specific timestamps or events (e.g. 'Who was the US president in 1970?'). Little work has studied questions whose temporal context is relative to the present time (e.g. 'Who was the previous US president?'). We refer to this problem as Present-Anchored Temporal QA (PATQA). PATQA poses unique challenges: (1) large language models (LLMs) may have outdated knowledge, (2) complex temporal relationships (e.g. 'before', 'previous') are hard to reason, (3) multi-hop reasoning may be required, and (4) the gold answers of benchmarks must be continuously updated. To address these challenges, we introduce the PAT-Questions benchmark, which includes single and multi-hop temporal questions. The answers in PAT-Questions can be automatically refreshed by re-running SPARQL queries on a knowledge graph, if available. We evaluate several state-of-the-art LLMs and a SOTA temporal reasoning model (TEMPREASON-T5) on PAT-Questions through direct prompting and retrieval-augmented generation (RAG). The results highlight the limitations of existing solutions in PATQA and motivate the need for new methods to improve PATQA reasoning capabilities. © 2024 Association for Computational Linguistics.},
	keywords = {Benchmarking; Computational linguistics; Problem oriented languages; Spatio-temporal data; Complex temporal relationships; Knowledge graphs; Language model; Multi-hops; Question Answering; Self-updating; Single hop; State of the art; Temporal questions; Time-stamp; Question answering},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{2024,
	title = {Workshop on Cognitive Aspects of the Lexicon, CogALex 2024 at LREC-COLING 2024 - Workshop Proceedings},
	year = {2024},
	journal = {Workshop on Cognitive Aspects of the Lexicon, CogALex 2024 at LREC-COLING 2024 - Workshop Proceedings},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195208755&partnerID=40&md5=2e51a712f619cec793267c9ace82e0a2},
	abstract = {The proceedings contain 19 papers. The topics discussed include: CLAVELL - cognitive linguistic annotation and visualization environment for language learning; individual text corpora predict openness, interests, knowledge and level of education; an empirical study on vague deictic temporal adverbials; symbolic learning of rules for semantic relation types identification in French genitive post-nominal prepositional phrases; idiom complexity in apple-pie order: the disentanglement of decomposability and transparency; can GPT-4 recover latent semantic relational information from word associations? a detailed analysis of agreement with human-annotated semantic ontologies; cross-linguistic processing of non-compositional expressions in Slavic languages; and representing abstract concepts with images: an investigation with large language models.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{El Ouadi2024,
	author = {El Ouadi, Ameir and Beskow, David},
	title = {Comparison of Common Crawl News & GDELT},
	year = {2024},
	journal = {SysCon 2024 - 18th Annual IEEE International Systems Conference, Proceedings},
	doi = {10.1109/SysCon61195.2024.10553540},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197361417&doi=10.1109%2fSysCon61195.2024.10553540&partnerID=40&md5=d3b93ccf23ea80473074b77e9018292e},
	abstract = {The corpus of worldwide news is important for natural language processing, knowledge graphs, large language models, and other technical efforts. Additionally, this corpus is important for understanding the people, places, organizations, and events that interact in real-time every day. This paper compares two news datasets used for these tasks today, namely the Global Database of Events, Language, and Tone (GDELT) and Common Crawl News. Our research highlights the strengths and limitations of each dataset, analyzing their content and coverage. Notably, while GDELT relies on broadcasts, prints, and web news from across the globe, Common Crawl focuses on news sites from around the world gathered through web crawling. Our analysis revealed considerable differences in where the two datasets gather their news sources.  © 2024 IEEE.},
	author_keywords = {LLMs; News Data; NLP; Open Source Data},
	keywords = {Knowledge graph; Web crawler; Global database; Knowledge graphs; Language model; Language processing; LLM; Natural languages; News data; Open source datum; Real- time; Technical efforts; Natural language processing systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Da Silva2024,
	author = {Da Silva, Luis Miguel Vieira and Köcher, Aljosha and Gehlhoff, Felix and Fay, Alexander},
	title = {On the Use of Large Language Models to Generate Capability Ontologies},
	year = {2024},
	journal = {IEEE International Conference on Emerging Technologies and Factory Automation, ETFA},
	doi = {10.1109/ETFA61755.2024.10710775},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197107836&doi=10.1109%2fETFA61755.2024.10710775&partnerID=40&md5=48dd75c57f8ce631b87a8b18ee212b15},
	abstract = {Capability ontologies are increasingly used to model functionalities of systems or machines. The creation of such onto-logical models with all properties and constraints of capabilities is very complex and can only be done by ontology experts. However, Large Language Models (LLMs) have shown that they can generate machine-interpretable models from natural language text input and thus support engineers / ontology experts. Therefore, this paper investigates how LLMs can be used to create capability ontologies. We present a study with a series of experiments in which capabilities with varying complexities are generated using different prompting techniques and with different LLMs. Errors in the generated ontologies are recorded and compared. To analyze the quality of the generated ontologies, a semi-automated approach based on RDF syntax checking, OWL reasoning, and SHACL constraints is used. The results of this study are very promising because even for complex capabilities, the generated ontologies are almost free of errors. © 2024 IEEE.},
	author_keywords = {Capabilities; Large Language Models; LLMs; Model-Generation; Ontologies; Semantic Web; Skills},
	keywords = {Computational linguistics; Natural language processing systems; Ontology; Capability; Language model; Large language model; Logical models; Model generation; Ontology's; Semantic-Web; Skill; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Green Open Access}
}

@ARTICLE{Sivarajkumar2024,
	author = {Sivarajkumar, Sonish and Gao, Fengyi and Denny, Parker and Aldhahwani, Bayan and Visweswaran, Shyam and Bove, Allyn and Wang, Yanshan},
	title = {Mining Clinical Notes for Physical Rehabilitation Exercise Information: Natural Language Processing Algorithm Development and Validation Study},
	year = {2024},
	journal = {JMIR Medical Informatics},
	volume = {12},
	doi = {10.2196/52289},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191372441&doi=10.2196%2f52289&partnerID=40&md5=84ea17bcd02dbeefa4cba59be2b3e3de},
	abstract = {Background: The rehabilitation of a patient who had a stroke requires precise, personalized treatment plans. Natural language processing (NLP) offers the potential to extract valuable exercise information from clinical notes, aiding in the development of more effective rehabilitation strategies. Objective: This study aims to develop and evaluate a variety of NLP algorithms to extract and categorize physical rehabilitation exercise information from the clinical notes of patients who had a stroke treated at the University of Pittsburgh Medical Center. Methods: A cohort of 13,605 patients diagnosed with stroke was identified, and their clinical notes containing rehabilitation therapy notes were retrieved. A comprehensive clinical ontology was created to represent various aspects of physical rehabilitation exercises. State-of-the-art NLP algorithms were then developed and compared, including rule-based, machine learning–based algorithms (support vector machine, logistic regression, gradient boosting, and AdaBoost) and large language model (LLM)–based algorithms (ChatGPT [OpenAI]). The study focused on key performance metrics, particularly F1-scores, to evaluate algorithm effectiveness. Results: The analysis was conducted on a data set comprising 23,724 notes with detailed demographic and clinical characteristics. The rule-based NLP algorithm demonstrated superior performance in most areas, particularly in detecting the “Right Side” location with an F1-score of 0.975, outperforming gradient boosting by 0.063. Gradient boosting excelled in “Lower Extremity” location detection (F1-score: 0.978), surpassing rule-based NLP by 0.023. It also showed notable performance in the “Passive Range of Motion” detection with an F1-score of 0.970, a 0.032 improvement over rule-based NLP. The rule-based algorithm efficiently handled “Duration,” “Sets,” and “Reps” with F1-scores up to 0.65. LLM-based NLP, particularly ChatGPT with few-shot prompts, achieved high recall but generally lower precision and F1-scores. However, it notably excelled in “Backward Plane” motion detection, achieving an F1-score of 0.846, surpassing the rule-based algorithm’s 0.720. Conclusions: The study successfully developed and evaluated multiple NLP algorithms, revealing the strengths and weaknesses of each in extracting physical rehabilitation exercise information from clinical notes. The detailed ontology and the robust performance of the rule-based and gradient boosting algorithms demonstrate significant potential for enhancing precision rehabilitation. These findings contribute to the ongoing efforts to integrate advanced NLP techniques into health care, moving toward predictive models that can recommend personalized rehabilitation treatments for optimal patient outcomes. © Sonish Sivarajkumar, Fengyi Gao, Parker Denny, Bayan Aldhahwani, Shyam Visweswaran, Allyn Bove, Yanshan Wang.},
	author_keywords = {artificial intelligence; ChatGPT; electronic health records; exercise; machine learning; natural language processing; physical exercise; physical rehabilitation; rehabilitation; rehabilitation therapy; stroke},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Iga2024168,
	author = {Iga, Vasile Ionut Remus and Silaghi, Gheorghe Cosmin},
	title = {LLMs for Knowledge-Graphs Enhanced Task-Oriented Dialogue Systems: Challenges and Opportunities},
	year = {2024},
	journal = {Lecture Notes in Business Information Processing},
	volume = {521},
	pages = {168 – 179},
	doi = {10.1007/978-3-031-61003-5_15},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196172848&doi=10.1007%2f978-3-031-61003-5_15&partnerID=40&md5=8cd6fd7c1ba9002d87e3bc5651a56636},
	abstract = {Large Language Models are a great tool for solving diverse tasks formulated in natural language. Recent work has demonstrated their capacity of solving tasks related to Knowledge Graphs, such as Knowledge Graph Completion or Knowledge Graph Reasoning, even in Zero- or Few-Shot paradigms. However, given a particular input, they do not always produce the same output, and sometimes point to intermediate reasoning steps that are not valid, even if they produce a satisfactorily answer. Moreover, the use of LLMs is mostly studied for static knowledge graphs, while temporal ones are overlooked. To highlight opportunities and challenges in knowledge graph related tasks, we experiment with ChatGPT on graph completion and reasoning for both static and temporal facets, using three different prompting techniques in Zero- and One-Shot contexts, on a Task-Oriented Dialogue system use case. Our results show that ChatGPT can solve given tasks, but mostly in a non-deterministic way. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {Knowledge Graph; Knowledge Graph Completion; Knowledge Graph Reasoning; Large Language Models; Task-Oriented Dialogue System},
	keywords = {Computational linguistics; Speech processing; Dialogue systems; Knowledge graph completion; Knowledge graph reasoning; Knowledge graphs; Language model; Large language model; Task-oriented; Task-oriented dialog system; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{2024,
	title = {16th JSAI International Symposia on Artificial Intelligence, JSAI-isAI 2024},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14741 LNAI},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195298229&partnerID=40&md5=cbe82788edf665af3ae3e622b171f2d9},
	abstract = {The proceedings contain 21 papers. The special focus in this conference is on Artificial Intelligence. The topics include: Research on Improving Decision-Making Efficiency with ChatGPT; Governing AI in Hiring: An Effort to Eliminate Biased Decision; navigating the Artificial Intelligence Dilemma: Exploring Paths for Norway’s Future; addressing Annotated Data Scarcity in Legal Information Extraction; enhancing Legal Argument Retrieval with Optimized Language Model Techniques; Overview of Benchmark Datasets and Methods for the Legal Information Extraction/Entailment Competition (COLIEE) 2024; CAPTAIN at COLIEE 2024: Large Language Model for Legal Text Retrieval and Entailment; LLM Tuning and Interpretable CoT: KIS Team in COLIEE 2024; similarity Ranking of Case Law Using Propositions as Features; pushing the Boundaries of Legal Information Processing with Integration of Large Language Models; NOWJ@COLIEE 2024: Leveraging Advanced Deep Learning Techniques for Efficient and Effective Legal Information Processing; AMHR COLIEE 2024 Entry: Legal Entailment and Retrieval; towards an In-Depth Comprehension of Case Relevance for Better Legal Retrieval; improving Robustness in Language Models for Legal Textual Entailment Through Artifact-Aware Training; a Framework for Enhancing Statute Law Retrieval Using Large Language Models; vietnamese Elementary Math Reasoning Using Large Language Model with Refined Translation and Dense-Retrieved Chain-of-Thought; texylon: Dataset of Log-to-Description and Description-to-Log Generation for Text Analytics Tools; semantic Parsing for Question and Answering over Scholarly Knowledge Graph with Large Language Models; Improving LLM Prompting with Ensemble of Instructions: A Case Study on Sentiment Analysis.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Li20242481,
	author = {Li, Jiakai and Hu, Jianpeng and Zhang, Geng},
	title = {Enhancing Relational Triple Extraction in Specific Domains: Semantic Enhancement and Synergy of Large Language Models and Small Pre-Trained Language Models},
	year = {2024},
	journal = {Computers, Materials and Continua},
	volume = {79},
	number = {2},
	pages = {2481 – 2503},
	doi = {10.32604/cmc.2024.050005},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193065505&doi=10.32604%2fcmc.2024.050005&partnerID=40&md5=563a84575c631c652eb1adc67b69db46},
	abstract = {In the process of constructing domain-specific knowledge graphs, the task of relational triple extraction plays a critical role in transforming unstructured text into structured information. Existing relational triple extraction models face multiple challenges when processing domain-specific data, including insufficient utilization of semantic interaction information between entities and relations, difficulties in handling challenging samples, and the scarcity of domain-specific datasets. To address these issues, our study introduces three innovative components: Relation semantic enhancement, data augmentation, and a voting strategy, all designed to significantly improve the model’s performance in tackling domain-specific relational triple extraction tasks. We first propose an innovative attention interaction module. This method significantly enhances the semantic interaction capabilities between entities and relations by integrating semantic information from relation labels. Second, we propose a voting strategy that effectively combines the strengths of large language models (LLMs) and fine-tuned small pre-trained language models (SLMs) to reevaluate challenging samples, thereby improving the model’s adaptability in specific domains. Additionally, we explore the use of LLMs for data augmentation, aiming to generate domain-specific datasets to alleviate the scarcity of domain data. Experiments conducted on three domain-specific datasets demonstrate that our model outperforms existing comparative models in several aspects, with F1 scores exceeding the State of the Art models by 2%, 1.6%, and 0.6%, respectively, validating the effectiveness and generalizability of our approach. © 2024 Tech Science Press. All rights reserved.},
	author_keywords = {data augmentation; large language models; Relational triple extraction; semantic interaction; specific domains},
	keywords = {Computational linguistics; Data handling; Data mining; Domain Knowledge; Knowledge graph; Natural language processing systems; Semantics; Data augmentation; Domain semantics; Domain specific; Language model; Large language model; Relational triple extraction; Semantic enhancements; Semantic interactions; Specific domain; Voting strategies; Extraction},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Lee2024,
	author = {Lee, Chang-Shing and Wang, Mei-Hui and Chiang, Jun-Kui and Kubota, Naoyuki and Sato-Shimokawara, Eri and Nojima, Yusuke and Acampora, Giovanni and Wu, Pei-Yu and Chiu, Szu-Chi and Yang, Sheng-Chi and Siow, Chyan-Zheng},
	title = {Quantum Computational Intelligence with Generative AI Image for Human-Machine Interaction},
	year = {2024},
	journal = {IEEE International Conference on Fuzzy Systems},
	doi = {10.1109/FUZZ-IEEE60900.2024.10611970},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191275657&doi=10.1109%2fFUZZ-IEEE60900.2024.10611970&partnerID=40&md5=ade4540c643c56b940fff9c96cd8e88b},
	abstract = {This paper introduces a Quantum Computational Intelligence (QCI) agent equipped with a content attention ontology model, specifically designed to enhance human-machine interaction based on a Generative Artificial Intelligence (GAI) image generation agent for Taiwanese/English learning and experience. Its diverse primary applications include social media analysis on Facebook groups and YouTube learning videos related to the 2023 IEEE CIS Education Portal (EP) Subcommittee, as well as in the areas of Taiwanese/English language learning and dialogue experience with GAI image generation. To establish the knowledge and inference models for the QCI agent, we initially developed a Taiwanese/English learning and experience ontology, including a content attention ontology, and an image attention ontology. The QCI agent utilizes metrics such as the number of views, posts, and comments to predict the fuzzy number of reactions. In addition, the GAI image agent generates Taiwanese speech-based/English text-based images and evaluates the fuzzy similarity score between Taiwanese/English and the attention ontology together with the Sentence BERT (SBERT) agent. This Taiwanese/English fuzzy similarity score is further validated through human assessments, with these evaluations subsequently serving as an additional metric for comparative analysis of Human-Machine Interaction (HMI). Furthermore, the GAI image agent is designed to create images and Chinese/English texts from text/speech translated by the Meta AI Universal Speech Translator (UST) Taiwanese/English agent. A Particle Swarm Optimization (PSO)-based machine learning mechanism is employed to train the QCI model for assessing learners' performance and predicting the performance of others. The National University of Tainan (NUTN) Taiwan-Large Language Model (NUTN.TW-LLM) agent has been further enhanced to support interactive learning experiences for HMI. An SBERT-based assessment agent is used to calculate fuzzy similarities between questions and answers in Taiwanese/English experiences and dialogues. Experimental results demonstrate the feasibility and efficacy of the proposed QCI model, equipped with QCI&AI-FML (Artificial Intelligence-Fuzzy Markup Language) and machine learning capabilities, for social media and language learning applications on HMI. In the future, we will extend the QCI model to various HMI applications for student learning around the world. © 2024 IEEE.},
	author_keywords = {ChatGPT; Content Attention Ontology; Fuzzy Markup Language; Generative AI Image Agent; IEEE CIS Education Portal; NUTN.TW-LLM; Quantum CI Agent; Sentence BERT},
	keywords = {Computational linguistics; Computer aided language translation; Curricula; Fuzzy inference; Fuzzy rules; Gene transfer; Intelligent systems; Machine learning; Motion estimation; Neural networks; Personnel training; Problem oriented languages; Semantics; SGML; Students; Swarm intelligence; Syntactics; ChatGPT; CI-Agent; Content attention ontology; Education portals; Fuzzy markup languages; Generative AI image agent; IEEE CIS education portal; National university of tainan.; Ontology's; Quantum CI agent; Sentence BERT; TW-LLM; Speech enhancement},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{2024,
	title = {36th International Conference on Advanced Information Systems Engineering, CAiSE 2024},
	year = {2024},
	journal = {Lecture Notes in Business Information Processing},
	volume = {520 LNBIP},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195536573&partnerID=40&md5=60130c44ff2f52a3ec44b235618e92fd},
	abstract = {The proceedings contain 18 papers. The special focus in this conference is on Advanced Information Systems Engineering. The topics include: Incorporating Behavioral Recommendations Mined from Event Logs into AI Planning; trustworthy Collaborative Business Intelligence Using Zero-Knowledge Proofs and Blockchains; Towards Intelligent Systems to Improve IEC 62559 Use Cases and Smart Grid Architecture Models Quality; pricing4SaaS: Towards a Pricing Model to Drive the Operation of SaaS; Validity at the Forefront: Investigating Threats in Green AI Research; requirement-Based Methodological Steps to Identify Ontologies for Reuse; Toward Ontology-Guided IFRS Standard-Setting; towards an Explorable Conceptual Map of Large Language Models; proReco: A Process Discovery Recommender System; recPro: A User-Centric Recommendation Tool for Business Process Execution; predictive Maintenance in a Fleet Management System: The Navarchos Case; CDMiA: Revealing Impacts of Data Migrations on Schemas in Multi-model Systems; MApp-KG: Mobile App Knowledge Graph for Document-Based Feature Knowledge Generation; CAKE: Sharing Slices of Confidential Data on Blockchain; PADI-web for Plant Health Surveillance; PROMISE: A Framework for Model-Driven Stateful Prompt Orchestration.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{2024,
	title = {SDS 2024 - Proceedings of the 2nd International Workshop on Semantics in Dataspaces, co-located with the 21st Extended Semantic Web Conference, ESWC 2024},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3705},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196272181&partnerID=40&md5=eee30806c543d90bfd980b0d68b5be23},
	abstract = {The proceedings contain 13 papers. The topics discussed include: FAIRness in dataspaces: the role of semantics for data management; the rights delegation proxy: an approach for delegations in the solid dataspace; towards LLM-augmented creation of semantic models for dataspaces; inter-pod credential exchange protocol via linked data notifications; selective disclosure of digital calibration certificate in a quality infrastructure data space; adapting ontology-based data access for data spaces; linking of open and private data in dataspace: a case study of air quality monitoring and forecasting; towards enabling FAIR dataspaces using large language models; interoperable and continuous usage control enforcement in dataspaces; and challenges and opportunities for enabling the next generation of cross-domain dataspaces.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{2024,
	title = {1st Workshop on Bridging Neurons and Symbols for Natural Language Processing and Knowledge Graphs Reasoning, NeusymBridge 2024 at LREC-COLING 2024 - Workshop Proceedings},
	year = {2024},
	journal = {1st Workshop on Bridging Neurons and Symbols for Natural Language Processing and Knowledge Graphs Reasoning, NeusymBridge 2024 at LREC-COLING 2024 - Workshop Proceedings},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195185675&partnerID=40&md5=43d581e5e73ce4a834fe2d29a81ebfe6},
	abstract = {The proceedings contain 5 papers. The topics discussed include: probing large language models from a human behavioral perspective; the semantic relations in LLMs: an information-theoretic compression approach; word sense disambiguation as a game of neurosymbolic darts; open event causality extraction by the assistance of LLM in task annotation, dataset, and method; and the need for grounding in LLM-based dialogue systems.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Jokinen202445,
	author = {Jokinen, Kristiina},
	title = {The Need for Grounding in LLM-based Dialogue Systems},
	year = {2024},
	journal = {1st Workshop on Bridging Neurons and Symbols for Natural Language Processing and Knowledge Graphs Reasoning, NeusymBridge 2024 at LREC-COLING 2024 - Workshop Proceedings},
	pages = {45 – 52},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195179717&partnerID=40&md5=3822a9e3b8d6f18994616f0fafbe0cc2},
	abstract = {Grounding is a pertinent part of the design of LLM-based dialogue systems. Although research on grounding has a long tradition, the paradigm shift caused by LLMs has brought the concept onto the foreground, in particular in the context of cognitive robotics. To avoid generation of irrelevant or false information, the system needs to ground its utterances into real-world events, and to avoid the statistical parrot effect, the system needs to construct shared understanding of the dialogue context and of the partner’s intents. Grounding and construction of the shared context enables cooperation between the participants, and thus supports trustworthy interaction. This paper discusses grounding using neural LLM technology. It aims to bridge neural and symbolic computing on the cognitive architecture level, so as to contribute to a better understanding of how conversational reasoning and collaboration can be linked to LLM implementations to support trustworthy and flexible interaction. © 2024 ELRA Language Resource Association.},
	author_keywords = {conversational AI; grounding; knowledge graphs; language-capable robots; large language models; spoken dialogue systems; Theory of Mind},
	keywords = {Computation theory; Knowledge graph; Cognitive robotics; Conversational AI; Dialogue systems; Knowledge graphs; Language model; Language-capable robot; Large language model; Paradigm shifts; Spoken dialogue system; Theory of minds; Speech processing},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Zhang2024197,
	author = {Zhang, Hao and Mohammed, Abrar and Dimitrova, Vania},
	title = {Weakly Supervised Short Text Classification for Characterising Video Segments},
	year = {2024},
	journal = {International Conference on Computer Supported Education, CSEDU - Proceedings},
	volume = {2},
	pages = {197 – 204},
	doi = {10.5220/0012618600003693},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193977562&doi=10.5220%2f0012618600003693&partnerID=40&md5=50d4e3e75084b058481b67d6e27d56e1},
	abstract = {In this age of life-wide learning, video-based learning has increasingly become a crucial method of education. However, the challenge lies in watching numerous videos and connecting key points from these videos with relevant study domains. This requires video characterization. Existing research on video characterization focuses on manual or automatic methods. These methods either require substantial human resources (experts to identify domain related videos and domain related areas in the videos) or rely on learner input (by relating video parts to their learning), often overlooking the assessment of their effectiveness in aiding learning. Manual methods are subjective, prone to errors and time consuming. Automatic supervised methods require training data which in many cases is unavailable. In this paper we propose a weakly supervised method that utilizes concepts from an ontology to guide models in thematically classifying and characterising video segments. Our research is concentrated in the health domain, conducting experiments with several models, including the large language model GPT-4. The results indicate that CorEx significantly outperforms other models, while GLDA and Guided BERTopic show limitations in this task. Although GPT-4 demonstrates consistent performance, it still falls behind CorEx. This study offers an innovative perspective in video-based learning, especially in automating the detection of learning themes in video content. Copyright © 2024 by SCITEPRESS – Science and Technology Publications, Lda.},
	author_keywords = {Large Language Model; Video-Based Learning; Weakly Supervised Text Classification},
	keywords = {Classification (of information); Computational linguistics; Computer vision; Learning systems; Supervised learning; Text processing; Language model; Large language model; Manual methods; Short text classifications; Supervised methods; Text classification; Video characterization; Video segments; Video-based learning; Weakly supervised text classification; Image segmentation},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{2024,
	title = {Disruptive Technologies in Information Sciences VIII},
	year = {2024},
	journal = {Proceedings of SPIE - The International Society for Optical Engineering},
	volume = {13058},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196518388&partnerID=40&md5=7e526888240e22dd8a41e4c8298122c1},
	abstract = {The proceedings contain 38 papers. The topics discussed include: HALO: an ontology for representing and categorizing hallucinations in large language models; adaptive object detection algorithms for resource constrained autonomous robotic systems; methodology of soft partition for image classification; circumventing broken neural networks, both real and imaginary, through SPSF-based neural decoding and interconnected associative memory matrices; latency-aware service placement for Genai at the edge; risk considerations for the department of defense’s fielding of large language models; quantifying decision complexity in IADS operations; combining AI control systems and human decision support via robustness and criticality; and situational awareness on a graph: towards graph neural networks for spectrum analysis and battlefield management.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{De Deyne202468,
	author = {De Deyne, Simon and Liu, Chunhua and Frermann, Lea},
	title = {Can GPT-4 Recover Latent Semantic Relational Information from Word Associations? A Detailed Analysis of Agreement with Human-annotated Semantic Ontologies},
	year = {2024},
	journal = {Workshop on Cognitive Aspects of the Lexicon, CogALex 2024 at LREC-COLING 2024 - Workshop Proceedings},
	pages = {68 – 78},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195200635&partnerID=40&md5=52eb858d22ac985b39a0b3e6f7929335},
	abstract = {Word associations, i.e., spontaneous responses to a cue word, provide not only a window into the human mental lexicon but have also been shown to be a repository of common-sense knowledge and can underpin efforts in lexicography and the construction of dictionaries. Especially the latter tasks require knowledge about the relations underlying the associations (e.g., Taxonomic vs. Situational); however, to date, there is neither an established ontology of relations nor an effective labelling paradigm. Here, we test GPT-4’s ability to infer semantic relations for human-produced word associations. We use four human-labelled data sets of word associations and semantic features, with differing relation inventories and various levels of annotator agreement. We directly prompt GPT-4 with detailed relation definitions without further fine-tuning or training. Our results show that while GPT-4 provided a good account of higher-level classifications (e.g., Taxonomic vs Situational), prompting instructions alone cannot obtain similar performance for detailed classifications (e.g., superordinate, subordinate or coordinate relations) despite high agreement among human annotators. This suggests that latent relations can at least be partially recovered from word associations and highlights ways in which LLMs could be improved and human annotation protocols could adapted to reduce coding ambiguity. © 2024 ELRA Language Resource Association.},
	author_keywords = {Large language models; semantic relations; word associations},
	keywords = {Ontology; Commonsense knowledge; Labeled data; Labelings; Language model; Large language model; Latent semantics; Ontology's; Semantic ontology; Semantic relations; Word-association; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Ogawa2024294,
	author = {Ogawa, Tomohiro and Yoshioka, Kango and Fukuda, Ken and Morita, Takeshi},
	title = {Prediction of actions and places by the time series recognition from images with Multimodal LLM},
	year = {2024},
	journal = {Proceedings - IEEE International Conference on Semantic Computing, ICSC},
	pages = {294 – 300},
	doi = {10.1109/ICSC59802.2024.00053},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192266625&doi=10.1109%2fICSC59802.2024.00053&partnerID=40&md5=e7917cebd8a920bee2ceee1a460ca5fe},
	abstract = {In recent years, the risk of accidents in the homes of older adults in an aging society has increased, and there is a need to address this problem. We took up the challenge of utilising explainable AI techniques to identify accident risks at home and suggest safer alternatives. This study combined knowledge graphs and large-scale language models to solve real-world problems. Specifically, we addressed answering questions using a multimodal dataset of videos recording daily activities and a knowledge graph. The dataset represents the living activities in the virtual space and provides environmental information. The task is divided into two main tasks. Task 1 utilises knowledge graph to answer direct questions and processes the data using SPARQL queries. Task 2 addresses more complex questions that cannot be answered by search alone. Consequently, in Task 1, the system could answer all questions using information from the SPARQL knowledge graph. In Task 2, a certain degree of success was achieved for complex questions by reasoning with images created by concatenating multimodal LLMs and time-series images. The source code used in the experiment is available at https://github.com/tomo1115tomo/kg_reasoning_challenge.  © 2024 IEEE.},
	author_keywords = {Knowledge Graph Reasoning Challenge},
	keywords = {Accidents; Query processing; Time series; Accident risks; Aging societies; AI techniques; Complex questions; Knowledge graph reasoning challenge; Knowledge graphs; Multi-modal; Older adults; Risk of accidents; Time series recognition; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Romanyshyn202451,
	author = {Romanyshyn, Nataliia and Chaplynskyi, Dmytro and Romanyshyn, Mariana},
	title = {Automated Extraction of Hypo-Hypernym Relations for the Ukrainian WordNet},
	year = {2024},
	journal = {3rd Ukrainian Natural Language Processing Workshop, UNLP 2024 at LREC-COLING 2024 - Workshop Proceedings},
	pages = {51 – 60},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195201848&partnerID=40&md5=16c677bffb6b68022a75edcf3d9625c0},
	abstract = {WordNet is a crucial resource in linguistics and natural language processing, providing a detailed and expansive set of lexico-semantic relationships among words in a language. The trend toward automated construction and expansion of WordNets has become increasingly popular due to the high costs of manual development. This study aims to automate the development of the Ukrainian WordNet, explicitly concentrating on hypo-hypernym relations that are crucial building blocks of the hierarchical structure of WordNet. Utilizing the linking between Princeton WordNet, Wikidata, and multilingual resources from Wikipedia, the proposed approach successfully mapped 17% of Princeton WordNet (PWN) content to Ukrainian Wikipedia. Furthermore, the study introduces three innovative strategies for generating new entries to fill in the gaps of the Ukrainian WordNet: machine translation, the Hypernym Discovery model, and the Hypernym Instruction-Following LLaMA model. The latter model shows a high level of effectiveness, evidenced by a 41.61% performance on the Mean Overlap Coefficient (MOC) metric. With the proposed approach that combines automated techniques with expert human input, we provide a reliable basis for creating the Ukrainian WordNet. © 2024 ELRA Language Resource Association: CC BY-NC 4.0.},
	author_keywords = {Hypernym Discovery; Large Language Models; Lexicography; Ukrainian; WordNet},
	keywords = {Automation; Computational linguistics; Natural language processing systems; Ontology; Automated extraction; Hypernym discovery; Language model; Language processing; Large language model; Lexicography; Natural languages; Ukrainian; Wikipedia; Wordnet; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Procko2024207,
	author = {Procko, Tyler Thomas and Ochoa, Omar},
	title = {Semantic Science: Publication beyond the PDF},
	year = {2024},
	journal = {Conference Proceedings - IEEE SOUTHEASTCON},
	pages = {207 – 215},
	doi = {10.1109/SoutheastCon52093.2024.10500258},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191705922&doi=10.1109%2fSoutheastCon52093.2024.10500258&partnerID=40&md5=ddff918f648af4dd361bba59172e9ac2},
	abstract = {Scientific papers have evolved since the establishment of the Royal Society in the mid-17th century. Today, despite the interconnectedness of Internet discourse, scientific papers are released as relatively static, inflexible artifacts, to wit, as Portable Document Format (PDF) files. This fact is an egregious slight to the base principle of science: that it is to be mutable and evolutionary. Thus, the present paper proposes a means of writing scientific papers that allows for change and explicit connection to other papers, through the use of (1) Linked Data knowledge graphs, (2) the Findable-Accessible-Interoperable-Reusable (FAIR) data principles, (3) the Markdown language, and (4) OpenAI's Large Language Model, the Generative Pre-trained Transformer, GPT -4. A handful of extant tools exist; these will be introduced in turn. The present paper cogently synthesizes the topic at hand and calls for science to be semantic.  © 2024 IEEE.},
	author_keywords = {FAIR data; GPT; knowledge graphs; scientific writing},
	keywords = {Semantics; Explicit connections; Findable-accessible-interoperable-reusable data; GPT; Knowledge graphs; Linked datum; Portable document format files; Portable document formats; Royal society; Scientific papers; Scientific writing; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Song20246962,
	author = {Song, Yaoxian and Sun, Penglei and Liu, Haoyu and Li, Zhixu and Song, Wei and Xiao, Yanghua and Zhou, Xiaofang},
	title = {Scene-Driven Multimodal Knowledge Graph Construction for Embodied AI},
	year = {2024},
	journal = {IEEE Transactions on Knowledge and Data Engineering},
	volume = {36},
	number = {11},
	pages = {6962 – 6976},
	doi = {10.1109/TKDE.2024.3399746},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193545813&doi=10.1109%2fTKDE.2024.3399746&partnerID=40&md5=c22f086be5c09b7e32fffa1ac88e9e86},
	abstract = {Embodied AI is one of the most popular studies in artificial intelligence and robotics, which can effectively improve the intelligence of real-world agents (i.e. robots) serving human beings. Scene knowledge is important for an agent to understand the surroundings and make correct decisions in the varied open world. Currently, knowledge base for embodied tasks is missing and most existing work use general knowledge base or pre-trained models to enhance the intelligence of an agent. For conventional knowledge base, it is sparse, insufficient in capacity and cost in data collection. For pre-trained models, they face the uncertainty of knowledge and hard maintenance. To overcome the challenges of scene knowledge, we propose a scene-driven multimodal knowledge graph (Scene-MMKG) construction method combining conventional knowledge engineering and large language models. A unified scene knowledge injection framework is introduced for knowledge representation. To evaluate the advantages of our proposed method, we instantiate Scene-MMKG considering typical indoor robotic functionalities (Manipulation and Mobility), named ManipMob-MMKG. Comparisons in characteristics indicate our instantiated ManipMob-MMKG has broad superiority on data-collection efficiency and knowledge quality. Experimental results on typical embodied tasks show that knowledge-enhanced methods using our instantiated ManipMob-MMKG can improve the performance obviously without re-designing model structures complexly.  © 2024 IEEE.},
	author_keywords = {embodied AI; Multimodal knowledge graph; robotic intelligence; scene driven},
	keywords = {Data acquisition; Intelligent robots; Job analysis; Model structures; Data collection; Embodied AI; Knowledge graphs; Knowledge-based systems; Multi-modal; Multimodal knowledge graph; Robotic intelligence; Scene driven; Task analysis; Knowledge graph},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Green Open Access}
}

@ARTICLE{Sartini202457,
	author = {Sartini, Bruno},
	title = {IICONGRAPH: Improved Iconographic and Iconological Statements in Knowledge Graphs},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14665 LNCS},
	pages = {57 – 74},
	doi = {10.1007/978-3-031-60635-9_4},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195301184&doi=10.1007%2f978-3-031-60635-9_4&partnerID=40&md5=13de00b754ad5aabf7dfa04ae65e52ed},
	abstract = {Iconography and iconology are fundamental domains when it comes to understanding artifacts of cultural heritage (CH). Iconography deals with the study and interpretation of visual elements depicted in artifacts and their symbolism, while iconology delves deeper, exploring the underlying cultural and historical meanings. Despite the advances in representing CH with Linked Open Data (LOD), recent studies show persistent gaps in the representation of iconographic and iconological statements in current knowledge graphs (KGs). To address them, this paper presents IICONGRAPH, a KG that was created by refining and extending the iconographic and iconological statements of ArCo (the Italian KG of CH) and Wikidata. The development of IICONGRAPH was also driven by a series of requirements emerging from research case studies expressed in competency questions (CQs) that were unattainable in the non-reengineered versions of the KGs. The evaluation results demonstrate that IICONGRAPH not only outperforms ArCo and Wikidata through domain-specific assessments from the literature but also serves as a robust platform for answering the formulated CQs. IICONGRAPH is released and documented in accordance with the FAIR principles to guarantee the resource’s reusability. The algorithms used to create it and assess the CQs have also been made available to ensure transparency and reproducibility. While future work focuses on ingesting more data into the KG, and on implementing it as a backbone of LLM-based question answering systems, the current version of IICONGRAPH still emerges as a valuable asset, contributing to the evolving landscape of CH representation within KGs, the Semantic Web, and beyond. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {Cultural Heritage; Digital Humanities; Iconography; Iconology; Knowledge Graph; Knowledge Graph Generation; Symbolism},
	keywords = {Linked data; Open Data; Reusability; 'current; Cultural heritages; Digital humanities; Graph generation; Iconography; Iconology; Knowledge graph generation; Knowledge graphs; Symbolism; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Shichman20241,
	author = {Shichman, Mollie and Bonial, Claire and Hudson, Taylor and Blodgett, Austin and Ferraro, Francis and Rudinger, Rachel},
	title = {PropBank-Powered Data Creation: Utilizing Sense-Role Labelling to Generate Disaster Scenario Data},
	year = {2024},
	journal = {5th International Workshop on Designing Meaning Representation, DMR 2024 at LREC-COLING 2024 - Workshop Proceedings},
	pages = {1 – 10},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195120613&partnerID=40&md5=66650431c3d8a76710b527a23e8673ae},
	abstract = {For human-robot dialogue in a search-and-rescue scenario, a strong knowledge of the conditions and objects a robot will face is essential for effective interpretation of natural language instructions. In order to utilize the power of large language models without overwhelming the limited storage capacity of a robot, we propose PropBank-Powered Data Creation. PropBank-Powered Data Creation is an expert-in-the-loop data generation pipeline which creates training data for disaster-specific language models. We leverage semantic role labeling and Rich Event Ontology resources to efficiently develop seed sentences for fine-tuning a smaller, targeted model that could operate onboard a robot for disaster relief. We developed 32 sentence templates, which we used to make 2 seed datasets of 175 instructions for earthquake search and rescue and train derailment response. We further leverage our seed datasets as evaluation data to test our baseline fine-tuned models. © 2024 ELRA Language Resource Association.},
	author_keywords = {Fine-tuning; Object Affordances; PropBank; Synthetic Data Creation},
	keywords = {Computational linguistics; Disaster prevention; Disasters; Robots; Semantics; Affordances; Data creation; Fine tuning; Labelings; Language model; Object affordance; Propbank; Search and rescue; Synthetic data; Synthetic data creation; Digital storage},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Stewart Kirubakaran20241128,
	author = {Stewart Kirubakaran, S. and Jasper Wilsie Kathrine, G. and Grace Mary Kanaga, E. and Mahimai Raja, J. and Ruban Gino Singh, A. and Yuvaraajan, E.},
	title = {A RAG-based Medical Assistant Especially for Infectious Diseases},
	year = {2024},
	journal = {7th International Conference on Inventive Computation Technologies, ICICT 2024},
	pages = {1128 – 1133},
	doi = {10.1109/ICICT60155.2024.10544639},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196085291&doi=10.1109%2fICICT60155.2024.10544639&partnerID=40&md5=bb3a836c6ff60ba0657bb461751d08dd},
	abstract = {Infectious diseases like COVID-19 have gained international attention recently. Furthermore, there are significantly fewer doctors per capita in densely populated nations like India, which hurts those in need. Under such circumstances, natural language processing techniques might make it feasible to create an intelligent and engaging chatbot system. The primary objective of the effort is to develop an interactive solution that is entirely open source and can be easily installed on a local computer using the most recent data. Even though there are numerous chatbots on the market, proposed solutions highlight the need to provide individualized and sympathetic responses. Getting Back While the data is stored in the graph database as nodes and relationships, and the knowledge graph is constructed on top of it, augmented generation is utilized to extract the pertinent content from the data. To improve the generator's context, pertinent sections are collected during the question-answering process. This reduces hallucinations and increases the correctness of abstractions by providing external knowledge streams. Furthermore, the research study employs a text-to-speech model that was replicated from a physician's voice recording to narrate the produced responses, thereby augmenting user confidence and interaction. Academic institutions and healthcare organizations can benefit from this work by better understanding the value and effectiveness of applying NLP techniques to infectious disease research.  © 2024 IEEE.},
	author_keywords = {chatbot; COVID-19; knowledge graph; large language model; natural language processing; retrieval augmented generation},
	keywords = {Graph Databases; Knowledge graph; Natural language processing systems; Open systems; Chatbots; Infectious disease; Knowledge graphs; Language model; Language processing; Large language model; Natural language processing; Natural languages; Per capita; Retrieval augmented generation; COVID-19},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Bertetto202482,
	author = {Bertetto, Lorenzo and Bettinelli, Francesca and Buda, Alessio and Da Mommio, Marco and Di Bari, Simone and Savelli, Claudio and Baralis, Elena and Bernasconi, Anna and Cagliero, Luca and Ceri, Stefano and Pierri, Francesco},
	title = {Towards an Explorable Conceptual Map of Large Language Models},
	year = {2024},
	journal = {Lecture Notes in Business Information Processing},
	volume = {520 LNBIP},
	pages = {82 – 90},
	doi = {10.1007/978-3-031-61000-4_10},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195581310&doi=10.1007%2f978-3-031-61000-4_10&partnerID=40&md5=e7ae63d495075dae72de8623bab3cc32},
	abstract = {Large Language Models (LLMs) have revolutionized the current landscape of Natural Language Processing, enabling unprecedented advances in text generation, translation, summarization, and more. Currently, limited efforts have been devoted to providing a high-level and systematic description of their properties. Today’s primary source of information is the Hugging Face (HF) catalog, a rich digital repository for researchers and developers. Although it hosts several models, datasets, and applications, its underlying data model supports limited exploration of linked information. In this work, we propose a conceptual map for describing the landscape of LLMs, organized by using the classical entity-relationship model. Our semantically rich data model allows end-users to answer insightful queries regarding, e.g., which metrics are most appropriate for assessing a specific LLM performance over a given downstream task. We first model the resources available in HF and then show how this map can be extended to support additional concepts and more insightful relationships. Our proposal is a first step towards developing a well-organized, high-level knowledge base supporting user-friendly interfaces for querying and discovering LLM properties. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {Conceptual Modeling; Knowledge Exploration; Knowledge Graph; Knowledge Management; Large Language Models},
	keywords = {Computational linguistics; Knowledge graph; Modeling languages; Natural language processing systems; Query processing; 'current; Conceptual maps; Conceptual model; Knowledge exploration; Knowledge graphs; Language model; Language processing; Large language model; Natural languages; Text generations; Knowledge management},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Zheng202411422,
	author = {Zheng, Jie and Du, Baoxia and Du, Hongyang and Kang, Jiawen and Niyato, Dusit and Zhang, Haijun},
	title = {Energy-Efficient Resource Allocation in Generative AI-Aided Secure Semantic Mobile Networks},
	year = {2024},
	journal = {IEEE Transactions on Mobile Computing},
	volume = {23},
	number = {12},
	pages = {11422 – 11435},
	doi = {10.1109/TMC.2024.3396860},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192979540&doi=10.1109%2fTMC.2024.3396860&partnerID=40&md5=d1a2618709d691f06a9d60cb468335ca},
	abstract = {The integration of semantic communication with Internet of Things (IoT) technologies has advanced the development of Semantic IoT (SIoT), with edge mobile networks playing an increasingly vital role. This paper presents a framework for SIoT-based image retrieval services, focusing on the application in automotive market analysis. Here, semantic information in the form of textual representations is transmitted to users, such as automotive companies, and stored as knowledge graphs, instead of raw imagery. This approach reduces the amount of data transmitted, thereby lowering communication resource usage, and ensures user privacy. We explore potential adversarial attacks that could disrupt image transmission in SIoT and propose a defense mechanism utilizing Generative Artificial Intelligence (GAI), specifically the Generative Diffusion Models (GDMs). Unlike methods that necessitate adversarial training with specifically crafted adversarial example samples, GDMs adopt a strategy of adding and removing noise to negate adversarial perturbations embedded in images, offering a more universally applicable defense strategy. The GDM-based defense aims to protect image transmission in SIoT. Furthermore, considering mobile devices' resource constraints, we employ GDM to devise resource allocation strategies, optimizing energy use and balancing between image transmission and defense-related energy consumption. Our numerical analysis reveals the efficacy of GDM in reducing energy consumption during adversarial attacks. For instance, in a scenario, GDM-based defense lowers energy consumption by 5.64%, decreasing the number of image retransmissions from 18 to 6, thus underscoring GDM's role in bolstering network security. © 2002-2012 IEEE.},
	author_keywords = {energy efficiency; Generative AI; resource allocation; semantic communication},
	keywords = {Energy efficiency; Energy utilization; Internet of things; Network security; Semantic Web; Wireless networks; Computational modelling; Diffusion model; Energy-efficient resource allocation; Generative AI; Image edge detection; Model-based OPC; Resources allocation; Semantic communication; Social internet of thing; Task analysis; Semantics},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Chis2024,
	author = {Chis, Andrei and Stoica, Oliviu Ionut and Ghiran, Ana-Maria and Buchmann, Robert Andrei},
	title = {A Knowledge Graph Approach to Cyber Threat Mitigation Derived from Data Flow Diagrams},
	year = {2024},
	journal = {2024 24th IEEE International Conference on Automation, Quality and Testing, Robotics, AQTR 2024 - Proceedings},
	doi = {10.1109/AQTR61889.2024.10554074},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197213706&doi=10.1109%2fAQTR61889.2024.10554074&partnerID=40&md5=945c735d93578a44e74734e90054219f},
	abstract = {Data Flow Diagrams (DFD) have proven effective in designing and analyzing the flow of data in enterprise systems. They serve as indispensable tools for enterprises that are undergoing transition to cloud services. DFDs aid in understanding the current processes, identifying interfaces and integration points that require security measures. This paper reports a Design Science project to mitigate the cyber security threats at the design phase of a system and to perform auditing of an existing system through knowledge graphs. The proposal leverages knowledge gathered from various sources in a knowledge graph to identify semantic relationships and patterns, enabling automated inference, analysis and detection of vulnerability patterns. Furthermore, LLM-based (large language models) capabilities transform data management details captured as Data Flow Diagrams (DFD) into knowledge graphs for semantic querying and improved decision support. © 2024 IEEE.},
	author_keywords = {data flow diagrams; knowledge graphs; LLMs; privacy; security; threat modeling},
	keywords = {Cybersecurity; Data flow analysis; Data flow graphs; Data transfer; Decision support systems; Information management; Knowledge graph; Security systems; Semantics; Cyber threats; Data flow diagrams; Enterprise system; Flow of data; Knowledge graphs; LLM; Privacy; Security; Threat modeling; Threats mitigations; Graphic methods},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Jin2024,
	author = {Jin, Hyunjee and Zhang, Tongtao and Ramamurthy, Arun and Hamza, Ahmed and Malinoski, Mark},
	title = {Learning to Verify and Assure Cyber-Physical Systems},
	year = {2024},
	journal = {AIAA SciTech Forum and Exposition, 2024},
	doi = {10.2514/6.2024-1853},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196833022&doi=10.2514%2f6.2024-1853&partnerID=40&md5=d487d01b1331ded6fbbb0d3d08d1daf1},
	abstract = {Certification of aircraft systems is a complex task that is difficult to automate requiring significant subjective decision making. Established certification standards such as CFR-25 and MIL-HDBK-516 require considerable subjective analysis to transform the certification requirements into meaningful actionable requirements. This prevents the automation of any verification, assurance and certification task. While established methods rely on automation of assurance case generation, several key tasks that still requires human input preventing the co-creation of designs, verification scenarios, evidences, and assurance cases. Building on the recent success of large language models, we develop a framework that enables the automated verification and assurance of cyber-physical systems. Our framework consists of two parts – (i) an automated pipeline permits the automatic extraction of information from system artifacts such that a they can be semantically linked using a graphical representation; and (ii) an automated pipeline that enables the synthesis of verification scenarios to co-generate evidence along with the assurance case of the cyber-physical systems. We demonstrate our framework on a concrete example of a landing gear sub-system of the aircraft and highlight the benefits that can be realized through the automation of the bottlenecks in the task of verification, assurance, and certification. Using semantically linked representations of the knowledge, we enable complex reasoning on the knowledge contained in system artifacts providing meaningful feedback to the designers and certifiers on means improve the overall system. Our investigations on the landing gear use-case demonstrates the feasibility of the use of large language models to support the systems engineering tasks for cyber-physical systems and the use of a knowledge graphs in the construction and assessment of the cyber-physical system’s assurance. © 2024 by the American Institute of Aeronautics and Astronautics, Inc.},
	keywords = {Automation; Cyber Physical System; Embedded systems; Landing gear (aircraft); Pipelines; Aircraft systems; Assurance case; Certification requirements; Certification standards; Complex task; Cybe-physical systems; Cyber-physical systems; Decisions makings; Language model; Subjective analysis; Decision making},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Abu-Rasheed2024230,
	author = {Abu-Rasheed, Hasan and Abdulsalam, Mohamad Hussam and Weber, Cristian and Fathi, Madjid},
	title = {Supporting Student Decisions on Learning Recommendations: An LLM-Based Chatbot with Knowledge Graph Contextualization for Conversational Explainability and Mentoring},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3667},
	pages = {230 – 239},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191971646&partnerID=40&md5=73647c62287adf729ae82fbe4ee3287c},
	abstract = {Student commitment towards a learning recommendation is not separable from their understanding of the reasons it was recommended to them; as well as their ability to modify it based on that understanding. Among explainability approaches, chatbots offer the potential to engage the student in a conversation, similar to a discussion with a peer or a mentor. The capabilities of chatbots, however, are still not sufficient to replace a human mentor, despite the advancements of generative AI (GenAI) and large language models (LLM). Therefore, we propose an approach to utilize chatbots as mediators of the conversation and sources of limited and controlled generation of explanations, to harvest the potential of LLMs while reducing their potential risks at the same time. The proposed LLM-based chatbot supports students in understanding learning-path recommendations. We use a knowledge graph (KG) as a human-curated source of information, to regulate the LLM’s output through defining its prompt’s context. A group chat approach is developed to connect students with human mentors, either on demand or in cases that exceed the chatbot’s pre-defined tasks. We evaluate the chatbot with a user study, to provide a proof-of-concept and highlight the potential requirements and limitations of utilizing chatbots in conversational explainability. © 2024 CEUR-WS. All rights reserved.},
	author_keywords = {Chatbot; ChatGPT; Conversational explanations; Decision support; Explainable AI (XAI); Generative AI (GenAI); GPT-4; Large language models (LLM); OpenAI; Recommender systems},
	keywords = {Computational linguistics; Decision support systems; Knowledge graph; Learning systems; Recommender systems; Chatbots; ChatGPT; Conversational explanation; Decision supports; Explainable AI (XAI); Generative AI; GPT-4; Language model; Large language model; Openai; Students},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Fu2024,
	author = {Fu, Wenhui and Dai, Dongming and Zhang, Kunli and Liu, Xiaomei and Zhang, Hengxing and Ao, Lingxiang and Xiao, Jinlong},
	title = {Research on KG and LLM knowledge-enhanced pediatric diseases intelligent diagnosis},
	year = {2024},
	journal = {Proceedings of SPIE - The International Society for Optical Engineering},
	volume = {13171},
	doi = {10.1117/12.3032061},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196483213&doi=10.1117%2f12.3032061&partnerID=40&md5=10e069ecdf6857a1ff4788963c32b4ed},
	abstract = {Pediatric diseases are challenging to diagnose due to their complex and diverse characteristics. To assist doctors in diagnosis and help them make informed decisions, this paper proposes a Knowledge graph and Large language model Knowledge-Enhanced (KLKE) intelligent diagnosis model. The intelligent diagnosis task is treated as a text classification task, where the original Electronic Medical Record are input into MacBERT model encoder to obtain the contextual representation after key information enhancement and KG prompted LLM enhancement respectively. The final text representation is obtained by concatenating and merging the enhanced representations. Graph Convolutional Network is utilized to obtain the knowledge representation and the two representations are fused using a fusion method based on interactive attention mechanism. Experiments are conducted on PeEMR, and compared with models that only fuses triples and graph structures. The KLKE achieved an increase of 9.15% and 2.28% in F1_micro scores respectively. © 2024 SPIE.},
	author_keywords = {Intelligent Diagnosis; Knowledge Enhancement; Knowledge Graph; LLM},
	keywords = {Classification (of information); Knowledge graph; Medical computing; Medical imaging; Pediatrics; Text processing; Classification tasks; Diagnosis model; Informed decision; Intelligent diagnosis; Knowledge enhancement; Knowledge graphs; Language model; LLM; Model knowledge; Text classification; Computer aided diagnosis},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Mousavi20243782,
	author = {Mousavi, Ali and Zhan, Xin and Bai, He and Shi, Peng and Rekatsinas, Theo and Han, Benjamin and Li, Yunyao and Pound, Jeff and Susskind, Josh and Schluter, Natalie and Ilyas, Ihab F. and Jaitly, Navdeep},
	title = {Construction of Paired Knowledge Graph - Text Datasets Informed by Cyclic Evaluation},
	year = {2024},
	journal = {2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation, LREC-COLING 2024 - Main Conference Proceedings},
	pages = {3782 – 3803},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195942803&partnerID=40&md5=1a4c03536a862d8e96e7ad7568b73e0c},
	abstract = {Datasets that pair Knowledge Graphs (KG) and text together (KG-T) can be used to train forward and reverse neural models that generate text from KG and vice versa. However models trained on datasets where KG and text pairs are not equivalent can suffer from more hallucination and poorer recall. In this paper, we verify this empirically by generating datasets with different levels of noise and find that noisier datasets do indeed lead to more hallucination. We argue that the ability of forward and reverse models trained on a dataset to cyclically regenerate source KG or text is a proxy for the equivalence between the KG and the text in the dataset. Using cyclic evaluation we find that manually created WebNLG is much better than automatically created TeKGen and T-REx. Informed by these observations, we construct a new, improved dataset called LAGRANGE using heuristics meant to improve equivalence between KG and text and show the impact of each of the heuristics on cyclic evaluation. We also construct two synthetic datasets using large language models (LLMs), and observe that these are conducive to models that perform significantly well on cyclic generation of text, but less so on cyclic generation of KGs, probably because of a lack of a consistent underlying ontology. © 2024 ELRA Language Resource Association: CC BY-NC 4.0.},
	keywords = {Knowledge graph; Forward modeling; Knowledge graphs; Language model; Neural modelling; Noisy datasets; Ontology's; Reverse Modeling; Synthetic datasets; Large datasets},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Murtagh202426,
	author = {Murtagh, Matt and Wall, P.J. and O’Sullivan, Declan},
	title = {PRICER: Leveraging Few-Shot Learning with Fine-Tuned Large Language Models for Unstructured Economic Data},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3697},
	pages = {26 – 36},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195490172&partnerID=40&md5=58db8e7f7cd61bf339c9c1b67bf5d2d0},
	abstract = {Accurate collection of economic data is crucial for metrics like the Consumer Price Index (CPI), informing policies on inflation and living costs. Traditional manual data collection methods from retail sources are labor-intensive and fraught with issues of scalability, accuracy, and data diversity. Our study introduces an OWL RDFS-based framework aligned with COICOP, and a transformer model,’PRICER’, to automate the extraction and structuring of online retail data into RDF. By iteratively fine-tuning PRICER—first with a broad DBPedia and Wikipedia knowledge base, then with specific online retail data—we achieve significant efficiency and accuracy improvements in data collection. Notably, PRICER shows marked performance gains in precision and recall after task-specific conditioning, validating our approach for converting unstructured text to structured knowledge. This advancement facilitates streamlined economic data aggregation and highlights PRICER’s adaptability for broader standardised data processing applications. Future work will focus scaling the domain specific price dataset, refining the model’s conditioning and exploring potential for other forms of technical data. © 2024 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).},
	author_keywords = {Deep Learning; Economic Data; Knowledge Graphs; Large Language Models},
	keywords = {Computational linguistics; Costs; Data acquisition; Data handling; Deep learning; Knowledge graph; Knowledge management; Refining; Resource Description Framework (RDF); Consumer price index; Data collection method; Deep learning; Economic data; Knowledge graphs; Labour-intensive; Language model; Large language model; Online retails; Transformer modeling; Iterative methods},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{2024,
	title = {AIxIA-DC 2023 - Proceedings of the AIxIA Doctoral Consortium 2023, co-located with the 22nd International Conference of the Italian Association for Artificial Intelligence, AIxIA 2023},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3670},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192007583&partnerID=40&md5=1072ed7fda402aa3ef2533731c163c11},
	abstract = {The proceedings contain 21 papers. The topics discussed include: RBF based NN architecture for structural health analysis of railway steel bridges; neural network heuristics for numeric planning: a preliminary study; neuro-symbolic recommender systems; specification languages and ASP-based solutions for scheduling problems in healthcare; knowledge graph completion with probabilistic logic programming; migratable AI systems for tailoring user experience through multimodal affective-cognitive state analysis; Monte Carlo tree search with state merging for reinforcement learning in regular decision processes; machine learning-based prediction of bio-oil yields from pyrolysis of biomass: a comparative study of imputation algorithms and model benchmarking; and skills-hunter: adapting large language models to the labor market for skills extraction.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Vizcarra2024231,
	author = {Vizcarra, Julio and Haruta, Shuichiro and Kurokawa, Mori},
	title = {Representing the Interaction between Users and Products via LLM-assisted Knowledge Graph Construction},
	year = {2024},
	journal = {Proceedings - IEEE International Conference on Semantic Computing, ICSC},
	pages = {231 – 232},
	doi = {10.1109/ICSC59802.2024.00043},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192226431&doi=10.1109%2fICSC59802.2024.00043&partnerID=40&md5=4bf9c2d4a932a6f54d710a24ec76c217},
	abstract = {To understand user behavior, representing the semantic knowledge of user-product interaction is essential. In this paper, we represent the interaction between user and product via large language model (LLM)-assisted knowledge graph construction. We capture users' behavioral actions and static properties of the products from raw text data of 'user review' and 'product catalog'. Moreover, the information needed for updating the knowledge graph is captured by raw texts of 'news related to the products'. The proposed methodology integrates them as a single knowledge graph to provide causal reasoning on user-product interaction. To alleviate the situation where a small quantity of annotated text exists in these data, we use LLM as a data annotator and augmentor.  © 2024 IEEE.},
	author_keywords = {causality; Knowledge graph; LLM; ontology; text mining; user-product interaction},
	keywords = {Behavioral research; Semantics; Causality; Graph construction; Knowledge graphs; Language model; Large language model; Ontology's; Product interaction; Text-mining; User behaviors; User-product interaction; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Pertsas202484,
	author = {Pertsas, Vayianos and Kasapaki, Marialena and Constantopoulos, Panos},
	title = {An Annotated Dataset for Transformer-based Scholarly Information Extraction and Linguistic Linked Data Generation},
	year = {2024},
	journal = {9th Workshop on Linked Data in Linguistics: Resources, Applications, Best Practices, LDL 2024 at LREC-COLING 2024 - Workshop Proceedings},
	pages = {84 – 93},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195174004&partnerID=40&md5=5d136eb016cc4bb370972d511703c02c},
	abstract = {We present a manually curated and annotated, multidisciplinary dataset of 15,262 sentences from research articles (abstract and main text) that can be used for transformer-based extraction from scholarly publications of three types of entities: 1) research methods, named entities of variable length, 2) research goals, entities that appear as textual spans of variable length with mostly fixed lexico-syntactic-structure, and 3) research activities, entities that appear as textual spans of variable length with complex lexico-syntactic structure. We explore the capabilities of our dataset by using it for training/fine-tuning various ML and transformer-based models. We compare our finetuned models as well as LLM responses (chat-GPT 3.5) based on 10-shot learning, by measuring F1 scores in token-based, entity-based strict and entity-based partial evaluations across interdisciplinary and discipline-specific datasets in order to capture any possible differences in discipline-oriented writing styles. Results show that fine tuning of transformer-based models significantly outperforms the performance of few-shot learning of LLMs such as chat-GPT, highlighting the significance of annotation datasets in such tasks. Our dataset can also be used as a source for linguistic linked data by itself. We demonstrate this by presenting indicative queries in SPARQL, executed over such an RDF knowledge graph. © 2024 ELRA Language Resource Association.},
	author_keywords = {Information Extraction from Text; Linguistic Linked Data; RDF Knowledge Graph; Scholarly Annotation Corpus; Transformer-based Information Extraction},
	keywords = {Abstracting; Data handling; Data mining; Information retrieval; Knowledge graph; Learning systems; Natural language processing systems; Resource Description Framework (RDF); Syntactics; Fine tuning; Information extraction from text; Knowledge graphs; Linguistic linked data; Linked datum; RDF knowledge graph; Scholarly annotation corpus; Syntactic structure; Transformer-based information extraction; Variable length; Linked data},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Wang202410303,
	author = {Wang, Chenhao and Cao, Pengfei and Li, Jiachun and Chen, Yubo and Liu, Kang and Jiang, Xiaojian and Xu, Jiexin and Qiuxia, Li and Zhao, Jun},
	title = {Leros: Learning Explicit Reasoning on Synthesized Data for Commonsense Question Answering},
	year = {2024},
	journal = {2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation, LREC-COLING 2024 - Main Conference Proceedings},
	pages = {10303 – 10315},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195969703&partnerID=40&md5=0da7c93b3ffc66a258d801b2f8c151a0},
	abstract = {Recent work shows large language models can be prompted to generate useful rationales for commonsense question answering (CQA), which can improve the performance of both themselves and other models. However, the cost of deployment and further tuning is relatively expensive for the large models. Some work explores to distill the the rationale-generation ability to convenient small-sized models, yet it typically requires human-authored QA instances during the distillation. In this paper, we propose a novel framework that leverages both knowledge graphs and large language models to synthesize rationale-augmented CQA data. Based on it, we train Leros, a model that can generate helpful rationales to assist generic QA models to accomplish unseen CQA tasks. Empirical results demonstrate Leros can substantially enhance the performance of QA models on five unseen CQA benchmarks, providing better gains than both same-sized counterpart models trained with downstream data and 10x larger language models. Our work reveals a novel way to integrate knowledge from both knowledge graphs and large language models into smaller models. The codes and synthesized resources are publicly available at https://github.com/wchrepo/leros. © 2024 ELRA Language Resource Association: CC BY-NC 4.0.},
	author_keywords = {Commonsense Knowledge; Commonsense Question Answering; Rationale Generation},
	keywords = {Benchmarking; Computational linguistics; Knowledge graph; Natural language processing systems; Commonsense knowledge; Commonsense question answering; Knowledge graphs; Language model; Large models; Performance; Question Answering; Question Answering Task; Rationale generation; Synthesised; Distillation},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Datta2024,
	author = {Datta, Arkajit and Verma, Tushar and Chawla, Rajat and Mukunda, N.S. and Bhola, Ishaan},
	title = {AUTONODE: A Neuro-Graphic Self-Learnable Engine for Cognitive GUI Automation},
	year = {2024},
	journal = {ICAC 2024 - 29th International Conference on Automation and Computing},
	doi = {10.1109/ICAC61394.2024.10718742},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192633213&doi=10.1109%2fICAC61394.2024.10718742&partnerID=40&md5=73309b6d5e44cd803e034af0fa72264f},
	abstract = {In recent advancements within the domain of Large Language Models (LLMs), there has been a notable emergence of agents capable of addressing Robotic Process Automation (RPA) challenges through enhanced cognitive capabilities and sophisticated reasoning. This development heralds a new era of scalability and human-like adaptability in goal attainment. In this context, we introduce AUTONODE (Autonomous User-interface Transformation through Online Neuro-graphic Operations and Deep Exploration). AUTONODE employs advanced neuro-graphical techniques to facilitate autonomous navigation and task execution on web interfaces, thereby obviating the necessity for predefined scripts or manual intervention. Our engine empowers agents to comprehend and implement complex workflows, adapting to dynamic web environments with unparalleled efficiency. Our methodology synergizes cognitive functionalities with robotic automation, endowing AUTONODE with the ability to learn from experience. We have integrated an exploratory module, DoRA (Discovery and mapping Operation for graph Retrieval Agent), which is instrumental in constructing a knowledge graph that the engine utilizes to optimize its actions and achieve objectives with minimal supervision. The versatility and efficacy of AUTONODE are demonstrated through a series of experiments, highlighting its proficiency in managing a diverse array of web-based tasks, ranging from data extraction to transaction processing. The implementation of our paper can be accessed at :https://github.com/TransformerOptimus/AutoNode © 2024 IEEE.},
	author_keywords = {Generative AI; Graphs; LLMs; Reinforcement Learning; Self-Operating Computer; Transformers; Vision-Transformers},
	keywords = {Deep neural networks; Distribution transformers; Graphical user interfaces; Robot learning; Generative AI; Graph; Language model; Large language model; Process automation; Reinforcement learnings; Self-operating computer; Transformer; User interface transformations; Vision-transformer; Reinforcement learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@CONFERENCE{2024,
	title = {D2R2 2024 - Proceedings of the 3rd International Workshop on Linked Data-Driven Resilience Research, co-located with European Semantic Web Conference 2024, ESWC 2024},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3707},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196313134&partnerID=40&md5=a067f1af60c2514eb647da333a7fa32f},
	abstract = {The proceedings contain 8 papers. The topics discussed include: empowering supply chains resilience: LLMs-powered BN for proactive supply chain risk identification; anticipate risk with the value and trade flows knowledge graph; entity alignment for knowledge graphs in the context of supply chain risk management; leveraging small language models for Text2SPARQL tasks to improve the resilience of AI assistance; towards a regional public dashboard for crisis and resilience management; an automated evaluation framework for graph database query generation leveraging large language models; and towards modeling the structure of product dependencies in supply networks to identify bottlenecks among suppliers.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{2024,
	title = {REFSQ-JP 2024 - Joint Proceedings of REFSQ-2024 Workshops, Doctoral Symposium, Posters and Tools Track, and Education and Training Track, co-located with the 30th International Conference on Requirements Engineering: Foundation for Software Quality, REFSQ 2024},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3672},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193051632&partnerID=40&md5=c52e2f75b8b4ef4eb034ead0d57b0c77},
	abstract = {The proceedings contain 28 papers. The topics discussed include: what is ready in a DoR? rationales, responsibility & rules in using a definition of ready; Cartooneering - using comics and personas to enable the definition of a software product vision; six thinking chatbots: a creativity technique deployed via a large language model; on the pulse of requirements elicitation: physiological triggers and explainability needs; towards a card game for creative solution ideas: InnoCards; Cartooneering - a collaborative workshop approach to develop scenarios with users; applying and validating a new creativity method: CityInnoCards; prompting the future: integrating generative LLMs and requirements engineering; leveraging knowledge graphs for goal model generation; and automated requirements demarcation using large language models: an empirical study.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Wang20249668,
	author = {Wang, Yilin and Hu, Minghao and Huang, Zhen and Li, Dongsheng and Yang, Dong and Lu, Xicheng},
	title = {KC-GenRe: A Knowledge-constrained Generative Re-ranking Method Based on Large Language Models for Knowledge Graph Completion},
	year = {2024},
	journal = {2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation, LREC-COLING 2024 - Main Conference Proceedings},
	pages = {9668 – 9680},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195931508&partnerID=40&md5=ef19d6e5e513fa59ba17fe6104f94331},
	abstract = {The goal of knowledge graph completion (KGC) is to predict missing facts among entities. Previous methods for KGC re-ranking are mostly built on non-generative language models to obtain the probability of each candidate. Recently, generative large language models (LLMs) have shown outstanding performance on several tasks such as information extraction and dialog systems. Leveraging them for KGC re-ranking is beneficial for leveraging the extensive pre-trained knowledge and powerful generative capabilities. However, it may encounter new problems when accomplishing the task, namely mismatch, misordering and omission. To this end, we introduce KC-GenRe, a knowledge-constrained generative re-ranking method based on LLMs for KGC. To overcome the mismatch issue, we formulate the KGC re-ranking task as a candidate identifier sorting generation problem implemented by generative LLMs. To tackle the misordering issue, we develop a knowledge-guided interactive training method that enhances the identification and ranking of candidates. To address the omission issue, we design a knowledge-augmented constrained inference method that enables contextual prompting and controlled generation, so as to obtain valid rankings. Experimental results show that KG-GenRe achieves state-of-the-art performance on four datasets, with gains of up to 6.7% and 7.7% in the MRR and Hits@1 metric compared to previous methods, and 9.0% and 11.1% compared to that without re-ranking. Extensive analysis demonstrates the effectiveness of components in KG-GenRe. © 2024 ELRA Language Resource Association: CC BY-NC 4.0.},
	author_keywords = {Knowledge Graph Completion; Large Language Model; Re-ranking},
	keywords = {Computational linguistics; Knowledge management; Dialogue systems; Information extraction systems; Interactive training; Knowledge graph completion; Knowledge graphs; Language model; Large language model; Performance; Ranking methods; Re-ranking; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Meyer2024103,
	author = {Meyer, Lars-Peter and Stadler, Claus and Frey, Johannes and Radtke, Norman and Junghanns, Kurt and Meissner, Roy and Dziwis, Gordian and Bulert, Kirill and Martin, Michael},
	title = {LLM-assisted Knowledge Graph Engineering: Experiments with ChatGPT},
	year = {2024},
	journal = {Informatik aktuell},
	pages = {103 – 115},
	doi = {10.1007/978-3-658-43705-3_8},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192232534&doi=10.1007%2f978-3-658-43705-3_8&partnerID=40&md5=356b2d38d98cc068bfdf89a9a52293cb},
	abstract = {Knowledge Graphs (KG) provide us with a structured, flexible, transparent, cross-system, and collaborative way of organizing our knowledge and data across various domains in society and industrial as well as scientific disciplines. KGs surpass any other form of representation in terms of effectiveness. However, Knowledge Graph Engineering (KGE) requires in-depth experiences of graph structures, web technologies, existing models and vocabularies, rule sets, logic, as well as best practices. It also demands a significant amount of work. Considering the advancements in large language models (LLMs) and their interfaces and applications in recent years, we have conducted comprehensive experiments with ChatGPT to explore its potential in supporting KGE. In this paper, we present a selection of these experiments and their results to demonstrate how ChatGPT can assist us in the development and management of KGs. Zusammenfassung. Wissensgraphen (englisch Knowledge Graphs, KGs), bieten uns eine strukturierte, flexible, transparente, systemübergreifende und kollaborative Möglichkeit, unser Wissen und unsere Daten über verschiedene Bereiche der Gesellschaft und der industriellen sowie wissenschaftlichen Disziplinen hinweg zu organisieren. KGs übertreffen jede andere Form der Repräsentation in Bezug auf die Effektivität. Die Entwicklung von Wissensgraphen (englisch Knowledge Graph Engineering, KGE) erfordert jedoch fundierte Erfahrungen mit Graphstrukturen, Webtechnologien, bestehenden Modellen und Vokabularen, Regelwerken, Logik sowie Best Practices. Es erfordert auch einen erheblichen Arbeitsaufwand. In Anbetracht der Fortschritte bei großen Sprachmodellen (englisch Large Language Modells, LLMs) und ihren Schnittstellen und Anwendungen in den letzten Jahren haben wir umfassende Experimente mit ChatGPT durchgeführt, um sein Potenzial zur Unterstützung von KGE zu untersuchen. In diesem Artikel stellen wir eine Auswahl dieser Experimente und ihre Ergebnisse vor, um zu zeigen, wie ChatGPT uns bei der Entwicklung und Verwaltung von KGs unterstützen kann. © Der/die Autor(en) 2024.},
	author_keywords = {AI application; ChatGPT; knowledge graph engineering; large language model use cases; RDF},
	keywords = {Computational linguistics; Graphic methods; Resource Description Framework (RDF); AI applications; Best practices; ChatGPT; Engineering experiments; Knowledge graph engineering; Knowledge graphs; Language model; Large language model use case; Model use; RDF; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{2024,
	title = {21st European Semantic Web Conference, ESWC 2024},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14665 LNCS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195259090&partnerID=40&md5=4a01a73d73a3f30ac3dae7ef63ca112e},
	abstract = {The proceedings contain 32 papers. The special focus in this conference is on Semantic Web. The topics include: Treat Different Negatives Differently: Enriching Loss Functions with Domain and Range Constraints for Link Prediction; QAGCN: Answering Multi-relation Questions via Single-Step Implicit Reasoning over Knowledge Graphs; leveraging Pre-trained Language Models for Time Interval Prediction in Text-Enhanced Temporal Knowledge Graphs; a Language Model Based Framework for New Concept Placement in Ontologies; low-Dimensional Hyperbolic Knowledge Graph Embedding for Better Extrapolation to Under-Represented Data; SC-Block: Supervised Contrastive Blocking Within Entity Resolution Pipelines; navigating Ontology Development with Large Language Models; ESLM: Improving Entity Summarization by Leveraging Language Models; explanation of Link Predictions on Knowledge Graphs via Levelwise Filtering and Graph Summarization; Large Language Models for Scientific Question Answering: An Extensive Analysis of the SciQA Benchmark; efficient Evaluation of Conjunctive Regular Path Queries Using Multi-way Joins; can Contrastive Learning Refine Embeddings; automation of Electronic Invoice Validation Using Knowledge Graph Technologies; towards Cyber Mapping the German Financial System with Knowledge Graphs; integrating Domain Knowledge for Enhanced Concept Model Explainability in Plant Disease Classification; generative Expression Constrained Knowledge-Based Decoding for Open Data.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Cabrera20245,
	author = {Cabrera, Christian and Paleyes, Andrei and Lawrence, Neil D.},
	title = {Self-sustaining Software Systems (S4): Towards Improved Interpretability and Adaptation},
	year = {2024},
	journal = {Proceedings - 2024 IEEE/ACM International Workshop New Trends in Software Architecture, SATrends 2024},
	pages = {5 – 9},
	doi = {10.1145/3643657.3643910},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195524608&doi=10.1145%2f3643657.3643910&partnerID=40&md5=7d5c443b03e6633e14f5aab34ce61a65},
	abstract = {Software systems impact society at different levels as they pervasively solve real-world problems. Modern software systems are often so sophisticated that their complexity exceeds the limits of human comprehension. These systems must respond to changing goals, dynamic data, unexpected failures, and security threats, among other variable factors in real-world environments. Systems' complexity challenges their interpretability and requires autonomous responses to dynamic changes. Two main research areas explore autonomous systems' responses: evolutionary computing and autonomic computing. Evolutionary computing focuses on software improvement based on iterative modifications to the source code. Autonomic computing focuses on optimising systems' performance by changing their structure, behaviour, or environment variables. Approaches from both areas rely on feedback loops that accumulate knowledge from the system interactions to inform autonomous decision-making. However, this knowledge is often limited, constraining the systems' interpretability and adaptability. This paper proposes a new concept for interpretable and adaptable software systems: self-sustaining software systems (S4). S4 builds knowledge loops between all available knowledge sources that define modern software systems to improve their interpretability and adaptability. This paper introduces and discusses the S4 concept.CCS CONCEPTS• Software and its engineering → Designing software; Automatic programming; Software evolution. © 2024 ACM.},
	author_keywords = {Autonomous Systems; Data-Oriented Architectures; Knowledge Graphs; Large Language Models; Software Engineering},
	keywords = {Man machine systems; Autonomic Computing; Autonomous system; Data-oriented architecture; Evolutionary computing; Interpretability; Knowledge graphs; Language model; Large language model; Software-systems; System impact; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Green Open Access}
}

@CONFERENCE{Su20241197,
	author = {Su, Yanqi and Liao, Dianshu and Xing, Zhenchang and Huang, Qing and Xie, Mulong and Lu, Qinghua and Xu, Xiwei},
	title = {Enhancing Exploratory Testing by Large Language Model and Knowledge Graph},
	year = {2024},
	journal = {Proceedings - International Conference on Software Engineering},
	pages = {1197 – 1208},
	doi = {10.1145/3597503.3639157},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192608714&doi=10.1145%2f3597503.3639157&partnerID=40&md5=d2dcccfa60e1eddbf7cf18d90db1b726},
	abstract = {Exploratory testing leverages the tester's knowledge and creativity to design test cases for effectively uncovering system-level bugs from the end user's perspective. Researchers have worked on test scenario generation to support exploratory testing based on a system knowledge graph, enriched with scenario and oracle knowledge from bug reports. Nevertheless, the adoption of this approach is hindered by difficulties in handling bug reports of inconsistent quality and varied expression styles, along with the infeasibility of the generated test scenarios. To overcome these limitations, we utilize the superior natural language understanding (NLU) capabilities of Large Language Models (LLMs) to construct a System KG of User Tasks and Failures (SysKG-UTF). Leveraging the system and bug knowledge from the KG, along with the logical reasoning capabilities of LLMs, we generate test scenarios with high feasibility and coherence. Particularly, we design chain-of-thought (CoT) reasoning to extract human-like knowledge and logical reasoning from LLMs, simulating a developer's process of validating test scenario feasibility. Our evaluation shows that our approach significantly enhances the KG construction, particularly for bug reports with low quality. Furthermore, our approach generates test scenarios with high feasibility and coherence. The user study further proves the effectiveness of our generated test scenarios in supporting exploratory testing. Specifically, 8 participants find 36 bugs from 8 seed bugs in two hours using our test scenarios, a significant improvement over the 21 bugs found by the state-of-the-art baseline.  © 2024 ACM.},
	author_keywords = {AI chain; Exploratory testing; Knowledge graph; Prompt engineering},
	keywords = {Knowledge graph; Knowledge management; Program debugging; AI chain; Bug reports; Design tests; Exploratory testing; Knowledge graphs; Language model; Logical reasoning; Prompt engineering; Test case; Test scenario; Computational linguistics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Alter20241,
	author = {Alter, Steven},
	title = {Produce a Useful and Teachable Theoretical Foundation for IS Engineering},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3692},
	pages = {1 – 9},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195202048&partnerID=40&md5=12d41d146e40866b69eb626d86451d76},
	abstract = {IS engineering (ISE) uses tools such as UML and BPMN, but it lacks a theoretical foundation that is useful and teachable, as has been noted many times. Efforts over the course of 30 years by the author and various collaborators have produced substantial progress toward articulating a useful and teachable theoretical foundation for IS engineering (a TFISE). A clear, intuitively plausible, and practical TFISE could help in assessing strengths and weaknesses of current ISE practice, developing better concepts, tools, and methods, and producing better results. Research to date unfolded around a core of work system theory, which emerged from a series of IS textbooks, was first formalized in 2013, and is more plausible as an overarching metaphor for a TFISE than known alternatives. Ongoing research aims to produce additional tangible products that could contribute to a TFISE and TFISE specifications. Results from distinct, separable steps such as several mentioned here could be published in conference and journal papers. Explaining a TFISE in detail would require one or several book-length documents. Current projects focus primarily on consolidating and extending earlier steps toward a TFISE by using knowledge graphs, possibly in conjunction with carefully structured prompting of large language models. Much of the development to date was inspired by university site visits, work with co-authors, and especially international interactions with researchers. The pace of near-term progress will depend on enlisting collaborators. In addition to work system theory, the long course of this project has produced theories related to workarounds, system interactions, IS usage, and IS user satisfaction; frameworks related to a system value chain, facets of work, smartness of systems, compliance and noncompliance, and roles and responsibilities of digital agents; a taxonomy of knowledge objects; applications of work system ideas to risk, security, collaborative workarounds, software engineering instruction, AI, and digital transformation; a toolkit of templates for description, analysis, and design; and a map of a broader work system perspective that continues to expand. © 2024 Copyright for this paper by the author.},
	author_keywords = {taxonomy of knowledge objects; theoretical foundation of IS engineering; work system theory},
	keywords = {Application programs; Curricula; Foundations; Multi agent systems; Risk assessment; Software agents; Taxonomies; 'current; Conference papers; Engineering practices; Tangible product; Taxonomy of knowledge object; Theoretical foundation of IS engineering; Theoretical foundations; Tools and methods; Work system; Work system theory; System theory},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{2024,
	title = {21st European Semantic Web Conference, ESWC 2024},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14664 LNCS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194235501&partnerID=40&md5=65e20693726d830550adc9ad39116169},
	abstract = {The proceedings contain 32 papers. The special focus in this conference is on Semantic Web. The topics include: Treat Different Negatives Differently: Enriching Loss Functions with Domain and Range Constraints for Link Prediction; QAGCN: Answering Multi-relation Questions via Single-Step Implicit Reasoning over Knowledge Graphs; leveraging Pre-trained Language Models for Time Interval Prediction in Text-Enhanced Temporal Knowledge Graphs; a Language Model Based Framework for New Concept Placement in Ontologies; low-Dimensional Hyperbolic Knowledge Graph Embedding for Better Extrapolation to Under-Represented Data; SC-Block: Supervised Contrastive Blocking Within Entity Resolution Pipelines; navigating Ontology Development with Large Language Models; ESLM: Improving Entity Summarization by Leveraging Language Models; explanation of Link Predictions on Knowledge Graphs via Levelwise Filtering and Graph Summarization; Large Language Models for Scientific Question Answering: An Extensive Analysis of the SciQA Benchmark; efficient Evaluation of Conjunctive Regular Path Queries Using Multi-way Joins; can Contrastive Learning Refine Embeddings; automation of Electronic Invoice Validation Using Knowledge Graph Technologies; towards Cyber Mapping the German Financial System with Knowledge Graphs; integrating Domain Knowledge for Enhanced Concept Model Explainability in Plant Disease Classification; generative Expression Constrained Knowledge-Based Decoding for Open Data.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Giarelis202413,
	author = {Giarelis, Nikolaos and Mastrokostas, Charalampos and Karacapilidis, Nikos},
	title = {A Unified LLM-KG Framework to Assist Fact-Checking in Public Deliberation},
	year = {2024},
	journal = {1st Workshop on Language-Driven Deliberation Technology, DELITE 2024 at LREC-COLING 2024 - Workshop Proceedings},
	pages = {13 – 19},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195365734&partnerID=40&md5=817968d7eec43ae2ed49ae5f59ca9e97},
	abstract = {Fact-checking plays a crucial role in public deliberation by promoting transparency, accuracy, credibility, and accountability. Aiming to augment the efficiency and adoption of current public deliberation platforms, which mostly rely on the abilities of participants to meaningfully process and interpret the associated content, this paper explores the combination of deep learning and symbolic reasoning. Specifically, it proposes a framework that unifies the capabilities of Large Language Models (LLMs) and Knowledge Graphs (KGs), and reports on an experimental evaluation. This evaluation is conducted through a questionnaire asking users to assess a baseline LLM against the proposed framework, using a series of fact-checking metrics, namely readability, coverage, non-redundancy, and quality. The experimentation results are promising and confirm the potential of combining the capabilities of these two technologies in the context of public deliberation and digital democracy. © 2024 ELRA Language Resource Association: CC BY-NC 4.0.},
	author_keywords = {Fact Checking; Knowledge Graphs; Large Language Models; Public Deliberation},
	keywords = {Computational linguistics; Knowledge graph; Quality control; 'current; Experimental evaluation; Fact checking; Graph framework; Knowledge graphs; Language model; Large language model; Model knowledge; Public deliberation; Symbolic reasoning; Deep learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@ARTICLE{Hu2024,
	author = {Hu, Xin and Liu, Ang and Dai, Yun},
	title = {Combining ChatGPT and knowledge graph for explainable machine learning-driven design: a case study},
	year = {2024},
	journal = {Journal of Engineering Design},
	doi = {10.1080/09544828.2024.2355758},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193737600&doi=10.1080%2f09544828.2024.2355758&partnerID=40&md5=1c4186b1497c268366953a2b780648fd},
	abstract = {Machine learning has been widely used in design activities, enabling more informed decision-making. However, high-performance machine learning models, often referred to as ‘black-box', result in a lack of explainability regarding predictions. The absence of explainability erodes the trust between designers and these models and hinders human-machine collaboration for desirable design decisions. Explainable AI focuses on creating explanations that are accessible and comprehensible to stakeholders, thereby improving explainability. A recent advancement in the field of explainable AI involves leveraging domain-specific knowledge via knowledge graph. Additionally, the advent of large language models like ChatGPT, acclaimed for their ability to output domain knowledge, perform complex language processing, and support seamless end-user interaction, has the potential to expand the horizons of explainable AI. Inspired by these developments, we propose the novel hybrid method that synergizes ChatGPT and knowledge graph to augment post-hoc explainability in design context. The outcome is the generation of more contextual and meaningful explanations, with the added possibility of further interaction to uncover deeper insights. The effectiveness of the proposed method is illustrated through a case study on customer segmentation. © 2024 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.},
	author_keywords = {ChatGPT; explainable AI; knowledge graph; Machine learning; product design},
	keywords = {Decision making; Domain Knowledge; Knowledge graph; Knowledge management; Machine learning; Case-studies; ChatGPT; Decisions makings; Design activity; Explainable AI; High-performance machines; Informed decision; Knowledge graphs; Machine learning models; Machine-learning; Product design},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Sawczyn20245768,
	author = {Sawczyn, Albert and Binkowski, Jakub and Bielak, Piotr and Kajdanowicz, Tomasz},
	title = {Empowering Small-Scale Knowledge Graphs: A Strategy of Leveraging General-Purpose Knowledge Graphs for Enriched Embeddings},
	year = {2024},
	journal = {2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation, LREC-COLING 2024 - Main Conference Proceedings},
	pages = {5768 – 5782},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195920884&partnerID=40&md5=5dc77a989c3a58476ae11c1787885be2},
	abstract = {Knowledge-intensive tasks pose a significant challenge for Machine Learning (ML) techniques. Commonly adopted methods, such as Large Language Models (LLMs), often exhibit limitations when applied to such tasks. Nevertheless, there have been notable endeavours to mitigate these challenges, with a significant emphasis on augmenting LLMs through Knowledge Graphs (KGs). While KGs provide many advantages for representing knowledge, their development costs can deter extensive research and applications. Addressing this limitation, we introduce a framework for enriching embeddings of small-scale domain-specific Knowledge Graphs with well-established general-purpose KGs. Adopting our method, a modest domain-specific KG can benefit from a performance boost in downstream tasks when linked to a substantial general-purpose KG. Experimental evaluations demonstrate a notable enhancement, with up to a 44% increase observed in the Hits@10 metric. This relatively unexplored research direction can catalyze more frequent incorporation of KGs in knowledge-intensive tasks, resulting in more robust, reliable ML implementations, which hallucinates less than prevalent LLM solutions. © 2024 ELRA Language Resource Association: CC BY-NC 4.0.},
	author_keywords = {entity alignment; knowledge graph; knowledge graph completion; machine learning; representation learning},
	keywords = {Domain Knowledge; Graph embeddings; Graphic methods; Knowledge management; Machine learning; Embeddings; Entity alignment; Knowledge graph completion; Knowledge graphs; Knowledge intensive tasks; Language model; Machine-learning; Representation learning; Small scale; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Moskvoretskii20241498,
	author = {Moskvoretskii, Viktor and Panchenko, Alexander and Nikishina, Irina},
	title = {Are Large Language Models Good at Lexical Semantics? A Case of Taxonomy Learning},
	year = {2024},
	journal = {2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation, LREC-COLING 2024 - Main Conference Proceedings},
	pages = {1498 – 1510},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195968824&partnerID=40&md5=62d830955a58a2e4366d6f4cd82571e1},
	abstract = {Recent studies on LLMs do not pay enousdfgh attention to linguistic and lexical semantic tasks, such as taxonomy learning. In this paper, we explore the capacities of Large Language Models featuring LLaMA-2 and Mistral for several Taxonomy-related tasks. We introduce a new methodology and algorithm for data collection via stochastic graph traversal leading to controllable data collection. Collected cases provide the ability to form nearly any type of graph operation. We test the collected dataset for learning taxonomy structure based on English WordNet and compare different input templates for fine-tuning LLMs. Moreover, we apply the fine-tuned models on such datasets on the downstream tasks achieving state-of-the-art results on the TexEval-2 dataset. © 2024 ELRA Language Resource Association: CC BY-NC 4.0.},
	author_keywords = {hypernym prediction; LLMs; taxonomy construction; WordNet},
	keywords = {Computational linguistics; Data acquisition; Learning systems; Ontology; Semantics; Statistical tests; Stochastic systems; Data collection; Hypernym prediction; Language model; Lexical semantics; Linguistic semantics; LLM; Semantic tasks; Taxonomy construction; Taxonomy learning; Wordnet; Taxonomies},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{Jhajj2024292,
	author = {Jhajj, Gaganpreet and Zhang, Xiaokun and Gustafson, Jerry Ryan and Lin, Fuhua and Lin, Michael Pin-Chuan},
	title = {Educational Knowledge Graph Creation and Augmentation via LLMs},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14799 LNCS},
	pages = {292 – 304},
	doi = {10.1007/978-3-031-63031-6_25},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196063004&doi=10.1007%2f978-3-031-63031-6_25&partnerID=40&md5=af799c3b00baacc63de5fa550c9a0ae8},
	abstract = {In this study, we explore the efficacy of Generative AI and Large Language Models (LLMs) in the tasks of constructing and completing Educational Knowledge Graphs (EduKGs). Knowledge Graphs (KGs) help represent real-world relationships. This can take the form of modeling course domains and student progression in educational settings. Through this work, we leverage GPT-4 to aid KG construction and align it with predefined learning objectives, course structure, and human interaction in validating and refining the generated KGs. The methodology employed utilized prompting LLMs with course materials and evaluating the generation of KGs through automatic and human assessment. Through a series of experiments, we show the potential of LLMs in enhancing the EduKG construction process, particularly for course modeling. Our findings suggest that LLMs such as GPT-4 can augment EduKGs by suggesting valuable and contextually relevant triplets. This KG creation and augmentation approach shows the potential to reduce the workload on educators and adaptive learning systems, paving the way for future applications in content recommendation and personalized learning experiences. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {Educational Knowledge Graphs; Knowledge Graphs; Large Language Models},
	keywords = {Computational linguistics; Graphic methods; Learning systems; Educational knowledge; Educational knowledge graph; Educational settings; Graph construction; Knowledge graphs; Language model; Large language model; Modeling course; Real-world; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{2024,
	title = {2nd Workshop on Natural Language Processing for Political Sciences, PoliticalNLP 2024 at LREC-COLING 2024- Proceedings},
	year = {2024},
	journal = {2nd Workshop on Natural Language Processing for Political Sciences, PoliticalNLP 2024 at LREC-COLING 2024- Proceedings},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195155410&partnerID=40&md5=e4b908413d0953a172cd9ba1ee51aa81},
	abstract = {The proceedings contain 10 papers. The topics discussed include: deciphering political entity sentiment in news with large language models: zero-shot and few-shot strategies; event detection in the socio political domain; multi-dimensional insights: annotated dataset of stance, sentiment, and emotion in Facebook comments on Tunisia’s July 25 measures; masking explicit pro-con expressions for development of a stance classification dataset on assembly minutes; analyzing pathos in user-generated argumentative text; knowledge graph representation for political information sources; analyzing conflict through data: a dataset on the digital framing of Sheikh Jarrah evictions; semi-automatic topic discovery and classification for epidemic intelligence via large language models; towards quantifying politicization in foreign aid project reports; and echo-chambers and idea labs: communication styles on Twitter.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Dong202479,
	author = {Dong, Hang and Chen, Jiaoyan and He, Yuan and Gao, Yongsheng and Horrocks, Ian},
	title = {A Language Model Based Framework for New Concept Placement in Ontologies},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14664 LNCS},
	pages = {79 – 99},
	doi = {10.1007/978-3-031-60626-7_5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194222248&doi=10.1007%2f978-3-031-60626-7_5&partnerID=40&md5=cfa6743f88dd716c0f29456ef04f0cc3},
	abstract = {We investigate the task of inserting new concepts extracted from texts into an ontology using language models. We explore an approach with three steps: edge search which is to find a set of candidate locations to insert (i.e., subsumptions between concepts), edge formation and enrichment which leverages the ontological structure to produce and enhance the edge candidates, and edge selection which eventually locates the edge to be placed into. In all steps, we propose to leverage neural methods, where we apply embedding-based methods and contrastive learning with Pre-trained Language Models (PLMs) such as BERT for edge search, and adapt a BERT fine-tuning-based multi-label Edge-Cross-encoder, and Large Language Models (LLMs) such as GPT series, FLAN-T5, and Llama 2, for edge selection. We evaluate the methods on recent datasets created using the SNOMED CT ontology and the MedMentions entity linking benchmark. The best settings in our framework use fine-tuned PLM for search and a multi-label Cross-encoder for selection. Zero-shot prompting of LLMs is still not adequate for the task, and we propose explainable instruction tuning of LLMs for improved performance. Our study shows the advantages of PLMs and highlights the encouraging performance of LLMs that motivates future studies. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {Concept Placement; Large Language Models; Ontology Enrichment; Pre-trained Language Models; SNOMED CT},
	keywords = {Computational linguistics; Signal encoding; Zero-shot learning; Concept placement; Edge searches; Edge selection; Language model; Large language model; Ontology enrichment; Ontology's; Pre-trained language model; SNOMED-CT; Ontology},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@CONFERENCE{Knez2024131,
	author = {Knez, Timotej and Žitnik, Slavko},
	title = {Towards using Automatically Enhanced Knowledge Graphs to Aid Temporal Relation Extraction},
	year = {2024},
	journal = {1st Workshop on Patient-Oriented Language Processing, CL4Health 2024 at LREC-COLING 2024 - Workshop Proceedings},
	pages = {131 – 136},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195205041&partnerID=40&md5=743870793a52e0324fc13095d636bd96},
	abstract = {Temporal relation extraction in medical document analysis is crucial for understanding patient histories and treatment outcomes. This paper introduces a novel approach leveraging a bimodal model integrating textual content and a knowledge graph to enhance temporal relation extraction. The paper presents ongoing research on constructing an optimal knowledge graph by augmenting PrimeKG with dynamically expanded information using a language model-generated knowledge graph. It also further personalizes the information with patient-specific graphs tailored for relation prediction. The pipeline for constructing this enriched knowledge graph is detailed, aiming to improve the capabilities of temporal relation extraction models. The preliminary results show that adding a simple knowledge graph to the temporal relation extraction model can significantly increase the performance, achieving new state-of-the-art results. While research on enhanced knowledge graphs is ongoing, this paper lays the groundwork for leveraging common knowledge to advance temporal relation extraction in medical contexts. This approach holds promise for enhancing the understanding of patient histories and treatment outcomes, potentially leading to improved healthcare decision-making and patient care. © 2024 ELRA Language Resource Association: CC BY-NC 4.0.},
	author_keywords = {Information extraction; Knowledge graph building; Large language models},
	keywords = {Computational linguistics; Data mining; Decision making; Knowledge management; Patient treatment; Extraction modeling; Information extraction; Knowledge graph building; Knowledge graphs; Language model; Large language model; Patient history; Relation extraction; Temporal relation; Treatment outcomes; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Chen202414579,
	author = {Chen, Zhuo and Zhang, Zhao and Li, Zixuan and Wang, Fei and Zeng, Yutao and Jin, Xiaolong and Xu, Yongjun},
	title = {Self-Improvement Programming for Temporal Knowledge Graph Question Answering},
	year = {2024},
	journal = {2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation, LREC-COLING 2024 - Main Conference Proceedings},
	pages = {14579 – 14594},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195967051&partnerID=40&md5=086d8d1e00b61597f09d01de2155ae0f},
	abstract = {Temporal Knowledge Graph Question Answering (TKGQA) aims to answer questions with temporal intent over Temporal Knowledge Graphs (TKGs). The core challenge of this task lies in understanding the complex semantic information regarding multiple types of time constraints (e.g., before, first) in questions. Existing end-to-end methods implicitly model the time constraints by learning time-aware embeddings of questions and candidate answers, which is far from understanding the question comprehensively. Motivated by semantic-parsing-based approaches that explicitly model constraints in questions by generating logical forms with symbolic operators, we design fundamental temporal operators for time constraints and introduce a novel self-improvement Programming method for TKGQA (Prog-TQA). Specifically, Prog-TQA leverages the in-context learning ability of Large Language Models (LLMs) to understand the combinatory time constraints in the questions and generate corresponding program drafts with a few examples given. Then, it aligns these drafts to TKGs with the linking module and subsequently executes them to generate the answers. To enhance the ability to understand questions, Prog-TQA is further equipped with a self-improvement strategy to effectively bootstrap LLMs using high-quality self-generated drafts. Extensive experiments demonstrate the superiority of the proposed Prog-TQA on MultiTQ and CronQuestions datasets, especially in the Hits@1 metric. © 2024 ELRA Language Resource Association: CC BY-NC 4.0.},
	author_keywords = {In-Context Learning; Self-Improvement; Temporal Knowledge Graph Question Answering},
	keywords = {Learning systems; Natural language processing systems; Semantics; Context learning; In contexts; In-context learning; Knowledge graphs; Language model; Question Answering; Self-improvement; Temporal knowledge; Temporal knowledge graph question answering; Time constraints; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{2024,
	title = {International workshops associated with the 36th International Conference on Advanced Information Systems Engineering, CAiSE 2024},
	year = {2024},
	journal = {Lecture Notes in Business Information Processing},
	volume = {521},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196159305&partnerID=40&md5=85f14af837281d59e3399cbc9387e98e},
	abstract = {The proceedings contain 30 papers. The special focus in this conference is on Advanced Information Systems Engineering. The topics include: Blockchain in E-Learning Platform to Enhance Trustworthy and Sharing of Micro-credentials; overstock Problems in a Purchase-to-Pay Process: An Object-Centric Process Mining Case Study; online Next Activity Prediction Under Concept Drifts; a Meta-Design Method for Modeling Customer Value; comparing Process Models Beyond Structural Equivalence; process-Specific Extensions for Enhanced Recommender Systems in Business Process Management; BPMN for Displaying the Progression of Musical Harmony and Chords - Case Study; conceptual Data Normalisation from the Practical View of Using Graph Databases; analyzing Customer Sentiments: A Comparative Evaluation of Large Language Models for Enhanced Business Intelligence; customizing a Generic Digital Transformation Objectives Model onto a Telecommunication Company; an Ontology-Based Meta-modelling Approach for Semantic-Driven Building Management Systems; LLMs for Knowledge-Graphs Enhanced Task-Oriented Dialogue Systems: Challenges and Opportunities; A Survey to Evaluate the Completeness and Correctness of a Morphological Box for AI Solutions; student Performance Prediction Model Based on Course Description and Student Similarity; Enhancing Research Clarity: Ontology-Based Modeling of Argumentation in RPML; a Conceptual Model for Blockchain-Based Trust in Digital Ecosystems (Short Paper); preface; deriving Object Oriented Normalisation from Conceptual Normalisation; empirical Insights into Context-Aware Process Predictions: Model Selection and Context Integration; improving the Service Quality in Fitness Industry by Using a Knowledge Graph Based Modeling Toolkit; An Explanation User Interface for a Knowledge Graph-Based XAI Approach to Process Analysis; Integrating Generative Artificial Intelligence into Supply Chain Management Education Using the SCOR Model; Towards Explainable Public Sector AI: An Exploration of Neuro-Symbolic AI and Enterprise Modeling (Short Paper).},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Ludwig2024143,
	author = {Ludwig, Heiner and Betker, Vincent and Schmidt, Thorsten and Kühn, Mathias},
	title = {SPEECH-TO-JOBSHOP: AN ONTOLOGY-DRIVEN DIGITAL ASSISTANT FOR SIMULATION MODELING},
	year = {2024},
	journal = {Proceedings - European Council for Modelling and Simulation, ECMS},
	volume = {38},
	number = {1},
	pages = {143 – 149},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195222610&partnerID=40&md5=4df1984998f2d5b0192a4f7b121cb30c},
	abstract = {This paper introduces a novel method utilizing speech-based digital assistants and large language models (LLMs) to streamline the creation of simulation models for Job Shop Scheduling Problems (JSSP). The system simplifies the process by allowing natural language interactions for ontology-based model generation. The study evaluates the performance of various LLMs in ontology-based simulation modeling by benchmarking their ability to extract and assign semantical entities and relations. We found that ChatGPT-4Turbo is able to correctly identify all model elements given in descriptions of the production scenarios we tested, while less resource-intensive and open source models like Mixtral-8x7b and Zephyr-beta perform well in a less complex scenario. The findings demonstrate the potential of integrating LLMs and natural language processing in simulation modeling, significantly enhancing efficiency and reducing the need for manual modeling. ©ECMS Daniel Grzonka, Natalia Rylko, Grazyna Suchacka, Vladimir Mityushev (Editors) 2024.},
	author_keywords = {Digital Assistant; Job Shop Scheduling; Large Language Models; Ontology; Simulation Modeling},
	keywords = {Benchmarking; Computational linguistics; Job shop scheduling; Modeling languages; Natural language processing systems; Digital assistants; Job shop scheduling problems; Job-shop; Job-Shop scheduling; Language model; Large language model; Novel methods; Ontology's; Simulation model; Simulation-modelling; Ontology},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{2024,
	title = {Text2Story 2024 - Proceedings of Text2Story: 7th Workshop on Narrative Extraction From Texts, held in conjunction with the 46th European Conference on Information Retrieval, ECIR 2024},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3671},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191976889&partnerID=40&md5=a84570a1b85d848f49fb348fb48ba76d},
	abstract = {The proceedings contain 13 papers. The topics discussed include: dataset annotation and model building for identifying biases in news narratives; evaluating the ability of computationally extracted narrative maps to encode media framing; from nodes to narratives: a knowledge graph-based storytelling approach; estimating narrative durations: proof of concept; ROGER: extracting narratives using large language models from Robert Gerstmann's historical photo archive of the Sacambaya Expedition in 1928; representing complex relative chronology across narrative levels in movie plots; untangling a web of temporal relations in news articles; the geography of ‘fear’, ‘sadness’, ‘anger’ and ‘joy’: exploring the emotional landscapes in the holocaust survivors’ testimonies; and unexpected gender stereotypes in AI-generated stories: hairdressers are female, but so are doctors.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Wang2024361,
	author = {Wang, Peng and Karigiannis, John and Gao, Robert X.},
	title = {Ontology-integrated tuning of large language model for intelligent maintenance},
	year = {2024},
	journal = {CIRP Annals},
	volume = {73},
	number = {1},
	pages = {361 – 364},
	doi = {10.1016/j.cirp.2024.04.012},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195267530&doi=10.1016%2fj.cirp.2024.04.012&partnerID=40&md5=ba267e63eb725962a7fdd0e1253e17d1},
	abstract = {As new AI technologies such as Large Language Models (LLM) quickly evolve, the need for enhancing general-purpose LLMs with physical knowledge to better serve the manufacturing community has been increasingly recognized. This paper presents a method that tailors GPT-3.5 with domain-specific knowledge for intelligent aircraft maintenance. Specifically, aircraft ontology is investigated to curate maintenance logs with encoded component hierarchical structure to fine-tune GPT-3.5. Experimental results demonstrate the effectiveness of the developed method in accurately identifying defective components and providing consistent maintenance action recommendations, outperforming general-purpose GPT-3.5 and GPT-4.0. The method can be adapted to other domains in manufacturing and beyond. © 2024 The Author(s)},
	author_keywords = {Large language models; Machine learning; Maintenance},
	keywords = {Aircraft; Computational linguistics; Domain Knowledge; Machine learning; Ontology; AI Technologies; Aircraft maintenance; Consistent maintenance; Domain-specific knowledge; Hierarchical structures; Intelligent maintenance; Language model; Large language model; Machine-learning; Ontology's; Maintenance},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Dong202413,
	author = {Dong, Haoling and Wu, Bin},
	title = {Enhancing Named Entity Recognition in Safety Hazard Analysis through GBD and LLMs},
	year = {2024},
	journal = {Proceedings - 2024 7th International Conference on Information and Computer Technologies, ICICT 2024},
	pages = {13 – 19},
	doi = {10.1109/ICICT62343.2024.00009},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196105772&doi=10.1109%2fICICT62343.2024.00009&partnerID=40&md5=1e1ce23ea877e667d34594300b77ebe7},
	abstract = {With the continuous enhancement of informatization in production safety, the need to strengthen the analysis capability of big data in production safety is increasingly growing. This is crucial for preventing major accidents and ensuring production safety. However, the main challenge currently faced is that information about safety hazards often appears in unstructured text formats, lacking a unified standard and normative system. This makes it difficult to standardize knowledge extraction from hazard information. Additionally, traditional named entity recognition methods arc inadequate in understanding sentence structures, lexical components, and the dependency relationships between words, especially in processing texts in specific complex domains, where their entity recognition effects arc still insufficient. Given this, the research focus of this paper includes: deeply exploring the concept and connotation of big data in hazard information, clarifying the classification system of hazard information; designing a standard hazard information annotation template specifically for the field of production safety; designing a named entity recognition method based on GBD; designing and implementing a named entity recognition method based on LLMs; and based on the recognition results, constructing a knowledge graph of the relevant field to promote its effective utilization in practical applications. © 2024 IEEE.},
	author_keywords = {deep learning; entity recognition; hazard information; large language models; production safety},
	keywords = {Big data; Classification (of information); Deep learning; Knowledge graph; Deep learning; Entity recognition; Hazard information; Hazards analysis; Language model; Large language model; Named entity recognition; Production safety; Recognition methods; Safety hazards; Hazards},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Almeman202417683,
	author = {Almeman, Fatemah and Schockaert, Steven and Espinosa-Anke, Luis},
	title = {WordNet under Scrutiny: Dictionary Examples in the Era of Large Language Models},
	year = {2024},
	journal = {2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation, LREC-COLING 2024 - Main Conference Proceedings},
	pages = {17683 – 17695},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195959037&partnerID=40&md5=e15ecd1594f4582b2aa659f387ad15ad},
	abstract = {Dictionary definitions play a prominent role in a wide range of NLP tasks, for instance by providing additional context about the meaning of rare and emerging terms. Many dictionaries also provide examples to illustrate the prototypical usage of words, which brings further opportunities for training or enriching NLP models. The intrinsic qualities of dictionaries, and related lexical resources such as glossaries and encyclopedias, are however still not well-understood. While there has been significant work on developing best practices, such guidance has been aimed at traditional usages of dictionaries (e.g. supporting language learners), and it is currently unclear how different quality aspects affect the NLP systems that rely on them. To address this issue, we compare WordNet, the most commonly used lexical resource in NLP, with a variety of dictionaries, as well as with examples that were generated by ChatGPT. Our analysis involves human judgments as well as automatic metrics. We furthermore study the quality of word embeddings derived from dictionary examples, as a proxy for downstream performance. We find that WordNet's examples lead to lower-quality embeddings than those from the Oxford dictionary. Surprisingly, however, the ChatGPT generated examples were found to be most effective overall. © 2024 ELRA Language Resource Association: CC BY-NC 4.0.},
	author_keywords = {dictionary examples; lexical resources; semantics},
	keywords = {Embeddings; Natural language processing systems; Ontology; Best practices; Dictionary definitions; Dictionary example; Embeddings; Human judgments; Language model; Lexical resources; NLP systems; Quality aspects; Wordnet; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Daga202437,
	author = {Daga, Enrico and Carvalho, Jason and Tirado, Alba Morales},
	title = {Extracting licence information from web resources with a Large Language Model},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3697},
	pages = {37 – 48},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195499649&partnerID=40&md5=a8b77fa594f7a7f7d3dbdbb62d259834},
	abstract = {Data catalogues play an increasing role in supporting information sharing and reuse on the Web. However, evaluating the reusability of Web resources requires an understanding of the related licence and terms of use. Recent methods for licence representation and reasoning allows to explore Web resources according to their permissions, obligations, and duties. Therefore, licence annotations should be linked to those representations in order to support users in filtering and exploring datasets according to their licencing requirements. However, populating data catalogues with licence information is a tedious and error-prone task. In this paper, we explore the suitability of a Large Language Model (LLM) to support the automatic extraction, annotation, and linking of licence information from reference Web pages of data catalogue items. The approach is evaluated for its capacity to automatically find relevant pages from within a main web page, extract data about copyright and licencing, and link licence descriptions to a knowledge graph of licences expressed in RDF/ODRL. We apply our method to extend the coverage of licence annotations of a data catalogue in the music domain. © 2024 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).},
	author_keywords = {Knowledge Graphs; Large Language Models; Licence Extraction; Open Digital Rights Language},
	keywords = {Computational linguistics; Copyrights; Data mining; High level languages; Knowledge graph; Resource Description Framework (RDF); Reusability; Websites; Digital rights; Error prone tasks; Information sharing and reuse; Knowledge graphs; Language model; Large language model; License extraction; Open digital right language; Web resources; Web-page; Extraction},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Luo202412361,
	author = {Luo, Zhizhao and Wang, Youchen and Ke, Wenjun and Qi, Rui and Guo, Yikai and Wang, Peng},
	title = {BOOSTING LLMS WITH ONTOLOGY-AWARE PROMPT FOR NER DATA AUGMENTATION},
	year = {2024},
	journal = {ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings},
	pages = {12361 – 12365},
	doi = {10.1109/ICASSP48485.2024.10446860},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195380625&doi=10.1109%2fICASSP48485.2024.10446860&partnerID=40&md5=bc05c98bc3d0a37a1e28f15d9cef2535},
	abstract = {Named Entity Recognition (NER) data augmentation (DA) aims to improve the performance and generalization capabilities of NER models by generating scalable training data. The key challenge lies in ensuring the generated samples maintain contextual diversity while preserving label consistency. However, existing dominant methods fail to simultaneously satisfy both criteria. Inspired by the extensive generative capabilities of large language models (LLMs), we propose ANGEL, a frAmework integrating the oNtoloGy structure and instructivE prompting within LLMs. Specifically, the hierarchical ontology structure guides prompt ranking, while instructive prompting enhances LLMs' mastery of domain knowledge, empowering synthetic sample generation and annotation. Experiments show ANGEL surpasses state-of-the-art (SOTA) baselines, conferring absolute F1 increases of 2.86% and 0.93% on two benchmark datasets, respectively. © 2024 IEEE.},
	author_keywords = {Data Augmentation; Knowledge Graph; Large language Model; Named Entity Recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Liga2024115,
	author = {Liga, Davide and Fidelangeli, Alessia and Markovich, Réka},
	title = {Using Ontological Knowledge and Large Language Model Vector Similarities to Extract Relevant Concepts in VAT-Related Legal Judgments},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14644 LNAI},
	pages = {115 – 131},
	doi = {10.1007/978-3-031-60511-6_8},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196742580&doi=10.1007%2f978-3-031-60511-6_8&partnerID=40&md5=4a6363d5c3d10e4818d6db0976ab391b},
	abstract = {In this paper, we present OntoVAT, a multilingual ontology designed for extracting knowledge in legal judgments related to VAT (Value-Added Tax). This is, to our knowledge, the first extensive ontology in the VAT domain. OntoVAT aims to encapsulate critical concepts in the European VAT area and offers a scalable and reusable knowledge structure to support the automatic identification of VAT-specific concepts in legal texts. Additionally, OntoVAT supports various Artificial Intelligence and Law (AI &Law) tasks, such as extracting legal knowledge, identifying keywords, modeling topics, and extracting semantic relations. Developed using OWL with SKOS lexicalization, OntoVAT’s initial version includes ontological patterns and relations. It is available in three languages, marking a collaborative effort between computer scientists and subject matter experts. In this work, we also present an application scenario where the knowledge encoded within OntoVAT is leveraged in combination with several recent Large Language Models (LLMs). For this application, for which we used the most powerful open source LLMs available today (both generative and non-generative, including legal LLMs), we show the system’s design and some preliminary results. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {AI &Law; Large Language Models; Legal Ontology; VAT},
	keywords = {Automation; Computational linguistics; Computer software reusability; Data mining; Distributed computer systems; Knowledge management; Open systems; Semantics; Artificial intelligence and laws; Language model; Large language model; Legal judgements; Legal ontology; Model vectors; Multilingual ontologies; Value-added tax; Vector similarity; Ontology},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Morales Tirado2024110,
	author = {Morales Tirado, Alba and Carvalho, Jason and Ratta, Marco and Uwasomba, Chukwudi and Mulholland, Paul and Barlow, Helen and Herbert, Trevor and Daga, Enrico},
	title = {Musical Meetups Knowledge Graph (MMKG): A Collection of Evidence for Historical Social Network Analysis},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14665 LNCS},
	pages = {110 – 127},
	doi = {10.1007/978-3-031-60635-9_7},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195284310&doi=10.1007%2f978-3-031-60635-9_7&partnerID=40&md5=4e278bf565de4d458f4286c5577df906},
	abstract = {Knowledge Graphs (KGs) have emerged as a valuable tool for supporting humanities scholars and cultural heritage organisations. In this resource paper, we present the Musical Meetups Knowledge Graph (MMKG), a collection of evidence of historical collaborations between personalities relevant to the music history domain. We illustrate how we built the KG with a hybrid methodology that, combining knowledge engineering with natural language processing, including the use of Large Language Models (LLM), machine learning, and other techniques, identifies the constituent elements of a historical meetup. MMKG is a network of historical meetups extracted from ∼33k biographies collected from Wikipedia focused on European musical culture between 1800 and 1945. We discuss how, by providing a structured representation of social interactions, MMKG supports digital humanities applications and music historians’ research, teaching, and learning. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {historical encounters; Historical Social Network Analysis; Knowledge Graph; MEETUPS},
	keywords = {History; Music; Natural language processing systems; Cultural heritages; Historical encounter; Historical social network analyse; Hybrid methodologies; Knowledge graphs; Language processing; MEETUPS; Natural languages; Resource paper; Social Network Analysis; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{2024,
	title = {SemTech4STLD 2024 - 2nd International Workshop on Semantic Technologies and Deep Learning Models for Scientific, Technical and Legal Data, co-located with the Extended Semantic Web Conference 2024, ESWC 2024},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3697},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195450397&partnerID=40&md5=f661c13e9a90fb88a27d4c3fc305a240},
	abstract = {The proceedings contain 8 papers. The topics discussed include: GerPS-NER: a dataset for named entity recognition to support public service process creation in Germany; ChatGPT vs. Google Gemini: assessing AI frontiers for patent prior art search using European search reports; PRICER: leveraging few-shot learning with fine-tuned large language models for unstructured economic data; extracting license information from web resources with a large language model; investigating environmental, social, and governance (ESG) discussions in news: a knowledge graph analysis empowered by AI; bridging the innovation gap: leveraging patent information for scientists by constructing a patent-centric knowledge graph; automating citation placement with natural language processing and transformers; and combining knowledge graphs and large language models to ease knowledge access in software architecture research.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Xu202411956,
	author = {Xu, Derong and Zhang, Ziheng and Lin, Zhenxi and Wu, Xian and Zhu, Zhihong and Xu, Tong and Zhao, Xiangyu and Zheng, Yefeng and Chen, Enhong},
	title = {Multi-perspective Improvement of Knowledge Graph Completion with Large Language Models},
	year = {2024},
	journal = {2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation, LREC-COLING 2024 - Main Conference Proceedings},
	pages = {11956 – 11968},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195893869&partnerID=40&md5=fa9a94965a16a4cdf9679d53a7de8f99},
	abstract = {Knowledge graph completion (KGC) is a widely used method to tackle incompleteness in knowledge graphs (KGs) by making predictions for missing links. Description-based KGC leverages pre-trained language models to learn entity and relation representations with their names or descriptions, which shows promising results. However, the performance of description-based KGC is still limited by the quality of text and the incomplete structure, as it lacks sufficient entity descriptions and relies solely on relation names, leading to sub-optimal results. To address this issue, we propose MPIKGC, a general framework to compensate for the deficiency of contextualized knowledge and improve KGC by querying large language models (LLMs) from various perspectives, which involves leveraging the reasoning, explanation, and summarization capabilities of LLMs to expand entity descriptions, understand relations, and extract structures, respectively. We conducted extensive evaluation of the effectiveness and improvement of our framework based on four description-based KGC models and four datasets, for both link prediction and triplet classification tasks. © 2024 ELRA Language Resource Association: CC BY-NC 4.0.},
	author_keywords = {Knowledge Graph Completion; Large Language Models},
	keywords = {Classification (of information); Computational linguistics; Knowledge management; Contextualized knowledge; Knowledge graph completion; Knowledge graphs; Language model; Large language model; Learn+; Link prediction; Multi-perspective; Optimal results; Performance; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5}
}

@ARTICLE{Schultenkämper2024150,
	author = {Schultenkämper, Sergej and Bäumer, Frederik Simon},
	title = {Structured Knowledge Extraction for Digital Twins: Leveraging LLMs to Analyze Tweets},
	year = {2024},
	journal = {Communications in Computer and Information Science},
	volume = {2109 CCIS},
	pages = {150 – 165},
	doi = {10.1007/978-3-031-60433-1_10},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197227122&doi=10.1007%2f978-3-031-60433-1_10&partnerID=40&md5=6a5b6479c2f692d34732197763242c2a},
	abstract = {This paper concentrates on the extraction of pertinent information from unstructured data, specifically analyzing textual content disseminated by users on X/Twitter. The objective is to construct an exhaustive knowledge graph by discerning implicit personal data from tweets. The gleaned information serves to instantiate a digital counterpart and establish a tailored alert mechanism aimed at shielding users from threats such as social engineering or doxing. The study assesses the efficacy of fine-tuning cutting-edge open source large language models for extracting pertinent triples from tweets. Additionally, it delves into the concept of digital counterparts within the realm of cyber threats and presents relevant works in information extraction. The methodology encompasses data acquisition, relational triple extraction, large language model fine-tuning, and subsequent result evaluation. Leveraging a X/Twitter dataset, the study scrutinizes the challenges inherent in user-generated data. The outcomes underscore the precision of the extracted triples and the discernible personal traits gleaned from tweets.  © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {Information extraction; Knowledge graph; Privacy},
	keywords = {Computational linguistics; Data mining; Data privacy; Information retrieval; Knowledge graph; Knowledge management; Digital counterparts; Fine tuning; Information extraction; Knowledge extraction; Knowledge graphs; Language model; Privacy; Structured knowledge; Textual content; Unstructured data; Data acquisition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Zhang20242594,
	author = {Zhang, Shiyao and Dong, Yuji and Zhang, Yichuan and Payne, Terry R. and Zhang, Jie},
	title = {Large Language Model Assisted Multi-Agent Dialogue for Ontology Alignment},
	year = {2024},
	journal = {Proceedings of the International Joint Conference on Autonomous Agents and Multiagent Systems, AAMAS},
	volume = {2024-May},
	pages = {2594 – 2596},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192997204&partnerID=40&md5=5a51d0a74903a3408ce05f2f077d62e6},
	abstract = {Ontology alignment is critical in cross-domain integration; however, it typically necessitates the involvement of a human domain-expert, which can make the task costly. Although a variety of machine-learning approaches have been proposed that can simplify this task by learning the patterns from experts, such techniques are still susceptible to domain knowledge updates that could potentially change the patterns and lead to extra expert involvement. The use of Large Language Models (LLMs) has demonstrated a general cognitive ability, which has the potential to assist ontology alignment from the cognition level, thus obviating the need for costly expert involvement. However, the process by which the output of LLMs is generated can be opaque and thus the reliability and interpretability of such models is not always predictable. This paper proposes a dialogue model, in which multiple agents negotiate the correspondence between two knowledge sets with the support from an LLM. We demonstrate that this approach not only reduces the need for the involvement of a domain expert for ontology alignment, but that the results are interpretable despite the use of LLMs. © 2024 International Foundation for Autonomous Agents and Multiagent Systems.},
	author_keywords = {Dialogue; Large Language Model; Multi-Agent System; Negotiation; Ontology Alignment},
	keywords = {Autonomous agents; Computational linguistics; Domain Knowledge; Learning systems; Ontology; Cross-domain; Dialog; Domain experts; Human domain; Language model; Large language model; Machine learning approaches; Multi agent; Negotiation; Ontology alignment; Multi agent systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@ARTICLE{Feng20241637,
	author = {Feng, Jun and Chang, Yanghong and Lu, Jiamin and Tang, Hailin and Lyu, Zhipeng and Qiu, Yuchun},
	title = {Construction and Application of Knowledge Graph for Water Engineering Scheduling Based on Large Language Model; [基于大语言模型的水工程调度知识图谱的构建与应用]},
	year = {2024},
	journal = {Journal of Frontiers of Computer Science and Technology},
	volume = {18},
	number = {6},
	pages = {1637 – 1647},
	doi = {10.3778/j.issn.1673-9418.2311098},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195585807&doi=10.3778%2fj.issn.1673-9418.2311098&partnerID=40&md5=26a7a3f6700ef3f928eac7a9207fa2f1},
	abstract = {With the growth of water conservancy and the increasing demand for information, handling and representing large volumes of water-related data has become complex. Particularly, scheduling textual data often exists in natural language form, lacking clear structure and standardization. Processing and utilizing such diverse data necessitates extensive domain knowledge and professional expertise. To tackle this challenge, a method based on large language model has been proposed to construct a knowledge graph for water engineering scheduling. This approach involves collecting and preprocessing scheduling rule data at the data layer, leveraging large language models to extract embedded knowledge, constructing the ontology at the conceptual layer, and extracting the“three- step”method prompt strategy at the instance layer. Under the interaction of the data, conceptual, and instance layers, high-performance extraction of rule texts is achieved, and the construction of the dataset and knowledge graph is completed. Experimental results show that the F1 value of the extraction method in this paper reaches 85.5%, and the effectiveness and rationality of the modules of the large language model are validated through ablation experiments. This graph integrates dispersed water conservancy rule information, effectively handles unstructured textual data, and offers visualization querying and functionality tracing. It aids professionals in assessing water conditions and selecting appropriate scheduling schemes, providing valuable support for conservancy decision-making and intelligent reasoning. © 2024 Journal of Computer Engineering and Applications Beijing Co., Ltd.; Science Press. All rights reserved.},
	author_keywords = {knowledge extraction; knowledge graph; large language model (LLM); ontology construction; water engineering scheduling},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@ARTICLE{2024,
	title = {30th International Working Conference on Requirements Engineering: Foundation for Software Quality, REFSQ 2024},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14588 LNCS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190711457&partnerID=40&md5=8a1ac6e4ce36f9ac3846b7874da487cc},
	abstract = {The proceedings contain 22 papers. The special focus in this conference is on Requirements Engineering: Foundation for Software Quality. The topics include: Assessing the Understandability and Acceptance of Attack-Defense Trees for Modelling Security Requirements; learning to Rank Privacy Design Patterns: A Semantic Approach to Meeting Privacy Requirements; a New Usability Inspection Method: Experience-Based Analysis; governance-Focused Classification of Security and Privacy Requirements from Obligations in Software Engineering Contracts; what Impact Do My Preferences Have?; Candidate Solutions for Defining Explainability Requirements of AI Systems; Opportunities and Limitations of AI in Human-Centered Design a Research Preview; A Tertiary Study on AI for Requirements Engineering; Exploring LLMs’ Ability to Detect Variability in Requirements; Designing NLP-Based Solutions for Requirements Variability Management: Experiences from a Design Science Study at Visma; Natural2CTL: A Dataset for Natural Language Requirements and Their CTL Formal Equivalents; Towards a Comprehensive Ontology for Requirements Engineering for AI-Powered Systems; Operationalizing Machine Learning Using Requirements-Grounded MLOps; unveiling Competition Dynamics in Mobile App Markets Through User Reviews; exploring the Automatic Classification of Usage Information in Feedback; channeling the Voice of the Crowd: Applying Structured Queries in User Feedback Collection; requirements Information in Backlog Items: Content Analysis; Requirements Engineering for No-Code Development (RE4NCD); behavior-Driven Specification in Practice: An Experience Report; the Return of Formal Requirements Engineering in the Era of Large Language Models.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Jiayang20246622,
	author = {Jiayang, Cheng and Qiu, Lin and Chan, Chunkit and Liu, Xin and Song, Yangqiu and Zhang, Zheng},
	title = {EventGround: Narrative Reasoning by Grounding to Eventuality-centric Knowledge Graphs},
	year = {2024},
	journal = {2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation, LREC-COLING 2024 - Main Conference Proceedings},
	pages = {6622 – 6642},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195892386&partnerID=40&md5=99fa1360f3ba93ebfdc48c31ea8f7a72},
	abstract = {Narrative reasoning relies on the understanding of eventualities in story contexts, which requires a wealth of background world knowledge. To help machines leverage such knowledge, existing solutions can be categorized into two groups. Some focus on implicitly modeling eventuality knowledge by pretraining language models (LMs) with eventuality-aware objectives. However, this approach breaks down knowledge structures and lacks interpretability. Others explicitly collect world knowledge of eventualities into structured eventuality-centric knowledge graphs (KGs). However, existing research on leveraging these knowledge sources for free-texts is limited. In this work, we propose an initial comprehensive framework called EventGround, which aims to tackle the problem of grounding free-texts to eventuality-centric KGs for contextualized narrative reasoning. We identify two critical problems in this direction: the event representation and sparsity problems. We provide simple yet effective parsing and partial information extraction methods to tackle these problems. Experimental results demonstrate that our approach consistently outperforms baseline models when combined with graph neural network (GNN) or large language model (LLM) based graph reasoning models. Our framework, incorporating grounded knowledge, achieves state-of-the-art performance while providing interpretable evidence. © 2024 ELRA Language Resource Association: CC BY-NC 4.0.},
	author_keywords = {Eventuality-centric Knowledge Graphs; Knowledge grounding; Reasoning},
	keywords = {Graph neural networks; Knowledge graph; Knowledge management; Modeling languages; Break down; Eventuality-centric knowledge graph; Free texts; Knowledge graphs; Knowledge grounding; Knowledge structures; Language model; Pre-training; Reasoning; World knowledge; Computational linguistics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Avila2024277,
	author = {Avila, Caio Viktor S. and Vidal, Vania M.P. and Franco, Wellington and Casanova, Marco A.},
	title = {Experiments with text-to-SPARQL based on ChatGPT},
	year = {2024},
	journal = {Proceedings - IEEE International Conference on Semantic Computing, ICSC},
	pages = {277 – 284},
	doi = {10.1109/ICSC59802.2024.00050},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192238824&doi=10.1109%2fICSC59802.2024.00050&partnerID=40&md5=45d00263fefd8d8ac020053950235db9},
	abstract = {Currently, large language models (LLMs) are the state of the art for pre-trained language models. LLMs have been applied to many tasks, including question and answering over Knowledge Graphs (KGs) and text-to-SPARQL, that is, the translation of Natural Language questions to SPARQL queries. With such motivation, this paper first describes preliminary experiments to evaluate the ability of ChatGPT to answer NL questions over KGs. Based on these experiments, the paper introduces Auto-KGQAGPT, an autonomous domain-independent framework based on LLMs for text-to-SPARQL. The framework selects fragments of the KG, which the LLM uses to translate the user's NL question to a SPARQL query on the KG. Finally, the paper describes preliminary experiments with Auto-KGQAGPT with ChatGPT that indicate that the framework substantially reduced the number of tokens passed to ChatGPT without sacrificing performance.  © 2024 IEEE.},
	author_keywords = {ChatGPT; Knowledge Graph; LLM; text-to-SPARQL},
	keywords = {Computational linguistics; Natural language processing systems; Query processing; Translation (languages); Autonomous domains; ChatGPT; Domain independents; Graph-based; Knowledge graphs; Language model; Large language model; Natural language questions; State of the art; Text-to-SPARQL; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@ARTICLE{2024,
	title = {36th International Conference on Advanced Information Systems Engineering, CAiSE 2024},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14663 LNCS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196732784&partnerID=40&md5=c128c45a09008e145a19f2e9a0bd558e},
	abstract = {The proceedings contain 18 papers. The special focus in this conference is on Advanced Information Systems Engineering. The topics include: Incorporating Behavioral Recommendations Mined from Event Logs into AI Planning; trustworthy Collaborative Business Intelligence Using Zero-Knowledge Proofs and Blockchains; Towards Intelligent Systems to Improve IEC 62559 Use Cases and Smart Grid Architecture Models Quality; pricing4SaaS: Towards a Pricing Model to Drive the Operation of SaaS; Validity at the Forefront: Investigating Threats in Green AI Research; requirement-Based Methodological Steps to Identify Ontologies for Reuse; Toward Ontology-Guided IFRS Standard-Setting; towards an Explorable Conceptual Map of Large Language Models; proReco: A Process Discovery Recommender System; recPro: A User-Centric Recommendation Tool for Business Process Execution; predictive Maintenance in a Fleet Management System: The Navarchos Case; CDMiA: Revealing Impacts of Data Migrations on Schemas in Multi-model Systems; MApp-KG: Mobile App Knowledge Graph for Document-Based Feature Knowledge Generation; CAKE: Sharing Slices of Confidential Data on Blockchain; PADI-web for Plant Health Surveillance; PROMISE: A Framework for Model-Driven Stateful Prompt Orchestration.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Nguyen2024284,
	author = {Nguyen, Le-Minh and Khang, Le-Nguyen and Anh, Kieu Que and Hien, Nguyen Dieu and Nagai, Yukari},
	title = {Semantic Parsing for Question and Answering over Scholarly Knowledge Graph with Large Language Models},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14741 LNAI},
	pages = {284 – 298},
	doi = {10.1007/978-981-97-3076-6_20},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195286062&doi=10.1007%2f978-981-97-3076-6_20&partnerID=40&md5=dddc5c237515dbe2072f324bb68fe633},
	abstract = {This paper presents a study to answer the question of how to map a natural language (NL) sentence to a semantic representation and its application to question answering over the DBLP database. We investigate the deep learning approach using pre-trained models and their fine-tuning on training data for semantic parsing tasks. Experimental results on standard datasets show the effectiveness of pre-trained models in mapping an NL sentence to SPARQL, a query language for semantic databases. The results also show that the T5 and Flan-T5 models outperform other models in terms of translation accuracy. In addition to the empirical results on pre-trained models, we also consider the problem of examining large language models (LLMs) such as Llama and Mistras, or Qwen models for answering questions on the DBLP database. Experimental results showed the potentiality of using LLMs with chain-of-thought prompting methods. The results indicated that without using training data, we were able to obtain promising results for some types of questions when translating them to SPARQL. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2024.},
	author_keywords = {Knowledge Graph; Mapping NL to SPARQL; Question Answering; Relation search; Semantic parsing; Semantic Representation},
	keywords = {Computational linguistics; Deep learning; Knowledge graph; Mapping; Natural language processing systems; Query languages; Semantic Web; Semantics; Syntactics; Translation (languages); ITS applications; Knowledge graphs; Language model; Mapping natural language to SPARQL; Natural languages; Question Answering; Relation search; Semantic parsing; Semantic representation; Training data; Query processing},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Kaplan202476,
	author = {Kaplan, Angelika and Keim, Jan and Schneider, Marco and Koziolek, Anne and Reussner, Ralf},
	title = {Combining Knowledge Graphs and Large Language Models to Ease Knowledge Access in Software Architecture Research},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3697},
	pages = {76 – 82},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195499477&partnerID=40&md5=22a5105c0a7568af5241268b7c815dff},
	abstract = {Science enables progress. Software engineering research and its sub-research fields like software architecture have high economic relevance (cf. "software is eating the world") and serve as an enabler for technical innovations in other research fields as well. The ever-increasing amount of research results and insights creates the need for efficient knowledge documentation and search functions to access relevant information. Till now, scientific papers have been published digitally as PDF documents. Researchers and practitioners can access these documents via digital libraries and scientific search engines mostly with a simple keyword-based search. Literature studies in software engineering show that this procedure (a) requires enhanced information literacy skills even for domain experts and (b) is very time-consuming for aggregating evidence in written PDF articles to a specific field of interest. Consequently, we can derive a need for speeding up the information-finding process and effective knowledge representation as well as aggregation for evidence-based literature studies. As a result, we present our approach idea for effective knowledge access and discovery in software architecture research by combining knowledge graphs and large language models, using the complementary advantages of both concepts. © 2024 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).},
	author_keywords = {Knowledge Graphs; Large Language Models; Scientific Knowledge Access; Software Architecture Research},
	keywords = {Computational linguistics; Digital libraries; Knowledge graph; Search engines; Architecture research; Knowledge graphs; Language model; Large language model; Literature studies; Research fields; Scientific knowledge; Scientific knowledge access; Software architecture research; Software engineering research; Software architecture},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{2024,
	title = {1st Working conference on Artificial Intelligence Development for a Resilient and Sustainable Tomorrow, AI Tomorrow 2023},
	year = {2024},
	journal = {Informatik aktuell},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192224466&partnerID=40&md5=4634a0c705ca9947501ad95b2367c2b5},
	abstract = {The proceedings contain 12 papers. The special focus in this conference is on Artificial Intelligence Development for a Resilient and Sustainable Tomorrow. The topics include: AI-Powered Knowledge and Expertise Mining in Healthcare from a Field Experiment; iterative Development of a Process-Oriented Approach for the Selection of Platform-Based Digital Services; classification of Static Poses Based on Key Point Detection for Application of Incriminated Image Files; Human Centered Implementation Process of AI in SMEs – Conditions for Success; LLM-assisted Knowledge Graph Engineering: Experiments with ChatGPT; Foundations for the Development of an AI-based, Platformindipendent cOmpanion-app [for] Lifelong Learning-Optimization (APOLLO); viability of Knowledge Management Practices for a Successful Digital Transformation in Small- and Medium- Sized Enterprises; identification of Machine Learning Algorithms to Share Tacit Experimental Knowledge in Manual Production; An Application of AI for Online Estimation of the Impact of Imperfections in Additive Manufactured Components.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Tseng20248,
	author = {Tseng, Yu-Hsiang and Chen, Pin-Er and Lian, Da-Chen and Hsieh, Shu-Kai},
	title = {The semantic relations in LLMs: an information-theoretic compression approach},
	year = {2024},
	journal = {1st Workshop on Bridging Neurons and Symbols for Natural Language Processing and Knowledge Graphs Reasoning, NeusymBridge 2024 at LREC-COLING 2024 - Workshop Proceedings},
	pages = {8 – 21},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195184478&partnerID=40&md5=4dee6a48db55f833b4bf8b62456ab68c},
	abstract = {Compressibility is closely related to the predictability of the texts from the information theory viewpoint. As large language models (LLMs) are trained to maximize the conditional probabilities of upcoming words, they may capture the subtlety and nuances of the semantic constraints underlying the texts, and texts aligning with the encoded semantic constraints are more compressible than those that do not. This paper systematically tests whether and how LLMs can act as compressors of semantic pairs. Using semantic relations from English and Chinese Wordnet, we empirically demonstrate that texts with correct semantic pairings are more compressible than incorrect ones, measured by the proposed compression advantages index. We also show that, with the Pythia model suite and a fine-tuned model on Chinese Wordnet, compression capacities are modulated by the model’s seen data. These findings are consistent with the view that LLMs encode the semantic knowledge as underlying constraints learned from texts and can act as compressors of semantic information or potentially other structured knowledge. © 2024 ELRA Language Resource Association.},
	author_keywords = {arithmetic encoding; Chinese Wordnet; compression; large language model; lexical resource},
	keywords = {Compressors; Computational linguistics; Encoding (symbols); Ontology; Signal encoding; Arithmetic encoding; Chinese wordnet; Compression; Encodings; Language model; Large language model; Lexical resources; Semantic constraints; Semantic relations; Wordnet; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Nananukul2024,
	author = {Nananukul, Navapat and Kejriwal, Mayank},
	title = {HALO: An Ontology for Representing and Categorizing Hallucinations in Large Language Models},
	year = {2024},
	journal = {Proceedings of SPIE - The International Society for Optical Engineering},
	volume = {13058},
	doi = {10.1117/12.3014048},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196524410&doi=10.1117%2f12.3014048&partnerID=40&md5=7c87bd8c9a2cabafb85e132071b44473},
	abstract = {Recent progress in generative AI, including large language models (LLMs) like ChatGPT, has opened up significant opportunities in fields ranging from natural language processing to knowledge discovery and data mining. However, there is also a growing awareness that the models can be prone to problems such as making information up or 'hallucinations', and faulty reasoning on seemingly simple problems. Because of the popularity of models like ChatGPT, both academic scholars and citizen scientists have documented hallucinations of several different types and severity. Despite this body of work, a formal model for describing and representing these hallucinations (with relevant meta-data) at a fine-grained level, is still lacking. In this paper, we address this gap by presenting the Hallucination Ontology or HALO, a formal, extensible ontology written in OWL that currently offers support for six different types of hallucinations known to arise in LLMs, along with support for provenance and experimental metadata. We also collect and publish a dataset containing hallucinations that we inductively gathered across multiple independent Web sources, and show that HALO can be successfully used to model this dataset and answer competency questions. © 2024 SPIE.},
	author_keywords = {ChatGPT; Hallucination; Large Language Model; Ontology},
	keywords = {Computational linguistics; Data mining; Natural language processing systems; Ontology; ChatGPT; Hallucination; In-field; Knowledge discovery and data minings; Language model; Language processing; Large language model; Natural languages; Ontology's; Recent progress; Metadata},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@CONFERENCE{Salman202471,
	author = {Salman, Muhammad and Haller, Armin and Rodríguez Méndez, Sergio J. and Naseem, Usman},
	title = {Tiny But Mighty: A Crowdsourced Benchmark Dataset for Triple Extraction from Unstructured Text},
	year = {2024},
	journal = {ISA 2024: 20th Joint ACL - ISO Workshop on Interoperable Semantic Annotation at LREC-COLING 2024, Workshop Proceedings},
	pages = {71 – 81},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195207916&partnerID=40&md5=194bc92f2923bd730c7105bffa281838},
	abstract = {In the context of Natural Language Processing (NLP) and Semantic Web applications, constructing Knowledge Graphs (KGs) from unstructured text plays a vital role. Several techniques have been developed for KG construction from text, but the lack of standardized datasets hinders the evaluation of triple extraction methods. The evaluation of existing KG construction approaches is based on structured data or manual investigations. To overcome this limitation, this work introduces a novel dataset specifically designed to evaluate KG construction techniques from unstructured text. Our dataset consists of a diverse collection of compound and complex sentences meticulously annotated by human annotators with potential triples (subject, predicate, object). The annotations underwent further scrutiny by expert ontologists to ensure accuracy and consistency. For evaluation purposes, the proposed F-measure criterion offers a robust approach to quantify the relatedness and assess the alignment between extracted triples and the ground-truth triples, providing a valuable tool for evaluating the performance of triple extraction systems. By providing a diverse collection of high-quality triples, our proposed benchmark dataset offers a comprehensive training and evaluation set for refining the performance of state-of-the-art language models on a triple extraction task. Furthermore, this dataset encompasses various KG-related tasks, such as named entity recognition, relation extraction, and entity linking. © 2024 ELRA Language Resource Association: CC BY-NC 4.0.},
	author_keywords = {Knowledge Graph (KG); Large Language Models (LLMs); Natural Language Processing (NLP); Text Annotation; Triple},
	keywords = {Computational linguistics; Crowdsourcing; Extraction; Knowledge graph; Large datasets; Natural language processing systems; Quality control; Knowledge graph; Knowledge graphs; Language model; Language processing; Large language model; Natural language processing; Natural languages; Text annotations; Triple; Unstructured texts; Benchmarking},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Kimura202472,
	author = {Kimura, Risa and Nakajima, Tatsuo},
	title = {Exploring Opportunities from the More-than-Human Perspective for Investigating Wicked Problem in Our Entangled World},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14718 LNCS},
	pages = {72 – 92},
	doi = {10.1007/978-3-031-59988-0_5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195867512&doi=10.1007%2f978-3-031-59988-0_5&partnerID=40&md5=655f1697f2a3a91bde05ffee2ed843d6},
	abstract = {This paper emphasizes the significance of embracing the more-than-human perspective, which goes beyond conventional human-centered design approaches and offers a foundation for innovative design methodologies. We will delve into the fundamental concepts underpinning the more-than-human perspective, elucidating its core principles. Following this, we will present recommendations on integrating this perspective into distinct design methodologies, fostering a comprehensive and inclusive approach to design. Furthermore, the paper will illuminate the practical implications of adopting the more-than-human perspective through three detailed case studies. These case studies will serve as practical illustrations of how this perspective can influence the design process, unlock novel design possibilities, and contribute to the development of innovative solutions. By delving into these real-world scenarios, we aim to showcase the tangible benefits and transformative potential of the more-than-human perspective in the realm of design. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {Affordance; Entanglement; Generative AI; Hybrid; More-than-Human; Ontological Turn; Posthuman; Practice Theory},
	keywords = {Artificial intelligence; Ontology; Affordances; Case-studies; Entanglement; Generative AI; Human perspectives; Hybrid; More-than-human; Ontological turn; Posthuman; Practice theories; Design},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{He2024,
	author = {He, Bailan and Liu, Yushan and Hildebrandt, Marcel and Ding, Zifeng and Han, Yaomengxi and Tresp, Volker},
	title = {An Automated Evaluation Framework for Graph Database Query Generation Leveraging Large Language Models},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3707},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196307062&partnerID=40&md5=166ecf1a54dd913b3a5749449af20bcc},
	abstract = {Large language models (LLMs) have attracted considerable attention in academia and industry due to their superior performance compared to classical machine learning models across various applications. In particular, prompt engineering and in-context learning enable LLMs to operate effectively in scenarios with minimal training data, where they demonstrate proficiency with only giving precise instructions or a few examples. The advanced reasoning abilities of LLMs have been instrumental in the development of intelligent assistants. These assistants often rely on accessing information from comprehensive databases such as knowledge graphs (KGs) through natural language. The process of converting natural language requests into query language to retrieve information from databases is known as query generation (QG). One challenge in QG is the evaluation of the LLMs' performance due to the absence of standardized evaluation frameworks and datasets. To tackle this challenge, we introduce an automated evaluation framework tailored for QG, featuring three key metrics: Gold Query Accuracy, Execution Accuracy, and Execution Rate. We focus on the exemplary use case of accessing a graph database in a supply chain management (SCM) setting via a natural language interface. Our results demonstrate the efficacy of our framework and metrics in accurately evaluating model performance for QG tasks. © 2024 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).},
	author_keywords = {Knowledge graph; Large language model; Query generation; Supply chain management},
	keywords = {Computational linguistics; Graph Databases; Knowledge graph; Knowledge management; Learning systems; Natural language processing systems; Supply chain management; Automated evaluation; Database queries; Evaluation framework; Graph database; Knowledge graphs; Language model; Large language model; Natural languages; Performance; Query generation; Query processing},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Chatterjee2024570,
	author = {Chatterjee, Ram and Pandey, Mrinal and Thakur, Hardeo Kumar and Gupta, Anand},
	title = {Checking Counterfeit Critiques on Commodities using Ensemble Classifiers Enhancing Information Credibility},
	year = {2024},
	journal = {Procedia Computer Science},
	volume = {233},
	pages = {570 – 579},
	doi = {10.1016/j.procs.2024.03.246},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192447328&doi=10.1016%2fj.procs.2024.03.246&partnerID=40&md5=dacfc1ee095fe9809a9301daea263c3a},
	abstract = {The conundrum of the ubiquitous deceptive reviews has overruled the online ontology with the obsession of obscure but obligatory posting of product reviews for the customers to believe, behold and beget the online product marketing. This mandates contemporary research in the direction to delve deeper on the application and analysis of deceiving online reviews with matured and advanced AI models functional on large scale datasets to effectively and efficiently demarcate between the genuine and the sham. The research counteracts the counterfeiting product reviews via the applications, assessment and analysis of the befitting AI models - Elastic-net Classifier model based on block coordinate descent with Wordcloud and its further performance enhancement through LightGBM Trees Classifier with Grid Search and Early Stopping support, with Log-Loss as performance metric for experimentation to gain insight into the intricacies of detection, diagnosis and diminution of fake product reviews. The paper also delineates discriminative and affirmative aspects of the dataset quality, statistics, stability and standards inherent and coherent to the creation of the dataset using Large Language Models (LLMs) intrinsic to the zeitgeist juncture of recent times promoting machines to produce large scale, cost effective bogus reviews in lieu of the Amazon Mechanical Turks. The results obtained with the Log-Loss holdout score of 0.1462 conforming the LightGBM classifier proves its performance better than the Elastic-Net classifier, conforming it as better than the ROC-AUC in terms of its proximity to the prediction probability for the matching actual/true value. © 2024 The Authors. Published by Elsevier B.V.},
	author_keywords = {Amazon Mechanical Turks; Elastic-net Classifier; Information credibility; Large Language Models; LightGBM Trees Classifier},
	keywords = {Classification (of information); Computational linguistics; Fake detection; Large datasets; Amazon's mechanical turks; Elastic net; Elastic-net classifier; Ensemble-classifier; Information credibilities; Language model; Large language model; Lightgbm tree classifier; Product reviews; Tree classifiers; Cost effectiveness},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Solano2024226,
	author = {Solano, Pablo and Herrera, Víctor and Abril-Ulloa, Victoria and Espinoza-Mejía, Mauricio},
	title = {Preventing Diabetes: Substituting Processed Foods and Nutritional Chatbot Assistance},
	year = {2024},
	journal = {Communications in Computer and Information Science},
	volume = {2050 CCIS},
	pages = {226 – 240},
	doi = {10.1007/978-3-031-58953-9_18},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196109554&doi=10.1007%2f978-3-031-58953-9_18&partnerID=40&md5=2d5c21125795129541307a072fe06aeb},
	abstract = {Type 2 Diabetes Mellitus (T2DM) is one of the biggest threats to Ecuador’s health. The intake of processed foods has been linked to a higher risk of T2DM. This paper proposes FoodSub, a mobile application to recommend substitutes for processed foods using the NOVA Classification. Nutrient-based food clustering is used to identify substitute pairs between processed and unprocessed foods. The recommendations are supported and personalized using a knowledge graph that contains foods, dietary guidelines, and user information. In addition, a chatbot is implemented to answer simple questions about foods. This chatbot is developed using a Large Language Model (LLM) to query the knowledge graph. The mobile application and the chatbot are evaluated in terms of usability; both perform well, but there is room for improvement. Additionally, the recommendations’ performance is evaluated through expert verification. The recommendations perform well when issues like food transformation processes, flavor, context, or meal time are not relevant. Future work will consider the enhancement of the chatbot and the improvement of substitute recommendations for the relevant cases. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {Chatbot; Clustering; Knowledge Graph; Processed Foods},
	keywords = {Health risks; Knowledge graph; Mobile computing; Query processing; Chatbots; Clusterings; Dietary Guidelines; Ecuador; Knowledge graphs; Language model; Mobile applications; Simple++; Type 2 diabetes mellitus; User information; Nutrition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Doumanas2024360,
	author = {Doumanas, Dimitrios and Soularidis, Andreas and Kotis, Konstantinos and Vouros, George},
	title = {Integrating LLMs in the Engineering of a SAR Ontology},
	year = {2024},
	journal = {IFIP Advances in Information and Communication Technology},
	volume = {714},
	pages = {360 – 374},
	doi = {10.1007/978-3-031-63223-5_27},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197341155&doi=10.1007%2f978-3-031-63223-5_27&partnerID=40&md5=b192905d8559355b427528d34142f332},
	abstract = {In Search and Rescue (SAR) missions, the integration of multiple sources of information may enhance operational efficiency and increase responsiveness significantly, improving situation awareness and aiding decision-making to save lives and mitigate incident impact. Ontologies are crucial for integrating and reasoning with data from diverse sources. Engineering a domain ontology for SAR can be better supported from an agile, collaborative, and iterative ontology engineering methodology (OEM), incorporating the interests of several stakeholders. Large Language Models (LLMs) can play a significant role in completing OEM processes. The goal of this work is to identify how ontology engineering (OE) tasks can be completed with the collaboration of LLMs and humans. The objectives of this paper are, a) to present preliminary exploration of LLMs to generate domain ontologies for the modeling of SAR missions in wildfire incidents b) to propose and evaluate an LLM-enhanced OE approach. In overall, the main contribution of the work presented in this paper is the analysis of LLMs capabilities to ontology engineering, and the evaluation of the synergy between humans and machines to efficiently represent knowledge, with specific focus in the SAR domain. © IFIP International Federation for Information Processing 2024.},
	author_keywords = {Large Language Models; Ontology Engineering; Search and Rescue},
	keywords = {Computational linguistics; Decision making; Iterative methods; Domain ontologies; Language model; Large language model; Multiple source; Ontology engineering; Ontology Engineering Methodologies; Ontology's; Rescue missions; Search and rescue; Search missions; Ontology},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Wang20248556,
	author = {Wang, Quan and Zhang, Licheng and Guo, Zikang and Mao, Zhendong},
	title = {IDEATE: Detecting AI-Generated Text using Internal and External Factual Structures},
	year = {2024},
	journal = {2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation, LREC-COLING 2024 - Main Conference Proceedings},
	pages = {8556 – 8568},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195946484&partnerID=40&md5=27356cece203e8817f46e46bdf7547b5},
	abstract = {The effective detection of AI-generated text is a vital principle to ensure responsible use of large language models (LLMs). Previous studies mainly focused on discovering and utilizing internal evidences contained in the text itself to perform the detection, while ignoring external evidences implicated in an established knowledge graph (KG) which may also be key discriminative factors between AI-generated and human-written text. To address this deficiency, we propose IDEATE, a novel hierarchical graph network that utilizes both internal and external factual structures to detect AI-generated text. IDEATE consists of a mention-level subgraph at the bottom to describe internal factual structures of mentioned entities reflected in the input text, and an entity-level subgraph at the top to describe external factual structures of mentioned entities reflected in an external KG. Hierarchical graph convolution is then applied successively on the two subgraphs, through which the two types of factual structures will be embedded into the output and used for the final detection. Extensive experiments on four benchmarking datasets show that IDEATE consistently outperforms current state-of-the-art methods in detecting text generated by various LLMs, ranging from GPT-2 to the more powerful ChatGPT, verifying the necessity and superiority of introducing external evidences for AI-generated text detection. © 2024 ELRA Language Resource Association: CC BY-NC 4.0.},
	author_keywords = {AI-generated text detection; external factual structures; internal factual structures},
	keywords = {AI-generated text detection; External factual structure; Graph networks; Hierarchical graphs; Internal factual structure; Knowledge graphs; Language model; Subgraphs; Text detection; Written texts; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{2024,
	title = {Proceedings - 18th IEEE International Conference on Semantic Computing, ICSC 2024},
	year = {2024},
	journal = {Proceedings - IEEE International Conference on Semantic Computing, ICSC},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192226352&partnerID=40&md5=36d94daa5b8ab6414996009ad5d2c0a0},
	abstract = {The proceedings contain 58 papers. The topics discussed include: ParsyBot: chatbot for Baskent University related FAQs; anomaly detection through graph autoencoder-based learning of screenshot image logs; functional food knowledge graph-based recipe recommendation system focused on lifestyle-related diseases; unsupervised ensemble semantic segmentation for foreground-background separation on satellite image; TWIG: towards pre-hoc hyperparameter optimization and cross-graph generalization via simulated KGE models; leveraging DALI to refine route planning by dynamically avoiding risky POIs; temporal analysis of editorial trends in major newspapers following the prime minister’s speech; trend extraction and analysis via large language models; stable or shaky? the semantics of ChatGPT’s behavior under repeated queries; and ReFrESH – relation-preserving feedback-reliant enhancement of subjective content descriptions.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Doh2024826,
	author = {Doh, SeungHeon and Lee, Minhee and Jeong, Dasaem and Nam, Juhan},
	title = {ENRICHING MUSIC DESCRIPTIONS WITH A FINETUNED-LLM AND METADATA FOR TEXT-TO-MUSIC RETRIEVAL},
	year = {2024},
	journal = {ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing - Proceedings},
	pages = {826 – 830},
	doi = {10.1109/ICASSP48485.2024.10446380},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195413705&doi=10.1109%2fICASSP48485.2024.10446380&partnerID=40&md5=75796f1f396c0fc74a592d7ea04e5405},
	abstract = {Text-to-Music Retrieval, finding music based on a given natural language query, plays a pivotal role in content discovery within extensive music databases. To address this challenge, prior research has predominantly focused on a joint embedding of music audio and text, utilizing it to retrieve music tracks that exactly match descriptive queries related to musical attributes (i.e. genre, instrument) and contextual elements (i.e. mood, theme). However, users also articulate a need to explore music that shares similarities with their favorite tracks or artists, such as I need a similar track to Superstition by Stevie Wonder. To address these concerns, this paper proposes an improved Text-to-Music Retrieval model, denoted as TTMR++, which utilizes rich text descriptions generated with a finetuned large language model and metadata. To accomplish this, we obtained various types of seed text from several existing music tag and caption datasets and a knowledge graph dataset of artists and tracks. The experimental results show the effectiveness of TTMR++ in comparison to state-of-the-art music-text joint embedding models through a comprehensive evaluation involving various musical text queries. © 2024 IEEE.},
	author_keywords = {Large Language Model; Music Informational Retrieval; Text-to-Music Retrieval},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Green Open Access}
}

@CONFERENCE{Loevenich2024,
	author = {Loevenich, Johannes F. and Adler, Erik and Mercier, Remi and Velazquez, Alexander and Lopes, Roberto Rigolin F.},
	title = {Design of an Autonomous Cyber Defence Agent using Hybrid AI models},
	year = {2024},
	journal = {2024 International Conference on Military Communication and Information Systems, ICMCIS 2024},
	doi = {10.1109/ICMCIS61231.2024.10540988},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195693813&doi=10.1109%2fICMCIS61231.2024.10540988&partnerID=40&md5=dc233935a69f2aeaf6141b8b4057d5e2},
	abstract = {This paper extends the design of an autonomous cyber defence (ACD) agent to monitor and actuate within a protected core network segment. The goal is to take advantage of recent developments in AI models to define a hybrid architecture that combines deep reinforcement learning (DRL), large language models (LLMs), and rule-based models. The motivation comes from the fact that modern network segments within colored clouds are using software-defined controllers with the means to host ACD agents and other cybersecurity tools implementing hybrid AI models. For example, our ACD agent uses a DRL model and the chatbot uses an LLM to create an interface with human cybersecurity experts. The ACD agent was evaluated against two red agent strategies in a gym environment using a set of actions to defend services in the network (monitor, analyse, decoy, remove, and restore). Our chatbot was developed using retrieval augmented generation and a prompting agent to augment a pre-trained LLM with data from cybersecurity knowledge graphs. We performed a comparative analysis between a baseline implementation and our chatbot using generation/retrieval metrics. The results suggest that both ACD agent and chatbot can potentially enhance the defence of critical networks connected to untrusted infrastructure.  © 2024 IEEE.},
	author_keywords = {Autonomous Cyber Defence; Cybersecurity; Deep Reinforcement Learning; Large Language Model},
	keywords = {Autonomous agents; Computational linguistics; Cybersecurity; Deep learning; Learning systems; Autonomous cybe defense; Chatbots; Core networks; Cyber security; Cyber-defense; Deep reinforcement learning; Language model; Large language model; Network segment; Reinforcement learnings; Reinforcement learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6}
}

@ARTICLE{Lehmann2024199,
	author = {Lehmann, Jens and Meloni, Antonello and Motta, Enrico and Osborne, Francesco and Recupero, Diego Reforgiato and Salatino, Angelo Antonio and Vahdati, Sahar},
	title = {Large Language Models for Scientific Question Answering: An Extensive Analysis of the SciQA Benchmark},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14664 LNCS},
	pages = {199 – 217},
	doi = {10.1007/978-3-031-60626-7_11},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194234220&doi=10.1007%2f978-3-031-60626-7_11&partnerID=40&md5=acc775f3895f1a36bf2e44d9f479cd5e},
	abstract = {The SciQA benchmark for scientific question answering aims to represent a challenging task for next-generation question-answering systems on which vanilla large language models fail. In this article, we provide an analysis of the performance of language models on this benchmark including prompting and fine-tuning techniques to adapt them to the SciQA task. We show that both fine-tuning and prompting techniques with intelligent few-shot selection allow us to obtain excellent results on the SciQA benchmark. We discuss the valuable lessons and common error categories, and outline their implications on how to optimise large language models for question answering over knowledge graphs. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {Few-shot learning; Fine-tuning; Knowledge graphs; Language models.; Question answering},
	keywords = {Benchmarking; Computational linguistics; Few-shot learning; Fine tuning; Knowledge graphs; Language model; Language model.; Performance; Question Answering; Question answering systems; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Luo202433,
	author = {Luo, Kun and Zhou, Tong and Chen, Yubo and Zhao, Jun and Liu, Kang},
	title = {Open Event Causality Extraction by the Assistance of LLM in Task Annotation, Dataset, and Method},
	year = {2024},
	journal = {1st Workshop on Bridging Neurons and Symbols for Natural Language Processing and Knowledge Graphs Reasoning, NeusymBridge 2024 at LREC-COLING 2024 - Workshop Proceedings},
	pages = {33 – 44},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195188201&partnerID=40&md5=1835ac1f95878616389423ebfcde121c},
	abstract = {Event Causality Extraction (ECE) aims to extract explicit causal relations between event pairs from the text. However, the event boundary deviation and the causal event pair mismatching are two crucial challenges that remain unaddressed. To address the above issues, we propose a paradigm to utilize LLM to optimize the task definition, evolve the datasets, and strengthen our proposed customized Contextual Highlighting Event Causality Extraction framework (CHECE). Specifically in CHECE, we propose an Event Highlighter and an Event Concretization Module, guiding the model to represent the event by a higher-level cluster and consider its causal counterpart in event boundary prediction to deal with event boundary deviation. And we propose a Contextual Event Causality Matching mechanism, meanwhile, applying LLM to diversify the content templates to force the model to learn causality from context to targeting on causal event pair mismatching. Experimental results on two ECE datasets demonstrate the effectiveness of our method. © 2024 ELRA Language Resource Association.},
	author_keywords = {Event Extraction; Knowledge Graph; Large Language Model},
	keywords = {Knowledge graph; Large datasets; Causal relations; Event boundary; Events extractions; Knowledge graphs; Language model; Large language model; Learn+; Matching mechanisms; Extraction},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Hoseini2024,
	author = {Hoseini, Sayed and Burgdorf, Andreas and Paulus, Alexander and Meisen, Tobias and Quix, Christoph and Pomp, André},
	title = {Towards LLM-augmented Creation of Semantic Models for Dataspaces},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3705},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196284048&partnerID=40&md5=53768af53f4fe37e71ec1f1095e450b3},
	abstract = {Dataspaces aim to enable smooth and reliable data exchange between different organizations. They have gained increasing attention in Europe following the enactment of the European Data Governance Act. This legislation emphasizes trust, accessibility, and shared dataspaces, which require semantic interoperability grounded in the FAIR principles. Although semantic descriptions in the form of semantic models and ontologies are integral to dataspaces, their full potential remains underutilized. Meaningful metadata, including contextual information, enhances data usability, but manually creating semantic models can be challenging. Large Language Models (LLMs) offer a new way to utilize data in dataspaces. Their advanced natural language processing capabilities enable context-aware data processing and semantic understanding. This paper presents initial experiments on customizing and optimizing LLMs for semantic labeling and modeling tasks. The contributions of this work include research questions for future investigations, early experiments demonstrating the applicability of LLM for semantic labeling, and proposed directions to address discovered challenges. © 2024 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).},
	author_keywords = {Dataspace; LLMs; Semantic Modeling},
	keywords = {Laws and legislation; Natural language processing systems; Semantics; Contextual information; Data governances; Data space; Language model; Large language model; Semantic descriptions; Semantic interoperability; Semantic labeling; Semantic modelling; Semantic ontology; Electronic data interchange},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{Bianchini2024147,
	author = {Bianchini, Filippo and Calamo, Marco and De Luzi, Francesca and Macrì, Mattia and Mecella, Massimo},
	title = {Enhancing Complex Linguistic Tasks Resolution Through Fine-Tuning LLMs, RAG and Knowledge Graphs (Short Paper)},
	year = {2024},
	journal = {Lecture Notes in Business Information Processing},
	volume = {521},
	pages = {147 – 155},
	doi = {10.1007/978-3-031-61003-5_13},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196186653&doi=10.1007%2f978-3-031-61003-5_13&partnerID=40&md5=40e449f918b271da33d8903866e114ad},
	abstract = {Given the synergy between Large Language Models (LLMs) and Knowledge Graphs (KGs), we introduce a pipeline to tackle complex linguistic tasks, which we are experimenting in the legal domain. While LLMs offer unprecedented generative capabilities, their reliance on sub-symbolic processing can lead to fallacious outcomes. Our methodology introduces an advanced Retrieval Augmented Generation (RAG) pipeline, enriched with two KGs and optimized LLMs, promising to enhance the resolution of complex linguistic tasks. Through KG construction based on prompt engineering techniques and iterative fine-tuning, we transcend the limitations of conventional LLMs. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {Complex linguistic tasks; Knowledge Graphs; Large Language Models},
	keywords = {Computational linguistics; Knowledge graph; Pipelines; Complex linguistic task; Engineering techniques; Fine tuning; Graph construction; Knowledge graphs; Language model; Large language model; Legal domains; Sub-symbolic; Symbolic processing; Iterative methods},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{Asadi2024166,
	author = {Asadi, Amir Reza and Appiah, Joel and Muntaka, Siddique Abubakr and Kropczynski, Jess},
	title = {Actions, Not Apps: Toward Using LLMs to Reshape Context Aware Interactions in Mixed Reality Systems},
	year = {2024},
	journal = {Communications in Computer and Information Science},
	volume = {2120 CCIS},
	pages = {166 – 176},
	doi = {10.1007/978-3-031-62110-9_17},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85196733497&doi=10.1007%2f978-3-031-62110-9_17&partnerID=40&md5=9cd702ff979c7f111a5172df8f155ddf},
	abstract = {Mixed reality computing merges user perception of the environment with digital information. As we move from flatscreen computing toward head-mounted computing, the necessity for developing alternative interactions and user flows becomes more evident. Activity theory provides a holistic overview of user interactions and motives. In this work in progress, we propose Action Sandbox Workspace as an interaction framework for the future of MR systems by focusing on action-centric interactions rather than application-centric interactions, aiming to bridge the gap between user goals and system functionalities in everyday tasks. By integrating the ontology of actions, user intentions, and context and connecting it to spatial data mapping, this forward-looking framework aims to create a contextually adaptive user interaction environment. The recent development in large language models (LLMs) has made the implementation of this interaction flow feasible by enabling inference and decision-making based on text-based descriptions of a user’s state and intentions with data and actions users have access to. We propose this approach as a future direction for developing mixed reality platforms and integrating AI in interacting with computers. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {Context Aware System; Interaction Design; Mixed Reality},
	keywords = {Computation theory; Decision making; User interfaces; Context-aware interaction; Context-aware systems; Digital information; Flat-screens; Interaction design; Language model; Mixed reality; Mixed reality systems; User interaction; User perceptions; Mixed reality},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Wei20243490,
	author = {Wei, Xiang and Chen, Yufeng and Cheng, Ning and Cui, Xingyu and Xu, Jinan and Han, Wenjuan},
	title = {CollabKG: A Learnable Human-Machine-Cooperative Information Extraction Toolkit for (Event) Knowledge Graph Construction},
	year = {2024},
	journal = {2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation, LREC-COLING 2024 - Main Conference Proceedings},
	pages = {3490 – 3506},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195929114&partnerID=40&md5=4d049a3f2554926a006a905ca024b853},
	abstract = {In order to construct or extend entity-centric and event-centric knowledge graphs (KG and EKG), the information extraction (IE) annotation toolkit is essential. However, existing IE toolkits have several non-trivial problems, such as not supporting multi-tasks, and not supporting automatic updates. In this work, we present CollabKG, a learnable human-machine-cooperative IE toolkit for KG and EKG construction. Specifically, for the multi-task issue, CollabKG unifies different IE subtasks, including named entity recognition (NER), entity-relation triple extraction (RE), and event extraction (EE), and supports both KG and EKG. Then, combining advanced prompting-based IE technology, the human-machine-cooperation mechanism with Large Language Models (LLMs) as the assistant machine is presented which can provide a lower cost as well as a higher performance. Lastly, owing to the two-way interaction between the human and machine, CollabKG with learning ability allows self-renewal. Besides, CollabKG has several appealing features (e.g., customization, training-free, and label propagation) that make the system powerful and high-productivity. We holistically compare our toolkit with other existing tools on these features. Human evaluation quantitatively illustrates that CollabKG significantly improves annotation quality, efficiency, and stability simultaneously. © 2024 ELRA Language Resource Association: CC BY-NC 4.0.},
	author_keywords = {Human-machine Cooperation; Information Extraction; Knowledge Graph Construction Toolkit},
	keywords = {Electrocardiography; Information retrieval; Natural language processing systems; Automatic updates; Graph construction; Human-machine; Human-machine cooperation; Information extraction; Knowledge graph construction toolkit; Knowledge graphs; Multi tasks; Non trivial problems; Subtask; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Stork2024199,
	author = {Stork, Lise and Zijdeman, Richard L. and Tiddi, Ilaria and ten Teije, Annette},
	title = {Enabling Social Demography Research Using Semantic Technologies},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14665 LNCS},
	pages = {199 – 216},
	doi = {10.1007/978-3-031-60635-9_12},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195271433&doi=10.1007%2f978-3-031-60635-9_12&partnerID=40&md5=10a992281c65455fccdecec30b48b3eb},
	abstract = {A shift in scientific publishing from paper-based to knowledge-based practices promotes reproducibility, machine actionability and knowledge discovery. This is important for disciplines like social demography, where study indicators are often social constructs such as race or education, hypothesis tests are challenging to compare due to their limited temporal and spatial coverage, and research output is presented in natural language, which can be ambiguous and imprecise. In this work, we present the MIRA resource, to aid researchers in their research workflow, and publish FAIR findings. MIRA consists of: (1) an ontology for social demography research, (2) a method for automated ontology population by prompting Large Language Models, and (3) a knowledge graph populated in terms of the ontology by annotating a set of research papers on health inequality. The resource allows researchers to formally represent their social demography research hypotheses, discovering research biases and novel research questions. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {Health Inequality; Hypothesis Representation; Information Extraction; Scientific Knowledge Graphs; Social Demography},
	keywords = {Knowledge graph; Ontology; Population statistics; Semantic Web; Semantics; Health inequality; Hypothesis representation; Information extraction; Knowledge based; Knowledge graphs; Ontology's; Scientific knowledge; Scientific knowledge graph; Semantic technologies; Social demography; Demography},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Yuan202475,
	author = {Yuan, Jicheng and Le-Tuan, Anh and Nguyen-Duc, Manh and Tran, Trung-Kien and Hauswirth, Manfred and Le-Phuoc, Danh},
	title = {VisionKG: Unleashing the Power of Visual Datasets via Knowledge Graph},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14665 LNCS},
	pages = {75 – 93},
	doi = {10.1007/978-3-031-60635-9_5},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195295743&doi=10.1007%2f978-3-031-60635-9_5&partnerID=40&md5=975a1571ea5b8ee02719ce6b383631cc},
	abstract = {The availability of vast amounts of visual data with diverse and fruitful features is a key factor for developing, verifying, and benchmarking advanced computer vision (CV) algorithms and architectures. Most visual datasets are created and curated for specific tasks or with limited data distribution for very specific fields of interest, and there is no unified approach to manage and access them across diverse sources, tasks, and taxonomies. This not only creates unnecessary overheads when building robust visual recognition systems, but also introduces biases into learning systems and limits the capabilities of data-centric AI. To address these problems, we propose the VisionKnowledge Graph (VisionKG), a novel resource that interlinks, organizes and manages visual datasets via knowledge graphs and Semantic Web technologies. It can serve as a unified framework facilitating simple access and querying of state-of-the-art visual datasets, regardless of their heterogeneous formats and taxonomies. One of the key differences between our approach and existing methods is that VisionKG is not only based on metadata but also utilizes a unified data schema and external knowledge bases to integrate, interlink, and align visual datasets. It enhances the enrichment of the semantic descriptions and interpretation at both image and instance levels and offers data retrieval and exploratory services via SPARQL and natural language empowered by Large Language Models (LLMs). VisionKG currently contains 617 million RDF triples that describe approximately 61 million entities, which can be accessed at https://vision.semkg.org and through APIs. With the integration of 37 datasets and four popular computer vision tasks, we demonstrate its usefulness across various scenarios when working with computer vision pipelines. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {Computer Vision; Knowledge Graph; Linked Data; Ontology; RDF},
	keywords = {Computer vision; HTTP; Image enhancement; Knowledge graph; Learning systems; Resource Description Framework (RDF); Taxonomies; Computer vision algorithms; Computer vision architectures; Key factors; Knowledge graphs; Linked datum; Ontology's; Power; RDF; Specific tasks; Visual data; Linked data},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@ARTICLE{Saeedizade2024143,
	author = {Saeedizade, Mohammad Javad and Blomqvist, Eva},
	title = {Navigating Ontology Development with Large Language Models},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14664 LNCS},
	pages = {143 – 161},
	doi = {10.1007/978-3-031-60626-7_8},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194261410&doi=10.1007%2f978-3-031-60626-7_8&partnerID=40&md5=5dc98df4e76d8fa173937f55e38db6e7},
	abstract = {Ontology engineering is a complex and time-consuming task, even with the help of current modelling environments. Often the result is error-prone unless developed by experienced ontology engineers. However, with the emergence of new tools, such as generative AI, inexperienced modellers might receive assistance. This study investigates the capability of Large Language Models (LLMs) to generate OWL ontologies directly from ontological requirements. Specifically, our research question centres on the potential of LLMs in assisting human modellers, by generating OWL modelling suggestions and alternatives. We experiment with several state-of-the-art models. Our methodology incorporates diverse prompting techniques like Chain of Thoughts (CoT), Graph of Thoughts (GoT), and Decomposed Prompting, along with the Zero-shot method. Results show that currently, GPT-4 is the only model capable of providing suggestions of sufficient quality, and we also note the benefits and drawbacks of the prompting techniques. Overall, we conclude that it seems feasible to use advanced LLMs to generate OWL suggestions, which are at least comparable to the quality of human novice modellers. Our research is a pioneering contribution in this area, being the first to systematically study the ability of LLMs to assist ontology engineers. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {LLM; Ontology; Ontology Engineering},
	keywords = {Birds; Computational linguistics; Zero-shot learning; Current modeling; Error prones; Language model; Large language model; Modeling environments; Ontology development; Ontology engineering; Ontology's; OWL ontologies; Time-consuming tasks; Ontology},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@CONFERENCE{Qian20248035,
	author = {Qian, Zhenyu and Qian, Yiming and Song, Yuting and Gao, Fei and Jin, Hai and Yu, Chen and Xie, Xia},
	title = {Harnessing the Power of Large Language Model for Uncertainty Aware Graph Processing},
	year = {2024},
	journal = {2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation, LREC-COLING 2024 - Main Conference Proceedings},
	pages = {8035 – 8049},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195901768&partnerID=40&md5=91d17b210a3042a0229a24f5b81023be},
	abstract = {Handling graph data is one of the most difficult tasks. Traditional techniques, such as those based on geometry and matrix factorization, rely on assumptions about the data relations that become inadequate when handling large and complex graph data. On the other hand, deep learning approaches demonstrate promising results in handling large graph data, but they often fall short of providing interpretable explanations. To equip the graph processing with both high accuracy and explainability, we introduce a novel approach that harnesses the power of a large language model (LLM), enhanced by an uncertainty-aware module to provide a confidence score on the generated answer. We experiment with our approach on two graph processing tasks: few-shot knowledge graph completion and graph classification. Our results demonstrate that through parameter efficient fine-tuning, the LLM surpasses state-of-the-art algorithms by a substantial margin across ten diverse benchmark datasets. Moreover, to address the challenge of explainability, we propose an uncertainty estimation based on perturbation, along with a calibration scheme to quantify the confidence scores of the generated answers. Our confidence measure achieves an AUC of 0.8 or higher on seven out of the ten datasets in predicting the correctness of the answer generated by LLM. © 2024 ELRA Language Resource Association: CC BY-NC 4.0.},
	author_keywords = {Graph Processing; Knowledge Graph; LLM; Model Calibration; Uncertainty},
	keywords = {Computational linguistics; Data handling; Deep learning; Factorization; Confidence score; Graph data; Graph processing; Knowledge graphs; Language model; Large language model; Model calibration; Power; Traditional techniques; Uncertainty; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}@CONFERENCE{Wang202324,
	author = {Wang, Chen and Hua, Min and Song, Jiale and Tang, Xue-Song},
	title = {Knowledge Graphs Enhanced Large Language Model Prompt for Electric Power Question Answering},
	year = {2023},
	journal = {ACM International Conference Proceeding Series},
	pages = {24 – 29},
	doi = {10.1145/3650400.3650405},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191439580&doi=10.1145%2f3650400.3650405&partnerID=40&md5=46314f3e8e0920f15bee49ed39e58b57},
	abstract = {With the continuous development and digital transformation in the field of electric power, the application of large language models in the electric power industry has become a remarkable trend. The electric power industry is an information-intensive domain involving extensive data processing, predictive analysis, and decision-making. Therefore, the application of large language models in the electric power sector is of great significance. Current large language models such as GPT3.5 and GLM can perform well in tasks such as question answering dialogues. However, these models still face challenges such as answer hallucination and inaccurate responses. This paper proposes a method to enhance question answering in large language models using knowledge graphs, aiming to improve the accuracy and reliability of these models in question answering tasks in the electric power domain.The proposed method first utilizes local electric power data to extract triplets and generate a question answering dataset specific to the electric power domain using a large language model. Then, the relationships of the knowledge graph triplets are incorporated into the question prompt to enhance the quality of the model's answers. Furthermore, we fine-tune the large language model using the expanded question set derived from the triplets as knowledge enhanced data. Subsequently, we conduct experiments on both an electric power question answering dataset and a knowledge graph question answering dataset. The experimental results demonstrate that our method significantly improves various metrics of the large language model in the electric power question answering task. This research provides new insights and approaches to enhance the effectiveness of question answering systems in the electric power domain. Future studies can further explore and optimize this prompt expansion method for application in broader domains and tasks.  © 2023 ACM.},
	author_keywords = {Electrical Engineering; Finetuning; Knowledge Graph; Large Language Models; Prompt Engineering},
	keywords = {Computational linguistics; Data handling; Electric industry; Knowledge graph; Large datasets; Electric power; Electric power industries; Finetuning; Knowledge graphs; Language model; Large language model; Powerdomains; Prompt engineering; Question Answering; Question Answering Task; Decision making},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Luo2024,
	author = {Luo, Linhao and Li, Yuan-Fang and Haffari, Gholamreza and Pan, Shirui},
	title = {REASONING ON GRAPHS: FAITHFUL AND INTERPRETABLE LARGE LANGUAGE MODEL REASONING},
	year = {2024},
	journal = {12th International Conference on Learning Representations, ICLR 2024},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189049374&partnerID=40&md5=b9a2cdbfe9c9b068b324cf1eb26f3882},
	abstract = {Large language models (LLMs) have demonstrated impressive reasoning abilities in complex tasks. However, they lack up-to-date knowledge and experience hallucinations during reasoning, which can lead to incorrect reasoning processes and diminish their performance and trustworthiness. Knowledge graphs (KGs), which capture vast amounts of facts in a structured format, offer a reliable source of knowledge for reasoning. Nevertheless, existing KG-based LLM reasoning methods only treat KGs as factual knowledge bases and overlook the importance of their structural information for reasoning. In this paper, we propose a novel method called reasoning on graphs (RoG) that synergizes LLMs with KGs to enable faithful and interpretable reasoning. Specifically, we present a planning-retrieval-reasoning framework, where RoG first generates relation paths grounded by KGs as faithful plans. These plans are then used to retrieve valid reasoning paths from the KGs for LLMs to conduct faithful reasoning. Furthermore, RoG not only distills knowledge from KGs to improve the reasoning ability of LLMs through training but also allows seamless integration with any arbitrary LLMs during inference. Extensive experiments on two benchmark KGQA datasets demonstrate that RoG achieves state-of-the-art performance on KG reasoning tasks and generates faithful and interpretable reasoning results. © 2024 12th International Conference on Learning Representations, ICLR 2024. All rights reserved.},
	keywords = {Benchmarking; Knowledge graph; Complex task; Graph-based; Knowledge and experience; Knowledge graphs; Language model; Model reasonings; Performance; Reasoning ability; Reasoning methods; Reasoning process; Computational linguistics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 16}
}

@ARTICLE{Hu2023,
	author = {Hu, Shulin and Zhang, Huajun and Zhang, Wanying},
	title = {Domain Knowledge Graph Question Answering Based on Semantic Analysis and Data Augmentation},
	year = {2023},
	journal = {Applied Sciences (Switzerland)},
	volume = {13},
	number = {15},
	doi = {10.3390/app13158838},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167883197&doi=10.3390%2fapp13158838&partnerID=40&md5=0328dec1c047deffc579faba77936845},
	abstract = {Information retrieval-based question answering (IRQA) and knowledge-based question answering (KBQA) are the main forms of question answering (QA) systems. The answer generated by the IRQA system is extracted from the relevant text but has a certain degree of randomness, while the KBQA system retrieves the answer from structured data, and its accuracy is relatively high. In the field of policy and regulations such as household registration, the QA system requires precise and rigorous answers. Therefore, we design a QA system based on the household registration knowledge graph, aiming to provide rigorous and accurate answers for relevant household registration inquiries. The QA system uses a semantic analysis-based approach to simplify one question into a simple problem consisting of a single event entity and a single intention relationship, and quickly generates accurate answers by searching in the household registration knowledge graph. Due to the scarcity and imbalance of QA corpus data in the field of household registration, we use GPT3.5 to augment the collected questions dataset and explore the impact of data augmentation on the QA system. The experiment results show that the accuracy rate of the QA system using the augmented dataset reaches 93%, which is 6% higher than before. © 2023 by the authors.},
	author_keywords = {data augmentation; domain knowledge graph; large language model; question answering},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; All Open Access, Gold Open Access}
}

@CONFERENCE{Alarcia2024334,
	author = {Alarcia, Ramón María García and Russo, Pietro and Renga, Alfredo and Golkar, Alessandro},
	title = {Bringing Systems Engineering Models to Large Language Models: An Integration of OPM with an LLM for Design Assistants},
	year = {2024},
	journal = {International Conference on Model-Driven Engineering and Software Development},
	volume = {1},
	pages = {334 – 345},
	doi = {10.5220/0012621900003645},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190371259&doi=10.5220%2f0012621900003645&partnerID=40&md5=fae4375bf75722f781cd1c1e675ef412},
	abstract = {Although showing remarkable zero-shot and few-shot capabilities across a wide variety of tasks, Large Language Models (LLMs) are still not mature enough for off-the-shelf use in engineering design tasks. Organizations implementing model-based systems engineering practices into their product development processes can leverage on ontologies, models, and procedures to enhance LLMs applied to engineering design tasks. We present a methodology to integrate an Object-Process Methodology model of a space system into an LLMbased spacecraft design assistant and show a performance improvement, as compared to a conventional LLM. The benchmark is evaluated through subjective expert-assessed and an objective cosine-similarity-based criteria. The results motivate additional efforts in integrating Model-Based Systems Engineering practice into LLMs as means to improve their performance and reduce shortcomings such as hallucinations and black-box, untraceable behavior. © 2024 by SCITEPRESS – Science and Technology Publications, Lda.},
	author_keywords = {Design Assistant; Engineering Design; Large Language Models; Model-Based Systems Engineering; Object-Process Methodology; Systems Engineering},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Jiang2024,
	author = {Jiang, Pengcheng and Xiao, Cao and Cross, Adam and Sun, Jimeng},
	title = {GRAPHCARE: ENHANCING HEALTHCARE PREDICTIONS WITH PERSONALIZED KNOWLEDGE GRAPHS},
	year = {2024},
	journal = {12th International Conference on Learning Representations, ICLR 2024},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188360892&partnerID=40&md5=47af1493218f53b93870f0b4fe385aed},
	abstract = {Clinical predictive models often rely on patients' electronic health records (EHR), but integrating medical knowledge to enhance predictions and decision-making is challenging. This is because personalized predictions require personalized knowledge graphs (KGs), which are difficult to generate from patient EHR data. To address this, we propose GRAPHCARE, a framework that uses external KGs to improve EHR-based predictions. Our method extracts knowledge from large language models (LLMs) and external biomedical KGs to build patient-specific KGs, which are then used to train our proposed Bi-attention AugmenTed (BAT) graph neural network (GNN) for healthcare predictions. On two public datasets, MIMIC-III and MIMIC-IV, GRAPHCARE surpasses baselines in four vital healthcare prediction tasks: mortality, readmission, length of stay (LOS), and drug recommendation. On MIMIC-III, it boosts AUROC by 17.6% and 6.6% for mortality and readmission, and F1-score by 7.9% and 10.8% for LOS and drug recommendation, respectively. Notably, GRAPHCARE demonstrates a substantial edge in scenarios with limited data. Our findings highlight the potential of using external KGs in healthcare prediction tasks and demonstrate the promise of GRAPHCARE in generating personalized KGs for promoting personalized medicine. © 2024 12th International Conference on Learning Representations, ICLR 2024. All rights reserved.},
	keywords = {Decision making; Graph neural networks; Health care; Knowledge graph; Decisions makings; Electronic health; External knowledge; Health records; Knowledge graphs; Length of stay; Medical knowledge; Prediction and decision; Prediction tasks; Predictive models; Forecasting},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@ARTICLE{Argüelles Terrón2023329,
	author = {Argüelles Terrón, Gabriela and Martín Chozas, Patricia and Rodríguez Doncel, Víctor},
	title = {Event Extraction and Semantic Representation from Spanish Workers Statute Using Large Language Models},
	year = {2023},
	journal = {Frontiers in Artificial Intelligence and Applications},
	volume = {379},
	pages = {329 – 334},
	doi = {10.3233/FAIA230983},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181171854&doi=10.3233%2fFAIA230983&partnerID=40&md5=f4287ea7c6437c9bc7ec8f285f538910},
	abstract = {This work uses Large Language Models to process an important piece of Spanish legislation: the Workers' Statute. The proposed method extracts the relevant events in its articles using a GPT-3.5 model and represents the entities involved in the events and the relationships between them as RDF triples. The experiments carried out to select a high-performance strategy include both zero- and few-shot learning tests. Finally, this work proposes a strategy to uplift the extracted legal relations into a legal knowledge graph.  © 2023 The Authors.},
	author_keywords = {Event Extraction; Knowledge Graph; Large Language Models; Legal Domain; Spanish Workers' Statute},
	keywords = {Computational linguistics; Extraction; Resource Description Framework (RDF); Semantics; Event semantics; Events extractions; Knowledge graphs; Language model; Large language model; Legal domains; RDF triples; Semantic representation; Spanish worker' statute; Workers'; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Sun2024,
	author = {Sun, Jiashuo and Xu, Chengjin and Tang, Lumingyuan and Wang, Saizhuo and Lin, Chen and Gong, Yeyun and Ni, Lionel M. and Shum, Heung-Yeung and Guo, Jian},
	title = {THINK-ON-GRAPH: DEEP AND RESPONSIBLE REASONING OF LARGE LANGUAGE MODEL ON KNOWLEDGE GRAPH},
	year = {2024},
	journal = {12th International Conference on Learning Representations, ICLR 2024},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187475304&partnerID=40&md5=b56ebefb95b5379819387e0f81865da5},
	abstract = {Although large language models (LLMs) have achieved significant success in various tasks, they often struggle with hallucination problems, especially in scenarios requiring deep and responsible reasoning. These issues could be partially addressed by introducing external knowledge graphs (KG) in LLM reasoning. In this paper, we propose a new LLM-KG integrating paradigm “LLM ⊗ KG” which treats the LLM as an agent to interactively explore related entities and relations on KGs and perform reasoning based on the retrieved knowledge. We further implement this paradigm by introducing a new approach called Think-on-Graph (ToG), in which the LLM agent iteratively executes beam search on KG, discovers the most promising reasoning paths, and returns the most likely reasoning results. We use a number of well-designed experiments to examine and illustrate the following advantages of ToG: 1) compared with LLMs, ToG has better deep reasoning power; 2) ToG has the ability of knowledge traceability and knowledge correctability by leveraging LLMs reasoning and expert feedback; 3) ToG provides a flexible plug- and-play framework for different LLMs, KGs and prompting strategies without any additional training cost; 4) the performance of ToG with small LLM models could exceed large LLM such as GPT-4 in certain scenarios and this reduces the cost of LLM deployment and application. As a training-free method with lower computational cost and better generality, ToG achieves overall SOTA in 6 out of 9 datasets where most previous SOTAs rely on additional training. Our code is publicly available at https://github.com/IDEA-FinAI/ToG. © 2024 12th International Conference on Learning Representations, ICLR 2024. All rights reserved.},
	keywords = {Computational linguistics; Iterative methods; Knowledge management; Beam search; External knowledge; Knowledge graphs; Language model; Model agents; Model knowledge; Model reasonings; Most likely; New approaches; Related entities; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 16}
}

@CONFERENCE{Na2023308,
	author = {Na, Qionglan and Li, Xin and Wang, Yifei and Li, Jing and Yang, Yixi and Zhang, Haiming},
	title = {A Pre-training Method Inspired by Large Language Model for Power Named Entity Recognition},
	year = {2023},
	journal = {ACM International Conference Proceeding Series},
	pages = {308 – 312},
	doi = {10.1145/3653081.3653131},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192811731&doi=10.1145%2f3653081.3653131&partnerID=40&md5=b7ce9150d78b0febfc5ab594063ede92},
	abstract = {In recent years, the field of natural language processing has witnessed remarkable advancements due to the success of large language models. These models leverage the Transformer architecture and pre-training techniques to achieve impressive results. In this paper, we draw inspiration from large language models and apply these techniques into the task of named entity recognition in the domain of power grids, which is critical for building power grid knowledge graphs and question-answering systems. Specifically, we propose a BERT-CNN-BIGRU-CRF deep learning model for named entity recognition. This model effectively harnesses the semantic modeling capabilities and pre-training knowledge of BERT, which is based on the Transformer architecture. By incorporating CNN and BIGRU, the model captures and models both local and global features, respectively. The CRF layer is employed for label classification. This combination of components ensures a high level of recognition accuracy. To evaluate the performance of the proposed model, we train our model on annotated maintenance plan data. We compare its results with those of other commonly used models. The evaluation metrics include recall, precision, and F1 score, which are widely employed in named entity recognition tasks. Our proposed model achieves optimal performance across all three metrics, demonstrating its superiority over other models.  © 2023 ACM.},
	author_keywords = {BERT; Deep-learning; Large language model; Named entity recognition; Power; Smart grid},
	keywords = {Classification (of information); Computational linguistics; Deep learning; Learning algorithms; Learning systems; Natural language processing systems; Semantics; BERT; Deep-learning; Language model; Large language model; Named entity recognition; Power; Power grids; Pre-training; Smart grid; Training methods; Smart power grids},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Zhang2024300,
	author = {Zhang, Ruipeng and Xie, Mengjun},
	title = {ForensiQ: A Knowledge Graph Question Answering System for IoT Forensics},
	year = {2024},
	journal = {Lecture Notes of the Institute for Computer Sciences, Social-Informatics and Telecommunications Engineering, LNICST},
	volume = {571 LNICST},
	pages = {300 – 314},
	doi = {10.1007/978-3-031-56583-0_20},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190706066&doi=10.1007%2f978-3-031-56583-0_20&partnerID=40&md5=002c850b8ea6d4b1ca471ba2c22f1f6c},
	abstract = {The increasing number of attacks against the Internet of Things (IoT) has made IoT forensics critically important for reporting and mitigating cyber incidents and crimes. However, the heterogeneity of IoT environments and the complexity and volume of IoT data present significant challenges to forensic practitioners. The advent of question answering (QA) systems and large language models (LLM) offers a potential solution to accessing sophisticated IoT forensic knowledge and data. In light of this, we propose ForensiQ, a framework based on knowledge graph question answering (KGQA), to help investigators navigate complex IoT forensic artifacts and cybersecurity knowledge. Our framework integrates knowledge graphs (KG) into the IoT forensic workflow to better organize and analyze forensic artifacts. We also have developed a novel KGQA model that serves as a natural-language user interface to the IoT forensic KG. Our evaluation results show that, compared to existing KGQA models, ForensiQ demonstrates higher accuracy in answering natural language questions when applied to our experimental IoT forensic KG. © ICST Institute for Computer Sciences, Social Informatics and Telecommunications Engineering 2024.},
	author_keywords = {Digital Forensics; Internet of Things; Knowledge Graph; Ontology Design; Question Answering},
	keywords = {Computer forensics; Cybersecurity; Electronic crime countermeasures; Knowledge graph; Natural language processing systems; User interfaces; Cyber security; Evaluation results; Forensic practitioner; Knowledge graphs; Language model; Natural languages; Ontology design; Question Answering; Question answering systems; Work-flows; Internet of things},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Pan20232403,
	author = {Pan, Yudai and Zhang, Lingling and Cai, Zhongmin and Zhao, Tianzhe and Wei, Bifan and Liu, Jun},
	title = {Differentiable Rule Extraction with Large Language Model for Knowledge Graph Reasoning; [基于大规模语言模型的知识图谱可微规则抽取]},
	year = {2023},
	journal = {Journal of Frontiers of Computer Science and Technology},
	volume = {17},
	number = {10},
	pages = {2403 – 2412},
	doi = {10.3778/j.issn.1673-9418.2306049},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184906284&doi=10.3778%2fj.issn.1673-9418.2306049&partnerID=40&md5=7a09271459725a737e6064ba9c89aaf1},
	abstract = {Knowledge graph (KG) reasoning is to predict missing entities or relationships in incomplete triples, complete structured knowledge, and apply to different downstream tasks. Different from black-box methods which are widely studied, such as methods based on representation learning, the method based on rule extraction achieves an interpretable reasoning paradigm by generalizing first-order logic rules from the KG. To address the gap between discrete symbolic space and continuous embedding space, a differentiable rule extracting method based on the large pre-trained language model (DRaM) is proposed, which integrates discrete first-order logical rules with continuous vector space. In view of the influence of atom sequences in first-order logic rules for the reasoning process, a large pre-trained language model is introduced to encode the reasoning process. The differentiable method DRaM, which integrates first-order logical rules, achieves good results in link prediction tasks on three knowledge graph datasets, Family, Kinship and UMLS, especially for the indicator Hits@10. Comprehensive experimental results show that DRaM can effectively solve the problems of differentiable reasoning on the KGs, and can extract first-order logic rules with confidences from the reasoning process. DRaM not only enhances the reasoning performance with the help of first-order logic rules, but also enhances the interpretability of the method. © 2023 Journal of Computer Engineering and Applications Beijing Co., Ltd.; Science Press. All rights reserved.},
	author_keywords = {first-order logic rule; interpretable reasoning; knowledge graph reasoning; large language model (LLM)},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Ghandikota2024171,
	author = {Ghandikota, Sudhir K. and Jegga, Anil G.},
	title = {Application of artificial intelligence and machine learning in drug repurposing},
	year = {2024},
	journal = {Progress in Molecular Biology and Translational Science},
	volume = {205},
	pages = {171 – 211},
	doi = {10.1016/bs.pmbts.2024.03.030},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189339992&doi=10.1016%2fbs.pmbts.2024.03.030&partnerID=40&md5=d8b63847052cb7aa333dbfa19f899ca5},
	abstract = {The purpose of drug repurposing is to leverage previously approved drugs for a particular disease indication and apply them to another disease. It can be seen as a faster and more cost-effective approach to drug discovery and a powerful tool for achieving precision medicine. In addition, drug repurposing can be used to identify therapeutic candidates for rare diseases and phenotypic conditions with limited information on disease biology. Machine learning and artificial intelligence (AI) methodologies have enabled the construction of effective, data-driven repurposing pipelines by integrating and analyzing large-scale biomedical data. Recent technological advances, especially in heterogeneous network mining and natural language processing, have opened up exciting new opportunities and analytical strategies for drug repurposing. In this review, we first introduce the challenges in repurposing approaches and highlight some success stories, including those during the COVID-19 pandemic. Next, we review some existing computational frameworks in the literature, organized on the basis of the type of biomedical input data analyzed and the computational algorithms involved. In conclusion, we outline some exciting new directions that drug repurposing research may take, as pioneered by the generative AI revolution. © 2024},
	author_keywords = {Artificial Intelligence; De novo drug discovery; Deep Learning; Drug repositioning; Drug repurposing; Machine Learning; Network analysis},
	keywords = {Artificial Intelligence; COVID-19; COVID-19 Drug Treatment; Drug Repositioning; Humans; Machine Learning; SARS-CoV-2; artificial intelligence; data mining; drug analysis; drug development; drug repositioning; drug targeting; heterogeneous knowledge graph mining; human; kernel method; knowledge; machine learning; molecular fingerprinting; multi view learning; network learning; coronavirus disease 2019; COVID-19 pharmacotherapy; drug effect; procedures; Severe acute respiratory syndrome coronavirus 2},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{2023,
	title = {ACM Web Conference 2023 - Companion of the World Wide Web Conference, WWW 2023},
	year = {2023},
	journal = {ACM Web Conference 2023 - Companion of the World Wide Web Conference, WWW 2023},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159628985&partnerID=40&md5=8cde0388c88634e63229b2a66865d552},
	abstract = {The proceedings contain 281 papers. The topics discussed include: lower risks, better choices: stock correlation based portfolio selection in stock markets; graph-level embedding for time-evolving graphs; on graph time-series representations for temporal networks; creation and analysis of a corpus of scam emails targeting universities; expressive user embedding from churn and recommendation multi-task learning; a concept knowledge graph for user next intent prediction at Alipay; Mirror: a natural language interface for data querying, summarization, and visualization; knowledge distillation on cross-modal adversarial reprogramming for data-limited attribute inference; incorporating embedding to topic modeling for more effective short text analysis; augmenting visualizations with predictive and investigative insights to facilitate decision making; improving the relevance of product search for queries with negations; and copyright protection and accountability of generative ai: attack, watermarking and attribution.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Zhao2023475,
	author = {Zhao, Wei and Chen, Qinghui and You, Junling},
	title = {LlmRe: A zero-shot entity relation extraction method based on the large language model},
	year = {2023},
	journal = {ACM International Conference Proceeding Series},
	pages = {475 – 480},
	doi = {10.1145/3650400.3650478},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191438497&doi=10.1145%2f3650400.3650478&partnerID=40&md5=3b8ba968993d8316bfff0c58a6d7432e},
	abstract = {Entity relation extraction aims to extract knowledge triples from unstructured or semi-structured text data and can be applied to various fields, including medicine, finance knowledge graph construction and intelligent question-answering. Traditional entity relation extraction requires a large amount of labeled data, consumes a lot of labor and time, and the trained model lacks generalization ability, which is difficult to migrate to other fields. Zero-shot entity relation extraction relieves the dependence on labeled data in traditional method. Based on unlabeled text data, zero-shot entity relation extraction has strong domain adaptability, which is a very challenging and practical task. Recent work on large language models shows that large models can effectively complete downstream tasks through natural language instructions and have good generalization ability. Inspired by this, we explore the use of large models for information extraction. Due to the randomness of large language model generation, we introduce in-context learning in entity relation extraction task to guide large language model to output data in a specified format to help obtain structured data. At the same time, we propose a three-stage extraction framework for decomposing entity relation extraction tasks, and each stage is conducted in the form of question and answer to reduce the complexity of extraction. We evaluated the knowledge triples extraction performance of the model on three self-built test datasets in different fields, and the experimental result showed that our proposed method achieved impressive performance in the zero-shot entity relation extraction task, surpassing the comparison model on multiple metrics, proving the effectiveness and domain adaptability of the proposed method.  © 2023 ACM.},
	author_keywords = {Entity relation extraction; In-context learning; Information extraction; Large language model; mutistage framework; Natural language processing},
	keywords = {Computational linguistics; Data mining; Information retrieval; Knowledge graph; Learning systems; Natural language processing systems; Context learning; Entity relation extractions; In contexts; In-context learning; Information extraction; Language model; Language processing; Large language model; Mutistage framework; Natural language processing; Natural languages; Zero-shot learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Chernomorchenko202449,
	author = {Chernomorchenko, Polina and Panchenko, Alexander and Nikishina, Irina},
	title = {Leveraging Taxonomic Information from Large Language Models for Hyponymy Prediction},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14486 LNCS},
	pages = {49 – 63},
	doi = {10.1007/978-3-031-54534-4_4},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189495217&doi=10.1007%2f978-3-031-54534-4_4&partnerID=40&md5=e475ae447d07010e0a46ff3279b8dad9},
	abstract = {Pre-trained language models contain a vast amount of linguistic information as well as knowledge about the structure of the world. Both of these attributes are extremely beneficial for automatic enrichment of semantic graphs, such as knowledge bases and lexical-semantic databases. In this article, we employ generative language models to predict descendants of existing nodes in lexical data structures based on IS-A relations, such as WordNet. To accomplish this, we conduct experiments utilizing diverse formats of artificial text input containing information from lexical taxonomy for the English and Russian languages. Our findings demonstrate that the incorporation of data from the knowledge graph into a text input significantly affects the quality of hyponym prediction. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {generative transformers; hyponym prediction; IS-A relations; taxonomy enrichment},
	keywords = {Computational linguistics; Forecasting; Knowledge graph; Semantics; Generative transformer; Hyponym prediction; Hyponyms; Hyponymy; IS-A relation; Language model; Linguistic information; Linguistic knowledge; Taxonomy enrichment; Text input; Taxonomies},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Colucci Cante2024597,
	author = {Colucci Cante, Luigi and Di Martino, Beniamino and Graziano, Mariangela and Branco, Dario and Pezzullo, Gennaro Junior},
	title = {Automated Storytelling Technologies for Cultural Heritage},
	year = {2024},
	journal = {Lecture Notes on Data Engineering and Communications Technologies},
	volume = {193},
	pages = {597 – 606},
	doi = {10.1007/978-3-031-53555-0_57},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186402642&doi=10.1007%2f978-3-031-53555-0_57&partnerID=40&md5=927cacb660653ab5487d3e2d6960fa4c},
	abstract = {The awareness of the importance of communicating cultural heritage through innovative and automated means is steadily increasing. This awareness is fueled by the need to promote cultural heritage knowledge in accessible and engaging ways for an increasingly digital audience. This article aims to examine in detail the various methodologies used in the creation of automated storytelling for historical cultural heritage communication. In particular, attention is given to models based on large language models, such as those derived from advanced neural networks, which demonstrate significant potential in generating rich and engaging narratives. Another key aspect of the analysis concerns the use of chatbots in the context of automated storytelling. The possibilities offered by interactive conversation managed by virtual agents are explored, which can enhance the user experience through personalized dialogues and contextualized information. Additionally, the article focuses on various tools dedicated to automatic storytelling writing, evaluating their effectiveness and versatility in the specific context of historical cultural heritage. These tools are essential to facilitate the creative process and ensure narrative coherence. A significant part of the analysis addresses automated storytelling models based on processes, exploring how the sequence of events and concepts can be managed automatically to construct meaningful and relevant stories from a historical perspective. Furthermore, applications of ontologies and other tools are examined with the aim of improving the structure and understanding of narratives, ensuring effective linkage between different elements of historical cultural heritage. The overall goal of the article is to provide a comprehensive view of the current landscape of automated storytelling techniques, highlighting the still-open challenges and potential future development directions in this field. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	keywords = {Chatbots; Creative process; Cultural heritages; Historical perspective; Language model; Model-based OPC; Neural-networks; Sequence of events; Users' experiences; Virtual agent; Automation},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5}
}

@CONFERENCE{Lin20231303,
	author = {Lin, Hongpeng and Ruan, Ludan and Xia, Wenke and Liu, Peiyu and Wen, Jingyuan and Xu, Yixin and Hu, Di and Song, Ruihua and Zhao, Wayne Xin and Jin, Qin and Lu, Zhiwu},
	title = {TikTalk: A Video-Based Dialogue Dataset for Multi-Modal Chitchat in Real World},
	year = {2023},
	journal = {MM 2023 - Proceedings of the 31st ACM International Conference on Multimedia},
	pages = {1303 – 1313},
	doi = {10.1145/3581783.3612425},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179552988&doi=10.1145%2f3581783.3612425&partnerID=40&md5=830f80d9a12954b28280c4393db4d621},
	abstract = {To facilitate the research on intelligent and human-like chatbots with multi-modal context, we introduce a new video-based multi-modal dialogue dataset, called TikTalk. We collect 38K videos from a popular video-sharing platform, along with 367K conversations posted by users beneath them. Users engage in spontaneous conversations based on their multi-modal experiences from watching videos, which helps recreate real-world chitchat context. Compared to previous multi-modal dialogue datasets, the richer context types in TikTalk lead to more diverse conversations, but also increase the difficulty in capturing human interests from intricate multi-modal information to generate personalized responses. Moreover, external knowledge is more frequently evoked in our dataset. These facts reveal new challenges for multi-modal dialogue models. We quantitatively demonstrate the characteristics of TikTalk, propose a video-based multi-modal chitchat task, and evaluate several dialogue baselines. Experimental results indicate that the models incorporating large language models (LLM) can generate more diverse responses, while the model utilizing knowledge graphs to introduce external knowledge performs the best overall. Furthermore, no existing model can solve all the above challenges well. There is still a large room for future improvements, even for LLM with visual extensions. Our dataset is available at https://ruc-aimind.github.io/projects/TikTalk/. © 2023 ACM.},
	author_keywords = {chitchat; dataset; multi-modal dialogue; real world},
	keywords = {Chatbots; Chitchat; Dataset; External knowledge; Human like; Language model; Multi-modal; Multi-modal dialog; Real-world; Video sharing},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; All Open Access, Green Open Access}
}

@ARTICLE{Jiang20241474,
	author = {Jiang, Yiwei and De Raedt, Maarten and Deleu, Johannes and Demeester, Thomas and Develder, Chris},
	title = {Few-shot out-of-scope intent classification: analyzing the robustness of prompt-based learning},
	year = {2024},
	journal = {Applied Intelligence},
	volume = {54},
	number = {2},
	pages = {1474 – 1496},
	doi = {10.1007/s10489-023-05215-x},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181448600&doi=10.1007%2fs10489-023-05215-x&partnerID=40&md5=72887131c573ea76cf0ec03cd540dcab},
	abstract = {Out-of-scope (OOS) intent classification is an emerging field in conversational AI research. The goal is to detect out-of-scope user intents that do not belong to a predefined intent ontology. However, establishing a reliable OOS detection system is challenging due to limited data availability. This situation necessitates solutions rooted in few-shot learning techniques. For such few-shot text classification tasks, prompt-based learning has been shown more effective than conventionally finetuned large language models with a classification layer on top. Thus, we advocate for exploring prompt-based approaches for OOS intent detection. Additionally, we propose a new evaluation metric, the Area Under the In-scope and Out-of-Scope Characteristic curve (AU-IOC). This metric addresses the shortcomings of current evaluation standards for OOS intent detection. AU-IOC provides a comprehensive assessment of a model’s dual performance capacities: in-scope classification accuracy and OOS recall. Under this new evaluation method, we compare our prompt-based OOS detector against 3 strong baseline models by exploiting the metadata of intent annotations, i.e., intent description. Our study found that our prompt-based model achieved the highest AU-IOC score across different data regimes. Further experiments showed that our detector is insensitive to a variety of intent descriptions. An intriguing finding shows that for extremely low data settings (1- or 5-shot), employing a naturally phrased prompt template boosts the detector’s performance compared to rather artificially structured template patterns. © The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature 2024.},
	author_keywords = {Dialogue intent classification; Few-shot learning; Outlier/novelty detection; Prompt-based models},
	keywords = {Learning systems; Text processing; Detection system; Dialog intent classification; Few-shot learning; Intent detection; Limited data; Novelty detection; Ontology's; Outlier/novelty detection; Performance; Prompt-based model; Classification (of information)},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Sadik2024149,
	author = {Sadik, Ahmed R. and Brulin, Sebastian and Olhofer, Markus},
	title = {Coding by Design: GPT-4 Empowers Agile Model Driven Development},
	year = {2024},
	journal = {International Conference on Model-Driven Engineering and Software Development},
	volume = {1},
	pages = {149 – 158},
	doi = {10.5220/0012356100003645},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190369863&doi=10.5220%2f0012356100003645&partnerID=40&md5=be458d58de130a32f6bfbfe1072be384},
	abstract = {Generating code from a natural language using Large Language Models (LLMs) such as ChatGPT, seems groundbreaking. Yet, with more extensive use, it's evident that this approach has its own limitations. The inherent ambiguity of natural language proposes challenges to auto-generate synergistically structured artifacts that can be deployed. Model Driven Development (MDD) is therefore being highlighted in this research as a proper approach to overcome these challenges. Accordingly, we introduced an Agile Model- Driven Development (AMDD) approach that enhances code auto-generation using OpenAI's GPT-4. Our work emphasizes "Agility" as a significant contribution to the current MDD approach, particularly when the model undergoes changes or needs deployment in a different programming language. Thus, we presented a case-study showcasing a multi-agent simulation system of an Unmanned Vehicle Fleet (UVF). In the first and second layer of our proposed approach, we modelled the structural and behavioural aspects of the case-study using Unified Modeling Language (UML). In the next layer, we introduced two sets of meta-modelling constraints that minimize the model ambiguity. Object Constraints Language (OCL) is applied to fine-tune the code constructions details, while FIPA ontology is used to shape the communication semantics. Ultimately, GPT-4 is used to auto-generate code from the model in both Java and Python. The Java code is deployed within the JADE framework, while the Python code is deployed in PADE framework. Concluding our research, we engaged in a comprehensive evaluation of the generated code. From a behavioural standpoint, the auto-generated code not only aligned with the expected UML sequence diagram, but also added new behaviours that improved the interaction among the classes. Structurally, we compared the complexity of code derived from UML diagrams constrained solely by OCL to that influenced by both OCL and FIPA-ontology. Results showed that ontology-constrained model produced inherently more intricate code, however it remains manageable. Thus, other constraints can still be added to the model without passing the complexity high risk threshold. © 2024 by SCITEPRESS – Science and Technology Publications, Lda.},
	author_keywords = {AI-Empowered; Auto-Generated Code; Cyclomatic Complexity; GPT-4; Model Driven Development; Object Constraint Language; Ontology-Constrained Class Diagram},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Ushio20242473,
	author = {Ushio, Asahi and Collados, Jose Camacho and Schockaert, Steven},
	title = {A RELENTLESS Benchmark for Modelling Graded Relations between Named Entities},
	year = {2024},
	journal = {EACL 2024 - 18th Conference of the European Chapter of the Association for Computational Linguistics, Proceedings of the Conference},
	volume = {1},
	pages = {2473 – 2486},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189940093&partnerID=40&md5=fa1fe6238646b24dbc5f2396edab210e},
	abstract = {Relations such as “is influenced by”, “is known for” or “is a competitor of” are inherently graded: we can rank entity pairs based on how well they satisfy these relations, but it is hard to draw a line between those pairs that satisfy them and those that do not. Such graded relations play a central role in many applications, yet they are typically not covered by existing Knowledge Graphs. In this paper, we consider the possibility of using Large Language Models (LLMs) to fill this gap. To this end, we introduce a new benchmark, in which entity pairs have to be ranked according to how much they satisfy a given graded relation. The task is formulated as a few-shot ranking problem, where models only have access to a description of the relation and five prototypical instances. We use the proposed benchmark to evaluate state-of-the-art relation embedding strategies as well as several publicly available LLMs and closed conversational models such as GPT-4. We find that smaller language models struggle to outperform a naive baseline. Overall, the best results are obtained with the 11B parameter Flan-T5 model and the 13B parameter OPT model, where further increasing the model size does not seem to be beneficial. For all models, a clear gap with human performance remains. © 2024 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Natural language processing systems; Conversational model; Embedding strategies; Human performance; Knowledge graphs; Language model; Model size; Named entities; Ranking problems; Relation embedding; State of the art; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Sukhwal202398,
	author = {Sukhwal, Prakash Chandra and Kankanhalli, Atreyi and Rajan, Vaibhav},
	title = {Evaluation Dimensions for Assessing Question Answer Systems for Lay Users: The Case of DiseaseGuru},
	year = {2023},
	journal = {Proceedings of the Inaugural 2023 Summer Symposium Series 2023},
	pages = {98 – 102},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175403061&partnerID=40&md5=a7da47fe7a516ea23707c15caf80493c},
	abstract = {Question answer (QA) systems can serve as vital tools to address lay users’ information needs in healthcare. While QA systems have the potential to lessen information overload and provide quality answers to users, it is important to holistically evaluate their performance. Here we propose multiple dimensions for this purpose comprising lexical similarity, semantic similarity, absence of contradictions and readability of responses. We then use the dimensions to evaluate DiseaseGuru, a generative large language model-based chronic disease QA system we developed that integrates knowledge graph technology to provide quality responses to lay users. The results are presented comparing it with three benchmark algorithms across the different dimensions. We also propose metrics for lay users and medical professionals for a future field study to evaluate the system. © 2023, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.},
	keywords = {Knowledge graph; Semantics; Chronic disease; Information overloads; Language model; Lexical similarity; Model-based OPC; Multiple dimensions; Performance; Question answer systems; Semantic similarity; User information need; Quality control},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Cardillo2024100,
	author = {Cardillo, Elena and Portaro, Alessio and Taverniti, Maria and Lanza, Claudia and Guarasci, Raffaele},
	title = {Towards the Automated Population of Thesauri Using BERT: A Use Case on the Cybersecurity Domain},
	year = {2024},
	journal = {Lecture Notes on Data Engineering and Communications Technologies},
	volume = {193},
	pages = {100 – 109},
	doi = {10.1007/978-3-031-53555-0_10},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186487152&doi=10.1007%2f978-3-031-53555-0_10&partnerID=40&md5=5356803f37d48124669c5ccb1d6767e5},
	abstract = {The present work delves into innovative methodologies leveraging the widely used BERT model to enhance the population and enrichment of domain-oriented controlled vocabularies as Thesauri. Starting from BERT’s embeddings, we extracted information from a sample corpus of Cybersecurity related documents and presented a novel Natural Language Processing-inspired pipeline that combines Neural language models, knowledge graph extraction, and natural language inference for identifying implicit relations (adaptable to thesaural relationships) and domain concepts to populate a domain thesaurus. Preliminary results are promising, showing the effectiveness of using the proposed methodology, and thus the applicability of LLMs, BERT in particular, to enrich specialized controlled vocabularies with new knowledge. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {Domain-specific language modeling; Knowledge Extraction; LLMs; Semantic analysis; Thesauri},
	keywords = {Computational linguistics; Domain Knowledge; Extraction; Knowledge graph; Modeling languages; Natural language processing systems; Pipeline processing systems; Problem oriented languages; Semantics; Vocabulary control; Cyber security; Domain-oriented; Domain-specific language modeling; Domains specific languages; Innovative methodologies; Knowledge extraction; Language model; LLM; Natural languages; Semantic analysis; Thesauri},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Li2023754,
	author = {Li, Wenqing and Qi, Xiaoman and Zhao, Qi and Wang, Chen and Wu, Qiongyu and Tang, Xue-Song},
	title = {Knowledge Graph-Based Credibility Evaluation Method for Electric Grid Large Language Model Knowledge Question-Answering},
	year = {2023},
	journal = {ACM International Conference Proceeding Series},
	pages = {754 – 759},
	doi = {10.1145/3650400.3650526},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191488515&doi=10.1145%2f3650400.3650526&partnerID=40&md5=b2e441e6ba87f4f30ecb75b1c7cb0d38},
	abstract = {In the field of electricity, specialized terminology is often intricate and complex, making it challenging for non-experts to comprehend. However, with the advancement of artificial intelligence technology, the emergence of large language models provides a new technological solution to address this issue. Large language models, based on deep learning techniques, have the capability to quickly understand and interpret specialized terminology in the electricity domain through learning from a vast corpus of professional literature and data. They can then be applied to various domains, including question-answering systems. However, existing large language models still face issues of unreliable outputs, necessitating a method to evaluate their results and improve the quality of their applications. We propose a knowledge graph-based credibility evaluation method for electric grid large language model knowledge question-answering. This method aligns the answers generated by large language models with the knowledge graph of a local knowledge base and calculates their cosine similarity and Pearson correlation coefficient. We batch-process the answers from the large language model into an electricity dataset and validate them using this method. Experimental results demonstrate that this method can accurately and efficiently reflect the relevance between texts, providing a reliable scoring basis for question-answering by large models in vertical domains. Future research can focus on exploring other embedding methods that can better extract semantic relationships between texts and validating the feasibility of this method in vertical domains other than electricity.  © 2023 ACM.},
	author_keywords = {Electrical Engineering; Knowledge Graph; Large Language Models},
	keywords = {Batch data processing; Computational linguistics; Correlation methods; Deep learning; Engineering education; Graphic methods; Knowledge graph; Learning systems; Quality control; Semantics; Artificial intelligence technologies; Credibility evaluation; Electric grids; Evaluation methods; Graph-based; Knowledge graphs; Language model; Large language model; Model knowledge; Question Answering; Terminology},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Kosa202425,
	author = {Kosa, Victoria and Dobosevych, Oles and Ermolayev, Vadim},
	title = {Terminology Saturation Analysis: Refinements and Applications},
	year = {2024},
	journal = {Communications in Computer and Information Science},
	volume = {1810 CCIS},
	pages = {25 – 41},
	doi = {10.1007/978-3-031-53770-7_3},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189532216&doi=10.1007%2f978-3-031-53770-7_3&partnerID=40&md5=9689c9246ca134d9defd60d5e0386fa6},
	abstract = {In this paper, we outline the results of our recent research on terminology saturation analysis (TSA) in subject domain-bounded textual corpora. We present the developed TSA method. We further report about the two use cases that proved the validity, efficiency, and effectiveness of TSA. Based on our experience of TSA use, we analyse the shortcomings of the method and figure out the ways to refinement and improvement. Further, we share our prognoses on how TSA could be used for: (i) generating quality datasets of minimal size for training large language models for performing better in scientific domains; (ii) iteratively constructing domain ontologies and knowledge graphs that representatively describe a subject domain, or topic; or (iii) detecting and predicting events based on the TSA of textual streams data. © The Author(s) 2024.},
	author_keywords = {Deep Learning; Event Detection; Event Prediction; Large Language Model; Scientific Domain Ontology; Scientific Knowledge Graph; Terminological Saturation Analysis; Transfer Learning},
	keywords = {Computational linguistics; Deep learning; Iterative methods; Large datasets; Ontology; Terminology; Deep learning; Domain ontologies; Event prediction; Events detection; Knowledge graphs; Language model; Large language model; Scientific domain ontology; Scientific knowledge; Scientific knowledge graph; Terminological saturation analyse; Transfer learning; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Fan20241269,
	author = {Fan, Haolin and Fuh, Jerry and Lu, Wen Feng and Kumar, A. Senthil and Li, Bingbing},
	title = {Unleashing the Potential of Large Language Models for Knowledge Augmentation: A Practical Experiment on Incremental Sheet Forming},
	year = {2024},
	journal = {Procedia Computer Science},
	volume = {232},
	pages = {1269 – 1278},
	doi = {10.1016/j.procs.2024.01.125},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189785894&doi=10.1016%2fj.procs.2024.01.125&partnerID=40&md5=fff8b19f64806640a1d9cb8bb3cb921a},
	abstract = {As the influence of Incremental Sheet Forming (ISF) grows in manufacturing sectors, so does the demand for precise and updated knowledge construction in this domain. In this research, we evaluate the capability of Large Language Models (LLMs) to capture domain-specific knowledge, using ISF as a case study. Recognizing common LLMs' limitations such as potential inaccuracies and outdated information reliance, we propose a comprehensive approach involving automated and adaptive knowledge extraction, enrichment, and integration into an ISF-specific dataset. We then fine-tune the LLMs for ISF-related text classification and prompt response tasks. Our results reveal a significant enhancement in LLMs' performance within the ISF domain, with a domain knowledge acquisition rate exceeding that of GPT-3.5 by 10.4%, achieved by the fine-tuned Alpaca-33B model. Additionally, we introduce a novel conversational prototype designed to refine the accuracy and relevance of LLMs in the ISF domain. Our findings will guide future efforts in downstream tasks such as ISF-domain knowledge graph construction and quality prediction. © 2024 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (https://creativecommons.org/licenses/by-nc-nd/4.0)},
	author_keywords = {Domain Knowledge Augmentation; Fine-tuning; Incremental Sheet Forming; Large Language Models},
	keywords = {Classification (of information); Computational linguistics; Knowledge graph; Text processing; Case-studies; Domain knowledge; Domain knowledge augmentation; Domain-specific knowledge; Fine tuning; Incremental sheet forming; Knowledge construction; Language model; Large language model; Manufacturing sector; Domain Knowledge},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Gold Open Access}
}

@ARTICLE{Li20232358,
	author = {Li, Yuan and Ma, Xinyu and Yang, Guoli and Zhao, Huiqun and Song, Wei},
	title = {Survey of Causal Inference for Knowledge Graphs and Large Language Models; [面向知识图谱和大语言模型的因果关系推断综述]},
	year = {2023},
	journal = {Journal of Frontiers of Computer Science and Technology},
	volume = {17},
	number = {10},
	pages = {2358 – 2376},
	doi = {10.3778/j.issn.1673-9418.2307065},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184923445&doi=10.3778%2fj.issn.1673-9418.2307065&partnerID=40&md5=f8551a46a582460f158f32c339d9188c},
	abstract = {In recent decades, causal inference has been a significant research topic in various fields, including statistics, computer science, education, public policy, and economics. Most causal inference methods focus on the analysis of sample observational data and text corpora. However, with the emergence of various knowledge graphs and large language models, causal inference tailored to knowledge graphs and large models has gradually become a research hotspot. In this paper, different causal inference methods are classified based on their orientation towards sample observational data, text data, knowledge graphs, and large language models. Within each classification, this paper provides a detailed analysis of classical research works, including their problem definitions, solution methods, contributions, and limitations. Additionally, this paper places particular emphasis on discussing recent advancements in the integration of causal inference methods with knowledge graphs and large language models. Various causal inference methods are analyzed and compared from the perspectives of efficiency and cost, and specific applications of knowledge graphs and large language models in causal inference tasks are summarized. Finally, future development directions of causal inference in combination with knowledge graphs and large models are prospected. © 2023 Journal of Computer Engineering and Applications Beijing Co., Ltd.; Science Press. All rights reserved.},
	author_keywords = {causal relationship; knowledge graph; large language model},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6}
}

@CONFERENCE{Lu20232052,
	author = {Lu, Jiaying and Ma, Wenjing and Shen, Jiaming and Staab, Steffen and Xiong, Bo and Yang, Carl},
	title = {HiPrompt: Few-Shot Biomedical Knowledge Fusion via Hierarchy-Oriented Prompting},
	year = {2023},
	journal = {SIGIR 2023 - Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval},
	pages = {2052 – 2056},
	doi = {10.1145/3539618.3591997},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167949945&doi=10.1145%2f3539618.3591997&partnerID=40&md5=0d973112a706c900bdc875a59bbd8c1f},
	abstract = {Medical decision-making processes can be enhanced by comprehensive biomedical knowledge bases, which require fusing knowledge graphs constructed from different sources via a uniform index system. The index system often organizes biomedical terms in a hierarchy to provide the aligned entities with fine-grained granularity. To address the challenge of scarce supervision in the biomedical knowledge fusion (BKF) task, researchers have proposed various unsupervised methods. However, these methods heavily rely on ad-hoc lexical and structural matching algorithms, which fail to capture the rich semantics conveyed by biomedical entities and terms. Recently, neural embedding models have proved effective in semantic-rich tasks, but they rely on sufficient labeled data to be adequately trained. To bridge the gap between the scarce-labeled BKF and neural embedding models, we propose HiPrompt, a supervision-efficient knowledge fusion framework that elicits the few-shot reasoning ability of large language models through hierarchy-oriented prompts. Empirical results on the collected KG-Hi-BKF benchmark datasets demonstrate the effectiveness of HiPrompt. © 2023 Copyright held by the owner/author(s).},
	author_keywords = {Biomedical Knowledge Fusion; Few-Shot Prompting; Large Language Models for Resource-Constrained Field; Retrieve & Re-Rank},
	keywords = {Bioinformatics; Computational linguistics; Decision making; Knowledge graph; Natural language processing systems; Semantics; Biomedical knowledge fusion; Decision-making process; Embeddings; Few-shot prompting; Indices systems; Knowledge fusion; Language model; Large language model for resource-constrained field; Medical decision making; Retrieve & re-rank; Embeddings},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Green Open Access}
}

@ARTICLE{Fecho2023,
	author = {Fecho, Karamarie and Bizon, Chris and Issabekova, Tursynay and Moxon, Sierra and Thessen, Anne E. and Abdollahi, Shervin and Baranzini, Sergio E. and Belhu, Basazin and Byrd, William E. and Chung, Lawrence and Crouse, Andrew and Duby, Marc P. and Ferguson, Stephen and Foksinska, Aleksandra and Forero, Laura and Friedman, Jennifer and Gardner, Vicki and Glusman, Gwênlyn and Hadlock, Jennifer and Hanspers, Kristina and Hinderer, Eugene and Hobbs, Charlotte and Hyde, Gregory and Huang, Sui and Koslicki, David and Mease, Philip and Muller, Sandrine and Mungall, Christopher J. and Ramsey, Stephen A. and Roach, Jared and Rubin, Irit and Schurman, Shepherd H. and Shalev, Anath and Smith, Brett and Soman, Karthik and Stemann, Sarah and Su, Andrew I. and Ta, Casey and Watkins, Paul B. and Williams, Mark D. and Wu, Chunlei and Xu, Colleen H.},
	title = {An approach for collaborative development of a federated biomedical knowledge graph-based question-answering system: Question-of-the-Month challenges},
	year = {2023},
	journal = {Journal of Clinical and Translational Science},
	volume = {7},
	number = {1},
	doi = {10.1017/cts.2023.619},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172300465&doi=10.1017%2fcts.2023.619&partnerID=40&md5=9ada9076ecfac48f23a62cbe7aa6aa7e},
	abstract = {Knowledge graphs have become a common approach for knowledge representation. Yet, the application of graph methodology is elusive due to the sheer number and complexity of knowledge sources. In addition, semantic incompatibilities hinder efforts to harmonize and integrate across these diverse sources. As part of The Biomedical Translator Consortium, we have developed a knowledge graph-based question-answering system designed to augment human reasoning and accelerate translational scientific discovery: the Translator system. We have applied the Translator system to answer biomedical questions in the context of a broad array of diseases and syndromes, including Fanconi anemia, primary ciliary dyskinesia, multiple sclerosis, and others. A variety of collaborative approaches have been used to research and develop the Translator system. One recent approach involved the establishment of a monthly Question-of-the-Month (QotM) Challenge series. Herein, we describe the structure of the QotM Challenge; the six challenges that have been conducted to date on drug-induced liver injury, cannabidiol toxicity, coronavirus infection, diabetes, psoriatic arthritis, and ATP1A3-related phenotypes; the scientific insights that have been gleaned during the challenges; and the technical issues that were identified over the course of the challenges and that can now be addressed to foster further development of the prototype Translator system. We close with a discussion on Large Language Models such as ChatGPT and highlight differences between those models and the Translator system.  © The Author(s), 2023. Published by Cambridge University Press on behalf of The Association for Clinical and Translational Science.},
	author_keywords = {bioinformatics; knowledge graphs; semantic technology; team science; Translational research},
	keywords = {cannabidiol; answering service; Article; biomedicine; cannabis addiction; ChatGPT; ciliary dyskinesia; clinical reasoning; collaborative learning; controlled study; Coronavirus infection; diabetes mellitus; drug-induced liver injury; Fanconi anemia; knowledge base; knowledge gap; liver disease; multiple sclerosis; nonhuman; phenotype; porphyria; psoriatic arthritis; questionnaire; translational medicine},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Jovanovic2023103,
	author = {Jovanovic, Mladan and Campbell, Mark},
	title = {Connecting AI: Merging Large Language Models and Knowledge Graph},
	year = {2023},
	journal = {Computer},
	volume = {56},
	number = {11},
	pages = {103 – 108},
	doi = {10.1109/MC.2023.3305206},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175178826&doi=10.1109%2fMC.2023.3305206&partnerID=40&md5=d0d2046c97d741103e27573fb236b498},
	abstract = {Combining the generative abilities of large language models with the logical and factual coherence of knowledge graphs using a connected artificial intelligence architecture minimizes each system's shortcomings and amplifies their strengths across many real-world domains. © 1970-2012 IEEE.},
	keywords = {Computational linguistics; Knowledge graphs; Language model; Real world domain; Knowledge graph},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; All Open Access, Bronze Open Access}
}

@CONFERENCE{Zhao20235,
	author = {Zhao, Ava and Su, Zhanqi and Fei, Bill and Zhuo, Na and Wang, Hao and Yu, Tianzhou and Li, Zuotian and Qian, Cheryl and Chen, Yingjie Victor},
	title = {Facilitating Visual Analytics with ChatGPT: 2023 VAST Challenge Award - Application of LLMs to Support VA Process},
	year = {2023},
	journal = {Proceedings - 2023 VAST Challenge, vast-challenge 2023},
	pages = {5 – 6},
	doi = {10.1109/VASTChallenge60523.2023.00008},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85199422414&doi=10.1109%2fVASTChallenge60523.2023.00008&partnerID=40&md5=c7942c14d3ef48f16ead02aebcfa9d0c},
	abstract = {To solve the VAST Challenge 2023 MC3, our team employed a large language model, ChatGPT, to explore the potential of AI -guided visual analytics for the detection of anomalies within a knowledge graph in the context of illegal fishing and marine trade. We employed a systematic and iterative approach, guided by GPT augmentation, that enabled problem understanding, data processing, solution exploration, code writing, and results analysis. By generating and analyzing various graphs, we identified anomalies related to revenue and product services. Further analyses unveiled potential illegal fishing activities and identified instances warranting additional investigation. Overall, our work highlights both the strengths and limitations of ChatGPT in aiding the visual analytics process and emphasizes the importance of human judgment in refining AI-generated outputs.  © 2023 IEEE.},
	author_keywords = {AI Language Model; Assisted Learning; ChatGPT; Knowledge GraphMarine Trade; Visual Analytics},
	keywords = {Computational linguistics; Crime; Data handling; Fisheries; Knowledge graph; Visualization; AI language model; Assisted learning; ChatGPT; Iterative approach; Knowledge graphmarine trade; Knowledge graphs; Language model; Marine trade; Problem understanding; Visual analytics; Commerce},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Shou202346520,
	author = {Shou, Xiao and Bhattacharjya, Debarun and Gao, Tian and Subramanian, Dharmashankar and Hassanzadeh, Oktie and Bennett, Kristin},
	title = {Pairwise Causality Guided Transformers for Event Sequences},
	year = {2023},
	journal = {Advances in Neural Information Processing Systems},
	volume = {36},
	pages = {46520 – 46533},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85205705787&partnerID=40&md5=0c26842c17c54de3ba65c8f8db9d2ead},
	abstract = {Although pairwise causal relations have been extensively studied in observational longitudinal analyses across many disciplines, incorporating knowledge of causal pairs into deep learning models for temporal event sequences remains largely unexplored. In this paper, we propose a novel approach for enhancing the performance of transformer-based models in multivariate event sequences by injecting pairwise qualitative causal knowledge such as 'event Z amplifies future occurrences of event Y'. We establish a new framework for causal inference in temporal event sequences using a transformer architecture, providing a theoretical justification for our approach, and show how to obtain unbiased estimates of the proposed measure. Experimental results demonstrate that our approach outperforms several state-of-the-art models in terms of prediction accuracy by effectively leveraging knowledge about causal pairs. We also consider a unique application where we extract knowledge around sequences of societal events by generating them from a large language model, and demonstrate how a causal knowledge graph can help with event prediction in such sequences. Overall, our framework offers a practical means of improving the performance of transformer-based models in multivariate event sequences by explicitly exploiting pairwise causal information. © 2023 Neural information processing systems foundation. All rights reserved.},
	keywords = {Contrastive Learning; Deep learning; Distribution transformers; Knowledge graph; Prediction models; ART model; Causal inferences; Causal relations; Event sequence; Learning models; Longitudinal analysis; Performance; State of the art; Temporal event sequences; Unbiased estimates; Spatio-temporal data},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Zhao20234844,
	author = {Zhao, Honda and Jiang, Wei and Deng, Jiewen and Ren, Qinghua and Zhang, Li},
	title = {Constructing Knowledge Graph for Electricity Keywords Based on Large Language Model},
	year = {2023},
	journal = {2023 IEEE 7th Conference on Energy Internet and Energy System Integration, EI2 2023},
	pages = {4844 – 4849},
	doi = {10.1109/EI259745.2023.10512525},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194156503&doi=10.1109%2fEI259745.2023.10512525&partnerID=40&md5=2e88a32adee5f9484979c3da86f1a9b3},
	abstract = {In the information age, the electric power industry, as a crucial pillar of modern society, has accumulated a wealth of valuable research literature. Knowledge graph technology offers the potential to tap into this knowledge repository, providing a better understanding of research outcomes in the electric power domain. However, due to the diversity and complexity of knowledge in the power industry, it is difficult to build a comprehensive and complete knowledge graph of power keywords. In recent years, large language models (LLMs) have made significant advancements. This paper harnesses LLM technology along with text similarity analysis and co-occurrence frequency analysis to establish a comprehensive framework for processing keyword knowledge in the field of electric power. Within this framework, various forms of information found in electric power research can be processed. This includes creating a thesaurus of electric power domain keywords; obtaining the individual attributes implied by the information keywords in this thesaurus and their interconnections; and generating a knowledge graph of electric power domain keywords. This knowledge graph includes attributes, interpretations, relationships, and associated literature for keywords. It serves as a valuable reference for the effective utilization of research outcomes in the electric power domain.  © 2023 IEEE.},
	author_keywords = {ChatGLM; co-occurrence; knowledge graph; LLM; similarity analysis},
	keywords = {Computational linguistics; Electric industry; Thesauri; ChatGLM; Co-occurrence; Electric power; Keyword-based; Knowledge graphs; Language model; Large language model; Powerdomains; Research outcome; Similarity analysis; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Neuhaus2023399,
	author = {Neuhaus, Fabian},
	title = {Ontologies in the era of large language models - a perspective},
	year = {2023},
	journal = {Applied Ontology},
	volume = {18},
	number = {4},
	pages = {399 – 407},
	doi = {10.3233/AO-230072},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182277245&doi=10.3233%2fAO-230072&partnerID=40&md5=c9cd4a4256dc12c86dcde09a17f31ea4},
	abstract = {The potential of large language models (LLM) has captured the imagination of the public and researchers alike. In contrast to previous generations of machine learning models, LLMs are general-purpose tools, which can communicate with humans. In particular, they are able to define terms and answer factual questions based on some internally represented knowledge. Thus, LLMs support functionalities that are closely related to ontologies. In this perspective article, I will discuss the consequences of the advent of LLMs for the field of applied ontology. © 2023 - IOS Press. All rights reserved.},
	author_keywords = {Bard; ChatGPT; Copilot; large language model; Ontology development},
	keywords = {Computational linguistics; Am generals; Bard; ChatGPT; Copilot; Language model; Large language model; Machine learning models; Ontology development; Ontology's; Ontology},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9}
}

@ARTICLE{Woodman20232363,
	author = {Woodman, Richard J. and Mangoni, Arduino A.},
	title = {A comprehensive review of machine learning algorithms and their application in geriatric medicine: present and future},
	year = {2023},
	journal = {Aging Clinical and Experimental Research},
	volume = {35},
	number = {11},
	pages = {2363 – 2397},
	doi = {10.1007/s40520-023-02552-2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170247682&doi=10.1007%2fs40520-023-02552-2&partnerID=40&md5=059dbb7096a74058033a86f53653be51},
	abstract = {The increasing access to health data worldwide is driving a resurgence in machine learning research, including data-hungry deep learning algorithms. More computationally efficient algorithms now offer unique opportunities to enhance diagnosis, risk stratification, and individualised approaches to patient management. Such opportunities are particularly relevant for the management of older patients, a group that is characterised by complex multimorbidity patterns and significant interindividual variability in homeostatic capacity, organ function, and response to treatment. Clinical tools that utilise machine learning algorithms to determine the optimal choice of treatment are slowly gaining the necessary approval from governing bodies and being implemented into healthcare, with significant implications for virtually all medical disciplines during the next phase of digital medicine. Beyond obtaining regulatory approval, a crucial element in implementing these tools is the trust and support of the people that use them. In this context, an increased understanding by clinicians of artificial intelligence and machine learning algorithms provides an appreciation of the possible benefits, risks, and uncertainties, and improves the chances for successful adoption. This review provides a broad taxonomy of machine learning algorithms, followed by a more detailed description of each algorithm class, their purpose and capabilities, and examples of their applications, particularly in geriatric medicine. Additional focus is given on the clinical implications and challenges involved in relying on devices with reduced interpretability and the progress made in counteracting the latter via the development of explainable machine learning. © 2023, The Author(s).},
	author_keywords = {Artificial intelligence; Clinical decisions; Diagnosis; Geriatric medicine; Machine learning; Treatment},
	keywords = {Aged; Algorithms; Artificial Intelligence; Geriatrics; Humans; Machine Learning; hemoglobin; new drug; accuracy; actor critic approach; adverse drug reaction; algorithm; algorithm transparency; artificial intelligence; artificial neural network; atrial fibrillation; autoencoder; Bayesian network; breast cancer; cancer growth; cancer therapy; catheter ablation; clinical decision support system; clustering algorithm; clustering intrinsic capacity; cognition; comorbidity; convolutional neural network; data extraction; data visualization; deep learning; deep Q learning; dementia; diabetic patient; dimensionality reduction; discriminant analysis; disease drug network; drug indication; electronic health record; feature selection; feed forward neural network; fitted Q learning; generative modelling; geriatric care; geriatrics; graph algorithm; graph embedded topic modelling; graph embedding; graph machine learning; graph neural network; health care; health data; health status; heart surgery; hemodialysis; hemoglobin determination; huatuoGPT; human; hypertension; independent component analysis; intensive care unit; knowledge graph; label propagation; label spreading; large language model; length of stay; lifestyle; long short term memory network; machine learning; multiple chronic conditions; natural language processing; non insulin dependent diabetes mellitus; patient care; personalized medicine; policy based reinforcement learning; prediction; principal component analysis; probabilistic algorithm; probabilistic graphical model; probabilistic neural network; prostate cancer; Q learning; recommender system; recurrent neural network; reinforcement learning (machine learning); Review; rheumatoid arthritis; risk assessment; risk factor; semi supervised machine learning; statistical bias; supervised machine learning; taxonomy; topic modelling; treatment response; unsupervised machine learning; urinary tract infection; aged; algorithm; artificial intelligence; machine learning},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 36; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Gupta20235271,
	author = {Gupta, Rajeev and Srinivasa, Srinath},
	title = {Workshop on Enterprise Knowledge Graphs using Large Language Models},
	year = {2023},
	journal = {International Conference on Information and Knowledge Management, Proceedings},
	pages = {5271 – 5272},
	doi = {10.1145/3583780.3615301},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178136348&doi=10.1145%2f3583780.3615301&partnerID=40&md5=91e170f4c1c67028abf9b3e763520795},
	abstract = {Knowledge graphs are used for organizing and connecting individual entities to integrate the information extracted from different data sources. Typically, knowledge graphs are used to connect various real-world entities like persons, places, things, actions, etc. For the knowledge graphs created using the enterprise data, the knowledge graph entities can be of different types-static entities (e.g., people, projects), communication entities (e.g., emails, meetings, documents), derived entities (e.g., rules, definitions, entities from emails), etc. The graphs are used to connect these entities with enriched context (as edges and node attributes) and used for powering various search and recommendations applications. With the advent of large language models, the whole lifecycle of knowledge graphs involving -information extraction, graph construction, application of graphs, querying knowledge graphs, using the graph for recommendations, etc., - is impacted. With large language models such as GPT, LLaMA, PALM, etc., entity and relationship extraction can be improved. Similarly, one can answer different types of queries with the help of LLMs which were very difficult without them. This workshop is about improving the enterprise knowledge graphs and its applications using large language models. Enterprise graphs can be of different scopes-whether they contain data from individual users/customers, a sub-organization, or the whole enterprise. This workshop will also cover various privacy and access control related issues which are typical for any enterprise graph. These include privacy preserving federated learning, using LLMs to extract information from private data, querying the knowledge graph in a privacy preserving manner, etc. © 2023 Copyright is held by the owner/author(s). Publication rights licensed to ACM.},
	author_keywords = {Entity Extraction; Knowledge Graph; Large Language Model; Recommendations; Relationship Extraction},
	keywords = {Access control; Computational linguistics; Data mining; Knowledge graph; Knowledge management; Life cycle; Natural language processing systems; Query processing; Data-source; Enterprise data; Entity extractions; Knowledge graphs; Language model; Large language model; Privacy preserving; Real-world entities; Recommendation; Relationship extraction; Graphic methods},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Xing2023208,
	author = {Xing, Xueyang and Jia, Bo and Huang, Zhicheng and Chen, Yongzhi and Wang, Junjie and Fan, Anfei and Chen, Xin and Cao, Lei},
	title = {A fusion inference method for large language models and knowledge graphs based on structured injection and causal inference},
	year = {2023},
	journal = {ACM International Conference Proceeding Series},
	pages = {208 – 213},
	doi = {10.1145/3653081.3653117},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192801712&doi=10.1145%2f3653081.3653117&partnerID=40&md5=9a7cf072ffd347015bba9015c16f9772},
	abstract = {In this paper, we propose a large language model and knowledge graph fusion reasoning method based on structured injection and causal reasoning (LKFSC) to address the limitations of existing large language models and knowledge graphs in practical applications. The approach effectively mitigates the problems of long-distance dependency and limited contextual information, and improves the reasoning capability of the large language model. Meanwhile, by fusing the generative ability of the large language model and the inference ability of the knowledge graph, the method realizes intelligent reasoning for complex problems. The main contributions of this paper include proposing a structured injection method that introduces causality for reasoning, and constructing a fusion reasoning framework that effectively mitigates the illusory problem of large language models and provides powerful and intelligent decision support for practical applications.  © 2023 ACM.},
	author_keywords = {causal reasoning; fusion reasoning; intelligent decision support; knowledge graph; large language models; structured injection},
	keywords = {Computational linguistics; Decision support systems; Causal inferences; Causal reasoning; Fusion reasoning; Graph-based; Inference methods; Intelligent decision support; Knowledge graphs; Language model; Large language model; Structured injection; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Yang20232389,
	author = {Yang, Bo and Sun, Xiaohu and Dang, Jiayi and Zhao, Haiyan and Jin, Zhi},
	title = {Named Entity Recognition Method of Large Language Model for Medical Question Answering System; [面向医疗问答系统的大语言模型命名实体识别方法]},
	year = {2023},
	journal = {Journal of Frontiers of Computer Science and Technology},
	volume = {17},
	number = {10},
	pages = {2389 – 2402},
	doi = {10.3778/j.issn.1673-9418.2307061},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185301415&doi=10.3778%2fj.issn.1673-9418.2307061&partnerID=40&md5=2cf8944141e191953c0ab0427a2b19ab},
	abstract = {In medical question answering systems, entity recognition plays a major role. Entity recognition based on deep learning has received more and more attention. However, in the medical question answering system, due to the lack of annotated training data, deep learning methods cannot well identify discontinuous and nested entities in medical text. Therefore, a large language model-based entity recognition application method is proposed, and it is applied to the medical problem system. Firstly, the dataset related to medical question answering is processed into text that can be analyzed and processed by a large language model. Secondly, the output of the large language model is classified, and different classifications are processed accordingly. Then, the input text is used for intent recognition, and finally the results of entity recognition and intent recognition are sent to the medical knowledge graph for query, and the answer to the medical question and answer is obtained. Experiments are performed on 3 typical datasets and compared with several typical correlation methods. The results show that the method proposed in this paper performs better. © 2023 Journal of Computer Engineering and Applications Beijing Co., Ltd.; Science Press. All rights reserved.},
	author_keywords = {answer system; entity recognition; intent recognition; large language models; medical question},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6}
}

@ARTICLE{Zhang20232377,
	author = {Zhang, Heyi and Wang, Xin and Han, Lifan and Li, Zhao and Chen, Zirui and Chen, Zhe},
	title = {Research on Question Answering System on Joint of Knowledge Graph and Large Language Models; [大语言模型融合知识图谱的问答系统研究]},
	year = {2023},
	journal = {Journal of Frontiers of Computer Science and Technology},
	volume = {17},
	number = {10},
	pages = {2377 – 2388},
	doi = {10.3778/j.issn.1673-9418.2308070},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184863982&doi=10.3778%2fj.issn.1673-9418.2308070&partnerID=40&md5=3ab78f20383745ee9f3a4dc2ecc55dbe},
	abstract = {The large language model (LLM), including ChatGPT, has shown outstanding performance in understanding and responding to human instructions, and has a profound impact on natural language question answering (Q&A). However, due to the lack of training in the vertical field, the performance of LLM in the vertical field is not ideal. In addition, due to its high hardware requirements, training and deploying LLM remains difficult. In order to address these challenges, this paper takes the application of traditional Chinese medicine formulas as an example, collects the domain related data and preprocesses the data. Based on LLM and knowledge graph, a vertical domain Q&A system is designed. The system has the following capabilities: (1) Information filtering. Filter out vertical domain related questions and input them into LLM to answer. (2) Professional Q&A. Generate answers with more professional knowledge based on LLM and self-built knowledge base. Compared with the fine-tuning method of introducing professional data, using this technology can deploy large vertical domain models without the need for retraining. (3) Extract conversion. By strengthening the information extraction ability of LLM and utilizing its generated natural language responses, structured knowledge is extracted and matched with a professional knowledge graph for professional verification. At the same time, structured knowledge can be transformed into readable natural language, achieving a deep integration of large models and knowledge graphs. Finally, the effect of the system is demonstrated and the performance of the system is verified from both subjective and objective perspectives through two experiments of subjective evaluation of experts and objective evaluation of multiple choice questions. © 2023 Journal of Computer Engineering and Applications Beijing Co., Ltd.; Science Press. All rights reserved.},
	author_keywords = {knowledge graph; large language model (LLM); Q&A system; traditional Chinese medicine; vertical field},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 16}
}

@ARTICLE{Acharya20241250,
	author = {Acharya, Sathwik and Das, Bhaskarjyoti and Sudarshan, T.S.B.},
	title = {Capturing the Concept Projection in Metaphorical Memes for Downstream Learning Tasks},
	year = {2024},
	journal = {IEEE Access},
	volume = {12},
	pages = {1250 – 1265},
	doi = {10.1109/ACCESS.2023.3347988},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181574267&doi=10.1109%2fACCESS.2023.3347988&partnerID=40&md5=b45965b31ac0cb4aac294b46d445121d},
	abstract = {Metaphorical memes, where a source concept is projected into a target concept, are an essential construct in figurative language. In this article, we present a novel approach for downstream learning tasks on metaphorical multimodal memes. Our proposed framework replaces traditional methods using metaphor annotations with a metaphor-capturing mechanism. Besides using the significant zero-shot learning capability of state-of-the-art pretrained encoders, this work introduces an alternative external knowledge enhancement strategy based on ChatGPT (chatbot generative pretrained transformer), demonstrating its effectiveness in bridging the intermodal semantic gap. We propose a new concept projection process consisting of three distinct components to capture the intramodal knowledge and intermodal concept gap in the forms of text modality embedding, visual modality embedding, and concept projection embedding. This approach leverages the attention mechanism of the Graph Attention Network for fusing the common aspects of external knowledge related to the knowledge in the text and image modality to implement the concept projection process. Our experimental results demonstrate the superiority of our proposed approach compared to existing methods.  © 2023 The Authors.},
	author_keywords = {cognitive computing; concept projection; knowledge graph; large language models; Memes; metaphor; multimodal machine learning},
	keywords = {Cognitive systems; Job analysis; Knowledge graph; Learning systems; Zero-shot learning; Chatbots; Cognitive Computing; Concept projection; Knowledge graphs; Knowledge-based systems; Language model; Large language model; Machine-learning; Meme; Metaphor; Multi-modal; Multimodal machine learning; Task analysis; Semantics},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@ARTICLE{Lo202323740,
	author = {Lo, Pei-Chi and Lim, Ee-Peng},
	title = {A transformer framework for generating context-aware knowledge graph paths},
	year = {2023},
	journal = {Applied Intelligence},
	volume = {53},
	number = {20},
	pages = {23740 – 23767},
	doi = {10.1007/s10489-023-04588-3},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164785206&doi=10.1007%2fs10489-023-04588-3&partnerID=40&md5=533a4e7e702901842a76be981f1cf667},
	abstract = {Contextual Path Generation (CPG) refers to the task of generating knowledge path(s) between a pair of entities mentioned in an input textual context to determine the semantic connection between them. Such knowledge paths, also called contextual paths, can be very useful in many advanced information retrieval applications. Nevertheless, CPG involves several technical challenges, namely, sparse and noisy input context, missing relations in knowledge graphs, and generation of ill-formed and irrelevant knowledge paths. In this paper, we propose a transformer-based model architecture. In this approach, we leverage a mixture of pre-trained word and knowledge graph embeddings to encode the semantics of input context, a transformer decoder to perform path generation controlled by encoded input context and head entity to stay relevant to the context, and scaling methods to sample a well-formed path. We evaluate our proposed CPG models derived using the above architecture on two real datasets, both consisting of Wikinews articles as input context documents and ground truth contextual paths, as well as a large synthetic dataset to conduct larger-scale experiments. Our experiments show that our proposed models outperform the baseline models, and the scaling methods contribute to better quality contextual paths. We further analyze how CPG accuracy can be affected by different amount of context data, and missing relations in the knowledge graph. Finally, we demonstrate that an answer model for knowledge graph questions adapted for CPG could not perform well due to the lack of an effective path generation module. © 2023, The Author(s), under exclusive licence to Springer Science+Business Media, LLC, part of Springer Nature.},
	author_keywords = {Contextual path generation; Information retrieval; Knowledge graph; Language model},
	keywords = {Embeddings; Graph theory; Knowledge graph; Knowledge management; Large dataset; Semantics; Advanced informations; Context-Aware; Contextual path generation; Graph path; Knowledge graphs; Language model; Path-generation; Retrieval applications; Scaling method; Textual contexts; Information retrieval},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{Zhu2024603,
	author = {Zhu, Jun and Dang, Pei and Cao, Yungang and Lai, Jianbo and Guo, Yukun and Wang, Ping and Li, Weilian},
	title = {A flood knowledge-constrained large language model interactable with GIS: enhancing public risk perception of floods},
	year = {2024},
	journal = {International Journal of Geographical Information Science},
	volume = {38},
	number = {4},
	pages = {603 – 625},
	doi = {10.1080/13658816.2024.2306167},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184247139&doi=10.1080%2f13658816.2024.2306167&partnerID=40&md5=145c2100a6b2402796d3d29421bfc922},
	abstract = {Public’s rational flood mitigation behaviors depend on accurate perception of flood risks. The use of natural language for flood risk perception is an effective approach, and it is critical to ensure the accuracy and comprehensibility of the flood information provided by the system in natural language dialogues. This study presents a framework for large language model (LLM) that is constrained by flood knowledge and can interact with geographic information system (GIS), aimed at enhancing the public’s perception of flood risks. We tested the performance of LLM within this framework and the results demonstrate that LLM can generate accurate information about floods under the constraints of entities and relationships in the knowledge graph, and interact with GIS to produce personalized knowledge through real-time coding. Furthermore, we conducted flood risk perception experiments on users with different cognitive levels. The results indicate that using natural language dialogue can narrow the differences brought about by cognitive levels, allowing the public to equally access knowledge related to flood events. © 2024 The Author(s). Published by Informa UK Limited, trading as Taylor & Francis Group.},
	author_keywords = {disaster visualization; flood risk perception; knowledge graph; Large language models},
	keywords = {flood; flood control; GIS; hazard assessment; language; risk perception},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 15; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{2024,
	title = {TEICAI 2024 - 1st Workshop Towards Ethical and Inclusive Conversational AI: Language Attitudes, Linguistic Diversity, and Language Rights, Proceedings of the Workshop},
	year = {2024},
	journal = {TEICAI 2024 - 1st Workshop Towards Ethical and Inclusive Conversational AI: Language Attitudes, Linguistic Diversity, and Language Rights, Proceedings of the Workshop},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188663058&partnerID=40&md5=827ea95eda19ba34c8993f559fe8c7e5},
	abstract = {The proceedings contain 7 papers. The topics discussed include: how do conversational agents in healthcare impact on patient agency?; why academia should cut back general enthusiasm about CAs; bridging the language gap: integrating language variations into conversational ai agents for enhanced user engagement; socio-cultural adapted chatbots: harnessing knowledge graphs and large language models for enhanced context awareness; how should conversational agent systems respond to sexual harassment?; non-referential functions of language in social agents: the case of social proximity; and making a long story short in conversation modeling.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{2023,
	title = {2023 7th International Conference on Electronic Information Technology and Computer Engineering, EITCE 2023},
	year = {2023},
	journal = {ACM International Conference Proceeding Series},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191431920&partnerID=40&md5=845a5347b4c9a10dcf0e1368745a53a0},
	abstract = {The proceedings contain 296 papers. The topics discussed include: a simulation design method of magnetic core for high precision integrated open-loop hall current sensor; radiation tolerant silicon-on-insulator MOSFETs based on special neutron irradiation process; a 6T2C pixel circuit compensating for TFT electrical characteristics variations, voltage drop, and OLED degradation; an a-IGZO TFT pixel circuit to compensate electrical characteristics variation and OLED degradation; knowledge graphs enhanced large language model prompt for electric power question answering; prediction of remaining life of IGBT in electric vehicles based on 1DCNN-ResNet-Fastformer model; instance and foreground aware single-stage outdoor 3D object detector from point clouds; and rolling bearing fault diagnosis method based on SOA-BiLSTM.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Zhang20231349,
	author = {Zhang, Gangyi},
	title = {User-Centric Conversational Recommendation: Adapting the Need of User with Large Language Models},
	year = {2023},
	journal = {Proceedings  of the 17th ACM Conference on Recommender Systems, RecSys 2023},
	pages = {1349 – 1354},
	doi = {10.1145/3604915.3608885},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174537606&doi=10.1145%2f3604915.3608885&partnerID=40&md5=686b2c3e964314d6b0f89f3b28bece13},
	abstract = {Conversational recommender systems (CRS) promise to provide a more natural user experience for exploring and discovering items of interest through ongoing conversation. However, effectively modeling and adapting to users' complex and changing preferences remains challenging. This research develops user-centric methods that focus on understanding and adapting to users throughout conversations to provide the most helpful recommendations. First, a graph-based Conversational Path Reasoning (CPR) framework is proposed that represents dialogs as interactive reasoning over a knowledge graph to capture nuanced user interests and explain recommendations. To further enhance relationship modeling, graph neural networks are incorporated for improved representation learning. Next, to address uncertainty in user needs, the Vague Preference Multi-round Conversational Recommendation (VPMCR) scenario and matching Adaptive Vague Preference Policy Learning (AVPPL) solution are presented using reinforcement learning to tailor recommendations to evolving preferences. Finally, opportunities to leverage large language models are discussed to further advance user experiences via advanced user modeling, policy learning, and response generation. Overall, this research focuses on designing conversational recommender systems that continuously understand and adapt to users' ambiguous, complex and changing needs during natural conversations. © 2023 Owner/Author.},
	author_keywords = {conversational recommendation; large language model; user-centric},
	keywords = {Complex networks; Computational linguistics; Graph neural networks; Graphic methods; Knowledge graph; Learning systems; Modeling languages; Recommender systems; User profile; Conversational recommendations; Conversational recommender systems; Graph-based; Interactive reasoning; Language model; Large language model; Policy learning; Reasoning framework; User-centric; Users' experiences; Reinforcement learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 13}
}

@CONFERENCE{Hang2024,
	author = {Hang, Ching Nam and Yu, Pei-Duo and Tan, Chee Wei},
	title = {TrumorGPT: Query Optimization and Semantic Reasoning over Networks for Automated Fact-Checking},
	year = {2024},
	journal = {2024 58th Annual Conference on Information Sciences and Systems, CISS 2024},
	doi = {10.1109/CISS59072.2024.10480162},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190626782&doi=10.1109%2fCISS59072.2024.10480162&partnerID=40&md5=419e520545338afb41d0df18278d0f15},
	abstract = {In the age of social media, the rapid spread of misinformation and rumors has led to the emergence of infodemics, where false information poses a significant threat to society. To combat this issue, we introduce TrumorGPT, a novel generative artificial intelligence solution designed for automated fact-checking. TrumorGPT aims to distinguish "trumors", which are rumors that turn out to be true, providing a crucial tool in differentiating between mere speculation and verified facts. This framework merges machine learning with natural language processing techniques, leveraging a large language model (LLM) with few-shot learning for knowledge graph construction and semantic reasoning. TrumorGPT addresses the "hallucination"issue common in LLMs and the limitations of static training data by incorporating retrieval-augmented generation. This approach involves accessing and utilizing information from regularly updated knowledge graphs that consist of the latest news and information, ensuring that fact-checking of TrumorGPT is based on the most recent data. Accessing updated knowledge graphs greatly enhances the proficiency of TrumorGPT in delivering accurate and reliable information promptly. Evaluating with extensive datasets, TrumorGPT demonstrates superior performance in automated fact-checking. Its ability to effectively conduct automated fact-checking across various platforms marks a critical step forward in the fight against misinformation, enhancing trust and accuracy in the digital information age. © 2024 IEEE.},
	author_keywords = {Fact-checking; knowledge graph; large language models; retrieval-augmented generation; semantic reasoning},
	keywords = {Automation; Computational linguistics; Knowledge management; Learning systems; Natural language processing systems; Semantics; Fact-checking; Knowledge graphs; Language model; Large language model; Machine-learning; Queries optimization; Query semantics; Retrieval-augmented generation; Semantic reasoning; Social media; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@ARTICLE{Stathopoulos2023,
	author = {Stathopoulos, Evangelos A. and Karageorgiadis, Anastasios I. and Kokkalas, Alexandros and Diplaris, Sotiris and Vrochidis, Stefanos and Kompatsiaris, Ioannis},
	title = {A Query Expansion Benchmark on Social Media Information Retrieval: Which Methodology Performs Best and Aligns with Semantics?},
	year = {2023},
	journal = {Computers},
	volume = {12},
	number = {6},
	doi = {10.3390/computers12060119},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85163671653&doi=10.3390%2fcomputers12060119&partnerID=40&md5=ce6d121edf4dd3fc74666c42c5e06f84},
	abstract = {This paper presents a benchmarking survey on query expansion techniques for social media information retrieval, with a focus on comparing the performance of methods using semantic web technologies. The study evaluated query expansion techniques such as generative AI models and semantic matching algorithms and how they are integrated in a semantic framework. The evaluation was based on cosine similarity metrics, including the Discounted Cumulative Gain (DCG), Ideal Discounted Cumulative Gain (IDCG), and normalized Discounted Cumulative Gain (nDCG), as well as the Mean Average Precision (MAP). Additionally, the paper discusses the use of semantic web technologies as a component in a pipeline for building thematic knowledge graphs from retrieved social media data with extended ontologies integrated for the refugee crisis. The paper begins by introducing the importance of query expansion in information retrieval and the potential benefits of incorporating semantic web technologies. The study then presents the methodologies and outlines the specific procedures for each query expansion technique. The results of the evaluation are presented, as well as the rest semantic framework, and the best-performing technique was identified, which was the curie-001 generative AI model. Finally, the paper summarizes the main findings and suggests future research directions. © 2023 by the authors.},
	author_keywords = {generative AI models; knowledge graph; ontology; query expansion; semantic matching algorithms; semantic web; social media information retrieval},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access}
}

@ARTICLE{Coyle2023207,
	author = {Coyle, Jeff and Jeske, Stephen},
	title = {The rise of AI copilots: How LLMs turn data into actions, advance the business intelligence industry and make data accessible company-wide},
	year = {2023},
	journal = {Applied Marketing Analytics},
	volume = {9},
	number = {3},
	pages = {207 – 214},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180219500&partnerID=40&md5=91c47f4008eace5a3cd83b75bd5cc009},
	abstract = {AI-powered collaboration is quickly advancing due to a convergence of technologies like large language models and language model programming. These developments have spawned the rise of AI (artificial intelligence) copilots, which are changing the way marketing analysts make decisions and boost productivity. This paper explores the capabilities of AI copilots and delves into the challenges, ethical considerations and data privacy issues that come with their adoption. It discusses real-world applications and future trends in the AI copilot landscape. The paper also emphasises the importance of data integration and personalisation in marketing strategies and offers insights into training and skill development for effective collaboration with AI copilots. This comprehensive analysis aims to equip marketing analytics professionals for the future of AI-powered collaboration. © 2023, Henry Stewart Publications. All rights reserved.},
	author_keywords = {AI-powered collaborator; artificial intelligence copilot; knowledge graph; language model query language; large language model},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Oduro-Afriyie2023,
	author = {Oduro-Afriyie, Joel and Jamil, Hasan M},
	title = {Enabling the Informed Patient Paradigm with Secure and Personalized Medical Question Answering},
	year = {2023},
	journal = {ACM-BCB 2023 - 14th ACM Conference on Bioinformatics, Computational Biology, and Health Informatics},
	doi = {10.1145/3584371.3613016},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175859728&doi=10.1145%2f3584371.3613016&partnerID=40&md5=ee953356ef7f31dbf974e9c67dcfe914},
	abstract = {Quality patient care is a complex and multifaceted problem requiring the integration of data from multiple sources. We propose Medicient, a knowledge-graph-based question answering system that processes heterogeneous data sources, including patient health records, drug databases, and medical literature, into a unified knowledge graph with zero training. The knowledge graph is then utilized to provide personalized recommendations for treatment or medication. The system leverages the power of large language models for question understanding and natural language response generation, while hiding sensitive patient information. We compare our system to a large language model (ChatGPT), which does not have access to patient health records, and show that our system provides better recommendations. This study contributes to a growing body of research on knowledge graphs and their applications in healthcare. © 2023 ACM.},
	author_keywords = {data integration; informed patients; knowledge graphs; large language models; personal health library; semantic graph search},
	keywords = {Computational linguistics; Graphic methods; Knowledge graph; Medical informatics; Natural language processing systems; Semantics; Graph search; Informed patient; Knowledge graphs; Language model; Large language model; Patient health; Personal health; Personal health library; Semantic graph search; Semantic graphs; Data integration},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Bronze Open Access}
}

@ARTICLE{Yang2023,
	author = {Yang, Yangrui and Chen, Sisi and Zhu, Yaping and Zhu, Hao and Chen, Zhigang},
	title = {Knowledge graph empowerment from knowledge learning to graduation requirements achievement},
	year = {2023},
	journal = {PLoS ONE},
	volume = {18},
	number = {10 October},
	doi = {10.1371/journal.pone.0292903},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174193764&doi=10.1371%2fjournal.pone.0292903&partnerID=40&md5=cbea04b92e772ebac92331027aae95ed},
	abstract = {A deep understanding of the relationship between the knowledge acquired and the graduation requirements is essential for students to precisely meet the graduation requirements and to become human resources with specific knowledge, skills and professionalism. In this paper, we define the ontology layer of the knowledge graph by deeply analyzing the relationship between graduation requirement, course and knowledge. Based on the implementation of the concept of Outcome Based Education, we use Knowledge extraction, fusion, reasoning techniques to construct a hierarchical knowledge graph with the main line of "knowledge- course-graduation requirements. In the process of knowledge extraction, in order to alleviate the huge labor overhead brought by traditional extraction methods, this paper adopts a transfer learning method to extract triadic knowledge using the multi-task framework EERJE, Finally, knowledge reasoning was also performed with the help of LLM to further expand the knowledge scope. The comprehensiveness, correctness and relatedness of the data were evaluated through the experiment, and the F1 value of the ternary group extraction was 87.76%, the accuracy rate of entity classification was 85.42%, the data coverage was more comprehensive, and the results showed that the data quality was better, and the knowledge graph constructed in this way can fully optimize the organization and management of teaching resources, help students intuitively and comprehensively grasp the correlation and difference between graduation requirements and various knowledge points, and let the Students can carry out personalized independent learning through the navigation mode of knowledge graph, strengthen their weak links, and complete the relevant graduation requirements, which effectively improves the degree of students' graduation requirements achievement. This new paradigm of knowledge graph enabled teaching is of reference significance for engineering education majors to improve the degree of graduation requirements achievement.  © 2023 Yang et al. This is an open access article distributed under the terms of the Creative Commons Attribution License, which permits unrestricted use, distribution, and reproduction in any medium, provided the original author and source are credited.},
	keywords = {Achievement; Educational Status; Humans; Learning; Pattern Recognition, Automated; Students; achievement; article; data quality; education; empowerment; extraction; human; human experiment; learning; ontology; reasoning; teaching; transfer of learning; achievement; automated pattern recognition; educational status; student},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Zhu2023723,
	author = {Zhu, Guibin and Zhao, Bo and Tang, Jianbo},
	title = {Research on the Application of AI in Personalized Education},
	year = {2023},
	journal = {ACM International Conference Proceeding Series},
	pages = {723 – 727},
	doi = {10.1145/3660043.3660172},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85195425608&doi=10.1145%2f3660043.3660172&partnerID=40&md5=3638b2687ea96b55aa9bc03201e33893},
	abstract = {Smart education uses advanced information technology, combined with educational theories and teaching methods, to achieve automatic, intelligent, and efficient teaching process. Personalized education represents the core content and goal of smart education because traditional classroom or remote teaching can't accurately grasp every student's individual knowledge and understanding of the content being taught. The development of artificial intelligence technology has provided technical support for smart education, particularly for personalized education. Natural language processing models such as chatGPT and knowledge graph technology have made personalized education increasingly practicable. This article describes the technological framework of smart education, its potential applications, and emphasizes the use of AI technology in personalized education. The article covers topic areas, including learning situation analysis, implementing personalized instruction, personalized teaching management. © 2023 ACM.},
	author_keywords = {artificial intelligence; knowledge graph; large language model; personalized education; smart education},
	keywords = {Education computing; Engineering education; Natural language processing systems; Students; Advanced informations; Applications of AI; Educational theory; Knowledge graphs; Language model; Large language model; Personalized education; Smart education; Teaching methods; Teaching process; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Saier2024254,
	author = {Saier, Tarek and Ohta, Mayumi and Asakura, Takuto and Färber, Michael},
	title = {HyperPIE: Hyperparameter Information Extraction from Scientific Publications},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14609 LNCS},
	pages = {254 – 269},
	doi = {10.1007/978-3-031-56060-6_17},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189309614&doi=10.1007%2f978-3-031-56060-6_17&partnerID=40&md5=01a1dac294668850f72f05c9dda3027f},
	abstract = {Automatic extraction of information from publications is key to making scientific knowledge machine-readable at a large scale. The extracted information can, for example, facilitate academic search, decision making, and knowledge graph construction. An important type of information not covered by existing approaches is hyperparameters. In this paper, we formalize and tackle hyperparameter information extraction (HyperPIE) as an entity recognition and relation extraction task. We create a labeled data set covering publications from a variety of computer science disciplines. Using this data set, we train and evaluate BERT-based fine-tuned models as well as five large language models: GPT-3.5, GALACTICA, Falcon, Vicuna, and WizardLM. For fine-tuned models, we develop a relation extraction approach that achieves an improvement of 29% F1 over a state-of-the-art baseline. For large language models, we develop an approach leveraging YAML output for structured data extraction, which achieves an average improvement of 5.5% F1 in entity recognition over using JSON. With our best performing model we extract hyperparameter information from a large number of unannotated papers, and analyze patterns across disciplines. All our data and source code is publicly available at https://github.com/IllDepence/hyperpie. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {Hyperparameter; Information Extraction; Scientific Text},
	keywords = {Computational linguistics; Data mining; Information retrieval; Knowledge graph; Publishing; Automatic extraction; Data set; Entity recognition; Extraction of information; Hyper-parameter; Information extraction; Language model; Relation extraction; Scientific publications; Scientific texts; Decision making},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@CONFERENCE{Bednar202315,
	author = {Bednar, Peter and Sarnovsky, Martin and Vanko, Jakub Ivan},
	title = {Cognitive Architecture for Process industries},
	year = {2023},
	journal = {ACM International Conference Proceeding Series},
	pages = {15 – 20},
	doi = {10.1145/3624486.3624489},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175423044&doi=10.1145%2f3624486.3624489&partnerID=40&md5=2bcd6de77d823a1918a7c92cb659fa87},
	abstract = {This paper introduces a Cross-Sectorial Big Data Processing platform which provides tools for the semantic modelling of the data analytical processes and for the automatic generation of data analysis scripts for solving the described problems. The main contribution of this paper is the cognitive component for the automatic extraction of the task definition from the narrative description of the problem based on the Large Language Models (LLMs). We have evaluated the proposed method on five problems from the different domains and found that the automatic extraction of the task definition can have promising results that can be applied to full-automatic data analytics.  © 2023 ACM.},
	author_keywords = {Data analytics; Large language models; Ontologies},
	keywords = {Computational linguistics; Data handling; Extraction; Semantics; Analytical process; Automatic extraction; Cognitive architectures; Data analytics; Language model; Large language model; Ontology's; Process industries; Processing platform; Semantic modelling; Data Analytics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Li2024458,
	author = {Li, Dawei and Tan, Zhen and Chen, Tianlong and Liu, Huan},
	title = {Contextualization Distillation from Large Language Model for Knowledge Graph Completion},
	year = {2024},
	journal = {EACL 2024 - 18th Conference of the European Chapter of the Association for Computational Linguistics, Findings of EACL 2024},
	pages = {458 – 477},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188752582&partnerID=40&md5=023389f51e5ff1e314b7b976c36805c8},
	abstract = {While textual information significantly enhances the performance of pre-trained language models (PLMs) in knowledge graph completion (KGC), the static and noisy nature of existing corpora collected from Wikipedia articles or synsets definitions often limits the potential of PLM-based KGC models. To surmount these challenges, we introduce the Contextualization Distillation strategy, a versatile plug-in-and-play approach compatible with both discriminative and generative KGC frameworks. Our method begins by instructing large language models (LLMs) to transform compact, structural triplets into context-rich segments. Subsequently, we introduce two tailored auxiliary tasks—reconstruction and contextualization—allowing smaller KGC models to assimilate insights from these enriched triplets. Comprehensive evaluations across diverse datasets and KGC techniques highlight the efficacy and adaptability of our approach, revealing consistent performance enhancements irrespective of underlying pipelines or architectures. Moreover, our analysis makes our method more explainable and provides insight into generating path selection, as well as the choosing of suitable distillation tasks. All the code and data in this work will be released at https://github.com/DavidLi0406/Contextulization-Distillation. © 2024 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Distillation; Comprehensive evaluation; Contextualization; Knowledge graphs; Language model; Model-based OPC; Performance; Plug-ins; Synsets; Textual information; Wikipedia articles; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Rula20239,
	author = {Rula, Anisa and D'Souza, Jennifer},
	title = {Procedural Text Mining with Large Language Models},
	year = {2023},
	journal = {K-CAP 2023 - Proceedings of the 12th Knowledge Capture Conference 2023},
	pages = {9 – 16},
	doi = {10.1145/3587259.3627572},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180376354&doi=10.1145%2f3587259.3627572&partnerID=40&md5=3e537932d23016b89812744882950820},
	abstract = {Recent advancements in the field of Natural Language Processing, particularly the development of large-scale language models that are pretrained on vast amounts of knowledge, are creating novel opportunities within the realm of Knowledge Engineering. In this paper, we investigate the usage of large language models (LLMs) in both zero-shot and in-context learning settings to tackle the problem of extracting procedures from unstructured PDF text in an incremental question-answering fashion. In particular, we leverage the current state-of-the-art GPT-4 (Generative Pre-trained Transformer 4) model, accompanied by two variations of in-context learning that involve an ontology with definitions of procedures and steps and a limited number of samples of few-shot learning. The findings highlight both the promise of this approach and the value of the in-context learning customisations. These modifications have the potential to significantly address the challenge of obtaining sufficient training data, a hurdle often encountered in deep learning-based Natural Language Processing techniques for procedure extraction. © 2023 Owner/Author.},
	author_keywords = {knowledge capture; knowledge representation},
	keywords = {Computational linguistics; Deep learning; Learning systems; Natural language processing systems; Zero-shot learning; Context learning; In contexts; Knowledge capture; Knowledge-representation; Language model; Language processing; Large-scales; Learning settings; Natural languages; Text-mining; Knowledge representation},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Hertling2023131,
	author = {Hertling, Sven and Paulheim, Heiko},
	title = {OLaLa: Ontology Matching with Large Language Models},
	year = {2023},
	journal = {K-CAP 2023 - Proceedings of the 12th Knowledge Capture Conference 2023},
	pages = {131 – 139},
	doi = {10.1145/3587259.3627571},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180367190&doi=10.1145%2f3587259.3627571&partnerID=40&md5=7b017e0ca919f17ccea79a17288582bb},
	abstract = {Ontology (and more generally: Knowledge Graph) Matching is a challenging task where information in natural language is one of the most important signals to process. With the rise of Large Language Models, it is possible to incorporate this knowledge in a better way into the matching pipeline. A number of decisions still need to be taken, e.g., how to generate a prompt that is useful to the model, how information in the KG can be formulated in prompts, which Large Language Model to choose, how to provide existing correspondences to the model, how to generate candidates, etc. In this paper, we present a prototype that explores these questions by applying zero-shot and few-shot prompting with multiple open Large Language Models to different tasks of the Ontology Alignment Evaluation Initiative (OAEI). We show that with only a handful of examples and a well-designed prompt, it is possible to achieve results that are en par with supervised matching systems which use a much larger portion of the ground truth. © 2023 Owner/Author.},
	author_keywords = {Entity Resolution; Large Language Model; Ontology Matching},
	keywords = {Computational linguistics; Knowledge graph; Zero-shot learning; Entity resolutions; Graph matchings; Knowledge graphs; Language model; Large language model; Matchings; Natural languages; Ontology alignment; Ontology matching; Ontology's; Ontology},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 23; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Xu2023,
	author = {Xu, Justin and Mazwi, Mjaye and Johnson, Alistair E.W.},
	title = {AnnoDash, a clinical terminology annotation dashboard},
	year = {2023},
	journal = {JAMIA Open},
	volume = {6},
	number = {3},
	doi = {10.1093/jamiaopen/ooad046},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166011912&doi=10.1093%2fjamiaopen%2fooad046&partnerID=40&md5=a5ed5a6321c19aacc31c05eb38c8cb6d},
	abstract = {Background: Standard ontologies are critical for interoperability and multisite analyses of health data. Nevertheless, mapping concepts to ontologies is often done with generic tools and is labor-intensive. Contextualizing candidate concepts within source data is also done in an ad hoc manner. Methods and Results: We present AnnoDash, a flexible dashboard to support annotation of concepts with terms from a given ontology. Text-based similarity is used to identify likely matches, and large language models are used to improve ontology ranking. A convenient interface is provided to visualize observations associated with a concept, supporting the disambiguation of vague concept descriptions. Time-series plots contrast the concept with known clinical measurements. We evaluated the dashboard qualitatively against several ontologies (SNOMED CT, LOINC, etc.) by using MIMIC-IV measurements. The dashboard is web-based and step-by-step instructions for deployment are provided, simplifying usage for nontechnical audiences. The modular code structure enables users to extend upon components, including improving similarity scoring, constructing new plots, or configuring new ontologies. Conclusion: AnnoDash, an improved clinical terminology annotation tool, can facilitate data harmonizing by promoting mapping of clinical data. AnnoDash is freely available at https://github.com/justin13601/AnnoDash (https://doi.org/10.5281/zenodo.8043943).  © 2023 The Author(s). Published by Oxford University Press on behalf of the American Medical Informatics Association.},
	author_keywords = {annotation; clinical concepts; natural language processing; ontology; software},
	keywords = {article; human; human experiment; Logical Observation Identifiers Names and Codes; natural language processing; nomenclature; ontology; software; Systematized Nomenclature of Medicine; time series analysis},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Dong20235316,
	author = {Dong, Hang and Chen, Jiaoyan and He, Yuan and Horrocks, Ian},
	title = {Ontology Enrichment from Texts: A Biomedical Dataset for Concept Discovery and Placement},
	year = {2023},
	journal = {International Conference on Information and Knowledge Management, Proceedings},
	pages = {5316 – 5320},
	doi = {10.1145/3583780.3615126},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174561342&doi=10.1145%2f3583780.3615126&partnerID=40&md5=3809212c828a8a15dd2d41fc727de296},
	abstract = {Mentions of new concepts appear regularly in texts and require automated approaches to harvest and place them into Knowledge Bases (KB), e.g., ontologies and taxonomies. Existing datasets suffer from three issues, (i) mostly assuming that a new concept is pre-discovered and cannot support out-of-KB mention discovery; (ii) only using the concept label as the input along with the KB and thus lacking the contexts of a concept label; and (iii) mostly focusing on concept placement w.r.t a taxonomy of atomic concepts, instead of complex concepts, i.e., with logical operators. To address these issues, we propose a new benchmark, adapting MedMentions dataset (PubMed abstracts) with SNOMED CT versions in 2014 and 2017 under the Diseases subcategory and the broader categories of Clinical finding, Procedure, and Pharmaceutical/biologic product. We provide usage on the evaluation with the dataset for out-of-KB mention discovery and concept placement, adapting recent Large Language Model based methods. © 2023 Copyright held by the owner/author(s).},
	author_keywords = {Biomedical Ontologies; Concept Placement; Entity Linking; Language Models; Ontology Enrichment; SNOMED CT; Text Mining},
	keywords = {Computational linguistics; Large dataset; Natural language processing systems; Ontology; Automated approach; Biomedical ontologies; Concept discoveries; Concept placement; Entity linking; Knowledge taxonomies; Language model; Ontology enrichment; SNOMED-CT; Text-mining; Taxonomies},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Atif2023781,
	author = {Atif, Farah and El Khatib, Ola and Difallah, Djellel},
	title = {BeamQA: Multi-hop Knowledge Graph Question Answering with Sequence-to-Sequence Prediction and Beam Search},
	year = {2023},
	journal = {SIGIR 2023 - Proceedings of the 46th International ACM SIGIR Conference on Research and Development in Information Retrieval},
	pages = {781 – 790},
	doi = {10.1145/3539618.3591698},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168675722&doi=10.1145%2f3539618.3591698&partnerID=40&md5=f77b7db65791b8aab4ee054ed768af3e},
	abstract = {Knowledge Graph Question Answering (KGQA) is a task that aims to answer natural language queries by extracting facts from a knowledge graph. Current state-of-the-art techniques for KGQA rely on text-based information from graph entity and relations labels, as well as external textual corpora. By reasoning over multiple edges in the graph, these can accurately rank and return the most relevant entities. However, one of the limitations of these methods is that they cannot handle the inherent incompleteness of real-world knowledge graphs and may lead to inaccurate answers due to missing edges. To address this issue, recent advances in graph representation learning have led to the development of systems that can use link prediction techniques to handle missing edges probabilistically, allowing the system to reason with incomplete information. However, existing KGQA frameworks that use such techniques often depend on learning a transformation from the query representation to the graph embedding space, which requires access to a large training dataset. We present BeamQA, an approach that overcomes these limitations by combining a sequence-to-sequence prediction model with beam search execution in the embedding space. Our model uses a pretrained large language model and synthetic question generation. Our experiments demonstrate the effectiveness of BeamQA when compared to other KGQA methods on two knowledge graph question-answering datasets. © 2023 Copyright held by the owner/author(s). Publication rights licensed to ACM.},
	author_keywords = {Knowledge Graphs; Question Answering},
	keywords = {Computational linguistics; Forecasting; Graph embeddings; Large dataset; Natural language processing systems; Query processing; 'current; Beam search; Knowledge graphs; Multi-hops; Natural language queries; Question Answering; Real-world; Sequence prediction; State-of-the-art techniques; Text-based information; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 12}
}

@ARTICLE{Zhao2023126,
	author = {Zhao, Chunjiang},
	title = {Agricultural Knowledge Intelligent Service Technology: A Review; [农业知识智能服务技术综述]},
	year = {2023},
	journal = {Smart Agriculture},
	volume = {5},
	number = {2},
	pages = {126 – 148},
	doi = {10.12133/j.smartag.SA202306002},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169928066&doi=10.12133%2fj.smartag.SA202306002&partnerID=40&md5=e8a2233c72c898f33288ec29a98afbfe},
	abstract = {[Significance] Agricultural environment is dynamic and variable, with numerous factors affecting the growth of animals and plants and complex interactions. There are numerous factors that affect the growth of all kinds of animals and plants. There is a close but complex correlation between these factors such as air temperature, air humidity, illumination, soil temperature, soil humidity, diseases, pests, weeds and etc. Thus, farmers need agricultural knowledge to solve production problems. With the rapid development of internet technology, a vast amount of agricultural information and knowledge is available on the internet. However, due to the lack of effective organization, the utilization rate of these agricultural information knowledge is relatively low.How to analyze and generate production knowledge or decision cases from scattered and disordered information is a big challenge all over the world. Agricultural knowledge intelligent service technology is a good way to resolve the agricultural data problems such as low rank, low correlation, and poor interpretability of reasoning. It is also the key technology to improving the comprehensive prediction and decision-making analysis capabilities of the entire agricultural production process. It can eliminate the information barriers between agricultural knowledge, farmers, and consumers, and is more conducive to improve the production and quality of agricultural products, provide effective information services. [Progress] The definition, scope, and technical application of agricultural knowledge intelligence services are introduced in this paper. The demand for agricultural knowledge services are analyzed combining with artificial intelligence technology. Agricultural knowledge intelligent service technologies such as perceptual recognition, knowledge coupling, and inference decision-making are conducted. The characteristics of agricultural knowledge services are analyzed and summarized from multiple perspectives such as industrial demand, industrial upgrading, and technological development. The development history of agricultural knowledge services is introduced. Current problems and future trends are also discussed in the agricultural knowledge services field. Key issues in agricultural knowledge intelligence services such as animal and plant state recognition in complex and uncertain environments, multimodal data association knowledge extraction, and collaborative reasoning in multiple agricultural application scenarios have been discussed. Combining practical experience and theoretical research, a set of intelligent agricultural situation analysis service framework that covers the entire life cycle of agricultural animals and plants and combines knowledge cases is proposed. An agricultural situation perception framework has been built based on satellite air ground multi-channel perception platform and Internet real-time data. Multimodal knowledge coupling, multimodal knowledge graph construction and natural language processing technology have been used to converge and manage agricultural big data. Through knowledge reasoning decision-making, agricultural information mining and early warning have been carried out to provide users with multi-scenario agricultural knowledge services. Intelligent agricultural knowledge services have been designed such as multimodal fusion feature extraction, cross domain knowledge unified representation and graph construction, and complex and uncertain agricultural reasoning and decision-making. An agricultural knowledge intelligent service platform composed of cloud computing support environment, big data processing framework, knowledge organization management tools, and knowledge service application scenarios has been built. Rapid assembly and configuration management of agricultural knowledge services could be provide by the platform. The application threshold of artificial intelligence technology in agricultural knowledge services could be reduced. In this case, problems of agricultural users can be solved. A novel method for agricultural situation analysis and production decision-making is proposed. A full chain of intelligent knowledge application scenario is constructed. The scenarios include planning, management, harvest and operations during the agricultural before, during and after the whole process. [Conclusions and Prospects] The technology trend of agricultural knowledge intelligent service is summarized in five aspects. (1) Multi-scale sparse feature discovery and spatiotemporal situation recognition of agricultural conditions. The application effects of small sample migration discovery and target tracking in uncertain agricultural information acquisition and situation recognition are discussed. (2) The construction and self-evolution of agricultural cross media knowledge graph, which uses robust knowledge base and knowledge graph to analyze and gather high-level semantic information of cross media content. (3) In response to the difficulties in tracing the origin of complex agricultural conditions and the low accuracy of comprehensive prediction, multi granularity correlation and multi-mode collaborative inversion prediction of complex agricultural conditions is discussed. (4) The large language model (LLM) in the agricultural field based on generative artificial intelligence. ChatGPT and other LLMs can accurately mine agricultural data and automatically generate questions through large-scale computing power, solving the problems of user intention understanding and precise service under conditions of dispersed agricultural data, multi-source heterogeneity, high noise, low information density, and strong uncertainty. In addition, the agricultural LLM can also significantly improve the accuracy of intelligent algorithms such as identification, prediction and decision-making by combining strong algorithms with Big data and super computing power. These could bring important opportunities for large-scale intelligent agricultural production. (5) The construction of knowledge intelligence service platforms and new paradigm of knowledge service, integrating and innovating a self-evolving agricultural knowledge intelligence service cloud platform. Agricultural knowledge intelligent service technology will enhance the control ability of the whole agricultural production chain. It plays a technical support role in achieving the transformation of agricultural production from "observing the sky and working" to "knowing the sky and working". The intelligent agricultural application model of "knowledge empowerment" provides strong support for improving the quality and efficiency of the agricultural industry, as well as for the modernization transformation and upgrading. © 2023 Chinese Journal of Clinical Research. All rights reserved.},
	author_keywords = {agricultural knowledge intelligent services; early warning of agricultural condition; knowledge coupling; multimodal knowledge graph; reasoning decisions},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 14}
}

@CONFERENCE{de Sá202421,
	author = {de Sá, Jader Martins Camboim and Anastasiou, Dimitra and Da Silveira, Marcos and Pruski, Cédric},
	title = {Socio-cultural adapted chatbots: Harnessing Knowledge Graphs and Large Language Models for enhanced context awareness},
	year = {2024},
	journal = {TEICAI 2024 - 1st Workshop Towards Ethical and Inclusive Conversational AI: Language Attitudes, Linguistic Diversity, and Language Rights, Proceedings of the Workshop},
	pages = {21 – 27},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188678057&partnerID=40&md5=5a63fdf37d57c4471f2f36c01521154c},
	abstract = {Understanding the socio-cultural context is crucial in machine translation (MT). Although conversational AI systems and chatbots, in particular, are not designed for translation, they can be used for MT purposes. Yet, chatbots often struggle to identify any socio-cultural context during user interactions. In this paper, we highlight this challenge with real-world examples from popular chatbots. We advocate for the use of knowledge graphs as an external source of information that can potentially encapsulate socio-cultural contexts, aiding chatbots in enhancing translation. We further present a method to exploit external knowledge and extract contextual information that can significantly improve text translation, as evidenced by our interactions with these chatbots. © 2024 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Computer aided language translation; Machine translation; AI systems; Chatbots; Context- awareness; Knowledge graphs; Language model; Machine translations; Real-world; Socio-cultural; Sociocultural context; User interaction; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Reboud20233951,
	author = {Reboud, Alison and Harrando, Ismail and Lisena, Pasquale and Troncy, Raphaël},
	title = {Stories of love and violence: zero-shot interesting events’ classification for unsupervised TV series summarization},
	year = {2023},
	journal = {Multimedia Systems},
	volume = {29},
	number = {6},
	pages = {3951 – 3969},
	doi = {10.1007/s00530-022-01040-3},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85145987077&doi=10.1007%2fs00530-022-01040-3&partnerID=40&md5=c4ef1f916ab353c412126f6cf56350a9},
	abstract = {In this paper, we propose an unsupervised approach to generate TV series summaries using screenplays that are composed of dialogue and scenic textual descriptions. In the last years, the creation of large language models has enabled zero-shot text classification to perform effectively in some conditions. We explore if and how such models can be used for TV series summarization by conducting experiments with varying text inputs. Our main hypothesis being that interesting moments in narratives are related to the presence of interesting events, we choose candidate labels to be events representative of two genres (crime and soap opera) and we obtain competitive results with respect to the state-of-the art baseline. © 2023, The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, part of Springer Nature.},
	author_keywords = {Face recognition; Knowledge graphs; Moment detection; Summarization; Zero-shot classification},
	keywords = {Classification (of information); Knowledge graph; Text processing; Zero-shot learning; Events classification; Knowledge graphs; Language model; Moment detection; Shot classification; Summarization; Text classification; Textual description; Unsupervised approaches; Zero-shot classification; Face recognition},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{He2023414,
	author = {He, Meng and Bai, Yunli},
	title = {LAL-JER: Label-Aware Learning for Adaptive Joint Entity and Relation Extraction with LLM data augmentation},
	year = {2023},
	journal = {ACM International Conference Proceeding Series},
	pages = {414 – 419},
	doi = {10.1145/3640912.3640993},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186957359&doi=10.1145%2f3640912.3640993&partnerID=40&md5=1cb3b848e14b5b8c1cc8e403db8c3ee8},
	abstract = {Joint entity and relation extraction has achieved great improvements in Natural Language Processing (NLP) and has been widely applied, such as constructing knowledge graph, query understanding and question answering. Existing methods usually spend long time on fitting the models on certain datasets with given label type, which greatly lacks the ability of generalization. The model cannot make prediction on label types that have not seen in the training set. To address this issue, we propose to use prompt to incorporate the semantic meaning of the label type description. Furthermore, we use large language model to perform data augmentation to improve the robustness of our model during training. Extensive experiments and ablation study on two joint entity and relation extraction validates the effectiveness of our work on that: 1. Our methods achieved states of art performance on joint entity and relation extraction benchmark based on pretrained language model bert. 2. Our methods can help the model make predictions on label type unseen before given prompts.  © 2023 ACM.},
	author_keywords = {Bert; data augmentation; Joint entity and relation extraction; large language model},
	keywords = {Benchmarking; Computational linguistics; Data mining; Extraction; Knowledge graph; Natural language processing systems; Query processing; Bert; Data augmentation; Entity extractions; Joint entity and relation extraction; Knowledge graphs; Language model; Language processing; Large language model; Natural languages; Relation extraction; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Fang2023184,
	author = {Fang, Yunfei and Chen, Yong and Jiang, Zhonglin and Xiao, Jun and Ge, Yanli},
	title = {Automatic Knowledge Structuration of Automotive User Manual for Question Answering},
	year = {2023},
	journal = {Proceedings - 2023 4th International Conference on Computer, Big Data and Artificial Intelligence, ICCBD+AI 2023},
	pages = {184 – 190},
	doi = {10.1109/ICCBD-AI62252.2023.00038},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85197173150&doi=10.1109%2fICCBD-AI62252.2023.00038&partnerID=40&md5=b10acca8834b2b0e17c49755b4b98cd5},
	abstract = {Automotive user manuals serve as repositories of valuable information pertaining to a vehicle, leveraging question answering (QA) systems provides users with a convenient means to access this knowledge. In pursuit of developing an efficient QA system for such documents, this paper proposes the organization of the content into a structured knowledge graph-like triplet format.After conducting a comprehensive analysis of the automotive user manual content, we introduce a <subject, function, content> (<s, f, c>) triplet knowledge representation to represent the knowledge. Our approach involves a three-step pipeline for extracting these triplets from semi-structured XML documents. Central to this structure is the "content"node, forming the core of knowledge items. Leveraging the in-context learning abilities of an off-the-shelf Large Language Model (LLM), specifically ChatGPT, the "subject"and "function"components are induced from the "content"node. To ensure compactness and coherence in knowledge representation, a tailored phrase normalization process is designed to select identical phrases.Additionally, a LLM-powered evaluation method is employed to validate the extracted triplets, affirming their accuracy and relevance. This methodology demonstrates the effectiveness of our proposed approach in automating the structuration of knowledge within automotive user manuals for seamless QA.  © 2023 IEEE.},
	author_keywords = {information extraction; knowledge graph construction; large language models; question answering},
	keywords = {Computational linguistics; Data mining; Knowledge management; Structure (composition); Automotives; Graph construction; Information extraction; Knowledge graph construction; Knowledge graphs; Language model; Large language model; Question Answering; Structuration; User manual; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Lotz2023,
	author = {Lotz, Jeffrey C. and Ropella, Glen and Anderson, Paul and Yang, Qian and Hedderich, Michael A. and Bailey, Jeannie and Hunt, C. Anthony},
	title = {An exploration of knowledge-organizing technologies to advance transdisciplinary back pain research},
	year = {2023},
	journal = {JOR Spine},
	volume = {6},
	number = {4},
	doi = {10.1002/jsp2.1300},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177452510&doi=10.1002%2fjsp2.1300&partnerID=40&md5=219c719cd9bca8a03d4d3beadb4f7cf7},
	abstract = {Chronic low back pain (LBP) is influenced by a broad spectrum of patient-specific factors as codified in domains of the biopsychosocial model (BSM). Operationalizing the BSM into research and clinical care is challenging because most investigators work in silos that concentrate on only one or two BSM domains. Furthermore, the expanding, multidisciplinary nature of BSM research creates practical limitations as to how individual investigators integrate current data into their processes of generating impactful hypotheses. The rapidly advancing field of artificial intelligence (AI) is providing new tools for organizing knowledge, but the practical aspects for how AI may advance LBP research and clinical are beginning to be explored. The goals of the work presented here are to: (1) explore the current capabilities of knowledge integration technologies (large language models (LLM), similarity graphs (SGs), and knowledge graphs (KGs)) to synthesize biomedical literature and depict multimodal relationships reflected in the BSM, and; (2) highlight limitations, implementation details, and future areas of research to improve performance. We demonstrate preliminary evidence that LLMs, like GPT-3, may be useful in helping scientists analyze and distinguish cLBP publications across multiple BSM domains and determine the degree to which the literature supports or contradicts emergent hypotheses. We show that SG representations and KGs enable exploring LBP's literature in novel ways, possibly providing, trans-disciplinary perspectives or insights that are currently difficult, if not infeasible to achieve. The SG approach is automated, simple, and inexpensive to execute, and thereby may be useful for early-phase literature and narrative explorations beyond one's areas of expertise. Likewise, we show that KGs can be constructed using automated pipelines, queried to provide semantic information, and analyzed to explore trans-domain linkages. The examples presented support the feasibility for LBP-tailored AI protocols to organize knowledge and support developing and refining trans-domain hypotheses. © 2023 The Authors. JOR Spine published by Wiley Periodicals LLC on behalf of Orthopaedic Research Society.},
	author_keywords = {artificial intelligence; biopsychosocial model; chronic low back pain; knowledge graphs},
	keywords = {Article; artificial intelligence; biopsychosocial model; chronic pain; data classification; human; hypothesis; information processing; interdisciplinary research; knowledge; knowledge graph; large language model; low back pain; medical literature; musculoskeletal system; ontology; preliminary data; scientist; similarity graph},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Li2024,
	author = {Li, Xiu and Henriksson, Aron and Duneld, Martin and Nouri, Jalal and Wu, Yongchao},
	title = {Evaluating Embeddings from Pre-Trained Language Models and Knowledge Graphs for Educational Content Recommendation},
	year = {2024},
	journal = {Future Internet},
	volume = {16},
	number = {1},
	doi = {10.3390/fi16010012},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183383290&doi=10.3390%2ffi16010012&partnerID=40&md5=231bde85581487531725e5cab3b471df},
	abstract = {Educational content recommendation is a cornerstone of AI-enhanced learning. In particular, to facilitate navigating the diverse learning resources available on learning platforms, methods are needed for automatically linking learning materials, e.g., in order to recommend textbook content based on exercises. Such methods are typically based on semantic textual similarity (STS) and the use of embeddings for text representation. However, it remains unclear what types of embeddings should be used for this task. In this study, we carry out an extensive empirical evaluation of embeddings derived from three different types of models: (i) static embeddings trained using a concept-based knowledge graph, (ii) contextual embeddings from a pre-trained language model, and (iii) contextual embeddings from a large language model (LLM). In addition to evaluating the models individually, various ensembles are explored based on different strategies for combining two models in an early vs. late fusion fashion. The evaluation is carried out using digital textbooks in Swedish for three different subjects and two types of exercises. The results show that using contextual embeddings from an LLM leads to superior performance compared to the other models, and that there is no significant improvement when combining these with static embeddings trained using a knowledge graph. When using embeddings derived from a smaller language model, however, it helps to combine them with knowledge graph embeddings. The performance of the best-performing model is high for both types of exercises, resulting in a mean Recall@3 of 0.96 and 0.95 and a mean MRR of 0.87 and 0.86 for quizzes and study questions, respectively, demonstrating the feasibility of using STS based on text embeddings for educational content recommendation. The ability to link digital learning materials in an unsupervised manner—relying only on readily available pre-trained models—facilitates the development of AI-enhanced learning. © 2023 by the authors.},
	author_keywords = {AI-enhanced learning; educational content recommendation; ensemble embeddings; knowledge graph embeddings; natural language processing; pre-trained language models; text similarity; textual semantic search},
	keywords = {Computational linguistics; Graph embeddings; Natural language processing systems; Semantics; Textbooks; AI-enhanced learning; Content recommendations; Educational content recommendation; Educational contents; Embeddings; Enhanced learning; Ensemble embedding; Graph embeddings; Knowledge graph embedding; Knowledge graphs; Language model; Language processing; Natural language processing; Natural languages; Pre-trained language model; Semantic search; Text similarity; Textual semantic search; Knowledge graph},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 11; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Nguyen Quang2023443,
	author = {Nguyen Quang, Tung and Nguyen, Thi-Oanh},
	title = {Language Knowledge-Assisted in Topology Construction for Skeleton-Based Action Recognition},
	year = {2023},
	journal = {ACM International Conference Proceeding Series},
	pages = {443 – 449},
	doi = {10.1145/3628797.3629008},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180548900&doi=10.1145%2f3628797.3629008&partnerID=40&md5=59096c6db04472a87245754d081d5860},
	abstract = {Skeleton-based action recognition is a challenging problem due to the high dimensionality and noisy nature of skeleton data. Graph convolution networks (GCNs), which use graph topology to extract representative features, have been effective for skeleton-based action recognition in recent years. However, effectively learning and aggregating topology information is challenging problem. In this work, we propose a strategy to construct topology representation to skeleton-based action recognition that combines language knowledge to learn the topology. Specifically, borrows the idea from Language Knowledge-Assisted Representation Learning (LAGCN) [20], which uses a large-scale language model (LLM) to learn a priori global relationship (GPR) topology that captures the global structural relationships between the joints and a priori category relationship (CPR) topology between nodes in the skeleton graph to capture the category-specific relationships between the joints. We propose to apply the GPR topology as a prior topology, provide significant momentum to learn the model along with the CPR which is used to learn the class-distinguishable features into the Channel-wise Topology Refinement Graph Convolution (CTRGCN) [4]. The proposed approach is evaluated on the NTU RGB+D and NW-UCLA datasets. The results show that the proposed approach achieves promising results with 96.76% on the NW-UCLA dataset and 97% on the NTU dataset with the cross-view benchmark along with 92.8% on NTU cross-subject benchmark.  © 2023 ACM.},
	author_keywords = {graph convolution network; graph topology; Human action recognition; language model},
	keywords = {Computational linguistics; Convolution; Graph neural networks; Knowledge graph; Musculoskeletal system; Action recognition; Graph convolution network; Graph topology; High dimensionality; Human-action recognition; Knowledge-assisted; Language model; Learn+; Topology construction; Topology information; Topology},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Harvey202337,
	author = {Harvey, D. and Ruchayskiy, O. and Boyarsky, A. and Solovyov, V. and Magalich, A. and Romaniukov, A. and Puhach, D. and Arekhta, O.},
	title = {Prophy: An automated reviewer finder to improve the efficiency, diversity and quality of reviews},
	year = {2023},
	journal = {Information Services and Use},
	volume = {44},
	number = {1},
	pages = {37 – 42},
	doi = {10.3233/ISU-230196},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180974142&doi=10.3233%2fISU-230196&partnerID=40&md5=0b5f03e90c76753e9c04603b55314796},
	abstract = {Peer review is under pressure. Without fair, transparent and efficient peer review we cannot ensure the right proposals get funded and the correct manuscripts get published. In the era of Open Access, which is driving an exponential increase in the number of submitted publications, how we carry out peer review is becoming increasingly important and how we find reviewers is coming under scrutiny. The current methods are slow and produce bias pools of reviewers. As such we need an improved way. At Prophy we have developed a state-of-the-art referee finder that can find experts to review any manuscript from any scientific field in seconds. Then through post-processing filters we can find appropriate candidate referees who are most likely to review a paper, whilst highlighting important conflicts of interest through our complex citation networks. These methods can ensure fair and independent experts who can review interdisciplinary papers from any discipline. These methods are being delivered through APIs and the editorial workflow of editors ensure the right people get access to these tools. Finally, as large-language models improve, so does Prophy and as such we will be looking to drive real innovation in this area in years to come. © 2024 - The authors. Published by IOS Press. This is an Open Access article distributed under the terms of the Creative Commons Attribution-NonCommercial License (CC BY-NC 4.0).},
	author_keywords = {machine learning; ontology; Peer-review; referee finder; semantic AI},
	keywords = {Machine learning; 'current; Exponential increase; Machine-learning; Ontology's; OpenAccess; Peer review; Referee finder; Scientific fields; Semantic AI; State of the art; Semantics},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Bronze Open Access}
}

@CONFERENCE{Schneider2024807,
	author = {Schneider, Phillip and Klettner, Manuel and Jokinen, Kristiina and Simperl, Elena and Matthes, Florian},
	title = {Evaluating Large Language Models in Semantic Parsing for Conversational Question Answering over Knowledge Graphs},
	year = {2024},
	journal = {International Conference on Agents and Artificial Intelligence},
	volume = {3},
	pages = {807 – 814},
	doi = {10.5220/0012394300003636},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185571476&doi=10.5220%2f0012394300003636&partnerID=40&md5=92a06e0bd93f02d28da475df1318e695},
	abstract = {Conversational question answering systems often rely on semantic parsing to enable interactive information retrieval, which involves the generation of structured database queries from a natural language input. For information-seeking conversations about facts stored within a knowledge graph, dialogue utterances are transformed into graph queries in a process that is called knowledge-based conversational question answering. This paper evaluates the performance of large language models that have not been explicitly pre-trained on this task. Through a series of experiments on an extensive benchmark dataset, we compare models of varying sizes with different prompting techniques and identify common issue types in the generated output. Our results demonstrate that large language models are capable of generating graph queries from dialogues, with significant improvements achievable through few-shot prompting and fine-tuning techniques, especially for smaller models that exhibit lower zero-shot performance. © 2024 by SCITEPRESS - Science and Technology Publications, Lda.},
	author_keywords = {Conversational Question Answering; Knowledge Graphs; Large Language Models; Semantic Parsing},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Zhou2024,
	author = {Zhou, Bin and Li, Xinyu and Liu, Tianyuan and Xu, Kaizhou and Liu, Wei and Bao, Jinsong},
	title = {CausalKGPT: Industrial structure causal knowledge-enhanced large language model for cause analysis of quality problems in aerospace product manufacturing},
	year = {2024},
	journal = {Advanced Engineering Informatics},
	volume = {59},
	doi = {10.1016/j.aei.2023.102333},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182431911&doi=10.1016%2fj.aei.2023.102333&partnerID=40&md5=2f365deef6c65220d929f6f986acbf99},
	abstract = {The whole cycle for manufacturing aerospace thin-walled shells is a lengthy and sophisticated process. A large amount of quality-related data exists within and between processes, involving many types of quality defects and influencing factors. However, there are ambiguous causal associations among quality-related data affecting the shape-properties of the shell. Also, the coupling of long processes and multiple factors makes it hard to analyze the main factors that affect the quality defects in shell manufacturing. In this paper, taking into account the advantages of causal Scientology and the large language model (LLM), we propose an industrial structure causal knowledge-enhanced large language model for the cause analysis of quality defects in aerospace product manufacturing. To reinforce the causal associations among quality-related data deriving from manufacturing documents (product defect survey sheets, quality inspection, and maintenance reports), a structure causal graph-based sum-product network (SCG-SPN) model is designed to model machining quality-related knowledge and eliminate pseudo-association confounding factors by doing an intervention. Thus, a causal quality-related knowledge graph (CQKG) with high-quality causal associations is constructed. With this, to provide a trustworthy guarantee in responding to quality problem solving, we construct a quality-related prompt dataset with multi-round conversations based on CQKG. Then, a novel P-tuning that adapts to utilize external CQKG instructions is designed to fine-tune an open-source ChatGLM base model. Based on this, a causal knowledge graph-augmented LLM, named CausalKGPT, is developed to enable reasoning and responding to quality defects in both Chinese and English. It uses natural text descriptions related to quality defects as input and takes a quality-related causal knowledge graph as an additional corpus. Finally, the case study shows that the CausalKGPT performs with more expertise and reliability in responding to quality question solving of aerospace shell manufacturing than the classic commercial models like ChatGPT and GPT4. The results indicate that the proposed method may provide a trustworthy guide in assisting workers to analyze quality defects in aerospace products. © 2023 Elsevier Ltd},
	author_keywords = {Aerospace product; Causal knowledge graph-guided prompt; Causal quality-related knowledge graph; Cause analysis of quality defects; Large language model},
	keywords = {Computational linguistics; Graphic methods; Knowledge graph; Quality control; Shells (structures); Thin walled structures; Aerospace products; Causal knowledge graph-guided prompt; Causal quality-related knowledge graph; Cause analyse of quality defect; Causes analysis; Knowledge graphs; Language model; Large language model; Quality defects; Defects},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 27}
}

@ARTICLE{Feng202310,
	author = {Feng, Xinguo and Zhang, Yanjun and Meng, Mark Huasong and Li, Yansong and Joe, Chegne Eu and Wang, Zhe and Bai, Guangdong},
	title = {Detecting contradictions from IoT protocol specification documents based on neural generated knowledge graph},
	year = {2023},
	journal = {ISA Transactions},
	volume = {141},
	pages = {10 – 19},
	doi = {10.1016/j.isatra.2023.04.025},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85158817992&doi=10.1016%2fj.isatra.2023.04.025&partnerID=40&md5=3c5e03fdd9e95774de6bc841a05a4ea9},
	abstract = {Due to the boom of Internet of Things (IoT) in recent years, various IoT devices are connected to the Internet and communicate with each other through network protocols such as the Constrained Application Protocol (CoAP). These protocols are typically defined and described in specification documents, such as Request for Comments (RFC), which are written in natural or semi-formal languages. Since developers largely follow the specification documents when implementing web protocols, they have become the de facto protocol specifications. Therefore, it must be ensured that the descriptions in them are consistent to avoid technological issues, incompatibility, security risks, or even legal concerns. In this work, we propose Neural RFC Knowledge Graph (NRFCKG), a neural network-generated knowledge graph based contradictions detection tool for IoT protocol specification documents. Our approach can automatically parse the specification documents and construct knowledge graphs from them through entity extraction, relation extraction, and rule extraction with large language models. It then conducts an intra-entity and inter-entity contradiction detection over the generated knowledge graph. We implement NRFCKG and apply it to the most extensively used messaging protocols in IoT, including the main RFC (RFC7252) of CoAP, the specification document of MQTT, and the specification document of AMQP. Our evaluation shows that NRFCKG generalizes well to other specification documents and it manages to detect contradictions from these IoT protocol specification documents. © 2023 ISA},
	author_keywords = {Contradiction detection; Internet of things; Large language models; Natural language processing; Web protocol},
	keywords = {Computational linguistics; Extraction; Formal languages; Graphic methods; Internet protocols; Knowledge graph; Natural language processing systems; Petroleum reservoir evaluation; Specifications; Contradiction detection; Knowledge graphs; Language model; Language processing; Large language model; Natural language processing; Natural languages; Protocol specifications; Specifications document; Web protocols; Internet of things},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@ARTICLE{Xiao2023417,
	author = {Xiao, Youzi and Zheng, Shuai and Shi, Jiancheng and Du, Xiaodong and Hong, Jun},
	title = {Knowledge graph-based manufacturing process planning: A state-of-the-art review},
	year = {2023},
	journal = {Journal of Manufacturing Systems},
	volume = {70},
	pages = {417 – 435},
	doi = {10.1016/j.jmsy.2023.08.006},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172474199&doi=10.1016%2fj.jmsy.2023.08.006&partnerID=40&md5=2b357eea76065452a93fccebefb07f6d},
	abstract = {Computer-aided process planning is the bridge between computer-aided design and computer-aided manufacturing. With the advent of the intelligent manufacturing era, process knowledge is important for process planning. Knowledge graph is a semantic representation method of knowledge that has attracted extensive attention from the industry and academia. Process planning using the process knowledge graph has become an important development direction for computer-aided process planning. From the analysis of the published reviews, there have been many computer-aided process planning reviews with different focuses. We focus on the techniques and applications of knowledge graph in manufacturing process planning. Therefore, this paper comprehensively reviews knowledge graphs in manufacturing process planning. We analyze the key technologies of process knowledge graph, including process knowledge representation, process knowledge extraction, process knowledge graph construction, process knowledge graph refinement, process knowledge graph validation, and process generation. We also explore the combination of process knowledge graphs and large language models. Finally, potential future research directions are proposed. © 2023 The Society of Manufacturing Engineers},
	author_keywords = {CAPP; Knowledge graph; Process knowledge graph; Process planning},
	keywords = {Bridges; Computer aided analysis; Computer aided design; Computer aided manufacturing; Computer aided process planning; Graphic methods; Knowledge graph; CAPP; Computer-aided design; Computeraided process planning(CAPP); Graph-based; Knowledge graphs; Manufacturing process planning; Process knowledge; Process knowledge graph; State-of-the art reviews; Semantics},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 46}
}

@CONFERENCE{Zhang20232179,
	author = {Zhang, Chenchen and Jian, Sun and Chao, Luo and Fan, Chen and Bo, Li and Chen, Luo},
	title = {A Semantic Understanding Method for Patent Text Based on Large Language Model},
	year = {2023},
	journal = {2023 IEEE 7th Conference on Energy Internet and Energy System Integration, EI2 2023},
	pages = {2179 – 2182},
	doi = {10.1109/EI259745.2023.10513309},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194162636&doi=10.1109%2fEI259745.2023.10513309&partnerID=40&md5=2037298a043e241a5b9c1fdaec6dce1d},
	abstract = {The large language model has powerful natural language understanding and generation capabilities, which can automatically extract keywords and key information from literature, thus achieving fast and efficient patent retrieval. At the same time, the large model can also be customized according to user needs, improving retrieval accuracy and efficiency. A semantic understanding method for patent text based on large language model is proposed in this paper. This method first requires preprocessing of the dataset, inputting the problem into ChatGPT according to the specified instruction format, and then classifying the output content for analysis based on different classifications. Then, the entity recognition results are input into the patent system, and the knowledge graph in the patent system is used for inference analysis to obtain the corresponding answer to the problem. The research results show that the method based on the large language model has high accuracy and generalization ability, and can achieve semantic understanding and analysis of patent texts.  © 2023 IEEE.},
	author_keywords = {ChatGPT; large language models; patent text; semantic understanding},
	keywords = {Computational linguistics; Knowledge graph; Natural language processing systems; Patents and inventions; Semantics; ChatGPT; Language model; Large language model; Large models; Natural language generation; Natural language understanding; Patent retrieval; Patent system; Patent text; Semantics understanding; Classification (of information)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Palagin2024111,
	author = {Palagin, O. and Kaverinskiy, V. and Malakhov, K. and Petrenko, M.},
	title = {Fundamentals of the Integrated Use of Neural Network and Ontolinguistic Paradigms: A Comprehensive Approach},
	year = {2024},
	journal = {Cybernetics and Systems Analysis},
	volume = {60},
	number = {1},
	pages = {111 – 123},
	doi = {10.1007/s10559-024-00652-z},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184410537&doi=10.1007%2fs10559-024-00652-z&partnerID=40&md5=349afa66ab92ef1953b3040ae38969dc},
	abstract = {The paper presents an integrated approach that combines neural network and ontolinguistic paradigms. The method encompasses methodological underpinnings, information technology, and the MedRehabBot system. Collectively, they embody the core principles of meta-learning and structured prompts, ultimately enhancing the efficiency of information system interaction with Chatbots and information retrieval rooted in ontologies. The method also offers the flexibility to adapt the MedRehabBot system for utilization within different Large Language Model (LLM) systems. © Springer Science+Business Media, LLC, part of Springer Nature 2024.},
	author_keywords = {Chatbot; ChatGPT; LLM-system; MedRehabBot; ontological engineering; ontology; ontology-driven information system; prompt engineering; transdisciplinary scientific research},
	keywords = {Information systems; Information use; Linguistics; Search engines; Chatbots; ChatGPT; Language model; Large language model-system; Medrehabbot; Modelling systems; Ontological engineering; Ontology's; Ontology-driven information system; Prompt engineering; Scientific researches; Transdisciplinary scientific research; Ontology},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 10}
}

@ARTICLE{Stathis2024107,
	author = {Stathis, Georgios and Biagioni, Giulia and de Graaf, Klaas Andries and Trantas, Athanasios and van den Herik, Jaap},
	title = {The Value of Proactive Data for Intelligent Contracts},
	year = {2024},
	journal = {Lecture Notes in Networks and Systems},
	volume = {803},
	pages = {107 – 125},
	doi = {10.1007/978-981-99-7569-3_10},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187647502&doi=10.1007%2f978-981-99-7569-3_10&partnerID=40&md5=1dfef30a0019243c6dabdbc2afc745f0},
	abstract = {Intelligent Contracts (iContracts) is a new branch of research at the intersection of AI and law. It has many challenges, among which including the quality of data used. In our research we focus on generating and including quality Proactive Control Data (PCD) to improve iContracts, which is a novel research scope in literature. Our scope is defined by the main challenge in regards to emerging legal technologies. Currently, the legal system is more reactive than proactive, leading to high consequential legal costs. By shifting the focus to proactiveness, we discuss and improve upon the available methodologies (Bow-Tie Method and Logocratic Method) and technologies (Ontology Engineering, Software Engineering and Large Language Models [LLMs]) to demonstrate a higher degree of proactiveness in iContracts. Our results are threefold. First, we prove that the generation of PCD is possible with the development of a prototype that leverages the foundations of the Bow-Tie Method. Second, we demonstrate that the impact of PCD on contract drafting is significant, as the explicit inclusion of PCD in prompt engineering alters significantly the content of an LLM-drafted contract. Third, we show how the quality of PCD can be assessed and improved upon with the application of the Logocratic Method. The discussion highlights the feasibility of the research with available technologies. Ultimately, the implementation of our research depends on organisational considerations and resource allocation. We conclude that the generation of PCD is feasible, their impact on contract drafting is significant and their quality assessment is both possible and novel. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2024.},
	author_keywords = {Bow-tie method; Contract automation; Intelligent contracts; Large language models; Legal technology; Logocratic method; Ontology engineering; Preventive/proactive law; Software engineering},
	keywords = {Computational linguistics; Contracts; Software engineering; Bow-tie methods; Contract automation; Control data; Intelligent contract; Language model; Large language model; Legal technology; Logocratic method; Ontology engineering; Preventive/proactive law; Ontology},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Fan2023586,
	author = {Fan, Lizhou and Lafia, Sara and Li, Lingyao and Yang, Fangyuan and Hemphill, Libby},
	title = {DataChat: Prototyping a Conversational Agent for Dataset Search and Visualization},
	year = {2023},
	journal = {Proceedings of the Association for Information Science and Technology},
	volume = {60},
	number = {1},
	pages = {586 – 591},
	doi = {10.1002/pra2.820},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174518185&doi=10.1002%2fpra2.820&partnerID=40&md5=f76c4aba8ca96fb51a32be437f0f7799},
	abstract = {Data users need relevant context and research expertise to effectively search for and identify relevant datasets. Leading data providers, such as the Inter-university Consortium for Political and Social Research (ICPSR), offer standardized metadata and search tools to support data search. Metadata standards emphasize the machine-readability of data and its documentation. There are opportunities to enhance dataset search by improving users' ability to learn about, and make sense of, information about data. Prior research has shown that context and expertise are two main barriers users face in effectively searching for, evaluating, and deciding whether to reuse data. In this paper, we propose a novel chatbot-based search system, DataChat, that leverages a graph database and a large language model to provide novel ways for users to interact with and search for research data. DataChat complements data archives' and institutional repositories' ongoing efforts to curate, preserve, and share research data for reuse by making it easier for users to explore and learn about available research data.  Annual Meeting of the Association for Information Science & Technology | Oct. 27 – 31, 2023 | London, United Kingdom. Author(s) retain copyright, but ASIS&T receives an exclusive publication license.},
	author_keywords = {data reuse; dataset search; knowledge graphs; large language model; research data management},
	keywords = {Computational linguistics; Data visualization; Graph theory; Information management; Information services; Knowledge graph; Search engines; Conversational agents; Data reuse; Dataset search; Knowledge graphs; Language model; Large language model; Learn+; Research data; Research data managements; Reuse; Metadata},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6}
}

@CONFERENCE{Dong20235792,
	author = {Dong, Xin Luna and Moon, Seungwhan and Xu, Yifan Ethan and Malik, Kshitiz and Yu, Zhou},
	title = {Towards Next-Generation Intelligent Assistants Leveraging LLM Techniques},
	year = {2023},
	journal = {Proceedings of the ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
	pages = {5792 – 5793},
	doi = {10.1145/3580305.3599572},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171379652&doi=10.1145%2f3580305.3599572&partnerID=40&md5=90f11a7b4c098b19ed719d98e734f91e},
	abstract = {Virtual Intelligent Assistants take user requests in the voice form, perform actions such as setting an alarm, turning on a light, and answering a question, and provide answers or confirmations in the voice form or through other channels such as a screen. Assistants have become prevalent in the past decade, and users have been taking services from assistants like Amazon Alexa, Apple Siri, Google Assistant, and Microsoft Cortana. The emergence of AR/VR devices raised many new challenges for building intelligent assistants. The unique requirements have inspired new research directions such as (a) understanding users' situated multi-modal contexts (e.g. vision, sensor signals) as well as language-oriented conversational contexts, (b) personalizing the assistant services by grounding interactions on growing public and personal knowledge graphs and online search engines, and (c) on- device model inference and training techniques that satisfy strict resource and privacy constraints. In this tutorial, we will provide an in-depth walk-through of techniques in the afore-mentioned areas in the recent literature. We aim to introduce techniques for researchers and practitioners who are building intelligent assistants, and inspire research that will bring us one step closer to realizing the dream of building an all-day accompanying assistant. Additionally, we will highlight the significant role that Large Language Models (LLMs) play in enhancing these strategies, underscoring their potential to reshape the future landscape of intelligent assistance.  © 2023 Owner/Author.},
	author_keywords = {conversational ai; federated learning; knowledge grounding; large language models; multi-modal conversation; personalization},
	keywords = {C (programming language); Computational linguistics; Intelligent buildings; Knowledge management; Conversational ai; Federated learning; Intelligent assistants; Knowledge grounding; Language model; Large language model; Modelling techniques; Multi-modal; Multi-modal conversation; Personalizations; Search engines},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 35}
}

@ARTICLE{2024,
	title = {3rd BenchCouncil International Symposium on Intelligent Computers, Algorithms, and Applications, IC 2023},
	year = {2024},
	journal = {Communications in Computer and Information Science},
	volume = {2036 CCIS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185770109&partnerID=40&md5=452717e8e9abb46917564adf4f02c103},
	abstract = {The proceedings contain 26 papers. The special focus in this conference is on Intelligent Computers, Algorithms, and Applications. The topics include: KGCN-DDA: A Knowledge Graph Based GCN Method for Drug-Disease Association Prediction; machine Learning for Time-to-Event Prediction and Survival Clustering: A Review from Statistics to Deep Neural Networks; label-Independent Information Compression for Skin Diseases Recognition; 3D Approach Trajectory Optimization Based on Combined Intelligence Algorithms; A-SMGCS: Innovation, Applications, and Future Prospects of Modern Aviation Ground Movement Management System; an Intelligent Image Segmentation Annotation Method Based on Segment Anything Model; ParticleNet for Jet Tagging in Particle Physics on FPGA; application of Graph Neural Networks in Dark Photon Search with Visible Decays at Future Beam Dump Experiment; second-Order Gradient Loss Guided Single-Image Super-Resolution; Neutrino Reconstruction in TRIDENT Based on Graph Neural Network; charged Particle Reconstruction for Future High Energy Colliders with Quantum Approximate Optimization Algorithm; A Levy Scheme for User-Generated-Content Platforms and Its Implication for Generative AI Providers; Moving Beyond Text: Multi-modal Expansion of the Toulmin Model for Enhanced AI Legal Reasoning; The Worldwide Contradiction of the GAI Regulatory Theory Paradigm and China’s Response: Focus on the Theories of Normative Models and Regulatory Systems; Intelligent Forecasting of Trademark Registration Appeal with TF-IDF and XGBoost; review of Big Data Evidence in Criminal Proceedings: Basis of Academic Theory, Practical Pattern and Mode Selection; The Implementation and Optimization of FFT Calculation Based on the MT-3000 Chip; EDFI: Endogenous Database Fault Injection with a Fine-Grained and Controllable Method; diffusion Probabilistic Models for Underwater Image Super-Resolution; classification Method for Ship-Radiated Noise Based on Joint Feature Extraction; Forecasting the Price of Bitcoin Using an Explainable CNN-LSTM Model; augmenting Bankruptcy Prediction Using Reported Behavior of Corporate Restructuring; a New Dataset and Method for Creativity Assessment Using the Alternate Uses Task.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Liu2024,
	author = {Liu, Hao and Feng, Jiarui and Kong, Lecheng and Liang, Ningyue and Tao, Dacheng and Chen, Yixin and Zhang, Muhan},
	title = {ONE FOR ALL: TOWARDS TRAINING ONE GRAPH MODEL FOR ALL CLASSIFICATION TASKS},
	year = {2024},
	journal = {12th International Conference on Learning Representations, ICLR 2024},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185663727&partnerID=40&md5=6ee6d0324844dcbd36f2c52452a9d2e5},
	abstract = {Designing a single model to address multiple tasks has been a long-standing objective in artificial intelligence. Recently, large language models have demonstrated exceptional capability in solving different tasks within the language domain. However, a unified model for various graph tasks remains underexplored, primarily due to the challenges unique to the graph learning domain. First, graph data from different areas carry distinct attributes and follow different distributions. Such discrepancy makes it hard to represent graphs in a single representation space. Second, tasks on graphs diversify into node, link, and graph tasks, requiring distinct embedding strategies. Finally, an appropriate graph prompting paradigm for in-context learning is unclear. We propose One for All (OFA), the first general framework that can use a single graph model to address the above challenges. Specifically, OFA proposes text-attributed graphs to unify different graph data by describing nodes and edges with natural language and uses language models to encode the diverse and possibly cross-domain text attributes to feature vectors in the same embedding space. Furthermore, OFA introduces the concept of nodes-of-interest to standardize different tasks with a single task representation. For in-context learning on graphs, OFA introduces a novel graph prompting paradigm that appends prompting substructures to the input graph, which enables it to address varied tasks without fine-tuning. We train the OFA model using graph data from multiple domains (including citation networks, molecular graphs, knowledge graphs, etc.) simultaneously and evaluate its ability in supervised, few-shot, and zero-shot learning scenarios. OFA performs well across different tasks, making it the first general-purpose across-domains classification model on graphs. © 2024 12th International Conference on Learning Representations, ICLR 2024. All rights reserved.},
	keywords = {Computational linguistics; Graph embeddings; Graph theory; Graphic methods; Knowledge graph; Vector spaces; Classification tasks; Context learning; Different distributions; Graph data; Graph model; In contexts; Language model; Multiple tasks; Single models; Unified Modeling; Zero-shot learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@CONFERENCE{Ranade2023603,
	author = {Ranade, Priyanka and Joshi, Anupam},
	title = {FABULA: Intelligence Report Generation Using Retrieval-Augmented Narrative Construction},
	year = {2023},
	journal = {Proceedings of the 2023 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining, ASONAM 2023},
	pages = {603 – 610},
	doi = {10.1145/3625007.3627505},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190626299&doi=10.1145%2f3625007.3627505&partnerID=40&md5=efc58e57f7452acfa42d51965d4f766f},
	abstract = {Narrative construction is the process of representing disparate event information into a logical plot structure that models an end to end story. Intelligence analysis is an example of a domain that can benefit tremendously from narrative construction techniques, particularly in aiding analysts during the largely manual and costly process of synthesizing event information into comprehensive intelligence reports. Manual intelligence report generation is often prone to challenges such as integrating dynamic event information, writing fine-grained queries, and closing information gaps. This motivates the development of a system that retrieves and represents critical aspects of events in a form that aids in automatic generation of intelligence reports.We introduce a Retrieval Augmented Generation (RAG) approach to augment prompting of an autoregressive decoder by retrieving structured information asserted in a knowledge graph to generate targeted information based on a narrative plot model. We apply our approach to the problem of neural intelligence report generation and introduce FABULA, framework to augment intelligence analysis workflows using RAG. An analyst can use FABULA to query an Event Plot Graph (EPG) to retrieve relevant event plot points, which can be used to augment prompting of a Large Language Model (LLM) during intelligence report generation. Our evaluation studies show that the plot points included in the generated intelligence reports have high semantic relevance, high coherency, and low data redundancy. © 2023 ACM.},
	author_keywords = {knowledge graphs; large language models; narratives; retrieval augmented generation},
	keywords = {Computational linguistics; Semantics; Construction technique; Dynamic events; End to end; Intelligence analysis; Knowledge graphs; Language model; Large language model; Narrative; Report generation; Retrieval augmented generation; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Bronze Open Access, Green Open Access}
}

@CONFERENCE{Liu2023484,
	author = {Liu, Wenjing and Zhang, Suxiang and Sun, Yang and Sheng, Xing and Wu, Zhidong},
	title = {New Energy Power Domain Question-Method Extraction and Soft Clustering},
	year = {2023},
	journal = {ACM International Conference Proceeding Series},
	pages = {484 – 491},
	doi = {10.1145/3638884.3638961},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192152765&doi=10.1145%2f3638884.3638961&partnerID=40&md5=cbd31c0e88a42923e25e27f9c16b4e2f},
	abstract = {In recent years, as the field of new energy power has gradually become a research hotspot, there are more and more research results related to new energy power. This paper first proposes to Fine-tune the Chinese LLaMA large language model to realize the extraction of research questions and methods in new energy power results. The fine-tuning dataset is constructed by the combination of rule template and gpt-3.5 enhancement, which avoids the costly and time-consuming problem caused by manual construction. The fine-tuning method adopts LoRA high-efficiency fine-tuning to save computing resources; Then, F1 value is used as the evaluation index to compare the extraction effect of the model under different fine-tuning datasets. The results show that the model has a good extraction effect on the research questions and method terms when training the dataset constructed by the combination of rule template and gpt-3.5 enhancement. Finally, according to the extracted research question phrases, BTM(Biterm Topic Model) is used to study the distribution of topic words, and soft clustering of research question phrases is carried out according to the obtained topic words, so as to realize the correlation between the research results and professional terms, which provides the foundation for the future establishment of the knowledge graph and knowledge base of new energy power. © 2023 Copyright held by the owner/author(s)},
	author_keywords = {Biterm Topic Model; Chinese LLaMA Fine-Tuning; Soft clustering; Terminology extraction},
	keywords = {Knowledge graph; Semantics; Terminology; Biterm topic model; Chinese LLaMA fine-tuning; Energies (power); Fine tuning; New energies; Research questions; Research results; Soft clustering; Terminology extraction; Topic Modeling; Extraction},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Chen2023,
	author = {Chen, Tong and Wang, Xuewei and Yue, Tianwei and Bai, Xiaoyu and Le, Cindy X. and Wang, Wenping},
	title = {Enhancing Abstractive Summarization with Extracted Knowledge Graphs and Multi-Source Transformers},
	year = {2023},
	journal = {Applied Sciences (Switzerland)},
	volume = {13},
	number = {13},
	doi = {10.3390/app13137753},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164828931&doi=10.3390%2fapp13137753&partnerID=40&md5=e8633d50779df03c4ab0bcffc89882a3},
	abstract = {As the popularity of large language models (LLMs) has risen over the course of the last year, led by GPT-3/4 and especially its productization as ChatGPT, we have witnessed the extensive application of LLMs to text summarization. However, LLMs do not intrinsically have the power to verify the correctness of the information they supply and generate. This research introduces a novel approach to abstractive summarization, aiming to address the limitations of LLMs in that they struggle to understand the truth. The proposed method leverages extracted knowledge graph information and structured semantics as a guide for summarization. Building upon BART, one of the state-of-the-art sequence-to-sequence pre-trained LLMs, multi-source transformer modules are developed as an encoder, which are capable of processing textual and graphical inputs. Decoding is performed based on this enriched encoding to enhance the summary quality. The Wiki-Sum dataset, derived from Wikipedia text dumps, is introduced for evaluation purposes. Comparative experiments with baseline models demonstrate the strengths of the proposed approach in generating informative and relevant summaries. We conclude by presenting our insights into utilizing LLMs with graph external information, which will become a powerful aid towards the goal of factually correct and verified LLMs. © 2023 by the authors.},
	author_keywords = {abstractive summarization; knowledge graph; multi-source transformers; pre-trained language models},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 17; All Open Access, Gold Open Access}
}

@CONFERENCE{Lotfy2024411,
	author = {Lotfy, Abdelrahman and Saleh, Kirollos and Mohamed, Saher and Lorance, John and Yehia, Ehab and Mohammed, Khaled and AbdAlbaky, Ibrahim and Fathy, Mostafa and Yasser, Tawfik},
	title = {Sentiment Analysis for Arabic Product Reviews using LLMs and Knowledge Graphs},
	year = {2024},
	journal = {6th International Conference on Computing and Informatics, ICCI 2024},
	pages = {411 – 417},
	doi = {10.1109/ICCI61671.2024.10485037},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190654881&doi=10.1109%2fICCI61671.2024.10485037&partnerID=40&md5=b8ad8aa0245a60b0f18ae8d33ddfd0f4},
	abstract = {The exploration of sentiment analysis in multilingual contexts, particularly through the integration of deep learning techniques and knowledge graphs, represents a significant advance in language processing research. This study specifically concentrates on the Arabic language, addressing the challenges presented by its morphological complexity. While the primary focus is Arabic, the research also includes a comprehensive review of related work in other languages such as Bangla and Chinese. This contextualizes the challenges and solutions found in Arabic sentiment analysis within a broader multilingual landscape. Utilizing pre-trained language models like BERT, the research has achieved noteworthy improvements in sentiment analysis accuracy and efficiency, particularly for the Arabic language. The integration of knowledge graphs stands out as a crucial innovation, offering essential contextual insights and mitigating the limitations posed by sparse labeled datasets in Arabic, a language less resourced compared to English. The findings of this study highlight the effectiveness of tailored BERT models for Arabic sentiment analysis, revealing the vast potential and inherent challenges of employing knowledge graphs and large language models for a deeper, more nuanced understanding. The future direction of this research includes enhancing these methods with cutting-edge machine learning techniques, aiming to further refine sentiment analysis processes and knowledge graph construction with a focus on Arabic within a multilingual framework. © 2024 IEEE.},
	author_keywords = {Arabic; Big Data; Knowledge Graph; LLMs; Sentiment Analysis},
	keywords = {Big data; Computational linguistics; Deep learning; Graphic methods; Knowledge graph; Learning algorithms; Learning systems; Arabic; Arabic languages; Knowledge graphs; Language model; Language processing; Learning techniques; LLM; Multilingual context; Product reviews; Sentiment analysis; Sentiment analysis},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Huang2023,
	author = {Huang, Jingxiu and Ding, Ruofei and Wu, Xiaomin and Chen, Shumin and Zhang, Jiale and Liu, Lixiang and Zheng, Yunxiang},
	title = {WERECE: An Unsupervised Method for Educational Concept Extraction Based on Word Embedding Refinement},
	year = {2023},
	journal = {Applied Sciences (Switzerland)},
	volume = {13},
	number = {22},
	doi = {10.3390/app132212307},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187354213&doi=10.3390%2fapp132212307&partnerID=40&md5=91a65b9196b966a1b0d4a23fd950abef},
	abstract = {The era of educational big data has sparked growing interest in extracting and organizing educational concepts from massive amounts of information. Outcomes are of the utmost importance for artificial intelligence–empowered teaching and learning. Unsupervised educational concept extraction methods based on pre-trained models continue to proliferate due to ongoing advances in semantic representation. However, it remains challenging to directly apply pre-trained large language models to extract educational concepts; pre-trained models are built on extensive corpora and do not necessarily cover all subject-specific concepts. To address this gap, we propose a novel unsupervised method for educational concept extraction based on word embedding refinement (i.e., word embedding refinement–based educational concept extraction (WERECE)). It integrates a manifold learning algorithm to adapt a pre-trained model for extracting educational concepts while accounting for the geometric information in semantic computation. We further devise a discriminant function based on semantic clustering and Box–Cox transformation to enhance WERECE’s accuracy and reliability. We evaluate its performance on two newly constructed datasets, EDU-DT and EDUTECH-DT. Experimental results show that WERECE achieves an average precision up to 85.9%, recall up to 87.0%, and F1 scores up to 86.4%, which significantly outperforms baselines (TextRank, term frequency–inverse document frequency, isolation forest, K-means, and one-class support vector machine) on educational concept extraction. Notably, when WERECE is implemented with different parameter settings, its precision and recall sensitivity remain robust. WERECE also holds broad application prospects as a foundational technology, such as for building discipline-oriented knowledge graphs, enhancing learning assessment and feedback, predicting learning interests, and recommending learning resources. © 2023 by the authors.},
	author_keywords = {clustering; concept extraction; knowledge graph; manifold learning; semantic computation; word embedding},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access}
}

@CONFERENCE{Martin2024,
	author = {Martin, James Lee and Zanuri, M. Nur Arif and Sockalingam, Muthu Kumar and Andersen, Eric},
	title = {LLMs, Embeddings and Indexing Pipelines to Enable Natural Language Searching on Upstream Datasets},
	year = {2024},
	journal = {International Petroleum Technology Conference, IPTC 2024},
	doi = {10.2523/IPTC-23626-EA},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187576256&doi=10.2523%2fIPTC-23626-EA&partnerID=40&md5=e51ab9196089c008e557cc9844b5c8ea},
	abstract = {Large Language Models (LLMs) are attracting an enormous amount of interest at the moment in many domains. Their general nature, and ability to "understand" natural language, has already stimulated multiple areas of research at our company. Here we successfully demonstrate a Natural Language querying system, which is able to search a large repository of unstructured exploration data. The system supports follow up querying on the returned results, plus automatic summarization of content. The system is integrated into our novel end-to-end data-mining platform, which continuously mines our unstructured exploration data for new changes and indexes the results. Important in our method are the enrichment processes that occur prior to use of the LLM. Our approach avoids usual "chunking" techniques, which in our experience results in inferior results, especially in the multiple domain areas of Exploration. By integrating our novel ontology-model AI in the enrichment of the initial Index, we drastically boost the performance of search resulting from the LLM steps. In order to perform the search, key parts of our unstructured data, plus the query itself, need to be transformed into a vector form. This is performed using the embedding feature of the LLM. For this work, we had around 500,000 embeddings to calculate. To improve performance these were indexed in a leading Analytics Engine as a vector object, allowing fast search via cosine or Euclidian similarity. A custom dashboard was made to allow fresh searches of the vector datastore to be returned for further analysis. Our current search time across 500,000 embeddings is under 20 milli-seconds. Our custom dashboard returns the top matches for further interrogation and analysis. This includes follow-up Natural Language question support on the returned matches for summarization tasks and other customised querying. Since our exploration-specific, ontology model is able to tag each piece of data with over 40 exploration-specific labels, we are able to cross-examine the LLM returned results with the tags. Agreement on a range of queries - ranging from targeted, highly specific questions to general, open-ended queries - was surprisingly good. Natural Language based querying of our unstructured data is opening a whole new approach to data discovery in our company. Tailoring it to the exploration domain has required specific domain expertise and a novel ontology-model be used to ensure relevant prompts and query results. Obtaining search results quickly has also required expertise and fine-tuning. Future directions include ingesting more data, scaling the support infrastructure and further capability enhancement. Copyright © 2024, International Petroleum Technology Conference.},
	keywords = {Data mining; Gasoline; Natural language processing systems; Ontology; Search engines; Embeddings; Exploration data; Follow up; General nature; Language model; Model embedding; Multiple areas; Natural languages; Ontology model; Unstructured data; Embeddings},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Miao2024,
	author = {Miao, Runqing and Jia, Qingxuan and Sun, Fuchun and Chen, Gang and Huang, Haiming},
	title = {Hierarchical Understanding in Robotic Manipulation: A Knowledge-Based Framework},
	year = {2024},
	journal = {Actuators},
	volume = {13},
	number = {1},
	doi = {10.3390/act13010028},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183191905&doi=10.3390%2fact13010028&partnerID=40&md5=ae35aee9484886e8c8625b988b1c3274},
	abstract = {In the quest for intelligent robots, it is essential to enable them to understand tasks beyond mere manipulation. Achieving this requires a robust parsing mode that can be used to understand human cognition and semantics. However, the existing methods for task and motion planning lack generalization and interpretability, while robotic knowledge bases primarily focus on static manipulation objects, neglecting the dynamic tasks and skills. To address these limitations, we present a knowledge-based framework for hierarchically understanding various factors and knowledge types in robotic manipulation. Using this framework as a foundation, we collect a knowledge graph dataset describing manipulation tasks from text datasets and an external knowledge base with the assistance of large language models and construct the knowledge base. The reasoning tasks of entity alignment and link prediction are accomplished using a graph embedding method. A robot in real-world environments can infer new task execution plans based on experience and knowledge, thereby achieving manipulation skill transfer. © 2024 by the authors.},
	author_keywords = {knowledge reasoning; knowledge representation; knowledge update; robotic manipulation},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access}
}

@CONFERENCE{Cavalleri2024,
	author = {Cavalleri, Emanuele and Mesiti, Marco},
	title = {On the extraction of meaningful RNA interactions from Scientific Publications through LLMs and SPIRES},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3651},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188542930&partnerID=40&md5=a20a94fa220cfd47caa80842c9f95a1d},
	abstract = {Knowledge graphs (KGs) are useful tools to uniformly represent and integrate heterogeneous information about a domain of interest. However, they are inherently incomplete; therefore, new facts should be introduced by extracting them from structured and unstructured data sources. Starting from RNA-KG, the first KG tailored for representing different kinds of RNA molecules that we recently developed, in this paper we evaluate the use of SPIRES for extracting interactions among bio-entities involving RNA molecules from scientific papers guided by the RNA-KG schema. SPIRES is a general-purpose knowledge extraction system for mining information conforming to a specified schema. A customized prompt is generated and submitted to a Large Language Model (LLM) along with a text to extract a set of RDF triples adhering to the schema constraints. The experiments show a high accuracy in extracting interactions from the scientific literature. © 2024 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).},
	author_keywords = {Knowledge Graphs; Large Language Models; RNA-based technologies; RNA-drug discovery},
	keywords = {Computational linguistics; Data mining; Extraction; Knowledge graph; Resource Description Framework (RDF); Drug discovery; Heterogeneous information; Knowledge graphs; Language model; Large language model; RNA interaction; RNA molecules; RNA-based technology; RNA-drug discovery; Scientific publications; RNA},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Phatak20247530,
	author = {Phatak, Atharva and Mago, Vijay K. and Agrawal, Ameeta and Giabbanelli, Philippe J.},
	title = {Narrating Causal Graphs with Large Language Models},
	year = {2024},
	journal = {Proceedings of the Annual Hawaii International Conference on System Sciences},
	pages = {7530 – 7539},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185705768&partnerID=40&md5=e986eef90a60c2e322e201ef955d70f2},
	abstract = {The use of generative AI to create text descriptions from graphs has mostly focused on knowledge graphs, which connect concepts using facts. In this work we explore the capability of large pretrained language models to generate text from causal graphs, where salient concepts are represented as nodes and causality is represented via directed, typed edges. The causal reasoning encoded in these graphs can support applications as diverse as healthcare or marketing. Using two publicly available causal graph datasets, we empirically investigate the performance of four GPT-3 models under various settings. Our results indicate that while causal text descriptions improve with training data, compared to fact-based graphs, they are harder to generate under zero-shot settings. Results further suggest that users of generative AI can deploy future applications faster since similar performances are obtained when training a model with only a few examples as compared to fine-tuning via a large curated dataset. © 2024 IEEE Computer Society. All rights reserved.},
	author_keywords = {Causal Map; Generative AI; GPT; Pre-Trained Large-Scale Language Model},
	keywords = {Computational linguistics; Graphic methods; Knowledge graph; Large datasets; Zero-shot learning; Causal graph; Causal Maps; Causal reasoning; Generative AI; GPT; Knowledge graphs; Language model; Large-scales; Performance; Pre-trained large-scale language model; Directed graphs},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Vladika2024376,
	author = {Vladika, Juraj and Fichtl, Alexander and Matthes, Florian},
	title = {Diversifying Knowledge Enhancement of Biomedical Language Models Using Adapter Modules and Knowledge Graphs},
	year = {2024},
	journal = {International Conference on Agents and Artificial Intelligence},
	volume = {2},
	pages = {376 – 387},
	doi = {10.5220/0012395200003636},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190687933&doi=10.5220%2f0012395200003636&partnerID=40&md5=e3b24c914912fa4fa4bb811b2eed1378},
	abstract = {Recent advances in natural language processing (NLP) owe their success to pre-training language models on large amounts of unstructured data. Still, there is an increasing effort to combine the unstructured nature of LMs with structured knowledge and reasoning. Particularly in the rapidly evolving field of biomedical NLP, knowledge-enhanced language models (KELMs) have emerged as promising tools to bridge the gap between large language models and domain-specific knowledge, considering the available biomedical knowledge graphs (KGs) curated by experts over the decades. In this paper, we develop an approach that uses lightweight adapter modules to inject structured biomedical knowledge into pre-trained language models (PLMs). We use two large KGs, the biomedical knowledge system UMLS and the novel biochemical ontology OntoChem, with two prominent biomedical PLMs, BERT and BioLinkBERT. The approach includes partitioning knowledge graphs into smaller subgraphs, fine-tuning adapter modules for each subgraph, and combining the knowledge in a fusion layer. We test the performance on three downstream tasks: document classification, question answering, and natural language inference. We show that our methodology leads to performance improvements in several instances while keeping requirements in computing power low. Finally, we provide a detailed interpretation of the results and report valuable insights for future work. © 2024 by SCITEPRESS – Science and Technology Publications, Lda.},
	author_keywords = {Adapters; Biomedical NLP; Biomedicine; Domain Knowledge; Knowledge Enhancement; Knowledge Graphs; Natural Language Processing (NLP); Pre-Trained Language Models},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Meng2024398,
	author = {Meng, Zaiqiao and Liang, Shangsong and Xin, Xin and Moro, Gianluca and Kanoulas, Evangelos and Yilmaz, Emine},
	title = {KEIR @ ECIR 2024: The First Workshop on Knowledge-Enhanced Information Retrieval},
	year = {2024},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14612 LNCS},
	pages = {398 – 402},
	doi = {10.1007/978-3-031-56069-9_53},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189291795&doi=10.1007%2f978-3-031-56069-9_53&partnerID=40&md5=0688a930a0fb0585503acf0614319899},
	abstract = {The infusion of external knowledge bases into IR models can provide enhanced ranking results and greater interpretability, offering substantial advancements in the field. The first workshop on Knowledge-Enhanced Information Retrieval (KEIR @ ECIR 2024) will serve as a platform to bring together researchers from academia and industry to explore and discuss various aspects of knowledge-enhanced information retrieval systems, such as models, techniques, data collection and evaluation. The workshop aims to not only deliberate upon the advantages and hurdles intrinsic to the development of knowledge-enhanced pretrained language models, IR models and recommendation models but also to facilitate in-depth discussions concerning the same. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2024.},
	author_keywords = {Information Retrieval; Knowledge Graph; Large Language Models; Recommendation System},
	keywords = {Computational linguistics; Information retrieval systems; Knowledge graph; Search engines; Data collection; Data evaluation; External knowledge; Information-retrieval systems; Interpretability; IR models; Knowledge graphs; Language model; Large language model; Modelling techniques; Recommender systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Schneider2024358,
	author = {Schneider, Phillip and Klettner, Manuel and Simperl, Elena and Matthes, Florian},
	title = {A Comparative Analysis of Conversational Large Language Models in Knowledge-Based Text Generation},
	year = {2024},
	journal = {EACL 2024 - 18th Conference of the European Chapter of the Association for Computational Linguistics, Proceedings of the Conference},
	volume = {2},
	pages = {358 – 367},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189927990&partnerID=40&md5=d533f72304001f6668aaf9a686db48cd},
	abstract = {Generating natural language text from graph-structured data is essential for conversational information seeking. Semantic triples derived from knowledge graphs can serve as a valuable source for grounding responses from conversational agents by providing a factual basis for the information they communicate. This is especially relevant in the context of large language models, which offer great potential for conversational interaction but are prone to hallucinating, omitting, or producing conflicting information. In this study, we conduct an empirical analysis of conversational large language models in generating natural language text from semantic triples. We compare four large language models of varying sizes with different prompting techniques. Through a series of benchmark experiments on the WebNLG dataset, we analyze the models’ performance and identify the most common issues in the generated predictions. Our findings show that the capabilities of large language models in triple verbalization can be significantly improved through few-shot prompting, post-processing, and efficient fine-tuning techniques, particularly for smaller models that exhibit lower zero-shot performance. © 2024 Association for Computational Linguistics.},
	keywords = {Benchmarking; Computational linguistics; Knowledge graph; Natural language processing systems; Zero-shot learning; Comparative analyzes; Conversational agents; Conversational interaction; Graph structured data; Information seeking; Knowledge based; Knowledge graphs; Language model; Natural languages texts; Text generations; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{Peng20232343,
	author = {Peng, Huang and Zeng, Weixin and Zhou, Jie and Tang, Jiuyang and Zhao, Xiang},
	title = {Contrast Research of Representation Learning in Entity Alignment Based on Graph Neural Network; [基于图神经网络的实体对齐表示学习方法比较研究]},
	year = {2023},
	journal = {Journal of Frontiers of Computer Science and Technology},
	volume = {17},
	number = {10},
	pages = {2343 – 2357},
	doi = {10.3778/j.issn.1673-9418.2307053},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184937524&doi=10.3778%2fj.issn.1673-9418.2307053&partnerID=40&md5=20679d394540b7a968509d66852fcc4f},
	abstract = {Entity alignment is an important step in knowledge fusion, which aims to identify equivalent entities in different knowledge graphs. In order to accurately determine the equivalent entities, the existing methods first perform representation learning to map the entities into a low-dimensional vector space, and then infer the equivalence of the entities by the similarity between the vectors. Recent works on entity alignment focus on the improvement of representation learning methods. In order to better understand the mechanism of these models, mine valuable design directions, and provide reference for subsequent optimization and improvement work, this paper reviews the research on representation learning methods for entity alignment. Firstly, based on the existing methods, a general framework for representation learning is proposed, and several representative works are summarized and analyzed. Then, these works are compared and analyzed through experiments, and the common methods of each module in the framework are compared. Through the results, the advantages and disadvantages of various methods are summarized, and the use suggestions are put forward. Finally, the feasibility of the alignment and fusion of large language models and knowledge graphs is preliminarily discussed, and the existing problems and challenges are analyzed. © 2023 Journal of Computer Engineering and Applications Beijing Co., Ltd.; Science Press. All rights reserved.},
	author_keywords = {entity alignment; graph neural network; knowledge fusion; large language model; representation learning},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Lehmann20231348,
	author = {Lehmann, Jens and Gattogi, Preetam and Bhandiwad, Dhananjay and Ferré, Sébastien and Vahdati, Sahar},
	title = {Language Models as Controlled Natural Language Semantic Parsers for Knowledge Graph Question Answering},
	year = {2023},
	journal = {Frontiers in Artificial Intelligence and Applications},
	volume = {372},
	pages = {1348 – 1356},
	doi = {10.3233/FAIA230411},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175792468&doi=10.3233%2fFAIA230411&partnerID=40&md5=65f6a98a35646164cc55e51d710f465d},
	abstract = {We propose the use of controlled natural language as a target for knowledge graph question answering (KGQA) semantic parsing via language models as opposed to using formal query languages directly. Controlled natural languages are close to (human) natural languages, but can be unambiguously translated into a formal language such as SPARQL. Our research hypothesis is that the pre-training of large language models (LLMs) on vast amounts of textual data leads to the ability to parse into controlled natural language for KGQA with limited training data requirements. We devise an LLM-specific approach for semantic parsing to study this hypothesis. To conduct our study, we created a dataset that allows the comparison of one formal and two different controlled natural languages. Our analysis shows that training data requirements are indeed substantially reduced when using controlled natural languages, which is relevant since collecting and maintaining high-quality KGQA semantic parsing training data is very expensive and time-consuming. © 2023 The Authors.},
	keywords = {Computational linguistics; Formal languages; Natural language processing systems; Quality control; Query languages; Semantics; Controlled natural language; Data requirements; Knowledge graphs; Language model; Natural language semantics; Natural languages; Pre-training; Question Answering; Semantic parsing; Training data; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{2024,
	title = {3rd International Conference on Ubiquitous Security, UbiSec 2023},
	year = {2024},
	journal = {Communications in Computer and Information Science},
	volume = {2034 CCIS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189618129&partnerID=40&md5=291068771a655196e7e9606fd724832d},
	abstract = {The proceedings contain 29 papers. The special focus in this conference is on Ubiquitous Security. The topics include: Impact of Library Code in Binary Similarity Systems; how Does Post-quantum Cryptography Affect Central Bank Digital Currency?; FRAD: Front-Running Attacks Detection on Ethereum Using Ternary Classification Model; a Comprehensive Survey of Attack Techniques, Implementation, and Mitigation Strategies in Large Language Models; process Mining with Programmable Logic Controller Memory States; honey-Gauge: Enabling User-Centric Honeypot Classification; Improving DNS Data Exfiltration Detection Through Temporal Analysis; deploying Post-quantum Algorithms in Existing Applications and Embedded Devices; SCORD: Shuffling Column-Oriented Relational Database to Enhance Security; A SLAHP in the Face of DLL Search Order Hijacking; poison Egg: Scrambling Federated Learning with Delayed Backdoor Attack; channel Spatio-Temporal Convolutional Network for Trajectory Prediction; multi-NetDroid: Multi-layer Perceptron Neural Network for Android Malware Detection; SmartBuoy: A Machine Learning-Based Detection Method for Interest Flooding Attacks in VNDN; loft: An Architecture for Lifetime Management of Privacy Data in Service Cooperation; privacy-Preserving Blockchain-Based Traceability System with Decentralized Ciphertext-Policy Attribute-Based Encryption; a Probability Mapping-Based Privacy Preservation Method for Social Networks; truFaaS - Trust Verification Framework for FaaS; detection of Cyberbullying in Social Media Texts Using Explainable Artificial Intelligence; privacy Preserving Elder Fall Detection Using Deep Learning; research on Authorization Model of Attribute Access Control Based on Knowledge Graph; simulation of Mixmining Reward Parameters for the Nym Mixnet; blockchain-Based Privacy-Preservation Platform for Data Storage and Query Processing; is It Really You Who Forgot the Password? When Account Recovery Meets Risk-Based Authentication; a Unified Knowledge Graph to Permit Interoperability of Heterogenous Digital Evidence; SMARPchain: A Smart Marker Based Reputational Probabilistic Blockchain for Multi-agent Systems; Automatically Inferring Image Base Addresses of ARM32 Binaries Using Architecture Features.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{2023,
	title = {K-CAP 2023 - Proceedings of the 12th Knowledge Capture Conference 2023},
	year = {2023},
	journal = {K-CAP 2023 - Proceedings of the 12th Knowledge Capture Conference 2023},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180571997&partnerID=40&md5=ea2ec399f08e94f4d3298eb7a5a11382},
	abstract = {The proceedings contain 33 papers. The topics discussed include: knowledge engineering for hybrid intelligence; annotation and extraction of industrial procedural knowledge from textual documents; procedural text mining with large language models; automatic topic label generation using conversational models; fine-grained and complex food entity recognition benchmark for ingredient substitution; a neuro-symbolic approach for anomaly detection and complex fault diagnosis exemplified in the automotive domain; finding concept representations in neural networks with self-organizing maps; capturing pertinent symbolic features for enhanced content-based misinformation detection; and do you catch my drift? on the usage of embedding methods to measure concept shift in knowledge graphs.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Zhou2023,
	author = {Zhou, Zhilun and Ding, Jingtao and Liu, Yu and Jin, Depeng and Li, Yong},
	title = {Towards Generative Modeling of Urban Flow through Knowledge-enhanced Denoising Diffusion},
	year = {2023},
	journal = {GIS: Proceedings of the ACM International Symposium on Advances in Geographic Information Systems},
	doi = {10.1145/3589132.3625641},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180602130&doi=10.1145%2f3589132.3625641&partnerID=40&md5=2f6db79702737ac760ac267cccbfdf8b},
	abstract = {Although generative AI has been successful in many areas, its ability to model geospatial data is still underexplored. Urban flow, a typical kind of geospatial data, is critical for a wide range of applications from public safety and traffic management to urban planning. Existing studies mostly focus on predictive modeling of urban flow that predicts the future flow based on historical flow data, which may be unavailable in data-sparse areas or newly planned regions. Some other studies aim to predict OD flow among regions but they fail to model dynamic changes of urban flow over time. In this work, we study a new problem of urban flow generation that generates dynamic urban flow for regions without historical flow data. To capture the effect of multiple factors on urban flow, such as region features and urban environment, we employ diffusion model to generate urban flow for regions under different conditions. We first construct an urban knowledge graph (UKG) to model the urban environment and relationships between regions, based on which we design a knowledge-enhanced spatio-temporal diffusion model (KSTDiff) to generate urban flow for each region. Specifically, to accurately generate urban flow for regions with different flow volumes, we design a novel diffusion process guided by a volume estimator, which is learnable and customized for each region. Moreover, we propose a knowledge-enhanced denoising network to capture the spatio-temporal dependencies of urban flow as well as the impact of urban environment in the denoising process. Extensive experiments on four real-world datasets validate the superiority of our model over state-of-the-art baselines in urban flow generation. Further in-depth studies demonstrate the utility of generated urban flow data and the ability of our model for long-term flow generation and urban flow prediction. Our code is released at: https://github.com/tsinghua-fib-lab/KSTDiff-Urban-flow-generation.  © 2023 ACM.},
	author_keywords = {diffusion model; generative model; knowledge graph; urban flow},
	keywords = {Flow graphs; Knowledge graph; Urban planning; De-noising; Diffusion model; Flow data; Flowthrough; Generative model; Geo-spatial data; Knowledge graphs; Public safety; Urban environments; Urban flow; Diffusion},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; All Open Access, Bronze Open Access, Green Open Access}
}

@CONFERENCE{2023,
	title = {Proceedings of the Inaugural 2023 Summer Symposium Series 2023},
	year = {2023},
	journal = {Proceedings of the Inaugural 2023 Summer Symposium Series 2023},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175435243&partnerID=40&md5=29762508958de61fe7246c01d0f4798f},
	abstract = {The proceedings contain 31 papers. The topics discussed include: an application for mental health monitoring using facial, voice, and questionnaire information; progressive 3D reconstruction for collaborative construction of digital twins; your memory palace in the metaverse with AI; a portable vision-based head tracking exergame solution for neck rehabilitation; multilingual aphasia speech analysis with machine learning; PNP: a review framework towards efficient NeRF study and research; taming diffusion models for music-driven conducting motion generation; evolutionary neural networks for option pricing: multi-assets option and exotic option; constructing and interpreting causal knowledge graphs from news; and taming simulators: challenges, pathways and vision for the alignment of large language models.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Tew2024,
	author = {Tew, Yishen and Fu, Ling and Li, Jing and Sun, Tianrui and Li, Lanyu and Wang, Xiaonan},
	title = {Construction of Knowledge Graph for Material and Energy Flow Integration in Biochemical Industry},
	year = {2024},
	journal = {Energy Proceedings},
	volume = {44},
	doi = {10.46855/energy-proceedings-11062},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190366728&doi=10.46855%2fenergy-proceedings-11062&partnerID=40&md5=cff3a5e06a37feafc76f62650334d40b},
	abstract = {Amid the escalating concerns of climate change and the mounting research papers on carbon neutrality and waste-to-energy solutions, comprehending crucial knowledge and technological trends in the chemical and energy sectors has become challenging. This study presents a novel approach combining large language models (LLM) and knowledge graphs (KG) to facilitate AI-supported knowledge retrieval. This work establishes a knowledge graph in the biochemical industry with 6,461 nodes and 8,969 relationships, emphasizing material and energy flow integration with the autonomous AI workflow. The graph's node attributes and relationships are analyzed using cosine similarities, with the capability to trace back to original literature through DOIs. This method not only underscores the relevance of node pairs in the graph but also links their similarities to the physical and chemical properties of materials. To sum up, this work provides an AI-enhanced tool that enables researchers and decision-makers to quickly build a knowledge base, learn about trends, and gain insights into specific fields. © 2024, Scanditale AB. All rights reserved.},
	author_keywords = {interpretability; knowledge graph; material flow integration; natural language processing; sustainable development},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Green Open Access}
}

@ARTICLE{Faiz202411133,
	author = {Faiz, Mehwish and Khan, Saad Jawaid and Azim, Fahad and Ejaz, Nazia},
	title = {Disclosing the locale of transmembrane proteins within cellular alcove by machine learning approach: systematic review and meta analysis},
	year = {2024},
	journal = {Journal of Biomolecular Structure and Dynamics},
	volume = {42},
	number = {20},
	pages = {11133 – 11148},
	doi = {10.1080/07391102.2023.2260490},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172448189&doi=10.1080%2f07391102.2023.2260490&partnerID=40&md5=4c24027018976f20185ad4503e3f2ff4},
	abstract = {Protein subcellular localization is a promising research question in Proteomics and associated fields, including Biological Sciences, Biomedical Engineering, Computational Biology, Bioinformatics, Proteomics, Artificial Intelligence, and Biophysics. However, computational techniques are preferred to explore this attribute for a massive number of proteins. The byproduct of this conjunction yields diversified location identifiers of proteins. These protein subcellular localization identifiers are unique regarding the database used, organisms, Machine Learning Technique, and accuracy. Despite the availability of these identifiers, the majority of the work has been done on the subcellular localization of proteins and, less work has been done specifically on locations of transmembrane proteins. This systematic review accounts for computational techniques implemented on transmembrane protein localization. Moreover, a literature search on PubMed, Science Direct, and IEEE Databases disclosed no systematic review or meta-analysis on the cell’s transmembrane protein locale. A Systematic review was formed under the guidelines of PRISMA by using Science Direct, PubMed, and IEEE Databases. Journal publications from 2000 to 2023 were taken into consideration and screened. This review has focused only on computational studies rather than experimental techniques. 1004 studies were reviewed and were categorized as relevant and non-relevant according to inclusion and exclusion criteria. All the screening was done through Endnote after importing citations. This systematic review characterizes the gap in targeting the locale of the transmembrane protein and will aid researchers in exploring its new horizons. Communicated by Ramaswamy H. Sarma. © 2023 Informa UK Limited, trading as Taylor & Francis Group.},
	author_keywords = {accuracy; deep learning; location; machine learning; Protein},
	keywords = {Cell Membrane; Computational Biology; Humans; Machine Learning; Membrane Proteins; Proteomics; membrane protein; accuracy; amino acid composition; amino acid sequence; artificial intelligence; artificial neural network; cells; cellular alcove; convolutional neural network; data base; feature extraction; gene ontology; human; IEEE Database; information; k nearest neighbor; large language model; machine learning; Medline; meta analysis; Preferred Reporting Items for Systematic Reviews and Meta-Analyses; protein localization; protein protein interaction; proteomics; random forest; Review; ScienceDirect; screening; Sequential evolutionary information; support vector machine; systematic review; bioinformatics; cell membrane; metabolism; procedures},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{2024,
	title = {IRCDL 2024 - Proceedings of the 20th Conference on Information and Research Science Connecting to Digital and Library Science},
	year = {2024},
	journal = {CEUR Workshop Proceedings},
	volume = {3643},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188207790&partnerID=40&md5=0931328b4827c15960530931add73c43},
	abstract = {The proceedings contain 23 papers. The topics discussed include: building and exploiting a web of machine-readable scientific facts to make discoveries; publishing CoreKB facts as nanopublications; exploiting large language models to train automatic detectors of sensitive data; evaluating differential privacy approaches for information retrieval; evaluation of expressing without asserting approaches in RDF. the case of conjectures; a holistic ontology for digital libraries; a tool for empowering symbol detection through technological integration in library science. a case study on the Voynich manuscript; Ontofest: an ontology to integrate and retrieve data from the Locarno film festival archives; a novel methodology for topic identification in hadith; and research and teaching public communication of science and technology on digital data.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Lin2023978,
	author = {Lin, Shiyong and Yuan, Yiping and Jin, Carol and Pan, Yi},
	title = {Skill Graph Construction From Semantic Understanding},
	year = {2023},
	journal = {ACM Web Conference 2023 - Companion of the World Wide Web Conference, WWW 2023},
	pages = {978 – 982},
	doi = {10.1145/3543873.3587667},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85159640603&doi=10.1145%2f3543873.3587667&partnerID=40&md5=d267435bba1c0b1e2e5e7e06ae12c00e},
	abstract = {LinkedIn is building a skill graph to power a skill-first talent marketplace. Constructing a skill graph from a flat list is not an trivial task, especially by human curation. In this paper, we leverage the pre-trained large language model BERT to achieve this through semantic understanding on synthetically generated texts as training data. We automatically create positive and negative labels from the seed skill graph. The training data are encoded by pre-trained language models into embeddings and they are consumed by the downstream classification module to classify the relationships between skill pairs.  © 2023 ACM.},
	author_keywords = {knowledge graph; link prediction; NLP},
	keywords = {Classification (of information); Computational linguistics; Semantics; Embeddings; Graph construction; Human curation; Knowledge graphs; Language model; Link prediction; LinkedIn; Power; Semantics understanding; Training data; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Khatun2023,
	author = {Khatun, Rabina and Sinhababu, Nilanjan},
	title = {Improved Sequence Predictions using Knowledge Graph Embedding for Large Language Models},
	year = {2023},
	journal = {ACM International Conference Proceeding Series},
	doi = {10.1145/3639856.3639872},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85194825117&doi=10.1145%2f3639856.3639872&partnerID=40&md5=09563cd7dfe5b5c0c04d6175db2cb32c},
	abstract = {Large Language Models (LLM) have gained huge popularity recently due to their problem-solving capability in multiple domains. Technically LLMs can be considered a critical mixture of huge amounts of training data, smart and exhaustive prompt engineering, and word prediction models along with Reinforcement and Supervised learning mechanisms. Word prediction models are at the core of any Large Language Model. The latest word prediction techniques are sequential and transformer models. Transformers have overcome most of the drawbacks of sequential models with similar embedding knowledge. The literature survey shows little to no improvement in the embedding techniques. In this paper, we examined the existing word prediction models by replacing embedding models with an auto-engineered Knowledge Graph Embedding. This auto-engineered data representation shows drastic improvements in prediction quality. This mechanism also accelerates the prediction by providing more context information to the models with respect to the general embedding mechanism. Standard evaluation strategies are used to compare the model behavior.  © 2023 ACM.},
	author_keywords = {attention mechanisms; generative models; neural networks; text prediction},
	keywords = {Computational linguistics; Forecasting; Graph embeddings; Attention mechanisms; Embeddings; Generative model; Graph embeddings; Knowledge graphs; Language model; Neural-networks; Prediction modelling; Text prediction; Word prediction; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}@CONFERENCE{De Bellis2023,
	author = {De Bellis, Alessandro},
	title = {Structuring the unstructured: an LLM-guided transition},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3678},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192734164&partnerID=40&md5=e8648811694849105191763866f59732},
	abstract = {The surge of interest in Large Language Models (LLM) has reached unprecedented levels of magnitude in the last year. Following the success of ChatGPT, a powerful conversational system powered by an LLM, both specialized and non-specialized users have started to leverage the efficacy of these systems. If this trend is to be maintained, it is reasonable to predict an ever more ubiquitous role for LLMs in our daily life. Nonetheless, the widespread adoption of LLMs in various applicative fields remains an ongoing challenge. In order to achieve competitive levels of performance in specialized tasks, LLMs can require complex fine-tuning procedures and high-quality data. Furthermore, LLMs are scarcely interpretable and often viewed as "black boxes". This proposal aims to lessen the gray areas around the subject of LLMs and shed some light on which kind of information they store internally. Specifically, the goal is to assess the ability of LLMs to model external semantic knowledge about concepts encoded from unstructured text, by means of their latent representations. The proposal aims to explore existing patterns in the latent space that convey explicit information about taxonomical information and relational connections between concepts, and that can therefore reflect the knowledge encoded by a Knowledge Graph. The resulting knowledge could be exploited to enable complex downstream tasks leveraging factual knowledge and aimed to deduce new structured information, possibly in zero-shot or few-shot settings. © 2023 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).},
	author_keywords = {Information Extraction; Knowledge Graphs; Large Language Models},
	keywords = {Computational linguistics; Knowledge management; Semantics; Zero-shot learning; Black boxes; Conversational systems; Daily lives; Fine tuning; High quality data; Information extraction; Knowledge graphs; Language model; Large language model; Performance; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Yang20231122,
	author = {Yang, Yangrui and Zhu, Yaping and Chen, Sisi and Liu, Xuemei and Li, Huimin},
	title = {Application of AI chain integrating crowd intelligence strategy in flood control knowledge inference; [融合群体智能策略的 ＡＩ 链在大坝防汛抢险知识推理中的应用]},
	year = {2023},
	journal = {Shuili Xuebao/Journal of Hydraulic Engineering},
	volume = {54},
	number = {9},
	pages = {1122 – 1132},
	doi = {10.13243/j.cnki.slxb.20230188},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181584955&doi=10.13243%2fj.cnki.slxb.20230188&partnerID=40&md5=102929aae505f8535139a01053454a11},
	abstract = {Flood control knowledge (entities and relationships) is an essential component of the flood control and rescue business knowledge graph. The complex relationships among flood control entities are distributed in unstructured text, and the scarcity and low quality of available texts pose challenges to knowledge extraction in this field. In response, a novel approach is proposed to use large language models to complete flood control and rescue knowledge inference (F C R K I) . Based on LLMs, three sub-modules are designed; flood control entity extractor, flood control entity knowdedge parser, and flood control inter - entity relationship decider. A series of effective task prompts are designed and connected to form an AI chain. The flood control knowdedge inference task is gradually completed through real-time interaction between the prompts and LLMs in the AI chain. Furthermore, a swarm intelligence strategy is designed to enhance the reliability of flood control inter—entity relationship inference. Comparing FCRKI with existing methods, experimental results show that FCRKI has a higher accuracy in inferring relationships between flood control entities, verifying the effectiveness of the AI chain and swarm intelligence strategy. This new knowdedge extraction paradigm provides a novel solution for intelligent processing of hydraulic engineering texts. © 2023 China Water Power Press. All rights reserved.},
	author_keywords = {AI chain; crowd intelligence strategy; flood control knowdedge graph; flood control knowledge inference},
	keywords = {Data mining; Extraction; Quality control; Swarm intelligence; AI chain; Applications of AI; Business knowledge; Complex relationships; Crowd intelligence strategy; Entity-relationship; Flood control knowdedge graph; Flood control knowledge inference; Knowledge graphs; Unstructured texts; Flood control},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{2023,
	title = {ISWC-Posters-Demos-Industry 2023 - Proceedings of the ISWC 2023 Posters, Demos and Industry Tracks: From Novel Ideas to Industrial Practice, co-located with 22nd International Semantic Web Conference, ISWC 2023},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3632},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184588070&partnerID=40&md5=b9cba7059d8f6b8243e55dd41e8288df},
	abstract = {The proceedings contain 70 papers. The topics discussed include: towards algebraic mapping operators for knowledge graph construction; economics assistant for robustness checks (EconARC): identifying confounders from causal knowledge graphs; exploring large language models for ontology alignment; correlating eye gaze with object to enrich cultural heritage knowledge graph; towards data integrity verification for more sustainable petroleum industry; towards statistical reasoning with ontology embeddings; schema.org: how is it used?; exploring large language models as a source of common-sense knowledge for robots; ASKG: an approach to enrich scholarly knowledge graphs through paper decomposition with deep learning; and towards preserving biodiversity using nature FIRST knowledge graph with crossovers.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{2023,
	title = {Proceedings - 2023 International Conference on Computing, Networking, Telecommunications and Engineering Sciences Applications, CoNTESA 2023},
	year = {2023},
	journal = {Proceedings - 2023 International Conference on Computing, Networking, Telecommunications and Engineering Sciences Applications, CoNTESA 2023},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184122281&partnerID=40&md5=e0f0d22d06ab044b71217255b47a42cd},
	abstract = {The proceedings contain 15 papers. The topics discussed include: application of LSTM network to predict InSAR-derived time-series deformation in the reclamation area of Busan, South Korea; generative AI: impactful considerations to responsible data practices in business execution; towards swarm intelligence ontology for formal description of metaheuristics algorithms; generating CGAN-based synthetic dermoscopy images and classifying with deep lightweight CNN; DesignSystemsJS - building a design systems API for aiding standardization and AI integration; availability of NETCONF training and documentation; teaching information literacy and critical thinking skills in ChatGPT time; six sigma: designing of a new product for an ISO 9001 certified company; and a comparative review of GPT-4’s applications in medicine and high decision making.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Qi20236932,
	author = {Qi, Chengwen and Li, Bowen and Hui, Binyuan and Wang, Bailin and Li, Jinyang and Wu, Jinwang and Laili, Yuanjun},
	title = {An Investigation of LLMs' Inefficacy in Understanding Converse Relations},
	year = {2023},
	journal = {EMNLP 2023 - 2023 Conference on Empirical Methods in Natural Language Processing, Proceedings},
	pages = {6932 – 6953},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182435991&partnerID=40&md5=0039cab34f070f2cde3c6d1a32d220dd},
	abstract = {Large Language Models (LLMs) have achieved remarkable success in many formal language oriented tasks, such as structural data-to-text and semantic parsing. However current benchmarks mostly follow the data distribution of the pre-training data of LLMs. Therefore, a natural question rises that do LLMs really understand the structured semantics of formal languages. In this paper, we investigate this problem on a special case, converse binary relation. We introduce a new benchmark ConvRe focusing on converse relations, which contains 17 relations and 1240 triples extracted from popular knowledge graph completion datasets. Our ConvRe features two tasks, Re2Text and Text2Re, which are formulated as multi-choice question answering to evaluate LLMs' ability to determine the matching between relations and associated text. For the evaluation protocol, apart from different prompting methods, we further introduce variants to the test text and few-shot example text. We conduct experiments on three popular LLM families and have observed various scaling trends. The results suggest that LLMs often resort to shortcut learning and still face challenges on our proposed benchmark. © 2023 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Knowledge graph; Natural language processing systems; Semantics; 'current; Binary relation; Data distribution; Knowledge graphs; Language model; Pre-training; Semantic parsing; Structural data; Text parsing; Training data; Formal languages},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Huang2023499,
	author = {Huang, Fei and Deng, Yi and Zhang, Chen and Guo, Menghao and Zhan, Kai and Sun, Shanxin and Jiang, Jinling and Sun, Zeyi and Wu, Xindong},
	title = {KOSA: KO Enhanced Salary Analytics based on Knowledge Graph and LLM Capabilities},
	year = {2023},
	journal = {IEEE International Conference on Data Mining Workshops, ICDMW},
	pages = {499 – 505},
	doi = {10.1109/ICDMW60847.2023.00071},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186139735&doi=10.1109%2fICDMW60847.2023.00071&partnerID=40&md5=b9bdefe0caf5c1a1429fa8d1d70b1b38},
	abstract = {Knowledge base question answering (KBQA) is designed to respond to natural language inquiries by utilizing factual information, such as entities, relationships, and attributes, derived from a knowledge base (KB). The advent of large language models (LLMs) has significantly boosted the performance of KBQA, owing to their exceptional capabilities in content comprehension and generation. In this paper, we present a Knowledge Ocean enhanced Salary Analytics (KOSA) system based on knowledge graphs and LLMs tailored to employee salary data from a public university. This system encompasses an interactive conversational interface, visualization of knowledge graphs, and advanced data analysis. By employing the framework of knowledge engineering, we enable knowledge graph modeling, Cypher (the query engine of Neo4j) reasoning, and question answering functionalities. Furthermore, machine learning algorithms are integrated to facilitate advanced features, such as salary prediction and allocation. © 2023 IEEE.},
	author_keywords = {KBQA; Knowledge Engineering; LLM; Salary distribution},
	keywords = {Data visualization; Learning algorithms; Machine learning; Natural language processing systems; Entity-relationship; Factual information; Knowledge base question answering; Knowledge graphs; Language model; Large language model; Natural languages; Performance; Question Answering; Salary distributions; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Conia20231612,
	author = {Conia, Simone and Minhas, Umar Farooq and Li, Min and Ilyas, Ihab and Lee, Daniel and Li, Yunyao},
	title = {Increasing Coverage and Precision of Textual Information in Multilingual Knowledge Graphs},
	year = {2023},
	journal = {EMNLP 2023 - 2023 Conference on Empirical Methods in Natural Language Processing, Proceedings},
	pages = {1612 – 1634},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184824790&partnerID=40&md5=d35b9b6be4c24654571ed83b5f9fc1ef},
	abstract = {Recent work in Natural Language Processing and Computer Vision has been using textual information - e.g., entity names and descriptions - available in knowledge graphs to ground neural models to high-quality structured data. However, when it comes to non-English languages, the quantity and quality of textual information are comparatively scarce. To address this issue, we introduce the novel task of automatic Knowledge Graph Enhancement (KGE) and perform a thorough investigation on bridging the gap in both the quantity and quality of textual information between English and non-English languages. More specifically, we: i) bring to light the problem of increasing multilingual coverage and precision of entity names and descriptions in Wikidata; ii) demonstrate that state-of-the-art methods, namely, Machine Translation (MT), Web Search (WS), and Large Language Models (LLMs), struggle with this task; iii) present M-NTA, a novel unsupervised approach that combines MT, WS, and LLMs to generate high-quality textual information; and, iv) study the impact of increasing multilingual coverage and precision of non-English textual information in Entity Linking, Knowledge Graph Completion, and Question Answering. As part of our effort towards better multilingual knowledge graphs, we also introduce WikiKGE-10, the first human-curated benchmark to evaluate KGE approaches in 10 languages across 7 language families. ©2023 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Computer aided language translation; Machine translation; Natural language processing systems; High quality; Knowledge graphs; Language model; Language processing; Machine translations; Natural languages; Neural modelling; Non-English languages; Textual information; Web searches; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7}
}

@CONFERENCE{Li2023589,
	author = {Li, Yujiao and He, Yanluo and Lian, Runze and Guo, Qiuquan},
	title = {Fault Diagnosis and System Maintenance Based on Large Language Models and Knowledge Graphs},
	year = {2023},
	journal = {2023 5th International Conference on Robotics, Intelligent Control and Artificial Intelligence, RICAI 2023},
	pages = {589 – 592},
	doi = {10.1109/RICAI60863.2023.10489566},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190939681&doi=10.1109%2fRICAI60863.2023.10489566&partnerID=40&md5=4d5f263a1cda572de6144fbba498ebc9},
	abstract = {The continuous development of Large Language Models (LLMs) has driven a new round of technological change, and for the specialized fields, LLMs have been criticized by their 'hallucination'. To this end, we propose a framework for applying LLMs to specialized fields. Specifically, the main work includes constructing Knowledge Graphs (KGs) and fine-tuning datasets for industrial fields fine-tuning and deploying LLMs. As well as combining multimodal data to construct more detailed prompts for inference, and realizing multi-hop inference with the help of KGs when necessary. This study takes Computer Numerical Control (CNC) machine tools as an example, by using this framework, effective fault prediction can be performed and reliable maintenance recommendations can be provided to effectively avoid and minimize the losses caused by equipment faults, and improve productivity and efficiency. © 2023 IEEE.},
	author_keywords = {Computer Numerical Control (CNC) machine tools; Knowledge Graphs; Large Language Models; Multi-hop Inference},
	keywords = {Computational linguistics; Computer control systems; Knowledge graph; Computer numerical control  machine tool; Computer numerical control machines; Faults diagnosis; Fine tuning; Knowledge graphs; Language model; Large language model; Multi-hop inference; Multi-hops; Numerical control machine tool; Machine tools},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Sheng2023,
	author = {Sheng, Jinghua},
	title = {An Augmentable Domain-specific Models for Financial Analysis},
	year = {2023},
	journal = {Proceedings - 2023 16th International Congress on Image and Signal Processing, BioMedical Engineering and Informatics, CISP-BMEI 2023},
	doi = {10.1109/CISP-BMEI60920.2023.10373245},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183315038&doi=10.1109%2fCISP-BMEI60920.2023.10373245&partnerID=40&md5=56b43bcf9f0e6b428eadab39e6baf2ec},
	abstract = {Large-scale language models such as GPT-4 have revolutionized data analysis and interpretation by generating human-like text, automating insights, and detecting data errors. Large-scale language models have been applied in various fields and played an important role in many aspects. Large language models can also perform financial and technical analysis by cleaning data, generating synthetic data, handling bias, and supporting natural language queries. This paper proposes a language model that integrates multimodal data with external knowledge bases and domain-specific data, enhancing its reasoning ability by extending domain-specific data. Reduce hallucinations and fine-tune domain-specific data by incorporating external knowledge bases to deepen model understanding of industry-specific language, concepts, and context. And technologies such as knowledge graph, attention mechanism, cross-modal embedding and federated collaborative training are used to deal with the challenges of different structures and semantics of multi-modal data. The model also employs a feedback loop mechanism to allow the model to adapt to changing conditions, such as changing languages or new domain information. Experimental results show that the proposed model has a preliminary domain-specific ability to analyze and predict multimodal financial and technical data. © 2023 IEEE.},
	author_keywords = {domain-specific data; external knowledge; financial and technical analysis; knowledge graph; Large-scale language models},
	keywords = {Computational linguistics; Data handling; Finance; Knowledge graph; Modal analysis; Natural language processing systems; Domain specific; Domain-specific data; External knowledge; Financial analysis; Knowledge graphs; Language model; Large-scale language model; Large-scales; Multi-modal data; Technical analysis; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Salmas2023,
	author = {Salmas, Konstantinos and Pantazi, Despina-Athanasia and Koubarakis, Manolis},
	title = {Extracting Geographic Knowledge from Large Language Models: An Experiment},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3577},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179546460&partnerID=40&md5=0fd90a6d6edc446515886a7202960882},
	abstract = {We perform an experimental analysis of how the inner architecture of large language models behaves whilst extracting geographic knowledge. Our aim is to conclude on whether models actually incorporate geospatial information or simply follow statistical patterns in the data; hence to contribute to the research area of creating knowledge graphs from large language models. To achieve this, we study one specific geospatial relation and explore different techniques that leverage the masked language modeling abilities of BERT and RoBERTa. Our study should be construed as a stepping stone to the general study of the ways large language models encapsulate geospatial knowledge. In addition, it has allowed us to observe important points one should focus on when querying language models, which we discuss in detail. © 2023 CEUR-WS. All rights reserved.},
	author_keywords = {geospatial data; geospatial knowledge; knowledge graphs; large language models},
	keywords = {Data mining; Knowledge graph; Knowledge management; Modeling languages; Experimental analysis; Geo-spatial; Geo-spatial data; Geographics; Geospatial information; Geospatial knowledge; Knowledge graphs; Language model; Large language model; Statistical pattern; Computational linguistics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Lee2023544,
	author = {Lee, Dong-Ho and Ahrabian, Kian and Jin, Woojeong and Morstatter, Fred and Pujara, Jay},
	title = {Temporal Knowledge Graph Forecasting Without Knowledge Using In-Context Learning},
	year = {2023},
	journal = {EMNLP 2023 - 2023 Conference on Empirical Methods in Natural Language Processing, Proceedings},
	pages = {544 – 557},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182442697&partnerID=40&md5=8ef89e61d4e4e7a0830d480e90a24824},
	abstract = {Temporal knowledge graph (TKG) forecasting benchmarks challenge models to predict future facts using knowledge of past facts. In this paper, we develop an approach to use in-context learning (ICL) with large language models (LLMs) for TKG forecasting. Our extensive evaluation compares diverse baselines, including both simple heuristics and state-of-the-art (SOTA) supervised models, against pre-trained LLMs across several popular benchmarks and experimental settings. We observe that naive LLMs perform on par with SOTA models, which employ carefully designed architectures and supervised training for the forecasting task, falling within the (-3.6%, +1.5%) Hits@1 margin relative to the median performance. To better understand the strengths of LLMs for forecasting, we explore different approaches for selecting historical facts, constructing prompts, controlling information propagation, and parsing outputs into a probability distribution. A surprising finding from our experiments is that LLM performance endures (±0.4% Hit@1) even when semantic information is removed by mapping entities/relations to arbitrary numbers, suggesting that prior semantic knowledge is unnecessary; rather, LLMs can leverage the symbolic patterns in the context to achieve such a strong performance. Our analysis also reveals that ICL enables LLMs to learn irregular patterns from the historical context, going beyond frequency and recency biases. ©2023 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Information dissemination; Knowledge graph; Knowledge management; Probability distributions; Semantics; ART model; Context learning; In contexts; Knowledge graphs; Language model; Performance; Simple heuristics; State of the art; Supervised trainings; Temporal knowledge; Forecasting},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6}
}

@CONFERENCE{Zhou20234755,
	author = {Zhou, Zongzhen and Yang, Tao and Hu, Kongfa},
	title = {Traditional Chinese Medicine Epidemic Prevention and Treatment Question-Answering Model Based on LLMs},
	year = {2023},
	journal = {Proceedings - 2023 2023 IEEE International Conference on Bioinformatics and Biomedicine, BIBM 2023},
	pages = {4755 – 4760},
	doi = {10.1109/BIBM58861.2023.10385748},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184871926&doi=10.1109%2fBIBM58861.2023.10385748&partnerID=40&md5=4fb66f71868a57e77ce600dc0b5ef89e},
	abstract = {Background: Epidemic diseases in Traditional Chinese Medicine (TCM) constitute an essential part of Chinese medical science. TCM has accumulated rich theoretical and practical experiences in the prevention and treatment of epidemic diseases, forming the academic system of epidemic febrile disease, providing robust support for epidemic prevention and resistance in TCM. However, the numerous and complex literature on TCM epidemic diseases brings challenges to the organization and discovery of epidemic disease knowledges. Objective: To leverage the powerful knowledge learning ability of state-of-the-art LLMs (LLMs) to address the efficient acquisition and utilization of TCM epidemic disease knowledges. Methods: By collecting content related to epidemic diseases from 194 ancient TCM books, as well as the knowledge graph of TCM epidemic disease prevention and treatment, we built the large TCM epidemic disease model EpidemicCHAT based on the ChatGLM model. To assess the performances of the model, several open-source LLMs were compared in the study. Results: Compared to traditional LLMs, which may fail to answer or produce hallucinations in the field of TCM epidemic diseases, EpidemicCHAT demonstrates superior answering and reasoning abilities. In the evaluation of TCM epidemic disease prescription generation, the model achieved scores of 44.02, 61.10, and 59.40 on the BLEU-4, ROUGE-L, and METEOR metrics, respectively. Conclusion: The EpidemicCHAT model proposed in this study performs excellently in the field of TCM epidemic diseases, which might provide a reference for the construction of TCM LLMs and applications such as TCM auxiliary diagnosis and Chinese herbal prescription generation.  © 2023 IEEE.},
	author_keywords = {epidemic; knowledge graph; LLMs; traditional Chinese medicine},
	keywords = {Diseases; Knowledge graph; Knowledge management; Academic system; Epidemic; Epidemic disease; Knowledge graphs; LLM; Medical science; Model-based OPC; Practical experience; Question Answering; Traditional Chinese Medicine; Diagnosis},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5}
}

@CONFERENCE{Nanwani2023507,
	author = {Nanwani, Laksh and Agarwal, Anmol and Jain, Kanishk and Prabhakar, Raghav and Monis, Aaron and Mathur, Aditya and Jatavallabhula, Krishna Murthy and Abdul Hafez, A.H. and Gandhi, Vineet and Krishna, K. Madhava},
	title = {Instance-Level Semantic Maps for Vision Language Navigation},
	year = {2023},
	journal = {IEEE International Workshop on Robot and Human Communication, RO-MAN},
	pages = {507 – 512},
	doi = {10.1109/RO-MAN57019.2023.10309534},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187015327&doi=10.1109%2fRO-MAN57019.2023.10309534&partnerID=40&md5=bc506309b5d4d028a43c976c2653eee5},
	abstract = {Humans have a natural ability to perform semantic associations with the surrounding objects in the environment. This allows them to create a mental map of the environment, allowing them to navigate on-demand when given linguistic instructions. A natural goal in Vision Language Navigation (VLN) research is to impart autonomous agents with similar capabilities. Recent works take a step towards this goal by creating a semantic spatial map representation of the environment without any labeled data. However, their representations are limited for practical applicability as they do not distinguish between different instances of the same object. In this work, we address this limitation by integrating instance-level information into spatial map representation using a community detection algorithm and utilizing word ontology learned by large language models (LLMs) to perform open-set semantic associations in the mapping representation. The resulting map representation improves the navigation performance by two-fold (233%) on realistic language commands with instance-specific descriptions compared to the baseline. We validate the practicality and effectiveness of our approach through extensive qualitative and quantitative experiments. © 2023 IEEE.},
	keywords = {Autonomous agents; Semantics; Community detection algorithms; Labeled data; Language model; Map representations; Mental maps; On demands; Ontology's; Semantic associations; Semantic map; Spatial maps; Navigation},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Green Open Access}
}

@CONFERENCE{Taffa2023,
	author = {Taffa, Tilahun Abedissa and Usbeck, Ricardo},
	title = {Leveraging LLMs in Scholarly Knowledge Graph Question Answering},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3592},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180546080&partnerID=40&md5=ccf7f534c71dcf553c48378d6818a7ee},
	abstract = {This paper presents a scholarly Knowledge Graph Question Answering (KGQA) that answers bibliographic natural language questions by leveraging a large language model (LLM) in a few-shot manner. The model initially identifies the top-n similar training questions related to a given test question via a BERT-based sentence encoder and retrieves their corresponding SPARQL. Using the top-n similar question-SPARQL pairs as an example and the test question creates a prompt. Then pass the prompt to the LLM and generate a SPARQL. Finally, runs the SPARQL against the underlying KG - ORKG (Open Research KG) endpoint and returns an answer. Our system achieves an F1 score of 99.0%, on SciQA - one of the Scholarly-QALD-23 challenge benchmarks. © 2023 CEUR-WS. All rights reserved.},
	author_keywords = {Knowledge Graph Question Answering (KGQA); Large Language Model; Open Research Knowledge Graph; ORKG; Scholarly KGQA; Scholarly-QALD; SciQA},
	keywords = {Computational linguistics; Knowledge management; Natural language processing systems; Knowledge graph question answering; Knowledge graphs; Language model; Large language model; Open research KG; Open research knowledge graph; Question Answering; Scholarly knowledge graph question answering; Scholarly-QALD; SciQA; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Yang20235705,
	author = {Yang, Chang and Zhang, Peng and Qiao, Wenbo and Gao, Hui and Zhao, Jiaming},
	title = {Rumor Detection on Social Media with Crowd Intelligence and ChatGPT-Assisted Networks},
	year = {2023},
	journal = {EMNLP 2023 - 2023 Conference on Empirical Methods in Natural Language Processing, Proceedings},
	pages = {5705 – 5717},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184816372&partnerID=40&md5=c45de9d7b294ca72d6a528027d39a7e2},
	abstract = {In the era of widespread dissemination through social media, the task of rumor detection plays a pivotal role in establishing a trustworthy and reliable information environment. Nonetheless, existing research on rumor detection confronts several challenges: the limited expressive power of text encoding sequences, difficulties in domain knowledge coverage and effective information extraction with knowledge graph-based methods, and insufficient mining of semantic structural information. To address these issues, we propose a Crowd Intelligence and ChatGPT-Assisted Network(CICAN) for rumor classification. Specifically, we present a crowd intelligence-based semantic feature learning module to capture textual content's sequential and hierarchical features. Then, we design a knowledge-based semantic structural mining module that leverages ChatGPT for knowledge enhancement. Finally, we construct an entity-sentence heterogeneous graph and design Entity-Aware Heterogeneous Attention to integrate diverse structural information meta-paths effectively. Experimental results demonstrate that CICAN achieves performance improvement in rumor detection tasks, validating the effectiveness and rationality of using large language models as auxiliary tools. © 2023 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Domain Knowledge; Graphic methods; Natural language processing systems; Social networking (online); Text processing; Domain knowledge; Expressive power; Feature learning; Graph-based methods; Information environment; Knowledge graphs; Semantic features; Social media; Structural information; Text encoding; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7}
}

@CONFERENCE{Hwang2023558,
	author = {Hwang, EunJeong and Thost, Veronika and Shwartz, Vered and Ma, Tengfei},
	title = {Knowledge Graph Compression Enhances Diverse Commonsense Generation},
	year = {2023},
	journal = {EMNLP 2023 - 2023 Conference on Empirical Methods in Natural Language Processing, Proceedings},
	pages = {558 – 572},
	doi = {10.18653/v1/2023.emnlp-main.37},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184817508&doi=10.18653%2fv1%2f2023.emnlp-main.37&partnerID=40&md5=42431a25397fd8806971546743ec0b04},
	abstract = {Generating commonsense explanations requires reasoning about commonsense knowledge beyond what is explicitly mentioned in the context. Existing models use commonsense knowledge graphs such as ConceptNet to extract a subgraph of relevant knowledge pertaining to concepts in the input. However, due to the large coverage and, consequently, vast scale of ConceptNet, the extracted subgraphs may contain loosely related, redundant and irrelevant information, which can introduce noise into the model. We propose to address this by applying a differentiable graph compression algorithm that focuses on more salient and relevant knowledge for the task. The compressed subgraphs yield considerably more diverse outputs when incorporated into models for the tasks of generating commonsense and abductive explanations. Moreover, our model achieves better quality-diversity tradeoff than a large language model with 100 times the number of parameters. Our generic approach can be applied to additional NLP tasks that can benefit from incorporating external knowledge. ©2023 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Data mining; Graph theory; Commonsense knowledge; Compression algorithms; ConceptNet; Generic approach; Graph compressions; Knowledge graphs; Knowledge pertaining; Language model; Model use; Subgraphs; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Shi2023515,
	author = {Shi, Yucheng and Ma, Hehuan and Zhong, Wenliang and Tan, Qiaoyu and Mai, Gengchen and Li, Xiang and Liu, Tianming and Huang, Junzhou},
	title = {ChatGraph: Interpretable Text Classification by Converting ChatGPT Knowledge to Graphs},
	year = {2023},
	journal = {IEEE International Conference on Data Mining Workshops, ICDMW},
	pages = {515 – 520},
	doi = {10.1109/ICDMW60847.2023.00073},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186137850&doi=10.1109%2fICDMW60847.2023.00073&partnerID=40&md5=8983eb4bc016e95c12e84cabb686049c},
	abstract = {ChatGPT, as a recently launched large language model (LLM), has shown superior performance in various natural language processing (NLP) tasks. However, two major limitations hinder its potential applications: 1) the inflexibility of finetuning on downstream tasks, and 2) the lack of interpretability in the decision-making process. To tackle these limitations, we propose a novel framework that leverages the power of ChatGPT for specific tasks, such as text classification, while improving its interpretability. The proposed framework conducts a knowledge graph extraction task to extract refined and structural knowledge from the raw data using ChatGPT. The rich knowledge is then converted into a graph, which is further used to train an interpretable linear classifier to make predictions. To evaluate the effectiveness of our proposed method, we conduct experiments on four benchmark datasets. The results demonstrate that our method can significantly improve the prediction performance compared to directly utilizing ChatGPT for text classification tasks. Furthermore, our method provides a more transparent decision-making process compared with previous text classification methods. The code is available at https://github.com/sycny/ChatGraph. © 2023 IEEE.},
	author_keywords = {Interpretability; Large Language Models; Text Classification},
	keywords = {Classification (of information); Computational linguistics; Decision making; Natural language processing systems; Text processing; Decision-making process; Down-stream; Interpretability; Language model; Language processing; Large language model; Natural languages; Performance; Power; Text classification; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8; All Open Access, Green Open Access}
}

@ARTICLE{Fatemi2023145386,
	author = {Fatemi, Bahareh and Rabbi, Fazle and Opdahl, Andreas L.},
	title = {Evaluating the Effectiveness of GPT Large Language Model for News Classification in the IPTC News Ontology},
	year = {2023},
	journal = {IEEE Access},
	volume = {11},
	pages = {145386 – 145394},
	doi = {10.1109/ACCESS.2023.3345414},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181543202&doi=10.1109%2fACCESS.2023.3345414&partnerID=40&md5=736a0a3be5737ac23440240ea35496f1},
	abstract = {News classification plays a vital role in newsrooms, as it involves the time-consuming task of categorizing news articles and requires domain knowledge. Effective news classification is essential for categorizing and organizing a constant flow of information, serving as the foundation for subsequent tasks, such as news aggregation, monitoring, filtering, and organization. The automation of this process can significantly benefit newsrooms by saving time and resources. In this study, we explore the potential of the GPT large language model in a zero-shot setting for multi-class classification of news articles within the widely accepted International Press Telecommunications Council (IPTC) news ontology. The IPTC news ontology provides a structured framework for categorizing news, facilitating the efficient organization and retrieval of news content. By investigating the effectiveness of the GPT language model in this classification task, we aimed to understand its capabilities and potential applications in the news domain. This study was conducted as part of our ongoing research in the field of automated journalism. © 2013 IEEE.},
	author_keywords = {IPTC media topics; journalism; large language models; news classification},
	keywords = {Classification (of information); Computational linguistics; Information filtering; Job analysis; Zero-shot learning; Adaptation models; Annotation; International press telecommunication council medium topic; International press telecommunications councils; Journalism; Language model; Large language model; News classification; Ontology's; Support vectors machine; Tag clouds; Task analysis; Ontology},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Tang20233893,
	author = {Tang, Yun and Da Costa, Antonio A. Bruto and Zhang, Xizhe and Patrick, Irvine and Khastgir, Siddartha and Jennings, Paul},
	title = {Domain Knowledge Distillation from Large Language Model: An Empirical Study in the Autonomous Driving Domain},
	year = {2023},
	journal = {IEEE Conference on Intelligent Transportation Systems, Proceedings, ITSC},
	pages = {3893 – 3900},
	doi = {10.1109/ITSC57777.2023.10422308},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186526218&doi=10.1109%2fITSC57777.2023.10422308&partnerID=40&md5=c8d214228af639aa633c570857e0a105},
	abstract = {Engineering knowledge-based (or expert) systems require extensive manual effort and domain knowledge. As Large Language Models (LLMs) are trained using an enormous amount of cross-domain knowledge, it becomes possible to automate such engineering processes. This paper presents an empirical automation and semi-automation framework for domain knowledge distillation using prompt engineering and the LLM ChatGPT. We assess the framework empirically in the autonomous driving domain and present our key observations. In our implementation, we construct the domain knowledge ontology by 'chatting' with ChatGPT. The key finding is that while fully automated domain ontology construction is possible, human supervision and early intervention typically improve efficiency and output quality as they lessen the effects of response randomness and the butterfly effect. We, therefore, also develop a web-based distillation assistant enabling supervision and flexible intervention at runtime. We hope our findings and tools could inspire future research toward revolutionizing the engineering of knowledge-based systems across application domains. © 2023 IEEE.},
	author_keywords = {autonomous driving; domain ontology distillation; large language model},
	keywords = {Autonomous vehicles; Computational linguistics; Distillation; Ontology; Autonomous driving; Cross-domain; Domain knowledge; Domain ontologies; Domain ontology distillation; Empirical studies; Engineering knowledge; Knowledge experts; Language model; Large language model; Domain Knowledge},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; All Open Access, Green Open Access}
}

@CONFERENCE{Miller202342,
	author = {Miller, John A. and Barna, Nasid Habib and Rana, Subas and Arpinar, I. Budak and Liu, Ninghao},
	title = {Knowledge Enhanced Deep Learning: Application to Pandemic Prediction},
	year = {2023},
	journal = {Proceedings - 2023 IEEE 9th International Conference on Collaboration and Internet Computing, CIC 2023},
	pages = {42 – 51},
	doi = {10.1109/CIC58953.2023.00016},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183806100&doi=10.1109%2fCIC58953.2023.00016&partnerID=40&md5=ac160ba66a00858f45bfea2412ed8698},
	abstract = {Deep Learning has been successfully applied to many problem domains, yet its advantages have been slow to emerge for time series forecasting. For example, in the well-known M Competitions, until recently, hybrids of traditional statistical or machine learning (e.g., gradient boosting) techniques were the top performers. With the recent architectural advances in deep learning being applied to time series forecasting, such as encoder-decoders with attention, transformers, representation learning, and graph neural networks, deep learning has begun to show its advantages. Still, in the area of pandemic prediction, there remain challenges for deep learning models: the time series is not long enough for effective training, ignorance of accumulated scientific knowledge, and interpretability of the model. Today, there is a vast amount of knowledge available that deep learning models can tap into, including Knowledge Graphs and Large Language Models fine-tuned with scientific domain knowledge. There is ongoing research examining how to utilize or inject knowledge into deep learning models. The state-of-the-art approaches are reviewed and suggestions for further work are provided. Recommendations for how this can be applied to future pandemics are given. © 2023 IEEE.},
	author_keywords = {deep learning; pandemic; Time series},
	keywords = {Adaptive boosting; Deep learning; Domain Knowledge; Forecasting; Graph neural networks; Knowledge graph; Learning systems; Taps; Deep learning; Encoder-decoder; Gradient boosting; Learning models; Machine-learning; Pandemic; Problem domain; Statistical learning; Time series forecasting; Times series; Time series},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{2023,
	title = {EXAG 2023 - Proceedings of the Experimental Artificial Intelligence in Games Workshop, co-located with the 19th AAAI Conference on Artificial Intelligence and Interactive Digital Entertainment, AIIDE 2023},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3626},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184800995&partnerID=40&md5=5e7bcaaf480e430e19c0d03bee264df1},
	abstract = {The proceedings contain 16 papers. The topics discussed include: exploring Minecraft settlement generators with generative shift analysis; HarmonyMapper: generating emotionally divers chord progressions for games; toward procedural generation of constructed languages for games; knowledge goal recognition for interactive narratives; moirai: enabling complex narrative structure in simulation-driven stories; towards automated video game commentary using generative AI; fast, declarative, character simulation using bottom-up logic programming; an executable ontology for social simulation; little learning machines: real-time deep reinforcement learning as a casual creativity game; examining early professionals' use of generative AI in the game development process; dialogue shaping: empowering agents through NPC interaction; and toward using ChatGPT to generate theme-relevant simulated storyworlds.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Castelnovo2023,
	author = {Castelnovo, Alessandro and Crupi, Riccardo and Mercorio, Fabio and Mezzanzanica, Mario and Potertì, Daniele and Regoli, Daniele},
	title = {Marrying LLMs with Domain Expert Validation for Causal Graph Generation},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3650},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85188448835&partnerID=40&md5=07d86b5dcbb046c0d91c5eea6a491145},
	abstract = {In the era of rapid growth and transformation driven by artificial intelligence across various sectors, which is catalyzing the fourth industrial revolution, this research is directed toward harnessing its potential to enhance the efficiency of decision-making processes within organizations. When constructing machine learning-based decision models, a fundamental step involves the conversion of domain knowledge into causal-effect relationships that are represented in causal graphs. This process is also notably advantageous for constructing explanation models. We present a method for generating causal graphs that integrates the strengths of Large Language Models (LLMs) with traditional causal theory algorithms. Our method seeks to bridge the gap between AI’s theoretical potential and practical applications. In contrast to recent related works that seek to exclude the involvement of domain experts, our method places them at the forefront of the process. We present a novel pipeline that streamlines and enhances domain-expert validation by providing robust causal graph proposals. These proposals are enriched with transparent reports that blend foundational causal theory reasoning with explanations from LLMs. © 2024 Copyright for this paper by its authors.},
	author_keywords = {Causal Discovery; Human-AI-Interaction; LLMs},
	keywords = {Domain Knowledge; Industrial research; Knowledge graph; Causal discovery; Causal graph; Causal theory; Domain experts; Graph generation; Human-AI-interaction; Language model; Large language model; Rapid growth; Rapid transformations; Decision making},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{2023,
	title = {KBC-LM + LM-KBC 2023 - Joint Proceedings of the 1st Workshop on Knowledge Base Construction from Pre-Trained Language Models and the 2nd Challenge on Language Models for Knowledge Base Construction, co-located with the 22nd International Semantic Web Conference, ISWC 2023},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3577},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179793559&partnerID=40&md5=6d62091d318f31477226c8a50f92fc45},
	abstract = {The proceedings contain 15 papers. The topics discussed include: language models as knowledge bases for visual word sense disambiguation; extracting geographic knowledge from large language models: an experiment; do instruction-tuned large language models help with relation extraction?; towards ontology construction with language models; towards syntax-aware pretraining and prompt engineering for knowledge retrieval from large language models; can large language models generate salient negative statements?; limits of zero-shot probing on object prediction; knowledge-centric prompt composition for knowledge base construction from pre-trained language models; and enhancing knowledge base construction from pre-trained language models using prompt ensembles.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Chari2023,
	author = {Chari, Shruthi},
	title = {An Ontology-Enabled Approach For User-Centered and Knowledge-Enabled Explanations of AI Systems},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3678},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192738787&partnerID=40&md5=482d059e9c4afaa0f9c82f4cf40c2ab1},
	abstract = {Explainable Artificial Intelligence (AI) focuses on helping humans understand the working of AI systems or their decisions and has been a cornerstone of AI for decades. Recent research in explainability has focused on explaining the workings of AI models or model explainability. There have also been several position statements and review papers detailing the needs of end-users for user-centered explainability but fewer implementations. Hence, this thesis seeks to bridge some gaps between model and user-centered explainability. We create an explanation ontology (EO) to represent literature-derived explanation types via their supporting components. We implement a knowledge-augmented question-answering (QA) pipeline to support contextual explanations in a clinical setting. Finally, we are implementing a system to combine explanations from different AI methods and data modalities. Within the EO, we can represent fifteen different explanation types, and we have tested these representations in six exemplar use cases. We find that knowledge augmentations improve the performance of base large language models in the contextualized QA, and the performance is variable across disease groups. In the same setting, clinicians also indicated that they prefer to see actionability as one of the main foci in explanations. In our explanations combination method, we plan to use similarity metrics to determine the similarity of explanations in a chronic disease detection setting. Overall, through this thesis, we design methods that can support knowledge-enabled explanations across different use cases, accounting for the methods in today's AI era that can generate the supporting components of these explanations and domain knowledge sources that can enhance them. © 2023 CEUR-WS. All rights reserved.},
	author_keywords = {Explainable AI; Knowledge-Enabled Explanations; User-Centered Explanations},
	keywords = {Domain Knowledge; Natural language processing systems; User interfaces; Artificial intelligence systems; Explainable artificial intelligence; Knowledge-enabled explanation; Ontology's; Performance; Question Answering; Recent researches; User knowledge; User-centered explanation; User-centred; Ontology},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Kosten20235272,
	author = {Kosten, Catherine and Cudre-Mauroux, Philippe and Stockinger, Kurt},
	title = {Spider4SPARQL: A Complex Benchmark for Evaluating Knowledge Graph Question Answering Systems},
	year = {2023},
	journal = {Proceedings - 2023 IEEE International Conference on Big Data, BigData 2023},
	pages = {5272 – 5281},
	doi = {10.1109/BigData59044.2023.10386182},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184975243&doi=10.1109%2fBigData59044.2023.10386182&partnerID=40&md5=ef56e1d7fe443d48f25523a312f555a4},
	abstract = {With the recent spike in the number and availability of Large Language Models (LLMs), it has become increasingly important to provide large and realistic benchmarks for evaluating Knowledge Graph Question Answering (KGQA) systems. So far the majority of benchmarks rely on pattern-based SPARQL query generation approaches. The subsequent natural language (NL) question generation is conducted through crowdsourcing or other automated methods, such as rule-based paraphrasing or NL question templates. Although some of these datasets are of considerable size, their pitfall lies in their pattern-based generation approaches, which do not always generalize well to the vague and linguistically diverse questions asked by humans in real-world contexts. In this paper, we introduce Spider4SPARQL -a new SPARQL benchmark dataset featuring 9,693 previously existing manually generated NL questions and 4,721 unique, novel, and complex SPARQL queries of varying complexity. In addition to the NL/SPARQL pairs, we also provide their corresponding 166 knowledge graphs and ontologies, which cover 138 different domains. Our complex benchmark enables novel ways of evaluating the strengths and weaknesses of modern KGQA systems. We evaluate the system with state-of-the-art KGQA systems as well as LLMs, which achieve only up to 45% execution accuracy, demonstrating that Spider4SPARQL is a challenging benchmark for future research.  © 2023 IEEE.},
	author_keywords = {Benchmark for Question Answering over Knowledge Graphs; Language Models; Performance Evaluation},
	keywords = {Benchmarking; Computational linguistics; Natural language processing systems; Automated methods; Benchmark for question answering over knowledge graph; Complex benchmark; Knowledge graphs; Language model; Natural language questions; Performances evaluation; Query generation; Question Answering; Question answering systems; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Green Open Access}
}

@CONFERENCE{2023,
	title = {Wikidata 2023 - Proceedings of the 4th Wikidata Workshop 2023, co-located with 22nd International Semantic Web Conference, ISWC 2023},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3640},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186098202&partnerID=40&md5=5d12ad9fc799a70245d97492ea0201d6},
	abstract = {The proceedings contain 16 papers. The topics discussed include: automating the use of shape expressions for the validation of semantic knowledge in Wikidata; Bravo MaRDI: a Wikibase knowledge graph on mathematics; conflations and duplications in Wikidata items: causes, detection, solutions, and issues; draw me like my triples: leveraging generative ai for wikidata image completion; KeySearchWiki: an automatically generated dataset for keyword search over Wikidata; knowledge gap discovery: a case study of Wikidata; PhyQus: automatic unit conversions for Wikidata physical quantities; preregistration: comparing the use of Wikidata and Wikipedia by open-source software programmers on GitHub repositories; qualifier recommendation for Wikidata; ten years of Wikidata: a bibliometric study; and WikiMed-DE: constructing a silver-standard dataset for German biomedical entity linking using Wikipedia and Wikidata.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Ocker2023,
	author = {Ocker, Felix and Deigmöller, Jörg and Eggert, Julian},
	title = {Exploring Large Language Models as a Source of Common-Sense Knowledge for Robots},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3632},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184382211&partnerID=40&md5=9fb8e419f9ec5f7722d6c3c66bf1f13b},
	abstract = {Service robots need common-sense knowledge to help humans in everyday situations as it enables them to understand the context of their actions. However, approaches that use ontologies face a challenge because common-sense knowledge is often implicit, i.e., it is obvious to humans but not explicitly stated. This paper investigates if Large Language Models (LLMs) can fill this gap. Our experiments reveal limited effectiveness in the selective extraction of contextual action knowledge, suggesting that LLMs may not be sufficient on their own. However, the large-scale extraction of general, actionable knowledge shows potential, indicating that LLMs can be a suitable tool for efficiently creating ontologies for robots. This paper shows that the technique used for knowledge extraction can be applied to populate a minimalist ontology, showcasing the potential of LLMs in synergy with formal knowledge representation. © 2023 Copyright for this paper by its authors.},
	author_keywords = {Common-Sense Knowledge; Knowledge Extraction; Large Language Models; Robotics},
	keywords = {Computational linguistics; Extraction; Knowledge representation; Robots; Commonsense knowledge; Formal knowledge representations; Knowledge extraction; Language model; Large language model; Large-scales; Ontology's; Selective extraction; Service robots; Ontology},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Hoogendoorn202343,
	author = {Hoogendoorn, Tjalling and Arachchige, Jeewanie Jayasinghe and Bukhsh, Faiza A.},
	title = {Survey of Explainability within Process Mining: A case study of BPI challenge 2020},
	year = {2023},
	journal = {Proceedings - 2023 International Conference on Frontiers of Information Technology, FIT 2023},
	pages = {43 – 48},
	doi = {10.1109/FIT60620.2023.00018},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185838784&doi=10.1109%2fFIT60620.2023.00018&partnerID=40&md5=e5af3f6a4de1743bcc112e9f3e1673f8},
	abstract = {The need for explainability in Business process management is tremendously increasing, especially in the age of generative AI. The number of published articles on explainable AI (XAI) has skyrocketed for five years. AI impacts the decision-making process in business analytics. Process mining as a sub-discipline of data science can play a role in explainable business decision-making. Process mining exhibits its intention in process discovery, performance measures of processes, and process improvements based on the event logs. Although the accuracy of the outcome of process mining models has been investigated at a certain level, the explainability of those is possible through the discretization of the analytic steps. As an initial step in exploring the explainability of process mining, this research conducts a technical analysis of 37 research papers submitted to the Business Process Intelligence (BPI) Challenge 2020. The main focus of this analysis aims to answer the question, "How and why a process model is produced? "To make a foundation for the research question, the notion of explainability is explored based on an Explainable AI ontology. Due to the small sample size, the study cannot identify clear trends of explainability in process mining. However, the results conclude that explainability depends on the process model's transparency and reproducibility. Moreover, further research with a large sample size is required to understand the discrete factors impacting decision-making in business process management.  © 2023 IEEE.},
	author_keywords = {Data Science; Explainability; Process Mining; Transparency},
	keywords = {Data mining; Data Science; Decision making; Enterprise resource management; Business Process; Business Process Intelligence; Case-studies; Decisions makings; Explainability; In-process; Management IS; Process management; Process mining; Process-models; Transparency},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Mountantonakis2023,
	author = {Mountantonakis, Michalis and Tzitzikas, Yannis},
	title = {Real-Time Validation of ChatGPT facts using RDF Knowledge Graphs},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3632},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184362692&partnerID=40&md5=241caf1cf1c52cec09cfeb1583443eb8},
	abstract = {ChatGPT is an innovative application of Large Language Models (LLMs) that produces detailed and articulate responses across many domains of knowledge. However, it does not provide evidence for its responses, and it returns several erroneous facts, even for popular persons, places and others. For tackling the mentioned limitation, we present the fact checking service of the research prototype GPT∙LODS, which can validate ChatGPT facts by using RDF Knowledge Graphs (KGs) containing high quality structured data. Indeed, GPT∙LODS is able to generate triples for a question, an entity or a given text using ChatGPT. Afterwards, it can validate at real-time the generated ChatGPT triples through DBpedia or LODsyndesis KG (a KG that has indexed 400 other RDF KGs), by combining SPARQL queries, word embeddings and sentence similarity metrics. We present the functionality and use cases of GPT∙LODS, including fact checking, question answering, triples generation from text and comparison of different GPT models. © 2023 Copyright for this paper by its authors.},
	author_keywords = {ChatGPT; Embeddings; Fact Checking; Knowledge Graphs; LODsyndesis; Provenance; Validation},
	keywords = {Graph embeddings; Natural language processing systems; Resource Description Framework (RDF); ChatGPT; Domain of knowledge; Embeddings; Fact checking; Knowledge graphs; Language model; Lodsyndesis; Provenance; Real-time validation; Validation; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Pliukhin2023,
	author = {Pliukhin, Dmitrii and Radyush, Daniil and Kovriguina, Liubov and Mouromtsev, Dmitry},
	title = {Improving Subgraph Extraction Algorithms for One-Shot SPARQL Query Generation with Large Language Models},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3592},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180551320&partnerID=40&md5=d3d62c78b1b2b37274a9e88314393de0},
	abstract = {Question answering over scholarly knowledge graphs involves many challenges: complex graph patterns, long-tail distributed data, revision and evolution of the scholarly ontologies, and knowledge graphs incompleteness due to constant research dynamics. In this work, we present an LLM-based approach for SPARQL query generation over Open Research Knowledge Graph (ORKG) for the ISWC SciQA Challenge. Our approach proposes a couple of improvements to the recently published SPARQLGEN approach, that performs one-shot SPARQL query generation by augmenting Large Language Models (LLMs) with the relevant context within a single prompt. Similar to SPARQLGEN, we include heterogeneous data sources in the SPARQL generation prompt: a question itself, an RDF subgraph required to answer the question, and an example of a correct SPARQL query. In the current work, we focused on designing subgraph extraction algorithms, that are close to real-life scenarios of generative KGQA, and replaced the random choice of example question-query pair with similarity scoring. © 2023 CEUR-WS. All rights reserved.},
	author_keywords = {Augmented Large Language Models; Knowledge Graphs Question Answering; Scholarly Knowledge Graphs; SPARQL query generation; Subgraph Extraction},
	keywords = {Computational linguistics; Data mining; Extraction; Graphic methods; Natural language processing systems; Query processing; Resource Description Framework (RDF); Augmented large language model; Knowledge graph question answering; Knowledge graphs; Language model; Query generation; Question Answering; Scholarly knowledge graph; SPARQL query generation; Subgraph extraction; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Yu2023707,
	author = {Yu, Lijun and Miao, Jin and Sun, Xiaoyu and Chen, Jiayi and Hauptmann, Alexander G. and Dai, Hanjun and Wei, Wei},
	title = {DocumentNet: Bridging the Data Gap in Document Pre-Training},
	year = {2023},
	journal = {EMNLP 2023 - 2023 Conference on Empirical Methods in Natural Language Processing, Proceedings of the Industry Track},
	pages = {707 – 722},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184665343&partnerID=40&md5=990ddf4cb69511c84df7f7c85dba3a31},
	abstract = {Document understanding tasks, in particular, Visually-rich Document Entity Retrieval (VDER), have gained significant attention in recent years thanks to their broad applications in enterprise AI. However, publicly available data have been scarce for these tasks due to strict privacy constraints and high annotation costs. To make things worse, the non-overlapping entity spaces from different datasets hinder the knowledge transfer between document types. In this paper, we propose a method to collect massive-scale and weakly labeled data from the web to benefit the training of VDER models. The collected dataset, named DocumentNet, does not depend on specific document types or entity sets, making it universally applicable to all VDER tasks. The current DocumentNet consists of 30M documents spanning nearly 400 document types organized in a four-level ontology. Experiments on a set of broadly adopted VDER tasks show significant improvements when DocumentNet is incorporated into the pre-training for both classic and few-shot learning settings. With the recent emergence of large language models (LLMs), DocumentNet provides a large data source to extend their multimodal capabilities for VDER. © 2023 Association for Computational Linguistics.},
	keywords = {Computational linguistics; 'current; Broad application; Data gap; Document understanding; Entity retrieval; Knowledge transfer; Labeled data; Pre-training; Privacy constraints; Retrieval models; Knowledge management},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Wu2023161,
	author = {Wu, Qinglin and Wang, Yan},
	title = {Research on Intelligent Question-Answering Systems Based on Large Language Models and Knowledge Graphs},
	year = {2023},
	journal = {Proceedings - 2023 16th International Symposium on Computational Intelligence and Design, ISCID 2023},
	pages = {161 – 164},
	doi = {10.1109/ISCID59865.2023.00045},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191753770&doi=10.1109%2fISCID59865.2023.00045&partnerID=40&md5=8094dfc358161f98f03d0556f41c0fd5},
	abstract = {With the continuous development of artificial intelligence and cloud computing technologies, the emergence of large language models (LLMs) has created new opportunities for intelligent applications. However, large language models may lack authenticity and accuracy when providing answers in specific professional domains, and they even generate "illusory facts." In response to the limitations of current large language models in solving specific professional fields, this paper proposes to use large language models and knowledge graph technology to construct an intelligent question answering system for specific fields. Through systematic training and optimization, efficient domain specific knowledge Q&A has been achieved, improving the satisfaction rate of domain specific knowledge Q&A. The intelligent question answering system based on large models and knowledge graphs brings more convenience to people's lives and work, which is beneficial for users to obtain intelligent solutions in fields such as education, healthcare, and customer service. ©2023 IEEE.},
	author_keywords = {deep learning; knowledge graph; large language models; natural language processing; question-answer system},
	keywords = {Computational linguistics; Deep learning; Domain Knowledge; Natural language processing systems; Deep learning; Domain-specific knowledge; Intelligent question answering systems; Knowledge graphs; Language model; Language processing; Large language model; Natural language processing; Natural languages; Question answer systems; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Arnaout2023,
	author = {Arnaout, Hiba and Razniewski, Simon},
	title = {Can large language models generate salient negative statements?},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3577},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179558782&partnerID=40&md5=8dc78d7f3aa74c3f6097d131906d405f},
	abstract = {We examine the ability of large language models (LLMs) to generate salient (interesting) negative statements about real-world entities; an emerging research topic of the last few years. We probe the LLMs using zero- and k-shot unconstrained probes, and compare with traditional methods for negation generation, i.e., pattern-based textual extractions and knowledge-graph-based inferences, as well as crowdsourced gold statements. We measure the correctness and salience of the generated lists about subjects from different domains. Our evaluation shows that guided probes do in fact improve the quality of generated negatives, compared to the zero-shot variant. Nevertheless, using both prompts, LLMs still struggle with the notion of factuality of negatives, frequently generating many ambiguous statements, or statements with negative keywords but a positive meaning. © 2023 CEUR-WS. All rights reserved.},
	keywords = {Computational linguistics; Graphic methods; Different domains; Graph-based; Knowledge graphs; Language model; Real-world entities; Research topics; Probes},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Biswas2023,
	author = {Biswas, Debanjali and Linzbach, Stephan and Dimitrov, Dimitar and Jabeen, Hajira and Dietze, Stefan},
	title = {Broadening BERT vocabulary for Knowledge Graph Construction using Wikipedia2Vec},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3577},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179557571&partnerID=40&md5=1609abf8ea196ad7f449e16ff3bd92f7},
	abstract = {Recent advancements in natural language processing (NLP) have been driven by the utilization of large language models like BERT. These models, pre-trained on extensive textual data, capture linguistic and relational knowledge. Therefore, cloze-style prompts, which involve filling in missing words in a sentence, can be used to solve knowledge-intensive NLP tasks with the help of a language model. The "Knowledge Base Construction from Pre-trained Language Models (LM-KBC 2023)" challenge aims to harness language models’ potential for knowledge graph construction through prompts. In particular, contestants are challenged to infer the correct Wikidata ID of objects, given a prompt used to link subject, relation, and object. Automatically inferring the correct objects would help in reducing the need for an expensive manual graph population. Our proposed approach in Track 1 focuses on expanding BERT’s vocabulary with a task-specific one (i.e., Wikipedia2Vec) and facilitating its usage through prompt tuning with OPTIPROMPT. © 2023 CEUR-WS. All rights reserved.},
	keywords = {Computational linguistics; Natural language processing systems; Filling in; Graph construction; Knowledge graphs; Knowledge-base construction; Language model; Language processing; Model potential; Natural languages; Textual data; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Sevastjanova202311,
	author = {Sevastjanova, Rita and Vogelbacher, Simon and Spitz, Andreas and Keim, Daniel and El-Assady, Mennatallah},
	title = {Visual Comparison of Text Sequences Generated by Large Language Models},
	year = {2023},
	journal = {Proceedings - 2023 IEEE Visualization in Data Science, VDS 2023},
	pages = {11 – 20},
	doi = {10.1109/VDS60365.2023.00007},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182731475&doi=10.1109%2fVDS60365.2023.00007&partnerID=40&md5=022e5cfffb7348edb5652be824645013},
	abstract = {Causal language models have emerged as the leading technology for automating text generation tasks. Although these models tend to produce outputs that resemble human writing, they still suffer from quality issues (e.g., social biases). Researchers typically use automatic analysis methods to evaluate the model limitations, such as statistics on stereotypical words. Since different types of issues are embedded in the model parameters, the development of automated methods that capture all relevant aspects remains a challenge. To tackle this challenge, we propose a visual analytics approach that supports the exploratory analysis of text sequences generated by causal language models. Our approach enables users to specify starting prompts and effectively groups the resulting text sequences. To this end, we leverage a unified, ontology-driven embedding space, serving as a shared foundation for the thematic concepts present in the generated text sequences. Visual summaries provide insights into various levels of granularity within the generated data. Among others, we propose a novel comparison visualization that slices the embedding space and represents the differences between two prompt outputs in a radial layout. We demonstrate the effectiveness of our approach through case studies, showcasing its potential to reveal model biases and other quality issues.  © 2023 IEEE.},
	author_keywords = {Causal Language Models; Prompt Output Comparison; Text Generation},
	keywords = {Computational linguistics; Visual languages; Visualization; Automatic analysis method; Causal language model; Embeddings; Language model; Leading technology; Modeling parameters; Prompt output comparison; Quality issues; Text generations; Visual comparison; Embeddings},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Datta202316,
	author = {Datta, V Dinesh and Ganesh, Sakthi and Haas, Roland E. and Talukder, Asoke K.},
	title = {GREAT AI in Medical Appropriateness and Value-Based-Care},
	year = {2023},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14418 LNCS},
	pages = {16 – 33},
	doi = {10.1007/978-3-031-49601-1_2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180527813&doi=10.1007%2f978-3-031-49601-1_2&partnerID=40&md5=4c27a648eb683a24f14789f02fc3ae5b},
	abstract = {Fee For Service, also known as Volume Based Care (VBC) model of healthcare encourages service volume – more service more reward. This model of care results in unnecessary, inappropriate, and wasted medical services. In the US, Fraud, Waste, and Abuse (FWA) ranges between $760 billion to $935 billion, accounting for approximately 25% of total healthcare spending. In India, the waste caused by FWA is estimated to be as high as 35%. This is due to a lack of smart digital health, absence of AI models, and lack of preventive vigilance against inappropriate medical interventions. Inappropriate medical intervention costs valuable resources and causes patient harm. This paper proposes GREAT AI (Generative, Responsible, Explainable, Adaptive, and Trustworthy Artificial Intelligence) in Medical Appropriateness. We show how GREAT AI is used to offer appropriate medical services. Moreover, we show how GREAT AI can function in vigilance role to curb FWA. We present two GREAT AI models namely MAKG (Medical Appropriateness Knowledge Graph) and RAG-GPT (Retrieval Augmented Generation – Generative Pretrained Transformer). MAKG is used as an autonomous coarse-grained medical-inappropriateness vigilance model for payers and regulators. Whereas RAG-GPT is used as a fine-grained LLM, with human-in-the-loop for medical appropriateness and medical inappropriateness model where the actor human-in-the loop can be anybody like providers, patients, payers, regulators, funders, or researchers. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Adaptive AI; Explainable AI; Generative AI; GREAT AI; MAKG; Medical Appropriateness; RAG-GPT; Responsible AI; Trustworthy AI},
	keywords = {Patient treatment; Adaptive AI; Explainable AI; Generative AI; GREAT AI; Knowledge graphs; Medical appropriateness; Medical appropriateness knowledge graph; Responsible AI; Retrieval augmented generation – generative pretrained transformer; Trustworthy AI; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Jiang2023,
	author = {Jiang, Longquan and Yan, Xi and Usbeck, Ricardo},
	title = {A Structure and Content Prompt-based Method for Knowledge Graph Question Answering over Scholarly Data},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3592},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180545725&partnerID=40&md5=f5ab3853af26941c54e4799988381362},
	abstract = {Answering scholarly questions is challenging without the help of query-based systems. Thus, we develop a divide-and-conquer approach based on a Large Language Model (LLM) for scholarly Knowledge Graph (KG) Question Answering (QA). Our system integrates the KG ontology into the LLM prompts and leverages a hybrid prompt learning strategy with both query structure and content. Our experiments suggest that given an ontology of a specific KG, LLMs are capable of automatically choosing the corresponding classes or predicates required to generate a target SPARQL query from a natural language question. Our approach shows state-of-the-art results over one scholarly KGQA dataset, namely sciQA [1]. © 2023 CEUR-WS. All rights reserved.},
	author_keywords = {KGQA; Large Language Model; Question Answering; Scholarly KGQA},
	keywords = {Computational linguistics; Natural language processing systems; Ontology; Divide-and-conquer approach; KGQA; Knowledge graphs; Language model; Large language model; Learning strategy; Ontology's; Query structures; Question Answering; Scholarly KGQA; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Liu2023166,
	author = {Liu, Ya-Chen and Kuo, Chen-Ho and Wang, Guo-Hua},
	title = {Dialogues of Creation: Collaborative Content Generation by the Human Author and ChatGPT and its Impact on the Evolving Intellectual Property Landscape},
	year = {2023},
	journal = {Proceedings of the International Conference on Electronic Business (ICEB)},
	volume = {23},
	pages = {166 – 185},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85181405359&partnerID=40&md5=7d9524da1c66ebeb59f4c0d9e9974201},
	abstract = {The paradigm of content creation and intellectual property (IP) is undergoing an unprecedented shift fueled by AI, with ChatGPT at its forefront. This study presents a distinctive approach—a dialogue between a human author and ChatGPT—to explore their collaborative impact on creative content generation, redefining authorship and reimagining the intellectual property landscape. As AI blurs distinctions between traditional authorship and machine-generated influence, questions emerge about attributing creative ownership, ethical considerations, and the economic valuation of AI's contributions. The human author's collaboration with ChatGPT reveals motivations that extend beyond innovation, encompassing a horizon of narrative experimentation with unique challenges. The subsequent interviews capture the evolving discourse, uncovering that while AI-generated concepts may not inherently spark entirely novel ideas, with careful human guidance, they act as catalysts for enhancing creativity. This dialogue also delves into the complexities of authorship in an AI-infused landscape. It probes the extent to which AI-generated ideas resonate with the author's artistic intent and the challenges of maintaining authorial voice in a dynamic, collaborative environment. Utilizing qualitative methods, this research seeks to illuminate AI's influence on human authors' creative processes, dissect the intricate interplay between human creativity and AI-generated content, and critically assess the profound implications for established concepts of authorship and the evolving dynamics of the IP economy—an arena witnessing disruption due to the increased prevalence of AI-infused work. The evolving definition of authorship and content ownership catalyzed by AI-generated contributions calls for a fundamental reassessment of the traditinoal IP models. Lastly, as AI-generated content becomes integral to creative works, it necessitates the emergence of new models for valuing, distributing royalties, and upholding ethical standards. We delve into the complexities of establishing fairness within this emerging model, which encompasses licensing issues related to the training data used by generative AI companies and these companies' stance on copyright ownership of the generated work. To address these challenges and the limitations inherent in current AI systems, we propose the concept of a Knowledge Graph as a valuable tool to serve as human guidance in AI-generated work. We suggest that the design of these knowledge graphs may play a pivotal role in shaping the future of the intellectual property economy. In essence, the research presents an unconventional exploration of the partnership between human authors and AI. Through this dialogue, the study not only unveils how they redefine creativity and authorship but also highlights the transformative impact on the IP economy. The outcomes of this research offer valuable recommendations for creators, industries, and policymakers to navigate this evolving landscape. © 2023 International Consortium for Electronic Business. All rights reserved.},
	author_keywords = {Artificial Intergence; ChatGPT; Collaborative content creation; Intellectual property economy},
	keywords = {Electronic commerce; Ethical technology; Knowledge graph; Artificial intergence; ChatGPT; Collaborative content creation; Content creation; Creatives; Economic valuation; Ethical considerations; Human guidance; Intellectual property economy; Knowledge graphs; Intellectual property},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Furumai2023871,
	author = {Furumai, Kazuaki and Wang, Yanan and Shinohara, Makoto and Ikeda, Kazushi and Yu, Yi and Kato, Tsuneo},
	title = {Detecting Dialogue Hallucination Using Graph Neural Networks},
	year = {2023},
	journal = {Proceedings - 22nd IEEE International Conference on Machine Learning and Applications, ICMLA 2023},
	pages = {871 – 877},
	doi = {10.1109/ICMLA58977.2023.00128},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190155742&doi=10.1109%2fICMLA58977.2023.00128&partnerID=40&md5=62462e942080d6410300c150a6400a50},
	abstract = {Even though large language models (LLMs) accumulate tremendous knowledge, dialogue systems built with LLMs induce hallucinations, leading to the generation of non-factual responses. How to provide proper references to achieve interpretable hallucination detection is a key issue that needs to be addressed. In this paper, we propose a graph neural network (GNN)-based method to achieve high-performance and interpretable hallucination detection for domain-specific dialogue systems. The method involves performing graph matching between a reference knowledge graph obtained from a knowledge database and a response knowledge graph extracted from the response to detect non-factual responses. By comparing with strong baselines, our method achieves a recall improvement of up to 11% and infers the cause of hallucinations with a probability of over 79%. © 2023 IEEE.},
	author_keywords = {Dialogue system; graph neural networks; hallucination detection},
	keywords = {Graph neural networks; Dialogue systems; Domain specific; Graph matchings; Graph neural networks; Hallucination detection; Key Issues; Knowledge graphs; Language model; Network-based; Performance; Speech processing},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Schulhoff20234945,
	author = {Schulhoff, Sander and Pinto, Jeremy and Khan, Anaum and Bouchard, Louis-François and Si, Chenglei and Anati, Svetlina and Tagliabue, Valen and Kost, Anson Liu and Carnahan, Christopher and Boyd-Graber, Jordan},
	title = {Ignore This Title and HackAPrompt: Exposing Systemic Vulnerabilities of LLMs through a Global Scale Prompt Hacking Competition},
	year = {2023},
	journal = {EMNLP 2023 - 2023 Conference on Empirical Methods in Natural Language Processing, Proceedings},
	pages = {4945 – 4977},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184261267&partnerID=40&md5=7f9abda1fac5374881b93810f683052e},
	abstract = {Large Language Models (LLMs) are deployed in interactive contexts with direct user engagement, such as chatbots and writing assistants. These deployments are vulnerable to prompt injection and jailbreaking (collectively, prompt hacking), in which models are manipulated to ignore their original instructions and follow potentially malicious ones. Although widely acknowledged as a significant security threat, there is a dearth of large-scale resources and quantitative studies on prompt hacking. To address this lacuna, we launch a global prompt hacking competition, which allows for free-form human input attacks. We elicit 600K+ adversarial prompts against three state-of-the-art LLMs. We describe the dataset, which empirically verifies that current LLMs can indeed be manipulated via prompt hacking. We also present a comprehensive taxonomical ontology of the types of adversarial prompts. © 2023 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Natural language processing systems; 'lacuna'; Chatbots; Freeforms; Global scale; Language model; Large-scales; Quantitative study; Security threats; State of the art; User engagement; Personal computing},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 8}
}

@ARTICLE{Johnston2023141406,
	author = {Johnston, Penny and Nogueira, Keiller and Swingler, Kevin},
	title = {NS-IL: Neuro-Symbolic Visual Question Answering Using Incrementally Learnt, Independent Probabilistic Models for Small Sample Sizes},
	year = {2023},
	journal = {IEEE Access},
	volume = {11},
	pages = {141406 – 141420},
	doi = {10.1109/ACCESS.2023.3341007},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179829960&doi=10.1109%2fACCESS.2023.3341007&partnerID=40&md5=7d7b597e8e365544d28bb7a30877447b},
	abstract = {This paper is motivated by the challenge of providing accurate and contextually relevant answers to natural language questions about visual scenes, particularly in support of individuals with visual impairments. We present a system that is capable of incrementally learning both visual concepts and symbolic facts to answer natural language questions about visual scenes via rich concepts. Deep neural networks are used to learn a feature space from which visual classes are learned as independent probability distributions, allowing new classes to be added arbitrarily with small sample sizes and without the risk of catastrophic forgetting associated with traditional neural networks. Visual classes are not limited to object labels, but also include visual attributes. A knowledge graph is used to represent facts about objects, such as their actions, locations and the relationships between different objects. This allows facts to be stored explicitly and added incrementally. A large language model is used to translate between natural language questions and knowledge graph traversal queries, providing a natural visual question answering process.  © 2013 IEEE.},
	author_keywords = {classification system; Gaussian mixture model; incremental learning; Neuro-symbolic system; visual question answering},
	keywords = {Deep neural networks; Knowledge graph; Natural language processing systems; Search engines; Visual languages; Adaptation models; Classification system; Cognition; Gaussian Mixture Model; Incremental learning; Knowledge graphs; Natural languages; Neuro-symbolic system; Question Answering; Question answering (information retrieval); Visual question answering; Gaussian distribution},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Ding20231148,
	author = {Ding, Ningpei and Mayer, Wolfgang and Geng, Yilin and Duan, Yucong and Feng, Zaiwen},
	title = {Generative Semantic Modeling for Structured Data Source with Large Language Model},
	year = {2023},
	journal = {Proceedings - 2023 IEEE International Conference on High Performance Computing and Communications, Data Science and Systems, Smart City and Dependability in Sensor, Cloud and Big Data Systems and Application, HPCC/DSS/SmartCity/DependSys 2023},
	pages = {1148 – 1152},
	doi = {10.1109/HPCC-DSS-SmartCity-DependSys60770.2023.00164},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189861060&doi=10.1109%2fHPCC-DSS-SmartCity-DependSys60770.2023.00164&partnerID=40&md5=810d676c01af17c413e0a813ede0daba},
	abstract = {The paper introduces a generative semantic model for representing human knowledge in a way that enables computer understanding and reasoning. The current approach to semantic modeling involves mapping between the space of plausible semantic models and the provided data source. However, this approach has limitations, as the score functions used to search for the best candidate semantic model are either trained on a specific integration knowledge graph or rely on manually designed features. To address these limitations, the authors propose a new approach that combines an encoder made with a pre-trained large language model (LLM) with a graph decoder customized to generate semantics. The encoder-decoder system is designed to be trained on knowledge graphs, and the authors introduce an algorithm to generate training samples from the big knowledge graph by decomposing training samples into construction actions using a method similar to the transition system of the Syntax Parser. The proposed method is novel, as it is the first time a generative method has been applied to the semantic modeling task, empowered with an LLM, and trained on knowledge graphs to achieve better performance on standard benchmarks than in past work. In conclusion, the proposed generative semantic model offers a promising new approach to representing and organizing human knowledge in a more generalizable way, using a combination of a pre-trained LLM and a customized graph decoder trained on knowledge graphs. The approach has shown improved performance on standard benchmarks and has the potential to advance the field of semantic modeling. © 2023 IEEE.},
	author_keywords = {Graph Neural Network; Knowledge graph; Large Language Model},
	keywords = {Computational linguistics; Decoding; Graph neural networks; Knowledge graph; Modeling languages; Sampling; Semantic Web; Semantics; Signal encoding; Syntactics; Data-source; Graph neural networks; Human knowledge; Knowledge graphs; Language model; Large language model; New approaches; Performance; Semantic modelling; Training sample; Benchmarking},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Wang2023146,
	author = {Wang, Zhu},
	title = {AMD Results for OAEI 2023},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3591},
	pages = {146 – 153},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180779638&partnerID=40&md5=5de524163e7e345de6e2c5ebd3bde262},
	abstract = {AgreementMakerDeep (AMD) is a new flexible and extensible ontology matching system. It exploits the contextual and structural information of ontologies by infusing knowledge to pre-trained masked language model, and then filter the output mappings using knowledge graph embedding techniques. AMD learns from classes and their relations between classes by constructing vector representations into the low dimensional embedding space with knowledge graph embedding methods. The results demonstrate that AMD achieves a competitive performance in many OAEI tracks, but AMD has limitations for property and instance matching. © 2023 Copyright for this paper by its authors.},
	author_keywords = {Knowledge graph embedding; Large Language model; Ontology matching},
	keywords = {Computational linguistics; Graph embeddings; Ontology; Vector spaces; Contextual information; Graph embeddings; Knowledge graph embedding; Knowledge graphs; Language model; Large language model; Matching system; Ontology matching; Ontology's; Structural information; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Cheng202375,
	author = {Cheng, Liang and Hosseini, Mohammad Javad and Steedman, Mark},
	title = {Complementary Roles of Inference and Language Models in QA},
	year = {2023},
	journal = {2nd Workshop on Pattern-Based Approaches to NLP in the Age of Deep Learning, Pan-DL 2023 - Proceedings of the Workshop},
	pages = {75 – 91},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184997143&partnerID=40&md5=c3f314cab000d6e14375f9dec0cbe581},
	abstract = {Answering open-domain questions through unsupervised methods poses challenges for both machine-reading (MR) and language model (LM)-based approaches. The MR-based approach suffers from sparsity issues in extracted knowledge graphs (KGs), while the performance of the LM-based approach significantly depends on the quality of the retrieved context for questions. In this paper, we compare these approaches and propose a novel methodology that leverages directional predicate entailment (inference) to address these limitations. We use entailment graphs (EGs), with natural language predicates as nodes and entailment as edges, to enhance parsed KGs by inferring unseen assertions, effectively mitigating the sparsity problem in the MR-based approach. We also show EGs improve context retrieval for the LM-based approach. Additionally, we present a Boolean QA task, demonstrating that EGs exhibit comparable directional inference capabilities to large language models (LLMs). Our results highlight the importance of inference in open-domain QA and the improvements brought by leveraging EGs. © 2023 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Natural language processing systems; Context retrieval; Inference models; Knowledge graphs; Language model; Model based approach; Natural languages; Novel methodology; Performance; Sparsity problems; Unsupervised method; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Huang2023,
	author = {Huang, Qian and Ren, Hongyu and Chen, Peng and Kržmanc, Gregor and Zeng, Daniel and Liang, Percy and Leskovec, Jure},
	title = {PRODIGY: Enabling In-context Learning Over Graphs},
	year = {2023},
	journal = {Advances in Neural Information Processing Systems},
	volume = {36},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186195894&partnerID=40&md5=b6df78cc09abccc627d97aca2e5375b9},
	abstract = {In-context learning is the ability of a pretrained model to adapt to novel and diverse downstream tasks by conditioning on prompt examples, without optimizing any parameters. While large language models have demonstrated this ability, how in-context learning could be performed over graphs is unexplored. In this paper, we develop Pretraining Over Diverse In-Context Graph Systems (PRODIGY), the first pretraining framework that enables in-context learning over graphs. The key idea of our framework is to formulate in-context learning over graphs with a novel prompt graph representation, which connects prompt examples and queries. We then propose a graph neural network architecture over the prompt graph and a corresponding family of in-context pretraining objectives. With PRODIGY, the pretrained model can directly perform novel downstream classification tasks on unseen graphs via in-context learning. We provide empirical evidence of the effectiveness of our framework by showcasing its strong in-context learning performance on tasks involving citation networks and knowledge graphs. Our approach outperforms the in-context learning accuracy of contrastive pretraining baselines with hard-coded adaptation by 18% on average across all setups. Moreover, it also outperforms standard finetuning with limited data by 33% on average with in-context learning. © 2023 Neural information processing systems foundation. All rights reserved.},
	keywords = {Graphic methods; Learning systems; Network architecture; Classification tasks; Context learning; Down-stream; Graph neural networks; Graph representation; In contexts; Language model; Learning performance; Neural network architecture; Pre-training; Graph neural networks},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@CONFERENCE{Abu Ahmad2023,
	author = {Abu Ahmad, Raia and Critelli, Martin and Efeoglu, Sefika and Mancini, Eleonora and Ringwald, Célian and Zhang, Xinyue and Meroño-Peñuela, Albert},
	title = {Draw Me Like My Triples: Leveraging Generative AI for Wikidata Image Completion},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3640},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185884370&partnerID=40&md5=888bb43c742e5666aa443c439bc48fd4},
	abstract = {Humans are critical for the creation and maintenance of high-quality Knowledge Graphs (KGs). However, creating and maintaining large KGs only with humans does not scale, especially for contributions based on multimedia (e.g. images) that are hard to find and reuse on the Web and expensive to generate by humans from scratch. Therefore, we leverage generative AI for the task of creating images for Wikidata items that do not have them. Our approach uses knowledge contained in Wikidata triples of items describing fictional characters and uses the fine-tuned T5 model based on the WDV dataset to generate natural text descriptions of items about fictional characters with missing images. We use those natural text descriptions as prompts for a transformer-based text-to-image model, Stable Diffusion v2.1, to generate plausible candidate images for Wikidata image completion. We design and implement quantitative and qualitative approaches to evaluate the plausibility of our methods, which include conducting a survey to assess the quality of the generated images. © 2023 Copyright for this paper by its authors.},
	author_keywords = {Automated Prompt Generation; Generative AI; Image Generation},
	keywords = {Knowledge graph; Automated prompt generation; Generative AI; High quality; Image completion; Image generations; Image modeling; Knowledge graphs; Model-based OPC; Quality knowledge; Reuse; Image reconstruction},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Allen2023211,
	author = {Allen, Robert B.},
	title = {Using Causal Threads to Explain Changes in a Dynamic System},
	year = {2023},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14458 LNNS},
	pages = {211 – 219},
	doi = {10.1007/978-981-99-8088-8_18},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180151227&doi=10.1007%2f978-981-99-8088-8_18&partnerID=40&md5=a99b6a2d035c22adf6b47ea82e741e85},
	abstract = {We explore developing rich semantic models of systems. Specifically we consider structured causal explanations about state changes in those systems. Essentially, we are developing process-based dynamic knowledge graphs. As an example, we construct a model of the causal threads for geological changes proposed by the Snowball Earth theory. Further, we describe an early prototype of a graphical interface to present the explanations. Unlike statistical approaches to summarization and explanation such as Large Language Models (LLMs), our approach of direct representation can be inspected and verified directly. © 2023, The Author(s).},
	author_keywords = {Causation; Direct Representation; Discourse; Dynamic Knowledge Graphs; Generative AI; Geology; Lexical Semantics; Multithreaded Explanations; Rules; Scientific Explanations; Semantic UML; User and Session Models; Visualization},
	keywords = {Geology; Knowledge graph; Causation; Direct representation; Discourse; Dynamic knowledge graph; Generative AI; Knowledge graphs; Lexical semantics; Multithreaded; Multithreaded explanation; Rule; Scientific explanation; Semantic UML; User and session model; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Funk2023,
	author = {Funk, Maurice and Hosemann, Simon and Jung, Jean Christoph and Lutz, Carsten},
	title = {Towards Ontology Construction with Language Models},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3577},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179559244&partnerID=40&md5=33969446bee8becffb8a2e0211cb3651},
	abstract = {We present a method for automatically constructing a concept hierarchy for a given domain by querying a large language model. We apply this method to various domains using OpenAI’s GPT 3.5. Our experiments indicate that LLMs can be of considerable help for constructing concept hierarchies. © 2023 CEUR-WS. All rights reserved.},
	keywords = {Concept hierarchies; Language model; Ontology construction; Computational linguistics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5}
}

@CONFERENCE{Zhong20237055,
	author = {Zhong, Victor and Shi, Weijia and Yih, Scott Wen-Tau and Zettlemoyer, Luke},
	title = {RoMQA: A Benchmark for Robust, Multi-evidence, Multi-answer Question Answering},
	year = {2023},
	journal = {Findings of the Association for Computational Linguistics: EMNLP 2023},
	pages = {7055 – 7067},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183306181&partnerID=40&md5=8a5fdb26fda8bc55fb1b2bd9b9f55587},
	abstract = {We introduce RoMQA, the first benchmark for robust, multi-evidence, multi-answer question answering (QA). RoMQA contains clusters of questions that are derived from related constraints mined from the Wikidata knowledge graph. RoMQA evaluates robustness of QA models to varying constraints by measuring worst-case performance within each question cluster. Compared to prior QA datasets, RoMQA has more human-written questions that require reasoning over more evidence text and have, on average, many more correct answers. In addition, human annotators rate RoMQA questions as more natural or likely to be asked by people. We evaluate state-of-the-art large language models in zero-shot, few-shot, and fine-tuning settings, and find that RoMQA is challenging: zero-shot and few-shot models perform similarly to naive baselines, while supervised retrieval methods perform well below gold evidence upper bounds. Moreover, existing models are not robust to variations in question constraints, but can be made more robust by tuning on clusters of related questions. Our results show that RoMQA is a challenging benchmark for large language models, and provides a quantifiable test to build more robust QA methods. © 2023 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Zero-shot learning; Fine tuning; Knowledge graphs; Language model; Question Answering; Retrieval methods; State of the art; Upper Bound; Worst-case performance; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{2023,
	title = {18th International Conference on Artificial Intelligence and Natural Language Processing and International Conference on Artificial Intelligence and Internet of Things, iSAI-NLP 2023},
	year = {2023},
	journal = {18th International Conference on Artificial Intelligence and Natural Language Processing and International Conference on Artificial Intelligence and Internet of Things, iSAI-NLP 2023},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182759459&partnerID=40&md5=538d54234182465f42c2b2ef3c5e63e4},
	abstract = {The proceedings contain 43 papers. The topics discussed include: solar-powered IoT charging system for ESP32 in organic rice field; STAT intelligence: data management and monitoring platform for BCG economy model; comment usefulness classification on YouTube using artificial neural networks; vehicle telematics system design for real-time applications using mobile networks; using knowledge graphs to enhance keyword search efficiency of the online encyclopedia and taxonomy system of the office of the royal society; decode brain signal into Thai word using EEG and L-SVM; cloud stateless server failover prediction using machine learning on proactive system metrics; generative AI for self-healing systems; machine learning to examine the foraging periods of bees; spoof detection using voice contribution on LFCC features and ResNet-34; and Simple2In1: a simple method for fusing two sequences from different captioning systems into one sequence for a small-scale Thai dataset.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Hendrik2023,
	author = {Hendrik, Hendrik and Permanasari, Adhistya Erna and Fauziati, Silmi and Kusumawardani, Sri Suning},
	title = {Judging Knowledge by its Cover: Leveraging Large Language Models in Establishing Criteria for Knowledge Graph Sources Selection},
	year = {2023},
	journal = {ICITDA 2023 - Proceedings of the 2023 8th International Conference on Information Technology and Digital Applications},
	doi = {10.1109/ICITDA60835.2023.10427395},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186531746&doi=10.1109%2fICITDA60835.2023.10427395&partnerID=40&md5=073c0bc75aa6f6ca56fb10c58b88f751},
	abstract = {The Knowledge Graph (KG) is a widely used paradigm for knowledge representation that leverages graph structures. It facilitates the discovery of relationships and provides context across various domains. Despite its popularity, there's a notable lack of emphasis on quality control during the KG construction process, particularly concerning the selection of knowledge sources. Our paper addresses this research gap by introducing criteria for selecting high-quality websites during the data acquisition phase of KG construction. We propose a set of criteria - credibility, relevance, content quality, coverage, comprehensiveness, and accessibility - that serves as a benchmark for evaluating potential online knowledge sources for KGs. We determine the weight of each criterion through expert judgment and validation using Large Language Models (LLMs) representing AI technologies. Our panel, consisting of academicians and practitioners, ranks the criteria by importance, with the Rank Ordered Centroid and Rank Reciprocal weighting methods generating weights from these rankings. We employ four LLMs: Google Bard, OpenAI ChatGPT 4, Anthropic Claude-2, and Meta Llama-2. Our findings suggest that LLMs can effectively validate human weighting results, as evidenced by a high correlation (Pearson's r > 0.9) between human and LLM criterion weights. Furthermore, hypothesis testing reveals no significant differences (p > 0.8), with the models demonstrating high internal consistency. Our study offers valuable insights for academics and industry professionals seeking to improve KG construction processes and establish standards for data quality and verification.  © 2023 IEEE.},
	author_keywords = {criteria development approach; knowledge graphs construction; knowledge source selection; large language models; website evaluation criteria},
	keywords = {Benchmarking; Computational linguistics; Construction; Data acquisition; Graphic methods; Knowledge management; Quality control; Websites; Criteria development approach; Development approach; Evaluation criteria; Graph construction; Knowledge graph construction; Knowledge graphs; Knowledge source selection; Knowledge sources; Language model; Large language model; Source selection; Website evaluation; Website evaluation criteria; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Procko2023147,
	author = {Procko, Tyler Thomas and Elvira, Timothy and Ochoa, Omar},
	title = {GPT-4: A Stochastic Parrot or Ontological Craftsman? Discovering Implicit Knowledge Structures in Large Language Models},
	year = {2023},
	journal = {Proceedings - 2023 5th International Conference on Transdisciplinary AI, TransAI 2023},
	pages = {147 – 154},
	doi = {10.1109/TransAI60598.2023.00043},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184808375&doi=10.1109%2fTransAI60598.2023.00043&partnerID=40&md5=10fd5c5e6afb21570af17fd717479d4c},
	abstract = {Ontologies are representational artifacts that purport to accurately portray the aspect of reality under the purview of the ontologists laboring upon them. Ontologies exist in a spectrum of formality, from lexical thesauri to knowledge graphs, to collections of statements of first-order logic. The recent proliferation of Large Language Models (LLMs) has brought to bear interactive 'knowledge bases' with general awareness of most things. As ontologists create ontologies from their understanding of reality; and as LLMs, presumably, possess some 'understanding' of reality, embedded in their vector matrices corresponding to lexical terms from massive quantities of learned texts, a question is posed: what form of ontology can an LLM create when prompted about some novel facet of reality, without explicitly asking it for an ontology? I.e., will an LLM categorize things into bins, or a subsumption hierarchy, or perhaps something else? LLMs, as they are understood, respond when prompted with the most likely response, because they are predictors of next tokens, i.e., they are stochastic parrots. In any case, it is posited that, if prompted without any explicit request for an ontology, an LLM can produce an ontology of novel form, effectively granting insight into the 'understanding' an LLM has of the world, as all humans possess an understanding of the world that ontologies are based upon. This paper explores the use of the flagship LLM, GPT-4, in forming an ontology of a novel domain.  © 2023 IEEE.},
	author_keywords = {GPT; large language models; ontology; taxonomy},
	keywords = {Birds; Computational linguistics; Formal logic; Stochastic models; Stochastic systems; First order logic; GPT; Implicit knowledge; Knowledge graphs; Knowledge structures; Language model; Large language model; Ontology's; Spectra's; Stochastics; Ontology},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Qin202344,
	author = {Qin, Xiaodong and He, Yuxuan and Ma, Jie and Peng, Weiyuan and Zio, Enrico and Su, Huai},
	title = {An Effective Knowledge Mining Method for Compressor Fault Text Data Based on Large Language Model},
	year = {2023},
	journal = {Proceedings - 2023 International Conference on Computer Science and Automation Technology, CSAT 2023},
	pages = {44 – 48},
	doi = {10.1109/CSAT61646.2023.00024},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85190411271&doi=10.1109%2fCSAT61646.2023.00024&partnerID=40&md5=dbefbeec606ff92b18f631dd71228f63},
	abstract = {The fault diagnosis method of compressors determines the reliability of the gas transmission pipeline station. Existing compressor fault diagnosis methods mostly relies on data-driven, which leads to a high application threshold from the mechanism. To address this issue, this paper introduces the knowledge graph into the compressor fault diagnosis for the first time and proposes a compressor fault text data knowledge mining method based on large language model. Firstly, the characteristics and principles of compressor faults are analyzed. Then, a text data knowledge mining model called CFRTE for compressors is constructed. Experimental results show that the Fl score of the CFRTE model can reach 0.98, meeting the requirements of compressor fault knowledge mining. Finally, combined with the results of knowledge mining and the graph database, a new system for the storage and indexing of the compressor fault knowledge graph is proposed. To further verify the role of the large language model in compressor fault knowledge mining, this paper conducts a comparative experiment of CFRTE models based on RNN encoder and BERT encoder. Experimental results show that compared with GRU, BiGRU, LSTM, and BiLSTM as the encoder layer, the Fl score of the CFRTE model with BERT as the encoder layer has increased by 26.78%, 6.18%, 21.89%, and 5.49% respectively. This work provides a systematic feasible scheme for introducing knowledge graphs into compressor fault diagnosis, which can be used for reference in the fault diagnosis of related equipment.  © 2023 IEEE.},
	author_keywords = {compressor; compressor station; knowledge graph; knowledge mining; large language model},
	keywords = {Big data; Computational linguistics; Data mining; Failure analysis; Fault detection; Gas compressors; Knowledge graph; Long short-term memory; Signal encoding; Compressor stations; Fault diagnosis method; Faults diagnosis; Gas transmission pipeline; Knowledge graphs; Knowledge mining; Language model; Large language model; Mining methods; Text data; Digital storage},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@CONFERENCE{2023,
	title = {International Conference Recent Advances in Natural Language Processing, RANLP 2023: Large Language Models for Natural Language Processing - Proceedings},
	year = {2023},
	journal = {International Conference Recent Advances in Natural Language Processing, RANLP},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179603977&partnerID=40&md5=fae59d12bc4af04d2a258b9ea496678c},
	abstract = {The proceedings contain 135 papers. The topics discussed include: Bipol: multi-axes evaluation of bias with explainability in benchmark datasets; automatically generating Hindi Wikipedia pages using Wikidata as a knowledge graph: a domain-specific template sentences approach; cross-lingual classification of crisis-related tweets using machine translation; lexicon-driven automatic sentence generation for the skills section in a job posting; multilingual racial hate speech detection using transfer learning; exploring Amharic hate speech data collection and classification approaches; are you not moved? incorporating sensorimotor knowledge to improve metaphor detection; HAQA and QUQA: constructing two Arabic question-answering Corpora for the Quran and Hadith; a review in knowledge extraction from knowledge bases; evaluating of large language models in relationship extraction from unstructured data: empirical study from holocaust testimonies; and impact of emojis on automatic analysis of individual emotion categories.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Anand202337,
	author = {Anand, Avinash and Gupta, Mohit and Prasad, Kritarth and Goel, Ujjwal and Lal, Naman and Verma, Astha and Shah, Rajiv Ratn},
	title = {KG-CTG: Citation Generation Through Knowledge Graph-Guided Large Language Models},
	year = {2023},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14418 LNCS},
	pages = {37 – 49},
	doi = {10.1007/978-3-031-49601-1_3},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180543792&doi=10.1007%2f978-3-031-49601-1_3&partnerID=40&md5=90a653ca5f034054a35f19088a4bd22a},
	abstract = {Citation Text Generation (CTG) is a task in natural language processing (NLP) that aims to produce text that accurately cites or references a cited document within a source document. In CTG, the generated text draws upon contextual cues from both the source document and the cited paper, ensuring accurate and relevant citation information is provided. Previous work in the field of citation generation is mainly based on the text summarization of documents. Following this, this paper presents a framework, and a comparative study to demonstrate the use of Large Language Models (LLMs) for the task of citation generation. Also, we have shown the improvement in the results of citation generation by incorporating the knowledge graph relations of the papers in the prompt for the LLM to better learn the relationship between the papers. To assess how well our model is performing, we have used a subset of standard S2ORC dataset, which only consists of computer science academic research papers in the English Language. Vicuna performs best for this task with 14.15 Meteor, 12.88 Rouge-1, 1.52 Rouge-2, and 10.94 Rouge-L. Also, Alpaca performs best, and improves the performance by 36.98% in Rouge-1, and 33.14% in Meteor by including knowledge graphs. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Citation Text Generation; Knowledge Graphs; Large Language Models; Natural Language Processing},
	keywords = {Computational linguistics; Natural language processing systems; Citation text generation; Cited papers; Contextual cue; Knowledge graphs; Language model; Language processing; Large language model; Natural language processing; Natural languages; Text generations; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{2023,
	title = {Proceedings of the Workshop on Multimodal, Multilingual Natural Language Generation and Multilingual WebNLG Challenge, MM-NLG 2023},
	year = {2023},
	journal = {Proceedings of the Workshop on Multimodal, Multilingual Natural Language Generation and Multilingual WebNLG Challenge, MM-NLG 2023},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187278203&partnerID=40&md5=25b5b5425edb36ed3f97aa86d8e19a5a},
	abstract = {The proceedings contain 11 papers. The topics discussed include: confidently wrong: exploring the calibration and expression of (un)certainty of large language models in a multilingual setting; visual question generation in Bengali; keeping an eye on context: attention allocation over input partitions in referring expression generation; are language-and-vision transformers sensitive to discourse? a case study of ViLBERT; using large language models for zero-shot natural language generation from knowledge graphs; the 2023 WebNLG shared task on low resource languages overview and evaluation results (WebNLG 2023); WebNLG-Interno: utilizing FRED-T5 to address the RDF-to-text problem; and better translation + split and generate for multilingual RDF-to-text.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Fahland202325,
	author = {Fahland, Dirk and Fournier, Fabiana and Limonad, Lior and Skarbovsky, Inna and Swevels, Ava J.E.},
	title = {Why are my Pizzas late?},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3569},
	pages = {25 – 28},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180150865&partnerID=40&md5=15385552ae5be202db9de0371cff4573},
	abstract = {We refer to explainability as a system's ability to provide sound and human-understandable insights concerning its outcomes. Explanations should accurately reflect causal relations in process executions [1]. This abstract suggests augmenting process discovery (PD) with causal process discovery (CD) to generate causal-process-execution narratives. These narratives serve as input for large language models (LLMs) to derive sound and human-interpretable explanations. A multi-layered knowledge-graph is employed to facilitate diverse process views. Background. Process discovery (PD) summarizes an event log L into a graph model M that represents activities and control-flow dependencies [2]. Most PD algorithms construct edges in M that indicates to which subsequent activities process control “flows to”. This relation is derived from traces by computing “temporally precedes” (<) and “directly precedes” (⋖) relations over activity names, and then discarding a < b iff a ⋖ b and b ⋖ a [3]. Advancements in Machine Learning (ML) have made ML models more complex, sacrificing explainability and resulting in “black box” models. This led to the emergence of external explanation frameworks, known as XAI, to enhance understandability [4]. XAI frameworks are predominantly applied post-hoc, after the ML model's training [5]. Causal discovery [6] infers causal graphs from data by exploring relationships like A →−c B where changes in A entail changes in B. In this work, we used the Linear Non-Gaussian Acyclic Model (LiNGAM) [7] for CD as in [1]. Inspired by[8], which highlights LLMs' ability to provide interpretable explanations, we aim to demonstrate that CD can enhance explanations of process execution outcomes when used as input for LLMs. LLMs are deep-learning models trained on text data, adept at few-shot and zero-shot learning using prompt-based techniques [9]. Approach. Our research aims are combining PD, CD, and XAI to generate narratives for improved process outcome explanations using LLMs. As a proof-of-concept (POC), we show how CD helps to leverage LLMs for more sound explanations. We use a multi-layered knowledge graph stored in a Neo4j database as infrastructure. We model the data using labeled property graphs in which each node and each relationship (directed edge) is typed by a label. Fig. 1 shows the graph schema. Each Event node has a timestamp, and is correlated to one case; the directly-follows relations describe the temporal order of all events correlated to the same case. These concepts allow modeling any event log in a graph [10]. © 2023 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).},
	keywords = {Abstracting; Flow graphs; Knowledge graph; Knowledge management; Learning systems; Process control; Zero-shot learning; Causal relations; Control-flow; Event logs; In-process; Knowledge graphs; Language model; Machine learning models; Multi-layered; Process Discovery; Process execution; Deep learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@BOOK{Lussier2023V1,
	author = {Lussier, Yves A.},
	title = {Enhancing Precision Medicine and Wellness with Computing and AI across Clinical, Imaging, Environmental, Multi-Omics, Wearable Sensors, and Socio-Cognitive Data},
	year = {2023},
	journal = {Comprehensive Precision Medicine, First Edition, Volume 1-2},
	volume = {1-2},
	pages = {V1–1 – V1–8},
	doi = {10.1016/B978-0-12-824010-6.00082-4},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85191915641&doi=10.1016%2fB978-0-12-824010-6.00082-4&partnerID=40&md5=172502481e3f59fe5f0484a5123f2772},
	abstract = {The convergence of computational capabilities and data-driven methodologies, spurred by the onset of the Third Industrial Revolution (Digital Age) as well as their integration into robotic tools and medical implants, often referred to as the Fourth Industrial Revolution (Park, 2016), is instigating a substantive transformation in clinical decision support that is rapidly changing the economics and practice of healthcare (Sutton et al., 2020). Here we introduce the strengths, challenges, and future trajectories of computational medicine, informatics, and machine learning (ML) methods as applied in the realm of precision healthcare and wellness (Lee et al., 2018). Precision medicine and precision wellness, situated at the intersection of technological advancements in clinical decision-making methods that impact the use, reuse, transformations, and analysis of data ranging from the nanoscale to clinical and societal dimensions of measurements, is the focal point of our discussion. We approach this subject through a dual perspective: one being a clinical data-focused approach that incorporates biomedical informatics with syntactic and semantic methods of interoperability (Garde et al., 2007; Strasberg et al., 2021), as well as human-interpretable decision algorithm and the other being a bottom-up approach rooted in genomics, biophysical and multiscale methods that increasingly employ robust yet human-opaque ML analytics (Lussier and Li, 2012). We conclude with an exploration of the remaining challenges, prospective opportunities, and future directions that arise at the confluence of these multifaceted methodologies inclusive of artificial intelligence and large language models in medicine (Shehab et al., 2022). © 2023 Elsevier Inc. All rights reserved.},
	author_keywords = {Artificial intelligence and medicine; Biomedical informatics; Biomedical ontologies and terminologies; Biomedical semantic interoperability; Biomedical syntactic interoperability; Clinical data science; Clinical decision support; Clinical explainability and interpretability; Clinical reasoning with certainty and uncertainty; Electronic health record; Genomic medicine; ML and medicine; Multi-omics medicine; N-of-1 trials; Precision diagnostic; Precision medicine; Precision therapeutic; Precision wellness; Predictive clinical analytics; Single-subject studies},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Kim202312930,
	author = {Kim, Hyunwoo and Hessel, Jack and Jiang, Liwei and West, Peter and Lu, Ximing and Yu, Youngjae and Zhou, Pei and Le Bras, Ronan and Alikhani, Malihe and Kim, Gunhee and Sap, Maarten and Choi, Yejin},
	title = {SODA: Million-scale Dialogue Distillation with Social Commonsense Contextualization},
	year = {2023},
	journal = {EMNLP 2023 - 2023 Conference on Empirical Methods in Natural Language Processing, Proceedings},
	pages = {12930 – 12949},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180115102&partnerID=40&md5=12b0e44e0a319f34c4059a94a40028d7},
	abstract = {Data scarcity has been a long standing issue in the field of open-domain social dialogue. To quench this thirst, we present SODA: the first publicly available, million-scale high-quality social dialogue dataset. By contextualizing social commonsense knowledge from a knowledge graph, we are able to distill an exceptionally broad spectrum of social interactions from a large language model. Human evaluation shows that conversations in SODA are more consistent, specific, and (surprisingly) natural than those in prior human-authored datasets. Using SODA, we train COSMO: a generalizable conversation model that is significantly more natural and consistent on unseen datasets than best-performing conversation models (e.g., GODEL, BlenderBot-1, Koala, Vicuna). Experiments reveal COSMO is sometimes even preferred to the original human-written gold responses. Additionally, our results shed light on the distinction between knowledge-enriched conversations and natural social chitchats. We make our data, models, and code public. ©2023 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Knowledge graph; Broad spectrum; Commonsense knowledge; Contextualization; Data scarcity; High quality; Human evaluation; Knowledge graphs; Language model; Social dialogue; Social interactions; Distillation},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 23}
}

@CONFERENCE{Du2023,
	author = {Du, Xinwei and Ahrabian, Kian and Ananthan, Arun Baalaaji Sankar and Myloth, Richard Delwin and Pujara, Jay},
	title = {Citation Intent Classification Through Weakly Supervised Knowledge Graphs},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3656},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85189172995&partnerID=40&md5=de7073c73cd007895dbebf41ad234ba1},
	abstract = {Citations are scientists’ tools for grounding their innovations and findings in the existing collective knowledge. They are used for semantically distinct purposes as scientists utilize them at different parts of their work to convey specific information. As a result, a crucial aspect of scientific document understanding is recognizing the authorial intent associated with citations. Current state-of-the-art methods rely on contextual sentences surrounding each citation to classify the intent. However, in the absence of textual content, these approaches become unusable. In this work, we propose a text-free citation intent classification method built on relational information among scholarly works in this work. To this end, we introduce a large-scale knowledge graph built from the publications in the SciCite dataset and their multi-hop neighborhood extracted from The Semantic Scholar Open Research Corpus (S2ORC). We also augment this knowledge graph by adding weakly-labeled links based on the intent information available in the S2ORC. Finally, we cast the intent classification task as a link prediction problem on the newly created knowledge graph. We study this problem in both transductive and inductive settings. Our experimental results show that we can achieve a comparable macro F1 score to word embedding content-based methods by only relying on features and relations derived from this knowledge graph. Specifically, we achieve macro F1 scores of 62.16 and 59.81 in the transductive and inductive settings, respectively, on the link-level SciCite dataset. Moreover, by combining our method with the state-of-the-art NLP-based model, we achieve improvements across all metrics. © 2023 Copyright for this paper by its authors.},
	author_keywords = {Citation Intent Classification; Graph Neural Networks; Knowledge Graphs; Large Language Models; Weakly supervised learning},
	keywords = {Graph neural networks; Knowledge graph; Large datasets; Machine learning; Semantics; Text processing; Citation intent classification; Document understanding; F1 scores; Graph neural networks; Knowledge graphs; Language model; Large language model; Scientific documents; Specific information; Weakly supervised learning; Classification (of information)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Händler202385,
	author = {Händler, Thorsten},
	title = {A Taxonomy for Autonomous LLM-Powered Multi-Agent Architectures},
	year = {2023},
	journal = {International Joint Conference on Knowledge Discovery, Knowledge Engineering and Knowledge Management, IC3K - Proceedings},
	volume = {3},
	pages = {85 – 98},
	doi = {10.5220/0012239100003598},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179763690&doi=10.5220%2f0012239100003598&partnerID=40&md5=b5052f30c5c4e2410e7e355e3aecd366},
	abstract = {Large language models (LLMs) have revolutionized the field of artificial intelligence, endowing it with sophisticated language understanding and generation capabilities. However, when faced with more complex and interconnected tasks that demand a profound and iterative thought process, LLMs reveal their inherent limitations. Autonomous LLM-powered multi-agent systems represent a strategic response to these challenges. While these architectures hold promising potential in amplifying AI capabilities, striking the right balance between different levels of autonomy and alignment remains the crucial challenge for their effective operation. This paper proposes a comprehensive multi-dimensional taxonomy, engineered to analyze how autonomous LLM-powered multi-agent systems balance the dynamic interplay between autonomy and alignment across various aspects inherent to architectural viewpoints such as goal-driven task management, agent composition, multi-agent collaboration, and context interaction. Our taxonomy aims to empower researchers, engineers, and AI practitioners to systematically analyze the architectural dynamics and balancing strategies employed by these increasingly prevalent AI systems. The exploratory taxonomic classification of selected representative LLM-powered multi-agent systems illustrates its practical utility and reveals potential for future research and development. An extended version of this paper is available on arXiv (Händler, 2023). Copyright © 2023 by SCITEPRESS - Science and Technology Publications, Lda.},
	author_keywords = {AI System Classification; Alignment; Architectural Viewpoints; Artificial Intelligence; Autonomous Agents; Context Interaction; Domain-Ontology Diagram; Feature Diagram; Large Language Models (LLMs); Multi-Agent Collaboration; Radar Chart; Software Architecture; Software-Design Rationale; Taxonomy},
	keywords = {Autonomous agents; Computational linguistics; Multi agent systems; Software architecture; Software design; Agent collaboration; AI system classification; AI systems; Architectural viewpoints; Context interaction; Design rationale; Domain ontologies; Domain-ontology diagram; Feature diagrams; Language model; Large language model; Multi agent; Multi-agent collaboration; Radar chart; Software-design rationale; System classification; Taxonomies},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Rockstroh2023,
	author = {Rockstroh, Johanna and D'Ippolito, Giada and Lazzari, Nicolas and Oudshoorn, Anouk M. and Purohit, Disha and Raoufi, Ensiyeh and Rudolph, Sebastian},
	title = {A is the B of C: (Semi)-Automatic Creation of Vossian Antonomasias},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3640},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85185883644&partnerID=40&md5=75310ef06d1a4910465068f543b5570e},
	abstract = {A Vossian Antonomasia (VA) is a stylistic device used to describe a person (or, more generally, an entity) in terms of a well-known person and a modifying context. For instance, the Norwegian chess world champion Magnus Carlsen was described as "the Mozart of chess"[1]. All VAs follow the pattern where a source (e.g., "Mozart"), is used to describe a target, (e.g., "Magnus Carlsen"), and the transfer of meaning is "channeled"through the use of the modifier "of chess". Although this rhetorical figure is well-known, there has not yet been a dedicated study of targeted automatic or semi-automatic methods to generate and judge the appropriateness of VAs using large Knowledge Graphs (KGs) such as Wikidata. In our work, we propose the use of vector space embeddings - both KG-based and text-based - for producing VAs. For comparison, we contrast our findings with a purely LLM-based approach, wherein VAs are obtained from ChatGPT using a reasonably engineered prompt. We provide a publicly available GitHub repository1 for the implementation of our method and a website2 that allows testing the proposed methods. © 2023 Copyright for this paper by its authors.},
	keywords = {Vector spaces; Automatic creations; Graph-based; Knowledge graphs; Semi-automatics; Semiautomatic methods; Stylistic devices; Vector-space embedding; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Zhou20236491,
	author = {Zhou, Wentao and Zhao, Jun and Gui, Tao and Zhang, Qi and Huang, Xuanjing},
	title = {Inductive Relation Inference of Knowledge Graph Enhanced by Ontology Information},
	year = {2023},
	journal = {Findings of the Association for Computational Linguistics: EMNLP 2023},
	pages = {6491 – 6502},
	doi = {10.18653/v1/2023.findings-emnlp.431},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183302828&doi=10.18653%2fv1%2f2023.findings-emnlp.431&partnerID=40&md5=a73a6239c552211f77ca38ab84dd8781},
	abstract = {The inductive inference of the knowledge graph aims to complete the potential relations between the new unknown entities in the graph. Most existing methods are based on entity-independent features such as graph structure information and relationship information to inference. However, the neighborhood of these new entities is often too sparse to obtain enough information to build these features effectively. In this work, we propose a knowledge graph inductive inference method that fuses ontology information. Based on the enclosing subgraph, we bring in feature embeddings of concepts corresponding to entities to learn the semantic information implicit in the ontology. Considering that the ontology information of entities may be missing, we build a type constraint regular loss to explicitly model the semantic connections between entities and concepts, and thus capture the missing concepts of entities. Experimental results show that our approach significantly outperforms large language models like ChatGPT on two benchmark datasets, YAGO21K-610 and DB45K-165, and improves the MRR metrics by 15.4% and 44.1%, respectively, when compared with the state-of-the-art methods. © 2023 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Graphic methods; Knowledge graph; Large datasets; Semantics; AS graph; Graph structures; Inductive inference; Inference methods; Knowledge graphs; Neighbourhood; Ontology's; Structure information; Subgraphs; Unknown entities; Ontology},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Qi20234623,
	author = {Qi, JuanZhi and Wang, XinYu and Yang, Tao},
	title = {Traditional Chinese Medicine Prescription Recommendation Model Based on Large Language Models and Graph Neural Networks},
	year = {2023},
	journal = {Proceedings - 2023 2023 IEEE International Conference on Bioinformatics and Biomedicine, BIBM 2023},
	pages = {4623 – 4627},
	doi = {10.1109/BIBM58861.2023.10385489},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184893779&doi=10.1109%2fBIBM58861.2023.10385489&partnerID=40&md5=ca82248177ed058ca988f02f0efc816f},
	abstract = {Background: Traditional Chinese medicine (TCM) has a millennia-long history, offering unique treatments and insights into global health. Given the intricate symptoms and shifting syndrome patterns, prescribing can be tough for young doctors. TCM prescription recommendations can help these doctors address their experience gap. In recent years, with advancements in technologies such as artificial intelligence and big data, intelligent recommendations for TCM prescriptions have become feasible, holding significant implications for enhancing treatment efficacy and optimizing patient experience. Objective: This study aims to establish a novel TCM prescription recommendation model by integrating large language models with Graph Neural Network (GNN) to enhance the accuracy of prescription suggestions. Method: Based on the co-occurrence of symptoms and herbal medicines, we constructed symptom graphs, symptom-herb graphs, and herb-herb graphs. Using Graph Convolutional Network (GCN), we acquired embeddings for both symptoms and herbs. The symptom embeddings are then integrated with insights from large language model embeddings, while auxiliary information from an external knowledge graph is incorporated into the herb embeddings. A final list of herb recommendations was generated by interacting with the embeddings of symptoms and herbs. Results: The proposed algorithm achieved 22.1%, 17.2%, and 13% on the evaluation metrics P@5, P@10, and P@20, respectively. Concurrently, scores for R@5, R@10, and R@20 were 14%, 24%, and 32.5%, respectively. The P@5 metric surpassed the KDHR by 4.7%, and the R@20 metric exceeded the KDHR by 6%. Overall, the performance of our model outperformed other baseline models across various evaluation criteria. Conclusion: The TCM prescription recommendation model, infused with information from a large language model, can effectively enhance the outcomes of TCM prescription recommendations. The study may offer valuable insights for auxiliary clinical research and treatment in TCM.  © 2023 IEEE.},
	author_keywords = {Graph neural network; Large language model; Prescription recommendation; Traditional Chinese Medicine},
	keywords = {Brain; Clinical research; Computational linguistics; Knowledge graph; Patient treatment; Recommender systems; Chinese medicine prescriptions; Embeddings; Global health; Graph neural networks; Language model; Large language model; Model-based OPC; Prescription recommendation; Syndrome patterns; Traditional Chinese Medicine; Embeddings},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Chen202314815,
	author = {Chen, Derek and Lee, Celine and Lu, Yunan and Rosati, Domenic and Yu, Zhou},
	title = {Mixture of Soft Prompts for Controllable Data Generation},
	year = {2023},
	journal = {Findings of the Association for Computational Linguistics: EMNLP 2023},
	pages = {14815 – 14833},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183292253&partnerID=40&md5=b4e1d0d512ae188891d239b0b716dba1},
	abstract = {Large language models (LLMs) effectively generate fluent text when the target output follows natural language patterns. However, structured prediction tasks confine the output format to a limited ontology, causing even very large models to struggle since they were never trained with such restrictions in mind. The difficulty of using LLMs for direct prediction is exacerbated in few-shot learning scenarios, which commonly arise due to domain shift and resource limitations. We flip the problem on its head by leveraging the LLM as a tool for data augmentation rather than a model for direct prediction. Our proposed Mixture of Soft Prompts (MSP) serves as a parameter-efficient procedure for generating multi-attribute data in a controlled manner. Denoising mechanisms are further applied to improve the quality of synthesized data. Automatic metrics show our method is capable of producing diverse and natural text, while preserving label semantics. Moreover, MSP achieves state-of-the-art results on three benchmarks when compared against strong baselines. Our method offers an alternate data-centric approach for applying LLMs to complex prediction tasks. © 2023 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Natural language processing systems; Semantics; Data generation; Direct prediction; Fluents; Language model; Large models; Natural language patterns; Ontology's; Output formats; Prediction tasks; Structured prediction; Forecasting},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@CONFERENCE{Hertling2023170,
	author = {Hertling, Sven and Paulheim, Heiko},
	title = {OLaLa Results for OAEI 2023},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3591},
	pages = {170 – 177},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180814848&partnerID=40&md5=b8d5fac66dc9350abb833bd534428cf1},
	abstract = {This paper presents the results of the OLaLa matching system participating in the OAEI 2023. The system is based on sentence-transformers as well as large language models. The former is used to generate correspondence candidates which is independent of any overlapping tokens because the comparison is only based on embeddings. To finally select the best mappings, a large language model is used to decide if two given textual representations of the source and target concept are equal or not. Based on positive and negative words that the LLM predicts, a confidence is extracted. Still, there are a lot of decisions that heavily influence the final result like (1) how can each concept be verbalized into text, (2) which prompt to use, and (3) which language model to choose. A lot of combinations were executed and the most useful one is submitted and packaged as a matching system. © 2023 Copyright for this paper by its authors.},
	author_keywords = {Knowledge Graphs; Large Language Model; Ontology Matching},
	keywords = {Knowledge graph; Ontology; Embeddings; Knowledge graphs; Language model; Large language model; Matching system; Ontology matching; Target concept; Textual representation; Computational linguistics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{2023,
	title = {11th International Conference on Big Data and Artificial Intelligence, BDA 2023},
	year = {2023},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14418 LNCS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180620699&partnerID=40&md5=9cd0e4cf11b1616b5c22b8618cb47f0b},
	abstract = {The proceedings contain 17 papers. The special focus in this conference is on Big Data and Artificial Intelligence. The topics include: Evaluation of Hybrid Quantum Approximate Inference Methods on Bayesian Networks; IndoorGNN: A Graph Neural Network Based Approach for Indoor Localization Using WiFi RSSI; ensemble-Based Road Surface Crack Detection: A Comprehensive Approach; fast Similarity Search in Large-Scale Iris Databases Using High-Dimensional Hashing; explaining Finetuned Transformers on Hate Speech Predictions Using Layerwise Relevance Propagation; multilingual Speech Sentiment Recognition Using Spiking Neural Networks; FopLAHD: Federated Optimization Using Locally Approximated Hessian Diagonal; A Review of Approaches on Facets for Building IT-Based Career Guidance Systems; GREAT AI in Medical Appropriateness and Value-Based-Care; KG-CTG: Citation Generation Through Knowledge Graph-Guided Large Language Models; SciPhyRAG - Retrieval Augmentation to Improve LLMs on Physics Q &A; revolutionizing High School Physics Education: A Novel Dataset; context-Enhanced Language Models for Generating Multi-paper Citations; GEC-DCL: Grammatical Error Correction Model with Dynamic Context Learning for Paragraphs and Scholarly Papers; a Deep Learning Emotion Classification Framework for Low Resource Languages.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Yang2023,
	author = {Yang, Dong and Wang, Xu and Celebi, Remzi},
	title = {Expanding the Vocabulary of BERT for Knowledge Base Construction},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3577},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179556106&partnerID=40&md5=573d7d647e57f6d728e501a00a111cb5},
	abstract = {Knowledge base construction entails acquiring structured information to create a knowledge base of factual and relational data, facilitating question answering, information retrieval, and semantic understanding. The challenge called”Knowledge Base Construction from Pretrained Language Models” at International Semantic Web Conference 2023 defines tasks focused on constructing knowledge base using language model. Our focus was on Track 1 of the challenge, where the parameters are constrained to a maximum of 1 billion, and the inclusion of entity descriptions within the prompt is prohibited. Although the masked language model offers sufficient flexibility to extend its vocabulary, it is not inherently designed for multi-token prediction. To address this, we present Vocabulary Expandable BERT for knowledge base construction, which expand the language model’s vocabulary while preserving semantic embeddings for newly added words. We adopt task-specific re-pre-training on masked language model to further enhance the language model. Through experimentation, the results show the effectiveness of our approaches. Our framework achieves F1 score of 0.323 on the hidden test set and 0.362 on the validation set, both data set is provided by the challenge. Notably, our framework adopts a lightweight language model (BERT-base, 0.13 billion parameters) and surpasses the model using prompts directly on large language model (Chatgpt-3, 175 billion parameters). Besides, Token-Recode achieves comparable performances as Re-pretrain. This research advances language understanding models by enabling the direct embedding of multi-token entities, signifying a substantial step forward in link prediction task in knowledge graph and metadata completion in data management. 1 © 2023 CEUR-WS. All rights reserved.},
	keywords = {Computational linguistics; Embeddings; Knowledge graph; Semantic Web; Statistical tests; Information semantics; Knowledge-base construction; Language model; Multi tokens; Question Answering; Relational data; Semantic-Web; Semantics understanding; Structured information; Web conferences; Information management},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Zuo2023834,
	author = {Zuo, Xu and Zhou, Yujia and Duke, Jon and Hripcsak, George and Shah, Nigam and Banda, Juan M. and Reeves, Ruth and Miller, Timothy and Waitman, Lemuel R. and Natarajan, Karthik and Xu, Hua},
	title = {Standardizing Multi-site Clinical Note Titles to LOINC Document Ontology: A Transformer-based Approach},
	year = {2023},
	journal = {AMIA ... Annual Symposium proceedings. AMIA Symposium},
	volume = {2023},
	pages = {834 – 843},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85182546900&partnerID=40&md5=685a6b791b7981d1ac091630bc9446e5},
	abstract = {The types of clinical notes in electronic health records (EHRs) are diverse and it would be great to standardize them to ensure unified data retrieval, exchange, and integration. The LOINC Document Ontology (DO) is a subset of LOINC that is created specifically for naming and describing clinical documents. Despite the efforts of promoting and improving this ontology, how to efficiently deploy it in real-world clinical settings has yet to be explored. In this study we evaluated the utility of LOINC DO by mapping clinical note titles collected from five institutions to the LOINC DO and classifying the mapping into three classes based on semantic similarity between note titles and LOINC DO codes. Additionally, we developed a standardization pipeline that automatically maps clinical note titles from multiple sites to suitable LOINC DO codes, without accessing the content of clinical notes. The pipeline can be initialized with different large language models, and we compared the performances between them. The results showed that our automated pipeline achieved an accuracy of 0.90. By comparing the manual and automated mapping results, we analyzed the coverage of LOINC DO in describing multi-site clinical note titles and summarized the potential scope for extension. ©2023 AMIA - All rights reserved.},
	keywords = {Electronic Health Records; Humans; Information Storage and Retrieval; Logical Observation Identifiers Names and Codes; Semantics; electronic health record; human; information retrieval; Logical Observation Identifiers Names and Codes; semantics},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Bai2023,
	author = {Bai, Chuanyang and Zheng, Jiaming and Hu, Jiexin and Zhou, Linna and Chen, Jiabin and Yang, Hongjie},
	title = {SSGCN: a graph convolutional neural network model based on syntactic structure and similarity features for relation extraction in shipbuilding industry},
	year = {2023},
	journal = {Proceedings of SPIE - The International Society for Optical Engineering},
	volume = {12943},
	doi = {10.1117/12.3014256},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180152539&doi=10.1117%2f12.3014256&partnerID=40&md5=b656bf486ea0980ee5619e38befa5d08},
	abstract = {The construction of the standard knowledge graph is to realize the reorganization of the internal knowledge of the traditional standard texts and achieve the purpose of innovating knowledge storage and the practice of knowledge supply. Technical requirement extraction is a typical relation extraction task in the construction process of a standard knowledge graph. However, the existing relation extraction models can not achieve ideal performance due to standard texts' unique organizational forms and special writing characteristics. Therefore, This paper proposes a Graph Convolutional Neural Network model based on Syntactic structure and Similarity features (SSGCN), integrating expert knowledge in syntactic pruning, dynamically interfering with the weight matrix by the pruning strategy based on attention, and making full use of supervised relation label semantic similarity features. The experiment in this paper compares the large language models (LLMs) such as GPT-3, and our model achieves better experimental performance than other relation extraction models on specialized datasets in the field, providing a related solution for standard technical requirement extraction tasks. © 2023 SPIE.},
	author_keywords = {graph convolutional neural network; llms; Relation extraction; standard knowledge graph; syntactic pruning},
	keywords = {Convolution; Convolutional neural networks; Extraction; Graph neural networks; Knowledge graph; Large dataset; Neural network models; Semantics; Convolutional neural network; Graph convolutional neural network; Knowledge graphs; Llms; Model-based OPC; Neural network model; Relation extraction; Standard knowledge graph; Syntactic pruning; Syntactic similarities; Syntactics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Bringsjord2023,
	author = {Bringsjord, Selmer and Slowik, John and Govindarajulu, Naveen Sundar and Giancola, Michael and Oswald, James and Ghosh, Rikhiya},
	title = {Affect-based Planning for a Meta-Cognitive Robot Sculptor: First Steps},
	year = {2023},
	journal = {2023 11th International Conference on Affective Computing and Intelligent Interaction Workshops and Demos, ACIIW 2023},
	doi = {10.1109/ACIIW59127.2023.10388202},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184799871&doi=10.1109%2fACIIW59127.2023.10388202&partnerID=40&md5=ee5fd498b3048508e0753bc892580df3},
	abstract = {Today's so-called 'generative AI' is in the minds of some capable of specifically generating genuine visual art; DALL-E is an example. While in fact intensely skeptical, we grant for the sake of argument that the likes of DALL-E can in fact generate genuine visual art. However, we observe that fine visual artistry is by no means monolithic; in particular, some forms of fine visual artistry are seemingly harder than others for artificial agents to achieve. In the traditional ontology, perhaps the very hardest type of fine visual artistry for an AI to achieve is literary sculpture, an activity carried out in the human sphere at the very highest level by Rodin. Artificial agents that operate in this sphere must for obvious reasons be cognitive robots. We explain such literary sculpture in broad terms, making clear that it's undertaken by the sculptor in question with the aim of bringing about certain affective states in the mind of the viewer of the sculpture. In short, literary sculpting is affect-driven. We provide a case study of robot sculpting, with help from pre-existing logic-based formalisms and automated-reasoning technology, and the cognitive robot PERI.2, operating as a sculptor. To our knowledge, ours is the very first foray into literary sculpture in AI and cognitive robotics.  © 2023 IEEE.},
	author_keywords = {AI; cognitive robotics; creativity; logic-based AI; sculpture},
	keywords = {Computer circuits; Affect-based; Artificial agents; Cognitive robotics; Cognitive robots; Creativity; Logic-based AI; Metacognitives; Monolithics; Sculpture; Visual arts; Robot programming},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Ren20233189,
	author = {Ren, Zixuan and Zhao, Yang and Zong, Chengqing},
	title = {Towards Informative Open-ended Text Generation with Dynamic Knowledge Triples},
	year = {2023},
	journal = {Findings of the Association for Computational Linguistics: EMNLP 2023},
	pages = {3189 – 3203},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183306120&partnerID=40&md5=85e02c018d29e3146ef9dd25a7746c30},
	abstract = {Pretrained language models (PLMs), especially large language models (LLMs) demonstrate impressive capabilities in open-ended text generation. While our statistical results show that LLMs often suffer from over-concentrated information, where the generated texts overly focus on the given prompt and fail to provide sufficient background and detailed information as humans do. To address this issue, we propose a dynamic knowledge-guided informative open-ended text generation approach, that utilizes a knowledge graph to help the model generate more contextually related entities and detailed facts. Specifically, we first employ a local knowledge filter to extract relevant knowledge from the comprehensive knowledge graph for a given topic sentence. Then we introduce a dynamic knowledge selector to predict the entity to be mentioned in the subsequent sentence. Finally, we utilize a knowledge-enhanced text generator to produce a more informative output. To evaluate the effectiveness of our approach, we evaluate the proposed approach in two scenarios: fine-tuning for small PLMs and prompt tuning for LLMs. Experimental results show that our approach could generate more informative texts than baselines. © 2023 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Fine tuning; Knowledge graphs; Language model; Local knowledge; Related entities; Text generations; Text generators; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Tothfalusi2023,
	author = {Tothfalusi, Tamas and Varga, Eszter and Csiszar, Zoltan and Varga, Pal},
	title = {ML-Based Translation Methods for Protocols and Data Formats},
	year = {2023},
	journal = {2023 19th International Conference on Network and Service Management, CNSM 2023},
	doi = {10.23919/CNSM59352.2023.10327850},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180009347&doi=10.23919%2fCNSM59352.2023.10327850&partnerID=40&md5=3e1635bc50df885fa13ecf0dc3f93654},
	abstract = {In order to exchange information between systems, the information must get encoded into a predefined data format, and it must be transferred in a protocol that the communicating parties have agreed upon. This works well if all parties follow the same protocol standard and use the same data description schemes. If systems use different data formats or protocols, then some sort of translation is required. Protocol and data format translation has been attempted previously through rule-based approaches, ontologies, and also by using machine learning (ML) techniques. Due to the current advances related to AI/ML methods, tools, and infrastructure, the accuracy and feasibility of 'translation' with ML-approaches improved significantly. This paper introduces a generic approach and methodology for translating data formats and protocols with ML-based methods and presents our initial results through JSON-XML and JSON-SenML translation. © 2023 IFIP.},
	author_keywords = {LLM; machine learning; natural language processing; neural machine translation; protocol translation},
	keywords = {Computational linguistics; Learning algorithms; Natural language processing systems; Translation (languages); Description schemes; Language processing; LLM; Machine-learning; Natural language processing; Natural languages; Protocol translations; Rule-based approach; System use; Translation method; Machine learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@CONFERENCE{Zhou2023,
	author = {Zhou, Wei and Peng, Xiangyu and Riedl, Mark},
	title = {Dialogue Shaping: Empowering Agents through NPC Interaction},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3626},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184665948&partnerID=40&md5=3414366cf8442f5670cd116895edef3c},
	abstract = {One major challenge in reinforcement learning (RL) is the large amount of steps for the RL agent needs to converge in the training process and learn the optimal policy, especially in text-based game environments where the action space is extensive. However, non-player characters (NPCs) sometimes hold some key information about the game, which can potentially help to train RL agents faster. Thus, this paper explores how to interact and converse with NPC agents to get the key information using large language models (LLMs), as well as incorporate this information to speed up RL agent’s training using knowledge graphs (KGs) and Story Shaping. © 2023 Copyright for this paper by its authors.},
	author_keywords = {ChatGPT; Knowledge Graph; Large Language Model; Reinforcement Learning; Text adventure game},
	keywords = {Computational linguistics; Information use; Knowledge graph; Adventure games; ChatGPT; Knowledge graphs; Language model; Large amounts; Large language model; Non-player character; Reinforcement learning agent; Reinforcement learnings; Text adventure game; Reinforcement learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{2023,
	title = {Scholarly QALD 2023 and SemREC 2023 - Joint Proceedings of 1st Scholarly QALD Challenge 2023 and 4th SeMantic Answer Type, Relation and Entity Prediction Tasks Challenge 2023, co-located with 22nd International Semantic Web Conference, ISWC 2023},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3592},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180801778&partnerID=40&md5=c2ad5e26f2c121747a43d361e9de2083},
	abstract = {The proceedings contain 9 papers. The topics discussed include: when context matters: entity linking in the scholarly domain; NLQxform: a language model-based question to SPARQL transformer; a structure and content prompt-based method for knowledge graph question answering over scholarly data; leveraging LLMs in scholarly knowledge graph question answering; improving subgraph extraction algorithms for one-shot SPARQL query generation with large language models; PSYCHIC: a neuro-symbolic framework for knowledge graph question-answering grounding; BERTologyNavigator: advanced question answering with BERT-based semantics; enhanced GAT: expanding receptive field with meta path-guided RDF rules for two-hop connectivity; and evaluating different methods for semantic reasoning over ontologies.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Vijayakumar202345,
	author = {Vijayakumar, Senthilkumar and Louis, Filious},
	title = {Revolutionizing Staffing and Recruiting with Contextual Knowledge Graphs and QNLP: An End-to-End Quantum Training Paradigm},
	year = {2023},
	journal = {Proceedings - IEEE International Conference on Knowledge Graph, ICKG 2023},
	pages = {45 – 51},
	doi = {10.1109/ICKG59574.2023.00011},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186145301&doi=10.1109%2fICKG59574.2023.00011&partnerID=40&md5=76f8fede171201dc0aa4e2320bd3c543},
	abstract = {The staffing and recruiting industry is continuously evolving, and recent advancements in Knowledge Graphs (KG) and Quantum Natural Language Processing (QNLP) has garnered considerable attention. The integration of these state-of-the-art technologies is fueled by the necessity to improve language models' capacity to comprehend context and make precise decisions. This research paper presents a novel approach to revolutionize the staffing and recruiting industry by integrating Knowledge Graph (KG) and Quantum Natural Language Processing (QNLP) to formulate an end-to-end QNLP training pipeline. The proposed solution consists of three interdependent subsystems that work in unison to construct contextual KG and train language models. The Information Extraction subsystem extracts semantic relationships and connections between entities from large and complex recruitment data to construct domain specific contextual KG. The QNLP model training pipeline subsystem, which is fed with domain-rich KG data, runs on Quantum Circuits, accelerates the training process by effectively incorporating high-dimensional features to the deep layers of language models. Finally, the Information Retrieval subsystem is based on semantic data taxonomy, retrieving contextual data from the KG for the trained language models to be implemented on various distinctive use cases in the staffing and recruiting industry. This solution provides a faster and more contextual approach to analyze recruitment data, empowering recruiters to concentrate on strategic tasks such as candidate engagement and client relationship building, ultimately leading to better business decision-making capabilities. © 2023 IEEE.},
	author_keywords = {Artificial Intelligence (AI); Contextual Information Extraction & Retrieval Systems; Knowledge Graph (KG); Large Language Models (LLM); Quantum Natural Language Processing (QNLP)},
	keywords = {Computational linguistics; Information retrieval; Information retrieval systems; Knowledge graph; Natural language processing systems; Pipeline processing systems; Pipelines; Search engines; Semantics; Artificial intelligence; Contextual information; Contextual information extraction & retrieval system; Information extraction systems; Information-retrieval systems; Knowledge graph; Knowledge graphs; Language model; Language processing; Large language model; Natural languages; Quantum natural language processing; Decision making},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Lee20236051,
	author = {Lee, Hyun Jung and Sohn, Mye},
	title = {Context-based Fact-checking Using Knowledge Graph},
	year = {2023},
	journal = {Proceedings - 2023 IEEE International Conference on Big Data, BigData 2023},
	pages = {6051 – 6056},
	doi = {10.1109/BigData59044.2023.10386121},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184977205&doi=10.1109%2fBigData59044.2023.10386121&partnerID=40&md5=5071c21e905a9a26740f0429ca3498ec},
	abstract = {There are many attentions for the fact-checking to prevent the hallucination, malfunction of circulating content on the web such as deception, counterfeit, fake news regardless of whether they are intended or not. For fact-checking, ConFcheKG (Context-based Fact-checking using Knowledge Graph) is proposed based on the Knowledge Graph (KG). In the content including multiple entities, the KG is adopted to check coherence between the entities to determine whether there are semantic conflicts among them. The coherence is based on the temporal, spatial, and logical arrangement of the contents based on the associated relationships among the entities using KG. To do this, it checks the existence of intersected KGs and conflicted KGs through mutual comparison of KGs step by step. According to the verifying process, if is the constructed KT with coherent entities of the content, then the reliability of the content's coherence is high because it has a high probability of not being false, hallucination, fake-news, and so on. Otherwise, the probability of being false increases. To check the fact, ConFcheKG can be applied based on semantic coherence of the content, to reduce the hallucination, to determine the fake news, to detect deceptions, to prevent counterfeits, to generate the well-composed prompt for the generative AI, and so on.  © 2023 IEEE.},
	author_keywords = {coherence; context; fact-checking; knowledge graph; reliability},
	keywords = {Semantics; Content-based; Context; Context-based; Fact-checking; High probability; Knowledge graphs; Semantic conflict; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{de Souza2023129,
	author = {de Souza, Rafael Roque and Pinheiro, Thiago Luna and Barbour Oliveira, Julio Cesar and dos Reis, Julio Cesar},
	title = {Knowledge Graphs Extracted from Medical Appointment Transcriptions: Results Generating Triples Relying on LLMs},
	year = {2023},
	journal = {International Joint Conference on Knowledge Discovery, Knowledge Engineering and Knowledge Management, IC3K - Proceedings},
	volume = {2},
	pages = {129 – 139},
	doi = {10.5220/0012259000003598},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179552636&doi=10.5220%2f0012259000003598&partnerID=40&md5=c85b8f6e07a5c0e095560e77b6b515bd},
	abstract = {Knowledge Graphs (KGs) represent computer-interpretable interactions between real-world entities. This can be valuable for representing medical data semantically. We address the challenge of automatically transforming transcripted medical conversations (clinical dialogues) into RDF triples to structure clinical information. In this article, we design and develop a software tool that simplifies clinical documentation. Our solution explores advanced techniques, such as the Fine-tuned GPT-NeoX 20B model, to extract and summarize crucial information from clinical dialogues. We designed the solution’s architecture, supported by technologies such as Docker and MongoDB, to be durable and scalable. We achieve accurate medical entity detection from Portuguese-language textual data and identify semantic relationships in interactions between doctors and patients. By applying advanced Natural Language Processing techniques and Large Language Models (LLMs), our results improve the accuracy and relevance of RDF triples generated from clinical textual data. Copyright © 2023 by SCITEPRESS – Science and Technology Publications, Lda. Under CC license (CC BY-NC-ND 4.0).},
	author_keywords = {Clinical Appointments; eHealth; Knowledge Graphs; LLMs; RDF Triple Generation; Telemedicine},
	keywords = {eHealth; Natural language processing systems; Resource Description Framework (RDF); Semantics; Telemedicine; Clinical appointment; Ehealth; Knowledge graphs; Language model; Large language model; Medical data; RDF triple generation; RDF triples; Real-world entities; Textual data; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{He2023,
	author = {He, Yuan and Chen, Jiaoyan and Dong, Hang and Horrocks, Ian},
	title = {Exploring Large Language Models for Ontology Alignment},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3632},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184375684&partnerID=40&md5=43d321af25029eca4ea303b161851303},
	abstract = {This work investigates the applicability of recent generative Large Language Models (LLMs), such as the GPT series and Flan-T5, to ontology alignment for identifying concept equivalence mappings across ontologies. To test the zero-shot1 performance of Flan-T5-XXL and GPT-3.5-turbo, we leverage challenging subsets from two equivalence matching datasets of the OAEI Bio-ML track, taking into account concept labels and structural contexts. Preliminary findings suggest that LLMs have the potential to outperform existing ontology alignment systems like BERTMap, given careful framework and prompt design. © 2023 Copyright for this paper by its authors.},
	author_keywords = {Flan-T5; GPT; Large Language Model; Ontology Alignment; Ontology Matching},
	keywords = {Computational linguistics; Concept equivalences; Flan-t5; GPT; Language model; Large language model; Matchings; Ontology alignment; Ontology matching; Ontology's; Performance; Ontology},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Chen20233117,
	author = {Chen, Bohan and Bertozzi, Andrea L.},
	title = {AutoKG: Efficient Automated Knowledge Graph Generation for Language Models},
	year = {2023},
	journal = {Proceedings - 2023 IEEE International Conference on Big Data, BigData 2023},
	pages = {3117 – 3126},
	doi = {10.1109/BigData59044.2023.10386454},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184978959&doi=10.1109%2fBigData59044.2023.10386454&partnerID=40&md5=b4862ec952ca7004cca003557ab4a3d9},
	abstract = {Traditional methods of linking large language models (LLMs) to knowledge bases via the semantic similarity search often fall short of capturing complex relational dynamics. To address these limitations, we introduce AutoKG, a lightweight and efficient approach for automated knowledge graph (KG) construction. For a given knowledge base consisting of text blocks, AutoKG first extracts keywords using a LLM and then evaluates the relationship weight between each pair of keywords using graph Laplace learning. We employ a hybrid search scheme combining vector similarity and graph-based associations to enrich LLM responses. Preliminary experiments demonstrate that AutoKG offers a more comprehensive and interconnected knowledge retrieval mechanism compared to the semantic similarity search, thereby enhancing the capabilities of LLMs in generating more insightful and relevant outputs.  © 2023 IEEE.},
	author_keywords = {Graph Learning; Knowledge Graph; Language model; Retrieval-augmented Generation},
	keywords = {Computational linguistics; Graphic methods; Semantic Web; Semantics; Graph construction; Graph generation; Graph learning; Hybrid search; Knowledge graphs; Language model; Retrieval-augmented generation; Search scheme; Semantic similarity; Similarity search; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Kim20239410,
	author = {Kim, Jiho and Kwon, Yeonsu and Jo, Yohan and Choi, Edward},
	title = {KG-GPT: A General Framework for Reasoning on Knowledge Graphs Using Large Language Models},
	year = {2023},
	journal = {Findings of the Association for Computational Linguistics: EMNLP 2023},
	pages = {9410 – 9421},
	doi = {10.18653/v1/2023.findings-emnlp.631},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183304875&doi=10.18653%2fv1%2f2023.findings-emnlp.631&partnerID=40&md5=1193b37277457a45668eeaf5d1e3a311},
	abstract = {While large language models (LLMs) have made considerable advancements in understanding and generating unstructured text, their application in structured data remains underexplored. Particularly, using LLMs for complex reasoning tasks on knowledge graphs (KGs) remains largely untouched. To address this, we propose KG-GPT, a multi-purpose framework leveraging LLMs for tasks employing KGs. KG-GPT comprises three steps: Sentence Segmentation, Graph Retrieval, and Inference, each aimed at partitioning sentences, retrieving relevant graph components, and deriving logical conclusions, respectively. We evaluate KG-GPT using KG-based fact verification and KGQA benchmarks, with the model showing competitive and robust performance, even outperforming several fully-supervised models. Our work, therefore, marks a significant step in unifying structured and unstructured data processing within the realm of LLMs. © 2023 Association for Computational Linguistics.},
	keywords = {Benchmarking; Computational linguistics; Data handling; Competitive performance; Graph-based; Knowledge graphs; Language model; Multi-purpose; Reasoning tasks; Robust performance; Sentence segmentation; Structured data; Unstructured texts; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 9; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Yadav2023,
	author = {Yadav, Divyanshi and Para, Hitesh and Selvakumar, Prakash},
	title = {Unleashing the Power of Large Language Model, Textual Embeddings, and Knowledge Graphs for Advanced Information Retrieval},
	year = {2023},
	journal = {International Conference on Electrical, Computer and Energy Technologies, ICECET 2023},
	doi = {10.1109/ICECET58911.2023.10389253},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85187250772&doi=10.1109%2fICECET58911.2023.10389253&partnerID=40&md5=c43d343029e5aa24750c1e6757bf5d5d},
	abstract = {Acquiring knowledge beyond the usual expertise is a critical challenge when implementing semantic information solutions for querying a knowledge base. To address this difficulty, one proposed solution was to use knowledge graphs in conjunction with traditional Question & Answering (Q&A) systems. However, this approach struggles with limited facts, difficulty in obtaining further insights into the context, and limited ability to handle complex questions, leading to inaccurate or irrelevant answers. To overcome these limitations, we present an approach for answering inference-based questions that integrates knowledge graphs, a large language model, and relevant embeddings from a vector database. Combining knowledge graphs and word embeddings significantly enhances the strength of both techniques, leading to improved performance of Question and Answering systems. We begin with generating representations of the relevant nodes in the knowledge graph and retrieve the most appropriate information from a collection of stored textual data using word embeddings. This approach tackles the shortcomings of conventional approaches that rely solely on knowledge graphs and are too rigid to handle the nuances of the context. This method provides a sophisticated understanding of language and context, enabling it to handle complex questions that may involve multiple entities and relationships with a better understanding of the facts and context in which the question is being asked. The system's ability to handle complex queries is evidenced through a combination of theoretical analysis and empirical data. Our approach has demonstrated exceptional efficiency on a benchmark dataset, as evidenced by evaluating the F1 score. © 2023 IEEE.},
	author_keywords = {Inference-Based Questions; Information Retrieval; Knowledge Graphs; Large Language Model; Natural Language Processing; Natural Language Understanding; Question & Answering Systems; Word Embeddings},
	keywords = {Computational linguistics; Graphic methods; Information retrieval; Knowledge graph; Natural language processing systems; Query processing; Search engines; Semantics; Embeddings; Inference-based question; Knowledge graphs; Language model; Language processing; Large language model; Natural language processing; Natural language understanding; Natural languages; Question answering systems; Word embedding; Embeddings},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Mateiu2023226,
	author = {Mateiu, Patricia and Groza, Adrian},
	title = {Ontology engineering with Large Language Models},
	year = {2023},
	journal = {Proceedings - 2023 25th International Symposium on Symbolic and Numeric Algorithms for Scientific Computing, SYNASC 2023},
	pages = {226 – 229},
	doi = {10.1109/SYNASC61333.2023.00038},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85193849216&doi=10.1109%2fSYNASC61333.2023.00038&partnerID=40&md5=3a11a52cf31f786c97e2f8e3c1c07cb5},
	abstract = {We tackle the task of enriching ontologies by automatically translating natural language (NL) into Description Logic (DL). Since Large Language Models (LLMs) are the best tools for translations, we fine-tuned a GPT-3 model to convert NL into OWL Functional Syntax. For fine-tuning, we designed pairs of sentences in NL and the corresponding translations. This training pairs cover various aspects from ontology engineering: instances, class subsumption, domain and range of relations, object properties relationships, disjoint classes, complements, or cardinality restrictions. The resulted axioms are used to enrich an ontology, in a human supervised manner. The developed tool is publicly provided as a Protégé plugin.  © 2023 IEEE.},
	author_keywords = {fine-tuning; large language models; ontology engineering; Protege plugin},
	keywords = {Computational linguistics; Data description; Translation (languages); Description logic; Fine tuning; Language model; Large language model; Natural languages; Ontology engineering; Ontology's; Plug-ins; Protege; Protege plugin; Ontology},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6}
}

@CONFERENCE{Yáñez-Romero2023104,
	author = {Yáñez-Romero, Fabio Antonio},
	title = {Entity Modelling through Ontologies and Large Language Models},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3625},
	pages = {104 – 110},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184831862&partnerID=40&md5=e7bfd8a5401e242aa037a5e8fd7e0a4e},
	abstract = {The aim of this paper is to present a line of research focused on improving the knowledge represented in natural language processing tasks through the use of ontologies, combining these with machine learning techniques. It is expected that with this kind of techniques it will be possible to fight against phenomena such as the hallucination present in current generative language models and to reach the state of the art in different tasks taking into account semantic knowledge. Initially, we will try to solve the problem of semantics in specific areas such as medicine, where the external knowledge that can be incorporated would help to provide knowledge that does not exist in unstructured data such as all ICD-10 codes. Therefore, we expect obtain enough conclusions to apply this methodology with other dominions. © 2021 Copyright for this paper by its authors.},
	author_keywords = {Embeddings; Generative Language Models; Graph Neural Networks; Knowledge Bases; Knowledge Graphs; Natural Language Processing; Ontologies; Semantics},
	keywords = {Computational linguistics; Embeddings; Graph neural networks; Knowledge graph; Modeling languages; Natural language processing systems; Ontology; Embeddings; Generative language model; Graph neural networks; Knowledge base; Knowledge graphs; Language model; Language processing; Natural language processing; Natural languages; Ontology's; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Liu2023516,
	author = {Liu, Jiehui and Zhan, Jieyu},
	title = {Constructing Knowledge Graph from Cyber Threat Intelligence Using Large Language Model},
	year = {2023},
	journal = {Proceedings - 2023 IEEE International Conference on Big Data, BigData 2023},
	pages = {516 – 521},
	doi = {10.1109/BigData59044.2023.10386611},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184980754&doi=10.1109%2fBigData59044.2023.10386611&partnerID=40&md5=4def110f5ab4d68c8fc274d50133d9b2},
	abstract = {Cyber Threat Intelligence (CTI) reports are valuable resources in various applications but manually extracting information from them is time-consuming. Existing approaches for automating extraction require specialized models trained on a substantial corpus. In this paper, we present an efficient methodology for constructing knowledge graphs from CTI by leveraging the Large Language Model (LLM), using ChatGPT for instance. Our approach automatically extracts attack-related entities and their relationships, organizing them within a CTI knowledge graph. We evaluate our approach on 13 CTIs, demonstrating better performance compared to AttacKG and REBEL while requiring less manual intervention and computational resources. This proves the feasibility and suitability of our method in low-resource scenarios, specifically within the domain of cyber threat intelligence.  © 2023 IEEE.},
	author_keywords = {ChatGPT; knowledge graph; large language model; threat intelligence},
	keywords = {Computational linguistics; Knowledge management; ChatGPT; Cyber threats; Extracting information; Knowledge graphs; Language model; Large language model; Manual intervention; Performance; Related entities; Threat intelligence; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7}
}

@CONFERENCE{Gosselin2023184,
	author = {Gosselin, Francis and Zouaq, Amal},
	title = {SORBETMatcher Results for OAEI 2023},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3591},
	pages = {184 – 190},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180813182&partnerID=40&md5=69e5e5b6ea4a65476d218c8e74d08e91},
	abstract = {This paper presents the results of SORBETMatcher in the OAEI 2023 competition. SORBETMatcher is a schema matching system for both equivalence matching and subsumption matching. SORBETMatcher is largely based on SORBET Embeddings, a novel ontology embedding method that leverages large language models, random walks, and a regression loss to construct a latent space that encapsulates ontology structures. Despite recognizing certain limitations inherent in SORBET Embeddings, SORBETMatcher performed well in the OAEI competition. It emerged as the leading system in three out of the five subsumption matching challenges within the Bio-ML track, as well as in the equivalence matching problem involving ORDO-DOID. © 2023 Copyright for this paper by its authors.},
	author_keywords = {ISWC-2023; Ontology alignment; Representation Learning; Schema matching},
	keywords = {Embeddings; Semantic Web; Embedding method; Embeddings; ISWC-2023; Language model; Matching system; Matchings; Ontology alignment; Ontology's; Representation learning; Schema matching; Ontology},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Luo202313272,
	author = {Luo, Linhao and Vu, Thuy-Trang and Phung, Dinh and Haffari, Gholamreza},
	title = {Systematic Assessment of Factual Knowledge in Large Language Models},
	year = {2023},
	journal = {Findings of the Association for Computational Linguistics: EMNLP 2023},
	pages = {13272 – 13286},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183300786&partnerID=40&md5=16c4c33f7a0276a282d59858af569cde},
	abstract = {Previous studies have relied on existing question-answering benchmarks to evaluate the knowledge stored in large language models (LLMs). However, this approach has limitations regarding factual knowledge coverage, as it mostly focuses on generic domains which may overlap with the pretraining data. This paper proposes a framework to systematically assess the factual knowledge of LLMs by leveraging knowledge graphs (KGs). Our framework automatically generates a set of questions and expected answers from the facts stored in a given KG, and then evaluates the accuracy of LLMs in answering these questions. We systematically evaluate the state-of-the-art LLMs with KGs in generic and specific domains. The experiment shows that ChatGPT is consistently the top performer across all domains. We also find that LLMs performance depends on the instruction finetuning, domain and question complexity and is prone to adversarial context. © 2023 Association for Computational Linguistics.},
	keywords = {Knowledge graph; Knowledge management; Factual knowledge; Knowledge graphs; Language model; Modeling performance; Pre-training; Question Answering; Set of questions; State of the art; Systematic assessment; Computational linguistics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6}
}

@CONFERENCE{2023,
	title = {OM 2023 - Proceedings of the 18th International Workshop on Ontology Matching, co-located with the 22nd International Semantic Web Conference, ISWC 2023},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3591},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180752538&partnerID=40&md5=a46172b5082beccb5fc1ca6c98e5880b},
	abstract = {The proceedings contain 23 papers. The topics discussed include: Truveta mapper: a zero-shot ontology alignment framework; the role of ontology matching in ontology network development; matching table metadata with business glossaries using large language models; contextualized structural self-supervised learning for ontology matching; evaluation toolkit for API and RDF alignment; conversational ontology alignment with ChatGPT; ontology matching using textual class descriptions; a simple standard for ontological mappings 2023: updates on data model, collaborations and tooling; repairing networks of ontologies using weakening and completing; towards a methodology for the semi-automatic generation of scientific knowledge graphs from XML documents; and combining word and sentence embeddings with alignment extension for property matching.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Anand202380,
	author = {Anand, Avinash and Prasad, Kritarth and Goel, Ujjwal and Gupta, Mohit and Lal, Naman and Verma, Astha and Shah, Rajiv Ratn},
	title = {Context-Enhanced Language Models for Generating Multi-paper Citations},
	year = {2023},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14418 LNCS},
	pages = {80 – 94},
	doi = {10.1007/978-3-031-49601-1_6},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180532354&doi=10.1007%2f978-3-031-49601-1_6&partnerID=40&md5=fd71ef30d11bfae8b754b6d245d73761},
	abstract = {Citation text plays a pivotal role in elucidating the connection between scientific documents, demanding an in-depth comprehension of the cited paper. Constructing citations is often time-consuming, requiring researchers to delve into extensive literature and grapple with articulating relevant content. To address this challenge, the field of citation text generation (CTG) has emerged. However, while earlier methods have primarily centered on creating single-sentence citations, practical scenarios frequently necessitate citing multiple papers within a single paragraph. To bridge this gap, we propose a method that leverages Large Language Models (LLMs) to generate multi-citation sentences. Our approach involves a single source paper and a collection of target papers, culminating in a coherent paragraph containing multi-sentence citation text. Furthermore, we introduce a curated dataset named MCG-S2ORC, composed of English-language academic research papers in Computer Science, showcasing multiple citation instances. In our experiments, we evaluate three LLMs LLaMA, Alpaca, and Vicuna to ascertain the most effective model for this endeavor. Additionally, we exhibit enhanced performance by integrating knowledge graphs from target papers into the prompts for generating citation text. This research underscores the potential of harnessing LLMs for citation generation, opening a compelling avenue for exploring the intricate connections between scientific documents. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Attention; Citation Text Generation; Knowledge Graphs; Large Language Models; Natural Language Processing; Text Generation},
	keywords = {Computational linguistics; Natural language processing systems; Paper; Attention; Citation text generation; Knowledge graphs; Language model; Language processing; Large language model; Natural language processing; Natural languages; Text generations; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@CONFERENCE{Xin20231236,
	author = {Xin, You and Chen, Liu and Yang, Yang},
	title = {Online Knowledge Fusion Method for Fault Diagnosis of Power Plant Equipment},
	year = {2023},
	journal = {IEEE Joint International Information Technology and Artificial Intelligence Conference (ITAIC)},
	pages = {1236 – 1240},
	doi = {10.1109/ITAIC58329.2023.10408849},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186105731&doi=10.1109%2fITAIC58329.2023.10408849&partnerID=40&md5=1197b1ff611e224a67e359a057b99d4a},
	abstract = {There are many types of documents in fossil-fuel power station to describe equipment failures, including maintenance records, treatment diagnosis suggestions, historical cases, and equipment knowledge. The knowledge of equipment anomaly diagnosis and handling is scattered in different documents. Extract and fuse scattered knowledge from these scattered documents to generate a knowledge graph for equipment fault di-agnosis, providing necessary decision support for maintenance personnel to discover and handle equipment faults. This article proposes an implementation method for extracting and integrating equipment fault knowledge from diverse and multi type text records to form a knowledge graph. A thermal power plant equipment fault Q&A system based on the fusion of open source large language models and knowledge graphs has been developed. Main contributions: (1) A knowledge extraction algorithm integrating BERT-WWM model and pointer annotation method is proposed to extract entity relations of fault text jointly. Experiments show that the method performs well in extracting overlapped triples, and F1 is improved by 8.51 % compared with existing algorithms; (2) A knowledge fusion model based on RoBERTa-BiLSTM is proposed, which fully utilizes the feature information of the entity text to be disambiguated and the entity mention text, and cap-tures the interdependent features within the sentence through attention mechanism. The experiment shows that this method improves F1 by 9.56% compared to existing fusion algorithms. (3) Based on the open-source large model ChatGLM, a fusion method of knowledge graph and large model ChatGLM was explored, and a device fault question answering system for thermal power plants was implemented, achieving high accuracy in practical applications. © 2023 IEEE.},
	author_keywords = {knowledge extraction; knowledge fusion; knowledge graph},
	keywords = {Anomaly detection; Data mining; Decision support systems; Extraction; Fossil fuel power plants; Fossil fuels; Open Data; Open systems; Thermoelectric power plants; Equipment failures; Faults diagnosis; Fusion methods; Knowledge extraction; Knowledge fusion; Knowledge graphs; Large models; Open-source; Power plant equipment; Thermal-power plants; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Lu202315108,
	author = {Lu, Keming and Pan, Xiaoman and Song, Kaiqiang and Zhang, Hongming and Yu, Dong and Chen, Jianshu},
	title = {PIVOINE: Instruction Tuning for Open-world Entity Profiling},
	year = {2023},
	journal = {Findings of the Association for Computational Linguistics: EMNLP 2023},
	pages = {15108 – 15127},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183306822&partnerID=40&md5=2867476d5bae67661a165547718b5a85},
	abstract = {This work considers the problem of Open-world Entity Profiling, which is a sub-domain of Open-world Information Extraction (Open-world IE). Unlike the conventional closed-world IE, Open-world IE considers a more general situation where entities and relations could be beyond a predefined ontology. We seek to develop a large language model (LLM) that can perform Open-world Entity Profiling with instruction tuning to extract desirable entity profiles characterized by (possibly fine-grained) natural language instructions. In particular, we construct INSTRUCTOPENWIKI, a substantial instruction-tuning dataset for Open-world Entity Profiling enriched with a comprehensive corpus, extensive annotations, and diverse instructions. We finetune pretrained BLOOM models on INSTRUCTOPENWIKI and obtain PIVOINE, an LLM for Open-world Entity Profiling with strong instruction-following capabilities. Our experiments demonstrate that PIVOINE significantly outperforms traditional methods and ChatGPT-based baselines, displaying impressive generalization capabilities on both unseen instructions and out-of-ontology cases. Consequently, PIVOINE emerges as a promising solution to tackle the open-world challenge in entity profiling. © 2023 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Fine grained; General situation; Generalization capability; Language model; Natural languages; Ontology's; Open world; Subdomain; Ontology},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{De Oliveira Silveira2023,
	author = {De Oliveira Silveira, Alysson and Ray, Arindam and Ebrahimi, Mohammadreza and Bhattacherjee, Anol},
	title = {Automated Deductive Content Analysis of Text: A Deep Contrastive and Active Learning Based Approach},
	year = {2023},
	journal = {International Conference on Information Systems, ICIS 2023: "Rising like a Phoenix: Emerging from the Pandemic and Reshaping Human Endeavors with Digital Technologies"},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85192549295&partnerID=40&md5=376592d022243c2cfa96a101ca52efb4},
	abstract = {Content analysis traditionally involves human coders manually combing through text documents to search for relevant concepts and categories. However, this approach is time-intensive and not scalable, particularly for secondary data like social media content, news articles, or corporate reports. To address this problem, the paper presents an automated framework called Automated Deductive Content Analysis of Text (ADCAT) that uses deep learning-based semantic techniques, an ontology of validated construct measures, a large language model, human-in-the-loop disambiguation, and a novel augmentation-based weighted contrastive learning approach for improved language representations, to build a scalable approach for deductive content analysis. We demonstrate the effectiveness of the proposed approach to identify firm innovation strategies from their 10-K reports to obtain inferences reasonably close to human coding. © 2023 International Conference on Information Systems, ICIS 2023: "Rising like a Phoenix: Emerging from the Pandemic and Reshaping Hu. All Rights Reserved.},
	author_keywords = {Content Analysis; Contrastive Learning; Deep Active Learning; Large Language Model; Sentence Transformers; Text Augmentation},
	keywords = {Computational linguistics; Deep learning; Information systems; Information use; Learning systems; Semantics; Active Learning; Content analysis; Contrastive learning; Deep active learning; Language model; Large language model; Learning-based approach; Sentence transformer; Text augmentation; Text document; Automation},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Wu2023,
	author = {Wu, Zhengqian and Li, Ruizhe and Guo, Jiahao and Wang, Zhongyuan and Liang, Chao},
	title = {A Deep Understanding Video Q&A System for Film Education in Acting Department},
	year = {2023},
	journal = {2023 International Conference on Intelligent Education and Intelligent Research, IEIR 2023},
	doi = {10.1109/IEIR59294.2023.10391232},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184665653&doi=10.1109%2fIEIR59294.2023.10391232&partnerID=40&md5=1239aa0b36ed5beef56c7df5242d6a9a},
	abstract = {Recently, advancements in artificial intelligence technology have greatly influenced the field of education, particularly in the area of intelligent homework assistance. However, current approaches are primarily designed for procedural and logical tasks and often lack comprehension abilities. This limitation is particularly evident when it comes to multi-hop and continuous tasks. To address this challenge, the integration of Large Language Model (LLM) has significantly enhanced the capability of AI systems to handle multi-hop and highly interconnected inputs. In this study, we focus on the learning needs of students in Acting Department, specifically their study of movies and the significance of classic movie videos in their learning process. However, assessing deep comprehension of classic movies poses its own challenges. To overcome these challenges, we develop a quiz system utilizing Knowledge Graphs (KG) and LLM to facilitate a deeper understanding of classic films. The generation of video quiz pairs is achieved through the use of Automatic Speech Recognition (ASR) technology, which leverages movie subtitles for question generation. For answering these questions, we employ techniques KG and LLM to process questions and retrieve corresponding answers. The proposed method achieves good performance in Deep Video Understanding (DVU) task of NIST TRECVID, demonstrating its effectiveness.  © 2023 IEEE.},
	author_keywords = {artificial intelligence; Large Language Model; video understanding},
	keywords = {Computational linguistics; Knowledge graph; Learning systems; Speech recognition; 'current; AI systems; Artificial intelligence technologies; Automatic Speech Recognition Technology; Knowledge graphs; Language model; Large language model; Learning process; Multi-hops; Video understanding; Motion pictures},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Wilcock20231396,
	author = {Wilcock, Graham and Jokinen, Kristiina},
	title = {To Err Is Robotic; to Earn Trust, Divine: Comparing ChatGPT and Knowledge Graphs for HRI},
	year = {2023},
	journal = {IEEE International Workshop on Robot and Human Communication, RO-MAN},
	pages = {1396 – 1401},
	doi = {10.1109/RO-MAN57019.2023.10309510},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186995135&doi=10.1109%2fRO-MAN57019.2023.10309510&partnerID=40&md5=694805f953e7c8d179e97b61783f7d06},
	abstract = {The paper discusses two current approaches to conversational AI, using large language models and knowledge graphs, and compares types of errors that occur in human-robot interactions based on these approaches. It provides example dialogues and describes solutions to several error types including false implications, ontological errors, theory of mind errors, and handling of speech recognition errors. The paper addresses issues of particular concern for earning user trust. © 2023 IEEE.},
	keywords = {Human robot interaction; Knowledge graph; Speech recognition; 'current; Error theory; Error types; Humans-robot interactions; Knowledge graphs; Language model; Recognition error; Theory of minds; Errors},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@CONFERENCE{Qiao2023,
	author = {Qiao, Zhe and Zhang, Chen and Du, Gang},
	title = {Improving Cybersecurity Named Entity Recognition with Large Language Models},
	year = {2023},
	journal = {2023 6th International Conference on Software Engineering and Computer Science, CSECS 2023},
	doi = {10.1109/CSECS60003.2023.10428218},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85186756974&doi=10.1109%2fCSECS60003.2023.10428218&partnerID=40&md5=0acd408cde4968e65bc756bbc08b7558},
	abstract = {A lot of attention has been paid to cybersecurity threat intelligence analysis based on security knowledge graphs because they can evaluate multi-source threat intelligence data at a fine-grained level. The primary effort in building knowledge graphs is named entity recognition (NER). However, the retrieved features from classic NER algorithms are insufficient to identify novel security entities in the cybersecurity field. Currently, the natural language processing(NLP) field has made unprecedented progress, driven by large language models(LLMs). In this paper, we present a BERT- BiLSTM-CRF cybersecurity NER method based on BiLSTM-CRF that combines the pre-trained large language model BERT. The preprocessed annotated corpus is fed into the Bi-LSTM and CRF models, which employ the word vectors to extract contextual features and annotate 9 different categories of named entities. The proposed cyberecurity NER method is effective in identifying cybersecurity entities on large-scale cybersecurity datasets, and the relevant evaluation indexes are superior to other algorithms, according to comparative experiments carried out within the cyberspace security corpus. © 2023 IEEE.},
	author_keywords = {BERT; BiLSTM; cybersecurity; LLMs; NER},
	keywords = {Computational linguistics; Knowledge graph; Large datasets; Long short-term memory; Natural language processing systems; BERT; BiLSTM; Cyber security; Intelligence analysis; Knowledge graphs; Language model; Large language model; Multi-Sources; Named entity recognition; Recognition methods; Cybersecurity},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Mihindukulasooriya2023,
	author = {Mihindukulasooriya, Nandana and Dash, Sarthak and Bagchi, Sugato and Chowdhury, Faisal and Gliozzo, Alfio and Farkash, Ariel and Glass, Michael and Gokhman, Igor and Hassanzadeh, Oktie and Pham, Nhan and Rossiello, Gaetano and Rozenberg, Boris and Sagron, Yehoshua and Subramanian, Dharmashankar and Takahashi, Toshihiro and Tateishi, Takaaki and Vu, Long},
	title = {Unleashing the Potential of Data Lakes with Semantic Enrichment Using Foundation Models},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3632},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184379489&partnerID=40&md5=3575ea110a78ffde7449db418c24400b},
	abstract = {Nowadays most organizations are managing data lakes containing heterogeneous data from various sources. However, the lack of adequate metadata often transforms these data lakes into data swamps, making it challenging to locate relevant data for critical organizational tasks and consequently limiting their utility. Recent advancements in large language models and foundation models have enabled the automation of metadata generation using generative AI models and the use of generated metadata for mapping tabular data into semantically richer glossaries, taxonomies, or ontologies. In this talk, we will present a semantic enrichment process that generates table metadata such as descriptive table captions, tags, expanded column names, and column descriptions and then uses that information to map table columns to concepts in a given business glossary or an ontology. Furthermore, during this process, we represent both table metadata and business glossaries as knowledge graphs and connect them by mapping columns to business concepts. As a result, the enrichment process makes the data in data lakes more meaningful to the organization and enhances downstream tasks, including improved table search and discovery, efficient table joins, and advanced business analytics. © 2023 Copyright for this paper by its authors.},
	author_keywords = {Data Lakes; Foundation Models; Knowledge Graph; Large Language Models; Semantic Enrichment},
	keywords = {Computational linguistics; Glossaries; Knowledge graph; Lakes; Mapping; Ontology; Semantics; Business glossary; Data lake; Foundation models; Heterogeneous data; Knowledge graphs; Language model; Large language model; Ontology's; Organisational; Semantic enrichment; Metadata},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Li202316,
	author = {Li, Jiao and Zhao, Ruixue and Xian, Guojian and Huang, Yongwen and Sun, Tan},
	title = {Research Advances in Argument Mining; [论证挖掘研究现状与进展]},
	year = {2023},
	journal = {Journal of Library and Information Science in Agriculture},
	volume = {35},
	number = {6},
	pages = {16 – 28},
	doi = {10.13998/j.cnki.issn1002-1248.23-0347},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183001524&doi=10.13998%2fj.cnki.issn1002-1248.23-0347&partnerID=40&md5=615d779a20504206cf4094b4ec0bdbcf},
	abstract = {[Purpose/Significance] Argument mining, a research hotspot in the field of computational linguistics, provides machine processable structured data for computational models of argument. Argument mining tasks are closely related to artificial intelligence (AI) technologies, such as natural language processing and knowledge representation. There are numerous systematic studies in academia and a clear technical realization route has come into being. New research results continue to emerge as a result of rich resources and rapid development and iteration of deep learning, large language models (LLMs), and other technologies. This study, which reviews the research status and progress of argument mining, can serve as a resource for future research and application development. [Method/Process] Through literature review, this paper systematically reviews the relevant research basis (including foundational techniques and semantic representation models), summarizes the related technical system in terms of task framework, influencing factors of technological complexity, and method classification, and then introduces the argument mining practice and application cases for specific fields and research objectives and makes a comparative analysis. Most importantly, the overall development and characteristics of this research field are summarized, with a focus on tracking the progress of multimedia argument mining in the context of the new AI environment. [Results/Conclusions] Relevant research has experienced the development of "machine learning - deep learning" and "text only - multimodal", and the levels of development and application of various fields vary much. Future research may focus on how to achieve multigranularity and multimodal content generalization, as well as how to promote its application and implementation in practice. Possible research directions include: 1) the use of LLMs in argument mining, because they exhibit significant benefits in downstream applications such as natural language processing and multimodal learning, and can also provide certain technical conditions for the generation of argument content; 2) the use of domain knowledge organization systems such as vocabulary, knowledge base and knowledge graph: with these systems, researchers can combine domain-specific argument mining models with rich knowledge structure, to strengthen semantic representation and organization improve the systematization and dig deeper into argument mining model research in the domain; 3) promoting the application research and practice of argument mining in more fields or across disciplines, and improving the retrieval and visualization of argument information, such as combining information retrieval methods with argument mining to build the next generation of argument search engines. © 2024 Chinese Journal of Obstetrics and Gynecology/Zhonghua Fu Chan Ke Za Zhi. All rights reserved.},
	author_keywords = {argument mining; development path; multimodal; technical system},
	type = {Review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Norouzi202361,
	author = {Norouzi, Sanaz Saki and Mahdavinejad, Mohammad Saeid and Hitzler, Pascal},
	title = {Conversational Ontology Alignment with ChatGPT},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3591},
	pages = {61 – 66},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85180754943&partnerID=40&md5=8a06be5d71f54f617249262d138c8531},
	abstract = {This study evaluates the applicability and efficiency of ChatGPT for ontology alignment using a naive approach. ChatGPT’s output is compared to the results of the Ontology Alignment Evaluation Initiative 2022 campaign using conference track ontologies. This comparison is intended to provide insights into the capabilities of a conversational large language model when used in a naive way for ontology matching and to investigate the potential advantages and disadvantages of this approach. © 2023 Copyright for this paper by its authors.},
	author_keywords = {ChatGPT; Large language models; LLM behavior; Ontology alignment; Ontology matching; Prompt engineering; Schema matching},
	keywords = {Computational linguistics; ChatGPT; Language model; Large language model; LLM behavior; Ontology alignment; Ontology matching; Ontology's; Prompt engineering; Schema matching; Ontology},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Procko2023141,
	author = {Procko, Tyler Thomas and Ochoa, Omar and Elvira, Timothy},
	title = {Automatic Generation of BFO-Compliant Aristotelian Definitions in OWL Ontologies with GPT},
	year = {2023},
	journal = {Proceedings - 2023 5th International Conference on Transdisciplinary AI, TransAI 2023},
	pages = {141 – 146},
	doi = {10.1109/TransAI60598.2023.00042},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85184805224&doi=10.1109%2fTransAI60598.2023.00042&partnerID=40&md5=be32e38cbeb397dde1522d132304542d},
	abstract = {Ontologies are representational artifacts that purport to accurately describe some aspect of reality, including the entities and the relations that hold between them. In computer science, ontologies are software artifacts containing the schematic structure for machine-readable knowledge, typically formed as a graph of subject-predicate-object triples, constrained through Description Logics. These resources and their relations are self-defining, i.e., some resource may be defined by considering all its stated relations. Resources are often attended with natural language annotations, that humans may read and interpret, such as labels and definitions. Many long-standing ontologies have useless lexical definitions that define resources cyclically, e.g., a FOAF: Person is simply defined as 'A person'. In Aristotelian terms, the definition of a thing should be reducible, by using terms simpler than itself, such that every definition can be unpacked up to the most general thing, which can only be defined by stating examples and use cases. This paper presents an innovative technique that leverages the Generative Pre-trained Transformer (GPT) large language model, GPT -4, for automatically generating Aristotelian definition annotations for OWL classes that engenders compliance with the Basic Formal Ontology standard.  © 2023 IEEE.},
	author_keywords = {BFO; epistemology; GPT; Linked Data; ontology},
	keywords = {Birds; Data description; Ontology; Regulatory compliance; Automatic Generation; BFO; Description logic; Epistemology; Generative pre-trained transformer; Linked datum; Ontology's; OWL ontologies; Schematic structures; Software artefacts; Linked data},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Wei20238667,
	author = {Wei, Yanbin and Huang, Qiushi and Zhang, Yu and Kwok, James T.},
	title = {KICGPT: Large Language Model with Knowledge in Context for Knowledge Graph Completion},
	year = {2023},
	journal = {Findings of the Association for Computational Linguistics: EMNLP 2023},
	pages = {8667 – 8683},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85183311284&partnerID=40&md5=879a60839ce7bc963a3ce78363db489e},
	abstract = {Knowledge Graph Completion (KGC) is crucial for addressing knowledge graph incompleteness and supporting downstream applications. Many models have been proposed for KGC. They can be categorized into two main classes: triple-based and text-based approaches. Triple-based methods struggle with long-tail entities due to limited structural information and imbalanced entity distributions. Text-based methods alleviate this issue but require costly training for language models and specific finetuning for knowledge graphs, which limits their efficiency. To alleviate these limitations, in this paper, we propose KICGPT, a framework that integrates a large language model (LLM) and a triple-based KGC retriever. It alleviates the long-tail problem without incurring additional training overhead. KICGPT uses an in-context learning strategy called Knowledge Prompt, which encodes structural knowledge into demonstrations to guide the LLM. Empirical results on benchmark datasets demonstrate the effectiveness of KICGPT with smaller training overhead and no finetuning. © 2023 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Context learning; Downstream applications; In contexts; Knowledge graphs; Language model; Long tail; Structural information; Text-based approach; Text-based methods; Training overhead; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 11}
}@CONFERENCE{Baek202370,
	author = {Baek, Jinheon and Aji, Alham Fikri and Saffari, Amir},
	title = {Knowledge-Augmented Language Model Prompting for Zero-Shot Knowledge Graph Question Answering},
	year = {2023},
	journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
	pages = {70 – 98},
	doi = {10.18653/v1/2023.matching-1.7},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174114810&doi=10.18653%2fv1%2f2023.matching-1.7&partnerID=40&md5=5521ba5b6673036f174b1f4d472e1585},
	abstract = {Large Language Models (LLMs) are capable of performing zero-shot closed-book question answering tasks, based on their internal knowledge stored in parameters during pre-training. However, such internalized knowledge might be insufficient and incorrect, which could lead LLMs to generate factually wrong answers. Furthermore, fine-tuning LLMs to update their knowledge is expensive. To this end, we propose to augment the knowledge directly in the input of LLMs. Specifically, we first retrieve the relevant facts to the input question from the knowledge graph based on semantic similarities between the question and its associated facts. After that, we prepend the retrieved facts to the input question in the form of the prompt, which is then forwarded to LLMs to generate the answer. Our framework, Knowledge-Augmented language model PromptING (KAPING), requires no model training, thus completely zero-shot. We validate the performance of our KAPING framework on the knowledge graph question answering task, that aims to answer the user's question based on facts over a knowledge graph, on which ours outperforms relevant zero-shot baselines by up to 48% in average, across multiple LLMs of various sizes.  © 2023 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Graphic methods; Semantics; Zero-shot learning; Fine tuning; Graph-based; Knowledge graphs; Language model; Pre-training; Question Answering; Question Answering Task; Semantic similarity; Task-based; Wrong answers; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 12; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@BOOK{Recto2023237,
	author = {Recto, Mitch and Chang, Anthony C.},
	title = {Artificial intelligence in the cardiology clinic},
	year = {2023},
	journal = {Intelligence-Based Cardiology and Cardiac Surgery: Artificial Intelligence and Human Cognition in Cardiovascular Medicine},
	pages = {237 – 242},
	doi = {10.1016/B978-0-323-90534-3.00038-X},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176838614&doi=10.1016%2fB978-0-323-90534-3.00038-X&partnerID=40&md5=d41eebc442399a968de20e427f2e2189},
	abstract = {The typical visit to the cardiology clinic remains a suboptimal experience with ample room for improvement for both the clinician and the patient or the patient’s family. Many of the issues are related to lack of a sophisticated digital and artificial intelligence (AI) strategy before, during, and after the clinic visit. An “AI-enabled” clinic can improve many aspects of the entire clinic experience for both the clinician and the patient and family, and tools include: natural language processing especially with large language models (like ChatGPT), AI in wearable devices, real world data and analytics, convolutional neural networks, and robotic process automation. © 2024 Elsevier Inc. All rights reserved.},
	author_keywords = {Deep learning; Knowledge graphs; Large language models; Machine learning; Natural language processing; Robotic process automation; Wearable technology},
	type = {Book chapter},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Frey2023,
	author = {Frey, Johannes and Meyer, Lars-Peter and Arndt, Natanael and Brei, Felix and Bulert, Kirill},
	title = {Benchmarking the Abilities of Large Language Models for RDF Knowledge Graph Creation and Comprehension: How Well Do LLMs Speak Turtle?},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3559},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178596343&partnerID=40&md5=e04931624848f328aa2c4965169f67e2},
	abstract = {Large Language Models (LLMs) are advancing at a rapid pace, with significant improvements at natural language processing and coding tasks. Yet, their ability to work with formal languages representing data, specifically within the realm of knowledge graph engineering, remains under-investigated. To evaluate the proficiency of various LLMs, we created a set of five tasks that probe their ability to parse, understand, analyze, and create knowledge graphs serialized in Turtle syntax. These tasks, each embodying distinct degrees of complexity and being able to scale with the size of the problem, have been integrated into our automated evaluation system, the LLM-KG-Bench. The evaluation encompassed four commercially available LLMs - GPT-3.5, GPT-4, Claude 1.3, and Claude 2.0, as well as two freely accessible offline models, GPT4All Vicuna and GPT4All Falcon 13B. This analysis offers an in-depth understanding of the strengths and shortcomings of LLMs in relation to their application within RDF knowledge graph engineering workflows utilizing Turtle representation. While our findings show that the latest commercial models outperform their forerunners in terms of proficiency with the Turtle language, they also reveal an apparent weakness. These models fall short when it comes to adhering strictly to the output formatting constraints, a crucial requirement in this context. © 2023 Copyright for this paper by its authors.},
	author_keywords = {Knowledge Graph Engineering; Large Language Model; Large Language Model Benchmark},
	keywords = {Computational linguistics; Formal languages; Natural language processing systems; Petroleum reservoir evaluation; Resource Description Framework (RDF); Automated evaluation systems; Degrees of complexity; Knowledge graph engineering; Knowledge graphs; Language model; Language processing; Large language model; Large language model benchmark; Natural languages; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@ARTICLE{Liu2023340,
	author = {Liu, Yibo and Zhang, Jian and Hu, Fanghuai and Li, Taowei and Wang, Zhaolei},
	title = {A Military Domain Knowledge-Based Question Answering Method Based on Large Language Model Enhancement},
	year = {2023},
	journal = {Communications in Computer and Information Science},
	volume = {1923 CCIS},
	pages = {340 – 352},
	doi = {10.1007/978-981-99-7224-1_27},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176916152&doi=10.1007%2f978-981-99-7224-1_27&partnerID=40&md5=4bc6b156789c8b7211965b8047dfbc0f},
	abstract = {With the rise of big language model technology, the application of big models in the military field is increasingly being valued. How to combine big language models with knowledge graph technology to improve the effectiveness of knowledge Q&A is currently a key research direction for improving military knowledge services. Based on the big language model technology, this paper implements knowledge Q&A in the military field by using template learning and template matching methods. For the key steps of knowledge linking and template matching, this paper uses the knowledge linking and semantic matching technology enhanced by the big language model. Finally, experimental verification was conducted in the test set provided by the CCKS (China Conference on Knowledge Graph and Semantic Computing) conference, and F1 reached 0.869. In summary, this paper provides a new solution for natural language Q&A in the military field using a large language model. This method achieves high accuracy while reducing dependence on training corpus data. © 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.},
	author_keywords = {Big language model; knowledge linking; military knowledge Q&A; template matching},
	keywords = {Computational linguistics; Domain Knowledge; Knowledge graph; Natural language processing systems; Semantics; Big language model; Domain knowledge; Knowledge based; Knowledge graphs; Knowledge linking; Language model; Military domains; Military fields; Military knowledge Q&A; Modeling technology; Template matching},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Yu2023339,
	author = {Yu, Shuang and Huang, Tao and Liu, Mingyi and Wang, Zhongjie},
	title = {BEAR: Revolutionizing Service Domain Knowledge Graph Construction with LLM},
	year = {2023},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14419 LNCS},
	pages = {339 – 346},
	doi = {10.1007/978-3-031-48421-6_23},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178217581&doi=10.1007%2f978-3-031-48421-6_23&partnerID=40&md5=9b4d7b798f33cf50d88b98d1d42b0663},
	abstract = {Knowledge graph (KG), as a novel knowledge storage approach, has been widely used in various domains. In the service computing community, researchers tried to harness the enormous potential of KG to tackle domain-specific tasks. However, the lack of an openly available service domain KG limits the in-depth exploration of KGs in domain-specific applications. Building a service domain KG primarily faces two challenges: first, the diversity and complexity of service domain knowledge, and second, the dispersion of domain knowledge and the lack of annotated data. These challenges discouraged costly investment in large, high-quality domain-specific KGs by researchers. In this paper, we present the construction of a service domain KG called BEAR. We design a comprehensive service domain knowledge ontology to automatically generate the prompts for the Large Language Model (LLM) and employ LLM to implement a zero-shot method to extract high-quality knowledge. A series of experiments are conducted to demonstrate the feasibility of graph construction process and showcase the richness of content available from BEAR. Currently, BEAR includes 133, 906 nodes, 169, 159 relations, and about 424, 000 factual knowledge as attributes, which is available through github.com/HTXone/BEAR. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Knowledge graph construction; Large language model; Service domain knowledge graph; Service domain ontology},
	keywords = {Computational linguistics; Digital storage; Domain Knowledge; Ontology; Zero-shot learning; Domain knowledge; Domain ontologies; Graph construction; Knowledge graph construction; Knowledge graphs; Language model; Large language model; Service domain; Service domain knowledge graph; Service domain ontology; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7}
}

@ARTICLE{2023,
	title = {22nd International Conference on Web-based Learning, ICWL 2023},
	year = {2023},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14409 LNCS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178572378&partnerID=40&md5=ea68bd763d1123339ecfb53fa9001bf9},
	abstract = {The proceedings contain 16 papers. The special focus in this conference is on Web-based Learning. The topics include: Intended Learning Outcomes and Taxonomy Mapping at University Level; mixed Reality Learning Visualizations Using Knowledge Graphs; tracking the Adaptive Learning Process with Topics Ontology; prompting Large Language Models to Power Educational Chatbots; motivating Learners with Gamified Chatbot-Assisted Learning Activities; a Transfer Learning Approach Interaction in an Academic Consortium; AI4T: A Teacher’s Dashboard for Visual Rendering of Students’ Assignments in Massive Open Online Courses; corpus-Based Translation Pedagogy: A Preliminary Case Study; investigating Student Profiles Related to Academic Learning Achievement; graduation Project Monitoring Platform Based on a Personalized Supervision Plan; an Online Tutoring and Assessment System for Teaching Relational Algebra in Database Classes; automatic and Authentic eAssessment of Online Database Design Theory Assignments; from Classroom to Metaverse: A Study on Gamified Constructivist Teaching in Higher Education; exploring the Transformative Potential of Virtual Reality in History Education: A Scoping Review.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Gupta2023,
	author = {Gupta, Rajeev and Srinivasa, Srinath},
	title = {Workshop on Enterprise Knowledge Graphs using Large Language Models},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3532},
	doi = {10.1145/3583780.3615301},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177552958&doi=10.1145%2f3583780.3615301&partnerID=40&md5=be6f73104495f7ba77ee88579b8aa2a6},
	abstract = {Knowledge graphs are used for organizing and connecting individual entities to integrate the information extracted from different data sources. Typically, knowledge graphs are used to connect various real-world entities like persons, places, things, actions, etc. For the knowledge graphs created using the enterprise data, the knowledge graph entities can be of different types—static entities (e.g., people, projects), communication entities (e.g., emails, meetings, documents), derived entities (e.g., rules, definitions, entities from emails), etc. The graphs are used to connect these entities with enriched context (as edges and node attributes) and used for powering various search and recommendations applications. With the advent of large language models, the whole lifecycle of knowledge graphs involving –information extraction, graph construction, application of graphs, querying knowledge graphs, using the graph for recommendations, etc., – is impacted. With large language models such as GPT, LLaMA, PALM, etc., entity and relationship extraction can be improved. Similarly, one can answer different types of queries with the help of LLMs which were very difficult without them. This workshop is about improving the enterprise knowledge graphs and its applications using large language models. Enterprise graphs can be of different scopes—whether they contain data from individual users/customers, a sub-organization, or the whole enterprise. This workshop will also cover various privacy and access control related issues which are typical for any enterprise graph. These include privacy preserving federated learning, using LLMs to extract information from private data, querying the knowledge graph in a privacy preserving manner, etc. © 2023 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).},
	author_keywords = {Entity Extraction; Knowledge Graph; Large Language Model; Recommendations; Relationship Extraction},
	keywords = {Computational linguistics; Data mining; Knowledge graph; Life cycle; Natural language processing systems; Query processing; Data-source; Enterprise data; Entity extractions; Knowledge graphs; Language model; Large language model; Privacy preserving; Real-world entities; Recommendation; Relationship extraction; Graphic methods},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{2023,
	title = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
	year = {2023},
	journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175420251&partnerID=40&md5=d3481577748387760fc6c19a0c97f0db},
	abstract = {The proceedings contain 12 papers. The topics discussed include: knowledge graph-augmented language models for complex question answering; exploring the curious case of code prompts; a smashed glass cannot be full: generation of commonsense explanations through prompt-based few-shot learning; saliency map verbalization: comparing feature importance representations from model-free and instruction-based methods; using planning to improve semantic parsing of instructional texts; reasoning circuits: few-shot multi-hop question generation with structured rationales; knowledge-augmented language model prompting for zero-shot knowledge graph question answering; can in-context learners learn a reasoning concept from demonstrations?; effect graph: effect relation extraction for explanation generation; and OPT-R: exploring the role of explanations in finetuning and prompting for reasoning skills of large language models.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Hristov2023519,
	author = {Hristov, Anton and Ivanov, Petar and Aksenova, Anna and Asamov, Tsvetan and Gyurov, Pavlin and Primov, Todor and Boytcheva, Svetla},
	title = {Clinical Text Classification to SNOMED CT Codes using Transformers Trained on Linked Open Medical Ontologies},
	year = {2023},
	journal = {International Conference Recent Advances in Natural Language Processing, RANLP},
	pages = {519 – 526},
	doi = {10.26615/978-954-452-092-2_057},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179181038&doi=10.26615%2f978-954-452-092-2_057&partnerID=40&md5=3a62b4ae6347296f9a3fbf9c07ee8313},
	abstract = {We present an approach for medical text coding with SNOMED CT. Our approach uses publicly available linked open data from terminologies and ontologies as training data for the algorithms. We claim that even small training corpora made of short text snippets can be used to train models for the given task. We propose a method based on transformers enhanced with clustering and filtering of the candidates. Further, we adopt a classical machine learning approach - support vector classification (SVC) using the transformer embeddings. The resulting approach proves to be more accurate than the predictions given by Large Language Models. We evaluate on a dataset generated from linked open data for SNOMED codes related to morphology and topography for four use cases. Our transformers-based approach achieves an F1-score of 0.82 for morphology and 0.99 for topography codes. Further, we validate the applicability of our approach in a clinical context using labelled real clinical data that are not used for model training. © 2023 Incoma Ltd. All rights reserved.},
	keywords = {Linked data; Ontology; Open Data; Text processing; Topography; Clinical text classifications; Linked open datum; Medical ontology; Ontology's; Short texts; Small training; SNOMED-CT; Text snippets; Training corpus; Training data; Classification (of information)},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Bronze Open Access}
}

@CONFERENCE{Huynh2023,
	author = {Huynh, Viet-Phi and Chabot, Yoan and Troncy, Raphaël},
	title = {Towards Generative Semantic Table Interpretation},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3462},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171281829&partnerID=40&md5=16ae0ed05db813ca4416cc870a8eca7b},
	abstract = {Semantic Table Interpretation (STI), or Semantic Table Annotation, is the process of understanding the semantics of tabular data with reference information identified in knowledge graphs (KG). In this paper, we first present insights gained from the design and implementation of DAGOBAH SL, a top performing STI system in state-of-the-art benchmarks, and we discuss the unsolved challenges that need to be addressed to make STI more effective in practice. Pre-trained generative Large Language Models (LLMs) have demonstrated their powerful versatility in tackling a broad spectrum of natural language understanding tasks. We envision their potential for improving STI systems. We describe several appealing research ideas that could lay the foundation for future development of Generative Semantic Table Interpretation. © 2023 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).},
	author_keywords = {DAGOBAH; Generative Information Extraction; Knowledge Graph; Large Language Model; Semantic Table Interpretation},
	keywords = {Computational linguistics; Semantics; DAGOBAH; Design and implementations; Generative information extraction; Interpretation systems; Knowledge graphs; Language model; Large language model; Semantic table interpretation; Semantic tables; Tabular data; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{2023,
	title = {22nd International Conference of the Italian Association for Artificial Intelligence, AIxIA 2023},
	year = {2023},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14318 LNAI},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177165552&partnerID=40&md5=dee4de302488ee3ab1ed82341f3a9893},
	abstract = {The proceedings contain 33 papers. The special focus in this conference is on Italian Association for Artificial Intelligence. The topics include: Unraveling ChatGPT: A Critical Analysis of AI-Generated Goal-Oriented Dialogues and Annotations; scaling Large Language Models to the Extreme: Neural Semantic Processing of Multiple Tasks in Italian; named Entity Recognition and Linking for Entity Extraction from Italian Civil Judgements; CENTAURO: An Explainable AI Approach for Customer Loyalty Prediction in Retail Sector; toward Novel Optimizers: A Moreau-Yosida View of Gradient-Based Learning; mastering the Card Game of Jaipur Through Zero-Knowledge Self-Play Reinforcement Learning and Action Masks; uncovering Bias in the Face Processing Pipeline: An Analysis of Popular and State-of-the-Art Algorithms Across Demographic Groups; A Multi-label Classification Study for the Prediction of Long-COVID Syndrome; PAUL-2: An Upgraded Transformer-Based Redesign of the Algorithmic Composer PAUL; deriving Dependency Graphs from Abstract Argumentation Frameworks; Understanding the Effect of Deep Ensembles in LiDAR-Based Place Recognition; Enhancing LiDAR Performance: Robust De-Skewing Exclusively Relying on Range Measurements; can Existing 3D Monocular Object Detection Methods Work in Roadside Contexts? A Reproducibility Study; Embedding Shepard’s Interpolation into CNN Models for Unguided Depth Completion; Performance Evaluation of Depth Completion Neural Networks for Various RGB-D Camera Technologies in Indoor Scenarios; inference in Probabilistic Answer Set Programming Under the Credal Semantics; efficient Modal Decision Trees; Clique-TF-IDF: A New Partitioning Framework Based on Dense Substructures; combining Contrastive Learning and Knowledge Graph Embeddings to Develop Medical Word Embeddings for the Italian Language; recognizing the Style, Genre, and Emotion of a Work of Art Through Visual and Knowledge Graph Embeddings; reConf: An Automatic Context-Based Software Reconfiguration Tool for Autonomous Vehicles Using Answer-Set Programming; combining Genetic Algorithms and Temporal Constraint Satisfaction for Recommending Personalized Tourist Itineraries; towards Automatic Digitalization of Railway Engineering Schematics; election Manipulation in Social Networks with Single-Peaked Agents; Mining Contrast Sequential Patterns with ASP.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Chen2023273,
	author = {Chen, Yilong and Cui, Shiyao and Huang, Kun and Wang, Shicheng and Tang, Chuanyu and Liu, Tingwen and Fang, Binxing},
	title = {Improving Adaptive Knowledge Graph Construction via Large Language Models with Multiple Views},
	year = {2023},
	journal = {Communications in Computer and Information Science},
	volume = {1923 CCIS},
	pages = {273 – 284},
	doi = {10.1007/978-981-99-7224-1_21},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176947983&doi=10.1007%2f978-981-99-7224-1_21&partnerID=40&md5=2d9e80284861c6c8d9d65311bfc04c8a},
	abstract = {Knowledge graph construction (KGC) aims to build the semantic network which expresses the relationship between named entities. Despite the success of prior studies, it is struggling to accommodate existing KGC models with evolving entity-relation knowledge schema. In this paper, we propose a schema-adaptive KGC method driven by the instruction-tuning large language models (LLM). We fine-tune a LLM with tailored KGC corpus, through which the generalization ability of LLMs are transfered for KGC with evolving schema. To alleviate the bias of a single LLM, we integrate the superiority of several expert models to derive credible results from multiple perspectives. We further boost KGC performances via an elaborately designed schema-constrained decoding strategy and a LLM-guided correction module. Experimental results validate the advantages of our proposed method. Besides, our method achieved the first place in the first task of CCKS-2023 Knowledge Graph Construction. © 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.},
	author_keywords = {Knowledge graph construction; Large language models},
	keywords = {Computational linguistics; Natural language processing systems; Semantics; Construction model; Graph construction; Knowledge graph construction; Knowledge graphs; Knowledge schemata; Language model; Large language model; Multiple views; Named entities; Semantics networks; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Markowitz2023,
	author = {Markowitz, Elan S. and Galstyan, Aram},
	title = {StATIK+: Structure and Text for Inductive Knowledge Graph Modeling and Paths towards Enterprise Implementations},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3532},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177571183&partnerID=40&md5=58aed3de71133c386241f9588b93c273},
	abstract = {While many enterprise knowledge Graphs (KGs) are updated frequently, most KG models require retraining to incorporate these updates. Inductive models are able to adapt to new edges and entities in the KG. This extended abstract presents a prior work StATIK–Structure And Text for Inductive Knowledge Completion– and a roadmap towards industry implementations. StATIK uses a Language Model to extract the semantic information from text descriptions, while using Message Passing Neural Networks to capture the structural information in the graph. While StATIK was evaluated for inductive knowledge graph completion, many applications have different end tasks. This work provides background and a roadmap of some of the opportunities in applying StATIK to industry tasks. © 2023 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).},
	author_keywords = {Enterprise Knowledge Graphs; KG; Knowledge Graphs; Large Language Models; LLM},
	keywords = {Abstracting; Computational linguistics; Graph neural networks; Message passing; Modeling languages; Semantics; Enterprise knowledge graph; Graph model; Graph path; Knowledge graphs; Language model; Large language model; LLM; Roadmap; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Phokela20231846,
	author = {Phokela, Kanchanjot Kaur and Sikand, Samarth and Singi, Kapil and Dey, Kuntal and Sharma, Vibhu Saujanya and Kaulgud, Vikrant},
	title = {Smart Prompt Advisor: Multi-Objective Prompt Framework for Consistency and Best Practices},
	year = {2023},
	journal = {Proceedings - 2023 38th IEEE/ACM International Conference on Automated Software Engineering, ASE 2023},
	pages = {1846 – 1848},
	doi = {10.1109/ASE56229.2023.00019},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179012657&doi=10.1109%2fASE56229.2023.00019&partnerID=40&md5=da263cfbd96f6ed4f6fbaae849cfea2e},
	abstract = {Recent breakthroughs in Large Language Models (LLM), comprised of billions of parameters, have achieved the ability to unveil exceptional insight into a wide range of Natural Language Processing (NLP) tasks. The onus of the performance of these models lies in the sophistication and completeness of the input prompt. Minimizing the enhancement cycles of prompt with improvised keywords becomes critically important as it directly affects the time to market and cost of the developing solution. However, this process inevitably has a trade-off between the learning curve/proficiency of the user and completeness of the prompt, as generating such a solutions is an incremental process. In this paper, we have designed a novel solution and implemented it in the form of a plugin for Visual Studio Code IDE, which can optimize this trade-off, by learning the underlying prompt intent to enhance with keywords. This will tend to align with developers' collection of semantics while developing a secure code, ensuring parameter and local variable names, return expressions, simple pre and post-conditions. and basic control and data flow are met.  © 2023 IEEE.},
	author_keywords = {Artificial Intelligence; Deep Learning; LLM; Ontology; Prompt Engineering},
	keywords = {Codes (symbols); Deep learning; Economic and social effects; Natural language processing systems; Best practices; Deep learning; Language model; Language processing; Large language model; Multi objective; Natural languages; Ontology's; Prompt engineering; Trade off; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Feng2023317,
	author = {Feng, Guandong and Zhu, Guoliang and Shi, Shengze and Sun, Yue and Fan, Zhongyi and Gao, Sulin and Hu, Jun},
	title = {Robust NL-to-Cypher Translation for KBQA: Harnessing Large Language Model with Chain of Prompts},
	year = {2023},
	journal = {Communications in Computer and Information Science},
	volume = {1923 CCIS},
	pages = {317 – 326},
	doi = {10.1007/978-981-99-7224-1_25},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176966002&doi=10.1007%2f978-981-99-7224-1_25&partnerID=40&md5=4f7d467cbd1641549620e23d2d2dc46e},
	abstract = {Knowledge Base Question Answering (KBQA) is a significant task in natural language processing, aiming to retrieve answers from structured knowledge bases in response to natural language questions. NL2Cypher is crucial for accurately querying answers from knowledge bases, but there is limited research in this area or the results are unsatisfactory. Our work explores the convergence of advanced natural language processing techniques with knowledge base question answering (KBQA), focusing on the automated generation of Cypher queries from natural language queries. By leveraging the capabilities of large language model (LLM), our approach bridges the gap between textual questions and structured knowledge representations. The proposed methodology showcases promising results in accurately formulating Cypher queries. We achieved substantial performance in the CCKS2023 Foreign Military Unmanned Systems Knowledge Graph Reasoning Question-Answering Evaluation Task. Our method achieved an F1 score of 0.94269 on the final testing dataset. © 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.},
	author_keywords = {Cypher; KBQA; LLM},
	keywords = {Computational linguistics; Knowledge graph; Knowledge management; Natural language processing systems; Statistical tests; Cipher; Knowledge base question answering; Language model; Language processing; Language processing techniques; Large language model; Natural language questions; Natural languages; Question Answering; Structured knowledge; Bridge approaches},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Mohanty2023,
	author = {Mohanty, Anurag},
	title = {EduEmbedd – A Knowledge Graph Embedding for Education},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3532},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177600940&partnerID=40&md5=57b001fdc0dc598036196e6031f0d44d},
	abstract = {Motivated by emerging strength of Knowledge graphs as an integrated information representation and repository that interlinks heterogeneous data from different domains and the growing adoption and application of artificial intelligence for various use-cases on education domain. We propose EduEmbedd, a framework to develop an Embedding (Knowledge Graph Embedding) for the education domain and demonstrate the usefulness of such embedding. We understand that in the emerging era of Large Language Model (LLMs), domain specific embeddings based on Knowledge Graph has the potential to aid the LLMs to overcome some of the most pressing challenges like hallucinations along with improving its interpretability. The knowledge held up in the education domain is an assimilation of information from multiple contexts. EduEmbedd leverages all these different contexts into one to learn an effective embedding which can be used for various upstream machine learning tasks. The heterogeneous data from different contexts is often related to each other. In order to derive value, the data should be integrated, structured and the relationships should be made explicit. Knowledge Graphs (KG) can play a key role in achieving these goals and gives us an opportunity to assimilate information from these multiple contexts into a single unified structure and semantic form. We also understand that several novel enhancements would be required on top of this base idea to ensure that we are able to deal with the nuances of the domain for which we are creating the embedding. EduEmbedd is a step towards this direction where we introduce a systematic framework to create an Embedding for the education domain by leveraging Knowledge Graph Embedding (KGE) approaches. We also demonstrate how these embeddings are useful in terms of its ability in representing the composite knowledge being held up in them along with the efficacy it brings to machine learning using this approach. © 2023 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).},
	author_keywords = {Knowledge Graph; Knowledge Graph Embedding; Large language Model},
	keywords = {Computational linguistics; Graph embeddings; Knowledge management; Machine learning; Semantics; Education domain; Embeddings; Graph embeddings; Heterogeneous data; Hold up; Knowledge graph embedding; Knowledge graphs; Language model; Large language model; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Subramaniam2023,
	author = {Subramaniam, Pranav and Khurana, Udayan and Srinivas, Kavitha and Samulowitz, Horst},
	title = {Related Table Search for Numeric data using Large Language Models and Enterprise Knowledge Graphs},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3532},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177565356&partnerID=40&md5=ab192b3a6307c4741d60a4ecd226f833},
	abstract = {Searching related tables is a crucial part of enterprise data lake exploration. However, data lakes often contain numeric tables with unreliable column headers, and ID columns whose text names have been lost. Finding such related numeric tables in large data lakes is a challenging task. State-of-the-art related table search relies on text values in tables, and cannot be applied on numeric tables. On the other hand, the state-of-the-art for semantic labeling of numeric tables using enterprise knowledge graphs (EKGs) has clear sources of semantic ambiguity due to its heuristic and rule-based approaches for determining numeric types and EKG labels, leading to poor performance. In this paper, we propose a system, NumSearchLLM, that leverages LLMs alongside EKGs to alleviate the ambiguity in semantic labeling of numeric columns and facilitate both joinable table search, and more general table relatedness tasks. Specifically, we use LLMs to: (i) discover new relationships absent from EKGs; (ii) validate numeric types assigned by heuristics; and (iii) check whether the semantic labels assigned to columns of a table form a meaningful schema. We also show how EKGs can be used in conjunction with LLMs to fix labeling inconsistencies discovered by LLMs by finding alternate labels. We show that by an integrated use of LLMs with EKGs, we can achieve superior performance in joinable and related table search tasks in comparison to the current approaches. © 2023 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).},
	author_keywords = {EKG- and LLM-based data discovery; numeric data discovery; paper formatting; tabular data},
	keywords = {Electrocardiography; Lakes; Semantics; Data discovery; Enterprise knowledge graph- and LLM-based data discovery; Knowledge graphs; Numeric data; Numeric data discovery; Paper formatting; Semantic labeling; State of the art; Tabular data; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Yu20231173,
	author = {Yu, Changlong and Wang, Weiqi and Liu, Xin and Bai, Jiaxin and Song, Yangqiu and Li, Zheng and Gao, Yifan and Cao, Tianyu and Yin, Bing},
	title = {FolkScope: Intention Knowledge Graph Construction for E-commerce Commonsense Discovery},
	year = {2023},
	journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
	pages = {1173 – 1191},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175070179&partnerID=40&md5=fdafe65bb81fbc3aaf6a626b20a06b21},
	abstract = {Understanding users' intentions in e-commerce platforms requires commonsense knowledge. In this paper, we present FolkScope, an intention knowledge graph construction framework to reveal the structure of humans' minds about purchasing items. As commonsense knowledge is usually ineffable and not expressed explicitly, it is challenging to perform information extraction. Thus, we propose a new approach that leverages the generation power of large language models (LLMs) and human-in-the-loop annotation to semi-automatically construct the knowledge graph. LLMs first generate intention assertions via e-commerce-specific prompts to explain shopping behaviors, where the intention can be an open reason or a predicate falling into one of 18 categories aligning with ConceptNet, e.g., IsA, MadeOf, UsedFor, etc. Then we annotate plausibility and typicality labels of sampled intentions as training data in order to populate human judgments to all automatic generations. Last, to structurize the assertions, we propose pattern mining and conceptualization to form more condensed and abstract knowledge. Extensive evaluations and studies demonstrate that our constructed knowledge graph can well model e-commerce knowledge and have many potential applications. Our codes and datasets are publicly available at https://github.com/HKUSTKnowComp/FolkScope. © 2023 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Electronic commerce; Commerce platforms; Commonsense knowledge; E- commerces; Graph construction; Human mind; Human-in-the-loop; Knowledge graphs; Language model; New approaches; User's intentions; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 13}
}

@CONFERENCE{Beermann2023,
	author = {Beermann, Jo and Benfer, Rebekka and Both, Maximilian and Muller, Jochen and Diedrich, Christian},
	title = {Comparison of Different Natural Language Processing Models to Achieve Semantic Interoperability of Heterogeneous Asset Administration Shells},
	year = {2023},
	journal = {IEEE International Conference on Industrial Informatics (INDIN)},
	volume = {2023-July},
	doi = {10.1109/INDIN51400.2023.10218154},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171186651&doi=10.1109%2fINDIN51400.2023.10218154&partnerID=40&md5=58f8cc8719f82a106c5c65a3cfc8a98d},
	abstract = {Self-organizing systems represent the next level of building automation and make it possible to reduce the manual engineering effort of automation systems. For self-organizing systems to be able to interact interoperable, the system components must be mapped by uniform digital twins and described in a semantically interoperable manner. Semantic interoperability is implemented in the current research approach of Industrie 4.0 through homogeneous semantics. However, given the large number of different manufacturers of technical components, agreement on uniform semantics seems unlikely. This paper presents a method that extends the Industrie 4.0 approach to heterogeneous semantics. Semantic interoperability is realized through the automated mapping of heterogeneous vocabularies to target semantics. Models from the artificial intelligence sub-field natural language processing are used for automated mapping. In this paper, existing models of natural language processing are compared with each other in terms of their mapping accuracy. A dataset based on the ECLASS standard is being developed as a basis for the comparison. This dataset is also being used to create new models that are fine-tuned to the target vocabulary. The results show that the mapping accuracy of existing approaches improves through fine-tuning by an average of 7.5% up to 93%. In addition to the improvement through fine-tuning, this work analyses the influence of the model size on the mapping accuracy by using large language models. Moreover, it examines the integration of structured knowledge in the form of knowledge graphs. © 2023 IEEE.},
	author_keywords = {Industrie 4.0; natural language processing; semantic interoperability},
	keywords = {Automation; Intelligent buildings; Interoperability; Mapping; Natural language processing systems; Automated mapping; Fine tuning; Industrie 4.0; Language processing; Mapping accuracy; Natural language processing; Natural languages; Processing model; Self-organizing systems; Semantic interoperability; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{2023,
	title = {20th Extended Semantic Web Conference, ESWC 2023},
	year = {2023},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {13998 LNCS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175965513&partnerID=40&md5=2f734909c53a66c228b68809319185d7},
	abstract = {The proceedings contain 93 papers. The special focus in this conference is on Extended Semantic Web. The topics include: AgriNER: An NER Dataset of Agricultural Entities for the Semantic Web; clayBot: Increasing Human-Centricity in Conversational Recommender Systems; mining Symbolic Rules to Explain Lung Cancer Treatments; GLENDA: Querying RDF Archives with Full SPARQL; Piloting Topic-Aware Research Impact Assessment Features in BIP! Services; explanation-Based Tool for Helping Data Producers to Reduce Privacy Risks; pathWays: Entity-Focused Exploration of Heterogeneous Data Graphs; a Geological Case Study on Semantically Triggered Processes; A System for Repairing $${\mathcal{E}\mathcal{L}}$$ Ontologies Using Weakening and Completing; sparnatural: A Visual Knowledge Graph Exploration Tool; a User Interface Model for Digital Humanities Research: Case BookSampo – Finnish Fiction Literature on the Semantic Web; modeling Grammars with Knowledge Representation Methods: Subcategorization as a Test Case; TRIC: A Triples Corrupter for Knowledge Graphs; ExeKGLib: Knowledge Graphs-Empowered Machine Learning Analytics; hannotate: Flexible Annotation for Text Analytics from Anywhere; study-Buddy: A Knowledge Graph-Powered Learning Companion for School Students; On the Problem of Automatically Aligning Indicators to SDGs; automating Benchmark Generation for Named Entity Recognition and Entity Linking; VRKG-CollaborativeExploration - Data-Driven Discussions in the Metaverse; FOO: An Upper-Level Ontology for the Forest Observatory; integrating Faceted Search with Data Analytic Tools in the User Interface of ParliamentSampo – Parliament of Finland on the Semantic Web; roXi: A Framework for Reactive Reasoning; SummaryGPT: Leveraging ChatGPT for Summarizing Knowledge Graphs; entity Typing with Triples Using Language Models; addressing the Scalability Bottleneck of Semantic Technologies at Bosch; Knowledge Injection to Counter Large Language Model (LLM) Hallucination; towards the Deployment of Knowledge Based Systems in Safety-Critical Systems; a Source-Agnostic Platform for Finding and Exploring Ontologies at Bosch; wisdom of the Sellers: Mining Seller Data for eCommerce Knowledge Graph Generation.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Guo20228548,
	author = {Guo, Quan and Cao, Shuai and Yi, Zhang},
	title = {A medical question answering system using large language models and knowledge graphs},
	year = {2022},
	journal = {International Journal of Intelligent Systems},
	volume = {37},
	number = {11},
	pages = {8548 – 8564},
	doi = {10.1002/int.22955},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85133671254&doi=10.1002%2fint.22955&partnerID=40&md5=7ea43e5404af0c332906aa84dfff8a93},
	abstract = {Question answering systems have become prominent in all areas, while in the medical domain it has been challenging because of the abundant domain knowledge. Retrieval based approach has become promising as large pretrained language models come forth. This study focuses on building a retrieval-based medical question answering system, tackling the challenge with large language models and knowledge extensions via graphs. We first retrieve an extensive but coarse set of answers via Elasticsearch efficiently. Then, we utilize semantic matching with pretrained language models to achieve a fine-grained ranking enhanced with named entity recognition and knowledge graphs to exploit the relation of the entities in question and answer. A new architecture based on siamese structures for answer selection is proposed. To evaluate the approach, we train and test the model on two Chinese data sets, NLPCC2017 and cMedQA. We also conduct experiments on two English data sets, TREC-QA and WikiQA. Our model achieves consistent improvement as compared to strong baselines on all data sets. Qualification studies with cMedQA and our in-house data set show that our system gains highly competitive performance. The proposed medical question answering system outperforms baseline models and systems in quantification and qualification evaluations. © 2022 Wiley Periodicals LLC.},
	author_keywords = {knowledge graph; medical question answering; named entity recognition; pretrained language model; Siamese network},
	keywords = {Computational linguistics; Domain Knowledge; Natural language processing systems; Semantics; Data set; Domain knowledge; Knowledge graphs; Language model; Medical domains; Medical question answering; Named entity recognition; Pretrained language model; Question answering systems; Siamese network; Knowledge graph},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 32}
}

@CONFERENCE{Zhang20231350,
	author = {Zhang, Junfeng and Zhang, Yang and Chu, Minnan and Yang, Shun and Zu, Taolei},
	title = {A LLM-Based Simulation Scenario Aided Generation Method},
	year = {2023},
	journal = {ITOEC 2023 - IEEE 7th Information Technology and Mechatronics Engineering Conference},
	pages = {1350 – 1354},
	doi = {10.1109/ITOEC57671.2023.10291525},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177614307&doi=10.1109%2fITOEC57671.2023.10291525&partnerID=40&md5=b9dc0e23d5a913985694277402634ffd},
	abstract = {In the simulation training system, the generation of simulation scenarios is a basic problem that needs to be studied. Firstly, expounds on the technical characteristics of LLM and knowledge graph; then structurally describe the simulation scenario related content, and build scenario knowledge graph; according to the characteristics of scenario aided generation, a simulation scenario generation method based on LLM is proposed, which uses prompt to fuse knowledge graph and LLM, next, the implementation steps of this method were elaborated; finally, the specific application proves that the method proposed in this paper is a good reference for the generation of simulation scenarios.  © 2023 IEEE.},
	author_keywords = {knowledge graph; LLM; prompt; scenario},
	keywords = {Generation method; Implementation steps; Knowledge graphs; LLM; Prompt; Related content; Scenario; Scenarios generation; Simulation training systems; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{Babaei Giglou2023408,
	author = {Babaei Giglou, Hamed and D’Souza, Jennifer and Auer, Sören},
	title = {LLMs4OL: Large Language Models for Ontology Learning},
	year = {2023},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14265 LNCS},
	pages = {408 – 427},
	doi = {10.1007/978-3-031-47240-4_22},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177183557&doi=10.1007%2f978-3-031-47240-4_22&partnerID=40&md5=1d401bd2c41ec196caa50fead5a98e88},
	abstract = {We propose the LLMs4OL approach, which utilizes Large Language Models (LLMs) for Ontology Learning (OL). LLMs have shown significant advancements in natural language processing, demonstrating their ability to capture complex language patterns in different knowledge domains. Our LLMs4OL paradigm investigates the following hypothesis: Can LLMs effectively apply their language pattern capturing capability to OL, which involves automatically extracting and structuring knowledge from natural language text? To test this hypothesis, we conduct a comprehensive evaluation using the zero-shot prompting method. We evaluate nine different LLM model families for three main OL tasks: term typing, taxonomy discovery, and extraction of non-taxonomic relations. Additionally, the evaluations encompass diverse genres of ontological knowledge, including lexicosemantic knowledge in WordNet, geographical knowledge in GeoNames, and medical knowledge in UMLS. The obtained empirical results show that foundational LLMs are not sufficiently suitable for ontology construction that entails a high degree of reasoning skills and domain expertise. Nevertheless, when effectively fine-tuned they just might work as suitable assistants, alleviating the knowledge acquisition bottleneck, for ontology construction. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Large Language Models; LLMs; Ontologies; Ontology Learning; Prompt-based Learning; Prompting},
	keywords = {Computational linguistics; Data mining; Learning systems; Natural language processing systems; Zero-shot learning; Language model; Language patterns; Large language model; Ontology construction; Ontology learning; Ontology's; Prompt-based learning; Prompting; Ontology},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 31}
}

@CONFERENCE{Agrawal20232604,
	author = {Agrawal, Ayush and Arora, Raghav and Datta, Ahana and Banerjee, Snehasis and Bhowmick, Brojeshwar and Jatavallabhula, Krishna Murthy and Sridharan, Mohan and Krishna, Madhava},
	title = {CLIPGraphs: Multimodal Graph Networks to Infer Object-Room Affinities},
	year = {2023},
	journal = {IEEE International Workshop on Robot and Human Communication, RO-MAN},
	pages = {2604 – 2609},
	doi = {10.1109/RO-MAN57019.2023.10309325},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179525078&doi=10.1109%2fRO-MAN57019.2023.10309325&partnerID=40&md5=b50c25502adbe493240972596a49c0e5},
	abstract = {This paper introduces a novel method for determining the best room to place an object in, for embodied scene rearrangement. While state-of-the-art approaches rely on large language models (LLMs) or reinforcement learned (RL) policies for this task, our approach, CLIPGraphs, efficiently combines commonsense domain knowledge, data-driven methods, and recent advances in multimodal learning. Specifically, it (a) encodes a knowledge graph of prior human preferences about the room location of different objects in home environments, (b) incorporates vision-language features to support multimodal queries based on images or text, and (c) uses a graph network to learn object-room affinities based on embeddings of the prior knowledge and the vision-language features. We demonstrate that our approach provides better estimates of the most appropriate location of objects from a benchmark set of object categories in comparison with state-of-the-art baselines.11Supplementary material and code: https://clipgraphs.github.io © 2023 IEEE.},
	author_keywords = {Commonsense knowledge; graph convolutional network; knowledge graph; large language models; scene rearrangement},
	keywords = {C (programming language); Computational linguistics; Convolutional neural networks; Domain Knowledge; Graph neural networks; Commonsense knowledge; Convolutional networks; Graph convolutional network; Graph networks; Knowledge graphs; Language features; Language model; Large language model; Multi-modal; Scene rearrangement; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Green Open Access}
}

@ARTICLE{Tara2023116919,
	author = {Tara, Andrei and Turesson, Hjalmar K. and Natea, Nicolae and Kim, Henry M.},
	title = {An Evaluation of Storage Alternatives for Service Interfaces Supporting a Decentralized AI Marketplace},
	year = {2023},
	journal = {IEEE Access},
	volume = {11},
	pages = {116919 – 116931},
	doi = {10.1109/ACCESS.2023.3326418},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174805348&doi=10.1109%2fACCESS.2023.3326418&partnerID=40&md5=484f55c039db3be15087aaa95ce8fcb2},
	abstract = {Given the exploding interest in generative AI and the concern that a few companies like Microsoft will monopolize access to such models, we address this centralization risk in the context of a DApp that matches buyers and sellers of various AI services. A key question for a decentralized marketplace is where and how to store the metadata that specifies the services' properties in human and machine-readable formats. Having one or a few actors controlling access to that data constitutes undesirable centralization. We explore data storage alternatives to ensure decentralization, equitable match-making, and efficiency. Classifying decentralized storage alternatives as simple peer-to-peer replication, replication governed by a permissionless consensus, and replication governed by a private consensus, we select an exemplar for each category: IPFS, Tendermint Cosmos and Hyperledger Fabric. We conduct experiments on performance and find that read and write speeds are fastest for IPFS, about two times slower for Tendermint and slowest for Hyperledger. Writing using IPFS and Tendermint takes significantly longer than reading, and finally, specifically with IPFS, write speeds strongly depend on configuration. Given these results and the properties of the storage technologies, we conclude that simple peer-to-peer storage is the best option for the proposed AI marketplace. © 2013 IEEE.},
	author_keywords = {Blockchain; decentralized AI decentralized storage; distributed ontology; semantic models},
	keywords = {Blockchain; Commerce; Digital storage; Distributed ledger; Peer to peer networks; Semantics; Block-chain; Decentralised; Decentralized AI decentralized storage; Distributed ontology; Ontology's; Peer-to-peer computing; Resources description frameworks; Semantic modelling; Ontology},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1; All Open Access, Gold Open Access}
}

@CONFERENCE{Tu2022343,
	author = {Tu, Tao and Loreaux, Eric and Chesley, Emma and Lelkes, Adam D. and Gamble, Paul and Bellaiche, Mathias and Seneviratne, Martin and Chen, Ming-Jun},
	title = {Automated LOINC standardization using pre-Trained large language models},
	year = {2022},
	journal = {Proceedings of Machine Learning Research},
	volume = {193},
	pages = {343 – 355},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171421517&partnerID=40&md5=35b85b4aba9ca95f5e71956acbfd651e},
	abstract = {Harmonization of local source concepts to standard clinical terminologies is a prerequisite for multi-center data aggregation and sharing. Challenges in automating the mapping process stem from the idiosyncratic source encoding schemes adopted by different health systems and the lack of large publicly available training data. In this study, we aim to develop a scalable and generalizable machine learning tool to facilitate standardizing laboratory observations to the Logical Observation Identifiers Names and Codes (LOINC). Specifically, we leverage the contextual embedding from pre-Trained T5 models and propose a two-stage fine-Tuning strategy based on contrastive learning to enable learning in a few-shot setting without manual feature engineering. Our method utilizes unlabeled general LOINC ontology and data augmentation to achieve high accuracy on retrieving the most relevant LOINC targets when limited amount of labeled data are available. We further show that our model generalizes well to unseen targets. Taken together, our approach shows great potential to reduce manual effort in LOINC standardization and can be easily extended to mapping other terminologies.  © 2022 P.N. Argaw, E. Healey & I.S. Kohane.},
	author_keywords = {Contrastive Learning; Data Standardization; Large Language Model; LOINC; Medical Entity Linking; Sentence Embedding; T5},
	keywords = {Computational linguistics; Mapping; Natural language processing systems; Standardization; Terminology; Code standardizations; Contrastive learning; Data standardization; Embeddings; Language model; Large language model; Logical observation identifiers names and codes; Medical entity linking; Sentence embedding; T5; Embeddings},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@CONFERENCE{Huang2023471,
	author = {Huang, Qing and Wan, Zhenyu and Xing, Zhenchang and Wang, Changjing and Chen, Jieshan and Xu, Xiwei and Lu, Qinghua},
	title = {Let's Chat to Find the APIs: Connecting Human, LLM and Knowledge Graph through AI Chain},
	year = {2023},
	journal = {Proceedings - 2023 38th IEEE/ACM International Conference on Automated Software Engineering, ASE 2023},
	pages = {471 – 483},
	doi = {10.1109/ASE56229.2023.00075},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179009379&doi=10.1109%2fASE56229.2023.00075&partnerID=40&md5=35cece058bfbbaa7bde6961be86dd4e3},
	abstract = {API recommendation methods have evolved from literal and semantic keyword matching to query expansion and query clarification. The latest query clarification method is knowledge graph (KG)-based, but limitations include out-of-vocabulary (OOV) failures and rigid question templates. To address these limitations, we propose a novel knowledge-guided query clarification approach for API recommendation that leverages a large language model (LLM) guided by KG. We utilize the LLM as a neural knowledge base to overcome OOV failures, generating fluent and appropriate clarification questions and options. We also leverage the structured API knowledge and entity relationships stored in the KG to filter out noise, and transfer the optimal clarification path from KG to the LLM, increasing the efficiency of the clarification process. Our approach is designed as an AI chain that consists of five steps, each handled by a separate LLM call, to improve accuracy, efficiency, and fluency for query clarification in API recommendation. We verify the usefulness of each unit in our AI chain, which all received high scores close to a perfect 5. When compared to the baselines, our approach shows a significant improvement in MRR, with a maximum increase of 63.9% higher when the query statement is covered in KG and 37.2% when it is not. Ablation experiments reveal that the guidance of knowledge in the KG and the knowledge-guided pathfinding strategy are crucial for our approach's performance, resulting in a 19.0% and 22.2% increase in MAP, respectively. Our approach demonstrates a way to bridge the gap between KG and LLM, effectively compensating for the strengths and weaknesses of both.  © 2023 IEEE.},
	author_keywords = {API recommendation; knowledge graph; large language model; out-of-vocabulary; query clarification},
	keywords = {Air navigation; Clarifiers; Computational linguistics; Knowledge graph; Knowledge management; Semantics; API recommendation; Key word matching; Knowledge graphs; Language model; Large language model; Literals; Out-of-vocabulary; Query clarification; Query expansion; Recommendation methods; Efficiency},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Green Open Access}
}

@CONFERENCE{Sewak2023,
	author = {Sewak, Mohit and Emani, Vamsi and Naresh, Annam},
	title = {CRUSH: Cybersecurity Research using Universal LLMs and Semantic Hypernetworks},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3532},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177576385&partnerID=40&md5=04f2785cc3dcf4e0b6b5f0334048b0fa},
	abstract = {Enterprise Knowledge Graphs (EKG) are powerful tools for representing and reasoning about complex and dynamic domains, such as cyber threat intelligence. However, designing and constructing such graphs can be challenging, especially when dealing with heterogeneous and noisy data sources. This paper presents our novel approach to using Large Language Models (LLM) for EKG design and development based on our experience building a Threat Intelligence Graph (TIG) using GPT3.5/ GPT4/ ChatGPT. We show how LLMs can automatically extract, infer, validate, and summarize information from various sources, such as threat reports, literature, scripts, etc., and populate the EKG with relevant entities, relationships, and properties. We also demonstrate how LLMs can identify malicious intents in any script file and map it to the TIG to detect any malicious techniques linked to the script. We demonstrate that an LLM-EKG-based approach could deliver up to 99% recall on the task of detection of malicious scripts and a consistent 90%+ recall on the task of detection of specific threat types across all script-based cybersecurity threats. © 2023 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).},
	author_keywords = {Endpoint Protection; Enterprise Knowledge Graph; GPT; Large Language Models; Threat Hunting},
	keywords = {Computational linguistics; Cybersecurity; Electrocardiography; Natural language processing systems; Semantics; Complex domains; Cyber security; Endpoint protection; Enterprise knowledge graph; GPT; Hypernetwork; Knowledge graphs; Language model; Large language model; Threat hunting; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Soriano2023138,
	author = {Soriano, Mario and Berlanga, Rafael and Lanza-Cruz, Indira},
	title = {On the Problem of Automatically Aligning Indicators to SDGs},
	year = {2023},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {13998 LNCS},
	pages = {138 – 142},
	doi = {10.1007/978-3-031-43458-7_26},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175944113&doi=10.1007%2f978-3-031-43458-7_26&partnerID=40&md5=4b7f19d3d82b60e5d869ad34465efe4d},
	abstract = {In this paper we present a first approach to the application of transformer-based language models to the automatic alignment to sustainable development goals (SDGs). This task is quite relevant for the development of new tools that aim at measuring the engagement degree of the organization’s indicators to the SGDs. Our first experiments show that this task is hard, and that even powerful large language models do not achieve a high accuracy as in other NLP tasks. © The Author(s), under exclusive license to Springer Nature Switzerland AG. 2023.},
	author_keywords = {Indicators; Knowledge Graphs; Transformers},
	keywords = {Knowledge graph; Automatic alignment; High-accuracy; Knowledge graphs; Language model; Transformer; Computational linguistics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Wu202318,
	author = {Wu, Yinan and Wu, Xiaowei and Li, Junwen and Zhang, Yue and Wang, Haofen and Du, Wen and He, Zhidong and Liu, Jingping and Ruan, Tong},
	title = {MMpedia: A Large-Scale Multi-modal Knowledge Graph},
	year = {2023},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14266 LNCS},
	pages = {18 – 37},
	doi = {10.1007/978-3-031-47243-5_2},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177439074&doi=10.1007%2f978-3-031-47243-5_2&partnerID=40&md5=d97d33de6b765a990acb315b64c495f3},
	abstract = {Knowledge graphs serve as crucial resources for various applications. However, most existing knowledge graphs present symbolic knowledge in the form of natural language, lacking other modal information, e.g., images. Previous multi-modal knowledge graphs have encountered challenges with scaling and image quality. Therefore, this paper proposes a highly-scalable and high-quality multi-modal knowledge graph using a novel pipeline method. Summarily, we first retrieve images from a search engine and build a new Recurrent Gate Multi-modal model to filter out the non-visual entities. Then, we utilize entities’ textual and type information to remove noisy images of the remaining entities. Through this method, we construct a large-scale multi-modal knowledge graph named MMpedia, containing 2,661,941 entity nodes and 19,489,074 images. As we know, MMpedia has the largest collection of images among existing multi-modal knowledge graphs. Furthermore, we employ human evaluation and downstream tasks to verify the usefulness of images in MMpedia. The experimental result shows that both the state-of-the-art method and multi-modal large language model (e.g., VisualChatGPT) achieve about a 4% improvement on Hit@1 in the entity prediction task by incorporating our collected images. We also find that the multi-modal large language model is hard to ground entities to images. The dataset (https://zenodo.org/record/7816711 ) and source code of this paper are available at https://github.com/Delicate2000/MMpedia. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2023.},
	author_keywords = {Entity grounding; Knowledge graph; Multi-modal},
	keywords = {Computational linguistics; Graphic methods; HTTP; Image enhancement; Natural language processing systems; Search engines; Entity grounding; High quality; Knowledge graphs; Language model; Large-scales; Multi-modal; Natural languages; Pipeline methods; Scalings; Symbolic knowledge; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 10}
}

@CONFERENCE{Axelsson202320,
	author = {Axelsson, Agnes and Skantze, Gabriel},
	title = {Using Large Language Models for Zero-Shot Natural Language Generation from Knowledge Graphs},
	year = {2023},
	journal = {Proceedings of the Workshop on Multimodal, Multilingual Natural Language Generation and Multilingual WebNLG Challenge, MM-NLG 2023},
	pages = {20 – 27},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175688234&partnerID=40&md5=37361e3fb8b3742b856f2f071d7c6c5d},
	abstract = {In any system that uses structured knowledge graph (KG) data as its underlying knowledge representation, KG-to-text generation is a useful tool for turning parts of the graph data into text that can be understood by humans. Recent work has shown that models that make use of pretraining on large amounts of text data can perform well on the KG-to-text task, even with relatively little training data on the specific graph-to-text task. In this paper, we build on this concept by using large language models to perform zero-shot generation based on nothing but the model’s understanding of the triple structure from what it can read. We show that ChatGPT achieves near state-of-the-art performance on some measures of the WebNLG 2020 challenge, but falls behind on others. Additionally, we compare factual, counter-factual and fictional statements, and show that there is a significant connection between what the LLM already knows about the data it is parsing and the quality of the output text. © 2023 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Natural language processing systems; Zero-shot learning; Graph data; Knowledge graphs; Knowledge-representation; Language model; Large amounts; Natural language generation; Pre-training; Structured knowledge; Text generations; Turning parts; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7}
}

@CONFERENCE{2023,
	title = {AAAI-MAKE 2023 - Proceedings of the AAAI 2023 Spring Symposium on Challenges Requiring the Combination of Machine Learning and Knowledge Engineering},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3433},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166525775&partnerID=40&md5=d0404ed875044b207b1de39cebd0e67d},
	abstract = {The proceedings contain 26 papers. The topics discussed include: a systematic and efficient approach to the design of modular hybrid ai systems; embedded to interpretive: a paradigm shift in knowledge discovery to represent dynamic knowledge; hybrid machine learning/knowledge base systems learning through natural language dialogue with deep learning models; robot behavior-tree-based task generation with large language models; an early warning system that combines machine learning and a rule-based approach for the prediction of cancer patients' unplanned visits; dynamic ontology matching challenge; ontology-driven enhancement of process mining with domain knowledge; towards hybrid dialog management strategies for a health coach chatbot; neuro-symbolic rule learning in real-world classification tasks; rule-based knowledge discovery via anomaly detection in tabular data; and leveraging RDF graphs, similarity metrics and network analysis for business process management.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Bruno2023,
	author = {Bruno, Alessandro and Pipitone, Arianna and Manzotti, Riccardo and Augello, Agnese and Mazzeo, Pier Luigi and Vella, Filippo and Chella, Antonio},
	title = {AIxPAC 2023 - Preface to the 1st Workshop on Artificial Intelligence for Perception and Artificial Consciousness},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3563},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178666040&partnerID=40&md5=a6689066d6d770628df0ffc62ddc4042},
	abstract = {The AIxPAC workshop aims to bring together researchers from academia and industry to discuss the latest advancements in AI for perception and consciousness. The workshop features presentations from experts on the physicalist ontology of consciousness, artificial consciousness, colour perception, and computer vision. Some research questions are addressed in AIxPAC: Can a visual perception system be embedded into machines? How accurately does AI tackle visual attention processes? What is the relation between attention and consciousness? Can AI architectures and approaches be used to design Artificial Consciousness? What are the pros and cons of Large Language Models? The given research questions foster multidisciplinary contributions and several critical readings for the given topics. © 2023 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).},
	keywords = {Behavioral research; Color vision; Artificial consciousness; Color computers; Colour perception; Language model; Ontology's; Perception systems; Research questions; Visual Attention; Visual perception; Artificial intelligence},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{2023,
	title = {21st International Conference on Service-Oriented Computing, ICSOC 2023},
	year = {2023},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14420 LNCS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178559266&partnerID=40&md5=abb2643e7d3ed38a41dfb2d39b560c46},
	abstract = {The proceedings contain 48 papers. The special focus in this conference is on Service-Oriented Computing. The topics include: IDLGen: Automated Code Generation for Inter-parameter Dependencies in Web APIs; time-Aware Log Anomaly Detection Based on Growing Self-organizing Map; an Empirical Evaluation of the Energy and Performance Overhead of Monitoring Tools on Docker-Based Systems; chainsFormer: A Chain Latency-Aware Resource Provisioning Approach for Microservices Cluster; energy-Efficient and Communication-Aware Resource Allocation in Container-Based Cloud with Group Genetic Algorithm; engineering Self-adaptive Microservice Applications: An Experience Report; FUSE: Fault Diagnosis and Suppression with eBPF for Microservices; serviceSim: A Modelling and Simulation Toolkit of Microservice Systems in Cloud-Edge Environment; 2DPChain: Orchestrating Transactions in Order-Execute Blockchain to Exploit Intra-batch and Inter-batch Parallelism; deep Learning Model for Personalized Web Service Recommendations Using Attention Mechanism; a Dynamical Model for the Nonlinear Features of Value-Driven Service Ecosystem Evolution; a Middleware for Hybrid Blockchain Applications: Towards Fast, Affordable, and Accountable Integration; An AI Chatbot for Explaining Deep Reinforcement Learning Decisions of Service-Oriented Systems; BEAR: Revolutionizing Service Domain Knowledge Graph Construction with LLM; dependency-Aware Resource Allocation for Serverless Functions at the Edge; distributing Quantum Computations, by Shots; energy-Efficient Task Offloading with Statistic QoS Constraint Through Multi-level Sleep Mode in Ultra-Dense Network; enhancing Blockchain Performance via On-chain and Off-chain Collaboration; deep Reinforcement Learning-Based Scheduling for Same Day Delivery with a Dynamic Number of Drones; designing Reconfigurable Intelligent Systems with Markov Blankets; exploiting Category Information in Sequential Recommendation; Niagara: Scheduling DNN Inference Services on Heterogeneous Edge Processors; plan, Generate and Match: Scientific Workflow Recommendation with Large Language Models; predicting Effect and Cost of Microservice System Evolution Using Graph Neural Network; qoS Prediction via Multi-scale Feature Fusion Based on Convolutional Neural Network.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Cadeddu2023,
	author = {Cadeddu, Andrea and Chessa, Alessandro and De Leo, Vincenzo and Fenu, Gianni and Motta, Enrico and Osborne, Francesco and Recupero, Diego Reforgiato and Salatino, Angelo and Secchi, Luca},
	title = {Enhancing Scholarly Understanding: A Comparison of Knowledge Injection Strategies in Large Language Models},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3559},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178584892&partnerID=40&md5=1a1e9863020e62bdd181f45745a1b8ee},
	abstract = {The use of transformer-based models like BERT for natural language processing has achieved remarkable performance across multiple domains. However, these models face challenges when dealing with very specialized domains, such as scientific literature. In this paper, we conduct a comprehensive analysis of knowledge injection strategies for transformers in the scientific domain, evaluating four distinct methods for injecting external knowledge into transformers. We assess these strategies in a single-label multi-class classification task involving scientific papers. For this, we develop a public benchmark based on 12k scientific papers from the AIDA knowledge graph, categorized into three fields. We utilize the Computer Science Ontology as our external knowledge source. Our findings indicate that most proposed knowledge injection techniques outperform the BERT baseline. © 2022 Copyright for this paper by its authors.},
	author_keywords = {BERT; Classification Tasks; Feature Engineering; Knowledge Graphs; Natural Language Processing},
	keywords = {Classification (of information); Computational linguistics; Natural language processing systems; BERT; Classification tasks; External knowledge; Feature engineerings; Knowledge graphs; Language model; Language processing; Natural language processing; Natural languages; Scientific papers; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Quevedo20231,
	author = {Quevedo, Ernesto and Cerny, Tomas and Rodriguez, Alejandro and Rivas, Pablo and Yero, Jorge and Sooksatra, Korn and Zhakubayev, Alibek and Taibi, Davide},
	title = {Legal Natural Language Processing from 2015-2022: A Comprehensive Systematic Mapping Study of Advances and Applications},
	year = {2023},
	journal = {IEEE Access},
	pages = {1–1},
	doi = {10.1109/ACCESS.2023.3333946},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178053115&doi=10.1109%2fACCESS.2023.3333946&partnerID=40&md5=eac0c8796015aa5f580a6b849806340f},
	abstract = {The surge in legal text production has amplified the workload for legal professionals, making many tasks repetitive and time-consuming. Furthermore, the complexity and specialized language of legal documents pose challenges not just for those in the legal domain but also for the general public. This emphasizes the potential role and impact of Legal Natural Language Processing (Legal NLP). Although advancements have been made in this domain, particularly after 2015 with the advent of Deep Learning and Large Language Models (LLMs), a systematic exploration of this progress until 2022 is nonexistent. In this research, we perform a Systematic Mapping Study (SMS) to bridge this gap.We aim to provide a descriptive statistical analysis of the Legal NLP research between 2015 and 2022. Categorize and sub-categorize primary publications based on their research problems. Identify limitations and areas of improvement in current research. Using a robust search methodology across four reputable indexers, we filtered 536 papers down to 75 pivotal articles. Our findings reveal the diverse methods employed for tasks such as Multiclass Classification, Summarization, and Question Answering in the Legal NLP field.We also highlight resources, challenges, and gaps in current methodologies and emphasize the need for curated datasets, ontologies, and a focus on inherent difficulties like data accessibility. As the legal sector gradually embraces Natural Language Processing (NLP), understanding the capabilities and limitations of Legal NLP becomes vital for ensuring efficient and ethical application. The research offers insights for both Legal NLP researchers and the broader legal community, advocating for continued advancements in automation while also addressing ethical concerns. Authors},
	author_keywords = {Deep learning; Deep Learning; Information retrieval; Law; Legal-NLP; Natural language processing; Search problems; Surveys; Systematic-Mapping-Study; Systematics; Task analysis},
	keywords = {Ethical technology; Job analysis; Mapping; Natural language processing systems; Deep learning; Language processing; Law; Legal-natural language processing; Natural language processing; Natural languages; Search problem; Systematic; Systematic mapping studies; Task analysis; Deep learning},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 4; All Open Access, Gold Open Access}
}

@CONFERENCE{2022,
	title = {AIGEL 2022 - Proceedings of Selected Papers of the Workshop on Artificial Intelligence Governance Ethics and Law},
	year = {2022},
	journal = {CEUR Workshop Proceedings},
	volume = {3531},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176948812&partnerID=40&md5=08deeeb8fce1c346522d2ededac100a4},
	abstract = {The proceedings contain 15 papers. The topics discussed include: supporting the combating of financing of weapons of mass destruction with AI technologies; generative AI and the rule of law; big techs and antitrust: lessons from a transatlantic comparison; how does a data code become taxable? a brief view from a Spanish law perspective; towards a European law on cooperative, connected and automated mobility (CCAM); privacy compliance with ontologies and blockchain: the OntoROPA Project; old ghosts in the age of ai: the foundations of liberal democracy and its identity crisis; the double-effect principle: from Thomas Aquinas to its current meaning; the use of agent-based simulation of public policy design to study the value alignment problem; and AML/CFT/CPF endeavors in the crypto-space: from blockchain analytics to machine learning.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Rodrigues2023249,
	author = {Rodrigues, Fabrício H. and Lopes, Alcides G. and dos Santos, Nicolau O. and Garcia, Luan F. and Carbonera, Joel L. and Abel, Mara},
	title = {On the Use of ChatGPT for Classifying Domain Terms According to Upper Ontologies},
	year = {2023},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14319 LNCS},
	pages = {249 – 258},
	doi = {10.1007/978-3-031-47112-4_24},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177226095&doi=10.1007%2f978-3-031-47112-4_24&partnerID=40&md5=aa7f5187c57fcc40fbd5f45713fde28b},
	abstract = {In this paper, we report an experiment to investigate the performance of ChatGPT in the task of classifying domain terms according to the categories of upper-level ontologies. The experiment consisted of (1) starting a conversation in ChatGPT with a contextual prompt listing the categories of an upper-level ontology along with their definitions, (2) submitting a follow-up prompt with a list of terms from a domain along with informal definitions, (3) asking ChatGPT to classify the terms according to the categories of the chosen upper-level ontology and explain its decision, and (4) comparing the answers of ChatGPT with the classification proposed by experts in the chosen ontology. Given the results, we evaluated the success rate of ChatGPT in performing the task and analyzed the cases of misclassification to understand the possible reasons underlying them. Based on that, we made some considerations about the extent to which we can employ ChatGPT as an assistant tool for the task of classifying domain terms into upper-level ontologies. For our experiment, we selected a set of 19 terms from the manufacturing domain that were gathered by the Industrial Ontologies Foundry (IOF) and for which there are informal textual definitions reflecting a community view of them. Also, as a baseline for comparison, we resorted to publicly available classifications of such terms according to DOLCE and BFO upper-level ontologies, which resulted from a thorough ontological analysis of those terms and informal definitions by experts in each of the ontologies. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {BFO; ChatGPT; DOLCE; Industrial Ontologies Foundry; IOF; Large Language Models; LLMs; Manufacturing; Ontologies; Term Classification},
	keywords = {Foundries; BFO; ChatGPT; DOLCE; Industrial ontology foundry; Language model; Large language model; LLM; Manufacturing; Ontology's; Term classification; Ontology},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@ARTICLE{2023,
	title = {22nd International Semantic Web Conference, ISWC 2023},
	year = {2023},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14265 LNCS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177195187&partnerID=40&md5=8b40c4b8d53d8783594689275fc7e0ed},
	abstract = {The proceedings contain 58 papers. The special focus in this conference is on Semantic Web. The topics include: How is Your Knowledge Graph Used: Content-Centric Analysis of SPARQL Query Logs; iterative Geographic Entity Alignment with Cross-Attention; entity-Relation Distribution-Aware Negative Sampling for Knowledge Graph Embedding; negative Sampling with Adaptive Denoising Mixup for Knowledge Graph Embedding; comparison of Knowledge Graph Representations for Consumer Scenarios; a Comprehensive Study on Knowledge Graph Embedding over Relational Patterns Based on Rule Learning; Compact Encoding of Reified Triples Using HDTr; causal Inference-Based Debiasing Framework for Knowledge Graph Completion; Can ChatGPT Replace Traditional KBQA Models? An In-Depth Analysis of the Question Answering Performance of the GPT LLM Family; Dense Re-Ranking with Weak Supervision for RDF Dataset Search; mapping and Cleaning Open Commonsense Knowledge Bases with Generative Translation; integrating Knowledge Graph Embeddings and Pre-trained Language Models in Hypercomplex Spaces; LLMs4OL: Large Language Models for Ontology Learning; biomedical Knowledge Graph Embeddings with Negative Statements; knowledge Graph Enhanced Language Models for Sentiment Analysis; TemporalFC: A Temporal Fact Checking Approach over Knowledge Graphs; Assessing the Generalization Capabilities of Neural Machine Translation Models for SPARQL Query Generation; linking Tabular Columns to Unseen Ontologies; neural Multi-hop Logical Query Answering with Concept-Level Answers; ForecastTKGQuestions: A Benchmark for Temporal Question Answering and Forecasting over Temporal Knowledge Graphs; Optimizing SPARQL Queries with SHACL; SORBET: A Siamese Network for Ontology Embeddings Using a Distance-Based Regression Loss and BERT; visualizing Mappings Between Pairwise Ontologies - An Empirical Study of Matrix and Linked Indented List in Their User Support During Class Mapping Creation and Evaluation; FeaBI: A Feature Selection-Based Framework for Interpreting KG Embeddings; CapsKG: Enabling Continual Knowledge Integration in Language Models for Automatic Knowledge Graph Completion; HAEE: Low-Resource Event Detection with Hierarchy-Aware Event Graph Embeddings; textual Entailment for Effective Triple Validation in Object Prediction.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Lal20221204,
	author = {Lal, Yash Kumar and Tandon, Niket and Aggarwal, Tanvi and Liu, Horace and Chambers, Nathanael and Mooney, Raymond and Balasubramanian, Niranjan},
	title = {Using Commonsense Knowledge to Answer Why-Questions},
	year = {2022},
	journal = {Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, EMNLP 2022},
	pages = {1204 – 1219},
	doi = {10.18653/v1/2022.emnlp-main.79},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149443386&doi=10.18653%2fv1%2f2022.emnlp-main.79&partnerID=40&md5=9498c299cd3d167547f5a06737bc622b},
	abstract = {Answering questions in narratives about why events happened often requires commonsense knowledge external to the text. What aspects of this knowledge are available in large language models? What aspects can be made accessible via external commonsense resources? We study these questions in the context of answering questions in the TELLMEWHY dataset using COMET as a source of relevant commonsense relations. We analyze the effects of model size (T5 variants and GPT-3) along with methods of injecting knowledge (COMET) into these models. Results show that the largest models, as expected, yield substantial improvements over base models and injecting external knowledge helps models of all sizes. We also find that the format in which knowledge is provided is critical, and that smaller models benefit more from larger amounts of knowledge. Finally, we develop an ontology of knowledge types and analyze the relative coverage of the models across these categories. © 2022 Association for Computational Linguistics.},
	keywords = {Base models; Commonsense knowledge; External knowledge; HELP model; Knowledge analysis; Language model; Large amounts; Large models; Model size; Ontology's},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 11; All Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Sen20231,
	author = {Sen, Priyanka and Mavadia, Sandeep and Saffari, Amir},
	title = {Knowledge Graph-augmented Language Models for Complex Question Answering},
	year = {2023},
	journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
	pages = {1 – 8},
	doi = {10.18653/v1/2023.nlrse-1.1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173903295&doi=10.18653%2fv1%2f2023.nlrse-1.1&partnerID=40&md5=eac5bedd4ddffbd57d02025956c7ab76},
	abstract = {Large language models have shown impressive abilities to reason over input text, however, they are prone to hallucinations. On the other hand, end-to-end knowledge graph question answering (KGQA) models output responses grounded in facts, but they still struggle with complex reasoning, such as comparison or ordinal questions. In this paper, we propose a new method for complex question answering where we combine a knowledge graph retriever based on an end-to-end KGQA model with a language model that reasons over the retrieved facts to return an answer. We observe that augmenting language model prompts with retrieved KG facts improves performance over using a language model alone by an average of 83%. In particular, we see improvements on complex questions requiring count, intersection, or multi-hop reasoning operations.  © 2023 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Complex questions; End to end; Improve performance; Knowledge graphs; Language model; Model outputs; Multi-hops; Output response; Question Answering; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 11; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Hu2023,
	author = {Hu, Zhiqiang and Li, Xinyu and Pan, Xinyu and Wen, Sijie and Bao, Jinsong},
	title = {A question answering system for assembly process of wind turbines based on multi-modal knowledge graph and large language model},
	year = {2023},
	journal = {Journal of Engineering Design},
	doi = {10.1080/09544828.2023.2272555},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174585056&doi=10.1080%2f09544828.2023.2272555&partnerID=40&md5=d34e7e9c0bab9ed1408dd5749390ccb0},
	abstract = {In the field of wind power generation, wind turbines serve as the foundation for harnessing electrical energy. However, the assembly process information for wind turbines is typically dispersed among various modalities such as 3D models, natural text, and images in the form of process documents. The difficulty in effectively utilising historical process knowledge hampers the efficiency of assembly process design and subsequently affects production efficiency. To address this issue, this paper constructs a Multi-modal Process Knowledge Graph for Wind Turbines, named MPKG-WT. Additionally, a wind turbine assembly process question-answering system combining multi-modal knowledge graphs with large language models (LLMs) is proposed to enable efficient utilisation of historical assembly process knowledge. The proposed approach achieves outstanding results when compared with other state-of-the-art KBQA methods and recent LLMs using a wind turbine assembly process dataset. The effectiveness of the approach is further validated through a visualised assembly process question-answering system. The research findings demonstrate a significant improvement in assembly process design efficiency. © 2023 Informa UK Limited, trading as Taylor & Francis Group.},
	author_keywords = {Assembly process knowledge; Large language model; Multi-modal knowledge graph; Question answering; Wind turbines},
	keywords = {Assembly; Computational linguistics; Computer aided language translation; Knowledge graph; Power generation; Process design; Production efficiency; Wind power; Assembly process; Assembly process knowledge; Knowledge graphs; Language model; Large language model; Multi-modal; Multi-modal knowledge graph; Process knowledge; Question Answering; Question answering systems; Wind turbines},
	type = {Article},
	publication_stage = {Article in press},
	source = {Scopus},
	note = {Cited by: 12}
}

@CONFERENCE{Korini2023,
	author = {Korini, Keti and Bizer, Christian},
	title = {Column Type Annotation using ChatGPT},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3462},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171297582&partnerID=40&md5=77a8d96d464a8cf27f9ba2bb9378a402},
	abstract = {Column type annotation is the task of annotating the columns of a relational table with the semantic type of the values contained in each column. Column type annotation is an important pre-processing step for data search and data integration in the context of data lakes. State-of-the-art column type annotation methods either rely on matching table columns to properties of a knowledge graph or fine-tune pre-trained language models such as BERT for column type annotation. In this work, we take a different approach and explore using ChatGPT for column type annotation. We evaluate different prompt designs in zero- and few-shot settings and experiment with providing task definitions and detailed instructions to the model. We further implement a two-step table annotation pipeline which first determines the class of the entities described in the table and depending on this class asks ChatGPT to annotate columns using only the relevant subset of the overall vocabulary. Using instructions as well as the two-step pipeline, ChatGPT reaches F1 scores of over 85% in zero- and one-shot setups. To reach a similar F1 score a RoBERTa model needs to be fine-tuned with 356 examples. This comparison shows that ChatGPT is able deliver competitive results for the column type annotation task given no or only a minimal amount of task-specific demonstrations. © 2023 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).},
	author_keywords = {ChatGPT; Column Type Annotation; Large Language Models; Prompt Engineering; Table Annotation},
	keywords = {Computational linguistics; Knowledge graph; Pipelines; Semantics; ChatGPT; Column type annotation; F1 scores; Language model; Large language model; Prompt engineering; Relational tables; Semantic types; Table annotation; Type annotations; Data integration},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@CONFERENCE{Baeck2023,
	author = {Baeck, Bert},
	title = {Unlocking a Digital Twin and Scalable AI Models Through Fit-For-Purpose Reliable Data},
	year = {2023},
	journal = {Society of Petroleum Engineers - ADIPEC, ADIP 2023},
	doi = {10.2118/216944-MS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176788434&doi=10.2118%2f216944-MS&partnerID=40&md5=d0cb67ab8ace35c73cac0fff2ee0eac7},
	abstract = {Digital transformation has become a strategic imperative for industrial manufacturers and asset owners, promising significant improvements in operational efficiency and profitability. According to Thierry Cartage, former Senior Vice President of Digital at SOLVAY and a renowned industry expert, the potential for digital transformation to enhance industrial operations is estimated at 2-3% improvement in EBITDA. However, unlocking this potential requires a comprehensive journey spanning 2 to 5 years, as highlighted in a joint presentation at the Connected Plant Conference in June 2023. When embarking on digital initiatives, various captivating topics emerge, such as Digital Twin, AI in production, Real-time optimizers, Predictive maintenance, industrial knowledge graphs, and the more recent addition of Generative AI. These topics generate considerable interest and enthusiasm among industry professionals, as they hold the promise of revolutionizing industrial operations and driving competitive advantages. The ability to create virtual replicas of physical assets (Digital Twins) and leverage advanced analytics and machine learning techniques (AI in production) can offer unprecedented insights and efficiencies. Real-time optimizers enable organizations to dynamically optimize operations based on real-time data, while predictive maintenance helps prevent costly equipment failures by identifying maintenance needs in advance. Industrial knowledge graphs provide a structured representation of information, allowing for effective data integration and knowledge discovery. The emerging field of Generative AI opens up possibilities for creating novel and innovative solutions by generating new content or designs based on existing data. © 2023, Society of Petroleum Engineers.},
	keywords = {Competition; Data Analytics; Data integration; Gasoline; Learning systems; Maintenance; Asset owners; Digital transformation; Fit for purpose; Industrial manufacturers; Industrial operations; Knowledge graphs; Operational efficiencies; Predictive maintenance; Real-time optimizers; Strategic imperative; Efficiency},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{Arachchige2023117,
	author = {Arachchige, Isuri Anuradha Nanomi and Ha, Le An and Mitkov, Ruslan and Nahar, Vinitar},
	title = {Evaluating Large Language Models in Relationship Extraction from Unstructured Data: Empirical Study from Holocaust Testimonies},
	year = {2023},
	journal = {International Conference Recent Advances in Natural Language Processing, RANLP},
	pages = {117 – 123},
	doi = {10.26615/978-954-452-092-2_013},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179177996&doi=10.26615%2f978-954-452-092-2_013&partnerID=40&md5=4aa71293a35772a7c5988c15a47f2c26},
	abstract = {Relationship extraction from unstructured data remains one of the most challenging tasks in the field of Natural Language Processing (NLP). The complexity of relationship extraction arises from the need to comprehend the underlying semantics, syntactic structures, and contextual dependencies within the text. Unstructured data poses challenges with diverse linguistic patterns, implicit relationships, contextual nuances, complicating accurate relationship identification and extraction. The emergence of Large Language Models (LLMs), such as GPT (Generative Pre-trained Transformer), has indeed marked a significant advancement in the field of NLP.In this work, we assess and evaluate the effectiveness of LLMs in relationship extraction in the Holocaust testimonies within the context of the Historical realm. By delving into this domainspecific context, we aim to gain deeper insights into the performance and capabilities of LLMs in accurately capturing and extracting relationships within the Holocaust domain by developing a novel knowledge graph to visualise the relationships of the Holocaust. To the best of our knowledge, there is no existing study which discusses relationship extraction in Holocaust testimonies. The majority of current approaches for Information Extraction (IE) in historic documents are either manual or Optical Character Recognition (OCR) based. Moreover, in this study, we found that the Subject-Object-Verb extraction using GPT3-based relations produced more meaningful results compared to the Semantic Role labelingbased triple extraction. © 2023 Incoma Ltd. All rights reserved.},
	keywords = {Computational linguistics; Data mining; Natural language processing systems; Optical character recognition; Syntactics; Domain specific; Empirical studies; Implicit relationships; Language model; Language processing; Linguistic patterns; Natural languages; Relationship extraction; Syntactic structure; Unstructured data; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0; All Open Access, Bronze Open Access}
}

@CONFERENCE{Khorashadizadeh2023132,
	author = {Khorashadizadeh, Hanieh and Mihindukulasooriya, Nandana and Tiwari, Sanju and Groppe, Jinghua and Groppe, Sven},
	title = {Exploring In-Context Learning Capabilities of Foundation Models for Generating Knowledge Graphs from Text},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3447},
	pages = {132 – 153},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85168818600&partnerID=40&md5=f1d79f7173a4f5005baba416c9acc899},
	abstract = {Knowledge graphs can represent information about the real-world using entities and their relations in a structured and semantically rich manner and they enable a variety of downstream applications such as question-answering, recommendation systems, semantic search, and advanced analytics. However, at the moment, building a knowledge graph involves a lot of manual effort and thus hinders their application in some situations and the automation of this process might benefit especially for small organizations. Automatically generating structured knowledge graphs from a large volume of natural language is still a challenging task and the research on sub-tasks such as named entity extraction, relation extraction, entity and relation linking, and knowledge graph construction aims to improve the state of the art of automatic construction and completion of knowledge graphs from text. The recent advancement of foundation models with billions of parameters trained in a self-supervised manner with large volumes of training data that can be adapted to a variety of downstream tasks has helped to demonstrate high performance on a large range of Natural Language Processing (NLP) tasks. In this context, one emerging paradigm is in-context learning where a language model is used as it is with a prompt that provides instructions and some examples to perform a task without changing the parameters of the model using traditional approaches such as fine-tuning. This way, no computing resources are needed for re-training/fine-tuning the models and the engineering effort is minimal. Thus, it would be beneficial to utilize such capabilities for generating knowledge graphs from text. In this paper, grounded by several research questions, we explore the capabilities of foundation models such as ChatGPT to generate knowledge graphs from the knowledge it captured during pre-training as well as the new text provided to it in the prompt. The paper provides a qualitative analysis of a set of example outputs generated by a foundation model with the aim of knowledge graph construction and completion. The results demonstrate promising capabilities. Furthermore, we discuss the challenges and next steps for this research work. © 2023 CEUR-WS. All rights reserved.},
	author_keywords = {Foundation Models; In-Context Learning; Knowledge Graph Completion; Knowledge Graph Construction; Large Language Models; Ontology; Relation Extraction},
	keywords = {Computational linguistics; Data mining; Engineering education; Extraction; Foundations; Graphic methods; Learning systems; Natural language processing systems; Semantics; Context learning; Foundation models; Graph construction; In contexts; In-context learning; Knowledge graph completion; Knowledge graph construction; Knowledge graphs; Language model; Large language model; Ontology's; Relation extraction; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5}
}

@ARTICLE{2023,
	title = {22nd International Semantic Web Conference, ISWC 2023},
	year = {2023},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14266 LNCS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177448280&partnerID=40&md5=5a6a808bf67cfb68607e7e3cb9533d1f},
	abstract = {The proceedings contain 58 papers. The special focus in this conference is on Semantic Web. The topics include: How is Your Knowledge Graph Used: Content-Centric Analysis of SPARQL Query Logs; iterative Geographic Entity Alignment with Cross-Attention; entity-Relation Distribution-Aware Negative Sampling for Knowledge Graph Embedding; negative Sampling with Adaptive Denoising Mixup for Knowledge Graph Embedding; comparison of Knowledge Graph Representations for Consumer Scenarios; a Comprehensive Study on Knowledge Graph Embedding over Relational Patterns Based on Rule Learning; Compact Encoding of Reified Triples Using HDTr; causal Inference-Based Debiasing Framework for Knowledge Graph Completion; Can ChatGPT Replace Traditional KBQA Models? An In-Depth Analysis of the Question Answering Performance of the GPT LLM Family; Dense Re-Ranking with Weak Supervision for RDF Dataset Search; mapping and Cleaning Open Commonsense Knowledge Bases with Generative Translation; integrating Knowledge Graph Embeddings and Pre-trained Language Models in Hypercomplex Spaces; LLMs4OL: Large Language Models for Ontology Learning; biomedical Knowledge Graph Embeddings with Negative Statements; knowledge Graph Enhanced Language Models for Sentiment Analysis; TemporalFC: A Temporal Fact Checking Approach over Knowledge Graphs; Assessing the Generalization Capabilities of Neural Machine Translation Models for SPARQL Query Generation; linking Tabular Columns to Unseen Ontologies; neural Multi-hop Logical Query Answering with Concept-Level Answers; ForecastTKGQuestions: A Benchmark for Temporal Question Answering and Forecasting over Temporal Knowledge Graphs; Optimizing SPARQL Queries with SHACL; SORBET: A Siamese Network for Ontology Embeddings Using a Distance-Based Regression Loss and BERT; visualizing Mappings Between Pairwise Ontologies - An Empirical Study of Matrix and Linked Indented List in Their User Support During Class Mapping Creation and Evaluation; FeaBI: A Feature Selection-Based Framework for Interpreting KG Embeddings; CapsKG: Enabling Continual Knowledge Integration in Language Models for Automatic Knowledge Graph Completion; HAEE: Low-Resource Event Detection with Hierarchy-Aware Event Graph Embeddings; textual Entailment for Effective Triple Validation in Object Prediction.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Lippolis2023,
	author = {Lippolis, Anna Sofia and Klironomos, Antonis and Milon-Flores, Daniela F. and Zheng, Heng and Jouglar, Alexane and Norouzi, Ebrahim and Hogan, Aidan},
	title = {Enhancing Entity Alignment Between Wikidata and ArtGraph Using LLMs},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3540},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178311919&partnerID=40&md5=ba7501ef8c69f4154305acfc78c3f637},
	abstract = {Knowledge graphs (KGs) are used in a wide variety of applications, including within the cultural heritage domain. An important prerequisite of such applications is the quality and completeness of the data. Using a single KG might not be enough to fulfill this requirement. The absence of connections between KGs complicates taking advantage of the complementary data they can provide. This paper focuses on the Wikidata and A rtG raph KGs, which exhibit gaps in content that can be filled by enriching one with data from the other. Entity alignment can help to combine data from KGs by connecting entities that refer to the same real-world entities. However, entity alignment in art-domain knowledge graphs remains under-explored. In the pursuit of entity alignment between A rtG raph and Wikidata, a hybrid approach is proposed. The first part, which we call WES (Wikidata Entity Search), utilizes traditional Wikidata SPARQL queries and is followed by a supplementary sequence-to-sequence large language model (LLM) pipeline that we denote as pArtLink. The combined approach successfully aligned artworks and artists, with WES identifying entities for 14,982 artworks and 2,029 artists, and pArtLink further aligning 76 additional artists, thus enhancing the alignment process beyond WES’ capabilities. © 2023 Copyright for this paper by its authors.},
	author_keywords = {ArtGraph; Entity alignment; Knowledge-graphs; Large Language Models; Wikidata},
	keywords = {Alignment; Computational linguistics; Artgraph; Complementary data; Cultural heritages; Entity alignment; Entity search; Knowledge graphs; Language model; Large language model; Real-world entities; Wikidata; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{2023,
	title = {DL4KG 2023 - Proceedings of the Workshop on Deep Learning for Knowledge Graphs, co-located with the 21st International Semantic Web Conference, ISWC 2023},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3559},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178567783&partnerID=40&md5=cf576de4a3e849674401ee051f8c2cea},
	abstract = {The proceedings contain 7 papers. The topics discussed include: location query answering using box embeddings; knowledge graph injection for reinforcement learning; benchmarking the abilities of large language models for RDF knowledge graph creation and comprehension: how well do LLMs speak turtle?; enhancing large language models with knowledge graphs for classification tasks in the tourism domain; universal preprocessing operators for embedding knowledge graphs with literals; NNKGC: improving knowledge graph completion with node neighborhoods; and enhancing scholarly understanding: a comparison of knowledge injection strategies in large language models.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Mahapatra2022942,
	author = {Mahapatra, Aniruddha and Nangi, Sharmila Reddy and Garimella, Aparna and Natarajan, Anandhavelu},
	title = {Entity Extraction in Low Resource Domains with Selective Pre-training of Large Language Models},
	year = {2022},
	journal = {Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing, EMNLP 2022},
	pages = {942 – 951},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149442616&partnerID=40&md5=690f4e26b7187247e184c0f230cfc78a},
	abstract = {Transformer-based language models trained on large natural language corpora have been very useful in downstream entity extraction tasks. However, they often result in poor performances when applied to domains that are different from those they are pretrained on. Continued pretraining using unlabeled data from target domains can help improve the performances of these language models on the downstream tasks. However, using all of the available unlabeled data for pretraining can be time-intensive; also, it can be detrimental to the performance of the downstream tasks, if the unlabeled data is not aligned with the data distribution for the target tasks. Previous works employed external supervision in the form of ontologies for selecting appropriate data samples for pretraining, but external supervision can be quite hard to obtain in low-resource domains. In this paper, we introduce effective ways to select data from unlabeled corpora of target domains for language model pretraining to improve the performances in target entity extraction tasks. Our data selection strategies do not require any external supervision. We conduct extensive experiments for the task of named entity recognition (NER) on seven different domains and show that language models pretrained on target domain unlabeled data obtained using our data selection strategies achieve better performances compared to those using data selection strategies in previous works that use external supervision. We also show that these pretrained language models using our data selection strategies outperform those pretrained on all of the available unlabeled target domain data. © 2022 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Data reduction; Data selection strategies; Down-stream; Entity extractions; Language model; Natural languages; Performance; Pre-training; Resource domains; Target domain; Unlabeled data; Extraction},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@CONFERENCE{Braşoveanu2023,
	author = {Braşoveanu, Adrian M.P. and Nixon, Lyndon J.B. and Weichselbraun, Albert and Scharl, Arno},
	title = {Framing Few-Shot Knowledge Graph Completion with Large Language Models},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3510},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175627576&partnerID=40&md5=e739d2ea8c5f81b27f25e636e20d37f8},
	abstract = {Knowledge Graph Completion (KGC) from text involves identifying known or unknown entities (nodes) as well as relations (edges) among these entities. Recent work has started to explore the use of Large Language Models (LLMs) for entity detection and relation extraction, due to their Natural Language Understanding (NLU) capabilities. However, LLM performance varies across models and depends on the quality of the prompt engineering. We examine specific relation extraction cases and present a set of examples collected from well-known resources in a small corpus. We provide a set of annotations and identify various issues that occur when using different LLMs for this task. As LLMs will remain a focal point of future KGC research, we conclude with suggestions for improving the KGC process. © 2023 Copyright for this paper by its authors.},
	author_keywords = {knowledge graph completion; large language models; relation extraction; slot filling},
	keywords = {Computational linguistics; Extraction; Entity detection; Knowledge graph completion; Knowledge graphs; Language model; Large language model; Modeling performance; Natural language understanding; Relation extraction; Slot filling; Unknown entities; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{2023,
	title = {8th China Conference on Knowledge Graph and Semantic Computing, CCKS 2023},
	year = {2023},
	journal = {Communications in Computer and Information Science},
	volume = {1923 CCIS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176944442&partnerID=40&md5=31c7f557ca86da031421f9b1bdf59b96},
	abstract = {The proceedings contain 28 papers. The special focus in this conference is on Knowledge Graph and Semantic Computing. The topics include: A Generalized Strategy of Chinese Grammatical Error Diagnosis Based on Task Decomposition and Transformation; conversational Search Based on Utterance-Mask-Passage Post-training; financial Fraud Detection Based on Deep Learning: Towards Large-Scale Pre-training Transformer Models; GERNS: A Graph Embedding with Repeat-Free Neighborhood Structure for Subgraph Matching Optimization; feature Enhanced Structured Reasoning for Question Answering; conditional Knowledge Graph: Design, Dataset and a Preliminary Model; ODKG: An Official Document Knowledge Graph for the Effective Management; CCD-ASQP: A Chinese Cross-Domain Aspect Sentiment Quadruple Prediction Dataset; move Structure Recognition in Scientific Papers with Saliency Attribution; causE: Towards Causal Knowledge Graph Embedding; Moral Essential Elements: MEE-A Dataset for Moral Judgement; improving Adaptive Knowledge Graph Construction via Large Language Models with Multiple Views; single Source Path-Based Graph Neural Network for Inductive Knowledge Graph Reasoning; a Graph Learning Based Method for Inductive Knowledge Graph Relation Prediction; LLM-Based SPARQL Generation with Selected Schema from Large Scale Knowledge Base; Robust NL-to-Cypher Translation for KBQA: Harnessing Large Language Model with Chain of Prompts; in-Context Learning for Knowledge Base Question Answering for Unmanned Systems Based on Large Language Models; a Military Domain Knowledge-Based Question Answering Method Based on Large Language Model Enhancement; Advanced PromptCBLUE Performance: A Novel Approach Leveraging Large Language Models; exploring the Logical Expressiveness of Graph Neural Networks by Establishing a Connection with C2 ; research on Joint Representation Learning Methods for Entity Neighborhood Information and Description Information; harvesting Event Schemas from Large Language Models; NTDA: Noise-Tolerant Data Augmentation for Document-Level Event Argument Extraction; Event-Centric Opinion Mining via In-Context Learning with ChatGPT; relation Repository Based Adaptive Clustering for Open Relation Extraction.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Buzzega2023160,
	author = {Buzzega, Giovanni and Guidetti, Veronica and Mandreoli, Federica and Mariotti, Luca and Belli, Andrea and Lombardi, Paolo},
	title = {Automated Knowledge Graph Completion for Natural Language Understanding: Known Paths and Future Directions},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3478},
	pages = {160 – 172},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173509733&partnerID=40&md5=2b085f795bbb88f3729d47198268ee32},
	abstract = {Knowledge Graphs (KGs) are large collections of structured data that can model real world knowledge and are important assets for the companies that employ them. KGs are usually constructed iteratively and often show a sparse structure. Also, as knowledge evolves, KGs must be updated and completed. Many automatic methods for KG Completion (KGC) have been proposed in the literature to reduce the costs associated with manual maintenance. Motivated by an industrial case study aiming to enrich a KG specifically designed for Natural Language Understanding tasks, this paper presents an overview of classical and modern deep learning completion methods. In particular, we delve into Large Language Models (LLMs), which are the most promising deep learning architectures. We show that their applications to KGC are affected by several shortcomings, namely they neglect the structure of KG and treat KGC as a classification problem. Such limitations, together with the brittleness of the LLMs themselves, stress the need to create KGC solutions at the interface between symbolic and neural approaches and lead to the way ahead for future research in intelligible corpus-based KGC. © 2023 CEUR-WS. All rights reserved.},
	author_keywords = {Knowledge Graph Completion; Knowledge Graphs; Large Language Models; Natural Language Understanding},
	keywords = {Computational linguistics; Deep learning; Fracture mechanics; Graph theory; Iterative methods; Knowledge management; Learning systems; Natural language processing systems; Automatic method; Knowledge graph completion; Knowledge graphs; Language model; Large language model; Natural language understanding; Real-world; Structured data; World knowledge; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Vassiliou2023164,
	author = {Vassiliou, Giannis and Papadakis, Nikolaos and Kondylakis, Haridimos},
	title = {SummaryGPT: Leveraging ChatGPT for Summarizing Knowledge Graphs},
	year = {2023},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {13998 LNCS},
	pages = {164 – 168},
	doi = {10.1007/978-3-031-43458-7_31},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175997700&doi=10.1007%2f978-3-031-43458-7_31&partnerID=40&md5=0dd3611044743600aafc155f822f2eca},
	abstract = {Semantic summaries try to extract compact information from the original knowledge graph (KG) while reducing its size for various purposes such as query answering, indexing, or visualization. Although so far several techniques have been exploited for summarizing individual KGs, to the best of our knowledge, there is no approach summarizing the interests of the users in exploring those KGs, capturing also how these evolve. SummaryGPT fills this gap by enabling the exploration of users’ interests as captured from their queries over time. For generating these summaries we first extract the nodes appearing in query logs, captured from a specific time period, and then we classify them into different categories in order to generate quotient summaries on top. For the classification, we explore both the KG type hierarchy (if existing) and also a large language model, i.e. ChatGPT. Exploring different time periods enables us to identify shifts in user interests and capture their evolution through time. In this demonstration we use WikiData KG in order to enable active exploration of the corresponding user interests, allowing end-users to visualize how these evolve over time. © The Author(s), under exclusive license to Springer Nature Switzerland AG. 2023.},
	keywords = {Information retrieval; Knowledge management; Semantics; Active explorations; End-users; Knowledge graphs; Language model; Query answering; Query logs; Specific time; Time-periods; Type hierarchies; Users' interests; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@ARTICLE{Gosselin2023561,
	author = {Gosselin, Francis and Zouaq, Amal},
	title = {SORBET: A Siamese Network for Ontology Embeddings Using a Distance-Based Regression Loss and BERT},
	year = {2023},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14265 LNCS},
	pages = {561 – 578},
	doi = {10.1007/978-3-031-47240-4_30},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177180876&doi=10.1007%2f978-3-031-47240-4_30&partnerID=40&md5=a80acda46843983fb7f3bf3481a9e5cb},
	abstract = {Ontology embedding methods have been popular in recent years, especially when it comes to representation learning algorithms for solving ontology-related tasks. Despite the impact of large language models on knowledge graphs’ related tasks, there has been less focus on adapting these models to construct ontology embeddings that are both semantically relevant and faithful to the ontological structure. In this paper, we present a novel ontology embedding method that encodes ontology classes into a pre-trained SBERT through random walks and then fine-tunes the embeddings using a distance-based regression loss. We benchmark our algorithm on four different datasets across two tasks and show the impact of transfer learning and our distance-based loss on the quality of the embeddings. Our results show that SORBET outperform state-of-the-art ontology embedding techniques for the performed tasks. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {BERT; Ontology; Ontology Embedding; Representation Learning; Sentence BERT; Transfer Learning},
	keywords = {Benchmarking; Knowledge graph; Ontology; BERT; Distance-based; Embedding method; Embeddings; Ontology embedding; Ontology's; Representation learning; Sentence BERT; Transfer learning; Embeddings},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6}
}

@ARTICLE{Ahmed2023124,
	author = {Ahmed, Abdullah Fathi and Firmansyah, Asep Fajar and Sherif, Mohamed Ahmed and Moussallem, Diego and Ngonga Ngomo, Axel-Cyrille},
	title = {Explainable Integration of Knowledge Graphs Using Large Language Models},
	year = {2023},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {13913 LNCS},
	pages = {124 – 139},
	doi = {10.1007/978-3-031-35320-8_9},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164721228&doi=10.1007%2f978-3-031-35320-8_9&partnerID=40&md5=d3d1c0f1395ceb90c4ce001e09fbac4a},
	abstract = {Linked knowledge graphs build the backbone of many data-driven applications such as search engines, conversational agents and e-commerce solutions. Declarative link discovery frameworks use complex link specifications to express the conditions under which a link between two resources can be deemed to exist. However, understanding such complex link specifications is a challenging task for non-expert users of link discovery frameworks. In this paper, we address this drawback by devising NMV-LS, a language model-based verbalization approach for translating complex link specifications into natural language. NMV-LS relies on the results of rule-based link specification verbalization to apply continuous training on T5, a large language model based on the Transformer architecture. We evaluated NMV-LS on English and German datasets using well-known machine translation metrics such as BLUE, METEOR, ChrF++ and TER. Our results suggest that our approach achieves a verbalization performance close to that of humans and outperforms state of the art approaches. Our source code and datasets are publicly available at https://github.com/dice-group/NMV-LS. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Explainable AI; KG Integration; Large Language Models; Machine Learning Applications; Neural Machine Verbalization; Semantic Web},
	keywords = {Computational linguistics; HTTP; Knowledge graph; Machine learning; Natural language processing systems; Neural machine translation; Search engines; Semantic Web; Discovery frameworks; Explainable AI; KG integration; Knowledge graphs; Language model; Large language model; Link Discovery; Machine learning applications; Neural machine verbalization; Semantic-Web; Specifications},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Razzaq202374148,
	author = {Razzaq, Muhammad Saad and Maqbool, Fahad and Ilyas, Muhammad and Jabeen, Hajira},
	title = {EvoRecipes: A Generative Approach for Evolving Context-Aware Recipes},
	year = {2023},
	journal = {IEEE Access},
	volume = {11},
	pages = {74148 – 74164},
	doi = {10.1109/ACCESS.2023.3296144},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165259066&doi=10.1109%2fACCESS.2023.3296144&partnerID=40&md5=366d00baef36045df0ce53ae7440be4e},
	abstract = {Generative AI e.g. Large Language Models (LLMs) can be used to generate new recipes. However, LLMs struggle with more complex aspects like recipe semantics and process comprehension. Furthermore, LLMs have limited ability to account for user preferences since they are based on statistical patterns. As a result, these recipes may be invalid. Evolutionary algorithms inspired by the process of natural selection are optimization algorithms that use stochastic operators to generate new solutions. These algorithms can generate large number of solutions from the set of possible solution space. Moreover, these algorithms have the capability to incorporate user preferences in fitness function to generate novel recipes that are more aligned with the fitness objective. In this paper, we propose the EvoRecipes framework to generate novel recipes. The EvoRecipes framework utilizes both Genetic Algorithm and generative AI in addition to RecipeOn ontology, and RecipeKG knowledge graph. Genetic Algorithm explore the large solution space of encoded recipe solutions and are capable of incorporating user preferences, while LLMs are used to generate recipe text from encoded recipe solutions. EvoRecipes uses a population of context-aware recipe solutions from the RecipeKG knowledge graph. RecipeKG encodes recipes in RDF format using classes and properties as defined in the RecipeOn ontology. Moreover, to evaluate the alignment of EvoRecipe generated recipes with multiple intended objectives, we propose a fitness function that incorporates novelty, simplicity, visual appeal, and feasibility. Additionally, to evaluate the quality of the EvoRecipe generated recipes while considering the subjective nature of recipes, we conducted a survey using multi-dimensional metrics (i.e. contextual, procedural, and novelty). Results show that EvoRecipes generated recipes are novel, valid and incorporate user preferences.  © 2013 IEEE.},
	author_keywords = {computational creativity; food; Knowledge graph; ontology; recipe; recipe evolution},
	keywords = {Food products; Function evaluation; Knowledge graph; Ontology; Quality control; Resource Description Framework (RDF); Semantics; Stochastic systems; User interfaces; Computational creativities; Creativity; Knowledge graphs; Language model; Ontology's; Recipe; Recipe evolution; Resources description frameworks; Genetic algorithms},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6; All Open Access, Gold Open Access}
}

@CONFERENCE{2023,
	title = {NeSy 2023 - Proceedings of the 17th International Workshop on Neural-Symbolic Learning and Reasoning},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3432},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85167418670&partnerID=40&md5=cb4edd11030180c6b763facb04fe7c02},
	abstract = {The proceedings contain 33 papers. The topics discussed include: a roadmap for neuro-argumentative learning; what's wrong with gradient-based complex query answering?; closing the neural-symbolic cycle: knowledge extraction, user intervention and distillation from convolutional neural networks; the challenge of learning symbolic representations; exploring mathematical conjecturing with large language models; learning logic constraints from demonstration; from axioms over graphs to vectors, and back again: evaluating the properties of graph-based ontology embeddings; neural-symbolic predicate invention: learning relational concepts from visual scenes; semantic interpretability of convolutional neural networks by taxonomy extraction; preliminary results on a state-driven method for rule construction in neural-symbolic reinforcement learning; and is the proof length a good indicator of hardness for reason-able embeddings?.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@CONFERENCE{2023,
	title = {Proceedings of the AISB Convention 2023},
	year = {2023},
	journal = {Proceedings of the AISB Convention 2023},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176314091&partnerID=40&md5=45b96d8c77e6cf260404b793a4cd50a9},
	abstract = {The proceedings contain 19 papers. The topics discussed include: a meta-semantics fit for large language models; holding large language models to account; intelligence, super-intelligence, superintelligence++, and ChatGPT: searching for substance amidst the hype; from epistemology to ethics of deep networks; my belief or Alexa’s? belief attribution and AI extension; who needs needy machine consciousness?; NLP based framework for recommending candidate ontologies for reuse; trust in cognitive models: understandability and computational Reliabilism; local minima drive communications in cooperative interaction; exploring the impact of external factors on ride-hailing demand: a predictive modelling approach; evolving time-dependent cognitive models; and switchable lightweight anti-symmetric processing (SLAP) with CNN outspeeds data augmentation by smaller sample - application in Gomoku reinforcement learning.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Jousselme2023,
	author = {Jousselme, A.-L. and De Villiers, J.P. and De Freitas, A. and Blasch, E. and Dragos, V. and Pavlin, G. and Costa, P.C. and Laskey, K.B. and Laudy, C.},
	title = {Uncertain about ChatGPT: enabling the uncertainty evaluation of large language models},
	year = {2023},
	journal = {2023 26th International Conference on Information Fusion, FUSION 2023},
	doi = {10.23919/FUSION52260.2023.10224086},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171522315&doi=10.23919%2fFUSION52260.2023.10224086&partnerID=40&md5=12ea9c6df3ce53d90e1ad93d8b658e82},
	abstract = {ChatGPT, OpenAI's chatbot, has gained consider-able attention since its launch in November 2022, owing to its ability to formulate articulated responses to text queries and comments relating to seemingly any conceivable subject. As impressive as the majority of interactions with ChatGPT are, this large language model has a number of acknowledged shortcomings, which in several cases, may be directly related to how ChatGPT handles uncertainty. The objective of this paper is to pave the way to formal analysis of ChatGPT uncertainty handling. To this end, the ability of the Uncertainty Representation and Reasoning Framework (URREF) ontology is assessed, to support such analysis. Elements of structured experiments for reproducible results are identified. The dataset built varies Information Criteria of Correctness, Non-specificity, Self-confidence, Relevance and Inconsistency, and the Source Criteria of Reliability, Competency and Type. ChatGPT's answers are analyzed along Information Criteria of Correctness, Non-specificity and Self-confidence. Both generic and singular information are sequentially provided. The outcome of this preliminary study is twofold: Firstly, we validate that the experimental setup is efficient in capturing aspects of ChatGPT uncertainty handling. Secondly, we identify possible modifications to the URREF ontology that will be discussed and eventually implemented in URREF ontology Version 4.0 under development.  © 2023 International Society of Information Fusion.},
	author_keywords = {Information quality; Large Language Models; NLP; Ontology; Source quality; Uncertainty evaluation},
	keywords = {Computational linguistics; Quality control; Uncertainty analysis; Information quality; Language model; Large language model; Ontology's; Reasoning framework; Source quality; Uncertainty evaluation; Uncertainty handling; Uncertainty reasoning; Uncertainty representation; Ontology},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; All Open Access, Green Open Access}
}

@CONFERENCE{2023,
	title = {EKG-LLM 2023 - Proceedings of the Workshop on Enterprise Knowledge Graphs using Large Language Models, co-located with 32nd ACM International Conference on Information and Knowledge Management, CIKM 2023},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3532},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177572636&partnerID=40&md5=04b4c0af7a5a4c0aa24c843e6681a886},
	abstract = {The proceedings contain 6 papers. The topics discussed include: EduEmbedd - a knowledge graph embedding for education; related table search for numeric data using large language models and enterprise knowledge graphs; cognitive retrieve: empowering document retrieval with semantics and domain specific knowledge graph; CRUSH: cybersecurity research using universal LLMs and semantic hypernetworks; and StATIK+: structure and text for inductive knowledge graph modeling and paths towards enterprise implementations.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Thant2023261,
	author = {Thant, Shin and Racharak, Teeradaj and Andres, Frederic},
	title = {BERT Fine-Tuning the Covid-19 Open Research Dataset for Named Entity Recognition},
	year = {2023},
	journal = {Communications in Computer and Information Science},
	volume = {1942 CCIS},
	pages = {261 – 275},
	doi = {10.1007/978-981-99-7969-1_19},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177820256&doi=10.1007%2f978-981-99-7969-1_19&partnerID=40&md5=daa58d05bc892480a069118e90d8af96},
	abstract = {This study employs the widely used Large Language Model (LLM), BERT, to implement Named Entity Recognition (NER) on the CORD-19 biomedical literature corpus. By fine-tuning the pre-trained BERT on the CORD-NER dataset, the model gains the ability to comprehend the context and semantics of biomedical named entities. The refined model is then utilized on the CORD-19 to extract more contextually relevant and updated named entities. However, fine-tuning large datasets with LLMs poses a challenge. To counter this, two distinct sampling methodologies are proposed to apply on each dataset. First, for the NER task on the CORD-19, a Latent Dirichlet Allocation (LDA) topic modeling technique is employed. This maintains the sentence structure while concentrating on related content. Second, a straightforward greedy method is deployed to gather the most informative data of 25 entity types from the CORD-NER dataset. The study realizes its goals by demonstrating the content comprehension capability of BERT-based models without the necessity of supercomputers, and converting the document-level corpus into a source for NER data, enhancing data accessibility. The outcomes of this research can shed light on the potential progression of more sophisticated NLP applications across various sectors, including knowledge graph creation, ontology learning, and conversational AI. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd 2023.},
	author_keywords = {BERT; CORD-19; CORD-NER; Dataset sampling; Document level entity extraction; Large language models; NER},
	keywords = {Computational linguistics; Large dataset; Natural language processing systems; Semantics; Statistics; BERT; CORD-19; CORD-named entity recognition; Dataset sampling; Document level entity extraction; Entity extractions; Language model; Large language model; Named entity recognition; Supercomputers},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Martinez2023133,
	author = {Martinez, Fernanda and Collarana, Diego and Calvaresi, Davide and Arispe, Martin and Florida, Carla and Calbimonte, Jean-Paul},
	title = {Study-Buddy: A Knowledge Graph-Powered Learning Companion for School Students},
	year = {2023},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {13998 LNCS},
	pages = {133 – 137},
	doi = {10.1007/978-3-031-43458-7_25},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175958900&doi=10.1007%2f978-3-031-43458-7_25&partnerID=40&md5=a148e2c0e62663fb8d0fbf7ffacd7091},
	abstract = {Large Language Models (LLMs) have the potential to substantially improve educational tools for students. However, they face limitations, including factual accuracy, personalization, and the lack of control over the sources of information. This paper presents Study-Buddy, a prototype of a conversational AI assistant for school students to address the above-mentioned limitations. Study-Buddy embodies an AI assistant based on a knowledge graph, LLMs models, and computational persuasion. It is designed to support educational campaigns as a hybrid AI solution. The demonstrator showcases interactions with Study-Buddy and the crucial role of the Knowledge Graph for the bot to present the appropriate activities to the students. A video demonstrating the main features of Study-Buddy is available at: https://youtu.be/DHPTsN1RI9o. © The Author(s), under exclusive license to Springer Nature Switzerland AG. 2023.},
	author_keywords = {Knowledge Graphs; NLP; Personalized Education},
	keywords = {Education computing; Students; Educational campaigns; Educational tools; Knowledge graphs; Language model; Learning companions; Personalizations; Personalized education; School students; Sources of informations; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{2023,
	title = {34th International Conference on Database and Expert Systems Applications, DEXA 2023},
	year = {2023},
	journal = {Communications in Computer and Information Science},
	volume = {1872 CCIS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85171574667&partnerID=40&md5=04f386e242620277ebf463165a3df6ec},
	abstract = {The proceedings contain 10 papers. The special focus in this conference is on . The topics include: Analyzing the Innovative Potential of Texts Generated by Large Language Models: An Empirical Evaluation; LocBERT: Improving Social Media User Location Prediction Using Fine-Tuned BERT; measuring Overhead Costs of Federated Learning Systems by Eavesdropping; a Context Ontology-Based Model to Mitigate Root Causes of Uncertainty in Cyber-Physical Systems; architecture for Self-protective Medical Cyber-Physical Systems; an Approach for Safe and Secure Software Protection Supported by Symbolic Execution; Towards Increasing Safety in Collaborative CPS Environments; an Intermediate Representation for Rewriting Cypher Queries.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Banerjee2023234,
	author = {Banerjee, Debayan},
	title = {Semantic Parsing for Knowledge Graph Question Answering with Large Language Models},
	year = {2023},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {13998 LNCS},
	pages = {234 – 243},
	doi = {10.1007/978-3-031-43458-7_42},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176013413&doi=10.1007%2f978-3-031-43458-7_42&partnerID=40&md5=20cbd9c7fa7e8a0b0b0c9008f65e33a5},
	abstract = {This thesis explores the topic of Knowledge Graph Question Answering with a special emphasis on semantic parsing approaches, incorporating pre-trained text-to-text language models. We use the text generation ability of these models to convert natural language questions to logical forms. We test whether correct logical forms are being generated, and if not, how to mitigate the failure cases. As a second step, we try to make the same models generate additional information to aid the process of grounding of the logical forms to entities, relations and literals in the Knowledge Graph. In experiments conducted so far, we see encouraging results on both generation of base logical forms, and grounding them to the KG elements. At the same time, we discover failure cases prompting directions in future work (The author considers himself a ‘middle-stage’ Ph.D. candidate). © The Author(s), under exclusive license to Springer Nature Switzerland AG. 2023.},
	keywords = {Computational linguistics; Natural language processing systems; Semantics; Knowledge graphs; Language model; Literals; Logical forms; Natural language questions; Question Answering; Semantic parsing; Text generations; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{2023,
	title = {21st International Conference on Service-Oriented Computing, ICSOC 2023},
	year = {2023},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14419 LNCS},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178228703&partnerID=40&md5=415e53b6cc8b6c04122f554f57b0cd44},
	abstract = {The proceedings contain 48 papers. The special focus in this conference is on Service-Oriented Computing. The topics include: IDLGen: Automated Code Generation for Inter-parameter Dependencies in Web APIs; time-Aware Log Anomaly Detection Based on Growing Self-organizing Map; an Empirical Evaluation of the Energy and Performance Overhead of Monitoring Tools on Docker-Based Systems; chainsFormer: A Chain Latency-Aware Resource Provisioning Approach for Microservices Cluster; energy-Efficient and Communication-Aware Resource Allocation in Container-Based Cloud with Group Genetic Algorithm; engineering Self-adaptive Microservice Applications: An Experience Report; FUSE: Fault Diagnosis and Suppression with eBPF for Microservices; serviceSim: A Modelling and Simulation Toolkit of Microservice Systems in Cloud-Edge Environment; 2DPChain: Orchestrating Transactions in Order-Execute Blockchain to Exploit Intra-batch and Inter-batch Parallelism; deep Learning Model for Personalized Web Service Recommendations Using Attention Mechanism; a Dynamical Model for the Nonlinear Features of Value-Driven Service Ecosystem Evolution; a Middleware for Hybrid Blockchain Applications: Towards Fast, Affordable, and Accountable Integration; An AI Chatbot for Explaining Deep Reinforcement Learning Decisions of Service-Oriented Systems; BEAR: Revolutionizing Service Domain Knowledge Graph Construction with LLM; dependency-Aware Resource Allocation for Serverless Functions at the Edge; distributing Quantum Computations, by Shots; energy-Efficient Task Offloading with Statistic QoS Constraint Through Multi-level Sleep Mode in Ultra-Dense Network; enhancing Blockchain Performance via On-chain and Off-chain Collaboration; deep Reinforcement Learning-Based Scheduling for Same Day Delivery with a Dynamic Number of Drones; designing Reconfigurable Intelligent Systems with Markov Blankets; exploiting Category Information in Sequential Recommendation; Niagara: Scheduling DNN Inference Services on Heterogeneous Edge Processors; plan, Generate and Match: Scientific Workflow Recommendation with Large Language Models; predicting Effect and Cost of Microservice System Evolution Using Graph Neural Network; qoS Prediction via Multi-scale Feature Fusion Based on Convolutional Neural Network.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Straková202385,
	author = {Straková, Jana and Fučíková, Eva and Hajič, Jan and Urešová, Zdeňka},
	title = {Extending an Event-type Ontology: Adding Verbs and Classes Using Fine-tuned LLMs Suggestions},
	year = {2023},
	journal = {Proceedings of the Annual Meeting of the Association for Computational Linguistics},
	pages = {85 – 95},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174806193&partnerID=40&md5=8eeb6ee14d3a258140ee86884e7c6a1c},
	abstract = {In this project, we have investigated the use of advanced machine learning methods, specifically fine-tuned large language models, for pre-annotating data for a lexical extension task, namely adding descriptive words (verbs) to an existing (but incomplete, as of yet) ontology of event types. Several research questions have been focused on, from the investigation of a possible heuristics to provide at least hints to annotators which verbs to include and which are outside the current version of the ontology, to the possible use of the automatic scores to help the annotators to be more efficient in finding a threshold for identifying verbs that cannot be assigned to any existing class and therefore they are to be used as seeds for a new class. We have also carefully examined the correlation of the automatic scores with the human annotation. While the correlation turned out to be strong, its influence on the annotation proper is modest due to its near linearity, even though the mere fact of such pre-annotation leads to relatively short annotation times. © 2023 Association for Computational Linguistics.},
	keywords = {Learning systems; 'current; Event Types; Human annotations; Language model; Machine learning methods; Ontology's; Research questions; Ontology},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{Martino2023182,
	author = {Martino, Ariana and Iannelli, Michael and Truong, Coleen},
	title = {Knowledge Injection to Counter Large Language Model (LLM) Hallucination},
	year = {2023},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {13998 LNCS},
	pages = {182 – 185},
	doi = {10.1007/978-3-031-43458-7_34},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175947794&doi=10.1007%2f978-3-031-43458-7_34&partnerID=40&md5=f338feecc105efe53da2e424217aa790},
	abstract = {A shortfall of Large Language Model (LLM) content generation is hallucination, i.e., including false information in the output. This is especially risky for enterprise use cases that require reliable, fact-based, controllable text generation at scale. To mitigate this, we utilize a technique called Knowledge Injection (KI), where contextual data about the entities relevant to a text-generation task is mapped from a knowledge graph to text space for inclusion in an LLM prompt. Using the task of responding to online customer reviews of retail locations as an example, we have found that KI increases the count of correct assertions included in generated text. In a qualitative review, fine-tuned bloom-560m with KI outperformed a non-fine-tuned text-davinci-003 model from OpenAI, though text-davinci-003 has 300 times more parameters. Thus, the KI method can increase enterprise users’ confidence leveraging LLMs to replace tedious manual text generation and enable better performance from smaller, cheaper models. © The Author(s), under exclusive license to Springer Nature Switzerland AG. 2023.},
	author_keywords = {bloom; gpt-3; hallucination; knowledge graph; large language model; prompt engineering},
	keywords = {Blooms (metal); Knowledge graph; Bloom; Davinci; Gpt-3; Hallucination; Knowledge graphs; Language model; Large language model; Online customer reviews; Prompt engineering; Text generations; Computational linguistics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 36}
}

@CONFERENCE{Heinisch20231347,
	author = {Heinisch, Philipp and Plenz, Moritz and Frank, Anette and Cimiano, Philipp},
	title = {ACCEPT at SemEval-2023 Task 3: An Ensemble-based Approach to Multilingual Framing Detection},
	year = {2023},
	journal = {17th International Workshop on Semantic Evaluation, SemEval 2023 - Proceedings of the Workshop},
	pages = {1347 – 1358},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175398208&partnerID=40&md5=9f8f55657ba512466f0c1030516fb612},
	abstract = {This paper describes the system and experimental results of an ensemble-based approach to multilingual framing detection for the submission of the ACCEPT team to the SemEval-2023 Task 3 on Framing Detection (Subtask 2). The approach is based on an ensemble that combines three different methods: a classifier based on large language models, a classifier based on static word embeddings, and an approach that uses external commonsense knowledge graphs, in particular, ConceptNet. The results of the three classification heads are aggregated into an overall prediction for each frame class. Our best submission yielded a micro F1-score of 50.69% (rank 10) and a macro F1-score of 50.20% (rank 3) for English articles. Our experimental results show that static word embeddings and knowledge graphs are useful components for frame detection, while the ensemble of all three methods combines the strengths of our three proposed methods. Through system ablations, we show that the commonsense-guided knowledge graphs are the outperforming method for many languages. © 2023 Association for Computational Linguistics.},
	keywords = {Knowledge graph; Semantics; Commonsense knowledge; ConceptNet; Embeddings; Frame detection; Knowledge graphs; Language model; Subtask; Embeddings},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@CONFERENCE{Ahmed2023235,
	author = {Ahmed, Umair},
	title = {Reimagining open data ecosystems: a practical approach using AI, CI, and Knowledge Graphs},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3514},
	pages = {235 – 249},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176118205&partnerID=40&md5=3aa98b44917bcdc9c7a8b2629ebf5cea},
	abstract = {Open data promotes transparency, facilitates innovation, and enables informed decision-making. In the information age, despite the abundance of data, issues related to findability, accessibility, usability, and value creation continue to be significant challenges. This study focuses on ways to tackle those challenges within the realm of open data ecosystem. It particularly investigates the utilization of AI (Artificial Intelligence) and CI (Collective Intelligence) to enhance the open data ecosystem in the aforementioned aspects. It also navigates through fitting knowledge representation methodologies for open data, which promote semantic reasoning and make it conducive for AI and CI to work more effectively. Given the main objectives of this study, in the preliminary stage, apart from the literature review, we surveyed multiple open data portals to find the state of functional traits currently. We found the state to be significantly lacking in terms of the aforementioned objectives. Initially, we focused on the problem of missing metadata. We explored state-of-the-art AI methodologies such as BERT, YAKE, RAKE, TextRank, ChatGPT and proposed BRYT (a hybrid methodology) for automated metadata extraction. We proposed to extract keywords, themes/categories, and descriptions of data sets using AI to fill in the missing metadata and recommend them to publishers while uploading new data sets. Following metadata extraction, we proposed to explore the idea of constructing a representative knowledge graph from open data sets and investigate how it aids with the objectives of this study. To address this, we chose Open Street Maps as our source of geographical open data and GTFS as a layer of mobility data on top of it. Following it, we propose to employ intuitive search algorithms and recommender systems on top of it to enhance the open data ecosystem. In association with OSM and GTFS, we also plan to focus on the problem of optimal route recommendation, improved navigation, and emergency response planning. The objectives of this study mainly focus on enhancing the open data ecosystem, and by employing the previously stated methods, we intend to advance it and evaluate the impact. © 2023 Copyright for this paper by its authors.},
	author_keywords = {Artificial Intelligence; Collective Intelligence; Knowledge Graphs; LLM; Metadata Extraction; Open Data; Open Street Map; Search Engine},
	keywords = {Data mining; Decision making; Decision support systems; Ecosystems; Extraction; Metadata; Open Data; Search engines; Semantics; Collective intelligences; Data set; Decisions makings; Informed decision; Knowledge graphs; LLM; Meta-data extractions; Open datum; Open street map; Street maps; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}

@CONFERENCE{Tamagnone20236219,
	author = {Tamagnone, Nicolò and Fekih, Selim and Contla, Ximena and Orozco, Nayid and Rekabsaz, Navid},
	title = {Leveraging Domain Knowledge for Inclusive and Bias-aware Humanitarian Response Entry Classification},
	year = {2023},
	journal = {IJCAI International Joint Conference on Artificial Intelligence},
	volume = {2023-August},
	pages = {6219 – 6227},
	doi = {10.24963/ijcai.2023/690},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85170385846&doi=10.24963%2fijcai.2023%2f690&partnerID=40&md5=305d1e90dc259977ba794e1f3a81ba56},
	abstract = {Accurate and rapid situation analysis during humanitarian crises is critical to delivering humanitarian aid efficiently and is fundamental to humanitarian imperatives and the Leave No One Behind (LNOB) principle. This data analysis can highly benefit from language processing systems, e.g., by classifying the text data according to a humanitarian ontology. However, approaching this by simply fine-tuning a generic large language model (LLM) involves considerable practical and ethical issues, particularly the lack of effectiveness on data-sparse and complex subdomains, and the encoding of societal biases and unwanted associations. In this work, we aim to provide an effective and ethically-aware system for humanitarian data analysis. We approach this by (1) introducing a novel architecture adjusted to the humanitarian analysis framework, (2) creating and releasing a novel humanitarian-specific LLM called HumBERT, and (3) proposing a systematic way to measure and mitigate biases. Our results show the better performance of our approach on zero-shot and full-training settings in comparison with strong baseline models, while also revealing the existence of biases in the resulting LLMs. Utilizing a targeted counterfactual data augmentation approach, we significantly reduce these biases without compromising performance. © 2023 International Joint Conferences on Artificial Intelligence. All rights reserved.},
	keywords = {Data handling; Information analysis; Knowledge management; Zero-shot learning; Domain knowledge; Fine tuning; Humanitarian aids; Language model; Language processing systems; Ontology's; Performance; Practical issues; Situation analysis; Text data; Domain Knowledge},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3; All Open Access, Bronze Open Access, Green Open Access}
}

@CONFERENCE{Kovriguina2023,
	author = {Kovriguina, Liubov and Teucher, Roman and Radyush, Daniil and Mouromtsev, Dmitry},
	title = {SPARQLGEN: One-Shot Prompt-based Approach for SPARQL Query Generation},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3526},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176588073&partnerID=40&md5=c408e2ce15847ce28f17e9d1edb1c112},
	abstract = {In this work, we present a one-shot generative approach (further referred to as SPARQLGEN) for generating SPARQL queries by augmenting Large Language Models (LLMs) with the relevant context within a single prompt. The prompt includes heterogeneous data sources: a question itself, an RDF subgraph required to answer the question, and an example of a correct SPARQL query for a different question. In the experiments, GPT-3, a popular pre-trained language model from OpenAI, was leveraged, but it is possible to extend the approach to any other generative LLM. We evaluate, how different types of context in the prompt influence the query generation performance on QALD-9, QALD-10 and Bestiary dataset (BESTIARY), which was created to test LLM performance on unseen data, and provide a detailed error analysis. One of the findings is that providing the model with the underlying KG and a random correct query improve the generation results. The approach shows strong results on QALD-9 dataset, but doesn’t generalize on QALD-10 and BESTIARY which can be caused by memorization problem. © 2023 CEUR-WS. All rights reserved.},
	author_keywords = {Augmented Large Language Models; Knowledge Graphs Question Answering; Prompt Template Design; SPARQL query generation},
	keywords = {Computational linguistics; Knowledge graph; Natural language processing systems; Resource Description Framework (RDF); Statistical tests; Augmented large language model; Heterogeneous data sources; Knowledge graph question answering; Knowledge graphs; Language model; Prompt template design; Query generation; Question Answering; SPARQL query generation; Template designs; Query processing},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5}
}

@CONFERENCE{Andrus202210436,
	author = {Andrus, Berkeley R and Nasiri, Yeganeh and Cui, Shilong and Cullen, Benjamin and Fulda, Nancy},
	title = {Enhanced Story Comprehension for Large Language Models through Dynamic Document-Based Knowledge Graphs},
	year = {2022},
	journal = {Proceedings of the 36th AAAI Conference on Artificial Intelligence, AAAI 2022},
	volume = {36},
	pages = {10436 – 10444},
	doi = {10.1609/aaai.v36i10.21286},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85136147942&doi=10.1609%2faaai.v36i10.21286&partnerID=40&md5=d9855635faced86178582d111c4f0302},
	abstract = {Large transformer-based language models have achieved incredible success at various tasks which require narrative comprehension, including story completion, answering questions about stories, and generating stories ex nihilo. However, due to the limitations of finite context windows, these language models struggle to produce or understand stories longer than several thousand tokens. In order to mitigate the document length limitations that come with finite context windows, we introduce a novel architecture that augments story processing with an external dynamic knowledge graph. In contrast to static commonsense knowledge graphs which hold information about the real world, these dynamic knowledge graphs reflect facts extracted from the story being processed. Our architecture uses these knowledge graphs to create informationrich prompts which better facilitate story comprehension than prompts composed only of story text. We apply our architecture to the tasks of question answering and story completion. To complement this line of research, we introduce two long-form question answering tasks, LF-SQuAD and LFQUOREF, in which the document length exceeds the size of the language model's context window, and introduce a story completion evaluation method that bypasses the stochastic nature of language model generation. We demonstrate broad improvement over typical prompt formulation methods for both question answering and story completion using GPT-2, GPT-3 and XLNet.  Copyright © 2022, Association for the Advancement of Artificial Intelligence (www.aaai.org). All rights reserved.},
	keywords = {Architecture; Computational linguistics; Graphic methods; Memory architecture; Stochastic models; Stochastic systems; Commonsense knowledge; Context window; Document length; Document-based; Dynamic documents; External dynamics; Knowledge graphs; Language model; Novel architecture; Question Answering; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 22; All Open Access, Gold Open Access}
}

@ARTICLE{Graham2023,
	author = {Graham, Shawn and Yates, Donna and El-Roby, Ahmed},
	title = {Investigating antiquities trafficking with generative pre-trained transformer (GPT)-3 enabled knowledge graphs: A case study},
	year = {2023},
	journal = {Open Research Europe},
	volume = {3},
	doi = {10.12688/openreseurope.16003.1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166644502&doi=10.12688%2fopenreseurope.16003.1&partnerID=40&md5=8bdf4ffbf065bb69cae7f623cae181ed},
	abstract = {Background: There is a wide variety of potential sources from which insight into the antiquities trade could be culled, from newspaper articles to auction catalogues, to court dockets, to personal archives, if it could all be systematically examined. We explore the use of a large language model, GPT-3, to semi-automate the creation of a knowledge graph of a body of scholarship concerning the antiquities trade. Methods: We give GPT-3 a prompt guiding it to identify knowledge statements around the trade. Given GPT-3’s understanding of the statistical properties of language, our prompt teaches GPT-3 to append text to each article we feed it where the appended text summarizes the knowledge in the article. The summary is in the form of a list of subject, predicate, and object relationships, representing a knowledge graph. Previously we created such lists by manually annotating the source articles. We compare the result of this automatic process with a knowledge graph created from the same sources via hand. When such knowledge graphs are projected into a multi-dimensional embedding model using a neural network (via the Ampligraph open-source Python library), the relative positioning of entities implies the probability of a connection; the direction of the positioning implies the kind of connection. Thus, we can interrogate the embedding model to discover new probable relationships. The results can generate new insight about the antiquity trade, suggesting possible avenues of research. Results: We find that our semi-automatic approach to generating the knowledge graph in the first place produces comparable results to our hand-made version, but at an enormous savings of time and a possible expansion of the amount of materials we can consider. Conclusions: These results have implications for working with other kinds of archaeological knowledge in grey literature, reports, articles, and other venues via computational means. Copyright: © 2023 Graham S et al.},
	author_keywords = {antiquities trade; antiquities trafficking; art market; gpt3; illicit antiquities; knowledge graph; knowledge graph embedding model; Large language models},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5; All Open Access, Gold Open Access, Green Open Access}
}

@ARTICLE{Kamath Barkur2023439,
	author = {Kamath Barkur, Sudarshan and Schacht, Sigurd and Lanquillon, Carsten},
	title = {Knowledge-Grounded and Self-extending NER},
	year = {2023},
	journal = {Communications in Computer and Information Science},
	volume = {1836 CCIS},
	pages = {439 – 446},
	doi = {10.1007/978-3-031-36004-6_60},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169467561&doi=10.1007%2f978-3-031-36004-6_60&partnerID=40&md5=d3a3d232212544c1c736480de88ad4b3},
	abstract = {The wave of digitization has begun. Organizations deal with huge amounts of data, such as logs, websites, and documents. A common way to make the information contained in these sources machine-accessible for automated processing is to first extract the information and then store it in a knowledge graph. A key task in this approach is to recognize entities. While common named entity recognition (NER) models work well for common entity types, they typically fail to recognize custom entities. Custom entity recognition requires data to be manually annotated and custom NER models to be trained. To efficiently extract the information, this paper proposes an innovative solution: Our Gazetteer approach uses a knowledge graph to create a coarse and fast NER component, reducing the need for manual annotation and saving human effort. Focusing on a university use case, our Gazetteer is integrated into a chatbot for entity recognition. In addition, data can be annotated using the Gazetteer and an NER model can be trained. Subsequently, the NER model can be used to recognize unseen custom entities, which are then added to the knowledge graph. This will improve the knowledge graph and make it self-extending. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Chatbots; Knowledge Graphs; Large Language Models; Named Entity Recognition (NER)},
	keywords = {Data mining; Automated processing; Chatbots; Digitisation; Entity recognition; Knowledge graphs; Language model; Large language model; Named entity recognition; Recognition models; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Baldazzi202386,
	author = {Baldazzi, Teodoro and Bellomarini, Luigi and Ceri, Stefano and Colombo, Andrea and Gentili, Andrea and Sallinger, Emanuel},
	title = {Fine-Tuning Large Enterprise Language Models via Ontological Reasoning},
	year = {2023},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14244 LNCS},
	pages = {86 – 94},
	doi = {10.1007/978-3-031-45072-3_6},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175989701&doi=10.1007%2f978-3-031-45072-3_6&partnerID=40&md5=c9ebc64aabb63e310c2b6e85edf9a58a},
	abstract = {Large Language Models (LLMs) exploit fine-tuning as a technique to adapt to diverse goals, thanks to task-specific training data. Task specificity should go hand in hand with domain orientation, that is, the specialization of an LLM to accurately address the tasks of a given realm of interest. However, models are usually fine-tuned over publicly available data or, at most, over ground data from databases, ignoring business-level definitions and domain experience. On the other hand, Enterprise Knowledge Graphs (EKGs) are able to capture and augment such domain knowledge via ontological reasoning. With the goal of combining LLM flexibility with the domain orientation of EKGs, we propose a novel neurosymbolic architecture that leverages the power of ontological reasoning to build task- and domain-specific corpora for LLM fine-tuning. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Knowledge graphs; Language models; Ontological reasoning},
	keywords = {Computational linguistics; Domain Knowledge; Ontology; Domain knowledge; Domain orientation; Fine tuning; Ground data; Knowledge graphs; Language model; Large enterprise; Ontological reasoning; Specialisation; Training data; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7}
}

@CONFERENCE{Mahajan20231088,
	author = {Mahajan, Arpana Dipak and Mahale, Akshay and Deshmukh, Amol S and Vidyadharan, Arun and Hegde, Vijeth S and Vijayaraghavan, Koushik},
	title = {Knowledge Graph-based Recommendation Engine: The Review},
	year = {2023},
	journal = {Proceedings of the 2023 2nd International Conference on Augmented Intelligence and Sustainable Systems, ICAISS 2023},
	pages = {1088 – 1095},
	doi = {10.1109/ICAISS58487.2023.10250672},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173627858&doi=10.1109%2fICAISS58487.2023.10250672&partnerID=40&md5=96cc1d702877e298140c1596635ef45c},
	abstract = {With the rapid growth of digital information and the increasing complexity of user preferences, recommender systems have become essential in various application domains. Knowledge graph-based recommendation methods have emerged as a promising approach to enhance the accuracy and interpretability of recommendations. This research study explores the landscape of knowledge graph-based recommendation methods and examine benchmark datasets from the perspectives of different application scenarios. Here, the application scenarios are categorized into e-commerce, social media, content-based, and cross-domain recommendations. This study has analyzed the challenges and opportunities that arise in each scenario and discuss the corresponding knowledge graph-based recommendation techniques. Furthermore, this study investigates the existing benchmark datasets specifically designed for knowledge graph-based recommendation, highlighting their characteristics, strengths, and limitations. By providing an in-depth analysis of knowledge graph-based recommendation methods and benchmark datasets, this review paper serves as a valuable resource for researchers and practitioners working in the field, aiding in the development and evaluation of effective recommendation systems tailored to specific application scenarios. © 2023 IEEE.},
	author_keywords = {Collaborative Filtering; Generative Ai; Graph Algorithm; Knowledge Graph; Recommendation Engine},
	keywords = {Benchmarking; Collaborative filtering; Electronic commerce; Engines; Graphic methods; Knowledge graph; Application scenario; Benchmark datasets; Digital information; Generative ai; Graph algorithms; Graph-based; Knowledge graphs; Rapid growth; Recommendation methods; User's preferences; Recommender systems},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Mu2023340,
	author = {Mu, Zonghao and Zhao, Wenyu and Yin, Yue and Xi, Xiangming and Song, Wei and Gu, Jianjun and Zhu, Shiqiang},
	title = {KGGPT: Empowering Robots with OpenAI’s ChatGPT and Knowledge Graph},
	year = {2023},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14271 LNAI},
	pages = {340 – 351},
	doi = {10.1007/978-981-99-6495-6_29},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175963151&doi=10.1007%2f978-981-99-6495-6_29&partnerID=40&md5=009e505328f38a3451c49ff90b3c0baa},
	abstract = {This paper presents a study on using knowledge graph with ChatGP for robotics applications, called KGGPT. Traditional planning methods for robot tasks based on structured data and sequential actions, such as rosplan, have limitations such as limited data range and lack of flexibility to modify behaviors based on user feedback. Recent research has focused on combining AI planning with large language models (LLMs) to overcome these limitations, but generated text may not always be consistent with real-world physics and the robot skills to perform physical actions. To address these challenges, we propose KGGPT, a system that incorporates prior knowledge to enable ChatGPT for a variety of robotic tasks. KGGPT extracts relevant knowledge from the knowledge graph, generates a semantic description of the knowledge, and connects it to ChatGPT. The gap between the knowledge of ChatGPT and actual service environments is addressed by using the knowledge graph to model robot skills, task rules, and environmental constraints. The output is a behavior tree based on robot skills. We evaluate our method in an office setting and show that it outperforms traditional PDDL planning and a separate ChatGPT planning scheme. Additionally, our system reduces programming effort for applications when new task requirements arise. This research has the potential to significantly advance the field of robotics. © The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd. 2023.},
	author_keywords = {AI planning; ChatGPT; Knowledge graph},
	keywords = {Robot programming; Semantics; Trees (mathematics); AI planning; ChatGPT; Knowledge graphs; Planning method; Robot skills; Robot tasks; Robotics applications; Structured data; Task-based; Traditional planning; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 1}
}

@ARTICLE{Chen2023327,
	author = {Chen, Yunlong and Zhang, Yaming and Yu, Jianfei and Yang, Li and Xia, Rui},
	title = {In-Context Learning for Knowledge Base Question Answering for Unmanned Systems Based on Large Language Models},
	year = {2023},
	journal = {Communications in Computer and Information Science},
	volume = {1923 CCIS},
	pages = {327 – 339},
	doi = {10.1007/978-981-99-7224-1_26},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176912695&doi=10.1007%2f978-981-99-7224-1_26&partnerID=40&md5=29b5937dcb0c64742c0190230ec6c29f},
	abstract = {Knowledge Base Question Answering (KBQA) aims to answer factoid questions based on knowledge bases. However, generating the most appropriate knowledge base query code based on Natural Language Questions (NLQ) poses a significant challenge in KBQA. In this work, we focus on the CCKS2023 Competition of Question Answering with Knowledge Graph Inference for Unmanned Systems. Inspired by the recent success of large language models (LLMs) like ChatGPT and GPT-3 in many QA tasks, we propose a ChatGPT-based Cypher Query Language (CQL) generation framework to generate the most appropriate CQL based on the given NLQ. Our generative framework contains six parts: an auxiliary model predicting the syntax-related information of CQL based on the given NLQ, a proper noun matcher extracting proper nouns from the given NLQ, a demonstration example selector retrieving similar examples of the input sample, a prompt constructor designing the input template of ChatGPT, a ChatGPT-based generation model generating the CQL, and an ensemble model to obtain the final answers from diversified outputs. With our ChatGPT-based CQL generation framework, we achieved the second place in the CCKS 2023 Question Answering with Knowledge Graph Inference for Unmanned Systems competition, achieving an F1-score of 0.92676. © 2023, The Author(s), under exclusive license to Springer Nature Singapore Pte Ltd.},
	author_keywords = {Chain-of-Thought; ChatGPT; In-Context Learning},
	keywords = {Computational linguistics; Knowledge graph; Learning systems; Natural language processing systems; Chain-of-thought; ChatGPT; Context learning; In contexts; In-context learning; Knowledge graphs; Language model; Natural language questions; Question Answering; Unmanned system; Query languages},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{Saba20233,
	author = {Saba, Walid S.},
	title = {Stochastic LLMs do not Understand Language: Towards Symbolic, Explainable and Ontologically Based LLMs},
	year = {2023},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14320 LNCS},
	pages = {3 – 19},
	doi = {10.1007/978-3-031-47262-6_1},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177460103&doi=10.1007%2f978-3-031-47262-6_1&partnerID=40&md5=c83bd830450111bef7c99792b7528f53},
	abstract = {In our opinion the exuberance surrounding the relative success of data-driven large language models (LLMs) is slightly misguided and for several reasons (i) LLMs cannot be relied upon for factual information since for LLMs all ingested text (factual or non-factual) was created equal; (ii) due to their subsymbolic nature, whatever ‘knowledge’ these models acquire about language will always be buried in billions of microfeatures (weights), none of which is meaningful on its own; and (iii) LLMs will often fail to make the correct inferences in several linguistic contexts (e.g., nominal compounds, copredication, quantifier scope ambiguities, intensional contexts). Since we believe the relative success of data-driven large language models (LLMs) is not a reflection on the symbolic vs. subsymbolic debate but a reflection on applying the successful strategy of a bottom-up reverse engineering of language at scale, we suggest in this paper applying the effective bottom-up strategy in a symbolic setting resulting in symbolic, explainable, and ontologically grounded language models. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2023.},
	author_keywords = {Bottom-up reverse engineering of language; Language Agnostic Ontology; Symbolic large language models},
	keywords = {Computational linguistics; Reverse engineering; Stochastic models; Stochastic systems; Bottom up; Bottom-up reverse engineering of language; Data driven; Factual information; Language agnostic ontology; Language model; Ontology's; Stochastics; Sub-symbolic; Symbolic large language model; Ontology},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 12}
}

@ARTICLE{Ng2023780,
	author = {Ng, Han Wei and Koh, Aiden and Foong, Anthea and Ong, Jeremy},
	title = {Real-Time Hybrid Language Model for Virtual Patient Conversations},
	year = {2023},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {13916 LNAI},
	pages = {780 – 785},
	doi = {10.1007/978-3-031-36272-9_71},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85164941428&doi=10.1007%2f978-3-031-36272-9_71&partnerID=40&md5=03f92b525169632d16fc9a139af46cdd},
	abstract = {Advancements in deep learning have enabled the development of online learning tools for medical training, which is important for remote learning. However, face-to-face interaction is essential for practicing human-centric skills such as clinical skills. Presently, in medical training, such interactions can be mimicked using deep learning methodologies. However, the understanding of such models is often limited whereby lightweight models are unable to generalize beyond scope while large language models tend to produce unexpected responses. To overcome this, we propose a hybrid lightweight and large language model for creating virtual patients, which can be used for real-time autonomous training of trainee doctors in clinical settings using online platforms. This ensures high-quality and standardized learning for all individuals regardless of location and background. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {Knowledge graph; Natural language generation; Natural language understanding; Simulated virtual human},
	keywords = {Computational linguistics; E-learning; Knowledge graph; Learning systems; Natural language processing systems; Virtual reality; Hybrid language model; Knowledge graphs; Language model; Medical training; Natural language generation; Natural language understanding; Real- time; Simulated virtual human; Virtual humans; Virtual patients; Deep learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Klager2023171,
	author = {Klager, Gerhard G. and Polleres, Axel},
	title = {Is GPT fit for KGQA? – Preliminary Results},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3447},
	pages = {171 – 191},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85169102980&partnerID=40&md5=bb331974a8da999aabf59b44e16e6bc4},
	abstract = {In this paper we report about preliminary results on running question answering benchmarks against the recently hyped conversational AI services such as ChatGPT: we focus on questions that are known to be possible to be answered by information in existing Knowledge graphs such as Wikidata. In a preliminary study we experiment, on the one hand, with questions from established KGQA benchmarks, and on the other hand, present a set of questions established in a student experiment, which should be particularly hard for Large Language Models (LLMs) to answer, mainly focusing on questions on recent events. In a second experiment, we assess how far GPT could be used for query generation in SPARQL. While our results are mostly negative for now, we hope to provide insights for further research in this direction, in terms of isolating and discussing the most obvious challenges and gaps, and to provide a research roadmap for a more extensive study planned as a current master thesis project. © 2023 CEUR-WS. All rights reserved.},
	author_keywords = {GPT; KGQA; LLMs; Question Answering},
	keywords = {Natural language processing systems; GPT; KGQA; Knowledge graphs; Language model; Large language model; Query generation; Question Answering; Research roadmap; Set of questions; Student experiments; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@CONFERENCE{Bruno202350,
	author = {Bruno, Alessandro and Mazzeo, Pier Luigi and Chetouani, Aladine and Tliba, Marouane and Kerkouri, Mohamed Amine},
	title = {Insights into Classifying and Mitigating LLMs' Hallucinations},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3563},
	pages = {50 – 63},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178666482&partnerID=40&md5=a80b8d1fe254ff592ac0b8fedd8bc186},
	abstract = {The widespread adoption of large language models (LLMs) across diverse AI applications is proof of the outstanding achievements obtained in several tasks, such as text mining, text generation, and question answering. However, LLMs are not exempt from drawbacks. One of the most concerning aspects regards the emerging problematic phenomena known as”Hallucinations”. They manifest in text generation systems, particularly in question-answering systems reliant on LLMs, potentially resulting in false or misleading information propagation. This paper delves into the underlying causes of AI hallucination and elucidates its significance in artificial intelligence. In particular, Hallucination classification is tackled over several tasks (Machine Translation, Question and Answer, Dialog Systems, Summarisation Systems, Knowledge Graph with LLMs, and Visual Question Answer). Additionally, we explore potential strategies to mitigate hallucinations, aiming to enhance the overall reliability of LLMs. Our research addresses this critical issue within the HeReFaNMi (Health-Related Fake News Mitigation) project, generously supported by NGI Search, dedicated to combating Health-Related Fake News dissemination on the Internet. This endeavour represents a concerted effort to safeguard the integrity of information dissemination in an age of evolving AI technologies. © 2022 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).},
	author_keywords = {Artificial Intelligence; Factualness; Hallucination; Hallucination Mitigation; LLMs},
	keywords = {Computational linguistics; Fake detection; Knowledge graph; Natural language processing systems; AI applications; Factualness; Generation systems; Hallucination; Hallucination mitigation; Language model; Large language model; Question Answering; Text generations; Text-mining; Information dissemination},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{Lenz2023263,
	author = {Lenz, Mirko and Bergmann, Ralph},
	title = {Case-Based Adaptation of Argument Graphs with WordNet and Large Language Models},
	year = {2023},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14141 LNAI},
	pages = {263 – 278},
	doi = {10.1007/978-3-031-40177-0_17},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172236578&doi=10.1007%2f978-3-031-40177-0_17&partnerID=40&md5=16c053188e78a303828ea1b95c941983},
	abstract = {Finding information online is hard, even more so once you get into the domain of argumentation. There have been developments around the specialized argumentation machines that incorporate structural features of arguments, but all current approaches share one pitfall: They operate on a corpora of limited sizes. Consequently, it may happen that a user searches for a rather general term like cost increases, but the machine is only able to serve arguments concerned with rent increases. We aim to bridge this gap by introducing approaches to generalize/specialize a found argument using a combination of WordNet and Large Language Models. The techniques are evaluated on a new benchmark dataset with diverse queries using our fully featured implementation. Both the dataset and the code are publicly available on GitHub. © 2023, The Author(s), under exclusive license to Springer Nature Switzerland AG.},
	author_keywords = {adaptation; argumentation; background knowledge; graphs; natural language processing},
	keywords = {Knowledge graph; Natural language processing systems; Ontology; Adaptation; Argumentation; Background knowledge; Case based; Graph; Language model; Language processing; Natural language processing; Natural languages; Wordnet; Computational linguistics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 5}
}

@ARTICLE{Dong2023,
	author = {Dong, Xuelian and Chen, Jiale},
	title = {PluDG: enhancing task-oriented dialogue system with knowledge graph plug-in module},
	year = {2023},
	journal = {PeerJ Computer Science},
	volume = {9},
	doi = {10.7717/peerj-cs.1707},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85179418203&doi=10.7717%2fpeerj-cs.1707&partnerID=40&md5=13915a4c98a19bf7281726859058b4ef},
	abstract = {Task-oriented dialogue systems continue to face significant challenges as they require not only an understanding of dialogue history but also domain-specific knowledge. However, knowledge is often dynamic, making it difficult to effectively integrate into the learning process. Existing large language model approaches primarily treat knowledge bases as textual resources, neglecting to capture the underlying relationships between facts within the knowledge base. To address this limitation, we propose a novel dialogue system called PluDG. We regard the knowledge as a knowledge graph and propose a knowledge extraction plug-in, Kg-Plug, to capture the features of the graph and generate prompt entities to assist the system's dialogue generation. Besides, we propose Unified Memory Integration, a module that enhances the comprehension of the sentence's internal structure and optimizes the knowledge base's encoding location. We conduct experiments on three public datasets and compare PluDG with several state-of-the-art dialogue models. The experimental results indicate that PluDG achieves significant improvements in both accuracy and diversity, outperforming the current state-of-the-art dialogue system models and achieving state-of-the-art performance. © 2023 Dong and Chen},
	author_keywords = {Artificial intelligence; Data science; Dialogue systems; Graph neural networks; Natural language processing},
	keywords = {Domain Knowledge; Graph neural networks; Learning systems; Natural language processing systems; Speech processing; Dialogue systems; Domain-specific knowledge; Graph neural networks; Knowledge graphs; Language processing; Natural language processing; Natural languages; Plug-ins; State of the art; Task-oriented; Knowledge graph},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2; All Open Access, Gold Open Access, Green Open Access}
}

@CONFERENCE{Visalli2023468,
	author = {Visalli, Francesco and Patrizio, Antonio and Lanza, Antonio and Papaleo, Prospero and Nautiyal, Anupam and Pupo, Mariella and Scilinguo, Umberto and Oro, Ermelinda and Ruffolo, Massimo},
	title = {ESG Data Collection with Adaptive AI},
	year = {2023},
	journal = {International Conference on Enterprise Information Systems, ICEIS - Proceedings},
	volume = {1},
	pages = {468 – 475},
	doi = {10.5220/0011844500003467},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85160731896&doi=10.5220%2f0011844500003467&partnerID=40&md5=cb361773a964585d66e27686466cfcaa},
	abstract = {The European Commission defines the sustainable finance as the process of taking Environmental, Social and Governance (ESG) considerations into account when making investment decisions, leading to more long-term investments in sustainable economic activities and projects. Banks, and other financial institutions, are increasingly incorporating data about ESG performances, with particular reference to risks posed by climate change, into their credit and investment portfolios evaluation methods. However, collecting the data related to ESG performances of corporate and businesses is still a difficult task. There exist no single source from which we can extract all the data. Furthermore, most important ESG data is in unstructured format, hence collecting it poses many technological and methodological challenges. In this paper we propose a method that addresses the ESG data collection problem based on AI-based approaches. We also present the implementation of the proposed method and discuss some experiments carried out on real world documents. Copyright © 2023 by SCITEPRESS - Science and Technology Publications, Lda. Under CC license (CC BY-NC-ND 4.0)},
	author_keywords = {Artificial Intelligence; Computer Vision; Deep Learning; Environmental Social and Governance (ESG); Hyperautomation; Information Retrieval; Intelligent Document Processing; Knowledge Graph; Large Language Models; Natural Language Processing; Socially Responsible Investment (SRI); Sustainable Investment; Workflow},
	keywords = {Climate change; Computer vision; Data acquisition; Deep learning; Economics; Knowledge graph; Knowledge management; Natural language processing systems; Sustainable development; Deep learning; Document-processing; Environmental social and governance; Hyperautomation; Intelligent document processing; Intelligent documents; Knowledge graphs; Language model; Language processing; Large language model; Natural language processing; Natural languages; Socially responsible investment; Socially responsible investments; Sustainable investments; Work-flows; Investments},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 7; All Open Access, Hybrid Gold Open Access}
}

@ARTICLE{Mihindukulasooriya2023247,
	author = {Mihindukulasooriya, Nandana and Tiwari, Sanju and Enguix, Carlos F. and Lata, Kusum},
	title = {Text2KGBench: A Benchmark for Ontology-Driven Knowledge Graph Generation from Text},
	year = {2023},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14266 LNCS},
	pages = {247 – 265},
	doi = {10.1007/978-3-031-47243-5_14},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177480752&doi=10.1007%2f978-3-031-47243-5_14&partnerID=40&md5=1c27c2ef98334d3bf4705e71000882c4},
	abstract = {The recent advances in large language models (LLM) and foundation models with emergent capabilities have been shown to improve the performance of many NLP tasks. LLMs and Knowledge Graphs (KG) can complement each other such that LLMs can be used for KG construction or completion while existing KGs can be used for different tasks such as making LLM outputs explainable or fact-checking in Neuro-Symbolic manner. In this paper, we present Text2KGBench, a benchmark to evaluate the capabilities of language models to generate KGs from natural language text guided by an ontology. Given an input ontology and a set of sentences, the task is to extract facts from the text while complying with the given ontology (concepts, relations, domain/range constraints) and being faithful to the input sentences. We provide two datasets (i) Wikidata-TekGen with 10 ontologies and 13,474 sentences and (ii) DBpedia-WebNLG with 19 ontologies and 4,860 sentences. We define seven evaluation metrics to measure fact extraction performance, ontology conformance, and hallucinations by LLMs. Furthermore, we provide results for two baseline models, Vicuna-13B and Alpaca-LoRA-13B using automatic prompt generation from test cases. The baseline results show that there is room for improvement using both Semantic Web and Natural Language Processing techniques. Resource Type: Evaluation Benchmark Source Repo: https://github.com/cenguix/Text2KGBench DOI: https://doi.org/10.5281/zenodo.7916716 License: Creative Commons Attribution (CC BY 4.0) © The Author(s), under exclusive license to Springer Nature Switzerland AG 2023.},
	author_keywords = {Benchmark; Knowledge Graph; Knowledge Graph Generation; Large Language Models; Relation Extraction},
	keywords = {Computational linguistics; Extraction; HTTP; Natural language processing systems; Ontology; Benchmark; Graph generation; Knowledge graph generation; Knowledge graphs; Language model; Large language model; Ontology's; Performance; Relation extraction; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 23}
}

@CONFERENCE{Wang2023532,
	author = {Wang, Xiao and Liu, Kai and Wang, Chunlei},
	title = {Knowledge-enhanced Pre-Training large language model for depression diagnosis and treatment},
	year = {2023},
	journal = {Proceeding of 2023 9th IEEE International Conference on Cloud Computing and Intelligence Systems, CCIS 2023},
	pages = {532 – 536},
	doi = {10.1109/CCIS59572.2023.10263217},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85174936763&doi=10.1109%2fCCIS59572.2023.10263217&partnerID=40&md5=af2d36b4525cac56d8c57c108b39b5ae},
	abstract = {Depression, a pervasive psychiatric disorder characterized by concealment, dependence on expert judgment, and a notable rate of misdiagnosis, poses a substantial burden on society. To enhance the diagnosis and treatment of depression, this study puts forth a proposition of employing knowledge-enhanced pre-Training technology leveraging large language models. By integrating domain knowledge and depression knowledge graph directives, the pre-Trained model undergoes optimization. Expert involvement in depression diagnosis and treatment fosters a guided learning process facilitated by expert feedback. Through the application of dialogue therapy, the efficacy of treatment is augmented. This technical approach aims to ameliorate the societal burden by improving the diagnosis and treatment of depressed individuals. © 2023 IEEE.},
	author_keywords = {Depression; Knowledge enhancement; Knowledge graph; Large language model},
	keywords = {Computational linguistics; Domain Knowledge; Knowledge management; Learning systems; Depression; Domain knowledge; Expert judgment; Knowledge enhancement; Knowledge graphs; Language model; Large language model; Optimisations; Pre-training; Psychiatric disorders; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 2}
}

@ARTICLE{Raggett202344,
	author = {Raggett, Dave},
	title = {Defeasible Reasoning with Knowledge Graphs},
	year = {2023},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14382 LNCS},
	pages = {44 – 51},
	doi = {10.1007/978-3-031-47745-4_4},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85177474902&doi=10.1007%2f978-3-031-47745-4_4&partnerID=40&md5=c5be555469cbaf1b14ccf8d226e89e80},
	abstract = {Human knowledge is subject to uncertainties, imprecision, incompleteness and inconsistencies. Moreover, the meaning of many everyday terms is dependent on the context. That poses a huge challenge for the Semantic Web. This paper introduces work on an intuitive notation and model for defeasible reasoning with imperfect knowledge, and relates it to previous work on argumentation theory. PKN is to N3 as defeasible reasoning is to deductive logic. Further work is needed on an intuitive syntax for describing reasoning strategies and tactics in declarative terms, drawing upon the AIF ontology for inspiration. The paper closes with observations on symbolic approaches in the era of large language models. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2023.},
	author_keywords = {argumentation theory; defeasible reasoning; knowledge graphs},
	keywords = {Argumentation theory; Deductive logic; Defeasible reasoning; Further works; Human knowledge; Incompleteness and inconsistency; Knowledge graphs; Language model; Ontology's; Uncertainty; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Meyer2023,
	author = {Meyer, Lars-Peter and Frey, Johannes and Junghanns, Kurt and Brei, Felix and Bulert, Kirill and Gründer-Fahrer, Sabine and Martin, Michael},
	title = {Developing a Scalable Benchmark for Assessing Large Language Models in Knowledge Graph Engineering},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3526},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176615313&partnerID=40&md5=8bb63c61f9bb09fa2d3e4e779ce7889a},
	abstract = {As the field of Large Language Models (LLMs) evolves at an accelerated pace, the critical need to assess and monitor their performance emerges. We introduce a benchmarking framework focused on knowledge graph engineering (KGE) accompanied by three challenges addressing syntax and error correction, facts extraction and dataset generation. We show that while being a useful tool, LLMs are yet unfit to assist in knowledge graph generation with zero-shot prompting. Consequently, our LLM-KG-Bench framework provides automatic evaluation and storage of LLM responses as well as statistical data and visualization tools to support tracking of prompt engineering and model performance. © 2023 CEUR-WS. All rights reserved.},
	author_keywords = {Knowledge Graph Engineering; Large Language Model; Large Language Model Benchmark},
	keywords = {Computational linguistics; Computer aided language translation; Data visualization; Digital storage; Error correction; Natural language processing systems; Petroleum reservoir evaluation; Semantics; Zero-shot learning; Errors correction; Fact extraction; Graph generation; Knowledge graph engineering; Knowledge graphs; Language model; Large language model; Large language model benchmark; Performance; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{2023,
	title = {Joint Workshop Proceedings of the 5th International Workshop on a Semantic Data Space for Transport, Sem4Tra 2023 and 2nd NLP4KGC: Natural Language Processing for Knowledge Graph Construction, co-located with the 19th International Conference on Semantic Systems, SEMANTiCS 2023},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3510},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175614197&partnerID=40&md5=891a8dcd63cc0e6fb6fa6ba6500c5bd1},
	abstract = {The proceedings contain 9 papers. The topics discussed include: policy patterns for usage control in data spaces; an interaction pattern ontology for data sharing about logistics activities; mobility profiles: a taxonomy for the standardization of mobility data spaces; towards aligning IoT data with domain-specific ontologies through semantic web technologies and NLP; probing large language models for scientific synonyms; effects of pretraining corpora on scientific relation extraction using BERT and SciBERT; framing few-shot knowledge graph completion with large language models; similar papers recommendation for research comparisons; and challenges of entity linking in KGQA datasets.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{2023,
	title = {SEMPDS 2023 - Proceedings of the Posters and Demo Track of the 19th International Conference on Semantic Systems, co-located with 19th International Conference on Semantic Systems, SEMANTiCS 2023},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3526},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85176562472&partnerID=40&md5=9fa6810968538af5fcc8f972422a755d},
	abstract = {The proceedings contain 9 papers. The topics discussed include: a framework generate, store, and publish FAIR data in experimental sciences; a mapping lifecycle for public procurement data; a toolset for normative interpretations in FLINT; developing a scalable benchmark for assessing large language models in knowledge graph engineering; enhancing interpretability of machine learning models over knowledge graphs; OntoAnon: an anonymizer for sharing ontology structure without data; SPARQLGEN: one-shot prompt-based approach for SPARQL query generation; and towards assessing FAIR research software best practices in an organization using RDF-star.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Hou20223931,
	author = {Hou, Yifan and Jiao, Wenxiang and Liu, Meizhen and Allen, Carl and Tu, Zhaopeng and Sachan, Mrinmaya},
	title = {Adapters for Enhanced Modeling of Multilingual Knowledge and Text},
	year = {2022},
	journal = {Findings of the Association for Computational Linguistics: EMNLP 2022},
	pages = {3931 – 3946},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85149830097&partnerID=40&md5=bf1136a31b487ea937e04c56d7fe2ad7},
	abstract = {Large language models appear to learn facts from the large text corpora they are trained on. Such facts are encoded implicitly within their many parameters, making it difficult to verify or manipulate what knowledge has been learned. Language models have recently been extended to multilingual language models (MLLMs), enabling knowledge to be learned across hundreds of languages. Meanwhile, knowledge graphs contain facts in an explicit triple format, which require careful and costly curation and are only available in a few high-resource languages, restricting their research and application. To address these issues, we propose to enhance MLLMs with knowledge from multilingual knowledge graphs (MLKGs) so as to tackle language and knowledge graph tasks across many languages, including low-resource ones. Specifically, we introduce a lightweight adapter set to enhance MLLMs with cross-lingual entity alignment and facts from MLKGs for many languages. Experiments on common benchmarks show that such enhancement benefits both MLLMs and MLKGs, achieving: (1) comparable or improved performance for knowledge graph completion and entity alignment relative to baselines, especially for low-resource languages (for which knowledge graphs are unavailable); and (2) improved MLLM performance on language understanding tasks that require multilingual factual knowledge; all while maintaining performance on other general language tasks. © 2022 Association for Computational Linguistics.},
	keywords = {Benchmarking; Computational linguistics; Cross-lingual; Curation; Knowledge graphs; Language model; Learn+; Low resource languages; Modeling performance; Performance; Research and application; Text corpora; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 6}
}

@ARTICLE{Palagin2023170,
	author = {Palagin, Oleksandr and Kaverinsky, Vladislav and Litvin, Anna and Malakhov, Kyrylo},
	title = {OntoChatGPT Information System: Ontology-Driven Structured Prompts for ChatGPT Meta-Learning},
	year = {2023},
	journal = {International Journal of Computing},
	volume = {22},
	number = {2},
	pages = {170 – 183},
	doi = {10.47839/ijc.22.2.3086},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85165118737&doi=10.47839%2fijc.22.2.3086&partnerID=40&md5=f5b734c5d3160e5f7eeca85c26f64efb},
	abstract = {This research presents a comprehensive methodology for utilizing an ontology-driven structured prompts system in interplay with ChatGPT, a widely used large language model (LLM). The study develops formal models, both information and functional, and establishes the methodological foundations for integrating ontology-driven prompts with ChatGPT’s meta-learning capabilities. The resulting productive triad comprises the methodological foundations, advanced information technology, and the OntoChatGPT system, which collectively enhance the effectiveness and performance of chatbot systems. The implementation of this technology is demonstrated using the Ukrainian language within the domain of rehabilitation. By applying the proposed methodology, the OntoChatGPT system effectively extracts entities from contexts, classifies them, and generates relevant responses. The study highlights the versatility of the methodology, emphasizing its applicability not only to ChatGPT but also to other chatbot systems based on LLMs, such as Google’s Bard utilizing the PaLM 2 LLM. The underlying principles of meta-learning, structured prompts, and ontology-driven information retrieval form the core of the proposed methodology, enabling their adaptation and utilization in various LLM-based systems. This versatile approach opens up new possibilities for NLP and dialogue systems, empowering developers to enhance the performance and functionality of chatbot systems across different domains and languages. © (2023), All Rights Reserved.},
	author_keywords = {chatbot; ChatGPT; composite service; meta-learning; OntoChatGPT; ontology engineering; ontology-driven information system; prompt engineering; prompt-based learning; transdisciplinary research},
	type = {Article},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 22; All Open Access, Green Open Access, Hybrid Gold Open Access}
}

@CONFERENCE{Thießen2023,
	author = {Thießen, Freya and D’Souza, Jennifer and Stocker, Markus},
	title = {Probing Large Language Models for Scientific Synonyms},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3510},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85175633008&partnerID=40&md5=ebda6ee4dbdf11fe1bd59423f9b78103},
	abstract = {Purpose: Automatically identifying synonyms is an important but challenging aspect of entity normalization in knowledge graphs. Entity normalization is crucial in ensuring that information in knowledge graphs is well connected and therefore efficiently reusable. We aim to investigate the potential of pre-trained large language models (LLMs) for this task. Methodology: We use k-Means clustering to compare latent concepts learned by LLMs with human-defined scientific synonymy concept clusters sourced from ORKG, CS-KG, SemEval 2017, and SciERC data. We investigate the models BERT, RoBERTa, BART, and OpenAI GPT3 (text-embedding-ada-002 variant) and evaluate clustering results by model layer. Findings: F1 scores average around 0.7 to 0.75 depending on the dataset and layer. The best results are reached using OpenAI GPT3 (max F1=0.914). We further notice no advantage of models trained on scientific data. Value: Our results suggest information learned by transformer models aligns with human-defined scientific synonyms. This shows the potential of information encoded in pre-trained LLMs to be leveraged for synonymy detection. © 2023 Copyright for this paper by its authors.},
	author_keywords = {entity normalization; knowledge graphs; LLMs; synonymy},
	keywords = {Computational linguistics; Knowledge graph; Clustering results; Embeddings; Entity normalization; K-means++ clustering; Knowledge graphs; Language model; Large language model; Normalisation; Scientific data; Synonymy; K-means clustering},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Lymperaiou2023,
	author = {Lymperaiou, Maria and Stamou, Giorgos},
	title = {The Contribution of Knowledge in Visiolinguistic Learning: A Survey on Tasks and Challenges},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3433},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166465476&partnerID=40&md5=8fb195719401d3640ea348259374011d},
	abstract = {Recent advancements in visiolinguistic (VL) learning have allowed the development of multiple models and techniques that offer several impressive implementations, able to currently resolve a variety of tasks that require the collaboration of vision and language. Current datasets used for VL pre-training only contain a limited amount of visual and linguistic knowledge, thus significantly limiting the generalization capabilities of many VL models. External knowledge sources such as knowledge graphs (KGs) and Large Language Models (LLMs) are able to cover such generalization gaps by filling in missing knowledge, resulting in the emergence of hybrid architectures. In the current survey, we analyze tasks that have benefited from such hybrid approaches. Moreover, we categorize existing knowledge sources and types, proceeding to discussion regarding the KG vs LLM dilemma and its potential impact to future hybrid approaches.  © 2023 Copyright for this paper by its authors.},
	author_keywords = {Hybrid Architectures; Knowledge Graphs; Large Language Models; Transformers; Visiolinguistic Learning},
	keywords = {Knowledge graph; Learning systems; 'current; Hybrid approach; Hybrid architectures; Knowledge graphs; Knowledge sources; Language model; Large language model; Multiple-modeling; Transformer; Visiolinguistic learning; Computational linguistics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Cadeddu2023,
	author = {Cadeddu, Andrea and Chessa, Alessandro and De Leo, Vincenzo and Fenu, Gianni and Motta, Enrico and Osborne, Francesco and Recupero, Diego Reforgiato and Salatino, Angelo and Secchi, Luca},
	title = {Leveraging Knowledge Graphs with Large Language Models for Classification Tasks in the Tourism Domain},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3559},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85178565843&partnerID=40&md5=37d0529ba5c1b6aa5e9028c19fc5edb0},
	abstract = {Online platforms, serving as the primary conduit for travelers to seek, compare, and secure travel accommodations, require a profound understanding of user dynamics to craft competitive and enticing offerings. Concurrently, recent advancements in Natural Language Processing, particularly large language models, have made substantial strides in capturing the complexity of human language. Simultaneously, knowledge graphs have become a formidable instrument for structuring and categorizing information. This paper introduces a cutting-edge deep learning methodology integrating large language models with domain-specific knowledge graphs to classify tourism offers. It aims at aiding hospitality operators in understanding their accommodation offerings’ market positioning, taking into account the visit propensity and user review ratings, with the goal of optimizing the offers themselves and enhancing their appeal. Comparative analysis against alternative methods on two datasets of London accommodation offers attests to our approach’s effectiveness, demonstrating superior results. © 2022 Copyright for this paper by its authors.},
	author_keywords = {BERT; Classification Tasks; Feature Engineering; Hospitality; Knowledge Graphs; Natural Language Processing; Tourism},
	keywords = {Computational linguistics; Domain Knowledge; Graphic methods; Knowledge graph; Knowledge management; Natural language processing systems; BERT; Classification tasks; Feature engineerings; Hospitality; Knowledge graphs; Language model; Language processing; Natural language processing; Natural languages; Online platforms; Deep learning},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@ARTICLE{2023,
	title = {Case-Based Reasoning Research and Development - 31st International Conference, ICCBR 2023, Proceedings},
	year = {2023},
	journal = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
	volume = {14141 LNAI},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85172217201&partnerID=40&md5=b1394d41bb89d2a4bfc2a98815c37b22},
	abstract = {The proceedings contain 26 papers. The special focus in this conference is on Case-Based Reasoning Research and Development. The topics include: CBR Driven Interactive Explainable AI; selecting Explanation Methods for Intelligent IoT Systems: A Case-Based Reasoning Approach; CBR-fox: A Case-Based Explanation Method for Time Series Forecasting Models; group Fairness in Case-Based Reasoning; Addressing Underestimation Bias in CBR Through Case-Base Maintenance; towards Addressing Problem-Distribution Drift with Case Discovery; case-Based Adaptation of Argument Graphs with WordNet and Large Language Models; Failure-Driven Transformational Case Reuse of Explanation Strategies in CloodCBR; a Case-Based Approach for Workflow Flexibility by Deviation; synergies Between Case-Based Reasoning and Deep Learning for Survival Analysis in Oncology; lazy Adaptation Knowledge Learning Based on Frequent Closed Itemsets; an Overview and Comparison of Case-Based Reasoning Frameworks; case-Based Cleaning of Text Images; a Multi-agent Case-Based Reasoning Intrusion Detection System Prototype; a Case-Based Reasoning Approach to Company Sector Classification Using a Novel Time-Series Case Representation; an Integrated Approach to Predicting the Influence of Reputation Mechanisms on Q&A Communities; retrieval of Similar Cases to Improve the Diagnosis of Diabetic Retinopathy; CBR Assisted Context-Aware Surface Realisation for Data-to-Text Generation; explanation of Similarities in Process-Oriented Case-Based Reasoning by Visualization; on-Demand and Model-Driven Case Building Based on Distributed Data Sources; the Case for Circularities in Case-Based Reasoning; a Contextual Information-Augmented Probabilistic Case-Based Reasoning Model for Knowledge Graph Reasoning; case-Based Sample Generation Using Multi-Armed Bandits; hybrid Event Memory as a Case Base for State Estimation in Cognitive Agents.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{2023,
	title = {NAIS 2023 - Proceedings of the 5th Symposium of the Norwegian AI Society},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3431},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85166773258&partnerID=40&md5=a2c7b3747d1fad40beb30944ca4ffff5},
	abstract = {The proceedings contain 10 papers. The topics discussed include: crowd simulation with deliberative-reactive agents; generating natural language dialogues using large language models with adapters; the AI Act and the risks posed by generative AI models; Bayesian exploration in deep reinforcement learning; analyzing literary texts in Lithuanian sign language with computer vision: a proof of concept; automatic detection of manipulative consent management platforms and the journey into the patterns of darkness; EvoLP.jl: a playground for evolutionary computation in Julia; making sense of nonsense: integrated gradient-based input reduction to improve recall for check-worthy claim detection; construction of a relevance knowledge graph with application to the LOCAL news angle; and container-based IoT architectures: use case for visual person counting.},
	type = {Conference review},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Visalli202384,
	author = {Visalli, Francesco and Patrizio, Antonio and Lanza, Antonio and Papaleo, Prospero and Nautiyal, Anupam and Pupo, Mariella and Scilinguo, Umberto and Oro, Ermelinda and Ruffolo, Massimo},
	title = {Building a Platform for Intelligent Document Processing: Opportunities and Challenges},
	year = {2023},
	journal = {CEUR Workshop Proceedings},
	volume = {3486},
	pages = {84 – 89},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85173859153&partnerID=40&md5=3d8f9c8194cf5dda9d00b9f19d3b3cc6},
	abstract = {Companies of any size and industry still struggle in automatic business processes where human cognitive and contextualization capabilities are required to read and understand complex documents. Ongoing progress in the fields of Computer Vision and Natural Language Processing, where (large) language models are becoming increasingly and freely available, have made possible to create a new generation of Intelligent Document Processing technologies that allow automatically analyzing and understanding both documents layout and contents. In this paper we present an Intelligent Document Processing platform that makes use of hybrid AI techniques to allow document reading comprehension by means of a combination of Document Layout Analysis and recognition, table recognition and detection, context free grammars, and question answering techniques. Such a technology combines also no-code principles with high performance computing based on micro-services to streamline the execution of tasks such as document and text classification, document segmentation, entity extraction, sentiment analysis, question answering, and more. © 2022 Copyright for this paper by its authors. Use permitted under Creative Commons License Attribution 4.0 International (CC BY 4.0).},
	author_keywords = {Artificial Intelligence; Computer Vision; Deep Learning; Hyperautomation; Information Retrieval; Intelligent Document Processing; Intelligent Process Automation; Knowledge Graph; Large Language Models; Natural Language Processing; Workflow},
	keywords = {Classification (of information); Computer vision; Deep learning; Information retrieval; Information retrieval systems; Intelligent systems; Knowledge graph; Sentiment analysis; Deep learning; Document-processing; Hyperautomation; Intelligent document processing; Intelligent documents; Intelligent process automation; Knowledge graphs; Language model; Language processing; Large language model; Natural language processing; Natural languages; Work-flows; Context free grammars},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}@CONFERENCE{An20223651,
	author = {An, Yuan and Greenberg, Jane and Hu, Xiaohua and Kalinowski, Alex and Fang, Xiao and Zhao, Xintong and McClellan, Scott and Uribe-Romo, Fernando J. and Langlois, Kyle and Furst, Jacob and Gomez-Gualdron, Diego A. and Fajardo-Rojas, Fernando and Ardila, Katherine and Saikin, Semion K. and Harper, Corey A. and Daniel, Ron},
	title = {Exploring Pre-Trained Language Models to Build Knowledge Graph for Metal-Organic Frameworks (MOFs)},
	year = {2022},
	journal = {Proceedings - 2022 IEEE International Conference on Big Data, Big Data 2022},
	pages = {3651 – 3658},
	doi = {10.1109/BigData55660.2022.10020568},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85147906256&doi=10.1109%2fBigData55660.2022.10020568&partnerID=40&md5=3c6a360dbf88757944621f12cb480597},
	abstract = {Building a knowledge graph is a time-consuming and costly process which often applies complex natural language processing (NLP) methods for extracting knowledge graph triples from text corpora. Pre-trained large Language Models (PLM) have emerged as a crucial type of approach that provides readily available knowledge for a range of AI applications. However, it is unclear whether it is feasible to construct domain-specific knowledge graphs from PLMs. Motivated by the capacity of knowledge graphs to accelerate data-driven materials discovery, we explored a set of state-of-the-art pre-trained general-purpose and domain-specific language models to extract knowledge triples for metal-organic frameworks (MOFs). We created a knowledge graph benchmark with 7 relations for 1248 published MOF synonyms. Our experimental results showed that domain-specific PLMs consistently outperformed the general-purpose PLMs for predicting MOF related triples. The overall benchmarking results, however, show that using the present PLMs to create domain-specific knowledge graphs is still far from being practical, motivating the need to develop more capable and knowledgeable pre-trained language models for particular applications in materials science. © 2022 IEEE.},
	author_keywords = {Knowledge Graph; Materials Science; Metal-Organic Frameworks; Pre-trained Language Model; Prompt Probing},
	keywords = {Benchmarking; Computational linguistics; Data mining; Domain Knowledge; Natural language processing systems; Organometallics; Domain-specific knowledge; Knowledge graphs; Language model; Language processing; Material science; Metalorganic frameworks (MOFs); Natural languages; Pre-trained language model; Processing method; Prompt probing; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 4}
}

@CONFERENCE{Hoppe2022,
	author = {Hoppe, Fabian},
	title = {Improving Zero-Shot Text Classification with Graph-based Knowledge Representations},
	year = {2022},
	journal = {CEUR Workshop Proceedings},
	volume = {3165},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85134525129&partnerID=40&md5=2b645d54b456fee825ea52244b27bc34},
	abstract = {Insufficient training data is a key challenge for text classification. In particular, long-tail class distributions and emerging, new classes do not provide any training data for specific classes. Therefore, such a zeroshot setting must incorporate additional, external knowledge to enable transfer learning by connecting the external knowledge of previously unseen classes to texts. Recent zero-shot text classifier utilize only distributional semantics defined by large language models and based on class names or natural language descriptions. This implicit knowledge contains ambiguities, is not able to capture logical relations nor is it an efficient representation of factual knowledge. These drawbacks can be avoided by introducing explicit, external knowledge. Especially, knowledge graphs provide such explicit, unambiguous, and complementary, domain specific knowledge. Hence, this thesis explores graph-based knowledge as additional modality for zero-shot text classification. Besides a general investigation of this modality, the influence on the capabilities of dealing with domain shifts by including domain-specific knowledge is explored. © 2022 Copyright for this paper by its authors.},
	author_keywords = {Knowledge Graph; Text Classification; Zero-Shot Learning},
	keywords = {Classification (of information); Domain Knowledge; Graphic methods; Natural language processing systems; Semantics; Text processing; Zero-shot learning; Class distributions; Domain-specific knowledge; External knowledge; Graph-based; Knowledge graphs; Knowledge-representation; Long tail; Specific class; Text classification; Training data; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 0}
}

@CONFERENCE{Logan20205962,
	author = {Logan, Robert L. and Liu, Nelson F. and Peters, Matthew E. and Gardner, Matt and Singh, Sameer},
	title = {Barack's wife Hillary: Using knowledge graphs for fact-aware language modeling},
	year = {2020},
	journal = {ACL 2019 - 57th Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference},
	pages = {5962 – 5971},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85084035303&partnerID=40&md5=bae32a9cf40bc8c2a3755d5922ecfdb9},
	abstract = {Modeling human language requires the ability to not only generate fluent text but also encode factual knowledge. However, traditional language models are only capable of remembering facts seen at training time, and often have difficulty recalling them. To address this, we introduce the knowledge graph language model (KGLM), a neural language model with mechanisms for selecting and copying facts from a knowledge graph that are relevant to the context. These mechanisms enable the model to render information it has never seen before, as well as generate out-of-vocabulary tokens. We also introduce the Linked WikiText-2 dataset,1 a corpus of annotated text aligned to the Wikidata knowledge graph whose contents (roughly) match the popular WikiText-2 benchmark (Merity et al., 2017). In experiments, we demonstrate that the KGLM achieves significantly better performance than a strong baseline language model. We additionally compare different language models' ability to complete sentences requiring factual knowledge, and show that the KGLM outperforms even very large language models in generating facts. © 2019 Association for Computational Linguistics},
	keywords = {Computational linguistics; Factual knowledge; Human language; Knowledge graphs; Language model; Training time; Modeling languages},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 109}
}

@CONFERENCE{Xing2021525,
	author = {Xing, Yiran and Shi, Zai and Meng, Zhao and Lakemeyer, Gerhard and Ma, Yunpu and Wattenhofer, Roger},
	title = {KM-BART: Knowledge enhanced multimodal BART for visual commonsense generation},
	year = {2021},
	journal = {ACL-IJCNLP 2021 - 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, Proceedings of the Conference},
	pages = {525 – 535},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85118931504&partnerID=40&md5=6ac5818aafafe229bb12cfbe8bfddc02},
	abstract = {We present Knowledge Enhanced Multimodal BART (KM-BART), which is a Transformer-based sequence-to-sequence model capable of reasoning about commonsense knowledge from multimodal inputs of images and texts. We adapt the generative BART architecture (Lewis et al., 2020) to a multimodal model with visual and textual inputs. We further develop novel pretraining tasks to improve the model performance on the Visual Commonsense Generation (VCG) task. In particular, our pretraining task of Knowledge-based Commonsense Generation (KCG) boosts model performance on the VCG task by leveraging commonsense knowledge from a large language model pretrained on external commonsense knowledge graphs. To the best of our knowledge, we are the first to propose a dedicated task for improving model performance on the VCG task. Experimental results show that our model reaches state-of-the-art performance on the VCG task (Park et al., 2020) by applying these novel pretraining tasks. © 2021 Association for Computational Linguistics},
	keywords = {Computational linguistics; Image enhancement; Knowledge based systems; Knowledge management; Commonsense knowledge; Knowledge based; Knowledge graphs; Language model; Modeling performance; Multi-modal; Multimodal inputs; Multimodal models; Pre-training; Sequence models; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 21}
}

@CONFERENCE{Moiseev20221581,
	author = {Moiseev, Fedor and Dong, Zhe and Alfonseca, Enrique and Jaggi, Martin},
	title = {SKILL: Structured Knowledge Infusion for Large Language Models},
	year = {2022},
	journal = {NAACL 2022 - 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Proceedings of the Conference},
	pages = {1581 – 1588},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85138332978&partnerID=40&md5=ec022641069053410f5fe5656b238e55},
	abstract = {Large language models (LLMs) have demonstrated human-level performance on a vast spectrum of natural language tasks. However, it is largely unexplored whether they can better internalize knowledge from a structured data, such as a knowledge graph, or from text. In this work, we propose a method to infuse structured knowledge into LLMs, by directly training T5 models on factual triples of knowledge graphs (KGs). We show that models pre-trained on Wikidata KG with our method outperform the T5 baselines on FreebaseQA and WikiHop, as well as the Wikidata-answerable subset of TriviaQA and NaturalQuestions. The models pre-trained on factual triples compare competitively with the ones on natural language sentences that contain the same knowledge. Trained on a smaller size KG, WikiMovies, we saw 3× improvement of exact match score on MetaQA task compared to T5 baseline. The proposed method has an advantage that no alignment between the knowledge graph and text corpus is required in curating training data. This makes our method particularly useful when working with industry-scale knowledge graphs. © 2022 Association for Computational Linguistics.},
	keywords = {Computational linguistics; Human-level performance; Knowledge graphs; Language model; Match score; Natural languages; Spectra's; Structured data; Structured knowledge; Text corpora; Training data; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 32}
}

@CONFERENCE{Ristoski202149,
	author = {Ristoski, Petar and Lin, Zhizhong and Zhou, Qunzhi},
	title = {KG-ZESHEL: Knowledge Graph-Enhanced Zero-Shot Entity Linking},
	year = {2021},
	journal = {K-CAP 2021 - Proceedings of the 11th Knowledge Capture Conference},
	pages = {49 – 56},
	doi = {10.1145/3460210.3493549},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85120850179&doi=10.1145%2f3460210.3493549&partnerID=40&md5=0aa3ed308343982493e30a91764c3db5},
	abstract = {Entity linking is a fundamental task for a successful use of knowledge graphs in many information systems. It maps textual mentions to their corresponding entities in a given knowledge graph. However, with the rapid evolution of knowledge graphs, a large number of entities is continuously added over time. Performing entity linking on new, or unseen, entities poses a great challenge, as standard entity linking approaches require large amounts of labeled data for all new entities, and the underlying model must be regularly updated. To address this challenge, several zero-shot entity linking approaches have been proposed, which don't require additional labeled data to perform entity linking over unseen entities and new domains. Most of these approaches use large language models, such as BERT, to encode the textual description of the mentions and entities in a common embedding space, which allows linking mentions to unseen entities. While such approaches have shown good performance, one big drawback is that they are not able to exploit the entity symbolic information from the knowledge graph, such as entity types, relations, popularity scores and graph embeddings. In this paper, we present KG-ZESHEL, a knowledge graph-enhanced zero-shot entity linking approach, which extends an existing BERT-based zero-shot entity linking approach with mention and entity auxiliary information. Experiments on two benchmark entity linking datasets, show that our proposed approach outperforms the related BERT-based state-of-the-art entity linking models.  © 2021 ACM.},
	author_keywords = {entity linking; knowledge graph; zero-shot learning},
	keywords = {Graph embeddings; Information use; Zero-shot learning; Embeddings; Entity linking; Entity-types; Graph embeddings; Knowledge graphs; Labeled data; Language model; Large amounts; Performance; Textual description; Knowledge graph},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 11}
}

@CONFERENCE{Chizhikova20224040,
	author = {Chizhikova, Anastasia and Murzakhmetov, Sanzhar and Serikov, Oleg and Shavrina, Tatiana and Burtsev, Mikhail},
	title = {Attention Understands Semantic Relations},
	year = {2022},
	journal = {2022 Language Resources and Evaluation Conference, LREC 2022},
	pages = {4040 – 4050},
	url = {https://www.scopus.com/inward/record.uri?eid=2-s2.0-85144341878&partnerID=40&md5=8e9ab0e2b9708c47b3448aae0cfa3fdb},
	abstract = {Today, natural language processing heavily relies on pre-trained large language models. Even though such models are criticised for poor interpretability, they still yield state-of-the-art solutions for a wide range of very different tasks. While many probing studies have been conducted to measure the models awareness of grammatical knowledge, semantic probing is less popular. In this work, we introduce a probing pipeline to study how semantic relations are represented in transformer language models. We show that in this task, attention scores express the information about relations similar to the layers' output activations despite their lesser ability to represent surface cues. This supports the hypothesis that attention mechanisms focus not only on syntactic relational information but semantic as well. © European Language Resources Association (ELRA), licensed under CC-BY-NC-4.0.},
	author_keywords = {bertology; explainable AI (XAI); knowledge probing; language models interpretation; ontology extraction; semantic probing},
	keywords = {Artificial intelligence; Computational linguistics; Natural language processing systems; Bertology; Explainable AI (XAI); Knowledge probing; Language model; Language model interpretation; Model interpretations; Natural languages; Ontology Extraction; Semantic probing; Semantic relations; Semantics},
	type = {Conference paper},
	publication_stage = {Final},
	source = {Scopus},
	note = {Cited by: 3}
}
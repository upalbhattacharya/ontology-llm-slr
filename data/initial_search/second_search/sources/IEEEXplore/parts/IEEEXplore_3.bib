@ARTICLE{10367969,
  author={Fatemi, Bahareh and Rabbi, Fazle and Opdahl, Andreas L.},
  journal={IEEE Access}, 
  title={Evaluating the Effectiveness of GPT Large Language Model for News Classification in the IPTC News Ontology}, 
  year={2023},
  volume={11},
  number={},
  pages={145386-145394},
  abstract={News classification plays a vital role in newsrooms, as it involves the time-consuming task of categorizing news articles and requires domain knowledge. Effective news classification is essential for categorizing and organizing a constant flow of information, serving as the foundation for subsequent tasks, such as news aggregation, monitoring, filtering, and organization. The automation of this process can significantly benefit newsrooms by saving time and resources. In this study, we explore the potential of the GPT large language model in a zero-shot setting for multi-class classification of news articles within the widely accepted International Press Telecommunications Council (IPTC) news ontology. The IPTC news ontology provides a structured framework for categorizing news, facilitating the efficient organization and retrieval of news content. By investigating the effectiveness of the GPT language model in this classification task, we aimed to understand its capabilities and potential applications in the news domain. This study was conducted as part of our ongoing research in the field of automated journalism.},
  keywords={Task analysis;Annotations;Ontologies;Adaptation models;Tag clouds;Support vector machines;Sports;IPTC media topics;journalism;large language models;news classification},
  doi={10.1109/ACCESS.2023.3345414},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{9980157,
  author={Vasantharajan, Charangan and Tun, Kyaw Zin and Thi-Nga, Ho and Jain, Sparsh and Rong, Tong and Siong, Chng Eng},
  booktitle={2022 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)}, 
  title={MedBERT: A Pre-trained Language Model for Biomedical Named Entity Recognition}, 
  year={2022},
  volume={},
  number={},
  pages={1482-1488},
  abstract={This paper introduces MedBERT, a new pre-trained transformer-based model for biomedical named entity recognition. MedBERT is trained with 57.46M tokens collected from biomedical-related data sources, i.e. datasets acquired from N2C2, BioNLP, CRAFT challenges, and biomedical-related articles crawled from Wikipedia. We validate the effectiveness of MedBERT by comparing it with four publicly available pre-trained models on ten biomedical datasets from BioNLP and CRAFT shared tasks. Our experimental results show that models fine-tuned on MedBERT achieve state-of-the-art performance in nine datasets that predict Protein, Gene, Chemical, Cellular/Component, Gene Ontology, and Taxonomy entities. Specifically, the model achieved an average of 84.04% F1-micro score on ten test sets from BioNLP and CRAFT challenges with an improvement of 3.7% and 7.83% as compared to models that were fine-tuned on BioBERT and Bio_ClinicalBERT, respectively.},
  keywords={Proteins;Protein engineering;Biological system modeling;Taxonomy;Predictive models;Ontologies;Transformers},
  doi={10.23919/APSIPAASC55919.2022.9980157},
  ISSN={2640-0103},
  month={Nov},}@ARTICLE{10623627,
  author={Bahaj, Adil and Ghogho, Mounir},
  journal={IEEE Access}, 
  title={Uncertain Knowledge Graph Embedding Using Auxiliary Information}, 
  year={2024},
  volume={12},
  number={},
  pages={138351-138361},
  abstract={Uncertain knowledge graphs (UKGs) offer a more realistic representation of knowledge by capturing the uncertainty associated with facts. However, existing UKG embedding methods primarily rely on structural information for confidence score prediction, neglecting other sources of uncertainty. This paper investigates the effectiveness of incorporating auxiliary information into UKG embeddings. We propose two approaches: Text-BEUrRE, which leverages textual information, and UCompGCN, which utilizes topological information. Our extensive experiments demonstrate that both methods successfully integrate these auxiliary data sources. Notably, Text-BEUrRE and UCompGCN outperform state-of-the-art baselines on most metrics in the confidence prediction task. On the CN15K dataset, Text-BEUrRE achieves a 7.39% improvement in Mean Squared Error (MSE) compared to the best existing model, while UCompGCN achieves an 8.27% improvement in Mean Absolute Error (MAE).},
  keywords={Semantics;Knowledge graphs;Task analysis;Uncertainty;Training;Computational modeling;Adaptation models;Predictive models;Uncertain knowledge graphs;knowledge graph embedding;box embedding;confidence prediction},
  doi={10.1109/ACCESS.2024.3439610},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10513309,
  author={Zhang, Chenchen and Jian, Sun and Chao, Luo and Fan, Chen and Bo, Li and Chen, Luo},
  booktitle={2023 IEEE 7th Conference on Energy Internet and Energy System Integration (EI2)}, 
  title={A Semantic Understanding Method for Patent Text Based on Large Language Model}, 
  year={2023},
  volume={},
  number={},
  pages={2179-2182},
  abstract={The large language model has powerful natural language understanding and generation capabilities, which can automatically extract keywords and key information from literature, thus achieving fast and efficient patent retrieval. At the same time, the large model can also be customized according to user needs, improving retrieval accuracy and efficiency. A semantic understanding method for patent text based on large language model is proposed in this paper. This method first requires preprocessing of the dataset, inputting the problem into ChatGPT according to the specified instruction format, and then classifying the output content for analysis based on different classifications. Then, the entity recognition results are input into the patent system, and the knowledge graph in the patent system is used for inference analysis to obtain the corresponding answer to the problem. The research results show that the method based on the large language model has high accuracy and generalization ability, and can achieve semantic understanding and analysis of patent texts.},
  keywords={Patents;Technological innovation;Semantics;Data preprocessing;Energy Internet;System integration;Knowledge graphs;large language models;patent text;semantic understanding;ChatGPT},
  doi={10.1109/EI259745.2023.10513309},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10605700,
  author={Safronov, Artyom A.},
  booktitle={2024 4th International Conference on Technology Enhanced Learning in Higher Education (TELE)}, 
  title={Using Neural Networks in Building an Ontology of Educational Subjects for Solving Educational Tasks}, 
  year={2024},
  volume={},
  number={},
  pages={189-191},
  abstract={In the modern world, information technologies have become an integral part of a human life, including the professional level. The rapid development of technologies based on artificial intelligence over the past few years has opened up new opportunities for their application in solving various educational tasks. One of the relevant topics for study is the investigation of ontological constructs in texts, identifying the terminology of concepts and determining the relationships between them. This article is dedicated to studying artificial intelligence systems as a tool for solving educational process tasks: it proposes the use of chatbots based on AI systems in conjunction with various digital tools in researching ontological constructs in educational texts. As part of the research, an example is provided with the processing an educational text on mathematics. Methodological characteristics are considered and a model for researching educational text using the ChatGPT is briefly described. Conclusions are drawn about the existing possibilities and difficulties in implementing the aforementioned model.},
  keywords={Systematics;Terminology;Neural networks;Chatbots;Educational courses;Mathematical models;Thesauri;artificial intelligence systems;ontology;thesaurus;chatbot;educational texts;digital tools},
  doi={10.1109/TELE62556.2024.10605700},
  ISSN={},
  month={June},}@INPROCEEDINGS{10466986,
  author={Du, Zhihong and Xu, Duo and Huang, Danruo and Hu, Yuren and He, Keqing and Wang, Chong and Wang, Jian and Zhang, Hong-Yu and Mayer, Wolfgang and Duan, Yucong and Wang, Ying and Feng, Zaiwen},
  booktitle={2023 IEEE International Conference on High Performance Computing & Communications, Data Science & Systems, Smart City & Dependability in Sensor, Cloud & Big Data Systems & Application (HPCC/DSS/SmartCity/DependSys)}, 
  title={An Ontology-based Method for Heterogeneous Data Governance with MFI and MDR}, 
  year={2023},
  volume={},
  number={},
  pages={1106-1113},
  abstract={Currently, data governance and integration in the fields are hindered by semantic ambiguity and syntactic inconsistencies among different sub domain data and models, making it difficult to use these valuable data for further application and research jointly. Therefore, it is necessary to unify and integrate existing metadata and meta-models more effectively for information resource sharing and interoperability in the field. This paper proposes an ontology-based approach with a hybrid ISO/IEC 11179 (MDR) and ISO/IEC 19763 (MFI) framework for data governance and integration. This framework takes a Global Ontology Model (GOM) constructed for the global domain as a bridge and basis for integrating and aligning heterogeneous sub domains. It extends MDR by adding ontology registration items to implement the mapping between the GOM and multiple subdomains, thereby promoting the semantic sharing of metadata between subdomains. In addition, the MFI-12 and MFI-10 are used to solve the model interoperability between different subdomains. A detailed case study is provided to illustrate the concrete registration process and demonstrate the validity of our method.},
  keywords={Information resources;ISO Standards;Semantics;Standardization;Metadata;Ontologies;Syntactics;Ontology;MDR;MFI;Data Governance;Data Standardization},
  doi={10.1109/HPCC-DSS-SmartCity-DependSys60770.2023.00158},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{8934256,
  author={Bikmullina, I. and Barkov, I.},
  booktitle={2019 International Multi-Conference on Industrial Engineering and Modern Technologies (FarEastCon)}, 
  title={Instrumentation and Control System for Test Bench}, 
  year={2019},
  volume={},
  number={},
  pages={1-6},
  abstract={The main problem of the article is the lack of automated structural synthesis of information systems based on the semantic relations of subject area. As presented in the article, in technology creation software system expert developing the domain ontology with help user-friendly the program interfaces. This program is a mechanism for automatically formalizing domain description and automatically synthesizing the class diagram in the Unified Modeling Language. In the article discusses the method for automatic design based on automated synthesis of Unified Modeling Language models of the application program to control the test stand. The method of its use in solving the problems of designing an instrumentation and control system for test bench of an unmanned aerial vehicle is described. Expert inputs a domain ontology, then system automatically formalizes domain description and synthesizes the class diagram in the Unified Modeling Language.},
  keywords={Unified modeling language;Software systems;Semantics;Ontologies;Information systems;Complexity theory;Industrial engineering;UML;synthesis of class diagrams;ontology;domain;an unmanned aerial vehicle},
  doi={10.1109/FarEastCon.2019.8934256},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{8549977,
  author={Albab, Muhammad Ulil and Arman, Arry Akhmad},
  booktitle={2018 International Conference on ICT for Smart Society (ICISS)}, 
  title={Resource-Based and Value-Based Extension for Archimate}, 
  year={2018},
  volume={},
  number={},
  pages={1-6},
  abstract={The concept of resource and value in the archimate that is too general allows for modeling and communication problems. Therefore, an ontological analysis is needed to evaluate and redesign the concept of resource and value on the archimate. In this paper, Unified foundational ontology (UFO) is used in conducting an ontological analysis on the concept of resource and value. An ontological analysis is done by considering the mapping between the concept on Archimate and ontology concept on UFO. Semantic problems in resource and value concepts are found when the ontological analysis is performed. The result of this study is Archimate extension with the improvement of resource and value concept. The resulting extension was successfully applied in case studies and was able to handle semantic problems that were identified.},
  keywords={Ontologies;Semantics;Business;Analytical models;Electrical engineering;Informatics;Information technology;resource;value;enterprise architecture modeling;ontology-based semantics;Archimate},
  doi={10.1109/ICTSS.2018.8549977},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10772514,
  author={Li, Yi and Tian, Liwei and Yi, Chengyi and Li, Jingjing and Qin, Xiaodong and He, Yuxuan and Su, Huai},
  booktitle={2024 6th International Conference on System Reliability and Safety Engineering (SRSE)}, 
  title={A Large Language Model Based Knowledge Mining Method for Improving the Reliability of Fire Water Systems}, 
  year={2024},
  volume={},
  number={},
  pages={410-413},
  abstract={The fire water system plays a critical role in protecting both infrastructure and human lives. An essential aspect of enhancing the reliability of this system is fault diagnosis. However, the current fault diagnosis methods primarily rely on data-driven approaches, which often result in a high threshold for application due to their lack of interpretability. To tackle this challenge, this paper introduces a novel approach based on large language models for knowledge mining from textual data to extract fault information related to the fire water system, thereby enhancing the interpretability of data-driven fault diagnosis methods. The methodology followed in this paper consists of two main steps: firstly, analyzing the characteristics and principles of fire water system faults to develop a fault ontology, and secondly, creating a knowledge mining model using a large language model guided by the established fault ontology. Experimental findings indicate that the proposed model achieves an F1 score of 0.944, meeting the necessary criteria for effective knowledge mining in fire water system fault analysis. Furthermore, a comparative experiment was conducted to evaluate the performance of various encoder models, including GRU, BiGRU, LSTM, BiLSTM, and pre-trained large language model BERT. The results revealed a significant improvement in performance with the BERT encoder, showing increases in F1 scores of $22.12 \%$, $2.27 \%, 17.41 \%$, and $3.16 \%$ compared to the other models, respectively. This study provides valuable interpretative insights that can enhance the engineering applicability and reliability of data-driven fault diagnosis methods in fire water system.},
  keywords={Fault diagnosis;Water;Analytical models;Accuracy;Large language models;Bidirectional control;Ontologies;Reliability engineering;Encoding;Data mining;large language model;system reliability;fire water system;safety engineering;knowledge mining},
  doi={10.1109/SRSE63568.2024.10772514},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10818303,
  author={Anaguchi, Fumikatsu and Chakraborty, Sudesna and Morita, Takeshi and Egami, Shusaku and Ugai, Takanori and Fukuda, Ken},
  booktitle={2024 Twelfth International Symposium on Computing and Networking (CANDAR)}, 
  title={Reasoning and Justification System for Domestic Hazardous Behaviors Based on Knowledge Graph of Daily Activities and Retrieval-Augmented Generation}, 
  year={2024},
  volume={},
  number={},
  pages={11-20},
  abstract={Accidents among people over 65 years of age predominantly occur within residential settings, making the maintenance of a safe home environment a crucial social issue. To address this issue, previous research has developed systems that construct Knowledge Graphs (KG) based on simulations of daily household activities, and studies have been conducted on detecting hazardous behaviors using such KG analysis. In this current study, we propose a system capable of presenting the reason and justification for the detected domestic hazardous behaviors. Our system will first generates the reason for the detected behavior using a Large Language Model (LLM). To ensure the accuracy, reliability and reproducibility of the LLM output, the system will provides reliable sources to support the output. We employed Retrieval-Augmented Generation (RAG) to search for sentences similar to the reason generated by the LLM within reliable, authoritative documents describing domestic accident cases and their causes and these will be presented as the evidence alongside the search engine results to the users. Consequently, a knowledge graph (KG) of domestic hazardous behavior is developed based on evidence ontology. Finally, to evaluate the ability of our proposed system in appropriately generating reasons for domestic hazardous behaviors and the adequacy of the justifications provided, the output was rated using LLMs and human volunteers. The rating results showed a significant correlation between LLMs and human evaluation, indicating that the proposed system can provide sufficient reasons and justifications for domestic hazardous behaviors at residential setting.},
  keywords={Correlation;Retrieval augmented generation;Knowledge graphs;Search engines;Ontologies;Reproducibility of results;Behavioral sciences;Sensors;Optimization;Accidents;Retrieval-Augmented Generation;Large Language Model;Explainable AI;Knowledge Graph},
  doi={10.1109/CANDAR64496.2024.00010},
  ISSN={2379-1896},
  month={Nov},}@INPROCEEDINGS{10773450,
  author={Kömeçoğlu, Başak Buluz and Yılmaz, Burcu},
  booktitle={2024 9th International Conference on Computer Science and Engineering (UBMK)}, 
  title={Knowledge-Augmented Large Language Model Prompting for Cypher Query Construction}, 
  year={2024},
  volume={},
  number={},
  pages={187-192},
  abstract={While existing large language models demonstrate remarkable proficiency inn a turall a nguage processing tasks, their capacity for knowledge graph structuring remains a potential avenue for enhancement, particularly in the context of knowledge graph question answering. This paper presents a novel method for knowledge-enriched LLM routing for the construction of Cypher queries utilising knowledge graphs. It is proposed that the prompts of LLMs be enriched with knowledge by the addition of relevant triples taken from the knowledge graph. The proposed method facilitates the generation of more precise and pertinent Cypher queries by LLMs, thereby enhancing their question-answering capabilities. The method is evaluated using a story-based knowledge graph question answering dataset, which is introduced in this paper as a new contribution to the literature. The results demonstrate that the incorporation of knowledge enhances the performance of knowledge graph question answering (KGQA), particularly in the context of complex and temporal inquiries. Furthermore, the utilisation of a story graph structure for the modelling of events in news texts facilitates the effective resolution of complex questions by following the paths on the graph. Finally, it is demonstrated that the extraction of temporal labels and their incorporation into the knowledge graph is of paramount importance in answering temporal questions.},
  keywords={Knowledge engineering;Computer science;Ciphers;Large language models;Computational modeling;Knowledge graphs;Routing;Question answering (information retrieval);knowledge graph;prompt engineering;language model;question answering;natural language processing},
  doi={10.1109/UBMK63289.2024.10773450},
  ISSN={2521-1641},
  month={Oct},}@INPROCEEDINGS{9204062,
  author={Zhu, Mingda and Xue, Jiqing and Zhou, Gaoyuan},
  booktitle={2020 12th International Conference on Intelligent Human-Machine Systems and Cybernetics (IHMSC)}, 
  title={Joint Extraction of Entity and Relation Based on Pre-trained Language Model}, 
  year={2020},
  volume={2},
  number={},
  pages={179-183},
  abstract={Extracting entities and relations from unstructured text is the key to building a large-scale knowledge graph. In recent years, the relation extraction approaches based on the neural network has achieved good results. However, the existing methods cannot accurately extract overlapping entities (i.e., one entity is shared by multiple relations). In this paper, we propose a simple Electra-based joint model for relation extraction. We use the subject extractor to identify the subject first, and then use the predicate-object extractor to predict its corresponding predicates and objects based on the encoded representation vector of the detected subject. Experiments on DuIE2.0 show good performance on the extraction of Chinese dataset with overlapping triples.},
  keywords={Conferences;Man-machine systems;Cybernetics;Erbium;component;joint extraction of entities and relations;overlapping triples;ELECTRA;tagging scheme},
  doi={10.1109/IHMSC49165.2020.10119},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10835639,
  author={Garza, Leon and Elluri, Lavanya and Piplai, Aritran and Kotal, Anantaa and Gupta, Deepti and Joshi, Anupam},
  booktitle={2024 IEEE 6th International Conference on Trust, Privacy and Security in Intelligent Systems, and Applications (TPS-ISA)}, 
  title={PrivComp-KG: Leveraging KG and LLM for Compliance Verification}, 
  year={2024},
  volume={},
  number={},
  pages={97-106},
  abstract={Regulatory documents are complex and lengthy, making full compliance a challenging task for businesses. Similarly, privacy policies provided by vendors frequently fall short of the necessary legal standards due to insufficient detail. To address these issues, we propose a solution that leverages a Large Language Model (LLM) in combination with Semantic Web technology. This approach aims to clarify regulatory requirements and ensure that organizations’ privacy policies align with the relevant legal frameworks, ultimately simplifying the compliance process, reducing privacy risks, and improving efficiency. In this paper, we introduce a novel tool, the Privacy Policy Compliance Verification Knowledge Graph, referred to as PrivComp-KG. PrivComp-KG is designed to efficiently store and retrieve comprehensive information related to privacy policies, regulatory frameworks, and domain-specific legal knowledge. By utilizing LLM and Retrieval Augmented Generation (RAG), we can accurately identify relevant sections in privacy policies and map them to the corresponding regulatory rules. Our LLM-based retrieval system has demonstrated a high level of accuracy, achieving a correctness score of 0.9, outperforming other models in privacy policy analysis. The extracted information from individual privacy policies is then integrated into the PrivComp-KG. By combining this data with contextual domain knowledge and regulatory rules, PrivComp-KG can be queried to assess each vendor’s compliance with applicable regulations. We demonstrate the practical utility of PrivComp-KG by verifying the compliance of privacy policies across various organizations. This approach not only helps policy writers better understand legal requirements but also enables them to identify gaps in existing policies and update them in response to evolving regulations.},
  keywords={Semantic Web;Privacy;Law;Large language models;Retrieval augmented generation;Standards organizations;Organizations;Knowledge graphs;Regulation;Security;Privacy Policy;Policy Compliance;Large Language Model;Knowledge Graph},
  doi={10.1109/TPS-ISA62245.2024.00021},
  ISSN={},
  month={Oct},}@ARTICLE{10836698,
  author={Phan, Truong H. V. and do, Phuc},
  journal={IEEE Access}, 
  title={QUERY2BERT: Combining Knowledge Graph and Language Model for Reasoning on Logical Queries}, 
  year={2025},
  volume={13},
  number={},
  pages={16103-16119},
  abstract={Answering logical questions with a knowledge graph has been a critical research focus because this needs to reason and synthesize information. Previous studies have mainly dealt with logical operations using graph embedding techniques, such as conjunctions, disjunctions, and negation. However, these studies have neither effectively organized the data to retrieve multi-hop reasoning quickly nor combined text description to enhance logical operations’ semantics. Our study introduces a model called QUERY2BERT, which solves two of the above limitations. Specifically, QUERY2BERT first combined the node2vec and the BERT models to embed a knowledge graph with description information of every entity. Then, embedded nodes were indexed with a K-D tree structure. Finally, we used nearest neighbor search on K-D tree to retrieve neighbor-embedded nodes and implemented logical operations like projection, intersection, union, and negation to find answers to complex questions. We tested our model on three benchmark knowledge graph datasets and showed that QUERY2BERT significantly improved accuracy and speed compared to other state-of-the-art models.},
  keywords={Knowledge graphs;Cognition;Semantics;Vectors;Computational modeling;Logic;Encoding;Transforms;Question answering (information retrieval);Knowledge based systems;BERT;K-D tree;k-NN;knowledge graph embedding;multi-hop reasoning;logical query},
  doi={10.1109/ACCESS.2025.3528097},
  ISSN={2169-3536},
  month={},}@ARTICLE{10552698,
  author={Larhrib, Mohamed and Escribano, Miguel and Cerrada, Carlos and Escribano, Juan Jose},
  journal={IEEE Access}, 
  title={An Ontological Behavioral Modeling Approach With SHACL, SPARQL, and RDF Applied to Smart Grids}, 
  year={2024},
  volume={12},
  number={},
  pages={82041-82056},
  abstract={Every engineering process, especially software, involves two complementary aspects: structural and behavioral. Behavior is, in essence, transforming the structure associated with the system. As a language for the object-oriented paradigm, Unified Modeling Language (UML) offers constructs for both aspects, for example, class diagrams for the structural aspect and activity diagrams for the behavioral aspect. However, without obtaining directly executable models, in glass-box terms, or reasoning support, on the other hand, when software engineering is approached with ontologies, only constructs for structural aspects are provided to develop a directly executable model, thanks to their reasoning capability. However, there are no constructs or approaches for this paradigm’s specification or definition of behavior. This lack appears mainly in the early stages of the software engineering process, where there are no constructs similar to, e.g., the activity diagram in the object-oriented domain. Object Management Group (OMG) already addressed the transformation between the two paradigms in structural terms throughout Ontology Definition Metamodel (ODM) from UML to Resource Description Framework (RDF) and Web Ontology Language (OWL). However, there is no transformation of the object-oriented behavioral constructs into ontologies because they are not defined in the ontological paradigm. This paper addresses the definition of behavior in the ontology paradigm and the transformation of behavioral constructs between the two paradigms. The foundation of behavior specification is the flow concept, and the basis of this is the transformation of the structural model in an evaluative sense. Therefore, once the behavior has been defined in the ontology domain, the artifacts obtained throughout the life cycle are directly executable, and their validation and testing are automatic. With this approach, the life cycle is reduced to a modeling process. Thus, the resulting software engineering process improves features such as agility, simplicity, productivity, and formalism. The target audience for this work is the software engineering community, especially in the Model-Driven Engineering (MDE) paradigm approached from object-oriented and ontology perspectives. The evaluation of the proposed approach has been performed in the electric utilities, solving the problem of the validation flow for the interoperability process specified by the Common Grid Model Exchange Standard (CGMES) standard.},
  keywords={Unified modeling language;Ontologies;Object oriented modeling;Resource description framework;Software engineering;OWL;Cognition;Behavioral sciences;Behavioral modeling;CIM for ENTSO-E (CGMES);directly executable;ontology RDF/RDFS/OWL/SHACL},
  doi={10.1109/ACCESS.2024.3412656},
  ISSN={2169-3536},
  month={},}@ARTICLE{8502923,
  author={Halawi, Bahia and Mourad, Azzam and Otrok, Hadi and Damiani, Ernesto},
  journal={IEEE Access}, 
  title={Few are as Good as Many: An Ontology-Based Tweet Spam Detection Approach}, 
  year={2018},
  volume={6},
  number={},
  pages={63890-63904},
  abstract={Due to the high popularity of Twitter, spammers tend to favor its use in spreading their commercial messages. In the context of detecting twitter spams, different statistical and behavioral analysis approaches were proposed. However, these techniques suffer from many limitations due to: 1) ongoing changes to Twitter's streaming API which constrains access to a user's list of followers/followees; 2) spammer's creativity in building diverse messages; 3) use of embedded links and new accounts; and 4) need for analyzing different characteristics about users without their consent. To address the aforementioned challenges, we propose a novel ontology-based approach for spam detection over Twitter during events by analyzing the relationship between ham user tweets versus spams. Our approach relies solely on public tweet messages while performing the analysis and classification tasks. In this context, ontologies are derived and used to generate a dictionary that validates real tweet messages from random topics. Similarity ratio among the dictionary and tweets is used to reflect the legitimacy of the messages. Experiments conducted on real tweet data illustrate that message-to-message techniques achieved a low detection rate compared with our ontology-based approach which outperforms them by approximately 200%, in addition to promising scalability for large data analysis.},
  keywords={Twitter;Ontologies;Electronic mail;Feature extraction;Uniform resource locators;Tagging;Analytical models;Twitter;meta-data;spam detection;text based analysis;event spammers;ontology},
  doi={10.1109/ACCESS.2018.2877685},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10296153,
  author={Elkodssi, Iman and Sbai, Hanae},
  booktitle={2023 International Conference on Digital Age & Technological Advances for Sustainable Development (ICDATA)}, 
  title={Toward Semantic Framework for Internet of Things-Aware Business Process Discovery}, 
  year={2023},
  volume={},
  number={},
  pages={12-16},
  abstract={The Internet of Things (IoT) is often considered a disruptive technology [1]. By using smart devices, it has the potential to change everyone's daily life. With large sets of advanced sensors and actuators, it can create opportunities for commercial organizations to establish new business models. A fundamental barrier to automatic business process sensing is the lack of modeling concepts that explicitly express Internet elements as components of a business process model. Thus, there is a clear need to model these processes associated with IoT elements in a formal and unambiguous manner. However, in the context of business processes, there is a lack of formalized and explicit descriptions of IoT elements, which hinders their effective modeling and management. This article proposes a semantic formalization of the business process management perspective in an IoT environment by proposing Extended BPMNO for IoT and Domain Ontology. It uses standard semantic technologies to give a semantic representation that allows us to describe concepts relating to the IoT and the elements of an executable business process described in BPMN.},
  keywords={Annotations;Semantics;Ontologies;Data models;Business process management;Internet of Things;Sustainable development;Business Process Management Notation (BPMN);IoT element;The IoT-aware BP;Ontology},
  doi={10.1109/ICDATA58816.2023.00012},
  ISSN={},
  month={May},}@INPROCEEDINGS{10779814,
  author={Zhao, Xinke and Yilahun, Hankiz and Hamdulla, Askar},
  booktitle={2024 IEEE 5th International Conference on Pattern Recognition and Machine Learning (PRML)}, 
  title={Text-to-CQL Based on Large Language Model and Graph Pattern Enhancement}, 
  year={2024},
  volume={},
  number={},
  pages={114-119},
  abstract={With the wide application of knowledge graphs in various scenarios and Neo4j graph databases becoming excellent knowledge graph carriers, Cypher (CQL for short) has become the most popular graph database query language. However, when performing graph database retrieval, the complex pattern and syntax make constructing CQL statements a complicated and time-consuming task. Therefore, similar to Text-to-SQL, it is necessary and urgent to study an effective method for end-to-end transformation of natural languages into CQL. There have been many advances in Text-to-SQL for traditional relational databases, but these methods cannot be well applied to Text-to-CQL, so there is still a lack of effective work on Text-to-CQL for graph databases. In recent years, as large language models have been widely applied to different tasks with good results, and considering that the fundamental difference between CQL and SQL is the representation of graph patterns. We propose in this paper PA-LLM, a Text-to-CQL method that utilizes large language models combined with graph patterns enhancement, which combines large language models and subdivides the graph patterns into three categories according to their respective characteristics. They are simple query patterns, multi-hop query patterns, and function query patterns. For different graph patterns, the method optimizes the process of generating CQL for the model, which can be subdivided into four sub-methods, simple pattern enhancement method, multi-hop pattern enhancement method, function pattern enhancement method, and entity-relationship enhancement method. The experimental results show that the method improves the quality of the CQL statements generated by the model, including the logical accuracy ACCLX and the execution result accuracy ACCEX, and achieves better results on the SpCQL dataset proposed by the National Defense University of Science and Technology (NDUST). It provides an effective solution for the task of converting CQL to natural language end-to-end.},
  keywords={Structured Query Language;Accuracy;Quantization (signal);Large language models;Natural languages;Knowledge graphs;Relational databases;Syntactics;Real-time systems;Pattern recognition;Knowledge graph;Neo4j;Text-to-CQL;ChatGLM;Graph patterns enhancement},
  doi={10.1109/PRML62565.2024.10779814},
  ISSN={},
  month={July},}@INPROCEEDINGS{10677303,
  author={Gupta, Pranav and Sharma, Raunak and Kumari, Rashmi and Aditya, Sri Krishna and Choudhary, Shwetank and Kumar, Sumit and M, Kanchana and R, Thilagavathy},
  booktitle={2024 IEEE International Conference on Electronics, Computing and Communication Technologies (CONECCT)}, 
  title={ECHO: Environmental Sound Classification with Hierarchical Ontology-guided Semi-Supervised Learning}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={Environment Sound Classification has been a well-studied research problem in the field of signal processing and till now more focus has been laid on fully supervised approaches. Recently, the focus has moved towards semi-supervised methods which concentrate on utilizing unlabeled data, and self-supervised methods which learn the intermediate representation through pretext tasks or contrastive learning. However, both approaches require a vast amount of unlabelled data to improve performance. In this work, we propose a novel framework called Environmental Sound Classification with Hierarchical Ontology-guided semi-supervised Learning (ECHO) that utilizes label ontology-based hierarchy to learn semantic representation by defining a novel pretext task. The model tries to predict coarse labels represented by the Large Language Model (LLM) based on ground truth label ontology, then further fine-tuned in a supervised way to predict the actual task. ECHO achieves a 1% to 8% accuracy improvement over baseline systems across UrbanSound8K, ESC-10, and ESC-50 datasets.},
  keywords={Accuracy;Large language models;Semantics;Contrastive learning;Ontologies;Semisupervised learning;Signal processing;semi-supervised learning;Environment Sound Classification;Label ontology},
  doi={10.1109/CONECCT62155.2024.10677303},
  ISSN={2766-2101},
  month={July},}@INPROCEEDINGS{10065877,
  author={Hu, Yaxuan and Xu, Weizhi and Liu, Qiang and Wang, Liping and Wu, Shu},
  booktitle={2022 IEEE 8th International Conference on Computer and Communications (ICCC)}, 
  title={Can Pretrained Language Models Reason on Sparse Commonsense Knowledge Graph?}, 
  year={2022},
  volume={},
  number={},
  pages={2016-2022},
  abstract={Commonsense knowledge is the knowledge shared by most humans, which is always stored in commonsense knowledge graph (CKG) as triplets. In this paper, we focus on the task of CKG competition, whose target is to predict the tail (head) target given the head (tail) entity and the relation. Most existing works employ the graph-based models, which aggregate information from neighboring entities on CKG. Despite their effectiveness, they still suffer from two main weaknesses. Firstly, the semantic relations between head and tail entities are neglected. Secondly, due to the sparsity of CKG, they rely on the graph densification that it will bring unexpected noises. To solve these problems, we propose a unified framework for COmmonSense knowledge graph completion based on BERT, namely COS-BERT. Firstly, we transfer each triplet into a natural sentence. Then, we fine-tune the pretrained language model using the transformed sentences. Finally, we rank the candidates based on the output representation of sentences. Furthermore, we add a pre-filter to obtain a subset of candidates on the inference stage to save unnecessary computation costs. Comprehensive experiments have demonstrated the superiority of COS-BERT over the state-of-the-arts.},
  keywords={Costs;Computational modeling;Aggregates;Semantics;Bit error rate;Tail;Task analysis;commonsense reasoning;pretrained language model},
  doi={10.1109/ICCC56324.2022.10065877},
  ISSN={},
  month={Dec},}@ARTICLE{10766600,
  author={Zhang, Ying and Shen, Yangpeng and Xiao, Gang and Peng, Jinghui},
  journal={IEEE Access}, 
  title={Leveraging Non-Parametric Reasoning With Large Language Models for Enhanced Knowledge Graph Completion}, 
  year={2024},
  volume={12},
  number={},
  pages={177012-177027},
  abstract={The completeness of knowledge graphs is critical to their effectiveness across various applications. However, existing knowledge graph completion methods face challenges such as difficulty in adapting to new entity information, parameter explosion, and limited generalization capability. To address these issues, this paper proposes a knowledge graph completion framework that integrates large language models with case-based reasoning (CBR-LLM). By combining non-parametric reasoning with the semantic understanding capabilities of large language models, the framework not only improves completion accuracy but also significantly enhances generalization under various data-missing scenarios. Experimental results demonstrate that CBR-LLM excels in handling complex reasoning tasks and large-scale data-missing scenarios, providing an efficient and scalable solution for knowledge graph completion.},
  keywords={Knowledge graphs;Cognition;Accuracy;Computational modeling;Data models;Semantics;Large language models;Training;User experience;Tail;Case-based reasoning;large language model;information entropy;knowledge graph completion},
  doi={10.1109/ACCESS.2024.3505433},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{9689347,
  author={Tseng, Wan-Ting and Wu, Chin-Ying and Hsu, Yung-Chang and Chen, Berlin},
  booktitle={2021 Asia-Pacific Signal and Information Processing Association Annual Summit and Conference (APSIPA ASC)}, 
  title={FAQ Retrieval using Question-Aware Graph Convolutional Network and Contextualized Language Model}, 
  year={2021},
  volume={},
  number={},
  pages={2006-2012},
  abstract={Frequently asked question (FAQ) retrieval, which seeks to provide the most relevant question, or question-answer (QA) pair, in response to a user's query, has found its applications in widespread use cases. More recently, methods based on bidirectional encoder representations from Transformers (BERT) and its variants, which typically take the word embeddings of a question in training time (or query in test time) as the input to predict relevant answers, have shown good promise for FAQ retrieval. However, these BERT-based methods do not pay enough attention to the global information specifically about an FAQ task. To cater for this, we in this paper put forward a question-aware graph convolutional network (QGCN) to induce vector embeddings of vocabulary words, thereby encapsulating the global question-question, question-word and word-word relations which can be used to augment the embeddings derived from BERT for better F AQ retrieval. Meanwhile, we also investigate leverage domain-specific knowledge graphs to enrich the question and query embeddings (denoted by K-BERT). Finally, we conduct extensive experiments to evaluate the utility of the proposed approaches on two publicly-available FAQ datasets (viz. TaipeiQA and StackF AQ), where the associated results confirm the promising efficacy of the proposed approach in comparison to some top-of-the-line methods.},
  keywords={Training;Vocabulary;Convolution;Bit error rate;Information processing;Transformers;Task analysis;Frequently Asked Question;Graph Convolutional Networks;knowledge graph;language model},
  doi={},
  ISSN={2640-0103},
  month={Dec},}@INPROCEEDINGS{10650745,
  author={Jian, Zhaorui and Liu, Shengquan and Gao, Wei and Cheng, Jianming},
  booktitle={2024 International Joint Conference on Neural Networks (IJCNN)}, 
  title={Distantly Supervised Relation Extraction based on Non-taxonomic Relation and Self-Optimization}, 
  year={2024},
  volume={},
  number={},
  pages={1-9},
  abstract={Distantly supervised relation extraction (DS-RE) leverages existing knowledge bases to generate annotated data for relation extraction (RE), addressing the issue of scarce labeled data. However, distant supervision (DS) is often limited by coarse annotations and insufficient contextual awareness, leading to relational ambiguity and introducing noise in the labeled results. Moreover, although one can optimize the classifiers in DS-RE models through weight updates, the static nature of the guiding rules for such adjustments often falls short when addressing the challenges posed by diverse non-taxonomic relations and complex noise patterns in datasets. In this paper, we propose a DS-RE framework that capitalizes on non-taxonomic relations and a self-optimizing mechanism. We define a set of consistent DS relation candidates and combine DS with a LLM to enhance the perception of entities’ contextual states during the DS process. Then, we design a Self-Optimizing Ontology-Enhanced Non-taxonomic Relation Extraction Model (SO-NRE). The model incorporates additional entity-relation knowledge to enhance the semantic depth of Non-taxonomic relation ontologies and uses an adaptive dynamic scheduling mechanism to refine the classification strategy through iterations informed by self-perception outcomes. The experimental results show that the improved DS annotation workflow has enhanced accuracy, and SO-NRE outperforms mainstream baselines in RE performance.},
  keywords={Adaptation models;Accuracy;Annotations;Large language models;Noise;Semantics;Neural networks;Distantly Supervised Relation Extraction;Non-taxonomic Relation;LLM;Self-Optimization},
  doi={10.1109/IJCNN60899.2024.10650745},
  ISSN={2161-4407},
  month={June},}@ARTICLE{10517649,
  author={Chen, Xingyu and Liu, Jiaxu and Liu, Zeyang and Wan, Lipeng and Lan, Xuguang and Zheng, Nanning},
  journal={IEEE Transactions on Circuits and Systems for Video Technology}, 
  title={Knowledge Graph Enhancement for Fine-Grained Zero-Shot Learning on ImageNet21K}, 
  year={2024},
  volume={34},
  number={10},
  pages={9090-9101},
  abstract={Fine-grained Zero-shot Learning on the large-scale dataset ImageNet21K is an important task that has promising perspectives in many real-world scenarios. One typical solution is to explicitly model the knowledge passing using a Knowledge Graph (KG) to transfer knowledge from seen to unseen instances. By analyzing the hierarchical structure and the word descriptions on ImageNet21K, we find that the noisy semantic information, the sparseness of seen classes, and the lack of supervision of unseen classes make the knowledge passing insufficient, which limits the KG-based fine-grained ZSL. To resolve this problem, in this paper, we enhance the knowledge passing from three aspects. First, we use more powerful models such as the Large Language Model and Vision-Language Model to get more reliable semantic embeddings. Then we propose a strategy that globally enhances the knowledge graph based on the convex combination relationship of the semantic embeddings. It effectively connects the edges between the non-kinship seen and unseen classes that have strong correlations while assigning an importance score to each edge. Based on the enhanced knowledge graph, we further present a novel regularizer that locally enhances the knowledge passing during training. We extensively conducted comparative evaluations to demonstrate the advantages of our method over state-of-the-art approaches.},
  keywords={Semantics;Knowledge graphs;Zero-shot learning;Circuits and systems;Visualization;Training;Task analysis;Fine-grained zero-shot learning;knowledge graph;graph convolutional neural network},
  doi={10.1109/TCSVT.2024.3396215},
  ISSN={1558-2205},
  month={Oct},}@INPROCEEDINGS{10781547,
  author={Abbasian, Mahyar and Yang, Zhongqi and Khatibi, Elahe and Zhang, Pengfei and Nagesh, Nitish and Azimi, Iman and Jain, Ramesh and Rahmani, Amir M.},
  booktitle={2024 46th Annual International Conference of the IEEE Engineering in Medicine and Biology Society (EMBC)}, 
  title={Knowledge-Infused LLM-Powered Conversational Health Agent: A Case Study for Diabetes Patients}, 
  year={2024},
  volume={},
  number={},
  pages={1-4},
  abstract={Effective diabetes management is crucial for maintaining health in diabetic patients. Large Language Models (LLMs) have opened new avenues for diabetes management, facilitating their efficacy. However, current LLM-based approaches are limited by their dependence on general sources and lack of integration with domain-specific knowledge, leading to inaccurate responses. In this paper, we propose a knowledge-infused LLM-powered conversational health agent (CHA) for diabetic patients. We customize and leverage the open-source openCHA framework, enhancing our CHA with external knowledge and analytical capabilities. This integration involves two key components: 1) incorporating the American Diabetes Association dietary guidelines and the Nutritionix information and 2) deploying analytical tools that enable nutritional intake calculation and comparison with the guidelines. We compare the proposed CHA with GPT4. Our evaluation includes 100 diabetes-related questions on daily meal choices and assessing the potential risks associated with the suggested diet. Our findings show that the proposed agent demonstrates superior performance in generating responses to manage essential nutrients.},
  keywords={Large language models;Knowledge based systems;Medical services;Nutrients;Information retrieval;Diabetes;Risk management;Guidelines;LLMs;Knowledge Graph;Diabetes;Nutrition Therapy;Health Agents},
  doi={10.1109/EMBC53108.2024.10781547},
  ISSN={2694-0604},
  month={July},}@INPROCEEDINGS{10479303,
  author={Ferchichi, Olfa and Beltaifa, Raoudha and Labed Jilani, Lamia},
  booktitle={2023 20th ACS/IEEE International Conference on Computer Systems and Applications (AICCSA)}, 
  title={Artificial Intelligence Based SysML Block Diagram Extension and Evolution for Product Lines}, 
  year={2023},
  volume={},
  number={},
  pages={1-8},
  abstract={SysML is a standard language that permits to model systems of any type such as plane, ships and software intensive systems. Software Product Line large scale reuse approach has demonstrated its success. The industry provides benefits in term of cost savings and acceleration of time to maket. The available literature indicates that there have been efforts to enhance the capability of SysML in handling product families. However, these attempts are not yet fully systematic, and there remains a significant amount of work to be undertaken in this area. In this present paper, we deal with the SysML Block Diagram in order to investigate to what extent it permits variability representation and how it can evolve during the system evolution or when agility is needed. We want to capitalize on the knowledge necessary for block diagram extention and evolution and take advantage of knowledge from Product Line domain engineering and application engineering. So, we decide to use an ontology which is an articifial intelligence artifact. An ontology is a powerful mean to represent knowledge and reason about it. Here, we use the ontology to help decision making for Block diagram evolution as well.},
  keywords={Industries;Systematics;Description logic;Systems architecture;Ontologies;Software;Mobile handsets;SysML block diagram;Product Line Engineering;Variability;Evolution;Artificial Intelligence Artifact;Ontology},
  doi={10.1109/AICCSA59173.2023.10479303},
  ISSN={2161-5330},
  month={Dec},}@INPROCEEDINGS{10348639,
  author={Palagin, Oleksandr and Kaverinsky, Vladislav and Petrenko, Mykola and Malakhov, Kyrylo},
  booktitle={2023 IEEE 12th International Conference on Intelligent Data Acquisition and Advanced Computing Systems: Technology and Applications (IDAACS)}, 
  title={Digital Health Systems: Ontology-Based Universal Dialog Service for Hybrid E-Rehabilitation Activities Support}, 
  year={2023},
  volume={1},
  number={},
  pages={84-89},
  abstract={The medical rehabilitation system in Ukraine encountered a set of crucial challenges that demanded immediate attention and action. The primary objective revolves around rehabilitating patients with Combat stress reaction. Ukraine possesses a network of medical and preventive institutions that cater to the psycho-physiological rehabilitation needs of military personnel. These institutions employ contemporary rehabilitation technologies. Nonetheless, not all individuals have access to long-term rehabilitation within these centers. Hence, the integration of telerehabilitation technology becomes crucial for patients dealing with post-traumatic stress disorder and related conditions. This integration, combined with objective monitoring of the functional state, holds significant importance. Remote patient-centered rehabilitation emerges as one of the most effective approaches within the realm of medical rehabilitation assistance. Moreover, there is a need for efficient methods that support the “Physical therapist - Patient - Multidisciplinary team” system in the field of rehabilitation. Hence, in this paper, we not only explore conventional rehabilitation techniques but also present and elucidate the following advancements: a revised and comprehensive understanding of the hybrid e-rehabilitation concept and its underlying principles, an enhanced formalization notion of the Smart-system for remote support in hybrid e-rehabilitation services and activities, and the conceptual framework and software implementation of the ontology-based universal dialog service within the Smart-system.},
  keywords={Data acquisition;Ontologies;Software;Electronic healthcare;Personnel;IEEE activities;Stress;Ontology engineering;hybrid e-rehabilitation;Telerehabilitation;Transdisciplinary research;Computational linguistics;Universal dialog service},
  doi={10.1109/IDAACS58523.2023.10348639},
  ISSN={2770-4254},
  month={Sep.},}@INPROCEEDINGS{8089860,
  author={Naranjo, David and Sánchez, Mario and Villalobos, Jorge},
  booktitle={2017 IEEE 21st International Enterprise Distributed Object Computing Conference (EDOC)}, 
  title={Visualizing the Bias of Enterprise Metamodels towards Nuanced Concepts}, 
  year={2017},
  volume={},
  number={},
  pages={30-39},
  abstract={In Enterprise Modeling, we use several languages for designing, analyzing, and communicating the different domains of an enterprise. Two important criteria for choosing a domainspecific language are its appropriateness to the requirements of the enterprise, as well as the accuracy of the language in describing the domain at hand. However, in some business domains, core concepts --such as Capability, Service, and Value-- represent constructs that have different (and often conflicting) definitions and interpretations among the literature. In this context, the bias of a language is the preference for a theory, i.e. a particular interpretation of a concept. Currently, there is no explicit way of assessing and communicating this bias, and thus it remains difficult to assess the appropriateness and accuracy of a language for a particular purpose. In this paper, we provide a method for visual comparison of this bias with regard to the Capability concept, comparing three theories and three modeling languages where this concept is pivotal.},
  keywords={Semantics;Unified modeling language;Ontologies;Pragmatics;Syntactics;Analytical models;Visualization;nuance;enterprise modeling;model theory;semantics;ontology},
  doi={10.1109/EDOC.2017.14},
  ISSN={2325-6362},
  month={Oct},}@INPROCEEDINGS{10131050,
  author={Dunbar, Daniel and Vierlboeck, Maximilian and Blackburn, Mark},
  booktitle={2023 IEEE International Systems Conference (SysCon)}, 
  title={Use of Natural Language Processing in Digital Engineering Context to Aid Tagging of Model}, 
  year={2023},
  volume={},
  number={},
  pages={1-8},
  abstract={This paper uses Natural Language Processing to provide augmented intelligence assistance to the resource intensive task of aligning systems engineering artifacts, namely text requirements and system models, with ontologies. Ontologies are a key enabling technology for digital, multidisciplinary interoperability. The approach presented in this paper combines the efficiency of statistical based natural language processing to process large sets of data with expert verification of output to enable accurate alignment to ontologies in a time efficient manner. It applies this approach to an example from the telecommunications domain to demonstrate the workflows and highlight key points in the process. Enabling easier, faster alignment of systems engineering artifacts with ontologies allows for a holistic view of a system under design and enables interoperability between tools and domains.},
  keywords={Measurement;Ontologies;Tagging;Natural language processing;Telecommunications;Requirements engineering;Task analysis;ontology;natural language processing;semantic web;digital engineering;authoritative source of truth;augmented intelligence},
  doi={10.1109/SysCon53073.2023.10131050},
  ISSN={2472-9647},
  month={April},}@INPROCEEDINGS{10186650,
  author={Chondamrongkul, Nacha and Sun, Jing and Warren, Ian and Lee, Scott Uk-Jin},
  booktitle={2020 IEEE/ACM 8th International Conference on Formal Methods in Software Engineering (FormaliSE)}, 
  title={Semantic-based Architecture Smell Analysis}, 
  year={2020},
  volume={},
  number={},
  pages={109-118},
  abstract={Software smells have negative impacts on the reliability and modifiability of software systems. The smells in architecture design can be cascaded down to the implementation level and cause issues that require much effort to fix. Therefore, early detection of the architecture smells can benefit the overall quality of the software system. This paper presents an integration of methods that formally define the software architecture design towards architecture smell detection. Our approach serves as a framework that allows the architectural structures and behaviours to be formally analysed based on a coherent technique. We evaluated the accuracy and performance of our approach with the models generated from open source projects. The results show that our approach is effective and functions well.},
  keywords={Software architecture;OWL;Computer architecture;Ontologies;Model checking;Software systems;Cognition;Architecture Smells;Software Architecture;Ontology Web Language;Model Checking;Smell Detection},
  doi={},
  ISSN={2575-5099},
  month={May},}@INPROCEEDINGS{10387634,
  author={Procko, Tyler Thomas and Ochoa, Omar and Elvira, Timothy},
  booktitle={2023 Fifth International Conference on Transdisciplinary AI (TransAI)}, 
  title={Automatic Generation of BFO-Compliant Aristotelian Definitions in OWL Ontologies with GPT}, 
  year={2023},
  volume={},
  number={},
  pages={141-146},
  abstract={Ontologies are representational artifacts that purport to accurately describe some aspect of reality, including the entities and the relations that hold between them. In computer science, ontologies are software artifacts containing the schematic structure for machine-readable knowledge, typically formed as a graph of subject-predicate-object triples, constrained through Description Logics. These resources and their relations are self-defining, i.e., some resource may be defined by considering all its stated relations. Resources are often attended with natural language annotations, that humans may read and interpret, such as labels and definitions. Many long-standing ontologies have useless lexical definitions that define resources cyclically, e.g., a FOAF: Person is simply defined as “A person”. In Aristotelian terms, the definition of a thing should be reducible, by using terms simpler than itself, such that every definition can be unpacked up to the most general thing, which can only be defined by stating examples and use cases. This paper presents an innovative technique that leverages the Generative Pre-trained Transformer (GPT) large language model, GPT -4, for automatically generating Aristotelian definition annotations for OWL classes that engenders compliance with the Basic Formal Ontology standard.},
  keywords={Annotations;Description logic;OWL;Natural languages;Maintenance engineering;Transformers;Software;ontology;epistemology;Linked Data;BFO;GPT},
  doi={10.1109/TransAI60598.2023.00042},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10807443,
  author={Li, Jinghong and Siritanawan, Prarinya and Gu, Wen and Hasegawa, Shinobu},
  booktitle={2024 IEEE International Conference on Agents (ICA)}, 
  title={Multi-Agent Approach for Dynamic Research Insight Path Generation}, 
  year={2024},
  volume={},
  number={},
  pages={128-129},
  abstract={In recent years, researchers have witnessed rapid advancements in conducting paper surveys using generative AI, enhancing survey efficiency to some extent. However, today’s generative AI lacks deep research training to analyze logical threads woven across multiple papers. A concise visualization method is also expected to present logical connections among various papers. These logical threads are often implicit in the issue ontology authors commonly employ when writing papers. Building on this issue ontology, our method utilizes Dynamic Programming with multiple agents to generate an insight path. The key feature of this approach is the collaboration of multiple agents to adapt to a complex environment and make optimized decisions on issue ontology selection. This path aims to succinctly express longitudinal logical connections among multiple papers, including commonality, difference, and inheritance.},
  keywords={Surveys;Training;Visualization;Generative AI;Collaboration;Ontologies;Writing;Programming;Weaving;Dynamic programming;Issue ontology;Insight path;Longitudinal;Agent;Dynamic programming},
  doi={10.1109/ICA63002.2024.00035},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{9728603,
  author={Wang, Kaiqiang and Zhang, Yu and Jiang, Chaoyuan and Luo, Junren and Yang, Xueke and Chen, Shikai},
  booktitle={2021 China Automation Congress (CAC)}, 
  title={Visual Semantic Planning for Service Robot via Natural Language Instructions}, 
  year={2021},
  volume={},
  number={},
  pages={793-798},
  abstract={The interactive instruction following task requires intelligent robots to complete natural language instructions by interacting with the surrounding environment through visual perception and mechanical manipulation. The most representative benchmark is the ALFRED challenge task, which aims to perform restricted sequential actions to accomplish daily housework in a virtual environment. However, recently proposed multi-modal task planning approaches that combine vision and language do not perform well on ALFRED task. In this work, we utilize natural language instructions to build a single-mode model, and translate the task into a sequential decision problem, which focuses on generating continuous high-level action sequences directly from the instructions. We demonstrate that our K-PLM (knowledge enabled pre-trained language model) may successfully generate concrete visual semantic plans in 31.4% tasks on unseen scenarios without visual cues, where 62.2% can be generated if the model merges some visual cues, i.e. the location of the first object in the scene. The results show that our model provides outstanding visual semantic plans for the embodied agent to perform tasks and outperforms prior works.},
  keywords={Visualization;Service robots;Semantics;Natural languages;Virtual environments;Planning;Indoor environment;natural language instructions;knowledge graph;pre-trained model;visual semantic planning;interactive instruction following task},
  doi={10.1109/CAC53003.2021.9728603},
  ISSN={2688-0938},
  month={Oct},}@INPROCEEDINGS{10771088,
  author={Li, Harry and Appleby, Gabriel and Suh, Ashley},
  booktitle={2024 IEEE Visualization and Visual Analytics (VIS)}, 
  title={LinkQ: An LLM-Assisted Visual Interface for Knowledge Graph Question-Answering}, 
  year={2024},
  volume={},
  number={},
  pages={116-120},
  abstract={We present LinkQ, a system that leverages a large language model (LLM) to facilitate knowledge graph (KG) query construction through natural language question-answering. Traditional approaches often require detailed knowledge of a graph querying language, limiting the ability for users – even experts – to acquire valuable insights from KGs. LinkQ simplifies this process by implementing a multistep protocol in which the LLM interprets a user’s question, then systematically converts it into a well-formed query. LinkQ helps users iteratively refine any open-ended questions into precise ones, supporting both targeted and exploratory analysis. Further, LinkQ guards against the LLM hallucinating outputs by ensuring users’ questions are only ever answered from ground truth KG data. We demonstrate the efficacy of LinkQ through a qualitative study with five KG practitioners. Our results indicate that practitioners find LinkQ effective for KG question-answering, and desire future LLM-assisted exploratory data analysis systems.},
  keywords={Analytical models;Protocols;Limiting;Data analysis;Visual analytics;Large language models;Data visualization;Knowledge graphs;Writing;Data models;Knowledge graphs;large language models;query construction;question-answering;natural language interfaces},
  doi={10.1109/VIS55277.2024.00031},
  ISSN={2771-9553},
  month={Oct},}@INPROCEEDINGS{8432294,
  author={Machado Lunardi, Gabriel and Medeiros Machado, Guilherme and Al Machot, Fadi and Maran, Vinícius and Machado, Alencar and C. Mayr, Heinrich and A. Shekhovtsov, Vladimir and Palazzo M. de Oliveira, José},
  booktitle={2018 IEEE 32nd International Conference on Advanced Information Networking and Applications (AINA)}, 
  title={Probabilistic Ontology Reasoning in Ambient Assistance: Predicting Human Actions}, 
  year={2018},
  volume={},
  number={},
  pages={593-600},
  abstract={Providing reminders to elderly people in their home environment, while they perform their daily activities, is considered as a user support activity, and thus a relevant topic in Active and Assisted Living (AAL) research and development. Determining such reminders implies decision-making, since the actions' flow (behavior) usually involves probabilistic branches. An automated system needs to decide which of the next actions is the best one for the user in a given situation. Problems of this nature involve uncertainty levels that have to be dealt with. Many approaches to this problem exploit statistical data only, thus ignoring important semantic data as, for instance, are provided by Ontologies. However, ontologies do not support reasoning over uncertainty natively. In this paper, we present a probabilistic semantic model that enables reasoning over uncertainty without losing semantic information. This model will be exemplified by an extension of the Human Behavior Monitoring and Support [HBMS] approach that provides a conceptual model for representing the user's behavior and its context in her/his living environment. The performance of this approach was evaluated using real data collected from a smart home prototype equipped with sensors. The experiments provided promising results which we will discuss regarding limits and challenges to overcome.},
  keywords={Ontologies;Uncertainty;Cognition;Probabilistic logic;Semantics;Hidden Markov models;Context modeling;Probabilistic ontologies;Uncertainty reasoning;Ambient assistance;Smart home;Context awareness},
  doi={10.1109/AINA.2018.00092},
  ISSN={2332-5658},
  month={May},}@ARTICLE{10288249,
  author={Zhang, Rui and Su, Yixin and Trisedya, Bayu Distiawan and Zhao, Xiaoyan and Yang, Min and Cheng, Hong and Qi, Jianzhong},
  journal={IEEE Transactions on Knowledge and Data Engineering}, 
  title={AutoAlign: Fully Automatic and Effective Knowledge Graph Alignment Enabled by Large Language Models}, 
  year={2024},
  volume={36},
  number={6},
  pages={2357-2371},
  abstract={The task of entity alignment between knowledge graphs (KGs) aims to identify every pair of entities from two different KGs that represent the same entity. Many machine learning-based methods have been proposed for this task. However, to our best knowledge, existing methods all require manually crafted seed alignments, which are expensive to obtain. In this paper, we propose the first fully automatic alignment method named AutoAlign, which does not require any manually crafted seed alignments. Specifically, for predicate embeddings, AutoAlign constructs a predicate-proximity-graph with the help of large language models to automatically capture the similarity between predicates across two KGs. For entity embeddings, AutoAlign first computes the entity embeddings of each KG independently using TransE, and then shifts the two KGs’ entity embeddings into the same vector space by computing the similarity between entities based on their attributes. Thus, both predicate alignment and entity alignment can be done without manually crafted seed alignments. AutoAlign is not only fully automatic, but also highly effective. Experiments using real-world KGs show that AutoAlign improves the performance of entity alignment significantly compared to state-of-the-art methods.},
  keywords={Learning systems;Knowledge graphs;Vectors;Data models;Task analysis;Attribute embeddings;deep learning;entity alignment;knowledge base;knowledge graph;knowledge graph alignment;large language model;predicate proximity graph;representation learning},
  doi={10.1109/TKDE.2023.3325484},
  ISSN={1558-2191},
  month={June},}@INPROCEEDINGS{10132129,
  author={Zhang, Pengyu and Gao, Shijie and Shen, Yi and Yang, Shiyu and Sun, Lizhuang},
  booktitle={2023 IEEE 9th Intl Conference on Big Data Security on Cloud (BigDataSecurity), IEEE Intl Conference on High Performance and Smart Computing, (HPSC) and IEEE Intl Conference on Intelligent Data and Security (IDS)}, 
  title={SG-RC: SG-CIM Grid Knowledge Graph Relationship Complementation Model Based on Entropy Uncertainty and Semantic Recognition}, 
  year={2023},
  volume={},
  number={},
  pages={181-186},
  abstract={SG-CIM grid knowledge graph is a domain knowledge graph based on the actual business knowledge of State Grid Corporation of China. SG-CIM grid knowledge graph consists of the triad of "entity-relationship-entity " of the grid. The traditional construction of SG-CIM grid knowledge graph needs experts familiar with relevant fields to build it manually, which is a necessary work in the early stage of data accumulation. This work consumes a lot of labor and cost, and some relations are missing due to manual operation. However, completing the relationship on the incomplete SG-CIM grid knowledge graph will lead to the problem that some difficult samples cannot be mined. To solve this problem, this paper proposes an SG-CIM grid knowledge graph relationship complementation method SG-RC based on entropy uncertainty and semantic recognition.SG-RC consists of an active learning module based on entropy uncertainty calculation and a relationship prediction module based on semantic recognition. The SG-RC model first mines all possible entity pairs to calculate the entropy uncertainty, and those with higher entropy uncertainty The higher entropy uncertainty represents the poor relationship prediction effect of the model, and those entity pairs with higher entropy uncertainty are recommended to experts for relationship labeling, and multiple iterations improve the quality of prediction results of the semantic recognition relationship prediction module. Compared with randomly selected entity pairs, this method can improve the completion probability of relation completion.},
  keywords={Uncertainty;Costs;Annotations;Semantics;Knowledge graphs;Predictive models;Entropy;SG-CIM;knowledge graph;semantic recognition;active learning;relationship complementation},
  doi={10.1109/BigDataSecurity-HPSC-IDS58521.2023.00040},
  ISSN={},
  month={May},}@INPROCEEDINGS{10677287,
  author={Saini, Shashwat and Vrindavanam, Jayavrinda and Mondal, Subhash},
  booktitle={2024 IEEE International Conference on Electronics, Computing and Communication Technologies (CONECCT)}, 
  title={Methodological Insights Into Protein Clustering Using BERT & RoBERTa}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Proteins are present in all living organisms, and understanding their processes is vital. Protein databases such as SWISS-PROT include curated information on only 570,000 protein sequences, representing a fraction of the 250 million known evidential and predicted sequences; it becomes crucial to cluster proteins into similar groups. This research explores the application of two transformer architectures, BERT and RoBERTa in clustering proteins in the supervised prediction of Gene Ontology (GO) annotations. The detailed methodology for both the pre-training and fine-tuning processes, as well as results that showcase RoBERTa outperforming BERT in the context of protein clustering, on performance metrics of accuracy and loss. Operating under constrained computational resources, the deployed model exhibits strong performance and highlight the robustness of methodology in protein clustering within resource constraints. This study not only contributes to the understanding of protein clustering but also signifies the potential of transformer models to handle biological data.},
  keywords={Proteins;Training;Analytical models;Annotations;Biological system modeling;Computational modeling;Ontologies;Protein Clustering;BERT;RoBERTa;Natural Language Processing;Transformers;Masked Language Modelling},
  doi={10.1109/CONECCT62155.2024.10677287},
  ISSN={2766-2101},
  month={July},}@INPROCEEDINGS{10350744,
  author={Guizzardi, Giancarlo},
  booktitle={2023 ACM/IEEE International Conference on Model Driven Engineering Languages and Systems Companion (MODELS-C)}, 
  title={An Ontological View on Types}, 
  year={2023},
  volume={},
  number={},
  pages={634-634},
  abstract={Types are fundamental for modeling, being an essential construct in all major modeling languages. These include traditional conceptual modeling languages - such as Entity-Relationship models, UML class diagrams, or Object-Role-Modeling (ORM) specifications, and knowledge representation languages alike (e.g., the Web Ontology Language - OWL).},
  keywords={Unified modeling language;OWL;Knowledge representation;Model driven engineering;Ontological Foundations for Modeling;Types and Taxonomic Structures;Multi-Level Modeling},
  doi={10.1109/MODELS-C59198.2023.00103},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{9776298,
  author={Qi, Peng and Huang, Zhen and Sun, Yan and Luo, Hong},
  booktitle={2022 IEEE 25th International Conference on Computer Supported Cooperative Work in Design (CSCWD)}, 
  title={A Knowledge Graph-Based Abstractive Model Integrating Semantic and Structural Information for Summarizing Chinese Meetings}, 
  year={2022},
  volume={},
  number={},
  pages={746-751},
  abstract={With the rapid increase of users, online meeting platforms have accumulated massive meeting transcripts. However, it is still a challenge for users to quickly master the chief information and manage the meetings, despite there are already some useful text summarization models. In this paper, a Knowledge Graph-based Meeting Summarization Framework is proposed to tackle this challenge. First, a two-layers meeting domain Knowledge Graph is developed to integrate more information of meetings. Based on which, an encoder-decoder architecture is utilized to summarize meetings. For encoding meetings, a structural-level and semantic-level embedding strategy is considered, concretely, the Knowledge Graph is embedded to obtain the structural information, an interaction intention recognition model and a two-level transformer mechanism are devised to get the semantic information. Finally, the structural information and semantic information are combined and fed into the decoding network to generate meeting summaries. Extensive experiments on the Chinese meeting dataset show that our summarization framework outperforms other state-of-the-art models.},
  keywords={Conferences;Computational modeling;Semantics;Transformers;Collaborative work;Encoding;Decoding;meeting domain Knowledge Graph;an interaction intention recognition model;a two-level transformer mechanism;meeting summarization},
  doi={10.1109/CSCWD54268.2022.9776298},
  ISSN={},
  month={May},}@INPROCEEDINGS{8089878,
  author={Sales, Tiago Prince and Guarino, Nicola and Guizzardi, Giancarlo and Mylopoulos, John},
  booktitle={2017 IEEE 21st International Enterprise Distributed Object Computing Conference (EDOC)}, 
  title={An Ontological Analysis of Value Propositions}, 
  year={2017},
  volume={},
  number={},
  pages={184-193},
  abstract={In competitive markets, companies need well-designed business strategies if they seek to grow and obtain sustainable competitive advantage. At the core of a successful business strategy there is a carefully crafted value proposition, which ultimately defines what a company delivers to its customers. Despite their widely recognized importance, there is however little agreement on what exactly value propositions are. This lack of conceptual clarity harms the communication among stakeholders and the harmonization of current business strategy theories and strategy support frameworks. Furthermore, it hinders the development of systematic methodologies for crafting value propositions, as well as adequate support for representing and analyzing them. In this paper, we present an ontological analysis of value propositions based on a review of most relevant business and marketing theories and on previous work on value ascription, grounded in the Unified Foundational Ontology (UFO). Our investigation clarifies how value propositions are different from value presentations, and shows the difference between value propositions at the business level from those related to specific offerings.},
  keywords={Companies;Ontologies;Unified modeling language;Semantics;Analytical models;Proposals;ontological analysis;formal ontology;value proposition},
  doi={10.1109/EDOC.2017.32},
  ISSN={2325-6362},
  month={Oct},}@INPROCEEDINGS{10250672,
  author={Mahajan, Arpana Dipak and Mahale, Akshay and Deshmukh, Amol S and Vidyadharan, Arun and Hegde, Vijeth S and Vijayaraghavan, Koushik},
  booktitle={2023 Second International Conference on Augmented Intelligence and Sustainable Systems (ICAISS)}, 
  title={Knowledge Graph-based Recommendation Engine: The Review}, 
  year={2023},
  volume={},
  number={},
  pages={1088-1095},
  abstract={With the rapid growth of digital information and the increasing complexity of user preferences, recommender systems have become essential in various application domains. Knowledge graph-based recommendation methods have emerged as a promising approach to enhance the accuracy and interpretability of recommendations. This research study explores the landscape of knowledge graph-based recommendation methods and examine benchmark datasets from the perspectives of different application scenarios. Here, the application scenarios are categorized into e-commerce, social media, content-based, and cross-domain recommendations. This study has analyzed the challenges and opportunities that arise in each scenario and discuss the corresponding knowledge graph-based recommendation techniques. Furthermore, this study investigates the existing benchmark datasets specifically designed for knowledge graph-based recommendation, highlighting their characteristics, strengths, and limitations. By providing an in-depth analysis of knowledge graph-based recommendation methods and benchmark datasets, this review paper serves as a valuable resource for researchers and practitioners working in the field, aiding in the development and evaluation of effective recommendation systems tailored to specific application scenarios.},
  keywords={Technological innovation;Social networking (online);Filtering;Semantics;Knowledge graphs;Benchmark testing;Complexity theory;Knowledge Graph;Recommendation Engine;Generative Ai;Graph Algorithm;Collaborative Filtering},
  doi={10.1109/ICAISS58487.2023.10250672},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{8876971,
  author={Guizzardi, Giancarlo and Figueiredo, Guylerme and Hedblom, Maria M. and Poels, Geert},
  booktitle={2019 13th International Conference on Research Challenges in Information Science (RCIS)}, 
  title={Ontology-Based Model Abstraction}, 
  year={2019},
  volume={},
  number={},
  pages={1-13},
  abstract={In recent years, there has been a growth in the use of reference conceptual models to capture information about complex and critical domains. However, as the complexity of domain increases, so does the size and complexity of the models that represent them. Over the years, different techniques for complexity management in large conceptual models have been developed. In particular, several authors have proposed different techniques for model abstraction. In this paper, we leverage on the ontologically well-founded semantics of the modeling language OntoUML to propose a novel approach for model abstraction in conceptual models. We provide a precise definition for a set of Graph-Rewriting rules that can automatically produce much-reduced versions of OntoUML models that concentrate the models' information content around the ontologically essential types in that domain, i.e., the so-called Kinds. The approach has been implemented using a model-based editor and tested over a repository of OntoUML models.},
  keywords={Unified modeling language;Object oriented modeling;Complexity theory;Ontologies;Semantics;Context modeling;Clustering methods;Model Abstraction;Complexity Management in Conceptual Modeling;Ontology-Based Conceptual Modeling},
  doi={10.1109/RCIS.2019.8876971},
  ISSN={2151-1357},
  month={May},}@INPROCEEDINGS{9892075,
  author={Lin, RuiMing and Cheng, LiangLun and Wang, Tao and Deng, Jianfeng},
  booktitle={2022 International Joint Conference on Neural Networks (IJCNN)}, 
  title={Trans-SBLGCN: A Transfer Learning Model for Event Logic Knowledge Graph Construction of Fault Diagnosis}, 
  year={2022},
  volume={},
  number={},
  pages={1-8},
  abstract={Taking fault diagnosis corpus as the research object, an event logic knowledge graph construction method is proposed in this paper. Firstly, we propose a data labeling strategy based on a constructed event logic ontology model, then collect large-scale robot transmission system fault diagnosis corpus, and label part of the data according to the strategy. Secondly, we propose a transfer learning model called Trans-SBLGCN for event argument entity and event argument relation joint extraction. A language model is trained based on large-scale unlabeled fault diagnosis corpus and transferred to a model based on stacked bidirectional long short term memory (BiLSTM) and bidirectional graph convolutional network (BiGCN). Experimental results show that the method is superior to other methods. Finally, an event logic knowledge graph of robot transmission system fault diagnosis is constructed to provide decision support for autonomous robot transmission system fault diagnosis.},
  keywords={Fault diagnosis;Knowledge engineering;Transfer learning;Neural networks;Ontologies;Data models;Labeling;Event Logic Knowledge Graph;Fault Diagnosis;Knowledge Joint Extraction;BiGCN},
  doi={10.1109/IJCNN55064.2022.9892075},
  ISSN={2161-4407},
  month={July},}@INPROCEEDINGS{10710783,
  author={Vieira da Silva, Luis Miguel and Kocher, Aljosha and Gehlhoff, Felix and Fay, Alexander},
  booktitle={2024 IEEE 29th International Conference on Emerging Technologies and Factory Automation (ETFA)}, 
  title={Toward a Method to Generate Capability Ontologies from Natural Language Descriptions}, 
  year={2024},
  volume={},
  number={},
  pages={1-4},
  abstract={To achieve a flexible and adaptable system, capabil-ity ontologies are increasingly leveraged to describe functions in a machine-interpretable way. However, modeling such complex ontological descriptions is still a manual and error-prone task that requires a significant amount of effort and ontology expertise. This contribution presents an innovative method to automate capability ontology modeling using Large Language Models (LLMs), which have proven to be well suited for such tasks. Our approach requires only a natural language description of a capability, which is then automatically inserted into a predefined prompt using a few-shot prompting technique. After prompting an LLM, the resulting capability ontology is automatically verified through various steps in a loop with the LLM to check the overall correctness of the capability ontology. First, a syntax check is performed, then a check for contradictions, and finally a check for hallucinations and missing ontology elements. Our method greatly reduces manual effort, as only the initial natural language description and a final human review and possible correction are necessary, thereby streamlining the capability ontology generation process.},
  keywords={Adaptation models;Costs;Reviews;Large language models;Natural languages;Manuals;Ontologies;Syntactics;Manufacturing automation;Testing;Large Language Models;LLMs;Capabilities;Skills;Ontologies;Semantic Web;Model-Generation},
  doi={10.1109/ETFA61755.2024.10710783},
  ISSN={1946-0759},
  month={Sep.},}@INPROCEEDINGS{10453813,
  author={Albokae, Nazeer and AlKhtib, Bassel and Omar, Khaled},
  booktitle={2023 24th International Arab Conference on Information Technology (ACIT)}, 
  title={Hybrid Method for ICD Prediction Using Word Embedding and Natural Language Processing}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={The international classification of diseases is a standard in medical coding, and it is contains all information and description of diseases in heroical structure, and finding the International Classification of Diseases (ICD) code for diseases is important and essential thing in medical sector, the coding process takes a lot of time and money to find the correct and the exact code of the patient disease, researchers in artificial intelligence and in natural language processing and in machine learning make a huge efforts to build and develop automatic systems and algorithms for automatic ICD encoding, in this paper we propose a hybrid method for automatic ICD encoding from patient claims, the proposed method contains two main parts first for ICD chapter, ICD group classification, and the second one for find the most relevant ICD code based on patient claim diagnosis description, the first step was implemented by using natural language processing techniques, that it include stemming (Porter Stemmer was used for stemming), stop word removing, and the implementation of the second step was done by using PubMed BERT model for embedding for the ICD codes the embedding done based on the descriptions, and also the embedding done for the patient claim diagnosis description, we have tested the developed algorithm on medical dataset The results of our tests indicate that the proposed method is highly efficient, with a precision rate of 87%.},
  keywords={Codes;Prediction algorithms;Natural language processing;Encoding;Classification algorithms;Medical diagnostic imaging;Diseases;automatic ICD coding;PubMed BERT;ICD ontology},
  doi={10.1109/ACIT58888.2023.10453813},
  ISSN={2831-4948},
  month={Dec},}@INPROCEEDINGS{10603963,
  author={Lyu, Yang},
  booktitle={2024 5th International Conference on Computer Engineering and Application (ICCEA)}, 
  title={Research on the Construction of Knowledge Platform for Pumped Storage Power Station}, 
  year={2024},
  volume={},
  number={},
  pages={1714-1718},
  abstract={The purpose of introducing the knowledge platform for pumped storage power station is to make full use of the experiential knowledge accumulated over a long period of time to provide a more effective organization, management and decision support ability. Firstly, this paper elaborates the definition, development, and architecture of the knowledge platform, then the key technologies and overall workflow of the knowledge platform are described in detail. Finally, some practical application scenarios are introduced and analyzed which has a certain reference value for the construction and application of knowledge platform for pumped storage power station.},
  keywords={Knowledge engineering;Industries;Computational modeling;Decision making;Organizations;Knowledge graphs;Computer architecture;knowledge platform;pumped storage power station;knowledge graph;large language model},
  doi={10.1109/ICCEA62105.2024.10603963},
  ISSN={2159-1288},
  month={April},}@INPROCEEDINGS{10387602,
  author={Leventi-Peetz, Anastasia-Maria and Raber, Frederic and Rüll, Annika and Weber, Kai},
  booktitle={2023 Fifth International Conference on Transdisciplinary AI (TransAI)}, 
  title={Biotechnology Machine Learning Techniques for Natural Language Processing}, 
  year={2023},
  volume={},
  number={},
  pages={118-119},
  abstract={The possibility to transfer machine learning techniques from biotechnology to natural language processing models to increase training efficiency will be generally discussed. The motivation and reasoning behind the idea will be briefly outlined.},
  keywords={Training;Biotechnology;Biological system modeling;Machine learning;Natural language processing;Cognition;Sustainable development;Machine learning;natural language processing;gene ontology;protein function;model sustainability},
  doi={10.1109/TransAI60598.2023.00029},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10442824,
  author={Wang, Xiaoyi and Liu, Jie and Zhou, Jianshe and Wang, Jincheng},
  booktitle={2023 IEEE International Conference on Electrical, Automation and Computer Engineering (ICEACE)}, 
  title={A Survey of Pre-Trained Language Models IncorporatingKnowledge Graphs}, 
  year={2023},
  volume={},
  number={},
  pages={1706-1710},
  abstract={Pre-trained models acquire knowledge from vast amounts of unannotated and unstructured data through self-supervised learning. However, they suffer from limitations such as inadequate performance and limited knowledge reasoning capabilities due to the lack of external knowledge guidance. To address these limitations, integrating structured knowledge from knowledge graphs into pretrained models enables them to acquire both general semantic knowledge from free text and real-world knowledge behind the text, thereby effectively addressing downstream knowledge-driven tasks. This paper introduces the concepts of pretrained models and knowledge graphs, discusses research advancements, provides an overview of methods for integrating knowledge into pretrained models, and proposes three classification approaches based on fusion methods. It also outlines the application domains where these approaches can be applied. Finally, the paper summarizes and discusses future research directions for pretrained models Integrated with knowledge.},
  keywords={Knowledge engineering;Surveys;Analytical models;Computational modeling;Semantics;Knowledge graphs;Task analysis;Pre-trained language model;Knowledge graph;Natural language processing},
  doi={10.1109/ICEACE60673.2023.10442824},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{8247474,
  author={Fiallos, Angel},
  booktitle={2017 IEEE Second Ecuador Technical Chapters Meeting (ETCM)}, 
  title={Assisted curricula design based on generation of domain ontologies and the use of NLP techniques}, 
  year={2017},
  volume={},
  number={},
  pages={1-6},
  abstract={The following work proposes an approach that allows educators to manage curricula of different academic disciplines, with the support of recommendations and suggestions of contents and educational materials. The recommendations will be process through by domain ontologies, constructed from digital texts and the use of natural language process techniques. These recommendations will also support students during the learning process on specific academic areas.},
  keywords={Ontologies;Training;Natural language processing;Semantics;Computational modeling;Context modeling;OWL;NLP;curriculum;ontology;topic;modeling;domain},
  doi={10.1109/ETCM.2017.8247474},
  ISSN={},
  month={Oct},}@ARTICLE{10816465,
  author={Xia, Liqiao and Fan, Junming and Parlikad, Ajith and Huang, Xiao and Zheng, Pai},
  journal={IEEE Transactions on Big Data}, 
  title={Unlocking Large Language Model Power in Industry: Privacy-Preserving Collaborative Creation of Knowledge Graph}, 
  year={2024},
  volume={},
  number={},
  pages={1-15},
  abstract={Semantic expertise remains a reliable foundation for industrial decision-making, while Large Language Models (LLMs) can augment the often limited empirical knowledge by generating domain-specific insights, though the quality of this generative knowledge is uncertain. Integrating LLMs with the collective wisdom of multiple stakeholders could enhance the quality and scale of knowledge, yet this integration might inadvertently raise privacy concerns for stakeholders. In response to this challenge, Federated Learning (FL) is harnessed to improve the knowledge base quality by cryptically leveraging other stakeholders' knowledge, where knowledge base is represented in Knowledge Graph (KG) form. Initially, a multi-field hyperbolic (MFH) graph embedding method vectorizes entities, furnishing mathematical representations in lieu of solely semantic meanings. The FL framework subsequently encrypted identifies and fuses common entities, whereby the updated entities' embedding can refine other private entities' embedding locally, thus enhancing the overall KG quality. Finally, the KG complement method refines and clarifies triplets to improve the overall quality of the KG. An experiment assesses the proposed approach across different industrial KGs, confirming its effectiveness as a viable solution for collaborative KG creation, all while maintaining data security.},
  keywords={Collaboration;Stakeholders;Data models;Knowledge engineering;Knowledge graphs;Federated learning;Big Data;Uncertainty;Tail;Mathematical models;Large Language Models;Knowledge Graph;Graph Embedding;Federated Learning;Industrial 4.0},
  doi={10.1109/TBDATA.2024.3522814},
  ISSN={2332-7790},
  month={},}@INPROCEEDINGS{10548271,
  author={Su, Yanqi and Liao, Dianshu and Xing, Zhenchang and Huang, Qing and Xie, Mulong and Lu, Qinghua and Xu, Xiwei},
  booktitle={2024 IEEE/ACM 46th International Conference on Software Engineering (ICSE)}, 
  title={Enhancing Exploratory Testing by Large Language Model and Knowledge Graph}, 
  year={2024},
  volume={},
  number={},
  pages={1197-1208},
  abstract={Exploratory testing leverages the tester's knowledge and creativity to design test cases for effectively uncovering system-level bugs from the end user's perspective. Researchers have worked on test scenario generation to support exploratory testing based on a system knowledge graph, enriched with scenario and oracle knowledge from bug reports. Nevertheless, the adoption of this approach is hindered by difficulties in handling bug reports of inconsistent quality and varied expression styles, along with the infeasibility of the generated test scenarios. To overcome these limitations, we utilize the superior natural language understanding (NLU) capabilities of Large Language Models (LLMs) to construct a System KG of User Tasks and Failures (SysKG-UTF). Leveraging the system and bug knowledge from the KG, along with the logical reasoning capabilities of LLMs, we generate test scenarios with high feasibility and coherence. Particularly, we design chain-of-thought (CoT) reasoning to extract human-like knowledge and logical reasoning from LLMs, simulating a developer's process of validating test scenario feasibility. Our evaluation shows that our approach significantly enhances the KG construction, particularly for bug reports with low quality. Furthermore, our approach generates test scenarios with high feasibility and coherence. The user study further proves the effectiveness of our generated test scenarios in supporting exploratory testing. Specifically, 8 participants find 36 bugs from 8 seed bugs in two hours using our test scenarios, a significant improvement over the 21 bugs found by the state-of-the-art baseline.},
  keywords={Computer bugs;Knowledge graphs;Coherence;Cognition;Natural language processing;Scenario generation;Task analysis;Exploratory testing;Knowledge graph;AI chain;Prompt engineering},
  doi={10.1145/3597503.3639157},
  ISSN={1558-1225},
  month={April},}@INPROCEEDINGS{10385754,
  author={Wang, Xun and Qu, Peng and Meng, Xiangyu and Yang, Qing and Qiao, Lian and Zhang, Chaogang and Xie, Xianjin},
  booktitle={2023 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)}, 
  title={MulAxialGO: Multi-Modal Feature-Enhanced Deep Learning Model for Protein Function Prediction}, 
  year={2023},
  volume={},
  number={},
  pages={132-137},
  abstract={Predicting protein function from sequences through machine learning can improve the understanding of novel proteins and biological mechanisms. Existing methods mainly rely on one-dimensional convolution or natural language processing (NLP) techniques to extract features from sequences, but they suffer from limited predictive performance. To address this challenge, we propose MulAxialGO, a new method that leverages multi-modal feature fusion to improve prediction accuracy. MulAxialGO integrates the prior features of a large-scale pre-trained protein language model and the posterior features of dynamic embedding coding and sequence homology. In addition, MulAxialGO employs a comprehensive image feature encoder to extract features from sequences, providing a novel perspective for protein function prediction. MulAxialGO is tested on two benchmark datasets and achieves state-of-the-art results. On the 2016 dataset, MulAxialGO significantly outperforms DeepGOPlus, improving molecular function by 4.5 points, biological process by 2.4 points and cellular component by 1.6 points for the AUPR metric. Similarly, on the NetGO dataset, MulAxialGO outperforms the state-of-the-art NetGO2.0, improving Fmax by 1.1 points for biological process and 2.3 points for cellular component.},
  keywords={Proteins;Measurement;Deep learning;Protein engineering;Convolution;Biological processes;Predictive models;Protein function prediction;Sequence analysis;Bioinformatics;Attention mechanism;Deep learning},
  doi={10.1109/BIBM58861.2023.10385754},
  ISSN={2156-1133},
  month={Dec},}@INPROCEEDINGS{10871140,
  author={Rani, Maneeha and Mishra, Bhupesh Kumar and Thakker, Dhavalkumar and Khan, Mohammad Nouman},
  booktitle={2024 18th International Conference on Open Source Systems and Technologies (ICOSST)}, 
  title={To Enhance Graph-Based Retrieval-Augmented Generation (RAG) with Robust Retrieval Techniques}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Large language models have demonstrated exceptional performance in multiple domains. However, practical deployment in the healthcare sector has distinctive challenges. These challenges include hallucination, inconsistency, explainability, reasoning, authenticity, and validity of information sources. Hallucinations in LLM often emerge due to unstructured and obsolete training data and the incompetence to upgrade the model data post-training. Retrieval-augmented generation (RAG) integration with LLM decision-making helps access real-time information from external resources. However, further improvements are needed to improve accurate response generation. A knowledge Graph is a structured data comprising nodes as entities and edges as relationships. When integrated with RAG, Knowledge Graph-based retrieval offers better contextu-ally relevant responses, traceability, and explainability of generated responses than RAG alone. This study proposes a novel knowledge graph-based RAG framework with a refined retrieval pipeline, robust chunking mechanism, and source traceability for enhanced diabetes-focused LLM. The retrieval pipeline integrates three robust retrieval strategies: keyword, graph, and vector. To ensure the authenticity of responses, a knowledge base focusing on diabetes is designed from validated sources. This verified knowledge base is preprocessed and converted to a knowledge graph to design A graph-based RAG pipeline. The empirical results demonstrate effective performance in diabetes-focused LLM, achieving a Rouge 1 score of 82.19%.},
  keywords={Accuracy;Retrieval augmented generation;Pipelines;Knowledge based systems;Training data;Knowledge graphs;Cognition;Vectors;Real-time systems;Diabetes;Retrieval-augmented generation;Large language model;Knowledge graph;Diabetes;Healthcare;Graph-based Retrieval-augmented generation},
  doi={10.1109/ICOSST64562.2024.10871140},
  ISSN={2770-8225},
  month={Dec},}@INPROCEEDINGS{9336541,
  author={Al-Obeidat, Feras and Adedugbe, Oluwasegun and Hani, Anoud Bani and Benkhelifa, Elhadj and Majdalawieh, Munir},
  booktitle={2020 Seventh International Conference on Social Networks Analysis, Management and Security (SNAMS)}, 
  title={Cone-KG: A Semantic Knowledge Graph with News Content and Social Context for Studying Covid-19 News Articles on Social Media}, 
  year={2020},
  volume={},
  number={},
  pages={1-7},
  abstract={Semantic knowledge graphs provide very significant benefits for structuring and analysing huge amounts of aggregated data across diverse heterogeneous sources. Beyond quick and efficient data query and analysis, they facilitate inference from data and generation of insights for several purposes. With the multi-faceted global challenges posed by the COVID-19 pandemic, this research focused on the use of a semantic knowledge graph to model, structure and store COVID-related news articles centrally and semantically towards knowledge discovery, knowledge acquisition and advanced data analytics for understanding varying metrics relating to the virus towards curbing its spread. The semantic knowledge graph provides a platform for researchers, data analysts and data scientists across societal sectors to investigate and recommend strategies towards addressing the challenges it poses to the global society.},
  keywords={COVID-19;Data analysis;Social networking (online);Pandemics;Semantics;Security;Viruses (medical);Knowledge Graphs;Semantic Graphs;Semantic Web;COVID-19 News;Social Media;Social Data Analysis},
  doi={10.1109/SNAMS52053.2020.9336541},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10687798,
  author={He, Jiabang and Liu, Jia and Wang, Lei and Li, Xiyao and Xu, Xing},
  booktitle={2024 IEEE International Conference on Multimedia and Expo (ICME)}, 
  title={MoCoSA: Momentum Contrast for Knowledge Graph Completion with Structure-Augmented Pre-trained Language Models}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Knowledge Graph Completion (KGC) aims to conduct reasoning on the facts within knowledge graphs and automatically infer missing links. Existing methods can mainly be categorized into structure-based or description-based. Structure-based methods effectively represent relational facts in knowledge graphs using entity embeddings and description-based methods leverage pre-trained language models (PLMs) to understand textual information. In this paper, we propose Momentum Contrast for knowledge graph completion with Structure-Augmented pre-trained language models (MoCoSA), which allows the PLM to perceive the structural information by the adaptable structure encoder. We proposed momentum hard negative and intra-relation negative sampling to improve learning efficiency. Experimental results demonstrate that our approach achieves state-of-the-art performance in terms of mean reciprocal rank (MRR), with improvements of 2.5% on WN18RR and 21% on OpenBG500.},
  keywords={Training;Adaptation models;Knowledge graphs;Contrastive learning;Predictive models;Cognition},
  doi={10.1109/ICME57554.2024.10687798},
  ISSN={1945-788X},
  month={July},}@ARTICLE{10771697,
  author={Gao, Yifu and Qiao, Linbo and Huang, Zhen and Kan, Zhigang and He, Yongquan and Li, Dongsheng},
  journal={IEEE Transactions on Audio, Speech and Language Processing}, 
  title={Unified Contextualized Knowledge Embedding Method for Static and Temporal Knowledge Graph}, 
  year={2025},
  volume={33},
  number={},
  pages={82-95},
  abstract={Recent years, there is a growing interest in knowledge graph embedding (KGE), which maps symbolic entities and relations into low-dimensional vector space to effectively represent structured data from the knowledge graph. In addition, the concept of temporal knowledge graph is proposed to document dynamically changing facts in the real world. Existing works attempt to incorporate temporal information into static KGE methods to accomplish temporal knowledge representations. However, existing static or temporal KGE approaches focus on the single query fact and ignore the query-relevant contextual information in the graph structure. This paper moves beyond the traditional way of scoring facts in distinct vector space and proposes a unified framework with pre-trained language models (PLM) to learn dynamic contextualized static/temporal knowledge graph embeddings, called CoS/TKGE. Given the query-specific subgraph, our model transforms it into an input sequence and uses the PLM to obtain the contextualized knowledge representations, which is flexible adaptive to the input graph contexts. We reformulate the link prediction task as a mask prediction problem to fine-tune the pre-trained language model. And the contrastive learning technique is employed to align dynamic contextual embeddings with static global embeddings. Experimental results on three widely used static and temporal KG datasets show the superiority of our model.},
  keywords={Knowledge graphs;Biological system modeling;Vectors;Contrastive learning;Semantics;Context modeling;Speech processing;Vegetation;Transforms;Tensors;Contrastive learning;knowledge graph embedding;pre-trained language model;representation learning},
  doi={10.1109/TASLP.2024.3507557},
  ISSN={2998-4173},
  month={},}@ARTICLE{10452779,
  author={Hu, Fan and Zhang, Weihong and Huang, Huazhen and Li, Wang and Li, Yang and Yin, Peng},
  journal={IEEE Journal of Biomedical and Health Informatics}, 
  title={A Transferability-Based Method for Evaluating the Protein Representation Learning}, 
  year={2024},
  volume={28},
  number={5},
  pages={3158-3166},
  abstract={Self-supervised pre-trained language models have recently risen as a powerful approach in learning protein representations, showing exceptional effectiveness in various biological tasks, such as drug discovery. Amidst the evolving trend in protein language model development, there is an observable shift towards employing large-scale multimodal and multitask models. However, the predominant reliance on empirical assessments using specific benchmark datasets for evaluating these models raises concerns about the comprehensiveness and efficiency of current evaluation methods. Addressing this gap, our study introduces a novel quantitative approach for estimating the performance of transferring multi-task pre-trained protein representations to downstream tasks. This transferability-based method is designed to quantify the similarities in latent space distributions between pre-trained features and those fine-tuned for downstream tasks. It encompasses a broad spectrum, covering multiple domains and a variety of heterogeneous tasks. To validate this method, we constructed a diverse set of protein-specific pre-training tasks. The resulting protein representations were then evaluated across several downstream biological tasks. Our experimental results demonstrate a robust correlation between the transferability scores obtained using our method and the actual transfer performance observed. This significant correlation highlights the potential of our method as a more comprehensive and efficient tool for evaluating protein representation learning.},
  keywords={Task analysis;Proteins;Protein engineering;Biological system modeling;Computational modeling;Predictive models;Biological information theory;Transferability;protein representation learning;optimal transport},
  doi={10.1109/JBHI.2024.3370680},
  ISSN={2168-2208},
  month={May},}@ARTICLE{10787401,
  author={Sukhwal, Prakash C. and Rajan, Vaibhav and Kankanhalli, Atreyi},
  journal={IEEE Journal of Biomedical and Health Informatics}, 
  title={A Joint LLM-KG System for Disease Q&A}, 
  year={2024},
  volume={},
  number={},
  pages={1-14},
  abstract={Medical question answer (QA) assistants respond to lay users' health-related queries by synthesizing information from multiple sources using natural language processing and related techniques. They can serve as vital tools to alleviate issues of misinformation, information overload, and complexity of medical language, thus addressing lay users' information needs while reducing the burden on healthcare professionals. QA systems, the engines of such assistants, have often used large language models (LLMs) or knowledge graphs (KG), though the approaches could be complementary. LLM-based QA systems excel at understanding complex questions and providing well-formed answers but are prone to factual mistakes. KG-based QA systems, which represent facts well, are mostly limited to answering short-answer questions with pre-created templates. While a few studies have used both LLM and KG for text-based QA, the approaches are still prone to incomplete or inaccurate answers. Extant QA systems also have limitations in terms of automation and performance. We address these challenges by designing a novel, automated disease QA system named Disease Guru - Long-Form Question Answer (DG-LFQA), which effectively utilizes both LLM and KG techniques through a joint reasoning approach to answer disease-related questions appropriate for lay users. Our evaluation of the system using a range of quality metrics demonstrates its efficacy over related baseline systems.},
  keywords={Diseases;Medical services;Cognition;Accuracy;Question answering (information retrieval);Measurement;Knowledge graphs;Fake news;Chatbots;Bioinformatics;Question answering;Healthcare;Large language model;Knowledge graph;Information extraction},
  doi={10.1109/JBHI.2024.3514659},
  ISSN={2168-2208},
  month={},}@INPROCEEDINGS{10822706,
  author={Zou, Haochen and Wang, Yongli},
  booktitle={2024 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)}, 
  title={A Novel Knowledge Enhanced Large Language Model Augmented Framework for Medical Question Answering}, 
  year={2024},
  volume={},
  number={},
  pages={3034-3041},
  abstract={Leveraging domain-specific knowledge from pre-trained large language models and knowledge graphs for reasoning in the medical question answering task has emerged as a prominent research field. However, the accuracy of the inference results is restricted by multiple factors, including the quality of analyzed topic entities, the selected inference path in the knowledge graph, and the absence of mutual updating for embedding representations from large language models and knowledge graphs. In this paper, we propose a novel medical question answering framework based on the domain-specific large language model, aiming to enhance the quality of topic entities by implementing the retrieval augmentation technique. Inspired by the concept of chain-of-thought reasoning, we introduce a joint reasoning approach based on analyzed topic entities to facilitate the generation of accurate inference paths. Additionally, we design a unified embedding mechanism that combines representations from both the large language model and graph neural networks, incorporating a pooling operation for predicting answers to input questions. To the best of our knowledge, this work signifies the pioneering efforts in implementing the retrieval augmentation technique and the joint reasoning approach within the context of the medical question answering task. Experimental results on public benchmark datasets demonstrate that the introduced method outperforms state-of-the-art baseline approaches.},
  keywords={Accuracy;Large language models;Biological system modeling;Knowledge graphs;Computer architecture;Benchmark testing;Question answering (information retrieval);Cognition;Graph neural networks;Bioinformatics;Medical question answering;knowledge graph;large language model;graph neural networks},
  doi={10.1109/BIBM62325.2024.10822706},
  ISSN={2156-1133},
  month={Dec},}@INPROCEEDINGS{10800230,
  author={Wang, Zihan and Huo, Hong and Xu, Renxin and Yang, Shijie and Fang, Tao},
  booktitle={2024 7th International Conference on Machine Learning and Natural Language Processing (MLNLP)}, 
  title={Ophthalmic Disease Zero-Shot Question Answering Through Knowledge Triple Augmented Language Model Prompting}, 
  year={2024},
  volume={},
  number={},
  pages={1-11},
  abstract={Ophthalmic disease zero-shot question answering aims to answer questions about ophthalmic disease in natural language without any model training. Although the pretrained large language models (LLMs) have stored quantities of general knowledge of the real-world and made zero-shot question answering come true, they ususally have insufficient ophthalmic knowledge, and fine-tuning LLMs to update their internal ophthalmic knowledge is very compute-intensive and expensive. By utilizing the specialized knowledge in the self-built ophthalmic disease knowledge graph (ODKG) to augment LLMs, the proposed Knowledge Triple Augmented language model Prompting (KTAP) has well implemented ophthalmic disease zero-shot question answering. Our KTAP is primarily divided into three modules: entity linking, knowledge retriever and knowledge injection. The entity linking module extracts ophthalmic disease entities from the question by a prompt-based zero-shot entity linking method, and a subgraph related to these ophthalmic disease entities is obtained from ODKG. The knowledge retriever module consists of two submodules, the text embedding and the similarity matching. The former is responsible for calculating embeddings of both each triple in the subgraph and entities in the question, while the latter calculates the semantic similarity between each triple embedding and the question embedding to obtain the top K triples most relevant to the question. In the knowledge injection module, a prompt template based on the top K triples and the question is designed to guide LLMs to perform ophthalmic disease zero-shot question answering. The experiments have shown that in the zero-shot question answering task of ophthalmic disease, the proposed KTAP has outperformed other language model prompting baselines by an average of 16% in the precision of generated answers.},
  keywords={Training;Computational modeling;Large language models;Semantics;Knowledge graphs;Medical services;Machine learning;Chatbots;Question answering (information retrieval);Diseases;Zero-shot Question Answering;Knowledge Graph;Language Model Prompting;Ophthalmic Disease},
  doi={10.1109/MLNLP63328.2024.10800230},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10845527,
  author={Long, Xinyao and Qiu, Houjie and Liu, Qiang and Su, Xin and Li, Chengqing},
  booktitle={2024 12th International Conference on Information Systems and Computing Technology (ISCTech)}, 
  title={Few-Shot Event Extraction with a Dialogue-based Large Language Model}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Event extraction is critical in various fields, including knowledge graph construction, public opinion monitoring, and situational awareness. Existing methods rely on supervised learning, which depends heavily on the scale and quality of the dataset, while the model’s generalization ability remains weak. As a result, their application in real-world scenarios is significantly constrained. To address this issue, we propose a few-shot event extraction method that harnesses large language models’ reading comprehension and event extraction capabilities. Our approach decomposes the task into multiple stages within a dialog-based framework. Experimental results show that our method outperforms most few-shot techniques, achieving a 4.1% performance improvement over ChatIE.},
  keywords={Computers;Computational modeling;Large language models;Supervised learning;Knowledge graphs;Data mining;Monitoring;Information systems;Few-Shot Event Extraction;Large Language Model},
  doi={10.1109/ISCTech63666.2024.10845527},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10447637,
  author={Santiesteban, Sergio Sánchez and Atito, Sara and Awais, Muhammad and Song, Yi-Zhe and Kittler, Josef},
  booktitle={ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Improved Image Captioning Via Knowledge Graph-Augmented Models}, 
  year={2024},
  volume={},
  number={},
  pages={4290-4294},
  abstract={Multimodal foundation models, pre-trained on large-scale data, effectively capture vast amounts of factual and commonsense knowledge. However, these models store all their knowledge within their parameters, requiring increasingly larger models and training data to capture more knowledge. To address this limitation and achieve a more scalable and modular integration of knowledge, we propose a novel knowledge graph-augmented multimodal model. This approach enables a base multimodal model to access pertinent information from an external knowledge graph. Our methodology leverages existing general domain knowledge to facilitate vision-language pre-training using paired images and text descriptions. We conduct comprehensive evaluations demonstrating that our model outperforms state-of-the-art models and yields comparable results to much larger models trained on more extensive datasets. Notably, our model reached a 145 Cider score on MS COCO Captions using only 2.9 million samples, outperforming a 1.4B parameter model by 1.7% despite having 11 times fewer parameters.},
  keywords={Training;Semantics;Training data;Knowledge graphs;Signal processing;Image representation;Transformers;image captioning;external knowledge;knowledge graphs},
  doi={10.1109/ICASSP48485.2024.10447637},
  ISSN={2379-190X},
  month={April},}@INPROCEEDINGS{9047450,
  author={Wang, Hongzhong and Guo, Kun and Liu, Zhanghui},
  booktitle={2019 IEEE Intl Conf on Parallel & Distributed Processing with Applications, Big Data & Cloud Computing, Sustainable Computing & Communications, Social Computing & Networking (ISPA/BDCloud/SocialCom/SustainCom)}, 
  title={Mixed Word Embedding Method Based on Knowledge Graph Augment for Text Classification}, 
  year={2019},
  volume={},
  number={},
  pages={1618-1623},
  abstract={This paper presents a self-training word embedding text classification model based on knowledge graph expansion for text classification. Current mixed word embedding methods are overly dependent on the Fasttext pre-training model and here is still a problem of missing words with rich semantic information are not mapped. First, we propose a method for extracting missing nouns based on shape near word filtering. Second, we design a self-training word embedding method based on knowledge graph that mixes with pre-training word embedding to obtain a high-quality mixed word vector with rich semantics and rich semantics. Third, we designed a GRU model based on improved mixed word embedding to improve the quality of text classification. Experiments conducted on multiple text classification datasets demonstrate that our methods can effectively improve the text classification accuracy.},
  keywords={Text categorization;Context modeling;Feature extraction;Training;Task analysis;Predictive models;Text Classification;Deep Learning;Mixed Word embedding;Self-trained Word embedding},
  doi={10.1109/ISPA-BDCloud-SustainCom-SocialCom48970.2019.00238},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{9207515,
  author={Pradhan, Abhishek and Todi, Ketan Kumar and Selvarasu, Anbarasan and Sanyal, Atish},
  booktitle={2020 International Joint Conference on Neural Networks (IJCNN)}, 
  title={Knowledge Graph Generation with Deep Active Learning}, 
  year={2020},
  volume={},
  number={},
  pages={1-8},
  abstract={Creating a knowledge graph automatically from raw unstructured text has always been a job of domain expert which takes months to curate and refine. In this paper, we propose a domain-independent semi-automatic knowledge graph learning system that can be trained with less amount of data, to identify entities and relations from a large text corpus. The system performs the following tasks to extract knowledge graph from the text: (i) Named Entity Recognition (NER), and (ii) Relation Identification (Open Relation Extraction (OpenRE) and Classification). The system uses deep active learning to calculate confidence scores using maximum normalized log-probability on each prediction for both NER, and relation identification. We experimented with both LSTM and transformer based models for NER and relation identification tasks. We achieved around 88% F1 score for the NER task on OntoNotes-5.0 English data set with 40% training data set and above 83% F1 score for relation identification on TACRED dataset. The OpenRE and relation classification systems were trained on domain-specific datasets. To the best of our knowledge, we are the first to introduce a knowledge graph generation learning system with deep active learning.},
  keywords={Task analysis;Training;Bit error rate;Feature extraction;Information retrieval;Computer architecture;Learning systems;Active Learning;Named Entity Recognition;Open Relation Extraction;Knowledge Graph;Open Information Extraction},
  doi={10.1109/IJCNN48605.2020.9207515},
  ISSN={2161-4407},
  month={July},}@INPROCEEDINGS{10606805,
  author={Chen, Weilin and Qu, Qiang and Guo, Huifeng and Li, Haibin and Mao, Zehui},
  booktitle={2024 IEEE 13th Data Driven Control and Learning Systems Conference (DDCLS)}, 
  title={A Fault Diagnosis Method for Key Equipment of Bearer Network Transmission Based on Knowledge Graph and Multi-modal Neural Network}, 
  year={2024},
  volume={},
  number={},
  pages={2277-2282},
  abstract={Aiming to address the challenge of incorporating multiple fault phenomena and utilizing accompanying information such as negation and time adverbials in the process of diagnosing faults in key equipment for bearer network transmission, this study proposes a fault diagnosis method based on knowledge graph and multi-modal neural network. By constructing a knowledge graph from a fault diagnosis knowledge base, this method retrieves candidate fault root causes based on the fault phenomena and extracts subgraphs along the reasoning paths from the fault phenomena to the candidate fault root causes in the knowledge graph. Subsequently, leveraging both the reasoning paths within the subgraphs and the fault maintenance texts, the multi-modal neural network calculates the confidence levels of the candidate fault root causes, selecting the fault root cause with the highest confidence as the reasoning conclusion. Finally, the proposed method constructs a knowledge graph based on the fault diagnosis knowledge base of key equipment for bearer network transmission provided by a domestic enterprise, and validates the efficacy of the approach using fault data employed to train the multi-modal neural network. Results demonstrate that this method effectively leverages multiple fault phenomena and their accompanying information in fault maintenance texts for accurate fault diagnosis, yielding favorable performance.},
  keywords={Fault diagnosis;Learning systems;Neural networks;Knowledge based systems;Knowledge graphs;Predictive models;Control systems;Fault Diagnosis;Knowledge Graph;Key Equipment of Bearer Network Transmission;Multi-modal Neural Network},
  doi={10.1109/DDCLS61622.2024.10606805},
  ISSN={2767-9861},
  month={May},}@INPROCEEDINGS{10309699,
  author={Lee, Chang-Shing and Wang, Mei-Hui and Chen, Chih-Yu and Reformat, Marek and Nojima, Yusuke and Kubota, Naoyuki},
  booktitle={2023 IEEE International Conference on Fuzzy Systems (FUZZ)}, 
  title={Knowledge Graph-Based Genetic Fuzzy Agent for Human Intelligence and Machine Co-Learning}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={This paper proposes a novel approach for evaluating the co-learning performance of human intelligence (HI) and machine intelligence (MI) using a Knowledge Graph-based genetic fuzzy agent. The agent utilizes a Knowledge Graph structure to represent a specific knowledge domain related to human learning and employs a genetic fuzzy learning mechanism to construct a personalized learning model. Human learners can engage in co-learning with machines using state-of-the-art AI tools such as the Meta AI S2ST Taiwanese-English language model and the OpenAI ChatGPT text model. The proposed approach was evaluated using human learning data from an undergraduate computer science course and a series of Taiwanese and English language translation experience activities. The experimental results indicate that the proposed approach can effectively enhance the co-learning process for both human and machine learners.},
  keywords={Computer science;Learning systems;Human intelligence;Computational modeling;Speech recognition;Genetics;Chatbots;Knowledge Graph;Genetic Algorithm;Fuzzy Agent;MetaAI S2ST;Human Intelligence;OpenAI ChatGPT},
  doi={10.1109/FUZZ52849.2023.10309699},
  ISSN={1558-4739},
  month={Aug},}@INPROCEEDINGS{8010709,
  author={Silva, Nuno and Mira da Silva, Miguel and Sousa, Pedro Manuel Moreira Vaz Antunes de},
  booktitle={2017 IEEE 19th Conference on Business Informatics (CBI)}, 
  title={Modelling the Evolution of Enterprise Architectures Using Ontologies}, 
  year={2017},
  volume={01},
  number={},
  pages={79-88},
  abstract={Enterprise architecture supports enterprise transformation through model-based holistic descriptions that capture and share the knowledge, concepts, and relationships representing the enterprise. Although enterprise architecture models portray the gap between the as-is and to-be enterprise, they disregard the underlying aspects that together enact enterprise transformation. This paper proposes an ontology-based approach for the specification of the concepts and relationships used to express and analyze the evolution of enterprise architecture models.},
  keywords={Ontologies;Unified modeling language;Computational modeling;Computer architecture;Analytical models;OWL;Business;enterprise architecture;enterprise transformation;model evolution;ontology},
  doi={10.1109/CBI.2017.17},
  ISSN={2378-1971},
  month={July},}@INPROCEEDINGS{10043275,
  author={Mendil, Ismail and Rivière, Peter and Ait-Ameur, Yamine and Singh, Neeraj Kumar and Méry, Dominique and Palanque, Philippe},
  booktitle={2022 29th Asia-Pacific Software Engineering Conference (APSEC)}, 
  title={Non-Intrusive Annotation-Based Domain-Specific Analysis to Certify Event-B Models Behaviours}, 
  year={2022},
  volume={},
  number={},
  pages={129-138},
  abstract={System engineering advocates a thorough under-standing of the engineering domain or certification standards (aeronautics, railway, medical, etc.) associated to the system under design. In this context, engineering domain knowledge plays a predominant role in system design and/or certification. Furthermore, it is a prerequisite to achieve the effectiveness and performance of the designed system. This article proposes a formal method for describing and setting up domain-specific behavioural analyses. It defines a formal verification technique for dynamic properties entailed by engineering domain knowledge where Event-B formal models are annotated and analysed in a non-intrusive way, i.e. without destructive alteration. This method is based on the formalisation of behavioural properties analyses relying on domain knowledge as an ontology on the one hand and a meta-theory for Event-B on the other hand. The proposed method is illustrated using a critical interactive system.},
  keywords={Knowledge engineering;Analytical models;Interactive systems;Ontologies;Rail transportation;Proposals;Certification;Domain knowledge;formal methods;Event-B;refinement;proof;ontology;behavioural analyses},
  doi={10.1109/APSEC57359.2022.00025},
  ISSN={2640-0715},
  month={Dec},}@INPROCEEDINGS{10800180,
  author={Wang, Changlong and Sang, Xiujuan and Wang, Xijie and Gao, Yuan and Liu, Yi},
  booktitle={2024 7th International Conference on Machine Learning and Natural Language Processing (MLNLP)}, 
  title={Research on Knowledge Graph Extraction Methods for Chinese STEM Curriculum}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={STEM education, as an innovative teaching model, has gained widespread attention in recent years. However, the lack of relevant textbooks and learning resources has made its implementation challenging. Developing interdisciplinary knowledge graphs tailored for STEM education has become an urgent issue. To address this, a knowledge extraction framework named Llms4edu is proposed, which utilizes a series of effective prompts to guide large language models in knowledge extraction. Specifically, the knowledge extraction task is transformed into multiple rounds of question-and-answer interactions with the LLM, gradually identifying entity-relation triplets from subject data. Through experiments, an F1-score of 89.4% was achieved on the named entity recognition task in the chemistry subject, and an F1-score of 66.7% on the relation extraction task. Finally, a subject ontology model was built for subject text, and a subject data set was constructed using Llms4edu, which includes three subjects of junior high school mathematics, physics, and chemistry, a total of 2,511 entities, 2,010 relationship triples, and cross-disciplinary knowledge is linked to construct a cross-disciplinary knowledge graph.},
  keywords={Knowledge engineering;Training;Chemistry;Annotations;Large language models;Knowledge graphs;Named entity recognition;Ontologies;Data mining;Physics;interdisciplinary knowledge graph;large language model;prompt engineering},
  doi={10.1109/MLNLP63328.2024.10800180},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{9742010,
  author={Yang, Wansheng and Deng, Fei and Ma, Siyou and Wu, Linbo and Sun, Zhe and Hu, Chi},
  booktitle={2021 IEEE 21st International Conference on Software Quality, Reliability and Security Companion (QRS-C)}, 
  title={Test Case Reuse Based on Software Testing Knowledge Graph and Collaborative Filtering Recommendation Algorithm}, 
  year={2021},
  volume={},
  number={},
  pages={67-76},
  abstract={As an important role of software test, the reuse of test cases is essential in terms of finding software defects and locating the causes of them. However, the existing related approaches are insufficient to establish an internal relationship between test cases and defects and their abilities to find or diagnose errors are limited. In this paper, an ontology model based on the software testing process is applied to establish a software testing knowledge graph, which serves as the foundation to build an recommendation system. Specifically, the recommendation system takes the functions of software under test as the “user”, and the defect-occurrence-chain which establishes the correlation between test cases and defects in the knowledge graph as the “item”. Both of them provide the evidence to build collaborative filtering recommendation algorithm based on the user-item scoring matrix. It aims to assist testers in recommending reusable test cases to identify software errors effectively. Against this background, the BERT+Bi-LSTM-CRF model is selected to extract the latent test requirements of the software under test, and an overt variable factorization model is built so as to iteratively optimize the user-item scoring matrix. Further, an empirical study has been conducted, and it is found that the recommended test cases can significantly help testers find software defects faster in a more efficient way, and locate defects more accurately.},
  keywords={Software testing;Collaborative filtering;Software algorithms;Semantics;Software quality;Ontologies;Software;software testing knowledge graph;collaborative filtering;BERT+Bi-LSTM-CRF;defect-occurrence-chain;overt variable factorization model},
  doi={10.1109/QRS-C55045.2021.00020},
  ISSN={2693-9371},
  month={Dec},}@ARTICLE{10734210,
  author={Xu, Jun and Zhang, Hao and Zhang, Haijing and Lu, Jiawei and Xiao, Gang},
  journal={IEEE Access}, 
  title={ChatTf: A Knowledge Graph-Enhanced Intelligent Q&A System for Mitigating Factuality Hallucinations in Traditional Folklore}, 
  year={2024},
  volume={12},
  number={},
  pages={162638-162650},
  abstract={Large language models are rapidly advancing the field of artificial intelligence, with current research focusing primarily on traditional natural language understanding tasks, such as question answering and information extraction. However, in knowledge-intensive domains, such as intangible cultural heritage, hallucination problems due to insufficient domain knowledge persist. To address this, we present ChatTf, a knowledge graph-enhanced intelligent Q&A system, exemplified by Chinese traditional folklore, aimed at reducing factuality hallucinations in this domain. Specifically, we constructed the Traditional Folklore Ontology (TFOnto) and proposed the Zero-shot Traditional Folklore Triplet Extraction (ZFTE) framework. Driven by TFOnto, ZFTE builds a Traditional Folklore Knowledge Graph (TFKG). We then proposed a dual-stage Retrieval-Augmented Generation framework (TFKG-RAG) based on TFKG to provide traditional folklore knowledge to large language models, mitigating factuality hallucinations in folklore Q&A tasks. In the experimental phase, ChatTf achieved an accuracy of 96.7% on a self-built TFCQD test set, outperforming several state-of-the-art baseline methods. This demonstrates the accuracy and reliability of folklore domain question answering.},
  keywords={Ontologies;Knowledge graphs;Cultural differences;Large language models;Knowledge engineering;Training;Cognition;Accuracy;Semantics;Reliability;Knowledge graph;large language model;question answering;retrieval-augmented generation;traditional folklore},
  doi={10.1109/ACCESS.2024.3485877},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10825785,
  author={Mansur, Elijah and Chen, Johnson and Raza, Muhammad Anas and Wardat, Mohammad},
  booktitle={2024 IEEE International Conference on Big Data (BigData)}, 
  title={RAGFix: Enhancing LLM Code Repair Using RAG and Stack Overflow Posts}, 
  year={2024},
  volume={},
  number={},
  pages={7491-7496},
  abstract={Identifying, localizing, and resolving bugs in software engineering is challenging and costly. Approaches to resolve software bugs range from Large Language Model (LLM) code analysis and repair, and automated code repair technology that aims to alleviate the technical burden of difficult to solve bugs. We propose RAGFix, which enhances LLM’s capabilities for bug localization and code repair using Retrieval Augmented Generation (RAG) based on dynamically collected Stack Overflow posts. These posts are searchable via a Question and Answer Knowledge Graph (KGQA). We evaluate our method on the HumanEvalFix benchmark for Python using relevant closed and open-source models. Our approach facilitates error resolution in Python coding problems by creating a searchable, embedded knowledge graph representation of bug and solution information from Stack Overflow, interlinking bugs, and solutions through semi-supervised graph construction methods. We use cosine similarity on embeddings based on LLM-synthesized summaries and algorithmic features describing the coding problem and potential solution to find relevant results that improve LLM in-context performance. Our results indicate that our system enhances small open-source models’ ability to effectively repair code, particularly where these models have less parametric knowledge about relevant coding problems and can leverage nonparametric knowledge to provide accurate, actionable fixes.},
  keywords={Codes;Computer bugs;Retrieval augmented generation;Knowledge graphs;Maintenance engineering;Search problems;Encoding;Software;Python;Software engineering;Retrieval-augmented generation;Large Language Models;knowledge graph;Bug detection;Code Repair},
  doi={10.1109/BigData62323.2024.10825785},
  ISSN={2573-2978},
  month={Dec},}@ARTICLE{9950327,
  author={Zhao, Yingwen and Yang, Zhihao and Hong, Yongkai and Wang, Lei and Zhang, Yin and Lin, Hongfei and Wang, Jian},
  journal={IEEE Journal of Biomedical and Health Informatics}, 
  title={Improving Protein Function Prediction by Adaptively Fusing Information From Protein Sequences and Biomedical Literature}, 
  year={2023},
  volume={27},
  number={2},
  pages={1140-1148},
  abstract={Proteins are the main undertakers of life activities, and accurately predicting their biological functions can help human better understand life mechanism and promote the development of themselves. With the rapid development of high-throughput technologies, an abundance of proteins are discovered. However, the gap between proteins and function annotations is still huge. To accelerate the process of protein function prediction, some computational methods taking advantage of multiple data have been proposed. Among these methods, the deep-learning-based methods are currently the most popular for their capability of learning information automatically from raw data. However, due to the diversity and scale difference between data, it is challenging for existing deep learning methods to capture related information from different data effectively. In this paper, we introduce a deep learning method that can adaptively learn information from protein sequences and biomedical literature, namely DeepAF. DeepAF first extracts the two kinds of information by using different extractors, which are built based on pre-trained language models and can capture rudimentary biological knowledge. Then, to integrate those information, it performs an adaptive fusion layer based on a Cross-attention mechanism that considers the knowledge of mutual interactions between two information. Finally, based on the mixed information, DeepAF utilizes logistic regression to obtain prediction scores. The experimental results on the datasets of two species (i.e., Human and Yeast) show that DeepAF outperforms other state-of-the-art approaches.},
  keywords={Proteins;Protein engineering;Data mining;Biological system modeling;Amino acids;Semantics;Predictive models;Protein function prediction;deep learning;multiple data;pre-trained language models;cross-attention mechanism},
  doi={10.1109/JBHI.2022.3221988},
  ISSN={2168-2208},
  month={Feb},}@INPROCEEDINGS{9574313,
  author={Wang, Xiaochen and Jia, Qinlin and Du, Hui},
  booktitle={2021 IEEE International Conference on Advances in Electrical Engineering and Computer Applications (AEECA)}, 
  title={An Intelligent Question Answering Method Combining Knowledge Graph and Corpus}, 
  year={2021},
  volume={},
  number={},
  pages={1050-1054},
  abstract={Traditional question answering methods are basically divided into the retrieval of KG (Knowledge Graph) and the QA (Question Answering) corpus. The purpose of this paper is to combine both types of methods to devise a quick and comprehensive QA method. In terms of question identifying, a method of question classification label and answer template are defined. The data used to fabricate the KG comes from the books. During processing the text data, Bi-LSTM-CRF combined with the BIO text labeling method is used to carry out named entity recognition. The relationships and attributes of entities are identified using parameter sharing through the previously defined tags and dictionaries. The KG will be stored and retrieved in the graph database. Moreover, the QA corpus comes from three sources: discussion issues, tutor-student interaction, and crowdsourcing platform. It focuses on solving multi-attribute multi-relationship problems that are not included in the KG. QA corpus will output the highest-ranking answer by comparing the semantic similarity of the questions. The final answer output is given both from KG and QA corpus.},
  keywords={Measurement;Electrical engineering;Crowdsourcing;Dictionaries;Text recognition;Databases;Conferences;KG;QA Corpus;Bi-LSTM-CRF;BIO;Text-CNN;Semantic Similarity},
  doi={10.1109/AEECA52519.2021.9574313},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{9194542,
  author={Lv, Jianghai and Du, Junping and Zhou, Nan and Xue, Zhe},
  booktitle={2020 IEEE International Conference on Knowledge Graph (ICKG)}, 
  title={BERT-BIGRU-CRF: A Novel Entity Relationship Extraction Model}, 
  year={2020},
  volume={},
  number={},
  pages={157-164},
  abstract={Entity name recognition and entity relationship extraction are the most critical foundation for building knowledge graph, and it is also the basic task of NPL. The main purpose of entity relationship extraction is to extract the semantic relationship between the pairs of marked entities in the sentence, that is, to determine the relationship categories between entity pairs in unstructured text based on entity identification, and to form structured data for storage and retrieval. This paper proposes a BERT-BIGRU-CRF entity relationship extraction method, which effectively changes the relationship between the pre-training generated word vector and the downstream specific NLP task, and gradually moves the downstream specific NLP task to the pre-training generated word vector. Our method achieves better performance of relationship extraction and entity name recognition, which helps to construct the knowledge graph more accurately.},
  keywords={Bit error rate;Feature extraction;Task analysis;Predictive models;Semantics;Communications technology;Training;Pre-training deep learning;Transformer encoder;Sentence-level representation;Masked LM},
  doi={10.1109/ICBK50248.2020.00032},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10747006,
  author={Almiani, Muder and Abu-Salih, Bilal and Alotaibi, Salihah and Aljaafari, Mohammed and Azar, Dima and Alrawashdeh, Tawfiq and Tahat, Yasean},
  booktitle={2024 Fifth International Conference on Intelligent Data Science Technologies and Applications (IDSTA)}, 
  title={Knowledge Graph Embedding for Detecting Brand Advocates in Online Social Networks}, 
  year={2024},
  volume={},
  number={},
  pages={137-144},
  abstract={In the dynamic and ever-changing environment of social media, customer advocacy forms part of the key success factors that need to be monitored by brand teams. Focusing on the social media engagement aspect, this paper outlines a conceptual model that guides the evaluation of customer advocacy.The approach involves developing a Knowledge Graph (KG) that captures the complex connections among customers, brands, and even products. The KG is constructed based on state-of-the-art methods of entity and relationship Mining from social media text, backed by a highly layered structure with XLNet, BiLSTM, and CRF ensembles. The performance of the KG embedding models namely TransE, DistMult, ComplEx, HolE, and RotatE models are assessed with parameters such as Hits@k, Median Rank (MR), Mean Reciprocal Rank (MRR), and Mean Rank. The performance of RotatE framework to predict relationships within the KG and its accuracy have been shown by the experimental results. In this respect, the results reveal the importance of KG-based perspectives for investigating and resolving issues related to customer advocacy, as well as for developing relevant marketing strategies in contemporary environment..},
  keywords={Sentiment analysis;Systematics;Social networking (online);Scalability;Soft sensors;Knowledge graphs;Predictive models;Web sites;Multimedia communication;Monitoring;Social Media Marketing;Online Brand Advocates Detection;Knowledge Graphs;KG Embedding;Social Media Analysis},
  doi={10.1109/IDSTA62194.2024.10747006},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{8536159,
  author={Prince Sales, Tiago and Almeida, João Paulo A. and Santini, Sebastiano and Baião, Fernanda and Guizzardi, Giancarlo},
  booktitle={2018 IEEE 22nd International Enterprise Distributed Object Computing Conference (EDOC)}, 
  title={Ontological Analysis and Redesign of Risk Modeling in ArchiMate}, 
  year={2018},
  volume={},
  number={},
  pages={154-163},
  abstract={Risk analysis is a complex and critical activity in various contexts, ranging from strategic planning to IT systems operation. Given its complexity, several Enterprise Architecture (EA) frameworks and modeling languages have been developed to help analysts in representing and analyzing risks. Yet, the notion of risk remains overloaded and conceptually unclear in most of them. In this paper, we investigate the real-world semantics underlying risk-related constructs in one of such approaches, namely ArchiMate's Risk and Security Overlay (RSO). We perform this investigation by means of ontological analysis to reveal semantic limitations in the overlay, such as ambiguity and missing constructs. Building on the results of this analysis, we propose a well-founded redesign of the risk modeling aspects of the RSO.},
  keywords={Security;Organizations;Ontologies;Risk management;Analytical models;Semantics;Risk Modeling;Enterprise Architecture;ArchiMate;Ontological Analysis;Unified Foundational Ontology},
  doi={10.1109/EDOC.2018.00028},
  ISSN={2325-6362},
  month={Oct},}@INPROCEEDINGS{10450693,
  author={Li, Dongze and Qu, Hanbing and Wang, Jiaqiang},
  booktitle={2023 China Automation Congress (CAC)}, 
  title={A Survey on Knowledge Graph-Based Recommender Systems}, 
  year={2023},
  volume={},
  number={},
  pages={2925-2930},
  abstract={Recommender systems have emerged as indispensable tools for information filtering, and the integration of knowledge graphs for auxiliary information is becoming an increasingly popular research topic. This paper reviews recent studies, discussing the current state and practical applications of knowledge graph-based recommender systems. We summarize the strengths and weaknesses of various knowledge graph-based recommendation methods, noting that these systems significantly enhance performance in areas like accuracy, diversity, interpretability, and novelty. Furthermore, the trend of combining different knowledge graph-based methods underscores the mainstream evolution of recommender systems, warranting future exploration. We finish with an analysis of current challenges and a forward-looking perspective on future advances. This review aims to assist the reader in understanding and navigating this research field.},
  keywords={Surveys;Automation;Reviews;Navigation;Diversity reception;Knowledge graphs;Market research;Recommender System;Knowledge Graph;Contrastive Learning;Reinforcement Learning},
  doi={10.1109/CAC59555.2023.10450693},
  ISSN={2688-0938},
  month={Nov},}@INPROCEEDINGS{9581237,
  author={Liu, Xinlong and Xu, Li-Qun},
  booktitle={2021 IEEE International Conference on Digital Health (ICDH)}, 
  title={Knowledge Graph Building from Real-world Multisource “Dirty” Clinical Electronic Medical Records for Intelligent Consultation Applications}, 
  year={2021},
  volume={},
  number={},
  pages={260-265},
  abstract={Intelligent clinical consultation is a diagnostic support system that inferred the likely diseases from the patient's chief complaints as per the established relationship between symptoms and diseases. The key here is to learn and build automatically the general “symptom-disease” medical knowledge graph (MKG) from real-world clinical data. So, the quality of clinical data (chiefly electronic medical records - EMRs) directly affects the quality of the MKG, which in turn determines the quality of the consultation results. The regional public health information platform gathered a large number of front-pages of EMRs' from hospitals of all tiers across the region. The fact that the health IT systems used by hospitals are often sourced from different vendors, and each may have its own data standards and data quality control criteria, would invariably lead to apparent difference in the quality of EMRs collected. This is even so, considering the gaps in knowledge and skills between clinicians at different qualification levels. By detailed analysis of one such collection we found that the two most prominent problems are the inconsistency in diagnosis results and the mismatch between the diagnosis results and the chief complaints and the current illness history. In order to ensure the quality and effectiveness in building a knowledge graph from these real-world data, this paper proposed a “dirty” data cleaning framework including diagnostic results normalization and semantic similarity matching. The symptom-disease knowledge graph constructed from the cleaned data has been applied and verified in the intelligent consultation system.},
  keywords={Hospitals;Data integrity;Semantics;Electronic medical records;Task analysis;Public healthcare;Medical diagnostic imaging;Knowledge graph;data cleaning;diagnostic results normalization;semantic similarity},
  doi={10.1109/ICDH52753.2021.00049},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{9313350,
  author={Sastre, Javier and Zaman, Faisal and Duggan, Noirin and McDonagh, Caitlin and Walsh, Paul},
  booktitle={2020 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)}, 
  title={A Deep Learning Knowledge Graph Approach to Drug Labelling}, 
  year={2020},
  volume={},
  number={},
  pages={2513-2521},
  abstract={Ensuring the accuracy and completeness of drug labels is a labour-intensive and potentially error prone process, as labels contain unstructured text that is not suitable for automated processing. To address this, we have developed a novel deep learning system that uses a bidirectional LSTM model to extract and structure drug information in a knowledge graph-based embedding space. This allows us to evaluate drug label consistency with ground truth knowledge, along with the ability to predict additional drug interactions. Annotated sentences from 7,117 drug labels sentences were used to train the LSTM model and 1,779 were used to test it. The drug entity extraction system was able to correctly detect relevant entities and relations with a F1 score of 91% and 81% respectively. The knowledge graph embedding model was able to identify inconsistent facts with ground truth data in 76% of the cases tested. This demonstrates that there is potential in building a natural language processing system that automatically extracts drug interaction information from drug labels and embeds this structured data into a knowledge graph embedding space to help evaluate drug label accuracy. We note that the accuracy of the system needs to be improved significantly before it can fully automate drug labeling related tasks. Rather such a system could provide best utility within a human-in-the-loop approach, where operators augment model training and evaluation.},
  keywords={Drugs;Data mining;Deep learning;Information retrieval;Feature extraction;Task analysis;Labeling;drug labels;deep learning;knowledge graph embeddings;LSTM},
  doi={10.1109/BIBM49941.2020.9313350},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10796042,
  author={Ji, Lintian and Du, Shuxin and Qiu, Yi and Xu, Hongyi and Guo, Xiaorui},
  booktitle={2024 IEEE 6th International Conference on Power, Intelligent Computing and Systems (ICPICS)}, 
  title={Constructing a Medical Domain Functional Knowledge Graph with Large Language Models}, 
  year={2024},
  volume={},
  number={},
  pages={491-496},
  abstract={The integration of medicine and artificial intelligence is creating novel opportunities to gather, analyze, and generate groundbreaking medical insights from the vast expanse of medical literature. Although these advancements hold great promise, difficulties including manual annotation and precise data retrieval, and transparency persist. Advanced natural language processing (NLP) techniques and large language models (LLMs) have shown potential in addressing these issues. This paper introduces the Medical Knowledge Graph (MedKG), a comprehensive and multidisciplinary medical knowledge graph. By utilizing advanced NLP algorithms, MedKG extracts millions of entities and converts them into triples from a corpus of superior medical research papers published over the last decade. It categorizes unstructured medical information into nine distinct tags, including disease names, treatments, diagnoses, symptoms, genetics, cellular structures of diseases, patient data, medical procedures, and treatment applications, while seamlessly integrating the digital object identifier (DOI) of each paper. As the latest structured database of medical knowledge, MedKG serves as a powerful tool for accelerating medical research and lays the groundwork for constructing a more extensive medical knowledge graph using full-text medical articles. Moreover, our research establishes a foundation for practical knowledge management systems based on text mining, applicable not only to complex medical systems but also to other professional domains.},
  keywords={Text mining;Annotations;Large language models;Pipelines;Knowledge graphs;Prediction algorithms;Natural language processing;Object recognition;Medical diagnostic imaging;Diseases;Medical engineering;NLP;Large language model;Knowledge graph;Database},
  doi={10.1109/ICPICS62053.2024.10796042},
  ISSN={2834-8567},
  month={July},}@INPROCEEDINGS{9945152,
  author={Zhu, Yangfu and Guan, Zhanming and Wei, Siqi and Wu, Bin},
  booktitle={2022 IEEE International Conference on Systems, Man, and Cybernetics (SMC)}, 
  title={PerKG: A Personality Knowledge Graph for Personality Analysis}, 
  year={2022},
  volume={},
  number={},
  pages={580-585},
  abstract={With the blossoming of online social networks (OSN), personality analysis based on OSN texts has gained much research attention in recent years. The previous methods mainly focus on human-designed features extracted through psychological dictionaries or semantic features extracted through language models. However, the shallow statistics features can not fully convey the personality information and the language models can not capture enough psychological background knowledge. Besides, the lack of large labeled datasets has been a serious obstacle impending further research. To tackle these problems, we propose a personality analysis model, namely PerKG, which combines personality knowledge graph and heterogeneous graph representation learning to exploit external knowledge from psycholinguistics and learn the group-level information to predict users’ personalities accurately. Specifically, we construct a personality knowledge graph based on existing psycholinguistics knowledge. And then, for each user, we align the user information with the knowledge graph to obtain the personality heterogeneous graph. Finally, the personality vector of each entity node is learned for prediction by designing a walk strategy on the personality heterogeneous graph. Detailed experimentation shows that our proposed PerKG architecture can effectively improve the performance and alleviate the label sparsity problem of personality analysis.},
  keywords={Knowledge engineering;Representation learning;Dictionaries;Social networking (online);Semantics;Psychology;Predictive models;knowledge graph;network representation learning;personality analysis;online social network},
  doi={10.1109/SMC53654.2022.9945152},
  ISSN={2577-1655},
  month={Oct},}@INPROCEEDINGS{10340611,
  author={Labbé, Thomas and Castel, Pierre and Sanner, Jean-Michel and Saleh, Majd},
  booktitle={2023 45th Annual International Conference of the IEEE Engineering in Medicine & Biology Society (EMBC)}, 
  title={ChatGPT for phenotypes extraction: one model to rule them all?}, 
  year={2023},
  volume={},
  number={},
  pages={1-4},
  abstract={Information Extraction (IE) is a core task in Natural Language Processing (NLP) where the objective is to identify factual knowledge in textual documents (often unstructured), and feed downstream use cases with the resulting output. In genomic medicine for instance, being able to extract the most precise list of phenotypes associated to a patient allows to improve genetic disease diagnostic, which represents a vital step in the modern deep phenotyping approach. As most of the phenotypic information lies in clinical reports, the challenge is to build an IE pipeline to automatically recognize phenotype concepts from free-text notes. A new machine learning paradigm around large language models (LLM) has given rise of an increasing number of academic works on this topic lately, where sophisticated combinations of different technics have been employed to improve the phenotypes extraction accuracy. Even more recently released, the ChatGPT1 application nevertheless raises the question of the relevance of these approches compared to this new generic one based on an instruction-oriented LLM. In this paper, we propose a rigorous evaluation of ChatGPT and the current state-of-the-art solutions on this specific task, and discuss the possible impacts and the technical evolutions to consider in the medical domain.Clinical relevance— Deep phenotyping on electronic health records has proven its ability to improve genetic diagnosis by clinical exomes [10]. Thus, comparing state-of-the-art solutions in order to derive insights and improving research paths is essential.},
  keywords={Temperature distribution;Pipelines;Statistical distributions;Machine learning;Ontologies;Chatbots;Information retrieval},
  doi={10.1109/EMBC40787.2023.10340611},
  ISSN={2694-0604},
  month={July},}@ARTICLE{9091850,
  author={Ji, Zizheng and Dai, Lin and Pang, Jin and Shen, Tingting},
  journal={IEEE Access}, 
  title={Leveraging Concept-Enhanced Pre-Training Model and Masked-Entity Language Model for Named Entity Disambiguation}, 
  year={2020},
  volume={8},
  number={},
  pages={100469-100484},
  abstract={Named Entity Disambiguation (NED) refers to the task of resolving multiple named entity mentions in an input-text sequence to their correct references in a knowledge graph. We tackle NED problem by leveraging two novel objectives for pre-training framework, and propose a novel pre-training NED model. Especially, the proposed pre-training NED model consists of: (i) concept-enhanced pre-training, aiming at identifying valid lexical semantic relations with the concept semantic constraints derived from external resource Probase; and (ii) masked entity language model, aiming to train the contextualized embedding by predicting randomly masked entities based on words and non-masked entities in the given input-text. Therefore, the proposed pre-training NED model could merge the advantage of pre-training mechanism for generating contextualized embedding with the superiority of the lexical knowledge (e.g., concept knowledge emphasized here) for understanding language semantic. We conduct experiments on the CoNLL dataset and TAC dataset, and various datasets provided by GERBIL platform. The experimental results demonstrate that the proposed model achieves significantly higher performance than previous models.},
  keywords={Context modeling;Task analysis;Semantics;Predictive models;Adaptation models;Natural language processing;Neural networks;Named entity disambiguation;pre-training;lexical knowledge},
  doi={10.1109/ACCESS.2020.2994247},
  ISSN={2169-3536},
  month={},}@ARTICLE{9292918,
  author={Gong, Peizhu and Liu, Jin and Yang, Yihe and He, Huihua},
  journal={IEEE Access}, 
  title={Towards Knowledge Enhanced Language Model for Machine Reading Comprehension}, 
  year={2020},
  volume={8},
  number={},
  pages={224837-224851},
  abstract={Machine reading comprehension is a crucial and challenging task in natural language processing (NLP). Recently, knowledge graph (KG) embedding has gained massive attention as it can effectively provide side information for downstream tasks. However, most previous knowledge-based models do not take into account the structural characteristics of the triples in KGs, and only convert them into vector representations for direct accumulation, leading to deficiencies in knowledge extraction and knowledge fusion. In order to alleviate this problem, we propose a novel deep model KCF-NET, which incorporates knowledge graph representations with context as the basis for predicting answers by leveraging capsule network to encode the intrinsic spatial relationship in triples of KG. In KCF-NET, we fine-tune BERT, a highly performance contextual language representation model, to capture complex linguistic phenomena. Besides, a novel fusion structure based on multi-head attention mechanism is designed to balance the weight of knowledge and context. To evaluate the knowledge expression and reading comprehension ability of our model, we conducted extensive experiments on multiple public datasets such as WN11, FB13, SemEval-2010 Task 8 and SQuAD. Experimental results show that KCF-NET achieves state-of-the-art results in both link prediction and MRC tasks with negligible parameter increase compared to BERT-Base, and gets competitive results in triple classification task with significantly reduced model size.},
  keywords={Task analysis;Semantics;Knowledge engineering;Knowledge based systems;Bit error rate;Encoding;Syntactics;Machine reading comprehension;knowledge graph embedding;BERT;capsule network},
  doi={10.1109/ACCESS.2020.3044308},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10638283,
  author={Hendawi, Rasha and Alian, Shadi and Li, Juan},
  booktitle={2024 15th International Conference on Information and Communication Systems (ICICS)}, 
  title={Breaking Down Barriers: Empowering Diabetes Patients with User-Friendly Medical Explanations}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Effective management of diabetes is contingent upon patients' understanding of their medical conditions and treatments. However, medical documents often contain complex jargon and technical details that can be challenging for patients, especially those with limited health literacy. This paper presents DiaKnow, an innovative tool that simplifies medical documents and customizes explanations to suit individual health literacy levels. Employing a robust self-attention transformer model and a comprehensive diabetes-focused knowledge graph, DiaKnow enhances patient comprehension by providing contextually relevant, simplified medical information. This study assesses DiaKnow’s efficacy in real-world clinical settings through a structured use case evaluation method. We tested the tool’s ability to accurately identify, link, and simplify crucial medical terms using a diverse set of medical documents. Our findings confirm that DiaKnow not only improves the readability of medical documents but also ensures that explanations are medically accurate, clear, and comprehensive.},
  keywords={Accuracy;Communication systems;Transforms;Knowledge graphs;Transformers;Diabetes;Context modeling;health literacy;knowledge graph;ontology;self-attention transformers;medical entity recognition;entity linking},
  doi={10.1109/ICICS63486.2024.10638283},
  ISSN={2573-3346},
  month={Aug},}@INPROCEEDINGS{10456842,
  author={Ollier, Guillaume and Adedjouma, Morayo and Gerasimou, Simos and Mraidha, Chokri},
  booktitle={2023 26th Euromicro Conference on Digital System Design (DSD)}, 
  title={An Ontological Approach for the Dependability Analysis of Automated Systems}, 
  year={2023},
  volume={},
  number={},
  pages={593-601},
  abstract={This paper presents the Ontology Language for the Dependability of Automated Systems (OLDAS), a modeling language based on Unified Modeling Language (UML) that aims to support dependability assessment for Automated Systems (ASs), i.e., systems intended to perform a function with minimal or no human intervention. OLDAS extends the Unified Foundational Ontology (UFO) and embeds validation rules to prevent constraint violations in ASs analysis. Specifically, the paper presents how OLDAS can support different activities during the design of ASs, from the definition of the Operational Design Domain to scenario-based analysis. OLDAS is available as a plugin of the open-source Papyrus for Robotics framework.},
  keywords={Analytical models;Runtime;Unified modeling language;Redundancy;Ontologies;Probabilistic logic;Hazards;Autonomous Systems;Automated Driving Systems;Artificial Intelligence;Safety Engineering;ODD;ML-based Systems},
  doi={10.1109/DSD60849.2023.00087},
  ISSN={2771-2508},
  month={Sep.},}@INPROCEEDINGS{8258079,
  author={Kim, Youngho and Zerfos, Petros and Sheinin, Vadim and Greco, Nancy},
  booktitle={2017 IEEE International Conference on Big Data (Big Data)}, 
  title={Ranking the importance of ontology concepts using document summarization techniques}, 
  year={2017},
  volume={},
  number={},
  pages={1457-1466},
  abstract={Automated Ontology Learning systems are nowadays practical and used in a variety of domains. By using these systems, subject matter experts (SMEs) and ontology designers can readily construct very large ontologies consisting of tens of thousands of concepts and their relations based on a corpus. However, ontologies of this size make it extremely challenging for such SMEs to understand and further tune these ontologies. Prior studies have proposed techniques for concept ranking based solely on the analysis of the structure of the ontology graphs. In this paper, we propose a novel approach, which further exploits a word-level summarization technique applied to the source documents used to generate the ontology. Using the document summarization technique, we devise features that measure concept importance based on source documents where concepts are extracted. We demonstrate the effectiveness of our approach by comparing with existing ranking methods and by devising a scalable evaluation process inspired from the document retrieval domain.},
  keywords={Ontologies;Dogs;Learning systems;Feature extraction;Visualization;Measurement},
  doi={10.1109/BigData.2017.8258079},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{8869059,
  author={Patzer, Florian and Volz, Friedrich and Usländer, Thomas and Blöcher, Immanuel and Beyerer, Jürgen},
  booktitle={2019 24th IEEE International Conference on Emerging Technologies and Factory Automation (ETFA)}, 
  title={The Industrie 4.0 Asset Administration Shell as Information Source for Security Analysis}, 
  year={2019},
  volume={},
  number={},
  pages={420-427},
  abstract={One of the essential concepts of the Reference Architecture Model Industrie 4.0 (RAMI4.0) is the uniform modelling of assets by means of a common meta-data model called the Asset Administration Shell (AAS). However, important practical experience with this concept is still missing, as not many use cases for the AAS have yet been implemented. Thus, practical issues within the AAS concept and respective solutions are hard to identify. In this paper, presents our experience with the implementation of an AAS use case. The AAS is used as information source to create an ontology, which is then used for security analysis. The paper discusses the use-case-specific modelling language selection and provides a practical examination of several of our implementations that use OWL and OPC UA together. Furthermore, it provides recommendations for the implementation of Asset Administration Shells for this and similar use cases.},
  keywords={Security;Protocols;Data models;Analytical models;Tools;XML;Cognition;Asset Administration Shell;Security Ontology;Ontology;OPC UA;Semantic Web;Industrial Systems},
  doi={10.1109/ETFA.2019.8869059},
  ISSN={1946-0759},
  month={Sep.},}@ARTICLE{10633699,
  author={Woods, Caitlin and Hodkiewicz, Melinda and French, Tim},
  journal={IEEE Access}, 
  title={Semantic Quality Assurance of Industrial Maintenance Procedures}, 
  year={2024},
  volume={12},
  number={},
  pages={122029-122046},
  abstract={Maintenance technicians in industry follow procedures that guide them through inspection, repair, and service tasks. Organisations seek to convert procedure documentation to machine-readable formats as their digital capabilities improve and regulatory requirements tighten. In this paper, we consider the opportunity for semantic quality assurance of digital procedures. We demonstrate a configurable and repeatable workflow containing three modules. The completeness module makes implicit information in procedures explicit using OpenAI’s Generative Pre-trained Transformer (GPT) model. The consistency module creates Resource Description Framework (RDF) triples that are aligned with, and checked against, the axioms of the open-source Ontology for Maintenance Procedure Documentation (OMPD). Finally, the correctness module performs closed-world checks on the RDF triples using the Shapes Constraints Language (SHACL). Each module can be used in isolation, or together, to realise an end-to-end semi-automated quality assurance workflow. Pre-processing of the raw maintenance procedure documents to extract entities (tools, materials and activities) and relations is achieved in a novel manner using prompt engineering with OpenAI’s GPT-3.5 Turbo model and few-shot learning. This end-to-end workflow enables organisations to perform quality assurance such as assessing the correct order for task sequences, and checking that all maintenance procedures have at least one maintenance task. We demonstrate this workflow on six procedures from the iFixit repository. The outputs of this workflow support maintenance technicians, planners and engineers by realising high-quality procedure documentation and automated procedure management update processes. The code and data used in this work is publicly available at https://github.com/equonto/quokka/.},
  keywords={Maintenance;Ontologies;OWL;Resource description framework;Data models;Documentation;Task analysis;Industrial ontology;ontology templates;OpenAI GPT;OTTR;SHACL;technical language processing},
  doi={10.1109/ACCESS.2024.3441757},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10412837,
  author={Guo, Menghao and Wu, Fan and Jiang, Jinling and Yan, Xiaoran and Chen, Guangyong and Li, Wenhui and Zhao, Yunhong and Sun, Zeyi},
  booktitle={2023 IEEE International Conference on Knowledge Graph (ICKG)}, 
  title={Investigations on Scientific Literature Meta Information Extraction Using Large Language Models}, 
  year={2023},
  volume={},
  number={},
  pages={249-254},
  abstract={The meta information in scientific literature including article title, author, institutions, year, journal, etc., plays a critical role in providing useful information to research peers. Traditional meta information extraction methods usually rely on rules and templates. Recently, due to the booming of Large Language Models (LLMs), its application in scientific literature meta-information extraction has drawn more and more attention. This paper aims to explore and evaluate the effects of meta information extraction for scientific literature using large language models. First, datasets consisting of the publications in given academic areas are built for the experiments. Then, the task definition and evaluation metric (i.e., accuracy rate) are described. Various large language models as well as the traditional methodology are used in experiments to execute the task of meta information extraction. The results are analyzed and compared among the use of various LLMs.},
  keywords={Measurement;Knowledge graphs;Information retrieval;Data mining;Task analysis;information extraction;large language model;scientific literature},
  doi={10.1109/ICKG59574.2023.00036},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10822152,
  author={Wang, Zhirui and Jiang, Xinlong and Gao, Chenlong and Dong, Fan and Dai, Weiwei and Wang, Bingyu and Yan, Bingjie and Chen, Qian and Huang, Wuliang and Zhang, Teng and Chen, Yiqiang},
  booktitle={2024 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)}, 
  title={EyeGraphGPT: Knowledge Graph Enhanced Multimodal Large Language Model for Ophthalmic Report Generation}, 
  year={2024},
  volume={},
  number={},
  pages={3784-3789},
  abstract={Automatic generation of ophthalmic reports holds significant potential to lessen clinicians’ workload, enhance work efficiency, and alleviate the imbalance between clinicians and patients. Recent advancements in multimodal large language models, represented by GPT-4, have demonstrated remarkable performance in the general domain. However, training such models necessitates a substantial amount of paired image-text data, yet paired ophthalmic data is limited, and ophthalmic reports are laden with specialized terminologies, making it challenging to transfer the training paradigm to the ophthalmic domain. In this paper, we propose EyeGraphGPT, a knowledge graph enhanced multimodal large language model for ophthalmic report generation. Specifically, we construct a knowledge graph by leveraging the knowledge from a medical database and expertise from ophthalmic experts to model relationships among ophthalmic diseases, enhancing the model’s focus on key disease information. We then perform relation-aware modal alignment to incorporate knowledge graph features into visual features, and further enhance modality collaboration through visual instruction fine-tuning to adapt the model to the ophthalmic domain. Our experiments on a real-world dataset demonstrates that EyeGraphGPT outperforms previous state-of-the-art models, highlighting its superiority in scenarios with limited medical data and extensive specialized terminologies.},
  keywords={Training;Adaptation models;Visualization;Terminology;Large language models;Unified modeling language;Collaboration;Knowledge graphs;Data models;Diseases;Ophthalmic Report Generation;Knowledge-enhanced Multimodal Models;Multimodal Large Language Models},
  doi={10.1109/BIBM62325.2024.10822152},
  ISSN={2156-1133},
  month={Dec},}@ARTICLE{10487851,
  author={Strader, Jared and Hughes, Nathan and Chen, William and Speranzon, Alberto and Carlone, Luca},
  journal={IEEE Robotics and Automation Letters}, 
  title={Indoor and Outdoor 3D Scene Graph Generation Via Language-Enabled Spatial Ontologies}, 
  year={2024},
  volume={9},
  number={6},
  pages={4886-4893},
  abstract={This letter proposes an approach to build 3D scene graphs in arbitrary indoor and outdoor environments. Such extension is challenging; the hierarchy of concepts that describe an outdoor environment is more complex than for indoors, and manually defining such hierarchy is time-consuming and does not scale. Furthermore, the lack of training data prevents the straightforward application of learning-based tools used in indoor settings. To address these challenges, we propose two novel extensions. First, we develop methods to build a spatial ontology defining concepts and relations relevant for indoor and outdoor robot operation. In particular, we use a Large Language Model (LLM) to build such an ontology, thus largely reducing the amount of manual effort required. Second, we leverage the spatial ontology for 3D scene graph construction using Logic Tensor Networks (LTN) to add logical rules, or axioms (e.g., “a beach contains sand”), which provide additional supervisory signals at training time thus reducing the need for labelled data, providing better predictions, and even allowing predicting concepts unseen at training time. We test our approach in a variety of datasets, including indoor, rural, and coastal environments, and show that it leads to a significant increase in the quality of the 3D scene graph generation with sparsely annotated data.},
  keywords={Three-dimensional displays;Ontologies;Semantics;Training data;Solid modeling;Artificial intelligence;Semantics;Image analysis;Spatial resolution;Indoor environment;AI-based methods;3D scene graphs;semantic scene understanding;spatial ontologies},
  doi={10.1109/LRA.2024.3384084},
  ISSN={2377-3766},
  month={June},}@ARTICLE{9623547,
  author={Loubach, Denis S. and Bonna, Ricardo and Ungureanu, George and Sander, Ingo and Söderquist, Ingemar},
  journal={IEEE Access}, 
  title={Classification and Mapping of Model Elements for Designing Runtime Reconfigurable Systems}, 
  year={2021},
  volume={9},
  number={},
  pages={156337-156360},
  abstract={Embedded systems are ubiquitous and control many critical functions in society. A fairly new type of embedded system has emerged with the advent of partial reconfiguration, i.e. runtime reconfigurable systems. They are attracting interest in many different applications. Such a system is capable of reconfiguring itself at the hardware level and without the need to halt the application’s execution. While modeling and implementing these systems is far from a trivial task, there is currently a lack of systematic approaches to tackle this issue. In other words, there is no unanimously agreed upon modeling paradigm that can capture adaptive behaviors at the highest level of abstraction, especially when regarding the design entry, namely, the initial high-level application and platform models. Given this, our paper proposes two domain ontologies for application and virtual platform models used to derive a classification system and to provide a set of rules on how the different model elements are allowed to be composed together. The application behavior is captured through a formal model of computation which dictates the semantics of execution, concurrency, and synchronization. The main contribution of this paper is to combine suitable formal models of computation, a functional modeling language, and two domain ontologies to create a systematic design flow from an abstract executable application model into a virtual implementation model based on a runtime reconfigurable architecture (virtual platform model) using well-defined mapping rules. We demonstrate the applicability, generality, and potential of the proposed model element classification system and mapping rules by applying them to representative and complete examples: an encoder/decoder system and an avionics attitude estimation system. Both cases yield a virtual implementation model from an abstract application model.},
  keywords={Computational modeling;Runtime;Unified modeling language;Ontologies;Embedded systems;Adaptation models;Hardware;Embedded systems;runtime reconfiguration;models of computation (MoC);domain ontology;mapping rules},
  doi={10.1109/ACCESS.2021.3129899},
  ISSN={2169-3536},
  month={},}@ARTICLE{10149041,
  author={Liang, Ke and Liu, Yue and Zhou, Sihang and Tu, Wenxuan and Wen, Yi and Yang, Xihong and Dong, Xiangjun and Liu, Xinwang},
  journal={IEEE Transactions on Knowledge and Data Engineering}, 
  title={Knowledge Graph Contrastive Learning Based on Relation-Symmetrical Structure}, 
  year={2024},
  volume={36},
  number={1},
  pages={226-238},
  abstract={Knowledge graph embedding (KGE) aims at learning powerful representations to benefit various artificial intelligence applications. Meanwhile, contrastive learning has been widely leveraged in graph learning as an effective mechanism to enhance the discriminative capacity of the learned representations. However, the complex structures of KG make it hard to construct appropriate contrastive pairs. Only a few attempts have integrated contrastive learning strategies with KGE. But, most of them rely on language models (e.g., Bert) for contrastive pair construction instead of fully mining information underlying the graph structure, hindering expressive ability. Surprisingly, we find that the entities within a relational symmetrical structure are usually similar and correlated. To this end, we propose a knowledge graph contrastive learning framework based on relation-symmetrical structure, KGE-SymCL, which mines symmetrical structure information in KGs to enhance the discriminative ability of KGE models. Concretely, a plug-and-play approach is proposed by taking entities in the relation-symmetrical positions as positive pairs. Besides, a self-supervised alignment loss is designed to pull together positive pairs. Experimental results on link prediction and entity classification datasets demonstrate that our KGE-SymCL can be easily adopted to various KGE models for performance improvements. Moreover, extensive experiments show that our model could outperform other state-of-the-art baselines.},
  keywords={Semantics;Knowledge graphs;Data models;Computational modeling;Learning systems;Contrastive learning;Graph learning;knowledge graph embedding;self-supervised contrastive learning;symmetrical property},
  doi={10.1109/TKDE.2023.3282989},
  ISSN={1558-2191},
  month={Jan},}@INPROCEEDINGS{9442198,
  author={Zhou, Bin and Bao, Jinsong and Liu, Yahui and Song, Dengqiang},
  booktitle={2020 IEEE 18th International Conference on Industrial Informatics (INDIN)}, 
  title={BA-IKG: BiLSTM Embedded ALBERT for Industrial Knowledge Graph Generation and Reuse}, 
  year={2020},
  volume={1},
  number={},
  pages={63-69},
  abstract={As the industrial production mode is shifting towards digitalization and intelligence in the new era. Enterprises put forward higher requirements for efficient processing and utilization of accumulated unstructured data. At present, the knowledge and data contained in a large number of unstructured documents are scattered. The types of entities and relationships are diverse. And the constraints of production rules are complicated, which increases the difficulty of knowledge management and utilization. Therefore, this paper studies the semantic knowledge graph generation and reuse method for industrial documents, which can form standardized production resources, the knowledge related to the industry, and question and answer strategies for industrial processing. The challenge of the research is to explore a feasible process knowledge model and efficient industrial information extraction method to effectively provide structured knowledge of process documents. We build process knowledge representation models and information extraction models and algorithms based on process knowledge representation model and natural language processing. The entities and relations of the main production factors are extracted. The knowledge representation model associates the extracted entities and relations to form an industrial knowledge graph, which provides information support for processing knowledge retrieval and question answering methods. Finally, the approach is evaluated by employing the aerospace machining documents. And the proposed method can obtain valuable information in the document and improve utilization of industrial unstructured data.},
  keywords={Industries;Semantics;Production;Knowledge representation;Machining;Information retrieval;Knowledge discovery;knowledge modeling;entity relation extraction;industrial knowledge graph;knowledge question and answer},
  doi={10.1109/INDIN45582.2020.9442198},
  ISSN={2378-363X},
  month={July},}@ARTICLE{10472080,
  author={Zhang, Geng and Liu, Jin and Zhou, Guangyou and Zhao, Kunsong and Xie, Zhiwen and Huang, Bo},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing}, 
  title={Question-Directed Reasoning With Relation-Aware Graph Attention Network for Complex Question Answering Over Knowledge Graph}, 
  year={2024},
  volume={32},
  number={},
  pages={1915-1927},
  abstract={Complex knowledge graph question answering (KGQA) aims at answering natural language questions by entities retrieving from a knowledge graph (KG). Recently, the relation path-based models have shown the unique advantage for complex KGQA. However, these existing models ignore the dependency between different relation paths, which leads to aimless reasoning over the KG. To resolve this issue, we propose the question-directed reasoning with relation-aware graph attention network (QRGAT) that encodes the reasoning process as a reasoning graph. The relation-aware GAT can recognize neighbor entities along with the corresponding relations for each entity. With the relation-aware GAT stacked in multiple layers, it can collaboratively capture the dependency of different relation paths for each entity. The question-directed reasoning utilizes the information learned by the relation-aware GAT to solve the aimless reasoning on the KG by constructing a reasoning graph. Extensive experiments demonstrate that our QRGAT outperforms the baseline models on both popular datasets WebQuestionsSP and ComplexWebQuestions. Compared with the strong GNN-based baseline NSM$_{+h}$, our QRGAT achieves the performance improvements of 2.3% on WebQuestionsSP and 3.6% on ComplexWebQuestions by the metric Hits@1.},
  keywords={Cognition;Semantics;Knowledge graphs;Task analysis;Training;Question answering (information retrieval);Speech processing;Graph attention network;information retrieval;knowledge graph;question answering},
  doi={10.1109/TASLP.2024.3375631},
  ISSN={2329-9304},
  month={},}@INPROCEEDINGS{9904215,
  author={Shi, Rui and Wang, Zhenchuan and Liu, Yang and Lan, Yunliang and Zhao, Wei and Liu, Yitang},
  booktitle={2022 5th International Conference on Pattern Recognition and Artificial Intelligence (PRAI)}, 
  title={Improve on Entity Recognition Method Based on BiLSTM-CRF Model for the Nuclear Technology Knowledge Graph}, 
  year={2022},
  volume={},
  number={},
  pages={241-246},
  abstract={The accuracy of entity recognition is particularly important for knowledge graph construction. The traditional Named Entity recognition (NER) model mainly includes HMM, CRF, BiLSTM, BiLSTM-CRF, etc. It is difficult to solve the problem of word meaning confusion resulting from the wrong separation at the end of the entity when using the four models for the labeled nuclear technology knowledge data sets. In order to improve the entity recognition effect and address the problem of polysemy in nuclear technology knowledge data set, an improved nuclear technology entity recognition method based on the BERT-BiLSTM-CRF combination model was proposed by comparative experiments. According to the results, it can conclude that the application of the BERT model instead of the Word2Vec algorithm for word vector training is helpful to the model recognition, and the exclusive dictionary word segmentation and part of speech classification of nuclear technology texts contribute to improving the quality of labeled data. The experiment verified that the usage of BERT pre-training model can solve the problem of polysemy in NER to some extent. Meanwhile, it validated the precision in nuclear technology knowledge entity recognition for collected data, which could be used in pre-procedure in nuclear technology knowledge graph construction.},
  keywords={Training;Dictionaries;Text recognition;Bit error rate;Hidden Markov models;Speech recognition;Data models;nuclear technology knowledge graph;named entity recognition;BERT-BiLSTM-CRF;Vector},
  doi={10.1109/PRAI55851.2022.9904215},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{9742130,
  author={Tang, Jing and Ning, Xinran and Wang, Kunfeng and Tan, Ying and Chen, Jianying},
  booktitle={2021 2nd International Conference on Electronics, Communications and Information Technology (CECIT)}, 
  title={A Hybrid Relation Extraction Model for Knowledge Graph of Heroic Epic “Gesar”}, 
  year={2021},
  volume={},
  number={},
  pages={65-70},
  abstract={Extracting relations from unstructured text is the primary step of knowledge graph construction. This step is harder in the Tibetan heroic epic “Epic Appreciation King Gesar” than in other Chinese stories because of the difficulties in the identification of the named entities and the complicated character relationships. Given this, based on the named entity corpus constructed with help of domain experts earlier, a hybrid relation extraction model combined with entity features and syntactic-semantic features, EBERT-BiLSTM, is proposed in this paper. The data set, corpus, and model construction principle and process are described in detail. Experiments show that EBERT-BiLSTM has better effectiveness and performance than just BiLSTM-Attention and BERT. Finally, EBERT-BiLSTM is used to extract 320-character relation triples and then construct the heroic epic “Gesar” knowledge graph.},
  keywords={Bit error rate;Feature extraction;Data models;Information and communication technology;Data mining;Artificial intelligence;Text processing;knowledge graph;relation extraction;Gesar},
  doi={10.1109/CECIT53797.2021.00019},
  ISSN={},
  month={Dec},}

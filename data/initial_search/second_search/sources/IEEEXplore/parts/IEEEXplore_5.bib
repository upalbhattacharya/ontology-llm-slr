@INPROCEEDINGS{10191712,
  author={Yuan, Xiaosong and Chen, Ke and Zuo, Wanli and Zhang, Yijia},
  booktitle={2023 International Joint Conference on Neural Networks (IJCNN)}, 
  title={TC-GAT: Graph Attention Network for Temporal Causality Discovery}, 
  year={2023},
  volume={},
  number={},
  pages={1-8},
  abstract={The present study explores the intricacies of causal relationship extraction, a vital component in the pursuit of causality knowledge. Causality is frequently intertwined with temporal elements, as the progression from cause to effect is not instantaneous but rather ensconced in a temporal dimension. Thus, the extraction of temporal causality holds paramount significance in the field. In light of this, we propose a method for extracting causality from the text that integrates both temporal and causal relations, with a particular focus on the time aspect. To this end, we first compile a dataset that encompasses temporal relationships. Subsequently, we present a novel model, TC-GAT, which employs a graph attention mechanism to assign weights to the temporal relationships and leverages a causal knowledge graph to determine the adjacency matrix. Additionally, we implement an equilibrium mechanism to regulate the interplay between temporal and causal relations. Our experiments demonstrate that our proposed method significantly surpasses baseline models in the task of causality extraction.},
  keywords={Knowledge engineering;Neural networks;Knowledge graphs;Task analysis;causal knowledge graph;graph neural network;temporal causality},
  doi={10.1109/IJCNN54540.2023.10191712},
  ISSN={2161-4407},
  month={June},}@INPROCEEDINGS{10485037,
  author={Lotfy, Abdelrahman and Saleh, Kirollos and Mohamed, Saher and Lorance, John and Yehia, Ehab and Mohammed, Khaled and AbdAlbaky, Ibrahim and Fathy, Mostafa and Yasser, Tawfik},
  booktitle={2024 6th International Conference on Computing and Informatics (ICCI)}, 
  title={Sentiment Analysis for Arabic Product Reviews Using LLMs and Knowledge Graphs}, 
  year={2024},
  volume={},
  number={},
  pages={411-417},
  abstract={The exploration of sentiment analysis in multilingual contexts, particularly through the integration of deep learning techniques and knowledge graphs, represents a significant advance in language processing research. This study specifically concentrates on the Arabic language, addressing the challenges presented by its morphological complexity. While the primary focus is Arabic, the research also includes a comprehensive review of related work in other languages such as Bangla and Chinese. This contextualizes the challenges and solutions found in Arabic sentiment analysis within a broader multilingual landscape. Utilizing pre-trained language models like BERT, the research has achieved noteworthy improvements in sentiment analysis accuracy and efficiency, particularly for the Arabic language. The integration of knowledge graphs stands out as a crucial innovation, offering essential contextual insights and mitigating the limitations posed by sparse labeled datasets in Arabic, a language less resourced compared to English. The findings of this study highlight the effectiveness of tailored BERT models for Arabic sentiment analysis, revealing the vast potential and inherent challenges of employing knowledge graphs and large language models for a deeper, more nuanced understanding. The future direction of this research includes enhancing these methods with cutting-edge machine learning techniques, aiming to further refine sentiment analysis processes and knowledge graph construction with a focus on Arabic within a multilingual framework.},
  keywords={Sentiment analysis;Analytical models;Technological innovation;Reviews;Knowledge graphs;Performance gain;Cognition;Sentiment Analysis;Big Data;LLMs;Knowledge Graph;Arabic},
  doi={10.1109/ICCI61671.2024.10485037},
  ISSN={},
  month={March},}@INPROCEEDINGS{9865330,
  author={Dordiuk, Vladislav and Demicheva, Ekaterina and Espino, Fernando Polanco and Ushenin, Konstantin},
  booktitle={2022 Ural-Siberian Conference on Computational Technologies in Cognitive Science, Genomics and Biomedicine (CSGB)}, 
  title={Natural language processing for clusterization of genes according to their functions}, 
  year={2022},
  volume={},
  number={},
  pages={1-4},
  abstract={There are hundreds of methods for analysis of data obtained in mRNA-sequencing. The most of them are focused on small number of genes. In this study, we propose an approach that reduces the analysis of several thousand genes to analysis of several clusters. The list of genes is enriched with information from open databases. Then, the descriptions are encoded as vectors using the pretrained language model (BERT) and some text processing approaches. The encoded gene function pass through the dimensionality reduction and clusterization. Aiming to find the most efficient pipeline, 180 cases of pipeline with different methods in the major pipeline steps were analyzed. The performance was evaluated with clusterization indexes and expert review of the results.},
  keywords={Dimensionality reduction;Databases;Pipelines;Bit error rate;Genomics;Natural language processing;Cognitive science;natural language processing;BERT;semantic analysis;differential gene expression analysis;gene ontology;gene expression;clusterization},
  doi={10.1109/CSGB56354.2022.9865330},
  ISSN={},
  month={July},}@INPROCEEDINGS{9671788,
  author={Eggleston, Chloe and Abramson, Jeremy},
  booktitle={2021 IEEE International Conference on Big Data (Big Data)}, 
  title={Woolery: Extending Frame Semantics to Structured Documents}, 
  year={2021},
  volume={},
  number={},
  pages={5597-5601},
  abstract={This paper presents Woolery, a system for semantic annotation and mapping of structured documents (such as JSON key-value pairs) to FrameNet. Implemented as a graphical interface, Woolery provides an annotator with a guided means to map keys in a JSON document to FrameNet elements, without the need for extensive knowledge of FrameNet's semantic structures. Candidate frame elements are identified via a search across FrameNet's internal representations, or via mapping keys to their potential WordNet synsets. Final element selection is automated via a pretrained language model. Initial results are promising, with the model giving an overall accuracy of 77.8% when labeling frames across a diverse corpus of JSON document schemas.},
  keywords={Annotations;Conferences;Semantics;Big Data;Labeling;FrameNet;natural language processing;annotation;lexical databases;JSON;ontology alignment;computational semantics},
  doi={10.1109/BigData52589.2021.9671788},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{8276845,
  author={Hussain, Ambreen and Wu, Wenyan},
  booktitle={2017 IEEE International Conference on Internet of Things (iThings) and IEEE Green Computing and Communications (GreenCom) and IEEE Cyber, Physical and Social Computing (CPSCom) and IEEE Smart Data (SmartData)}, 
  title={Sustainable Interoperability and Data Integration for the IoT-Based Information Systems}, 
  year={2017},
  volume={},
  number={},
  pages={824-829},
  abstract={Devices used in Internet of Things (IoT) technology are interconnected through internet and continuously send data for storage in disparate databases and files. This poses heterogeneity in data syntax and semantics. In the past few years, researches have been carried out to handle these problems in various information systems such as water and healthcare by applying semantic and syntactic uniformity. This research presents an Information and Communication Technology (ICT) framework to sustain the interoperability between stakeholders within an information system by applying Model Driven Software Development (MDSD) paradigm and ontology. The major contribution of this research is building software model which is annotated with semantic model to maintain the comprehension between the modelers and the programmers allowing sustainability by adapting to the changing environment. Moreover, the framework offers two types of semantic validation i.e. model and data of the documents to integrate sensor data which we claim as a novelty in this study. The validated IoT data is integrated through RESTful web service interface of SensorThings API. The aim of this paper is to apply the methodology of the framework, on IoT based healthcare system, that has been successful in water information system.},
  keywords={Unified modeling language;Semantics;Interoperability;Ontologies;Medical services;Adaptation models;Software;Model Driven Software Development;Ontology;Healthcare systems;Semantic Validation;OGC SensorThings},
  doi={10.1109/iThings-GreenCom-CPSCom-SmartData.2017.126},
  ISSN={},
  month={June},}@INPROCEEDINGS{9218173,
  author={Parvizimosaed, Alireza},
  booktitle={2020 IEEE 28th International Requirements Engineering Conference (RE)}, 
  title={Towards the Specification and Verification of Legal Contracts}, 
  year={2020},
  volume={},
  number={},
  pages={445-450},
  abstract={A contract is a legally binding agreement that expresses high-level requirements of parties in terms of obligations, powers and constraints. Parties' actions influence the status of a contract and shall comply with its clauses. Manual contract monitoring is very laborious in real markets, such as transactive energy, where plenty of complex contracts are running concurrently. Furthermore, liability, right and performance transition through run-time operations such as subcontracting, assignment and substitution complicate contract interpretation. Automation is needed to ensure that contracts respect desirable properties and to support monitoring of compliance and handling of violations. In this thesis research, I propose an innovative ontology that defines fundamental contractual notions (such as the ones mentioned above) and their relationships, on which is built a specification language, called Symboleo, that provides syntax and axiomatic semantics of contracts via first-order logic. Symboleo enables the development of advanced automation tools such as a compliance checker that monitors contracts at runtime, and a model checking verification method that analyzes liveness and safety properties of contracts. This paper reports on the problem domain, research method, current status, expected contributions, and main foreseen challenges.},
  keywords={Contracts;Law;Ontologies;Monitoring;Tools;Legal Contract;Specification Language;Model Checking;Smart Contract;Ontology},
  doi={10.1109/RE48521.2020.00066},
  ISSN={2332-6441},
  month={Aug},}@INPROCEEDINGS{9397038,
  author={Bhoomkar, Yogiraj and Vernekar, Sushant and Kulkarni, Arya and Kulkarni, Pranav and Aniyan, Arun},
  booktitle={2021 International Conference on Emerging Smart Computing and Informatics (ESCI)}, 
  title={Knowledge Graph of Mergers and Acquisitions}, 
  year={2021},
  volume={},
  number={},
  pages={6-12},
  abstract={Context driven decision making is a key factor to make critical decisions in business applications. We present the design and application of a knowledge graph to aid the context driven decision making for studying the patterns in Mergers and Acquisitions (M&A) activities in the industry. Using text data from news articles we make use of a Natural Language Processing pipeline to extract entities and relations to build a knowledge graph. The entity recognition model was 90.97% accurate in detecting the entities. The graph is further enriched with metadata from Wikipedia. We finally demonstrate two use cases to showcase the utility of the knowledge graph for making business decisions.},
  keywords={Industries;Corporate acquisitions;Decision making;Pipelines;Metadata;Natural language processing;Business;Knowledge Graphs;Natural Language Processing},
  doi={10.1109/ESCI50559.2021.9397038},
  ISSN={},
  month={March},}@ARTICLE{9349177,
  author={Amato, Flora and Cozzolino, Giovanni and Moscato, Francesco and Moscato, Vincenzo and Xhafa, Fatos},
  journal={IEEE Transactions on Industrial Informatics}, 
  title={A Model for Verification and Validation of Law Compliance of Smart Contracts in IoT Environment}, 
  year={2021},
  volume={17},
  number={11},
  pages={7752-7759},
  abstract={The interest of Industry 4.0 in smart contracts and blockchain technologies is growing up day by day. Smart contracts have enabled new kinds of interactions whereby contractors can even fully automate processes they agree on. This technology is really appealing in Internet of Things (IoT) domain because smart devices generate events for software agents involved in a smart contract execution, making full automation possible. However, smart contracts have to comply with national and international laws and accountability of participant's actions. Soundness of a smart contract has to be verified in terms of law compliance. Here, we propose a model for verification and validation of law compliance of smart contracts in IoT environments. The main goal of this article is to propose a formal model (based on multiagent logic and ontological description of contracts) for validating law compliance of smart contracts and to determine potential responsibilities of failures.},
  keywords={Unified modeling language;Law;Internet of Things;Insurance;Automobiles;Analytical models;Smart contracts;Blockchain;industry 4.0;Internet of Things (IoT);multiagent systems;smart contracts},
  doi={10.1109/TII.2021.3057595},
  ISSN={1941-0050},
  month={Nov},}@INPROCEEDINGS{9672080,
  author={Parolin, Erick Skorupa and Hu, Yibo and Khan, Latifur and Osorio, Javier and Brandt, Patrick T. and D’Orazio, Vito},
  booktitle={2021 IEEE International Conference on Big Data (Big Data)}, 
  title={CoMe-KE: A New Transformers Based Approach for Knowledge Extraction in Conflict and Mediation Domain}, 
  year={2021},
  volume={},
  number={},
  pages={1449-1459},
  abstract={Knowledge discovery and extraction approaches attract special attention across industries and areas moving toward the 5V Era. In the political and social sciences, scholars and governments dedicate considerable resources to develop intelligent systems for monitoring, analyzing and predicting conflicts and affairs involving political entities across the globe. Such systems rely on background knowledge from external knowledge bases, that conflict experts commonly maintain manually. The high costs and extensive human efforts associated with updating and extending these repositories often compromise their correctness of. Here we introduce CoMe-KE (Conflict and Mediation Knowledge Extractor) to extend automatically knowledge bases about conflict and mediation events. We explore state-of-the-art natural language models to discover new political entities, their roles and status from news. We propose a distant supervised method and propose an innovative zero-shot approach based on a dynamic hypothesis procedure. Our methods leverage pre-trained models through transfer learning techniques to obtain excellent results with no need for a labeled data. Finally, we demonstrate the superiority of our method through a comprehensive set of experiments involving two study cases in the social sciences domain. CoMe-KE significantly outperforms the existing baseline, with (on average) double of the performance retrieving new political entities.},
  keywords={Knowledge based systems;Social sciences;Transfer learning;Natural languages;Big Data;Transformers;Knowledge discovery;knowledge base construction;knowledge extraction;ontologies;link and graph mining;transfer-learning;natural language processing;web search and mining;semantic-based data mining;CAMEO},
  doi={10.1109/BigData52589.2021.9672080},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{8369586,
  author={Blackburn, Mark R. and Austin, Mark A. and Coelho, Maria},
  booktitle={2018 Annual IEEE International Systems Conference (SysCon)}, 
  title={Modeling and cross-domain dependability analysis of cyber-physical systems}, 
  year={2018},
  volume={},
  number={},
  pages={1-8},
  abstract={This paper discusses a novel method of modeling and formal verification to support dependability analyses. The method is demonstrated in an example of a fault management capability of robots that interacts with equipment and humans. Hazard analyses produce derived requirements for fault management capabilities. These include safety critical functions for collision avoidance and temporary autonomy. Derived requirements are represented formally in models that are used to produce dependability evidence using theorem proving, model-based test vector generation, test execution with code coverage analysis, and requirement-to-test traceability. To address the challenges of heterogeneity of modeling tools and languages, Semantic Web Technologies are used for model composition and model transformation from modeling tools to formal analysis tools.},
  keywords={Object oriented modeling;Analytical models;Robots;Mathematical model;Tools;Software;Hazards;component;formatting;style;styling;formal methods;modeling;formal verification;dependability;fault management;cyber physical systems},
  doi={10.1109/SYSCON.2018.8369586},
  ISSN={2472-9647},
  month={April},}@INPROCEEDINGS{9995651,
  author={Wang, Hong and Wang, Xiaoqi and Liu, Wenjuan and Xie, Xiaolan and Peng, Shaoliang},
  booktitle={2022 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)}, 
  title={deepDGA: Biomedical Heterogeneous Network-based Deep Learning Framework for Disease-Gene Association Predictions}, 
  year={2022},
  volume={},
  number={},
  pages={601-606},
  abstract={Accurate prediction of disease-gene associations is a crucial tissue in the treatment of diseases. Currently, deep learning-based methods have been proposed to determine the associations between diseases and genes. However, previous network-based models do not consider the semantic characteristics of various biomedical entities and suffer from the problems of cold-start. To this end, this study proposes a heterogeneous network-based deep learning framework (termed deepDGA) to predict disease-gene associations. First, a heterogeneous network with four kinds of biological nodes and eight kinds of edges is constructed. Second, we develop a meta path-driven deep Transformer encoder to learn node representations which contains semantic characteristics of nodes in the heterogeneous network. Finally, the inductive matrix completion algorithm that can solve problem of cold-start, is used for disease-gene association prediction. The results of 5-flod cross-validation and top-ranked predictions suggest that deepDGA is superior to other methods. In addition, we further observe that deepDGA performs the highest predictive ability for specific diseases via the literature verification, KEGG human pathway analyses, and GO enrichment analyses. In summary, deepDGA is an effective framework for predicting the diseases-gene associations.},
  keywords={Deep learning;Biological system modeling;Semantics;Pipelines;Predictive models;Transformers;Prediction algorithms;disease-gene association;heterogeneous network;deep Transformer encoder;inductive matrix completion},
  doi={10.1109/BIBM55620.2022.9995651},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10350773,
  author={Lange, Arne and Atkinson, Colin},
  booktitle={2023 ACM/IEEE International Conference on Model Driven Engineering Languages and Systems Companion (MODELS-C)}, 
  title={Modeling in LML with DOCL: A Contribution to the MULTI Warehouse Challenge}, 
  year={2023},
  volume={},
  number={},
  pages={649-658},
  abstract={This paper responds to the “Warehouse” challenge that was posed to the community of multi-level modeling researchers for the MULTI 2023 workshop. Given the many flavors of multi-level modeling approaches, the purpose of this and other similar challenges defined by the MULTI workshop community is to clarify the trade-offs entailed by the design choices underpinning the different approaches. This challenge revolves around product copies, product specifications, and product type specifications and how to guarantee certain properties at the product instance level. After first providing an overview of our modeling approach, and summarising the requirements laid out in the challenge, we present our solution using the LML and DOCL languages. We then discuss how well the solution fulfills the requirements laid out in the challenge.},
  keywords={Conferences;Semantics;Syntactics;Model driven engineering;Complexity theory;Safety;Currencies;Multi-level modeling;LML;DOCL},
  doi={10.1109/MODELS-C59198.2023.00106},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10554074,
  author={Chiş, Andrei and Stoica, Oliviu Ionuţ and Ghiran, Ana-Maria and Buchmann, Robert Andrei},
  booktitle={2024 IEEE International Conference on Automation, Quality and Testing, Robotics (AQTR)}, 
  title={A Knowledge Graph Approach to Cyber Threat Mitigation Derived from Data Flow Diagrams}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Data Flow Diagrams (DFD) have proven effective in designing and analyzing the flow of data in enterprise systems. They serve as indispensable tools for enterprises that are undergoing transition to cloud services. DFDs aid in understanding the current processes, identifying interfaces and integration points that require security measures. This paper reports a Design Science project to mitigate the cyber security threats at the design phase of a system and to perform auditing of an existing system through knowledge graphs. The proposal leverages knowledge gathered from various sources in a knowledge graph to identify semantic relationships and patterns, enabling automated inference, analysis and detection of vulnerability patterns. Furthermore, LLM-based (large language models) capabilities transform data management details captured as Data Flow Diagrams (DFD) into knowledge graphs for semantic querying and improved decision support.},
  keywords={Current measurement;Semantics;Knowledge graphs;Transforms;Data models;Security;Proposals;knowledge graphs;security;privacy;data flow diagrams;threat modeling;LLMs},
  doi={10.1109/AQTR61889.2024.10554074},
  ISSN={1844-7872},
  month={May},}@INPROCEEDINGS{8054828,
  author={Aydemir, Fatma Başak and Dalpiaz, Fabiano},
  booktitle={2017 IEEE 25th International Requirements Engineering Conference Workshops (REW)}, 
  title={Towards Aligning Multi-concern Models via NLP}, 
  year={2017},
  volume={},
  number={},
  pages={46-50},
  abstract={The design of large-scale complex systems requires their analysis from multiple perspectives, often through the use of requirements models. Diversely located experts with different backgrounds (e.g., safety, security, performance) create such models using different requirements modeling languages. One open challenge is how to align these models such that they cover the same parts of the domain. We propose a technique based on natural language processing (NLP) that analyzes several models included in a project and provides suggestions to modelers based on what is represented in the models that analyze other concerns. Unlike techniques based on meta-model alignment, ours is flexible and language agnostic. We report the results of a focus group session in which experts from the air traffic management domain discussed our approach.},
  keywords={Conferences;Requirements engineering;requirements models;natural language processing;alignment;collaborative modeling;model management},
  doi={10.1109/REW.2017.82},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{9816191,
  author={Andreadis, Stelios and Elias, Mirette and Mavropoulos, Thanassis and Papadopoulos, Charis and Pantelidis, Nick and Gialampoukidis, Ilias and Vrochidis, Stefanos and Kompatsiaris, Ioannis},
  booktitle={2022 IEEE 14th Image, Video, and Multidimensional Signal Processing Workshop (IVMSP)}, 
  title={SPARQL querying for validating the usage of automatically georeferenced social media data as human sensors for air quality}, 
  year={2022},
  volume={},
  number={},
  pages={1-5},
  abstract={The problem of air pollution is one of the countless topics discussed on social media on an everyday basis. This rich, crowdsourced information can be exploited to assess the air quality of urban areas, using humans as sensors. Nevertheless, the majority of social media data are falsely geotagged or completely lack geoinformation, which is an essential attribute, while the reliability of the air pollution events reported by online citizens has to be proven. The scope of this work is to present a framework that collects Twitter messages in German that refer to the atmosphere, automatically georeferences them, and finally validates them through semantic representation and SPARQL queries in order to associate them with real measurements of air quality sensors. The georeferencing models are evaluated against state-of-the-art works and the proposed framework is validated in a near-six-month scenario in Germany.},
  keywords={Multidimensional signal processing;Social networking (online);Atmospheric measurements;Atmospheric modeling;Urban areas;Semantics;Sensor phenomena and characterization;air quality;social media;georeferencing;semantic representation;SPARQL querying},
  doi={10.1109/IVMSP54334.2022.9816191},
  ISSN={},
  month={June},}@INPROCEEDINGS{8600201,
  author={Lohar, Nitin K. and Kar, Subrat},
  booktitle={2018 Twenty Fourth National Conference on Communications (NCC)}, 
  title={Control and Management of Optical Networks Using Optical Network Description Language}, 
  year={2018},
  volume={},
  number={},
  pages={1-5},
  abstract={Management and configuration of optical networks, implementing new policies to keep up with ever-changing network etc. have always been tedious tasks. Software-defined networking (SDN) has provided many network solutions in the electrical counterpart. SDN for optical networks can provide new opportunities to make the above mentioned tasks easier and faster. As a first step towards this goal, we develop an optical network description language (ONDL). We use it to describe various network components, and their configuration and run-time states, such as modulation schemes, wavelength and spectral-width of a transponder, switching matrix of an optical switch etc. The language is based on resource description framework (RDF). Furthermore, we develop a controller which understands and sends instructions in this language to different network devices to provide/change their states. We show the applicability of ONDL by simulating a network, controlling and managing its nodes using ONDL and developed controller.},
  keywords={Optical switches;Optical fiber networks;Resource description framework;Modulation},
  doi={10.1109/NCC.2018.8600201},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{10275701,
  author={Knorr, Felix and Kastner, Wolfgang},
  booktitle={2023 IEEE 28th International Conference on Emerging Technologies and Factory Automation (ETFA)}, 
  title={Towards a Uniform Exchange Format for Home and Building Automation using VDI 3814}, 
  year={2023},
  volume={},
  number={},
  pages={1-4},
  abstract={Exchanging technical documents in the building automation domain is a complicated process. Files are distributed either as drawings, spreadsheets, or text documents. Each stakeholder has to re-enter the data into their own system, and changes are revised manually, often even without revision control. This paper presents a uniform exchange format based on the ’graphical’ standard VDI 3814. To increase acceptance, the industry standards XSD and XML were chosen. As a result of this work, a model is provided that covers the concepts and exchange files provided in the VDI 3814 standard. Given a supporting tool, data can be entered, revised, and exchanged automatically. Based on this unified representation, it is subsequently possible to transfer the data into one of the already existing ontologies in this domain by using model transformations. Some of these ontologies are also referred to in this paper.},
  keywords={Industries;Buildings;XML;Ontologies;Data models;Stakeholders;Standards;Building Automation;Uniform Format;VDI 3813;VDI 3814},
  doi={10.1109/ETFA54631.2023.10275701},
  ISSN={1946-0759},
  month={Sep.},}@INPROCEEDINGS{8862131,
  author={Vijaya, B. and Gharpure, Prachi},
  booktitle={2019 International Conference on Computational Intelligence in Data Science (ICCIDS)}, 
  title={Candidate Generation for Instance Matching on Semantic Web}, 
  year={2019},
  volume={},
  number={},
  pages={1-5},
  abstract={The growth of semantic web has given rise to proliferation of data sources wherein the task of recognizing real world entities and identifying multiple references of the same real world entity becomes an essential task in order to facilitate sharing and integration of data. Due to the heterogeneous nature of data on the semantic web, entities belonging to different sources are compared by assessing the similarity of features that are common in order to identify matches. With the increasing size of data sets Candidate generation methods are generally employed to avoid quadratic time complexity that would otherwise be incurred if pairwise similarity of all entities are computed. Here we propose a novel index based approach for candidate generation and reduction. The evaluation shows that the proposed method scales well and improves recall significantly.},
  keywords={Indexes;Semantic Web;Task analysis;Mathematical model;Computational intelligence;Data science;Couplings;Instance matching;Record Linkage;Blocking;Candidate generation;Semantic web},
  doi={10.1109/ICCIDS.2019.8862131},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{9507178,
  author={Vlasenko, Sergey V.},
  booktitle={2021 XXIV International Conference on Soft Computing and Measurements (SCM)}, 
  title={Usage Features of Semantic Query and Rule Languages of Semantic Web in the Intelligent Systems, Based on Conceptual Graphs Technologies}, 
  year={2021},
  volume={},
  number={},
  pages={120-123},
  abstract={The article considers some problems related to applying languages of semantic query and rules, oriented towards their application within Semantic Web, in the information systems, based on conceptual graphs techniques and knowledge models of the appropriate type. At this, special attention is paid to the analysis of given languages interpretation correctness, as well as technological aspects of organizing for processing chosen-class knowledge models.},
  keywords={Semantic Web;ISO Standards;Semantics;W3C;Tools;Software;Regulation;intelligent systems;knowledge models;Semantic Web;conceptual graphs},
  doi={10.1109/SCM52931.2021.9507178},
  ISSN={},
  month={May},}@INPROCEEDINGS{10350821,
  author={Henzgen, Arne and Strey, Lukas},
  booktitle={2023 ACM/IEEE International Conference on Model Driven Engineering Languages and Systems Companion (MODELS-C)}, 
  title={Model-Driven Approach for Automatic Model Information Aggregation in Structured Documents}, 
  year={2023},
  volume={},
  number={},
  pages={403-413},
  abstract={While models are widely used in software development projects originating from industry and academic research, their documentation can be a time-intensive process. This paper focuses on providing a Proof of Concept for the automatic aggregation of various model data in two different document types conforming to ISO/IEC/IEEE 42010 architecture descriptions or instructional information documents according to ISO/IEC/IEEE 26514. Therefore, this work leverages a model-driven mapping approach of model information to the required document structure, dynamic templating algorithms to transform model data into text and a prototypical implementation that executes the defined mapping and transformation logic in practice. The generation results show that most of the documentation standard requirements can be fulfilled automatically and therefore, reduce the manual processing effort while enhancing consistency.},
  keywords={Industries;ISO Standards;Heuristic algorithms;Documentation;Computer architecture;Transforms;Data models;Model-Driven Engineering;Documentation;BPMN;UML;GSN;Model-to-Document;Architecture Description;Instructional Information},
  doi={10.1109/MODELS-C59198.2023.00072},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10678676,
  author={Gerasimov, Irina and Mehrabian, Armin and KC, Binita and Alfred, Jerome and McGuire, Michael P.},
  booktitle={2024 IEEE 20th International Conference on e-Science (e-Science)}, 
  title={Discovering Research Areas in Dataset Applications through Knowledge Graphs and Large Language Models}, 
  year={2024},
  volume={},
  number={},
  pages={1-10},
  abstract={Scientific datasets are increasingly cited in peer-reviewed journal publications, facilitating easy access to research utilizing those datasets. Datasets undergo a life cycle where older versions of datasets are replaced by newer versions often due to improvements in data resolution, algorithms, and other factors. Unlike peer reviewed documents registered with a single Digital Unique Identifier (DOI), datasets can be updated over time and the newer version of the datasets are registered with a new DOI which is not necessarily linked to the previous version of the dataset. It is challenging when publications citing a dataset need to be traced over the entire life cycle of that dataset. We provide an innovative approach to link the dataset versions and publications using a knowledge graph (KG). KG can help to trace the dataset cited in publications over the entire dataset life cycle and shed light into dataset usage in various applied research areas. We fine-tuned the pretrained NASA IMPACT INDUS Large Language Model (LLM) on a set of labeled publications abstracts. Our results showed that 87% of the publications were classified into one of twenty applied research areas, while the remaining 13% were classified into non-applied research areas. By linking datasets to applied research areas through the KG and employing Global Change Master Directory (GCMD), a well-established controlled vocabulary of scientific keywords describing Earth science datasets, we contribute to a transparent and advanced search and discovery mechanism for datasets across the Earth data ecosystem. The integrated KG and LLM approach is now incorporated and operational in dataset publication management at one of NASA’s Earth science data archival centers.},
  keywords={Vocabulary;Navigation;Large language models;Instruments;NASA;Ecosystems;Knowledge graphs;LLM;Knowledge Graph;data citation},
  doi={10.1109/e-Science62913.2024.10678676},
  ISSN={2325-3703},
  month={Sep.},}@INPROCEEDINGS{10223881,
  author={Ji, Wei and Cao, Qinghong and Shi, Jin and Zhu, Enyao and Xu, Tianyi and He, Hao},
  booktitle={2023 26th ACIS International Winter Conference on Software Engineering, Artificial Intelligence, Networking and Parallel/Distributed Computing (SNPD-Winter)}, 
  title={Research on Domain Knowledge Representation Techniques}, 
  year={2023},
  volume={},
  number={},
  pages={150-157},
  abstract={Knowledge is the fruit of human's knowledge of the objective world in practice and the crystallization of wisdom. A knowledge base makes a knowledge-based system (or expert system) intelligent by structuring and sorting out knowledge in a specific field and storing, organizing, managing and using it in a computer using a scientific knowledge representation. Based on the research of knowledge base construction in securities industry, this paper first summarizes and explains several representative knowledge representation models. Then, it summarizes the application scenarios of common knowledge representation techniques in the fields of product design, robot control, and natural language processing. In addition, based on the investigation of the knowledge characteristics of the securities industry, a knowledge representation model of the securities industry based on 5W1lH is proposed to organize and manage the multimodal information resources and provide high-value information for user needs, while the knowledge representation technology of the mechanical industry based on hypergraph embedding is examined and the specific processes and application scenarios are summarized.},
  keywords={Industries;Service robots;Robot control;Knowledge representation;Product design;Natural language processing;Security;knowledge representation;knowledge graph;industry knowledge base},
  doi={10.1109/SNPD-Winter57765.2023.10223881},
  ISSN={},
  month={July},}@INPROCEEDINGS{10205180,
  author={Gu, Xin and Chen, Guang and Wang, Yufei and Zhang, Libo and Luo, Tiejian and Wen, Longyin},
  booktitle={2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)}, 
  title={Text with Knowledge Graph Augmented Transformer for Video Captioning}, 
  year={2023},
  volume={},
  number={},
  pages={18941-18951},
  abstract={Video captioning aims to describe the content of videos using natural language. Although significant progress has been made, there is still much room to improve the performance for real-world applications, mainly due to the long-tail words challenge. In this paper, we propose a text with knowledge graph augmented transformer (TextKG)for video captioning. Notably, TextKG is a two-stream transformer, formed by the external stream and internal stream. The external stream is designed to absorb additional knowledge, which models the interactions between the additional knowledge, e.g., pre-built knowledge graph, and the built-in information of videos, e.g., the salient object regions, speech transcripts, and video captions, to mitigate the long-tail words challenge. Meanwhile, the internal stream is designed to exploit the multi-modality information in videos (e.g., the appearance of video frames, speech transcripts, and video captions) to ensure the quality of caption results. In addition, the cross attention mechanism is also used in between the two streams for sharing information. In this way, the two streams can help each other for more accurate results. Extensive experiments conducted on four challenging video captioning datasets, i.e., YouCookII, ActivityNet Captions, MSR-VTT, and MSVD, demonstrate that the proposed method performs favorably against the state-of-the-art methods. Specifically, the proposed TextKG method out-performs the best published results by improving 18.7% absolute CIDEr scores on the YouCookII dataset.},
  keywords={Computer vision;Semantics;Natural languages;Knowledge graphs;Speech recognition;Streaming media;Transformers;Vision;language;and reasoning},
  doi={10.1109/CVPR52729.2023.01816},
  ISSN={2575-7075},
  month={June},}@INPROCEEDINGS{10394492,
  author={Ming, Yan and Shang, Yong and Li, Huiting},
  booktitle={2023 IEEE International Conference on Systems, Man, and Cybernetics (SMC)}, 
  title={Relation Extraction with Knowledge-Enhanced Prompt-Tuning on Multimodal Knowledge Graph}, 
  year={2023},
  volume={},
  number={},
  pages={460-465},
  abstract={Recently, Multimodal Knowledge Graphs (MKGs) with visual and textual factual knowledge have been widely used in tasks such as knowledge question answering, recommender systems, and entity disambiguation. Since most of the current MKGs still have defects, a multimodal knowledge graph completion technology is proposed, and multimodal relation extraction (MRE) is one of the basic processes. However, visual objects with high object classification scores are usually selected in previous tasks, which may result in the addition of noise from objects that are either irrelevant or redundant, which can adversely affect multimodal relationship extraction. For this reason, in this paper, we propose a Relation Extraction with Knowledge-enhanced Prompt-tuning modal on multimodal knowledge graph (REKP) to address these issues. Specifically, we inject potential knowledge from relational labels into the prompt construction of answer words and optimize their representation with structured constraints. A Transformer architecture with cross-modal attention is then used to fuse the visual and textual representations. We conduct extensive experiments to verify that our REKP model can achieve SOTA performance on the MNRE dataset with multimodal relational extraction.},
  keywords={Visualization;Fuses;Knowledge graphs;Transformers;Question answering (information retrieval);Task analysis;Recommender systems;Multimodal;Knowledge Graphs;relation extraction;Knowledge-enhanced;Prompt-tuning},
  doi={10.1109/SMC53992.2023.10394492},
  ISSN={2577-1655},
  month={Oct},}@INPROCEEDINGS{10463196,
  author={Kundu, Arghya and Nguyen, Uyen Trang},
  booktitle={2024 International Conference on Artificial Intelligence in Information and Communication (ICAIIC)}, 
  title={Automated Fact Checking Using A Knowledge Graph-based Model}, 
  year={2024},
  volume={},
  number={},
  pages={709-716},
  abstract={Misinformation is a growing threat to the economy, social stability, public health, democracy, and national security. One of the most effective methods to combat misinformation is fact checking. Fact checking is the process of verifying the factual accuracy of a statement or claim. Fact checkers employ rigorous methodologies to scrutinize claims, verify sources, and expose falsehoods. However, the huge volume of content circulating online makes it challenging for humans to identify misinformation manually. Automated tools can analyze large datasets to detect patterns in misinformation content, scaling up fact checking efforts. This paper proposes a knowledge graph-based fact checking model that uses two separate knowledge graphs, one containing true claims and the other, false claims. The model uses knowledge graph embeddings which are based on convolutional neural networks. The deep learning model is trained on the above two knowledge graphs to learn distinguishing patterns between true and false claims. Additionally, we employ explainable artificial intelligence (XAI) techniques to provide explanations for the model's classification, reducing cost of errors and increasing transparency and user trust in the system.},
  keywords={Training;Explainable AI;Knowledge graphs;Predictive models;Vectors;Stability analysis;Convolutional neural networks;Misinformation;disinformation;fake news;fact checking;knowledge graphs;machine learning;natural language processing},
  doi={10.1109/ICAIIC60209.2024.10463196},
  ISSN={2831-6983},
  month={Feb},}@INPROCEEDINGS{10260382,
  author={Xia, Liqiao and Zheng, Pai and Liang, Yongshi and Zheng, Ge and Ling, Zhengyang},
  booktitle={2023 IEEE 19th International Conference on Automation Science and Engineering (CASE)}, 
  title={Secure Co-Creation of Industrial Knowledge Graph: Graph Complement Method with Federated Learning and ChatGPT}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={Industrial areas have increasingly developed their own Knowledge Graph (KG) for organizing and leveraging vast amounts of data. One major challenge in constructing KG is the heavy reliance on available resources, restricting the scalability and accuracy of the resulting graphs. To address this issue, an end-to-end method is proposed to create a multi-benefit ecosystem by integrating Federated Learning with ChatGPT (a popular language model). Different stakeholders may leverage ChatGPT to search for novel knowledge that complements their existing KGs, however, this approach could potentially introduce ambiguous and wrong triples into the KG. To overcome this, Federated Learning is applied to align and disambiguate the triples using other industrial KGs as super-vision. The proposed method applies a multi-field hyperbolic embedding method to vectorize entities and edges, which are then associatively aggregated to achieve edge replenishment and entity fusion for each KG encrypted. Finally, an incentive win-win mechanism is proposed to motivate diverse stakeholders to contribute to this co-creation actively. A case study is conducted on different industrial KG to evaluate the proposed method. Results demonstrate that this method provides a practical solution for KG co-creation and no compromise to data security.},
  keywords={Federated learning;Scalability;Semantics;Ecosystems;Knowledge graphs;Chatbots;Reliability engineering},
  doi={10.1109/CASE56687.2023.10260382},
  ISSN={2161-8089},
  month={Aug},}@INPROCEEDINGS{10394554,
  author={Jing, Xiaonan and Rayz, Julia M.},
  booktitle={2023 IEEE International Conference on Systems, Man, and Cybernetics (SMC)}, 
  title={Prompt-assisted Relation Fusion in Knowledge Graph Acquisition}, 
  year={2023},
  volume={},
  number={},
  pages={2960-2965},
  abstract={This paper investigated how prompt-based learning techniques can assist with relation fusion in Knowledge Graph (KG) acquisition. We created a unsupervised framework to generate a KG from a real-world dataset. The framework incorporates prompting with knowledge entity metadata and generating predicate embeddings with the pretrained Masked Language Model (MLM) RoBERTa. Predicate embeddings were clustered to form conceptual groups and feature tokens were used to derive relation labels. In addition, we conducted a comparative study on the effects of different prompting templates. The resulting relation labels were evaluated by human annotators, which indicated that prompt-based learning, if applied appropriately, can help with deducing conceptualized relations. Our framework proposed a way to improve the quality of KGs acquired using traditional Relation Extraction (RE). It can also assist human experts effectively in semi-automated knowledge acquisition.},
  keywords={Knowledge acquisition;Knowledge graphs;Metadata;Cybernetics},
  doi={10.1109/SMC53992.2023.10394554},
  ISSN={2577-1655},
  month={Oct},}@ARTICLE{10839124,
  author={Wang, Xingfei and Zhang, Ke and Niu, Muyuan and Wang, Xiaofen},
  journal={IEEE Transactions on Knowledge and Data Engineering}, 
  title={SemSI-GAT: Semantic Similarity-based Interaction Graph Attention Network for Knowledge Graph Completion}, 
  year={2025},
  volume={},
  number={},
  pages={1-13},
  abstract={Graph Neural Networks (GNNs) show great power in Knowledge Graph Completion (KGC) as they can handle nonEuclidean graph structures and do not depend on the specific shape or topology of the graph. However, many current GNNbased KGC models have difficulty in effectively capturing and utilizing the substantial structure and global semantic information in Knowledge Graphs (KGs). For more effective use of GNN for KGC, we innovatively propose the Semantic Similaritybased Interaction Graph Attention Network (SemSI-GAT) for the KGC task. In SemSI-GAT, we utilize BERT, a pre-trained language model, to learn the global semantic information and obtain semantic similarity between entities and their neighbors. Furthermore, we creatively design a novel encoder network called the interaction graph attention network and introduce a semantic similarity sampling mechanism to optimize the aggregation of interaction information between neighbors. By aggregating local features with interaction features, this network can generate more expressive structural embeddings. This network generates more expressive embeddings by fusing global semantic information, local structure features, and interaction features. The experimental evaluations demonstrate that the proposed SemSIGAT outperforms existing state-of-the-art KGC methods on four benchmark datasets},
  keywords={Semantics;Knowledge graphs;Encoding;Bidirectional control;Decoding;Computational modeling;Vectors;Training;Predictive models;Feature extraction;Knowledge graph completion;interaction information;semantic similarity sampling;graph attention network},
  doi={10.1109/TKDE.2025.3528496},
  ISSN={1558-2191},
  month={},}@INPROCEEDINGS{10800417,
  author={Chow, Sabrina and Guo, Lilian and Chow, Jonathan and Chia, Chelsea and Li, Sarah and Huang, Dong-Yan},
  booktitle={2024 IEEE 14th International Symposium on Chinese Spoken Language Processing (ISCSLP)}, 
  title={Semantic Search Using LLM-Aided Topic Generation on Knowledge Graphs for Paper Discovery}, 
  year={2024},
  volume={},
  number={},
  pages={353-357},
  abstract={The exponential growth of academic papers presents a huge challenge for researchers, exacerbating the already tedious literature review process. Current tools like Google Scholar and Connected Papers offer solutions for text-based and citation-based searches but fail to address the need for finding semantically similar yet terminologically different papers efficiently. This paper proposes an innovative approach to paper discovery using semantic search to create a knowledge graph of topics and papers. By generating a tree of topics using ChatGPT 4o and calculating semantic similarity with SciBERT, this method aims to uncover relevant papers overlooked by traditional citation-based searches. The solution, validated through quantitative evaluation, demonstrates the potential to improve the efficiency and comprehensiveness of paper discovery.},
  keywords={Semantic search;Navigation;Bibliographies;Focusing;Knowledge graphs;Chatbots;Rendering (computer graphics);Internet;Semantic Search;Knowledge Graphs;Literature Review;Natural Language Processing (NLP);SciBERT},
  doi={10.1109/ISCSLP63861.2024.10800417},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10814632,
  author={Von der Assen, Jan and Huertas, Alberto and Sharif, Jamo and Feng, Chao and Bovet, Gérôme and Stiller, Burkhard},
  booktitle={2024 20th International Conference on Network and Service Management (CNSM)}, 
  title={ThreatFinderAI: Automated Threat Modeling Applied to LLM System Integration}, 
  year={2024},
  volume={},
  number={},
  pages={1-3},
  abstract={Artificial Intelligence (AI) is a rapidly integrated technology, significantly contributing to advancements like 6G. However, its swift adoption raises considerable security concerns. Large Language Models (LLMs) pose risks such as spear phishing, code injections, and remote code execution. Conventional threat modeling, used in secure software development, faces challenges when applied to AI systems, as existing methodologies are designed for traditional software. Furthermore, AI-specific threat modeling research is sparse and lacks approaches providing practical support or automation. Thus, this demo paper presents ThreatFinderAI, an asset-centric threat modeling and risk assessment framework. ThreatFinderAI fulfills seven steps aligned with AI system design and transforms AI threat and control knowledge bases into a queryable knowledge graph for automated asset identification and threat elicitation. It also proposes business impact analysis and expert estimates for AI threat impact quantification. In the demonstration, ThreatFinderAI is illustrated by securing a customer care application relying on LLMs. Through this, it is demonstrated how the proposed framework can be used to identify relevant threats and practical countermeasures and communicate strategic risk.},
  keywords={Threat modeling;Codes;Transforms;System integration;Software;Security;Risk management;Artificial intelligence;System analysis and design;Software development management;Threat Modeling;AI Systems;Large Language Models;AI Security},
  doi={10.23919/CNSM62983.2024.10814632},
  ISSN={2165-963X},
  month={Oct},}@ARTICLE{9386086,
  author={Liu, Shu-Kan and Xu, Rui-Lin and Geng, Bo-Ying and Sun, Qiao and Duan, Li and Liu, Yi-Ming},
  journal={IEEE Access}, 
  title={Metaknowledge Extraction Based on Multi-Modal Documents}, 
  year={2021},
  volume={9},
  number={},
  pages={50050-50060},
  abstract={The triplet-based knowledge in large-scale knowledge bases is most likely lacking in structural logic and problematic of conducting knowledge hierarchy. In this paper, we introduce the concept of metaknowledge to knowledge engineering research for the purpose of structural knowledge construction. Therefore, the Metaknowledge Extraction Framework and Document Structure Tree model are presented to extract and organize metaknowledge elements (titles, authors, abstracts, sections, paragraphs, etc.), so that it is feasible to extract the structural knowledge from multi-modal documents. Experiment results have proved the effectiveness of metaknowledge elements extraction by our framework. Meanwhile, detailed examples are given to demonstrate what exactly metaknowledge is and how to generate it. At the end of this paper, we propose and analyze the task flow of metaknowledge applications and the associations between knowledge and metaknowledge.},
  keywords={Task analysis;Optical character recognition software;Layout;Object detection;Semantics;Knowledge based systems;Computational modeling;Metaknowledge;multi-modal;document layout analysis;knowledge graph},
  doi={10.1109/ACCESS.2021.3068728},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10062878,
  author={Li, Jianli and Yilahun, Hankiz and Hamdulla, Askar},
  booktitle={2022 International Conference on Virtual Reality, Human-Computer Interaction and Artificial Intelligence (VRHCIAI)}, 
  title={Chinese Named Entity Recognition Based on Improved K-BERT}, 
  year={2022},
  volume={},
  number={},
  pages={248-254},
  abstract={Named entity recognition of Chinese text using pre-trained models is the mainstream approach at present, and the proposed K-BERT model overcomes the problem that BERT models do not possess background knowledge. We use the Chinese pre-trained model BERT-wwm and adversarial training based on full-word masking technology on the basis of K-BERT to improve the disadvantages of poor robustness of traditional K-BERT neural network and the existence of WordPiece sequence mask of traditional BERT. The experimental results on three open source datasets, MEDICAL_NER, MSRA_NER and FINANCIAL_NER, show that the evaluation index F1-score is improved after adding the adversarial training model. And the comparison experiments verify that adding adversarial training can elevate the prediction ability and robustness.},
  keywords={Training;Human computer interaction;Solid modeling;Text recognition;Bit error rate;Neural networks;Virtual reality;K-BERT;Knowledge Graph;Chinese Named Entity Recognition;Pre-trained language models;Adversarial Training},
  doi={10.1109/VRHCIAI57205.2022.00050},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10229400,
  author={Wu, Kuan-Wei and Hsu, Tz-Huan and Huang, Yen-Hao and Chen, Yi-Shin and Wang, Ho-Lung and Hsieh, Bing-Jing and Hsu, Chi-Hung},
  booktitle={2023 IEEE 24th International Conference on Information Reuse and Integration for Data Science (IRI)}, 
  title={LeCAR: Leveraging Context for Enhanced Automotive Specification Retrieval}, 
  year={2023},
  volume={},
  number={},
  pages={185-190},
  abstract={In the domain of automotive manufacturing, specification documents represent intricate descriptions detailing every aspect of a product, design, or service. Conventionally, these specifications demand the deployment of expert teams to manually identify crucial data from the extensive documentation. The need to automate the extraction of candidate information from these documents is increasingly pressing in this industry. This research encounters two central challenges: Firstly, the queries for the specifications input by users are typically concise and ambiguous; secondly, not every word in a query carries the same significance. In response to these challenges, we propose LeCAR, which exploits contextual data to clarify query sentences and concentrate the search scope. Our experiments validate that the proposed method outperforms existing techniques that employ pre-trained language models, all without necessitating additional training data.},
  keywords={Training;Semantics;Training data;Knowledge graphs;Pressing;Information retrieval;Product design;Information Retrieval;Dense Retrieval;Specific Domain;Knowledge Graph},
  doi={10.1109/IRI58017.2023.00038},
  ISSN={2835-5776},
  month={Aug},}@INPROCEEDINGS{9719180,
  author={Chen, Meiling and Tian, Ye and Wang, Zhaorui and Jiang, Bo and Xu, Hong},
  booktitle={2021 International Conference on Computer Information Science and Artificial Intelligence (CISAI)}, 
  title={A Comprehensive Study of Cognitive Graphs: Techniques, Applications, and Challenges}, 
  year={2021},
  volume={},
  number={},
  pages={1108-1122},
  abstract={The realization of third-generation artificial intelligence (AI) requires the evolution from perceptual intelligence to cognitive intelligence; in this context, knowledge graphs may no longer meet practical needs. Based on dual channel theory, cognitive graphs are established and developed by coordinating an implicit extraction module and an explicit reasoning module, as well as integrating knowledge graphs, cognitive reasoning, and logical expressions, which have achieved successes in multi-hop question answering. The widespread use of cognitive graphs in advanced AI applications (e.g., large-scale knowledge representations and intelligent responses) is desirable, which will promote the development of AI dramatically. This review discusses cognitive graphs systematically and elaborately, including their basic concepts, generation, theories, and technologies. Moreover, we try to predict the development of cognitive intelligence in the short-term future and further encourage more research works and studies.},
  keywords={Deep learning;Information science;Knowledge representation;Learning (artificial intelligence);Computer architecture;Cognition;Cognitive science;cognitive graph;knowledge graph;knowledge reasoning;natural language generation},
  doi={10.1109/CISAI54367.2021.00222},
  ISSN={},
  month={Sep.},}@ARTICLE{8047091,
  author={Zhou, Nan and Li, Di and Li, Song and Wang, Shiyong and Liu, Chengliang},
  journal={IEEE Access}, 
  title={Model-Based Development of Knowledge-Driven Self-Reconfigurable Machine Control Systems}, 
  year={2017},
  volume={5},
  number={},
  pages={19909-19919},
  abstract={To accommodate the trend toward mass customization launched by intelligent manufacturing in the era of Industry 4.0, this paper proposes the combination of model-driven engineering and knowledgedriven engineering during the development process of self-reconfigurable machine control systems. The complete tool chain for model development, execution, and reconfiguration is established. For the design phase, a machine-control-domain-specific modeling language and the supporting design environment are developed. With regard to the execution stage, a runtime framework compliant with the IEC 61499 standard is proposed. On the ground of the modeling environment and the reconfigurable run-time framework, a self-adaptive control module is developed to establish the close-loop self-reconfiguration infrastructure. The ontological representation of knowledge base toward this end is described, along with extendable SQWRL rules specified to automatically initiate the reconfiguration process in the cases of external user demands and internal faults. A prototype motion control kernel in the low-level layer of machine control system architecture is developed with the proposed modeling language and is then deployed to the runtime framework. Two case studies on self-reconfiguration of the proof-of-concept motion control kernel are demonstrated, which prove the feasibility of our proposal.},
  keywords={Machine control;Computer architecture;Software;IEC Standards;Control systems;Real-time systems;Microwave integrated circuits;Reconfiguration;machine control system;domain-specific modeling language;ontology;IEC 61499},
  doi={10.1109/ACCESS.2017.2754507},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{8088312,
  author={Hoppe, Tobias and Eisenmann, Harald and Viehl, Alexander and Bringmann, Oliver},
  booktitle={2017 IEEE International Systems Engineering Symposium (ISSE)}, 
  title={Shifting from data handling to knowledge engineering in aerospace industry}, 
  year={2017},
  volume={},
  number={},
  pages={1-6},
  abstract={The development of increasingly complex systems with improved quality levels becomes more and more challenging. Engineering data frameworks with integrated system models have been developed to manage such systems. This paper presents the experiences that have been made in digital systems engineering in the aerospace domain and focuses on the roadmap that has been taken to establish a knowledge engineering framework. While working with first versions of these tools, it became obvious that an engineering framework reflecting all aspects of an engineering data object was required. In addition, data analytics and technologies used to check data consistency became increasingly relevant. As a consequence, semantically rich data models expressed by ontologies come into focus of forming the engineering framework baseline in conjunction with related technologies such as reasoning, error avoidance based on data analytics, and knowledge-driven engineering environments.},
  keywords={Data models;Semantics;Ontologies;OWL;Unified modeling language;Model-based Systems Engineering;Digitalization;Industry 4.0;Ontology;Semantic Engineering Framework},
  doi={10.1109/SysEng.2017.8088312},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{9256484,
  author={Helmke, Hartmut and Kleinert, Matthias and Ohneiser, Oliver and Ehr, Heiko and Shetty, Shruthi},
  booktitle={2020 AIAA/IEEE 39th Digital Avionics Systems Conference (DASC)}, 
  title={Machine Learning of Air Traffic Controller Command Extraction Models for Speech Recognition Applications}, 
  year={2020},
  volume={},
  number={},
  pages={1-9},
  abstract={Increasing digitization and automation is a widely accepted method to cope with the challenges of constantly increasing air traffic. The analogue communication of air traffic controllers (ATCo) to pilots has been excluded so far from the digitization process. However, the content of this communication is of decisive importance for various automation systems. Although Assistant Based Speech Recognition (ABSR) has recently significantly improved the recognition performance and, therefore, enables the digitization of ATCo-pilot-communication, its adaptation to other airports is a critical and costly process, This is even more important, if ATCos tend to deviate from the published ICAO phraseology: “start reducing to two fifty” instead of “reduce two five zero knots” is just an example. User acceptance requires that these deviations are also correctly recognized. Therefore, this paper presents an approach, which automatically learns a so-called Command Extraction Model from labelled controller utterances. The initial Command Extraction Model without learning only covers 60% of the commands, whereas the automatically learned Command Extraction Model covers more than 98%. With just six hours of training data we could achieve 94%.},
  keywords={Speech recognition;Atmospheric modeling;Adaptation models;Ontologies;Engines;Annotations;Airports;Automatic Speech Recognition;Machine Learning;Annotation;Ontology;Controller Command Extraction Model},
  doi={10.1109/DASC50938.2020.9256484},
  ISSN={2155-7209},
  month={Oct},}@INPROCEEDINGS{8577518,
  author={Wan, Guangxi and Wang, Peng and Xue, Lingling and Zeng, Peng},
  booktitle={2018 IEEE 3rd Advanced Information Technology, Electronic and Automation Control Conference (IAEAC)}, 
  title={An Integrated Design Method For Cyber-Physical Production Systems}, 
  year={2018},
  volume={},
  number={},
  pages={791-796},
  abstract={The industrial cyber-physical production system contains a variety of heterogeneous devices and models, which increase the complexity of system design, particularly in software programming. Although the proposed model-driven engineering (MDE) is applied to industrial automation for this issue, the inherent complex dependencies and constraints between models and the availability of suitable tools for code generation limit the application of the model-driven approach in practice, especially as the system becomes more enormous. The component-based design (CBD) approach, which is a bottom-up approach, in contrast to the MDE that is top-down, is proposed to manage the complexity of software aspect based on the idea that building a system from existing components instead of the scratch. However, CBD can't provide the whole system model, so other ways should be adopted to design the system structure in advance. This paper presents an integrated design approach based on the combination of CBD and MDE to realize auto-design for cyber-physical production systems.},
  keywords={Unified modeling language;Automation;Control systems;Software;Ontologies;Testing;Integrated design;Component-based Design;IEC 61499;Industrial automation;Model-based design;Ontology;Semantic technology},
  doi={10.1109/IAEAC.2018.8577518},
  ISSN={2381-0947},
  month={Oct},}@INPROCEEDINGS{10651121,
  author={Yang, Dongyu and Deng, Wenqing and Wang, Zhe and Wang, Kewen and Zhuang, Zhiqiang and Li, Hao},
  booktitle={2024 International Joint Conference on Neural Networks (IJCNN)}, 
  title={Learning Choice Nuance for Multiple-Choice Commonsense Question Answering}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={Existing models for commonsense question answering (CQA) usually focus on combining pre-trained language models (PLMs) and structured knowledge graphs (KGs) for joint reasoning. However, such approaches encode a QA context (i.e., a pair of the question and a choice) separately from other choices, ineffective for explicitly capturing useful subtle differences among the choices, which results in incorrect answers in some cases. This paper proposes a novel model LNC (Learning Nuance among Choices) for addressing this problem and thus provides an improved approach to multiple-choice question answering. Specifically, LNC explicitly interacts between the text knowledge corresponding to each choice and the external KG knowledge corresponding to each choice, and removes the commonalities among similar choices, allowing the model to focus on different relevant knowledge based on the choices, thereby distinguishing semantically similar choices. Experimental results on major benchmark datasets show that LNC is competitive comparing to the baseline models.},
  keywords={Neural networks;Knowledge based systems;Knowledge graphs;Benchmark testing;Question answering (information retrieval);Cognition;Optimization;Commonsense Question Answering;Multiple-Choice Question Answering;Pre-trained Language Model;Knowledge Graph},
  doi={10.1109/IJCNN60899.2024.10651121},
  ISSN={2161-4407},
  month={June},}@INPROCEEDINGS{10394522,
  author={Li, Jinbao and Wang, Guangchen and Tian, Cheng and Liu, Song},
  booktitle={2023 IEEE International Conference on Systems, Man, and Cybernetics (SMC)}, 
  title={A Dynamic Global Semantic Fusion GNN Model For Commonsense Question Answering}, 
  year={2023},
  volume={},
  number={},
  pages={659-665},
  abstract={Commonsense question answering (CSQA) is a challenging learning task that aims to give correct answers to commonsense questions. CSQA models combining large pretrained language models with knowledge graphs are proposed to perform one-way or two-way information fusion to enhance their commonsense reasoning ability. However, existing CSQA models only fuse local information at the word level, ignoring the global semantic information fusion. Furthermore, current CSQA models often introduce noise nodes when constructing the knowledge subgraph. In addition, existing methods neglect the edge information in message aggregation. To solve these shortcomings, we propose a novel CSQA model named MDEQA. In our model, we design the multi-layer attention fusion module to bidirectionally fuse the word-level local information and global semantic information of question context and knowledge subgraph. Moreover, we design the dynamic graph neural network module with improved GAT and aggregating edge information to form the dynamic subgraphs which alleviate the interference of noise nodes on reasoning and enhance the commonsense reasoning ability of our model. Finally, we evaluated our model on CommonsenseQA and OpenBookQA datasets to compare with other baseline models.},
  keywords={Fuses;Semantics;Question answering (information retrieval);Graph neural networks;Task analysis;Commonsense reasoning;Context modeling;Commonsense Question Answering;Large Pretrained Language Model;Knowledge Graph;Multi-layer Attention Fusion;Dynamic Graph Neural Network},
  doi={10.1109/SMC53992.2023.10394522},
  ISSN={2577-1655},
  month={Oct},}@INPROCEEDINGS{9435777,
  author={Sarsembayeva, Talshyn and Mansurova, Madina and Chikibayeva, Darya and Karymsakova, Dariya},
  booktitle={2020 IEEE 8th Workshop on Advances in Information, Electronic and Electrical Engineering (AIEEE)}, 
  title={The Problem of Named Entities Unification based on Geographical Ontologies}, 
  year={2021},
  volume={},
  number={},
  pages={1-6},
  abstract={The subject of this research is to develop a system for extracting knowledge from both semi-structured and unstructured data and filling with this system a knowledge base that would provide support for decision-making on any problematic issues. The article deals with the problem of unification of named entities based on geographical ontologies.},
  keywords={Knowledge engineering;Decision making;Knowledge based systems;Machine learning;Ontologies;Information retrieval;Data models;semi-structured and unstructured data;decision support system;ontology;thesaurus;information extraction;knowledge extraction;knowledge base;machine learning;named entities},
  doi={10.1109/AIEEE51419.2021.9435777},
  ISSN={2689-7342},
  month={April},}@INPROCEEDINGS{9921520,
  author={Deppe, Sahar and Brandt, Lukas and Brünninghaus, Marc and Papenkordt, Jörg and Heindorf, Stefan and Tschirner-Vinke, Gudrun},
  booktitle={2022 IEEE 27th International Conference on Emerging Technologies and Factory Automation (ETFA)}, 
  title={AI-Based Assistance System for Manufacturing}, 
  year={2022},
  volume={},
  number={},
  pages={1-4},
  abstract={Manufacturing companies are challenged to make the increasingly complex work processes equally manageable for all employees to prevent an impending loss of competence. In this contribution, an intelligent assistance system is proposed enabling employees to help themselves in the workplace and provide them with competence-related support. This results in increasing the short- and long-term efficiency of problem solving in companies.},
  keywords={Employment;Companies;Manufacturing;Problem-solving;Manufacturing automation;Assistance system;Knowledge graph;Information retrieval;Neural networks;AR},
  doi={10.1109/ETFA52439.2022.9921520},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10219862,
  author={You, Jiuxiang and Yang, Zhenguo and Li, Qing and Liu, Wenyin},
  booktitle={2023 IEEE International Conference on Multimedia and Expo (ICME)}, 
  title={A Retriever-Reader Framework with Visual Entity Linking for Knowledge-Based Visual Question Answering}, 
  year={2023},
  volume={},
  number={},
  pages={13-18},
  abstract={In this paper, we propose a Retriever-Reader framework with Visual Entity Linking (RR-VEL) for knowledge-based visual question answering. Given images and original questions, the visual entity linking (VEL) module extracts key entities in images to replace the question referents for semantic disambiguation, achieving entity-oriented queries with explicit entities. Furthermore, the Retriever encodes the queries and knowledge items by Bert with a feed-forward layer, and obtains a set of knowledge candidates. The Reader encodes the questions with image captions and knowledge candidates in two branches, which avoids their interference during self-attentive encoding. Finally, the decoder of Reader fuses the encoded features to generate answers. Extensive experiments conducted on the two public datasets show that our method significantly outperforms the existing baselines.},
  keywords={Visualization;Image coding;Fuses;Knowledge based systems;Semantics;Interference;Benchmark testing;VQA;Knowledge graph;Entity linking},
  doi={10.1109/ICME55011.2023.00011},
  ISSN={1945-788X},
  month={July},}@INPROCEEDINGS{9664111,
  author={Yang, Jianxi and Yang, Xiaoxia and Li, Ren and Luo, Mengting},
  booktitle={2021 7th International Conference on Systems and Informatics (ICSAI)}, 
  title={A Multi-Task Information Extraction Framework for Bridge Inspection Based on Joint Neural Networks}, 
  year={2021},
  volume={},
  number={},
  pages={1-6},
  abstract={Focused on the issue that insufficient information extraction and knowledge services in the bridge management and maintenance domain, a multi-task information extraction framework for bridge inspection based on joint neural networks is proposed. Firstly, a multi-task information extraction training dataset for bridge inspection is constructed and a distributed representation of the text is obtained using BERT as the embedding layer. Secondly, the subtasks of topic word detection and other bridge inspection information extraction are jointly learned by sharing BERT weights and fine-tuning, and the context features are further extracted in depth. Finally, the bridge inspection knowledge service is used as application examples to verify the effectiveness of the bridge inspection information extraction model in actual application scenarios such as bridge domain question answering. In the comparison experiments with mainstream models, the proposed method outperforms the mainstream models with F1-score of 85.27%, 72.73%, and 90.76% for the NER, RE, and topic word detection respectively. The experimental results show that the model can meet the requirements of a variety of practical tasks for information extraction of bridge inspection.},
  keywords={Bridges;Bit error rate;Neural networks;Inspection;Information retrieval;Multitasking;Knowledge discovery;bridge inspection;information extraction;BERT;knowledge graph;knowledge base question answering},
  doi={10.1109/ICSAI53574.2021.9664111},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10098037,
  author={Ma, Haoyang and Li, Zeyu and Guo, Hongyu},
  booktitle={2022 IEEE 34th International Conference on Tools with Artificial Intelligence (ICTAI)}, 
  title={Using Noise and External Knowledge to Enhance Chinese Pre-trained Model}, 
  year={2022},
  volume={},
  number={},
  pages={476-480},
  abstract={Pre-trained language models (PLMs) have the risk of overfitting pre-trained tasks and data in fine-tuning, while Chinese PLMs often ignore external knowledge such as word and sentence to learn representations. Therefore, we propose a Chinese PLM enhancement method using noise and external knowledge (NEK). NEK first adds different uniform noises to the PLM according to the standard deviation of different parameter matrices, so as to obtain the perturbed PLM. In the fine-tuning phase, NEK builds a heterogeneous linguistic graph based on external knowledge. This module adopts a graph-based approach to generalize information of different granularities in Chinese linguistics, and enhances Chinese PLM on this basis. Experimental results show that NEK brings performance improvements to a variety of different Chinese PLMs on six natural language processing tasks on eight benchmark datasets.},
  keywords={Linguistics;Benchmark testing;Natural language processing;Data models;Task analysis;Artificial intelligence;Standards;External Knowledge;Graph neural network;Pre-trained language model},
  doi={10.1109/ICTAI56018.2022.00076},
  ISSN={2375-0197},
  month={Oct},}@INPROCEEDINGS{9914462,
  author={Wu, Jun and Yan, Qingguo and Dong, Qinwei and Zha, Xianguang and Cui, Lin and Zhao, Xindong and Dai, Wei and Luo, Chong},
  booktitle={2022 9th International Conference on Dependable Systems and Their Applications (DSA)}, 
  title={Task-driven Dialogue System based on Dynamic Intention Capture}, 
  year={2022},
  volume={},
  number={},
  pages={859-864},
  abstract={With the continuous development of artificial intelligence technology, dialogue system has attracted more and more attention because of its strong applicability and wide application scenarios. It has gradually entered all aspects of people's lives. The development of science and technology such as speech recognition and synthesis, natural language processing, machine learning, deep neural network and soon has also accelerated the transformation of this process, Make the machine closer to the goal of smooth dialogue with people. This paper mainly studies the task driven human-computer interaction system. Aiming at the sequence track of humancomputer conversation, we use the encoding and decoding model to capture human's dynamic intention. From the final system, this way can significantly improve the accuracy of machine response compared with the previous way of only recommending answers through single state conversation.},
  keywords={Human computer interaction;Knowledge engineering;Deep learning;Neural networks;Oral communication;Speech recognition;Natural language processing;man-computer communication;dynamic intention;knowledge graph;encoder-decoder network;natural language processing},
  doi={10.1109/DSA56465.2022.00121},
  ISSN={2767-6684},
  month={Aug},}@INPROCEEDINGS{10222675,
  author={Dao, Minh-Son and Zettsu, Koji},
  booktitle={2023 IEEE International Conference on Multimedia and Expo Workshops (ICMEW)}, 
  title={Leveraging Knowledge Graphs for CheapFakes Detection: Beyond Dataset Evaluation}, 
  year={2023},
  volume={},
  number={},
  pages={99-104},
  abstract={The proliferation of the internet and the availability of vast amounts of information have given rise to a critical and pressing issue of fake news. Among the various forms of fake news, cheapfakes are particularly prominent in deceiving people. Existing research on cheapfakes detection has primarily focused on analyzing the context and correlation between textual and visual information, but has largely overlooked the significance of external knowledge. As a result, most previous approaches, apart from the baseline of ICME‘23 Grand Challenge on Detecting Cheapfakes, have heavily relied on evaluating the dataset itself to improve performance. However, despite achieving impressive results on public test datasets, these approaches often suffer from poor performance in real-world scenarios due to their overreliance on the given dataset. In this study, we propose a novel approach that utilizes knowledge graphs to address the issue of insufficient information from external knowledge. Unlike previous approaches, our proposal does not directly alter or participate in the public test dataset to enhance performance, which can potentially result in significant overfitting. Our proposed approach achieved an accuracy score of 83.52% on Task 1, surpassing the baseline by 1.7%, and an accuracy score of 84% on Task 2, outperforming the best result from the previous challenge by 8%.},
  keywords={Visualization;Correlation;Conferences;Knowledge graphs;Pressing;Syntactics;Linguistics;Deep Learning;Computer Vision;Natural Language Processing;Knowledge Graph;Cheapfakes;Misinformation;News},
  doi={10.1109/ICMEW59549.2023.00024},
  ISSN={},
  month={July},}@INPROCEEDINGS{10391221,
  author={Zhang, Zilin and YuFan and Li, BaiHong and Zeng, ZhiZhong},
  booktitle={2023 International Conference on Intelligent Education and Intelligent Research (IEIR)}, 
  title={Review of research on synonym equivalence relation mining}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={Synonym discovery, also known as synonym relation mining or synonym extraction, aims to identify and establish synonymous relationships between words, phrases, or sentences. The primary objective of this relationship mining is to enhance the performance of natural language processing (NLP) tasks, such as information retrieval, question-answering systems, text summarization, and machine translation. Considering that there are still numerous areas and issues awaiting further research in synonym relation mining, this paper provides a comprehensive review of the research methods employed in this field over the past two decades. The review is organized into four main categories. The first category explores the u e of language models for synonym extraction, including techniques such as word embeddings and the recent BERT model. The second category focuses on computing semantic similarity in synonym semantic spaces. The third category examines neural network-based approaches for synonym relation mining. Lastly, the fourth category delves into constructing synonym relationships based on knowledge graphs. Additionally, this paper provides an outlook and summary of potential future developments in this direction, with the aim of offering valuable guidance for future research in the field.},
  keywords={Computational modeling;Semantics;Education;Knowledge graphs;Information retrieval;Machine translation;Task analysis;Synonym discovery;equivalence relation detection;pre-trained model (BERT);knowledge graph;neural network},
  doi={10.1109/IEIR59294.2023.10391221},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10212829,
  author={Xian, Guangming and Zhang, Wencong and Lan, Fucai and Lin, Yifan and Lin, Yanhang},
  booktitle={2023 5th International Conference on Electronic Engineering and Informatics (EEI)}, 
  title={Multimodal Knowledge Triple Extraction Based on Representation Learning}, 
  year={2023},
  volume={},
  number={},
  pages={684-689},
  abstract={Knowledge based visual question-answering is an emerging technique that combines computer vision and natural language processing to address image-based questions. This approach requires the model to possess internal reasoning ability and incorporate external knowledge to enhance its generalization performance. Knowledge graphs are commonly employed to integrate various types of knowledge, such as image knowledge, text knowledge, and basic common sense, into visual language question answering models, significantly enhancing their interpretability. However, introducing knowledge into these models often involves retrieval and pre-training methods, which can introduce noise due to the local correlation among knowledge sources and the existence of modality gaps, thereby affecting the model's performance. To mitigate this issue, this paper proposes a multimodal knowledge extraction approach based on distributed representation learning. The approach models inexpressible multimodal facts using explicit triples, considering the semantic gap between visual and textual modalities. Cross-modal representations are obtained through an attention mechanism, resulting in knowledge triplets comprising visual features, cross-modal representations, and text features. By incorporating these knowledge triplets into the visual language question answering model, the task is transformed into pattern matching using knowledge triples. The proposed approach comprehensively considers multiple factors, is not restricted to specific forms of knowledge, and can effectively incorporate a substantial amount of knowledge. Experimental results demonstrate its superiority, with a performance improvement of 0.5% on the OKVQA dataset compared to the baseline model, highlighting its strong generalization ability.},
  keywords={Representation learning;Visualization;Knowledge based systems;Semantics;Transforms;Knowledge graphs;Feature extraction;component;Knowledge Graph;Knowledge-based Visual Question Answering;Represention Learning},
  doi={10.1109/EEI59236.2023.10212829},
  ISSN={},
  month={June},}@INPROCEEDINGS{10687974,
  author={Cao, Han and Wei, Lingwei and Zhou, Wei and Hu, Songlin},
  booktitle={2024 IEEE International Conference on Multimedia and Expo (ICME)}, 
  title={Multi-source Knowledge Enhanced Graph Attention Networks for Multimodal Fact Verification}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Multimodal fact verification is an under-explored and emerging field that has gained increasing attention in recent years. The goal is to assess the veracity of claims that involve multiple modalities by analyzing the retrieved evidence. The main challenge in this area is to effectively fuse features from different modalities to learn meaningful multimodal representations. To this end, we propose a novel model named Multi-Source Knowledge-enhanced Graph Attention Network (MultiKE-GAT). MultiKE-GAT introduces external multimodal knowledge from different sources and constructs a heterogeneous graph to capture complex cross-modal and cross-source interactions. We exploit a Knowledge-aware Graph Fusion (KGF) module to learn knowledge-enhanced representations for each claim and evidence and eliminate inconsistencies and noises introduced by redundant entities. Experiments on two public benchmark datasets demonstrate that our model outperforms other comparison methods, showing the effectiveness and superiority of the proposed model.},
  keywords={Knowledge engineering;Fuses;Noise;Benchmark testing;Feature extraction;multimodal fact verification;multi-source knowledge;graph attention network},
  doi={10.1109/ICME57554.2024.10687974},
  ISSN={1945-788X},
  month={July},}@INPROCEEDINGS{10435553,
  author={Wang, Hongchang and Ma, Qingxin},
  booktitle={2023 3rd International Conference on Electronic Information Engineering and Computer Science (EIECS)}, 
  title={Domain Knowledge Enhanced BERT for Chinese Named Entity Recognition}, 
  year={2023},
  volume={},
  number={},
  pages={406-409},
  abstract={Digitalization of educational resources and revolutionizing knowledge frameworks are essential in achieving smart education. Knowledge graphs play a pivotal role in addressing knowledge representation, correlation, and sharing within digital education. Named Entity Recognition (NER) is a fundamental task in constructing knowledge graphs. This study introduces a Domain Knowledge-Enhanced BERT Chinese NER model, DK-BERT-CRF (Domain Knowledge BERT CRF), to address the deficiency of lexical information features within the Chinese NER task using the BERT pre-trained model. To construct an automated labeling dataset, we perform an automated labeling dataset construction based on ChatGPT, focusing on the example of computer science's data structures. We conduct experiments and evaluations using this dataset and the general CLUENER2020 dataset. Comparative experiments with BERT+CRF and BiLSTM+CRF are also conducted. The experimental results demonstrate that the DK-BERT-CRF model, enriched with domain knowledge, exhibits an improved F1 score compared to the other two models. Particularly, the DK-BERT-CRF model showcases enhanced F1 scores on the computer science data structure dataset after the incorporation of domain knowledge.},
  keywords={Computer science;Annotations;Computational modeling;Knowledge graphs;Data structures;Labeling;Task analysis;Smart Education;Knowledge Graph;Named Entity Recognition;BERT;ChatGPT},
  doi={10.1109/EIECS59936.2023.10435553},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10551258,
  author={Fang, Yunfei and Chen, Yong and Jiang, Zhonglin and Xiao, Jun and Ge, Yanli},
  booktitle={2023 4th International Conference on Computer, Big Data and Artificial Intelligence (ICCBD+AI)}, 
  title={Automatic Knowledge Structuration of Automotive User Manual for Question Answering}, 
  year={2023},
  volume={},
  number={},
  pages={184-190},
  abstract={Automotive user manuals serve as repositories of valuable information pertaining to a vehicle, leveraging question answering (QA) systems provides users with a convenient means to access this knowledge. In pursuit of developing an efficient QA system for such documents, this paper proposes the organization of the content into a structured knowledge graph-like triplet format.After conducting a comprehensive analysis of the automotive user manual content, we introduce a <subject, function, content> (<s, f, c>) triplet knowledge representation to represent the knowledge. Our approach involves a three-step pipeline for extracting these triplets from semi-structured XML documents. Central to this structure is the "content" node, forming the core of knowledge items. Leveraging the in-context learning abilities of an off-the-shelf Large Language Model (LLM), specifically ChatGPT, the "subject" and "function" components are induced from the "content" node. To ensure compactness and coherence in knowledge representation, a tailored phrase normalization process is designed to select identical phrases.Additionally, a LLM-powered evaluation method is employed to validate the extracted triplets, affirming their accuracy and relevance. This methodology demonstrates the effectiveness of our proposed approach in automating the structuration of knowledge within automotive user manuals for seamless QA.},
  keywords={Pipelines;XML;Manuals;Knowledge representation;Organizations;Question answering (information retrieval);Data models;large language models;question answering;knowledge graph construction;information extraction},
  doi={10.1109/ICCBD-AI62252.2023.00038},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10030076,
  author={Li, Zhiyuan and Jin, Zhou and Wang, Rujing and Ji, Jie and Liu, Haiyan},
  booktitle={2022 IEEE International Conference on Knowledge Graph (ICKG)}, 
  title={A Generative Adversarial Net Assisted Method for User Intention Recognition on Imbalanced Dataset}, 
  year={2022},
  volume={},
  number={},
  pages={157-163},
  abstract={Class imbalance is a classic problem in machine learning and deep learning. This problem bothers recognizing user intention in knowledge graph question answering domain. Some intentions would not be recognized well when the training set is unbalanced. Sampling and weighted loss methods are widely used to address it. However, these methods pay little attention to the form of question texts in feature space. We propose a novel method based on generative adversarial net to deal with imbalanced class problem, which firstly learns how a user question text of a certain class is represented in feature space and then generates samples. Our method designs a model that contains three parts: text encoder, generator, and discriminator. The text encoder transforms user question text into words vectors. The generator generates vectors that would converge to expected classes and the discriminator is responsible for recognizing classes. We split the training period into two stages. In the first stage, the discriminator is going to distinguish between samples from encoder and generator. In the second stage, the generator learns data distribution and generates related samples to enhance the ability of encoder. Experimental results show that our method can balance the model performance on each class and significantly outperforms traditional methods on unbalanced datasets for user intention recognition.},
  keywords={Training;Deep learning;Fluctuations;Design methodology;Transforms;Generators;Robustness;user intention recognition;imbalanced dataset;generative adversarial net;generating samples;two-stage training},
  doi={10.1109/ICKG55886.2022.00027},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10412757,
  author={Zhang, Bofeng and Yao, Xiuhong and Li, Haiyan and Aini, Mirensha},
  booktitle={2023 IEEE International Conference on Knowledge Graph (ICKG)}, 
  title={Chinese Medical Named Entity Recognition based on Expert Knowledge and Fine-tuning Bert}, 
  year={2023},
  volume={},
  number={},
  pages={84-90},
  abstract={Medical Named Entity Recognition (MNER) plays a pivotal role in Natural Language Processing (NLP), particularly within the medical domain. This research presents an innovative methodology for MNER, adeptly tackling the challenges presented by the diversity of terminologies, privacy issues, and the significant costs associated with annotation in Chinese medical records. In this study, we begin by assembling a meticulously curated medical terminology database, drawing upon the expertise of domain specialists. This comprehensive database enhances the precision in comprehending medical semantic structures, enabling more accurate recognition of named entities in medical texts. To further improve the performance of MNER, we leverage the power of the pre-trained Bidirectional Encoder Representations from Transformers (BERT) language model. By fine-tuning BERT on Chinese medical diagnostic and treatment texts, we achieve proficient recognition and categorization of entities, along with their respective types. Through rigorous experimentation on a large-scale, real-world Chinese medical record datasets, we showcase the superior performance of our proposed framework. Our comprehensive and novel approach is instrumental in accurately extracting named entities from medical texts, thereby enhancing clinical decision support, organizing medical knowledge, facilitating drug discovery, and contributing to a broad spectrum of other medical applications. The results of this study demonstrate the effectiveness and potential impact of our methodology in the field of medical named entity recognition. By addressing the challenges specific to Chinese medical records, we provide valuable insights and advancements that can benefit various healthcare applications and ultimately improve patient care. This research holds significant value and relevance in the field.},
  keywords={Terminology;Annotations;Databases;Text recognition;Semantics;Natural language processing;Medical diagnostic imaging;Medical Named Entity Recognition;Bert;Expert Knowledge;Fine-tuning},
  doi={10.1109/ICKG59574.2023.00016},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{9194511,
  author={Peng, Yuwei and Jiang, Huan and Li, Rongrong and Peng, Zhiyong},
  booktitle={2020 IEEE International Conference on Knowledge Graph (ICKG)}, 
  title={PZXG: A Genealogy Data Service Platform for Kinship Management and Application}, 
  year={2020},
  volume={},
  number={},
  pages={505-512},
  abstract={Genealogy is one of the three kinds of historical literatures which are valuable to historical research and humanities research. However, traditionally, it is hard to build and revise a genealogy. And it is even impossible to manage and query the genealogy efficiently. In this paper, we proposed PZXG, which is a genealogy data service platform, to solve these issues. Firstly, for structured and unstructured genealogy data, we employ relational database, graph database and distributed file system to store them respectively. Secondly, depending on the hybrid data model of genealogy data, various management features like data acquisition, kin seeking, genealogy exhibition and automatic typesetting are provided. Then in order to extract knowledge from genealogy data, the features of routine statistics and query, root tracing, correlation analysis and data visualization in genealogical data are discussed, and several methods and ideas of text mining for genealogical text are given. Finally, two more urgent research points in the genealogical data management platform are suggested: extracting structural information from unstructured genealogy data and construction of genealogy-specific text language model.},
  keywords={Data models;Biographies;Data acquisition;Optical character recognition software;Data mining;Typesetting;Computer architecture;Genealogy Data;Service Platform;Kinship;Management},
  doi={10.1109/ICBK50248.2020.00077},
  ISSN={},
  month={Aug},}@ARTICLE{10428937,
  author={Wu, Kan and Zhou, Yonglin and Ma, Jun and Guo, Xianhui},
  journal={IEEE Access}, 
  title={Topic-Specific Political Stance Inference in Social Networks With Case Studies}, 
  year={2024},
  volume={12},
  number={},
  pages={21921-21935},
  abstract={Topic-specific political stance inference in social networks (SNs) aims at inferring target users’ attitudes toward different target topics. Traditional methods mainly used a language model to classify sentiments from the postings of the SN users. However, people’s stances are not always equal to their sentiments. Some others tried to build separate models toward different target topics. In many cases, though SN users talked about the target topics, the information given was limited; or they only expressed attitudes toward some other issues except the target topics. When information is incomplete, the methods that treat the topics independently fail to work, let alone for users who didn’t post any of the topics. To solve the above problems, we introduced a political knowledge graph (PKG) to supplement side information for users and topics and proposed a united Knowledge Graph-aware and Social Network-enhanced framework (KGSN) to capture not only the knowledge connections between topics but also the social connections between users. KGSN utilized two levels of graph convolutional networks, the one at the knowledge graph level generating knowledge-aware representations merging knowledge entities for the users and topics respectively, and the one at the social graph level generating social-enhanced representations merging social neighbors for the target users. Beyond that, the respective topic-specific attention mechanisms were leveraged to emphasize special knowledge entities in the knowledge graph and special neighboring users in the social graph. The advantages of KGSN are that: first, it can infer users’ attitudes toward more than one topic in one model; second, it can infer users’ implicit attitudes toward the target topics through users’ explicit attitudes toward the other issues; last but not least, even for users without any postings, KGSN can infer users’ implicit attitudes through their social neighbors. Finally, extensive experiments were conducted to demonstrate the superiority of KGSN over state-of-the-art models and case studies were investigated to testify the effectiveness of the model.},
  keywords={Social networking (online);Knowledge graphs;Blogs;Knowledge engineering;Training;Solid modeling;Knowledge based systems;Graph neural networks;Government;Graph neural networks;knowledge graph;political stance inference;social networks},
  doi={10.1109/ACCESS.2024.3360487},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{9736481,
  author={Lim, Chae-Gyun and Lee, Dongkun and Lee, Young-Jun and Choi, Ho-Jin},
  booktitle={2022 IEEE International Conference on Big Data and Smart Computing (BigComp)}, 
  title={Knowledge Management Approach for Memory Components Based on User-friendly Conversational System}, 
  year={2022},
  volume={},
  number={},
  pages={401-403},
  abstract={Due to the recent technological development and the growth of computing resources, there are various studies that apply large-scale language models in the field of natural language processing such as conversational systems. Also, there are researches that attempt to maintain a conversation flow and naturally lead a dialogue by treating the contextual information exchanged with users from the perspective of knowledge. In this paper, we propose a method for managing various contextual information such as chat history, situations, and preferred topics based on a knowledge base and generating a conversation customized for the specific user. We design a schema of memory components to deal with the user's contextual information so that implement a Web-based conversational system, which is friendly come to those users. It is expected that these systems using the user-specific memory components will be helpful in such domains like education or customer consultation.},
  keywords={Conferences;Computational modeling;Memory management;Knowledge based systems;Education;Lead;Big Data;memory component;ontology-based approach;conversation history;conversational system},
  doi={10.1109/BigComp54360.2022.00091},
  ISSN={2375-9356},
  month={Jan},}@INPROCEEDINGS{9673037,
  author={Amini, M. Mohammad and Aldanondo, M. and Vareilles, E. and Coudert, T.},
  booktitle={2021 IEEE International Conference on Industrial Engineering and Engineering Management (IEEM)}, 
  title={Twenty Years of Configuration Knowledge Modeling Research. Main Works, What To Do Next?}, 
  year={2021},
  volume={},
  number={},
  pages={1328-1332},
  abstract={A configuration software (configurator) associates a knowledge base (KB) with a knowledge processing unit (PU). The KB describes all possible combinations of components while the PU overlays this knowledge with the customer requirements. Our work deals with the KB and the approaches, models, or tools for modeling configuration knowledge. Our goal is to present a small quantitative literature survey highlighting two work streams: the first one gathers modeling works dealing with constraint-based approaches while the second deals with ontologies, description logic, or object-oriented modeling approach. We will also consider hybrid approaches. We will present a quantitative analysis of published materials in Web of science over the last twenty years. The keywords occurrence versus time will also be studied in detail to identify tendencies in configuration knowledge modeling.},
  keywords={Knowledge engineering;Statistical analysis;Object oriented modeling;Engineering management;Knowledge based systems;Ontologies;Maintenance engineering;Configuration knowledge modeling;constraints satisfaction problem;ontology;UML;OWL;rules},
  doi={10.1109/IEEM50564.2021.9673037},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10471842,
  author={Do, Nhon V. and Mai, Thanh T.},
  booktitle={2023 RIVF International Conference on Computing and Communication Technologies (RIVF)}, 
  title={A Knowledge Representation Model for Designing the Knowledge Querying System in Programming Language C/C++}, 
  year={2023},
  volume={},
  number={},
  pages={366-371},
  abstract={Knowledge querying support systems need to assist users in querying the knowledge, relationships, or combination of multiple requirements. A proper knowledge representation model and the well-structured query language play important roles in the developing the knowledge querying systems. There are knowledge representation models and systems that support the querying or searching on the knowledge-based, but they have not supported well for various query requirements on the knowledge. Specially, the structured query sentences combine the multiple requirements. The paper will propose a knowledge representation model for the programming language C/C++ knowledge domain. Moreover, the paper will present structured query sentences that meet various requirements from users. Especially, the combination of multiple requirements based on the operators AND, OR, and NOT. Results of the research will be applied to design the knowledge querying system in the programming language C/C++ knowledge domain. The system is useful for first and second-year students in the field of technology information.},
  keywords={Computational modeling;Knowledge based systems;Knowledge representation;Communications technology;Database languages;ontology;structured query sentences;knowledge representation;knowledge querying system;programming language},
  doi={10.1109/RIVF60135.2023.10471842},
  ISSN={2473-0130},
  month={Dec},}@INPROCEEDINGS{10784366,
  author={Fang, Yunfei and Chen, Yong and Jiang, Zhonglin and Xiao, Jun and Ge, Yanli},
  booktitle={2024 IEEE International Conference on e-Business Engineering (ICEBE)}, 
  title={Effective and Reliable Domain-Specific Knowledge Question Answering}, 
  year={2024},
  volume={},
  number={},
  pages={238-243},
  abstract={Large language models (LLMs) serve as powerful knowledge bases, capable of embedding knowledge from text into model parameters. However, the widespread issue of hallucination and opaque black-box processes restrict their broader application in professional sectors that place high demands on safety and predictability. Conversely, knowledge graphs provide inherent superiority in the authenticity and interpretability in question answering sessions. However, building a knowledge graph in specialized fields and conduct question answering over the knowledge graph are both nontrivial problems. This paper introduces an efficient knowledge graph question answering (KGQA) approach tailored to customized domain-specific knowledge graphs. Our “extract-then-bind” KGQA method leverages the in-context learning capabilities of the LLM to extract mention and relation proposals from the query, which are then matched with nodes and edges in the knowledge graph. Experimental results demonstrate the effectiveness of our approach in a question answering task using automotive user manuals. Notably, the knowledge graph was created through an automated process. By combining this innovative KGQA technique with its corresponding knowledge graph construction method, this paper proposes an effective and reliable system for addressing domain-specific knowledge question answering. This integrated solution guarantees authenticity and traceability in question answering while significantly reducing the need for manual labour.},
  keywords={Training;Large language models;Knowledge based systems;Knowledge graphs;Manuals;Question answering (information retrieval);Safety;Reliability;Proposals;Automotive engineering;Large language models;knowledge graph;question answering;domain-specific},
  doi={10.1109/ICEBE62490.2024.00044},
  ISSN={2472-8527},
  month={Oct},}@INPROCEEDINGS{10391425,
  author={Sharma, Hemendra Shanker and Sharma, Ashish},
  booktitle={2023 Second International Conference On Smart Technologies For Smart Nation (SmartTechCon)}, 
  title={Query Expansion Using Word Embedding, Ontology and Natural Language Processing}, 
  year={2023},
  volume={},
  number={},
  pages={410-414},
  abstract={Query Expansion (QE) is the art of reconstructing specific queries to expand validation presentation, especially in the data mining process in a requirement understanding environment. Expanding requirements is one of the techniques involved in finding information. In the search engine environment, the query extension includes the evaluation of the value of the construction and the extension of search queries to match new documents. In natural language processing (NLP), word embedding is a term used in textbook parsing, usually as a real-valued vector that encodes the meaning of adjacent words in the vector. It is assumed that the space will be analogous in meaning. Word embedding can be achieved using a set of language models and point literacy methods where vocabulary words or expressions are mapped to vectors of real numbers. For query expansion, one method used is natural language processing through word embedding. Other approaches are ontology, machine learning, and deep learning for automatic query expansion. This paper proposes a hybrid approach for query expansion by combining NLP and ontology through word embedding.},
  keywords={Deep learning;Vocabulary;Art;Ontologies;Search engines;Natural language processing;Data mining;Query expansion;word embedding;natural language processing;Data mining;information retrieval},
  doi={10.1109/SmartTechCon57526.2023.10391425},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10802273,
  author={Nakajima, Haru and Miura, Jun},
  booktitle={2024 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, 
  title={Combining Ontological Knowledge and Large Language Model for User-Friendly Service Robots}, 
  year={2024},
  volume={},
  number={},
  pages={4755-4762},
  abstract={Lifestyle support through robotics is an increasingly promising field, with expectations for robots to take over or assist with chores like floor cleaning, table setting and clearing, and fetching items. The growth of AI, particularly foundation models, such as large language models (LLMs) and visual language models (VLMs), is significantly shaping this sector. LLMs, by facilitating natural interactions and providing vast general knowledge, are proving invaluable for robotic tasks. This paper focuses on the benefits of LLMs for "bring-me" tasks, where robots fetch specific items for users, often based on ambiguous instructions. Our previous efforts utilized an ontology extended to handle environmental data to resolve such ambiguities, but faced limitations when unresolvable ambiguities required user intervention for clarity. Here, we enhance our approach by integrating LLMs for providing additional commonsense knowledge, pairing it with ontological data to mitigate the issue of hallucinations and reduce the need for user queries, thus improving system usability. We present a system that merges these knowledge bases and assess its efficacy on "bring-me" tasks, aiming to provide a more seamless and efficient robotic assistance experience.},
  keywords={Visualization;Service robots;Foundation models;Large language models;Knowledge based systems;Ontologies;Usability;Intelligent robots;Floors;Commonsense reasoning},
  doi={10.1109/IROS58592.2024.10802273},
  ISSN={2153-0866},
  month={Oct},}@INPROCEEDINGS{9412877,
  author={Tang, Xunzhu and Sun, Tiezhu and Zhu, Rujie and Wang, Shi},
  booktitle={2020 25th International Conference on Pattern Recognition (ICPR)}, 
  title={CKG: Dynamic Representation Based on Context and Knowledge Graph}, 
  year={2021},
  volume={},
  number={},
  pages={2889-2895},
  abstract={Recently, neural language representation models pre-trained on large corpus can capture rich co-occurrence information and be fine-tuned in downstream tasks to improve the performance. As a result, they have achieved state-of-the-art results in a large range of language tasks. However, there exists other valuable semantic information such as similar, opposite, or other possible meanings in external knowledge graphs (KGs). We argue that entities in KGs could be used to enhance the correct semantic meaning of language sentences. In this paper, we propose a new method CKG: Dynamic Representation Based on Context and Knowledge Graph. On the one side, CKG can extract rich semantic information of large corpus. On the other side, it can make full use of inside information such as co-occurrence in large corpus and outside information such as similar entities in KGs. We conduct extensive experiments on a wide range of tasks, including QQP, MRPC, SST-5, SQuAD, CoNLL 2003, and SNLI. The experiment results show that CKG achieves SOTA 89.2 on SQuAD compared with SAN (84.4), ELMo (85.8), and BERTBase (88.5).},
  keywords={Semantics;Data mining;Task analysis;Context modeling},
  doi={10.1109/ICPR48806.2021.9412877},
  ISSN={1051-4651},
  month={Jan},}@INPROCEEDINGS{8473447,
  author={Zhu, Minchen and Ye, Xinshu and Xiang, Tao and Ma, Yun and Chen, Xing},
  booktitle={2018 IEEE International Congress on Internet of Things (ICIOT)}, 
  title={Runtime Knowledge Graph Based Approach to Smart Home Application Development}, 
  year={2018},
  volume={},
  number={},
  pages={110-117},
  abstract={Smart home is an important application area of the Internet of things (IoT). However, the diversification of smart home application scenarios increases the difficulty of understanding the scenarios for developers. And the heterogeneity of the programming interfaces of smart devices as well as the close coupling of the code to the underlying systems is still an important work for the developers. Furthermore, the complexity and variability of business requirements poses a great challenge to the development of applications logic. In this paper, we present a runtime knowledge graph based approach to smart home application development. First, a conceptual model describing the smart home scenarios is defined. Second, the manageability of smart devices is abstracted as runtime knowledge graphs that are automatically connected with the corresponding systems. Last, a method of automatically generating smart home applications is proposed. Our approach can reduce code by about 85 percent at least, and an experiment on a real-world application scenario demonstrates the feasibility, effectiveness, and benefits of the new approach to smart home application development.},
  keywords={Smart homes;Runtime;Smart devices;Programming;Internet of Things;Data models;Software;Internet of things;models at runtime;software architecture},
  doi={10.1109/ICIOT.2018.00022},
  ISSN={},
  month={July},}@INPROCEEDINGS{10004260,
  author={Lin, Gongqi and Zhong, Xiuqin and Fu, Hongguang},
  booktitle={2022 17th International Conference on Control, Automation, Robotics and Vision (ICARCV)}, 
  title={MathCLM: Mathematical Cognitive Learning Model Based on the Evolution of Knowledge Graph}, 
  year={2022},
  volume={},
  number={},
  pages={616-622},
  abstract={In real-world applications, the effective integration of learning and reasoning in a cognitive agent model is a challenging mission. However, such integration may lead to a better understanding, practice, and construction of more realistic models, especially for mathematical learning. Unfortunately, existing models are either oversimplified or require much processing time, which is unsuitable for online learning and education. Therefore, we propose a novel cognitive learning model, called Mathematical Cognitive Learning Model (MathCLM) based on the evolution of knowledge graph, for online mathematical learning that seeks to effectively represent, learn, and reason in online learning environments. The model's architecture combines cognitive learning with symbolic knowledge representation based on natural language processing (NLP). We introduce the mathematical instance concept to build the strategies by mathematical knowledge, such as theorems, axioms, etc., and infer new custom instances based on the learning knowledge. Furthermore, it can deal with uncertainty and errors from instances recommendation using a graph matching model and displays the inference progressing with different combinations of instances. We build a platform to promote and validate our model. The validation of the model on the real-world platform and the results presented here indicate the promise of the approach when performing online learning and reasoning in real-world scenarios, with possible applications in various areas.},
  keywords={Visualization;Uncertainty;Automation;Education;Knowledge representation;Mathematical models;Natural language processing},
  doi={10.1109/ICARCV57592.2022.10004260},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10350156,
  author={Zheng, Yao and Cen, Jianhe and Sun, Shiqi and Yin, Dahu and Li, Jingyuan and Wang, Yuanzhuo},
  booktitle={2023 IEEE/WIC International Conference on Web Intelligence and Intelligent Agent Technology (WI-IAT)}, 
  title={MKGS: Maintains the Original Structure of Knowledge Graph}, 
  year={2023},
  volume={},
  number={},
  pages={449-456},
  abstract={In the field of graph-generated text, one of the core issues commonly explored is how to maintain the structural information of the graph to the maximum extent and reduce the problem of knowledge loss during training. Current research has mainly focused on exploring the ability of models to learn graph structures by increasing model size and refining the graph representation. In contrast, our work emphasizes the importance of perceiving and exploring edges in the graph itself. Edges provide a wide variety of structures to the graph structure, offering it freedom and diversity. Therefore, improving the model's ability to perceive edges could potentially enhance the task metrics of graph generation for text. To address this, we propose a graph-generated text model MKGS that maintains the original structure of the knowledge graph, effectively reducing knowledge loss during the learning process. Our approach achieves this at three levels: reorganizing the knowledge sequence as input to the model, enhancing edge perception during processing, and incorporating a graph rational activation function at the output. We validate our method using the Kg-to-text benchmark dataset WebNLG, where MKGS achieves a score of 66.22%. Additionally, the model exhibits fewer syntactic errors and produces smoother expressions in the generated text.},
  keywords={Training;Measurement;Computational modeling;Refining;Knowledge graphs;Syntactics;Benchmark testing;Graph-generated Text;Knowledge Representation;Knowledge Graphs;Graph Theory;Edge-aware Attention},
  doi={10.1109/WI-IAT59888.2023.00074},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10386182,
  author={Kosten, Catherine and Cudré-Mauroux, Philippe and Stockinger, Kurt},
  booktitle={2023 IEEE International Conference on Big Data (BigData)}, 
  title={Spider4SPARQL: A Complex Benchmark for Evaluating Knowledge Graph Question Answering Systems}, 
  year={2023},
  volume={},
  number={},
  pages={5272-5281},
  abstract={With the recent spike in the number and availability of Large Language Models (LLMs), it has become increasingly important to provide large and realistic benchmarks for evaluating Knowledge Graph Question Answering (KGQA) systems. So far the majority of benchmarks rely on pattern-based SPARQL query generation approaches. The subsequent natural language (NL) question generation is conducted through crowdsourcing or other automated methods, such as rule-based paraphrasing or NL question templates. Although some of these datasets are of considerable size, their pitfall lies in their pattern-based generation approaches, which do not always generalize well to the vague and linguistically diverse questions asked by humans in real-world contexts. In this paper, we introduce Spider4SPARQL -a new SPARQL benchmark dataset featuring 9,693 previously existing manually generated NL questions and 4,721 unique, novel, and complex SPARQL queries of varying complexity. In addition to the NL/SPARQL pairs, we also provide their corresponding 166 knowledge graphs and ontologies, which cover 138 different domains. Our complex benchmark enables novel ways of evaluating the strengths and weaknesses of modern KGQA systems. We evaluate the system with state-of-the-art KGQA systems as well as LLMs, which achieve only up to 45% execution accuracy, demonstrating that Spider4SPARQL is a challenging benchmark for future research.},
  keywords={Measurement;Crowdsourcing;Natural languages;Knowledge graphs;Benchmark testing;Ontologies;Question answering (information retrieval);Benchmark for Question Answering over Knowledge Graphs;Language Models;Performance Evaluation},
  doi={10.1109/BigData59044.2023.10386182},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10822556,
  author={Qi, Jiewei and Luo, Ling and Yang, Zhihao and Wang, Jian and Zhou, Huiwei and Lin, Hongfei},
  booktitle={2024 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)}, 
  title={An Improved Method for Phenotype Concept Recognition Using Rich HPO Information}, 
  year={2024},
  volume={},
  number={},
  pages={1135-1140},
  abstract={Automatically identifying human phenotype ontology (HPO) concepts from text is important for disease analysis. Existing ontology-driven methods for phenotype concept recognition mainly rely on concept names and synonym information from the ontology, without fully exploiting the rich ontology information. In this paper, we present an improved phenotype concept recognition method by incorporating rich HPO information. We first design prompts with HPO information and use a cutting-edge large language model GPT-4 to generate synonym augmentation for expanding distant supervised training data. We then propose an ontology vector-enhanced phenotype concept classification model to efficiently integrate the taxonomic hierarchical structure of HPO. Additionally, we employ noisy data augmentation to improve the model’s recognition ability in noisy texts and implement a negation detection function. Experimental results on three standard corpora and two typo corpora show our method compares favorably to previous methods and achieves a significant improvement in noisy texts. The source code and data are freely available at https://github.com/DUTIR-BioNLP/PhenoTagger-Updates.},
  keywords={Phenotypes;Source coding;Large language models;Training data;Ontologies;Data augmentation;Noise measurement;Reliability;Standards;Diseases;Phenotype Concept Recognition;Human Phenotype Ontology;Ontology Information Enhancement},
  doi={10.1109/BIBM62325.2024.10822556},
  ISSN={2156-1133},
  month={Dec},}@INPROCEEDINGS{10521188,
  author={Timperley, Louis and Berthoud, Lucy and Snider, Chris and Tryfonas, Theo},
  booktitle={2024 IEEE Aerospace Conference}, 
  title={Mapping the MBSE Environment and Complementary Design Space Exploration Techniques}, 
  year={2024},
  volume={},
  number={},
  pages={1-20},
  abstract={Today’s MBSE tools and environments are highly varied and therefore present a challenge for organizations looking to implement MBSE. Furthermore, while MBSE environments are highly capable of supporting the description of design baselines, the current capabilities within these environments could be further refined for exploring alternative designs. As a result it is important to gain an understanding of the limitations of current MBSE tooling in performing the valuable activity of design space exploration, and identify a set of candidate techniques to combat these. This paper reviews the various options available to MBSE practitioners by comparing some of the most common MBSE languages, tools and methods. The possible issues that can be encountered when exploring different designs have been identified and assigned a severity rating. A set of design space exploration techniques are presented, and where possible these have been sourced from existing literature. A knowledge graph has been constructed to collect all this data into a structured format, containing all the MBSE languages, tools, methods, design space exploration-related issues and techniques, as well as the relationships between each of these. This knowledge graph, implemented as a Neo4j graph database, allowed deeper insights to be drawn from the collected information. By defining a selected MBSE environment, including language, tool and method, the knowledge graph could be used to identify the least troublesome sequence (with minimum number of related issues) to arrive at a desired design artifact, for example a set of optimized system parameters. Beside this, the knowledge graph could be used to display the relationships and clusters of MBSE languages, tools and methods, to assist organizations with selecting suitable MBSE environment elements. Future work will bring greater depth to the analysis available with the knowledge graph, for instance, differentiation between different types of design space exploration issues and techniques.},
  keywords={Codes;Reviews;Databases;Design methodology;Knowledge based systems;Knowledge graphs;Organizations},
  doi={10.1109/AERO58975.2024.10521188},
  ISSN={1095-323X},
  month={March},}@INPROCEEDINGS{9194518,
  author={Zhang, Jingzhuo and Liu, Weijie and Wang, Ping},
  booktitle={2020 IEEE International Conference on Knowledge Graph (ICKG)}, 
  title={Drug Drug Interaction Extraction from Chinese Biomedical Literature Using Distant Supervision}, 
  year={2020},
  volume={},
  number={},
  pages={593-598},
  abstract={The field of pharmacovigilance has attracted widespread attention due to the increasing impact of drug safety incidents. In this paper, we try to extract Drug Drug Interactions (DDIs) from Chinese biomedical literature. In addition, we used a variety of biomedical resources to develop the first Chinese DDIs database with the help of expert annotations. Based on this database, we applied distant supervision method to extract DDIs from 11,319 biomedical sentences. In order to classify the relationship instances, we extract feature based on the Bidirectional Encoder Representation from Transformers (BERT) model, combine the attention mechanism to select effective instances, and provide drug descriptions to supplement background knowledge. At last. Our method achieves an F-score of 0.732, which is better than the traditional method. Furthermore, we analyze the false negatives in our results.},
  keywords={5G mobile communication;Conferences;distant supervision;drug drug interaction;relation extraction;attention mechanism},
  doi={10.1109/ICBK50248.2020.00089},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10412786,
  author={Guo, Dongsheng and Yue, Aizhen and Ning, Fanggang and Huang, Dengrong and Chang, Bingxin and Duan, Qiang and Zhang, Lianchao and Chen, Zhaoliang and Zhang, Zheng and Zhan, Enhao and Zhang, Qilai and Jiang, Kai and Li, Rui and Zhao, Shaoxiang and Wei, Zizhong},
  booktitle={2023 IEEE International Conference on Knowledge Graph (ICKG)}, 
  title={A Study Case of Automatic Archival Research and Compilation using Large Language Models}, 
  year={2023},
  volume={},
  number={},
  pages={52-59},
  abstract={Archival research and compilation is a specialized task that focuses on exploration, selection and processing of vast quantities of archival documents pertaining to specific subjects. Traditionally, this task has been characterized by its labor-intensive and time-consuming requirements. In recent years, the advancement of artificial intelligence has made automatic archival research and compilation tasks feasible. However, the limited availability of relevant samples imposes significant constraints on the application of deep learning models, given their high demand for sufficient data and knowledge. In this paper, we present a study case and propose an innovative method for automatic archival research and compilation, leveraging the robust knowledge base and text generation ability offered by large language models. Specifically, our method comprises three essential components: document retrieval, document summarization, and rule-based compilation. In the document summarization component, we leverage fine-tuned large language models to enhance the performance by simulation data generation and summary generation. Experimental results substantiate the effectiveness of our method. Furthermore, our method provides a general idea in using large language models, as well as a solution for addressing similar challenges in different domains.},
  keywords={Deep learning;Knowledge based systems;Manuals;Knowledge graphs;Data models;Task analysis;Archival research and compilation;Automatic method;Large language models;Fine-tuning},
  doi={10.1109/ICKG59574.2023.00012},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10412842,
  author={Iqbal, Mohammad and Laili Udhiah, Rosita and Rana Nugraha, Tsamarah and Pao, Hsing-Kuo},
  booktitle={2023 IEEE International Conference on Knowledge Graph (ICKG)}, 
  title={ASAGeR: Automated Short Answer Grading Regressor via Sentence Simplification}, 
  year={2023},
  volume={},
  number={},
  pages={60-68},
  abstract={We propose an automated short answer grading system (ASAG) to estimate the student answer scores via text summarization from LLMs. The step of text summarization provides enough question answer normalization so that the summarized answers have the answer keys well organized and the grading based on that should be more accurate and easier than before, no matter the answers are graded by human or automatic graders. On the other hand, we also discuss the scenario when more than one grader are involved in the grading but providing inconsistent scores. We adopt a majority voting mechanism to overcome such difficulty and produce superior result in average. Overall the proposed methodology has its evaluation done to show the superiority to other state-of-the-art methods. The pre-trained transformer version 3.5 (GPT 3.5) is used to serve the text summarization tool given a well-designed prompt.},
  keywords={Performance evaluation;Computational modeling;Natural languages;Transformers;Question answering (information retrieval);Magnetic heads;Task analysis;Natural Language Processing;Answer Grading;Regression;Text Simplification},
  doi={10.1109/ICKG59574.2023.00013},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10480162,
  author={Hang, Ching Nam and Yu, Pei-Duo and Tan, Chee Wei},
  booktitle={2024 58th Annual Conference on Information Sciences and Systems (CISS)}, 
  title={TrumorGPT: Query Optimization and Semantic Reasoning over Networks for Automated Fact-Checking}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={In the age of social media, the rapid spread of misinformation and rumors has led to the emergence of infodemics, where false information poses a significant threat to society. To combat this issue, we introduce TrumorGPT, a novel generative artificial intelligence solution designed for automated fact-checking. TrumorGPT aims to distinguish "trumors", which are rumors that turn out to be true, providing a crucial tool in differentiating between mere speculation and verified facts. This framework merges machine learning with natural language processing techniques, leveraging a large language model (LLM) with few-shot learning for knowledge graph construction and semantic reasoning. TrumorGPT addresses the "hallucination" issue common in LLMs and the limitations of static training data by incorporating retrieval-augmented generation. This approach involves accessing and utilizing information from regularly updated knowledge graphs that consist of the latest news and information, ensuring that fact-checking of TrumorGPT is based on the most recent data. Accessing updated knowledge graphs greatly enhances the proficiency of TrumorGPT in delivering accurate and reliable information promptly. Evaluating with extensive datasets, TrumorGPT demonstrates superior performance in automated fact-checking. Its ability to effectively conduct automated fact-checking across various platforms marks a critical step forward in the fight against misinformation, enhancing trust and accuracy in the digital information age.},
  keywords={Social networking (online);Voting;Query processing;Semantics;Training data;Knowledge graphs;Cognition;Fact-checking;large language models;retrieval-augmented generation;semantic reasoning;knowledge graph},
  doi={10.1109/CISS59072.2024.10480162},
  ISSN={2837-178X},
  month={March},}@INPROCEEDINGS{10386615,
  author={Samel, Karan and Ma, Jun and Wang, Zhengyang and Zhao, Tong and Essa, Irfan},
  booktitle={2023 IEEE International Conference on Big Data (BigData)}, 
  title={Integrating Noisy Knowledge into Language Representations for E-Commerce Applications}, 
  year={2023},
  volume={},
  number={},
  pages={548-553},
  abstract={Integrating structured knowledge into language model representations increases recall of domain-specific information useful for downstream tasks. Matching between knowledge graph entities and text entity mentions can be easily performed when entity names are unique or there exists entity linking data. When extending this setting to new domains, newly mined knowledge contains ambiguous and incorrect information, with no explicit linking information. In such settings, we design a framework to robustly link relevant knowledge to input texts as an intermediate modeling step while performing end-to-end domain fine-tuning tasks. This is done by first computing the similarity of the existing task labels with candidate knowledge triplets to generate relevance labels. We use these labels to train a relevance model, which predicts the relevance of the inserted triplets to the original text. This relevance model is integrated within a language model, leading to our Knowledge Relevance BERT (KR-BERT) framework. We test KR-BERT for entity linking tasks on a real-world e-commerce dataset as well as a public linking task, where we show performance improvements over strong baselines.},
  keywords={Computational modeling;Design methodology;Knowledge graphs;Predictive models;Logic gates;Transformers;Noise measurement;noisy data;knowledge graphs;search;entity linking},
  doi={10.1109/BigData59044.2023.10386615},
  ISSN={},
  month={Dec},}@ARTICLE{9815253,
  author={Rony, Md Rashad Al Hasan and Kumar, Uttam and Teucher, Roman and Kovriguina, Liubov and Lehmann, Jens},
  journal={IEEE Access}, 
  title={SGPT: A Generative Approach for SPARQL Query Generation From Natural Language Questions}, 
  year={2022},
  volume={10},
  number={},
  pages={70712-70723},
  abstract={SPARQL query generation from natural language questions is complex because it requires an understanding of both the question and underlying knowledge graph (KG) patterns. Most SPARQL query generation approaches are template-based, tailored to a specific knowledge graph and require pipelines with multiple steps, including entity and relation linking. Template-based approaches are also difficult to adapt for new KGs and require manual efforts from domain experts to construct query templates. To overcome this hurdle, we propose a new approach, dubbed SGPT, that combines the benefits of end-to-end and modular systems and leverages recent advances in large-scale language models. Specifically, we devise a novel embedding technique that can encode linguistic features from the question which enables the system to learn complex question patterns. In addition, we propose training techniques that allow the system to implicitly employ the graph-specific information (i.e., entities and relations) into the language model’s parameters and generate SPARQL queries accurately. Finally, we introduce a strategy to adapt standard automatic metrics for evaluating SPARQL query generation. A comprehensive evaluation demonstrates the effectiveness of SGPT over state-of-the-art methods across several benchmark datasets.},
  keywords={Measurement;Linguistics;Syntactics;Resource description framework;Adaptation models;Standards;Training;Knowledge based systems;knowledge graph;information retrieval;query generation;language models},
  doi={10.1109/ACCESS.2022.3188714},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10191495,
  author={Zhang, Jingyi and Wei, Yuting and Zhu, Yangfu and Wu, Bin},
  booktitle={2023 International Joint Conference on Neural Networks (IJCNN)}, 
  title={Self-adaptive Prompt-tuning for Event Extraction in Ancient Chinese Literature}, 
  year={2023},
  volume={},
  number={},
  pages={1-8},
  abstract={Extracting different types of war events from ancient Chinese literature is significant, as war is an important factor in driving the development of Chinese history. The existing trend of event extraction models utilizes template-based generative approaches, which do not take into account the brevity and obscurity of ancient Chinese, as well as the diversity of templates for similar event types. In this paper, we propose a novel Knowledge Graph-based generative event extraction framework with a self-Adaptive Prompt (KGAP) for ancient Chinese war. Specifically, we construct a self-adaptive prompt, which considers its unique trigger words for different types of wars and is designed to solve the problem of the similarity in events. Moreover, we construct a semantic knowledge graph of ancient literature, assisting the pre-trained language model to better understand the ancient Chinese text. Since there is no public dataset for the ancient Chinese event extraction task, we provide an event extraction dataset and conduct experiments on it. Experimental results show that our model is more state-of-the-art than both the classification-based and generative-based methods for event extraction in ancient Chinese literature.},
  keywords={Semantics;Neural networks;Knowledge graphs;Market research;History;Task analysis;Ancient Chinese;Event Extraction;Self-adaptive Prompt;Knowledge Graph},
  doi={10.1109/IJCNN54540.2023.10191495},
  ISSN={2161-4407},
  month={June},}@INPROCEEDINGS{10224086,
  author={Jousselme, A-L. and de Villiers, J.P. and de Freitas, A. and Blasch, E. and Dragos, V. and Pavlin, G. and Costa, P. C. and Laskey, K. B. and Laudy, C.},
  booktitle={2023 26th International Conference on Information Fusion (FUSION)}, 
  title={Uncertain about ChatGPT: enabling the uncertainty evaluation of large language models}, 
  year={2023},
  volume={},
  number={},
  pages={1-8},
  abstract={ChatGPT, OpenAI’s chatbot, has gained consider-able attention since its launch in November 2022, owing to its ability to formulate articulated responses to text queries and comments relating to seemingly any conceivable subject. As impressive as the majority of interactions with ChatGPT are, this large language model has a number of acknowledged shortcomings, which in several cases, may be directly related to how ChatGPT handles uncertainty. The objective of this paper is to pave the way to formal analysis of ChatGPT uncertainty handling. To this end, the ability of the Uncertainty Representation and Reasoning Framework (URREF) ontology is assessed, to support such analysis. Elements of structured experiments for reproducible results are identified. The dataset built varies Information Criteria of Correctness, Non-specificity, Self-confidence, Relevance and Inconsistency, and the Source Criteria of Reliability, Competency and Type. ChatGPT’s answers are analyzed along Information Criteria of Correctness, Non-specificity and Self-confidence. Both generic and singular information are sequentially provided. The outcome of this preliminary study is twofold: Firstly, we validate that the experimental setup is efficient in capturing aspects of ChatGPT uncertainty handling. Secondly, we identify possible modifications to the URREF ontology that will be discussed and eventually implemented in URREF ontology Version 4.0 under development.},
  keywords={Uncertainty;Ontologies;Media;Chatbots;Cognition;Reliability;Disruptive technologies;Uncertainty evaluation;Ontology;Information quality;Source quality;Large Language Models;NLP},
  doi={10.23919/FUSION52260.2023.10224086},
  ISSN={},
  month={June},}@INPROCEEDINGS{10385346,
  author={Xie, Jing and Li, Xin and Yuan, Ye and Guan, Yi and Guo, Xitong and Lin, Yi},
  booktitle={2023 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)}, 
  title={Disease Diagnosis based on Multiple Semantic Relationship Prompt Subgraph}, 
  year={2023},
  volume={},
  number={},
  pages={3398-3405},
  abstract={Existing disease diagnosis models are often trained on clinical data such as electronic medical records (EMRs), which are lack of knowledge guidance. In this paper, we propose a new disease diagnosis model based on Multiple Semantic Relationship Prompt Subgraph (MSRPS), which can efficiently incorporate medical knowledge and utilize pretrained language models (PLMs) to achieve reasonable and accurate diagnosis results. Firstly, the MSRPS is extracted from the medical knowledge graph based on the patient’s personalized condition. Then graph encoder is used to generate a continuous prompt learning template based on graph neural network (GNN). Finally, a disease diagnosis model with prompt learning template under pre-trained and prompt paradigm is constructed to predict diagnosis results. Compared with the fine-tuning approach, this method needs fewer trainable parameters and less training data but achieve better performance. Experiments are conduct on two multi-label disease diagnosis datasets: ChineseEMR-50 and MIMIC-III-50. Results demonstrate that our model can be used in various pre-trained models and achieve the state-of-the-art results.},
  keywords={Semantics;MIMICs;Training data;Predictive models;Graph neural networks;Medical diagnosis;Task analysis;disease diagnosis;medical knowledge;pre-trained language model;promote learning;electronic medical record},
  doi={10.1109/BIBM58861.2023.10385346},
  ISSN={2156-1133},
  month={Dec},}@INPROCEEDINGS{10261615,
  author={Zeng, Ling and Liang, Zaoqing and Liang, Yun and Huang, Peijie},
  booktitle={2023 5th International Conference on Computer Science and Technologies in Education (CSTE)}, 
  title={Research on Key Technologies of Automated Instructional Design for Engineering Education Courses}, 
  year={2023},
  volume={},
  number={},
  pages={86-92},
  abstract={An Automated Instructional Design (AID) solution for engineering education courses instructional design is proposed in this research. By limiting the Domain of AID to engineering education courses, and limiting the course objectives to the graduate attributes and professional competence of engineering education programme, as well as limiting the instructional methods to task-and-activity-based methods, and applying the evaluation vocabulary regularly used in the field of engineering education, a complete set of instructional design vocabulary related to the instructional design domain can be abstracted. Using the Unified Modeling Language (UML) Profile mechanism, the complete set of instructional design vocabulary can be represented by a designed visual model language, which provide a complete instructional design description language, named Instructional Design Visual Model Language (IDVML), dedicated to the field of engineering education for AID tool implementation. Then the existed Model-Driven Architecture (MDA) tools can be applied to design IDVML-related Platform Independent Model (PIM) and various Platform Specific Model (PSM) meta-models, and the conversion templates from PIM to various PSM, as well as various conversion templates from PSM to executable code, database table, Web page, course Ontology, etc., so as to realize the conversion from IDVML to program code directly. Finally, using the Meta-model Object Facility (MOF), an independent AID can be implemented. This AID can help the teacher to design the teaching objectives, content, tasks and activities, evaluation of engineering education related courses which meet the requirements of engineering education accreditation. At the same time, the course Ontology can be generated to provide Ontology basis for the subsequent construction of individualized learning system.},
  keywords={Vocabulary;Visualization;Limiting;Unified modeling language;Computer architecture;Ontologies;Accreditation;automated instructional design;engineering education;instructional design visulized modleing language;instructional design meta-model},
  doi={10.1109/CSTE59648.2023.00022},
  ISSN={},
  month={April},}@INPROCEEDINGS{9905090,
  author={Pradeepani, M. K. T. and Jayawardena, C. and Rajapaksha, U. U. S.},
  booktitle={2022 International Research Conference on Smart Computing and Systems Engineering (SCSE)}, 
  title={Adding Commonsense to Robotic Application Using Ontology-Based Model Retraining}, 
  year={2022},
  volume={5},
  number={},
  pages={157-164},
  abstract={In terms of the level of technological capability in the world today, the use of automated robotics is common in various fields. There are large projects going on in many industries that collaborate between robots and other robots, as well as humans and robots. In hospital environments, care for people with medical needs and their needs and used to make appropriate suggestions to their problems. Robots can also be found in certain areas that can respond quickly as an emergency rescue agent. Furthermore, robots, which can be seen in the hotel industry as waiters and as farm assistants in agriculture, have a great tendency to be used as multi-tasking agents in many fields. In each of these areas, robots must co-operate with humans. In that situation, the importance of the exchange of mutual knowledge between robots-robots and between humans-robots comes into the picture. What matters here is not only the quantitative vastness of knowledge but also the ability to understand each other in the same medium. Although the common sense that people need in their day-to-day work is completely obvious to humans, the commonsense knowledge domain needs to be implanted in robots. Whatever concept is defined for adding commonsense to robotics, it should be a consistent concept that can be logically constructed so that it can be understood by a machine. As will be discussed later in the paper, different methods have been used in various related works to add a different kind of domain knowledge to robotics. The objective of this paper is to provide an improved retrained model for robotics in order to give them the ability to act more human-like when performing tasks. By using the proposed model robots are able to answer the incomplete command or inquiries related to a given context. One of the objectives of this work is to use the ontology-based, commonsense-support existing knowledge base as a mechanism to retrain and build a new model.},
  keywords={Training;Adaptation models;Service robots;Knowledge based systems;Robot sensing systems;Hardware;Sensors;BERT;commonsense;robotics;transfer learning},
  doi={10.1109/SCSE56529.2022.9905090},
  ISSN={2613-8662},
  month={Sep.},}@INPROCEEDINGS{8226470,
  author={Kidanu, Solomon Asres and Chbeir, Richard and Cardinale, Yudith},
  booktitle={2017 XLIII Latin American Computer Conference (CLEI)}, 
  title={MAS2DES-onto: Ontology for MAS-based digital ecosystems}, 
  year={2017},
  volume={},
  number={},
  pages={1-8},
  abstract={Multi-Agent Systems (MASs) have received much attention in recent years because of their advantages on modeling complex distributed systems, such Digital Ecosystems (DESs). Many existing modeling languages that support the design of such systems are based on ontologies to assist the representation of agents knowledge. However, in the context of DESs, there is still a need for more general conceptual models to represent the specific characteristics of DESs in terms of win-win interaction, engagement, equilibrium, and self-organization. Then, concepts such behavior, roles, rules, and environment are needed. This paper describes an ontology-based approach by proposing MAS2DES-Onto, as the conceptual model, which considers the essential static and dynamic aspects of MASs by a clear representation of their concepts and relationships to support the design and development of DESs. To validate and conduct experimental tests, we integrate MAS2DES-Onto into a framework to automatically generate MAS-based DESs. Results show the efficiency and effectiveness of our approach.},
  keywords={Ontologies;Cognition;Ecosystems;Biological system modeling;Organizations;Electronic mail},
  doi={10.1109/CLEI.2017.8226470},
  ISSN={},
  month={Sep.},}@ARTICLE{10553231,
  author={Li, Xiaodong and Tian, Guohui and Cui, Yongcheng},
  journal={IEEE Robotics and Automation Letters}, 
  title={Fine-Grained Task Planning for Service Robots Based on Object Ontology Knowledge via Large Language Models}, 
  year={2024},
  volume={9},
  number={8},
  pages={6872-6879},
  abstract={In domestic environment, the successful execution of service tasks heavily relies on the robot's capability to identify and understand objects within its surrounding. This crucial process predominantly takes place during task planning, prior to the actual performance of service tasks. Therefore, it is vital that the robot is capable of formulating object-specific action sequences through task planning. In this letter, we propose the Fine-Grained Task Planning (FGTP) framework, an innovative method that combines object ontology knowledge with Large Language Models (LLMs) to create detailed action sequences. The FGTP framework is uniquely designed to process both text descriptions of service tasks and images of relevant objects, enabling a thorough comprehension of object attributes essential for task execution. Moreover, we have developed a set of rules based on these attributes to assist in the robot's decision-making process. In scenarios where service tasks fail because the object is in an unsuitable state, our framework deploys a logic-based reasoning method, concentrating on object attributes to identify suitable substitutes. This process leverages a pre-established semantic map to locate these alternatives, thus enabling a transition back to standard task planning. Our evaluations, conducted in both the VirtualHome simulation environment and with the TIAGo real robot, demonstrate the efficacy of our approach. This confirms our framework's capability to generate practical and implementable plans for various service tasks.},
  keywords={Task analysis;Planning;Ontologies;Service robots;Robot kinematics;Object recognition;Task planning;service robotics},
  doi={10.1109/LRA.2024.3412593},
  ISSN={2377-3766},
  month={Aug},}@INPROCEEDINGS{10706469,
  author={Incitti, Francesca and Salfinger, Andrea and Snidaro, Lauro and Challapalli, Sri},
  booktitle={2024 27th International Conference on Information Fusion (FUSION)}, 
  title={Leveraging LLMs for Knowledge Engineering from Technical Manuals: A Case Study in the Medical Prosthesis Manufacturing Domain}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={Ontologies are nowadays widely used to organize information across specific domains, being effective due to their hierarchical structure and the ability to explicitly represent relationships between concepts. Knowledge engineering, like compiling companies’ vast bodies of knowledge into these structures, however, still represents a time-consuming, largely manually performed process, esp. with significant amounts of knowledge often only recorded within unstructured text documents. Since the recently introduced Large Language Models (LLMs) excel on text summarization, this raises the question whether these could be exploited within dedicated knowledge fusion architectures to assist human knowledge engineers by automatically suggesting relevant classes, instances and relations extracted from textual corpora. We therefore propose a novel approach that leverages the taxonomic structure of a partially defined ontology to prompt LLMs for hierarchical knowledge organization. Unlike conventional methods that rely solely on static ontologies, our methodology dynamically generates prompts based on the ontology’s existing class taxonomy, prompting the LLM to generate responses that extract supplementary information from unstructured documents. It thus introduces the concept of using ontologies as scaffolds for guiding LLMs, in order to realize a mutual interplay between structured ontological knowledge and the soft fusion capabilities of LLMs. We evaluate our proposed algorithm on a real-world case study, performing a knowledge fusion task on heterogeneous technical documentation from a medical prosthesis manufacturer.},
  keywords={Knowledge engineering;Large language models;Taxonomy;Text summarization;Organizations;Manuals;Documentation;Ontologies;Manufacturing;Prosthetics;Large Language Models;Knowledge Engineering;Ontology Population;Soft Fusion;Natural Language Processing},
  doi={10.23919/FUSION59988.2024.10706469},
  ISSN={},
  month={July},}@INPROCEEDINGS{10507374,
  author={Yang, Yi and Du, Mengjun and Li, Ang and Qian, Jin and Wang, Junyi},
  booktitle={2023 9th International Conference on Computer and Communications (ICCC)}, 
  title={A Fine Granular Relational Reasoning KGQA model Based on Weak Supervised Learning}, 
  year={2023},
  volume={},
  number={},
  pages={2198-2206},
  abstract={Knowledge graph question-answering (KGQA) task aims to provide answers in the form of entities from the knowledge graph for natural language questions. Conventional information retrieval modeling methods focus on controlling the size of the candidate reasoning path set through effective relationship filtering. However, these methods often perform iterative relational reasoning solely based on the overall semantic information of the question, neglecting the local relevance of relationships within the question statement and the value of fine granular information for filtering. KGQA task datasets typically lack annotations for inference paths, and existing weak supervised learning strategies may not effectively eliminate the misleading influence of erroneous reference reasoning paths on model reasoning capabilities. Based on the fundamental ideas of “reducing the size of candidate path sets” and “eliminating erroneous reference reasoning paths,” this paper proposes a knowledge graph question-answering model for fine granular relational reasoning based on weak supervised learning. First, it enhances relationship and path filtering capabilities from a model structure perspective and then, on this basis, improves the model’s ability to differentiate erroneous reference reasoning paths from a supervised strategy perspective. Compared to state-of-the-art KGQA models, the weak supervised fine granular relational reasoning KGQA model proposed in this paper achieves significant performance improvement.},
  keywords={Filtering;Computational modeling;Supervised learning;Semantics;Natural languages;Knowledge graphs;Cognition;Deep Learning;Natural Language Processing;Knowledge Graph Question Answering;Weak Supervised Learning},
  doi={10.1109/ICCC59590.2023.10507374},
  ISSN={2837-7109},
  month={Dec},}@INPROCEEDINGS{10386013,
  author={Xu, Dexuan and Chen, Yanyuan and Zhang, Jiayu and Lou, Yiwei and Wang, Hanpin and He, Jing and Huang, Yu},
  booktitle={2023 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)}, 
  title={Radiology Report Generation via Structured Knowledge-Enhanced Multi-modal Attention and Contrastive Learning}, 
  year={2023},
  volume={},
  number={},
  pages={2320-2325},
  abstract={The automated generation of radiology reports has attracted significant attention in the field of bioinformatics. Currently, the main limitations of this task include insufficient utilization of prior medical knowledge, lack of efficient knowledge fusion algorithms, and less distinctiveness between different generated reports. To address these issues, we propose a novel algorithm for radiology report generation, which includes Structured Knowledge-Enhanced Multi-modal Attention (SKEMA) and Dual-Branch Contrastive Learning (DBCL) for the first time. SKEMA aims to effectively bridge the gap between visual and prior knowledge by leveraging the high-order adjacency matrix of the knowledge graph to weightedly fuse image features and knowledge features. We enhance both features through masking, and use the original features and augmented features as positive and negative samples in the dual-branch contrastive learning (DBCL). DBCL increases the differences between positive and negative samples to avoid generating templated results, and enhances the robustness of the model. Finally, we conducted experiments to demonstrate the effectiveness of our model on two public radiology datasets, IU-Xray and MIMIC-CXR. Our model outperformed previous baseline methods on both datasets and achieved excellent evaluation scores.},
  keywords={Visualization;Fuses;MIMICs;Self-supervised learning;Knowledge graphs;Radiology;Robustness;Radiology Report Generation;Knowledge Graph;Contrastive Learning;Multi-modal Fusion},
  doi={10.1109/BIBM58861.2023.10386013},
  ISSN={2156-1133},
  month={Dec},}@ARTICLE{10858700,
  author={Yhdego, Tsegai O. and Wang, Hui},
  journal={IEEE Transactions on Automation Science and Engineering}, 
  title={Automated Ontology Generation for Zero-shot Defect Identification in Manufacturing}, 
  year={2025},
  volume={},
  number={},
  pages={1-1},
  abstract={A lack of labeled data presents a significant challenge to automatic defect identification in manufacturing, which is a crucial step in process control and certification during process development. State-of-the-art transfer learning is incapable of handling such zero-shot learning (ZSL) when defect labels are absent in training datasets. The latest research on ZSL leverages natural language processing (NLP) based on large language models (LLM) and shows promise by supplementing information to generate labels. However, its performance is hampered by the supporting LLMs pre-trained on generic vocabulary that failed to characterize manufacturing defects accurately. This paper establishes a methodology to automatically extract multi-level attributes from literature to improve defect representation, thereby facilitating ZSL. The extracted attributes contribute to a hierarchical knowledge graph, called defect ontology, to characterize multiple aspects of manufacturing defects. The proposed algorithm takes the defect images and associated text from the literature as input and develops an unsupervised method to identify the hierarchical relationships among the tokenized information extracted from the input text-feature corpora. The hierarchical graph is refined to retain the most relevant information by a pruning algorithm based on a minimum path search. A walk algorithm, along with NLP, parsed the generated ontology to create embedding of defects to enable zero-shot attribute learning to identify defects. The proposed method advances the ZSL methodology by automatically creating a hierarchical knowledge representation from literature and images to replace generic vocabulary in LLM adopted by ZSL algorithms, thus improving defect representation. The case studies are among the earlier attempts to demonstrate the feasibility of using literature data from public sources to extract attributes automatically to identify defects in a real additive manufacturing process based on direct-ink-writing.},
  keywords={Manufacturing;Zero shot learning;Ontologies;Automation;Data mining;Vocabulary;Accuracy;Transfer learning;Certification;Process control;Zero-shot learning;defect identification;manufacturing automation;self-supervised learning},
  doi={10.1109/TASE.2025.3537463},
  ISSN={1558-3783},
  month={},}@ARTICLE{10179162,
  author={Sui, Yicheng and Zhang, Yuzhe and Sun, Jianjun and Xu, Ting and Zhang, Shenglin and Li, Zhengdan and Sun, Yongqian and Guo, Fangrui and Shen, Junyu and Zhang, Yuzhi and Pei, Dan and Yang, Xiao and Yu, Li},
  journal={IEEE Transactions on Services Computing}, 
  title={LogKG: Log Failure Diagnosis Through Knowledge Graph}, 
  year={2023},
  volume={16},
  number={5},
  pages={3493-3507},
  abstract={Logs are one of the most valuable data to describe the running state of services. Failure diagnosis through logs is crucial for service reliability and security. The current automatic log failure diagnosis methods cannot fully use the multiple fields of logs, which fail to capture the relation between them. In this article, we propose LogKG, a new framework for diagnosing failures based on knowledge graphs (KG) of logs. LogKG fully extracts entities and relations from logs to mine multi-field information and their relations through the KG. To fully use the information represented by KG, we propose a failure-oriented log representation (FOLR) method to extract the failure-related patterns. Utilizing the OPTICS clustering method, LogKG aggregates historical failure cases, labels typical failure cases, and trains a failure diagnosis model to identify the root cause. We evaluate the effectiveness of LogKG on a real-world log dataset and a public log dataset, respectively, showing that it outperforms existing methods. With the deployment in a top-tier global Internet Service Provider (ISP), we demonstrate the performance and practicability of LogKG.},
  keywords={Semantics;Task analysis;Sun;Manuals;Security;Natural language processing;Knowledge graphs;Cluster;diagnosis;embedding;LogKG},
  doi={10.1109/TSC.2023.3293890},
  ISSN={1939-1374},
  month={Sep.},}@ARTICLE{10582529,
  author={Wu, Feng and Zhao, Guoshuai and Li, Tengjiao and Shen, Jialie and Qian, Xueming},
  journal={IEEE Transactions on Knowledge and Data Engineering}, 
  title={Improving Conversational Recommendation System Through Personalized Preference Modeling and Knowledge Graph}, 
  year={2024},
  volume={36},
  number={12},
  pages={8529-8540},
  abstract={Conversational recommendation systems (CRS) can actively discover users’ preferences and perform recommendations during conversations. The majority of works on CRS tend to focus on a single conversation and dig it using knowledge graphs, language models, etc. However, they often overlook the abundant and rich preference information that exists in the user's historical conversations. Meanwhile, end-to-end generation of recommendation results may lead to a decrease in recommendation quality. In this work, we propose a personalized conversational recommendation system infused with historical interaction information. This framework leverages users’ preferences extracted from their historical conversations and integrates them with the users’ preferences in current conversations. We find that this contributes to higher accuracy in recommendations and fewer recommendation turns. Moreover, we improve the interactive pattern between the recommendation module and the dialogue generation module by utilizing the slot filling method. This enables the results inferred by the recommendation module to be integrated into the conversation naturally and accurately. Our experiments on the benchmark dataset demonstrate that our model significantly outperforms the state-of-the-art methods in the evaluation of recommendations and dialogue generation.},
  keywords={Oral communication;Recommender systems;Knowledge graphs;Task analysis;Accuracy;Motion pictures;History;Conversational recommendation system;dialogue generation;personalized recommendations},
  doi={10.1109/TKDE.2024.3421580},
  ISSN={1558-2191},
  month={Dec},}@INPROCEEDINGS{10698993,
  author={Kumar, Amala Rashmi and Kumari, S. Meena and Rao, Tanvi and Shetty, Tavishi S},
  booktitle={2024 Second International Conference on Networks, Multimedia and Information Technology (NMITCON)}, 
  title={ReidLM: Fine-Tuning LLaMA3 using Evol-Instruct for Enhanced Contextual Accuracy in Rare Disease Research}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={This study introduces ReidLM, a fine-tuned large language model (LLM) optimized for the rare disease domain. By generating a diverse and complex question-and-answer dataset using the EvolInstruct methodology, Meta’s LLaMA-3-8B-Instruct model was enhanced to deliver better performance across multiple evaluation metrics. ReidLM demonstrates significant improvements in generating contextually accurate responses for rare diseases, highlighting the potential of Evol-Instruct in specialized medical applications. Specifically, ReidLM achieved the highest ROUGE-1 (0.3281) and GEval (0.87) scores among the evaluated models, along with strong performances in METEOR (0.3662) and BERTScore (0.8782), indicating its effectiveness in producing semantically sound and relevant responses. These results offer promising advancements in medical research and patient care, with future work aimed at expanding datasets and validating clinical utility.},
  keywords={Measurement;Accuracy;Terminology;Multimedia systems;Large language models;Medical services;Meteors;Information technology;Medical diagnostic imaging;Diseases;fine-tuning;LLaMA 3;evol-instruct;rare diseases},
  doi={10.1109/NMITCON62075.2024.10698993},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{9973695,
  author={Filgueira, Rosa},
  booktitle={2022 IEEE 18th International Conference on e-Science (e-Science)}, 
  title={frances: A Deep Learning NLP and Text Mining Web Tool to Unlock Historical Digital Collections: A Case Study on the Encyclopaedia Britannica}, 
  year={2022},
  volume={},
  number={},
  pages={246-255},
  abstract={This work presents frances, an integrated text mining tool that combines information extraction, knowledge graphs, NLP, deep learning, parallel processing and Semantic Web techniques to unlock the full value of historical digital textual collections, offering new capabilities for researchers to use powerful analysis methods without being distracted by the technology and middleware details. To demonstrate these capabilities, we use the first eight editions of the Encyclopaedia Britannica offered by the National Library of Scotland (NLS) as an example digital collection to mine and analyse. We have developed novel parallel heuristics to extract terms from the original collection (alongside metadata), which provides a mix of unstructured and semi-structured input data, and populated a new knowledge graph with this information. Our Natural Language Processing models enable frances to perform advanced analyses that go significantly beyond simple search using the information stored in the knowledge graph. Furthermore, frances also allows for creating and running complex text mining analyses at scale. Our results show that the novel computational techniques developed within frances provide a vehicle for researchers to formalize and connect findings and insights derived from the analysis of large-scale digital corpora such as the Encyclopaedia Britannica.},
  keywords={Text mining;Deep learning;Semantic Web;Knowledge engineering;Parallel processing;Metadata;Information retrieval;information extraction;knowledge graphs;deep transfer learning;natural language processing;text mining;web tools;semantic web;parallel computing;digital tools;historical digital textual collections},
  doi={10.1109/eScience55777.2022.00038},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10005324,
  author={Zindel, Andreas and Feo-Arenis, Sergio and Helle, Philipp and Schramm, Gerrit and Elaasar, Maged},
  booktitle={2022 IEEE International Symposium on Systems Engineering (ISSE)}, 
  title={Building a Semantic Layer for Early Design Trade Studies in the Development of Commercial Aircraft}, 
  year={2022},
  volume={},
  number={},
  pages={1-8},
  abstract={To improve the adoption of Model-based Systems Engineering (MBSE), data that is distributed across engineering disciplines needs to be made available in an open and descriptive way. This paper describes a new approach to implementing a semantic layer that allows integrating and publishing MBSE data stored in heterogeneous models in a uniform way by means of Semantic Web technologies. The tool-independent views on engineering data provided by the semantic layer enable the implementation of services for accessing, classifying, checking and reuse of federated information. We report on the creation of a common vocabulary in the Ontology Modeling Language (OML) that can be automatically instantiated from distributed models into a knowledge graph. We demonstrate the benefits of our approach using a Systems Modeling Language (SysML) based early design trade study in the aeronautics domain.},
  keywords={Semantic Web;Vocabulary;Atmospheric modeling;Unified modeling language;Semantics;Ontologies;Data models},
  doi={10.1109/ISSE54508.2022.10005324},
  ISSN={2687-8828},
  month={Oct},}@INPROCEEDINGS{10834324,
  author={Chen, Xin and Yin, Chuantao and Chen, Hui and Rong, Wenge and Ouyang, Yuanxin and Chai, Yanmei},
  booktitle={2024 IEEE International Conference on Teaching, Assessment and Learning for Engineering (TALE)}, 
  title={Course Recommendation System Based on Course Knowledge Graph Generated by Large Language Models}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={With the advent of the big data era, knowledge graphs, as important tools for organizing, managing, and understanding massive amounts of information, are gradually becoming a research hotspot in the field of artificial intelligence. This article focuses on the research and practice of automated construction and application of knowledge graphs in the field of university courses, aiming to improve the efficiency and accuracy of knowledge graph construction and provide strong support for the application in related fields.This study integrated publicly available datasets, mainstream online education platforms, and course explanation texts. Using rule-based and deep learning information extraction methods, combined with a large language model, the automatic extraction of entities, attributes, and relationships was successfully achieved, and an initial course knowledge graph was constructed based on this. Furthermore, by calculating the similarity between course description texts and combining the extracted course prerequisite and peer relationships from the texts, the study not only enriches the structure and content of the course knowledge graph, but also enhances its accuracy and practicality. In order to provide more personalized course recommendation services, this article combines sequence based recommendation algorithms and graph embedding algorithms, fully utilizing the information of the course itself and the dependency information of the course sequence, designing a unique personalized recommendation algorithm, and verifying its effectiveness and accuracy through experiments. This study not only provides strong knowledge graph support for online education platforms, but also provides strong technical support for personalized learning recommendations.},
  keywords={Deep learning;Accuracy;Large language models;Soft sensors;Education;Knowledge graphs;Big Data;Information retrieval;Data mining;Recommender systems;component;formatting;style;styling;insert},
  doi={10.1109/TALE62452.2024.10834324},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{8406642,
  author={Figueiredo, Guylerme and Duchardt, Amelie and Hedblom, Maria M. and Guizzardi, Giancarlo},
  booktitle={2018 12th International Conference on Research Challenges in Information Science (RCIS)}, 
  title={Breaking into pieces: An ontological approach to conceptual model complexity management}, 
  year={2018},
  volume={},
  number={},
  pages={1-10},
  abstract={In recent years, there has been a growth in the use of reference conceptual models, in general, and domain ontologies, in particular, to capture information about complex and critical domains. These models play a fundamental role in different types of critical semantic interoperability tasks. Therefore, it is essential that domain experts are able to understand and reason using the models' content. In other words, it is important that conceptual models are cognitively tractable. However, it is unavoidable that when the information of the represented domain grows, so does the size and complexity of the artifacts and models that represent them. For this reason, more sophisticated techniques for complexity management in ontology-driven conceptual models, need to be developed. Some approaches are based on the notion of model modularization. In this paper, we follow the work on model modularization to present an approach for view extraction for the ontology-driven conceptual modeling language OntoUML. We provide a formal definition for ontological views over OntoUML conceptual models that completely leverages on the ontologically well-grounded real-world semantics of that language. Moreover, we present a plug-in tool, particularly developed for an OntoUML model-based editor that implements this formal view structure in terms of queries defined over the OntoUML metamodel embedded in that tool.},
  keywords={Unified modeling language;Ontologies;Semantics;Complexity theory;Marine vehicles;Tools;Computational modeling;Conceptual Model Modularization;Ontological Views;Complexity Management in Conceptual Modeling;On-toUML},
  doi={10.1109/RCIS.2018.8406642},
  ISSN={2151-1357},
  month={May},}@ARTICLE{10328733,
  author={Wang, Songsong and Xu, Ouguan},
  journal={IEEE Access}, 
  title={Semantic Information Modeling and Implementation Method for Water Conservancy Equipment}, 
  year={2023},
  volume={11},
  number={},
  pages={133879-133890},
  abstract={Water conservancy equipment (WCE) has a large amount of information, structural heterogeneity and complex relationship leads to the difficulty of semantic interoperability in smart water conservancy. To overcome this issue, we propose the WCE information interaction dimension theory, modeling process and instancing method. First, we analyze the smart water conservancy ontology and information factor, and propose semantic information interaction dimension structure of water conservancy Ontology. Second, we construct the network information model structure of water conservancy, through the relationship degree, a tree model which can realize semantic expression and interoperability is formed through the dimensionality reduction of the model. Third, the component attribute set hierarchical relationship architecture water conservancy information model is established, which use XML language to describe this model. Moreover, the three types of instancing methods are proposed. Through OPC unified architecture (OPC UA) technology, water conservancy information model can implement semantic interoperability. The experimental show that the proposed method of semantic information modeling and semantic interoperability of WCE is feasible, and obvious advantages of complete semantic interoperability than in the model architecture, semantic structure and technical implementation.},
  keywords={Water conservation;Ontologies;Optical wavelength conversion;Semantics;Data models;Interoperability;Water resources;Information model;semantics;smart water conservancy;water conservancy equipment;OPC UA},
  doi={10.1109/ACCESS.2023.3336817},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10708094,
  author={Wang, Dan and Li, Xiaofeng and Gu, Bin and Cao, Yue and Liu, Yusheng},
  booktitle={2023 6th International Conference on Mechatronics, Robotics and Automation (ICMRA)(}, 
  title={An Architecture Modeling Framework for Distributed Automation Systems Using SysML and Semantic Web Technologies}, 
  year={2023},
  volume={},
  number={},
  pages={191-200},
  abstract={The rising interdisciplinarity and complexity of the Distributed Automation Systems (DASs) require the systems to be modeled in an unambiguous and high-level abstract way for cross-discipline/stage communication and interoperability in the Model-Driven Development (MDD) lifecycle. The concept of the System Architecture Model in systems engineering has been adopted for this challenge. To support the creation and analysis of this model, a modeling framework with a modeling methodology, modeling language, knowledge base, and related toolkit is established based on SysML and Semantic Web Technologies. A modeling methodology which is the core of the framework for modeling the architecture of DASs is formally defined with domain-specificity, comprehensiveness, discipline-neutrality, and platform-independency. Based on it, the SysML-DAS modeling language is extended from SysML, and the System Architecture Ontology is built with the help of the Knowledge Extraction Tool. This ontology works as the knowledge base not only to provide a unified and unambiguous view of the system but also to support the automated accomplishment of tasks in the MDD process. As a typical task, the semantic correctness and integrity of the system architecture model can be assessed by the Knowledge Analysis Tool in this framework.},
  keywords={Semantic Web;Analytical models;Automation;Mechatronics;Knowledge based systems;Semantics;Systems architecture;Ontologies;Service-oriented architecture;Model-driven development;distributed automation system;SysML;Semantic Web technologies;System Architecture Model},
  doi={10.1109/ICMRA59796.2023.10708094},
  ISSN={2996-380X},
  month={Nov},}@INPROCEEDINGS{10692968,
  author={Bhargava, Urvashi and Teresha, Y. and Koul, Nishank and Chavan, Chandrashekhar Pomu},
  booktitle={2024 IEEE 7th International Conference on Big Data and Artificial Intelligence (BDAI)}, 
  title={Overcoming the Challenges of Large Language Models: Introducing a Novel Proposition for Synthetic Data Validation}, 
  year={2024},
  volume={},
  number={},
  pages={290-295},
  abstract={The market debut of ChatGPT gave rise to the development and deployment of various other Large Language Models (LLMs) that achieve state-of-the-art performance across various tasks. The growing popularity of these models has captivated some to attempt to construct or enhance their own LLM. We must be aware of the significant problems that already exist and that we might face along the way. This paper aims to identify and investigate the main challenges in this field, provide existing solutions, and propose novel approaches to mitigate them. A unique Truth-Table proposition for validating synthetic data is presented examining two models, along with a bidirectional knowledge graph-based solution for curing the reverse curse problem, data generation strategies, domain adaptation methods, and the use of a custom dataset to address model hallucinations. The methodology and findings of this study provide valuable insights for users, researchers, and industry experts who are interested in LLMs. It serves as a reference for future research on current models, refining models or developing domain-specific ones.},
  keywords={Industries;Adaptation models;Analytical models;Large language models;Refining;Knowledge graphs;Data models;Reliability;Faces;Synthetic data;Large Language Models;Challenges;Strategies;Synthetic Data Validation;Reversal Curse;Model Hallucinations;Knowledge Graph;Data Scarcity},
  doi={10.1109/BDAI62182.2024.10692968},
  ISSN={},
  month={July},}@ARTICLE{9119385,
  author={Hou, Jiaqi and Li, Xin and Yao, Haipeng and Sun, Haichun and Mai, Tianle and Zhu, Rongchen},
  journal={IEEE Access}, 
  title={BERT-Based Chinese Relation Extraction for Public Security}, 
  year={2020},
  volume={8},
  number={},
  pages={132367-132375},
  abstract={The past few years have witnessed some public safety incidents occurring around the world. With the advent of the big data era, effectively extracting public security information from the internet has become of great significance. Up to hundreds of TBs of data are injected into the network every second, and thus it is impossible to process them manually. Natural Language Processing (NLP) is dedicated to the development of an intelligent system for effective text information mining. By analysing the text and quickly extracting the relationships between the relevant entities, NLP can establish the knowledge graph (KG) of public security, which lays the foundation for safety case analysis, information monitoring, and activity tracking and locating. One of the current pre-training relation extraction models is the Word2Vec model. The Word2vec model is single mapped, and it produces a static, single representation of the words in sentences. Then, the BERT model considers contextual information and provides more dynamic, richer vector representations of generated words. Therefore, in this paper, we propose a Bidirectional Encoder Representation from Transformers (BERT) based on the Chinese relation extraction algorithm for public security, which can effectively mine security information. The BERT model is obtained by training the Masked Language Model and predicting the next sentence task, which is based on the Transformer Encoder and the main model structure is the stacked Transformers. Extensive simulations are conducted to evaluate our proposed algorithm in comparison to some state-of-the-art schemes.},
  keywords={Bit error rate;Feature extraction;Security;Task analysis;Training;Semantics;Data mining;BERT;relationship extraction;public security;MaxPooler;ReLU},
  doi={10.1109/ACCESS.2020.3002863},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{9265932,
  author={Duan, Jiajia and Zhao, Hui and Zhou, Qian and Qiu, Meikang and Liu, Meiqin},
  booktitle={2020 IEEE International Conference on Smart Cloud (SmartCloud)}, 
  title={A Study of Pre-trained Language Models in Natural Language Processing}, 
  year={2020},
  volume={},
  number={},
  pages={116-121},
  abstract={Pre-trained Language Model (PLM) is a very popular topic in natural language processing (NLP). It is the rapid development of pre-trained language models (PLMs) that has led to the achievements of natural language today. In this article, we give a review of important PLMs. First, we generally introduce the development history and achievements of PLMs. Second, we present several extraordinary PLMs, including BERT, the variants of BERT, Multimodal PLMs, PLMs combined with Knowledge Graph and PLMs applied to natural language generation. In the end, we summarize and look into the future of PLMs. We expect this article will provide a practical guide for learners to understanding, using and developing PLMs with the abundant literature existing for various NLP tasks.},
  keywords={Bit error rate;Task analysis;Training;Computational modeling;Predictive models;Natural language processing;Context modeling;Pre-trained;Embedding;BERT;Cross-modal;KG;Natural Language Generation},
  doi={10.1109/SmartCloud49737.2020.00030},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{9892028,
  author={Li, Chen and Bai, Jun and Wang, Chuanarui and Hu, Yuanhao and Rong, Wenge and Xiong, Zhang},
  booktitle={2022 International Joint Conference on Neural Networks (IJCNN)}, 
  title={Graph and Question Interaction Aware Graph2Seq Model for Knowledge Base Question Generation}, 
  year={2022},
  volume={},
  number={},
  pages={1-8},
  abstract={The Knowledge Base Question Generation (KBQG) is an essential natural language processing task. Taking knowledge graph and answer entities as input, KBQG aims to generate corresponding natural language question. Recently Graph2Seq has been proposed to encode the knowledge graph and achieved remarkable results, while one important challenge still remains, i.e., the graph encoding lacks the interaction with the target question. To deal with the above challenge, we propose a graph and question interaction enhanced Graph2Seq model, in which we design an encoder-decoder parallel enhancement mechanism and apply the knowledge distillation for both inter-mediate representation and prediction distribution to employ the knowledge of the target question into the graph representation. Experiments have been conducted on KBQG benchmark dataset and experimental results have shown the promising potential of proposed method.},
  keywords={Knowledge based systems;Neural networks;Predictive models;Benchmark testing;Natural language processing;Encoding;Task analysis;Question Generation;Knowledge Graph;Graph and Question Interaction;Knowledge Distillation},
  doi={10.1109/IJCNN55064.2022.9892028},
  ISSN={2161-4407},
  month={July},}@INPROCEEDINGS{10511095,
  author={C, Naveen and B, Amutha},
  booktitle={2024 5th International Conference on Intelligent Communication Technologies and Virtual Mobile Networks (ICICV)}, 
  title={Comparative Methods of Implementation for Different Question Answering Systems}, 
  year={2024},
  volume={},
  number={},
  pages={567-575},
  abstract={This research introduces an innovative Question Answering (QA) system tailored explicitly for government department inquiries regarding individuals. Harnessing the prowess of cutting-edge language models such as BERT and T5 (Text-to-Text Transfer Transformer), the system excels in understanding complex queries within diverse governmental domains. Moreover, it incorporates a specialized Knowledge Graph meticulously curated with interconnected information about people across various departments. By integrating BERT and T5 for versatile query comprehension and answer generation alongside a comprehensive People-centric Knowledge Graph, this system aims to revolutionize information retrieval within government entities. The seamless fusion of these technologies promises accurate, contextually rich responses, optimizing operational efficiency across government departments and fostering streamlined access to crucial information.},
  keywords={Government;Knowledge graphs;Transformers;Information retrieval;Question answering (information retrieval);Communications technology;BERT(Bidirectional Encoder Representations from Transformers);T5(Text-to-Text Transfer Transformer);Natural Language Processing;Knowledge Graph;Question Answering},
  doi={10.1109/ICICV62344.2024.00096},
  ISSN={},
  month={March},}

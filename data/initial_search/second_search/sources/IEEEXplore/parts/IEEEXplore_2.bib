@INPROCEEDINGS{8355023,
  author={Kurniawan, Andri and Afriyanti, Iis and Azurat, Ade},
  booktitle={2017 International Conference on Advanced Computer Science and Information Systems (ICACSIS)}, 
  title={ABS microservices and ontology-zotonic integration for SPL implementation in information system}, 
  year={2017},
  volume={},
  number={},
  pages={131-136},
  abstract={Software Product Line (SPL) promises to accelerate the development process with higher quality of product and low budget of production. The essential key of SPL is feature diagram which describes the relation between features for the domain and captures the commonalities and variabilities. The approach gains numerous attention in research and industry area. However, the implementation of SPL approach for information system development is still inadequate. Some works explain the inclusion of ontology for SPL such as having feature diagram in ontology language. The inclusion benefits to produce an information system automatically. On the other side, the executable modelling language such as Abstract Behavioural Specification (ABS) can be utilized to implement the feature diagram for distributed object-oriented systems. The trend of ABS expands to accommodate microservices-based software variabilities, that is ABS Microservices Framework. The Framework allows to build different services for different devices who consume the data from ABS. However, these two area of research have not been integrated. We propose an adaptor to integrate the ABS microservices and ontology-based information system to produce automated business logics into the system. We show that by using the ontology as its basis, the system is semantically structured and the business logics required by the system is updated automatically.},
  keywords={Web services;Adaptation models;Business;Information systems;Ontologies;Object oriented modeling;OWL},
  doi={10.1109/ICACSIS.2017.8355023},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10446380,
  author={Doh, SeungHeon and Lee, Minhee and Jeong, Dasaem and Nam, Juhan},
  booktitle={ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Enriching Music Descriptions with A Finetuned-LLM and Metadata for Text-to-Music Retrieval}, 
  year={2024},
  volume={},
  number={},
  pages={826-830},
  abstract={Text-to-Music Retrieval, finding music based on a given natural language query, plays a pivotal role in content discovery within extensive music databases. To address this challenge, prior research has predominantly focused on a joint embedding of music audio and text, utilizing it to retrieve music tracks that exactly match descriptive queries related to musical attributes (i.e. genre, instrument) and contextual elements (i.e. mood, theme). However, users also articulate a need to explore music that shares similarities with their favorite tracks or artists, such as I need a similar track to Superstition by Stevie Wonder. To address these concerns, this paper proposes an improved Text-to-Music Retrieval model, denoted as TTMR++, which utilizes rich text descriptions generated with a finetuned large language model and metadata. To accomplish this, we obtained various types of seed text from several existing music tag and caption datasets and a knowledge graph dataset of artists and tracks. The experimental results show the effectiveness of TTMR++ in comparison to state-of-the-art music-text joint embedding models through a comprehensive evaluation involving various musical text queries.1},
  keywords={Mood;Databases;Soft sensors;Instruments;Knowledge graphs;Signal processing;Probabilistic logic;Music Informational Retrieval;Text-to-Music Retrieval;Large Language Model},
  doi={10.1109/ICASSP48485.2024.10446380},
  ISSN={2379-190X},
  month={April},}@INPROCEEDINGS{9537870,
  author={Wen, Song and Zeng, Bi and Liao, Wenxiong},
  booktitle={2021 3rd International Conference on Natural Language Processing (ICNLP)}, 
  title={Named Entity Recognition for Instructions of Chinese Medicine Based on Pre-trained Language Model}, 
  year={2021},
  volume={},
  number={},
  pages={139-144},
  abstract={Named Entity Recognition (NER) of Chinese medicine text is a basic task of constructing medical and health knowledge graph. Many scholars have researched the NER task of electronic medical records and drug names, while many factors restrict the research of NER tasks for the instructions of Chinese medicine. For example, there is no obvious boundary between words in Chinese, and it is impossible to capture the interactive information between sentences and the global information at the same time. Considering that this type of data is highly professional and there is no publicly available data set. This paper collected 1,000 pieces of instructions of Chinese medicine, then explored the effectiveness of pre-trained models in NER task in this field. The experimental results showed that compared with the experimental results of the single or joint model on the same data set, the F1 value of pre-trained model was increased by 9.65% and 8.71% respectively.},
  keywords={Drugs;Text recognition;Data models;Natural language processing;Task analysis;Electronic medical records;NER;instruction of Chinese medicine;pre-trained language model;CRF},
  doi={10.1109/ICNLP52887.2021.00029},
  ISSN={},
  month={March},}@INPROCEEDINGS{9206698,
  author={Sai Sharath, Japa and Banafsheh, Rekabdar},
  booktitle={2020 International Joint Conference on Neural Networks (IJCNN)}, 
  title={Question Answering over Knowledge Base using Language Model Embeddings}, 
  year={2020},
  volume={},
  number={},
  pages={1-8},
  abstract={Knowledge Base, represents facts about the world, often in some form of subsumption ontology, rather than implicitly, embedded in procedural code, the way a conventional computer program does. While there is a rapid growth in knowledge bases, it poses a challenge of retrieving information from them. Knowledge Base Question Answering is one of the promising approaches for extracting substantial knowledge from Knowledge Bases. Unlike web search, Question Answering over a knowledge base gives accurate and concise results, provided that natural language questions can be understood and mapped precisely to an answer in the knowledge base. However, some of the existing embedding-based methods for knowledge base question answering systems ignore the subtle correlation between the question and the Knowledge Base (e.g., entity types, relation paths, and context) and suffer from the Out Of Vocabulary problem. In this paper, we focused on using a pre-trained language model for the Knowledge Base Question Answering task. Firstly, we used Bert base uncased for the initial experiments. We further fine-tuned these embeddings with a two way attention mechanism from the knowledge base to the asked question and from the asked question to the knowledge base answer aspects. Our method is based on a simple Convolutional Neural Network architecture with a Multi-Head Attention mechanism to represent the asked question dynamically in multiple aspects. Our experimental results show the effectiveness and the superiority of the Bert pre-trained language model embeddings for question answering systems on knowledge bases over other well-known embedding methods.},
  keywords={Knowledge based systems;Task analysis;Bit error rate;Knowledge discovery;Semantics;Natural languages;Context modeling;knowledge base question answering;BERT;Language Model;KBQA;Multi-Head Attention},
  doi={10.1109/IJCNN48605.2020.9206698},
  ISSN={2161-4407},
  month={July},}@INPROCEEDINGS{10429117,
  author={Guo, Zhenyu and Ma, Huan and Liu, Wentao},
  booktitle={2023 10th International Forum on Electrical Engineering and Automation (IFEEA)}, 
  title={Cause Analysis of Substation Faults Based on Multimodal Fusion Detection and Knowledge Graph}, 
  year={2023},
  volume={},
  number={},
  pages={1252-1256},
  abstract={The expansion of the grid scale puts forward higher requirements for the stability of substation operation, so it is necessary to detect faults in time and analyze possible fault causes through intelligent inspection. However, commonly used fault detection methods based on image processing or single-mode data such as voltage and temperature are likely to cause misjudgment of faults and cannot realize the function of fault cause analysis. Based on this, this paper proposes a substation fault cause analysis model based on multi-modal data fusion and knowledge graph. The cause of the fault is inferred based on the substation fault cause knowledge graph. For the first time, this solution comprehensively uses target detection technology, audio recognition neural network and knowledge map, and achieves a fault cause analysis accuracy rate higher than 90% on the substation fault data set we constructed.},
  keywords={Temperature distribution;Substations;Data integration;Knowledge graphs;Object detection;Voltage;Thermal stability;Substation Faults;Multimodal Fusion Detection;Knowledge Graph},
  doi={10.1109/IFEEA60725.2023.10429117},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{7934810,
  author={Shani, Uri and Franke, Marco and Hribernik, Karl A. and Thoben, Klaus-Dieter},
  booktitle={2017 Annual IEEE International Systems Conference (SysCon)}, 
  title={Ontology mediation to rule them all: Managing the plurality in product service systems}, 
  year={2017},
  volume={},
  number={},
  pages={1-7},
  abstract={The lifecycle of a product is managed not only through the Product Lifecycle Management (PLM), but needs to integrate with product services into a Product Service System (PSS). The related activities are performed throughout the entire lifecycle and require sharing information among tools of the different product lifecycle phases. When extending collaboration of PLM with services as integrated within a PSS, the physical product is linked with a vastly extended universe of information during the PSS lifecycle. To achieve robust and maintainable PSS the interoperability must be fulfilled between the physical products related data sources and the relevant services. To meet that end, we use ontologies to define a formal semantic for information sources and targets. Each tool or data source can use its own ontology independently of the other tools and sources, creating the potential of an unmanageable universe of data. Yet, the benefit is that components of the PSS have weak dependencies among them which leads to an open and flexible system that can easily evolve and adapt. This paper focuses on the provision of ontology driven services including the transformation of product related data into different ontologies and the aggregation of different data source specific ontologies to a holistic PSS universe with no specific ontology in its core. We present two approaches that implement ontology mediation (also termed "semantic mediation") as a variant of ontology matching since the level of matching can be rather complex. The application of this technology is also demonstrated in related domains, showing its potential when applied in PSS that is presently an ongoing research within the PSYMBIOSYS EU project. In consequence, the applicable data integration and ontology matching approaches are the hand tools to instantiate sustainable PSS into the market.},
  keywords={Ontologies;Tools;Mediation;Interoperability;Semantics;OWL;Resource description framework;Semantic Mediation;Ontology Mediation;Heterogeneous data management;Ontologies in Product Service Systems;large-scale systems Integration},
  doi={10.1109/SYSCON.2017.7934810},
  ISSN={2472-9647},
  month={April},}@INPROCEEDINGS{10035090,
  author={Shang, Chunnan and Qin, Bo and Peng, Peng and Wang, Hongwei},
  booktitle={2022 IEEE International Conference on e-Business Engineering (ICEBE)}, 
  title={Simultaneous Extraction of Entities and Relations Based on Pre-trained Language Model and Pre-defined Language Templates}, 
  year={2022},
  volume={},
  number={},
  pages={222-227},
  abstract={With the advent of the era of big data, the need to obtain core information from text data is getting stronger and stronger. And the knowledge graph can visually represent the core information of the text. Entity relation extraction is a challenge and key part of knowledge graph construction. In this paper, we propose a model that can effectively perform entity relation extraction. The model adopts a joint training approach based on parameter sharing to solve the error propagation problem in pipelined extraction. At the same time, the model uses a pre-trained language model as the basis to solve the problem of lack of semantic knowledge in traditional models. Further, it uses a linguistic template-based approach to bridge the discrepancies in training and fine-tuning of pre-trained language models. To validate the proposed approach, we conduct comparative experiments on the SemEval2010 dataset and conll04 dataset. The validation results demonstrate that our model can improve the accuracy, recall, and F1 score of joint entity relationship extraction compared to the baseline models.},
  keywords={Training;Bridges;Measurement;Knowledge engineering;Semantics;Linguistics;Big Data;knowledge graph construction;joint extraction of entities and relations;pre-trained language model;language templates},
  doi={10.1109/ICEBE55470.2022.00046},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10148356,
  author={Na, Qionglan and Su, Dan and Zhang, Jiaojiao and Li, Xin and Xiao, Na},
  booktitle={2022 4th International Conference on Intelligent Information Processing (IIP)}, 
  title={Construction of Power Knowledge Graph based on Entity Relation Extraction}, 
  year={2022},
  volume={},
  number={},
  pages={77-80},
  abstract={In order to integrate the fragmented text data in the power domain and solve the problems of disordered and weak correlation of transmission protocols, an improved BERT model was proposed by combining deep learning and knowledge graph for entity relationship extraction in the power domain. This method uses the BERT model based on a full word mask to generate sentence vectors, word vectors with contextual semantics, and then takes the average value of word vectors to get entity vectors. The sentence vectors and entity vectors are combined by the attention machine. Finally, the combined new vectors are put into a fully layer for sequential labeling and finding the optimal tag to implement the entity extracted object. The experimental results show that the precision, recall value, and F1 score of this method are 90.12%, 85.25%, and 87.56 % respectively when entity extraction is performed on the corpus data set of transmission procedures.},
  keywords={Technological innovation;Protocols;Bit error rate;Semantics;Knowledge graphs;Feature extraction;Regulation;Power;BERT;Information Extraction;Deep-learning},
  doi={10.1109/IIP57348.2022.00022},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10475660,
  author={Ogawa, Tomohiro and Yoshioka, Kango and Fukuda, Ken and Morita, Takeshi},
  booktitle={2024 IEEE 18th International Conference on Semantic Computing (ICSC)}, 
  title={Prediction of actions and places by the time series recognition from images with Multimodal LLM}, 
  year={2024},
  volume={},
  number={},
  pages={294-300},
  abstract={In recent years, the risk of accidents in the homes of older adults in an aging society has increased, and there is a need to address this problem. We took up the challenge of utilising explainable AI techniques to identify accident risks at home and suggest safer alternatives. This study combined knowledge graphs and large-scale language models to solve real-world problems. Specifically, we addressed answering questions using a multimodal dataset of videos recording daily activities and a knowledge graph. The dataset represents the living activities in the virtual space and provides environmental information. The task is divided into two main tasks. Task 1 utilises knowledge graph to answer direct questions and processes the data using SPARQL queries. Task 2 addresses more complex questions that cannot be answered by search alone. Consequently, in Task 1, the system could answer all questions using information from the SPARQL knowledge graph. In Task 2, a certain degree of success was achieved for complex questions by reasoning with images created by concatenating multimodal LLMs and time-series images. The source code used in the experiment is available at https://github.com/tomo1115tomo/kg_reasoning_challenge.},
  keywords={Training;Source coding;Time series analysis;Training data;Knowledge graphs;Data models;Cognition;Knowledge Graph Reasoning Challenge},
  doi={10.1109/ICSC59802.2024.00053},
  ISSN={2472-9671},
  month={Feb},}@INPROCEEDINGS{10389253,
  author={Yadav, Divyanshi and Para, Hitesh and Selvakumar, Prakash},
  booktitle={2023 International Conference on Electrical, Computer and Energy Technologies (ICECET)}, 
  title={Unleashing the Power of Large Language Model, Textual Embeddings, and Knowledge Graphs for Advanced Information Retrieval}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={Acquiring knowledge beyond the usual expertise is a critical challenge when implementing semantic information solutions for querying a knowledge base. To address this difficulty, one proposed solution was to use knowledge graphs in conjunction with traditional Question & Answering (Q&A) systems. However, this approach struggles with limited facts, difficulty in obtaining further insights into the context, and limited ability to handle complex questions, leading to inaccurate or irrelevant answers. To overcome these limitations, we present an approach for answering inference-based questions that integrates knowledge graphs, a large language model, and relevant embeddings from a vector database. Combining knowledge graphs and word embeddings significantly enhances the strength of both techniques, leading to improved performance of Question and Answering systems. We begin with generating representations of the relevant nodes in the knowledge graph and retrieve the most appropriate information from a collection of stored textual data using word embeddings. This approach tackles the shortcomings of conventional approaches that rely solely on knowledge graphs and are too rigid to handle the nuances of the context. This method provides a sophisticated understanding of language and context, enabling it to handle complex questions that may involve multiple entities and relationships with a better understanding of the facts and context in which the question is being asked. The system's ability to handle complex queries is evidenced through a combination of theoretical analysis and empirical data. Our approach has demonstrated exceptional efficiency on a benchmark dataset, as evidenced by evaluating the F1 score.},
  keywords={Databases;Computational modeling;Semantics;Knowledge based systems;Knowledge graphs;Benchmark testing;Information retrieval;Information Retrieval;Question & Answering Systems;Knowledge Graphs;Word Embeddings;Natural Language Processing;Large Language Model;Natural Language Understanding;Inference-Based Questions},
  doi={10.1109/ICECET58911.2023.10389253},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{9843341,
  author={Mordecai, Yaniv and Markina–Khusid, Aleksandra and Quinn, Greg and Crawley, Edward F.},
  booktitle={2022 IEEE Aerospace Conference (AERO)}, 
  title={Applying Model-Based Ontology Coverage Analysis to Mission Architectures}, 
  year={2022},
  volume={},
  number={},
  pages={01-18},
  abstract={This paper introduces a method for Model-based Ontology Coverage Analysis (MOCA) and applies it to SysML models of mission architectures. An ontology is a set of concepts that constitute a common language, standard terminology, and consistent pattern reference across multiple models within an organization, industry, or domain. The purpose of MOCA is to assess the overlap between a system architecture model and a given ontology, and thereby the architecture model's compliance with the ontology and the ontology's utilization by the architecture. We demonstrate MOCA on a SysML model of a humanitarian airlift mission, using a conceptual mission architecting SysML profile model that serves as the ontology. MOCA automates and simplifies reasoning over models, and creates digital model-based artifacts that support stakeholders in concept validation, decision making, and system/mission design. Thus, MOCA enhances digital systems engineering.},
  keywords={Analytical models;Vocabulary;Visualization;Digital systems;Atmospheric modeling;Unified modeling language;Semantics;Digital Engineering;Model-Based Systems Engineering;MBSE;Mission Architecture;Mission Engineering;Ontology;Ontological Analysis},
  doi={10.1109/AERO53065.2022.9843341},
  ISSN={1095-323X},
  month={March},}@INPROCEEDINGS{10350785,
  author={Dhaouadi, Mouna and Oakes, Bentley James and Famelis, Michalis},
  booktitle={2023 ACM/IEEE International Conference on Model Driven Engineering Languages and Systems Companion (MODELS-C)}, 
  title={Towards Understanding and Analyzing Rationale in Commit Messages Using a Knowledge Graph Approach}, 
  year={2023},
  volume={},
  number={},
  pages={622-630},
  abstract={Extracting rationale information from commit messages allows developers to better understand a system and its past development. Here we present our ongoing work on the Kantara end-to-end rationale reconstruction pipeline to a) structure rationale information in an ontologically-based knowledge graph, b) extract and classify this information from commits, and c) produce analysis reports and visualizations for developers. We also present our work on creating a labelled dataset for our running example of the Out-of-Memory component of the Linux kernel. This dataset is used as ground truth for our evaluation of NLP classification techniques which show promising results, especially the multi-classification technique XGBoost.},
  keywords={Visualization;Analytical models;Linux;Pipelines;Knowledge graphs;Model driven engineering;Data mining;rationale structuring;rationale extraction;Natural Language Processing;Linux;ontology;dataset;openCAESAR},
  doi={10.1109/MODELS-C59198.2023.00101},
  ISSN={},
  month={Oct},}@ARTICLE{10433728,
  author={Pan, Yudai and Liu, Jun and Zhao, Tianzhe and Zhang, Lingling and Wang, Qianying},
  journal={IEEE Transactions on Knowledge and Data Engineering}, 
  title={Context-Aware Commonsense Knowledge Graph Reasoning With Path-Guided Explanations}, 
  year={2024},
  volume={36},
  number={8},
  pages={3725-3738},
  abstract={Commonsense knowledge graphs (CKGs) store massive commonsense knowledge as triples whose nodes consist of free-form texts. CKG reasoning aims to predict missing nodes in incomplete commonsense triples, which is challenging as it requires more accurate embeddings for reasoning. Compared to conventional knowledge graphs (KGs), CKGs have deficient structural information due to their sparsity and contain nodes indistinguishable due to the conceptual diversity. These issues limit the performance of previous reasoning methods, because they face difficulties obtaining precise CKG representations. To address these issues, we propose a context-aware CKG reasoning framework with path-guided explanations, named CoRPe. First, CoRPe constructs context sentences based on the target commonsense triple using designed templates. The context captures reasoning paths instantiated from the first-order logic. Second, to improve CKG representations, CoRPe injects context semantics and employs a context-augmented tuning strategy on a pre-trained language model (PLM) via a synergistic optimization. Finally, CoRPe embeds structural information using a graph convolutional network (GCN) and associates the textual semantics for joint scoring. Extensive experiments on two CKGs show that CoRPe outperforms state-of-the-art KG and CKG reasoning baselines in terms of embedding and reasoning performance. Furthermore, the interpretability of CoRPe is reflected in the implicit logic during reasoning.},
  keywords={Semantics;Commonsense reasoning;Task analysis;Knowledge graphs;Tuning;Electronic mail;Education;Commonsense knowledge graph reasoning;representation learning;context-augmented tuning;first-order logic},
  doi={10.1109/TKDE.2024.3365103},
  ISSN={1558-2191},
  month={Aug},}@INPROCEEDINGS{10066745,
  author={Kaneda, Ryoya and Okada, Makoto and Mori, Naoki},
  booktitle={2023 IEEE 17th International Conference on Semantic Computing (ICSC)}, 
  title={A Method to Constract a Masked Knowlege Graph Model using Transformer for Knowledge Graph Reasoning}, 
  year={2023},
  volume={},
  number={},
  pages={298-299},
  abstract={Most of the previous methods using machine learning for this challenge generate a new knowledge graph from the original one, and some information is lost in the process of creating a new knowledge graph. Therefore, we proposed a new model to estimate the criminal without changing the original knowledge graph. The proposed model uses a Transformer and allows the estimation of unknown criminals in nonexistent scenes by learning similar to Masked Language Modeling in BERT. This model, which uses the original knowledge graph, is expected to infer information about the crime scene at the same time as predicting the criminal. We confirmed by experiments that the model had gained the ability to estimate the hidden story parts by considering the surrounding stories.},
  keywords={Computational modeling;Semantics;Bit error rate;Estimation;Knowledge graphs;Machine learning;Predictive models;Knowledge Graph;Transformer;Masked learning},
  doi={10.1109/ICSC56153.2023.00061},
  ISSN={2325-6516},
  month={Feb},}@INPROCEEDINGS{10195092,
  author={Roy, Kaushik and Garg, Tarun and Palit, Vedant},
  booktitle={2023 IEEE Conference on Artificial Intelligence (CAI)}, 
  title={Knowledge Graph Guided Semantic Evaluation of Language Models For User Trust}, 
  year={2023},
  volume={},
  number={},
  pages={234-236},
  abstract={A fundamental question in natural language processing is - what kind of language structure and semantics is the language model capturing? Graph formats such as knowledge graphs are easy to evaluate as they explicitly express language semantics and structure. This study evaluates the semantics encoded in the self-attention transformers by leveraging explicit knowledge graph structures. We propose novel metrics to measure the reconstruction error when providing graph path sequences from a knowledge graph and trying to reproduce/reconstruct the same from the outputs of the self-attention transformer models. The opacity of language models has an immense bearing on societal issues of trust and explainable decision outcomes. Our findings suggest that language models are models of stochastic control processes for plausible language pattern generation. However, they do not ascribe object and concept-level meaning and semantics to the learned stochastic patterns such as those described in knowledge graphs. This has significant application-level user trust implications as stochastic patterns without a strong sense of meaning cannot be trusted in high-stakes applications.},
  keywords={Semantics;Measurement uncertainty;Stochastic processes;Process control;Knowledge graphs;Medical services;Predictive models;Knowledge Graph;Graph Neural Networks;Transformers},
  doi={10.1109/CAI54212.2023.00108},
  ISSN={},
  month={June},}@INPROCEEDINGS{10020568,
  author={An, Yuan and Greenberg, Jane and Hu, Xiaohua and Kalinowski, Alex and Fang, Xiao and Zhao, Xintong and McCLellan, Scott and Uribe-Romo, Fernando J. and Langlois, Kyle and Furst, Jacob and Gómez-Gualdrón, Diego A. and Fajardo-Rojas, Fernando and Ardila, Katherine and Saikin, Semion K. and Harper, Corey A. and Daniel, Ron},
  booktitle={2022 IEEE International Conference on Big Data (Big Data)}, 
  title={Exploring Pre-Trained Language Models to Build Knowledge Graph for Metal-Organic Frameworks (MOFs)}, 
  year={2022},
  volume={},
  number={},
  pages={3651-3658},
  abstract={Building a knowledge graph is a time-consuming and costly process which often applies complex natural language processing (NLP) methods for extracting knowledge graph triples from text corpora. Pre-trained large Language Models (PLM) have emerged as a crucial type of approach that provides readily available knowledge for a range of AI applications. However, it is unclear whether it is feasible to construct domain-specific knowledge graphs from PLMs. Motivated by the capacity of knowledge graphs to accelerate data-driven materials discovery, we explored a set of state-of-the-art pre-trained general-purpose and domain-specific language models to extract knowledge triples for metal-organic frameworks (MOFs). We created a knowledge graph benchmark with 7 relations for 1248 published MOF synonyms. Our experimental results showed that domain-specific PLMs consistently outperformed the general-purpose PLMs for predicting MOF related triples. The overall benchmarking results, however, show that using the present PLMs to create domain-specific knowledge graphs is still far from being practical, motivating the need to develop more capable and knowledgeable pre-trained language models for particular applications in materials science.},
  keywords={Materials science and technology;Big Data;Benchmark testing;Natural language processing;Data models;Artificial intelligence;Domain specific languages;Knowledge Graph;Pre-trained Language Model;Prompt Probing;Materials Science;Metal-Organic Frameworks},
  doi={10.1109/BigData55660.2022.10020568},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{8945003,
  author={Nardi, Julio Cesar and Almeida, João Paulo A. and da Silva, Paulo Henrique A. and Guizzardi, Giancarlo},
  booktitle={2019 IEEE 23rd International Enterprise Distributed Object Computing Conference (EDOC)}, 
  title={An Ontology-Based Diagnosis of Mainstream Service Modeling Languages}, 
  year={2019},
  volume={},
  number={},
  pages={112-121},
  abstract={This paper presents a diagnosis of mainstream service modeling languages (SoaML, USDL, and ArchiMate) in light of UFO-S, a reference ontology for services. UFO-S is intended as a broad ontology for service phenomena, harmonizing different perspectives on services (e.g., "service as commitment", and "service as capability"), and addressing several phases of the service lifecycle (service offering, service agreement, and service delivery). As result, UFO-S is used as an "analysis theory" to identify choices in these languages concerning their focus and coverage of service phenomena. We identify a number of possible improvements concerning the representation of service participant (roles), the description of service offerings, service agreements and service delivery.},
  keywords={Computational modeling;Conferences;Ontologies;service modeling languages;service ontology;SoaML;USDL;ArchiMate},
  doi={10.1109/EDOC.2019.00023},
  ISSN={2325-6362},
  month={Oct},}@INPROCEEDINGS{10112187,
  author={Saraswat, Deepak},
  booktitle={2023 6th International Conference on Information Systems and Computer Networks (ISCON)}, 
  title={Ontology Based Agriculture Data Mining using IWO and RNN}, 
  year={2023},
  volume={},
  number={},
  pages={1-8},
  abstract={An ontology is a machine-interpretable formal description of domain knowledge. In current years, ontologies have risen to prominence as a key tool for demonstrating domain knowledge and a key element of several knowledge management systems, decision-support systems (DSS) and other intelligent systems including in agriculture. However, a study of the current literature on agricultural ontologies suggests that the majority of research that suggest agricultural ontologies lack a clear assessment mechanism. This is unwanted because this is impossible to assess the value of ontologies in research and practise without well-structured assessment mechanisms. Furthermore, relying on such ontologies and sharing them on the Semantic Web or amongst semantic-aware apps is problematic. This paper presents a framework for selecting appropriate assessment techniques for Ontology Based Agriculture Data Mining utilizing Invasive Weed Optimization (IWO) and Re-current Neural Network (RNN) that appears to be absent from most recent agricultural ontology research. The framework facilitates the selection of relevant evaluation techniques for a particular ontology based on its intended user.},
  keywords={Decision support systems;Semantic Web;Knowledge engineering;Recurrent neural networks;Prototypes;Ontologies;Agriculture;Data Mining;Ontology;IWO;RNN;Agriculture 4.0;Agriculture 5.0},
  doi={10.1109/ISCON57294.2023.10112187},
  ISSN={2832-143X},
  month={March},}@INPROCEEDINGS{10605389,
  author={Schoch, Nicolai and Hoernicke, Mario},
  booktitle={2024 IEEE Conference on Artificial Intelligence (CAI)}, 
  title={NL2IBE – Ontology-controlled Transformation of Natural Language into Formalized Engineering Artefacts}, 
  year={2024},
  volume={},
  number={},
  pages={997-1004},
  abstract={Looking at Process and Automation Engineering (P&AE) today, for the technically adept engineer, there are many different tools available to support the engineering work from translation of engineering intentions into module and plant descriptions, to definition and parametrization of entire process plant setups, for export to a control system. However, still today, in the very early engineering phases, engineering intentions either need to be entered already in a structured and controlled expert language or require a human expert’s manual efforts for translation from unstructured language into formalized representations, in order for thereon-based consistent further processing in the existing tools. This process is time-consuming, fuzzy, and error-prone due to potential misconceptions and ambiguities, even for domain experts. In this work, we therefore present our NL2IBE Tool, which makes use of modern Natural Language Processing in combination with Ontology Mining, and which, based on and controlled by an underlying ontology, allows for the deterministic transformation of natural language intentions into structured and consistent engineering artefacts. We describe the overall tool architecture as well as crucial functionalities and implementation features, followed by an evaluation by the example of a hydrogen generation and CCSU use case. We conclude with a discussion of the proposed tool and give an outlook on future research. (Abstract)},
  keywords={Automation;Hydrogen;Process control;Manuals;Ontologies;Control systems;Natural language processing;process &Amp; automation engineering;intend-based engineering;natural language processing;NLP;generative AI;ontological domain representation},
  doi={10.1109/CAI59869.2024.00182},
  ISSN={},
  month={June},}@INPROCEEDINGS{10353415,
  author={Bhuvanesh Shathyan, R and Begam, M. Farida and Jashwanth, K and Jayaprakash, Anirudh},
  booktitle={2023 4th IEEE Global Conference for Advancement in Technology (GCAT)}, 
  title={Knowledge Graph Based Medical Chatbot building}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={To have a good and unproblematic life without any health risks, it is very important to get medical advice on any health-related problems. However, getting medical advice incurs costs. Chatbots are AI/ML based software which may be trained with a lot of inquiries and responses and match users’ inquiries against a large repository of evidence-based medical data to provide simple answers. To reduce the healthcare costs and improve accessibility of medical knowledge a medical chatbot can be built using ML and NLP techniques. In the existing system of such chatbots several databases are connected together using join statements making it more complicated to access the data. The medical knowledge is vast and varied hence giving many disadvantages to use fixed schema. In this paper we have proposed a knowledge graph based method of chatbot creation for the healthcare field. When the patient enters the symptoms, they are suffering from, then chatbot evaluates and based on the evaluation recognizes the disease. The basic idea of our work is to build a chatbot which can evaluate the symptoms and using this evaluation, rank the possible disease which the patient could be suffering from. The chatbot gets its knowledge from a knowledge graph built on an extensive TigerGraph database. The data from the TigerGraph database can be accessed using different analysis queries. The chatbot will be considered profitable only when it can diagnose all kinds of disease and provides the necessary advice measures to be taken. The knowledge graph used here can be improvised by including results from lab tests to arrive at a better diagnosis and increase the precautions by including the medicines to be taken. The chatbot can only be as smart as the knowledge graph database and hence the evaluations made must be checked with the medical professional. The chatbot has good accuracy in predicting the disease the user is suffering from.},
  keywords={Costs;Databases;Computational modeling;Web pages;Knowledge graphs;Medical services;Predictive models;Knowledge Graph;Rasa;TigerGraph;Random Forest Classifier},
  doi={10.1109/GCAT59970.2023.10353415},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10743169,
  author={Ye, Weiqi and Zhang, Qiang and Zhou, Xian and Hu, Wenpeng and Tian, Changhai and Cheng, Jiajun},
  booktitle={2024 International Conference on Computational Linguistics and Natural Language Processing (CLNLP)}, 
  title={Correcting Factual Errors in LLMs via Inference Paths Based on Knowledge Graph}, 
  year={2024},
  volume={},
  number={},
  pages={12-16},
  abstract={Large language models (LLMs) have been observed to occasionally exhibit hallucination, a phenomenon where they generate statements unsupported by factual evidence, thereby compromising the trustworthiness of their output. Current approaches to mitigating this problem largely rely on extracting a single triplet from a knowledge graph, which fails to adequately capture the complex and interlinked nature of factual reasoning. In an effort to address this critical challenge, this paper delves into the utilization of inference paths based on knowledge graph for factual error correction of LLMs. At the heart of our approach lies the deployment of deep reinforcement learning algorithms, which traverse the knowledge graph to retrieve inference paths. These paths, replete with contextual depth and logical coherence, thereby amending the content and diminishing the incidence of factual discrepancies in the reasoning process of LLMs. Experimental results demonstrate that our approach markedly enhances the factual QA performance of LLMs. Furthermore, it shows great potential in improving the reliability of LLMs in complex reasoning scenarios, highlighting the effectiveness of inference path derived from knowledge graph.},
  keywords={Heart;Large language models;Knowledge graphs;Deep reinforcement learning;Cognition;Natural language processing;Inference algorithms;Error correction;Computational linguistics;Reliability;factual error correction;inference path;knowledge graph;reinforcement learning},
  doi={10.1109/CLNLP64123.2024.00011},
  ISSN={},
  month={July},}@INPROCEEDINGS{10475642,
  author={Fukuda, Ken and Ugai, Takanori and Egami, Shusaku and Matsushita, Kyoumoto},
  booktitle={2024 IEEE 18th International Conference on Semantic Computing (ICSC)}, 
  title={Zero-Shot Query Experiments in Knowledge Graph Reasoning Challenge for Older Adults Safety}, 
  year={2024},
  volume={},
  number={},
  pages={301-305},
  abstract={The 2nd International Knowledge Graph Reasoning Challenge involves social issues focusing on the safety of older adults in their homes. The challenge aims to extract statistical information related to actions and objects that pose risks to daily life. To answer each question in a video, we used Video-LLaVa, a large-scale visual language model (LVLM), using two approaches. The first approach involves inputting question text and video into Video-LLaVa. In this paper, we describe the results of zero-shot queries. The second approach is to obtain a detailed description of the video output using Video-LLaVa and then answer questions based on it. We have yet to achieve good results with these approaches, but we have identified some issues that we will discuss along with the results.},
  keywords={Visualization;Semantics;Focusing;Knowledge graphs;Cognition;Safety;Data mining;Knowledge Graph Reasoning Challenge},
  doi={10.1109/ICSC59802.2024.00054},
  ISSN={2472-9671},
  month={Feb},}@INPROCEEDINGS{10386048,
  author={Guo, Kuo and Li, Yifan and Chen, Hao and Shen, Hong-Bin and Yang, Yang},
  booktitle={2023 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)}, 
  title={Isoform Function Prediction Based on Heterogeneous Graph Attention Networks}, 
  year={2023},
  volume={},
  number={},
  pages={522-527},
  abstract={Isoforms refer to different mRNA molecules transcribed from the same gene, which can be translated into proteins with varying structures and functions. Predicting the functions of isoforms is an essential topic in bioinformatics as it can provide valuable insights into the intricate mechanisms of gene regulation and biological processes. Conventionally, gene function labels are standardized in Gene Ontology (GO) terms. However, traditional methods for predicting isoform function are largely limited by the absence of isoform-specific labels, sparse annotations, and the vast number of GO terms. To address these issues, we propose HANIso, a deep learning-based method for isoform function prediction. HANIso leverages a pretrained protein language model to extract features from protein sequences. It also integrates heterogeneous information, such as isoform sequence features, GO annotations, and isoform interaction data, using a Heterogeneous Graph Attention Network (HAN). This allows the model to learn the importance of different sources of information and their semantic relationships through the attention mechanism. Our method can predict function labels at both the gene level and isoform level. We conduct experiments on two species datasets, and the results demonstrate that our method outperforms existing methods on both AUROC and AUPRC. HANIso has the potential to overcome the limitations of traditional methods and provide a more accurate and comprehensive understanding of isoform function.},
  keywords={Proteins;Annotations;Biological system modeling;Semantics;Predictive models;Ontologies;Feature extraction;alternative splicing;isoform function prediction;protein language model;gene ontology;heterogeneous graph attention network},
  doi={10.1109/BIBM58861.2023.10386048},
  ISSN={2156-1133},
  month={Dec},}@ARTICLE{9534721,
  author={Lu, Jinzhi and Ma, Junda and Zheng, Xiaochen and Wang, Guoxin and Li, Han and Kiritsis, Dimitris},
  journal={IEEE Systems Journal}, 
  title={Design Ontology Supporting Model-Based Systems Engineering Formalisms}, 
  year={2022},
  volume={16},
  number={4},
  pages={5465-5476},
  abstract={Model-based systems engineering (MBSE) provides an important capability for managing the complexities of system development. MBSE empowers the formalism of system architectures for supporting model-based requirement elicitation, specification, design, development, testing, fielding, etc. However, the modeling languages and techniques are heterogeneous, even within the same enterprise system, which leads to difficulties for data interoperability. The discrepancies among data structures and language syntaxes make information exchange among MBSE models more difficult, resulting in considerable information deviations when connecting data flows across the enterprise. Therefore, this article presents an ontology based upon graphs, objects, points, properties, roles, and relationships with extensions (GOPPRRE), providing metamodels that support the various MBSE formalisms across lifecycle stages. In particular, knowledge graph models are developed to support unified model representations to further implement ontological data integration based on GOPPRRE throughout the entire lifecycle. The applicability of the MBSE formalism is verified using quantitative and qualitative approaches. Moreover, the GOPPRRE ontologies are used to create the MBSE formalisms in a domain-specific modeling tool, MetaGraph, for evaluating its availability. The results demonstrate that the proposed ontology supports the formal structures and descriptive logic of the systems engineering lifecycle.},
  keywords={Modeling;Ontologies;Unified modeling language;Tools;Systems engineering and theory;Semantics;Data models;Formalism;interoperability;knowledge graph;model-based systems engineering;ontology},
  doi={10.1109/JSYST.2021.3106195},
  ISSN={1937-9234},
  month={Dec},}@INPROCEEDINGS{9194505,
  author={Jiang, Xuhui and Shen, Yinghan and Wang, Yuanzhuo and Jin, Xiaolong and Cheng, Xueqi},
  booktitle={2020 IEEE International Conference on Knowledge Graph (ICKG)}, 
  title={BaKGraSTeC: A Background Knowledge Graph Based Method for Short Text Classification}, 
  year={2020},
  volume={},
  number={},
  pages={360-366},
  abstract={Short text classification is an important task in the area of natural language processing. Recent studies attempt to employ external knowledge to improve classification performance, but they ignore the correlation between external knowledge and have poor interpretability. This paper proposes a novel Background Knowledge Graph based method for Short Text Classification called BaKGraSTeC for short, which can not only employ external knowledge from a knowledge graph to enrich text information, but also utilize its structural information through a graph neural network to promote the understanding of texts. Specifically, we construct a background knowledge graph based on training data, then we propose a novel architecture that integrates background knowledge graph into a graph neural network to model and capture implicit interactions between its concepts and classes. Besides, we propose an attention mechanism considering both similarity and co-occurrence between concepts and classes to identify the informative concepts in texts. Our experimental results demonstrate the effectiveness with good interpretability of BaKGraSTeC through using external knowledge and their structural information for short text classification.},
  keywords={Knowledge engineering;Neural networks;Task analysis;Semantics;Natural language processing;Syntactics;Machine learning;knowledge graph;short text;attention mechanism;graph neural network.},
  doi={10.1109/ICBK50248.2020.00058},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10581693,
  author={Li, Zhidong and Wang, Licai and Luo, Qibin and Qiao, Silong},
  booktitle={2024 5th International Seminar on Artificial Intelligence, Networking and Information Technology (AINIT)}, 
  title={Large Language Model Based on Full-Text Retrieval for Temporal Knowledge Q&A Approach}, 
  year={2024},
  volume={},
  number={},
  pages={441-446},
  abstract={Knowledge Q&A is one of the hot research topics in the field of natural language processing, and temporal knowledge Q&A is a difficult area of Q&A reasoning because it also needs to consider the temporal relationship of knowledge. Today's research usually focuses on the word vector similarity between knowledge and questions as an important basis for answering, while ignoring the sentence granularity semantic information embedded in the knowledge. In this paper, we propose a method of temporal knowledge Q&A for large language models based on full-text retrieval, firstly, the sentence granularity knowledge recall is performed by Elasticsearch so that large language models can learn the knowledge that is highly relevant to the problem, and then verify the temporal knowledge Q&A ability of large language models under Zero-shot, One-shot and Few-shot. The experiments were conducted on the ICEWS05-15 dataset, and the accuracy of answers was significantly improved, demonstrating the effectiveness of the temporal knowledge Q&A method for large language models based on Elasticsearch.},
  keywords={Seminars;Knowledge engineering;Accuracy;Large language models;Semantics;Knowledge graphs;Vectors;temporal knowledge graph question-answering;large language models;prompt learning;natural language processing},
  doi={10.1109/AINIT61980.2024.10581693},
  ISSN={},
  month={March},}@INPROCEEDINGS{10803797,
  author={Kireev, Vasily and Vasiliev, Feodosiy},
  booktitle={2024 6th International Conference on Control Systems, Mathematical Modeling, Automation and Energy Efficiency (SUMMA)}, 
  title={Development of a Tool for Constructing a Knowledge Graph Using Gan}, 
  year={2024},
  volume={},
  number={},
  pages={720-723},
  abstract={The main objective of this research was to develop a tool capable of automatically extracting and structuring information from textual data using generative networks to construct knowledge graphs. The developed tool demonstrated high efficiency in automating the extraction and transformation of text into RDF triplets, ensuring accurate and complete knowledge graph construction. Testing on various text datasets confirmed its high performance and precision. The created model enables automation of information processing and can be applied across different domains to solve knowledge graph construction tasks.},
  keywords={Automation;Accuracy;Scalability;Process control;Knowledge graphs;Resource description framework;Mathematical models;Data models;Data mining;Testing;Knowledge graph;LLM;NLP;automation},
  doi={10.1109/SUMMA64428.2024.10803797},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10632664,
  author={Huang, Weichun and Xiao, Gang and Yang, Jian and Hu, Xinyu},
  booktitle={2023 11th International Conference on Information Technology: IoT and Smart City (ITIoTSC)}, 
  title={Domain Terminology Knowledge Graph Completion Method Based on Bert}, 
  year={2023},
  volume={},
  number={},
  pages={1-4},
  abstract={Domain terminology knowledge graphs play a critical role in many applications such as text retrieval and information extraction. However, most domain knowledge graphs are constructed manually and often be incomplete on the relation. To this end, we propose a bert-based relational prediction model, which extract relations between entities automatically. Concretely, we utilize the definition of domain terminologies as context of BERT and add special characters to the input of the model to capture the semantic features of domain terms. Through this method, the model can effectively obtain the semantic information of terminology definition and predict the relationship between them. The experimental results demonstrate that our model achieves significant improvement over the baselines on the domain-specific dataset.},
  keywords={Terminology;Smart cities;Semantics;Knowledge graphs;Tail;Predictive models;Feature extraction;Domain Terminology;Bert;Relation Prediction},
  doi={10.1109/ITIoTSC60379.2023.00007},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{9549978,
  author={Hao, Nan and Xie, Pengwei and Chen, Bo},
  booktitle={2021 40th Chinese Control Conference (CCC)}, 
  title={Research on Intent-Slot Recognition Algorithm Based on Knowledge Graph and User Topic}, 
  year={2021},
  volume={},
  number={},
  pages={7276-7281},
  abstract={In this article, we propose a joint recognition method of intention and slot. The model can directly obtain the user's intention and slot information through the user's historical interaction information, knowledge graph and current input. In this method, we first use a knowledge reasoning module based on user topic and knowledge graph. The topic model is used to filter the user's historical information, remove meaningless chat information, retain the most important topic information, and further obtain the external information vector from the knowledge graph which is helpful for current intention recognition and slot filling. In addition, we use attention mechanism modules to fuse the historical information, external knowledge vector and sentence features, and suppress the invalid part of external information. Experiments on the data sets show that our method can effectively improve the accuracy of intention recognition and F value of slot filling.},
  keywords={Fuses;Transforms;Filtering algorithms;Information filters;Filling;Cognition;Intent recognition;Knowledge graph;User topic;Slot filling},
  doi={10.23919/CCC52363.2021.9549978},
  ISSN={1934-1768},
  month={July},}@INPROCEEDINGS{10020882,
  author={Hsiao, Yi-Hao and Chuang, Chia-Yi and Huang, Megn-Chi and Yang, Chia-Lee and Wu, Jyh-Horng},
  booktitle={2022 IEEE International Conference on Big Data (Big Data)}, 
  title={Using Contextual Text Mining and Ontology Methods to Establish a Novel Technology Trend and Associative Analysis Framework for Sustainable Energy Development in Taiwan}, 
  year={2022},
  volume={},
  number={},
  pages={4491-4494},
  abstract={In 2015, the United Nations proposed 17 Sustainable Development Goals, SDGs, as the guidelines for all countries in the world to promote sustainable development before 2030. Government Research Bulletin (GRB), the research projects and technical reports sponsored by government, which has long-term, numerous, complete research method, technology development and policy analysis information in Taiwan. Therefore, it is an important and effective way to explore SDG-related information from a large amount of GRB text. In this paper, a novel technologies trend and associative analysis framework which uses contextual text mining and ontology methods is proposed and applied to SDG 7, which "Affordable and Clean Energy". First, we integrate dictionary-based method and semantic textual similarity analysis algorithm to obtain a SDG 7 classifier which can exactly and quickly classify a large amount number of GRB text to SDG 7. Then, two major SDG 7 analysis procedures based on the classification results are implemented. One is using contextual text mining algorithm to obtain energy technologies trend information. The other is adopting ontology method to establish energy technologies associative analysis concept map. According to the analysis results mentioned above, we are able to efficiently incorporate the energy technology with long-term trend, energy technology associative information, and the most influential authors on the specify energy technology in order to generate a global strategy for continuous improvement in Taiwan.},
  keywords={Text mining;Government;Semantics;Ontologies;Big Data;Writing;Market research;Contextual text mining;Ontology;SBERTs;Sustainable Development Goals (SDGs)},
  doi={10.1109/BigData55660.2022.10020882},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{8901302,
  author={Rui, Jiang},
  booktitle={2019 International Conference on Smart Grid and Electrical Automation (ICSGEA)}, 
  title={Research on Semantic Service Technology in Mobile Geographic Information System}, 
  year={2019},
  volume={},
  number={},
  pages={304-307},
  abstract={This paper combines the conceptual construction and classification methods of geo-ontology, explores the method of formal description language to express geo-domain ontology concepts, and defines the concept of geo-ontology in the process of geo-spatial information semantic expression. Controposing to the problem of inadequate description of spatial information services by traditional description methods, Construction of spatial information application ontology with Protege tool and description service information with OWL-S description language are adopted, to realize the semantic integration between geo-information system. It constructs spatial information application ontology and describes service information with OWL-S description language. The elements of service quality are expanded to improve the comprehensiveness of service description. To verify the feasibility of the combination of theory and practical application of geo-ontology, a mobile GIS is developed from the bottom under the support of current mobile development technology, and an example of spatial semantic retrieval is tested. The superiority of geo-ontology in semantic retrieval is verified, which has important theoretical and practical significance.},
  keywords={Semantics;Information services;Ontologies;Tools;Topology;Smart grids;Geographic information systems;semantic service;GIS;OWL;ontology;Protege},
  doi={10.1109/ICSGEA.2019.00076},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{7930204,
  author={Hoppe, Tobias and Eisenmann, Harald and Viehl, Alexander and Bringmann, Oliver},
  booktitle={2017 IEEE International Conference on Software Architecture (ICSA)}, 
  title={Digital Space Systems Engineering through Semantic Data Models}, 
  year={2017},
  volume={},
  number={},
  pages={93-96},
  abstract={Model-based Systems Engineering requires an intuitive semantically strong data model to enable precise data specification and provide the foundation for fruitful data analyses during data evolution. This paper presents an approach to use the Web Ontology Language (OWL) for specifying a Conceptual Data Model (CDM) being transformed into a format understandable by the Eclipse Modeling Framework (EMF) to profit from powerful data handling and knowledge management functions during runtime. Coalescing OWL with EMF brings up the strength of both approaches leading to considerably better data models with less failure potential and reveal notably more analysis potential by using a common data model specification. This approach also enables the direct application of reasoning functionality for automatic inference of several pieces of knowledge and automatic checks as illustrated by examples from aerospace industry.},
  keywords={Data models;Ontologies;Unified modeling language;OWL;Semantics;Model-based Systems Engineering;Conceptual Data Model Implementation;Eclipse Modeling Framework;Ontology},
  doi={10.1109/ICSA.2017.35},
  ISSN={},
  month={April},}@INPROCEEDINGS{10415662,
  author={Liu, Kangzheng and Zhao, Feng and Xu, Guandong and Wu, Shiqing},
  booktitle={2023 IEEE International Conference on Data Mining (ICDM)}, 
  title={IE-Evo: Internal and External Evolution-Enhanced Temporal Knowledge Graph Forecasting}, 
  year={2023},
  volume={},
  number={},
  pages={408-417},
  abstract={Temporal knowledge graph (TKG) forecasting is widely used in various fields due to its ability to infer future events based on historical information. Modeling the internal structures and chronological dependencies of historical subgraph sequences has been proven effective. Nevertheless, on the one hand, the TKG forecasting process generally suffers from a lack of sufficient sample data due to historical resource limitations; thus, most works focus on continuously mining the patterns of historical sequences while ignoring the semantically-rich background information provided by external knowledge, especially when historical query-related information is scarce. On the other hand, when merely serializing the given subgraph sequence to mimic its temporal evolution process, only the chronological dependencies between the subgraphs can be considered, thus ignoring the evolution of time information. Hence, a method that integrates internal and external knowledge to enhance the representations of entities is urgently needed. To this end, we propose a novel TKG forecasting method, namely, the internal and external evolution-enhanced framework (IE-Evo). For the former issue, we design an external evolution encoder and use a pre-trained language model (PLM) to provide powerful external knowledge semantics for TKG forecasting. To address the latter concern, we propose an internal evolution encoder that explicitly embeds the time information while modeling the aggregation and evolution processes of the observed sequential structural information. IE-Evo has been evaluated on four public benchmark datasets, showcasing its significant improvements across multiple evaluation metrics.},
  keywords={Measurement;Semantics;Knowledge graphs;Predictive models;Data models;Data mining;Forecasting;Temporal knowledge graph extrapolation;External knowledge;Time information evolution},
  doi={10.1109/ICDM58522.2023.00050},
  ISSN={2374-8486},
  month={Dec},}@INPROCEEDINGS{9776230,
  author={Shang, Jialin and Huang, Jingyuan and Zeng, Shihua and Zhang, Jian and Wang, Hongwei},
  booktitle={2022 IEEE 25th International Conference on Computer Supported Cooperative Work in Design (CSCWD)}, 
  title={Representation and Extraction of Physics Knowledge Based on Knowledge Graph and Embedding-Combined Text Classification for Cooperative Learning}, 
  year={2022},
  volume={},
  number={},
  pages={1053-1058},
  abstract={Physical knowledge is the foundation of most engineering fields in particular such as product design, analysis, and operation and maintenance. However, due to the complexity of physical concepts, laws, and calculations, students can be easily overwhelmed by the conceptual ideas in the process of learning physics. This paper proposes a new way for helping students grasp the logical relation between the physics knowledge points based on neural networks and knowledge graph technology. Specifically, we use Python scripts to collect the articles about physics knowledge on the Internet as the raw data. After removing the special characters and other irrelevant text, the rest of the data is passed to several neural networks based on BERT and ERNIE for their effective and efficient classification into seven kinds of physics knowledge. The experimental results show that using ERNIE-BERT for embedding and using RCNN for the downstream model achieve the best performance. Knowledge graph is used to build a tree structure of physics knowledge, holding the physics knowledge picked out by the neural networks under corresponding nodes.},
  keywords={Knowledge engineering;Training;Neural networks;Text categorization;Knowledge based systems;Maintenance engineering;Product design;computer assisted learning;knowledge graph;em-bedding;text classification},
  doi={10.1109/CSCWD54268.2022.9776230},
  ISSN={},
  month={May},}@INPROCEEDINGS{9832371,
  author={Shi, Xiaowen and Yang, Jing and He, Liang},
  booktitle={2022 IEEE 2nd International Conference on Electronic Technology, Communication and Information (ICETCI)}, 
  title={Commonsense Generative Model for Chinese Automatic Knowledge Graph Construction}, 
  year={2022},
  volume={},
  number={},
  pages={20-24},
  abstract={Commonsense knowledge graph support applications in commonsense reasoning, question answering, and so on. However, automatic knowledge graph construction is still a continuing goal for AI researchers due to the difficulty of obtaining tractable and objective commonsense information. Besides, the relative researches have so far been mainly limited to English, making it slow to develop the research of commonsense knowledge in other languages. Previous studies constructed the knowledge bases as the relational schemas which use the expert knowledge, semi-structured text extraction and unstructured text extraction. However, with the way of extraction, these methods can only capture the explicit knowledge mentioned in the text, while the commonsense knowledge in the text is usually implicit. In this paper, we propose a commonsense generative model with a novel attention mechanism and discuss whether pre-trained language models can effectively learn and generate novel knowledge. The empirical results show that our model could generate correct commonsense knowledge with high scores which up to 50.10% precision on ATOMIC dataset humans given.},
  keywords={Training;Adaptation models;Conferences;Knowledge based systems;Question answering (information retrieval);Commonsense reasoning;Commonsense knowledge graph construction;Generative model;Attention mechanism},
  doi={10.1109/ICETCI55101.2022.9832371},
  ISSN={},
  month={May},}@INPROCEEDINGS{10849426,
  author={Yang, Yan and Ye, Feng and Xu, Dong and Zhang, Xuejie and Xu, Jin},
  booktitle={2024 IEEE 36th International Conference on Tools with Artificial Intelligence (ICTAI)}, 
  title={LLM-Based Digital Twin Water Conservancy Knowledge Graph Construction}, 
  year={2024},
  volume={},
  number={},
  pages={656-662},
  abstract={In the study, a novel method for extracting domain-specific knowledge in digital twin water conservancy construction is proposed, addressing the challenges of interdisciplinary complexity and the limitations in existing knowledge extraction models' understanding capabilities of domain-specific knowledge. Utilizing a large language model, the novel method incorporates the domain knowledge of digital twin water conservancy into a local model framework. It employs prompt-based fine-tuning and leverages the semantic understanding and generative capabilities of the model to enhance knowledge extraction precision. To optimize entity extraction, innovative heterogeneous entity alignment strategies are introduced. The efficacy of the proposed method is validated through comparative and ablation studies conducted on a water domain corpus. Results indicate a significant improvement over conventional models, with F1 scores for entity and relationship extraction at 88.63% and 84.46%, respectively, and an entity extraction precision rate of 90.11%. Ablation experiments further demonstrate that our method outperforms the baseline large language model, enhancing the F1 scores for entity and relation extraction by 5.5 and 3.2 percentage points, respectively. By adjusting the amount of domain knowledge injected, the influence of the amount of domain text on the knowledge extraction effect is explored.},
  keywords={Large language models;Semantics;Knowledge graphs;Water conservation;Digital twins;Complexity theory;Personnel;large language model;prompt learning;knowledge graph;knowledge extraction;digital twin water conservancy construction},
  doi={10.1109/ICTAI62512.2024.00098},
  ISSN={2375-0197},
  month={Oct},}@INPROCEEDINGS{10152692,
  author={Ma, Zuyang and Yan, Kaihong and Wang, Hongwei},
  booktitle={2023 26th International Conference on Computer Supported Cooperative Work in Design (CSCWD)}, 
  title={BERT-based Question Answering using Knowledge Graph Embeddings in Nuclear Power Domain}, 
  year={2023},
  volume={},
  number={},
  pages={267-272},
  abstract={In order to improve the resource utilization rate of existing nuclear power data and promote workers to efficiently obtain the operation information of nuclear power units and assist them in fault diagnosis and maintenance decision-making, this paper constructs a knowledge graph question answering (KGQA) dataset in the field of nuclear power. The BEm-KGQA model based on the pre-trained language model and knowledge graph embedding method was proposed. Our model learns the embedded representation of the knowledge graph through BERT and fine-tunes the BERT model. In the question embedding stage, it learns the embedded representation of the question based on the fine-tuned BERT model. Through experiments, we demonstrate the effectiveness of the method over other models. In addition, this paper implements a nuclear power question answering system. Based on the question answering system, employees can learn about unit information and efficiently obtain information on unusual operating events of nuclear power.},
  keywords={Industries;Fault diagnosis;Federated learning;Bit error rate;Decision making;Knowledge graphs;Maintenance engineering;Knowledge Graph Question Answering;KBQA;Knowledge Graph Embedding;BERT;Nuclear Power},
  doi={10.1109/CSCWD57460.2023.10152692},
  ISSN={2768-1904},
  month={May},}@INPROCEEDINGS{10090855,
  author={Tang, Jin and Xu, Chengxian and Zhang, Wanda},
  booktitle={2023 IEEE 2nd International Conference on Electrical Engineering, Big Data and Algorithms (EEBDA)}, 
  title={Construction and Accurate Retrieval Method of Knowledge Graph of Automobile Engine Fault}, 
  year={2023},
  volume={},
  number={},
  pages={336-345},
  abstract={In order to improve the efficiency and accuracy of automobile engine fault maintenance, an accurate retrieval method of automobile engine fault driven by knowledge graph was proposed. Firstly, the definition and framework of knowledge graph are discussed. The entity extraction of engine fault features was carried out by multi-source neural network, and the disambiguation of fault entities was carried out by integrating entity link technologies; Secondly, fault knowledge reasoning is carried out to eliminate the wrong knowledge in the knowledge base and infer new knowledge to form a complete knowledge graph.. On this basis, the retrieval subgraph of engine fault semantics is designed. Combined with the influence of physical distance and proximity, the retrieval result evaluation model is established, and the subgraph matching was carried out based on the similarity calculation of graph structure and semantic information. Finally, four knowledge graphs including entity equipment graph, ontology graph, maintenance rule graph and history graph were constructed by selecting some automobile engine fault cases from 2017 to 2020. Finally, the process architecture of engine fault search and analysis is constructed and the effectiveness of the proposed method was verified by precision rate and recall rata, which provides a new idea for accurate and efficient engine maintenance.},
  keywords={Knowledge engineering;Visualization;Semantic search;Decision making;Knowledge graphs;Maintenance engineering;Feature extraction;engine fault;knowledge graph;entity link;Subgraph matching;semantic search},
  doi={10.1109/EEBDA56825.2023.10090855},
  ISSN={},
  month={Feb},}@INPROCEEDINGS{10722780,
  author={Cheng, Xiyao and Edara, Lakshmi Srinivas and Zhang, Yuanxun and Kejriwal, Mayank and Calyam, Prasad},
  booktitle={2024 IEEE 11th International Conference on Data Science and Advanced Analytics (DSAA)}, 
  title={Influence Role Recognition and LLM-Based Scholar Recommendation in Academic Social Networks}, 
  year={2024},
  volume={},
  number={},
  pages={1-11},
  abstract={Identifying scholars and their relevant publications in interdisciplinary collaborations within an academic social network (ASN) can help drive new scientific knowledge discovery. This involves a challenging and time-consuming process, which requires scholar's influence role recognition in a scholar team for a given research task. In this paper, we propose a novel “ScholarInfluencer” recommendation system that: (a) uses a classification model combined with network analysis on a heterogeneous knowledge graph to recognize the scholar influencers within interdisciplinary teams of collaborators, and (b) features a large language model (LLM) to use influence role recognition results to support user queries to produce pertinent scholar and their publication recommendations. Our novel approach involves building a heterogeneous knowledge graph using diverse ASN datasets involving entities such as scholars, publications, research grants, and the relationship among these entities. We perform an evaluation of ScholarInfluencer using four widely-used ASN datasets (i.e., NSF, DBLP, Cora and CA-HepTh). Our experiment results show that our influence role recognition model outperforms the state-of-the-art models across the different datasets; especially in the case of the NSF dataset, our model outperforms by up to 13.6%. Further, we show how our recommendation model with role recognition outperforms the model without role recognition across the different datasets; especially in the case of the NSF dataset, our model outperforms by 7%.},
  keywords={Analytical models;Social networking (online);Large language models;Knowledge graphs;Network analyzers;Medical services;Data models;System implementation;Recommender systems;Portals;heterogeneous knowledge graph;recommender system;large language model;academic social network},
  doi={10.1109/DSAA61799.2024.10722780},
  ISSN={2766-4112},
  month={Oct},}@INPROCEEDINGS{10825744,
  author={Zeng, Zefan and Cheng, Qing and Hu, Xingchen and Liu, Zhong and Shen, Jingke and Zhang, Yahao},
  booktitle={2024 IEEE International Conference on Big Data (BigData)}, 
  title={Aligning the Representation of Knowledge Graph and Large Language Model for Causal Question Answering}, 
  year={2024},
  volume={},
  number={},
  pages={1177-1186},
  abstract={Causal Question Answering (CQA) is essential for knowledge discovery, focusing on the intricate dynamics between events and entities without predefined contexts. Despite advancements of CQA models through Knowledge Graphs (KGs) and Pre-Trained Language Models (PLMs), existing approaches are hindered by knowledge conflict, insufficient capacity, and limitations in information fusion. Large Language Models (LLMs) have significantly improved natural language understanding and reasoning but often suffer from causal hallucinations. To address these challenges, we introduce KLop, a framework that aligns representations of Causal Knowledge Graph (CKG) and Large Language Models for CQA. KLop pre-trains a graph embedding model for entity embedding and uses a frozen LLM for text embedding. The main components of KLop are the descriptor module and the aligner module. The descriptor leverages descriptive texts generated by LLMs to create training data for knowledge alignment, while the aligner utilizes self-attention to train query tokens for modality alignment. Experiments on public CQA datasets validate that KLop outperforms various advanced baselines in reasoning accuracy, as well as achieving causal knowledge integration and joint reasoning.},
  keywords={Accuracy;Large language models;Knowledge based systems;Training data;Focusing;Knowledge graphs;Knowledge discovery;Cognition;Question answering (information retrieval);Optimization;causal question answering;knowledge graph;large language model;reasoning;representation},
  doi={10.1109/BigData62323.2024.10825744},
  ISSN={2573-2978},
  month={Dec},}@INPROCEEDINGS{10076731,
  author={Taru, Uma and Patil, Archana},
  booktitle={2022 International Conference on Machine Learning, Computer Systems and Security (MLCSS)}, 
  title={Building Ontology for Toxic words}, 
  year={2022},
  volume={},
  number={},
  pages={241-246},
  abstract={Many online social media platforms have particular community guidelines for comment sections. The platforms that maintain commentary sections in various posts, videos, and blogs need to adhere to these guidelines. These comment sections may have specific comments that fail to satisfy the rules and regulations to maintain societal norms of communication. These comments are classified as toxic comments. Google's Perspective API defines toxic comments as comments that are rude, offensive, and likely to make someone leave the conversation. In this paper, we have built a toxic words ontology, which is as per our knowledge, first Ontology built on toxic words. This Ontology consists of toxic words and their antonyms and synonyms in increasing order of their toxicity levels. Traversing this ontology, we can find the best-suited word with less toxicity and similar meaning. This is a dynamic ontology and new words can be added easily. Thus letting us convey messages in a civil manner. We propose to reduce toxicity in the most straightforward way. After studying several papers, we found out that the toxicity mainly occurs because of use of toxic words. We also observed that use of less toxic synonyms or no toxic synonyms has huge effects on toxicity score given by the Perspective API, and results section proves that.},
  keywords={Toxicology;Social networking (online);Oral communication;Machine learning;Ontologies;Regulation;Internet;toxicity;ontology;similarity;antonyms;synonyms},
  doi={10.1109/MLCSS57186.2022.00052},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10597678,
  author={Wang, Yubo and Xin, Hao and Chen, Lei},
  booktitle={2024 IEEE 40th International Conference on Data Engineering (ICDE)}, 
  title={KGLink: A Column Type Annotation Method that Combines Knowledge Graph and Pre-Trained Language Model}, 
  year={2024},
  volume={},
  number={},
  pages={1023-1035},
  abstract={The semantic annotation of tabular data plays a crucial role in various downstream tasks. Previous research has proposed knowledge graph (KG)-based and deep learning-based methods, each with its inherent limitations. KG-based methods encounter difficulties annotating columns when there is no match for column cells in the KG. Moreover, KG-based methods can provide multiple predictions for one column, making it challenging to determine the semantic type with the most suitable granularity for the dataset. This type granularity issue limits their scalability. On the other hand, deep learning-based methods face challenges related to the valuable context missing issue. This occurs when the information within the table is insufficient for determining the correct column type. This paper presents KGLink, a method that combines Wiki-Data KG information with a pre-trained deep learning language model for table column annotation, effectively addressing both type granularity and valuable context missing issues. Through comprehensive experiments on widely used tabular datasets encompassing numeric and string columns with varying type granularity, we showcase the effectiveness and efficiency of KGLink. By leveraging the strengths of KGLink, we successfully surmount challenges related to type granularity and valuable context issues, establishing it as a robust solution for the semantic annotation of tabular data.},
  keywords={Learning systems;Deep learning;Knowledge engineering;Annotations;Semantics;Training data;Knowledge graphs;knowledge graph;column type annotation;data mining},
  doi={10.1109/ICDE60146.2024.00083},
  ISSN={2375-026X},
  month={May},}@INPROCEEDINGS{9362652,
  author={Yu, Jianyou and Sun, Jian and Dong, Yunchang and Zhao, Dezhi and Chen, Xiaoyu and Chen, Xianghong},
  booktitle={2021 IEEE International Conference on Power Electronics, Computer Applications (ICPECA)}, 
  title={Entity recognition model of power safety regulations knowledge graph based on BERT-BiLSTM-CRF}, 
  year={2021},
  volume={},
  number={},
  pages={49-53},
  abstract={In the process of constructing the knowledge graph of power safety regulations, the traditional named entity recognition method is difficult to effectively identify the key information of the entity because the boundary of the power safety entity is fuzzy and difficult to define. Therefore, this paper proposes a power safety named entity recognition model based on BERT-BiLSTM-CRF. First, the word vector expression layer based on Transformer's bidirectional encoder (BERT) obtains word-level features; then the bidirectional long-short-term memory neural network (BiLSTM) layer is used to extract contextual features to form a feature matrix, thereby improving the accuracy of text feature extraction; The optimal tag sequence is generated by the conditional random field layer (CRF), and the output result is corrected. Through the analysis of experimental examples, the validity and superiority of the proposed model are verified.},
  keywords={Analytical models;Computational modeling;Neural networks;Feature extraction;Regulation;Power electronics;Safety;knowledge of power safety regulations;entity recognition;knowledge graph;machine learning},
  doi={10.1109/ICPECA51329.2021.9362652},
  ISSN={},
  month={Jan},}@INPROCEEDINGS{9393163,
  author={Jia, Huiran and Li, Yuan and Song, Dandan and Wang, Qinglin},
  booktitle={2021 International Bhurban Conference on Applied Sciences and Technologies (IBCAST)}, 
  title={Entity Classification for Military Knowledge Graph based on Baidu Encyclopedia Distance Learning}, 
  year={2021},
  volume={},
  number={},
  pages={366-371},
  abstract={Entity types are a critical enabler for many NLP tasks that use KGs as a reference source. However, Classifying terminological entities without context remains an important outstanding obstacle in the field of KG completion. In this paper, we put forward a method combining distance learning and deep learning to address the classification of entity with no context. We compare the performance of our method with several text classification methods and shows our approach is empirically effective. Furthermore, the experiment result shows our approach can reduce the labeling work cost and expand the entities for further knowledge graph construction.},
  keywords={Deep learning;Industries;Computer aided instruction;Web and internet services;Text categorization;Encyclopedias;Labeling;Entity classification;Distance learning;Web crawler;Military industry knowledge graph},
  doi={10.1109/IBCAST51254.2021.9393163},
  ISSN={2151-1411},
  month={Jan},}@INPROCEEDINGS{9669508,
  author={Han, Xiaosong and Li, Xiaoran and Liang, Yanchun and Wang, Xinghao and Xu, Dong and Guan, Renchu},
  booktitle={2021 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)}, 
  title={Acupuncture and Tuina Knowledge Graph for Ancient Literature of Traditional Chinese Medicine}, 
  year={2021},
  volume={},
  number={},
  pages={674-677},
  abstract={The Traditional Chinese Medicine’s ancient literature recorded the massive medical theories and abundant medical experiences. To better understand and utilize, the knowledge from the literature, the Acupuncture and Tuina Knowledge Graph is proposed in this paper. Meanwhile, a deep learning network is established for acupuncture and tuina-related entity recognition and entity-relationship extraction. Finally, the trained network is able to reach an 82%+ F1-score for NER and 70%+ F1-score for relationship extraction.},
  keywords={Deep learning;Conferences;Labeling;Bioinformatics;Traditional Chinese medicine literature;acupuncture;tuina;named entity recognition;entity relationship extraction;knowledge graph},
  doi={10.1109/BIBM52615.2021.9669508},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10672720,
  author={Liu, Xuan and Liang, Zhirong},
  booktitle={2024 9th International Symposium on Computer and Information Processing Technology (ISCIPT)}, 
  title={Knowledge Distillation Based on Knowledge Graph Data Augmentation}, 
  year={2024},
  volume={},
  number={},
  pages={331-335},
  abstract={Two-stage distillation, as the name suggests, first general distillation using a task-independent general corpus, and then task-specific distillation using an augmented taskspecific corpus, is popular because of its practicality and wide applicability. Currently available data enhancement methods include substituting similar words, adding similar sentences, etc., which we believe do not do a good job of mining the relationships between corpora. There are some obvious relationships between the data, and simply replacing similar words or calculating the similarity between whole sentences does not reveal the relationship between them. We propose a new way of data enhancement, i.e. using knowledge graphs to enrich the corpus. In our experiments, we find that by combining the data augmentation approach with knowledge graphs, we can significantly improve the accuracy of the model, and our approach can improve the model performance faster in the same training time. In addition, we propose a method to vectorise computational similarities in the knowledge graph, which improves computational efficiency. These results suggest that data augmentation using knowledge graphs is a more efficient way to better explore the structure of the data and thus improve model performance.},
  keywords={Training;Accuracy;Computational modeling;Knowledge graphs;Data augmentation;Data models;Computational efficiency;knowledge distillation;knowledge graph;data augmentation;natural language processing},
  doi={10.1109/ISCIPT61983.2024.10672720},
  ISSN={},
  month={May},}@INPROCEEDINGS{10164900,
  author={Qian, Peng and Maalla, Allam and WenHai, He and ShaoQiang, Li},
  booktitle={2023 IEEE 3rd International Conference on Information Technology, Big Data and Artificial Intelligence (ICIBA)}, 
  title={Agricultural Planting Big Data Q & A System Technology Research Based on Knowledge Graph}, 
  year={2023},
  volume={3},
  number={},
  pages={955-959},
  abstract={In the process of agricultural production, planting has the characteristics of decentralization, complexity, seasonal differences, and regional differences, which affects agricultural growers to easily obtain effective planting information to help their own agricultural planting. The purpose of this study is to apply knowledge graph technology and natural language processing technology to the process of agricultural planting, and use the intelligent Q & A system to provide agricultural growers with regional natural conditions and suggestions and decisions of agricultural plant problems. Provide agricultural growers with a new solution for question and answer to high - efficiency and professional crop planting decisions. Finally, the intelligent decision -making and knowledge generation of farming planting, production, and operational process is achieved, and it is agricultural growers and improves farming income and farmland production efficiency. Change the agriculture from “watching the sky” to the intelligent “knowing the sky”.},
  keywords={Training;Computational modeling;Production;Knowledge graphs;Big Data;Data models;Cognition;Agricultural planting;knowledge graph;Natural language processing;Q & A system},
  doi={10.1109/ICIBA56860.2023.10164900},
  ISSN={},
  month={May},}@INPROCEEDINGS{10858986,
  author={Weng, Xinxu and Wang, Yuqing and Weng, Shijing and Xiong, Juan and Weng, Lei},
  booktitle={2024 IEEE 9th International Conference on Data Science in Cyberspace (DSC)}, 
  title={Bibliometric Analysis of Large Language Model Artificial Intelligence Based on Knowledge Graph}, 
  year={2024},
  volume={},
  number={},
  pages={428-434},
  abstract={With the advancement of artificial intelligence technology, large-scale pre-trained language models (LLMs) have emerged as a core component of the field. This paper employs knowledge graph and bibliometric analysis tools to systematically examine and quantify research literature on large language model artificial intelligence. We delve into the evolution of research hotspots, collaboration networks, and keywords, spanning from the inception stage to the rapid development phase. Additionally, through the collaboration networks of countries/regions, research institutions, and researchers, the paper showcases the landscape of collaboration within the field and the evolving frontiers of research.},
  keywords={Deep learning;Large language models;Bibliometrics;Collaboration;Knowledge graphs;Speech recognition;Data science;Natural language processing;Artificial intelligence;Speech processing;Large Language Model;Artificial Intelligence;Knowledge Graph;Bibliometrics;Collaboration Network},
  doi={10.1109/DSC63484.2024.00064},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{9362571,
  author={Gao, Shuo and Xu, Hao and Chen, Zhongmin and Wang, Yongsheng},
  booktitle={2021 IEEE International Conference on Power Electronics, Computer Applications (ICPECA)}, 
  title={Detection Mechanism of News-text matching based on Knowledge Graph}, 
  year={2021},
  volume={},
  number={},
  pages={264-267},
  abstract={Online news is an important means to spread information. However, in order to attract readers, some online news writers often add pictures that have nothing to do with the news content, which seriously affects the credibility of the media. To solve these problems, we propose a news detection mechanism based on the knowledge graph, which can enrich the news image description and use the news image description to calculate the sentence similarity with the news text, so as to identify whether a news belongs to the news image mismatch. The realization of the image-text matching detection mechanism of news enhance the credibility of social media and purify the network environment.},
  keywords={Social networking (online);Semantics;Tools;Syntactics;Media;Power electronics;Security;Knowledge graph;Image captioning;Network ecosystem},
  doi={10.1109/ICPECA51329.2021.9362571},
  ISSN={},
  month={Jan},}@INPROCEEDINGS{9458782,
  author={Zhang, Wen and Wong, Chi-Man and Ye, Ganqiang and Wen, Bo and Zhang, Wei and Chen, Huajun},
  booktitle={2021 IEEE 37th International Conference on Data Engineering (ICDE)}, 
  title={Billion-scale Pre-trained E-commerce Product Knowledge Graph Model}, 
  year={2021},
  volume={},
  number={},
  pages={2476-2487},
  abstract={In recent years, knowledge graphs have been widely applied to organize data in a uniform way and enhance many tasks that require knowledge, for example, online shopping which has greatly facilitated people’s life. As a backbone for online shopping platforms, we built a billion-scale e-commerce product knowledge graph for various item knowledge services such as item recommendation. However, such knowledge services usually include tedious data selection and model design for knowledge infusion, which might bring inappropriate results. Thus, to avoid this problem, we propose a Pre-trained Knowledge Graph Model (PKGM) for our billion-scale e-commerce product knowledge graph, providing item knowledge services in a uniform way for embedding-based models without accessing triple data in the knowledge graph. Notably, PKGM could also complete knowledge graphs during servicing, thereby overcoming the common incompleteness issue in knowledge graphs. We test PKGM in three knowledge-related tasks including item classification, same item identification, and recommendation. Experimental results show PKGM successfully improves the performance of each task.},
  keywords={Knowledge engineering;Conferences;Data engineering;Data models;Electronic commerce;Task analysis;knowledge graph;pre-training;e-commerce},
  doi={10.1109/ICDE51399.2021.00280},
  ISSN={2375-026X},
  month={April},}@INPROCEEDINGS{10780864,
  author={Dominic, Nicholas and Pardamean, Bens},
  booktitle={2024 International Conference on Information Management and Technology (ICIMTech)}, 
  title={Knowledge Graph-Enhanced Semantic Cache for Low-Latency and Cost-Effective Inference in Large Language Models}, 
  year={2024},
  volume={},
  number={},
  pages={340-344},
  abstract={In organizational knowledge management, Large Language Model (LLM) caches act as a semantic repository gathered from previous LLM responses. Due to intensive calls from multiple users, LLM may suffer from high inference latency. While there are many prior available approaches to solve this problem, most of them are inherently complex. This paper introduced a Knowledge Graph-enhanced Semantic Cache mechanism as an alternative, lightweight technique to boost retrieval for similar prompts. The latest state-of-the-art open-source LLM, named Google's Gemma-2B-it, was used to generate sample prompts and responses as a draft, while a knowledge graph (KG) was built from Wikipedia sentences. To create embeddings of prompts and KG, all-MiniLM-L6-v2 from SentenceTransformer was used. This new cache system resulted in up to 28% improvement over a standard model. In particular, reinforcement with KG cache embeddings yielded more than 85% semantic cache accuracy. To map the next trajectory of this pilot study, an overview of the extended framework for LLM knowledge management was also presented in this paper. The framework includes the new KG- enhanced cache system equipped with scalable security and fallback mechanisms that can promote green technology through substantial improvements in latency, throughput, and overall LLM costs.},
  keywords={Large language models;Semantics;Throughput;Knowledge management;Internet;Trajectory;Security;Online services;Low latency communication;Standards;semantic cache;knowledge graph;symmetric similarity search;large language models;green technology},
  doi={10.1109/ICIMTech63123.2024.10780864},
  ISSN={2837-2778},
  month={Aug},}@ARTICLE{8015195,
  author={Schneider, Georg Ferdinand and Pauwels, Pieter and Steiger, Simone},
  journal={IEEE Transactions on Industrial Informatics}, 
  title={Ontology-Based Modeling of Control Logic in Building Automation Systems}, 
  year={2017},
  volume={13},
  number={6},
  pages={3350-3360},
  abstract={The control logic implemented in building automation systems (BAS) has a significant impact on the overall energy demand of the building. However, information on the control logic, if documented, is often concealed from further data integration and reuse in heterogeneous information silos using disparate data formats. In particular, existing data formats and information models offer limited support to describe control logic explicitly. Ontology-based modeling of the control logic of BAS can potentially result in a versatile source of information for information-driven processes to further increase the performance of technical equipment in a building. Therefore, we present a novel information model, CTRLont, which allows to formally specify the domain of control logic in BAS. We demonstrate the usefulness of the novel information model by using it as a knowledge base for automating rule-based verification of designed control logic in BAS. We successfully apply the methodology to a simple control of an air handling unit and indicate a number of future steps.},
  keywords={Automation;Ontologies;Unified modeling language;OWL;Home appliances;Informatics;Process control;Building automation system (BAS);control;ontology;schedule;state graph;state machine},
  doi={10.1109/TII.2017.2743221},
  ISSN={1941-0050},
  month={Dec},}@ARTICLE{10313062,
  author={Zhang, Liyuan and Jiang, Yongquan and Yang, Yan},
  journal={IEEE Transactions on Knowledge and Data Engineering}, 
  title={GNNGO3D: Protein Function Prediction Based on 3D Structure and Functional Hierarchy Learning}, 
  year={2024},
  volume={36},
  number={8},
  pages={3867-3878},
  abstract={Protein sequences accumulate in large quantities, and the traditional method of annotating protein function by experiment has been unable to bridge the gap between annotated proteins and unannotated proteins. Machine learning-based protein function prediction is an effective approach to solve this problem. Most of the existing methods only use the protein sequence but ignore the three-dimensional structure which is closely related to the protein function. And the hierarchy of protein functions is not adequately considered. To solve this problem, we propose a graph neural network (GNNGO3D) that combines the three-dimensional structure and functional hierarchy learning. GNNGO3D simultaneously uses three kinds of information: protein sequence, tertiary structure, and hierarchical relationship of protein function to predict protein function. The novelty of GNNGO3D lies in that it integrates the learning of functional level information into the method of predicting protein function by using tertiary structure information, fully learning the relationship between protein functions, and helping to better predict protein function. Experimental results show that our method is superior to existing methods for predicting protein function based on sequence and structure.},
  keywords={Proteins;Feature extraction;Protein sequence;Three-dimensional displays;Task analysis;Ontologies;Convolutional neural networks;Graph neural networks;gene ontology;language model;machine learning;protein function prediction},
  doi={10.1109/TKDE.2023.3331005},
  ISSN={1558-2191},
  month={Aug},}@INPROCEEDINGS{8710519,
  author={Landolfi, Giuseppe and Bami, Andrea and Izzo, Gabriele and Montini, Elias and Bettoni, Andrea and Vujasinovic, Marko and Gugliotta, Alessio and Soares, Antόnio Lucas and Diogo Silva, Henrique},
  booktitle={2018 International Conference on Intelligent Systems (IS)}, 
  title={An Ontology Based Semantic Data Model Supporting A Maas Digital Platform}, 
  year={2018},
  volume={},
  number={},
  pages={896-904},
  abstract={The integration of IoT infrastructures across production systems, together with the extensive digitalisation of industrial processes, are drastically impacting manufacturing value chains and the business models built on the top of them. By exploiting these capabilities companies are evolving the nature of their businesses shifting value proposition towards models relying on product servitization and share, instead of ownership. In this paper, we describe the semantic data-model developed to support a digital platform fostering the reintroduction in the loop and optimization of unused industrial capacity. Such data-model aims to establish the main propositions of the semantic representation that constitutes the essential nature of the ecosystem to depict their interactions, the flow of resources and exchange of production services. The inference reasoning on the semantic representation of the ecosystem allows to make emerge nontrivial and previously unknown opportunities. This will apply not only to the matching of demand and supply of manufacturing services, but to possible and unpredictable relations. For instance, a particular kind of waste being produced at an ecosystem node can be linked to the requirements for an input material needed in a new product being developed on the platform, or new technologies can be suggested to enhance processes under improvement. The overall architecture and individual ontologies are presented and their usefulness is motivated via the application to use cases.},
  keywords={US Department of Transportation;Technological innovation;Production;Reliability;Manganese;Ions;Stakeholders;servitization;manufacturing ontologies;semantic data-model;knowledge discovery},
  doi={10.1109/IS.2018.8710519},
  ISSN={1541-1672},
  month={Sep.},}@INPROCEEDINGS{10578654,
  author={Abu-Rasheed, Hasan and Weber, Christian and Fathi, Madjid},
  booktitle={2024 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Knowledge Graphs as Context Sources for LLM-Based Explanations of Learning Recommendations}, 
  year={2024},
  volume={},
  number={},
  pages={1-5},
  abstract={In the era of personalized education, the provision of comprehensible explanations for learning recommendations is of great value to enhance the learner's understanding and engagement with the recommended learning content. Large language models (LLMs) and generative AI have recently opened new doors for generating human-like explanations, for and along learning recommendations. However, their precision is still far away from acceptable in a sensitive field like education. To harness the abilities of LLMs, while still ensuring a high level of precision towards the intent of the learners, this paper proposes an approach to utilize knowledge graphs (KG) as a source of factual context for LLM prompts, reducing the risk of model hallucinations, and safeguarding against wrong or imprecise information, while maintaining an application-intended learning context. We utilize the semantic relations in the knowledge graph to offer curated knowledge about learning recommendations. With domain-experts in the loop, we design the explanation as a textual template, which is filled and completed by the LLM. Domain experts were integrated in the prompt engineering phase as part of a study, to ensure that explanations include information that is relevant to the learner. We evaluate our approach quantitatively using Rouge-N and Rouge-L measures, as well as qualitatively with experts and learners. Our results show an enhanced recall and precision of the generated explanations compared to those generated solely by the GPT model, with a greatly reduced risk of generating imprecise information in the final learning explanation.},
  keywords={Shape;Large language models;Semantics;Knowledge graphs;Prompt engineering;Data mining;Engineering education;Large language models (LLMs);Knowledge graphs;ChatGPT;Generative AI (GenAI) Learning recommendations;explainable AI (XAI)},
  doi={10.1109/EDUCON60312.2024.10578654},
  ISSN={2165-9567},
  month={May},}@INPROCEEDINGS{9724493,
  author={Liu, Yuefeng and Guo, Wei and Zhang, Hanyu and Bian, Haodong and He, Yingjie and Zhang, Xiaoyan and Gong, Yanzhang and Dong, Jianmin and Liu, Zhen},
  booktitle={2021 IEEE 20th International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom)}, 
  title={Construction of Knowledge Graph Based on Discipline Inspection and Supervision}, 
  year={2021},
  volume={},
  number={},
  pages={1467-1472},
  abstract={To solve the problems of large number of notifications, low relevance and no relevant knowledge base in the field of discipline inspection, a method of constructing a knowledge map of discipline inspection and supervision based on the BERT-BiLSTM-CRF model is proposed. Firstly, the unstructured data is collected from the content of the disciplinary inspection and supervision report. Through the bottom-up method the notification concept layer is constructed. By using deep learning models to extract entities. Then the entities and semantic relations are stored in the graph database Neo4j and displayed in the form of a knowledge graph. This method realizes the whole process from unstructured data to knowledge graph, and provides technical reference for the construction of domain-based knowledge graph. Simultaneously, the knowledge map of discipline inspection field established through the example can find the hidden association between those who break the law and discipline, prevent criminal facts in advance, and provide support and help for discipline inspection personnel to implement the spirit of the eight-point regulation of the Central Committee and continue to fight against the “four winds” and other actions.},
  keywords={Deep learning;Databases;Soft sensors;Knowledge based systems;Semantics;Inspection;Transformers;discipline inspection and supervision;knowledge graph;NER(natural language processing);BERT(Bidirectional Encoder Representations from Transformers);graph database},
  doi={10.1109/TrustCom53373.2021.00209},
  ISSN={2324-9013},
  month={Oct},}@INPROCEEDINGS{9095669,
  author={Chondamrongkul, Nacha and Sun, Jing and Warren, Ian},
  booktitle={2020 IEEE International Conference on Software Architecture Companion (ICSA-C)}, 
  title={Automated Security Analysis for Microservice Architecture}, 
  year={2020},
  volume={},
  number={},
  pages={79-82},
  abstract={Designing a software system that applied the microservice architecture style is a challenging task, as its characteristics are vulnerable to various security attacks. Software architect, therefore, needs to pinpoint the security flaws in the design before the implementation can proceed. This task is error-prone as it requires manual analysis on the design model, to identify security threats and trace possible attack scenarios. This paper presents an automated security analysis approach for microservice architecture. Our approach can automatically identify security threats according to a collection of formally defined security characteristics and provide an insightful result that demonstrates how the attack scenarios may happen. A collection of formally defined security characteristics can be extended to support other security characteristics not addressed in this paper.},
  keywords={Security;Computer architecture;Connectors;Ontologies;Containers;Tools;Analytical models;Microservice Architecture;Security Analysis;Ontology Web Language;Model Checking},
  doi={10.1109/ICSA-C50368.2020.00024},
  ISSN={},
  month={March},}@INPROCEEDINGS{9603816,
  author={Lu, Yonghe and Zhao, Ruijie and Huang, Shan and Liu, Runjia},
  booktitle={2021 7th Annual International Conference on Network and Information Systems for Computers (ICNISC)}, 
  title={Construction of Diabetes Knowledge Graph Based on Deep Learning}, 
  year={2021},
  volume={},
  number={},
  pages={966-970},
  abstract={To integrate medical data which is scattered over the internet, natural language processing (NLP) is widely used in medical text mining. BERT (Bidirectional Encoder Representations from Transformers) is outstanding among many other representation models and vector representation based on Bert pre-training language model can help the target task learn more semantic information. The knowledge graph intuitively reveals the relationship between entities and helps explore deeper semantic connections between entities. There are three important parts in the construction of a knowledge graph, including entity extraction, relation extraction, and graph generation. Based on these methods this paper proposes a Bert-based named entities identification model Bert-BiLSTM-CRF and it is outperforming the established methods. In the relation extraction part, use the BERT-Softmax to improve the semantic expression and its F1-value increased by 12 percent compared with the traditional entity relation extraction model. Based on the above redefined the entities of diabetes and their relationships to enrich the semantics of the knowledge graph. Finally, the Neo4j graph database was used to realize the visualization of the diabetes knowledge map.},
  keywords={Knowledge engineering;Text mining;Semantics;Search engines;Transformers;Natural language processing;Diabetes;named entity recognition;relation extraction;knowledge extraction},
  doi={10.1109/ICNISC54316.2021.00181},
  ISSN={},
  month={July},}@INPROCEEDINGS{10710806,
  author={Meyer, Frederic and Freitag, Lennart and Hinrichsen, Sven and Niggemann, Oliver},
  booktitle={2024 IEEE 29th International Conference on Emerging Technologies and Factory Automation (ETFA)}, 
  title={Potentials of Large Language Models for Generating Assembly Instructions}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={With the increasing complexity in manual assembly and a demographic decline in skilled workforce, the importance of well-documented processes through assembly instructions has grown. Creating these instructions is a time-consuming and knowledge-intensive task that typically relies on experienced employees. Although various automation solutions have been proposed to assist in generating assembly instructions, they often fall short in providing detailed textual guidance. With the rise of generative artificial intelligence (AI), new potentials arise in this domain. Therefore, this paper explores these potentials by employing various large language models (LLMs), prompting techniques and input data in an experimental setup for generating detailed assembly instructions, including the planning of assembly sequences as well as textual guidance on tools, assembly activities, and quality assurance measures. The findings reveal promising opportunities in leveraging LLMs but also substantial challenges, particularly in assembly sequence planning. To improve the reliability of generating assembly instructions, we propose a multi-agent concept that decomposes the complex task into simpler subtasks, each managed by specialized agents.},
  keywords={Quality assurance;Generative AI;Large language models;Decision making;Manuals;Planning;Complexity theory;Reliability;Assembly;Manufacturing automation;agent;assembly instruction;experiment;GPT;large language model;LLM;prompt},
  doi={10.1109/ETFA61755.2024.10710806},
  ISSN={1946-0759},
  month={Sep.},}@ARTICLE{10141863,
  author={Xie, Zhiwen and Zhu, Runjie and Liu, Jin and Zhou, Guangyou and Huang, Jimmy Xiangji},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing}, 
  title={TARGAT: A Time-Aware Relational Graph Attention Model for Temporal Knowledge Graph Embedding}, 
  year={2023},
  volume={31},
  number={},
  pages={2246-2258},
  abstract={Temporal knowledge graph embedding (TKGE) aims to learn the embedding of entities and relations in a temporal knowledge graph (TKG). Although the previous graph neural networks (GNN) based models have achieved promising results, they cannot directly capture the interactions of multi-facts at different timestamps. To address the above limitation, we propose a time-aware relational graph attention model (TARGAT), which takes the multi-facts at different timestamps as a unified graph. First, we develop a relational generator to dynamically generate a series of time-aware relational message transformation matrices, which jointly models the relations and the timestamp information into a unified way. Then, we apply the generated message transformation matrices to project the neighborhood features into different time-aware spaces and aggregate these neighborhood features to explicitly capture the interactions of multi-facts. Finally, a temporal transformer classifier is applied to learn the representation of the query quadruples and predict the missing entities. The experimental results show that our TARGAT model beats the GNN-based models by a large margin and achieves new state-of-the-art results on four popular benchmark datasets.},
  keywords={Graph neural networks;Task analysis;Knowledge graphs;Convolution;Aggregates;Speech processing;Interpolation;Graph embedding;link prediction;knowledge graph;representation learning},
  doi={10.1109/TASLP.2023.3282101},
  ISSN={2329-9304},
  month={},}@INPROCEEDINGS{9533753,
  author={Yang, Xia and Chiang, Meng-Fen and Lee, Wang-Chien and Chang, Yi},
  booktitle={2021 International Joint Conference on Neural Networks (IJCNN)}, 
  title={Cost-Effective Knowledge Graph Reasoning for Complex Factoid Questions}, 
  year={2021},
  volume={},
  number={},
  pages={1-8},
  abstract={The task of reasoning over knowledge graph for factoid questions has received significant interest from the research community of natural language processing. Performing this task inevitably faces the issues of question complexity and reasoning efficiency. In this paper, we investigate modern reasoning approaches over knowledge graph to tackle complex factoid questions of diverse reasoning schemas with attractive speedup in computational efficiency. To this end, we propose two evidence retrieval strategies to generate concise and informative evidence graph of high semantic-relevance and factual coverage to the question. Then, we adopt DELFT, a graph neural networks based framework that takes the linguistic structure representation of a question and the evidence graph as input, to predict the answer by reasoning over the evidence graph. We evaluate the performance across several baselines in terms of effectiveness and efficiency on two real-world datasets, MOOCQA and MetaQA. The results show the superiority of message passing paradigm in delivering a robust reasoner with better answer quality and significantly improved computational efficiency.},
  keywords={Message passing;Linguistics;Cognition;Natural language processing;Graph neural networks;Computational efficiency;Complexity theory;Factoid Question Answering;Knowledge Graph;Reasoning},
  doi={10.1109/IJCNN52387.2021.9533753},
  ISSN={2161-4407},
  month={July},}@ARTICLE{10185050,
  author={Razzaq, Muhammad Saad and Maqbool, Fahad and Ilyas, Muhammad and Jabeen, Hajira},
  journal={IEEE Access}, 
  title={EvoRecipes: A Generative Approach for Evolving Context-Aware Recipes}, 
  year={2023},
  volume={11},
  number={},
  pages={74148-74164},
  abstract={Generative AI e.g. Large Language Models (LLMs) can be used to generate new recipes. However, LLMs struggle with more complex aspects like recipe semantics and process comprehension. Furthermore, LLMs have limited ability to account for user preferences since they are based on statistical patterns. As a result, these recipes may be invalid. Evolutionary algorithms inspired by the process of natural selection are optimization algorithms that use stochastic operators to generate new solutions. These algorithms can generate large number of solutions from the set of possible solution space. Moreover, these algorithms have the capability to incorporate user preferences in fitness function to generate novel recipes that are more aligned with the fitness objective. In this paper, we propose the  $EvoRecipes$  framework to generate novel recipes. The  $EvoRecipes$  framework utilizes both Genetic Algorithm and generative AI in addition to  $RecipeOn$  ontology, and  $RecipeKG$  knowledge graph. Genetic Algorithm explore the large solution space of encoded recipe solutions and are capable of incorporating user preferences, while LLMs are used to generate recipe text from encoded recipe solutions.  $EvoRecipes$  uses a population of context-aware recipe solutions from the  $RecipeKG$  knowledge graph.  $RecipeKG$  encodes recipes in RDF format using classes and properties as defined in the  $RecipeOn$  ontology. Moreover, to evaluate the alignment of  $EvoRecipe$  generated recipes with multiple intended objectives, we propose a fitness function that incorporates novelty, simplicity, visual appeal, and feasibility. Additionally, to evaluate the quality of the  $EvoRecipe$  generated recipes while considering the subjective nature of recipes, we conducted a survey using multi-dimensional metrics (i.e. contextual, procedural, and novelty). Results show that  $EvoRecipes$  generated recipes are novel, valid and incorporate user preferences.},
  keywords={Ontologies;Creativity;Resource description framework;Knowledge graphs;Genetic algorithms;Sociology;Semantics;Food products;Knowledge graph;ontology;computational creativity;recipe evolution;recipe;food},
  doi={10.1109/ACCESS.2023.3296144},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{7950320,
  author={Janulevičius, Justinas and Marozas, Leonardas and Čenys, Antanas and Goranin, Nikolaj and Ramanauskaitė, Simona},
  booktitle={2017 Open Conference of Electrical, Electronic and Information Sciences (eStream)}, 
  title={Enterprise architecture modeling based on cloud computing security ontology as a reference model}, 
  year={2017},
  volume={},
  number={},
  pages={1-6},
  abstract={The recent growth of popularity of cloud computing services delivers various benefits in multiple fields of activity, including reduced resource costs due to optimized hardware setup, as well as improving mobility. However, cloud computing has some issues that need to be clarified, one of which is the security of cloud computing. The dispersion of cloud service vendors means that most security issues are still addressed often as unique to the particular vendor or cloud computing system, lacking standardization of the procedures and protocols that users and vendors follow when implementing a cloud computing system and running it. This paper deals with cloud computing security management. It offers an ontology, designed by the authors of the paper, specifically built to deal with cloud security controls covering the most important documents of the domain of cloud security management and the implementation of the proposed ontology to an enterprise architecture modeling language.},
  keywords={Cloud computing;Security;Ontologies;Computer architecture;Computational modeling;Analytical models;Documentation;ontology;cloud computing;information security;enterprise architecture},
  doi={10.1109/eStream.2017.7950320},
  ISSN={},
  month={April},}@INPROCEEDINGS{10803829,
  author={Suleykin, Alexander and Panfilov, Peter},
  booktitle={2024 6th International Conference on Control Systems, Mathematical Modeling, Automation and Energy Efficiency (SUMMA)}, 
  title={Smart Technical Support System Development Using Knowledge Map-Aided Approach}, 
  year={2024},
  volume={},
  number={},
  pages={455-460},
  abstract={Strong technical support is crucial to success of any brand. It provides answers to customer's questions and solutions to different situations and is an important factor in keeping customers loyal. A new level of technical support can be achieved through combination of traditional service automation offers with the current advancement of Generative Artificial Intelligence (GenAI) embedded into technical support. GenAI in general and the large language models (LLM s) in particular create new opportunities for natural conversational interfaces and the development of ‘smart’ technical support systems. Based on experiences and observations from other intelligent assistance projects, this paper presents new methodological perspectives from academia and best practice from industry on architecting intelligent technical support systems. It discusses the impact of GenAI and LLMs through real cases supporting an ongoing validation. The maj or focus of this paper is on architectural models for intelligent technical support systems, showing the fundamental Knowledge Map mechanism of AIbased customer service, which allows for not only controlling the information used to generate responses and minimizing errors but also automatically processes requests in accounting systems. An example of successful implementation of Knowledge Mapbased approach is given, where the intelligent assistant chat-bot demonstrates high accuracy of answers and in case of uncertainty redirects requests to human operators. The paper presents the key architectural model perspectives for the development of intelligent technical support systems.},
  keywords={Industries;Automation;Uncertainty;Generative AI;Large language models;Customer services;Process control;Control systems;Mathematical models;Energy efficiency;technical support;smart assistant;chat-bot;large language model;knowledge map;knowledge graph},
  doi={10.1109/SUMMA64428.2024.10803829},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{9084840,
  author={Zhang, Xiao and Li, Chuanzhen and Du, Huaichang},
  booktitle={2020 IEEE 4th Information Technology, Networking, Electronic and Automation Control Conference (ITNEC)}, 
  title={Named Entity Recognition for Terahertz Domain Knowledge Graph based on Albert-BiLSTM-CRF}, 
  year={2020},
  volume={1},
  number={},
  pages={2602-2606},
  abstract={Named entity recognition is a vital part of the question answering system. The current methods for identifying named entities are mostly for short entities. In our terahertz domain question answering system, there are both long and short entities in questions. In this paper, an entity recognition method based on Albert-BiLSTM-CRF is applied to recognize long entity completely. Specifically, a pre-trained model of deep bidirectional representation is applied to fully understand the semantics of the entire sentence. The experimental results on the terahertz domain dataset show that the proposed method improves the accuracy of long domain entity recognition and improves the performance of the terahertz domain question answering system.},
  keywords={Training;Automation;Conferences;Semantics;Knowledge discovery;Information technology;Context modeling;albert;BiLSTM;CRF;named entity recognition;terahertz domain;knowledge graph},
  doi={10.1109/ITNEC48623.2020.9084840},
  ISSN={},
  month={June},}@INPROCEEDINGS{10422308,
  author={Tang, Yun and Da Costa, Antonio A. Bruto and Zhang, Xizhe and Patrick, Irvine and Khastgir, Siddartha and Jennings, Paul},
  booktitle={2023 IEEE 26th International Conference on Intelligent Transportation Systems (ITSC)}, 
  title={Domain Knowledge Distillation from Large Language Model: An Empirical Study in the Autonomous Driving Domain}, 
  year={2023},
  volume={},
  number={},
  pages={3893-3900},
  abstract={Engineering knowledge-based (or expert) systems require extensive manual effort and domain knowledge. As Large Language Models (LLMs) are trained using an enormous amount of cross-domain knowledge, it becomes possible to automate such engineering processes. This paper presents an empirical automation and semi-automation framework for domain knowledge distillation using prompt engineering and the LLM ChatGPT. We assess the framework empirically in the autonomous driving domain and present our key observations. In our implementation, we construct the domain knowledge ontology by “chatting” with ChatGPT. The key finding is that while fully automated domain ontology construction is possible, human supervision and early intervention typically improve efficiency and output quality as they lessen the effects of response randomness and the butterfly effect. We, therefore, also develop a web-based distillation assistant enabling supervision and flexible intervention at runtime. We hope our findings and tools could inspire future research toward revolutionizing the engineering of knowledge-based systems across application domains.},
  keywords={Knowledge engineering;Runtime;Manuals;Ontologies;Chatbots;Autonomous vehicles;Intelligent transportation systems;large language model;domain ontology distillation;autonomous driving},
  doi={10.1109/ITSC57777.2023.10422308},
  ISSN={2153-0017},
  month={Sep.},}@INPROCEEDINGS{10730393,
  author={Bhat, Vani and Cheerla, Sree Divya and Mathew, Jinu Rose and Pathak, Nupur and Liu, Guannan and Gao, Jerry},
  booktitle={2024 IEEE 10th International Conference on Big Data Computing Service and Machine Learning Applications (BigDataService)}, 
  title={Retrieval Augmented Generation (RAG) Based Restaurant Chatbot with AI Testability}, 
  year={2024},
  volume={},
  number={},
  pages={1-10},
  abstract={Post-COVID the restaurant industry is experiencing a surge in demand, presenting a unique challenge of efficiently managing increased customer flow while ensuring seamless interactions. Chatbots have emerged as an innovative solution to meet the demand increase. The paper addresses the enhancement of AI chatbots through the integration of Retrieval-Augmented Generation (RAG) with the Large Language Model (LLM). This paper focuses on the development of a restaurant chatbot that not only engages in natural-language conversations but also addresses context optimization and LLM optimization for restaurant context learning. The approach uses a Neo4j Knowledge graph built using the restaurant data as an external source of knowledge. The graph is traversed to match the user question with appropriate answer tokens using Term Frequency - Inverse Document Frequency (TF-IDF) embeddings. The relevant tokens along with user questions are used to provide additional context to the T5 language model to provide nuanced responses to the users. This improvement is quantitatively evidenced by a Bilingual Evaluation Understudy (BLEU) score of 0.60, indicating a high level of precision in language understanding and generation. An extensive evaluation of the chatbot includes assessing AI testability on the level of words, sentences, and information. These evaluations include simulated dialogue assessments and performance analyses, with a focus on the chatbot's ability to retrieve and integrate information. Based on the AI testability evaluation, the models consistently produce more knowledgeable, diverse, and relevant answers as compared with state-of-the-art models with an average information score in the range of 0.6-0.8.},
  keywords={Industries;Large language models;Knowledge graphs;Oral communication;Chatbots;Performance analysis;Artificial intelligence;Surges;Standards;Optimization;Natural Language Processing (NLP);Retrieval Augmented Generation (RAG);Large Language Model (LLM);Information Retrieval (IR);Knowledge Graph;AI Testability},
  doi={10.1109/BigDataService62917.2024.00008},
  ISSN={2690-828X},
  month={July},}@INPROCEEDINGS{10386454,
  author={Chen, Bohan and Bertozzi, Andrea L.},
  booktitle={2023 IEEE International Conference on Big Data (BigData)}, 
  title={AutoKG: Efficient Automated Knowledge Graph Generation for Language Models}, 
  year={2023},
  volume={},
  number={},
  pages={3117-3126},
  abstract={Traditional methods of linking large language models (LLMs) to knowledge bases via the semantic similarity search often fall short of capturing complex relational dynamics. To address these limitations, we introduce AutoKG, a lightweight and efficient approach for automated knowledge graph (KG) construction. For a given knowledge base consisting of text blocks, AutoKG first extracts keywords using a LLM and then evaluates the relationship weight between each pair of keywords using graph Laplace learning. We employ a hybrid search scheme combining vector similarity and graph-based associations to enrich LLM responses. Preliminary experiments demonstrate that AutoKG offers a more comprehensive and interconnected knowledge retrieval mechanism compared to the semantic similarity search, thereby enhancing the capabilities of LLMs in generating more insightful and relevant outputs.},
  keywords={Training;Semantics;Knowledge based systems;Data visualization;Knowledge graphs;Computer architecture;Big Data;Language model;Knowledge Graph;Graph Learning;Retrieval-augmented Generation},
  doi={10.1109/BigData59044.2023.10386454},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10407599,
  author={Tu, Ming-Yu and Ehm, Hans and Ismail, Abdelgafar and Ulrich, Philipp},
  booktitle={2023 Winter Simulation Conference (WSC)}, 
  title={Reusable Ontology Generation and Matching from Simulation Models}, 
  year={2023},
  volume={},
  number={},
  pages={2298-2309},
  abstract={As simulating semiconductor manufacturing grows complex, model reuse becomes appealing since it can reduce the time incurred in developing future models. Also, considering a large network of the semiconductor supply chain, knowledge sharing can enable the efficient development of simulation models in a collaborative organization. Such necessity of reusability and interoperability of simulation models motivates this paper. We will address these challenges through ontological modeling and linking of the simulation components. The first application is generating reusable ontologies from simulation models. Another discussed application is ontology matching for knowledge sharing between simulation components and a meta-model of the semiconductor supply chain. The proposed approach succeeds in automatically transforming simulation into reusable knowledge and identifying interconnection in a semiconductor manufacturing system.},
  keywords={Semiconductor device modeling;Knowledge engineering;Supply chains;Organizations;Ontologies;Semiconductor device manufacture;Interoperability},
  doi={10.1109/WSC60868.2023.10407599},
  ISSN={1558-4305},
  month={Dec},}@INPROCEEDINGS{8756968,
  author={Bučko, B. and Zábovská, K. and Zábovský, M.},
  booktitle={2019 42nd International Convention on Information and Communication Technology, Electronics and Microelectronics (MIPRO)}, 
  title={Ontology as a Modeling Tool within Model Driven Architecture Abstraction}, 
  year={2019},
  volume={},
  number={},
  pages={1525-1530},
  abstract={This paper is focused on automatic transformation process of top levels of Model Driven Architecture (MDA) within the information system development phase. System architects are always trying to find easier, complex and more united way of information system development. Although the Model Driven Architecture (MDA) provides a set of guidelines for the structuring of specifications it also comes with challenging tasks of transformations between the various levels of abstraction. The primary objective of this work is to design a universal automated approach within the Computer Independent Model (CIM) and Platform Independent Model (PIM) manual transformation. The manual process of the transformations within MDA could be automated using ontology model with the combination of mapping rules and Extensible Markup Process Definition Language (XPDL) and Extensible Markup Language Metadata interchange (XMI) conversion.},
  keywords={Unified modeling language;Ontologies;Business;Computational modeling;Data models;Computer architecture;Information systems;Model driven architecture;Computer independent model;Platform independent model;Ontology;Information system development},
  doi={10.23919/MIPRO.2019.8756968},
  ISSN={2623-8764},
  month={May},}@INPROCEEDINGS{8051363,
  author={Zhou, Jiale and Hänninen, Kaj and Lundqvist, Kristina},
  booktitle={2017 43rd Euromicro Conference on Software Engineering and Advanced Applications (SEAA)}, 
  title={A Hazard Modeling Language for Safety-Critical Systems Based on the Hazard Ontology}, 
  year={2017},
  volume={},
  number={},
  pages={301-304},
  abstract={Preliminary hazard analysis (PHA) is a key safetyconcerned activity to identify potential hazards. However, since various stakeholders will be involved in the identification process, a common understanding of the nature of hazards among stakeholders, such as what a hazard consists of and how to describe it without ambiguities, is of crucial importance to achieve the goal of PHA. In this work, we propose a hazard modeling language (HML) based on a domain ontology to facilitate the specification of identified hazards. In addition, we present an approach to guide the transformation from natural language hazard descriptions into the HML specification. Finally, an industrial PHA example is used to illustrate the usefulness of our work.},
  keywords={Hazards;Ontologies;Unified modeling language;Stakeholders;Analytical models;Natural languages;Injuries;preliminary hazard analysis;hazard ontology;hazard modeling language},
  doi={10.1109/SEAA.2017.48},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10740163,
  author={Wang, Li-C.},
  booktitle={2024 ACM/IEEE 6th Symposium on Machine Learning for CAD (MLCAD)}, 
  title={LLM-Assisted Analytics in Semiconductor Test (Invited)}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={The emergence of Large Language Models (LLMs) has impacted our perspective on applying Machine Learning (ML) in semiconductor test. This paper shares our experience in leveraging the power of LLMs to build an AI agent for test data analytics. We advocate for an end-to-end approach where the Knowledge Graph (KG) plays a central role. Using wafermap analytics as an example, we highlight the key ideas behind developing the LLM-assisted AI agent named IEA-Plot, and discuss its practical applications.CCS Concepts• Hardware → Hardware test; • Computing methodologies → Artificial intelligence.},
  keywords={Solid modeling;Analytical models;Data analysis;Grounding;Large language models;Machine learning;Knowledge graphs;Hardware;Data models;Optimization;Test Data Analytics;Large Language Model;Knowledge Graph;Machine Learning},
  doi={10.1109/MLCAD62225.2024.10740163},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10030025,
  author={Kabir, Anowarul and Shehu, Amarda},
  booktitle={2022 IEEE International Conference on Knowledge Graph (ICKG)}, 
  title={Sequence-Structure Embeddings via Protein Language Models Improve on Prediction Tasks}, 
  year={2022},
  volume={},
  number={},
  pages={105-112},
  abstract={Building on the transformer architecture and its revolutionizing of language models for natural language processing, protein language models (PLMs) are now emerging as a powerful tool for learning over large numbers of sequences in protein sequence databases and linking protein sequence to function. PLMs are shown to learn useful, task-agnostic sequence representations that allow predicting protein secondary structure, protein subcellular localization, and evolutionary relationships within protein families. However, existing models are strictly trained over protein sequences and miss an opportunity to leverage and integrate the information present in heterogeneous data sources. In this paper, inspired by the intrinsic role of three-dimensional/tertiary protein structure in determining a broad range of protein properties, we propose a PLM that integrates and attends to both protein sequence and tertiary structure. In particular, this paper posits that learning joint sequence-structure representations yields better representations for function-related prediction tasks. A detailed experimental evaluation shows that such joint sequence-structure representations are more powerful than sequence-based representations, yield better performance on superfamily membership across various metrics, and capture interesting relationships in the PLM-learned embedding space.},
  keywords={Location awareness;Soft sensors;Semantics;Training data;Predictive models;Transformers;Protein sequence;Protein language model;Transformer;Sequence structure transformer;Protein function;superfamily},
  doi={10.1109/ICKG55886.2022.00021},
  ISSN={},
  month={Nov},}@ARTICLE{10417790,
  author={Yang, Linyao and Chen, Hongyang and Li, Zhao and Ding, Xiao and Wu, Xindong},
  journal={IEEE Transactions on Knowledge and Data Engineering}, 
  title={Give us the Facts: Enhancing Large Language Models With Knowledge Graphs for Fact-Aware Language Modeling}, 
  year={2024},
  volume={36},
  number={7},
  pages={3091-3110},
  abstract={Recently, ChatGPT, a representative large language model (LLM), has gained considerable attention. Due to their powerful emergent abilities, recent LLMs are considered as a possible alternative to structured knowledge bases like knowledge graphs (KGs). However, while LLMs are proficient at learning probabilistic language patterns and engaging in conversations with humans, they, like previous smaller pre-trained language models (PLMs), still have difficulty in recalling facts while generating knowledge-grounded contents. To overcome these limitations, researchers have proposed enhancing data-driven PLMs with knowledge-based KGs to incorporate explicit factual knowledge into PLMs, thus improving their performance in generating texts requiring factual knowledge and providing more informed responses to user queries. This paper reviews the studies on enhancing PLMs with KGs, detailing existing knowledge graph enhanced pre-trained language models (KGPLMs) as well as their applications. Inspired by existing studies on KGPLM, this paper proposes enhancing LLMs with KGs by developing knowledge graph-enhanced large language models (KGLLMs). KGLLM provides a solution to enhance LLMs’ factual reasoning ability, opening up new avenues for LLM research.},
  keywords={Task analysis;Training;Long short term memory;Knowledge graphs;Transformers;Knowledge based systems;Chatbots;Large language model;knowledge graph;ChatGPT;knowledge reasoning;knowledge management},
  doi={10.1109/TKDE.2024.3360454},
  ISSN={1558-2191},
  month={July},}@INPROCEEDINGS{9669736,
  author={Huang, Lan and Guan, Hongrui and Liang, Yanchun and Guan, Renchu and Feng, Xiaoyue},
  booktitle={2021 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)}, 
  title={COVID-19 Knowledge Graph for Drug and Vaccine Development}, 
  year={2021},
  volume={},
  number={},
  pages={328-333},
  abstract={The worldwide spread of COVID-19 has made a severe impact on human health and life. It has shown rapid propagation, long in vitro survival, and a long incubation period. More seriously, COVID-19 is more susceptible to variation, as it is an RNA virus. Mutations of COVID-19 have been reported in multiple countries worldwide, which makes drug and vaccine development a significant challenge. To search for potential drugs and vaccines and reveal the atlas of COVID-19 evolution, we extract information from massive unstructured data and construct a COVID-19 knowledge graph using the COVID-19 data. Based on machine learning approaches, we infer and predict novel coronavirus pneumonia-related diseases, drug action targets, etc. to speculate on new and more effective treatment methods. In addition, to study transcriptome of SARS-CoV-2, new ideas can be provided to biomedical experts with flexible responses to viral variation. An in-depth analysis of the COVID-19 pathomechanism at the pharmaceutical, genetic, and protein levels provides effective means and tools for novel coronavirus pneumonia vaccines, drug development, and therapeutic program design.},
  keywords={COVID-19;Drugs;Proteins;Protein engineering;Pulmonary diseases;RNA;Machine learning;COVID-19;knowledge graph;vaccine;mutation},
  doi={10.1109/BIBM52615.2021.9669736},
  ISSN={},
  month={Dec},}@ARTICLE{10531671,
  author={Song, Yaoxian and Sun, Penglei and Liu, Haoyu and Li, Zhixu and Song, Wei and Xiao, Yanghua and Zhou, Xiaofang},
  journal={IEEE Transactions on Knowledge and Data Engineering}, 
  title={Scene-Driven Multimodal Knowledge Graph Construction for Embodied AI}, 
  year={2024},
  volume={36},
  number={11},
  pages={6962-6976},
  abstract={Embodied AI is one of the most popular studies in artificial intelligence and robotics, which can effectively improve the intelligence of real-world agents (i.e. robots) serving human beings. Scene knowledge is important for an agent to understand the surroundings and make correct decisions in the varied open world. Currently, knowledge base for embodied tasks is missing and most existing work use general knowledge base or pre-trained models to enhance the intelligence of an agent. For conventional knowledge base, it is sparse, insufficient in capacity and cost in data collection. For pre-trained models, they face the uncertainty of knowledge and hard maintenance. To overcome the challenges of scene knowledge, we propose a scene-driven multimodal knowledge graph (Scene-MMKG) construction method combining conventional knowledge engineering and large language models. A unified scene knowledge injection framework is introduced for knowledge representation. To evaluate the advantages of our proposed method, we instantiate Scene-MMKG considering typical indoor robotic functionalities (Manipulation and Mobility), named ManipMob-MMKG. Comparisons in characteristics indicate our instantiated ManipMob-MMKG has broad superiority on data-collection efficiency and knowledge quality. Experimental results on typical embodied tasks show that knowledge-enhanced methods using our instantiated ManipMob-MMKG can improve the performance obviously without re-designing model structures complexly.},
  keywords={Task analysis;Knowledge graphs;Artificial intelligence;Knowledge based systems;Robots;Knowledge engineering;Visualization;Multimodal knowledge graph;scene driven;embodied AI;robotic intelligence},
  doi={10.1109/TKDE.2024.3399746},
  ISSN={1558-2191},
  month={Nov},}@INPROCEEDINGS{9667755,
  author={Lu, Yuxun and Ichise, Ryutaro},
  booktitle={2021 IEEE International Conference on Big Knowledge (ICBK)}, 
  title={Unsupervised Type Constraint Inference in Bilinear Knowledge Graph Completion Models}, 
  year={2021},
  volume={},
  number={},
  pages={15-22},
  abstract={Knowledge graph completion (KGC) models aim to provide a feasible way of manipulating facts in knowledge graphs. Most KGC models do not consider type constraint in relations due to the scarcity of type information in training data. We proposed an unsupervised method for inferring type constraint based on existing bilinear KGC models. Our method induces two type indicators into every relation and adjusts the location of entity embeddings in feature space to match the type indicators. Our approach eliminates the external feature space for entity types and type constraints in relations and has a consistent feature space; therefore, it has fewer parameters than other methods. Experiments show that our methods can improve the performance of the base models and outperform other methods on datasets about general knowledge.},
  keywords={Conferences;Refining;Training data;Benchmark testing;Data models;Type Constraint Inference;Knowledge Graph Completion Model;Unsupervised Learning},
  doi={10.1109/ICKG52313.2021.00012},
  ISSN={},
  month={Dec},}@ARTICLE{10219140,
  author={Ding, Yi and Li, He and Zhu, Feng and Wang, Zhe and Peng, Weiwen and Xie, Min},
  journal={IEEE Transactions on Industrial Informatics}, 
  title={A Semi-Supervised Failure Knowledge Graph Construction Method for Decision Support in Operations and Maintenance}, 
  year={2024},
  volume={20},
  number={3},
  pages={3104-3114},
  abstract={Maintenance logs of industrial equipment record descriptive and unstructured operation and maintenance (O&M) information, which is the basis of reliability, availability, and maintainability investigations. However, the construction of failure knowledge graphs as a basis for understanding the failure and maintenance properties of systems is challenging due to the requirement of annotation efforts and domain knowledge. This article proposes a novel semi-supervised method for failure knowledge graph construction. Initially, a semantic module is proposed to extract hidden contextual information from maintenance records and identify corresponding failure modes. The semantic module is trained by unlabeled maintenance records with the assistance of the hard pseudo-label acquisition and the proposed self-training algorithm. Subsequently, a taxonomy induction module is presented to extract failure items and their relationships to construct failure knowledge graphs that provide decision support. The feasibility and superiority of the proposed method are validated by maintenance logs from real wind farms. Overall, the proposed method provides an effective tool for semantic information digitalization of well-cumulated industrial O&M data.},
  keywords={Maintenance engineering;Knowledge graphs;Semantics;Feature extraction;Data mining;Bit error rate;Taxonomy;Knowledge graph;operation and maintenance;unstructured maintenance logs},
  doi={10.1109/TII.2023.3299078},
  ISSN={1941-0050},
  month={March},}@ARTICLE{10052691,
  author={Jha, Kanchan and Saha, Sriparna and Karmakar, Sourav},
  journal={IEEE/ACM Transactions on Computational Biology and Bioinformatics}, 
  title={Prediction of Protein-Protein Interactions Using Vision Transformer and Language Model}, 
  year={2023},
  volume={20},
  number={5},
  pages={3215-3225},
  abstract={The knowledge of protein-protein interaction (PPI) helps us to understand proteins’ functions, the causes and growth of several diseases, and can aid in designing new drugs. The majority of existing PPI research has relied mainly on sequence-based approaches. With the availability of multi-omics datasets (sequence, 3D structure) and advancements in deep learning techniques, it is feasible to develop a deep multi-modal framework that fuses the features learned from different sources of information to predict PPI. In this work, we propose a multi-modal approach utilizing protein sequence and 3D structure. To extract features from the 3D structure of proteins, we use a pre-trained vision transformer model that has been fine-tuned on the structural representation of proteins. The protein sequence is encoded into a feature vector using a pre-trained language model. The feature vectors extracted from the two modalities are fused and then fed to the neural network classifier to predict the protein interactions. To showcase the effectiveness of the proposed methodology, we conduct experiments on two popular PPI datasets, namely, the human dataset and the S. cerevisiae dataset. Our approach outperforms the existing methodologies to predict PPI, including multi-modal approaches. We also evaluate the contributions of each modality by designing uni-modal baselines. We perform experiments with three modalities as well, having gene ontology as the third modality.},
  keywords={Proteins;Feature extraction;Three-dimensional displays;Protein sequence;Amino acids;Deep learning;Transformers;Language model;protein-protein interaction;vision transformer},
  doi={10.1109/TCBB.2023.3248797},
  ISSN={1557-9964},
  month={Sep.},}@INPROCEEDINGS{10821904,
  author={Lijuan, Ke and Lianting, Lai and Xiaoyi, Xu and Qianyun, Yang and Guoshan, Zhang and Lei, Lei},
  booktitle={2024 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)}, 
  title={Construction of a knowledge graph of acupuncture famous doctors' medical cases based on information extraction from large language model}, 
  year={2024},
  volume={},
  number={},
  pages={4854-4860},
  abstract={Objective: To construct a knowledge graph of acupuncture case studies from renowned acupuncturists, analyze acupuncture medical case knowledge, mine implicit knowledge, and perform visual representation, providing methodological references for the research of acupuncture medical cases. Methods: The types of knowledge entities and relationships between entities involved in acupuncture case studies from renowned acupuncturists were sorted out. The TCM Miner platform was used for text annotation, and a large language model was employed to identify and label entities. The relationships between entities were determined based on Chinese medicine-related standards, literature reviews, and established rules. After knowledge fusion, the data was imported into the Neo4j graph database using the Cypher language for storage and visual representation, constructing a knowledge graph of acupuncture medical cases. Results: The acupuncture medical case knowledge graph contained 577 nodes and 3,905 relationships, with a schema comprising 5 entity classes and 5 relationship types. Through Cypher language queries, knowledge can be visually presented in four aspects: commonly used treatment methods of practitioners, research on the relationship between acupuncture techniques and diseases, exploration of disease-acupoint patterns, and research on other therapies and diseases. Discussion: The knowledge graph constructed in this study can visually display the knowledge and implicit relationships recorded in acupuncture medical cases, making it suitable for knowledge mining and visual representation of acupuncture medical cases.},
  keywords={Visualization;Ciphers;Large language models;Knowledge graphs;Information retrieval;Acupuncture;Visual databases;Standards;Diseases;Systematic literature review;acupuncture famous doctors' medical cases;knowledge graph;large language models;visualization},
  doi={10.1109/BIBM62325.2024.10821904},
  ISSN={2156-1133},
  month={Dec},}@ARTICLE{10748382,
  author={Hu, Binhao and Zhang, Jianpeng and Chen, Hongchang},
  journal={Chinese Journal of Electronics}, 
  title={Knowledge Graph Completion Method of Combining Structural Information with Semantic Information}, 
  year={2024},
  volume={33},
  number={6},
  pages={1412-1420},
  abstract={With the development of knowledge graphs, a series of applications based on knowledge graphs have emerged. The incompleteness of knowledge graphs makes the effect of the downstream applications affected by the quality of the knowledge graphs. To improve the quality of knowledge graphs, translation-based graph embeddings such as TransE, learn structural information by representing triples as low-dimensional dense vectors. However, it is difficult to generalize to the unseen entities that are not observed during training but appear during testing. Other methods use the powerful representational ability of pre-trained language models to learn entity descriptions and contextual representation of triples. Although they are robust to incompleteness, they need to calculate the score of all candidate entities for each triple during inference. We consider combining two models to enhance the robustness of unseen entities by semantic information, and prevent combined explosion by reducing inference overhead through structured information. We use a pre-training language model to code triples and learn the semantic information within them, and use a hyperbolic space-based distance model to learn structural information, then integrate the two types of information together. We evaluate our model by performing link prediction experiments on standard datasets. The experimental results show that our model achieves better performances than state-of-the-art methods on two standard datasets.},
  keywords={Training;Semantics;Knowledge graphs;Predictive models;Vectors;Robustness;Explosions;Standards;Testing;Context modeling;Knowledge graph;Knowledge graph completion;Representation learning},
  doi={10.23919/cje.2022.00.299},
  ISSN={2075-5597},
  month={November},}@INPROCEEDINGS{10451936,
  author={Zhan, Ding and Wu, Xingyu and Chang, Yubiao and Tian, Chao and Wang, Tian and Chen, Cui and Xie, Liping and Huang, Wang and Tong, Endong and Niu, Wenjia},
  booktitle={2023 China Automation Congress (CAC)}, 
  title={Improving Knowledge Graph-based BERT Pre-Training Through Entity Hot Partition and Adapter Fusion}, 
  year={2023},
  volume={},
  number={},
  pages={7669-7675},
  abstract={Enhancing pre-training models based on knowledge graphs is an emerging technique used to handle knowledge-intensive tasks. In the latest research presented at EMNLP 2021, an approach to multi-subgraph BERT embedding using knowledge graph partitioning is developed, demonstrating the effectiveness of parallel multiple subgraphs-based BERT embeddings. However, this approach is task-agnostic and only consider topological features during the knowledge graph partitioning process, while in practical applications such as question answering, the graph partitioning can dynamically change as users' interaction, that may neglect entity popularity features and potentially affect the performance of pre-training models. In this paper, we propose an entity hot partition(EHP) approach to multi-subgraph BERT embedding. We improve the performance of the BERT model through integrating entity hot partitioning and adapter fusion. By calculating entity popularity based on knowledge graph triplets, we construct an entity popularity weight vector and introduce it into the classic METIS method to achieve popularity-sensitive graph partitioning. Finally, the partitioned graph results are fed into adapters to facilitate fine-tuning-based BERT pretraining. We conducted extensive experiments on three biomedical BERT models, namely SciBERT, BioBERT, and PubMedBERT, across six downstream tasks. The results demonstrate the effectiveness of our approach in achieving the performance improvements under simulated popularity scenarios.},
  keywords={Adaptation models;Automation;Computational modeling;Biological system modeling;Knowledge graphs;Vectors;Question answering (information retrieval);Knowledge Graph;Hot Partition;BERT;Embedding},
  doi={10.1109/CAC59555.2023.10451936},
  ISSN={2688-0938},
  month={Nov},}@INPROCEEDINGS{9534398,
  author={Ahmad, Zishan and Ekbal, Asif and Sengupta, Shubhashis and Maitra, Anutosh and Ramnani, Roshni and Bhattacharyya, Pushpak},
  booktitle={2021 International Joint Conference on Neural Networks (IJCNN)}, 
  title={Unsupervised Approach for Knowledge-Graph Creation from Conversation: The Use of Intent Supervision for Slot Filling}, 
  year={2021},
  volume={},
  number={},
  pages={1-8},
  abstract={In this paper, we propose an unsupervised approach for knowledge graph (KG) creation from conversational data. We make use of intent classification and slot-filling, the two important components of any dialogue agent, exploit their interconnectedness, and finally construct a KG. We build a supervised intent classifier to extract the intent classes, and then on top of this we run our occlusion based slot-information extraction algorithm. Our algorithm is able to make use of supervised training of intent classifiers for extracting the relevant slot-information in an unsupervised way. To test the effectiveness of our system, we perform both automatic and manual evaluation of our intent-classifier and slot-filling system on three dialog datasets. Finally, we construct a knowledge graph from the dialogue conversation using an algorithm that makes use of our occlusion based slot-information extraction module. Empirical evaluation shows that our occlusion based method is able to successfully extract slot information from conversations, resulting in a high-quality KG.},
  keywords={Training;Codes;Neural networks;Bit error rate;Manuals;Information retrieval;Filling;Deep-learning;Unsupervised;Style-transfer;Text generation},
  doi={10.1109/IJCNN52387.2021.9534398},
  ISSN={2161-4407},
  month={July},}@ARTICLE{10198434,
  author={Jaradeh, Amer and Kurdy, Mohamad-Bassam},
  journal={IEEE Access}, 
  title={ArEmotive Bridging the Gap: Automatic Ontology Augmentation Using Zero-Shot Classification for Fine-Grained Sentiment Analysis of Arabic Text}, 
  year={2023},
  volume={11},
  number={},
  pages={81318-81330},
  abstract={Human-computer interaction remains one of the final frontiers to conquer while held in perspective with the rapid developments and technology growth over recent years. It is an arduous task to convey the true human intent to the machine in order to generate a computerized relevant decision in a certain field. In recent years, focus has shifted to cover fields of study that relate to Sentiment Analysis (SA) to improve and ease the tasks of our daily lives. We Propose ArEmotive (Arabic Emotive), a fine-grained sentiment analysis system that is human-independent which can automatically grow its source of information allowing for more precision and a greater dataset each time it is used through ontology augmentation and classification. Our proposed architecture relies on multiple data sources running through certain pipelines to generate a central online repository utilized by any mobile system to access this info-base. This system is important because many researchers in the field of automated ontology alignment and ontology mapping achieved a semi-automated approach to map new ontologies out of old ones or to extend already existing ontologies with data from new ones. ArEmotive identifies fine-grained emotions in text based on a dynamic ontology enriched through ontology alignment, mapping and machine learning assisted classification, resulting in a structure that contributes in: a centralized dataset ever growing to fit the need of the users, a sustainable structure able to allocate new data sources without the need to modify the system, ability to generate appropriate information even with the absence of “parent” sources.},
  keywords={Ontologies;Task analysis;Social networking (online);Sentiment analysis;Bridges;Blogs;Soft sensors;Emotion recognition;Arabic NLP;fine-grained emotions;ontology augmentation},
  doi={10.1109/ACCESS.2023.3300737},
  ISSN={2169-3536},
  month={},}@ARTICLE{10505027,
  author={Gao, Xingyu and Wang, Xi and Chen, Zhenyu and Zhou, Wei and Hoi, Steven C. H.},
  journal={IEEE Transactions on Multimedia}, 
  title={Knowledge Enhanced Vision and Language Model for Multi-Modal Fake News Detection}, 
  year={2024},
  volume={26},
  number={},
  pages={8312-8322},
  abstract={The rapid dissemination of fake news and rumors through the Internet and social media platforms poses significant challenges and raises concerns in the public sphere. Automatic detection of fake news plays a crucial role in mitigating the spread of misinformation. While recent approaches have focused on leveraging neural networks to improve textual and visual representations in multi-modal fake news analysis, they often overlook the potential of incorporating knowledge information to verify facts within news articles. In this paper, we present a vision and language model that incorporates knowledge to enhance multi-modal fake news detection. Our proposed model integrates information from large scale open knowledge graphs to augment its ability to discern the veracity of news content. Unlike previous methods that utilize separate models to extract textual and visual features, we synthesize a unified model capable of extracting both types of features simultaneously. To represent news articles, we introduce a graph structure where nodes encompass entities, relationships extracted from the textual content, and objects depicted in associated images. By utilizing the knowledge graph, we establish meaningful relationships between nodes within the news articles. Experimental evaluations on a real-world multi-modal dataset from Twitter demonstrate significant performance improvement by incorporating knowledge information.},
  keywords={Fake news;Feature extraction;Visualization;Knowledge graphs;Social networking (online);Knowledge engineering;Task analysis;Deep neural network;fake news detection;knowledge graph;vision and language model},
  doi={10.1109/TMM.2023.3330296},
  ISSN={1941-0077},
  month={},}@INPROCEEDINGS{10659709,
  author={Tobola, Kirill V. and Dorodnykh, Nikita O.},
  booktitle={2024 Ivannikov Memorial Workshop (IVMEM)}, 
  title={Semantic Annotation of Russian-Language Tables Based on a Pre-Trained Language Model}, 
  year={2024},
  volume={},
  number={},
  pages={62-68},
  abstract={Tables are widely used in organizing, presenting, and storing data. However, as a rule, they have different arbitrary layouts and are not accompanied by explicit semantics necessary for machine interpretation of their content. Recent research has shown great progress in solving various problems in the field of automatic table understanding. Despite this, there is still a need to develop more effective solutions that are applicable in practice and take into account data with different linguistic backgrounds. In this paper, we propose a new RuTaBERT framework based on a pre-trained language model and provide semantic column annotation of Russian-language tables. We used a preprocessed large-scale corpus of Russian-language web tables extracted from Wikipedia pages as training data to fine-tune the language model. The experimental results obtained show the prospect of using the proposed framework, including when solving applied problems.},
  keywords={Annotations;Semantics;Layout;Training data;Knowledge graphs;Encyclopedias;Linguistics;tabular data;Russian-language tables;pre-trained language model;semantic table interpretation;column annotation;knowledge graph},
  doi={10.1109/IVMEM63006.2024.10659709},
  ISSN={2831-5847},
  month={May},}@ARTICLE{10752733,
  author={Xie, Bingbing and Ma, Xiaoxiao and Shan, Xue and Beheshti, Amin and Yang, Jian and Fan, Hao and Wu, Jia},
  journal={IEEE Transactions on Computational Social Systems}, 
  title={Multiknowledge and LLM-Inspired Heterogeneous Graph Neural Network for Fake News Detection}, 
  year={2024},
  volume={},
  number={},
  pages={1-13},
  abstract={The widespread diffusion of fake news has become a critical problem on dynamic social media worldwide, which requires effective strategies for fake news detection to alleviate its hazardous consequences for society. However, most recent efforts only focus on the features of news content and social context without realizing the benefits of large language models (LLMs) and multiple knowledge graphs (KGs), thus failing to improve detection capabilities further. To tackle this issue, we present a multiknowledge and LLM-inspired heterogeneous graph neural network for fake news detection (MiLk-FD), by combining KGs, LLMs, and graph neural networks (GNNs). Specifically, we first model news content as a heterogeneous graph (HG) containing news, entity, and topic nodes and then fuse the knowledge from three KGs to augment the factual basis of news articles. Meanwhile, we leverage TransE to initialize the knowledge features and employ LLaMa2-7B to obtain the initial feature vectors of news articles. After that, we utilize the devised HG transformer to learn news embeddings with specific feature distribution in high-dimensional spaces by aggregating neighborhood information according to metapaths. Finally, a classifier based on multilayer perceptron (MLP) is trained to predict each news article as fake or true. Through experiments, we demonstrate that our proposed framework surpasses ten baselines according to accuracy, precision, F1-score, recall, and ROC in four public real-world benchmarks (i.e., COVID-19, FakeNewsNet, PAN2020, Liar).},
  keywords={Deep learning;fake news detection;graph anomaly detection;knowledge graph (KG);large language model (LLM)},
  doi={10.1109/TCSS.2024.3488191},
  ISSN={2329-924X},
  month={},}@ARTICLE{10807340,
  author={Guo, Wenying and Du, Shengdong and Hu, Jie and Teng, Fei and Yang, Yan and Li, Tianrui},
  journal={Big Data Mining and Analytics}, 
  title={RP-KGC: A Knowledge Graph Completion Model Integrating Rule-Based Knowledge for Pretraining and Inference}, 
  year={2025},
  volume={8},
  number={1},
  pages={18-30},
  abstract={The objective of knowledge graph completion is to comprehend the structure and inherent relationships of domain knowledge, thereby providing a valuable foundation for knowledge reasoning and analysis. However, existing methods for knowledge graph completion face challenges. For instance, rule-based completion methods exhibit high accuracy and interpretability, but encounter difficulties when handling large knowledge graphs. In contrast, embedding-based completion methods demonstrate strong scalability and efficiency, but also have limited utilisation of domain knowledge. In response to the aforementioned issues, we propose a method of pre-training and inference for knowledge graph completion based on integrated rules. The approach combines rule mining and reasoning to generate precise candidate facts. Subsequently, a pre-trained language model is fine-tuned and probabilistic structural loss is incorporated to embed the knowledge graph. This enables the language model to capture more deep semantic information while the loss function reconstructs the structure of the knowledge graph. This enables the language model to capture more deep semantic information while the loss function reconstructs the structure of the knowledge graph. Extensive tests using various publicly accessible datasets have indicated that the suggested model performs better than current techniques in tackling knowledge graph completion problems.},
  keywords={Scalability;Semantics;Knowledge graphs;Transforms;Probabilistic logic;Cognition;Encoding;Data models;Data mining;Faces;Knowledge Graph Completion (KGC);Bidirectional Encoder Representation from Transforms (BERT) fine-tuning;knowledge graph embedding},
  doi={10.26599/BDMA.2024.9020063},
  ISSN={2097-406X},
  month={February},}@INPROCEEDINGS{9686335,
  author={Palchunov, Dmitry and Tregubov, A.S.},
  booktitle={2021 International Symposium on Knowledge, Ontology, and Theory (KNOTH)}, 
  title={Semantic methods of intelligent assistant developing}, 
  year={2021},
  volume={},
  number={},
  pages={30-35},
  abstract={Human-computer interaction with people whose visual perception is limited is possible only with tactile and voice interfaces, the latter are being used more and more recently. The aim of the work is to create an intelligent assistant for an indoor navigation system designed for blind and visually impaired people. The development of an intelligent assistant is based on a semantic user model and a four-level ontological model of the subject domain. To build a dialogue between an intelligent assistant and a user, we use the theory of speech acts, argumentation theory and case-based reasoning. The developed software system is aimed at identifying the desires and user needs and proposing possible user actions aimed at achieving them. The system allows for the decomposition of user tasks and the formation of a sequence of their execution based on semantic models of the user and the subject domain.},
  keywords={Knowledge engineering;Uncertainty;Web services;Semantics;Speech recognition;Ontologies;Software systems;intelligent assistant;ontology;machine learning;natural language processing;intent recognition;argumentation theory;case-based reasoning},
  doi={10.1109/KNOTH54462.2021.9686335},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10074709,
  author={Chen, Luming and Qi, Yifan and Wu, Aiping and Deng, Lizong and Jiang, Taijiao},
  booktitle={2022 IEEE 24th Int Conf on High Performance Computing & Communications; 8th Int Conf on Data Science & Systems; 20th Int Conf on Smart City; 8th Int Conf on Dependability in Sensor, Cloud & Big Data Systems & Application (HPCC/DSS/SmartCity/DependSys)}, 
  title={Enhancing Cross-lingual Medical Concept Alignment by Leveraging Synonyms and Translations of the Unified Medical Language System}, 
  year={2022},
  volume={},
  number={},
  pages={2078-2083},
  abstract={Well-developed medical terminology systems like the Unified Medical Language System (UMLS) improve the ability of language models to handle medical entity linking tasks. However, such magnificent terminology systems are only available for few languages, such as English. For Chinese, both simplified and traditional, the lack of well-developed terminology systems remains a big challenge to unify Chinese medical terminologies by linking medical entities as concepts. In this study, we purpose a translation enhanced contrastive learning scheme which leverages translations and synonyms of UMLS to infuse knowledge into the language model, and present a cross-lingual pre-trained language model called TeaBERT that aligns cross-lingual Chinese and English medical synonyms well at semantic level. Comparing with former cross-lingual language models, TeaBERT significantly outperforms on evaluation datasets, with 93.21%, 89.89% and 76.45% of Top 5 accuracy on ICDI0-CN, CHPO and RealWorld dataset respectively, and achieves new state-of-theart performance without task specific fine-tuning. Our contrastive learning scheme can not only be used for enhancing Chinese-English medical concepts alignment, but also be applied to other languages facing the same challenges.},
  keywords={Terminology;Biological system modeling;Unified modeling language;Semantics;Knowledge representation;Task analysis;NLP;pre-trained language model;cross-lingual medical entity linking;UMLS},
  doi={10.1109/HPCC-DSS-SmartCity-DependSys57074.2022.00309},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{9340905,
  author={Jiang, Chen and Dehghan, Masood and Jagersand, Martin},
  booktitle={2020 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, 
  title={Understanding Contexts Inside Robot and Human Manipulation Tasks through Vision-Language Model and Ontology System in Video Streams}, 
  year={2020},
  volume={},
  number={},
  pages={8366-8372},
  abstract={Manipulation tasks in daily life, such as pouring water, unfold through human intentions. Being able to process contextual knowledge from these Activities of Daily Living (ADLs) over time can help us understand manipulation intentions, which are essential for an intelligent robot to transition smoothly between various manipulation actions. In this paper, to model the intended concepts of manipulation, we present a vision dataset under a strictly constrained knowledge domain for both robot and human manipulations, where manipulation concepts and relations are stored by an ontology system in a taxonomic manner. Furthermore, we propose a scheme to generate a combination of visual attentions and an evolving knowledge graph filled with commonsense knowledge. Our scheme works with real-world camera streams and fuses an attention-based Vision-Language model with the ontology system. The experimental results demonstrate that the proposed scheme can successfully represent the evolution of an intended object manipulation procedure for both robots and humans. The proposed scheme allows the robot to mimic human-like intentional behaviors by watching real-time videos. We aim to develop this scheme further for real-world robot intelligence in Human-Robot Interaction.},
  keywords={Visualization;Fuses;Ontologies;Real-time systems;Task analysis;Intelligent robots;Videos},
  doi={10.1109/IROS45743.2020.9340905},
  ISSN={2153-0866},
  month={Oct},}@ARTICLE{10539104,
  author={Li Chong, You and Poo Lee, Chin and Zen Muhd-Yassin, Shahrin and Ming Lim, Kian and Kamsani Samingan, Ahmad},
  journal={IEEE Access}, 
  title={TransKGQA: Enhanced Knowledge Graph Question Answering With Sentence Transformers}, 
  year={2024},
  volume={12},
  number={},
  pages={74872-74887},
  abstract={Knowledge Graph Question Answering (KGQA) plays a crucial role in extracting valuable insights from interconnected information. Existing methods, while commendable, face challenges such as contextual ambiguity and limited adaptability to diverse knowledge domains. This paper introduces TransKGQA, a novel approach addressing these challenges. Leveraging Sentence Transformers, TransKGQA enhances contextual understanding, making it adaptable to various knowledge domains. The model employs question-answer pair augmentation for robustness and introduces a threshold mechanism for reliable answer retrieval. TransKGQA overcomes limitations in existing works by offering a versatile solution for diverse question types. Experimental results, notably with the sentence-transformers/all-MiniLM-L12-v2 model, showcase remarkable performance with an F1 score of 78%. This work advances KGQA systems, contributing to knowledge graph construction, enhanced question answering, and automated Cypher query execution.},
  keywords={Knowledge graphs;Transformers;Question answering (information retrieval);Natural languages;Task analysis;Noise;Encoding;Question answering;knowledge graph;machine learning;natural language processing;Neo4j;sentence transformer},
  doi={10.1109/ACCESS.2024.3405583},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10393780,
  author={Yang, Yahu and Zhang, Hu and Xu, Jiashu and Song, Shenmin},
  booktitle={2023 IEEE 6th International Conference on Information Systems and Computer Aided Education (ICISCAE)}, 
  title={MATEKG: A Large-scale Multi-class Equipment Knowledge Graph for Military Auxiliary Tasks}, 
  year={2023},
  volume={},
  number={},
  pages={133-138},
  abstract={In the era of rapid advances in artificial intelligence, the digitization of armed forces around the world has seen unprecedented growth. A wealth of military information and knowledge is available on the Internet. The task of harnessing and analyzing this vast amount of data, and structuring the existing information to facilitate the development of information-centric weapons, has emerged as a prominent area of research. Knowledge graphs, which encapsulate and represent human knowledge in a format that machines can understand, are essential for performing tasks such as information retrieval, data analysis and inference. The creation of a knowledge graph specific to military equipment is a cornerstone in the process of military digitization. In this paper, a military equipment dataset is first constructed through structured data collection and processing based on the globally popular open data websites on equipment. Then, based on this military equipment dataset, a large-scale multi-class equipment knowledge graph for military auxiliary tasks is constructed by the proposed entity recognition method and relational triple extraction method. The experimental results show that the proposed BERT-enhanced BiLSTM and SPN achieve 90.43% and 93% F1 scores, respectively, proving the effectiveness of the proposed methods on the military equipment data.},
  keywords={Military computing;Weapons;Knowledge based systems;Knowledge graphs;Data collection;Information retrieval;Internet;knowledge graph;named entity recognition;relationship extraction;military equipment},
  doi={10.1109/ICISCAE59047.2023.10393780},
  ISSN={2770-663X},
  month={Sep.},}@INPROCEEDINGS{10679399,
  author={Karalka, Christina and Meditskos, Georgios and Papoutsoglou, Maria and Bassiliades, Nick},
  booktitle={2024 IEEE International Conference on Cyber Security and Resilience (CSR)}, 
  title={Towards a Generic Knowledge Graph Construction Framework for Privacy Awareness}, 
  year={2024},
  volume={},
  number={},
  pages={700-705},
  abstract={Knowledge graphs (KGs) organize data from multi-ple sources, capturing information about entities of interest in a given domain or task, such as people, places, or events, and forge connections between them. In this paper, we introduce a generic framework for building knowledge graphs designed to enhance data privacy through semantic interpretation. We demonstrate the effectiveness of our framework by applying it to the healthcare sector, where it helps organize and analyze com-plex information, support data analysis, improve decision-making processes, and uncover hidden relationships between entities. Our approach leverages domain-specific ontologies like SNOMED CT and integrates vector databases to assess and mitigate privacy risks. By using semantic techniques, we enhance the robustness of data against reidentification attacks and suggest appropriate de-identification methods. The integration of SNOMED with vector databases allows for efficient storage, retrieval, and analysis of high-dimensional healthcare data, facilitating advanced data an-alytics and knowledge discovery while maintaining data privacy. Through this framework, we aim to provide sufficient insights for identifying privacy vulnerabilities and ensuring the security and usability of sensitive health information.},
  keywords={Data privacy;Privacy;Databases;Semantics;Knowledge graphs;Medical services;Vectors},
  doi={10.1109/CSR61664.2024.10679399},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{9447453,
  author={Xu, Wenwen and Fang, Mingzhe and Yang, Li and Jiang, Huaxi and Liang, Geng and Zuo, Chun},
  booktitle={2021 International Conference on Computer Communication and Artificial Intelligence (CCAI)}, 
  title={Enabling Language Representation with Knowledge Graph and Structured Semantic Information}, 
  year={2021},
  volume={},
  number={},
  pages={91-96},
  abstract={Pre-trained language models have been widely recognized and applied. While common pre-training language representation models(PLMs) usually focus on grasping the co-occurrence of words or sentences in simple tasks, more and more researchers realize that external information, i.e., knowledge graph (KG) and clear structured semantics, can be vital in natural language understanding tasks. Therefore, using external information to enhance PLMs (such as BERT) has gradually become a popular direction. However, the existing improvement methods often only use a certain type of external information, and it is difficult to solve the problems of common PLMs that lack common sense and semantic incompleteness in one fell swoop. Suppose the model wants to integrate multiple external information. In that case, it not only requires the model to deal with the noise problem that external information may bring but also requires the model to ensure that different information can work together effectively. In this paper, we propose Sem-K-BERT, which integrates the information of KG and semantic role labeling(SRL) before and after the BERT encoding layer, and introduces a context-aware knowledge screening mechanism based on semantic correlation calculation and a text-semantic alignment mechanism to effectively integrate the two external information and reduce the impact of noise. Experiments and analysis on 8 different Chinese natural language processing tasks show that Sem-K-BERT has better performance than BERT and the BERT model that only incorporates KG. This indicates that the simultaneous use of knowledge graph and SRL information offers a promising solution to improve the performance of PLMs.},
  keywords={Analytical models;Correlation;Computational modeling;Semantics;Bit error rate;Grasping;Natural language processing;language model;knowledge graph;semantic information},
  doi={10.1109/CCAI50917.2021.9447453},
  ISSN={},
  month={May},}@INPROCEEDINGS{10754778,
  author={Govindharajan, Hariharan and Vijayakumar, Senthilkumar},
  booktitle={2024 IEEE 15th Annual Ubiquitous Computing, Electronics & Mobile Communication Conference (UEMCON)}, 
  title={A Framework for automated selective Fine-Tuning of Domain-Specific Large Language Models Using Graph-Based Retrieval Augmented Generation}, 
  year={2024},
  volume={},
  number={},
  pages={431-439},
  abstract={Graph based retrieval augmented generation technique in Large Language Model (LLM) brings in major advantages by providing deep context to LLMs through relational knowledge graph for text generation, classification, question and answering use cases. However, maintaining vast data volume of domain specific data in a knowledge graph with complex relationships and querying from it every time a prompt is being posted to LLM, is a time consuming and expensive process. This paper presents a novel framework for selectively fine-tuning domain-specific large language models (LLMs) using a multi-stage Knowledge Graph (KG) based Retrieval Augmented Generation (RAG) pipeline and an Automated Incremental Fine-tuning System (AIFS). The proposed system aims to enhance the accuracy and relevance of LLM responses for text generation and Question Answering use cases by finetuning the LLM incrementally based on highly sought and highly relevant information in knowledge graph identified by leveraging page rank algorithm in KG. The framework comprises three major subsystems: Knowledge Graph Generation, Automated Incremental fine-tuning system (AIFS), and Domain Based Information Retrieval (DBIR). The effectiveness of the system is demonstrated through its ability to incrementally fine-tune LLMs based on selected highly relevant nodes within the KG, thereby improving the model’s domain-specific knowledge, response accuracy by 90% and reduce cost by 71.8%.},
  keywords={Accuracy;Costs;Large language models;Pipelines;Knowledge graphs;Information retrieval;Mobile communication;Question answering (information retrieval);Artificial Intelligence(AI);Knowledge Graph(KG);Large Language Models(LLM);LLM Fine-tuning;Contextual Information Extraction &Retrieval Systems},
  doi={10.1109/UEMCON62879.2024.10754778},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10808357,
  author={Yongfei, Miao and Yihang, Zhang and Li, Wang and Xiaoxue, Song and Yuze, Song and Zekun, Tang},
  booktitle={2024 10th International Conference on Big Data and Information Analytics (BigDIA)}, 
  title={Millitary Knowledge Graph Construction Based on Universal Information Extraction Models}, 
  year={2024},
  volume={},
  number={},
  pages={877-881},
  abstract={Data in military domain is characterized by diverse types, scattered storage and high confidentiality, which greatly limits the promotion and application of knowledge graph in military domain. The advantage of big language model in understanding complex text and semantic relations provides a possibility for the automated construction of knowledge graph in military domain. This paper proposed a knowledge graph construction method for military domain based on Universal information extraction(UIE) models, which improved the automation level of knowledge graph construction in military domain through the steps of generating high-quality corpus by domain expert annotation, unified modeling information extraction task and model fine-tuning, and provided a reference for the wide application of knowledge graph in military domain.},
  keywords={Accuracy;Information resources;Decision making;Semantics;Knowledge graphs;Information retrieval;Data models;Data mining;Security;Military equipment;Large Language Models;Knowledge Graph;Information Extraction;Military Domain},
  doi={10.1109/BigDIA63733.2024.10808357},
  ISSN={2771-6902},
  month={Oct},}@INPROCEEDINGS{7934726,
  author={Shani, Uri},
  booktitle={2017 Annual IEEE International Systems Conference (SysCon)}, 
  title={Can ontologies prevent MBSE models from becoming obsolete?}, 
  year={2017},
  volume={},
  number={},
  pages={1-8},
  abstract={Model-based systems engineering provides a soft, manageable, and query-able representation of product design and lifecycle. However, at the same time, it creates a discontinuous space of data that does not integrate, constantly becomes outdated, and has to be upgraded as tools evolve. Models that are not maintained become legacy, and then become obsolete and useless. We look at how ontologies that follow the semantic web technology for data representation can create interoperability among the modeling tools, support model reuse, and fight the aging and obsolescence of models.},
  keywords={Tools;Ontologies;Resource description framework;OWL;Semantics;Data models;Ontology;MBSE;modeling;obsolescence;reusability;interoperability},
  doi={10.1109/SYSCON.2017.7934726},
  ISSN={2472-9647},
  month={April},}@INPROCEEDINGS{10578858,
  author={Lehmann, Alexander and Landes, Dieter},
  booktitle={2024 IEEE Global Engineering Education Conference (EDUCON)}, 
  title={Extracting Metadata from Learning Videos for Ontology-Based Recommender Systems Using Whisper & GPT}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={In modern education, individualized learning environments play a vital role by allowing learners to tailor their learning paths based on personal needs, interests, and abilities. Achieving effective individualization relies on dynamic adaptation of the learning path, typically facilitated by recommender systems. These systems offer personalized suggestions, commonly employing content-based or collaborative filtering approaches. However, traditional recommender systems often lack consideration of the semantics of learning elements. To address this limitation, ontology-based recommender systems integrate semantic modeling, establishing additional connections within a domain to enhance precision and context in recommendations. Notably, these systems mitigate the cold start problem and are particularly advantageous in learning environments with limited data. While videos are prevalent in learning platforms, their unstructured nature poses challenges for processing. This paper introduces an innovative approach, leveraging Large Language Models, specifically GPT, to extract metadata from learning videos. The proposed method intelligently augments videos and links them to a domain ontology, enabling the integration of videos into ontology-based recommender systems. The application of this approach is demonstrated through a case study in software engineering education, showcasing its potential to enhance individualized learning experiences in specific domains. The presented method offers an automated alternative to manual video processing, aligning with the evolving landscape of education technology.},
  keywords={Large language models;Semantics;Manuals;Metadata;Ontologies;Engineering education;Recommender systems;learning analytics;adaptive learning environments;generative AI;large language models;ontology-based recommender systems;learning videos},
  doi={10.1109/EDUCON60312.2024.10578858},
  ISSN={2165-9567},
  month={May},}@INPROCEEDINGS{10096669,
  author={Su, Ruolin and Yang, Jingfeng and Wu, Ting-Wei and Juang, Biing-Hwang},
  booktitle={ICASSP 2023 - 2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={Choice Fusion As Knowledge For Zero-Shot Dialogue State Tracking}, 
  year={2023},
  volume={},
  number={},
  pages={1-5},
  abstract={With the demanding need for deploying dialogue systems in new domains with less cost, zero-shot dialogue state tracking (DST), which tracks user’s requirements in task-oriented dialogues without training on desired domains, draws attention increasingly. Although prior works have leveraged question-answering (QA) data to reduce the need for in-domain training in DST, they fail to explicitly model knowledge transfer and fusion for tracking dialogue states. To address this issue, we propose CoFunDST, which is trained on domain-agnostic QA datasets and directly uses candidate choices of slot-values as knowledge for zero-shot dialogue-state generation, based on a T5 pre-trained language model. Specifically, CoFunDST selects highly-relevant choices to the reference context and fuses them to initialize the decoder to constrain the model outputs. Our experimental results show that our proposed model achieves outperformed joint goal accuracy compared to existing zero-shot DST approaches in most domains on the MultiWOZ 2.1. Extensive analyses demonstrate the effectiveness of our proposed approach for improving zero-shot DST learning from QA.},
  keywords={Training;Costs;Fuses;Signal processing;Data models;Decoding;Task analysis;Dialogue state tracking;zero-shot;question answering;pre-trained language model;knowledge fusion},
  doi={10.1109/ICASSP49357.2023.10096669},
  ISSN={2379-190X},
  month={June},}

@INPROCEEDINGS{9678627,
  author={Xue, Zengcan and Liu, Hai and Zhang, Zhaoli and Yang, Shuoqiu},
  booktitle={2021 IEEE International Conference on Engineering, Technology & Education (TALE)}, 
  title={Dynamic Educational Knowledge Graph Model via Information Entropy for Knowledge Building}, 
  year={2021},
  volume={},
  number={},
  pages={01-07},
  abstract={Knowledge building is the production and continual improvement of ideas of value to a community, which attaches importance to conceptual engagement and contribution. However, knowledge building community will accumulate large and complex semi-structured educational data over time. It is not conducive to the continuation of in-depth knowledge building activities. To overcome these issues, we propose a dynamic educational knowledge graph with information entropy (IE-DEKG) model for knowledge building community. The model can construct dynamic knowledge graphs that contain instructional concepts and educational relations for learners. Specifically, it adopts the mutual information and adjacent information entropy to detect new terminologies on pedagogical data, and then the topic modeling algorithm is utilized to extract instructional concepts. Moreover, the model employs association rule mining to identify the prerequisite relations and uses pattern matching to obtain the inclusion relations. For the sake of satisfying the needs of educational applications and services, we design and implement the dynamic educational knowledge graph system. Experimental results demonstrate that the proposed IE-DEKG method outperforms the state-of-the-art methods.},
  keywords={Matched filters;Terminology;Education;Production;Information filters;Data models;Data mining;knowledge building;educational knowledge graph;information entropy;concept extraction;educational relation;system design},
  doi={10.1109/TALE52509.2021.9678627},
  ISSN={2470-6698},
  month={Dec},}@INPROCEEDINGS{10538922,
  author={Chen, Chen and Xia, Chunhe and Wang, Tianbo and Lin, Wanshuang and Zhao, Yuan and Li, Yang},
  booktitle={2023 IEEE 22nd International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom)}, 
  title={EFwork: An Efficient Framework for Constructing a Malware Knowledge Graph}, 
  year={2023},
  volume={},
  number={},
  pages={1258-1265},
  abstract={Malware Knowledge Graph (MKG) serves as an essential auxiliary tool for malware detection and analysis. However, the construction of MKG faces several challenges, such as inadequate dataset quality, incomplete entity feature extraction, and the limitations imposed by deep learning techniques. To address these issues, we present an Efficient Framework for constructing a malware knowledge graph (EFwork). Firstly, we build a High-Quality Dataset (HQDataset) and introduce a metric for data quality assessment based on knowledge coverage, timeliness, and density. Subsequently, we develop a Named Entity Recognition (NER) model that extracts character features, part-of-speech features, and word features from the data, leveraging deep learning models to identify malware-related entities. Finally, we implement a rule-based filtering mechanism, utilizing a comprehensive Rule Database to eliminate entities that do not conform to predefined rules. Experimental result shows that our HQDataset demonstrates superior data quality when compared to other open-source datasets. Furthermore, our NER model combined with our Rule Database outperforms existing models, achieving improvements of 0.67%, 0.74%, and 0.69% in Precision, Recall, and F1-Score, respectively.},
  keywords={Measurement;Deep learning;Databases;Filtering;Data integrity;Knowledge graphs;Feature extraction;Malware;Knowledge Graph;Dataset Quality;Named Entity Recognition},
  doi={10.1109/TrustCom60117.2023.00171},
  ISSN={2324-9013},
  month={Nov},}@INPROCEEDINGS{10365964,
  author={Liu, Zhipeng and Weng, Heng and Yan, Jun and Liu, Hai and Hao, Tianyong},
  booktitle={2023 IEEE International Symposium on Product Compliance Engineering - Asia (ISPCE-ASIA)}, 
  title={Query Reformulator And Contrastive Answer Ranker For Conversational Question Answering Over Knowledge Graph}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={Conversational KGQA (Knowledge Graph Question Answering) is a sequential process of question-answering over a knowledge graph (KG). Conversational KGQA involves follow-up questions that are presented in anaphoric or abbreviated form, known as ellipsis. Another challenge is the difficulty in selecting corrects answer for follow-up questions from a large number of candidate answers from KGs. This paper aims to tackle the challenge of alleviating the ellipsis phenomena and selecting correct answers from copious candidates. We present a module called CSR, which effectively merges information-retrieval-based method with pretrained language models. This module aims to identify the most relevant entity for elliptical questions based on instructional templates and subsequently rephrase the questions. Additionally, we propose a contrastive answer ranker to address the challenge of selecting the correct answer from copious candidates by leveraging the relationship between the questions and answers. Leveraging fewer trainable parameters, our method outperforms baselines on ConvQuestions and surpass the F1-Score metric of state-of-the-art on ConvRef dataset.},
  keywords={Measurement;Asia;Knowledge graphs;Oral communication;Question answering (information retrieval);Standards;Question Answering;Conversation;Knowledge Graph},
  doi={10.1109/ISPCE-ASIA60405.2023.10365964},
  ISSN={2831-3410},
  month={Nov},}@INPROCEEDINGS{10386891,
  author={Jiang, Wenjuan and Guo, Yi and Fu, Jiaojiao},
  booktitle={2023 IEEE International Conference on Big Data (BigData)}, 
  title={Temporal Knowledge Graph Question Answering Models Enhanced with GAT}, 
  year={2023},
  volume={},
  number={},
  pages={1162-1167},
  abstract={Temporal Knowledge Graph Question Answering (TKGQA) task aims to find an entity or timestamp from a temporal knowledge graph to answer temporal reasoning questions. However, most existing models fail to capture the implicit temporal information in the questions, resulting in weak performance when handling complex temporal reasoning tasks. To address this issue, this paper proposes a novel TKGQA model called GATQR, which integrates graph attention mechanism. The model utilizes a pre-trained temporal knowledge base in the form of quadruples and introduces Graph Attention Network (GAT) to effectively capture the implicit temporal information in the questions. By integrating with relation representations trained by the RoBERTa, it further enhances the temporal relationship representation in the queries. Finally, this representation is combined with the pre-trained TKG embeddings to predict the entity or timestamp with the highest score as the answer. Experimental results on the largest benchmark dataset CronQuestion demonstrate that compared to baseline models such as CronKGQA, EntityQR, and TempoQR-Soft, the GATQR achieves significant improvements in Hits@l results for handling complex and temporal question types, with increases of 35% and 13%, 18% and 9%, and 9% and 3%, respectively. These results validate the effectiveness and superiority of the GATQR model in capturing implicit temporal information and enhancing complex reasoning capabilities.},
  keywords={Knowledge engineering;Navigation;Merging;Knowledge based systems;Knowledge graphs;Cognition;Question answering (information retrieval);Temporal Knowledge Graph;Complex Questions Answering;Graph Attention Network;Temporal Reasoning;temporal relationship representation},
  doi={10.1109/BigData59044.2023.10386891},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{8622503,
  author={Kharlamov, Evgeny and Martin-Recuerda, Francisco and Perry, Brandon and Cameron, David and Fjellheim, Roar and Waaler, Arild},
  booktitle={2018 IEEE International Conference on Big Data (Big Data)}, 
  title={Towards Semantically Enhanced Digital Twins}, 
  year={2018},
  volume={},
  number={},
  pages={4189-4193},
  abstract={Digital twins (DTs) are a powerful mechanism for representing complex industrial assets such as oil platforms as digital models. These models can facilitate temporal analyses and computer simulations of assets. In order to enable this, DTs should be able to capture characteristics of an asset as specified by the manufacturer, its state during the run time, as well as how the asset interacts with other assets in a complex system. We argue that semantic technologies and in particular semantic models or ontologies is promising modelling paradigm for DTs. Semantic models allow to capture complex systems in an intuitive fashion, can be written in standardised ontology languages, and come with a wide range of off-the-shelf systems to design, maintain, query, and navigate semantic models. In this work we report our preliminary results on developing a system that would support semantic-based DTs. In particular, we plan to augment the PI System developed by OSIsoft with ontologies and show how the resulting solution can help in simplifying analytical and machine learning routines for DTs.},
  keywords={Data models;Semantics;Analytical models;Computational modeling;Context modeling;Ontologies;Turbines},
  doi={10.1109/BigData.2018.8622503},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{9276945,
  author={Trivedi, Ishdutt and Majhi, Sudhan},
  booktitle={2020 5th International Conference on Computing, Communication and Security (ICCCS)}, 
  title={Span Level Model for the Construction of Scientific Knowledge Graph}, 
  year={2020},
  volume={},
  number={},
  pages={1-6},
  abstract={In the recent years, knowledge graphs (KGs) are getting lots of attention due to their wide applications. Constructing KGs involves two major steps, named entity recognition (NER) and relation extraction (RE). Current approaches for extracting entities and relation use (beginning, outside, inside) BIO/(beginning, inside, last, outside, unit) BILOU based models which faces issues of cascading errors. In this paper, we introduce a novel neural architecture for the construction of scientific KG employing span based methods for extraction of entities, unlike previous models which use BIO/BILOU based approach. We use bidirectional encoder representations from transformers (BERT) word embeddings for this task and neural network classifier for the detection of entities in the span and convolutional neural network (CNN) for extracting relation between the entities. Evaluation results yield the recall, precision and f-measure values of 70.61%, 71.16% and 70.88% respectively for NER, and 54.89%, 50.72% and 52.72% respectively for RE task. Results show that our model outperforms the previous models for the scientific dataset, SciERC, by a margin of 3% in entity extraction task and 7% for the relation extraction task. We achieved these results without raising the overall complexity of the model.},
  keywords={Task analysis;Data mining;Bit error rate;Neural networks;Feature extraction;Training;Faces},
  doi={10.1109/ICCCS49678.2020.9276945},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{8104505,
  author={Zambon, Eduardo and Guizzardi, Giancarlo},
  booktitle={2017 Federated Conference on Computer Science and Information Systems (FedCSIS)}, 
  title={Formal definition of a general ontology pattern language using a graph grammar}, 
  year={2017},
  volume={},
  number={},
  pages={1-10},
  abstract={In recent years, there has been a growing interest in the use of ontological theories in the philosophical sense (Foundational Ontologies) to analyze and (re)design conceptual modeling languages. This paper is about an ontologically well-founded conceptual modeling language in this tradition, termed OntoUML. This language embeds a number of ontological patterns that reflect the micro-theories comprising a particular foundational ontology named UFO. We here (re)define OntoUML as a formal graph grammar and demonstrate how the models of this language can be constructed by the combined application of ontological patterns following a number of graph transformation rules. As a result, we obtain a version of this language fully defined as a formal Ontology Pattern Grammar. In other words, this paper presents a formal definition of OntoUML that is both explicit in terms of the ontological patterns that it incorporates and is completely independent of the UML meta-model.},
  keywords={Unified modeling language;Ontologies;Grammar;Computational modeling;Aggregates;Tools},
  doi={10.15439/2017F001},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10650208,
  author={Kang, Jiaju and Pan, Weichao and Zhang, Tian and Wang, Ziming and Yang, Shuqin and Wang, Zhiqin and Wang, Jian and Niu, Xiaofei},
  booktitle={2024 International Joint Conference on Neural Networks (IJCNN)}, 
  title={Correcting Factuality Hallucination in Complaint Large Language Model via Entity-Augmented}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={Complaint Large Language Model (Complaint-LLM) is designed as a "customer service" tool to address the scenario of handling a massive volume of public complaints, effectively leveraging the "common sense" possessed by Large Language Models (LLMs) to solve issues. Unfortunately, pre-trained LLMs often exhibit significant Factual Hallucination and Causal Errors in knowledge domains with sparse experience distribution, greatly affecting the accuracy of user interactions with LLMs. We propose an architecture that utilizes external data to support pre-trained models, aiming to avoid the expensive cost of retraining LLMs. The core concept involves leveraging prompts to inject strongly correlated additional information into LLMs and adjusting the initialized alternative outputs along the inference pathway of the LLM. To achieve this, we construct a rich knowledge graph as a knowledge base for algorithm retrieval and learning. Each input text is decomposed into subgraphs corresponding to nodes on the knowledge graph, and a graph neural network classifier is trained to obtain classification results and additional knowledge. Numerous experiments demonstrate that the Complaint-LLMs shows a significant improvement in the question-answering evaluation of various subclass scenarios in the complaint domain. Moreover, the graph neural network trained with complaint text data exhibits good transferability in classification tests for open scenarios.},
  keywords={Knowledge engineering;Measurement;Accuracy;Large language models;Semantics;Knowledge graphs;Transforms},
  doi={10.1109/IJCNN60899.2024.10650208},
  ISSN={2161-4407},
  month={June},}@INPROCEEDINGS{10750098,
  author={Buchmüller, Raphael and Fürst, Daniel and Frings, Alexander and Schlegel, Udo and Keim, Daniel},
  booktitle={2024 IEEE Visual Analytics Science and Technology VAST Challenge}, 
  title={Visual Bias Detection for Addressing Illegal Fishing Activities}, 
  year={2024},
  volume={},
  number={},
  pages={9-10},
  abstract={In this work, we present a visual analytics approach designed to address the 2024 VAST Challenge Mini-Challenge 1, which focuses on detecting bias in a knowledge graph. Our solution utilizes pixel-based visualizations to explore patterns within the knowledge graph, CatchNet, which is employed to identify potential illegal fishing activities. CatchNet is constructed by FishEye analysts who aggregate open-source data, including news articles and public reports. They have recently begun incorporating knowledge extracted from these sources using advanced language models. Our method combines pixel-based visualizations with ordering techniques and sentiment analysis to uncover hidden patterns in both the news articles and the knowledge graph. Notably, our analysis reveals that news articles covering critiques and convictions of companies are subject to elevated levels of bias.},
  keywords={Sentiment analysis;Visual analytics;Large language models;Pipelines;Data visualization;Knowledge graphs;Companies;Data aggregation;VAST Challenge;Mini-Challenge 1;Visual Analytics;LLM;Pixel Visualization},
  doi={10.1109/VASTChallenge64683.2024.00009},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10446325,
  author={Xu, Hongshen and Cao, Ruisheng and Zhu, Su and Jiang, Sheng and Zhang, Hanchong and Chen, Lu and Yu, Kai},
  booktitle={ICASSP 2024 - 2024 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={A Birgat Model for Multi-Intent Spoken Language Understanding with Hierarchical Semantic Frames}, 
  year={2024},
  volume={},
  number={},
  pages={12251-12255},
  abstract={Previous work on spoken language understanding (SLU) mainly focuses on single-intent settings, where each input utterance merely contains one user intent. This configuration significantly limits the surface form of user utterances and the capacity of output semantics. In this work, we firstly propose a Multi-Intent dataset which is collected from a realistic in-Vehicle dialogue System, called MIVS. The target semantic frame is organized in a 3-layer hierarchical structure to tackle the alignment and assignment problems in multi-intent cases. Accordingly, we devise a BiRGAT model to encode the hierarchy of ontology items, the backbone of which is a dual relational graph attention network. Coupled with the 3-way pointer-generator decoder, our method outperforms traditional sequence labeling and classification-based schemes by a large margin. Ablation study in transfer learning settings further uncovers the poor generalizability of current models in multi-intent cases.},
  keywords={Semantics;Transfer learning;Ontologies;Signal processing;Acoustics;Decoding;Labeling;Spoken Language Understanding;relational graph attention network;hierarchical semantic frame},
  doi={10.1109/ICASSP48485.2024.10446325},
  ISSN={2379-190X},
  month={April},}@INPROCEEDINGS{10731381,
  author={Grassi, Lucrezia and Recchiuto, Carmine Tommaso and Sgorbissa, Antonio},
  booktitle={2024 33rd IEEE International Conference on Robot and Human Interactive Communication (ROMAN)}, 
  title={Enhancing LLM-Based Human-Robot Interaction with Nuances for Diversity Awareness}, 
  year={2024},
  volume={},
  number={},
  pages={2287-2294},
  abstract={This paper presents a system for diversity-aware autonomous conversation leveraging the capabilities of large language models (LLMs). The system adapts to diverse populations and individuals, considering factors like background, personality, age, gender, and culture. The conversation flow is guided by the structure of the system’s pre-established knowledge base, while LLMs are tasked with various functions, including generating diversity-aware sentences. Achieving diversity-awareness involves providing carefully crafted prompts to the models, incorporating comprehensive information about users, conversation history, contextual details, and specific guidelines. To assess the system’s performance, we conducted both controlled and real-world experiments, measuring a wide range of performance indicators.},
  keywords={Large language models;Knowledge based systems;Human-robot interaction;Oral communication;Ontologies;Hybrid power systems;Time factors;Noise measurement;History;Robots},
  doi={10.1109/RO-MAN60168.2024.10731381},
  ISSN={1944-9437},
  month={Aug},}@INPROCEEDINGS{10385489,
  author={Qi, JuanZhi and Wang, XinYu and Yang, Tao},
  booktitle={2023 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)}, 
  title={Traditional Chinese Medicine Prescription Recommendation Model Based on Large Language Models and Graph Neural Networks}, 
  year={2023},
  volume={},
  number={},
  pages={4623-4627},
  abstract={Background: Traditional Chinese medicine (TCM) has a millennia-long history, offering unique treatments and insights into global health. Given the intricate symptoms and shifting syndrome patterns, prescribing can be tough for young doctors. TCM prescription recommendations can help these doctors address their experience gap. In recent years, with advancements in technologies such as artificial intelligence and big data, intelligent recommendations for TCM prescriptions have become feasible, holding significant implications for enhancing treatment efficacy and optimizing patient experience. Objective: This study aims to establish a novel TCM prescription recommendation model by integrating large language models with Graph Neural Network (GNN) to enhance the accuracy of prescription suggestions. Method: Based on the co-occurrence of symptoms and herbal medicines, we constructed symptom graphs, symptom-herb graphs, and herb-herb graphs. Using Graph Convolutional Network (GCN), we acquired embeddings for both symptoms and herbs. The symptom embeddings are then integrated with insights from large language model embeddings, while auxiliary information from an external knowledge graph is incorporated into the herb embeddings. A final list of herb recommendations was generated by interacting with the embeddings of symptoms and herbs. Results: The proposed algorithm achieved 22.1%, 17.2%, and 13% on the evaluation metrics P@5, P@10, and P@20, respectively. Concurrently, scores for R@5, R@10, and R@20 were 14%, 24%, and 32.5%, respectively. The P@5 metric surpassed the KDHR by 4.7%, and the R@20 metric exceeded the KDHR by 6%. Overall, the performance of our model outperformed other baseline models across various evaluation criteria. Conclusion: The TCM prescription recommendation model, infused with information from a large language model, can effectively enhance the outcomes of TCM prescription recommendations. The study may offer valuable insights for auxiliary clinical research and treatment in TCM.},
  keywords={Measurement;Knowledge engineering;Biological system modeling;Knowledge graphs;Self-supervised learning;Medical services;Graph neural networks;Prescription recommendation;Large language model;Traditional Chinese Medicine;Graph neural network},
  doi={10.1109/BIBM58861.2023.10385489},
  ISSN={2156-1133},
  month={Dec},}@INPROCEEDINGS{9202197,
  author={Liang, Xuchao and Cao, Han and Zhang, Weizhen},
  booktitle={2020 IEEE International Conference on Power, Intelligent Computing and Systems (ICPICS)}, 
  title={Knowledge Extraction Experiment Based on Tourism Knowledge Graph Q & A Data Set}, 
  year={2020},
  volume={},
  number={},
  pages={828-832},
  abstract={At present, the most natural language processing tasks use common data sets for experiments. However, as the concept of domain knowledge graphs is proposed, domain-based data sets have gradually become a demand. In this article, we collect data from various travel websites and official websites of tourist attractions, and use this to build a question and answer data set. At the same time, we also introduce the current Bert model with outstanding effect in the nlp field, and use this model to conduct experiments in the travelling question and answer data set. The experimental results not only show the feasibility of the constructed tourism data set, but also lay a foundation for the subsequent construction of a knowledge question answering system for tourism knowledge graph.},
  keywords={Natural language processing;Task analysis;Knowledge discovery;Semantics;Computational modeling;Data models;Context modeling;Knowledge map;tourism data;named entity recognition;relationship recognition},
  doi={10.1109/ICPICS50287.2020.9202197},
  ISSN={},
  month={July},}@INPROCEEDINGS{10020689,
  author={Pugazhenthi, Thamizhiniyan and Liang, Huizhi},
  booktitle={2022 IEEE International Conference on Big Data (Big Data)}, 
  title={Improving Conversational Recommender Systems via Knowledge Graph-based Semantic Fusion with Historical Interaction Data}, 
  year={2022},
  volume={},
  number={},
  pages={4303-4312},
  abstract={Conversational recommender systems (CRS) use interactive discussions to recommend high-quality items to users. Two essential components in a good CRS are the recommendation module that makes pertinent product recommendations to consumers and a conversation component that creates text-based sentences with product recommendations. The most commonly used dataset to train CRS models is ReDial. In this paper, we found that using the INSPIRED dataset in place of the ReDial dataset significantly improves model performance in terms of effectiveness. Along with the INSPIRED dataset, the inclusion of historical data in the input improves efficiency. The accuracy and efficiency of the model increase when we include the historical data into the system in the form of DialoGPT corpus and Gutenberg books. The paper further extends to compare three versions of state-of-the-art knowledge graph based conversational recommender systems called KGSF â one with the INSPIRED dataset with history, one with the INSPIRED dataset without historical data and the last with the ReDial dataset without historical data, which is the original version of the KGSF model. The comparison between three versions of the KGSF model shows that the change of the dataset and the inclusion of historical data can promote the performance of this conversational recommendation system.},
  keywords={Vocabulary;Semantics;Natural languages;Oral communication;Machine learning;Big Data;Data models;natural language processing;conversational recommender systems},
  doi={10.1109/BigData55660.2022.10020689},
  ISSN={},
  month={Dec},}@ARTICLE{10670469,
  author={Yan, Youfu and Hou, Yu and Xiao, Yongkang and Zhang, Rui and Wang, Qianwen},
  journal={IEEE Transactions on Visualization and Computer Graphics}, 
  title={KNowNEt:Guided Health Information Seeking from LLMs via Knowledge Graph Integration}, 
  year={2025},
  volume={31},
  number={1},
  pages={547-557},
  abstract={The increasing reliance on Large Language Models (LLMs) for health information seeking can pose severe risks due to the potential for misinformation and the complexity of these topics. This paper introduces KnowNet a visualization system that integrates LLMs with Knowledge Graphs (KG) to provide enhanced accuracy and structured exploration. Specifically, for enhanced accuracy, KnowNet extracts triples (e.g., entities and their relations) from LLM outputs and maps them into the validated information and supported evidence in external KGs. For structured exploration, KnowNet provides next-step recommendations based on the neighborhood of the currently explored entities in KGs, aiming to guide a comprehensive understanding without overlooking critical aspects. To enable reasoning with both the structured data in KGs and the unstructured outputs from LLMs, KnowNet conceptualizes the understanding of a subject as the gradual construction of graph visualization. A progressive graph visualization is introduced to monitor past inquiries, and bridge the current query with the exploration history and next-step recommendations. We demonstrate the effectiveness of our system via use cases and expert interviews.},
  keywords={Knowledge graphs;Visualization;Alzheimer's disease;Accuracy;Data visualization;Large language models;Electronic mail;Human-AI interactions;knowledge graph;conversational agent;large language model;progressive visualization},
  doi={10.1109/TVCG.2024.3456364},
  ISSN={1941-0506},
  month={Jan},}@ARTICLE{9207885,
  author={Mendsaikhan, Otgonpurev and Hasegawa, Hirokazu and Yamaguchi, Yukiko and Shimada, Hajime},
  journal={IEEE Access}, 
  title={Quantifying the Significance and Relevance of Cyber-Security Text Through Textual Similarity and Cyber-Security Knowledge Graph}, 
  year={2020},
  volume={8},
  number={},
  pages={177041-177052},
  abstract={In order to proactively mitigate cyber-security risks, security analysts have to continuously monitor sources of threat information. However, the sheer amount of textual information that needs to be processed is overwhelming, and it requires a great deal of mundane labor to separate the threats from the noise. We propose a novel approach to represent the relevance and significance of the cyber-security text in quantitative numbers. We trained custom Named Entity Recognition (NER) model and constructed a Cyber-security Knowledge Graph (CKG) to infer the subjective relevance of the cyber-security text to the user and to generate correlation features. In addition, the significance of the given text was analyzed in terms of its textual similarity with different repositories of pre-defined “significant” text and the maximum similarities were computed. These analysis results then act as features of the classifier to generate the significance score. The experimental result showed that the overall system could determine the significance and relevance of the text within a controlled environment with 88% accuracy.},
  keywords={Computer security;Data mining;Task analysis;Autonomous systems;Tagging;Computational modeling;Cyber-security knowledge graph;cyber threat;text analysis;textual similarity},
  doi={10.1109/ACCESS.2020.3027321},
  ISSN={2169-3536},
  month={},}@ARTICLE{10058174,
  author={Xu, Liang and Chen, Tao and Hou, Zhaoxiang and Zhang, Weishan and Hon, Chitin and Wang, Xiao and Wang, Di and Chen, Long and Zhu, Wenyin and Tian, Yunlong and Ning, Huansheng and Wang, Fei-Yue},
  journal={IEEE Transactions on Computational Social Systems}, 
  title={Knowledge Graph-Based Reinforcement Federated Learning for Chinese Question and Answering}, 
  year={2024},
  volume={11},
  number={1},
  pages={1035-1045},
  abstract={Knowledge question and answering (Q&A) is widely used. However, most existing semantic parsing methods in Q&A usually use cascading, which can incur error accumulation. In addition, using only one institution’s Q&A data definitely will limit the Q&A performance, while data privacy prevents sharing between institutions. This article proposes a knowledge graph-based reinforcement federated learning (KGRFL)-based Q&A approach to address these challenges. We design an end-to-end multitask semantic parsing model [MSP-bidirectional and auto-regressive transformers (BART)] that identifies question categories while converting questions into SPARQL statements to improve semantic parsing. Meanwhile, a reinforcement learning (RL)-based model fusion strategy is proposed to improve the effectiveness of federated learning, which enables multi-institution joint modeling and data privacy protection using cross-domain knowledge. In particular, it also reduces the negative impact of low-quality clients on the global model. Furthermore, a prompt learning-based entity disambiguation method is proposed to address the semantic ambiguity problem because of joint modeling. The experiments show that the proposed method performs well on different datasets. The Q&A results of the proposed approach outperform the approach of using only a single institution. Experiments also demonstrate that the proposed approach is resilient to security attacks, which is required for real applications.},
  keywords={Data models;Semantics;Federated learning;Knowledge graphs;Data privacy;Transformers;Multitasking;Question answering (information retrieval);Reinforcement learning;Knowledge graph;multitask semantic parsing [MSP-bidirectional and auto-regressive transformers (BART)];prompt learning;question and answering (Q&A);reinforcement federated learning (RFL)},
  doi={10.1109/TCSS.2023.3246795},
  ISSN={2329-924X},
  month={Feb},}@INPROCEEDINGS{10299526,
  author={Vuong, Thi-Hai-Yen and Hoang, Minh-Quan and Nguyen, Tan-Minh and Nguyen, Hoang-Trung and Nguyen, Ha-Thanh},
  booktitle={2023 15th International Conference on Knowledge and Systems Engineering (KSE)}, 
  title={Constructing a Knowledge Graph for Vietnamese Legal Cases with Heterogeneous Graphs}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={We develop a novel approach to construct a knowledge graph encompassing legal case documents and relevant legislation to improve legal information organization and retrieval. Our method involves data collection, entity extraction, and graph construction using natural language processing techniques. The constructed heterogeneous graph connects courts, cases, domains, and laws, significantly enriching information provided by retrieval systems. Our approach demonstrates potential in case analysis, legal recommendations, and decision support, providing valuable insights and resources for the legal domain.},
  keywords={Knowledge engineering;Law;Refining;Decision making;Legislation;Knowledge graphs;Organizations;knowledge graph;legal case documents;relevant law identification;heterogeneous graph;unsupervised learning},
  doi={10.1109/KSE59128.2023.10299526},
  ISSN={2694-4804},
  month={Oct},}@INPROCEEDINGS{9345000,
  author={Zhang, Jie and Pei, Zhongmin and Xiong, Wei and Luo, Zhangkai},
  booktitle={2020 IEEE 6th International Conference on Computer and Communications (ICCC)}, 
  title={Answer Extraction with Graph Attention Network for Knowledge Graph Question Answering}, 
  year={2020},
  volume={},
  number={},
  pages={1645-1650},
  abstract={In the knowledge graph question answering, the graph neural network can be used to encode the subgraph nodes related to the question entity to select the correct answer node. However, existing researches mainly focus on the modalities for the node encoding with graph neural network, ignoring that different types of subgraphs have different requirements for encoding information. To overcome the problem, this paper divides the subgraph into two types: the searching graph and the extending graph. Then we propose an answer extraction method with graph attention network for the searching graph, which can weight the information of neighbor nodes with different attention instead of the average. The hierarchical attention is also introduced to integrate question information into the subgraph node embedding to obtain the node presentation with question dependency. The accuracy of 48.2% is achieved on the CommonsenseQA dataset, which is much higher than the random guess (20%). In addition, the accuracy of the simplified model with no hierarchical attention decreases by 3.5%, which indicates the hierarchical attention mechanism can improve the predictive performance of the proposed model.},
  keywords={Computational modeling;Predictive models;Knowledge discovery;Search problems;Graph neural networks;Encoding;Task analysis;knowledge graph question answering;answer extraction;the searching graph;graph attention network;hierarchical attention},
  doi={10.1109/ICCC51575.2020.9345000},
  ISSN={},
  month={Dec},}@ARTICLE{10210018,
  author={Wang, Lihu and Liu, Xuemei and Liu, Yang and Li, Hairui and Liu, Jiaqi and Yang, Libo},
  journal={IEEE Access}, 
  title={Knowledge Graph-Based Method for Intelligent Generation of Emergency Plans for Water Conservancy Projects}, 
  year={2023},
  volume={11},
  number={},
  pages={84414-84429},
  abstract={In response to the issues of poor content correlation and insufficient intelligent decision support in emergency plans for water conservancy projects, a method for intelligent generation of emergency plans based on knowledge graphs is proposed. Utilizing pre-trained language models (PTM) based on entity masking, the accuracy of entity recognition tasks is enhanced by uncovering contextual features surrounding the masked entities. By employing translations, rotations, and superpositions within the vector space, a multiview convolutional neural network (MCNN) is constructed to enhance the accuracy of relation extraction through complementary and integrated feature representation. Integrating PTM with MCNN enables the construction of an emergency entity relationship extraction method based on PTM-MCNN. Neo4j is utilized for storing entity relationship triplets to construct an emergency knowledge graph. Through the utilization of the mutual information criterion, knowledge retrieval and matching are performed to accomplish the intelligent generation of emergency plans. The results indicate that PTM-MCNN achieves high recognition accuracy (F1 score of 92.2%), ensuring the reliability of the generated emergency plans. Related studies can effectively improve the intelligence of emergency management of water conservancy projects.},
  keywords={Transformers;Feature extraction;Knowledge graphs;Computational modeling;Water conservation;Task analysis;Bit error rate;Emergency services;Water conservation;Convolutional neural networks;Large-scale systems;Emergency plan;knowledge graph;water conservancy projects;convolutional neural network;large-scale pre-trained model},
  doi={10.1109/ACCESS.2023.3302399},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{9667720,
  author={Li, Weichen and Abels, Patrick and Ahmadi, Zahra and Burkhardt, Sophie and Schiller, Benjamin and Gurevych, Iryna and Kramer, Stefan},
  booktitle={2021 IEEE International Conference on Big Knowledge (ICBK)}, 
  title={Topic-Guided Knowledge Graph Construction for Argument Mining}, 
  year={2021},
  volume={},
  number={},
  pages={315-322},
  abstract={Decision-making tasks usually follow five steps: identifying the problem, collecting data, extracting evidence, iden-tifying arguments, and making the decision. This paper focuses on two steps of decision-making: extracting evidence by building knowledge graphs (KGs) of specialized topics and identifying sentences' arguments through sentence-level argument mining. We present a hybrid model that combines topic modeling using latent Dirichlet allocation (LDA) and word embeddings to obtain external knowledge from structured and unstructured data. We use a topic model to extract topic- and sentence-specific evidence from the structured knowledge base Wikidata. A knowledge graph is constructed based on the cosine similarity between the entity word vectors of Wikidata and the vector of the given sentence. A second graph based on topic-specific articles found via Google supplements the general incompleteness of the structured knowledge base. Combining these graphs, we obtain a graph-based model that, as our evaluation shows, successfully capitalizes on both structured and unstructured data.},
  keywords={Conferences;Knowledge based systems;Decision making;Data models;Internet;Data mining;Resource management;Topic model;knowledge graph;argument mining},
  doi={10.1109/ICKG52313.2021.00049},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10350103,
  author={Parniani, Mohammad Sahand and Reformat, Marek Z.},
  booktitle={2023 IEEE/WIC International Conference on Web Intelligence and Intelligent Agent Technology (WI-IAT)}, 
  title={Triple Extraction with Generative Technique for Constructing Weighted Knowledge Graph}, 
  year={2023},
  volume={},
  number={},
  pages={127-134},
  abstract={Extracting relational facts from unstructured text is crucial in natural language processing used in many applications, particularly in constructing knowledge graphs. Relational facts are represented as triples in which two entities are connected through a relation. This work introduces a new and effective end-to-end method to generate triples from the input text. In the proposed method, we develop an encoder-decoder-based transformer model and warm-start both the encoder and decoder with pretrained checkpoints that are publicly accessible. These checkpoints can be taken from models such as BERT, GPT-2, and RoBERTa. Experimental results show that our method achieves better results for triple extraction on publicly available datasets (NYT and WebNLG) than the other state-of-the-art techniques. Further, the extracted triples are processed and used to build a knowledge graph. Complete control of this process allows for determining the weights of the relations (triples). The weights reflect the frequency of occurrences of facts represented by the relations and provide the degree of confidence in the facts.},
  keywords={Process control;Knowledge graphs;Transformers;Natural language processing;Decoding;Data mining;Intelligent agents;triple extraction;knowledge graph;encoder-decoder;transformer},
  doi={10.1109/WI-IAT59888.2023.00023},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10628284,
  author={Vergara-Vargas, Jeisson and Sadou, Salah and Tibermacine, Chouki and Restrepo-Calle, Felipe},
  booktitle={2024 IEEE 21st International Conference on Software Architecture Companion (ICSA-C)}, 
  title={Sarch-Checks: A Method for Checking Software Architecture Security Properties Using a Knowledge Graph}, 
  year={2024},
  volume={},
  number={},
  pages={135-142},
  abstract={Checking the security properties of a software system during design is essential to enable the construction of a foundationally secure system. However, combining design tasks with security checks leads to a difficult and error-prone activity. This paper presents a checking method for security properties, called Sarch-Checks. This method allows analyzing the context of architectural elements in terms of an expected security property and identifying the presence of countermeasures and vulnerabilities. It uses an architectural description of the system to be analyzed, through the use of a modeling language. It also uses a knowledge graph, modeled and built from the elements of the software architecture, and cybersecurity elements taken from official information sources such as NIST and MITRE. This solution is an aide to the architect to design more secure architectures. Additionally, a validation process of the proposed method is presented through a case study based on a real report of a vulnerability in an open-source software system.},
  keywords={Analytical models;Software architecture;Knowledge graphs;Computer architecture;NIST;Software systems;Security;Security property;software architecture description;checking method;knowledge graph},
  doi={10.1109/ICSA-C63560.2024.00030},
  ISSN={2768-4288},
  month={June},}@INPROCEEDINGS{9667690,
  author={Wang, Yin and Xia, Nan and Luo, Xiangfeng and Li, Jinhui},
  booktitle={2021 IEEE International Conference on Big Knowledge (ICBK)}, 
  title={Global Semantics with Boundary Constraint Knowledge Graph for Chinese Financial Event Detection}, 
  year={2021},
  volume={},
  number={},
  pages={281-289},
  abstract={Chinese financial event detection has a great significance in the application of financial risk analysis, en-terprise management and decision-making. The existing tasks of Chinese event detection are mainly regarded as character-based or word-based classification, which suffers from the ambiguity of trigger words. These tasks only concentrate on local information (e.g character and word), which loses sight of global information like sentence semantics. Furthermore, in the finance field, there exists the problem of fuzzy boundary between different event types. In this paper, we propose a global semantics with boundary constraint knowledge graph (BCKG) for Chinese financial event detection, which considers both sentence semantics and boundary knowledge. At first, Chinese financial dataset (CFD) is constructed by considering the complexity in financial area. And then, the sentence seman-tics embedding is obtained by pre-training BERT fine-tuning mechanism to address the problem of ambiguity of trigger words, which considers both syntactic information and context sentence semantics comprehensively. Finally, we construct the BCKG for financial event, which can add additional prior knowledge to solve fuzzy boundary problem. The proposed method for event detection achieves outstanding performance on standard ACE 2005 Chinese dataset and constructed CFD. The experimental results demonstrate the effectiveness of the proposed method.},
  keywords={Event detection;Conferences;Semantics;Bit error rate;Decision making;Finance;Syntactics;event detection;global semantics;boundary con-straint knowledge graph;Chinese financial dataset},
  doi={10.1109/ICKG52313.2021.00045},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10723870,
  author={Parmar, Darshna and Nagrani, Tanish and Babre, Rushabh and Mazumdar, Pramit},
  booktitle={2024 15th International Conference on Computing Communication and Networking Technologies (ICCCNT)}, 
  title={From Conversations to Knowledge: Enriching Movie Datasets with Knowledge Graph}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={Knowledge graphs are invaluable assets for facilitating the dissemination of structured and semantically enriched data to both humans and machines while ensuring its accuracy and reliability. However, it has been observed that a direct approach of generating knowledge graph from existing benchmark data sources such as ReDial, DBPedia, etc. fails to highlight many crucial relationships between entities. In this work we proposed a strategy to enrich a knowledge graph by resolving multiple entity relationships generated from the ReDial movie dataset. First the missing entities and their corresponding relationships were identified. Subsequently, the publicly available large TMDb dataset is leveraged to align additional information such as genre, director, actor, writer, and year as nodes. Bidirectional links are then introduced to semantically enrich the knowledge graph. Validating a knowledge graph is considered as another important step. In this direction, we extract triplets in (movie, relationship, genre) format from the knowledge graph. The triplets are validated using IMDb which is a vast repository of movie details, and the Gemini Generative AI model. We compute accuracy of the extracted triplets and the results indicate improvement in the knowledge graph generation strategy and the IMDb as an efficient validator for our approach.},
  keywords={Accuracy;Soft sensors;Semantics;Knowledge graphs;Oral communication;Named entity recognition;Motion pictures;Resource description framework;Reliability;Recommender systems;Knowledge Graph;TMDb;ReDial;Named Entity Recognition;IMDb;Gemini;Fact Validation},
  doi={10.1109/ICCCNT61001.2024.10723870},
  ISSN={2473-7674},
  month={June},}@ARTICLE{10817607,
  author={Kim, Wooyoung and Jung, Haemin and Kim, Wooju},
  journal={IEEE Access}, 
  title={Knowledge Graph as Pre-Training Corpus for Structural Reasoning via Multi-Hop Linearization}, 
  year={2025},
  volume={13},
  number={},
  pages={7273-7283},
  abstract={Large language models have demonstrated exceptional performance across various natural language processing tasks. However, their reliance on unstructured text corpora for pre-training limits their effectiveness in tasks requiring structured reasoning such as multi-hop question-answering. Knowledge Graphs provide a rich, structured source of relational data, offering an opportunity to enhance the reasoning capabilities of Large language models. In this paper, we propose a novel framework, Knowledge Graph as Pre-training Corpus (KGPC), which transforms knowledge graphs into text using a multi-hop linearization process. Unlike existing approaches that linearize singular triples, our method captures the interconnected nature of knowledge graphs by linking multiple triples across multiple hops, preserving their relational structure during the pre-training phase. This structured knowledge injection improves language models to perform complex reasoning tasks. We evaluate our approach on multi-hop reasoning benchmarks, demonstrating significant performance gains over existing models, particularly in question-answering tasks. Our results highlight the potential of multi-hop linearization in enhancing the structural reasoning capacity of language models, reducing error propagation, and improving the integration of structured knowledge into language models.},
  keywords={Cognition;Knowledge graphs;Training;Data models;Periodic structures;Large language models;Accuracy;Natural language processing;Knowledge based systems;Electronic mail;Large language model;knowledge graph;multi-hop reasoning;question-answering},
  doi={10.1109/ACCESS.2024.3523579},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10800729,
  author={Lee, Chang-Shing and Wang, Mei-Hui and Tseng, Guan-Ying and Yue, Chao-Cyuan and Hsieh, Hao-Chun and Reformat, Marek},
  booktitle={2024 27th Conference of the Oriental COCOSDA International Committee for the Co-ordination and Standardisation of Speech Databases and Assessment Techniques (O-COCOSDA)}, 
  title={Cao Robot for Taiwanese/English Knowledge Graph Application}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={This paper proposes a Content Attention Ontology (CAO) robot for constructing Taiwanese/English Knowledge Graphs (KGs) by prompting audio or texts to Large Language Models (LLMs), including TAIDE, Zephyr, and Llama 3.1. The collected data includes lecture videos from the IEEE WCCI 2024 in Japan and the 2024 National Language Development Forum in Taiwan, along with students' learning data from the 2024 Summer School on Taiwanese/English Human and Robot Co-Learning at Rende Elementary School (RDES). In addition, the fundamental concepts of Computational Intelligence (CI) and Quantum CI (QCI) learning were incorporated into the study. The generative KGs highlight important concepts, relations, and communities within the collected teaching and learning data. Additionally, we utilized data from subjects wearing braincomputer interface (BCI) devices while speaking Taiwanese/English to generate KGs. We also compared the differences in these KGs and analyzed the similarities between the transcribed texts of lectures and learners. In the future, we plan to expand the CAO robot to more validation fields across Taiwan, aiming to engage young students in speaking Taiwanese while concurrently enhancing their English language skills through interaction with the robot.},
  keywords={Measurement;Quantum computing;Statistical analysis;Large language models;Knowledge graphs;Speech enhancement;Ontologies;Physiology;Robots;Videos;CAO Robot;Knowledge Graph;Taiwanese/English Language Co-learning;Large Language Model;Llama 3.1;TAIDE},
  doi={10.1109/O-COCOSDA64382.2024.10800729},
  ISSN={2472-7695},
  month={Oct},}@INPROCEEDINGS{9166221,
  author={Alamsyah, Andry and Bastikarana, Rafa Syafiq and Ramadhanti, Alya Rysda and Widiyanesti, Sri},
  booktitle={2020 8th International Conference on Information and Communication Technology (ICoICT)}, 
  title={Recognizing Personality from Social Media Linguistic Cues: A Case Study of Brand Ambassador Personality}, 
  year={2020},
  volume={},
  number={},
  pages={1-5},
  abstract={The burgeoning need of a brand ambassador (BA) as a company representative begin to rise in recent year. The phenomena followed by the increase of method to select the most suitable BA. The universal way of selecting one appropriate ambassador is by understanding their personality, therefore, measurement of a BA personality considered as one way to characterize a company credibility. This research proposes to design a method of measuring the BA personality from their social media data in Bahasa Indonesia. We enrich the methodology to measure human personality using the ontology modeling approach. The ontology model constructed under the ngram language model which provides a rapid and effective way of measuring a BA personality. The results of a BA personality measurement allow the utilization to portray of how an ambassador represent their brand and interact with their customer.},
  keywords={Brand Ambassador;Personality Measurement;Ontology},
  doi={10.1109/ICoICT49345.2020.9166221},
  ISSN={},
  month={June},}@INPROCEEDINGS{8816987,
  author={Oba, Atsushi and Paik, Incheon},
  booktitle={2019 IEEE International Conference on Cognitive Computing (ICCC)}, 
  title={Extraction of Taxonomic Relation of Complex Terms by Recurrent Neural Network}, 
  year={2019},
  volume={},
  number={},
  pages={70-72},
  abstract={In recent years, while the Internet has brought various technological evolutions, a lot of ontology is required to organize and systemize knowledge, and its generation is necessary. Especially, classification of hypernym-hyponym relation which describes taxonomy of ontology has received a lot of attention. As a method to automate the generation, word embedding based method was proposed recently. Although the method enabled high accuracy classification by using semantics, it does not correspond to complex term consisting of multiple words. Based on this background, in this paper, we proposed a new model combined word embedding and Recurrent Neural Network(RNN), evaluated the classification performance with data extracted from WordNet. For the result, it is indicated that the RNN approach is more effective and general for ontology generation.},
  keywords={Ontologies;Data models;Recurrent neural networks;Semantics;Training;Taxonomy;Support vector machines;Ontological Classification;Word Embedding;Word2Vector;Recurrent Neural Network;Natural Language Processing;Recurrent Neural Network Language Model},
  doi={10.1109/ICCC.2019.00024},
  ISSN={},
  month={July},}@INPROCEEDINGS{8569238,
  author={Helmke, Hartmut and Slotty, Michael and Poiger, Michael and Herrer, Damián Ferrer and Ohneiser, Oliver and Vink, Nathan and Cerna, Aneta and Hartikainen, Petri and Josefsson, Billy and Langr, David and Lasheras, Raquel García and Marin, Gabriela and Mevatne, Odd Georg and Moos, Sylvain and Nilsson, Mats N. and Pérez, Mario Boyero},
  booktitle={2018 IEEE/AIAA 37th Digital Avionics Systems Conference (DASC)}, 
  title={Ontology for Transcription of ATC Speech Commands of SESAR 2020 Solution PJ.16-04}, 
  year={2018},
  volume={},
  number={},
  pages={1-10},
  abstract={Nowadays Automatic Speech Recognition (ASR) applications are increasingly successful in the air traffic (ATC) domain. Paramount to achieving this is collecting enough data for speech recognition model training. Thousands of hours of ATC communication are recorded every day. However, the transcription of these data sets is resource intense, i.e. writing down the sequence of spoken words, and more importantly, interpreting the relevant semantics. Many different approaches including CPDLC (Controller Pilot Data Link Communications) currently exist in the ATC community for command transcription, a fact that e.g. complicates exchange of transcriptions. The partners of the SESAR funded solution PJ.16-04 are currently developing on a common ontology for transcription of controller-pilot communications, which will harmonize integration of ASR into controller working positions. The resulting ontology is presented in this paper.},
  keywords={Speech recognition;Training;Ontologies;Standards;Radar;Aircraft;Strips;Automatic Speech Recognition (ASR);CWP HMI;Transcription;Controller Command;Ontology;SESAR;PJ.16-04},
  doi={10.1109/DASC.2018.8569238},
  ISSN={2155-7209},
  month={Sep.},}@INPROCEEDINGS{9194550,
  author={Yu, Houjin and Mao, Xian-Ling and Chi, Zewen and Wei, Wei and Huang, Heyan},
  booktitle={2020 IEEE International Conference on Knowledge Graph (ICKG)}, 
  title={A Robust and Domain-Adaptive Approach for Low-Resource Named Entity Recognition}, 
  year={2020},
  volume={},
  number={},
  pages={297-304},
  abstract={Recently, it has attracted much attention to build reliable named entity recognition (NER) systems using limited annotated data. Nearly all existing works heavily rely on domain-specific resources, such as external lexicons and knowledge bases. However, such domain-specific resources are often not available, meanwhile it’s difficult and expensive to construct the resources, which has become a key obstacle to wider adoption. To tackle the problem, in this work, we propose a novel robust and domain-adaptive approach RDANER for low-resource NER, which only uses cheap and easily obtainable resources. Extensive experiments on three benchmark datasets demonstrate that our approach achieves the best performance when only using cheap and easily obtainable resources, and delivers competitive results against state-of-the-art methods which use difficultly obtainable domainspecific resources. All our code and corpora can be found on https://github.com/houking-can/RDANER.},
  keywords={Task analysis;Knowledge based systems;Data models;Bit error rate;Learning systems;Training;Biological system modeling;named entity recognition;low resource;domain adaptive},
  doi={10.1109/ICBK50248.2020.00050},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10412813,
  author={Yang, Ze and Sun, Yimeng and Nakaguchi, Takao and Imai, Masaharu},
  booktitle={2023 IEEE International Conference on Knowledge Graph (ICKG)}, 
  title={EMoDi: Entity-Enhanced Momentum-Difference Contrastive Learning for Semantic-Aware Verification of Scientific Information}, 
  year={2023},
  volume={},
  number={},
  pages={142-151},
  abstract={This paper proposes the EMoDi system to improve the performance of the entire scientific information verification pipeline. First, the Momentum-Difference contrastive learning framework is introduced to capture more semantics information. In abstract retrieval, entity-enhancement and noise-ignoration are introduced to improve the ability to retrieve relevant abstracts more accurately. In addition, a two-step verification method is used in label prediction to improve the label prediction ability and reduce the false positive rate of the “NOT ENOUGH INFO” label. The proposed pipeline outperforms the baseline VERISCI and QMUL-SDS. The code of this system is available on GitHub.},
  keywords={Codes;Pipelines;Semantics;Self-supervised learning;Knowledge graphs;Software development management;scientific information verification;entity-enhancement;noise-ignoration;two-step prediction;contrastive learning},
  doi={10.1109/ICKG59574.2023.00023},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10485759,
  author={Zhu, Ruiliang and Song, Xiangshuai and Zhang, Hao and Cai, Xuli},
  booktitle={2024 IEEE 3rd International Conference on Electrical Engineering, Big Data and Algorithms (EEBDA)}, 
  title={Joint Extraction of Entity Relationships in Walnut Disease and Pest Based on Chinese NLP Models}, 
  year={2024},
  volume={},
  number={},
  pages={1027-1035},
  abstract={This study addresses the limited application of deep learning techniques in the field of walnut disease and pest and the challenges posed by complex relationships and diverse entity types in this domain. We propose a deep learning-based method for constructing a knowledge graph in the walnut disease and pest domain, incorporating ontologies to establish a conceptual model for the disease and pest knowledge graph. To overcome issues such as relationship overlap (e.g., one-to-many, many-to-many) and loss of relationship chains, we introduce a novel labeling scheme called “based on ontology binding BIESO (Begin-Inside-End-Single-Other)” that directly models triplets. By employing a label matching algorithm, we obtain triplet data. We train and predict on the dataset using an end-to-end model consisting of Bidirectional Encoder Representations from Transformers (BERT), Bi-directional Gate Recurrent Unit (BiGRU), and Conditional Random Field (CRF). Experimental results show an F1 score of 75.79%, outperforming models such as BERT-BiLSTM-CRF and word2vec-BiGRU-CRF. We semiautomatically extract unstructured knowledge and store the extracted triplets in a Neo4j graph database, enabling visualization of the knowledge. The research methodology of this knowledge graph can serve as a reference for constructing knowledge graphs in walnut agriculture and developing intelligent question-answering systems for walnut disease and pest.},
  keywords={Knowledge graphs;Bidirectional control;Ontologies;Predictive models;Logic gates;Transformers;Prediction algorithms;Walnut disease and pest;ontology;BERTBiGRU-CRF;knowledge graph;deep learning},
  doi={10.1109/EEBDA60612.2024.10485759},
  ISSN={},
  month={Feb},}@ARTICLE{10210700,
  author={Qu, Xiaoye and Gu, Yingjie and Xia, Qingrong and Li, Zechang and Wang, Zhefeng and Huai, Baoxing},
  journal={IEEE Transactions on Knowledge and Data Engineering}, 
  title={A Survey on Arabic Named Entity Recognition: Past, Recent Advances, and Future Trends}, 
  year={2024},
  volume={36},
  number={3},
  pages={943-959},
  abstract={As more and more Arabic texts emerged on the Internet, extracting important information from these Arabic texts is especially useful. As a fundamental technology, Named entity recognition (NER) serves as the core component in information extraction technology, while also playing a critical role in many other Natural Language Processing (NLP) systems, such as question answering and knowledge graph building. In this paper, we provide a comprehensive review of the development of Arabic NER, especially the recent advances in deep learning and pre-trained language model. Specifically, we first introduce the background of Arabic NER, including the characteristics of Arabic and existing resources for Arabic NER. Then, we systematically review the development of Arabic NER methods. Traditional Arabic NER systems focus on feature engineering and designing domain-specific rules. In recent years, deep learning methods achieve significant progress by representing texts via continuous vector representations. With the growth of pre-trained language model, Arabic NER yields better performance. Finally, we conclude the method gap between Arabic NER and NER methods from other languages, which helps outline future directions for Arabic NER.},
  keywords={Surveys;Text recognition;Task analysis;Deep learning;Social networking (online);Focusing;Writing;Named entity recognition;arabic texts;deep learning;pretrained language model},
  doi={10.1109/TKDE.2023.3303136},
  ISSN={1558-2191},
  month={March},}@INPROCEEDINGS{10385760,
  author={Shuai, Yunyan and Wang, Wenkang and Li, Yiming and Zeng, Min and Li, Min},
  booktitle={2023 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)}, 
  title={Protein function prediction using graph neural network with multi-type biological knowledge}, 
  year={2023},
  volume={},
  number={},
  pages={30-35},
  abstract={Proteins play crucial roles in diverse biological functions, and accurately annotating their functions is essential for understanding cellular mechanisms and developing therapies for complex diseases. Computational methods have been proposed as alternatives to laborious experimental approaches. However, existing network-based methods focus on the protein-protein interaction (PPI) networks, while the proteins without interactions are ignored. To address this limitation, we propose a novel deep learning framework for protein function prediction, named PFP-GMB, which incorporates multi-type biological knowledge to consider the proteins not present in the PPI networks. PFP-GMB leverages a pre-trained protein language model to extract sequence representations. Moreover, PPIs and orthology relationships are used to generate functional related features via graph neural networks and attention mechanisms. Finally, these multi-type features are fused for protein function prediction. Compared to eight state-of-the-art methods, PFP-GMB outperforms all of them in terms of F-max and AUPR. The ablation studies further confirm the relevance and significance of the multi-type biological knowledge incorporated into PFP-GMB for protein function prediction.},
  keywords={Proteins;Knowledge engineering;Protein engineering;Medical treatment;Feature extraction;Graph neural networks;Diseases;protein function;orthology network;PPI network;protein sequence;graph neural network},
  doi={10.1109/BIBM58861.2023.10385760},
  ISSN={2156-1133},
  month={Dec},}@ARTICLE{10474025,
  author={Farghaly, Maha and Mounir, Mahmoud and Aref, Mostafa and Moussa, Sherin M.},
  journal={IEEE Access}, 
  title={Investigating the Challenges and Prospects of Construction Models for Dynamic Knowledge Graphs}, 
  year={2024},
  volume={12},
  number={},
  pages={40973-40988},
  abstract={Recently, Dynamic knowledge graphs (DKGs) have been considered the foundation stone for several powerful knowledge-aware applications. DKG has a great advancement over static knowledge graph with the ability to capture the dynamicity of knowledge. The correctness and completeness of DKGs strongly affect the accuracy of the dependent application, in which many factors may have an impact, including data sources, graph construction model, and evaluation methods. Despite the increasing attention to DKGs, the literature of DKG construction is not comprehensively investigated, and the limitations are not fully revealed. In this paper, a comparative study is conducted for the emerging construction models of DKG. An extensive analysis is provided for each of the three main phases of DKG construction: entity extraction, relationship extraction and graph completion. For the different phases, we investigated the employed techniques, the used data sources, as well as the associated challenges, limitations, and evaluation metrics of each model. The learning approach is introduced as a novel categorization perspective for the employed techniques in the DKG construction. Finally, the encountered challenges and limitations are inspected to deduce the possible future directions that can be adopted for effective and advanced DKGs construction. It was found that 100% of the investigated models lack the key aspects of dynamicity in DKGs, 75% suffer from insufficient training features, 58% have a clear exposure to bias, 33% are vulnerable to changes, 25% have a performance and efficiency concerns, while lack of evaluation and comparison represented 25% and 17% of the models respectively.},
  keywords={Data mining;Feature extraction;Knowledge graphs;Soft sensors;Data models;Internet;Task analysis;Dynamic knowledge graph;learning approaches;knowledge graph completion;knowledge graph construction},
  doi={10.1109/ACCESS.2024.3378514},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10373245,
  author={Sheng, Jinghua},
  booktitle={2023 16th International Congress on Image and Signal Processing, BioMedical Engineering and Informatics (CISP-BMEI)}, 
  title={An Augmentable Domain-specific Models for Financial Analysis}, 
  year={2023},
  volume={},
  number={},
  pages={1-4},
  abstract={Large-scale language models such as GPT-4 have revolutionized data analysis and interpretation by generating human-like text, automating insights, and detecting data errors. Large-scale language models have been applied in various fields and played an important role in many aspects. Large language models can also perform financial and technical analysis by cleaning data, generating synthetic data, handling bias, and supporting natural language queries. This paper proposes a language model that integrates multimodal data with external knowledge bases and domain-specific data, enhancing its reasoning ability by extending domain-specific data. Reduce hallucinations and fine-tune domain-specific data by incorporating external knowledge bases to deepen model understanding of industry-specific language, concepts, and context. And technologies such as knowledge graph, attention mechanism, cross-modal embedding and federated collaborative training are used to deal with the challenges of different structures and semantics of multi-modal data. The model also employs a feedback loop mechanism to allow the model to adapt to changing conditions, such as changing languages or new domain information. Experimental results show that the proposed model has a preliminary domain-specific ability to analyze and predict multimodal financial and technical data.},
  keywords={Training;Analytical models;Adaptation models;Feedback loop;Biological system modeling;Knowledge based systems;Natural languages;Large-scale language models;financial and technical analysis;external knowledge;domain-specific data;knowledge graph},
  doi={10.1109/CISP-BMEI60920.2023.10373245},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10218646,
  author={Chen, Binghong and Chen, Jenhui},
  booktitle={2023 IEEE 5th Eurasia Conference on Biomedical Engineering, Healthcare and Sustainability (ECBIOS)}, 
  title={Inclusion-Exclusion Knowledge Filtering Approach for Conversation-Based Preliminary Diagnosis}, 
  year={2023},
  volume={},
  number={},
  pages={170-174},
  abstract={Using natural language processing (NLP) techniques, we conducted a preliminary diagnosis of the disease from the patient syndrome description. Because patients are not medical professionals, they cannot accurately describe all symptoms. To solve this issue, we build a medical knowledge graph (KG) by constructing symptom-disease relation triples for pre-processing the patient syndrome description. According to the medical KG, the descriptions were reconstructed into KG embedding representation. To avoid the knowledge noise issue, we investigate an inclusion-exclusion knowledge filtering approach (IKFA) for symptom-to-disease triples to load them to a pretrained language model (PLM), i.e., bidirectional encoder representations from Transformers (BERT). To train the IKFA, we built a medical diagnosis question-answer dataset (MDQA dataset), which contains large-scale and high-quality questions (patient symptom description) and answers (diagnosis) (Q&A) corpus with 1.63 million entries in the size of 213 MB. The KG was built based on 8,731 diseases with detailed syndrome descriptions in the size of 1.98 MB. The experimental results showed that the IKFA preliminarily diagnosed 8,731 different diseases based on the patient's initial symptom description with an accuracy of 0.9894.},
  keywords={Training;Filtering;Bidirectional control;Transformers;Natural language processing;Encoding;Medical diagnosis;diagnosis;disease;knowledge graph;NLP;PLM;symptom;syndrome},
  doi={10.1109/ECBIOS57802.2023.10218646},
  ISSN={},
  month={June},}@INPROCEEDINGS{10628465,
  author={Lian, Xiaoli and Ma, Jieping and Lv, Heyang and Zhang, Li},
  booktitle={2024 IEEE 32nd International Requirements Engineering Conference (RE)}, 
  title={ReqCompletion: Domain-Enhanced Automatic Completion for Software Requirements}, 
  year={2024},
  volume={},
  number={},
  pages={142-154},
  abstract={Software requirements are the driving force behind software development. As the cornerstone of the entire software lifecycle, the efficiency of crafting requirement specifications and the quality of these requirements significantly influence the duration of software development. Despite massive research on requirements elicitation, the reality is that requirements are often painstakingly crafted manually, word by word. This manual process is not only time-consuming but also prone to issues such as the misuse of terminology. To address these challenges, we introduce ReqCompletion, an approach designed to recommend the next token in real-time for given prefix of requirements description. ReqCompletion comprises two primary components. First, we have devised and integrated a knowledge-injection module into GPT-2—which stands as the largest available GPT model that allows for fine-tuning on specialized downstream tasks. This injection imbues GPT-2 with richer domain-specific knowledge, thus improving the relevance of the suggested tokens. Additionally, we employ a pointer network to optimize the recommendation quality by utilizing completed requirements as contextual support. Empirical evaluations using two public datasets demonstrate that ReqCompletion surpasses all baselines in performance (Recall@7 gains up to 65.87% than the second-best model). Furthermore, the effectiveness of its two pivotal design elements has been substantiated through rigorous ablation studies. The utility of our work has been evaluated preliminarily through a small user study.},
  keywords={Terminology;Force;Manuals;Computer architecture;Benchmark testing;Software;Real-time systems;Software Requirements;Automatic Text Completion;Knowledge Injection},
  doi={10.1109/RE59067.2024.00023},
  ISSN={2332-6441},
  month={June},}@INPROCEEDINGS{8595067,
  author={Singh, Neeraj Kumar and Ait-Ameur, Yamine and Mery, Dominique},
  booktitle={2018 23rd International Conference on Engineering of Complex Computer Systems (ICECCS)}, 
  title={Formal Ontology Driven Model Refactoring}, 
  year={2018},
  volume={},
  number={},
  pages={136-145},
  abstract={Refactoring, successfully used in the field of programming, can be used in maintenance and restructuring of the large and complex models. In this paper, we present a novel approach for model refactoring and a set of modelling patterns that are applicable for refinement-based formal development. In order to carry out this study, we investigate the previously developed large and complex model and required ontology to develop a domain model and a refactored system model. Further, we use the Rodin tools to check the internal consistency with respect to the desired functional behaviour and the required safety properties. Our main contributions are: to develop a refactoring technique related to the correct by construction approach; to use the domain specific knowledge in a system model explicitly; to define a set of modelling patterns; and to define a restructuring mechanism in the formal development. Finally, this proposed approach is evaluated through a complex medical case study: ECG clinical assessment protocol.},
  keywords={Ontologies;Computational modeling;Safety;Semantics;Tools;Electrocardiography;Analytical models;Refactoring, refinement and proofs, ontologies, do main theories, Event-B},
  doi={10.1109/ICECCS2018.2018.00022},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{9874511,
  author={Faramarzi, Noushin Salek and Dara, Akanksha and Banerjee, Ritwik},
  booktitle={2022 IEEE 10th International Conference on Healthcare Informatics (ICHI)}, 
  title={Combining Attention-based Models with the MeSH Ontology for Semantic Textual Similarity in Clinical Notes}, 
  year={2022},
  volume={},
  number={},
  pages={74-83},
  abstract={In this study, we present several transformer-based models as well as traditional machine learning methods to detect semantic textual similarity (STS) in clinical notes. We investigate transformer models pretrained on general English as well as clinical notes, and use generic English STS datasets as a supplemental corpus to clinical notes data. Our work is based on the 2019 National NLP Clinical Challenge (n2c2). We identify and annotate six types of sentences in the clinical notes corpus, and report an ensemble method that combines attention-based contextualized embeddings with a similarity score based on the MeSH ontology obtained by computing least common ancestors of clinical terms. Our approach does not need additional clinical data for model training, while still achieving comparable Pearson's correlation coefficient of 0.901.},
  keywords={Training;Drugs;Vocabulary;Computational modeling;Semantics;Machine learning;Ontologies;Electronic Health Records;Natural Language Processing;Clinical Semantic Textual Similarity;Transformers;MeSH},
  doi={10.1109/ICHI54592.2022.00023},
  ISSN={2575-2634},
  month={June},}@INPROCEEDINGS{9926710,
  author={Ji, Fan and Ocker, Felix and Zou, Minjie and Vogel-Heuser, Birgit and Oligschläger, Marius},
  booktitle={2022 IEEE 18th International Conference on Automation Science and Engineering (CASE)}, 
  title={Identifying Inconsistencies in the Design of Large-scale Casting Systems – An Ontology-based Approach}, 
  year={2022},
  volume={},
  number={},
  pages={319-325},
  abstract={The development of modern automated production systems requires the close cooperation of engineers from different domains. Due to the large amount of domain-specific documents and heterogeneous data they create during the multidisciplinary engineering activities, ensuring the consistency of information is always challenging. Since most of these documents are texted-based and lack a standardized structure, extracting required information from these files is oftentimes problematic. This issue is particularly critical in the development of large-scale production plants due to the high complexity of the systems and the diversity of disciplines involved. To help engineers efficiently utilize unstructured data sources as well as identify potential information contradictions, we propose an ontology-based inconsistency management approach for large-scale production systems that generates the knowledge base from unstructured engineering data and (semi-) automatically detects multiple types of inconsistencies. In addition, the presented framework also supports the tracking of information changes during the system design process.},
  keywords={Production systems;Casting;Computer aided software engineering;Automation;Soft sensors;Knowledge based systems;Complexity theory},
  doi={10.1109/CASE49997.2022.9926710},
  ISSN={2161-8089},
  month={Aug},}@ARTICLE{9940925,
  author={Borrego, Agustín and Dessì, Danilo and Hernández, Inma and Osborne, Francesco and Reforgiato Recupero, Diego and Ruiz, David and Buscaldi, Davide and Motta, Enrico},
  journal={IEEE Access}, 
  title={Completing Scientific Facts in Knowledge Graphs of Research Concepts}, 
  year={2022},
  volume={10},
  number={},
  pages={125867-125880},
  abstract={In the last few years, we have witnessed the emergence of several knowledge graphs that explicitly describe research knowledge with the aim of enabling intelligent systems for supporting and accelerating the scientific process. These resources typically characterize a set of entities in this space (e.g., tasks, methods, evaluation techniques, proteins, chemicals), their relations, and the relevant actors (e.g., researchers, organizations) and documents (e.g., articles, books). However, they are usually very partial representations of the actual research knowledge and may miss several relevant facts. In this paper, we introduce SciCheck, a new triple classification approach for completing scientific statements in knowledge graphs. SciCheck was evaluated against other state-of-the-art approaches on seven benchmarks, yielding excellent results. Finally, we provide a real-world use case and applied SciCheck to the Artificial Intelligence Knowledge Graph (AI-KG), a large-scale automatically-generated open knowledge graph including 1.2M statements extracted from the 333K most cited articles in the field of Artificial Intelligence, and generated a new version of this knowledge graph with 300K additional triples.},
  keywords={Machine learning;Feature extraction;Semantic Web;Task analysis;Context modeling;Computational modeling;Benchmark testing;Knowledge based systems;Knowledge graphs;science of science;knowledge graph completion;triple classification;machine learning;semantic web},
  doi={10.1109/ACCESS.2022.3220241},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{9018722,
  author={Qie, Yongiun and Zhu, Weijie and Liu, Aishan and Zhang, Yuchen and Wang, Jun and Li, Teng and Li, Yaqing and Ge, Yufei and Wang, Yufeng},
  booktitle={2018 IEEE CSAA Guidance, Navigation and Control Conference (CGNCC)}, 
  title={A Deep Learning Based Framework for Textual Requirement Analysis and Model Generation}, 
  year={2018},
  volume={},
  number={},
  pages={1-6},
  abstract={Requirement analysis is a key part of systems engineering process. Analyzing requirements correctly and creating design model sequentially could be critical to the whole process of a product development. Nevertheless, requirement text handling and model transferring could be really time-consuming and error-prone. Thus, we proposed an artificial intelligence based framework to deal with textual requirement handling and model creation. With deep learning and natural language process skills, our approach could be able to analyze textual requirements automatically, and then create the related models. This would indeed alleviate the work of engineers and promote the efficiency and quality of product development process. With our limited knowledge, our paper is the first one to propose the deep learning and NLP based framework to automatically create requirement models.},
  keywords={Semantics;Computational modeling;Machine learning;Natural language processing;Air traffic control;Analytical models;requirement modeling;deep learning;NLP},
  doi={10.1109/GNCC42960.2018.9018722},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{10825984,
  author={Linxen, Andrea and Schmidt, Vera-Maria and Klinke, Harald and Beecks, Christian},
  booktitle={2024 IEEE International Conference on Big Data (BigData)}, 
  title={Ontology-driven knowledge base for digital humanities: Restructuring knowledge organization at the library of the Folkwang University of the Arts}, 
  year={2024},
  volume={},
  number={},
  pages={2449-2455},
  abstract={Academic libraries are increasingly challenged by the need to efficiently manage and analyse vast collections of data and knowledge. The divers formats and organisation methods of these collections, ranging from traditional print media to digital archives and multimedia assets, can hinder researchers’ ability to easily access and retrieve relevant information. This paper introduces an ontology-driven knowledge base to address this issue by enabling the efficient access to knowledge in the application domain and enhancing the semantic search capabilities in the field of Digital Humanities. Our approach focuses on the development of an ontology-drive knowledge base for semantic search in academic libraries by the example of the library of the Folkwang University of Arts that captures the knowledge concepts present in the library’s archival collections. The resulting ontology framework provides a structured representation of domain knowledge, facilitating the integration of diverse data sources, including structured, semi-structured, and unstructured data from the application domain into a triple store knowledge base. By leveraging SPARQL queries generated from Large Language Model (LLM) prompts, we aim to facilitate more intuitive and effective knowledge retrieval. This approach allows users to express their information needs in a more natural and flexible way, leading to more accurate and relevant search results. We evaluate the proposed ontology-driven knowledge base in terms of its integrity, consistency, flexibility, relevance, and scalability. Our evaluation methodology includes a combination of verification and validation techniques, including automated reasoners and query results based on competence questions. Our findings demonstrate the potential of ontology engineering to enhance complex information retrieval in academic libraries. However, we also identify limitations related to processing speed for complex queries and the quality of search results. This research contributes to the field of computational archival science by providing a novel approach to semantic search in academic libraries. By enabling more precise and efficient access to knowledge, our ontology-driven knowledge base has the potential to enrich the academic and Digital Humanities landscape, empowering researchers to delve deeper into the vast resources available within these institutions.},
  keywords={Knowledge engineering;Art;Semantic search;Soft sensors;Scalability;Knowledge based systems;Organizations;Ontologies;Media;Libraries;knowledge engineering;ontology framework;digital humanities;knowledge base;semantic search},
  doi={10.1109/BigData62323.2024.10825984},
  ISSN={2573-2978},
  month={Dec},}@INPROCEEDINGS{9651799,
  author={Kroll, Hermann and Pirklbauer, Jan and Balke, Wolf-Tilo},
  booktitle={2021 ACM/IEEE Joint Conference on Digital Libraries (JCDL)}, 
  title={A Toolbox for the Nearly-Unsupervised Construction of Digital Library Knowledge Graphs}, 
  year={2021},
  volume={},
  number={},
  pages={21-30},
  abstract={Knowledge graphs are essential for digital libraries to store entity-centric knowledge. The applications of knowledge graphs range from summarizing entity information over answering complex queries to inferring new knowledge. Yet, building knowledge graphs means either relying on manual curation or designing supervised extraction processes to harvest knowledge from unstructured text. Obviously, both approaches are cost-intensive. Yet, the question is whether we can minimize the efforts to build a knowledge graph. And indeed, we propose a toolbox that provides methods to extract knowledge from arbitrary text. Our toolkit bypasses the need for supervision nearly completely and includes a novel algorithm to close the missing gaps. As a practical demonstration, we analyze our toolbox on established biomedical benchmarks. As far as we know, we are the first who propose, analyze and share a nearly unsupervised and complete toolbox for building knowledge graphs from text.},
  keywords={Training;Vocabulary;Biological system modeling;Training data;Benchmark testing;Libraries;Cleaning;Knowledge Graph;Information Extraction;Digital Library},
  doi={10.1109/JCDL52503.2021.00014},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{8926665,
  author={Jue, Wang and Song, Yineng and Wu, Xian and Dai, Wenbin},
  booktitle={IECON 2019 - 45th Annual Conference of the IEEE Industrial Electronics Society}, 
  title={A Semi-Formal Requirement Modeling Pattern for Designing Industrial Cyber-Physical Systems}, 
  year={2019},
  volume={1},
  number={},
  pages={2883-2888},
  abstract={Requirement engineering is a crucial part of the engineering process. The traditional methods of requirement engineering are time-consuming and human-centered. A well-established software requirement description model needs to ensure the accuracy and integrity of the transformation and is also hoped to be scalable, versatile, and efficient in transformation and transmission. This paper presents a method of requirement engineering, including constricted nature language requirement input pattern, and the formalized requirement description JSON model. This method provides convenience for requirement modification and validation that can satisfy the real-time constraints of industrial cyber-physical systems.},
  keywords={Unified modeling language;Software;Solid modeling;Requirements engineering;Analytical models;Real-time systems;requirement engineering;requirement component;formal models;system behavior decomposition},
  doi={10.1109/IECON.2019.8926665},
  ISSN={2577-1647},
  month={Oct},}@INPROCEEDINGS{10633526,
  author={Yang, Hang and Xiao, Liang and Zhu, Rujun and Liu, Ziji and Chen, Jianxia},
  booktitle={2024 IEEE 48th Annual Computers, Software, and Applications Conference (COMPSAC)}, 
  title={Interlinking Clinical Guidelines via Mining Medical Literature Knowledge for Multi-Morbidity Decision-Making}, 
  year={2024},
  volume={},
  number={},
  pages={1250-1255},
  abstract={Independently developed clinical guidelines present a systematic challenge in managing patients with multi-morbidity in a consistent and integrated manner. Existing approaches mainly focus on combining multiple guidelines and lack approaches that combine with additional medical resources. The correlations and conflicts between treatment plans in the management of multi-morbidity are well-documented in medical literature but are less explored in the Clinical Decision Support line of research. In this paper, we propose a literature-based guideline interlinking method to address these challenges through the integration of clinical guidelines and the harmonization of conflicting recommendations, thereby providing a more holistic and efficient way to manage patients with multi-morbidity conditions. This method employs an ontology model and knowledge graph technology to represent and analyze the complexity and interrelations of diseases, with the aim of transcending the limitations of traditional single disease guidelines and providing a holistic and integrated framework for multi-morbidity management. The objective is to construct a multi-morbidity knowledge graph by correlating medical literature with clinical guidelines and to provide optimal decision support for patients with multi-morbidity complications in a clinical decision support system (CDSS).},
  keywords={Accuracy;Systematics;Databases;Computational modeling;Biological system modeling;Knowledge graphs;Ontologies;multi-morbidity management;clinical guidelines;ontology model;knowledge graph},
  doi={10.1109/COMPSAC61105.2024.00165},
  ISSN={2836-3795},
  month={July},}@INPROCEEDINGS{10743159,
  author={Hong, Bin and Wu, Jinze and Liu, Jiayu and Ding, Liang and Sha, Jing and Zhang, Kai and Wang, Shijin and Huang, Zhenya},
  booktitle={2024 International Conference on Computational Linguistics and Natural Language Processing (CLNLP)}, 
  title={End-to-End Graph Flattening Method for Large Language Models}, 
  year={2024},
  volume={},
  number={},
  pages={41-45},
  abstract={In recent years, the breakthrough of Large Language Models (LLMs) offers new ideas for achieving universal methods on graph data. The common practice of converting graphs into natural language for LLMs, which refers to graph flattening, exhibits good generalizability and interpretability. However, the poor organization of the textual format results in poor performance in long-distance scenario understanding. Inspired by human cognitive reasoning habits, we propose a novel method for graph flattening to fit LLMs, termed as End-to-End DAG-Path prompting (EEDP). Experiments on real-world datasets show that EEDP enhances the reasoning performance of LLMs in long-distance scenarios while maintaining excellent performance in short-distance scenarios, demonstrating good robustness in the face of distance variations.},
  keywords={Large language models;Organizations;Cognition;Robustness;Natural language processing;Computational linguistics;Faces;graph flattening;Large Language Model;graph representation},
  doi={10.1109/CLNLP64123.2024.00016},
  ISSN={},
  month={July},}@INPROCEEDINGS{10651190,
  author={Li, Jinlin and Wang, Zikang and Li, Linjing and Zeng, Daniel Dajun},
  booktitle={2024 International Joint Conference on Neural Networks (IJCNN)}, 
  title={BERT-FKGC: Text-Enhanced Few-Shot Representation Learning for Knowledge Graphs}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={In recent years, few-shot knowledge graph completion (FKGC) emerged as a prominent research problem, focused on utilizing a limited number of reference entity pairs to complete triples with unseen relations. Recent studies have attempted addressing this problem by modeling interactions between head and tail entities. However, existing FKGC methods represent semantics predominantly based on the neighborhood information of entities in the knowledge graph, thus can only infer the hidden and unobserved relations within the knowledge graph, limiting their reasoning capabilities. To overcome these limitations, we introduce text descriptions to FKGC and propose BERT-FKGC, a model capable of learning the integrated distribution of both the entity text descriptions and neighborhood information. By using a gating network that allows the model to dynamically select weights, our method can flexibly combine neighborhood information and textual descriptions. Besides addressing the prediction of unseen relations, our method is also capable of representing unseen entities. To validate the effectiveness of our model, we introduce a new dataset, FB15K-237-One, which includes textual descriptions for entities. We conduct extensive experiments on the FB15K-237-One dataset to validate the superiority of BERTFKGC.},
  keywords={Representation learning;Adaptation models;Limiting;Semantics;Neural networks;Knowledge graphs;Tail;few-shot learning;knowledge graph completion;pre-trained language model},
  doi={10.1109/IJCNN60899.2024.10651190},
  ISSN={2161-4407},
  month={June},}@INPROCEEDINGS{10408849,
  author={Xin, You and Chen, Liu and Yang, Yang},
  booktitle={2023 IEEE 11th Joint International Information Technology and Artificial Intelligence Conference (ITAIC)}, 
  title={Online Knowledge Fusion Method for Fault Diagnosis of Power Plant Equipment}, 
  year={2023},
  volume={11},
  number={},
  pages={1236-1240},
  abstract={There are many types of documents in fossil-fuel power station to describe equipment failures, including maintenance records, treatment diagnosis suggestions, historical cases, and equipment knowledge. The knowledge of equipment anomaly diagnosis and handling is scattered in different documents. Extract and fuse scattered knowledge from these scattered documents to generate a knowledge graph for equipment fault di-agnosis, providing necessary decision support for maintenance personnel to discover and handle equipment faults. This article proposes an implementation method for extracting and integrating equipment fault knowledge from diverse and multi type text records to form a knowledge graph. A thermal power plant equipment fault Q&A system based on the fusion of open source large language models and knowledge graphs has been developed. Main contributions: (1) A knowledge extraction algorithm integrating BERT-WWM model and pointer annotation method is proposed to extract entity relations of fault text jointly. Experiments show that the method performs well in extracting overlapped triples, and F1 is improved by 8.51 % compared with existing algorithms; (2) A knowledge fusion model based on RoBERTa-BiLSTM is proposed, which fully utilizes the feature information of the entity text to be disambiguated and the entity mention text, and cap-tures the interdependent features within the sentence through attention mechanism. The experiment shows that this method improves F1 by 9.56% compared to existing fusion algorithms. (3) Based on the open-source large model ChatGLM, a fusion method of knowledge graph and large model ChatGLM was explored, and a device fault question answering system for thermal power plants was implemented, achieving high accuracy in practical applications.},
  keywords={Knowledge graphs;Maintenance engineering;Feature extraction;Question answering (information retrieval);Data mining;Personnel;Power generation;knowledge graph;knowledge extraction;knowledge fusion},
  doi={10.1109/ITAIC58329.2023.10408849},
  ISSN={2693-2865},
  month={Dec},}@ARTICLE{10423114,
  author={Zhao, Yingwen and Yang, Zhihao and Wang, Lei and Zhang, Yin and Lin, Hongfei and Wang, Jian},
  journal={IEEE Journal of Biomedical and Health Informatics}, 
  title={Predicting Protein Functions Based on Heterogeneous Graph Attention Technique}, 
  year={2024},
  volume={28},
  number={4},
  pages={2408-2415},
  abstract={In bioinformatics, protein function prediction stands as a fundamental area of research and plays a crucial role in addressing various biological challenges, such as the identification of potential targets for drug discovery and the elucidation of disease mechanisms. However, known functional annotation databases usually provide positive experimental annotations that proteins carry out a given function, and rarely record negative experimental annotations that proteins do not carry out a given function. Therefore, existing computational methods based on deep learning models focus on these positive annotations for prediction and ignore these scarce but informative negative annotations, leading to an underestimation of precision. To address this issue, we introduce a deep learning method that utilizes a heterogeneous graph attention technique. The method first constructs a heterogeneous graph that covers the protein-protein interaction network, ontology structure, and positive and negative annotation information. Then, it learns embedding representations of proteins and ontology terms by using the heterogeneous graph attention technique. Finally, it leverages these learned representations to reconstruct the positive protein-term associations and score unobserved functional annotations. It can enhance the predictive performance by incorporating these known limited negative annotations into the constructed heterogeneous graph. Experimental results on three species (i.e., Human, Mouse, and Arabidopsis) demonstrate that our method can achieve better performance in predicting new protein annotations than state-of-the-art methods.},
  keywords={Proteins;Protein engineering;Annotations;Feature extraction;Predictive models;Deep learning;Amino acids;Protein function prediction;positive and negative annotations;constructed heterogeneous graph;heterogeneous graph attention},
  doi={10.1109/JBHI.2024.3357834},
  ISSN={2168-2208},
  month={April},}@INPROCEEDINGS{9994899,
  author={Huang, Zhijian and Zheng, Rongtao and Deng, Lei},
  booktitle={2022 IEEE International Conference on Bioinformatics and Biomedicine (BIBM)}, 
  title={DeepFusionGO: Protein function prediction by fusing heterogeneous features through deep learning}, 
  year={2022},
  volume={},
  number={},
  pages={12-17},
  abstract={Exploring the functions of proteins is crucial for explaining cellular mechanisms, treating diseases, and developing new drugs. Due to experimental limitations, large-scale identification of protein function remains a challenging task in cell biology. Here we propose DeepFusionGo, a novel protein function prediction method that adopts a graph representation learning approach (GraphSAGE) to extract features from heterogeneous data sources. First, we generate embeddings from protein sequences using the pre-trained protein language model and InterPro domains with scaling gradient. Then we integrate these two embeddings with adaptive feature weights to the PPI graph and use GraphSAGE to generate the representation vector. Finally, we build the classification model to predict protein function based on the concatenated feature vector. The experimental results show that DeepFusionGO outperforms existing state-of-the-art methods, including sequence-based DeepGOPLUS, and PPI-based DeepGraphGO. DeepFusionGO also performs well in difficult protein function prediction. We demonstrate that selecting an appropriate protein features fusion method can improve the prediction performance, and using the PPI network and the protein representation vector obtained from the protein language model through the GraphSAGE algorithm is an effective way to mine potential functional clues. The source code and data sets are available at: https://github.com/Hhhzj-7/DeepFusionGO.},
  keywords={Proteins;Representation learning;Adaptation models;Biological system modeling;Source coding;Soft sensors;Predictive models;Protein function prediction;graph representation learning;GraphSAGE;feature fusion},
  doi={10.1109/BIBM55620.2022.9994899},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{10795847,
  author={Dong, Haomin and Wang, Wenbin and Sun, Zhenjiang and Kang, Ziyi and Ge, Xiaojun},
  booktitle={2024 4th International Conference on Computer Systems (ICCS)}, 
  title={Iterative LLM Prompting for Intelligent Cockpit Knowledge Graph Construction}, 
  year={2024},
  volume={},
  number={},
  pages={136-145},
  abstract={With the development of digital and intelligent cockpits, the data within these environments exhibit complexity and diversity, leading to issues such as inefficient data processing and difficulty in information extraction. Consequently, effectively capturing and representing the hidden associative knowledge in cockpits is crucial. Against this backdrop, knowledge graphs serve as an effective tool capable of retrieving and organizing a vast amount of information within a connected and interpretable structure. By systematically representing complex data relationships in the cockpit, they help enhance the prediction of precise interaction intentions and provide richer and more relevant knowledge support for personalized recommendations. However, rapidly and flexibly generating domain-specific knowledge graphs still poses certain challenges. This paper introduces an innovative method of knowledge graph construction using generative large language models, implementing a novel iterative zero-shot and domain-agnostic strategy. We propose an innovative strategy of iteratively prompting large language models to extract relevant triples for constructing knowledge graphs, effectively addressing key challenges such as entity recognition ambiguity and relationship extraction complexity in cockpit data. Experiments conducted in a domain-specific dataset demonstrate the feasibility of this method.},
  keywords={Knowledge engineering;Large language models;Pipelines;Knowledge graphs;Information retrieval;Data processing;Complexity theory;Data mining;Iterative methods;Intelligent systems;knowledge graphs;triples;prompting engineering;LLMs;intelligent cockpit},
  doi={10.1109/ICCS62594.2024.10795847},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{10650221,
  author={Wang, ZhenYu and Wu, YiFei},
  booktitle={2024 International Joint Conference on Neural Networks (IJCNN)}, 
  title={Enhance Large Language Models for Multilingual Sentence Embedding with Knowledge Graph}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={Sentence representation is a major challenge in natural language processing, especially in multilingual environments. Current approaches to sentence representation using Large Language Models (LLMs) often require large amounts of data for fine-tuning, and research has focused on English content. In addition, comparative datasets translated directly from English can contain many semantic and syntactic errors. To address these issues, we propose a new approach to enhance multilingual sentence embeddings using LLMs and knowledge graphs. We first present a dedicated designed prompt that exploits in-context learning of LLMs for sentence embedding without fine-tuning. We further introduce an innovative method that utilizes knowledge graphs, such as Wikidata, for generating diverse multilingual training data for contrastive finetuning. This approach significantly reduces the reliance on translated sentences and mitigates issues related to translation accuracy. Furthermore, we develop a unique multilingual contrastive learning loss function, which, when combined with QLora’s efficient fine-tuning technique, enables LLMs to achieve state-of-the-art performance in Sentence Text Similarity (STS) tasks, even with limited computational resources.},
  keywords={Large language models;Computational modeling;Semantics;Neural networks;Training data;Knowledge graphs;Contrastive learning;sentence embedding;contrastive learning;large language model;data argumentation},
  doi={10.1109/IJCNN60899.2024.10650221},
  ISSN={2161-4407},
  month={June},}@ARTICLE{10604878,
  author={Guo, Yike},
  journal={IEEE Access}, 
  title={Design of Improved Artificial Intelligence Generative Dialogue Algorithm and Dialogue System Model Based on Knowledge Graph}, 
  year={2024},
  volume={12},
  number={},
  pages={102637-102648},
  abstract={Dialogue systems are an important research direction in artificial intelligence, with broad application prospects and market value. In order to improve system efficiency and user satisfaction, an open domain generative dialogue system integrating knowledge graphs has been developed, which facilitates the utilization of rich background knowledge during dialogue generation, thereby generating more coherent and meaningful dialogue content. At the same time, based on the sequence to sequence model, a bidirectional gated loop unit is introduced to better capture contextual information and improve the model’s understanding and generation ability. These results confirmed that the average values of the improved model in the training and validation sets were 98.66% and 87.34%, respectively, with loss values of 0.01 and 0.10. Compared to the baseline model, this improved model improved Hits@1 and Hits@3 by 0.09% and 0.25%, respectively. This improved model had the minimum perplexity of 17.62. The security and diversity of this improved system were 0.80 and 0.82, respectively, taking into account the balance of these two types of performance. Its correlation and fluency were 1.44 and 1.56, respectively. This indicates that this improved model is beneficial for improving the efficiency of generating dialogue and has certain effectiveness, better meeting users’ needs and improve user satisfaction. This system can provide users with a better conversation experience and provide technological and innovative features for artificial intelligence dialogue assistants.},
  keywords={Data mining;Accuracy;Oral communication;Knowledge based systems;Training;Task analysis;Data models;Knowledge graphs;Bidirectional control;Dialogue system;generative;knowledge graph;Seq2Seq model;bidirectional GRU},
  doi={10.1109/ACCESS.2024.3430902},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10538914,
  author={Jinhua, Du and Hao, Yin},
  booktitle={2023 IEEE 22nd International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom)}, 
  title={KLDP:A Data Profiling Technique Based on Knowledge Graph and Large Language Modeling}, 
  year={2023},
  volume={},
  number={},
  pages={2333-2340},
  abstract={The explosive growth of medical data has perfected the establishment of patients' personal health records and provided favorable conditions for smart healthcare, but its fragmentation also brings challenges to patient management. Mainstream research focuses on utilizing medical data to construct disease knowledge graphs to assist patient management, but does not effectively manage massive patient data. In order to make full use of patient data and facilitate the circulation of patient data elements, we propose a new patient sketching technique, KLDP. it constructs knowledge graphs through pre-training techniques, effectively manages patient data based on patients' personal health records and medical history information throughout the treatment cycle, and elementalizes patient data, providing new ideas and implementation solutions for patient management.},
  keywords={Data privacy;Computational modeling;Knowledge graphs;Medical services;Data models;Explosives;Security;China electronic medical record;knowledge graph;data elements;patient sketch;deep learning;pre-trained model;natural language processing;healthcare informatization},
  doi={10.1109/TrustCom60117.2023.00329},
  ISSN={2324-9013},
  month={Nov},}@INPROCEEDINGS{10858965,
  author={Ou, Lu and Ni, Xiaoya and Wu, Wei and Tian, Zhihong},
  booktitle={2024 IEEE 9th International Conference on Data Science in Cyberspace (DSC)}, 
  title={CyGPT: Knowledge Graph-Based Enhancement Techniques for Large Language Models in Cybersecurity}, 
  year={2024},
  volume={},
  number={},
  pages={216-223},
  abstract={Large Language Models (LLMs) excel in numerous Natural Language Processing (NLP) tasks but encounter significant challenges in practical applications, including hallucinations, outdated information, and a lack of domain-specific external knowledge. This study proposes a collaborative, training-free reasoning approach, leveraging close cooperation between Knowledge Graphs (KG) and LLMs for cybersecurity applications. Our approach employs the ‘Joint Reasoning Chain,’ which dynamically integrates information from network security-specific knowledge graphs, serving as an external knowledge base to enhance the domain-specific external knowledge of LLMs. This cooperative method not only improves reliable knowledge-based reasoning but also enhances the traceability of decision-making processes. Furthermore, we introduce a novel GPT-based technique to evaluate answer quality and have performed systematic experiments on a purpose-built test set. The results confirm that our method significantly boosts GPT’s performance in network security knowledge, demonstrating the potential of knowledge graphs to augment LLMs’ reasoning abilities and their applicability in specialized fields.},
  keywords={Knowledge engineering;Systematics;Large language models;Knowledge based systems;Knowledge graphs;Network security;Cognition;Natural language processing;Data models;Computer security;Large Language Model;Knowledge Graph;Retrieval-Augmented Generation;Cybersecurity},
  doi={10.1109/DSC63484.2024.00036},
  ISSN={},
  month={Aug},}@INPROCEEDINGS{9053975,
  author={Lai, Tuan Manh and Hung Tran, Quan and Bui, Trung and Kihara, Daisuke},
  booktitle={ICASSP 2020 - 2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={A Simple But Effective Bert Model for Dialog State Tracking on Resource-Limited Systems}, 
  year={2020},
  volume={},
  number={},
  pages={8034-8038},
  abstract={In a task-oriented dialog system, the goal of dialog state tracking (DST) is to monitor the state of the conversation from the dialog history. Recently, many deep learning based methods have been proposed for the task. Despite their impressive performance, current neural architectures for DST are typically heavily-engineered and conceptually complex, making it difficult to implement, debug, and maintain them in a production setting. In this work, we propose a simple but effective DST model based on BERT. In addition to its simplicity, our approach also has a number of other advantages: (a) the number of parameters does not grow with the ontology size (b) the model can operate in situations where the domain ontology may change dynamically. Experimental results demonstrate that our BERT-based model outperforms previous methods by a large margin, achieving new state-of-the-art results on the standard WoZ 2.0 dataset 1. Finally, to make the model small and fast enough for resource-restricted systems, we apply the knowledge distillation method to compress our model. The final compressed model achieves comparable results with the original model while being 8x smaller and 7x faster.},
  keywords={Bit error rate;Production;Ontologies;Signal processing;Task analysis;Speech processing;Standards;Task-Oriented Dialog Systems;Dialog State Tracking;BERT;Knowledge Distillation},
  doi={10.1109/ICASSP40776.2020.9053975},
  ISSN={2379-190X},
  month={May},}@INPROCEEDINGS{10387600,
  author={Procko, Tyler Thomas and Elvira, Timothy and Ochoa, Omar},
  booktitle={2023 Fifth International Conference on Transdisciplinary AI (TransAI)}, 
  title={GPT-4: A Stochastic Parrot or Ontological Craftsman? Discovering Implicit Knowledge Structures in Large Language Models}, 
  year={2023},
  volume={},
  number={},
  pages={147-154},
  abstract={Ontologies are representational artifacts that purport to accurately portray the aspect of reality under the purview of the ontologists laboring upon them. Ontologies exist in a spectrum of formality, from lexical thesauri to knowledge graphs, to collections of statements of first-order logic. The recent proliferation of Large Language Models (LLMs) has brought to bear interactive “knowledge bases” with general awareness of most things. As ontologists create ontologies from their understanding of reality; and as LLMs, presumably, possess some “understanding” of reality, embedded in their vector matrices corresponding to lexical terms from massive quantities of learned texts, a question is posed: what form of ontology can an LLM create when prompted about some novel facet of reality, without explicitly asking it for an ontology? I.e., will an LLM categorize things into bins, or a subsumption hierarchy, or perhaps something else? LLMs, as they are understood, respond when prompted with the most likely response, because they are predictors of next tokens, i.e., they are stochastic parrots. In any case, it is posited that, if prompted without any explicit request for an ontology, an LLM can produce an ontology of novel form, effectively granting insight into the “understanding” an LLM has of the world, as all humans possess an understanding of the world that ontologies are based upon. This paper explores the use of the flagship LLM, GPT-4, in forming an ontology of a novel domain.},
  keywords={Visualization;Taxonomy;Natural languages;Supervised learning;OWL;Stochastic processes;Organizations;ontology;taxonomy;large language models;GPT},
  doi={10.1109/TransAI60598.2023.00043},
  ISSN={},
  month={Sep.},}@INPROCEEDINGS{9736309,
  author={Burgdorf, Andreas and Paulus, Alexander and Pomp, André and Meisen, Tobias},
  booktitle={2022 IEEE 16th International Conference on Semantic Computing (ICSC)}, 
  title={DocSemMap: Leveraging Textual Data Documentations for Mapping Structured Data Sets into Knowledge Graphs}, 
  year={2022},
  volume={},
  number={},
  pages={209-216},
  abstract={Today, knowledge graphs have been proven to enable the efficient integration of heterogeneous data sets. An important step in creating such knowledge graphs is the mapping of the attributes of a data set to the knowledge graph's ontology. So far, numerous methods have been developed to support this mapping process by using both the schema information as well as the actual data values from a data set in conjunction with external knowledge bases or machine learning approaches. A third source of information, namely textual data documentations, has not yet been considered. In this paper, we present DocSemMap, a novel approach that utilizes textual data documentations of data sets as an additional source for the creation of semantic mappings. We train custom embeddings on the textual data documentations. Further, we utilize pre-trained embeddings that allow us to identify similarities between excerpts of the textual data documentations and descriptions of ontological concepts. Based on this, we build candidate sets of the best suitable concepts for mapping and finally use weighted similarity scores to identify the best fitting concept for each attribute of a data set. The evaluation of our approach outperforms existing approaches for semantic mapping but still has potential for improvement.},
  keywords={Semantics;Natural languages;Knowledge based systems;Fitting;Documentation;Machine learning;Syntactics;semantic mapping;knowledge graph construction;natural language processing;textual data documentation},
  doi={10.1109/ICSC52841.2022.00042},
  ISSN={2325-6516},
  month={Jan},}@INPROCEEDINGS{10553629,
  author={Melzer, Sylvia and Weilkiens, Tim and Muggeo, Christian and Berres, Axel},
  booktitle={2024 IEEE International Systems Conference (SysCon)}, 
  title={Sustainable Development of Information Systems Using SysML, FAS and DOL}, 
  year={2024},
  volume={},
  number={},
  pages={1-8},
  abstract={The use of product families can improve the efficiency of product development as opposed to develop a single-product by reusing existing artefacts and optimizing variability, which leads to a saving of resources and is therefore a sustainable approach. To extend new variants of an already modelled product via the approach of a product family the challenge is to merge the product models, so that the same and varying parts in the model are semantically correct identified and mapped to each other. This paper proposes a comprehensive approach for sustainable development of product families using the Distributed Ontology Language (DOL), Functional Architectures for Systems (FAS), and Systems Modeling Language (SysML). The proposed approach integrates the idea of DOL to represent an ontology of sustainability criteria and to map them to the functional architecture of a product family. FAS is used to model the functional architecture of the product family, while the FAS ontology is used to formalize the functional architecture and provide a standardized vocabulary and set of rules for modelling the functional aspects of the product family. SysML is used to model the product family. The proposed method is demonstrated through a case study of developing a sustainable product family of vacuum cleaner robots. The results show that the proposed method can help to identify opportunities for reducing environ-mental impact and improving social responsibility in the product family design while ensuring that functional requirements and design constraints are met semantically correct.},
  keywords={Vocabulary;Biological system modeling;Ontologies;Systems Modeling Language;Product development;Product design;Sustainable development;sustainability;functional architectures for systems;Distributed Ontology Language;product family;SysML},
  doi={10.1109/SysCon61195.2024.10553629},
  ISSN={2472-9647},
  month={April},}@INPROCEEDINGS{10628803,
  author={Liu, Hao and Zhou, Shuxin and Chen, Zhehuan and Perl, Yehoshua and Wang, Jiayin},
  booktitle={2024 IEEE 12th International Conference on Healthcare Informatics (ICHI)}, 
  title={Using Generative Large Language Models for Hierarchical Relationship Prediction in Medical Ontologies}, 
  year={2024},
  volume={},
  number={},
  pages={248-256},
  abstract={This study extends the exploration of ontology enrichment by evaluating the performance of various open-sourced Large Language Models (LLMs) on the task of predicting hierarchical relationships (IS-A) in medical ontologies including SNOMED CT Clinical Finding and Procedure hierarchies and the human Disease Ontology. With the previous finetuned BERT models for hierarchical relationship prediction as the baseline, we assessed eight open-source generative LLMs for the same task. We observed only three models, without finetuning, demonstrated comparable or superior performance compared to the baseline BERT -based models. The best performance model OpenChat achieved a macro average F1 score of 0.96 (0.95) on SNOMED CT Clinical Finding (Procedure) hierarchy, an increase over 7% from the baseline 0.89 (0.85). On human Disease Ontology, OpenChat excels with an F1 score of 0.91, outperforming the second-best performance model Vicuna (0.84). Notably, some LLMs prove unsuitable for hierarchical relationship prediction tasks or appliable for concept placement of medical ontologies. We also explored various prompt templates and ensemble techniques to uncover potential confounding factors in applying LLMs for IS-A relation predictions for medical ontologies.},
  keywords={Accuracy;Large language models;Medical services;Ontologies;Predictive models;Task analysis;Informatics;Hieratical Relation Prediction;Large Language Models;Medical Ontology;Prompts Design;SNOMED CT},
  doi={10.1109/ICHI61247.2024.00040},
  ISSN={2575-2634},
  month={June},}@ARTICLE{8246712,
  author={Hafeez Khan, Abdul and Hyder Abbas Musavi, Sayed and Rehman, Aqeel-Ur and Shaikh, Asadullah},
  journal={IEEE Access}, 
  title={Ontology-Based Finite Satisfiability of UML Class Model}, 
  year={2018},
  volume={6},
  number={},
  pages={3040-3050},
  abstract={Software models are core artifacts in model driven engineering (MDE) and processable by computer. They are automatically transformed into other models and in MDE, programming code is also produced by the models. The automatic transformation provides a systematic reuse of existing artifacts. However, sometimes models are developed with defects and the defects can implicitly shift into the code, which may be difficult to discover and repair. A promising solution to this problem is model verification. UML class model is a key ingredient of MDE. However, UML only offers graphical components without the support of reasoning, due to lack of the formal foundation. Therefore, the verification of formal properties, such as consistency and finite satisfiability is not possible in UML. This paper proposes an ontology-based optimized verification method for important correctness property “finite satisfiability”of UML class model.},
  keywords={Unified modeling language;Ontologies;Computational modeling;Object oriented modeling;Software;Business;Semantics;Finite satisfiability;model satisfiability;ontology-based satisfiability;model checking;model verification},
  doi={10.1109/ACCESS.2017.2786781},
  ISSN={2169-3536},
  month={},}@ARTICLE{10214033,
  author={Wang, Quanxiu and Cao, Xinlei and Wang, Jianyong and Zhang, Wei},
  journal={IEEE Transactions on Knowledge and Data Engineering}, 
  title={Knowledge-Aware Collaborative Filtering With Pre-Trained Language Model for Personalized Review-Based Rating Prediction}, 
  year={2024},
  volume={36},
  number={3},
  pages={1170-1182},
  abstract={Personalized review-based rating prediction aims at leveraging existing reviews to model user interests and item characteristics for rating prediction. Most of the existing studies mainly encounter two issues. First, the rich knowledge contained in the fine-grained aspects of each review and the knowledge graph is rarely considered to complement the pure text for better modeling user-item interactions. Second, the power of pre-trained language models is not carefully studied for personalized review-based rating prediction. To address these issues, we propose an approach named Knowledge-aware Collaborative Filtering with Pre-trained Language Model (KCF-PLM). For the first issue, to utilize rich knowledge, KCF-PLM develops a transformer network to model the interactions of the extracted aspects w.r.t. a user-item pair. For the second issue, to better represent users and items, KCF-PLM takes all the historical reviews of a user or an item as input to pre-trained language models. Moreover, KCF-PLM integrates the transformer network and the pre-trained language models through representation propagation on the knowledge graph and user-item guided attention of the aspect representations. Thus KCF-PLM combines review text, aspect, knowledge graph, and pre-trained language models together for review-based rating prediction. We conduct comprehensive experiments on several public datasets, demonstrating the effectiveness of KCF-PLM.},
  keywords={Predictive models;Task analysis;Transformers;Knowledge graphs;Microstrip;Fabrics;Image color analysis;Review-based rating prediction;pre-trained language model;collaborative filtering},
  doi={10.1109/TKDE.2023.3301884},
  ISSN={1558-2191},
  month={March},}@INPROCEEDINGS{10750089,
  author={Diaz, Dany and Moreno-Vera, Felipe and Heredia, Juanpablo and Venturim, Fabrício and Poco, Jorge},
  booktitle={2024 IEEE Visual Analytics Science and Technology VAST Challenge}, 
  title={FishBiasLens: Integrating Large Language Models and Visual Analytics for Bias Detection}, 
  year={2024},
  volume={},
  number={},
  pages={17-18},
  abstract={Identifying unreliable sources is crucial for preventing misinformation and making informed decisions. CatchNet, the Oceanus Knowledge Graph, contains biased perspectives that threaten its credibility. We use Large Language Models (LLMs) and interactive visualization systems to identify these biases. By analyzing police reports and using GPT-3.5 to extract information from articles, we establish the ground truth for our analysis. Our visual analytics system detects anomalies, revealing unreliable news sources such as The News Buoy and biased analysts such as Harvey Janus and Junior Shurdlu.},
  keywords={Law enforcement;Visual analytics;Large language models;Soft sensors;Knowledge graphs;Real-time systems;Data mining;Fake news;GPT;Visualization;Knowledge Graph;Bias detection;LLM},
  doi={10.1109/VASTChallenge64683.2024.00013},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{9861086,
  author={Morine, Melissa J. and Priami, Corrado and Coronado, Edith and Haber, Juliana and Kaput, Jim},
  booktitle={2022 IEEE International Conference on Digital Health (ICDH)}, 
  title={A Comprehensive and Holistic Health Database}, 
  year={2022},
  volume={},
  number={},
  pages={202-207},
  abstract={Health and the initiation, progression, and outcome of disease are the result of multiple environmental factors interacting with individual genetic makeups. Collectively, results from primary clinical research on health and disease represent the most compendious and reliable source of actionable knowledge on strategies to optimize health. However, the dispersal of this information as unstructured data, distributed across millions of documents, is a substantial challenge in bridging the gap between primary research and concrete recommendations for improving health. Described here is the development and implementation of a machine reading pipeline that builds a knowledge graph of causal relationships between a broad range of predictive/modifiable diet and lifestyle factors and health outcomes, extracted from the vast biomedical corpus in the National Library of Medicine.},
  keywords={Text mining;Systematics;Pipelines;Semantics;Genetics;Libraries;Environmental factors;Healthware;knowledge graphs;natural language processing},
  doi={10.1109/ICDH55609.2022.00039},
  ISSN={},
  month={July},}@INPROCEEDINGS{10169047,
  author={Xu, Shiyu and Song, Hui and Wu, Renchang and Shi, Junwei},
  booktitle={2023 2nd Asia Conference on Electrical, Power and Computer Engineering (EPCE)}, 
  title={A Natural Language Understanding Model Based on Encoding Fusion For Power Marketing Indicator Answering}, 
  year={2023},
  volume={},
  number={},
  pages={13-17},
  abstract={Accurate understanding of user questions is the core of a domain oriented task oriented dialogue system. To apply the Natural Language Understanding Model (NLU) to power marketing indicator Q&A, the first is to define the NLU task schema based on domain background knowledge, and manually annotate a training dataset for model training. Due to the lack of historical conversation data, manually organizing problem and annotating is labor-intensive. Insufficient sample size affects the performance of the model. We further propose an approach to improve the end-to-end NLU model with marketing domain triple knowledge, which provide rich contextual information for the slot representation. During the NLU model coding stage, the representation of entity relationships is incorporated into the token coding, enhancing the model's understanding of domain terms that do not appear in the samples. Practice has shown that introducing domain knowledge do make up for the lack of training samples and significantly improve the accuracy of slot value recognition.},
  keywords={Training;Databases;Semantics;Training data;Oral communication;Encoding;Natural language processing;Power Marketing;Natural Language Understanding;Encoding Fusion;Knowledge Graph},
  doi={10.1109/EPCE58798.2023.00011},
  ISSN={},
  month={April},}@INPROCEEDINGS{10207605,
  author={Li, Jingyi and Chen, Qi and Wang, Wei and Wu, Fangyu},
  booktitle={2023 IEEE International Conference on Smart Computing (SMARTCOMP)}, 
  title={Knowledge-embedded Prompt Learning for Zero-shot Social Media Text Classification}, 
  year={2023},
  volume={},
  number={},
  pages={222-224},
  abstract={Social media plays an irreplaceable role in shaping the way information is created shared and consumed. While it provides access to a vast amount of data, extracting and analyzing useful insights from complex and dynamic social media data can be challenging. Deep learning models have shown promise in social media analysis tasks, but such models require a massive amount of labelled data which is usually unavailable in real-world settings. Additionally, these models lack common-sense knowledge which can limit their ability to generate comprehensive results. To address these challenges, we propose a knowledge-embedded prompt learning model for zero-shot social media text classification. Our experimental results on four social media datasets demonstrate that our proposed approach outperforms other well-known baselines.},
  keywords={Deep learning;Analytical models;Data analysis;Social networking (online);Computational modeling;Text categorization;Media;Zero-shot text classification;prompt learning;knowledge graph embedding;social media data analysis},
  doi={10.1109/SMARTCOMP58114.2023.00054},
  ISSN={2693-8340},
  month={June},}@INPROCEEDINGS{9378066,
  author={Stojanov, Riste and Kocev, Ilija and Gramatikov, Sasho and Popovski, Gorjan and Koroušić Seljak, Barbara and Eftimov, Tome},
  booktitle={2020 IEEE International Conference on Big Data (Big Data)}, 
  title={Toward Robust Food Ontology Mapping}, 
  year={2020},
  volume={},
  number={},
  pages={3596-3601},
  abstract={Data normalization methodologies are extremely welcome to link extracted information from textual data to different semantic resources. These methodologies have been previously well researched especially in the biomedical domain, where health concepts were normalized and described using semantic tags. Recently, a methodology for normalizing food concepts has been proposed, based on Named-Entity Recognition methods resulting in the FoodOntoMap semantic resource. In this paper, we propose and evaluate a new architecture for linking phrases (i.e. textual name for foods) to concepts from semantic resources in the Food and Nutrition domain. We represent the food phrases (i.e. their textual name) in continuous vector space using state-of-the-art Natural Language Processing (NLP) embedding algorithms, and evaluate their proximity with respect to the annotated semantic food concepts. Additionally, indexing was incorporated to improve efficiency.The GloVe embedding with mean pooling provided best evaluation results, with maximum recall of 74% for the Snomed CT semantic dataset, which is promising result, but also opens a space for future improvement of the phrase representations, and their incorporation in this system.},
  keywords={Semantics;Taxonomy;Ontologies;Big Data;Syntactics;Natural language processing;Indexing;Natural Language Processing;Text representation;Embeddings;Data normalization and linking},
  doi={10.1109/BigData50022.2020.9378066},
  ISSN={},
  month={Dec},}@INPROCEEDINGS{9750154,
  author={Zhang, Jian and Qin, Bo and Zhang, Yufei and Zhou, Junhua and Wang, Hongwei},
  booktitle={2021 IEEE International Conference on e-Business Engineering (ICEBE)}, 
  title={A Framework for Effective Knowledge Extraction from A Data Space Formed by Unstructured Technical Reports using Pre-trained Models}, 
  year={2021},
  volume={},
  number={},
  pages={120-125},
  abstract={The transformation of unstructured data into triples is a key task in knowledge graph construction. It remains a great challenge to complete this task on technical reports. In this work, we propose a framework for effectively structuring data structuring in knowledge graph construction from a data space formed by technical reports. This framework specifically consist of two pre-trained language models to provide the embed dings and a sequence labeling model to tag the entity labels. The pre-trained models, i.e. the Flair embedding and the BERT model, are employed to combine the output vectors to downstream tasks. To evaluate the proposed method, we conduct named entity recognition experiments using the status reports of complex equipment in nuclear power plants. The evaluation shows the framework achieves remarkable improvement on F1 score. This paper details the framework, the experiments, and the evaluation of the proposed method.},
  keywords={Knowledge engineering;Conferences;Bit error rate;Writing;Data models;Labeling;Data mining;knowledge graph construction;data space;pre-trained language model;named entity recognition},
  doi={10.1109/ICEBE52470.2021.00028},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10339738,
  author={Stoyanov, Stanimir and Kumurdjieva, Milena and Tabakova-Komsalova, Veneta and Doukovska, Lyubka},
  booktitle={2023 International Conference on Big Data, Knowledge and Control Systems Engineering (BdKCSE)}, 
  title={Using LLMs in Cyber-Physical Systems for Agriculture - ZEMELA}, 
  year={2023},
  volume={},
  number={},
  pages={1-6},
  abstract={This paper presents the idea of developing an advisory service using the capabilities of generative artificial intelligence and in particular of Large Language Model. The service will assess the risks for farmers when preparing projects under different programs, taking into account the Bulgarian legislation related to agriculture, as well as the requirements of the relevant program. The results of a feasibility analysis are summarized in the article. Furthermore, two architectural approaches are discussed. The service will be integrated in the platform for smart agriculture named ZEMELA. A brief overview of this platform is also given in the article.},
  keywords={Smart agriculture;Knowledge engineering;Prototypes;Legislation;Cyber-physical systems;Big Data;Control systems;generative artificial intelligence;large language model;advisory service;smart agriculture},
  doi={10.1109/BdKCSE59280.2023.10339738},
  ISSN={},
  month={Nov},}@INPROCEEDINGS{10724185,
  author={Aryan and Thingbaijam, Lenin and Palle, Kowstubha and Prasad, P. Venkata and Mallala, Balasubbareddy and Patil, Shrishailappa},
  booktitle={2024 15th International Conference on Computing Communication and Networking Technologies (ICCCNT)}, 
  title={Incorporating Knowledge Graphs in Semantic Search}, 
  year={2024},
  volume={},
  number={},
  pages={1-6},
  abstract={Information Graphs are a powerful mechanism for incorporating dependent facts into semantic search. They are a form of graph database that represents standards and their relationships, as opposed to just information and their attributes. This additional layer of abstraction enables greater and a sophisticated inferencing and querying, making them perfect to be used in semantic search. Incorporating knowledge Graphs into semantic search entails numerous technical steps: 1. Information Extraction: The first step is to pick out and extract applicable facts from various resources, such as databases, text documents, and APIs. This fact can encompass entities, relationships, and their attributes. 2. Information Alignment: Once the records have been extracted, it needs to be aligned with the ideas in the knowledge graph. This includes mapping the extracted records to the suitable entities and their relationships in the graph. 3. Information Enrichment: To improve the first-class and completeness of the knowledge graph, the extracted statistics may additionally need to be enriched with additional statistics. This will involve incorporating information from external sources or leveraging device mastering techniques to deduce lacking facts. 4. Entity Disambiguation: Considering that entities in the understanding graph may additionally have comparable or ambiguous names, it is very much essential to disambiguate them to ensure correct search outcomes. This can be done through strategies inclusive of named entity recognition.},
  keywords={Knowledge engineering;Accuracy;Semantic search;Databases;Knowledge graphs;Named entity recognition;Information retrieval;Data mining;Standards;Knowledge graph;semantic search;multi-modal knowledge graph},
  doi={10.1109/ICCCNT61001.2024.10724185},
  ISSN={2473-7674},
  month={June},}@ARTICLE{10613766,
  author={Liu, Shuang and Ao, Zhizhuo and Chen, Peng and Kolmanič, Simon},
  journal={IEEE Access}, 
  title={CollRec: Pre-Trained Language Models and Knowledge Graphs Collaborate to Enhance Conversational Recommendation System}, 
  year={2024},
  volume={12},
  number={},
  pages={104663-104675},
  abstract={Existing conversational recommender systems (CRS) use insufficient generality in incorporating external information using knowledge graphs. The recommendation module and generation module are loosely connected during model training and shallowly integrated during inference. A simple switching or copying mechanism is used to merge recommended items into generated responses. These problems significantly degrade the recommendation performance. To alleviate this problem, we propose a novel unified framework for collaboratively enhancing conversational recommendations using pre-trained language models and knowledge graphs (CollRec). We use a fine-tuned pre-trained language model to efficiently extract knowledge graphs from conversational text descriptions, perform entity-based recommendations based on the generated graph nodes and edges, and fine-tune a large-scale pre-trained language model to generate fluent and diverse responses. Experimental results on the WebNLG 2020 Challenge dataset, ReDial dataset, and Reddit-Movie dataset show that our CollRec model significantly outperforms the state-of-the-art methods.},
  keywords={Knowledge graphs;Oral communication;Task analysis;Recommender systems;Motion pictures;Costs;Accuracy;Large language models;Conversational recommendation system;knowledge graph;large language model;end-to-end generation;fine-tuning;ReDial;WebNLG 2020 challenge},
  doi={10.1109/ACCESS.2024.3434720},
  ISSN={2169-3536},
  month={},}@INPROCEEDINGS{10208670,
  author={Srinivasan, Tejas and Ren, Xiang and Thomason, Jesse},
  booktitle={2023 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)}, 
  title={Curriculum Learning for Data-Efficient Vision-Language Alignment}, 
  year={2023},
  volume={},
  number={},
  pages={5619-5624},
  abstract={Aligning image and text encoders from scratch using contrastive learning requires large amounts of paired image-text data. We alleviate this need by aligning individually pre-trained language and vision representation models using a much smaller amount of paired data with a curriculum learning algorithm to learn fine-grained vision-language alignments. TOnICS (Training with Ontology-Informed Contrastive Sampling) initially samples minibatches whose image-text pairs contain a wide variety of objects to learn object-level vision-language alignment, and progressively samples minibatches where all image-text pairs contain the same object to learn finer-grained contextual alignment. Aligning pre-trained BERT and VinVL-OD models to each other using TOnICS outperforms CLIP on downstream zero-shot image retrieval using < 1% as much training data.},
  keywords={Training;Computer vision;Conferences;Computational modeling;Image retrieval;Bit error rate;Training data},
  doi={10.1109/CVPRW59228.2023.00595},
  ISSN={2160-7516},
  month={June},}@INPROCEEDINGS{10298429,
  author={Phokela, Kanchanjot Kaur and Sikand, Samarth and Singi, Kapil and Dey, Kuntal and Sharma, Vibhu Saujanya and Kaulgud, Vikrant},
  booktitle={2023 38th IEEE/ACM International Conference on Automated Software Engineering (ASE)}, 
  title={Smart Prompt Advisor: Multi-Objective Prompt Framework for Consistency and Best Practices}, 
  year={2023},
  volume={},
  number={},
  pages={1846-1848},
  abstract={Recent breakthroughs in Large Language Models (LLM), comprised of billions of parameters, have achieved the ability to unveil exceptional insight into a wide range of Natural Language Processing (NLP) tasks. The onus of the performance of these models lies in the sophistication and completeness of the input prompt. Minimizing the enhancement cycles of prompt with improvised keywords becomes critically important as it directly affects the time to market and cost of the developing solution. However, this process inevitably has a trade-off between the learning curve/proficiency of the user and completeness of the prompt, as generating such a solutions is an incremental process. In this paper, we have designed a novel solution and implemented it in the form of a plugin for Visual Studio Code IDE, which can optimize this trade-off, by learning the underlying prompt intent to enhance with keywords. This will tend to align with developers' collection of semantics while developing a secure code, ensuring parameter and local variable names, return expressions, simple pre and post-conditions. and basic control and data flow are met.},
  keywords={Visualization;Codes;Costs;Semantics;Time to market;Natural language processing;Task analysis;Prompt Engineering;Artificial Intelligence;Deep Learning;LLM;Ontology},
  doi={10.1109/ASE56229.2023.00019},
  ISSN={2643-1572},
  month={Sep.},}@ARTICLE{9034075,
  author={Jiang, Tianwen and Zeng, Qingkai and Zhao, Tong and Qin, Bing and Liu, Ting and Chawla, Nitesh V. and Jiang, Meng},
  journal={IEEE/ACM Transactions on Computational Biology and Bioinformatics}, 
  title={Biomedical Knowledge Graphs Construction From Conditional Statements}, 
  year={2021},
  volume={18},
  number={3},
  pages={823-835},
  abstract={Conditions play an essential role in biomedical statements. However, existing biomedical knowledge graphs (BioKGs) only focus on factual knowledge, organized as a flat relational network of biomedical concepts. These BioKGs ignore the conditions of the facts being valid, which loses essential contexts for knowledge exploration and inference. We consider both facts and their conditions in biomedical statements and proposed a three-layered information-lossless representation of BioKG. The first layer has biomedical concept nodes, attribute nodes. The second layer represents both biomedical fact and condition tuples by nodes of the relation phrases, connecting to the subject and object in the first layer. The third layer has nodes of statements connecting to a set of fact tuples and/or condition tuples in the second layer. We transform the BioKG construction problem into a sequence labeling problem based on a novel designed tag schema. We design a Multi-Input Multi-Output sequence labeling model (MIMO) that learns from multiple input signals and generates proper number of multiple output sequences for tuple extraction. Experiments on a newly constructed dataset show that MIMO outperforms the existing methods. Further case study demonstrates that the BioKGs constructed provide a good understanding of the biomedical statements.},
  keywords={Biological system modeling;Labeling;Tagging;Feeds;MIMO communication;Task analysis;Biomedical knowledge graph;information extraction;conditional statement;sequence labeling},
  doi={10.1109/TCBB.2020.2979959},
  ISSN={1557-9964},
  month={May},}@ARTICLE{10737425,
  author={Wei, Yuting and Hu, Linmei and Zhu, Yangfu and Zhao, Jiaqi and Wu, Bin},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing}, 
  title={Knowledge-Guided Transformer for Joint Theme and Emotion Classification of Chinese Classical Poetry}, 
  year={2024},
  volume={32},
  number={},
  pages={4783-4794},
  abstract={The classifications of the theme and emotion are essential for understanding and organizing Chinese classical poetry. Existing works often overlook the rich semantic knowledge derived from poem annotations, which contain crucial insights into themes and emotions and are instrumental in semantic understanding. Additionally, the complex interdependence and diversity of themes and emotions within poems are frequently disregarded. Hence, this paper introduces a Poetry Knowledge-augmented Joint Model (Poka) specifically designed for the multi-label classification of themes and emotions in Chinese classical poetry. Specifically, we first employ an automated approach to construct two semantic knowledge graphs for theme and emotion. These graphs facilitate a deeper understanding of the poems by bridging the semantic gap between the obscure ancient words and their modern Chinese counterparts. Representations related to themes and emotions are then acquired through a knowledge-guided mask-transformer. Moreover, Poka leverages the inherent correlations between themes and emotions by adopting a joint classification strategy with shared training parameters. Extensive experiments demonstrate that our model achieves state-of-the-art performance on both theme and emotion classifications, especially on tail labels.},
  keywords={Semantics;Knowledge graphs;Annotations;Correlation;Symbols;Support vector machines;Speech processing;Bayes methods;Transformers;Training;Chinese classical poetry;data mining;joint learning;knowledge graph;multi-label classification},
  doi={10.1109/TASLP.2024.3487409},
  ISSN={2329-9304},
  month={},}@INPROCEEDINGS{9836511,
  author={Liu, Di and Zhang, Yungui and Li, Zhuoqing},
  booktitle={2022 IEEE 10th Joint International Information Technology and Artificial Intelligence Conference (ITAIC)}, 
  title={A Survey of Graph Neural Network Methods for Relation Extraction}, 
  year={2022},
  volume={10},
  number={},
  pages={2209-2223},
  abstract={Relation extraction, as an important part of knowl-edge graph and natural language processing, aims to extract semantic relations between entities by understanding text, which has attracted great interest of researchers. Recently, with the rise of the advanced technology of graph neural networks, numer-ous methods have emerged that employ graph neural network techniques to address relation extraction tasks. However, to the best of our knowledge, few studies provide a complete picture of how and to what extent graph neural networks has been applied to this problem. In this paper, we provide a thorough review of graph neural network-based relation extraction methods. We first present a brief introduction of graph neural networks. Besides, we describe the relation extraction task, comprehensively review the corresponding datasets, and discuss the reason why graph neural networks are adopted for relation extraction tasks. After that, we focus on relation extraction existing approaches built upon graph neural networks, including specialized architectures designed for the basic task as well as novel graph neural network models designed to tackle the challenging problems. We also discuss relation extraction methods based on graph neural networks in combination with pre-trained language models. Finally, we give out our conclusion and provide several further research directions for this research topic.},
  keywords={Knowledge engineering;Conferences;Semantics;Learning (artificial intelligence);Graph neural networks;Natural language processing;Data mining;Relation extraction;Knowledge graph;Graph neural network;Natural language processing;Deep learning},
  doi={10.1109/ITAIC54216.2022.9836511},
  ISSN={2693-2865},
  month={June},}@INPROCEEDINGS{8843314,
  author={Paczona, Martin and Mayr, Heinrich C.},
  booktitle={2019 IEEE 15th International Conference on Automation Science and Engineering (CASE)}, 
  title={Model-Driven Mechatronic System Development}, 
  year={2019},
  volume={},
  number={},
  pages={1730-1736},
  abstract={This paper presents an approach for model-driven mechatronic system development. The approach starts with the definition of a suitable domain-specific modeling language and its semantic foundation in a domain ontology. Models created in this language are used to generate application-specific artefacts. We illustrate our approach with the example of the development of Electric Vehicle Testbeds (EVTs), i.e. systems for testing high-voltage electric vehicle components. Companies in the electric vehicle industry (automobile, aircraft and rail vehicle manufacturers) mainly use such systems. Like many other mechatronic systems, EVTs are typically tailor-made solutions. Our approach automates manual development steps and can thus contribute to quality improvement, development time reduction and finally cost reduction.},
  keywords={Ontologies;Integrated circuit modeling;Unified modeling language;Software;Tools;Electric vehicles},
  doi={10.1109/COASE.2019.8843314},
  ISSN={2161-8089},
  month={Aug},}@INPROCEEDINGS{10540801,
  author={Libro, Mario and Gaiardelli, Sebastiano and Lora, Michele and Fummi, Franco},
  booktitle={2024 IEEE International Conference on Industrial Technology (ICIT)}, 
  title={Integrating Modeling Languages with Ontologies in the Context of Industry 4.0}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  abstract={The evolving landscape of manufacturing systems and the increasing complexity of production lines necessitate innovative approaches for efficient information management and process modeling. The System Modeling Language (SysML) provides a powerful language to express such information. However, the expressiveness comes at a cost: on the one hand, the modeling phase requires a deep understanding of the domain; on the other, SysML lacks rigorous semantics. This work introduces a novel methodology that enriches the SysML with ontology reasoning in the context of manufacturing systems. The approach uses ontologies as a comprehensive knowledge base that encapsulates essential details about the machinery, their provided functions, and the associated constraints. The approach offers a reliable and efficient way to verify the consistency and correctness of production recipes: it ensures recipes' practical applicability in the manufacturing process while reducing errors that can occur in the modeling phase. The proposed methodology has been validated through its application to a fully-fledged manufacturing line, showing its applicability in real-world scenarios.},
  keywords={Manufacturing processes;Process modeling;Knowledge based systems;Ontologies;Cognition;Systems Modeling Language;Reliability;Computer-aided manufacturing;process modeling;knowledge representation},
  doi={10.1109/ICIT58233.2024.10540801},
  ISSN={2643-2978},
  month={March},}@INPROCEEDINGS{10645449,
  author={Xie, Qinhua and Liu, Weicong and Yuan, Fan and Shi, Jifan and Liu, Ziyu and Zhang, Yanbing},
  booktitle={2024 IEEE International Conference on Multimedia and Expo Workshops (ICMEW)}, 
  title={VidBot: Intelligent Video Learning Tool for Content Mining and Playback Traffic Statistics}, 
  year={2024},
  volume={},
  number={},
  pages={1-3},
  abstract={With the rapid development of online education, video-based learning has become a significant mode of learning. However, existing video learning tools often fail to fully meet learners' needs for in-depth learning and interactive communication, thereby hindering learning outcomes. To address this challenge, this study proposes and implements an innovative intel-ligent video learning tool named VidBot, which is based on large language models for deep content mining and playback traffic analysis of videos. VidBot integrates Whisper and ChatGLM3-6B language models as well as the Pyltp library to build seven major functional modules, including Video Playback Visualization, Mind Mapping, Knowledge Graph, Cross-referencing of Knowledge Points, Automatic Video Segmentation, Intelligent Tutor, and Shared Notes. These modules aim to provide learners with deeper and more interactive learning experiences. The client of VidBot is released in the form of a plugin, and the server is integrated into the online education platform developed independently by our university.},
  keywords={Industries;Visualization;Analytical models;Large language models;Conferences;Education;Knowledge graphs;Online education;video analysis;interactive learning;text summarization;large language model},
  doi={10.1109/ICMEW63481.2024.10645449},
  ISSN={2995-1429},
  month={July},}@INPROCEEDINGS{10242690,
  author={Luo, Ziqian},
  booktitle={2023 International Conference on Communications, Computing and Artificial Intelligence (CCCAI)}, 
  title={Knowledge-guided Aspect-based Summarization}, 
  year={2023},
  volume={},
  number={},
  pages={17-22},
  abstract={Contextualized pre-trained models, such as BERT [1] and BART [2], have shown great potential in various NLP tasks, pushing the state-of-the-art results to a new level. Although studies have shown that those pre-trained models have captured different kinds of knowledge due to the massive corpus they have been trained on [3], injecting task-specific external knowledge often shows further improvement [4]. Here we choose aspect-based abstractive summarization as a case study and explore two different ways to inject external knowledge into BART. One is through a knowledge graph, the other is through human-defined sequence-level scores. Experiment results show that both methods can get an improvement over vanilla BART.},
  keywords={Computational modeling;Knowledge graphs;Telecommunication computing;Task analysis;Artificial intelligence;Context modeling;pre-trained models;knowledge graph},
  doi={10.1109/CCCAI59026.2023.00012},
  ISSN={},
  month={June},}@INPROCEEDINGS{9643650,
  author={Smajevic, Muhamed and Bork, Dominik},
  booktitle={2021 ACM/IEEE International Conference on Model Driven Engineering Languages and Systems Companion (MODELS-C)}, 
  title={From Conceptual Models to Knowledge Graphs: A Generic Model Transformation Platform}, 
  year={2021},
  volume={},
  number={},
  pages={610-614},
  abstract={Semantic processing of conceptual models is a focus of research since several years, bridging the disciplines of knowledge-based systems, conceptual modeling, and model-driven software engineering. With the uptake of Knowledge Graphs, the research in this area gained further momentum. In this paper, we introduce a generic and extensible platform that enables the automated transformation of conceptual models into Knowledge Graphs. The platform can transform any model created by a state-of-the-art metamodeling platform (EMF and ADOxx) into standardized Knowledge Graph representations like GraphML, RDF, and OWL. In the paper at hand, we introduce our platform and evaluate it with a corpus of 5.000 UML models that we transform into Knowledge Graphs and subsequently exemplify the rich functionalities enabled by the graph structure by an automated detection of UML model smells.},
  keywords={Knowledge engineering;Analytical models;Codes;Scalability;Unified modeling language;Software algorithms;Semantics;Knowledge Graph;Modeling tool;Code smells;Model refactoring;Model transformation},
  doi={10.1109/MODELS-C53483.2021.00093},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{9362691,
  author={Chen, Zhongmin and Xu, Hao and Gao, Shuo and Wang, Yongsheng},
  booktitle={2021 IEEE International Conference on Power Electronics, Computer Applications (ICPECA)}, 
  title={Semantic generation mechanism of news images based on Concept-Net}, 
  year={2021},
  volume={},
  number={},
  pages={245-248},
  abstract={Online news is an important means of disseminating information, but some online news texts do not match the content described in the original news pictures, and even cause ambiguity among readers. This phenomenon has seriously affected the authority of news and the credibility of news media. In response to this problem, this paper proposes a rich news image description mechanism based on the Concept-Net knowledge graph. The model we provide consists of two parts, namely, extracting the image content and rendering with natural language to generate an accurate description of the news image.},
  keywords={Conferences;Semantics;Natural languages;Computer applications;Media;Rendering (computer graphics);Power electronics;Social media;picture description;entity association;knowledge graph},
  doi={10.1109/ICPECA51329.2021.9362691},
  ISSN={},
  month={Jan},}@INPROCEEDINGS{10574957,
  author={Abane, Amar and Battou, Abdella and Merzouki, Mheni},
  booktitle={NOMS 2024-2024 IEEE Network Operations and Management Symposium}, 
  title={An Adaptable AI Assistant for Network Management}, 
  year={2024},
  volume={},
  number={},
  pages={1-3},
  abstract={This paper presents a network management AI assistant built with Large Language Models. It adapts at runtime to the network state and specific platform, leveraging techniques like prompt engineering, document retrieval, and Knowledge Graph integration. The AI assistant aims to simplify management tasks and is easily reproducible with available source code.},
  keywords={Runtime;Databases;Source coding;Knowledge graphs;Task analysis;LLMs;text embeddings;RAG;network management;knowledge graph;Neo4j;graph database},
  doi={10.1109/NOMS59830.2024.10574957},
  ISSN={2374-9709},
  month={May},}@INPROCEEDINGS{10459794,
  author={Zhang, Hongzhi and Shafiq, M. Omair},
  booktitle={2023 International Conference on Machine Learning and Applications (ICMLA)}, 
  title={ConKGP: A Contrastive Learning Framework on Knowledge Graphs for Commonsense Reasoning with Perturbation}, 
  year={2023},
  volume={},
  number={},
  pages={1120-1125},
  abstract={Question-answering systems are widely used in var-ious productions, and the use of knowledge graphs has been proven to improve their performance. However, current question-answering systems utilizing knowledge graphs suffer from the long tail effect, where high-degree nodes in the knowledge graph are favored by the model. This can lead to a bias in the model towards rare or complex answers, negatively impacting the performance of the question-answering system on questions with uncommon answers. In this paper, we propose a method, ConKGP, to improve the performance of the model QA-GNN. QA-GNN is a state-of-the-art question-answering method that combines language models and knowledge graphs. For the original model structure, we combine contrastive learning to obtain better representation and evenly distribute representation in the data space. Furthermore, we add perturbations to the input of the decoder to enhance the robustness and generalization ability of the model. Our proposed method achieves better results on CommonsenseQA and MedQA-USMLE datasets. The average improvements over QA-GNN are 4.3% and 3.6% respectively. Our experiments show that ConKGP can effectively solve the long tail effect and improve the performance of QA-GNN in processing uncommon answers.},
  keywords={Visualization;Perturbation methods;Self-supervised learning;Knowledge graphs;Tail;Production;Machine learning;Question Answering;Commonsense Reasoning;Knowledge Graph;Contrastive Learning;Perturbations},
  doi={10.1109/ICMLA58977.2023.00167},
  ISSN={1946-0759},
  month={Dec},}@INPROCEEDINGS{9509672,
  author={Meng, Fanqi and Zheng, Yujie and Bao, Songbin and Wang, Jingdong},
  booktitle={2021 10th IEEE International Conference on Communication Systems and Network Technologies (CSNT)}, 
  title={The Research Status of Formulaic Language Identification}, 
  year={2021},
  volume={},
  number={},
  pages={886-891},
  abstract={Formulaic language, also known as formulaic sequences, is essentially a special kind of multiword strings. The words in the string usually have a fixed or semi-fixed combination form that falls in between phrase and sentence in the language. Formulaic language identification is to identifying schematic string patterns in corpora. According to statistics from different researchers, formulaic language is very common in both spoken and written language. Therefore, its research is helpful to the development of machine translation as well as second language acquisition. In order to better sort out the research hotspots of formula identification, this article took 143 papers included in the core database of web of science and 139 papers in CNKI in the past ten years as the research objects, adopted the method of bibliometric to conduct the following research. By using bibliometric online analysis platform, knowledge graph is drawn from the distribution of research forces of countries, institutions, authors and journals, and keyword co-occurrence, so as to deeply analyze the technical topics of formulaic language identification. The research found that the research strength of formula identification is mainly concentrated in universities at home and abroad. The identification methods have changed from initial manual labeling to simple frequency-based identification. At present, the application of computer technology identification has become a new research hotspot.},
  keywords={Knowledge engineering;Databases;Communication systems;Conferences;Bibliometrics;Manuals;Object recognition;bibliometric;knowledge graph;formulaic language identification},
  doi={10.1109/CSNT51715.2021.9509672},
  ISSN={2329-7182},
  month={June},}@INPROCEEDINGS{10405568,
  author={Corrado, Mario and Giliberti, Vincenzo and Gozzi, Manuel and Lanzolla, Vincenzo and Vetere, Guido and Zurlo, Domenico},
  booktitle={2023 IEEE International Conference on Metrology for eXtended Reality, Artificial Intelligence and Neural Engineering (MetroXRAINE)}, 
  title={VO.I.C.E. FIRST: Supporting Human Assistants with Real-Time Voice Understanding}, 
  year={2023},
  volume={},
  number={},
  pages={1104-1109},
  abstract={While AI and automation have made significant strides in customer support, there are still situations where human intervention via voice channels is necessary to provide the best possible customer experience. In fact, although AI and chatbots have become increasingly sophisticated, they may not always be able to handle complex or nuanced customer issues. Human agents can better understand and respond to these situations, providing tailored solutions. At the same time, solving non-trivial customer problems often requires access to knowledge bases and contextual customer information, for which AI is particularly well suited. Hence the idea of integrating human and artificial intelligence in a hybrid solution. We developed an AI system to help human assistants in the process of handling conversations. This system can be viewed as a collaborative bot (cobot). The cobot captures the audio stream of the conversation, converts it to text and analyzes it in real time. The extracted tokens are classified and sent to a reasoning system based on a knowledge graph, that provides information and action suggestions to the human assistant. Assistants are also capable of providing information to the reasoning system, utilizing their human understanding of the client's circumstances as they unfold. While designing a prototypical solution for utility services, we have faced the problem of real-time use of computationally complex procedures, including spontaneous speech understanding and knowledge-based heuristic rules. Moreover, we adopted a standards-based approach and experimented with open source reasoners and publicly available language models. The paper outlines the system architecture and design, and discusses the results of the first experiments.},
  keywords={Computational modeling;Knowledge based systems;Oral communication;Chatbots;Real-time systems;Cognition;Business;virtual assistants;natural language understanding;knowledge graph;real time reasoning},
  doi={10.1109/MetroXRAINE58569.2023.10405568},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{10475614,
  author={Avila, Caio Viktor S. and Vidal, Vânia M.P. and Franco, Wellington and Casanova, Marco A.},
  booktitle={2024 IEEE 18th International Conference on Semantic Computing (ICSC)}, 
  title={Experiments with text-to-SPARQL based on ChatGPT}, 
  year={2024},
  volume={},
  number={},
  pages={277-284},
  abstract={Currently, large language models (LLMs) are the state of the art for pre-trained language models. LLMs have been applied to many tasks, including question and answering over Knowledge Graphs (KGs) and text-to-SPARQL, that is, the translation of Natural Language questions to SPARQL queries. With such motivation, this paper first describes preliminary experiments to evaluate the ability of ChatGPT to answer NL questions over KGs. Based on these experiments, the paper introduces Auto-KGQAGPT, an autonomous domain-independent framework based on LLMs for text-to-SPARQL. The framework selects fragments of the KG, which the LLM uses to translate the user’s NL question to a SPARQL query on the KG. Finally, the paper describes preliminary experiments with Auto-KGQAGPT with ChatGPT that indicate that the framework substantially reduced the number of tokens passed to ChatGPT without sacrificing performance.},
  keywords={Training;Semantics;Natural languages;Knowledge graphs;Benchmark testing;Chatbots;Iterative methods;text-to-SPARQL;ChatGPT;LLM;Knowledge Graph},
  doi={10.1109/ICSC59802.2024.00050},
  ISSN={2472-9671},
  month={Feb},}@INPROCEEDINGS{10817806,
  author={Mitsuji, Fumiya and Chakraborty, Sudesna and Morita, Takeshi and Egami, Shusaku and Ugai, Takanori and Fukuda, Ken},
  booktitle={2024 Twelfth International Symposium on Computing and Networking Workshops (CANDARW)}, 
  title={Entity Linking for Wikidata using Large Language Models and Wikipedia Links}, 
  year={2024},
  volume={},
  number={},
  pages={144-149},
  abstract={Entity Linking (EL), a task that maps named entities in text to corresponding entities in a knowledge base, has gained attention as a fundamental technology in knowledge processing and natural language processing. Conventional EL methods typically tokenize input text and utilize multiple features such as word embeddings and knowledge graph embeddings. Adapting these conventional EL methods to specific languages requires modifying language-dependent modules like tokenizers and word embedding models for the target language. In this study, we propose an EL method targeting Wikidata, based on Large Language Models (LLMs) and links from Wikidata to Wikipedia. Our method prompts LLMs to extract entity names from the input text and generate the corresponding Wikipedia URLs. Furthermore, it queries the Wikidata SPARQL endpoint to obtain Wikidata IDs from the Wikipedia URLs, outputting the entity names and their Wikidata IDs. This method can be applied to various languages by modifying the prompts. To evaluate, we compared the proposed method with conventional EL methods (PNEL and Japanese PNEL) on Japanese and English datasets from LC-QuAD2.0, SimpleQuestions, and WebQSP; using GPT-3.5, GPT-4, and Llama 2 as LLMs. The results showed that our method using GPT-4 outperformed conventional EL methods in recall and F-scores on datasets except for Japanese SimpleQuestions.},
  keywords={Translation;Large language models;Conferences;Computational modeling;Knowledge based systems;Encyclopedias;Knowledge graphs;Natural language processing;Internet;Online services;Entity Linking;Large Language Model;Wiki-data;Wikipedia;Knowledge Graph},
  doi={10.1109/CANDARW64572.2024.00030},
  ISSN={2832-1324},
  month={Nov},}@INPROCEEDINGS{10628949,
  author={Hadar, Ethan and Heursch, Sven T.},
  booktitle={2024 IEEE 32nd International Requirements Engineering Conference Workshops (REW)}, 
  title={Scattered Requirements Dust in the Era of Web3 – a Vision Keynote}, 
  year={2024},
  volume={},
  number={},
  pages={328-329},
  abstract={This extended abstract paper presents a vision for data and AI requirements governance in distributed System-of-Systems (SoS) that involve multiple parties and dynamic alliances, such as in the defense domain (e.g. different weapon systems on the battlefield). The paper proposes to use web3 technologies, such as distributed ledger and secure multi-party computation, to enable collaborative analytics and data interoperability among the SoS members, while preserving their sovereignty and privacy. The paper also suggests a model-driven approach that can generate executable code and workflows from a common ontology and a semantic mapping tool, which can facilitate the alignment and verification of the data and AI requirements among the coalition members. The paper demonstrates the feasibility and effectiveness of the approach through a prototype implementation in the defense domain and a case study involving a multi-party coalition of the willing to detect a SA-8 anti-aircraft battery that in essence is a sensor-Data Fusion with different sensors on different weapon systems.},
  keywords={Weapons;Semantics;Distributed databases;Prototypes;Sensor fusion;Ontologies;Sensor systems;Generative AI;Distributed Requirements Integrity;DataGPT;Ontology driven integration},
  doi={10.1109/REW61692.2024.00050},
  ISSN={2770-6834},
  month={June},}@INPROCEEDINGS{9874473,
  author={Miller, Kurt},
  booktitle={2022 IEEE 10th International Conference on Healthcare Informatics (ICHI)}, 
  title={Comprehension of Contextual Semantics Across Clinical Healthcare Domains}, 
  year={2022},
  volume={},
  number={},
  pages={479-480},
  abstract={The widespread lack of adoption of clinical notetaking standards has rendered information retrieval from Electronic Health Records (EHRs) especially challenging using traditional Natural Language Processing (NLP) techniques. Clinical note authors too commonly adopt their own note-taking structures and styles, limiting the applicability of rule-based and statistical models. While the context of any given sentence within a note carries important implied information, context is notoriously difficult for a language model to infer. However, recent advances in deep learning NLP methods such as pre-training on domain-specific corpora, novel embedding structures, and transformer architectures have enabled an awareness of context not previously attainable. In this work, I study the application of these evidenced NLP approaches to a gold standard annotated corpus of primary care notes of multiple Mayo Clinic EHR systems. The strongly labelled data will be supplemented with large volumes of weakly labelled data curated using distant supervision. The combined dataset will be used to train and evaluate context classification and section boundary detection models that classify the current context of a sentence given adjacent text segments. Once validated against primary care corpora, transfer learning methods will enable access to shared knowledge across more specific clinical domains, enabling generalizability across clinical domains and a degree of transparency into the shared aspects of the integrated model.},
  keywords={Limiting;Transfer learning;Semantics;Medical services;Transformers;Information retrieval;Natural language processing;natural language processing;electronic health records;knowledge graph;transformer architectures},
  doi={10.1109/ICHI54592.2022.00077},
  ISSN={2575-2634},
  month={June},}@INPROCEEDINGS{10684661,
  author={Bo, Lili and He, Yuting and Sun, Xiaobing and Ji, Wangjie and Wu, Xiaohan},
  booktitle={2024 IEEE 24th International Conference on Software Quality, Reliability and Security (QRS)}, 
  title={A Software Bug Fixing Approach Based on Knowledge-Enhanced Large Language Models}, 
  year={2024},
  volume={},
  number={},
  pages={169-179},
  abstract={Software Bug Fixing is a time-consuming task in software development and maintenance. Despite the success of Large Language Models (LLMs) using in Automatic Program Repair (APR), they still have the limitations of generating patches with low accuracy and explainability. In this paper, we propose a software bug-fixing approach based on knowledge-enhanced large language models. First, we collect bugs as well as their fix information from bug tracking systems, such as Github and Stack Overflow. Then, we extract bug entities and inter-entity relationships using Named Entity Recognition (NER) to construct a Bug Knowledge Graph (BKG). Finally, we utilize LLMs (e.g., GPT-4) which is enhanced by the knowledge of the similar historical bugs as well as fix information from BKG to generate patches for new bugs. The experimental results show that the our approach can fix 28.52% (85\298) bugs correctly, which is significantly better than the state-of-the-art approaches. Furthermore, the generated patches are explainable and more credible.},
  keywords={Codes;Accuracy;Large language models;Computer bugs;Knowledge graphs;Maintenance engineering;Software;Bug fixing;Knowledge Graph;Generative AI;Explainable},
  doi={10.1109/QRS62785.2024.00026},
  ISSN={2693-9177},
  month={July},}@INPROCEEDINGS{10350471,
  author={Chen, Boqi and Yi, Fandi and Varró, Dániel},
  booktitle={2023 ACM/IEEE International Conference on Model Driven Engineering Languages and Systems Companion (MODELS-C)}, 
  title={Prompting or Fine-tuning? A Comparative Study of Large Language Models for Taxonomy Construction}, 
  year={2023},
  volume={},
  number={},
  pages={588-596},
  abstract={Taxonomies represent hierarchical relations between entities, frequently applied in various software modeling and natural language processing (NLP) activities. They are typically subject to a set of structural constraints restricting their content. However, manual taxonomy construction can be time-consuming, incomplete, and costly to maintain. Recent studies of large language models (LLMs) have demonstrated that appropriate user inputs (called prompting) can effectively guide LLMs, such as GPT-3, in diverse NLP tasks without explicit (re-)training. However, existing approaches for automated taxonomy construction typically involve fine-tuning a language model by adjusting model parameters. In this paper, we present a general framework for taxonomy construction that takes into account structural constraints. We subsequently conduct a systematic comparison between the prompting and fine-tuning approaches performed on a hypernym taxonomy and a novel computer science taxonomy dataset. Our result reveals the following: (1) Even without explicit training on the dataset, the prompting approach outperforms fine-tuning-based approaches. Moreover, the performance gap between prompting and fine-tuning widens when the training dataset is small. However, (2) taxonomies generated by the fine-tuning approach can be easily post-processed to satisfy all the constraints, whereas handling violations of the taxonomies produced by the prompting approach can be challenging. These evaluation findings provide guidance on selecting the appropriate method for taxonomy construction and highlight potential enhancements for both approaches.},
  keywords={Training;Computer science;Systematics;Computational modeling;Taxonomy;Ontologies;Software;taxonomy construction;domain-specific constraints;large language models;few-shot learning;fine-tuning},
  doi={10.1109/MODELS-C59198.2023.00097},
  ISSN={},
  month={Oct},}@INPROCEEDINGS{8653655,
  author={Rajasekar, M. and Udhayakumar, A.},
  booktitle={2018 2nd International Conference on I-SMAC (IoT in Social, Mobile, Analytics and Cloud) (I-SMAC)I-SMAC (IoT in Social, Mobile, Analytics and Cloud) (I-SMAC), 2018 2nd International Conference on}, 
  title={"E MARUTHUVACHI" – INFORMATION EXTRACTION FRAMEWORK FOR DATA ABOUT OBSTETRICS AND GYNECOLOGY IN TAMIL}, 
  year={2018},
  volume={},
  number={},
  pages={399-407},
  abstract={Technology is transforming the world from traditional into Artificial Intelligence. Human beings are adopting themselves into the change using Technology. India is famous for the name of unique traditional culture. The traditional culture protected people to do useful things. Especially for women, they were protected by the traditional culture to gain knowledge about maternity and gynecology. The target framework to extract the useful information from the raw documents. The extraction process extracts the NLP elements from the raw documents. The framework is developed using modified model of neural network language model (NNLM). The proposed model is evaluated with F-Test. The evaluation produces the good result for accuracy.},
  keywords={Computational modeling;Neural networks;Task analysis;Data mining;Taxonomy;Gynecology;Artificial Intelligence;Information Extraction;Obstetrics and Gynecology;Neural Networks;Neural Network Language Model},
  doi={10.1109/I-SMAC.2018.8653655},
  ISSN={},
  month={Aug},}@ARTICLE{9335254,
  author={Balaraman, Vevake and Magnini, Bernardo},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing}, 
  title={Domain-Aware Dialogue State Tracker for Multi-Domain Dialogue Systems}, 
  year={2021},
  volume={29},
  number={},
  pages={866-873},
  abstract={In task-oriented dialogue systems the dialogue state tracker component (DST) is responsible for predicting the current state of the dialogue based on the dialogue history and the user utterance. Current DST approaches rely on a predefined domain ontology, a fact that limits their effective usage for large scale conversational agents, where the DST constantly needs to be interfaced with ever-increasing services and APIs. Focused towards overcoming this drawback, we propose a domain-aware dialogue state tracker, that is completely data-driven and it is modeled to predict for dynamic service schemas, including zero-shot domains. Unlike approaches that propose separate models for prediction of intents, requested slots, slot status, categorical slots and non-categorical slots, we propose a single model in an end-to-end architecture. The proposed model utilizes domain and slot information to extract both domain and slot specific representations from a given dialogue, and then uses such representations to predict the values of the corresponding slot in a given domain. Integrating this mechanism with pretrained language models, our approach can effectively learn semantic relations and effectively perform transfer learning between domains or zero-shot tracking for domains not present in training.},
  keywords={Predictive models;Bit error rate;Task analysis;Ontologies;Virtual assistants;Semantics;Training data;Dialogue state tracking;multi-domain dialogue systems;zero-shot tracking;end-to-end},
  doi={10.1109/TASLP.2021.3054309},
  ISSN={2329-9304},
  month={},}@INPROCEEDINGS{10538949,
  author={Kong, Luyue and Zhang, Shu and Li, Jinbao and Liu, Song},
  booktitle={2023 IEEE 22nd International Conference on Trust, Security and Privacy in Computing and Communications (TrustCom)}, 
  title={An Instruction Inference Graph Optimal Transport Network Model For Biomedical Commonsense Question Answering}, 
  year={2023},
  volume={},
  number={},
  pages={2749-2754},
  abstract={Biomedical commonsense question answering is a challenging learning task that aims to give correct answers to biomedical commonsense questions. Many works have used rule-based or deep learning approachs to accomplish this task. Recently, an extensive research path is that pre-trained language models combined with graph neural networks (GNNs) to improve the accuracy of biomedical commonsense question answering. However, GNN is prone to the over-smoothing problem, causing the models to lose the ability to reason. In order to alleviate the over-smoothing problem and improve the inference ability for biomedical commonsense question answering, we propose a new end-to-end model named BiomGIN. In BiomGIN, we introduce the Graph Optimal Transport Networks (GOTNet) to use node-centroid attention to capture non-local messages in the knowledge graph, which alleviates the model over-smoothing problem. In addition, we design a question parsing module based on Transformer to generate linguistic instructions, which enhances the inference capability of the GNN. Finally, we evaluated our model on MedQA-USMLE dataset to compare with other baseline models. The experimental results demonstrate the method proposed in this paper achieves state-of-the-art results.},
  keywords={Privacy;Biological system modeling;Computational modeling;Message passing;Linguistics;Transformers;Question answering (information retrieval);Biomedical Commonsense Question Answering;Large Pre-trained Language Model;Graph Neural Network;Knowledge Graph;Graph Optimal Transport Network;Question Parsing},
  doi={10.1109/TrustCom60117.2023.00383},
  ISSN={2324-9013},
  month={Nov},}@INPROCEEDINGS{10674574,
  author={Su, Yi-Jen and Wu, Cheng-Wei and Chen, Yi-Ju},
  booktitle={2024 6th International Conference on Computer Communication and the Internet (ICCCI)}, 
  title={Enhancing KBQA Performance in Large-Scale Chinese Knowledge Graphs Using Apache Spark}, 
  year={2024},
  volume={},
  number={},
  pages={181-186},
  abstract={Knowledge graph (KG) is a kind of fundamental technologies in the development of knowledge base question answering (KBQA) systems, primarily designed to assist in rapidly retrieving accurate information from massive knowledge repositories. Due to the content of knowledge bases continues to expand, the search performance of KBQA systems has become a crucial research topic. This study focuses on enhancing the query efficiency of KBQA systems by increasing the throughput of system queries through a distributed computing framework based on Apache Spark. The main research achievements of this study include optimizing the performance of Chinese KBQA systems using Apache Spark's distributed computing architecture, improving the efficiency of question-answering services, enhancing the accuracy of semantic similarity models to gain a deeper understanding of natural language semantics, and increasing the accuracy and reliability of similarity matching. Under the evaluation method of exact matching, the accuracy of knowledge base queries can reach 90.5%.},
  keywords={Accuracy;Systematics;Computational modeling;Knowledge based systems;Semantics;Cluster computing;Knowledge graphs;knowledge base question answering;knowledge graph;BERT},
  doi={10.1109/ICCCI62159.2024.10674574},
  ISSN={2833-2350},
  month={June},}@INPROCEEDINGS{10544639,
  author={S, Stewart Kirubakaran and G, Jasper Wilsie Kathrine and E, Grace Mary Kanaga and J, Mahimai Raja and Singh A, Ruban Gino and E, Yuvaraajan},
  booktitle={2024 International Conference on Inventive Computation Technologies (ICICT)}, 
  title={A RAG-based Medical Assistant Especially for Infectious Diseases}, 
  year={2024},
  volume={},
  number={},
  pages={1128-1133},
  abstract={Infectious diseases like COVID-19 have gained international attention recently. Furthermore, there are significantly fewer doctors per capita in densely populated nations like India, which hurts those in need. Under such circumstances, natural language processing techniques might make it feasible to create an intelligent and engaging chatbot system. The primary objective of the effort is to develop an interactive solution that is entirely open source and can be easily installed on a local computer using the most recent data. Even though there are numerous chatbots on the market, proposed solutions highlight the need to provide individualized and sympathetic responses. Getting Back While the data is stored in the graph database as nodes and relationships, and the knowledge graph is constructed on top of it, augmented generation is utilized to extract the pertinent content from the data. To improve the generator’s context, pertinent sections are collected during the question-answering process. This reduces hallucinations and increases the correctness of abstractions by providing external knowledge streams. Furthermore, the research study employs a text-to-speech model that was replicated from a physician’s voice recording to narrate the produced responses, thereby augmenting user confidence and interaction. Academic institutions and healthcare organizations can benefit from this work by better understanding the value and effectiveness of applying NLP techniques to infectious disease research.},
  keywords={COVID-19;Infectious diseases;Databases;Chatbots;Recording;Reliability;Artificial intelligence;natural language processing;chatbot;COVID-19;large language model;retrieval augmented generation;knowledge graph},
  doi={10.1109/ICICT60155.2024.10544639},
  ISSN={2767-7788},
  month={April},}

@article{10.1145/3641850,
author = {Bi, Zhen and Chen, Jing and Jiang, Yinuo and Xiong, Feiyu and Guo, Wei and Chen, Huajun and Zhang, Ningyu},
title = {CodeKGC: Code Language Model for Generative Knowledge Graph Construction},
year = {2024},
issue_date = {March 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {3},
issn = {2375-4699},
url = {https://doi.org/10.1145/3641850},
doi = {10.1145/3641850},
abstract = {Current generative knowledge graph construction approaches usually fail to capture structural knowledge by simply flattening natural language into serialized texts or a specification language. However, large generative language model trained on structured data such as code has demonstrated impressive capability in understanding natural language for structural prediction and reasoning tasks. Intuitively, we address the task of generative knowledge graph construction with code language model: given a code-format natural language input, the target is to generate triples which can be represented as code completion tasks. Specifically, we develop schema-aware prompts that effectively utilize the semantic structure within the knowledge graph. As code inherently possesses structure, such as class and function definitions, it serves as a useful model for prior semantic structural knowledge. Furthermore, we employ a rationale-enhanced generation method to boost the performance. Rationales provide intermediate steps, thereby improving knowledge extraction abilities. Experimental results indicate that the proposed approach can obtain better performance on benchmark datasets compared with baselines.1},
journal = {ACM Trans. Asian Low-Resour. Lang. Inf. Process.},
month = mar,
articleno = {45},
numpages = {16},
keywords = {Knowledge graph construction, code, language model}
}

@inproceedings{10.1145/3640457.3691703,
author = {Balloccu, Giacomo and Boratto, Ludovico and Fenu, Gianni and Marras, Mirko and Soccol, Alessandro},
title = {KGGLM: A Generative Language Model for Generalizable Knowledge Graph Representation Learning in Recommendation},
year = {2024},
isbn = {9798400705052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3640457.3691703},
doi = {10.1145/3640457.3691703},
abstract = {Current recommendation methods based on knowledge graphs rely on entity and relation representations for several steps along the pipeline, with knowledge completion and path reasoning being the most influential. Despite their similarities, the most effective representation methods for these steps differ, leading to inefficiencies, limited representativeness, and reduced interpretability. In this paper, we introduce KGGLM, a decoder-only Transformer model designed for generalizable knowledge representation learning to support recommendation. The model is trained on generic paths sampled from the knowledge graph to capture foundational patterns, and then fine-tuned on paths specific of the downstream step (knowledge completion and path reasoning in our case). Experiments on ML1M and LFM1M show that KGGLM beats twenty-two baselines in effectiveness under both knowledge completion and recommendation. Source code and pre-processed data sets are available at https://github.com/mirkomarras/kgglm.},
booktitle = {Proceedings of the 18th ACM Conference on Recommender Systems},
pages = {1079–1084},
numpages = {6},
keywords = {Generative Artificial Intelligence., Knowledge Completion, Knowledge Graph, Knowledge Graph Embeddings, Knowledge Representation Learning, Language Model, Recommendation},
location = {Bari, Italy},
series = {RecSys '24}
}

@inproceedings{10.1145/3597503.3639157,
author = {Su, Yanqi and Liao, Dianshu and Xing, Zhenchang and Huang, Qing and Xie, Mulong and Lu, Qinghua and Xu, Xiwei},
title = {Enhancing Exploratory Testing by Large Language Model and Knowledge Graph},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597503.3639157},
doi = {10.1145/3597503.3639157},
abstract = {Exploratory testing leverages the tester's knowledge and creativity to design test cases for effectively uncovering system-level bugs from the end user's perspective. Researchers have worked on test scenario generation to support exploratory testing based on a system knowledge graph, enriched with scenario and oracle knowledge from bug reports. Nevertheless, the adoption of this approach is hindered by difficulties in handling bug reports of inconsistent quality and varied expression styles, along with the infeasibility of the generated test scenarios. To overcome these limitations, we utilize the superior natural language understanding (NLU) capabilities of Large Language Models (LLMs) to construct a System KG of User Tasks and Failures (SysKG-UTF). Leveraging the system and bug knowledge from the KG, along with the logical reasoning capabilities of LLMs, we generate test scenarios with high feasibility and coherence. Particularly, we design chain-of-thought (CoT) reasoning to extract human-like knowledge and logical reasoning from LLMs, simulating a developer's process of validating test scenario feasibility. Our evaluation shows that our approach significantly enhances the KG construction, particularly for bug reports with low quality. Furthermore, our approach generates test scenarios with high feasibility and coherence. The user study further proves the effectiveness of our generated test scenarios in supporting exploratory testing. Specifically, 8 participants find 36 bugs from 8 seed bugs in two hours using our test scenarios, a significant improvement over the 21 bugs found by the state-of-the-art baseline.},
booktitle = {Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
articleno = {98},
numpages = {12},
keywords = {exploratory testing, knowledge graph, AI chain, prompt engineering},
location = {Lisbon, Portugal},
series = {ICSE '24}
}

@inproceedings{10.1145/3637528.3672503,
author = {Wang, Haixun},
title = {Generative AI in E-Commerce: What Can We Expect?},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3672503},
doi = {10.1145/3637528.3672503},
abstract = {The impact of generative AI on e-commerce is profound. It has significantly improved the understanding of user intent and serves as a comprehensive product knowledge graph. However, the most substantial disruptions are yet to come, partic- ularly through the rise of autonomous agents. In this talk, I will outline a tentative path toward a future where e-commerce not only offers an unparalleled customer experience but also thrives in a world dominated by generative AI and autonomous agents.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {4739–4740},
numpages = {2},
keywords = {e-commerce, generative ai, information retrieval, large language models},
location = {Barcelona, Spain},
series = {KDD '24}
}

@inproceedings{10.1145/3627673.3679087,
author = {Mane, Mansi Ranjit and Gligorijevic, Djordje and Wang, Dingxian and Shahrasbi, Behzed and Biswas, Topojoy and Korpeoglu, Evren and Savvides, Marios},
title = {Workshop on Generative AI for E-commerce},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679087},
doi = {10.1145/3627673.3679087},
abstract = {The "Gen AI for E-commerce" workshop explores the role of Generative Artificial Intelligence in transforming e-commerce through enhanced user experience and operational efficiency. E-commerce companies grapple with multiple challenges such as lack of quality content for products, subpar user experience, sparse datasets etc. Gen AI offers significant potential to address these complexities. Yet, deploying these technologies at scale presents challenges such as hallucination in data, excessive costs, increased latency response, and limited generalization in sparse data environments. This workshop will bring together experts from academia and industry to discuss these challenges and opportunities, aiming to showcase case studies, breakthroughs, and insights into practical implementations of Gen AI in e-commerce.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {5592–5595},
numpages = {4},
keywords = {LLMs, e-commerce, generative AI},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@inproceedings{10.1145/3664647.3681327,
author = {Zhang, Yichi and Chen, Zhuo and Guo, Lingbing and Xu, Yajing and Zhang, Wen and Chen, Huajun},
title = {Making Large Language Models Perform Better in Knowledge Graph Completion},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3681327},
doi = {10.1145/3664647.3681327},
abstract = {Large language model (LLM) based knowledge graph completion (KGC) aims to predict the missing triples in the KGs with LLMs. However, research about LLM-based KGC fails to sufficiently harness LLMs' inference proficiencies, overlooking critical structural information integral to KGs. In this paper, we explore methods to incorporate structural information into the LLMs, with the overarching goal of facilitating structure-aware reasoning. We first discuss on the existing LLM paradigms like in-context learning and instruction tuning, proposing basic structural information injection approaches. Then we propose a Knowledge Prefix Adapter (KoPA) to fulfill this stated goal. KoPA uses a structural pre-training phase to comprehend the intricate entities and relations within KGs, representing them as structural embeddings. Then KoPA communicates such cross-modal structural information understanding to the LLMs through a knowledge prefix adapter which projects the structural embeddings into the textual space and obtains virtual knowledge tokens positioned as a prefix of the input prompt. We conduct comprehensive experiments and provide incisive analysis. Our code and data are available at https://github.com/zjukg/KoPA.},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {233–242},
numpages = {10},
keywords = {cross-modal adapter, graph-text fusion, knowledge graph completion, knowledge graphs, large language models},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@inproceedings{10.1145/3637528.3671542,
author = {Baughman, Aaron and Morales, Eduardo and Agarwal, Rahul and Akay, Gozde and Feris, Rogerio and Johnson, Tony and Hammer, Stephen and Karlinsky, Leonid},
title = {Large Scale Generative AI Text Applied to Sports and Music},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671542},
doi = {10.1145/3637528.3671542},
abstract = {We address the problem of scaling up the production of media content, including commentary and personalized news stories, for large-scale sports and music events worldwide. Our approach relies on generative AI models to transform a large volume of multimodal data (e.g., videos, articles, real-time scoring feeds, statistics, and fact sheets) into coherent and fluent text. Based on this approach, we introduce, for the first time, an AI commentary system, which was deployed to produce automated narrations for highlight packages at the 2023 US Open, Wimbledon, and Masters tournaments. In the same vein, our solution was extended to create personalized content for ESPN Fantasy Football and stories about music artists for the GRAMMY awards. These applications were built using a common software architecture achieved a 15x speed improvement with an average Rouge-L of 82.00 and perplexity of 6.6. Our work was successfully deployed at the aforementioned events, supporting 90 million fans around the world with 8 billion page views, continuously pushing the bounds on what is possible at the intersection of sports, entertainment, and AI.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {4784–4792},
numpages = {9},
keywords = {applied computing, generative ai, large scale computing, neural networks, sports and entertainment},
location = {Barcelona, Spain},
series = {KDD '24}
}

@article{10.1145/3644820,
author = {Yuan, Xiaowei and Liu, Kang and Wang, Yequan},
title = {Contrastive Language-knowledge Graph Pre-training},
year = {2024},
issue_date = {April 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {4},
issn = {2375-4699},
url = {https://doi.org/10.1145/3644820},
doi = {10.1145/3644820},
abstract = {Recent years have witnessed a surge of academic interest in knowledge-enhanced pre-trained language models (PLMs) that incorporate factual knowledge to enhance knowledge-driven applications. Nevertheless, existing studies primarily focus on shallow, static, and separately pre-trained entity embeddings, with few delving into the potential of deep contextualized knowledge representation for knowledge incorporation. Consequently, the performance gains of such models remain limited. In this article, we introduce a simple yet effective knowledge-enhanced model, College (Contrastive Language-Knowledge Graph Pre-training), which leverages contrastive learning to incorporate factual knowledge into PLMs. This approach maintains the knowledge in its original graph structure to provide the most available information and circumvents the issue of heterogeneous embedding fusion. Experimental results demonstrate that our approach achieves more effective results on several knowledge-intensive tasks compared to previous state-of-the-art methods. Our code and trained models are available at .},
journal = {ACM Trans. Asian Low-Resour. Lang. Inf. Process.},
month = apr,
articleno = {51},
numpages = {21},
keywords = {Language Model, Knowledge Graph, Contrastive Learning}
}

@article{10.1145/3686803,
author = {Li, Jialong and Zhang, Mingyue and Li, Nianyu and Weyns, Danny and Jin, Zhi and Tei, Kenji},
title = {Generative AI for Self-Adaptive Systems: State of the Art and Research Roadmap},
year = {2024},
issue_date = {September 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {19},
number = {3},
issn = {1556-4665},
url = {https://doi.org/10.1145/3686803},
doi = {10.1145/3686803},
abstract = {Self-adaptive systems (SASs) are designed to handle changes and uncertainties through a feedback loop with four core functionalities: monitoring, analyzing, planning, and execution. Recently, generative artificial intelligence (GenAI), especially the area of large language models, has shown impressive performance in data comprehension and logical reasoning. These capabilities are highly aligned with the functionalities required in SASs, suggesting a strong potential to employ GenAI to enhance SASs. However, the specific benefits and challenges of employing GenAI in SASs remain unclear. Yet, providing a comprehensive understanding of these benefits and challenges is complex due to several reasons: limited publications in the SAS field, the technological and application diversity within SASs, and the rapid evolution of GenAI technologies. To that end, this article aims to provide researchers and practitioners a comprehensive snapshot that outlines the potential benefits and challenges of employing GenAI’s within SAS. Specifically, we gather, filter, and analyze literature from four distinct research fields and organize them into two main categories to potential benefits: (i) enhancements to the autonomy of SASs centered around the specific functions of the MAPE-K feedback loop, and (ii) improvements in the interaction between humans and SASs within human-on-the-loop settings. From our study, we outline a research roadmap that highlights the challenges of integrating GenAI into SASs. The roadmap starts with outlining key research challenges that need to be tackled to exploit the potential for applying GenAI in the field of SAS. The roadmap concludes with a practical reflection, elaborating on current shortcomings of GenAI and proposing possible mitigation strategies.†},
journal = {ACM Trans. Auton. Adapt. Syst.},
month = sep,
articleno = {13},
numpages = {60},
keywords = {Self-Adaptive Systems, MAPE, Generative AI, Large Language Model, diffusion model, survey}
}

@inproceedings{10.1145/3639631.3639689,
author = {Qian, Jing and Li, Gangmin and Atkinson, Katie and Yue, Yong},
title = {Enhancing Text Comprehension via Fusing Pre-trained Language Model with Knowledge Graph},
year = {2024},
isbn = {9798400709203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639631.3639689},
doi = {10.1145/3639631.3639689},
abstract = {Pre-trained language models (PLMs) such as BERT and GPTs capture rich linguistic and syntactic knowledge from pre-training over large-scale text corpora, which can be further fine-tuned for specific downstream tasks. However, these models still have limitations as they rely on knowledge gained from plain text and ignore structured knowledge such as knowledge graphs (KGs). Recently, there has been a growing trend of explicitly integrating KGs into PLMs to improve their performance. For instance, K-BERT incorporates KG triples as domain-specific supplements into input sentences. Nevertheless, we have observed that such methods do not consider the semantic relevance between the introduced knowledge and the original input sentence, leading to the issue of knowledge impurities. To address this issue, we propose a semantic matching-based approach that enriches the input text with knowledge extracted from an external KG. The architecture of our model comprises three components: the knowledge retriever (KR), the knowledge injector (KI), and the knowledge aggregator (KA). The KR, built upon the sentence representation learning model (i.e. CoSENT), retrieves triples with high semantic relevance to the input sentence from an external KG to alleviate the issue of knowledge impurities. The KI then integrates the retrieved triples from the KR into the input text by converting the original sentence into a knowledge tree with multiple branches, the knowledge tree is transformed into an accessible sequence of text that can be fed into the KA. Finally, the KA takes the flattened knowledge tree and passes it through an embedding layer and a masked Transformer encoder. We conducted extensive evaluations on eight datasets covering five text comprehension tasks, and the experimental results demonstrate that our approach exhibits competitive advantages over popular knowledge-enhanced PLMs such as K-BERT and ERNIE.},
booktitle = {Proceedings of the 2023 6th International Conference on Algorithms, Computing and Artificial Intelligence},
pages = {353–360},
numpages = {8},
keywords = {knowledge graphs, natural language understanding, sentence representation learning},
location = {Sanya, China},
series = {ACAI '23}
}

@article{10.1145/3708478,
author = {Meng, Zhixin and Zhan, Shaoxiong and Xu, Ruiqing and Mayer, Wolfgang and Zhu, Ye and Zhang, Hong-Yu and He, Chuan and He, Keqing and Cheng, Debo and Feng, Zaiwen},
title = {Domain Ontology-Driven Knowledge Graph Generation from Text},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3708478},
doi = {10.1145/3708478},
abstract = {A knowledge graph serves as a unified and standardized representation for extracting and representing textual information. In the field of knowledge extraction and representation research, named entity recognition and relation extraction provide effective solutions for knowledge graph generation tasks. However, it is a challenge that lies in extracting domain-specific knowledge from the rich and general textual corpora and generating corresponding domain knowledge graphs to support domain-specific reasoning, question-answering, and decision-making tasks. The hierarchical domain knowledge representation model (i.e. domain ontology) provides a solution for this problem. Therefore, we propose an end-to-end approach based on domain ontology embedding and pre-trained language models for domain knowledge graph generation from text, which incorporates domain node recognition and domain relation extraction phases. We evaluated our domain ontology-driven model on the Wikidata-TekGen dataset and the DBpedia-WebNLG dataset, and the results indicate that our approach based on the pre-trained language models with fewer parameters compared with the baseline models has significantly contributed to the domain knowledge graph generation without prompts.},
note = {Just Accepted},
journal = {ACM Trans. Probab. Mach. Learn.},
month = dec,
keywords = {Domain Knowledge Graph, Domain Ontology, Ontology Embedding, Domain Node Recognition, Domain Relation Extraction}
}

@article{10.1145/3688850,
author = {Yang, Guangqian and Zhang, Lei and Liu, Yi and Xie, Hongtao and Mao, Zhendong},
title = {Exploiting Pre-Trained Language Models for Black-Box Attack against Knowledge Graph Embeddings},
year = {2024},
issue_date = {January 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {19},
number = {1},
issn = {1556-4681},
url = {https://doi.org/10.1145/3688850},
doi = {10.1145/3688850},
abstract = {Despite the emerging research on adversarial attacks against knowledge graph embedding (KGE) models, most of them focus on white-box attack settings. However, white-box attacks are difficult to apply in practice compared to black-box attacks since they require access to model parameters that are unlikely to be provided. In this article, we propose a novel black-box attack method that only requires access to knowledge graph data, making it more realistic in real-world attack scenarios. Specifically, we utilize pre-trained language models (PLMs) to encode text features of the knowledge graphs, an aspect neglected by previous research. We then employ these encoded text features to identify the most influential triples for constructing corrupted triples for the attack. To improve the transferability of the attack, we further propose to fine-tune the PLM model by enriching triple embeddings with structure information. Extensive experiments conducted on two knowledge graph datasets illustrate the effectiveness of our proposed method.},
journal = {ACM Trans. Knowl. Discov. Data},
month = nov,
articleno = {1},
numpages = {14},
keywords = {Knowledge Graph, Adversarial Attack, Language Model}
}

@inproceedings{10.1145/3650400.3650526,
author = {Li, Wenqing and Qi, Xiaoman and Zhao, Qi and Wang, Chen and Wu, Qiongyu and Tang, Xue-song},
title = {Knowledge Graph-Based Credibility Evaluation Method for Electric Grid Large Language Model Knowledge Question-Answering},
year = {2024},
isbn = {9798400708305},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3650400.3650526},
doi = {10.1145/3650400.3650526},
abstract = {In the field of electricity, specialized terminology is often intricate and complex, making it challenging for non-experts to comprehend. However, with the advancement of artificial intelligence technology, the emergence of large language models provides a new technological solution to address this issue. Large language models, based on deep learning techniques, have the capability to quickly understand and interpret specialized terminology in the electricity domain through learning from a vast corpus of professional literature and data. They can then be applied to various domains, including question-answering systems. However, existing large language models still face issues of unreliable outputs, necessitating a method to evaluate their results and improve the quality of their applications. We propose a knowledge graph-based credibility evaluation method for electric grid large language model knowledge question-answering. This method aligns the answers generated by large language models with the knowledge graph of a local knowledge base and calculates their cosine similarity and Pearson correlation coefficient. We batch-process the answers from the large language model into an electricity dataset and validate them using this method. Experimental results demonstrate that this method can accurately and efficiently reflect the relevance between texts, providing a reliable scoring basis for question-answering by large models in vertical domains. Future research can focus on exploring other embedding methods that can better extract semantic relationships between texts and validating the feasibility of this method in vertical domains other than electricity.},
booktitle = {Proceedings of the 2023 7th International Conference on Electronic Information Technology and Computer Engineering},
pages = {754–759},
numpages = {6},
location = {Xiamen, China},
series = {EITCE '23}
}

@inproceedings{10.1145/3695719.3695726,
author = {Payne, Lucas and Xie, Mengjun},
title = {Log File Anomaly Detection Using Knowledge Graph Completion},
year = {2024},
isbn = {9798400716867},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3695719.3695726},
doi = {10.1145/3695719.3695726},
abstract = {Log files can be vital in detecting anomalous behavior in a computing system. However, the largely unstructured format of log files makes it difficult for computers to process them, and their large volume makes it infeasible for large-scale manual analysis. Previous research has suggested converting log messages into knowledge graph data for querying but does not consider anomaly detection as the downstream task. Other research has suggested using knowledge graph completion for anomaly detection, but it does not include the conversion of log messages to log data. This study fills in the gaps by presenting an end-to-end system that generates knowledge graph data from log messages and applies the knowledge graph completion task to binary classification for anomaly detection. Results are reported using both knowledge graph completion and classification metrics, and they demonstrate the feasibility of the proposed method.},
booktitle = {Proceedings of the 2024 8th International Conference on Deep Learning Technologies},
pages = {42–48},
numpages = {7},
keywords = {anomaly detection, knowledge graph, knowledge graph completion, link prediction, log file},
location = {
},
series = {ICDLT '24}
}

@inproceedings{10.1145/3627673.3680266,
author = {Ni, Bo},
title = {Reliable Knowledge Graph Reasoning with Uncertainty Quantification},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3680266},
doi = {10.1145/3627673.3680266},
abstract = {Recently, Knowledge Graphs (KGs) have been successfully coupled with Large Language Models (LLMs) to mitigate their hallucinations and enhance their reasoning capability, e.g., KG-based retrieval-augmented framework for question-answering. However, current KG-LLM frameworks lack rigorous uncertainty estimation, limiting their reliable deployment in high-stake applications where the cost of errors is significant. To address this crucial gap, we propose a new trustworthy KG-LLM framework, UaG(&lt;u&gt;U&lt;/u&gt;ncertainty &lt;u&gt;A&lt;/u&gt;ware &lt;u&gt;G&lt;/u&gt;raph Reasoning), which incorporates uncertainty quantification into the KG-LLM framework. We design an uncertainty-aware multi-step reasoning framework that leverages conformal prediction to provide a theoretical guarantee on the prediction set. To manage the error rate of the multi-step process, we additionally introduce an error rate control module to adjust the error rate within the individual components. Our preliminary results demonstrate that UaG can achieve the desired theoretical coverage while maintaining a reasonable prediction set size.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {5463–5466},
numpages = {4},
keywords = {knowledge graph, question answering, trustworthy AI, uncertainty quantification},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@article{10.1145/3677524,
author = {Cao, Yukun and Jin, Chengkun and Tang, Yijia and Wei, ZiYue},
title = {Word Sense Disambiguation Combining Knowledge Graph and Text Hierarchical Structure},
year = {2024},
issue_date = {December 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {12},
issn = {2375-4699},
url = {https://doi.org/10.1145/3677524},
doi = {10.1145/3677524},
abstract = {Current supervised word sense disambiguation models have obtained high disambiguation results using annotated information of different word senses and pre-trained language models. However, the semantic data of the supervised word sense disambiguation models are in the form of short texts, and much of the corpus information is not rich enough to distinguish the semantics in different scenarios. This article proposes a bi-encoder word sense disambiguation method combining a knowledge graph and text hierarchy structure, by introducing structured knowledge from the knowledge graph to supplement more extended semantic information, using the hierarchy of contextual input text to describe the meaning of words and phrases, and constructing a BERT-based bi-encoder, introducing a graph attention network to reduce the noise information in the contextual input text, so as to improve the disambiguation accuracy of the target words in phrase form and ultimately improve the disambiguation effectiveness of the method. By comparing the method with the latest nine comparison algorithms in five test datasets, the disambiguation accuracy of the method mostly outperformed the comparison algorithms and achieved better results.},
journal = {ACM Trans. Asian Low-Resour. Lang. Inf. Process.},
month = nov,
articleno = {161},
numpages = {16},
keywords = {Word sense disambiguation, knowledge graph, BERT, graph attention network}
}

@inproceedings{10.1145/3700906.3700925,
author = {Liu, Tongtong},
title = {Multi-modal Knowledge Graph Completion: A Survey},
year = {2024},
isbn = {9798400707032},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3700906.3700925},
doi = {10.1145/3700906.3700925},
abstract = {In recent years, with the rapid development of artificial intelligence, multi-modal knowledge graph completion (MMKGC) has become increasingly important. Many scholars have conducted in-depth research on multi-modal knowledge graphs (MMKGs), leading to the proposal of numerous MMKGC models. Summarizing the current state of research is crucial for guiding future studies. This survey aims to review the current advanced techniques for MMKGC. By analyzing and elaborating on the value and categories of MMKGs in detail, we summarize the challenges faced by existing MMKGC methods. Our work provides valuable insights and explorations for the research and application of completing MMKGs.},
booktitle = {Proceedings of the International Conference on Image Processing, Machine Learning and Pattern Recognition},
pages = {116–121},
numpages = {6},
keywords = {Explainable Artificial Intelligence, Few-shot Learning, Multi-modal Knowledge Graph Completion},
location = {
},
series = {IPMLP '24}
}

@article{10.1145/3686806,
author = {Cheng, Kewei and Ahmed, Nesreen K. and Rossi, Ryan A. and Willke, Theodore and Sun, Yizhou},
title = {Neural-Symbolic Methods for Knowledge Graph Reasoning: A Survey},
year = {2024},
issue_date = {November 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {9},
issn = {1556-4681},
url = {https://doi.org/10.1145/3686806},
doi = {10.1145/3686806},
abstract = {Neural symbolic knowledge graph (KG) reasoning offers a promising approach that combines the expressive power of symbolic reasoning with the learning capabilities inherent in neural networks. This survey provides a comprehensive overview of advancements, techniques, and challenges in the field of neural symbolic KG reasoning. The survey introduces the fundamental concepts of KGs and symbolic logic, followed by an exploration of three significant KG reasoning tasks: KG completion, complex query answering, and logical rule learning. For each task, we thoroughly discuss three distinct categories of methods: pure symbolic methods, pure neural approaches, and the integration of neural networks and symbolic reasoning methods known as neural-symbolic. We carefully analyze and compare the strengths and limitations of each category of methods to provide a comprehensive understanding. By synthesizing recent research contributions and identifying open research directions, this survey aims to equip researchers and practitioners with a comprehensive understanding of the state-of-the-art in neural symbolic KG reasoning, fostering future advancements in this interdisciplinary domain.},
journal = {ACM Trans. Knowl. Discov. Data},
month = nov,
articleno = {225},
numpages = {44},
keywords = {Knowledge Graph, Neural Symbolic Reasoning}
}

@inproceedings{10.1145/3627673.3679753,
author = {Zhang, Zhiqiang and Wen, Liqiang and Zhao, Wen},
title = {A GAIL Fine-Tuned LLM Enhanced Framework for Low-Resource Knowledge Graph Question Answering},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679753},
doi = {10.1145/3627673.3679753},
abstract = {Recent studies on knowledge graph question answering (KGQA) have focused on tackling complex inquiries to enhance the applicability of models in real-life settings. Unfortunately, KGQA models encounter significant challenges due to the lack of high-quality annotated data, making it difficult to accurately answer the diverse range of complex natural language questions posed by users. Inspired by the recent success of Large Language Models (LLMs), the burden associated with manual annotation can be mitigated by utilizing LLMs. However, the data generated directly by LLMs may exhibit a potential distribution discrepancy with real user queries. In this paper, we present an enhancement framework that utilizes Generative Adversarial Imitation Learning (GAIL) to fine-tune LLMs, which can address the challenges inherent in the low-resource KGQA task. Specifically, based on GAIL, the LLMs act as the generator aiming to output samples resembling expert demonstrations. Meanwhile, we utilize a paired discriminator to assess the authenticity of generated sequences and their relevance to the input SPARQL queries. Additionally, proximal policy optimization is leveraged to stabilize the training of the generator. Furthermore, we employ an automated algorithm to controllably sample various SPARQL queries from the knowledge graph, subsequently transforming them into corresponding natural language questions using fine-tuned LLMs. The synthetic dataset can serve as supplementary data for training lightweight KGQA models in real-world scenarios. Experimental results on the WebQuestionsSP, ComplexWebQuestions, and GrailQA show that our framework achieves state-of-the-art performance in a low-resource setting, even approaching the performance of supervised models.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {3300–3309},
numpages = {10},
keywords = {generative adversarial imitation learning, knowledge graph, large language model, question answering},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@inproceedings{10.1145/3589334.3645451,
author = {Long, Xiao and Zhuang, Liansheng and Li, Aodi and Li, Houqiang and Wang, Shafei},
title = {Fact Embedding through Diffusion Model for Knowledge Graph Completion},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3645451},
doi = {10.1145/3589334.3645451},
abstract = {Knowledge graph embedding (KGE) is an efficient and scalable method for knowledge graph completion tasks. Existing KGE models typically map entities and relations into a unified continuous vector space and define a score function to capture the connectivity patterns among the elements (entities and relations) of facts. The score on a fact measures its plausibility in a knowledge graph (KG). However, since the connectivity patterns are very complex in a real knowledge graph, it is difficult to define an explicit and efficient score function to capture them, which also limits their performance. This paper argues that plausible facts in a knowledge graph come from a distribution in the low-dimensional fact space. Inspired by this insight, this paper proposes a novel framework called Fact Embedding through Diffusion Model (FDM) to address the knowledge graph completion task. Instead of defining a score function to measure the plausibility of facts in a knowledge graph, this framework directly learns the distribution of plausible facts from the known knowledge graph and casts the entity prediction task into the conditional fact generation task. Specifically, we concatenate the elements embedding in a fact as a whole and take it as input. Then, we introduce a Conditional Fact Denoiser to learn the reverse denoising diffusion process and generate the target fact embedding from noised data. Extensive experiments demonstrate that FDM significantly outperforms existing state-of-the-art methods in three benchmark datasets.},
booktitle = {Proceedings of the ACM Web Conference 2024},
pages = {2020–2029},
numpages = {10},
keywords = {knowledge graph, knowledge graph embedding, link prediction},
location = {Singapore, Singapore},
series = {WWW '24}
}

@article{10.1145/3637216,
author = {Ren, Xuhui and Chen, Tong and Nguyen, Quoc Viet Hung and Cui, Lizhen and Huang, Zi and Yin, Hongzhi},
title = {Explicit Knowledge Graph Reasoning for Conversational Recommendation},
year = {2024},
issue_date = {August 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {4},
issn = {2157-6904},
url = {https://doi.org/10.1145/3637216},
doi = {10.1145/3637216},
abstract = {Traditional recommender systems estimate user preference on items purely based on historical interaction records, thus failing to capture fine-grained yet dynamic user interests and letting users receive recommendation only passively. Recent conversational recommender systems (CRSs) tackle those limitations by enabling recommender systems to interact with the user to obtain her/his current preference through a sequence of clarifying questions. Recently, there has been a rise of using knowledge graphs (KGs) for CRSs, where the core motivation is to incorporate the abundant side information carried by a KG into both the recommendation and conversation processes. However, existing KG-based CRSs are subject to two defects: (1) there is a semantic gap between the learned representations of utterances and KG entities, hindering the retrieval of relevant KG information; (2) the reasoning over KG is mostly performed with the implicitly learned user interests, overlooking the explicit signals from the entities actually mentioned in the conversation.To address these drawbacks, we propose a new CRS framework, namely, the Knowledge Enhanced Conversational Reasoning (KECR) model. As a user can reflect her/his preferences via both attribute- and item-level expressions, KECR jointly embeds the structured knowledge from two levels in the KG. A mutual information maximization constraint is further proposed for semantic alignment between the embedding spaces of utterances and KG entities. Meanwhile, KECR utilizes the connectivity within the KG to conduct explicit reasoning of the user demand, making the model less dependent on the user’s feedback to clarifying questions. As such, the semantic alignment and explicit KG reasoning can jointly facilitate accurate recommendation and quality dialogue generation. By comparing with strong baselines on two real-world datasets, we demonstrate that KECR obtains state-of-the-art recommendation effectiveness, as well as competitive dialogue generation performance.},
journal = {ACM Trans. Intell. Syst. Technol.},
month = jul,
articleno = {86},
numpages = {21},
keywords = {Conversational recommendation, knowledge graph, preference mining}
}

@inproceedings{10.1145/3627673.3679602,
author = {Zhang, Tianli and Zheng, Tongya and Xiao, Zhenbang and Chen, Zulong and Li, Liangyue and Feng, Zunlei and Zhang, Dongxiang and Song, Mingli},
title = {Language Models-enhanced Semantic Topology Representation Learning For Temporal Knowledge Graph Extrapolation},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679602},
doi = {10.1145/3627673.3679602},
abstract = {Temporal Knowledge Graph (TKG) extrapolation aims to predict future missing facts based on historical information, which has exhibited both semantics and topology of events. The mainstream methods have advanced the prediction performance by exploring the potential of topology representations of TKGs based on dedicated temporal Graph Neural Networks (GNNs). Until recently, few Language Models (LM) based methods have attempted to model the semantic representations of TKGs, however, lacking specific designs for the topology information. Therefore, we propose a Semantic TOpology REpresentation learning (STORE) framework enhanced by LMs to bridge the gap between the semantics and topology of TKGs. Firstly, we tackle the challenge of long historical facts modeling by a time-aware sampling based on semantic priors to extract concise yet precise facts. Secondly, we handle the challenge of the interaction between topology and semantics by transforming graph representations into virtual tokens that are then integrated with generated prompts and fed into LMs. Finally, multi-head attention is adopted to obtain better semantic topology representations, thereby achieving joint optimization of both temporal GNNs and LMs. Extensive experiments on five datasets show that our STORE outperforms state-of-the-art GNNs- and LM-based methods.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {3227–3236},
numpages = {10},
keywords = {knowledge graph reasoning, large language model, temporal knowledge graph},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@inproceedings{10.1145/3627673.3680022,
author = {Zhao, Qian and Qian, Hao and Liu, Ziqi and Zhang, Gong-Duo and Gu, Lihong},
title = {Breaking the Barrier: Utilizing Large Language Models for Industrial Recommendation Systems through an Inferential Knowledge Graph},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3680022},
doi = {10.1145/3627673.3680022},
abstract = {Recommendation systems are widely used in e-commerce websites and online platforms to address information overload. However, existing systems primarily rely on historical data and user feedback, making it difficult to capture user intent transitions. Recently, Knowledge Base (KB)-based models are proposed to incorporate expert knowledge, but it struggle to adapt to new items and the evolving e-commerce environment. To address these challenges, we propose a novel Large Language Model based Complementary Knowledge Enhanced Recommendation System (LLM-KERec). It introduces an entity extractor that extracts unified concept terms from item and user information. To provide cost-effective and reliable prior knowledge, entity pairs are generated based on entity popularity and specific strategies. The large language model determines complementary relationships in each entity pair, constructing a complementary knowledge graph. Furthermore, a new complementary recall module and an Entity-Entity-Item (E-E-I) weight decision model refine the scoring of the ranking model using real complementary exposure-click samples. Extensive experiments conducted on three industry datasets demonstrate the significant performance improvement of our model compared to existing approaches. Additionally, detailed analysis shows that LLM-KERec enhances users' enthusiasm for consumption by recommending complementary items. In summary, LLM-KERec addresses the limitations of traditional recommendation systems by incorporating complementary knowledge and utilizing a large language model to capture user intent transitions, adapt to new items, and enhance recommendation efficiency in the evolving e-commerce landscape.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {5086–5093},
numpages = {8},
keywords = {knowledge graph, large language model, recommendation system},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@inproceedings{10.1145/3626772.3657665,
author = {Liu, Lingyuan and Du, Huifang and Zhang, Xiaolian and Guo, Mengying and Wang, Haofen and Wang, Meng},
title = {A Question-Answering Assistant over Personal Knowledge Graph},
year = {2024},
isbn = {9798400704314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626772.3657665},
doi = {10.1145/3626772.3657665},
abstract = {We develop a Personal Knowledge Graph Question-Answering (PKGQA) assistant, seamlessly integrating information from multiple mobile applications into a unified and user-friendly query interface to offer users convenient information retrieval and personalized knowledge services. Based on a fine-grained schema customized for PKG, the PKGQA system in this paper comprises Symbolic Semantic Parsing, Frequently Asked Question (FAQ) Semantic Matching, and Neural Semantic Parsing modules, which are designed to take into account both accuracy and efficiency. The PKGQA system achieves high accuracy on the constructed dataset and demonstrates good performance in answering complex questions. Our system is implemented through an Android application, which is shown in https://youtu.be/p732U5KPEq4.},
booktitle = {Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {2708–2712},
numpages = {5},
keywords = {intelligent personal assistant, knowledge graph, neural networks, question answering, symbolic system},
location = {Washington DC, USA},
series = {SIGIR '24}
}

@inproceedings{10.1145/3689218.3689221,
author = {Kong, Xiangxing and Li, Yangyang and Fan, Manyi and Shi, Jiayi and Wei, Lingxiang and Qu, Shaojie},
title = {Automated Knowledge Mining and Knowledge Graph Reasoning for Aircraft Engine Maintenance},
year = {2024},
isbn = {9798400718250},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689218.3689221},
doi = {10.1145/3689218.3689221},
abstract = {The maintenance process for aircraft engines is fraught with significant challenges due to their inherent complexity. Large Language Models excel in general Natural Language Processing tasks, yet they lack domain-specific knowledge, thereby compromising their performance in specialized areas. The varied descriptions of engine faults also render traditional text matching algorithms unsuitable for this maintenance domain. In this paper, we construct a knowledge graph integrated with fault diagnosis reasoning ability with knowledge mined from aircraft engine maintenance data. Firstly, we propose the Knowledge Mining and Knowledge Graph Reasoning framework for aircraft engine maintenance data knowledge mining and aircraft engine fault diagnosis. Secondly, we utilize prompt with in-context learning to mitigate the issue of the model lacking expertise in the field of aircraft engine maintenance. Finally, we adopt a sentence similarity calculation method based on BERT, which enables more effective processing of semantic information. We apply our method to Aircraft Engine Fault dataset which is collected from maintenance records of civil aircraft engine since 2007 to 2015, and experimental results demonstrate the effectiveness of our knowledge mining method and aircraft engine fault reasoning algorithm.},
booktitle = {Proceedings of the 2024 6th International Conference on Pattern Recognition and Intelligent Systems},
pages = {35–40},
numpages = {6},
keywords = {aircraft engine maintenance, knowledge graph reasoning, large language model},
location = {Hong Kong, Hong Kong},
series = {PRIS '24}
}

@inproceedings{10.1145/3698587.3701538,
author = {Chu, Lei and Wu, Hongyan and Pan, Yi},
title = {ChatASD: A Dialogue Framework for LLMs Enhanced by Autism Knowledge Graph Retrieval},
year = {2024},
isbn = {9798400713026},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3698587.3701538},
doi = {10.1145/3698587.3701538},
abstract = {Autism Spectrum Disorder (ASD) is a neurodevelopmental disorder characterized by developmental delays, communication difficulties, repetitive behaviors, and restricted interests. Large Language Models (LLMs) have demonstrated exceptional capabilities in various natural language tasks, particularly in providing personalized question-and-answer(Q&amp;A) services, making them well-suited for constructing dialogue engines for autism Q&amp;A systems. However, general LLMs often lack integrated autism knowledge during training, limiting their professional competency in autism consultation. Additionally, the automatic evaluation of scientific accuracy in autism medical knowledge Q&amp;A remains underexplored. To address this gap, we propose ChatASD, an autism knowledge Q&amp;A framework based on Graph Retrieval-Augmented Generation (GraphRAG) technology. This framework leverages LLMs and retrieves relevant information from medical literature to generate an autism knowledge graph, employing a combination of global and community queries to produce reliable responses. Compared to traditional methods, ChatASD effectively addresses the sparse distribution of autism knowledge, providing more accurate and comprehensive answersAutomatic efficacy evaluations and competitive experiments on system responses indicate our approach significantly improves reliability of autism-related professional knowledge queries.},
booktitle = {Proceedings of the 15th ACM International Conference on Bioinformatics, Computational Biology and Health Informatics},
articleno = {36},
numpages = {8},
keywords = {Autism, Knowledge Graph, LLM, Question-and-Answer System, Retrieval-Augmented Generation},
location = {Shenzhen, China},
series = {BCB '24}
}

@inproceedings{10.1145/3632410.3633292,
author = {Agarwal, Manoj},
title = {Building Knowledge Graph for Products at Web Scale},
year = {2024},
isbn = {9798400716348},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3632410.3633292},
doi = {10.1145/3632410.3633292},
abstract = {A knowledge graph is the key to entity search as it can store the factual entity related information in a structured manner without the rigidity of a fixed schema. Both Google and Bing have web scale knowledge graphs and for a large fraction of web queries knowledge graph is invoked. E-commerce search is primarily an entity search. Therefore, building a Knowledge Graph is the key to improve the eCommerce search in many ways. However, building it at web scale is a highly challenging problem. It is an equally or even more challenging problem to build the knowledge graph for products. In this tutorial, we present state-of-the-art work to address some of the key challenges to build the knowledge graph as well as our methodology to build a product graph at web scale for Microsoft-Shopping, containing a few billion facts.},
booktitle = {Proceedings of the 7th Joint International Conference on Data Science &amp; Management of Data (11th ACM IKDD CODS and 29th COMAD)},
pages = {498–500},
numpages = {3},
keywords = {Product graph, faceted search, knowledge graph, semantic search, taxonomy},
location = {Bangalore, India},
series = {CODS-COMAD '24}
}

@inproceedings{10.1145/3670105.3670139,
author = {Lin, Wangqun and Xu, Jing and Tian, Yu and Peng, Baoyun and Li, Yan and Ge, Yawei},
title = {Cognitive Intelligence: Driven by Knowledge Graph and Big Model Collaboration},
year = {2024},
isbn = {9798400716751},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3670105.3670139},
doi = {10.1145/3670105.3670139},
abstract = {Abstract: Cognitive intelligence is primarily characterized by the understanding, reasoning, cognition, and decision-making of complex things. It is a higher-order form of artificial intelligence development. This paper provides an in-depth analysis of two representative technologies, knowledge graph and big model, which promote the development of cognitive intelligence. Firstly, we systematically sorts out the characteristics, advantages, and shortcomings of these two technologies. Secondly, we proposes technical approaches and main methods for the mutual enhancement of knowledge graph and big model. Finally, we provides the main direction for the integrated development of knowledge graph and big model to promote the development of cognitive intelligence. We hope our work can provide reference and inspiration for relevant engineers and technical researchers.CCS Concepts: .Computing methodologies → Artificial intelligence; Knowledge representation and reasoning},
booktitle = {Proceedings of the 2024 5th International Conference on Computing, Networks and Internet of Things},
pages = {204–209},
numpages = {6},
keywords = {artificial intelligence, big model, cognitive intelligence, knowledge graph},
location = {Tokyo, Japan},
series = {CNIOT '24}
}

@article{10.1145/3696664,
author = {Zhao, Yang and Kang, Xiaomian and Zhang, Yaping and Zhang, Jiajun and Zhou, Yu and Zong, Chengqing},
title = {Knowledge Graph Guided Neural Machine Translation with Dynamic Reinforce-selected Triples},
year = {2024},
issue_date = {December 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {12},
issn = {2375-4699},
url = {https://doi.org/10.1145/3696664},
doi = {10.1145/3696664},
abstract = {Previous methods incorporating knowledge graphs (KGs) into neural machine translation (NMT) adopt a static knowledge utilization strategy, that introduces many useless knowledge triples and makes the useful triples difficult to be utilized by NMT. To address this problem, we propose a KG guided NMT model with dynamic reinforce-selected triples. The proposed methods could dynamically select the different useful knowledge triples for different source sentences. Specifically, the proposed model contains two components: (1) knowledge selector, that dynamically selects useful knowledge triples for a source sentence, and (2) knowledge guided NMT (KgNMT), that utilizes the selected triples to guide the translation of NMT. Meanwhile, to overcome the non-differentiable problem and guide the training procedure, we propose a policy gradient strategy to encourage the model to select useful triples and improve the generation probability of gold target sentence. Various experimental results show that the proposed method can significantly outperform the baseline models in both translation quality and handling the entities.},
journal = {ACM Trans. Asian Low-Resour. Lang. Inf. Process.},
month = nov,
articleno = {163},
numpages = {21},
keywords = {Neural machine translation, knowledge graph, reinforcement learning}
}

@inproceedings{10.1145/3589334.3645564,
author = {Zhang, Honggen and Zhang, June and Molybog, Igor},
title = {HaSa: Hardness and Structure-Aware Contrastive Knowledge Graph Embedding},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3645564},
doi = {10.1145/3589334.3645564},
abstract = {We consider a contrastive learning approach to knowledge graph embedding (KGE) via InfoNCE. For KGE, efficient learning relies on augmenting the training data with negative triples. However, most KGE works overlook the bias from generating the negative triples- false negative triples (factual triples missing from the knowledge graph). We argue that generating high-quality (i.e., hard) negative triples might lead to an increase in false negative triples. To mitigate the impact of false negative triples during the generation of hard negative triples, we propose the Hardness and Structure-aware (HaSa) contrastive KGE method, which alleviates the effect of false negative triples while generating the hard negative triples. Experiments show that HaSa improves the performance of InfoNCE-based KGE approaches and achieves state-of-the-art results in several metrics for WN18RR datasets and competitive results for FB15k-237 datasets compared to classic and pre-trained LM-based KGE methods.},
booktitle = {Proceedings of the ACM Web Conference 2024},
pages = {2116–2127},
numpages = {12},
keywords = {contrastive learning, knowledge graph embedding, negative sampling},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3597503.3639109,
author = {Wang, Jun and Li, Yanhui and Chen, Zhifei and Chen, Lin and Zhang, Xiaofang and Zhou, Yuming},
title = {Knowledge Graph Driven Inference Testing for Question Answering Software},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597503.3639109},
doi = {10.1145/3597503.3639109},
abstract = {In the wake of developments in the field of Natural Language Processing, Question Answering (QA) software has penetrated our daily lives. Due to the data-driven programming paradigm, QA software inevitably contains bugs, i.e., misbehaving in real-world applications. Current testing techniques for testing QA software include two folds, reference-based testing and metamorphic testing.This paper adopts a different angle to achieve testing for QA software: we notice that answers to questions would have inference relations, i.e., the answers to some questions could be logically inferred from the answers to other questions. If these answers on QA software do not satisfy the inference relations, an inference bug is detected. To generate the questions with the inference relations automatically, we propose a novel testing method Knowledge Graph driven Inference Testing (KGIT), which employs facts in the Knowledge Graph (KG) as the seeds to logically construct test cases containing questions and contexts with inference relations. To evaluate the effectiveness of KGIT, we conduct an extensive empirical study with more than 2.8 million test cases generated from the large-scale KG YAGO4 and three QA models based on the state-of-the-art QA model structure. The experimental results show that our method (a) could detect a considerable number of inference bugs in all three studied QA models and (b) is helpful in retraining QA models to improve their inference ability.},
booktitle = {Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
articleno = {119},
numpages = {13},
keywords = {question answering, software testing, knowledge graph, inference rules},
location = {Lisbon, Portugal},
series = {ICSE '24}
}

@inproceedings{10.1145/3686397.3686420,
author = {Sun, Yi and Yang, Wanru and Liu, Yin},
title = {The Application of Constructing Knowledge Graph of Oral Historical Archives Resources Based on LLM-RAG},
year = {2024},
isbn = {9798400717345},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3686397.3686420},
doi = {10.1145/3686397.3686420},
abstract = {Oral historical archive resources are an emerging archive resource with the rapid development of modern technology. Its "bottom-up" approach to historical research has received widespread attention in the fields of history, archives, and libraries. Under the common knowledge discovery mode, oral historical archives resources are showing a dispersed state. Information technology represented by knowledge graphs can break through the data solidification of oral historical archives, reshape the information stack of oral historical archives, and achieve knowledge association and aggregation of oral historical archive resources. The article attempts to construct a knowledge graph of the oral historical archives resources on the theme of "science and art" in the collection of T.D. Lee Library of Shanghai Jiao Tong University. It uses Large Language Model - Retrieval Augmented Generation (LLM-RAG) for knowledge extraction, and then uses a semantic model for knowledge organization and management. The article attempts to empower humanities with technology, exploring the possibility of combining "digital technology" and "humanities research", extending traditional humanities research methods, breaking down barriers between technology and humanities resources, and providing a new path reference for revealing resource content characteristics, semantic deep correlation, and multi-dimensional knowledge discovery.},
booktitle = {Proceedings of the 2024 8th International Conference on Information System and Data Mining},
pages = {142–149},
numpages = {8},
keywords = {Knowledge Graph, LLM-RAG, Oral History Archives},
location = {
},
series = {ICISDM '24}
}

@inproceedings{10.1145/3616855.3636507,
author = {Quintero-Narvaez, Carlos Efrain and Monroy, Raul},
title = {Integrating Knowledge Graph Data with Large Language Models for Explainable Inference},
year = {2024},
isbn = {9798400703713},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3616855.3636507},
doi = {10.1145/3616855.3636507},
abstract = {We propose a method to enable Large Language Models to access Knowledge Graph (KG) data and justify their text generation by showing the specific graph data the model accessed during inference. For this, we combine Language Models with methods from Neurosymbolic Artificial Intelligence designed to answer queries on Knowledge Graphs. This is done by modifying the model so that at different stages of inference it outputs an Existential Positive First-Order (EPFO) query, which is then processed by an additional query appendix. In turn, the query appendix uses neural link predictors along with description aware embeddings to resolve these queries. After that, the queries are logged and used as an explanation of the inference process of the complete model. Lastly, we train the model using a Linear Temporal Logic (LTL) constraint-based loss function to measure the consistency of the queries among each other and with the final model output.},
booktitle = {Proceedings of the 17th ACM International Conference on Web Search and Data Mining},
pages = {1198–1199},
numpages = {2},
keywords = {advanced artificial intelligence, existential positive first order query, explainable, knowledge graph, language model, linear temporal logic, query},
location = {Merida, Mexico},
series = {WSDM '24}
}

@inproceedings{10.1145/3643479.3662055,
author = {Bui, Tuan and Tran, Oanh and Nguyen, Phuong and Ho, Bao and Nguyen, Long and Bui, Thang and Quan, Tho},
title = {Cross-Data Knowledge Graph Construction for LLM-enabled Educational Question-Answering System: A Case Study at HCMUT},
year = {2024},
isbn = {9798400705472},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643479.3662055},
doi = {10.1145/3643479.3662055},
abstract = {In today's rapidly evolving landscape of Artificial Intelligence, large language models (LLMs) have emerged as a vibrant research topic. LLMs find applications in various fields and contribute significantly. Despite their powerful language capabilities, similar to pre-trained language models (PLMs), LLMs still face challenges in remembering events, incorporating new information, and addressing domain-specific issues or hallucinations. To overcome these limitations, researchers have proposed Retrieval-Augmented Generation (RAG) techniques, some others have proposed the integration of LLMs with Knowledge Graphs (KGs) to provide factual context, thereby improving performance and delivering more accurate feedback to user queries.Education plays a crucial role in human development and progress. With the technology transformation, traditional education is being replaced by digital or blended education. Therefore, educational data in the digital environment is increasing day by day. Data in higher education institutions are diverse, comprising various sources such as unstructured/structured text, relational databases, web/app-based API access, etc. Constructing a Knowledge Graph from these cross-data sources is not a simple task. This article proposes a method for automatically constructing a Knowledge Graph from multiple data sources and discusses some initial applications (experimental trials) of KG in conjunction with LLMs for question-answering tasks.},
booktitle = {Proceedings of the 1st ACM Workshop on AI-Powered Q&amp;A Systems for Multimedia},
pages = {36–43},
numpages = {8},
keywords = {Education, Knowledge Graph, Large language model, Open Intent Discovery, Question-Answering System},
location = {Phuket, Thailand},
series = {AIQAM '24}
}

@inproceedings{10.1145/3627673.3680262,
author = {Wang, Wenbo},
title = {The 'Path' to Clarity: Identifying False Claims Through a Knowledge Graph Exploration},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3680262},
doi = {10.1145/3627673.3680262},
abstract = {Automated fact-checking has emerged as a safeguard against the spread of false information. Existing fact-checking approaches aim to determine whether a news claim is true or false, and they have achieved decent accuracy of veracity prediction. However, the current state-of-the-art models still face challenges, such as ambiguity in the claims and lack of contextual information. This study introduces a fact-checking model, Path-FC, which focuses on 1) augmenting the representations of claims and evidence by incorporating additional context using the Knowledge Paths extracted from the external Knowledge Graph; 2) Identifying false claims by learning the differences between claims and evidence. The experimental results demonstrate that Knowledge Path retrieval, combined with the multi-head attention technique, contributes to improved performance of fact-checking. The code is available at https://anonymous.4open.science/r/Path-FC.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {5487–5490},
numpages = {4},
keywords = {claim verification, deep learning, fact checking, knowledge graph, natural language processing},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@article{10.1145/3660521,
author = {Zeng, Kaisheng and Jin, Hailong and Lv, Xin and Zhu, Fangwei and Hou, Lei and Zhang, Yi and Pang, Fan and Qi, Yu and Liu, Dingxiao and Li, Juanzi and Feng, Ling},
title = {XLORE 3: A Large-Scale Multilingual Knowledge Graph from Heterogeneous Wiki Knowledge Resources},
year = {2024},
issue_date = {November 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {42},
number = {6},
issn = {1046-8188},
url = {https://doi.org/10.1145/3660521},
doi = {10.1145/3660521},
abstract = {In recent years, knowledge graph (KG) has attracted significant attention from academia and industry, resulting in the development of numerous technologies for KG construction, completion, and application. XLORE is one of the largest multilingual KGs built from Baidu Baike and Wikipedia via a series of knowledge modeling and acquisition methods. In this article, we utilize systematic methods to improve XLORE's data quality and present its latest version, XLORE 3, which enables the effective integration and management of heterogeneous knowledge from diverse resources. Compared with previous versions, XLORE 3 has three major advantages: (1) We design a comprehensive and reasonable schema, namely XLORE ontology, which can effectively organize and manage entities from various resources. (2) We merge equivalent entities in different languages to facilitate knowledge sharing. We provide a large-scale entity linking system to establish the associations between unstructured text and structured KG. (3) We design a multi-strategy knowledge completion framework, which leverages pre-trained language models and vast amounts of unstructured text to discover missing and new facts. The resulting KG contains 446 concepts, 2,608 properties, 66 million entities, and more than 2 billion facts. It is available and downloadable online at , providing a valuable resource for researchers and practitioners in various fields.},
journal = {ACM Trans. Inf. Syst.},
month = aug,
articleno = {145},
numpages = {47},
keywords = {Knowledge graph, knowledge management, knowledge fusion, knowledge completion, schema construction, entity typing, entity alignment, entity linking}
}

@inproceedings{10.1145/3589334.3645592,
author = {Liu, Ben and Peng, Miao and Xu, Wenjie and Jia, Xu and Peng, Min},
title = {UniLP: Unified Topology-aware Generative Framework for Link Prediction in Knowledge Graph},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3645592},
doi = {10.1145/3589334.3645592},
abstract = {Link prediction (LP) in knowledge graph (KG) is a crucial task that has received increasing attention recently. Due to the heterogeneous structures of KGs, various application scenarios, and demand-specific downstream objectives, there exist multiple subtasks in LP. Most studies only focus on designing a dedicated architecture for a specific subtask, which results in various complicated LP models. The isolated architectures and chaotic situations make it significant to construct a unified model that can handle multiple LP subtasks simultaneously. However, unifying all subtasks in LP presents numerous challenges, including unified input forms, task-specific context modeling, and topological information encoding. To address these challenges, we propose a topology-aware generative framework, namely UniLP, which utilizes a generative pre-trained language model to accomplish different LP subtasks universally. Specifically, we introduce a context demonstration template to convert task-specific context into a unified generative formulation. Based on the unified formulation, to address the limitation of transformer architecture that may overlook important structural signals in KGs, we design novel topology-aware soft prompts to deeply couple topology and text information in a contextualized manner. Extensive experiment results demonstrate that our framework achieves substantial performance gain and provides a real unified end-to-end solution for the whole LP subtasks. We also perform comprehensive ablation studies to support in-depth analysis of each component in UniLP.},
booktitle = {Proceedings of the ACM Web Conference 2024},
pages = {2170–2180},
numpages = {11},
keywords = {knowledge graph, link prediction, unified generative framework},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3686397.3686417,
author = {Alqaaidi, Sakher Khalil and Kochut, Krzysztof J.},
title = {Relations Prediction in Knowledge Graph Completion using Large Language Models},
year = {2024},
isbn = {9798400717345},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3686397.3686417},
doi = {10.1145/3686397.3686417},
abstract = {Knowledge graphs have been widely used to represent facts in a structured format. Due to their large-scale applications, knowledge graphs suffer from being incomplete. The relation prediction task obtains knowledge graph completion by assigning one or more possible relations to each pair of nodes. In this work, we make use of the knowledge graph node names to fine-tune a large language model for the relation prediction task. By utilizing the node names only, we enable our model to operate sufficiently in the inductive settings. Our experiments show that we accomplish new scores on a widely used knowledge graph benchmark.},
booktitle = {Proceedings of the 2024 8th International Conference on Information System and Data Mining},
pages = {122–127},
numpages = {6},
keywords = {Knowledge Graphs, Large Language Models},
location = {
},
series = {ICISDM '24}
}

@inproceedings{10.1145/3627673.3679711,
author = {Zhao, Kaichen and Song, Yaoxian and Zhao, Haiquan and Liu, Haoyu and Li, Tiefeng and Li, Zhixu},
title = {Towards Coarse-grained Visual Language Navigation Task Planning Enhanced by Event Knowledge Graph},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679711},
doi = {10.1145/3627673.3679711},
abstract = {Visual language navigation (VLN) is one of the important research in embodied AI. It aims to enable an agent to understand the surrounding environment and complete navigation tasks. VLN instructions could be categorized into coarse-grained and fine-grained commands. Fine-grained command describes a whole task with subtasks step-by-step. In contrast, coarse-grained command gives an abstract task description, which more suites human habits. Most existing work focuses on the former kind of instruction in VLN tasks, ignoring the latter abstract instructions belonging to daily life scenarios. To overcome the above challenge in abstract instruction, we attempt to consider coarse-grained instruction in VLN by event knowledge enhancement. Specifically, we first propose a prompt-based framework to extract an event knowledge graph (named VLN-EventKG =) for VLN integrally over multiple mainstream benchmark datasets. Through small and large language model collaboration, we realize knowledge-enhanced navigation planning (named EventNav) for VLN tasks with coarse-grained instruction input. Additionally, we design a novel dynamic history backtracking module to correct potential error action planning in real time. Experimental results in various public benchmarks show our knowledge-enhanced method has superiority in coarse-grained-instruction VLN using our proposed VLN-EventKG with over 5% improvement in success rate. Our project is available at https://sites.google.com/view/vln-eventkg},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {3320–3330},
numpages = {11},
keywords = {dynamic backtracking, event knowledge graph, knowledge retrieval, task planning, visual language navigation},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@article{10.1145/3671148,
author = {Meng, Siyuan and Zhou, Jie and Chen, Xuxin and Liu, Yufei and Lu, Fengyuan and Huang, Xinli},
title = {Structure-Information-Based Reasoning over the Knowledge Graph: A Survey of Methods and Applications},
year = {2024},
issue_date = {September 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {8},
issn = {1556-4681},
url = {https://doi.org/10.1145/3671148},
doi = {10.1145/3671148},
abstract = {The knowledge graph (KG) is an efficient form of knowledge organization and expression, providing prior knowledge support for various downstream tasks, and has received extensive attention in natural language processing. However, existing large-scale KGs have many hidden facts that need to be discovered. How to effectively use the structure information of KG is an important research direction of knowledge reasoning. Structure-Information-based reasoning over the KG is a technique used to find the missing facts by the structure information of KG. This survey summarizes the methods and applications of Structure-Information-based reasoning and hopes to be helpful to the research in this field. First, we introduced the definition of knowledge reasoning and the conceptual description of related tasks. Then, we reviewed the methods of Structure-Information-based reasoning. Specifically, we categorized them into four representative classes: PRA-based reasoning, Path-Embedding-based reasoning, RL-based reasoning, and GNN-based reasoning. We compared the motivations and details between practices in the same category. After that, we described the application of Structure-Information-based knowledge reasoning in the KG Completion, Question Answering System, Recommendation System, and other fields. Finally, we discussed the future research directions of Structure-Information-based reasoning.},
journal = {ACM Trans. Knowl. Discov. Data},
month = aug,
articleno = {210},
numpages = {42},
keywords = {Knowledge graph, knowledge reasoning, structure information}
}

@inproceedings{10.1109/ASE56229.2023.00075,
author = {Huang, Qing and Wan, Zhenyu and Xing, Zhenchang and Wang, Changjing and Chen, Jieshan and Xu, Xiwei and Lu, Qinghua},
title = {Let's Chat to Find the APIs: Connecting Human, LLM and Knowledge Graph through AI Chain},
year = {2024},
isbn = {9798350329964},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASE56229.2023.00075},
doi = {10.1109/ASE56229.2023.00075},
abstract = {API recommendation methods have evolved from literal and semantic keyword matching to query expansion and query clarification. The latest query clarification method is knowledge graph (KG)-based, but limitations include out-of-vocabulary (OOV) failures and rigid question templates. To address these limitations, we propose a novel knowledge-guided query clarification approach for API recommendation that leverages a large language model (LLM) guided by KG. We utilize the LLM as a neural knowledge base to overcome OOV failures, generating fluent and appropriate clarification questions and options. We also leverage the structured API knowledge and entity relationships stored in the KG to filter out noise, and transfer the optimal clarification path from KG to the LLM, increasing the efficiency of the clarification process. Our approach is designed as an AI chain that consists of five steps, each handled by a separate LLM call, to improve accuracy, efficiency, and fluency for query clarification in API recommendation. We verify the usefulness of each unit in our AI chain, which all received high scores close to a perfect 5. When compared to the baselines, our approach shows a significant improvement in MRR, with a maximum increase of 63.9% higher when the query statement is covered in KG and 37.2% when it is not. Ablation experiments reveal that the guidance of knowledge in the KG and the knowledge-guided pathfinding strategy are crucial for our approach's performance, resulting in a 19.0% and 22.2% increase in MAP, respectively. Our approach demonstrates a way to bridge the gap between KG and LLM, effectively compensating for the strengths and weaknesses of both.},
booktitle = {Proceedings of the 38th IEEE/ACM International Conference on Automated Software Engineering},
pages = {471–483},
numpages = {13},
keywords = {API recommendation, query clarification, knowledge graph, large language model, out-of-vocabulary},
location = {Echternach, Luxembourg},
series = {ASE '23}
}

@inproceedings{10.1145/3605098.3635957,
author = {Bellan, Patrizio and Dragoni, Mauro and Ghidini, Chiara},
title = {Process Knowledge Extraction and Knowledge Graph Construction Through Prompting: A Quantitative Analysis},
year = {2024},
isbn = {9798400702433},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3605098.3635957},
doi = {10.1145/3605098.3635957},
abstract = {The automated construction of process knowledge graphs from process description documents is a challenging research area. Here, the lack of massive annotated data, as well as raw text repositories describing real-world process documents, makes it extremely difficult to adopt deep learning approaches to perform this transformation. Indeed, the main challenge is to extract conceptual elements representing the actual entities or relations of the process model described within its corresponding natural language document. Large Language Models (LLMs) have shown promising results in supporting the extraction of structured knowledge from unstructured texts. Although several works explored this strategy to build or complete knowledge graphs, the exploitation of LLMs toward domain-specific knowledge base construction from scratch has not yet been investigated deeply. Our aim is to exploit the LLM capabilities to extract process knowledge from unseen natural language descriptions. In this work, we present a prompt-based in-context learning strategy to extract, from process descriptions, conceptual information that can be converted into their equivalent knowledge graphs. Such a strategy is performed in a multi-turn dialog fashion. We validate the accuracy of the proposed approach from a quantitative perspective. The results highlight the feasibility of the proposed approach within our low-resource scenarios and open interesting perspectives for future activities.},
booktitle = {Proceedings of the 39th ACM/SIGAPP Symposium on Applied Computing},
pages = {1634–1641},
numpages = {8},
keywords = {process extraction from text, in-context learning, knowledge graph, large language model, business process management},
location = {Avila, Spain},
series = {SAC '24}
}

@inproceedings{10.1145/3631700.3665235,
author = {Carta, Salvatore and Giuliani, Alessandro and Manca, Marco Manolo and Piano, Leonardo and Pompianu, Livio and Tiddia, Sandro Gabriele},
title = {Towards Knowledge Graph Refinement: Misdirected Triple Identification},
year = {2024},
isbn = {9798400704666},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3631700.3665235},
doi = {10.1145/3631700.3665235},
abstract = {In the current digital transformation scenario, Knowledge Graphs (KGs) represent an across-the-board instrument for representing knowledge in a structured form. Such tools allow to effectively enhance the performance of Artificial Intelligence models in manifold contexts, such as reasoning or information retrieval. Nevertheless, the effectiveness of KGs is often affected by the incorrect directionality of some of their edges, due in most cases to human error or the inefficiency of automatic and semi-automatic graph creation methods. This paper proposes a classification-based approach to identify misdirected triples within a KG, aiming to support and assist humans in creating graph refinement. Triples are the main component of KGs, and they model the connection between nodes with a &lt;subject, predicate, object&gt; form. Our proposal allows us to refine a KG by devising a classification-based approach for recognizing whether the subjects and objects are not compliant with the logic directionality of the corresponding predicate, meaning that they should be switched (e.g., the triple &lt;U.S.A., is capital, Washington&gt; should be inverted as &lt;Washington, is capital, U.S.A.&gt;). We compare traditional machine learning techniques with cutting-edge advanced methods, including pre-trained language models and large language models. Extensive experiments have been performed across several datasets, confirming the effectiveness of our proposal.},
booktitle = {Adjunct Proceedings of the 32nd ACM Conference on User Modeling, Adaptation and Personalization},
pages = {460–466},
numpages = {7},
keywords = {Artificial Intelligence, Digital Transformation, Large Language Models},
location = {Cagliari, Italy},
series = {UMAP Adjunct '24}
}

@inproceedings{10.1145/3639233.3639357,
author = {Zhu, Ruiqi and Bundy, Alan and Pan, Jeff and Nuamah, Kwabena and Wang, Fangrong and Li, Xue and Xu, Lei and Mauceri, Stefano},
title = {Assessing the Quality of a Knowledge Graph via Link Prediction Tasks},
year = {2024},
isbn = {9798400709227},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639233.3639357},
doi = {10.1145/3639233.3639357},
abstract = {Knowledge Graph (KG) Construction is the prerequisite for all other KG research and applications. Researchers and engineers have proposed various approaches to build KGs for their use cases. However, how can we know whether our constructed KG is good or bad? Is it correct and complete? Is it consistent and robust? In this paper, we propose a method called LP-Measure to assess the quality of a KG via a link prediction tasks, without using a gold standard or other human labour. Though theoretically, the LP-Measure can only assess consistency and redundancy, instead of the more desirable correctness and completeness, empirical evidence shows that this measurement method can quantitatively distinguish the good KGs from the bad ones, even in terms of incorrectness and incompleteness. Compared with the most commonly used manual assessment, our LP-Measure is an automated evaluation, which saves time and human labour.},
booktitle = {Proceedings of the 2023 7th International Conference on Natural Language Processing and Information Retrieval},
pages = {124–129},
numpages = {6},
keywords = {Knowledge Graph, Link Prediction, Quality Assessment},
location = {Seoul, Republic of Korea},
series = {NLPIR '23}
}

@inproceedings{10.1145/3664647.3681112,
author = {Liang, Ke and Meng, Lingyuan and Liu, Yue and Liu, Meng and Wei, Wei and Liu, Suyuan and Tu, Wenxuan and Wang, Siwei and Zhou, Sihang and Liu, Xinwang},
title = {Simple Yet Effective: Structure Guided Pre-trained Transformer for Multi-modal Knowledge Graph Reasoning},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3681112},
doi = {10.1145/3664647.3681112},
abstract = {Various information in different modalities in an intuitive way in multi-modal knowledge graphs (MKGs), which are utilized in different downstream tasks, like recommendation. However, most MKGs are still far from complete, which motivates the flourishing of MKG reasoning models. Recently, with the development of general artificial intelligence, pre-trained transformers have drawn increasing attention, especially in multi-modal scenarios. However, the research of multi-modal pre-trained transformers (MPT) for knowledge graph reasoning (KGR) is still at an early stage. As the biggest difference between MKG and other multi-modal data, the rich structural information underlying the MKG is still not fully utilized in previous MPT. Most of them only use the graph structure as a retrieval map for matching images and texts connected with the same entity, which hinders their reasoning performances. To this end, the graph Structure Guided Multi-modal Pre-trained Transformer is proposed for knowledge graph reasoning (SGMPT). Specifically, the graph structure encoder is adopted for structural feature encoding. Then, a structure-guided fusion module with two simple yet effective strategies, i.e., weighted summation and alignment constraint, is designed to inject the structural information into both the textual and visual features. To the best of our knowledge, SGMPT is the first MPT for multi-modal KGR, which mines structural information underlying MKGs. Extensive experiments on FB15k-237-IMG and WN18-IMG, demonstrate that our SGMPT outperforms existing state-of-the-art models, and proves the effectiveness of the designed strategies.},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {1554–1563},
numpages = {10},
keywords = {knowledge graph reasoning, multimodal information fusion, pretrained transformer model},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@inproceedings{10.1145/3627673.3679698,
author = {Li, Lijie and Wang, Hui and Li, Jiahang and Xu, Xiaodi and Wang, Ye and Ren, Tao},
title = {Integrating Structure and Text for Enhancing Hyper-relational Knowledge Graph Representation via Structure Soft Prompt Tuning},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679698},
doi = {10.1145/3627673.3679698},
abstract = {Different from traditional knowledge graphs, where facts are usually represented as (subject, relation, object), hyper-relational knowledge graphs (HKGs) allow facts to be associated with additional relation-entity pairs to constrain the validity of facts. HKGs contain a substantial amount of textual information, which plays a crucial role in enriching representations. However, existing HKG embedding methods mainly rely on structural information but overlook textual information in HKGs, which are less effective in representing entities with limited structural information. To address this issue, the paper proposes HIST (Hyper-relational Knowledge Graph Encoder Integrating Structure and Text), which incorporates textual information and structural information in HKGs to enhance representations of entities and relations. HIST adopts the graph convolutional network to extract structural information and utilizes it to generate the Structure Soft Prompt. During the Structure Soft Prompt Tuning process, the textual information and structural information are fully integrated to generate more comprehensive representations. Additionally, an effective contrastive learning method for HKG embedding is formulated to improve the efficiency of negative sampling. Experimental results show that HIST achieves state-of-the-art performance on several public datasets. Our code is available at https://github.com/QieFangBaiLuQingYaJian/HIST.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {1226–1234},
numpages = {9},
keywords = {hyper-relational knowledge graph, hyper-relational knowledge graph embedding, soft prompt},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@inproceedings{10.1145/3640457.3688171,
author = {Ali, Zafar and Qi, Guilin and Ullah, Irfan and Mohammed, Adam A. Q. and Kefalas, Pavlos and Muhammad, Khan},
title = {GLAMOR: Graph-based LAnguage MOdel embedding for citation Recommendation},
year = {2024},
isbn = {9798400705052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3640457.3688171},
doi = {10.1145/3640457.3688171},
abstract = {Digital publishing’s exponential growth has created vast scholarly collections. Guiding researchers to relevant resources is crucial, and knowledge graphs (KGs) are key tools for unlocking hidden knowledge. However, current methods focus on external links between concepts, ignoring the rich information within individual papers. Challenges like insufficient multi-relational data, name ambiguity, and cold-start issues further limit existing KG-based methods, failing to capture the intricate attributes of diverse entities. To solve these issues, we propose GLAMOR, a robust KG framework encompassing entities e.g., authors, papers, fields of study, and concepts, along with their semantic interconnections. GLAMOR uses a novel random walk-based KG text generation method and then fine-tunes the language model using the generated text. Subsequently, the acquired context-preserving embeddings facilitate superior top@k predictions. Evaluation results on two public benchmark datasets demonstrate our GLAMOR’s superiority against state-of-the-art methods especially in solving the cold-start problem.},
booktitle = {Proceedings of the 18th ACM Conference on Recommender Systems},
pages = {929–933},
numpages = {5},
keywords = {Attributed Graph Embedding, Citation Recommendation, Cold-start, GLAMOR, Large Language Model, Recommender Systems},
location = {Bari, Italy},
series = {RecSys '24}
}

@inproceedings{10.1145/3627673.3679805,
author = {Zhao, Runhao and Tang, Jiuyang and Zeng, Weixin and Chen, Ziyang and Zhao, Xiang},
title = {Zero-shot Knowledge Graph Question Generation via Multi-agent LLMs and Small Models Synthesis},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679805},
doi = {10.1145/3627673.3679805},
abstract = {Knowledge Graph Question Generation (KGQG) is the task of generating natural language questions based on the given knowledge graph (KG). Although extensively explored in recent years, prevailing models predominantly depend on labelled data for training deep learning models or employ large parametric frameworks, e.g., Large Language Models (LLMs), which can incur significant deployment costs and pose practical implementation challenges. To address these issues, in this work, we put forward a zero-shot, multi-agent KGQG framework. This framework integrates the capabilities of LLMs with small models to facilitate cost-effective, high-quality question generation. In specific, we develop a professional editorial team architecture accompanied by two workflow optimization tools to reduce unproductive collaboration among LLMs-based agents and enhance the robustness of the system. Extensive experiments demonstrate that our proposed framework derives the new state-of-the-art performance on the zero-shot KGQG tasks, with relative gains of 20.24% and 13.57% on two KGQG datasets, respectively, which rival fully supervised state-of-the-art models.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {3341–3351},
numpages = {11},
keywords = {large language models, multi-agents framework, zero-shot knowledge graph question generation},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@inproceedings{10.5555/3635637.3663238,
author = {Zhang, Shiyao and Dong, Yuji and Zhang, Yichuan and Payne, Terry R. and Zhang, Jie},
title = {Large Language Model Assissted Multi-Agent Dialogue for Ontology Alignment},
year = {2024},
isbn = {9798400704864},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {Ontology alignment is critical in cross-domain integration; however, it typically necessitates the involvement of a human domain-expert, which can make the task costly. Although a variety of machine-learning approaches have been proposed that can simplify this task by learning the patterns from experts, such techniques are still susceptible to domain knowledge updates that could potentially change the patterns and lead to extra expert involvement. The use of Large Language Models (LLMs) has demonstrated a general cognitive ability, which has the potential to assist ontology alignment from the cognition level, thus obviating the need for costly expert involvement. However, the process by which the output of LLMs is generated can be opaque and thus the reliability and interpretability of such models is not always predictable. This paper proposes a dialogue model, in which multiple agents negotiate the correspondence between two knowledge sets with the support from an LLM. We demonstrate that this approach not only reduces the need for the involvement of a domain expert for ontology alignment, but that the results are interpretable despite the use of LLMs.},
booktitle = {Proceedings of the 23rd International Conference on Autonomous Agents and Multiagent Systems},
pages = {2594–2596},
numpages = {3},
keywords = {dialogue, large language model, multi-agent system, negotiation, ontology alignment},
location = {Auckland, New Zealand},
series = {AAMAS '24}
}

@inproceedings{10.1145/3616855.3635738,
author = {Das, Sudeep and Saboo, Raghav and Vadrevu, Chaitanya S. K. and Wang, Bruce and Xu, Steven},
title = {Applications of LLMs in E-Commerce Search and Product Knowledge Graph: The DoorDash Case Study},
year = {2024},
isbn = {9798400703713},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3616855.3635738},
doi = {10.1145/3616855.3635738},
abstract = {Extracting knowledge from unstructured or semi-structured textual information is essential for the machine learning applications that power DoorDash's search experience, and the development and maintenance of its product knowledge graph. Large language models (LLMs) have opened up new possibilities for utilizing their power in these areas, replacing or complementing traditional natural language processing methods. LLMs are also proving to be useful in the label and annotation generation process, which is critical for these use cases. In this talk, we will provide a high-level overview of how we incorporated LLMs for search relevance and product understanding use cases, as well as the key lessons learned and challenges faced during their practical implementation.},
booktitle = {Proceedings of the 17th ACM International Conference on Web Search and Data Mining},
pages = {1163–1164},
numpages = {2},
keywords = {large language model, natural language processing, product knowledge graph, search},
location = {Merida, Mexico},
series = {WSDM '24}
}

@inproceedings{10.1145/3665689.3665701,
author = {Chang, Xu},
title = {Research on Recommendation Algorithm Based on Knowledge Graph},
year = {2024},
isbn = {9798400716645},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3665689.3665701},
doi = {10.1145/3665689.3665701},
abstract = {In response to issues such as data explosion leading to data overload and a subsequent decrease in the effectiveness of information retrieval, this paper proposes a Knowledge Graph Attention Network Splicing Semantics (KGAT-SS) model based on attention mechanisms. The model combines graph attention networks with a dual-tower model framework, extending the breadth of recommendations through the fusion of entity and text semantics. It enhances the depth of recommendations based on graph attention networks and adds constraints on the weights of transfer nodes in the graph to facilitate more efficient learning of embedded representations in nodes. The model consists of three modules: text processing, graph representation, and prediction. The main contributions include utilizing the pre-trained natural language processing model BERT for vectorizing user and item review texts, GRU encoding for further hidden information exploration, TransR mapping of instances in the dataset to vectors, and knowledge representation through the knowledge graph. The graph representation module employs graph attention networks to differentiate weights between nodes, allowing nodes to assess the importance of received information based on neighboring node weights. A threshold is set during propagation to filter out low-relevance entities. In the prediction layer, multiple representations of entity nodes are concatenated with semantic vectors of user and item texts from the text processing module to obtain the final vector representation. The matching degree is calculated through attention scores. Experimental results indicate that the proposed algorithm outperforms baseline models, leading to an improvement in recommendation effectiveness and enhancing the recommendation performance of the system.},
booktitle = {Proceedings of the 2024 4th International Conference on Bioinformatics and Intelligent Computing},
pages = {66–75},
numpages = {10},
location = {Beijing, China},
series = {BIC '24}
}

@inproceedings{10.1145/3675249.3675256,
author = {Zhou, Qian and Cao, Yanan and Wu, Ruiru and Tang, Jinglei},
title = {Construction of Meteorological Disasters Knowledge Graph Based on Deep Learning},
year = {2024},
isbn = {9798400718267},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3675249.3675256},
doi = {10.1145/3675249.3675256},
abstract = {Under the background of frequent meteorological disasters, the science popularization and decision support of meteorological disasters have snowballs. What's more, the existing meteorological science popularization websites have some defects such as document retrieval, low retrieval efficiency and narrow knowledge coverage. Therefore, this paper builds the meteorological disaster knowledge graph based on deep learning model, which can be applied to the fields of meteorological disaster science popularization and decision support. This paper compares the application effects of several deep learning models in the stage of knowledge acquisition, and adopts the top-down method to build the meteorological disaster knowledge graph. On this basis, the data layer of knowledge graph is constructed from bottom up. At the same time, this paper discusses the application of meteorological disaster knowledge graph in the field of meteorology.},
booktitle = {Proceedings of the 2024 International Conference on Computer and Multimedia Technology},
pages = {37–42},
numpages = {6},
location = {Sanming, China},
series = {ICCMT '24}
}

@article{10.14778/3685800.3685810,
author = {Yi, Peng and Liang, Lei and Zhang, Da and Chen, Yong and Zhu, Jinye and Liu, Xiangyu and Tang, Kun and Chen, Jialin and Lin, Hao and Qiu, Leijie and Zhou, Jun},
title = {KGFabric: A Scalable Knowledge Graph Warehouse for Enterprise Data Interconnection},
year = {2024},
issue_date = {August 2024},
publisher = {VLDB Endowment},
volume = {17},
number = {12},
issn = {2150-8097},
url = {https://doi.org/10.14778/3685800.3685810},
doi = {10.14778/3685800.3685810},
abstract = {Based on the diversified application scenarios at Ant Group, we built the Ant Knowledge Graph Platform (AKGP). It has constructed numerous domain-specific knowledge graphs related to merchants, companies, accounts, products, and more. AKGP manages trillions of structured knowledge graphs, serving search, recommendation, risk control and other businesses. However, as the demand increasing for various workloads such as graph pattern matching, graph representation learning, and cross-domain knowledge reuse, the existing warehouse systems based on relational DBMS or graph databases are unable to meet the requirements. To address these issues, we propose KGFabric, an industrial-scale knowledge graph management system built on the distributed file system (DFS). KGFabric offers a nearline knowledge storage engine that utilizes a Semantic-enhanced Programmable Graph (SPG) model, which is compatible with the Labeled Property Graph (LPG) model. The data is persistently stored in DFS, such as HDFS, which leverages the POSIX file system API, making it suitable for deployment in multi-cloud environment at low cost. KGFabric provides a native graph-based and hybrid storage format that can serve as a shared backend for parallel graph computing systems, significantly accelerating the analysis of multi-workload. Additionally, KGFabric includes a graph fabric framework that minimizes data duplication and guarantees data security.KGFabric is able to manage Peta-scale data and has supported graph fabric and analysis with over 100 billion relations at Ant Group. We conduct experiments on various datasets to evaluate the performance of KGFabric. Compared with popular relational DBMS and graph databases, the storage space for semantic relations is reduced by over 90%. The performance of graph fabric improves by 21\texttimes{} in real-world workloads. In multi-hop semantic graph analysis, KGFabric enhances performance by 100\texttimes{}.},
journal = {Proc. VLDB Endow.},
month = aug,
pages = {3841–3854},
numpages = {14}
}

@inproceedings{10.1145/3626772.3657762,
author = {Yang, Shenghao and Ma, Weizhi and Sun, Peijie and Ai, Qingyao and Liu, Yiqun and Cai, Mingchen and Zhang, Min},
title = {Sequential Recommendation with Latent Relations based on Large Language Model},
year = {2024},
isbn = {9798400704314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626772.3657762},
doi = {10.1145/3626772.3657762},
abstract = {Sequential recommender systems predict items that may interest users by modeling their preferences based on historical interactions. Traditional sequential recommendation methods rely on capturing implicit collaborative filtering signals among items. Recent relation-aware sequential recommendation models have achieved promising performance by explicitly incorporating item relations into the modeling of user historical sequences, where most relations are extracted from knowledge graphs. However, existing methods rely on manually predefined relations and suffer the sparsity issue, limiting the generalization ability in diverse scenarios with varied item relations.In this paper, we propose a novel relation-aware sequential recommendation framework with Latent Lelation Riscovery (LRD). Different from previous relation-aware models that rely on predefined rules, we propose to leverage the Large Language Model (LLM) to provide new types of relations and connections between items. The motivation is that LLM contains abundant world knowledge, which can be adopted to mine latent relations of items for recommendation. Specifically, inspired by that humans can describe relations between items using natural language, LRD harnesses the LLM that has demonstrated human-like knowledge to obtain language knowledge representations of items. These representations are fed into a latent relation discovery module based on the discrete state variational autoencoder (DVAE). Then the self-supervised relation discovery tasks and recommendation tasks are jointly optimized. Experimental results on multiple public datasets demonstrate our proposed latent relation discovery method can be incorporated with existing relation-aware sequential recommendation models and significantly improve the performance. Further analysis experiments indicate the effectiveness and reliability of the discovered latent relations.},
booktitle = {Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {335–344},
numpages = {10},
keywords = {large language model, latent relation, sequential recommendation},
location = {Washington DC, USA},
series = {SIGIR '24}
}

@inproceedings{10.1145/3627673.3680094,
author = {Gubanov, Michael and Pyayt, Anna and Karolak, Aleksandra},
title = {CancerKG.ORG - A Web-scale, Interactive, Verifiable Knowledge Graph-LLM Hybrid for Assisting with Optimal Cancer Treatment and Care},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3680094},
doi = {10.1145/3627673.3680094},
abstract = {Here, we describe one of the first Web-scale hybrid Knowledge Graph (KG)-Large Language Model (LLM), populated with the latest peer-reviewed medical knowledge on colorectal Cancer. It is currently being evaluated to assist with both medical research and clinical information retrieval tasks at Moffitt Cancer Center and Research Institute, which is one of the top Cancer centers in the U.S. and in the world. Our hybrid is remarkable as it serves the user needs better than just an LLM, KG or a search-engine in isolation. LLMs as is are known to exhibit hallucinations and catastrophic forgetting as well as are trained on outdated corpora. The state of the art KGs, such as PrimeKG, cBioPortal, ChEMBL, NCBI, and other require manual curation, hence are quickly getting stale. CancerKG is unsupervised and is capable of automatically ingesting and organizing the latest medical findings. To alleviate the LLMs shortcomings, the verified KG serves as a Retrieval Augmented Generation (RAG) guardrail. CancerKG exhibits 5 different advanced user interfaces, each tailored to serve different data modalities better and more convenient for the user. We evaluated CancerKG on real user queries and report a high NDCG score on a large-scale corpora of approximately 44K publications.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {4497–4505},
numpages = {9},
keywords = {LLM, artificial intelligence (AI), cancer, data management},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@inproceedings{10.1145/3631700.3665234,
author = {Carta, Salvatore and Giuliani, Alessandro and Manca, Marco Manolo and Piano, Leonardo and Tiddia, Sandro Gabriele},
title = {Towards Zero-shot Knowledge Graph building: Automated Schema Inference},
year = {2024},
isbn = {9798400704666},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3631700.3665234},
doi = {10.1145/3631700.3665234},
abstract = {In the current Digital Transformation scenario, Knowledge Graphs are essential for comprehending, representing, and exploiting complex information in a structured form. The main paradigm in automatically generating proper Knowledge Graphs relies on predefined schemas or ontologies. Such schemas are typically manually constructed, requiring an intensive human effort, and are often sensitive to information loss due to negligence, incomplete analysis, or human subjectivity or inclination. Limiting human bias and the resulting information loss in creating proper Knowledge Graphs is paramount, particularly for user modeling in various sectors, such as education or healthcare. To this end, we propose a novel approach to automatically generating a proper entity schema. The devised methodology combines the language understanding capabilities of LLM with classical machine learning methods such as clustering to properly build an entity schema from a set of documents. This solution eliminates the need for human intervention and fosters a more efficient and comprehensive knowledge representation. The assessment of our proposal concerns adopting a state-of-the-art entity extraction model (UniNER) to estimate the relevance of the extracted entities based on the generated schema. Results confirm the potential of our approach, as we observed a negligible difference between the topic similarity score obtained with the ground truth and with the automatically generated schema (less than 1% on average on three different datasets). Such an outcome confirms that the proposed approach may be valuable in automatically creating an entity schema from a set of documents.},
booktitle = {Adjunct Proceedings of the 32nd ACM Conference on User Modeling, Adaptation and Personalization},
pages = {467–473},
numpages = {7},
keywords = {Large Language Models, Named Entity Recognition, Ontology Learning},
location = {Cagliari, Italy},
series = {UMAP Adjunct '24}
}

@inproceedings{10.1145/3673277.3673306,
author = {Peng, Zhen and Du, Ye and Chen, Qifang and Zheng, Tianshuai},
title = {Research on Knowledge Graph Construction for Smart Grid Cybersecurity},
year = {2024},
isbn = {9798400716959},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3673277.3673306},
doi = {10.1145/3673277.3673306},
abstract = {This paper proposes a construction method for smart grid cybersecurity knowledge graph and solves the difficulty of multilingual entity extraction with a small amount of labeled data. First, the construction method of smart grid cybersecurity knowledge graph is proposed with the multi-source heterogeneous data in the field of electric power cybersecurity collected by subject crawlers. Then, for the problems of insufficient labeled data and language mixing in the electric power cybersecurity domain, a DA-XLMR-BiLSTM-FC-CRF model based on a five-layer architecture is proposed to realize the entity extraction of multilingual unstructured text. Finally, comparative and ablation experiments are designed to prove the effectiveness of the proposed model, and the F1 value of the model reaches 94.04% and the accuracy rate reaches 94.48%.},
booktitle = {Proceedings of the 2024 3rd International Conference on Cryptography, Network Security and Communication Technology},
pages = {164–170},
numpages = {7},
location = {Harbin, China},
series = {CNSCT '24}
}

@inproceedings{10.1145/3627043.3659565,
author = {Petruzzelli, Alessandro and Martina, Alessandro Francesco Maria and Spillo, Giuseppe and Musto, Cataldo and De Gemmis, Marco and Lops, Pasquale and Semeraro, Giovanni},
title = {Improving Transformer-based Sequential Conversational Recommendations through Knowledge Graph Embeddings},
year = {2024},
isbn = {9798400704338},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627043.3659565},
doi = {10.1145/3627043.3659565},
abstract = {Conversational Recommender Systems (CRS) have recently drawn attention due to their capacity of delivering personalized recommendations through multi-turn natural language interactions. In this paper, we fit into this research line and we introduce a Knowledge-Aware Sequential Conversational Recommender System (KASCRS) that exploits transformers and knowledge graph embeddings to provide users with recommendations in a conversational setting. In particular, KASCRS is able to predict a suitable recommendation based on the elements that are mentioned in a conversation between a user and a CRS. To do this, we design a model that: (i) encodes each conversation as a sequence of entities that are mentioned in the dialogue (i.e., items and properties), and (ii) is trained on a cloze task, that is to say, it learns to predict the final element in the sequence - that corresponds to the item to be recommended - based on the information it has previously seen. The model has two main hallmarks: first, we exploit Transformers and self-attention to capture the sequential dependencies that exist among the entities that are mentioned in the training dialogues, in a way similar to session-based recommender systems [25]. Next, we used knowledge graphs (KG) to improve the quality of the representation of the elements mentioned in each sequence. Indeed, we exploit knowledge graph embeddings techniques to pre-train the representation of items and properties, and we fed the input layer of our architecture with the resulting embeddings. In this way, KASCRS integrates both knowledge from the KGs as well as the dependencies and the co-occurrences emerging from conversational data, resulting in a more accurate representation of users and items. Our experiments confirmed this intuition, since KASCRS overcame several state-of-the-art baselines on two different datasets.},
booktitle = {Proceedings of the 32nd ACM Conference on User Modeling, Adaptation and Personalization},
pages = {172–182},
numpages = {11},
keywords = {Conversational Recommendations, Knowledge Graphs, Recommender Systems, Transformers},
location = {Cagliari, Italy},
series = {UMAP '24}
}

@article{10.1145/3635273,
author = {Liu, Jhih-Chen and Chen, Chiao-Ting and Lee, Chi and Huang, Szu-Hao},
title = {Evolving Knowledge Graph Representation Learning with Multiple Attention Strategies for Citation Recommendation System},
year = {2024},
issue_date = {April 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {2},
issn = {2157-6904},
url = {https://doi.org/10.1145/3635273},
doi = {10.1145/3635273},
abstract = {The growing number of publications in the field of artificial intelligence highlights the need for researchers to enhance their efficiency in searching for relevant articles. Most paper recommendation models either rely on simplistic citation relationships among papers or focus on content-based approaches, both of which overlook interactions within academic networks. To address the aforementioned problem, knowledge graph embedding (KGE) methods have been used for citation recommendations because recent research proves that graph representations can effectively improve recommendation model accuracy. However, academic networks are dynamic, leading to changes in the representations of users and items over time. The majority of KGE-based citation recommendations are primarily designed for static graphs, thus failing to capture the evolution of dynamic knowledge graph (DKG) structures. To address these challenges, we introduced the evolving knowledge graph embedding (EKGE) method. In this methodology, evolving knowledge graphs are input into time-series models to learn the patterns of structural evolution. The model has the capability to generate embeddings for each entity at various time points, thereby overcoming limitation of static models that require retraining to acquire embeddings at each specific time point. To enhance the efficiency of feature extraction, we employed a multiple attention strategy. This helped the model find recommendation lists that are closely related to a user’s needs, leading to improved recommendation accuracy. Various experiments conducted on a citation recommendation dataset revealed that the EKGE model exhibits a 1.13% increase in prediction accuracy compared to other KGE methods. Moreover, the model’s accuracy can be further increased by an additional 0.84% through the incorporation of an attention mechanism.},
journal = {ACM Trans. Intell. Syst. Technol.},
month = mar,
articleno = {33},
numpages = {26},
keywords = {Multiple attention strategies, evolving knowledge graph embedding, citation recommendation}
}

@inproceedings{10.1145/3661725.3661733,
author = {Anuyah, Sydney and Chakraborty, Sunandan},
title = {Can Deep Learning Large Language Models be Used to Unravel Knowledge Graph Creation?},
year = {2024},
isbn = {9798400716393},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3661725.3661733},
doi = {10.1145/3661725.3661733},
abstract = {This research focuses on advancing RE methodologies by employing and comparing various NLP models for analyzing medical relationships, particularly concerning Gastroesophageal Reflux Disease (GERD). Leveraging a comprehensive dataset of GERD-related articles from PubMed, the study explores the effectiveness of SpaCy for Named Entity Recognition (NER) and BERT-based models (including Bio-BERT and ELECTRA) for tokenization and deep learning classification tasks. Unique to this study is the extensive comparison across multiple advanced models, providing an insightful evaluation of their performance in terms of precision, recall, F1-score, and accuracy in the context of biomedical text analysis. Significantly, Bio-BERT emerged as the most effective model for this dataset, excelling across all metrics compared to BERT-BASE and ELECTRA. This performance underscores Bio-BERT’s specialized pre-training on biomedical literature. The analysis includes the application of these models in constructing a comprehensive knowledge graph, which consolidates diverse information about GERD. Additionally, the paper presents a critical comparison between SpaCy’s automated annotation and human annotators, utilizing the F-1 score for assessing the reliability of BERT’s RE capabilities.},
booktitle = {Proceedings of the International Conference on Computing, Machine Learning and Data Science},
articleno = {8},
numpages = {6},
keywords = {BERT, Bio-BERT, NER, RE, biomedical NLP., deep learning, knowledge graph, medical text analysis, transformer models},
location = {Singapore, Singapore},
series = {CMLDS '24}
}

@inproceedings{10.1145/3626772.3657706,
author = {Fang, Zhiyu and Lei, Shuai-Long and Zhu, Xiaobin and Yang, Chun and Zhang, Shi-Xue and Yin, Xu-Cheng and Qin, Jingyan},
title = {Transformer-based Reasoning for Learning Evolutionary Chain of Events on Temporal Knowledge Graph},
year = {2024},
isbn = {9798400704314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626772.3657706},
doi = {10.1145/3626772.3657706},
abstract = {Temporal Knowledge Graph (TKG) reasoning often involves completing missing factual elements along the timeline. Although existing methods can learn good embeddings for each factual element in quadruples by integrating temporal information, they often fail to infer the evolution of temporal facts. This is mainly because of (1) insufficiently exploring the internal structure and semantic relationships within individual quadruples and (2) inadequately learning a unified representation of the contextual and temporal correlations among different quadruples. To overcome these limitations, we propose a novel Transformer-based reasoning model (dubbed ECEformer) for TKG to learn the Evolutionary Chain of Events (ECE). Specifically, we unfold the neighborhood subgraph of an entity node in chronological order, forming an evolutionary chain of events as the input for our model. Subsequently, we utilize a Transformer encoder to learn the embeddings of intra-quadruples for ECE. We then craft a mixed-context reasoning module based on the multi-layer perceptron (MLP) to learn the unified representations of inter-quadruples for ECE while accomplishing temporal knowledge reasoning. In addition, to enhance the timeliness of the events, we devise an additional time prediction task to complete effective temporal information within the learned unified representation. Extensive experiments on six benchmark datasets verify the state-of-the-art performance and the effectiveness of our method.},
booktitle = {Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {70–79},
numpages = {10},
keywords = {context information mining, evolutionary chain of event, link prediction, temporal knowledge graph completion},
location = {Washington DC, USA},
series = {SIGIR '24}
}

@article{10.1145/3694979,
author = {Qiu, Jingyi and Song, Aibo and Jin, Jiahui and Chen, Jiaoyan and Zhang, Xinyu and Fang, Xiaolin and Zhang, Tianbo},
title = {Matching Tabular Data to Knowledge Graph with Effective Core Column Set Discovery.},
year = {2024},
issue_date = {November 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {4},
issn = {1559-1131},
url = {https://doi.org/10.1145/3694979},
doi = {10.1145/3694979},
abstract = {Matching tabular data to a knowledge graph (KG) is critical for understanding the semantic column types, column relationships, and entities of a table. Existing matching approaches rely heavily on core columns that represent primary subject entities on which other columns in the table depend. However, discovering these core columns before understanding the table’s semantics is challenging. Most prior works use heuristic rules, such as the leftmost column, to discover a single core column, while an insightful discovery of the core column set that accurately captures the dependencies between columns is often overlooked. To address these challenges, we introduce Dependency-aware Core Column Set Discovery (DaCo), an iterative method that uses a novel rough matching strategy to identify both inter-column dependencies and the core column set. Additionally, DaCo can be seamlessly integrated with pre-trained language models, as proposed in the optimization module. Unlike other methods, DaCo does not require labeled data or contextual information, making it suitable for real-world scenarios. In addition, it can identify multiple core columns within a table, which is common in real-world tables. We conduct experiments on six datasets, including five datasets with single core columns and one dataset with multiple core columns. Our experimental results show that DaCo&nbsp; outperforms existing core column set detection methods, further improving the effectiveness of table understanding tasks.},
journal = {ACM Trans. Web},
month = oct,
articleno = {51},
numpages = {27},
keywords = {Table&nbsp;understanding, core column set, semantic dependency}
}

@article{10.1145/3639472,
author = {Wei, Wanxu and Song, Yitong and Yao, Bin},
title = {Enhancing Heterogeneous Knowledge Graph Completion with a Novel GAT-based Approach},
year = {2024},
issue_date = {May 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {4},
issn = {1556-4681},
url = {https://doi.org/10.1145/3639472},
doi = {10.1145/3639472},
abstract = {Knowledge graphs (KGs) play a vital role in enhancing search results and recommendation systems. With the rapid increase in the size of KGs, they are becoming inaccurate and incomplete. This problem can be solved by the KG completion methods, of which graph attention network (GAT)-based methods stand out because of their superior performance. However, existing GAT-based KG completion methods often suffer from overfitting issues when dealing with heterogeneous KGs, primarily due to the unbalanced number of samples. Additionally, these methods demonstrate poor performance in predicting the tail (head) entity that shares the same relation and head (tail) entity with others. To solve these problems, we propose GATH, a novel GAT-based method designed for Heterogeneous KGs. GATH incorporates two separate attention network modules that work synergistically to predict the missing entities. We also introduce novel encoding and feature transformation approaches, enabling the robust performance of GATH in scenarios with imbalanced samples. Comprehensive experiments are conducted to evaluate GATH’s performance. Compared with the existing state-of-the-art GAT-based model on Hits@10 and MRR metrics, our model improves performance by 5.2% and 5.2% on the FB15K-237 dataset and by 4.5% and 14.6% on the WN18RR dataset, respectively.},
journal = {ACM Trans. Knowl. Discov. Data},
month = feb,
articleno = {104},
numpages = {20},
keywords = {Knowledge graph completion, graph attention network, attention mechanism}
}

@inproceedings{10.1145/3652628.3652718,
author = {Zheng, Jianlong and Yu, Yan and Xiong, Xi},
title = {Joint Learning Framework of Semantics and Knowledge Graph Reasoning},
year = {2024},
isbn = {9798400708831},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652628.3652718},
doi = {10.1145/3652628.3652718},
abstract = {The existing embedded Knowledge Graph Question Answering (KGQA) methods based on relationship chain reasoning primarily rely on explicit relationship chains in natural language questions and implicit relationship chains in the knowledge graph (KG) for reasoning. However, these methods overlook the semantic contributions of entity semantics and question context to the relationship chain, merely focusing on the order of relationships within the chain. To address this limitation, a joint learning model is proposed that incorporates both text and KG reasoning using the Graph Attention Network (GAT). In this approach, the semantics of entities are integrated into the reasoning process of multi-hop KGQA, thereby enhancing the semantic expression within the relationship chain. Additionally, a fusion of the question context with the KG is performed to achieve a comprehensive understanding of the abundant semantic information contained in the question. The experimental results, obtained from three benchmark datasets, clearly demonstrate the significant superiority of the proposed model over the previous state-of-the-art methods, including GraftNet, EmbedKGQA, and Rce-KGQA. This validation verifies that the integration of question context and entity semantics effectively enhances the expression ability of incomplete KGs, leading to improved KGQA performance.},
booktitle = {Proceedings of the 4th International Conference on Artificial Intelligence and Computer Engineering},
pages = {535–541},
numpages = {7},
location = {Dalian, China},
series = {ICAICE '23}
}

@article{10.1109/TASLP.2024.3407575,
author = {Chen, Weize and Han, Xu and Lin, Yankai and He, Kaichen and Xie, Ruobing and Zhou, Jie and Liu, Zhiyuan and Sun, Maosong},
title = {Hyperbolic Pre-Trained Language Model},
year = {2024},
issue_date = {2024},
publisher = {IEEE Press},
volume = {32},
issn = {2329-9290},
url = {https://doi.org/10.1109/TASLP.2024.3407575},
doi = {10.1109/TASLP.2024.3407575},
abstract = {In recent years, we have witnessed significant improvements in pre-trained language models (PLM) brought about by the scaling of parameter sizes and data amounts. However, this also brings high computational and storage costs. In this paper, we present a new direction to improve PLMs without scaling parameters and data: adopting a geometric feature space that is more suitable for encoding the intrinsic structured features of text. Although text is generally considered unstructured data, it possesses rich intrinsic structured features that signify syntactic and semantic relationships. Leveraging these structured features is vital for text understanding. Given that structured features are better encoded in hyperbolic spaces than in the Euclidean spaces used by conventional PLMs, we propose that PLMs should operate entirely within hyperbolic spaces. Our experiments demonstrate the superiority of hyperbolic PLMs over Euclidean PLMs across a wide variety of tasks, using the same parameter and data settings. This suggests that altering the geometry of model representation is a promising direction for model enhancement.},
journal = {IEEE/ACM Trans. Audio, Speech and Lang. Proc.},
month = may,
pages = {3101–3112},
numpages = {12}
}

@inproceedings{10.1145/3677779.3677800,
author = {Xie, Yijie},
title = {Temporal Knowledge Graph Completion based on Historical Constraints and Contemporaneous Subgraphs},
year = {2024},
isbn = {9798400709760},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3677779.3677800},
doi = {10.1145/3677779.3677800},
abstract = {Temporal knowledge graph (TKG) can model entities and relations in the real world in the time dimension. However, due to the problem of incomplete information in TKGs, research on TKG completion techniques is needed. Most TKG completion methods heavily rely on the repetitive appearance of historical entities, which poses a challenge for completing entities in the same period. Therefore, we propose a TKG completion model based on historical constraints and contemporaneous subgraphs, named HC-TKGC. HC-TKGC divides candidate entities into historical entities, non-historical entities, and contemporaneous entities, and learns distribution vectors for different types of entities. It also adjusts the final candidate entity scores by using a binary classifier based on external knowledge to determine the historical visibility of candidate entities. We evaluate our proposed model on three datasets. The results show that HC-TKGC outperforms baseline models in most metrics, demonstrating the effectiveness of the model in TKG completion tasks.},
booktitle = {Proceedings of the International Conference on Modeling, Natural Language Processing and Machine Learning},
pages = {128–132},
numpages = {5},
location = {Xi'an, China},
series = {CMNM '24}
}

@inproceedings{10.1145/3589335.3651247,
author = {Bernard, Nolwenn and Kostric, Ivica and \L{}ajewska, Weronika and Balog, Krisztian and Galus\v{c}\'{a}kov\'{a}, Petra and Setty, Vinay and Skj\ae{}veland, Martin G.},
title = {PKG API: A Tool for Personal Knowledge Graph Management},
year = {2024},
isbn = {9798400701726},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589335.3651247},
doi = {10.1145/3589335.3651247},
abstract = {Personal knowledge graphs (PKGs) offer individuals a way to store and consolidate their fragmented personal data in a central place, improving service personalization while maintaining full user control. Despite their potential, practical PKG implementations with user-friendly interfaces remain scarce. This work addresses this gap by proposing a complete solution to represent, manage, and interface with PKGs. Our approach includes (1) a user-facing PKG Client, enabling end-users to administer their personal data easily via natural language statements, and (2) a service-oriented PKG API. To tackle the complexity of representing these statements within a PKG, we present an RDF-based PKG vocabulary that supports this, along with properties for access rights and provenance.},
booktitle = {Companion Proceedings of the ACM Web Conference 2024},
pages = {1051–1054},
numpages = {4},
keywords = {knowledge representation, personal data management, personal knowledge graphs, semantic technologies},
location = {Singapore, Singapore},
series = {WWW '24}
}

@article{10.1145/3657305,
author = {Wu, Ling-I and Su, Yuxin and Li, Guoqiang},
title = {Zero-Shot Construction of Chinese Medical Knowledge Graph with GPT-3.5-turbo and GPT-4},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {2158-656X},
url = {https://doi.org/10.1145/3657305},
doi = {10.1145/3657305},
abstract = {Knowledge graphs have revolutionized the organization and retrieval of real-world knowledge, prompting interest in automatic NLP-based approaches for extracting medical knowledge from texts. However, the availability of high-quality Chinese medical knowledge remains limited, posing challenges for constructing Chinese medical knowledge graphs. As LLMs like ChatGPT show promise in zero-shot learning for many NLP downstream tasks, their potential on constructing Chinese medical knowledge graphs is still uncertain. In this study, we create a Chinese medical knowledge graph by manually annotating textual data and using ChatGPT to automatically generate the graph. We refine the results using filtering and mapping rules to align with our schema. The manually generated graph serves as the ground truth for evaluation, and we explore different methods to enhance its accuracy through knowledge graph completion techniques. As a result, we emphasize the potential of employing ChatGPT for automated knowledge graph construction within the Chinese medical domain. While ChatGPT successfully identifies a larger number of entities, further enhancements are required to improve its performance in extracting more qualified relations.},
note = {Just Accepted},
journal = {ACM Trans. Manage. Inf. Syst.},
month = apr,
keywords = {Medical knowledge graph, ChatGPT, Nature language processing, Named entity recognition, Relation extraction}
}

@inproceedings{10.1145/3660043.3660119,
author = {Chang, Xiaoyu and Liu, Yong and Huang, Liang and Li, Jianbin and Liang, Yin and Li, Shike and Sun, Yifan},
title = {Blockchain Threat Intelligence Knowledge Graph Alignment via Graph Convolutional Networks},
year = {2024},
isbn = {9798400716157},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3660043.3660119},
doi = {10.1145/3660043.3660119},
abstract = {The escalating prevalence of security incidents in the blockchain sphere is posing sig- nificant challenges to its future development. The integration of knowledge graphs into blockchain security is being investigated as a potential solution to offer a com- prehensive view of the blockchain security landscape. Despite the promise, the di- versity and subpar quality of existing blockchain threat intelligence data complicate the use of knowledge graphs for representing this information. The paper proposes the use of knowledge graph fusion, particularly focusing on entity alignment and en- tity linking, as an innovative approach to reconcile knowledge graphs of blockchain threat intelligence from disparate sources. Additionally, it utilizes GCN to model the structural information and an improved TransE to model the attribute information. By combining both representations, the accuracy of blockchain threat intelligence knowledge graph alignment is significantly improved.},
booktitle = {Proceedings of the 2023 International Conference on Information Education and Artificial Intelligence},
pages = {421–430},
numpages = {10},
location = {Xiamen, China},
series = {ICIEAI '23}
}

@inproceedings{10.1145/3674225.3674332,
author = {Xin, Rui and Zhang, Pengfei and Chen, Xi and Peng, Jiao and Liu, Haifeng},
title = {Knowledge Graph Question-Answering Based on Link Reasoning for Electrical Equipment},
year = {2024},
isbn = {9798400716638},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3674225.3674332},
doi = {10.1145/3674225.3674332},
abstract = {The construction of an intelligent question-answering system based on a knowledge graph of electrical equipment can facilitate the complex retrieval, querying, and answering of questions related to electrical equipment knowledge. However, existing knowledge graph question-answering techniques encounter various challenges. Traditional template-based approaches require substantial human effort and time, limiting their scalability. On the other hand, deep learning-based methods demand vast amounts of data for model training. To address these issues, this paper establishes a knowledge graph of electrical equipment and creates a question-answering dataset based on this graph. Subsequently, a knowledge graph question-answering method grounded in link reasoning is proposed. Research findings demonstrate that the method presented in this paper outperforms three baseline methods in terms of accuracy on the knowledge graph of electrical equipment.},
booktitle = {Proceedings of the 2024 International Conference on Power Electronics and Artificial Intelligence},
pages = {594–600},
numpages = {7},
location = {Xiamen, China},
series = {PEAI '24}
}

@article{10.1145/3643565,
author = {Rong, Huan and Qian, Minfeng and Ma, Tinghuai and Jin, Di and Sheng, Victor S.},
title = {CoBjeason: Reasoning Covered Object in Image by Multi-Agent Collaboration Based on Informed Knowledge Graph},
year = {2024},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {5},
issn = {1556-4681},
url = {https://doi.org/10.1145/3643565},
doi = {10.1145/3643565},
abstract = {Object detection is a widely studied problem in existing works. However, in this paper, we turn to a more challenging problem of “Covered Object Reasoning”, aimed at reasoning the category label of target object in the given image particularly when it has been totally covered (or invisible). To resolve this problem, we propose CoBjeason to seize the opportunity when visual reasoning meets the knowledge graph, where “empirical cognition” on common visual contexts have been incorporated as knowledge graph to conduct reinforced multi-hop reasoning via two collaborative agents. Such two agents, for one thing, stand at the covered object (or unknown entity) to observe the surrounding visual cues in the given image and gradually select entities and relations from the global gallery-level knowledge graph which contains entity-pairs frequently occurring across the entire image-collection, so as to infer the main structure of image-level knowledge graph forward expanded from the unknown entity. In turn, for another, based on the reasoned image-level knowledge graph, the semantic context among entities will be aggregated backward into unknown entity to select an appropriate entity from the global gallery-level knowledge graph as the reasoning result. Moreover, such two agents will collaborate with each other, securing that the above Forward &amp; Backward Reasoning will step towards the same destination of the higher performance on covered object reasoning. To our best knowledge, this is the first work on Covered Object Reasoning with Knowledge Graphs and reinforced Multi-Agent collaboration. Particularly, our study on Covered Object Reasoning and the proposed model CoBjeason could offer novel insights into more basic Computer Vision (CV) tasks, such as Semantic Segmentation with better understanding on the current scene when some objects are blurred or covered, Visual Question Answering with enhancement on the inference in more complicated visual context when some objects are covered or invisible, and Image Caption Generation with the augmentation on the richness of visual context for images containing partially visible objects. The improvement on the above basic CV tasks can further refine more complicated ones involved with nuanced visual interpretation like Autonomous Driving, where the recognition and reasoning on partially visible or covered object are critical. According to the experimental results, our proposed CoBjeason can achieve the best overall ranking performance on covered object reasoning compared with other models, meanwhile enjoying the advantage of lower “exploration cost”, with the insensitivity against the long-tail covered objects and the acceptable time complexity.},
journal = {ACM Trans. Knowl. Discov. Data},
month = feb,
articleno = {116},
numpages = {56},
keywords = {Covered object reasoning, visual reasoning, multi-hop knowledge graph reasoning, multi-agent reinforcement learning}
}

@inproceedings{10.1145/3589335.3651557,
author = {Venkatakrishnan, Radhakrishnan and Tanyildizi, Emrah and Canbaz, M. Abdullah},
title = {Semantic interlinking of Immigration Data using LLMs for Knowledge Graph Construction},
year = {2024},
isbn = {9798400701726},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589335.3651557},
doi = {10.1145/3589335.3651557},
abstract = {The challenge of managing immigration data is exacerbated by its reliance on paper-based, evidence-driven records maintained by legal professionals, creating obstacles for efficient processing and analysis due to inherent trust issues with AI-based systems. This paper introduces a cutting-edge framework to surmount these hurdles by synergizing Large Language Models (LLMs) with Knowledge Graphs (KGs), revolutionizing traditional data handling methods. Our method transforms archaic, paper-based immigration records into a structured, interconnected knowledge network that intricately mirrors the legal and procedural nuances of immigration, ensuring a dynamic and trustworthy platform for data analysis. Utilizing LLMs, we extract vital entities and relationships from diverse legal documents to forge a comprehensive knowledge graph, encapsulating the complex legalities and procedural disparities in immigration processes and mapping the multifaceted interactions among stakeholders like applicants, sponsors, and legal experts. This graph not only facilitates a deep dive into the legal stipulations but also incorporates them, significantly boosting the system's reliability and precision. With the integration of Retrieval Augmented Generation (RAG) for exact, context-aware data retrieval and Augmented Knowledge Creation for developing a conversational interface via LLMs, our framework offers a scalable, adaptable solution to immigration data management. This innovative amalgamation of LLMs, KGs, and RAG techniques marks a paradigm shift towards more informed, efficient, and trustworthy decision-making in the sphere of global migration, setting a new benchmark for legal technology and data source management.},
booktitle = {Companion Proceedings of the ACM Web Conference 2024},
pages = {605–608},
numpages = {4},
keywords = {data restructuring, document processing, information retrieval, knowledge graphs, large language models, legal tech},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3691720.3691779,
author = {Liu, Qingqing and Wang, Zhiguo and Yang, Qiping},
title = {KGBL: A Study on the Design of a Knowledge Graph-based Blended Learning Framework},
year = {2024},
isbn = {9798400710230},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691720.3691779},
doi = {10.1145/3691720.3691779},
abstract = {Blended learning has emerged as a significant trend in global higher education due to its flexible and personalized characteristics. From the literature, it can be observed that almost every case of blended teaching practice presents a blended teaching design model. This indicates a lack of a universal framework for blended learning. Additionally, the emergence of the Knowledge Graph has introduced new challenges to traditional blended learning scenarios. Faced with these challenges, this study aims to utilize knowledge graphs to develop a generic framework for blended learning through a literature research approach. A review of the literature revealed that knowledge graphs in the field of education are micro-classes with learning resources. Based on this, a general process for constructing knowledge graphs was proposed with the use of MOOC platform. The constructed knowledge graph serves as the foundation for the Knowledge Graph Blended Learning framework. The online component implements an adaptive learning cycle based on the knowledge graph, while the offline component facilitates students' deep learning. In future related research, the Knowledge Graph Blended Learning framework can be used to guide the practice of blended learning and further expand and deepen it in terms of personalized and accurate teaching decision-making and whole-process enhancement of process evaluation.},
booktitle = {Proceedings of the 2nd International Conference on Educational Knowledge and Informatization},
pages = {343–350},
numpages = {8},
location = {Shanghai, China},
series = {EKI '24}
}

@inproceedings{10.1145/3589334.3645676,
author = {Zamiri, Mona and Qiang, Yao and Nikolaev, Fedor and Zhu, Dongxiao and Kotov, Alexander},
title = {Benchmark and Neural Architecture for Conversational Entity Retrieval from a Knowledge Graph},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3645676},
doi = {10.1145/3589334.3645676},
abstract = {This paper introduces a novel information retrieval (IR) task of Conversational Entity Retrieval from a Knowledge Graph (CER-KG), which extends non-conversational entity retrieval from a knowledge graph (KG) to the conversational scenario. The user queries in CER-KG dialog turns may rely on the results of the preceding turns, which are KG entities. Similar to the conversational document IR, CER-KG can be viewed as a sequence of interrelated ranking tasks. To enable future research on CER-KG, we created QBLink-KG, a publicly available benchmark that was adapted from QBLink, a benchmark for text-based conversational reading comprehension of Wikipedia. As an initial approach to CER-KG, we experimented with Transformer- and LSTM-based query encoders in combination with the Neural Architecture for Conversational Entity Retrieval (NACER), our proposed feature-based neural architecture for entity ranking in CER-KG. NACER computes the ranking score of a candidate KG entity by taking into account diverse lexical and semantic matching signals between various KG components in its neighborhood, such as entities, categories, and literals, as well as entities in the results of the preceding turns in dialog history. The reported experimental results reveal the key challenges of CER-KG along with the possible directions for new approaches to this task.},
booktitle = {Proceedings of the ACM Web Conference 2024},
pages = {1519–1528},
numpages = {10},
keywords = {conversational ir, deep learning, entity retrieval, ir benchmarks, knowledge graphs},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3637528.3671745,
author = {Komarlu, Tanay and Jiang, Minhao and Wang, Xuan and Han, Jiawei},
title = {OntoType: Ontology-Guided and Pre-Trained Language Model Assisted Fine-Grained Entity Typing},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671745},
doi = {10.1145/3637528.3671745},
abstract = {Fine-grained entity typing (FET), which assigns entities in text with context-sensitive, fine-grained semantic types, is a basic but important task for knowledge extraction from unstructured text. FET has been studied extensively in natural language processing and typically relies on human-annotated corpora for training, which is costly and difficult to scale. Recent studies explore the utilization of pre-trained language models (PLMs) as a knowledge base to generate rich and context-aware weak supervision for FET. However, a PLM still requires direction and guidance to serve as a knowledge base as they often generate a mixture of rough and fine-grained types, or tokens unsuitable for typing. In this study, we vision that an ontology provides a semantics-rich, hierarchical structure, which will help select the best results generated by multiple PLM models and head words. Specifically, we propose a novel annotation-free, ontology-guided FET method, OntoType, which follows a type ontological structure, from coarse to fine, ensembles multiple PLM prompting results to generate a set of type candidates, and refines its type resolution, under the local context with a natural language inference model. Our experiments on the Ontonotes, FIGER, and NYT datasets using their associated ontological structures demonstrate that our method outperforms the state-of-the-art zero-shot fine-grained entity typing methods as well as a typical LLM method, ChatGPT. Our error analysis shows that refinement of the existing ontology structures will further improve fine-grained entity typing.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {1407–1417},
numpages = {11},
keywords = {fine-grained entity typing, masked language model prompting, natural language understanding, zero-shot entity typing},
location = {Barcelona, Spain},
series = {KDD '24}
}

@inproceedings{10.1145/3652628.3652766,
author = {Liu, Yuxin and Yu, Jianhui and Jia, Wenyang and Liu, Yuliang},
title = {TCM Automatic Diagnosis System Based on Knowledge Graph and BERT},
year = {2024},
isbn = {9798400708831},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652628.3652766},
doi = {10.1145/3652628.3652766},
abstract = {Artificial intelligence technology has provided significant benefits to Traditional Chinese Medicine (TCM) diagnosis. In this paper, we build a TCM automatic system utilizing knowledge graphs and natural language processing. We first train a standard word alignment model by fine-tuning the Bidirectional Encoder Representations from Transformers (BERT) based model to help nonstandard input align to standard text. Then we propose an algorithm for calculating the recommended score for each prescription in the knowledge graph, thereby obtaining the recommended results for a given set of patient symptoms. To evaluate the effectiveness of our system, we conducted experiments using our TCM diagnosis dataset. The results demonstrate that our system has the potential to be a traditional Chinese medicine AI assistant with low computing resource consumption and high accuracy.},
booktitle = {Proceedings of the 4th International Conference on Artificial Intelligence and Computer Engineering},
pages = {829–834},
numpages = {6},
location = {Dalian, China},
series = {ICAICE '23}
}

@inproceedings{10.1145/3639856.3639872,
author = {Khatun, Rabina and Sinhababu, Nilanjan},
title = {Improved Sequence Predictions using Knowledge Graph Embedding for Large Language Models},
year = {2024},
isbn = {9798400716492},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639856.3639872},
doi = {10.1145/3639856.3639872},
abstract = {Large Language Models (LLM) have gained huge popularity recently due to their problem-solving capability in multiple domains. Technically LLMs can be considered a critical mixture of huge amounts of training data, smart and exhaustive prompt engineering, and word prediction models along with Reinforcement and Supervised learning mechanisms. Word prediction models are at the core of any Large Language Model. The latest word prediction techniques are sequential and transformer models. Transformers have overcome most of the drawbacks of sequential models with similar embedding knowledge. The literature survey shows little to no improvement in the embedding techniques. In this paper, we examined the existing word prediction models by replacing embedding models with an auto-engineered Knowledge Graph Embedding. This auto-engineered data representation shows drastic improvements in prediction quality. This mechanism also accelerates the prediction by providing more context information to the models with respect to the general embedding mechanism. Standard evaluation strategies are used to compare the model behavior.},
booktitle = {Proceedings of the Third International Conference on AI-ML Systems},
articleno = {16},
numpages = {5},
keywords = {attention mechanisms, generative models, neural networks, text prediction},
location = {Bangalore, India},
series = {AIMLSystems '23}
}

@inproceedings{10.1145/3627673.3680020,
author = {Shu, Dong and Zhao, Haoran and Liu, Xukun and Demeter, David and Du, Mengnan and Zhang, Yongfeng},
title = {LawLLM: Law Large Language Model for the US Legal System},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3680020},
doi = {10.1145/3627673.3680020},
abstract = {In the rapidly evolving field of legal analytics, finding relevant cases and accurately predicting judicial outcomes are challenging because of the complexity of legal language, which often includes specialized terminology, complex syntax, and historical context. Moreover, the subtle distinctions between similar and precedent cases require a deep understanding of legal knowledge. Researchers often conflate these concepts, making it difficult to develop specialized techniques to effectively address these nuanced tasks. In this paper, we introduce the Law Large Language Model (LawLLM), a multi-task model specifically designed for the US legal domain to address these challenges. LawLLM excels at Similar Case Retrieval (SCR), Precedent Case Recommendation (PCR), and Legal Judgment Prediction (LJP). By clearly distinguishing between precedent and similar cases, we provide essential clarity, guiding future research in developing specialized strategies for these tasks. We propose customized data preprocessing techniques for each task that transform raw legal data into a trainable format. Furthermore, we also use techniques such as in-context learning (ICL) and advanced information retrieval methods in LawLLM. The evaluation results demonstrate that LawLLM consistently outperforms existing baselines in both zero-shot and few-shot scenarios, offering unparalleled multi-task capabilities and filling critical gaps in the legal domain. Code and data are available at https://github.com/Tizzzzy/Law_LLM.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {4882–4889},
numpages = {8},
keywords = {large language models, legal system, multitask learning, natural language processing},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@inproceedings{10.1145/3698587.3701359,
author = {Yue, Ling and Xing, Sixue and Chen, Jintai and Fu, Tianfan},
title = {ClinicalAgent: Clinical Trial Multi-Agent System with Large Language Model-based Reasoning},
year = {2024},
isbn = {9798400713026},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3698587.3701359},
doi = {10.1145/3698587.3701359},
abstract = {Large Language Models (LLMs) and multi-agent systems have shown impressive capabilities in natural language tasks but face challenges in clinical trial applications, primarily due to limited access to external knowledge. Recognizing the potential of advanced clinical trial tools that aggregate and predict based on the latest medical data, we propose an integrated solution to enhance their accessibility and utility. We introduce Clinical Agent System (ClinicalAgent), a clinical multi-agent system designed for clinical trial tasks, leveraging GPT-4, multi-agent architectures, LEAST-TO-MOST, and ReAct reasoning technology. This integration not only boosts LLM performance in clinical contexts but also introduces novel functionalities. The proposed method achieves competitive predictive performance in clinical trial outcome prediction (0.7908 PR-AUC), obtaining a 0.3326 improvement over the standard prompt Method. Publicly available code can be found at https://github.com/LeoYML/clinical-agent.},
booktitle = {Proceedings of the 15th ACM International Conference on Bioinformatics, Computational Biology and Health Informatics},
articleno = {11},
numpages = {10},
keywords = {Clinical Trial, Clinical Trial Outcome Prediction, Drug Development, Healthcare, Large Language Model-based Reasoning, Large Language Models, Multi-Agent Planning},
location = {Shenzhen, China},
series = {BCB '24}
}

@article{10.1145/3643806,
author = {Cao, Jiahang and Fang, Jinyuan and Meng, Zaiqiao and Liang, Shangsong},
title = {Knowledge Graph Embedding: A Survey from the Perspective of Representation Spaces},
year = {2024},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {56},
number = {6},
issn = {0360-0300},
url = {https://doi.org/10.1145/3643806},
doi = {10.1145/3643806},
abstract = {Knowledge graph embedding (KGE) is an increasingly popular technique that aims to represent entities and relations of knowledge graphs into low-dimensional semantic spaces for a wide spectrum of applications such as link prediction, knowledge reasoning and knowledge completion. In this article, we provide a systematic review of existing KGE techniques based on representation spaces. Particularly, we build a fine-grained classification to categorise the models based on three mathematical perspectives of the representation spaces: (1) algebraic perspective, (2) geometric perspective and (3) analytical perspective. We introduce the rigorous definitions of fundamental mathematical spaces before diving into KGE models and their mathematical properties. We further discuss different KGE methods over the three categories, as well as summarise how spatial advantages work over different embedding needs. By collating the experimental results from downstream tasks, we also explore the advantages of mathematical space in different scenarios and the reasons behind them. We further state some promising research directions from a representation space perspective, with which we hope to inspire researchers to design their KGE models as well as their related applications with more consideration of their mathematical space properties.},
journal = {ACM Comput. Surv.},
month = mar,
articleno = {159},
numpages = {42},
keywords = {Knowledge graphs, representation spaces, embedding techniques, mathematical perspectives}
}

@inproceedings{10.1145/3631908.3631928,
author = {Fan, Jiawei and Ren, Xianghui and Zhang, Hao and Ma, Huisheng and Wei, Xinlei and Yue, Yifeng},
title = {Advanced Attention for Causality Classification of Verb Nodes of Knowledge Graph},
year = {2024},
isbn = {9798400709098},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3631908.3631928},
doi = {10.1145/3631908.3631928},
abstract = {In this paper, the causal relationship between verb nodes in knowledge graph is determined according to the verb nodes and the sentences in which they are located. For the operation of paying attention to the whole sentence, the verb is not studied specifically, which is disadvantageous to the judgment of causality. Therefore, this paper proposes an advanced attention method based on attention mechanism to judge the causality of knowledge graph. It can not only focus on the extraction of verb related information, but also learn the whole sentence features. The experiment verifies the method, and the results show that the method in this paper has advantages.},
booktitle = {Proceedings of the 7th International Conference on Algorithms, Computing and Systems},
pages = {140–144},
numpages = {5},
keywords = {attention, classification, knowledge graphs, verbs},
location = {Larissa, Greece},
series = {ICACS '23}
}

@inproceedings{10.1145/3616855.3635772,
author = {Deng, Cheng and Zhang, Tianhang and He, Zhongmou and Chen, Qiyuan and Shi, Yuanyuan and Xu, Yi and Fu, Luoyi and Zhang, Weinan and Wang, Xinbing and Zhou, Chenghu and Lin, Zhouhan and He, Junxian},
title = {K2: A Foundation Language Model for Geoscience Knowledge Understanding and Utilization},
year = {2024},
isbn = {9798400703713},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3616855.3635772},
doi = {10.1145/3616855.3635772},
abstract = {Large language models (LLMs) have achieved great success in general domains of natural language processing. In this paper, we bring LLMs to the realm of geoscience with the objective of advancing research and applications in this field. To this end, we present the first-ever LLM in geoscience, K2, alongside a suite of resources developed to further promote LLM research within geoscience. For instance, we have curated the first geoscience instruction tuning dataset, GeoSignal, which aims to align LLM responses to geoscience-related user queries. Additionally, we have established the first geoscience benchmark, GeoBench, to evaluate LLMs in the context of geoscience. In this work, we experiment with a complete recipe to adapt a pre-trained general-domain LLM to the geoscience domain. Specifically, we further train the LLaMA-7B model on 5.5B tokens of geoscience text corpus, including over 1 million pieces of geoscience literature, and utilize GeoSignal's supervised data to fine-tune the model. Moreover, we share a protocol that can efficiently gather domain-specific data and construct domain-supervised data, even in situations where manpower is scarce. Meanwhile, we equip K2 with the abilities of using tools to be a naive geoscience aide. Experiments conducted on the GeoBench demonstrate the effectiveness of our approach and datasets on geoscience knowledge understanding and utilization.We open-source all the training data and K2 model checkpoints at https://github.com/davendw49/k2},
booktitle = {Proceedings of the 17th ACM International Conference on Web Search and Data Mining},
pages = {161–170},
numpages = {10},
keywords = {foundation model, geoscience knowledge mining, geoscience large language model},
location = {Merida, Mexico},
series = {WSDM '24}
}

@article{10.1145/3643745,
author = {Zan, Daoguang and Yu, Ailun and Shen, Bo and Chen, Bei and Li, Wei and Gong, Yongshun and Chen, Xiaolin and Yao, Yafen and Luo, Weihua and Guan, Bei and Liu, Yan and Wang, Yongji and Wang, Qianxiang and Cui, Lizhen},
title = {DiffCoder: Enhancing Large Language Model on API Invocation via Analogical Code Exercises},
year = {2024},
issue_date = {July 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {FSE},
url = {https://doi.org/10.1145/3643745},
doi = {10.1145/3643745},
abstract = {The task of code generation aims to generate code solutions based on given programming problems. Recently, code large language models (code LLMs) have shed new light on this task, owing to their formidable code generation capabilities. While these models are powerful, they seldom focus on further improving the accuracy of library-oriented API invocation. Nonetheless, programmers frequently invoke APIs in routine coding tasks. In this paper, we aim to enhance the proficiency of existing code LLMs regarding API invocation by mimicking analogical learning, which is a critical learning strategy for humans to learn through differences among multiple instances. Motivated by this, we propose a simple yet effective approach, namely DiffCoder, which excels in API invocation by effectively training on the differences (diffs) between analogical code exercises. To assess the API invocation capabilities of code LLMs, we conduct experiments on seven existing benchmarks that focus on mono-library API invocation. Additionally, we construct a new benchmark, namely PanNumEval, to evaluate the performance of multi-library API invocation. Extensive experiments on eight benchmarks demonstrate the impressive performance of DiffCoder. Furthermore, we develop a VSCode plugin for DiffCoder, and the results from twelve invited participants further verify the practicality of DiffCoder.},
journal = {Proc. ACM Softw. Eng.},
month = jul,
articleno = {19},
numpages = {21},
keywords = {Code Generation, Code Library, Instruction Tuning, Large Language Model}
}

@article{10.1109/TASLP.2024.3485500,
author = {Li, Pengfei and Zhou, Guangyou and Xie, Zhiwen and Xie, Penghui and Huang, Jimmy Xiangji},
title = {Learning Dynamic and Static Representations for Extrapolation-Based Temporal Knowledge Graph Reasoning},
year = {2024},
issue_date = {2024},
publisher = {IEEE Press},
volume = {32},
issn = {2329-9290},
url = {https://doi.org/10.1109/TASLP.2024.3485500},
doi = {10.1109/TASLP.2024.3485500},
abstract = {Temporal knowledge graph reasoning aims to predict the missing links (facts) in the future timestamps. However, most existing methods have a common limitation: they focus on learning dynamic representations of temporal knowledge graphs and rarely consider static characteristics that remain unchanged over time. To address the above issues, we propose to learn the dynamic and static representations for temporal knowledge graph reasoning (DSTKG), which introduces two latent variables to capture the dynamic and static characteristics of entities in temporal knowledge graphs. First, we use a Bi-GRU-based inference network to learn the static latent representation of historical facts and a nonlinear discrete-time transition-based inference network to learn the dynamic latent representation. Then, we sample the latent variables multiple times using re-parameterization tricks to obtain high-quality embeddings and make predictions in the future timestamps. The empirical results on four benchmark datasets show that our model is more effective than state-of-the-art approaches. Compared with the strong baseline model DBKGE (RotatE), the proposed model achieves performance improvements of 2.69%, &lt;inline-formula&gt;&lt;tex-math notation="LaTeX"&gt;$1.59%$&lt;/tex-math&gt;&lt;/inline-formula&gt;, 1.18% and 1.22% on Yago11k, Wikidata12k, ICEWS14 and ICEWS05-15 respectively, regarding the evaluation metric MRR.},
journal = {IEEE/ACM Trans. Audio, Speech and Lang. Proc.},
month = oct,
pages = {4741–4754},
numpages = {14}
}

@inproceedings{10.1145/3689218.3689222,
author = {Zhao, Jinxiong and Ma, Zhicheng and Zhao, Hong and Zhang, Xun and Liu, Qichuan and Peng, Xinjie and Zhang, Gefei},
title = {Power Large Language Model Exploration: Activation, Measurement and Enhancement for Operations and Maintenance Knowledge: Activation, Measurement and Enhancement for Power O&amp;M Knowledge},
year = {2024},
isbn = {9798400718250},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689218.3689222},
doi = {10.1145/3689218.3689222},
abstract = {With the rapid advancement of Large Language Models, their applications are gradually transitioning from general to specific domains. However, the application of LLM in the electric power domain is still in its early stages, and few studies have explored power LLM. Currently, there are two main challenges against power LLMs: (1) determining how to measure the real power knowledge capacity of LLMs to facilitate targeted enhancement of specific knowledge. (2) identifying practical enhancement methods to facilitate efficient and feasible power LLM applications in real-world scenarios. In this paper, we ask three insightful questions that address the power knowledge capacity of LLMs and then draw inspiration from Reflexion and CoT to design an Activation, Measurement and Enhancement framework (AME) for power operations and maintenance (O&amp;M) knowledge. Specifically, we ask three “HOW” questions based on the activation, measurement, and enhancement of power O&amp;M knowledge. We introduce a Reflexion Module to discover the knowledge capacity of LLM and a Knowledge Graph Module to provide external knowledge of LLM in our proposed AME. Experiments on the real-world dataset provide strong evidence when we answer the above three insightful questions.},
booktitle = {Proceedings of the 2024 6th International Conference on Pattern Recognition and Intelligent Systems},
pages = {1–7},
numpages = {7},
keywords = {Power Large Language Model, Power Operations and Maintenance, Practical Knowledge Graph, Reflexion},
location = {Hong Kong, Hong Kong},
series = {PRIS '24}
}

@inproceedings{10.1145/3589334.3645720,
author = {Jiang, Xuhui and Xu, Chengjin and Shen, Yinghan and Wang, Yuanzhuo and Su, Fenglong and Shi, Zhichao and Sun, Fei and Li, Zixuan and Guo, Jian and Shen, Huawei},
title = {Toward Practical Entity Alignment Method Design: Insights from New Highly Heterogeneous Knowledge Graph Datasets},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3645720},
doi = {10.1145/3589334.3645720},
abstract = {The flourishing of knowledge graph (KG) applications has driven the need for entity alignment (EA) across KGs. However, the heterogeneity of practical KGs, characterized by differing scales, structures, and limited overlapping entities, greatly surpasses that of existing EA datasets. This discrepancy highlights an oversimplified heterogeneity in current EA datasets, which obstructs the exploration of the EA application. In this paper, we study the performance of EA methods on the alignment of highly heterogeneous KGs (HHKGs). Firstly, we address the oversimplified heterogeneity settings of current datasets and propose two new HHKG datasets that closely mimic practical EA scenarios. Then, based on these datasets, we conduct extensive experiments to evaluate previous representative EA methods. Our findings reveal that, in aligning HHKGs, valuable structure information can hardly be exploited, which leads to inferior performance of existing EA methods, especially those based on GNNs. These findings shed light on the potential problems associated with the conventional application of GNN-based methods as a panacea for all EA datasets. Consequently, to elucidate what EA methodology is genuinely beneficial in practical scenarios, we undertake an in-depth analysis by implementing a simple but effective approach: Simple-HHEA. Our experiment results conclude that the key to the future EA model design in practice lies in their adaptability and efficiency to varying information quality conditions, as well as their capability to capture patterns across HHKGs. The datasets and source code are available at https://github.com/IDEA-FinAI/Simple-HHEA.},
booktitle = {Proceedings of the ACM Web Conference 2024},
pages = {2325–2336},
numpages = {12},
keywords = {entity alignment, graph neural networks, knowledge graphs},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3672758.3672845,
author = {Guo, Yingqi and Zhao, Ying and Wang, Bo},
title = {A method integrating enhanced hinge loss function for few-shot knowledge graph completion},
year = {2024},
isbn = {9798400716942},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3672758.3672845},
doi = {10.1145/3672758.3672845},
abstract = {Few-shot knowledge graph completion (FKGC) is a fundamental task to supply missing triples for knowledge graphs. Many recently proposed few-shot relational learning methods exhibit excellent performance. However, they rely solely on the angle-based scoring function that is valid only for some relations. The distance-based scoring function has difficulty adapting to embedding distribution where positive candidates follow a loose distribution embracing the negatives, which is common in the FKGC dataset. Here, we propose a novel approach integrating enhanced hinge loss function for FKGC. It is based on an adaptive Ensemble Learning FrameworK, namely ELFK, which contains two base modules with different types of scoring functions to improve the model's generalization across different relations. Specially, we utilize a modified margin hinge loss function by incorporating an upper bound loss function for the base module with an Euclidean-distance-based scoring function to improve the embedding distribution and reduce the chance that positive candidates are distributed outside the negatives. In addition, two base module are adaptive integrated by a trainable weight learned in an ensemble module. Experiments on the NELL and wiki datasets demonstrate that our approach achieves state-of-the-art performance.},
booktitle = {Proceedings of the 3rd International Conference on Computer, Artificial Intelligence and Control Engineering},
pages = {535–540},
numpages = {6},
location = {Xi' an, China},
series = {CAICE '24}
}

@inproceedings{10.1145/3676288.3676289,
author = {Jamil, Hasan M and Oduro-Afriyie, Joel},
title = {Knowledge Graph Enhancement for Improved Natural Language Health Question Answering using Large Language Models},
year = {2024},
isbn = {9798400710209},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3676288.3676289},
doi = {10.1145/3676288.3676289},
abstract = {In this paper we present a method for enhancing Question Answering (QA) systems by iteratively improving Knowledge Graphs (KGs) with a focus on maintaining monotonicity in the enhancement process. We introduce a mathematical framework employing functions τ and ϕ, where τ transforms text T into a KG K, and ϕ generates an answer from T for a given question. We propose that augmenting K with domain-specific information, denoted as ΔK, leads to a more accurate approximation of the expected answer, adhering to the principle that each enhancement either maintains or improves answer quality. This concept is formalized as ϕ− 1(ϕ(T) ∪ ΔK) yielding better results than ϕ− 1(ϕ(T)). The paper elaborates on this process with practical examples, demonstrating how KG enhancements, under the constraints of monotonicity, lead to successive improvements in the Question Answering (QA) system.},
booktitle = {Proceedings of the 36th International Conference on Scientific and Statistical Database Management},
articleno = {14},
numpages = {4},
keywords = {graph augmentation, knowledge graphs, monotonic answer improvement, natural language processing},
location = {Rennes, France},
series = {SSDBM '24}
}

@inproceedings{10.1145/3650400.3650405,
author = {Wang, Chen and Hua, Min and Song, Jiale and Tang, Xue-song},
title = {Knowledge Graphs Enhanced Large Language Model Prompt for Electric Power Question Answering},
year = {2024},
isbn = {9798400708305},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3650400.3650405},
doi = {10.1145/3650400.3650405},
abstract = {With the continuous development and digital transformation in the field of electric power, the application of large language models in the electric power industry has become a remarkable trend. The electric power industry is an information-intensive domain involving extensive data processing, predictive analysis, and decision-making. Therefore, the application of large language models in the electric power sector is of great significance. Current large language models such as GPT3.5 and GLM can perform well in tasks such as question answering dialogues. However, these models still face challenges such as answer hallucination and inaccurate responses. This paper proposes a method to enhance question answering in large language models using knowledge graphs, aiming to improve the accuracy and reliability of these models in question answering tasks in the electric power domain.The proposed method first utilizes local electric power data to extract triplets and generate a question answering dataset specific to the electric power domain using a large language model. Then, the relationships of the knowledge graph triplets are incorporated into the question prompt to enhance the quality of the model's answers. Furthermore, we fine-tune the large language model using the expanded question set derived from the triplets as knowledge enhanced data. Subsequently, we conduct experiments on both an electric power question answering dataset and a knowledge graph question answering dataset. The experimental results demonstrate that our method significantly improves various metrics of the large language model in the electric power question answering task. This research provides new insights and approaches to enhance the effectiveness of question answering systems in the electric power domain. Future studies can further explore and optimize this prompt expansion method for application in broader domains and tasks.},
booktitle = {Proceedings of the 2023 7th International Conference on Electronic Information Technology and Computer Engineering},
pages = {24–29},
numpages = {6},
location = {Xiamen, China},
series = {EITCE '23}
}

@inproceedings{10.1145/3696500.3696523,
author = {He, Yudong and Tang, Yinqiu and Chen, Tianhong},
title = {A Study on Large Language Model-Based Approach for Construction Contract Risk Detection},
year = {2024},
isbn = {9798400710278},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696500.3696523},
doi = {10.1145/3696500.3696523},
abstract = {Construction projects typically involve large-scale operations and are subject to complex external conditions, making it essential to safeguard the interests of contractor enterprises through well-crafted contract clauses. However, the current reliance on expert judgment for identifying contract risks presents several challenges, including lengthy processing times, heavy workloads, and inconsistent results. To address these issues, this study introduces a Large Language Model (LLM)-based approach for automating the identification of risks in construction contracts. The proposed method was rigorously validated on 26 actual contracts, achieving an average accuracy of 76.7% across four state-of-the-art LLMs. This research advances the application of LLMs in construction contract management, providing practical solutions to existing challenges and setting the stage for further exploration in LLM-driven contract analysis.},
booktitle = {Proceedings of the 2024 International Conference on Big Data and Digital Management},
pages = {136–141},
numpages = {6},
location = {Shanghai, China},
series = {ICBDDM '24}
}

@inproceedings{10.1145/3644116.3644179,
author = {Gao, Mingxia and Li, Hao and Chen, Furong},
title = {An Entity Prediction Method for Chinese Medical Knowledge Graph via Bert Sentence Embedding and Classification},
year = {2024},
isbn = {9798400708138},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3644116.3644179},
doi = {10.1145/3644116.3644179},
abstract = {Automatic Knowledge Graph Completion is becoming the main research direction of Knowledge graph construction. Among, the entity prediction method can complete the complement of entities in RDF triples, and is widely used in the generation process of the Knowledge graph. In order to complete the Chinese medical Knowledge graph, this paper proposes an entity prediction method based on BRRT sentence embedding and classification. This method needs three steps, the first step is to introduce a large-scale medical corpus to fine tune the basic BERT model into a BERT Domain model. The second step is obtaining the sentence embedding through the model for candidate triples. The third step is to obtain the top N candidate entity lists according to the ranking of classifier probabilities of all candidate. In order to verify the effectiveness of this method, a series of experiments are conducted on the BIOS. The experimental results show that the optimal accuracy of the entity prediction method in this paper is 20.5%, which is 7.2% higher than that using Word embedding+distance.},
booktitle = {Proceedings of the 2023 4th International Symposium on Artificial Intelligence for Medicine Science},
pages = {376–381},
numpages = {6},
location = {Chengdu, China},
series = {ISAIMS '23}
}

@article{10.1145/3680469,
author = {Huang, Qing and Sun, Yanbang and Xing, Zhenchang and Cao, Yuanlong and Chen, Jieshan and Xu, Xiwei and Jin, Huan and Lu, Jiaxing},
title = {Let’s Discover More API Relations: A Large Language Model-Based AI Chain for Unsupervised API Relation Inference},
year = {2024},
issue_date = {November 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {33},
number = {8},
issn = {1049-331X},
url = {https://doi.org/10.1145/3680469},
doi = {10.1145/3680469},
abstract = {APIs have intricate relations that can be described in text and represented as knowledge graphs to aid software engineering tasks. Existing relation extraction methods have limitations, such as limited API text corpus, and are affected by the characteristics of the input text. To address these limitations, we propose utilizing large language models (LLMs) (e.g., GPT-3.5) as a neural knowledge base for API relation inference. This approach leverages the entire Web used to pre-train LLMs as a knowledge base and is insensitive to the context and complexity of input texts. To ensure accurate inference, we design an AI chain consisting of three AI modules: API Fully Qualified Name (FQN) Parser, API Knowledge Extractor, and API Relation Decider. The accuracy of the API FQN Parser and API Relation Decider is 0.81 and 0.83, respectively. Using the generative capacity of the LLM and our approach’s inference capability, we achieve an average F1 value of 0.76 under the three datasets, significantly higher than the state-of-the-art method’s average F1 value of 0.40. Compared to the original CoT and modularized CoT methods, our AI chain design has improved the performance of API relation inference by 71% and 49%, respectively. Meanwhile, the prompt ensembling strategy enhances the performance of our approach by 32%. The API relations inferred by our method can be further organized into structured forms to provide support for other software engineering tasks.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = dec,
articleno = {212},
numpages = {34},
keywords = {API Relation, AI Chain, Knowledge Inference, Large Language Model}
}

@inproceedings{10.1145/3589335.3651941,
author = {Zhao, Wenting and Deng, Zhongfen and Yadav, Shweta and Yu, Philip S.},
title = {Heterogeneous Knowledge Grounding for Medical Question Answering with Retrieval Augmented Large Language Model},
year = {2024},
isbn = {9798400701726},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589335.3651941},
doi = {10.1145/3589335.3651941},
abstract = {The Large Language Model (LLM) is renowned for its ability to encode a vast amount of general domain knowledge, enabling it to excel in question-answering, dialogue systems, and summarization tasks. However, the medical domain presents a unique challenge to LLM due to the distribution of medical knowledge, which follows a long-tail pattern. Existing approaches address this challenge by injecting medical knowledge into LLM through single sources such as medical textbooks or medical knowledge bases. However, medical knowledge is distributed across multiple heterogeneous information sources. A medical question-answering system can enhance answer coverage and confidence by considering these diverse knowledge sources together. To bridge this gap, we propose a novel approach called Heterogeneous Knowledge Retrieval-Augmented LLM for medical domain question answering. Our experiments, conducted on the MedQA-USMLE dataset, demonstrate promising performance improvements. These results underscore the importance of harnessing heterogeneous knowledge sources in the medical domain.},
booktitle = {Companion Proceedings of the ACM Web Conference 2024},
pages = {1590–1594},
numpages = {5},
keywords = {healthcare, medical question answering, retrieval augmented language models},
location = {Singapore, Singapore},
series = {WWW '24}
}

@article{10.14778/3654621.3654640,
author = {Huo, Nan and Cheng, Reynold and Kao, Ben and Ning, Wentao and Haldar, Nur Al Hasan and Li, Xiaodong and Li, Jinyang and Najafi, Mohammad Matin and Li, Tian and Qu, Ge},
title = {ZeroEA: A Zero-Training Entity Alignment Framework via Pre-Trained Language Model},
year = {2024},
issue_date = {March 2024},
publisher = {VLDB Endowment},
volume = {17},
number = {7},
issn = {2150-8097},
url = {https://doi.org/10.14778/3654621.3654640},
doi = {10.14778/3654621.3654640},
abstract = {Entity alignment (EA), a crucial task in knowledge graph (KG) research, aims to identify equivalent entities across different KGs to support downstream tasks like KG integration, text-to-SQL, and question-answering systems. Given rich semantic information within KGs, pre-trained language models (PLMs) have shown promise in EA tasks due to their exceptional context-aware encoding capabilities. However, the current solutions based on PLMs encounter obstacles such as the need for extensive training, expensive data annotation, and inadequate incorporation of structural information. In this study, we introduce a novel zero-training EA framework, ZeroEA, which effectively captures both semantic and structural information for PLMs. To be specific, Graph2Prompt module serves as the bridge between graph structure and plain text by converting KG topology into textual context suitable for PLM input. Additionally, in order to provide PLMs with concise and clear input text of reasonable length, we design a motif-based neighborhood filter to eliminate noisy neighbors. The comprehensive experiments and analyses on 5 benchmark datasets demonstrate the effectiveness of ZeroEA, outperforming all leading competitors and achieving state-of-the-art performance in entity alignment. Notably, our study highlights the considerable potential of EA technique in improving the performance of downstream tasks, thereby benefitting the broader research field.},
journal = {Proc. VLDB Endow.},
month = mar,
pages = {1765–1774},
numpages = {10}
}

@article{10.1109/TASLP.2024.3375631,
author = {Zhang, Geng and Liu, Jin and Zhou, Guangyou and Zhao, Kunsong and Xie, Zhiwen and Huang, Bo},
title = {Question-Directed Reasoning With Relation-Aware Graph Attention Network for Complex Question Answering Over Knowledge Graph},
year = {2024},
issue_date = {2024},
publisher = {IEEE Press},
volume = {32},
issn = {2329-9290},
url = {https://doi.org/10.1109/TASLP.2024.3375631},
doi = {10.1109/TASLP.2024.3375631},
abstract = {Complex knowledge graph question answering (KGQA) aims at answering natural language questions by entities retrieving from a knowledge graph (KG). Recently, the relation path-based models have shown the unique advantage for complex KGQA. However, these existing models ignore the dependency between different relation paths, which leads to aimless reasoning over the KG. To resolve this issue, we propose the question-directed reasoning with relation-aware graph attention network (QRGAT) that encodes the reasoning process as a reasoning graph. The relation-aware GAT can recognize neighbor entities along with the corresponding relations for each entity. With the relation-aware GAT stacked in multiple layers, it can collaboratively capture the dependency of different relation paths for each entity. The question-directed reasoning utilizes the information learned by the relation-aware GAT to solve the aimless reasoning on the KG by constructing a reasoning graph. Extensive experiments demonstrate that our QRGAT outperforms the baseline models on both popular datasets WebQuestionsSP and ComplexWebQuestions. Compared with the strong GNN-based baseline NSM&lt;inline-formula&gt;&lt;tex-math notation="LaTeX"&gt;$_{+h}$&lt;/tex-math&gt;&lt;/inline-formula&gt;, our QRGAT achieves the performance improvements of 2.3% on WebQuestionsSP and 3.6% on ComplexWebQuestions by the metric Hits@1.},
journal = {IEEE/ACM Trans. Audio, Speech and Lang. Proc.},
month = mar,
pages = {1915–1927},
numpages = {13}
}

@inproceedings{10.1145/3627673.3679963,
author = {Zhang, Feng and Chen, Wei and Ding, Fei and Wang, Tengjiao and Lu, Dawei and Zheng, Jiabin},
title = {Meta-Prompt Tuning Vision-Language Model for Multi-Label Few-Shot Image Recognition},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679963},
doi = {10.1145/3627673.3679963},
abstract = {Multi-label few-shot image recognition aims to identify multiple unseen objects using only a handful of examples. Recent methods typically tune pre-trained vision-language models with shared or class-specific prompts. However, they still have drawbacks. Tuning a shared prompt is insufficient for all samples especially when the tasks are complex and tuning specific prompts for each class is inevitable to lose generalization ability, thus failing to capture diverse visual knowledge. To address these issues, we propose to meta-tune a generalized prompt pool, enabling each prompt to act as an expert for multi-label few-shot image recognition. Specifically, we first construct a diverse prompt pool to handle complex samples and tasks effectively. Then, the meta-tuning strategy is designed to learn meta-knowledge and transfer it from source tasks to target tasks, enhancing the generalization of prompts. Extensive experimental results on two widely used multi-label image recognition datasets demonstrate the effectiveness of our method.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {4258–4262},
numpages = {5},
keywords = {few-shot learning, meta-prompt learning, multi-label image recognition},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@inproceedings{10.1145/3638584.3638635,
author = {Zhou, Yifan and Ding, Yizhou and Dong, Yuwu and He, Hao},
title = {Ontology-Semantic Alignment On Contrastive Video-Language Model for Multimodel Video Retrieval Task},
year = {2024},
isbn = {9798400708688},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3638584.3638635},
doi = {10.1145/3638584.3638635},
abstract = {Contrastive Learning-based models have shown impressive performance in text-image retrieval tasks. However, when applied in video retrieval, traditional contrastive learning strategies have faced challenges in achieving satisfactory results due to redundancy of video contents. We discern several potential reasons: (1)Current methodologies sometimes overlook the significant information imbalance between videos and query text, specifically neglecting the in-depth textual representation of the content within the videos. (2) Current video matching methodologies typically focus on cross-model alignment at general entity similarity level, without specific consideration for how entity pair preferences and similarity properties affect the task at hand. (3) Previous vectorized retrieval based on video content features have been somewhat flawed. They primarily focused on aligning overall features without having an video content tags feature for meaningful feature discrimination. Considering the shortcomings identified in the mentioned three aspects, we propose an ontology semantic labels augments retrieval model and introduce a method to integrate video ontology semantic labels into the contrastive learning framework. In particular, we have developed ontology semantic descriptions about entities encompassing both human figures and textual elements within the videos. Subsequently, we conducted training and testing on the CMIVQA dataset to assess the performance of our approach. The experimental results show that employing fine-grained ontology labels as sample pairs for contrastive learning leads to an increased level of precision in video retrieval tasks.},
booktitle = {Proceedings of the 2023 7th International Conference on Computer Science and Artificial Intelligence},
pages = {408–413},
numpages = {6},
keywords = {Multimodal alignment, Ontology description, Video content understanding},
location = {Beijing, China},
series = {CSAI '23}
}

@article{10.1145/3654987,
author = {Bobed Lisbona, Carlos and Bernad, Jordi and Maillot, Pierre},
title = {Language-Model Based Informed Partition of Databases to Speed Up Pattern Mining},
year = {2024},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {3},
url = {https://doi.org/10.1145/3654987},
doi = {10.1145/3654987},
abstract = {Extracting interesting patterns from data is the main objective of Data Mining. In this context, Frequent Itemset Mining has shown its usefulness in providing insights from transactional databases, which, in turn, can be used to gain insights about the structure of Knowledge Graphs. While there have been a lot of advances in the field, due to the NP-hard nature of the problem, the main approaches still struggle when they are faced with large databases with large and sparse vocabularies, such as the ones obtained from graph propositionalizations. There have been efforts to propose parallel algorithms, but, so far, the goal has not been to tackle this source of complexity (i.e., vocabulary size), thus, in this paper, we propose to parallelize frequent itemset mining algorithms by partitioning the database horizontally (i.e., transaction-wise) while not neglecting all the possible vertical information (i.e., item-wise). Instead of relying on pure item co-appearance metrics, we advocate for the adoption of a different approach: modeling databases as documents, where each transaction is a sentence, and each item a word. In this way, we can apply recent language modeling techniques (i.e., word embeddings) to obtain a continuous representation of the database, clusterize it in different partitions, and apply any mining algorithm to them. We show how our proposal leads to informed partitions with a reduced vocabulary size and a reduced entropy (i.e., disorder). This enhances the scalability, allowing us to speed up mining even in very large databases with sparse vocabularies. We have carried out a thorough experimental evaluation over both synthetic and real datasets showing the benefits of our proposal.},
journal = {Proc. ACM Manag. Data},
month = may,
articleno = {184},
numpages = {27},
keywords = {knowledge graphs, language models, pattern mining}
}

@inproceedings{10.1145/3650400.3650478,
author = {Zhao, Wei and Chen, Qinghui and You, Junling},
title = {LlmRe: A zero-shot entity relation extraction method based on the large language model},
year = {2024},
isbn = {9798400708305},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3650400.3650478},
doi = {10.1145/3650400.3650478},
abstract = {Entity relation extraction aims to extract knowledge triples from unstructured or semi-structured text data and can be applied to various fields, including medicine, finance knowledge graph construction and intelligent question-answering. Traditional entity relation extraction requires a large amount of labeled data, consumes a lot of labor and time, and the trained model lacks generalization ability, which is difficult to migrate to other fields. Zero-shot entity relation extraction relieves the dependence on labeled data in traditional method. Based on unlabeled text data, zero-shot entity relation extraction has strong domain adaptability, which is a very challenging and practical task. Recent work on large language models shows that large models can effectively complete downstream tasks through natural language instructions and have good generalization ability. Inspired by this, we explore the use of large models for information extraction. Due to the randomness of large language model generation, we introduce in-context learning in entity relation extraction task to guide large language model to output data in a specified format to help obtain structured data. At the same time, we propose a three-stage extraction framework for decomposing entity relation extraction tasks, and each stage is conducted in the form of question and answer to reduce the complexity of extraction. We evaluated the knowledge triples extraction performance of the model on three self-built test datasets in different fields, and the experimental result showed that our proposed method achieved impressive performance in the zero-shot entity relation extraction task, surpassing the comparison model on multiple metrics, proving the effectiveness and domain adaptability of the proposed method.},
booktitle = {Proceedings of the 2023 7th International Conference on Electronic Information Technology and Computer Engineering},
pages = {475–480},
numpages = {6},
location = {Xiamen, China},
series = {EITCE '23}
}

@inproceedings{10.1145/3661304.3661901,
author = {Sequeda, Juan and Allemang, Dean and Jacob, Bryon},
title = {A Benchmark to Understand the Role of Knowledge Graphs on Large Language Model's Accuracy for Question Answering on Enterprise SQL Databases},
year = {2024},
isbn = {9798400706530},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3661304.3661901},
doi = {10.1145/3661304.3661901},
abstract = {Enterprise applications of Large Language Models (LLMs) hold promise for question answering on enterprise SQL databases. However, the extent to which LLMs can accurately respond to enterprise questions in such databases remains unclear, given the absence of suitable Text-to-SQL benchmarks tailored to enterprise settings. Additionally, the potential of Knowledge Graphs (KGs) to enhance LLM-based question answering by providing business context is not well understood. This study aims to evaluate the accuracy of LLM-powered question answering systems in the context of enterprise questions and SQL databases, while also exploring the role of knowledge graphs in improving accuracy. To achieve this, we introduce a benchmark comprising an enterprise SQL schema in the insurance domain, a range of enterprise queries encompassing reporting to metrics, and a contextual layer incorporating an ontology and mappings that define a knowledge graph. Our primary finding reveals that question answering using GPT-4, with zero-shot prompts directly on SQL databases, achieves an accuracy of 16%. Notably, this accuracy increases to 54% when questions are posed over a Knowledge Graph representation of the enterprise SQL database. Therefore, investing in Knowledge Graph provides higher accuracy for LLM powered question answering systems.},
booktitle = {Proceedings of the 7th Joint Workshop on Graph Data Management Experiences &amp; Systems (GRADES) and Network Data Analytics (NDA)},
articleno = {5},
numpages = {12},
location = {Santiago, AA, Chile},
series = {GRADES-NDA '24}
}

@inproceedings{10.1145/3696500.3696588,
author = {Yu, Miao and Feng, Chenying and Xu, Xiaodong and Tang, Runheng and Shi, Shengwei},
title = {Research on text relation extraction of power administrative duty based on improved pre-trained language model},
year = {2024},
isbn = {9798400710278},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3696500.3696588},
doi = {10.1145/3696500.3696588},
abstract = {Strategies for efficiently and accurately extracting relationships from power system administrative shift texts are explored using an optimized pre-trained language model, such as BERT (Bidirectional Encoder Representations from Transformers). Tailored improvements to the model address the nuanced and variable nature of power texts, including the integration of domain-specific pre-training corpora and architectural enhancements. The model, enhanced with the R-BERT (Relation-Bidirectional Encoder Representations from Transformers) algorithm, demonstrates advanced proficiency in identifying entity positions and yields exceptional results in experimental evaluations, particularly achieving a high F1 score for the identification of cooperative relationships. The findings indicate that this innovation can significantly enhance the level of intelligence in power system administrative shift management. Subsequent developments may involve the incorporation of additional expert knowledge to further refine the model.},
booktitle = {Proceedings of the 2024 International Conference on Big Data and Digital Management},
pages = {528–534},
numpages = {7},
location = {Shanghai, China},
series = {ICBDDM '24}
}

@article{10.1145/3652028,
author = {Spinner, Thilo and Kehlbeck, Rebecca and Sevastjanova, Rita and St\"{a}hle, Tobias and Keim, Daniel A. and Deussen, Oliver and El-Assady, Mennatallah},
title = {-generAItor: Tree-in-the-loop Text Generation for Language Model Explainability and Adaptation},
year = {2024},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {14},
number = {2},
issn = {2160-6455},
url = {https://doi.org/10.1145/3652028},
doi = {10.1145/3652028},
abstract = {Large language models (LLMs) are widely deployed in various downstream tasks, e.g., auto-completion, aided writing, or chat-based text generation. However, the considered output candidates of the underlying search algorithm are under-explored and under-explained. We tackle this shortcoming by proposing a tree-in-the-loop approach, where a visual representation of the beam search tree is the central component for analyzing, explaining, and adapting the generated outputs. To support these tasks, we present generAItor, a visual analytics technique, augmenting the central beam search tree with various task-specific widgets, providing targeted visualizations and interaction possibilities. Our approach allows interactions on multiple levels and offers an iterative pipeline that encompasses generating, exploring, and comparing output candidates, as well as fine-tuning the model based on adapted data. Our case study shows that our tool generates new insights in gender bias analysis beyond state-of-the-art template-based methods. Additionally, we demonstrate the applicability of our approach in a qualitative user study. Finally, we quantitatively evaluate the adaptability of the model to few samples, as occurring in text-generation use cases.},
journal = {ACM Trans. Interact. Intell. Syst.},
month = jun,
articleno = {14},
numpages = {32},
keywords = {Large language models, beam search tree, natural language generation, explainability, language transformers, visual analytics}
}

@inproceedings{10.1145/3653081.3653131,
author = {Na, Qionglan and Li, Xin and Wang, Yifei and Li, Jing and Yang, Yixi and Zhang, Haiming},
title = {A Pre-training Method Inspired by Large Language Model for Power Named Entity Recognition},
year = {2024},
isbn = {9798400716485},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3653081.3653131},
doi = {10.1145/3653081.3653131},
abstract = {In recent years, the field of natural language processing has witnessed remarkable advancements due to the success of large language models. These models leverage the Transformer architecture and pre-training techniques to achieve impressive results. In this paper, we draw inspiration from large language models and apply these techniques into the task of named entity recognition in the domain of power grids, which is critical for building power grid knowledge graphs and question-answering systems. Specifically, we propose a BERT-CNN-BIGRU-CRF deep learning model for named entity recognition. This model effectively harnesses the semantic modeling capabilities and pre-training knowledge of BERT, which is based on the Transformer architecture. By incorporating CNN and BIGRU, the model captures and models both local and global features, respectively. The CRF layer is employed for label classification. This combination of components ensures a high level of recognition accuracy. To evaluate the performance of the proposed model, we train our model on annotated maintenance plan data. We compare its results with those of other commonly used models. The evaluation metrics include recall, precision, and F1 score, which are widely employed in named entity recognition tasks. Our proposed model achieves optimal performance across all three metrics, demonstrating its superiority over other models.},
booktitle = {Proceedings of the 2023 5th International Conference on Internet of Things, Automation and Artificial Intelligence},
pages = {308–312},
numpages = {5},
location = {Nanchang, China},
series = {IoTAAI '23}
}

@inproceedings{10.1145/3644116.3644294,
author = {Zhu, Jinyang and Gong, Qingyue and Zhou, Chunfang and Luan, Huidan},
title = {ZhongJing: A Locally Deployed Large Language Model for Traditional Chinese Medicine and Corresponding Evaluation Methodology: A Large Language Model for data fine-tuning in the field of Traditional Chinese Medicine, and a new evaluation method called TCMEval are proposed},
year = {2024},
isbn = {9798400708138},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3644116.3644294},
doi = {10.1145/3644116.3644294},
abstract = {The success of ChatGPT has showcased the potential applications of Large Language Models (LLMs) in the field of Traditional Chinese Medicine (TCM), encompassing areas such as medical diagnosis, adjunctive therapy, and TCM talent cultivation. However, the current challenges, including hardware constraints, insufficient model domain knowledge, and difficulties in domain-specific evaluation, have constrained the fusion of LLMs with TCM. In an attempt to address these issues, this paper introduces ZhongJing, a domain-specific LLM fine-tuned within the domain of TCM, capable of generating responses at a rate of 8 tokens per second, smoothly operating on local personal computers. To assess the model's domain expertise, this paper introduces the TCMEval evaluation method, designed concerning medical students' exams. Experimental results demonstrate that ZhongJing achieves a 6.49 TCMEval Score improvement over Chinese-LLaMA2 in the field of TCM, indicating the model's ability to generate more specialized responses compared to baseline models.},
booktitle = {Proceedings of the 2023 4th International Symposium on Artificial Intelligence for Medicine Science},
pages = {1036–1042},
numpages = {7},
location = {Chengdu, China},
series = {ISAIMS '23}
}

@inproceedings{10.1145/3670474.3685974,
author = {Wang, Li-C.},
title = {LLM-Assisted Analytics in Semiconductor Test (Invited)},
year = {2024},
isbn = {9798400706998},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3670474.3685974},
doi = {10.1145/3670474.3685974},
abstract = {The emergence of Large Language Models (LLMs) has impacted our perspective on applying Machine Learning (ML) in semiconductor test. This paper shares our experience in leveraging the power of LLMs to build an AI agent for test data analytics. We advocate for an end-to-end approach where the Knowledge Graph (KG) plays a central role. Using wafermap analytics as an example, we highlight the key ideas behind developing the LLM-assisted AI agent named IEA-Plot, and discuss its practical applications.},
booktitle = {Proceedings of the 2024 ACM/IEEE International Symposium on Machine Learning for CAD},
articleno = {38},
numpages = {7},
keywords = {Knowledge Graph, Large Language Model, Machine Learning, Test Data Analytics},
location = {Salt Lake City, UT, USA},
series = {MLCAD '24}
}

@article{10.1145/3686970,
author = {Cheng, Zirui and Xu, Jingfei and Jin, Haojian},
title = {TreeQuestion: Assessing Conceptual Learning Outcomes with LLM-Generated Multiple-Choice Questions},
year = {2024},
issue_date = {November 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {CSCW2},
url = {https://doi.org/10.1145/3686970},
doi = {10.1145/3686970},
abstract = {The advances of generative AI have posed a challenge for using open-ended questions to assess conceptual learning outcomes, as it is increasingly common for students to use tools like ChatGPT to generate long textual answers. However, teachers still have to spend substantial time reading the answers and inferring students' learning outcomes. We present TreeQuestion, a human-in-the-loop system designed to help teachers create a set of multiple-choice questions to assess students' conceptual learning outcomes. When a teacher seeks to assess students' comprehension of specific concepts, TreeQuestion taps into the wealth of knowledge embedded within large language models and generates a set of multiple-choice questions organized in a tree-like structure. We evaluated TreeQuestion with 96 students and 10 teachers. Results indicated that students achieved similar performance in multiple-choice questions generated by TreeQuestion and open-ended questions graded by teachers. Meanwhile, TreeQuestion could reduce teachers' efforts in creating and grading the multiple-choice questions in contrast to manually generated open-ended questions. We estimate that in a hypothetical class with 20 students, using multiple-choice questions from TreeQuestion may require only 4.6% of the time compared to open-ended questions for assessing learning outcomes.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = nov,
articleno = {431},
numpages = {29},
keywords = {education, generative AI, large language models, multiple-choice questions, open-ended questions}
}

@inproceedings{10.1145/3678890.3678906,
author = {Ma, Hualong and Lv, Peizhuo and Chen, Kai and Zhou, Jiachen},
title = {KGDist: A Prompt-Based Distillation Attack against LMs Augmented with Knowledge Graphs},
year = {2024},
isbn = {9798400709593},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3678890.3678906},
doi = {10.1145/3678890.3678906},
abstract = {With Knowledge Graph (KG) increasingly applied in various fields, the integration of KG has gained significant attention to augment the knowledge-specific task capabilities of language models (LMs). However, constructing and maintaining large KGs, much like LMs, can be expensive and challenging, often requiring extensive domain knowledge and human resources. This makes KG a valuable resource potentially vulnerable to theft threats from attackers. In this paper, we present KGDist, the first prompt-based KG distillation technique for extracting KG knowledge from KG+LM augmented models. Through iterations of prompt-based queries, we can steal a substitute KG containing task domain knowledge from the original KG. First of all, we initialize entities from a small scale task-specific corpus. Then, we construct specific task prompts for querying the victim LMs. According to the model outputs, we iteratively select entities showing strong correlation and reconstruct the relation edges for subsequent prompt crafting. We also propose a multi-granularity prompt construction method for reducing the querying cost. After acquiring the extracted KG, we launch a relation type-based pruning to cut off redundant edges forming cycles decreasing the performance of distilled KGs. We evaluate the effectiveness of KGDist &nbsp;on five benchmark KG+LM models designed for various tasks. Results demonstrate that our attack successfully extracts the distilled KGs with minimal performance degradation (under 2.4%) applied on LMs and less storage space. And also, the mechanism we apply greatly saves API queries compared to brute force method. In addition, further experiments demonstrate that we can split the KG knowledge from the LM noises effectively, and the distilled KGs have similar properties in knowledge distribution and graph structures to the original ones. Our code is available at https://github.com/Haro-M/KGDist.},
booktitle = {Proceedings of the 27th International Symposium on Research in Attacks, Intrusions and Defenses},
pages = {480–495},
numpages = {16},
keywords = {knowledge distillation, knowledge graph, language model},
location = {Padua, Italy},
series = {RAID '24}
}

@inproceedings{10.1145/3703187.3703192,
author = {Li, Chengxue and Chen, Xuyang and Ding, Min and Jin, Wei and Gao, Feng},
title = {Research on Chinese Knowledge Base and Knowledge Q&amp;A Technology for Power Grid Dispatching},
year = {2024},
isbn = {9798400707254},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3703187.3703192},
doi = {10.1145/3703187.3703192},
abstract = {To support online professional knowledge query for power grid dispatchers, this article proposes a method for constructing a knowledge base based on knowledge graph, which implements systematic organization and management of knowledge resources in the field of power-grid dispatching. Moreover, a questions and answers (Q&amp;A) service is design based on large language model and proposed knowledge base. Based on the constructed knowledge base and Q&amp;A service, auxiliary learning functions can be provided in the domain of power grid operation. This enables accurate acquisition of professional knowledge through Chinese natural language interaction, enhancing the effectiveness and flexibility of online training for power-grid dispatchers.},
booktitle = {Proceedings of the 2024 7th International Conference on Computer Information Science and Artificial Intelligence},
pages = {18–23},
numpages = {6},
keywords = {Graph database, Knowledge graph, Large language model, Question answering},
location = {
},
series = {CISAI '24}
}

@article{10.1145/3690391,
author = {Liu, Jiangfeng and Ma, Xueliang and Wang, Lanyu and Pei, Lei},
title = {How Can Generative Artificial Intelligence Techniques Facilitate Intelligent Research into Ancient Books?},
year = {2024},
issue_date = {December 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {4},
issn = {1556-4673},
url = {https://doi.org/10.1145/3690391},
doi = {10.1145/3690391},
abstract = {Generative AI changes the paradigm of natural language processing research, sets off a new trend of research in computational humanities and computational social sciences, and provides unique perspectives on digital intelligence-enabled ancient book revitalization and intelligent applications. The article explores the role of multimodal large models in image processing and OCR of ancient books. We discuss and exemplify how to use Large Language Models for intelligent information processing of ancient texts and explore combining prompt engineering, retrieval augmented generation (RAG), supervised fine-tuning, LangChain, and other techniques to improve performance in ancient text mining and applications. This article also looks forward to the broad prospect of intelligent agent technology combined with the Large Language Model in the innovative application of ancient book revitalization. The research focuses on digitizing ancient books, intelligent processing of ancient texts, and intelligent application of ancient book revitalization. It demonstrates the feasibility, advancement, and creativity of the application of generative AI and its derivative technologies in the field of computational humanities, especially in the field of ancient book preservation, to provide intelligent solutions for the dissemination of traditional thought and culture, from the perspective of the whole process of the technology of digital humanities and computational humanities research. The article also gives examples of the intelligent application of AI in the restoration of ancient books and the annotation of ancient texts. Although Large Language Models demonstrate transformative potential in advancing the field of ancient text research toward intelligent analysis, there remain certain limitations. This article points out their shortcomings in areas such as knowledge completion for ancient texts, understanding emotions and cultural nuances, as well as ethical and accountability issues. It emphasizes the need for a more balanced perspective on the role that generative AI plays in the exploration and utilization of cultural heritage.},
journal = {J. Comput. Cult. Herit.},
month = dec,
articleno = {57},
numpages = {20},
keywords = {Computational Humanities, Ancient Book Revitalization, Intelligent Information Processing of Ancient Texts, ChatGPT, Generative AI, AIGC}
}

@inproceedings{10.1145/3627673.3679231,
author = {Afreen, Neda and Balloccu, Giacomo and Boratto, Ludovico and Fenu, Gianni and Malloci, Francesca Maridina and Marras, Mirko and Martis, Andrea Giovanni},
title = {EDGE: A Conversational Interface driven by Large Language Models for Educational Knowledge Graphs Exploration},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679231},
doi = {10.1145/3627673.3679231},
abstract = {As education adopts digital platforms, the vast amount of information from various sources, such as learning management systems and learning object repositories, presents challenges in navigation and elaboration. Traditional interfaces involve a steep learning curve, limited user accessibility, and lack flexibility. Language models alone cannot address these issues as they do not have access to structured information specific to the educational organization. In this paper, we propose EDGE (EDucational knowledge Graph Explorer), a natural language interface that uses knowledge graphs to organize educational information. EDGE translates natural language requests into queries and converts the results back into natural language responses. We show EDGE's versatility using knowledge graphs built from public datasets, providing example interactions of different stakeholders. Demo video: https://u.garr.it/eYq63.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {5159–5163},
numpages = {5},
keywords = {conversational interface, graph database, information retrieval, knowledge graph, language model, learning management},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@inproceedings{10.1145/3626246.3655999,
author = {Dong, Xin Luna},
title = {The Journey to a Knowledgeable Assistant with Retrieval-Augmented Generation (RAG)},
year = {2024},
isbn = {9798400704222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626246.3655999},
doi = {10.1145/3626246.3655999},
abstract = {For decades, multiple communities (Database, Information Retrieval, Natural Language Processing, Data Mining, AI) have pursued the mission of providing the right information at the right time. Efforts span web search, data integration, knowledge graphs, question answering. Recent advancements in Large Language Models (LLMs) have demonstrated remarkable capabilities in comprehending and generating human language, revolutionizing techniques in every front. However, their inherent limitations such as factual inaccuracies and hallucinations make LLMs less suitable for creating knowledgeable and trustworthy assistants.This talk describes our journey in building a knowledgeable AI assistant by harnessing LLM techniques. We start with our findings from a comprehensive set of experiments to assess LLM reliability in answering factual questions and analyze performance variations across different knowledge types. Next, we describe our federated Retrieval-Augmented Generation (RAG) system that integrates external information from both the web and knowledge graphs for trustworthy text generation on real-time topics like stocks and sports, as well as on torso-to-tail entities like local restaurants. Additionally, we brief our explorations on extending our techniques towards multi-modal, contextualized, and personalized Q&amp;A. We will share our techniques, our findings, and the path forward, high- lighting how we are leveraging and advancing the decades of work in this area.},
booktitle = {Companion of the 2024 International Conference on Management of Data},
pages = {3},
numpages = {1},
keywords = {RAG (retrieval augmented generation), data integration, generative AI, knowledge graph, question answering},
location = {Santiago AA, Chile},
series = {SIGMOD/PODS '24}
}

@inproceedings{10.1145/3626246.3653398,
author = {Yu, Changlong and Liu, Xin and Maia, Jefferson and Li, Yang and Cao, Tianyu and Gao, Yifan and Song, Yangqiu and Goutam, Rahul and Zhang, Haiyang and Yin, Bing and Li, Zheng},
title = {COSMO: A Large-Scale E-commerce Common Sense Knowledge Generation and Serving System at Amazon},
year = {2024},
isbn = {9798400704222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626246.3653398},
doi = {10.1145/3626246.3653398},
abstract = {Applications of large-scale knowledge graphs in the e-commerce platforms can improve shopping experience for their customers. While existing e-commerce knowledge graphs (KGs) integrate a large volume of concepts or product attributes, they fail to discover user intentions, leaving the gap with how people think, behave, and interact with the surrounding world. In this work, we present COSMO, a scalable system to mine user-centric commonsense knowledge from massive behaviors and construct industry-scale knowledge graphs to empower diverse online services. In particular, we describe a pipeline for collecting high-quality seed knowledge assertions that are distilled from large language models (LLMs) and further refined by critic classifiers trained over human-in-the-loop annotated data.Since those generations may not always align with human preferences and contain noises, we then describe how we adopt instruction tuning to finetune an efficient language model~(COSMO-LM) for faithful e-commerce commonsense knowledge generation at scale. COSMO-LM effectively expands our knowledge graph to 18 major categories at Amazon, producing millions of high-quality knowledge with only 30k annotated instructions. Finally COSMO has been deployed in Amazon search applications such as search navigation. Both offline and online A/B experiments demonstrate our proposed system achieves significant improvement. Furthermore, these experiments highlight the immense potential of commonsense knowledge extracted from instruction-finetuned large language models.},
booktitle = {Companion of the 2024 International Conference on Management of Data},
pages = {148–160},
numpages = {13},
keywords = {commonsense knowledge, knowledge graph, large language model},
location = {Santiago AA, Chile},
series = {SIGMOD/PODS '24}
}

@inproceedings{10.1145/3626772.3657656,
author = {Rollings, Nathaniel},
title = {Mosaicing Prevention in Declassification},
year = {2024},
isbn = {9798400704314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626772.3657656},
doi = {10.1145/3626772.3657656},
abstract = {Multiple methods can be used to infer as-yet unrecorded information. However, this ability can place confidentiality at risk when some inferences, although correct, could cause harm. We therefore flip the problem, seeking not to enable but to prevent specific inferences. This inference prevention task is motivated by what has been called the "mosaicing'' problem in declassification review for documents that in the past were withheld from public access for national security reasons~citepozen2005mosaic. The goal of such a review is to reveal as much as can now be safely revealed but to also withhold things that could be used to infer facts that require continued protection. This problem is modeled using three primary components: (1) currently public information, (2) a set of secrets (information that is not public and requires continuing protection), and (3) a review set (other information now being reviewed for possible release). The inference prevention task is to determine what in the review set would substantially increase the inference rick for a secret.Our initial work investigated use of knowledge graphs for keeping secrets using Knowledge Graph Completion (KGC) techniques. While declassification is typically text-based, we expect a structured analog to that problem can provide some useful insights. There also are applications where prevention of inference in a knowledge graph is the actual task, such as protecting against specific drug discovery inferences when augmenting the Hetionet knowledge graph. Our mosaicing problem is the inverse of KGC---rather than inferring a link, we need to prevent inference of a link. This challenge is distinct from anonymization for social media graphs because we can't alter most relationships, only those in the review set. Using the FB15K-237 knowledge graph, we analyzed three KGC models to identify the relation in a defined review set most critical to inference of a missing secret relation (thus "nominating" a relation for redaction). We evaluated the impact of redactions nominated by one model on inference by other models by ranking a secret with some selected confounds, finding that our simplest model (RuleN) produced the best nominations, despite being least effective of the three on the KGC task. Future work will use graphs more closely modeling declassification, and other KGC models. It will also explore areas in which differences between the traditional KGC task and the declassification problem may be exploited, most notably in the focus on specific secrets for declassification which may allow more focused training of models and improve scalability.Our ultimate goal is to perform redaction directly on text. We will explore two sets of techniques, one building on traditional Multi-Hop Question Answering (MHQA) and a second using Large Language Models (LLM) which now constitute a major element of text-based inference methods. Both approaches to MHQA typically operate over limited document sets, so a retrieval step is needed for preselection. This retrieval step adds challenges because we must accommodate redundant information spread across the collection. We can evaluate nomination generalizability across model classes and the impact of alternative retrieval approaches using the same confound ranking technique, but ultimately we will also need absolute measures of effectiveness, not just relative comparisons, because we must balance the benefit of releasing information with the cost imposed by the risk of revealing a secret. While our work begins the exploration of the mosaicing problem, it has limitations. We must use analogs for our problem as working with classified information is challenging in access and distribution. While these are selected to serve as reasonable representations of our problem, they will exhibit differences from the actual classified datasets. Furthermore, the performance of the model classes used for inference in both the text and KG scenarios may not generalize against novel approaches developed in the future. The framework established in testing the current models would still be applicable but would have to be rerun with these new classes of models.},
booktitle = {Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {3075},
numpages = {1},
keywords = {information protection, knowledge graph, large language model},
location = {Washington DC, USA},
series = {SIGIR '24}
}

@inproceedings{10.1145/3640457.3691714,
author = {Tachioka, Yuuki},
title = {User Knowledge Prompt for Sequential Recommendation},
year = {2024},
isbn = {9798400705052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3640457.3691714},
doi = {10.1145/3640457.3691714},
abstract = {The large language model (LLM) based recommendation system is effective for sequential recommendation, because general knowledge of popular items is included in the LLM. To add domain knowledge of items, the conventional method uses a knowledge prompt obtained from the item knowledge graphs and has achieved SOTA performance. However, for personalized recommendation, it is necessary to consider user knowledge, which the conventional method does not fully consider because user knowledge is not included in the item knowledge graphs; thus, we propose a user knowledge prompt, which converts a user knowledge graph into a prompt using the relationship template. The existing prompt denoising framework is extended to prevent hallucination caused by undesirable interactions between knowledge graph prompts. We propose user knowledge prompts of user traits and user preferences and associate relevant items. Experiments on three types of dataset (movie, music, and book) show the significant and consistent improvement of our proposed user knowledge prompt.},
booktitle = {Proceedings of the 18th ACM Conference on Recommender Systems},
pages = {1142–1146},
numpages = {5},
keywords = {LLM, collaborative filtering, personalization, sequential recommendation, user knowledge graph},
location = {Bari, Italy},
series = {RecSys '24}
}

@inproceedings{10.1145/3627673.3679091,
author = {Xu, Eric and Zhang, Wenbin and Xu, Weifeng},
title = {Transforming Digital Forensics with Large Language Models: Unlocking Automation, Insights, and Justice},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679091},
doi = {10.1145/3627673.3679091},
abstract = {In the pursuit of justice and accountability in the digital age, the integration of Large Language Models (LLMs) with digital forensics holds immense promise. This half-day tutorial provides a comprehensive exploration of the transformative potential of LLMs in automating digital investigations and uncovering hidden insights. Through a combination of real-world case studies, interactive exercises, and hands-on labs, participants will gain a deep understanding of how to harness LLMs for evidence analysis, entity identification, and knowledge graph reconstruction. By fostering a collaborative learning environment, this tutorial aims to empower professionals, researchers, and students with the skills and knowledge needed to drive innovation in digital forensics. As LLMs continue to revolutionize the field, this tutorial will have far-reaching implications for enhancing justice outcomes, promoting accountability, and shaping the future of digital investigations.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {5543–5546},
numpages = {4},
keywords = {automation, digital forensics, evidence analysis, knowledge graph reconstruction, large language model},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@inproceedings{10.1145/3644815.3644959,
author = {Xia, Boming and Lu, Qinghua and Zhu, Liming and Lee, Sung Une and Liu, Yue and Xing, Zhenchang},
title = {Towards a Responsible AI Metrics Catalogue: A Collection of Metrics for AI Accountability},
year = {2024},
isbn = {9798400705915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3644815.3644959},
doi = {10.1145/3644815.3644959},
abstract = {Artificial Intelligence (AI), particularly through the advent of large-scale generative AI (GenAI) models such as Large Language Models (LLMs), has become a transformative element in contemporary technology. While these models have unlocked new possibilities, they simultaneously present significant challenges, such as concerns over data privacy and the propensity to generate misleading or fabricated content. Current frameworks for Responsible AI (RAI) often fall short in providing the granular guidance necessary for tangible application, especially for Accountability---a principle that is pivotal for ensuring transparent and auditable decision-making, bolstering public trust, and meeting increasing regulatory expectations. This study bridges the Accountability gap by introducing our effort towards a comprehensive metrics catalogue, formulated through a systematic multivocal literature review (MLR) that integrates findings from both academic and grey literature. Our catalogue delineates process metrics that underpin procedural integrity, resource metrics that provide necessary tools and frameworks, and product metrics that reflect the outputs of AI systems. This tripartite framework is designed to operationalize Accountability in AI, with a special emphasis on addressing the intricacies of GenAI.},
booktitle = {Proceedings of the IEEE/ACM 3rd International Conference on AI Engineering - Software Engineering for AI},
pages = {100–111},
numpages = {12},
keywords = {responsible AI, accountable AI, risk assessment, generative AI},
location = {Lisbon, Portugal},
series = {CAIN '24}
}

@inproceedings{10.1145/3626772.3661370,
author = {Xu, Zhentao and Cruz, Mark Jerome and Guevara, Matthew and Wang, Tie and Deshpande, Manasi and Wang, Xiaofeng and Li, Zheng},
title = {Retrieval-Augmented Generation with Knowledge Graphs for Customer Service Question Answering},
year = {2024},
isbn = {9798400704314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626772.3661370},
doi = {10.1145/3626772.3661370},
abstract = {In customer service technical support, swiftly and accurately retrieving relevant past issues is critical for efficiently resolving customer inquiries. The conventional retrieval methods in retrieval-augmented generation (RAG) for large language models (LLMs) treat a large corpus of past issue tracking tickets as plain text, ignoring the crucial intra-issue structure and inter-issue relations, which limits performance. We introduce a novel customer service question-answering method that amalgamates RAG with a knowledge graph (KG). Our method constructs a KG from historical issues for use in retrieval, retaining the intra-issue structure and inter-issue relations. During the question-answering phase, our method parses consumer queries and retrieves related sub-graphs from the KG to generate answers. This integration of a KG not only improves retrieval accuracy by preserving customer service structure information but also enhances answering quality by mitigating the effects of text segmentation. Empirical assessments on our benchmark datasets, utilizing key retrieval (MRR, Recall@K, NDCG@K) and text generation (BLEU, ROUGE, METEOR) metrics, reveal that our method outperforms the baseline by 77.6% in MRR and by 0.32 in BLEU. Our method has been deployed within LinkedIn's customer service team for approximately six months and has reduced the median per-issue resolution time by 28.6%.},
booktitle = {Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {2905–2909},
numpages = {5},
keywords = {knowledge graph, large language model, question answering, retrieval-augmented generation},
location = {Washington DC, USA},
series = {SIGIR '24}
}

@article{10.1145/3640313,
author = {Subagdja, Budhitama and Shanthoshigaa, D. and Wang, Zhaoxia and Tan, Ah-Hwee},
title = {Machine Learning for Refining Knowledge Graphs: A Survey},
year = {2024},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {56},
number = {6},
issn = {0360-0300},
url = {https://doi.org/10.1145/3640313},
doi = {10.1145/3640313},
abstract = {Knowledge graph (KG) refinement refers to the process of filling in missing information, removing redundancies, and resolving inconsistencies in KGs. With the growing popularity of KG in various domains, many techniques involving machine learning have been applied, but there is no survey dedicated to machine learning-based KG refinement yet. Based on a novel framework following the KG refinement process, this article presents a survey of machine learning approaches to KG refinement according to the kind of operations in KG refinement, the training datasets, mode of learning, and process multiplicity. Furthermore, the survey aims to provide broad practical insights into the development of fully automated KG refinement.},
journal = {ACM Comput. Surv.},
month = feb,
articleno = {156},
numpages = {38},
keywords = {Knowledge graphs, knowledge graph refinement}
}

@inproceedings{10.1145/3610978.3640622,
author = {Jokinen, Kristiina and Wilcock, Graham},
title = {Exploring a Japanese Cooking Database},
year = {2024},
isbn = {9798400703232},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3610978.3640622},
doi = {10.1145/3610978.3640622},
abstract = {The paper describes ongoing work applying Generative AI to a real world application. We use Retrieval Augmented Generation and other GenAI tools that combine large language models with Neo4j knowledge graphs. These tools help a robot to chat in English about Japanese cooking using a knowledge base that is in Japanese.},
booktitle = {Companion of the 2024 ACM/IEEE International Conference on Human-Robot Interaction},
pages = {578–582},
numpages = {5},
keywords = {Japanese cooking, cypher query language, generative AI, graph databases, knowledge graphs, large language models, retrieval augmented generation, semantic search, social robots},
location = {Boulder, CO, USA},
series = {HRI '24}
}

@inproceedings{10.1145/3613905.3650844,
author = {Walker, Johanna and Koutsiana, Elisavet and Nwachukwu, Michelle and Mero\~{n}o Pe\~{n}uela, Albert and Simperl, Elena},
title = {The Promise and Challenge of Large Language Models for Knowledge Engineering: Insights from a Hackathon},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3650844},
doi = {10.1145/3613905.3650844},
abstract = {Knowledge engineering (KE) is the process of building, maintaining and using knowledge-based systems. This recently takes the form of knowledge graphs (KGs). The advent of new technologies like Large Language Models (LLMs) has the potential to improve automation in KE work due to the richness of their training data and their performance at solving natural language processing tasks. We conducted a multiple-methods study exploring user opinions and needs regarding the use of LLMs in KE. We used ethnographic techniques to observe KE workers using LLMs to solve KE tasks during a hackathon, followed by interviews with some of the participants. This interim study found that despite LLMs’ promising capabilities for efficient knowledge acquisition and requirements elicitation, their effective deployment requires an extended set of capabilities and training, particularly in prompting and understanding data. LLMs can be useful for simple quality assessment tasks, but in complex scenarios, the output is hard to control and evaluation may require novel approaches. With this study, we aim to evidence the interaction of KE stakeholders with LLMs, identify areas of potential, and understand the barriers to their effective use. We find copilot approaches may be valuable in developing processes where the human or a team of humans is assisted by generative AI.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {318},
numpages = {9},
keywords = {Interviews, Knowledge Engineering, Knowledge Graph, Large Language Models},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}

@inproceedings{10.1145/3698587.3701392,
author = {ALMutairi, Mariam and AlKulaib, Lulwah and Wang, Shengkun and Chen, Zhiqian and ALMutairi, Youssif and Alenazi, Thamer M. and Luther, Kurt and Lu, Chang-Tien},
title = {FHIRViz: Multi-Agent Platform for FHIR Visualization to Advance Healthcare Analytics},
year = {2024},
isbn = {9798400713026},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3698587.3701392},
doi = {10.1145/3698587.3701392},
abstract = {The shift to electronic health records (EHRs) has enhanced patient care and research, but data sharing and complex clinical terminology remain challenges. The Fast Healthcare Interoperability Resource (FHIR) addresses interoperability issues, though extracting insights from FHIR data is still difficult. Traditional analytics often miss critical clinical context, and managing FHIR data requires advanced skills that are in short supply. This study presents FHIRViz, a novel analytics tool that integrates FHIR data with a semantic layer via a knowledge graph. It employs a large language model (LLM) system to extract insights and visualize them effectively. A retrieval vector store improves performance by saving successful generations for fine-tuning. FHIRViz translates clinical queries into actionable insights with high accuracy. Results show FHIRViz with GPT-4 achieving 92.62% accuracy, while Gemini 1.5 Pro reaches 89.34%, demonstrating the tool's potential in overcoming healthcare data analytics challenges.},
booktitle = {Proceedings of the 15th ACM International Conference on Bioinformatics, Computational Biology and Health Informatics},
articleno = {38},
numpages = {7},
keywords = {Clinical Analytics, FHIR, Health Informatics, Knowledge Graph, LLMs, Multi-Agent, visualization},
location = {Shenzhen, China},
series = {BCB '24}
}

@article{10.1145/3627994,
author = {Lo, Pei-Chi and Lim, Ee-Peng},
title = {Non-monotonic Generation of Knowledge Paths for Context Understanding},
year = {2024},
issue_date = {March 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {1},
issn = {2158-656X},
url = {https://doi.org/10.1145/3627994},
doi = {10.1145/3627994},
abstract = {Knowledge graphs can be used to enhance text search and access by augmenting textual content with relevant background knowledge. While many large knowledge graphs are available, using them to make semantic connections between entities mentioned in the textual content remains to be a difficult task. In this work, we therefore introduce contextual path generation (CPG), which refers to the task of generating knowledge paths, contextual path, to explain the semantic connections between entities mentioned in textual documents with given knowledge graph. To perform the CPG task well, one has to address its three challenges, namely, path relevance, incomplete knowledge graph, and path well-formedness. This article designs a two-stage framework comprised of the following: (1) a knowledge-enabled embedding matching and learning-to-rank with multi-head self-attention context extractor to determine a set of context entities relevant to both the query entities and context document, and (2) a non-monotonic path generation method with pretrained transformer to generate high-quality contextual paths. Our experiment results on two real-world datasets show that our best performing CPG model successfully recovers 84.13% of ground truth contextual paths, outperforming the context window baselines. Finally, we demonstrate that the non-monotonic model generates more well-formed paths compared to the monotonic counterpart.},
journal = {ACM Trans. Manage. Inf. Syst.},
month = mar,
articleno = {1},
numpages = {28},
keywords = {Information retrieval, knowledge graph, contextual path generation, generation model}
}

@inproceedings{10.1145/3656156.3665133,
author = {Haghighi, Nava},
title = {Ontological Breakdown: Toward a World of Many Worlds},
year = {2024},
isbn = {9798400706325},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3656156.3665133},
doi = {10.1145/3656156.3665133},
abstract = {Examining the taken-for-granted assumptions and views of the world underlying the design of technological artifacts, this work posits that a lack of ontological self-reflection can constrain imagination, impeding movement toward a world of many worlds. I propose ontological breakdown as an analytic lens for interrogating the default assumptions underlying the design of technology, using LLMs as a case-study and drawing parallels to the discourse on values in design. Then, I share three ways in which I have used ontological breakdowns generatively to (1) surface ontological difference and create spaces for experiencing ontological alternatives to our defaults, (2) explore ontological alternatives in the design of artifacts and enable the end-users to notice their own ontological defaults, and (3) expand ontological diversity by empowering the end-users to move beyond the prescribed defaults. I demonstrate the generative potential of ontological breakdowns by providing examples of my work in personal informatics.},
booktitle = {Companion Publication of the 2024 ACM Designing Interactive Systems Conference},
pages = {70–73},
numpages = {4},
keywords = {LLM, generative AI, ontological breakdown, ontological design, ontologies, personal informatics},
location = {IT University of Copenhagen, Denmark},
series = {DIS '24 Companion}
}

@inproceedings{10.1145/3670474.3685976,
author = {Francisco, Luis and Arikati, Srini},
title = {LLM Based Physical Verification Runset Generator},
year = {2024},
isbn = {9798400706998},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3670474.3685976},
doi = {10.1145/3670474.3685976},
abstract = {The complexity in design rule description and coding is drastically increasing as technology nodes advance. This complexity makes the process of implementing the physical verification (PV) rule checks more time-consuming and susceptible to human error, creating the need to explore alternate methods to improve the runset creation process. The work presented proposes a generative AI solution that uses Large Language Models (LLMs) to interpret rule descriptions and generate design rule check decks (runsets) in a language that a PV tool can interpret. The LLM is fine-tuned with existing design rule manuals and runsets. After post-processing the LLM output, the presented solution can generate rules implementation with up to 97% accuracy. The proposed solution can be used as a runset writer Co-Pilot to help develop the new physical verification runsets.},
booktitle = {Proceedings of the 2024 ACM/IEEE International Symposium on Machine Learning for CAD},
articleno = {35},
numpages = {7},
keywords = {AI, Design Rule Checking, GenAI, LLMs, Physical Verification, Runset Creation},
location = {Salt Lake City, UT, USA},
series = {MLCAD '24}
}

@inproceedings{10.1145/3700297.3700331,
author = {Yang, Da and Liu, Shutian and Fu, Haoyang and Shen, Jiayi},
title = {Research and Practice on the Construction of Course Ideological and Political Education Based on Knowledge Graphs and Large Language Models},
year = {2024},
isbn = {9798400707100},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3700297.3700331},
doi = {10.1145/3700297.3700331},
abstract = {Knowledge graphs and large language models (LLMs) have become important tools for educational innovation. This paper explores the application of these two technologies in the construction of ideological and political education in university courses. The paper begins by analyzing the importance of course-based ideological and political education and the challenges currently faced. It then introduces the role of knowledge graphs in integrating educational resources and constructing knowledge systems, as well as the potential and current status of LLMs in natural language processing and providing personalized educational content. This study presents a method that integrates the use of knowledge graphs and LLMs to construct resources and application systems for course-based ideological and political education. The results of practical case studies demonstrate that the proposed method improves the efficiency of constructing ideological and political education content, enhances the effectiveness of moral education within courses, and contributes to the innovative development of ideological and political education.},
booktitle = {Proceedings of the 2024 International Symposium on Artificial Intelligence for Education},
pages = {193–198},
numpages = {6},
keywords = {Course Ideological and Political Education, Educational Innovation, Knowledge Graph, Large Language Model (LLM)},
location = {
},
series = {ISAIE '24}
}

@article{10.1145/3658451,
author = {Dou, Yutao and Huang, Yuwei and Zhao, Xiongjun and Zou, Haitao and Shang, Jiandong and Lu, Ying and Yang, Xiaolin and Xiao, Jian and Peng, Shaoliang},
title = {ShennongMGS: An LLM-based Chinese Medication Guidance System},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {2158-656X},
url = {https://doi.org/10.1145/3658451},
doi = {10.1145/3658451},
abstract = {The rapidly evolving field of Large Language Models (LLMs) holds immense promise for healthcare, particularly in medication guidance and adverse drug reaction prediction. Despite their potential, existing LLMs face challenges in dealing with complex polypharmacy scenarios and often grapple with data lag issues. To address these limitations, we introduce an LLM-based Chinese medication guidance system, called ShennongMGS, specifically tailored for robust medication guidance and adverse drug reaction predictions. Our system transforms multi-source heterogeneous medication information into a knowledge graph and employs a two-stage training strategy to construct a specialised LLM (ShennongGPT). This method enables the simulation of professional pharmacists’ decision-making processes and incorporates the capability for knowledge self-updating, thereby significantly enhancing drug safety and the overall quality of medical services. Rigorously evaluated by medical professionals and artificial intelligence experts, our method demonstrates superiority, outperforming existing general and specialised LLMs in performance.},
note = {Just Accepted},
journal = {ACM Trans. Manage. Inf. Syst.},
month = apr,
keywords = {Large Language Model, Model Fine-tuning, Medication Guidance, Chinese Medical System, Natural Language Processing, Software System}
}

@inproceedings{10.1145/3589334.3645616,
author = {Mou, Xinyi and Li, Zejun and Lyu, Hanjia and Luo, Jiebo and Wei, Zhongyu},
title = {Unifying Local and Global Knowledge: Empowering Large Language Models as Political Experts with Knowledge Graphs},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3645616},
doi = {10.1145/3589334.3645616},
abstract = {Large Language Models (LLMs) have revolutionized solutions for general natural language processing (NLP) tasks. However, deploying these models in specific domains still faces challenges like hallucination. While existing knowledge graph retrieval-based approaches offer partial solutions, they cannot be well adapted to the political domain. On one hand, existing generic knowledge graphs lack vital political context, hindering deductions for practical tasks. On the other hand, the nature of political questions often renders the direct facts elusive, necessitating deeper aggregation and comprehension of retrieved evidence. To address these challenges, we propose a Political Experts through Knowledge Graph Integration (PEG) framework. PEG entails the creation and utilization of a multi-view political knowledge graph (MVPKG), which integrates U.S. legislative, election, and diplomatic data, as well as conceptual knowledge from Wikidata. With MVPKG as its foundation, PEG enhances existing methods through knowledge acquisition, aggregation, and injection. This process begins with refining evidence through semantic filtering, followed by its aggregation into global knowledge via implicit or explicit methods. The integrated knowledge is then utilized by LLMs through prompts. Experiments on three real-world datasets across diverse LLMs confirm PEG's superiority in tackling political modeling tasks.},
booktitle = {Proceedings of the ACM Web Conference 2024},
pages = {2603–2614},
numpages = {12},
keywords = {knowledge graph, large language models, political science},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3698587.3701384,
author = {Patel, Parth and Chiu, Yu-Chiao and Hunag, Yufei and Zhang, Jianqiu},
title = {MetaphorPrompt - An Analogical Reasoning Approach for Extracting Causal Links from Biological Text},
year = {2024},
isbn = {9798400713026},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3698587.3701384},
doi = {10.1145/3698587.3701384},
abstract = {In recent years, Large Language Models (LLMs) have revolutionized Natural Language Processing (NLP), offering significant improvements for extracting complex information from biomedical literature. Our research introduces a novel metaphor-based approach, MetaphorPrompt, to enhance the accuracy of extracting molecular regulatory pathways (MRPs) from biomedical texts. This method employs LLMs such as GPT4 to develop metaphors that map biological processes onto familiar, real-world scenarios, facilitating a better understanding and extracting causal events in MRPs. MetaphorPrompt is tested using the reguloGPT dataset and compared to a baseline method (without metaphors) and reguloGPT's best prompt. Test results demonstrate improved precision, recall, and F1 scores in node and edge prediction of causal event links through analogical reasoning. The effect of in-context learning (ICL) in MetaphorPrompt is investigated, and it is found that analogical reasoning offers significant improvements over ICL. This supports the claim that LLMs can perform novel problem-solving through analogical reasoning. This work paves the way for more intuitive and user-friendly representations of MRPs in biomedical data, ultimately contributing to advancements in biomedical NLP, knowledge graph construction, and effective applications of LLMs in novel problem-solving through analogical reasoning.},
booktitle = {Proceedings of the 15th ACM International Conference on Bioinformatics, Computational Biology and Health Informatics},
articleno = {49},
numpages = {6},
keywords = {Analogical Reasoning, Causal Event Links, GPT4, Knowledge Graph, LLM, Metaphor, Molecular Regulation Pathway, Prompt},
location = {Shenzhen, China},
series = {BCB '24}
}

@inproceedings{10.1145/3613905.3650784,
author = {Han, Jiyeon and Park, Jimin and Huh, Jinyoung and Oh, Uran and Do, Jaeyoung and Kim, Daehee},
title = {AscleAI: A LLM-based Clinical Note Management System for Enhancing Clinician Productivity},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3650784},
doi = {10.1145/3613905.3650784},
abstract = {While clinical notes are essential to the field of healthcare, they pose several challenges for clinicians since it is difficult to write down medical information, review prior notes, and extract the desired information at the same time while examining a patient. Thus, we designed a system that can automatically generate clinical notes from dialogues between patients and clinicians and provide specific information upon clinicians’ query using a Large Language Model (LLM) both in real-time. To explore how this system can be used to support clinicians in practice, we conducted an interview with six clinicians followed by a design probe study with the current version of our system for feedback. Findings suggest that our system has the potential to enable clinicians to write and access clinical notes and examine the patients simultaneously with reduced cognitive loads and increased efficiency and accuracy.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {50},
numpages = {7},
keywords = {Large language model, clinical note, design probe, interview},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}

@inproceedings{10.1145/3637528.3671984,
author = {Gong, Jiahui and Ding, Jingtao and Meng, Fanjin and Chen, Guilong and Chen, Hong and Zhao, Shen and Lu, Haisheng and Li, Yong},
title = {A Population-to-individual Tuning Framework for Adapting Pretrained LM to On-device User Intent Prediction},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671984},
doi = {10.1145/3637528.3671984},
abstract = {Mobile devices, especially smartphones, can support rich functions and have developed into indispensable tools in daily life. With the rise of generative AI services, smartphones can potentially transform into personalized assistants, anticipating user needs and scheduling services accordingly. Predicting user intents on smartphones, and reflecting anticipated activities based on past interactions and context, remains a pivotal step towards this vision. Existing research predominantly focuses on specific domains, neglecting the challenge of modeling diverse event sequences across dynamic contexts. Leveraging pre-trained language models (PLMs) offers a promising avenue, yet adapting PLMs to on-device user intent prediction presents significant challenges. To address these challenges, we propose PITuning, a Population-to-Individual Tuning framework. PITuning enhances common pattern extraction through dynamic event-to-intent transition modeling and addresses long-tailed preferences via adaptive unlearning strategies. Experimental results on real-world datasets demonstrate PITuning's superior intent prediction performance, highlighting its ability to capture long-tailed preferences and its practicality for on-device prediction scenarios.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {896–907},
numpages = {12},
keywords = {device-cloud collaboration, personalization, pretrained language model, user intent},
location = {Barcelona, Spain},
series = {KDD '24}
}

@inproceedings{10.1145/3689492.3690049,
author = {Thiede, Christoph and Taeumel, Marcel and B\"{o}hme, Lukas and Hirschfeld, Robert},
title = {Talking to Objects in Natural Language: Toward Semantic Tools for Exploratory Programming},
year = {2024},
isbn = {9798400712159},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689492.3690049},
doi = {10.1145/3689492.3690049},
abstract = {In exploratory programming, programmers often face a semantic gap between their high-level understanding and the low-level interfaces available for interacting with objects in a system. That is, technical object structure and behavior need to be interpreted as abstract domain concepts, which then increases cognitive load and thus impedes exploration progress. We propose semantic object interfaces that bridge this gap by enabling contextual, natural-language conversations with objects. Our approach leverages an exploratory programming agent powered by a large language model (LLM) to translate natural-language questions into low-level experiments and provide high-level answers. We describe a framework for integrating semantic object interfaces into existing exploratory programming systems, including a prototype implementation in Squeak/Smalltalk using GPT-4o. We showcase the potential of semantic object interfaces through case studies and discuss their feasibility, limitations, and impact on the programming experience. While challenges remain, our approach promises to reduce mental effort and empower programmers to explore and understand systems at a higher level of abstraction for a better programming experience.},
booktitle = {Proceedings of the 2024 ACM SIGPLAN International Symposium on New Ideas, New Paradigms, and Reflections on Programming and Software},
pages = {68–84},
numpages = {17},
keywords = {ChatGPT, LLMs, Smalltalk, conversational agents, exploratory programming, generative AI, natural-language programming, object-oriented programming, semantic tools},
location = {Pasadena, CA, USA},
series = {Onward! '24}
}

@inproceedings{10.1145/3664647.3681705,
author = {Wang, Siqi and Liang, Chao and Gao, Yunfan and Liu, Yang and Li, Jing and Wang, Haofen},
title = {Decoding Urban Industrial Complexity: Enhancing Knowledge-Driven Insights via IndustryScopeGPT},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3681705},
doi = {10.1145/3664647.3681705},
abstract = {Industrial parks are critical to urban economic growth. Yet, their development often encounters challenges stemming from imbalances between industrial requirements and urban services, underscoring the need for strategic planning and operations. This paper introduces IndustryScopeKG, a pioneering large-scale multi-modal, multi-level industrial park knowledge graph, which integrates diverse urban data including street views, corporate, socio-economic, and geospatial information, capturing the complex relationships and semantics within industrial parks. Alongside this, we present the IndustryScopeGPT framework, which leverages Large Language Models (LLMs) with Monte Carlo Tree Search to enhance tool-augmented reasoning and decision-making in Industrial Park Planning and Operation (IPPO). Our work significantly improves site recommendation and functional planning, demonstrating the potential of combining LLMs with structured datasets to advance industrial park management. This approach sets a new benchmark for intelligent IPPO research and lays a robust foundation for advancing urban industrial development. The dataset and related code are available at https://github.com/Tongji-KGLLM/IndustryScope.},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {4757–4765},
numpages = {9},
keywords = {industrial park planning and operation, large language model agent, urban design and planning, urban knowledge graph},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@inproceedings{10.1145/3703187.3703193,
author = {Li, Jiaqi and Li, Guanhua and Liu, Biqi and Zhou, Yuxiao and Li, Shuang and Yu, Haichuan and Wang, Nan},
title = {Construction of a Professional Vocabulary Database for Power Transformers Based on Automatic Word Segmentation},
year = {2024},
isbn = {9798400707254},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3703187.3703193},
doi = {10.1145/3703187.3703193},
abstract = {Power transformers are essential equipment in power systems for energy conversion and transmission. The construction of a knowledge graph for power transformers can effectively organize relevant knowledge about them. To achieve this, the first step is to build a specialized vocabulary database for the power industry. This paper employs an automatic word segmentation algorithm capable of processing both specialized power-related corpora and non-specialized general corpora to generate an initial vocabulary list. Given the potential for non-relevant words and non-word elements introduced during unsupervised word segmentation, optimization strategies are further introduced, utilizing the product of left and right entropies as a screening criterion to aggregate and purify the vocabulary. By comparing the word segmentation results of specialized and non-specialized corpora, a professional vocabulary database in the field of power transformers has been successfully constructed. This accomplishment not only automates the recognition and accumulation of power industry-specific vocabulary but also lays a solid foundation for the subsequent construction of a knowledge graph for power transformers.},
booktitle = {Proceedings of the 2024 7th International Conference on Computer Information Science and Artificial Intelligence},
pages = {24–28},
numpages = {5},
keywords = {Knowledge graph, Power transformer, Professional term base, Word segmentation algorithm},
location = {
},
series = {CISAI '24}
}

@article{10.1145/3678183,
author = {Chi, Te-Yu and Jang, Jyh-Shing Roger},
title = {WC-SBERT: Zero-Shot Topic Classification Using SBERT and Light Self-Training on Wikipedia Categories},
year = {2024},
issue_date = {October 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {5},
issn = {2157-6904},
url = {https://doi.org/10.1145/3678183},
doi = {10.1145/3678183},
abstract = {In natural language processing (NLP), zero-shot topic classification requires machines to understand the contextual meanings of texts in a downstream task without using the corresponding labeled texts for training, which is highly desirable for various applications. In this article, we propose a novel approach to construct a zero-shot task-specific model called WC-SBERT with satisfactory performance. The proposed approach is highly efficient since it uses light self-training requiring target labels (target class names of downstream tasks) only, which is distinct from other research that uses both the target labels and the unlabeled texts for training. In particular, during the pre-training stage, WC-SBERT uses contrastive learning with multiple negative ranking losses to construct the pre-trained model based on the similarity between Wiki categories. For the self-training stage, online contrastive loss is utilized to reduce the distance between a target label and Wiki categories of similar Wiki pages to the label. Experimental results indicate that compared to existing self-training models, WC-SBERT achieves rapid inference on approximately 6.45 million Wiki text entries by utilizing pre-stored Wikipedia text embeddings, significantly reducing inference time per sample by a factor of 2,746 to 16,746. During the fine-tuning step, the time required for each sample is reduced by a factor of 23–67. Overall, the total training time shows a maximum reduction of 27.5 times across different datasets. Most importantly, our model has achieved state-of-the-art (SOTA) accuracy on two of the three commonly used datasets for evaluating zero-shot classification, namely the AG News (0.84) and Yahoo! Answers (0.64) datasets. The code for WC-SBERT is publicly available on GitHub,1 and the dataset can also be accessed on Hugging Face.2},
journal = {ACM Trans. Intell. Syst. Technol.},
month = oct,
articleno = {111},
numpages = {18},
keywords = {Zero-shot topic classification, SBERT, Wikipedia, Self-training, Contrastive learning, Knowledge graph, LLM}
}

@article{10.1145/3708326,
author = {Mountantonakis, Michalis and Tzitzikas, Yannis},
title = {Generating SPARQL Queries over CIDOC-CRM using a Two-Stage Ontology Path Patterns Method in LLM Prompts},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1556-4673},
url = {https://doi.org/10.1145/3708326},
doi = {10.1145/3708326},
abstract = {In this paper, we focus on the task of exploiting the capabilities of Large Language Models (LLMs) to generate SPARQL Queries for answering natural questions over cultural Knowledge Graphs (KGs) expressed according to the ISO standard ontology CIDOC-CRM. Since CIDOC-CRM is an event-based model, usually we have to follow long paths for answering a question, thereby, the challenge is how to construct the prompt for aiding the LLM to produce the right SPARQL query. We propose and comparatively evaluate methods based on the creation of ontology path patterns of a configurable path radius (or length). Then, we construct a new dedicated benchmark that includes 100 natural questions and the corresponding SPARQL queries over two real KGs from the cultural domain describing artworks. Finally, we present comparative results about the effectiveness and efficiency over the benchmark by using ChatGPT-3.5. The most effective method follows a two-stage process that predicts and uses the most appropriate path patterns of  (rleq 4) . This method achieves 3.5  (times)  higher accuracy than the baseline method (0.66 versus 0.19), that includes in the prompt only the list of properties and classes of the KG.Benchmark:},
note = {Just Accepted},
journal = {J. Comput. Cult. Herit.},
month = dec,
keywords = {Question Answering, CIDOC-CRM, Prompt Engineering, Cultural Heritage, LLM}
}

@inproceedings{10.1145/3613904.3642868,
author = {Wang, Sitong and Menon, Samia and Long, Tao and Henderson, Keren and Li, Dingzeyu and Crowston, Kevin and Hansen, Mark and Nickerson, Jeffrey V and Chilton, Lydia B},
title = {ReelFramer: Human-AI Co-Creation for News-to-Video Translation},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642868},
doi = {10.1145/3613904.3642868},
abstract = {Short videos on social media are the dominant way young people consume content. News outlets aim to reach audiences through news reels—short videos conveying news—but struggle to translate traditional journalistic formats into short, entertaining videos. To translate news into social media reels, we support journalists in reframing the narrative. In literature, narrative framing is a high-level structure that shapes the overall presentation of a story. We identified three narrative framings for reels that adapt social media norms but preserve news value, each with a different balance of information and entertainment. We introduce ReelFramer, a human-AI co-creative system that helps journalists translate print articles into scripts and storyboards. ReelFramer supports exploring multiple narrative framings to find one appropriate to the story. AI suggests foundational narrative details, including characters, plot, setting, and key information. ReelFramer also supports visual framing; AI suggests character and visual detail designs before generating a full storyboard. Our studies show that narrative framing introduces the necessary diversity to translate various articles into reels, and establishing foundational details helps generate scripts that are more relevant and coherent. We also discuss the benefits of using narrative framing and foundational details in content retargeting.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {169},
numpages = {20},
keywords = {creativity support tools, generative AI, narratives, scriptwriting, short videos, storyboarding},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3637528.3671997,
author = {Cao, Zongsheng and Li, Jing and Wang, Zigan and Li, Jinliang},
title = {DiffusionE: Reasoning on Knowledge Graphs via Diffusion-based Graph Neural Networks},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671997},
doi = {10.1145/3637528.3671997},
abstract = {Graph Neural Networks (GNNs) have demonstrated powerful capabilities in reasoning within Knowledge Graphs (KGs), gathering increasing attention. Our idea stems from the observation that the prior work typically employs hand-designed or sample-designed paradigms in the process of message propagation, engaging a set of adjacent entities at each step of propagation. As a result, such methods struggle with the increasing number of entities involved as propagation steps extend. Moreover, they neglect the message interactions between adjacent entities and propagation relations in KG reasoning, leading to semantic inconsistency during the message aggregation phase. To address these issues, we introduce a novel knowledge graph embedding method through a diffusion process, termed DiffusionE. Specifically, we reformulate the message propagation in knowledge reasoning as a diffusion process, regarding the message semantics as the diffusion signal. In this sense, guided by semantic information, messages can be transmitted between nodes effectively and adaptively. Furthermore, the theoretical analysis suggests our method can leverage an optimal diffusivity for message propagation in the semantic interactions of KGs. It shows that DiffusionE effectively leverages message interactions between entities and propagation relations, ensuring semantic consistency in KG reasoning. Comprehensive experiments reveal that our method attains state-of-the-art performance compared to prior work on several well-established benchmarks.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {222–230},
numpages = {9},
keywords = {diffusion process, graph neural networks, knowledge graph},
location = {Barcelona, Spain},
series = {KDD '24}
}

@inproceedings{10.1145/3627673.3679781,
author = {Mannino, Miro and Garcia, Junior and Hazim, Reem and Abouzied, Azza and Papotti, Paolo},
title = {Data Void Exploits: Tracking &amp; Mitigation Strategies},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679781},
doi = {10.1145/3627673.3679781},
abstract = {A data void is a gap in online information, providing an opportunity for the spread of disinformation or a data void exploit. We introduce lightweight measures to track the progress of data void exploits and mitigation efforts in two contexts: Web search and Knowledge Graph (KG) querying. We use case studies to demonstrate the viability of these measures as data void trackers in the Web search context. To tackle data voids, we introduce an adversarial game model involving two agents: a disinformer and a mitigator. Both agents insert content into the information ecosystem to have their narrative rank higher than their counterpart in search results. At every turn, each agent chooses which content to deploy within their resource constraints, mimicking real-world situations where different entities have varying levels of influence and access to resources. Using simulations of this game, we compare and evaluate different mitigation strategies to recommend ones that maximize mitigation impact while minimizing costs.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {1627–1637},
numpages = {11},
keywords = {data void, exploit, knowledge graph, misinformation, web search},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@inproceedings{10.1145/3637528.3671837,
author = {Ning, Liang-bo and Wang, Shijie and Fan, Wenqi and Li, Qing and Xu, Xin and Chen, Hao and Huang, Feiran},
title = {CheatAgent: Attacking LLM-Empowered Recommender Systems via LLM Agent},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671837},
doi = {10.1145/3637528.3671837},
abstract = {Recently, Large Language Model (LLM)-empowered recommender systems (RecSys) have brought significant advances in personalized user experience and have attracted considerable attention. Despite the impressive progress, the research question regarding the safety vulnerability of LLM-empowered RecSys still remains largely under-investigated. Given the security and privacy concerns, it is more practical to focus on attacking the black-box RecSys, where attackers can only observe the system's inputs and outputs. However, traditional attack approaches employing reinforcement learning (RL) agents are not effective for attacking LLM-empowered RecSys due to the limited capabilities in processing complex textual inputs, planning, and reasoning. On the other hand, LLMs provide unprecedented opportunities to serve as attack agents to attack RecSys because of their impressive capability in simulating human-like decision-making processes. Therefore, in this paper, we propose a novel attack framework called CheatAgent by harnessing the human-like capabilities of LLMs, where an LLM-based agent is developed to attack LLM-Empowered RecSys. Specifically, our method first identifies the insertion position for maximum impact with minimal input modification. After that, the LLM agent is designed to generate adversarial perturbations to insert at target positions. To further improve the quality of generated perturbations, we utilize the prompt tuning technique to improve attacking strategies via feedback from the victim RecSys iteratively. Extensive experiments across three real-world datasets demonstrate the effectiveness of our proposed attacking method.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {2284–2295},
numpages = {12},
keywords = {adversarial attacks, large language models, llm-empowered recommender systems, llms-based agent, recommender systems},
location = {Barcelona, Spain},
series = {KDD '24}
}

@inproceedings{10.1145/3627673.3679894,
author = {Kasuga, Akira and Yonetani, Ryo},
title = {CXSimulator: A User Behavior Simulation using LLM Embeddings for Web-Marketing Campaign Assessment},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679894},
doi = {10.1145/3627673.3679894},
abstract = {This paper presents the Customer Experience (CX) Simulator, a novel framework designed to assess the effects of untested web-marketing campaigns through user behavior simulations. The proposed framework leverages large language models (LLMs) to represent various events in a user's behavioral history, such as viewing an item, applying a coupon, or purchasing an item, as semantic embedding vectors. We train a model to predict transitions between events from their LLM embeddings, which can even generalize to unseen events by learning from diverse training data. In web-marketing applications, we leverage this transition prediction model to simulate how users might react differently when new campaigns or products are presented to them. This allows us to eliminate the need for costly online testing and enhance the marketers' abilities to reveal insights. Our numerical evaluation and user study, utilizing BigQuery Public Datasets from the Google Merchandise Store, demonstrate the effectiveness of our framework.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {3817–3821},
numpages = {5},
keywords = {embedding, large language model, link prediction, marketing campaign, user simulation},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@inproceedings{10.1145/3627673.3680268,
author = {Colombo, Andrea},
title = {Leveraging Knowledge Graphs and LLMs to Support and Monitor Legislative Systems},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3680268},
doi = {10.1145/3627673.3680268},
abstract = {Knowledge Graphs (KGs) have been used to organize large datasets into structured, interconnected information, enhancing data analytics across various fields. In the legislative context, one potential natural application of KGs is modeling the intricate set of interconnections that link laws and their articles with each other and the broader legislative context.At the same time, the rise of large language models (LLMs) such as GPT has opened new opportunities in legal applications, such as text generation and document drafting. Despite their potential, the use of LLMs in legislative contexts is critical since it requires the absence of hallucinations and reliance on up-to-date information, as new laws are published on a daily basis.This work investigates how Legislative Knowledge Graphs and LLMs can synergize and support legislative processes. We address three key questions: the benefits of using KGs for legislative systems, how LLM can support legislative activities by ensuring an accurate output, and how we can allow non-technical users to use such technologies in their activities. To this aim, we develop Legis AI Platform, an interactive platform focused on Italian legislation that enhances the possibility of conducting legislative analysis and that aims to support lawmaking activities.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {5443–5446},
numpages = {4},
keywords = {graphrag, knowledge graph, large language models, laws, legislative systems},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@inproceedings{10.1145/3652583.3658069,
author = {Mu, Hongzhang and Zhang, Shuili and Xu, Hongbo},
title = {A Knowledge-Driven Approach to Enhance Topic Modeling with Multi-Modal Representation Learning},
year = {2024},
isbn = {9798400706196},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652583.3658069},
doi = {10.1145/3652583.3658069},
abstract = {multi-modal topic models strive to integrate semantic information from multi-modal data to generate more precise topics. Topic modeling methods encounter challenges in terms of topic diversity and effectiveness. To address this issue, the majority of current approaches focus on modeling the correlation among numerous multi-modal sources. Nevertheless, little emphasis has been placed on fine-grained feature representation and structured knowledge. In this regard, we propose a fine-grained Prompt representation method. Specifically, we adopt a dual-stream structure where a pre-trained language model and an image model are parallelly combined to construct a multi-modal model. We then enhance the structured representation by integrating fine-grained scene graph knowledge through a Knowledge-Enhanced Encoder, which is constructed based on the scene graph. To validate the effectiveness of the proposed framework, we significantly improve topic quality (such as coherence and diversity) using the aforementioned approach. On publicly available datasets, our approach outperforms state-of-the-art multi-modal topic models respectively.},
booktitle = {Proceedings of the 2024 International Conference on Multimedia Retrieval},
pages = {1347–1355},
numpages = {9},
keywords = {deep learning, knowledge graph, multi-modal, topic model},
location = {Phuket, Thailand},
series = {ICMR '24}
}

@inproceedings{10.1145/3589335.3651263,
author = {Jain, Monika},
title = {Knowledge Enabled Relation Extraction},
year = {2024},
isbn = {9798400701726},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589335.3651263},
doi = {10.1145/3589335.3651263},
abstract = {Relation extraction is the task of extracting relationships from input text, where input can be a sentence, document, or multiple documents. This task has been popular for decades and is still of keen interest. Various techniques have been proposed to solve the relation extraction problem, among which the most popular are using distant supervision, deep learning-based models, reasoning-based models, and transformer-based models. We propose three approaches (named ReOnto, DocRE-CLip, and KDocRE) for relation extraction from text at three levels of granularity (sentence, document and across documents). These approaches embed knowledge in a deep learning based model to improve performance. ReOnto and DocRE-CLip have been evaluated and the source code is publicly available. We are currently implementing and evaluating KDocRE.},
booktitle = {Companion Proceedings of the ACM Web Conference 2024},
pages = {1210–1213},
numpages = {4},
keywords = {graph neural network, knowledge graph, neurosymbolic ai, ontology, relation extraction},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3639479.3639484,
author = {Zhang, Liqi and Yang, Lianhe and Bai, Yinhao and Zhu, Hongfei and Liu, Xingyu},
title = {R-TES: Regularized Template Style for Generative Joint Relational Triple Extraction},
year = {2024},
isbn = {9798400709241},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639479.3639484},
doi = {10.1145/3639479.3639484},
abstract = {Joint Relational Triple Extraction (RTE) is an important task in the field of information extraction. With the development of the pre-trained language models, the sequence-to-sequence (seq2seq) approaches have become one of the promising methods for this task, utilizing a predefined template to convert the relational triples into a structure target sequence, which can be easily decoded as relational triples. However, most existing seq2seq studies focus on the improvement of methods but ignore that template styles also have impacts on performance. Inspired by this idea, we first explore the effects of different template styles on performance and find that some template styles can help generate models to achieve better performance. Based on the above findings, we argue that different template styles lead to various understandings of the relation triple. Therefore, we propose Regularized template style (R-TES) to improve the performance of a main template by reducing the gap between it and other selected templates. Specifically, R-TES uses the pre-trained language model to select the templates with kullback-leibler (KL) divergence. Then, we further reduce the gap between the main template and these selected templates by minimizing KL divergence. Experimental results show that our method outperforms state-of-the-art methods on the publicly available dataset.},
booktitle = {Proceedings of the 2023 6th International Conference on Machine Learning and Natural Language Processing},
pages = {21–26},
numpages = {6},
keywords = {information extraction, language model, neural networks},
location = {Sanya, China},
series = {MLNLP '23}
}

@inproceedings{10.1145/3695080.3695127,
author = {Chen, Hao and Hou, Jun},
title = {Intelligent data governance: building an enterprise data management system using KG and LLM},
year = {2024},
isbn = {9798400710223},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3695080.3695127},
doi = {10.1145/3695080.3695127},
abstract = {In tobacco enterprises, data governance is the key to improving operational efficiency and decision-making quality. This study focuses on how to build an advanced data management system for tobacco enterprises through knowledge graph (KG) and large language model (LLM). Firstly, this paper describes the process of integrating the core resources of tobacco enterprises, such as metadata, data elements, data constraints, arithmetic, storage and network, into a KG. Subsequently, it analyses in depth how to use local LLM combined with the KG to form a ‘think tank’ for tobacco enterprise data governance. This think tank would not only be able to store and process the vast amount of data governance information in the tobacco industry, but also provide intelligent recommendations, predict future trends, and diagnose problems in existing data governance processes. In addition, the paper discusses the potential impact of this integrated approach on enhancing data governance strategies, improving data quality and compliance in tobacco organisations, as well as its role in fostering cross-functional collaboration and improving data governance efficiency. A series of recommendations for implementing and optimising such an integrated data governance system are also presented to address the specificities of the tobacco industry, such as the high requirements for data security and regulatory compliance. These recommendations are designed to help tobacco organisations manage their growing data assets more effectively and ensure data security and compliance to stay ahead of the game in a competitive market. With this advanced data governance system, tobacco companies can better adapt to the trend of digital transformation and maximise the use of their data assets.},
booktitle = {Proceedings of the 2024 International Conference on Cloud Computing and Big Data},
pages = {266–271},
numpages = {6},
location = {Dali, China},
series = {ICCBD '24}
}

@inproceedings{10.1145/3589335.3651955,
author = {Zhu, Lixi and Huang, Xiaowen and Sang, Jitao},
title = {How Reliable is Your Simulator? Analysis on the Limitations of Current LLM-based User Simulators for Conversational Recommendation},
year = {2024},
isbn = {9798400701726},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589335.3651955},
doi = {10.1145/3589335.3651955},
abstract = {Conversational Recommender System (CRS) interacts with users through natural language to understand their preferences and provide personalized recommendations in real-time. CRS has demonstrated significant potential, prompting researchers to address the development of more realistic and reliable user simulators as a key focus. Recently, the capabilities of Large Language Models (LLMs) have attracted a lot of attention in various fields. Simultaneously, efforts are underway to construct user simulators based on LLMs. While these works showcase innovation, they also come with certain limitations that require attention. In this work, we aim to analyze the limitations of using LLMs in constructing user simulators for CRS, to guide future research. To achieve this goal, we conduct analytical validation on the notable work, iEvaLM. Through multiple experiments on two widely-used datasets in the field of conversational recommendation, we highlight several issues with the current evaluation methods for user simulators based on LLMs: (1) Data leakage, which occurs in conversational history and the user simulator's replies, results in inflated evaluation results. (2) The success of CRS recommendations depends more on the availability and quality of conversational history than on the responses from user simulators. (3) Controlling the output of the user simulator through a single prompt template proves challenging. To overcome these limitations, we propose SimpleUserSim, employing a straightforward strategy to guide the topic toward the target items. Our study validates the ability of CRS models to utilize the interaction information, significantly improving the recommendation results.},
booktitle = {Companion Proceedings of the ACM Web Conference 2024},
pages = {1726–1732},
numpages = {7},
keywords = {conversational recommendation system, large language model, user simulator},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3589334.3645397,
author = {Sun, Chenchen and Xu, Yang and Shen, Derong and Nie, Tiezheng},
title = {Matching Feature Separation Network for Domain Adaptation in Entity Matching},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3645397},
doi = {10.1145/3589334.3645397},
abstract = {Entity matching (EM) determines whether two records from different data sources refer to the same real-world entity. It is a fundamental task in knowledge graph construction and data integration. Currently, deep learning (DL) based EM methods have achieved state-of-the-art (SOTA) results. However, apply-ing DL-based EM methods often costs a lot of human efforts to label the data. To address this challenge, we propose a new do-main adaptation (DA) framework for EM called Matching Fea-ture Separation Network (MFSN). We implement DA by sepa-rating private and common matching features. Briefly, MFSN first uses three encoders to explicitly model the private and common matching features in both the source and target do-mains. Then, it transfers the knowledge learned from the source common matching features to the target domain. We also pro-pose an enhanced variant called Feature Representation and Separation Enhanced MFSN (MFSN-FRSE). Compared with MFSN, it has superior feature representation and separation capabilities. We evaluate the effectiveness of MFSN and MFSN-FRSE on twelve DA in EM tasks. The results show that our framework is approximately 7% higher in F1 score on average than the previous SOTA methods. Then, we verify the effec-tiveness of each module in MFSN and MFSN-FRSE by ablation study. Finally, we explore the optimal strategy of each module in MFSN and MFSN-FRSE through detailed tests.},
booktitle = {Proceedings of the ACM Web Conference 2024},
pages = {1975–1985},
numpages = {11},
keywords = {data integration, domain adaptation, entity matching, knowledge graph construction, matching feature separation network},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3639233.3639347,
author = {Wang, Jingdong and Guo, Yongjia},
title = {Named Entities Based on the BERT-BILSTM-ACRF Model Recognition Research},
year = {2024},
isbn = {9798400709227},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639233.3639347},
doi = {10.1145/3639233.3639347},
abstract = {As a crucial first step in the process of constructing knowledge graph, the accuracy of named entity recognition determines the construction effect of the final graph. However, at present, Chinese named entity recognition methods still have many problems, such as long training time and lower accuracy. Hence, we come up with a BERT-BILSTM-ACRF entity recognition method that combines the “self-attention” mechanism. To begin with, Bert model is selected as the embedding layer, the text is vectorized, and the character position in-formation is obtained through the bidirectional Long Short-Term Memory network. Secondly, the internal relationship of the character sequence is further searched through the self-attention mechanism, and finally the final optimal sequence is decoded by the conditional random field model. To check the effectiveness of the BERT-BILSTM-ACRF model, the model is applied to the data set of the university course textbook” Da-ta Structure”, and the result reaches 98.97%F1 value and 98.14%accuracy, which has good experimental results and certain practical value.},
booktitle = {Proceedings of the 2023 7th International Conference on Natural Language Processing and Information Retrieval},
pages = {228–233},
numpages = {6},
keywords = {Knowledge graph, Named entity recognition, Natural language processing, Self-attention mechanism},
location = {Seoul, Republic of Korea},
series = {NLPIR '23}
}

@inproceedings{10.1109/ASE56229.2023.00131,
author = {Chakraborty, Sarthak and Agarwal, Shubham and Garg, Shaddy and Sethia, Abhimanyu and Pandey, Udit Narayan and Aggarwal, Videh and Saini, Shiv},
title = {ESRO: Experience Assisted Service Reliability against Outages},
year = {2024},
isbn = {9798350329964},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASE56229.2023.00131},
doi = {10.1109/ASE56229.2023.00131},
abstract = {Modern cloud services are prone to failures due to their complex architecture, making diagnosis a critical process. Site Reliability Engineers (SREs) spend hours leveraging multiple sources of data, including the alerts, error logs, and domain expertise through past experiences to locate the root cause(s). These experiences are documented as natural language text in outage reports for previous outages. However, utilizing the raw yet rich semi-structured information in the reports systematically is time-consuming. Structured information, on the other hand, such as alerts that are often used during fault diagnosis, is voluminous and requires expert knowledge to discern. Several strategies have been proposed to use each source of data separately for root cause analysis. In this work, we build a diagnostic service called ESRO that recommends root causes and remediation for failures by utilizing structured as well as semi-structured sources of data systematically. ESRO constructs a causal graph using alerts and a knowledge graph using outage reports, and merges them in a novel way to form a unified graph during training. A retrieval-based mechanism is then used to search the unified graph and rank the likely root causes and remediation techniques based on the alerts fired during an outage at inference time. Not only the individual alerts, but their respective importance in predicting an outage group is taken into account during recommendation. We evaluated our model on several cloud service outages of a large SaaS enterprise over the course of ~2 years, and obtained an average improvement of 27% in rouge scores after comparing the likely root causes against the ground truth over state-of-the-art baselines. We further establish the effectiveness of ESRO through qualitative analysis on multiple real outage examples.},
booktitle = {Proceedings of the 38th IEEE/ACM International Conference on Automated Software Engineering},
pages = {255–267},
numpages = {13},
keywords = {system monitoring, cloud services, causal graph, knowledge graph},
location = {Echternach, Luxembourg},
series = {ASE '23}
}

@inproceedings{10.1145/3640912.3640993,
author = {He, Meng and Bai, Yunli},
title = {LAL-JER: Label-Aware Learning for Adaptive Joint Entity and Relation Extraction with LLM data augmentation},
year = {2024},
isbn = {9798400716683},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3640912.3640993},
doi = {10.1145/3640912.3640993},
abstract = {Joint entity and relation extraction has achieved great improvements in Natural Language Processing (NLP) and has been widely applied, such as constructing knowledge graph, query understanding and question answering. Existing methods usually spend long time on fitting the models on certain datasets with given label type, which greatly lacks the ability of generalization. The model cannot make prediction on label types that have not seen in the training set. To address this issue, we propose to use prompt to incorporate the semantic meaning of the label type description. Furthermore, we use large language model to perform data augmentation to improve the robustness of our model during training. Extensive experiments and ablation study on two joint entity and relation extraction validates the effectiveness of our work on that: 1. Our methods achieved states of art performance on joint entity and relation extraction benchmark based on pretrained language model bert. 2. Our methods can help the model make predictions on label type unseen before given prompts.},
booktitle = {Proceedings of the 2023 International Conference on Communication Network and Machine Learning},
pages = {414–419},
numpages = {6},
location = {Zhengzhou, China},
series = {CNML '23}
}

@inproceedings{10.1145/3675417.3675574,
author = {Ji, Wei and Sun, Jian and Chen, Biaoxin and Luo, Chuangli},
title = {The Current Status and Trends of Research on the Impact of Generative Artificial Intelligence on Employment in China},
year = {2024},
isbn = {9798400717147},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3675417.3675574},
doi = {10.1145/3675417.3675574},
abstract = {With the increasing expansion of technology application scenarios, generative artificial intelligence is set to significantly boost global productivity and profoundly impact China's employment market. This article employs 218 academic papers from 2013 to 2023, featured in Peking University's core journals and CSSCI, focusing on generative AI's impact on China's job market, for quantitative analysis using CiteSpace software. Multidimensional exploration of research overviews and hotspots reveals that the evolving and rapid application of generative AI on China's employment market becomes more and more in-depth. On this basis, the paper analyzes the challenges and opportunities generative AI presents to China's job market and proposes corresponding strategies.},
booktitle = {Proceedings of the 2024 Guangdong-Hong Kong-Macao Greater Bay Area International Conference on Digital Economy and Artificial Intelligence},
pages = {948–953},
numpages = {6},
location = {Hongkong, China},
series = {DEAI '24}
}

@inproceedings{10.1145/3670474.3685952,
author = {Qin, Zongyue and Bai, Yunsheng and Sohrabizadeh, Atefeh and Ding, Zijian and Hu, Ziniu and Sun, Yizhou and Cong, Jason},
title = {Cross-Modality Program Representation Learning for Electronic Design Automation with High-Level Synthesis},
year = {2024},
isbn = {9798400706998},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3670474.3685952},
doi = {10.1145/3670474.3685952},
abstract = {In recent years, domain-specific accelerators (DSAs) have gained popularity for applications such as deep learning and autonomous driving. To facilitate DSA designs, programmers use high-level synthesis (HLS) to compile a high-level description written in C/C++ into a design with low-level hardware description languages that eventually synthesize DSAs on circuits. However, creating a high-quality HLS design still demands significant domain knowledge, particularly in microarchitecture decisions expressed as pragmas. Thus, it is desirable to automate such decisions with the help of machine learning for predicting the quality of HLS designs, requiring a deeper understanding of the program that consists of original code and pragmas. Naturally, these programs can be considered as sequence data. In addition, these programs can be compiled and converted into a control data flow graph (CDFG). But existing works either fail to leverage both modalities or combine the two in shallow or coarse ways. We propose ProgSG, a model that allows interaction between the source code sequence modality and the graph modality in a deep and fine-grained way. To alleviate the scarcity of labeled designs, a pre-training method is proposed based on a suite of compiler's data flow analysis tasks. Experimental results show that ProgSG reduces the RMSE of design performance predictions by up to 22%, and identifies designs with an average of 1.10\texttimes{} and 1.26\texttimes{} (up to 8.17\texttimes{} and 13.31\texttimes{}) performance improvement in design space exploration (DSE) task compared to HARP and AutoDSE, respectively.},
booktitle = {Proceedings of the 2024 ACM/IEEE International Symposium on Machine Learning for CAD},
articleno = {14},
numpages = {12},
keywords = {FPGA, GNN, HLS, Language Model},
location = {Salt Lake City, UT, USA},
series = {MLCAD '24}
}

@inproceedings{10.1145/3632410.3633291,
author = {Tripathi, Sandhya and King, Christopher Ryan},
title = {Contrastive learning: Big Data Foundations and Applications},
year = {2024},
isbn = {9798400716348},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3632410.3633291},
doi = {10.1145/3632410.3633291},
abstract = {Contrastive learning (CL) has exploded in popularity due to its ability to learn effective representations using vast quantities of unlabelled data across multiple domains. CL underlies some of the most impressive applications of generative AI for the general public. We will review the fundamentals and applied work on contrastive learning representations focusing on three main topics: 1) CL in supervised, unsupervised and self-supervised setup and its revival in AI research as an instance discriminator. In this part, we will focus on learning about the nuts and bolts, such as different augmentation techniques, loss functions, performance evaluation metrics, and some theoretical understanding of contrastive loss. We will also present the methods supporting DALL · E 2, a popular generative AI. 2) Learning contrastive representations across vision, text, time series, tabular data and knowledge graph modalities. Specifically, we will present the literature representative of solution approaches regarding new augmentation techniques, modification in the loss function, and additional information. The first two parts will also have small hands-on session on the application shown and some of the methods learned. 3) Discussing the various theoretical and empirical claims for CL’s success, including the role of negative examples. We will also present some work that challenges the shared information assumption of CL and propose alternative explanations. Finally, we will conclude with some future directions and applications for CL.},
booktitle = {Proceedings of the 7th Joint International Conference on Data Science &amp; Management of Data (11th ACM IKDD CODS and 29th COMAD)},
pages = {493–497},
numpages = {5},
keywords = {augmentations, clustering, contrastive learning, distillation, graphs, multi-modal, multi-view, noise estimation loss, tabular datasets, time-series},
location = {Bangalore, India},
series = {CODS-COMAD '24}
}

@inproceedings{10.1145/3627673.3679085,
author = {Vakaj, Edlira and Mihindukulasooriya, Nandana and Gaur, Manas and Khan, Arijit},
title = {Knowledge Graphs for Responsible AI},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679085},
doi = {10.1145/3627673.3679085},
abstract = {Responsible AI is built upon a set of principles that prioritize fairness, transparency, accountability, and inclusivity in AI development and deployment. As AI systems become increasingly sophisticated, including the explosion of generative AI, there is a growing need to address ethical considerations and potential societal impacts of their uses. Knowledge graphs (KGs), as structured representations of information, can enhance generative AI performance by providing context, explaining outputs, and reducing biases, thereby offering a powerful framework to address the challenges of responsible AI. By leveraging semantic relationships and contextual understanding, KGs facilitate transparent decision-making, enabling stakeholders to trace and interpret the reasoning behind AI driven outcomes. Moreover, they provide a means to capture and manage diverse knowledge sources, supporting the development of fair and unbiased AI models. The workshop aims to investigate the role of knowledge graphs in promoting responsible AI principles and creating a cooperative space for researchers, practitioners, and policymakers to exchange insights and enhance their comprehension of KGs' impact on achieving responsible AI solutions. It seeks to facilitate collaboration and idea-sharing to advance the understanding of how KGs can contribute to responsible AI.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {5596–5598},
numpages = {3},
keywords = {bias mitigation, ethical AI, fairness, interpretability, knowledge graphs, large language models, privacy, responsible AI},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@inproceedings{10.1145/3627673.3680119,
author = {Xu, Jiejun and Tong, Hanghang and Bertozzi, Andrea},
title = {The 8th Workshop on Graph Techniques for Adversarial Activity Analytics (GTA3 2024)},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3680119},
doi = {10.1145/3627673.3680119},
abstract = {Graphs are powerful analytic tools for modeling adversarial activities across a wide range of domains and applications. Examples include identifying and responding to cybersecurity systems' threats and vulnerabilities, strengthening critical infrastructure's resilience and robustness, and combating covert illicit activities that span various domains like finance, communication, and transportation. With the rapid development of generative AI, the lifecycle and throughput of adversarial activities, such as generating attacks or synthesizing deceptive signals, have accelerated significantly. For instance, a malicious actor can generate a large number of malware variants to flood defense systems or create agents to disseminate misleading signals, obscuring their activities. Consequently, there is a pressing need for novel and effective technology to autonomously handle these adversarial activities and keep pace with the evolving threats. The purpose of this workshop is to provide a forum to discuss emerging research problems and novel approaches in graph analysis for modeling adversarial activities in the age of generative AI.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {5603–5604},
numpages = {2},
keywords = {adversarial activity analytics, graph machine learning, graph mining, knowledge representation},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@inproceedings{10.1145/3626772.3657790,
author = {Wang, Duokang and Hu, Linmei and Hao, Rui and Shao, Yingxia and Lv, Xin and Nie, Liqiang and Li, Juanzi},
title = {Let Me Show You Step by Step: An Interpretable Graph Routing Network for Knowledge-based Visual Question Answering},
year = {2024},
isbn = {9798400704314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626772.3657790},
doi = {10.1145/3626772.3657790},
abstract = {Visual Question Answering based on external Knowledge Bases (KB-VQA) requires a model to incorporate knowledge beyond the content of given image and question for answer prediction. Most existing works made efforts on using graph neural networks or Multi-modal Large Language Models to incorporate external knowledge for answer generation. Despite the promising results, they have limited interpretability and exhibit a deficiency in handling questions with unseen answers. In this paper, we propose a novel interpretable graph routing network (GRN) which explicitly conducts entity routing over a constructed scene knowledge graph step by step for KB-VQA. At each step, GRN keeps an entity score vector representing how likely of each entity to be activated as the answer, and a transition matrix representing the transition probability from one entity to another. To answer the given question, GRN will focus on certain keywords of the question at each step and correspondingly conduct entity routing by transiting the entity scores according to the transition matrix computed referring to the focused question keywords. In this way, it clearly provides the reasoning process of KB-VQA and can handle the questions with unseen answers without distinction. Experiments on the benchmark dataset KRVQA have demonstrated that GRN improves the performance of KB-VQA by a large margin, surpassing existing state-of-the art KB-VQA methods and Multi-modal Large Language Models, as well as shows competent capability in handling unseen answers and good interpretability in KB-VQA.},
booktitle = {Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {1984–1994},
numpages = {11},
keywords = {graph routing network, knowledge-based visual question answering, scene knowledge graph},
location = {Washington DC, USA},
series = {SIGIR '24}
}

@inproceedings{10.1145/3664647.3680717,
author = {yuan, li and Cai, Yi and Huang, Junsheng},
title = {Few-Shot Joint Multimodal Entity-Relation Extraction via Knowledge-Enhanced Cross-modal Prompt Model},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3680717},
doi = {10.1145/3664647.3680717},
abstract = {Joint Multimodal Entity-Relation Extraction (JMERE) is a challenging task that aims to extract entities and their relations from textimage pairs in social media posts. Existing methods for JMERE require large amounts of labeled data. However, gathering and annotating fine-grained multimodal data for JMERE poses significant challenges. Initially, we construct diverse and comprehensive multimodal few-shot datasets fitted to the original data distribution. To address the insufficient information in the few-shot setting, we introduce the Knowledge-Enhanced Cross-modal Prompt Model (KECPM) for JMERE. This method can effectively address the problem of insufficient information in the few-shot setting by guiding a large language model to generate supplementary background knowledge. Our proposed method comprises two stages: (1) a knowledge ingestion stage that dynamically formulates prompts based on semantic similarity guide ChatGPT generating relevant knowledge and employs self-reflection to refine the knowledge; (2) a knowledge-enhanced language model stage that merges the auxiliary knowledge with the original input and utilizes a transformerbased model to align with JMERE's required output format. We extensively evaluate our approach on a few-shot dataset derived from the JMERE dataset, demonstrating its superiority over strong baselines in terms of both micro and macro F1 scores. Additionally, we present qualitative analyses and case studies to elucidate the effectiveness of our model. Code and Data are released at https://github.com/YuanLi95/KECPM.},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {8701–8710},
numpages = {10},
keywords = {few-shot learning, large language model, multimodal information extraction},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@proceedings{10.1145/3657604,
title = {L@S '24: Proceedings of the Eleventh ACM Conference on Learning @ Scale},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our great pleasure to present the Proceedings of the Eleventh Annual ACM Conference on Learning at Scale, L@S 2024, held July 18-20, 2024 at Georgia Tech in Atlanta, Georgia, USA.The Learning at Scale conference was created by the Association for Computing Machinery (ACM), inspired by the emergence of Massive Open Online Courses (MOOCs) and the accompanying shift in thinking about education. During the last few years, new opportunities for scaling up learning have emerged, like hybrid learning environments combining online and face-to-face, and informal learning enabled by all sorts of platforms (e.g., gamified language learning, citizen science communities, and collaborative programming communities). In the recent two years, the unprecedented development of generative AI has brought profound opportunities to scale the teaching and learning experiences, with the goal of enhancing learning for the increasingly diverse group of learners in both formal and informal contexts. L@S has evolved along with these emergent massive learning scenarios and opportunities and is today one of the most prominent venues for discussion of the highest quality of research on how learning and teaching can be transformed at scale, in diverse learning environments.The theme of L@S 2024 is Scaling Learning in the Age of AI. Rapid advances in AI have created new opportunities but also challenges for the Learning@Scale community. The advances in generative AI show potential to enhance pedagogical practices and the efficacy of learning at scale. This has led to an unprecedented level of interest in employing generative AI for scaling tutoring and feedback. The prevalence of such tools calls for new practices and understanding on how AI-based methods should be designed and developed to enhance the experiences and outcomes of teachers and learners.Learning@Scale 2024 solicits empirical and theoretical papers on, but not limited to, the following topics (in no particular order): 1) Instruction at scale: studies that examine how teachers and educators scale their instructions, what aspects of instruction could be scaled effectively, and which of these instructional strategies are the most effective for learning. 2) Interventions at scale: studies that examine the effects of interventions on student learning and performance when implemented at scale. We welcome studies that use both qualitative and quantitative methods. 3) The use of generative AI to scale learning: studies that investigate stakeholders' experiences with generative AI, students' and teachers' interactions with generative AI, and the potentials and limitations of using generative AI in education. 4) Systems and tools to support learning at scale: research that designs and develops systems and tools to support learning at scale. For example, this involves scaling learning through web-based systems, MOOCs, visualization, intelligent tutoring systems, gamification, immersive techniques (AR/VR/MR), mobile technologies, tangible interfaces, and various other technologies. 5) The evaluation of existing learning at scale systems and online learning environments using but not limited to the above-mentioned technologies. 6) Methods and algorithms that model learner behavior: research that contributes methods, algorithms, and pipelines that process large student data to enhance learning at scale. 7) Scaling learning in informal contexts: studies that explore how people take advantage of online environments to pursue their interests informally. 8) Review and synthesis of existing literature related to learning at scale. 9) Empirical studies and interventions that address equity, trust, algorithmic transparency and explainability, fairness and bias when using AI in education. 10) Research that addresses accessibility in learning at scale contexts. 11) Design and deployment of learning at scale systems for learners from underrepresented groups.},
location = {Atlanta, GA, USA}
}

@inproceedings{10.1145/3691422.3691471,
author = {Ma, Xiaoqian},
title = {The potential legal risks of artificial intelligence},
year = {2025},
isbn = {9798400717260},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691422.3691471},
doi = {10.1145/3691422.3691471},
abstract = {ChatGPT, as a typical application of generative artificial intelligence, means that human society is moving towards the "era of high knowledge revolution". From the perspective of functionalism, generative artificial intelligence will certainly have an important impact on the reshaping of legal society at the level of "instrument" and "Tao". However, while generative AI is deeply embedded in Chinese society, it also impacts personal information security on a large scale, challenges national security, causes intellectual property rights disputes, and academic ethics irregularities. Therefore, it is necessary for the national regulatory authorities to exercise careful governance, formulate accurate and fair market access guidelines and mechanism accountability systems, improve the public's awareness of risk prevention, and gradually improve the generative AI governance system.},
booktitle = {Proceedings of the 2024 15th International Conference on E-Business, Management and Economics},
pages = {366–370},
numpages = {5},
keywords = {ChatGPT, Generative artificial intelligence, Legal regulation, Risk management},
location = {
},
series = {ICEME '24}
}

@inproceedings{10.1145/3589334.3645584,
author = {Shi, Jingchuan and Dong, Hang and Chen, Jiaoyan and Wu, Zhe and Horrocks, Ian},
title = {Taxonomy Completion via Implicit Concept Insertion},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3645584},
doi = {10.1145/3589334.3645584},
abstract = {beginabstract High quality taxonomies play a critical role in various domains such as e-commerce, web search and ontology engineering. While there has been extensive work on expanding taxonomies from externally mined data, there has been less attention paid to enriching taxonomies by exploiting existing concepts and structure within the taxonomy. In this work, we show the usefulness of this kind of enrichment, and explore its viability with a new taxonomy completion system ICON (I mplicit CON cept Insertion). ICON generates new concepts by identifying implicit concepts based on the existing concept structure, generating names for such concepts and inserting them in appropriate positions within the taxonomy. ICON integrates techniques from entity retrieval, text summary, and subsumption prediction; this modular architecture offers high flexibility while achieving state-of-the-art performance. We have evaluated ICON on two e-commerce taxonomies, and the results show that it offers significant advantages over strong baselines including recent taxonomy completion models and the large language model, ChatGPT.},
booktitle = {Proceedings of the ACM Web Conference 2024},
pages = {2159–2169},
numpages = {11},
keywords = {ontology engineering, pre-trained language model, taxonomy completion, taxonomy enrichment, text summarisation},
location = {Singapore, Singapore},
series = {WWW '24}
}

@article{10.1145/3639363,
author = {Fan, Wenfei and Lu, Ping and Pang, Kehan and Jin, Ruochun and Yu, Wenyuan},
title = {Linking Entities across Relations and Graphs},
year = {2024},
issue_date = {March 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {49},
number = {1},
issn = {0362-5915},
url = {https://doi.org/10.1145/3639363},
doi = {10.1145/3639363},
abstract = {This article proposes a notion of parametric simulation to link entities across a relational database 𝒟 and a graph G. Taking functions and thresholds for measuring vertex closeness, path associations, and important properties as parameters, parametric simulation identifies tuples t in 𝒟 and vertices v in G that refer to the same real-world entity, based on both topological and semantic matching. We develop machine learning methods to learn the parameter functions and thresholds. We show that parametric simulation is in quadratic-time by providing such an algorithm. Moreover, we develop an incremental algorithm for parametric simulation; we show that the incremental algorithm is bounded relative to its batch counterpart, i.e., it incurs the minimum cost for incrementalizing the batch algorithm. Putting these together, we develop HER, a parallel system to check whether (t, v) makes a match, find all vertex matches of t in G, and compute all matches across 𝒟 and G, all in quadratic-time; moreover, HER supports incremental computation of these in response to updates to 𝒟 and G. Using real-life and synthetic data, we empirically verify that HER is accurate with F-measure of 0.94 on average, and is able to scale with database 𝒟 and graph G for both batch and incremental computations.},
journal = {ACM Trans. Database Syst.},
month = feb,
articleno = {2},
numpages = {50},
keywords = {Entity resolution, Knowledge graph, Relational database, Parallelization, Incremental algorithm, Relative boundedness}
}

@inproceedings{10.1145/3648188.3675120,
author = {Wehnert, Sabine and Fiorelli, Manuel and Picca, Davide and De Luca, Ernesto William and Stellato, Armando},
title = {LIRAI'24: 2nd Workshop on Legal Information Retrieval meets Artificial Intelligence},
year = {2024},
isbn = {9798400705953},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3648188.3675120},
doi = {10.1145/3648188.3675120},
abstract = {LIRAI is a workshop series on Legal Information Retrieval and Legal Artificial Intelligence. It provides a forum for discussing current trends and challenges in legal artificial intelligence, specifically related to the hypertext nature of legal documents and retrieval tasks. The second edition of LIRAI focuses on three main directions: explainable / justifiable artificial intelligence, hybrid systems that combine formal approaches and machine learning-based methods, including deep learning-based methods, and finally generative artificial intelligence. We call for contributions on these topics in the form of short and long papers, and we aim to publish them as open-access proceedings on CEUR-WS.org once again.},
booktitle = {Proceedings of the 35th ACM Conference on Hypertext and Social Media},
pages = {390–392},
numpages = {3},
keywords = {Explainable AI, FAIRness, Generative AI, High-Recall Retrieval, Hybrid Approaches, Legal Compliance, Legal Informatics, Legal Information Retrieval, Legal Knowledge Representation, Legal Text Mining, Linguistic Legal Linked Open Data, Semantic Web},
location = {Poznan, Poland},
series = {HT '24}
}

@inproceedings{10.1109/JCDL52503.2021.00014,
author = {Kroll, Hermann and Pirklbauer, Jan and Balke, Wolf-Tilo},
title = {A Toolbox for the Nearly-Unsupervised Construction of Digital Library Knowledge Graphs},
year = {2024},
isbn = {9781665417709},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/JCDL52503.2021.00014},
doi = {10.1109/JCDL52503.2021.00014},
abstract = {Knowledge graphs are essential for digital libraries to store entity-centric knowledge. The applications of knowledge graphs range from summarizing entity information over answering complex queries to inferring new knowledge. Yet, building knowledge graphs means either relying on manual curation or designing supervised extraction processes to harvest knowledge from unstructured text. Obviously, both approaches are cost-intensive. Yet, the question is whether we can minimize the efforts to build a knowledge graph. And indeed, we propose a toolbox that provides methods to extract knowledge from arbitrary text. Our toolkit bypasses the need for supervision nearly completely and includes a novel algorithm to close the missing gaps. As a practical demonstration, we analyze our toolbox on established biomedical benchmarks. As far as we know, we are the first who propose, analyze and share a nearly unsupervised and complete toolbox for building knowledge graphs from text.},
booktitle = {Proceedings of the 2021 ACM/IEEE Joint Conference on Digital Libraries},
pages = {21–30},
numpages = {10},
keywords = {knowledge graph, information extraction, digital library},
location = {Virtual Event},
series = {JCDL '21}
}

@inproceedings{10.1145/3652037.3652072,
author = {Tsampos, Ioannis and Marakakis, Emmanouil},
title = {Querying Knowledge Graphs in Greek Language},
year = {2024},
isbn = {9798400717604},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652037.3652072},
doi = {10.1145/3652037.3652072},
abstract = {We present a method for querying knowledge graphs through natural language, emphasizing its application to the Greek language. It integrates NLP techniques with the capabilities of graph databases to enable seamless interaction with knowledge graphs through natural language queries. Upon receiving a user's question in Greek language, we use linguistic analysis tools to convert it into a graph structure by employing predefined rules and adhering to a graph database schema. This methodology enables the handling of different question types and the efficient extraction of relations, ensuring accurate mapping of linguistic structures to database queries. The representation of a question as a knowledge graph enables its direct translation to a Cypher query, facilitating the extraction of related answers. The approach can handle complex questions and is language independent.},
booktitle = {Proceedings of the 17th International Conference on PErvasive Technologies Related to Assistive Environments},
pages = {27–33},
numpages = {7},
keywords = {Graph Databases, Greek Language, Knowledge Graph Construction, Knowledge Representation, Natural Language Processing, Query languages, Question Answering},
location = {Crete, Greece},
series = {PETRA '24}
}

@inproceedings{10.1145/3627673.3679845,
author = {Guan, Saiping and Wei, Jiyao and Jin, Xiaolong and Guo, Jiafeng and Cheng, Xueqi},
title = {Look Globally and Reason: Two-stage Path Reasoning over Sparse Knowledge Graphs},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679845},
doi = {10.1145/3627673.3679845},
abstract = {Sparse Knowledge Graphs (KGs), frequently encountered in real-world applications, contain fewer facts in the form of (head entity, relation, tail entity) compared to more populated KGs. The sparse KG completion task, which reasons answers for given queries in the form of (head entity, relation, ?) for sparse KGs, is particularly challenging due to the necessity of reasoning missing facts based on limited facts. Path-based models, known for excellent explainability, are often employed for this task. However, existing path-based models typically rely on external models to fill in missing facts and subsequently perform path reasoning. This approach introduces unexplainable factors or necessitates meticulous rule design. In light of this, this paper proposes an alternative approach by looking inward instead of seeking external assistance. We introduce a two-stage path reasoning model called LoGRe (Look Globally and Reason) over sparse KGs. LoGRe constructs a relation-path reasoning schema by globally analyzing the training data to alleviate the sparseness problem. Based on this schema, LoGRe then aggregates paths to reason out answers. Experimental results on five benchmark sparse KG datasets demonstrate the effectiveness of the proposed LoGRe model.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {695–705},
numpages = {11},
keywords = {path reasoning, reasoning schema, sparse knowledge graph, sparse knowledge graph completion},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@inproceedings{10.1145/3589334.3648152,
author = {Shang, Lanyu and Zhang, Yang and Chen, Bozhang and Zong, Ruohan and Yue, Zhenrui and Zeng, Huimin and Wei, Na and Wang, Dong},
title = {MMAdapt: A Knowledge-guided Multi-source Multi-class Domain Adaptive Framework for Early Health Misinformation Detection},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3648152},
doi = {10.1145/3589334.3648152},
abstract = {This paper studies a critical problem of emergent health misinformation detection, aiming to mitigate the spread of misinformation in emergent health domains to support well-informed healthcare decisions towards a Web for good health. Our work is motivated by the lack of timely resources (e.g., medical knowledge, annotated data) during the initial phases of an emergent health event or topic. In this paper, we develop a multi-source domain adaptive framework that jointly exploits medical knowledge and annotated data from different high-resource source domains (e.g., cancer, COVID-19) to detect misleading posts in an emergent target domain (e.g., mpox, polio). Two important challenges exist in developing our solution: 1) how to accurately detect the partially misleading and unverifiable content in an emergent target domain? 2) How to identify the conflicting knowledge facts from different source domains to accurately detect emergent misinformation in the target domain? To address these challenges, we develop MMAdapt, a multi-source multi-class domain adaptive misinformation detection framework that effectively explores diverse knowledge facts from different source domains to accurately detect not only the outright misleading but also the partially misleading or unverifiable posts on the Web. Extensive experimental results on four real-world misinformation datasets demonstrate that MMAdapt substantially outperforms state-of-the-art baselines in accurately detecting misinformation in an emergent health domain.},
booktitle = {Proceedings of the ACM Web Conference 2024},
pages = {4653–4663},
numpages = {11},
keywords = {domain adaptation, healthcare misinformation, knowledge graph, multiclass classification},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3649158.3657036,
author = {Ahmed, Mohiuddin and Wei, Jinpeng and Al-Shaer, Ehab},
title = {Prompting LLM to Enforce and Validate CIS Critical Security Control},
year = {2024},
isbn = {9798400704918},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649158.3657036},
doi = {10.1145/3649158.3657036},
abstract = {Proper security control enforcement reduces the attack surface and protects the organizations against attacks. Organizations like NIST and CIS (Center for Internet Security) provide critical security controls (CSCs) as a guideline to enforce cyber security. Automated enforcement and measurability mechanisms for these CSCs still need to be developed. Analyzing the implementations of security products to validate security control enforcement is non-trivial. Moreover, manually analyzing and developing measures and metrics to monitor, and implementing those monitoring mechanisms are resource-intensive tasks and massively dependent on the security analyst's expertise and knowledge. To tackle those problems, we use large language models (LLMs) as a knowledge base and reasoner to extract measures, metrics, and monitoring mechanism implementation steps from security control descriptions to reduce the dependency on security analysts. Our approach used few-shot learning with chain-of-thought (CoT) prompting to generate measures and metrics and generated knowledge prompting for metrics implementation. Our evaluation shows that prompt engineering to extract measures, metrics, and monitoring implementation mechanisms can reduce dependency on humans and semi-automate the extraction process. We also demonstrate metric implementation steps using generated knowledge prompting with LLMs.},
booktitle = {Proceedings of the 29th ACM Symposium on Access Control Models and Technologies},
pages = {93–104},
numpages = {12},
keywords = {account management., critical security control, llm, prompt engineering},
location = {San Antonio, TX, USA},
series = {SACMAT 2024}
}

@inproceedings{10.1145/3653081.3653117,
author = {Xing, Xueyang and Jia, Bo and Huang, Zhicheng and Chen, Yongzhi and Wang, Junjie and Fan, Anfei and Chen, Xin and Cao, Lei},
title = {A fusion inference method for large language models and knowledge graphs based on structured injection and causal inference},
year = {2024},
isbn = {9798400716485},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3653081.3653117},
doi = {10.1145/3653081.3653117},
abstract = {In this paper, we propose a large language model and knowledge graph fusion reasoning method based on structured injection and causal reasoning (LKFSC) to address the limitations of existing large language models and knowledge graphs in practical applications. The approach effectively mitigates the problems of long-distance dependency and limited contextual information, and improves the reasoning capability of the large language model. Meanwhile, by fusing the generative ability of the large language model and the inference ability of the knowledge graph, the method realizes intelligent reasoning for complex problems. The main contributions of this paper include proposing a structured injection method that introduces causality for reasoning, and constructing a fusion reasoning framework that effectively mitigates the illusory problem of large language models and provides powerful and intelligent decision support for practical applications.},
booktitle = {Proceedings of the 2023 5th International Conference on Internet of Things, Automation and Artificial Intelligence},
pages = {208–213},
numpages = {6},
location = {Nanchang, China},
series = {IoTAAI '23}
}

@inproceedings{10.1145/3641825.3687716,
author = {Christiansen, Frederik Roland and Hollensberg, Linus N\o{}rgaard and Jensen, Niko Bach and Julsgaard, Kristian and Jespersen, Kristian Nyborg and Nikolov, Ivan},
title = {Exploring Presence in Interactions with LLM-Driven NPCs: A Comparative Study of Speech Recognition and Dialogue Options},
year = {2024},
isbn = {9798400705359},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641825.3687716},
doi = {10.1145/3641825.3687716},
abstract = {Combining modern technologies like large-language models (LLMs), speech-to-text, and text-to-speech can enhance immersion in virtual reality (VR) environments. However, challenges exist in effectively implementing LLMs and educating users. This paper explores implementing LLM-powered virtual social actors and facilitating user communication. We developed a murder mystery game where users interact with LLM-based non-playable characters (NPCs) through interrogation, clue-gathering, and exploration. Two versions were tested: one using speech recognition and another with traditional dialog boxes. While both provided similar social presence, users felt more immersed with speech recognition but found it overwhelming, while the dialog version was more challenging. Slow NPC response times were a source of frustration, highlighting the need for faster generation or better masking for a seamless experience.},
booktitle = {Proceedings of the 30th ACM Symposium on Virtual Reality Software and Technology},
articleno = {6},
numpages = {11},
keywords = {Immersive systems, Large Language Models (LLM), NPC, Presence, Social Actors, Speech Recognition, VR},
location = {Trier, Germany},
series = {VRST '24}
}

@inproceedings{10.1145/3694811.3697819,
author = {Alfasi, Daniel and Shapira, Tal and Bremler-Barr, Anat},
title = {VulnScopper: Unveiling Hidden Links Between Unseen Security Entities},
year = {2024},
isbn = {9798400712548},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3694811.3697819},
doi = {10.1145/3694811.3697819},
abstract = {The Common Vulnerabilities and Exposures (CVE) system is crucial for cybersecurity, providing standardized identification of vulnerabilities. In February 2024, the National Vulnerability Database (NVD) announced it could no longer enrich new CVEs due to increasing volumes, significantly impacting global security efforts. This paper introduces VulnScopper, an innovative approach to automate and enhance vulnerability enrichment using Graph Neural Networks (GNNs). VulnScopper combines Knowledge Graphs (KG) with Natural Language Processing (NLP) by leveraging ULTRA, a GNN-based knowledge graph foundation model, alongside a Large Language Model (LLM). VulnScopper's inductive approach enables it to handle unseen entities, overcoming a crucial limitation of previous CVE enrichment methods. We evaluate VulnScopper on the NVD dataset in inductive and transductive setups for CVE to Common Platform Enumerations (CPE) linking. Our results show that VulnScopper outperforms state-of-the-art techniques, achieving up to 60% Hits@10 accuracy in linking CVEs to CPE on unseen CVE records. We demonstrate VulnScopper's effectiveness on unseen 2023 CVEs, showcasing its ability to uncover new vulnerable products and potentially reduce vulnerability remediation time.},
booktitle = {Proceedings of the 3rd GNNet Workshop on Graph Neural Networking Workshop},
pages = {33–40},
numpages = {8},
keywords = {cpe, cve, cwe, cybersecurity, graph neural networks (gnn), knowledge graphs, large language models (llm), link prediction, vulnerabilities},
location = {Los Angeles, CA, USA},
series = {GNNet '24}
}

@inproceedings{10.1145/3589334.3645594,
author = {Pan, Yudai and Liu, Jun and Zhao, Tianzhe and Zhang, Lingling and Lin, Yun and Dong, Jin Song},
title = {A Symbolic Rule Integration Framework with Logic Transformer for Inductive Relation Prediction},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3645594},
doi = {10.1145/3589334.3645594},
abstract = {Relation prediction in knowledge graphs (KGs) aims at predicting missing relations in incomplete triples, whereas the dominant paradigm by KG embeddings has a limitation to predict the relation between unseen entities. This situation is called an inductive setting, which is more common in the real-world scenario. To handle this issue, implicit symbolic rules have shown great potential in capturing the inductive capability. However, it is still challenging to obtain precise representations of logic rules from KGs. The argument variability and predicate non-commutativity in symbolic rule integration make the modeling of component symbols difficult. To this end, we propose a novel inductive relation prediction model named SymRITa with a logic transformer integrating rules. SymRITa firstly extracts the subgraph, whose embeddings are captured by a graph network. Meanwhile, symbolic rule graphs in the subgraph can be generated. Then, the symbolic rules are modeled by a proposed logic transformer. Specifically, the input format based on the subgraph-based embeddings is to focus on the argument variability in symbolic rules. In addition, a conjunction attention mechanism in the logic transformer can resolve predicate non-commutativity in the symbolic rule integration process. Finally, the subgraph-based and symbol-based embeddings obtained from the previous steps are combined for the training regime, and prediction results as well as rules explaining the reasoning process are explicitly output. Extensive experiments on twelve inductive datasets show that SymRITa achieves outstanding effectiveness compared to state-of-the-art inductive baselines. Moreover, the logic rules with corresponding confidences provide an interpretable paradigm.},
booktitle = {Proceedings of the ACM Web Conference 2024},
pages = {2181–2192},
numpages = {12},
keywords = {first-order logic, inductive relation prediction, knowledge graph, logic transformer},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3616855.3638207,
author = {Dong, Xin Luna},
title = {The Journey to A Knowledgeable Assistant with Retrieval-Augmented Generation (RAG)},
year = {2024},
isbn = {9798400703713},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3616855.3638207},
doi = {10.1145/3616855.3638207},
abstract = {Large Language Models (LLMs) have demonstrated strong capabilities in comprehending and generating human language, as well as emerging abilities like reasoning and using tools. These advancements have been revolutionizing techniques in every front, including the development of personal assistants. However, their inherent limitations such as lack of factuality and hallucinations make LLMs less suitable for creating knowledgeable and trustworthy assistants.  In this talk, we describe our journey in building a knowledgeable AI assistant by harnessing LLM techniques. We start with a comprehensive set of experiments designed to answer the questions of em how reliable are LLMs on answering factual questions and em how the performance differs across different types of factual knowledge. Subsequently, we constructed a em federated Retrieval-Augmented Generation (RAG) system that integrates external information from both the web and knowledge graphs in text generation. This system supports conversation functionality for the Ray-ban Meta smart glasses, providing trustworthy information on real-time topics like stocks and sports, and information on torso-to-tail entities such as local restaurants. Additionally, we are exploring the potential of external knowledge to facilitate multi-modal Q&amp;A. We will share our techniques, our findings, and the path forward in this talk.},
booktitle = {Proceedings of the 17th ACM International Conference on Web Search and Data Mining},
pages = {4},
numpages = {1},
keywords = {ai assistant, large language model, retrieval-augmented generation (rag)},
location = {Merida, Mexico},
series = {WSDM '24}
}

@article{10.1145/3650041,
author = {Sekuli\'{c}, Ivan and Alinannejadi, Mohammad and Crestani, Fabio},
title = {Analysing Utterances in LLM-Based User Simulation for Conversational Search},
year = {2024},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {3},
issn = {2157-6904},
url = {https://doi.org/10.1145/3650041},
doi = {10.1145/3650041},
abstract = {Clarifying underlying user information needs by asking clarifying questions is an important feature of modern conversational search systems. However, evaluation of such systems through answering prompted clarifying questions requires significant human effort, which can be time-consuming and expensive. In our recent work, we proposed an approach to tackle these issues with a user simulator, USi. Given a description of an information need, USi is capable of automatically answering clarifying questions about the topic throughout the search session. However, while the answers generated by USi are both in line with the underlying information need and in natural language, a deeper understanding of such utterances is lacking. Thus, in this work, we explore utterance formulation of large language model (LLM)–based user simulators. To this end, we first analyze the differences between USi, based on GPT-2, and the next generation of generative LLMs, such as GPT-3. Then, to gain a deeper understanding of LLM-based utterance generation, we compare the generated answers to the recently proposed set of patterns of human-based query reformulations. Finally, we discuss potential applications as well as limitations of LLM-based user simulators and outline promising directions for future work on the topic.},
journal = {ACM Trans. Intell. Syst. Technol.},
month = may,
articleno = {62},
numpages = {22},
keywords = {User simulation, conversational search, mixed-initiative}
}

@article{10.1145/3659610,
author = {Garcia, Kimberly and Vontobel, Jonathan and Mayer, Simon},
title = {A Digital Companion Architecture for Ambient Intelligence},
year = {2024},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {2},
url = {https://doi.org/10.1145/3659610},
doi = {10.1145/3659610},
abstract = {Ambient Intelligence (AmI) focuses on creating environments capable of proactively and transparently adapting to users and their activities. Traditionally, AmI focused on the availability of computational devices, the pervasiveness of networked environments, and means to interact with users. In this paper, we propose a renewed AmI architecture that takes into account current technological advancements while focusing on proactive adaptation for assisting and protecting users. This architecture consist of four phases: Perceive, Interpret, Decide, and Interact. The AmI systems we propose, called Digital Companions (DC), can be embodied in a variety of ways (e.g., through physical robots or virtual agents) and are structured according to these phases to assist and protect their users. We further categorize DCs into Expert DCs and Personal DCs, and show that this induces a favorable separation of concerns in AmI systems, where user concerns (including personal user data and preferences) are handled by Personal DCs and environment concerns (including interfacing with environmental artifacts) are assigned to Expert DCs; this separation has favorable privacy implications as well. Herein, we introduce this architecture and validate it through a prototype in an industrial scenario where robots and humans collaborate to perform a task.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = may,
articleno = {66},
numpages = {26},
keywords = {ambient intelligence, architecture, connected devices, digital companion systems, industrial environments, knowledge graph, mixed reality, scene graph generation algorithm}
}

@article{10.1145/3641286,
author = {Lu, Kezhi and Zhang, Qian and Hughes, Danny and Zhang, Guangquan and Lu, Jie},
title = {AMT-CDR: A Deep Adversarial Multi-Channel Transfer Network for Cross-Domain Recommendation},
year = {2024},
issue_date = {August 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {4},
issn = {2157-6904},
url = {https://doi.org/10.1145/3641286},
doi = {10.1145/3641286},
abstract = {Recommender systems are one of the most successful applications of using AI for providing personalized e-services to customers. However, data sparsity is presenting enormous challenges that are hindering the further development of advanced recommender systems. Although cross-domain recommendation partly overcomes data sparsity by transferring knowledge from a source domain with relatively dense data to augment data in the target domain, the current methods do not handle heterogeneous data very well. For example, using today’s cross-domain transfer learning schemes with data comprising clicks, ratings, user reviews, item metadata, and knowledge graphs will likely result in a poorly performing model. User preferences will not be comprehensively profiled, and accurate recommendations will not be generated. To solve these three challenges—handling heterogeneous data, avoiding negative transfer, and dealing with data sparsity—we designed a new end-to-end deep Adversarial Multi-channel Transfer network for Cross-Domain Recommendation named AMT-CDR. Heterogeneous data is handled by constructing a cross-domain graph based on real-world knowledge graphs—we used Freebase and YAGO. Negative transfer is prevented through an adversarial learning strategy that maintains consistency across the different data channels. Data sparsity is addressed with an end-to-end neural network that considers data across multiple channels and generates accurate recommendations by leveraging knowledge from both the source and target domains. Extensive experiments on three dual-target cross-domain recommendation tasks demonstrate the superiority of AMT-CDR compared to eight state-of-the-art methods. All source code is available at .},
journal = {ACM Trans. Intell. Syst. Technol.},
month = jul,
articleno = {87},
numpages = {26},
keywords = {Recommender systems, cross-domain recommender systems, semantic representations, knowledge graph, knowledge transfer}
}

@inproceedings{10.1145/3627673.3679077,
author = {Wallace, Joseph and Dogra, Tushar and Qiao, Wei and Wang, Yuan},
title = {Advertiser Content Understanding via LLMs for Google Ads Safety},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679077},
doi = {10.1145/3627673.3679077},
abstract = {Ads Content Safety at Google requires classifying billions of ads for Google Ads content policies. Consistent and accurate policy enforcement is important for advertiser experience and user safety and it is a challenging problem, so there is a lot of value for improving it for advertisers and users. Inconsistent policy enforcement causes increased policy friction and poor experience with good advertisers, and bad advertisers exploit the inconsistency by creating multiple similar ads in the hope that some will get through our defenses. This study proposes a method to understand advertiser's intent for content policy violations, using Large Language Models (LLMs). We focus on identifying good advertisers to reduce content over-flagging and improve advertiser experience, though the approach can easily be extended to classify bad advertisers too. We generate advertiser's content profile based on multiple signals from their ads, domains, targeting info, etc. We then use LLMs to classify the advertiser content profile, along with relying on any knowledge the LLM has of the advertiser, their products or brand, to understand whether they are likely to violate a certain policy or not. After minimal prompt tuning our method was able to reach 95% accuracy on a small test set.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {5566–5567},
numpages = {2},
keywords = {content moderation, content understanding, large language model},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@article{10.1145/3642979.3642995,
author = {B\'{e}n\'{e}dict, Gabriel and Zhang, Ruqing and Metzler, Donald and Yates, Andrew and Deffayet, Romain and Hager, Philipp and Jullien, Sami},
title = {Report on the 1st Workshop on Generative Information Retrieval (Gen-IR 2023) at SIGIR 2023},
year = {2024},
issue_date = {December 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {57},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/3642979.3642995},
doi = {10.1145/3642979.3642995},
abstract = {The first edition of the workshop on Generative Information Retrieval (Gen-IR 2023) took place in July 2023 in a hybrid fashion, co-located with the ACM SIGIR Conference 2023 in Taipei (SIGIR 2023). The aim was to bring information retrieval researchers together around the topic of generative AI that gathered attention in 2022 and 2023 with large language models and diffusion models. Given the novelty of the topic, the workshop was focused around multi-sided discussions, namely panels and poster sessions of the accepted proceedings papers. Two main research outcomes are the proceedings of the workshop1 and the potential research directions discussed in this report.Date: 27 July 2023.Website: https://coda.io/@sigir/gen-ir.},
journal = {SIGIR Forum},
month = jan,
articleno = {13},
numpages = {23}
}

@inproceedings{10.1145/3637528.3671515,
author = {Cao, Lele and von Ehrenheim, Vilhelm and Granroth-Wilding, Mark and Anselmo Stahl, Richard and McCornack, Andrew and Catovic, Armin and Cavalcanti Rocha, Dhiana Deva},
title = {CompanyKG: A Large-Scale Heterogeneous Graph for Company Similarity Quantification},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671515},
doi = {10.1145/3637528.3671515},
abstract = {This paper presents CompanyKG (version 2), a large-scale heterogeneous graph developed for fine-grained company similarity quantification and relationship prediction, crucial for applications in the investment industry such as market mapping, competitor analysis, and mergers and acquisitions. CompanyKG comprises 1.17 million companies represented as graph nodes, enriched with company description embeddings, and 51.06 million weighted edges denoting 15 distinct inter-company relations. To facilitate a thorough evaluation of methods for company similarity quantification and relationship prediction, we have created four annotated evaluation tasks: similarity prediction, competitor retrieval, similarity ranking, and edge prediction. We offer extensive benchmarking results for 11 reproducible predictive methods, categorized into three groups: node-only, edge-only, and node+edge. To our knowledge, CompanyKG is the first large-scale heterogeneous graph dataset derived from a real-world investment platform, specifically tailored for quantifying inter-company similarity and relationships.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {4816–4827},
numpages = {12},
keywords = {benchmark, company similarity quantification, edge prediction, graph neural network, investment, knowledge graph, private equity},
location = {Barcelona, Spain},
series = {KDD '24}
}

@article{10.1145/3687273.3687288,
author = {Azzopardi, Leif and Clarke, Charles L. A. and Kantor, Paul and Mitra, Bhaskar and Trippas, Johanne R. and Ren, Zhaochun and Aliannejadi, Mohammad and Arabzadeh, Negar and Chandrasekar, Raman and de Rijke, Maarten and Eustratiadis, Panagiotis and Hersh, William and Huang, Jin and Kanoulas, Evangelos and Kareem, Jasmin and Li, Yongkang and Lupart, Simon and Mekonnen, Kidist Amde and Roegiest, Adam and Soboroff, Ian and Silvestri, Fabrizio and Verberne, Suzan and Vos, David and Yang, Eugene and Zhao, Yuyue},
title = {Report on the Search Futures Workshop at ECIR 2024},
year = {2024},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {58},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/3687273.3687288},
doi = {10.1145/3687273.3687288},
abstract = {The First Search Futures Workshop, in conjunction with the Fourty-sixth European Conference on Information Retrieval (ECIR) 2024, looked into the future of search to ask questions such as:• How can we harness the power of generative AI to enhance, improve and re-imagine Information Retrieval (IR)?• What are the principles and fundamental rights that the field of Information Retrieval should strive to uphold?• How can we build trustworthy IR systems in light of Large Language Models and their ability to generate content at super human speeds?• What new applications and affordances does generative AI offer and enable, and can we go back to the future, and do what we only dreamed of previously?The workshop started with seventeen lightning talks from a diverse set speakers. Instead of conventional paper presentations, the lightning talks provided a rapid and concise overview of ideas, allowing speakers to share critical points or novel concepts quickly. This format was designed to encourage discussion and introduce a wide range of topics within a short period, thereby maximising the exchange of ideas and ensuring that participants could gain insights into various future search areas without the deep dive typically required in longer presentations. This report, co-authored by the workshop's organisers and its participants, summarises the talks and discussions. This report aims to provide the broader IR community with the insights and ideas discussed and debated during the workshop - and to provide a platform for future discussion.Date: 24 March 2024.Website: https://searchfutures.github.io/.},
journal = {SIGIR Forum},
month = aug,
pages = {1–41},
numpages = {41}
}

@inproceedings{10.1145/3637528.3672354,
author = {Zhang, Fanjin and Shi, Shijie and Zhu, Yifan and Chen, Bo and Cen, Yukuo and Yu, Jifan and Chen, Yelin and Wang, Lulu and Zhao, Qingfei and Cheng, Yuqing and Han, Tianyi and An, Yuwei and Zhang, Dan and Tam, Weng Lam and Cao, Kun and Pang, Yunhe and Guan, Xinyu and Yuan, Huihui and Song, Jian and Li, Xiaoyan and Dong, Yuxiao and Tang, Jie},
title = {OAG-Bench: A Human-Curated Benchmark for Academic Graph Mining},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3672354},
doi = {10.1145/3637528.3672354},
abstract = {With the rapid proliferation of scientific literature, versatile academic knowledge services increasingly rely on comprehensive academic graph mining. Despite the availability of public academic graphs, benchmarks, and datasets, these resources often fall short in multi-aspect and fine-grained annotations, are constrained to specific task types and domains, or lack underlying real academic graphs. In this paper, we present OAG-Bench, a comprehensive, multi-aspect, and fine-grained human-curated benchmark based on the Open Academic Graph (OAG). OAG-Bench covers 10 tasks, 20 datasets, 70+ baselines, and 120+ experimental results to date. We propose new data annotation strategies for certain tasks and offer a suite of data pre-processing codes, algorithm implementations, and standardized evaluation protocols to facilitate academic graph mining. Extensive experiments reveal that even advanced algorithms like large language models (LLMs) encounter difficulties in addressing key challenges in certain tasks, such as paper source tracing and scholar profiling. We also introduce the Open Academic Graph Challenge (OAG-Challenge) to encourage community input and sharing. We envisage that OAG-Bench can serve as a common ground for the community to evaluate and compare algorithms in academic graph mining, thereby accelerating algorithm development and advancement in this field. OAG-Bench is accessible at https://www.aminer.cn/data/.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {6214–6225},
numpages = {12},
keywords = {academic graph mining, academic knowledge graph, benchmark},
location = {Barcelona, Spain},
series = {KDD '24}
}

@inproceedings{10.1145/3640457.3688104,
author = {Xi, Yunjia and Liu, Weiwen and Lin, Jianghao and Cai, Xiaoling and Zhu, Hong and Zhu, Jieming and Chen, Bo and Tang, Ruiming and Zhang, Weinan and Yu, Yong},
title = {Towards Open-World Recommendation with Knowledge Augmentation from Large Language Models},
year = {2024},
isbn = {9798400705052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3640457.3688104},
doi = {10.1145/3640457.3688104},
abstract = {Recommender system plays a vital role in various online services. However, its insulated nature of training and deploying separately within a specific closed domain limits its access to open-world knowledge. Recently, the emergence of large language models (LLMs) has shown promise in bridging this gap by encoding extensive world knowledge and demonstrating reasoning capabilities. Nevertheless, previous attempts to directly use LLMs as recommenders cannot meet the inference latency demand of industrial recommender systems. In this work, we propose an Open-World Knowledge Augmented Recommendation Framework with Large Language Models, dubbed KAR, to acquire two types of external knowledge from LLMs — the reasoning knowledge on user preferences and the factual knowledge on items. We introduce factorization prompting to elicit accurate reasoning on user preferences. The generated reasoning and factual knowledge are effectively transformed and condensed into augmented vectors by a hybrid-expert adaptor in order to be compatible with the recommendation task. The obtained vectors can then be directly used to enhance the performance of any recommendation model. We also ensure efficient inference by preprocessing and prestoring the knowledge from the LLM. Extensive experiments show that KAR significantly outperforms the state-of-the-art baselines and is compatible with a wide range of recommendation algorithms. We deploy KAR to Huawei’s news and music recommendation platforms and gain a 7% and 1.7% improvement in the online A/B test, respectively.},
booktitle = {Proceedings of the 18th ACM Conference on Recommender Systems},
pages = {12–22},
numpages = {11},
keywords = {Knowledge Augmentation, Large Language Model, Recommender System},
location = {Bari, Italy},
series = {RecSys '24}
}

@article{10.1145/3705314,
author = {Mai, Cheng-Cheng and Chen, Yu and Gong, Ziyu and Wang, Hanxiang and Qiu, Mengchuan and Yuan, Chunfeng and Huang, Yihua},
title = {PromptCNER: A Segmentation-based Method for Few-shot Chinese NER with Prompt-tuning},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {2375-4699},
url = {https://doi.org/10.1145/3705314},
doi = {10.1145/3705314},
abstract = {Recognizing Chinese entities in low-resource settings is a challenging but promising task, which extracts structured pre-defined entities and corresponding types from unstructured text. Compared with the prosperous Named Entity Recognition (NER) methods for Indo-European languages, such as English, the research on Chinese NER is still in its infancy. The main obstacles to the development of Chinese NER methods include the ambiguity of Chinese entity boundary recognition and limited data resources. To address these issues, in this paper, a word-segmentation-based model is present for few-shot Chinese NER. First, we enumerate all possible candidate entity spans on the character level for accurate entity boundary identification with the proposed word segmentation and combination strategy. Then, one kind of question-answer-based prompt template loaded with the candidate entity spans is proposed to cast entity extraction into the masked token prediction task, for dealing with the low-data problem by taking full advantage of the generality and transferability of the pre-trained language model. The extensive experimental results show that our method outperforms the state-of-the-art baselines in low-data settings and also achieves comparable performance in full-data settings.},
note = {Just Accepted},
journal = {ACM Trans. Asian Low-Resour. Lang. Inf. Process.},
month = nov,
keywords = {Chinese Named Entity Recognition, Word Segmentation, Prompt-tuning, Pre-training Language Model, Few-shot Learning}
}

@inproceedings{10.1145/3647444.3647910,
author = {Rawat, Swati and Mittal, Sumit and Nehra, Deepa and Sharma, Chandani and Kamboj, Dalip},
title = {Exploring the Potential of ChatGPT to improve experiential learning in Education},
year = {2024},
isbn = {9798400709418},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3647444.3647910},
doi = {10.1145/3647444.3647910},
abstract = {Artificial Intelligence (AI) is revolutionizing the field of education by offering new possibilities for personalized and experiential learning along with data-driven insights. The advancement in AI to Generative Artificial Intelligence (GAI) has made the tables turn notably in the field of education. Generative AI application tool ChatGPT is emerging as a game changer offering personalized learning experiences by analyzing huge amounts of student data, generating study materials and pacing to individual needs. Intelligent educational tools powered by AI provide personalized guidance and feedback, adapting to curriculum to address knowledge gaps. GAI also automates the grading process, providing instant feedback and relieving teachers for qualitative assessments. This research paper offers a thorough examination of the potential uses, advantages, difficulties, and moral issues related to implementing ChatGPT in educational contexts. The authors closely analyze how ChatGPT can improve educational experiences, assist personalized learning, and encourage student- teacher interaction, while exploring the drawbacks of using generative AI models in education, such as concerns about bias, data privacy, and over-reliance on technology. This research article intends to offer educators &amp; academicians useful insights into the usage of ChatGPT in the educational field through a critical analysis of the existing literature and real- world experiences.},
booktitle = {Proceedings of the 5th International Conference on Information Management &amp; Machine Intelligence},
articleno = {83},
numpages = {8},
keywords = {ChatGPT, Generative Artificial Intelligence (GAI), Natural Language Processing, OpenAI, Teaching &amp; Learning, Education},
location = {Jaipur, India},
series = {ICIMMI '23}
}

@proceedings{10.1145/3644032,
title = {AST '24: Proceedings of the 5th ACM/IEEE International Conference on Automation of Software Test (AST 2024)},
year = {2024},
isbn = {9798400705885},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {AST continues to be a venue for researchers and practitioners where they can discuss high quality research contributions on methods for software test automation, and various case studies reporting practices in this field. Indeed, software test automation is a discipline that has produced noteworthy research in the last decade.The special theme of AST 2024 is "Test automation for and with Generative AI". This innovative and promising research direction deals with the application of test automation technologies to the testing of Generative AI applications, as well as the adoption of generative AI to facilitate test automation.},
location = {Lisbon, Portugal}
}

@inproceedings{10.1145/3616855.3636450,
author = {Jin, Bowen and Zhang, Yu and Li, Sha and Han, Jiawei},
title = {Bridging Text Data and Graph Data: Towards Semantics and Structure-aware Knowledge Discovery},
year = {2024},
isbn = {9798400703713},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3616855.3636450},
doi = {10.1145/3616855.3636450},
abstract = {Graphs and texts are two key modalities in data mining. In many cases, the data presents a mixture of the two modalities and the information is often complementary: in e-commerce data, the product-user graph and product descriptions capture different aspects of product features; in scientific literature, the citation graph, author metadata, and the paper content all contribute to modeling the paper impact.},
booktitle = {Proceedings of the 17th ACM International Conference on Web Search and Data Mining},
pages = {1122–1125},
numpages = {4},
keywords = {graph mining, pretrained language model},
location = {Merida, Mexico},
series = {WSDM '24}
}

@inproceedings{10.1145/3687311.3687340,
author = {Liu, Xianghong and Li, Haoyu},
title = {A comprehensive survey and visual analysis of AIGC education and teaching},
year = {2024},
isbn = {9798400709920},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3687311.3687340},
doi = {10.1145/3687311.3687340},
abstract = {To comprehensively understand the research landscape of Artificial Intelligence-Generated Content applications in educational scenarios. This study employs the CiteSpace visual bibliometric tool to conduct a quantitative analysis of 366 publications related to AIGC in education and teaching. The findings indicate that research on AIGC in education and teaching focuses primarily on three aspects. The connotation and characteristics of AIGC in education, the educational threats posed by AIGC, and the application scenarios of AIGC in education and teaching. It is evident that education researchers need to address the potential crises introduced by AIGC, actively explore strategies and models suited for various educational scenarios based on its functional characteristics and adapt to contemporary needs.Dominant typeAdvantages and characteristicsPersonalized learning supportAIGC can conduct one-on-one open-ended question-and-answer sessions with usersteacher instructional assistanceGenerative AI can assist teachers in lesson preparation and teaching[4]timely feedback evaluationProvide immediate feedback to learners to help them identify and correct mistakes in their learning.Multi-dimensional educational interactionExtending into the cyberspace that facilitates human-machine-human interaction.educational resource sharingEfficiently create personalized and cross-modal educational resources based on different resources[5].},
booktitle = {Proceedings of the 2024 International Conference on Intelligent Education and Computer Technology},
pages = {158–162},
numpages = {5},
location = {Guilin, China},
series = {IECT '24}
}

@article{10.1145/3677376,
author = {Zou, Jie and Sun, Aixin and Long, Cheng and Kanoulas, Evangelos},
title = {Knowledge-Enhanced Conversational Recommendation via Transformer-Based Sequential Modeling},
year = {2024},
issue_date = {November 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {42},
number = {6},
issn = {1046-8188},
url = {https://doi.org/10.1145/3677376},
doi = {10.1145/3677376},
abstract = {In conversational recommender systems (CRSs), conversations usually involve a set of items and item-related entities or attributes, e.g., director is a related entity of a movie. These items and item-related entities are often mentioned along the development of a dialog, leading to potential sequential dependencies among them. However, most of existing CRSs neglect these potential sequential dependencies. In this article, we first propose a Transformer-based sequential conversational recommendation method, named TSCR, to model the sequential dependencies in the conversations to improve CRS. In TSCR, we represent conversations by items and the item-related entities, and construct user sequences to discover user preferences by considering both the mentioned items and item-related entities. Based on the constructed sequences, we deploy a Cloze task to predict the recommended items along a sequence. Meanwhile, in certain domains, knowledge graphs formed by the items and their related entities are readily available, which provide various different kinds of associations among them. Given that TSCR does not benefit from such knowledge graphs, we then propose a knowledge graph enhanced version of TSCR, called TSCRKG. In specific, we leverage the knowledge graph to offline initialize our model TSCRKG, and augment the user sequence of conversations (i.e., sequence of the mentioned items and item-related entities in the conversation) with multi-hop paths in the knowledge graph. Experimental results demonstrate that our TSCR model significantly outperforms state-of-the-art baselines, and the enhanced version TSCRKG further improves recommendation performance on top of TSCR.},
journal = {ACM Trans. Inf. Syst.},
month = oct,
articleno = {162},
numpages = {27},
keywords = {Conversational recommendation, sequential recommendation, recommender system, transformer}
}

@inproceedings{10.1145/3687311.3687317,
author = {Ji, Zibo and Li, Yanjun and Yang, Ruiting and Wu, Haoning},
title = {Research on the application and practice of curriculum with AI assistance based on students' adaptive learning needs},
year = {2024},
isbn = {9798400709920},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3687311.3687317},
doi = {10.1145/3687311.3687317},
abstract = {In the era of continuous development of education from informationization to digital transformation, in order to improve students' learning autonomy in mechanics courses and to solve the problem of resource richness and personalized demand of mechanics course teaching under the demand of students' self-adaptive learning, through the fusion technology of big language model and knowledge graph, the interaction technology of Solidworks 3D modeling and Realibox rendering, and cloud computing, cloud supervision and other technological tools to assist teaching by providing knowledge systematic model and visualization model to help students effectively complete the learning tasks and cultivate and improve their independent learning ability. Supervision and other technical tools through the provision of knowledge systematic model and visualization model to assist teaching, help students effectively complete the learning task and cultivate and improve independent learning ability.},
booktitle = {Proceedings of the 2024 International Conference on Intelligent Education and Computer Technology},
pages = {30–34},
numpages = {5},
location = {Guilin, China},
series = {IECT '24}
}

@inproceedings{10.1145/3627673.3679673,
author = {Xu, Derong and Zhang, Ziheng and Zhu, Zhihong and Lin, Zhenxi and Liu, Qidong and Wu, Xian and Xu, Tong and Wang, Wanyu and Ye, Yuyang and Zhao, Xiangyu and Chen, Enhong and Zheng, Yefeng},
title = {Editing Factual Knowledge and Explanatory Ability of Medical Large Language Models},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679673},
doi = {10.1145/3627673.3679673},
abstract = {Model editing aims to precisely alter the behaviors of large language models (LLMs) in relation to specific knowledge, while leaving unrelated knowledge intact. This approach has proven effective in addressing issues of hallucination and outdated information in LLMs. However, the potential of using model editing to modify knowledge in the medical field remains largely unexplored, even though resolving hallucination is a pressing need in this area. Our observations indicate that current methods face significant challenges in dealing with specialized and complex knowledge in medical domain. Therefore, we propose MedLaSA, a novel Layer-wise Scalable Adapter strategy for medical model editing. MedLaSA harnesses the strengths of both adding extra parameters and locate-then-edit methods for medical model editing. We utilize causal tracing to identify the association of knowledge in neurons across different layers, and generate a corresponding scale set from the association value for each piece of knowledge. Subsequently, we incorporate scalable adapters into the dense layers of LLMs. These adapters are assigned scaling values based on the corresponding specific knowledge, which allows for the adjustment of the adapter's weight and rank. The more similar the content, the more consistent the scale between them. This ensures precise editing of semantically identical knowledge while avoiding impact on unrelated knowledge. To evaluate the editing impact on the behaviours of LLMs, we propose two model editing studies for medical domain: (1) editing factual knowledge for medical specialization and (2) editing the explanatory ability for complex knowledge. We build two novel medical benchmarking datasets and introduce a series of challenging and comprehensive metrics. Extensive experiments on medical LLMs demonstrate the editing efficiency of MedLaSA, without affecting unrelated knowledge.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {2660–2670},
numpages = {11},
keywords = {large language model, medical sciences, model editing},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@inproceedings{10.1145/3626772.3657676,
author = {Zhang, Wenling and Li, Yixiao and Li, Zhaotian and Sun, Hailong and Gao, Xiang and Liu, Xudong},
title = {ModelGalaxy: A Versatile Model Retrieval Platform},
year = {2024},
isbn = {9798400704314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626772.3657676},
doi = {10.1145/3626772.3657676},
abstract = {With the growing number of available machine learning models and the emergence of model-sharing platforms, model reuse has become a significant approach to harnessing the power of artificial intelligence. One of the key issues to realizing model reuse resides in efficiently and accurately finding the target models that meet user needs from a model repository. However, the existing popular model-sharing platforms (e.g., Hugging Face) mainly support model retrieval based on model name matching and task filtering. If not familiar with the platform or specific models, users may suffer from low retrieval efficiency and a less user-friendly interaction experience. To address these issues, we have developed ModelGalaxy, a versatile model retrieval platform supporting multiple model retrieval methods, including keyword-based search, dataset-based search, and user-task-centric search. Moreover, ModelGalaxy leverages the power of large language models to provide users with easily retrieving and using models. Our source code is available at https://github.com/zwl906711886/ModelGalaxy.},
booktitle = {Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {2771–2775},
numpages = {5},
keywords = {large language model, meta-learning, model retrieval},
location = {Washington DC, USA},
series = {SIGIR '24}
}

@inproceedings{10.1145/3627673.3679156,
author = {Peng, Yiwen and Bonald, Thomas and Alam, Mehwish},
title = {Refining Wikidata Taxonomy using Large Language Models},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679156},
doi = {10.1145/3627673.3679156},
abstract = {Due to its collaborative nature, Wikidata is known to have a complex taxonomy, with recurrent issues like the ambiguity between instances and classes, the inaccuracy of some taxonomic paths, the presence of cycles, and the high level of redundancy across classes. Manual efforts to clean up this taxonomy are time-consuming and prone to errors or subjective decisions. We present WiKC, a new version of Wikidata taxonomy cleaned automatically using a combination of Large Language Models (LLMs) and graph mining techniques. Operations on the taxonomy, such as cutting links or merging classes, are performed with the help of zero-shot prompting on an open-source LLM. The quality of the refined taxonomy is evaluated from both intrinsic and extrinsic perspectives, on a task of entity typing for the latter, showing the practical interest of WiKC.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {5395–5399},
numpages = {5},
keywords = {graph mining, knowledge graphs, large language model},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@inproceedings{10.1145/3627673.3679791,
author = {Shi, Yuchen and Jiang, Guochao and Qiu, Tian and Yang, Deqing},
title = {AgentRE: An Agent-Based Framework for Navigating Complex Information Landscapes in Relation Extraction},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679791},
doi = {10.1145/3627673.3679791},
abstract = {The relation extraction (RE) in complex scenarios faces challenges such as diverse relation types and ambiguous relations between entities within a single sentence, leading to the poor performance of pure "text-in, text-out" language models (LMs). To address these challenges, in this paper, we propose an agent-based RE framework, namely "AgentRE", which fully leverages the potential of large language models (LLMs) including memory, retrieval and reflection, to achieve RE in complex scenarios. Specifically, three major modules are built in AgentRE serving as the tools to help the agent acquire and process various useful information, thereby obtaining improved RE performance. Our extensive experimental results upon two datasets in English and Chinese demonstrate our AgentRE's superior performance, especially in low-resource scenarios. Additionally, the trajectories generated by AgentRE can be refined to construct a high-quality training dataset incorporating different reasoning methods, which can be used to fine-tune smaller models.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {2045–2055},
numpages = {11},
keywords = {agent, large language model, memory, relation extraction, retrieval},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@inproceedings{10.1145/3627673.3679229,
author = {Lee, Zhicheng and Huang, Zhidian and Yao, Zijun and Liu, Jinxin and Xin, Amy and Hou, Lei and Li, Juanzi},
title = {DiaKoP: Dialogue-based Knowledge-oriented Programming for Neural-symbolic Knowledge Base Question Answering},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679229},
doi = {10.1145/3627673.3679229},
abstract = {We present Dialogue-based Knowledge-oriented Programming system (DiaKoP), a system with a chat interface designed for multi-turn knowledge base question answering (KBQA). DiaKoP enables users to decompose complex questions into multiple simpler follow-up questions and interact with the system to obtain answers. Multi-turn KBQA presents unique challenges because users may switch topics or ask incomplete questions that rely on previous interactions. To address this, we develop a Dialogue History Tracker and Dialogue Policy to manage user conversations effectively. Additionally, we enhance the knowledge from the knowledge graph by integrating parametric knowledge from a large language model (LLM) to provide more comprehensive answers. To mitigate the issue of wrongly parsed questions by semantic parser, we implement a human-in-the-loop mechanism, allowing users to correct errors. We evaluate DiaKoP both qualitatively and quantitatively, with user study indicating that our system better meets users' needs. DiaKoP is open-sourced on https://github.com/THU-KEG/DiaKoP with a guiding demo on https://youtu.be/Tq17k0OxPVg.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {5234–5238},
numpages = {5},
keywords = {explainability, human-in-the-loop, knowledge based question answering system, multi-turn dialogue},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@inproceedings{10.1145/3664647.3681661,
author = {Luo, Pengfei and Xu, Tong and Liu, Che and Zhang, Suojuan and Xu, Linli and Li, Minglei and Chen, Enhong},
title = {Bridging Gaps in Content and Knowledge for Multimodal Entity Linking},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3681661},
doi = {10.1145/3664647.3681661},
abstract = {Multimodal Entity Linking (MEL) aims to address the ambiguity in multimodal mentions and associate them with Multimodal Knowledge Graphs (MMKGs). Existing works primarily focus on designing multimodal interaction and fusion mechanisms to enhance the performance of MEL. However, these methods still overlook two crucial gaps within the MEL task. One is the content discrepancy between mentions and entities, manifested as uneven information density. The other is the knowledge gap, indicating insufficient knowledge extraction and reasoning during the linking process. To bridge these gaps, we propose a novel framework FissFuse, as well as a plug-and-play knowledge-aware re-ranking method KAR. Specifically, FissFuse collaborates with the Fission and Fusion branches, establishing dynamic features for each mention-entity pair and adaptively learning multimodal interactions to alleviate content discrepancy. Meanwhile, KAR is endowed with carefully crafted instruction for intricate knowledge reasoning, serving as re-ranking agents empowered by Large Language Models (LLMs). Extensive experiments on two well-constructed MEL datasets demonstrate outstanding performance of FissFuse compared with various baselines. Comprehensive evaluations and ablation experiments validate the effectiveness and generality of KAR.},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {9311–9320},
numpages = {10},
keywords = {content discrepancy, multimodal entity linking, multimodal fusion, multimodal knowledge graph},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@inproceedings{10.1145/3664647.3681593,
author = {Li, Haoxuan and Yang, Zhengmao and Ma, Yunshan and Bin, Yi and Yang, Yang and Chua, Tat-Seng},
title = {MM-Forecast: A Multimodal Approach to Temporal Event Forecasting with Large Language Models},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3681593},
doi = {10.1145/3664647.3681593},
abstract = {We study an emerging and intriguing problem of multimodal temporal event forecasting with large language models. Compared to using text or graph modalities, the investigation of utilizing images for temporal event forecasting has not been fully explored, especially in the era of large language models (LLMs). To bridge this gap, we are particularly interested in two key questions of: 1) why images will help in temporal event forecasting, and 2) how to integrate images into the LLM-based forecasting framework. To answer these research questions, we propose to identify two essential functions that images play in the scenario of temporal event forecasting, i.e., highlighting and complementary. Then, we develop a novel framework, named MM-Forecast. It employs an Image Function Identification module to recognize these functions as verbal descriptions using multimodal large language models (MLLMs), and subsequently incorporates these function descriptions into LLM-based forecasting models. To evaluate our approach, we construct a new multimodal dataset, MidEast-TE-mm, by extending an existing event dataset MidEast-TE-mini with images. Empirical studies demonstrate that our MM-Forecast can correctly identify the image functions, and further more, incorporating these verbal function descriptions significantly improves the forecasting performance. The dataset, code, and prompts are available at https://github.com/LuminosityX/MM-Forecast.},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {2776–2785},
numpages = {10},
keywords = {multimodal event forecasting, multimodal large language model, temporal event forecasting},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@inproceedings{10.1145/3627673.3679582,
author = {Zhu, Yinghao and Ren, Changyu and Wang, Zixiang and Zheng, Xiaochen and Xie, Shiyun and Feng, Junlan and Zhu, Xi and Li, Zhoujun and Ma, Liantao and Pan, Chengwei},
title = {EMERGE: Enhancing Multimodal Electronic Health Records Predictive Modeling with Retrieval-Augmented Generation},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679582},
doi = {10.1145/3627673.3679582},
abstract = {The integration of multimodal Electronic Health Records (EHR) data has significantly advanced clinical predictive capabilities. Existing models, which utilize clinical notes and multivariate time-series EHR data, often fall short of incorporating the necessary medical context for accurate clinical tasks, while previous approaches with knowledge graphs (KGs) primarily focus on structured knowledge extraction. In response, we propose EMERGE, a Retrieval-Augmented Generation (RAG) driven framework to enhance multimodal EHR predictive modeling. We extract entities from both time-series data and clinical notes by prompting Large Language Models (LLMs) and align them with professional PrimeKG, ensuring consistency. In addition to triplet relationships, we incorporate entities' definitions and descriptions for richer semantics. The extracted knowledge is then used to generate task-relevant summaries of patients' health statuses. Finally, we fuse the summary with other modalities using an adaptive multimodal fusion network with cross-attention. Extensive experiments on the MIMIC-III and MIMIC-IV datasets' in-hospital mortality and 30-day readmission tasks demonstrate the superior performance of the EMERGE framework over baseline models. Comprehensive ablation studies and analysis highlight the efficacy of each designed module and robustness to data sparsity. EMERGE contributes to refining the utilization of multimodal EHR data in healthcare, bridging the gap with nuanced medical contexts essential for informed clinical predictions. We have publicly released the code at https://github.com/yhzhu99/EMERGE.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {3549–3559},
numpages = {11},
keywords = {electronic health record, large language model, multimodal learning, retrieval-augmented generation},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@inproceedings{10.1145/3589335.3651572,
author = {Hsu, Chi-Yang and Cox, Kyle and Xu, Jiawei and Tan, Zhen and Zhai, Tianhua and Hu, Mengzhou and Pratt, Dexter and Chen, Tianlong and Hu, Ziniu and Ding, Ying},
title = {Thought Graph: Generating Thought Process for Biological Reasoning},
year = {2024},
isbn = {9798400701726},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589335.3651572},
doi = {10.1145/3589335.3651572},
abstract = {We present the Thought Graph as a novel framework to support complex reasoning and use gene set analysis as an example to uncover semantic relationships between biological processes. Our framework stands out for its ability to provide a deeper understanding of gene sets, significantly surpassing GSEA by 40.28% and LLM baselines by 5.38% based on cosine similarity to human annotations. Our analysis further provides insights into future directions of biological processes naming, and implications for bioinformatics and precision medicine.},
booktitle = {Companion Proceedings of the ACM Web Conference 2024},
pages = {537–540},
numpages = {4},
keywords = {bioinformatics, biological process., gene ontology, large language model, natural language processing, semantic web},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3605098.3636053,
author = {Alharbi, Reham and Tamma, Valentina and Grasso, Floriana and Payne, Terry},
title = {An Experiment in Retrofitting Competency Questions for Existing Ontologies},
year = {2024},
isbn = {9798400702433},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3605098.3636053},
doi = {10.1145/3605098.3636053},
abstract = {Competency Questions (CQs) are a form of ontology functional requirements expressed as natural language questions. Inspecting CQs together with the axioms in an ontology provides critical insights into the intended scope and applicability of the ontology. CQs also underpin a number of tasks in the development of ontologies e.g. ontology reuse, ontology testing, requirement specification, and the definition of patterns that implement such requirements. Although CQs are integral to the majority of ontology engineering methodologies, the practice of publishing CQs alongside the ontological artefacts is not widely observed by the community.In this context, we present an experiment in retrofitting CQs from existing ontologies. We propose RETROFIT-CQs, a method to extract candidate CQs directly from ontologies using Generative AI. In the paper we present the pipeline that facilitates the extraction of CQs by leveraging Large Language Models (LLMs) and we discuss its application to a number of existing ontologies.},
booktitle = {Proceedings of the 39th ACM/SIGAPP Symposium on Applied Computing},
pages = {1650–1658},
numpages = {9},
keywords = {ontology engineering, competency questions, large language models},
location = {Avila, Spain},
series = {SAC '24}
}

@inproceedings{10.1145/3677779.3677794,
author = {Wang, Cangqing and Yang, Yutian and Li, Ruisi and Sun, Dan and Cai, Ruicong and Zhang, Yuzhu and Fu, Chengqian},
title = {Adapting LLMs for Efficient Context Processing through Soft Prompt Compression},
year = {2024},
isbn = {9798400709760},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3677779.3677794},
doi = {10.1145/3677779.3677794},
abstract = {The rapid advancement of Large Language Models (LLMs) has inaugurated a transformative epoch in natural language processing, fostering unprecedented proficiency in text generation, comprehension, and contextual scrutiny. Nevertheless, effectively handling extensive contexts, crucial for myriad applications, poses a formidable obstacle owing to the intrinsic constraints of the models’ context window sizes and the computational burdens entailed by their operations. This investigation presents an innovative framework that strategically tailors LLMs for streamlined context processing by harnessing the synergies among natural language summarization, soft prompt com- pression, and augmented utility preservation mechanisms. Our methodology, dubbed SoftPromptComp, amalgamates natural language prompts extracted from summarization methodologies with dynamically generated soft prompts to forge a concise yet semantically robust depiction of protracted contexts. This depiction undergoes further refinement via a weighting mechanism optimizing information retention and utility for subsequent tasks. We substantiate that our framework markedly diminishes computational overhead and enhances LLMs’ efficacy across various benchmarks, while upholding or even augmenting the caliber of the produced content. By amalgamating soft prompt compression with sophisticated summarization, SoftPromptComp confronts the dual challenges of managing lengthy contexts and ensuring model scalability. Our findings point towards a propitious trajectory for augmenting LLMs’ applicability and efficiency, rendering them more versatile and pragmatic for real- world applications. This research enriches the ongoing discourse on optimizing language models, providing insights into the potency of soft prompts and summarization techniques as pivotal instruments for the forthcoming generation of NLP solutions.},
booktitle = {Proceedings of the International Conference on Modeling, Natural Language Processing and Machine Learning},
pages = {91–97},
numpages = {7},
keywords = {Knowledge Graph Reasoning, Reinforcement Learning, Reward Shaping, Transfer Learning},
location = {Xi'an, China},
series = {CMNM '24}
}

@inproceedings{10.1145/3635059.3635062,
author = {Giarelis, Nikolaos and Mastrokostas, Charalampos and Siachos, Ilias and Karacapilidis, Nikos},
title = {A Review of Greek NLP Technologies for Chatbot Development},
year = {2024},
isbn = {9798400716263},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3635059.3635062},
doi = {10.1145/3635059.3635062},
abstract = {The advent of Generative AI has certainly boosted the interest in developing innovative chatbot applications. Despite a vast amount of machine learning (ML) and natural language processing (NLP) research and English language resources that greatly improve chatbot technology, the corresponding research and resources for the Greek language are limited. The contribution of this paper is twofold: (i) it reports on the state-of-the-art research in Greek NLP, as far as language resources, embeddings-based techniques, deep learning models, and existing chatbot applications are concerned; (ii) it offers a set of insights on current NLP models and chatbot implementation methodologies, and outlines a set of pending issues and future research directions.},
booktitle = {Proceedings of the 27th Pan-Hellenic Conference on Progress in Computing and Informatics},
pages = {15–20},
numpages = {6},
keywords = {Deep Learning, Greek Language, Large Language Models, Review, Text Classification, Text Summarization, Word Embeddings},
location = {Lamia, Greece},
series = {PCI '23}
}

@inproceedings{10.1145/3652620.3687809,
author = {G\"{o}bel, Susanne and L\"{a}mmel, Ralf},
title = {Model-Based Trust Analysis of LLM Conversations},
year = {2024},
isbn = {9798400706226},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652620.3687809},
doi = {10.1145/3652620.3687809},
abstract = {LLM-based chatbots are routinely advertised as supporting the collaboration of humans and AI. We study LLM conversations from a knowledge elicitation perspective with the objective of being able to understand and assess the human's trust in knowledge elicited from the LLM and complementary sources. Our approach is supported by the DSML KEML, the Knowledge Elicitation Modeling Language, subject to abstract and visual syntax as well as a model transformation-based model semantics for trust analysis. Conversations are modeled by a combination of sequence diagrams and enhanced argumentation graphs --- the latter for the purpose of relating information pieces (facts and instructions) that are extracted from messages. The analysis of the corresponding models entails trust scores for gathered information (i.e., elicited knowledge).},
booktitle = {Proceedings of the ACM/IEEE 27th International Conference on Model Driven Engineering Languages and Systems},
pages = {602–610},
numpages = {9},
keywords = {MDE for AI, knowledge representation models, model-based analysis of LLMS, dsmls for AI usage},
location = {Linz, Austria},
series = {MODELS Companion '24}
}

@article{10.1145/3709138,
author = {Yuan, Wei and Yang, Chaoqun and Ye, Guanhua and Chen, Tong and Hung, Nguyen Quoc Viet and Yin, Hongzhi},
title = {FELLAS: Enhancing Federated Sequential Recommendation with LLM as External Services},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1046-8188},
url = {https://doi.org/10.1145/3709138},
doi = {10.1145/3709138},
abstract = {Sequential recommendation has been widely studied in the recommendation domain since it can capture users’ temporal preferences and provide more accurate and timely recommendations. To address user privacy concerns, the combination of federated learning and sequential recommender systems (FedSeqRec) has gained growing attention. Unfortunately, the performance of FedSeqRec is still unsatisfactory because the models used in FedSeqRec have to be lightweight to accommodate communication bandwidth and clients’ on-device computational resource constraints. Recently, large language models (LLMs) have exhibited strong transferable and generalized language understanding abilities and therefore, in the NLP area, many downstream tasks now utilize LLMs as a service to achieve superior performance without constructing complex models. Inspired by this successful practice, we propose a generic FedSeqRec framework, FELLAS, which aims to enhance FedSeqRec by utilizing LLMs as an external service.Specifically, FELLAS employs an LLM server to provide both item-level and sequence-level representation assistance. The item-level representation service is queried by the central server to enrich the original ID-based item embedding with textual information, while the sequence-level representation service is accessed by each client. However, invoking the sequence-level representation service requires clients to send sequences to the external LLM server. To safeguard privacy, we implement  (d_{mathcal{X}}) -privacy satisfied sequence perturbation, which protects clients’ sensitive data with guarantees. Additionally, a contrastive learning-based method is designed to transfer knowledge from the noisy sequence representation to clients’ sequential recommendation models. Furthermore, to empirically validate the privacy protection capability of FELLAS, we propose two interacted item inference attacks, considering the threats posed by the LLM server and the central server acting as curious-but-honest adversaries in cooperation. Extensive experiments conducted on three datasets with two widely used sequential recommendation models demonstrate the effectiveness and privacy-preserving capability of FELLAS.},
note = {Just Accepted},
journal = {ACM Trans. Inf. Syst.},
month = dec,
keywords = {Recommender System, Federated Learning, Privacy Protection}
}

@article{10.1145/3704729,
author = {Asprino, Luigi and Damiano, Rossana and Daquino, Marilena and De Giorgis, Stefano and Gangemi, Aldo and Lieto, Antonio and Sartini, Bruno and Striani, Manuel},
title = {An Ontology Network for Citizen Curation},
year = {2024},
issue_date = {December 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {4},
issn = {1556-4673},
url = {https://doi.org/10.1145/3704729},
doi = {10.1145/3704729},
abstract = {Citizen curation is gaining momentum as a new form of engagement with cultural heritage. Citizen curatorial activities require and produce a wealth of information, ranging from descriptions of the artefacts to visitor experience feedback. Although formalising and integrating such various data is of paramount importance, the domain lacks comprehensive ontologies to enable querying, interpreting and reasoning over the collected data. Social Participation, Cohesion and Inclusion through Cultural Engagement (SPICE) is an EU project dedicated to experimenting with citizen curation activities to foster cultural engagement. SPICE develops technologies that help communities to create and share their own interpretation of cultural artefacts, hence developing a better understanding of, and empathy for, themselves and other communities. Part of the SPICE ecosystem of technologies is the SPICE Ontology Network (SON), which empowers applications with knowledge-level reasoning abilities and supports both applications and users interacting with data involved in citizen curation activities. This article provides an overview of the SON and outlines its main use cases.},
journal = {J. Comput. Cult. Herit.},
month = dec,
articleno = {72},
numpages = {30},
keywords = {citizen curation, ontologies, cultural heritage, semantic web}
}

@inproceedings{10.1145/3626772.3657966,
author = {Zhang, Wenjia and Gui, Lin and Procter, Rob and He, Yulan},
title = {Multi-Layer Ranking with Large Language Models for News Source Recommendation},
year = {2024},
isbn = {9798400704314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626772.3657966},
doi = {10.1145/3626772.3657966},
abstract = {To seek reliable information sources for news events, we introduce a novel task of expert recommendation, which aims to identify trustworthy sources based on their previously quoted statements. To achieve this, we built a novel dataset, called NewsQuote, consisting of 23,571 quote-speaker pairs sourced from a collection of news articles. We formulate the recommendation task as the retrieval of experts based on their likelihood of being associated with a given query. We also propose a multi-layer ranking framework employing Large Language Models to improve the recommendation performance. Our results show that employing an in-context learning based LLM ranker and a multi-layer ranking-based filter significantly improve both the predictive quality and behavioural quality of the recommender system.},
booktitle = {Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {2537–2542},
numpages = {6},
keywords = {in-context learning, large language model, recommender system},
location = {Washington DC, USA},
series = {SIGIR '24}
}

@inproceedings{10.1145/3639233.3639242,
author = {Miskell, Cameron and Diaz, Richard and Ganeriwala, Parth and Slhoub, Khaled and Nembhard, Fitzroy},
title = {Automated Framework to Extract Software Requirements from Source Code},
year = {2024},
isbn = {9798400709227},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639233.3639242},
doi = {10.1145/3639233.3639242},
abstract = {Software maintenance and innovation are constant challenges across industries, especially as programming languages evolve with technology. Similarly, poor lexicon quality degrades program comprehension, increasing the effort required by developers to improve existing software products. To address these challenges, we propose a novel automated framework that extracts software requirements directly from source code using a baseline AI language model applied to a Java code base. Leveraging natural language processing techniques, the framework validates programs and generates easily readable requirements by analyzing file contents. The framework enhances agility and flexibility by providing comprehensive documentation for existing software systems. It caters to both experienced and less-experienced developers, offering an intuitive graphical user interface and enabling efficient identification and resolution of errors. The resulting output facilitates natural interaction through language processing. By automating the extraction process, the framework allows developers to better understand software systems, make informed decisions, and adapt to evolving needs.},
booktitle = {Proceedings of the 2023 7th International Conference on Natural Language Processing and Information Retrieval},
pages = {130–134},
numpages = {5},
keywords = {AI language model, Extracting functional requirements, Legacy code, Natural Language Processing, Software evolution, Software verification},
location = {Seoul, Republic of Korea},
series = {NLPIR '23}
}

@inproceedings{10.1145/3589334.3645686,
author = {Yu, Weijian and Yang, Jie and Yang, Dingqi},
title = {Robust Link Prediction over Noisy Hyper-Relational Knowledge Graphs via Active Learning},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3645686},
doi = {10.1145/3589334.3645686},
abstract = {Modern Knowledge Graphs (KGs) are inevitably noisy due to the nature of their construction process. Existing robust learning techniques for noisy KGs mostly focus on triple facts, where the fact-wise confidence is straightforward to evaluate. However, hyper-relational facts, where an arbitrary number of key-value pairs are associated with a base triplet, have become increasingly popular in modern KGs, but significantly complicate the confidence assessment of the fact. Against this background, we study the problem of robust link prediction over noisy hyper-relational KGs, and propose NYLON, a underlineN oise-resistant hunderlineY per-reunderlineL atiunderlineON al link prediction technique via active crowd learning. Specifically, beyond the traditional fact-wise confidence, we first introduce element-wise confidence measuring the fine-grained confidence of each entity or relation of a hyper-relational fact. We connect the element- and fact-wise confidences via a "least confidence'' principle to allow efficient crowd labeling. NYLON is then designed to systematically integrate three key components, where a hyper-relational link predictor uses the fact-wise confidence for robust prediction, a cross-grained confidence evaluator predicts both element- and fact-wise confidences, and an effort-efficient active labeler selects informative facts for crowd annotators to label using an efficient labeling mechanism guided by the element-wise confidence under the "least confidence'' principle and further followed by data augmentation. We evaluate NYLON on three real-world KG datasets against a sizeable collection of baselines. Results show that NYLON achieves superior and robust performance in both link prediction and error detection tasks on noisy KGs, and outperforms best baselines by 2.42-10.93% and 3.46-10.65% in the two tasks, respectively.},
booktitle = {Proceedings of the ACM Web Conference 2024},
pages = {2282–2293},
numpages = {12},
keywords = {hyper-relation, link prediction, noisy knowledge graph},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3664647.3680790,
author = {Hu, Linmei and Wang, Duokang and Pan, Yiming and Yu, Jifan and Shao, Yingxia and Feng, Chong and Nie, Liqiang},
title = {NovaChart: A Large-scale Dataset towards Chart Understanding and Generation of Multimodal Large Language Models},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3680790},
doi = {10.1145/3664647.3680790},
abstract = {Multimodal Large Language Models (MLLMs) have shown significant potential for chart understanding and generation. However, they are still far from achieving the desired effectiveness in practical applications. This could be due to the limitations of the used training chart data. Existing chart datasets suffer from scarcity of chart types, limited coverage of tasks, and insufficient scalability, making them incapable of effectively enhancing the chart-related capabilities of MLLMs. To tackle these obstacles, we construct NovaChart, a large-scale dataset for chart understanding and generation of MLLMs. NovaChart contains 47K high-resolution chart images and 856K chart-related instructions, covering 18 different chart types and 15 unique tasks of chart understanding and generation. To build NovaChart, we propose a data generation engine for metadata curation, chart visualization and instruction formulation. Chart metadata in NovaChart contains detailed annotations, i.e., data points, visual elements, source data and the visualization code of every chart. This additional information endows NovaChart with considerable scalability, as it can facilitate the extension of chart instruction data to a larger scale and greater diversity. We utilize NovaChart to train several open-source MLLMs. Experimental results demonstrate NovaChart empowers MLLMs with stronger capabilities in 15 chart understanding and generation tasks by a large-margin (35.47%-619.47%), bringing them a step closer to smart chart assistants. Our dataset is now available at https://github.com/Elucidator-V/NovaChart.},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {3917–3925},
numpages = {9},
keywords = {chart generation, chart understanding, multimodal large language model},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@inproceedings{10.1145/3589334.3645627,
author = {Huang, Xuanwen and Han, Kaiqiao and Yang, Yang and Bao, Dezheng and Tao, Quanjin and Chai, Ziwei and Zhu, Qi},
title = {Can GNN be Good Adapter for LLMs?},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3645627},
doi = {10.1145/3589334.3645627},
abstract = {Recently, large language models (LLMs) have demonstrated superior capabilities in understanding and zero-shot learning on textual data, promising significant advances for many text-related domains. In the graph domain, various real-world scenarios also involve textual data, where tasks and node features can be described by text. These text-attributed graphs (TAGs) have broad applications in social media, recommendation systems, etc. Thus, this paper explores how to utilize LLMs to model TAGs. Previous methods for TAG modeling are based on million-scale LMs. When scaled up to billion-scale LLMs, they face huge challenges in computational costs. Additionally, they also ignore the zero-shot inference capabilities of LLMs. Therefore, we propose GraphAdapter, which uses a graph neural network (GNN) as an efficient adapter in collaboration with LLMs to tackle TAGs. In terms of efficiency, the GNN adapter introduces only a few trainable parameters and can be trained with low computation costs. The entire framework is trained using auto-regression on node text (next token prediction). Once trained, GraphAdapter can be seamlessly fine-tuned with task-specific prompts for various downstream tasks. Through extensive experiments across multiple real-world TAGs, GraphAdapter based on Llama 2 gains an average improvement of approximately 5% in terms of node classification. Furthermore, GraphAdapter can also adapt to other language models, including RoBERTa, GPT-2. The promising results demonstrate that GNNs can serve as effective adapters for LLMs in TAG modeling.},
booktitle = {Proceedings of the ACM Web Conference 2024},
pages = {893–904},
numpages = {12},
keywords = {graph neural networks, large language model, text-attributed graph},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3643795.3648384,
author = {Koziolek, Heiko and Gr\"{u}ner, Sten and Hark, Rhaban and Ashiwal, Virendra and Linsbauer, Sofia and Eskandani, Nafise},
title = {LLM-based and Retrieval-Augmented Control Code Generation},
year = {2024},
isbn = {9798400705793},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643795.3648384},
doi = {10.1145/3643795.3648384},
abstract = {Control code is designed and implemented for industrial automation applications that manage power plants, petrochemical processes, or steel production. Popular large language models (LLM) can synthesize low-level control code in the Structured Text programming notation according to the standard IEC 61131-3, but are not aware of proprietary control code function block libraries, which are often used in practice. To automate control logic implementation tasks, we proposed a retrieval-augmented control code generation method that can integrate such function blocks into the generated code. With this method control engineers can benefit from the code generation capabilities of LLMs, re-use proprietary and well-tested function blocks, and speed up typical programming tasks significantly. We have evaluated the method using a prototypical implementation based on GPT-4, LangChain, Open-PLC, and the open-source OSCAT function block library. In several spot sample tests, we successfully generated IEC 61131-3 ST code that integrated the desired function blocks, could be compiled, and validated through simulations.},
booktitle = {Proceedings of the 1st International Workshop on Large Language Models for Code},
pages = {22–29},
numpages = {8},
keywords = {large language models, code generation, IEC 61131-3, industrial automation, PLC, DCS, ChatGPT, GPT-4},
location = {Lisbon, Portugal},
series = {LLM4Code '24}
}

@article{10.1145/3685679,
author = {Hou, Jingrui and Zhang, Shitou},
title = {Exploring Thematic Diversity in Classical Chinese Poetry: A Novel Dataset and a BERT-enhanced Ensemble Learning Approach},
year = {2024},
issue_date = {December 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {17},
number = {4},
issn = {1556-4673},
url = {https://doi.org/10.1145/3685679},
doi = {10.1145/3685679},
abstract = {Classical Chinese poetry, as an essential aspect of cultural heritage, exhibits rich theme diversity often overlooked in natural language processing research. To address this gap, we aim to explore the classification of thematic categories within this literary domain. We curate a dataset of 2,918 annotated poems spanning 7 common themes and propose a BERT-based ensemble learning approach for effective classification. Although this method integrates existing models, it achieves an accuracy and F1 score of over 72% in the 7-class task, surpassing established baselines, and providing a baseline for future research. The experimental findings reveal the effectiveness of ensemble strategies in improving individual base model performance and highlight the potential of the MLP-based ensemble technique. The study contributes to a deeper understanding of thematic categories and textual features in classical Chinese poetry and offers an automated classification system for classical Chinese poems.},
journal = {J. Comput. Cult. Herit.},
month = dec,
articleno = {60},
numpages = {19},
keywords = {Thematic Classification, Classical Chinese Poetry, Ensemble Learning, Pre-trained Language Model}
}

@inproceedings{10.1145/3651671.3651721,
author = {Zhang, Haiying and Shi, Yunmei and Yang, Teng},
title = {BP-TEG: Topic-to-Essay Generation for Official Documents},
year = {2024},
isbn = {9798400709234},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3651671.3651721},
doi = {10.1145/3651671.3651721},
abstract = {In natural language generation tasks, topic-to-essay generation (TEG) is a challenging task. The main diﬀiculty is that the amount of source information is much smaller than that of generated information. To solve the problem, the paper proposes a topic-to-essay generation model combined BART-based pointer generator networks (BP-TEG for short), which can generate high quality text by expanding the given topic words. The topic word expansion method is based on the LDA method, which is used to select appropriate expansion words that semantically consist with the topic words. In the proposed model, BART is introduced to get semantic and syntactic knowledge from a large-scale corpus. In order to improve the generated text quality and topic relevance, BP-TEG model introduces the pointer generator networks to pay more attention to unexpressed topic words. Experiments on both the oﬀicial document dataset and the public dataset Zhihu show that BP-TEG is superior to other advanced baseline models; manual evaluation results show that the model can generate more complete sentences, topic-relevant contents, in addition, the generated text has coherent language, and consistent with semantic logic and oﬀicial document standards.},
booktitle = {Proceedings of the 2024 16th International Conference on Machine Learning and Computing},
pages = {545–556},
numpages = {12},
keywords = {Natural Language Generation, Pointer Generation Network, Pre-trained Language Model, Topic-to-Essay Generation},
location = {Shenzhen, China},
series = {ICMLC '24}
}

@article{10.1145/3702647,
author = {Wang, Yuqi and Chen, Qiuyi and Zhang, Haiyang and Wang, Wei and Wang, Qiufeng and Pan, Yushan and Xie, Liangru and Huang, Kaizhu and Nguyen, Anh},
title = {Biomedical Information Retrieval with Positive-Unlabeled Learning and Knowledge Graphs},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {2157-6904},
url = {https://doi.org/10.1145/3702647},
doi = {10.1145/3702647},
abstract = {The rapid growth of biomedical publications has presented significant challenges in the field of information retrieval. Most existing work focuses on document retrieval given explicit queries. However, in real applications such as curated biomedical database maintenance, explicit queries are missing. In this paper, we propose a two-step model for biomedical information retrieval in the case that only a small set of example documents is available without explicit queries. Initially, we extract keywords from the observed documents using large pre-trained language models and biomedical knowledge graphs. These keywords are then enriched with domain-specific entities. Information retrieval techniques can subsequently use the collected entities to rank the documents. Following this, we introduce an iterative Positive-Unlabeled learning method to classify all unlabeled documents. Experiments conducted on the PubMed dataset demonstrate that the proposed technique outperforms the state-of-the-art positive-unlabeled learning methods. The results underscore the effectiveness of integrating large language models and biomedical knowledge graphs in improving zero-shot information retrieval performance in the biomedical domain.},
note = {Just Accepted},
journal = {ACM Trans. Intell. Syst. Technol.},
month = nov,
keywords = {Knowledge graph embedding, pre-trained large language models, positive-unlabeled learning, text classification, natural language processing, information retrieval}
}

@inproceedings{10.1145/3627673.3679228,
author = {Dew, Rebecca and Li, Mingzhao and Baratha Raj, Sandya},
title = {A Skill Proficiency Framework for Workforce Learning and Development},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679228},
doi = {10.1145/3627673.3679228},
abstract = {Understanding the skills and proficiency levels required for various roles is crucial for effective workforce planning, learning and development. In this paper, we propose a robust skill proficiency modeling framework that offers a structured method to help describe, assess and develop proficiency in key skills, facilitating individuals' career pathways and aiding organizations in talent management and adaptability. We first design a skill proficiency description pipeline, which generates statements describing the requirements at each proficiency level of a skill. Following this, we build a skill proficiency by occupation model using large-scale job ad data to help organizations and individuals understand the skill proficiency requirements for different roles. Finally,we design a visual analytics system, based on a real-world career pathway scenario, to demonstrate the practical usefulness and effectiveness of our framework. A demo video is available at www.dropbox.com/scl/fi/nd0f3vi03n12g4y0sluaw/cikm24_demo.mp4?rlkey=55vya144q5ftai1uqqaubr5u5.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {5210–5214},
numpages = {5},
keywords = {GPT, large language model, skill proficiency, visual analytics},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@inproceedings{10.1145/3677052.3698597,
author = {Cho, Nicole and Srishankar, Nishan and Cecchi, Lucas and Watson, William},
title = {FISHNET: Financial Intelligence from Sub-querying, Harmonizing, Neural-Conditioning, Expert Swarms, and Task Planning},
year = {2024},
isbn = {9798400710810},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3677052.3698597},
doi = {10.1145/3677052.3698597},
abstract = {Financial intelligence generation from vast data sources has typically relied on traditional methods of knowledge-graph construction or database engineering. Recently, fine-tuned financial domain-specific Large Language Models (LLMs), have emerged. While these advancements are promising, limitations such as high inference costs, hallucinations, and the complexity of concurrently analyzing high-dimensional financial data, emerge. This motivates our invention FISHNET (Financial Intelligence from Sub-querying, Harmonizing, Neural-Conditioning, Expert swarming, and Task planning), an agentic architecture that accomplishes highly complex analytical tasks for more than 98,000 regulatory filings that vary immensely in terms of semantics, data hierarchy, or format. FISHNET shows remarkable performance for financial insight generation (61.8% success rate over 5.0% Routing, 45.6% RAG R-Precision). We conduct rigorous ablations to empirically prove the success of FISHNET, each agent’s importance, and the optimized performance of assembling all agents. Our modular architecture can be leveraged for a myriad of use-cases, enabling scalability, flexibility, and data integrity that are critical for financial tasks.},
booktitle = {Proceedings of the 5th ACM International Conference on AI in Finance},
pages = {591–599},
numpages = {9},
keywords = {Harmonizing, LLM Agents, Planning, Sub-querying, Swarming},
location = {Brooklyn, NY, USA},
series = {ICAIF '24}
}

@inproceedings{10.1145/3664647.3681349,
author = {Ma, Yunshan and He, Yingzhi and Zhong, Wenjun and Wang, Xiang and Zimmermann, Roger and Chua, Tat-Seng},
title = {CIRP: Cross-Item Relational Pre-training for Multimodal Product Bundling},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3681349},
doi = {10.1145/3664647.3681349},
abstract = {Product bundling has been a prevailing marketing strategy that is beneficial in the online shopping scenario. Effective product bundling methods depend on high-quality item representations capturing both the individual items' semantics and cross-item relations. However, previous item representation learning methods, either feature fusion or graph learning, suffer from inadequate cross-modal alignment and struggle to capture the cross-item relations for cold-start items. Multimodal pre-train models could be the potential solutions given their promising performance on various multimodal downstream tasks. However, the cross-item relations have been under-explored in the current multimodal pre-train models.To bridge this gap, we propose a novel and simple framework Cross-Item Relational Pre-training (CIRP) for item representation learning in product bundling. Specifically, we employ a multimodal encoder to generate image and text representations. Then we leverage both the cross-item contrastive loss (CIC) and individual item's image-text contrastive loss (ITC) as the pre-train objectives. Our method seeks to integrate cross-item relation modeling capability into the multimodal encoder. Therefore, even for cold-start items without explicit relations, their representations are still relation-aware. Furthermore, to eliminate the potential noise and reduce the computational cost, we harness a relation pruning module to remove the noisy and redundant relations. We apply the item representations extracted by CIRP to the product bundling model ItemKNN, and experiments on three e-commerce datasets demonstrate that CIRP outperforms various leading representation learning methods. The code and dataset are available at https://github.com/HappyPointer/CIRP.},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {9641–9649},
numpages = {9},
keywords = {bundle recommendation, multimodal bundle construction, multimodal pre-train, vision language model},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@inproceedings{10.1145/3677052.3698603,
author = {Li, Xiaohui Victor and Sanna Passino, Francesco},
title = {FinDKG: Dynamic Knowledge Graphs with Large Language Models for Detecting Global Trends in Financial Markets},
year = {2024},
isbn = {9798400710810},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3677052.3698603},
doi = {10.1145/3677052.3698603},
abstract = {Dynamic knowledge graphs (DKGs) are popular structures to express different types of connections between objects over time. They can also serve as an efficient mathematical tool to represent information extracted from complex unstructured data sources, such as text or images. Within financial applications, DKGs could be used to detect trends for strategic thematic investing, based on information obtained from financial news articles. In this work, we explore the properties of large language models (LLMs) as dynamic knowledge graph generators, proposing a novel open-source fine-tuned LLM for this purpose, called the Integrated Contextual Knowledge Graph Generator (ICKG). We use ICKG to produce a novel open-source DKG from a corpus of financial news articles, called FinDKG, and we propose an attention-based GNN architecture for analysing it, called KGTransformer. We test the performance of the proposed model on benchmark datasets and FinDKG, demonstrating superior performance on link prediction tasks. Additionally, we evaluate the performance of the KGTransformer on FinDKG for thematic investing, showing it can outperform existing thematic ETFs.},
booktitle = {Proceedings of the 5th ACM International Conference on AI in Finance},
pages = {573–581},
numpages = {9},
keywords = {Dynamic knowledge graphs, graph attention networks, graph neural networks, graph transformers, large language models.},
location = {Brooklyn, NY, USA},
series = {ICAIF '24}
}

@inproceedings{10.1145/3613904.3642698,
author = {Liu, Yiren and Chen, Si and Cheng, Haocong and Yu, Mengxia and Ran, Xiao and Mo, Andrew and Tang, Yiliu and Huang, Yun},
title = {How AI Processing Delays Foster Creativity: Exploring Research Question Co-Creation with an LLM-based Agent},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642698},
doi = {10.1145/3613904.3642698},
abstract = {Developing novel research questions (RQs) often requires extensive literature reviews, especially in interdisciplinary fields. To support RQ development through human-AI co-creation, we leveraged Large Language Models (LLMs) to build an LLM-based agent system named CoQuest. We conducted an experiment with 20 HCI researchers to examine the impact of two interaction designs: breadth-first and depth-first RQ generation. The findings revealed that participants perceived the breadth-first approach as more creative and trustworthy upon task completion. Conversely, during the task, participants considered the depth-first generated RQs as more creative. Additionally, we discovered that AI processing delays allowed users to reflect on multiple RQs simultaneously, leading to a higher quantity of generated RQs and an enhanced sense of control. Our work makes both theoretical and practical contributions by proposing and evaluating a mental model for human-AI co-creation of RQs. We also address potential ethical issues, such as biases and over-reliance on AI, advocating for using the system to improve human research creativity rather than automating scientific inquiry. The system’s source is available at: https://github.com/yiren-liu/coquest.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {17},
numpages = {25},
keywords = {Co-creation Systems, Large Language Models, Mixed-initiative Design, Scientifc Discovery},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3674805.3690751,
author = {Deng, Yang and Wang, Bangchao and Zou, Zhiyuan and Ye, Luyao},
title = {PromptLink: Multi-template prompt learning with adversarial training for issue-commit link recovery},
year = {2024},
isbn = {9798400710476},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3674805.3690751},
doi = {10.1145/3674805.3690751},
abstract = {In recent years, Prompt Learning, based on pre-training, prompting, and prediction, has achieved significant success in natural language processing (NLP). The current issue-commit link recovery (ILR) method converts the ILR into a classification task using pre-trained language models (PLMs) and dedicated neural networks. However, due to inconsistencies between the ILR task and PLMs, these methods not fully leverage the semantic information in PLMs. To imitate the above problem, we make the first trial of the new paradigm to propose a Multi-template prompt learning method with adversarial training for issue-commit link recovery (PromptLink), which transforms the ILR task into a cloze task through the template. Specifically, a Multi-template PromptLink is designed to enhance the generalisation capability by integrating various templates and adopting adversarial training to mitigate the model overfitting. Experiments are conducted on six open-source projects and comprehensively evaluated across six commonly measures. The results show that PromptLink achieves an average F1 of 96.10%, Precision of 96.49%, Recall of 95.92%, MCC of 94.04%, AUC of 96.05%, and ACC of 98.15%, significantly outperforming existing state-of-the-art methods on all measures. Overall, PromptLink not only enhances performance and generalisation but also emerges new ideas and methods for future research. The source code of PromptLink is available at https://figshare.com/s/6130d42ff464c579cdec.},
booktitle = {Proceedings of the 18th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement},
pages = {461–467},
numpages = {7},
keywords = {Issue-commit link recovery, Natural language processing, Pre-trained language model, Prompt learning},
location = {Barcelona, Spain},
series = {ESEM '24}
}

@inproceedings{10.1145/3680529.3688968,
author = {Kraft, Georgy \`{E}gor},
title = {One and Infinite Chairs: 1 &amp; ∞ ⑁},
year = {2024},
isbn = {9798400711329},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3680529.3688968},
doi = {10.1145/3680529.3688968},
abstract = {Joseph Kossuth's 'One &amp; Three Chairs' is the most textbook -introductory - example to conceptual art, as it touches upon a number of characteristics definitive of conceptual art. Emphasising the concept above all other perceptual content, it dematerialises art itself as a practice.In 1 &amp; ∞ Initial images of chairs were generated using the text-to-image Ai model, based on the prompt: 'a single chair on a plain background'. This dataset, of photo-realistic images of a wide variety of chairs, was then used to train the Stable Diffusion model again, extending its knowledge capacity of what 'a chair on a plain background' can look like. This process of re-training the model on its own generated imagery was repeated again and again. Until, at the 6th iteration, instead of photo-realistic images of chairs, as seen in the initial step, the model produced colourful digital noise in which any resemblance to the represented subject -a chair, would fade completely.In another iconic conceptual sound artwork, 'I am sitting in a room,' the author Alvin Lucier is recording himself narrating a text, and then playing the tape recording back into the room, re-recording it. Eventually the words become unintelligible, replaced by the characteristic resonant frequencies of the room itself.In data science, the phenomena of AI feeding into AI is often referred to as data-cannibalism. Through the necessity to augment datasets and due to AI image and data generation's increasing and insidious prevalence, more and more new Ai systems will be trained on synthetic datasets, produced by generative Ai models, thus posing ontological challenges and poisoning future datasets and epistemic accuracy of those models. Via such feedback loops within echo chambers of auto-generated and consumed data, the domain ontology of a subject and its visual representation decay into non-figurative abstraction... at least so for a human eye.},
booktitle = {SIGGRAPH Asia 2024 Art Gallery},
articleno = {1},
numpages = {1},
location = {Tokyo, Japan},
series = {SA Art Gallery '24}
}

@inproceedings{10.1145/3663649.3664371,
author = {Prakash, Kishore and Rao, Shashwat and Hamza, Rayan and Lukich, Jack and Chaudhari, Vatsal and Nandi, Arnab},
title = {Integrating LLMs into Database Systems Education},
year = {2024},
isbn = {9798400706783},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663649.3664371},
doi = {10.1145/3663649.3664371},
abstract = {Large Language Models (LLMs) have sparked a drastic improvement in the ways computers can understand, process, and generate language. As LLM-based offerings become mainstream, we explore the incorporation of such LLMs into introductory or undergraduate database systems education. Students and instructors are both faced with the calculator dilemma: while the use of LLM-based tools may “solve” tasks such as assignments and exams, do they impede or accelerate the learning itself? We review deficiencies of using existing off-the-shelf tools for learning, and further articulate the differentiated needs of database systems students as opposed to trained data practitioners. Building on our exploration, we outline a vision that integrates LLMs into database education in a principled manner, keeping pedagogical best practices in mind. If implemented correctly, we posit that LLMs can drastically amplify the impact of existing instruction, minimizing costs and barriers towards learning database systems fundamentals.},
booktitle = {Proceedings of the 3rd International Workshop on Data Systems Education: Bridging Education Practice with Education Research},
pages = {33–39},
numpages = {7},
keywords = {ChatGPT, database systems education, foundation models, intro to db, large language models, llm, undergrad databases},
location = {Santiago, AA, Chile},
series = {DataEd '24}
}

@article{10.1145/3689040,
author = {Bomba, Federico and Men\'{e}ndez-Blanco, Mar\'{\i}a and Grigis, Paolo and Cremaschi, Michele and De Angeli, Antonella},
title = {The Choreographer-Performer Continuum: A Diffraction Tool to Illuminate Authorship in More Than Human Co-Performances},
year = {2024},
issue_date = {December 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {31},
number = {6},
issn = {1073-0516},
url = {https://doi.org/10.1145/3689040},
doi = {10.1145/3689040},
abstract = {The design of robust and trustworthy Generative AI (GenAI) requires a deep understanding of the agencies emerging from human interactions with them. To contribute to this goal, we retrospectively studied an art project involving a visual artist, a computer scientist, an artistic director, and a generative model (GPT-2). The model was fine-tuned with trip reports describing the experience of eating psychedelic mushrooms. Building on agential realism, we analysed the co-performance between the artist and the model as their agency moved along the choreographer-performer continuum. Results reveal ontological surprises, leading to the proposal of entangled authorship to de-individualise the production of knowledge from a More Than Human perspective. The paper illustrates how art can expose different forms of relationships, challenging the idea of GenAI as just a tool that simplifies or replaces human labour. We conclude by emphasising the transformational potential of GenAI for novel modes of engagement between humans and machines.},
journal = {ACM Trans. Comput.-Hum. Interact.},
month = dec,
articleno = {75},
numpages = {23},
keywords = {Agency, Agential Realism, Large Language Models, AI and Art, Creative AI, Hallucination}
}

@inproceedings{10.1145/3625007.3627505,
author = {Ranade, Priyanka and Joshi, Anupam},
title = {FABULA: Intelligence Report Generation Using Retrieval-Augmented Narrative Construction},
year = {2024},
isbn = {9798400704093},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3625007.3627505},
doi = {10.1145/3625007.3627505},
abstract = {Narrative construction is the process of representing disparate event information into a logical plot structure that models an end to end story. Intelligence analysis is an example of a domain that can benefit tremendously from narrative construction techniques, particularly in aiding analysts during the largely manual and costly process of synthesizing event information into comprehensive intelligence reports. Manual intelligence report generation is often prone to challenges such as integrating dynamic event information, writing fine-grained queries, and closing information gaps. This motivates the development of a system that retrieves and represents critical aspects of events in a form that aids in automatic generation of intelligence reports.We introduce a Retrieval Augmented Generation (RAG) approach to augment prompting of an autoregressive decoder by retrieving structured information asserted in a knowledge graph to generate targeted information based on a narrative plot model. We apply our approach to the problem of neural intelligence report generation and introduce FABULA, framework to augment intelligence analysis workflows using RAG. An analyst can use FABULA to query an Event Plot Graph (EPG) to retrieve relevant event plot points, which can be used to augment prompting of a Large Language Model (LLM) during intelligence report generation. Our evaluation studies show that the plot points included in the generated intelligence reports have high semantic relevance, high coherency, and low data redundancy.},
booktitle = {Proceedings of the 2023 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining},
pages = {603–610},
numpages = {8},
keywords = {retrieval augmented generation, large language models, knowledge graphs, narratives},
location = {Kusadasi, Turkiye},
series = {ASONAM '23}
}

@inproceedings{10.1109/ASE56229.2023.00019,
author = {Phokela, Kanchanjot Kaur and Sikand, Samarth and Singi, Kapil and Dey, Kuntal and Sharma, Vibhu Saujanya and Kaulgud, Vikrant},
title = {Smart Prompt Advisor: Multi-Objective Prompt Framework for Consistency and Best Practices},
year = {2024},
isbn = {9798350329964},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASE56229.2023.00019},
doi = {10.1109/ASE56229.2023.00019},
abstract = {Recent breakthroughs in Large Language Models (LLM), comprised of billions of parameters, have achieved the ability to unveil exceptional insight into a wide range of Natural Language Processing (NLP) tasks. The onus of the performance of these models lies in the sophistication and completeness of the input prompt. Minimizing the enhancement cycles of prompt with improvised keywords becomes critically important as it directly affects the time to market and cost of the developing solution. However, this process inevitably has a trade-off between the learning curve/proficiency of the user and completeness of the prompt, as generating such a solutions is an incremental process. In this paper, we have designed a novel solution and implemented it in the form of a plugin for Visual Studio Code IDE, which can optimize this trade-off, by learning the underlying prompt intent to enhance with keywords. This will tend to align with developers' collection of semantics while developing a secure code, ensuring parameter and local variable names, return expressions, simple pre and post-conditions, and basic control and data flow are met.},
booktitle = {Proceedings of the 38th IEEE/ACM International Conference on Automated Software Engineering},
pages = {1846–1848},
numpages = {3},
keywords = {prompt engineering, artificial intelligence, deep learning, LLM, ontology},
location = {Echternach, Luxembourg},
series = {ASE '23}
}

@inproceedings{10.1145/3637528.3671857,
author = {Ouyang, Siru and Huang, Jiaxin and Pillai, Pranav and Zhang, Yunyi and Zhang, Yu and Han, Jiawei},
title = {Ontology Enrichment for Effective Fine-grained Entity Typing},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671857},
doi = {10.1145/3637528.3671857},
abstract = {Fine-grained entity typing (FET) is the task of identifying specific entity types at a fine-grained level for entity mentions based on their contextual information. Conventional methods for FET require extensive human annotation, which is time-consuming and costly given the massive scale of data. Recent studies have been developing weakly supervised or zero-shot approaches. We study the setting of zero-shot FET where only an ontology is provided. However, most existing ontology structures lack rich supporting information and even contain ambiguous relations, making them ineffective in guiding FET. Recently developed language models, though promising in various few-shot and zero-shot NLP tasks, may face challenges in zero-shot FET due to their lack of interaction with task-specific ontology. In this study, we propose \o{}urs, where we (1) enrich each node in the ontology structure with two categories of extra information:instance information for training sample augmentation andtopic information to relate types with contexts, and (2) develop a coarse-to-fine typing algorithm that exploits the enriched information by training an entailment model with contrasting topics and instance-based augmented training samples. Our experiments show that \o{}urs achieves high-quality fine-grained entity typing without human annotation, outperforming existing zero-shot methods by a large margin and rivaling supervised methods. \o{}urs also enjoys strong transferability to unseen and finer-grained types. We will open source this work upon acceptance.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {2318–2327},
numpages = {10},
keywords = {fine-grained entity typing, language models, natural language inference, zero-shot learning},
location = {Barcelona, Spain},
series = {KDD '24}
}

@inproceedings{10.1145/3670105.3670144,
author = {Lin, Yunxiao and Tang, Jiahao and Huang, Wenjun and Ding, Yanyu and Hu, Jianguo},
title = {Chinese Named Entity Recognition for IC Patent Domain Based on RoBERTa-wwm-ext, GCN and Efficient Global Pointer},
year = {2024},
isbn = {9798400716751},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3670105.3670144},
doi = {10.1145/3670105.3670144},
abstract = {In the domain of Natural Language Processing (NLP), the task of Named Entity Recognition (NER)for Integrated Circuits (IC) Intellectual Property (IP) presents a substantial challenge.This challenge stems from the intricacies of the Chinese language, characterized by its complexity and character-based nature, the unique structural attributes of IP data, and the difficulties in identifying lengthy and nested entities. To tackle these challenges, our study introduces a novel Chinese Entity Recognition approach named RGEGP, meticulously crafted for the IC IP domain. This approach integrates RoBERTa-wwm-ext, Graph Convolutional Networks (GCN), and Efficient Global Pointer (EGP) techniques into a cohesive framework. Specifically, RoBERTa-wwm-ext, which is designed for Chinese character attributes through a whole word masking pretraining approach, considerably improves the capability of model in recognizing Chinese entities. Additionally, the incorporation of GCN enhances the ability of model to exploit entity relationships and structured Chinese textual information, markedly boosting its performance in entity recognition within complex Chinese texts. Addressing the occurrence of elongated and nested entities, the EGP method utilizes global pointers coupled with an efficient encoding strategy to directly predict entity boundaries and categories. Experimental results on two datasets, particularly concerning IC domain, show that our methodology outperforms existing leading NER models in this field, achieving significant advancements in precision, recall, and F1 scores.},
booktitle = {Proceedings of the 2024 5th International Conference on Computing, Networks and Internet of Things},
pages = {234–240},
numpages = {7},
keywords = {Large Language Model, Machine Learning, Named Entity Recognition, Natural Language Processing},
location = {Tokyo, Japan},
series = {CNIOT '24}
}

@inproceedings{10.1145/3671151.3671313,
author = {Shao, Yujie and Zou, Mengyuan and Kong, Ruiyuan and Dong, Shuhan},
title = {Research on Entity Linking Techniques for Architecture-Oriented Knowledge Graphs},
year = {2024},
isbn = {9798400718106},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3671151.3671313},
doi = {10.1145/3671151.3671313},
abstract = {In the face of the current increasing demand for the use of architecture knowledge graph, in order to improve the use of architecture knowledge graph efficiency and functional effect, the end of entity linking suitable for architecture knowledge graph is utilized to realize the linking of entities with multiple different entity names referring to the same entity object. Firstly, the BERT-based organizational relationship classification model is used to classify the entities, and the combination of BiLSTM neural network and CRF is used to construct the BERT-BiLSTM-CRF entity recognition framework for entity category identification, and the similarity matching algorithm is used to select the entities with the top three similarity rankings as the entity candidate list after determining the classification of the user input content, and the weights of the entities are increased based on the similarity score and user selection, and the weights are increased based on the similarity score and user selection. degree score and user selection to increase the weight to determine the linking entity pairs, thus improving the quality and efficiency of the past entity categorization identification and linking in the system knowledge graph, and realizing the effect of entity fusion and localization.},
booktitle = {Proceedings of the 5th International Conference on Computer Information and Big Data Applications},
pages = {924–930},
numpages = {7},
location = {Wuhan, China},
series = {CIBDA '24}
}

@article{10.1145/3657631,
author = {Biancofiore, Giovanni Maria and Deldjoo, Yashar and Noia, Tommaso Di and Di Sciascio, Eugenio and Narducci, Fedelucio},
title = {Interactive Question Answering Systems: Literature Review},
year = {2024},
issue_date = {September 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {56},
number = {9},
issn = {0360-0300},
url = {https://doi.org/10.1145/3657631},
doi = {10.1145/3657631},
abstract = {Question-answering systems are recognized as popular and frequently effective means of information seeking on the web. In such systems, information seekers can receive a concise response to their queries by presenting their questions in natural language. Interactive question answering is a recently proposed and increasingly popular solution that resides at the intersection of question answering and dialogue systems. On the one hand, the user can ask questions in normal language and locate the actual response to her inquiry; on the other hand, the system can prolong the question-answering session into a dialogue if there are multiple probable replies, very few, or ambiguities in the initial request. By permitting the user to ask more questions, interactive question answering enables users to interact with the system and receive more precise results dynamically.This survey offers a detailed overview of the interactive question-answering methods that are prevalent in current literature. It begins by explaining the foundational principles of question-answering systems, hence defining new notations and taxonomies to combine all identified works inside a unified framework. The reviewed published work on interactive question-answering systems is then presented and examined in terms of its proposed methodology, evaluation approaches, and dataset/application domain. We also describe trends surrounding specific tasks and issues raised by the community, so shedding light on the future interests of scholars. Our work is further supported by a GitHub page synthesizing all the major topics covered in this literature study.},
journal = {ACM Comput. Surv.},
month = may,
articleno = {239},
numpages = {38},
keywords = {Question answering, natural language processing, interactive systems, human-computer interaction, artificial intelligence, large language model}
}

@inproceedings{10.1145/3605098.3635889,
author = {Arrieta, Kutz and Fillottrani, Pablo R and Keet, C. Maria},
title = {CoSMo: A multilingual modular language for Content Selection Modelling},
year = {2024},
isbn = {9798400702433},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3605098.3635889},
doi = {10.1145/3605098.3635889},
abstract = {Representing snippets of information abstractly is a task that needs to be performed for various purposes, such as database view specification and the first stage in the natural language generation pipeline for generative AI from structured input, i.e., the content selection stage to determine what needs to be verbalised. For the Abstract Wikipedia project, requirements analysis revealed that such an abstract representation requires multilingual modelling, content selection covering declarative content and functions, and both classes and instances. There is no modelling language that meets either of the three features, let alone a combination. Following a rigorous language design process inclusive of broad stakeholder consultation, we created CoSMo, a novel Content Selection Modeling language that meets these and other requirements so that it may be useful both in Abstract Wikipedia as well as other contexts. We describe the design process, rationale and choices, the specification, and preliminary evaluation of the language.},
booktitle = {Proceedings of the 39th ACM/SIGAPP Symposium on Applied Computing},
pages = {706–713},
numpages = {8},
keywords = {modeling language, query language, wikidata, multilingualism},
location = {Avila, Spain},
series = {SAC '24}
}

@inproceedings{10.1145/3626772.3657815,
author = {Joko, Hideaki and Chatterjee, Shubham and Ramsay, Andrew and de Vries, Arjen P. and Dalton, Jeff and Hasibi, Faegheh},
title = {Doing Personal LAPS: LLM-Augmented Dialogue Construction for Personalized Multi-Session Conversational Search},
year = {2024},
isbn = {9798400704314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626772.3657815},
doi = {10.1145/3626772.3657815},
abstract = {The future of conversational agents will provide users with personalized information responses. However, a significant challenge in developing models is the lack of large-scale dialogue datasets that span multiple sessions and reflect real-world user preferences. Previous approaches rely on experts in a wizard-of-oz setup that is difficult to scale, particularly for personalized tasks. Our method, LAPS, addresses this by using large language models (LLMs) to guide a single human worker in generating personalized dialogues. This method has proven to speed up the creation process and improve quality. LAPS can collect large-scale, human-written, multi-session, and multi-domain conversations, including extracting user preferences. When compared to existing datasets, LAPS-produced conversations are as natural and diverse as expert-created ones, which stays in contrast with fully synthetic methods. The collected dataset is suited to train preference extraction and personalized response generation. Our results show that responses generated explicitly using extracted preferences better match user's actual preferences, highlighting the value of using extracted preferences over simple dialogue history. Overall, LAPS introduces a new method to leverage LLMs to create realistic personalized conversational data more efficiently and effectively than previous methods.},
booktitle = {Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {796–806},
numpages = {11},
keywords = {conversational search, dialogue collection, personalization},
location = {Washington DC, USA},
series = {SIGIR '24}
}

@inproceedings{10.1145/3654522.3654568,
author = {Nguyen, Anh Quynh and Tran, My Tu and Nguyen, Quang Nhat and Huynh, Huy Khai and Le, Lan Thi Thu and Quach, Luyl-Da},
title = {Classification of Rice Plant Disease Based on Descriptive Information with DistilBERT's Architecture},
year = {2024},
isbn = {9798400716713},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3654522.3654568},
doi = {10.1145/3654522.3654568},
abstract = {Rice has a significant role in human life, and currently, the issue of rice plant diseases is receiving attention in image-related data processing. However, the possibility of applying text classification to address this issue has yet to be explored. Nonetheless, it deserves attention due to the complexity of image-related data. The study gathered descriptive passages on four prevalent rice diseases in Vietnam, with 365 descriptions. The collected data underwent data preprocessing through stopword removal, then visualization to identify crucial words and phrases for disease identification in rice plants. The study used feature extraction and fine-tuning based on DistilBERT's architecture to build models. The research findings showed an impressive peak accuracy rate of 87%, highlighting the potential of using text classification algorithms to classify diseases in crops using descriptions.},
booktitle = {Proceedings of the 2024 9th International Conference on Intelligent Information Technology},
pages = {155–163},
numpages = {9},
keywords = {DistilBERT, Large Language model,, Rice Disease, Text Classification},
location = {Ho Chi Minh City, Vietnam},
series = {ICIIT '24}
}

@inproceedings{10.1145/3626772.3661349,
author = {Kejriwal, Mayank and Haidarian, Hamid and Chiu, Min-Hsueh and Xiang, Andy and Shrestha, Deep and Javed, Faizan},
title = {A Semantic Search Engine for Helping Patients Find Doctors and Locations in a Large Healthcare Organization},
year = {2024},
isbn = {9798400704314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626772.3661349},
doi = {10.1145/3626772.3661349},
abstract = {Efficiently finding doctors and locations (FDL) is an important search problem for patients in the healthcare domain, for which traditional information retrieval (IR) methods tend to be sub-optimal. This paper introduces and defines FDL as an important healthcare industry-specific problem in IR. We then propose a semantic search engine as a robust solution to FDL in Kaiser Permanente (KP), a large healthcare organization with 12 million members. Our solution meets practical needs of data security and privacy, scalability, cost-effectiveness, backward compatibility with existing indexes and search infrastructure, and interpretability of outputs for patients. It uses a concept-rich ontology to model raw data from multiple sources as entities, relations, and attributes in a knowledge graph that is stored and indexed in an industry-scale graph database. We evaluate the solution on a real patient-query log and demonstrate its practical utility. The system has been implemented and deployed live to KP customers.},
booktitle = {Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {2945–2949},
numpages = {5},
keywords = {finding doctors and locations, healthcare, knowledge graphs, neo4j},
location = {Washington DC, USA},
series = {SIGIR '24}
}

@inproceedings{10.1145/3677779.3677821,
author = {Zhang, Shuai and Guan, Yanzhi and Gu, Zhongyu},
title = {Research on named entity recognition in the field of CNC machine tool design based on deep learningKnowledge map of mechanical field},
year = {2024},
isbn = {9798400709760},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3677779.3677821},
doi = {10.1145/3677779.3677821},
abstract = {Our goal is to extract entities from the text data of unstructured CNC machine tool design for the construction of knowledge graph. The key entity extraction problem in the construction of CNC machine tool design knowledge graph is studied. In order to realize the recognition of named entities, we have formulated the standard and labeling method of knowledge classification for the field of CNC machine tools, and constructed the corresponding domain data set. In addition, we also propose an entity recognition technology based on RoBertTa-BiLSTM-LCRF for CNC machine tool design text. Firstly, we fine-tune the RoBertTa-BiLSTM-LCRF model using data sets in the field of CNC machine tools, and then use RoBERTa to encode the text to generate a vector representation ; next, we use bidirectional long short-term memory ( BiLSTM ) to extract the features of vectors. Finally, we introduce LCRF as the overall optimization layer of the label, so as to derive the best answer and label the entity.The experimental results show that the F1 value of the model in the data set reaches 71.16 % ; for most of the key entities, the value of F1 exceeds 65 % ; this method shows significant advantages in the entity recognition of CNC machine tool design knowledge. It can accurately identify the core entities in the machine tool design knowledge document, and provides a solid data support for the construction of CNC machine tool design knowledge graph.},
booktitle = {Proceedings of the International Conference on Modeling, Natural Language Processing and Machine Learning},
pages = {257–262},
numpages = {6},
location = {Xi'an, China},
series = {CMNM '24}
}

@inproceedings{10.1145/3589335.3641292,
author = {Graux, Damien and Montella, S\'{e}bastien and Jabeen, Hajira and Gardent, Claire and Pan, Jeff Z.},
title = {[PromptEng] First International Workshop on Prompt Engineering for Pre-Trained Language Models},
year = {2024},
isbn = {9798400701726},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589335.3641292},
doi = {10.1145/3589335.3641292},
abstract = {The recent achievements and availability of Large Language Models have paved the road to a new range of applications and use-cases. Pre-trained language models are now being involved at-scale in many fields where they were until now absent from. More specifically, the progress made by causal generative models has open the door to using them through textual instructions aka. prompts. Unfortunately, the performances of these prompts are highly dependent on the exact phrasing used and therefore practitioners need to adopt fail-retry strategies. This first international workshop on prompt engineering aims at gathering practitioners (both from Academia and Industry) to exchange about good practices, optimizations, results and novel paradigms about the design of efficient prompts to make use of LLMs.},
booktitle = {Companion Proceedings of the ACM Web Conference 2024},
pages = {1311–1312},
numpages = {2},
keywords = {best practices, collective task, llm, prompt engineering},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3652628.3652747,
author = {Wang, Nan and Yilahun, Hankiz and Hamdulla, Askar},
title = {Research on the Construction and Knowledge Representation Learning Based on Multi-modal Knowledge Graphs},
year = {2024},
isbn = {9798400708831},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652628.3652747},
doi = {10.1145/3652628.3652747},
abstract = {Knowledge is the crystallization of human wisdom. As a form of structured human knowledge, knowledge graphs have received widespread attention from the academic and industrial communities since their inception, and have been widely applied in fields such as information retrieval, intelligent question answering, and recommendation systems. Traditionally, these graphs focused solely on textual data, overlooking inter-modality influences. However, with the internet's information explosion, the demand for multi-modal knowledge graphs has surged. Knowledge representation learning is an important application for knowledge graphs completing, and traditional knowledge graph representation learning has often only considered single modality information, which has certain limitations. To address this, our study leverages the FreeBase15K dataset to create a sample multi-modal knowledge graph incorporating text, images, and speech. We also develop an information retrieval system tailored to this knowledge graph and conduct knowledge representation learning across these multi-modal data. Our experiments demonstrate the positive impact of integrating multi-modal data into knowledge representation models. Moreover, compared to the original model, our proposed method, with the same parameters, achieved a 24% improvement on the Hit@10 (raw) metric. To our knowledge, this is the first study to construct a multi-modal knowledge graph and apply it to knowledge representation learning tasks using text, images, and speech as a combined approach.},
booktitle = {Proceedings of the 4th International Conference on Artificial Intelligence and Computer Engineering},
pages = {715–720},
numpages = {6},
location = {Dalian, China},
series = {ICAICE '23}
}

@inproceedings{10.1145/3638884.3638961,
author = {Liu, Wenjing and Zhang, Suxiang and Sun, Yang and Sheng, Xing and Wu, Zhidong},
title = {New Energy Power Domain Question-Method Extraction And Soft Clustering},
year = {2024},
isbn = {9798400708909},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3638884.3638961},
doi = {10.1145/3638884.3638961},
abstract = {In recent years, as the field of new energy power has gradually become a research hotspot, there are more and more research results related to new energy power. This paper first proposes to Fine-tune the Chinese LLaMA large language model to realize the extraction of research questions and methods in new energy power results. The fine-tuning dataset is constructed by the combination of rule template and gpt-3.5 enhancement, which avoids the costly and time-consuming problem caused by manual construction. The fine-tuning method adopts LoRA high-efficiency fine-tuning to save computing resources; Then, F1 value is used as the evaluation index to compare the extraction effect of the model under different fine-tuning datasets. The results show that the model has a good extraction effect on the research questions and method terms when training the dataset constructed by the combination of rule template and gpt-3.5 enhancement. Finally, according to the extracted research question phrases, BTM(Biterm Topic Model) is used to study the distribution of topic words, and soft clustering of research question phrases is carried out according to the obtained topic words, so as to realize the correlation between the research results and professional terms, which provides the foundation for the future establishment of the knowledge graph and knowledge base of new energy power.CCS CONCEPTS • Theory of computation • Theory and algorithms for application domains • Unsupervised learning and clustering},
booktitle = {Proceedings of the 2023 9th International Conference on Communication and Information Processing},
pages = {484–491},
numpages = {8},
keywords = {Biterm Topic Model, Chinese LLaMA Fine-Tuning, Soft clustering, Terminology extraction},
location = {Lingshui, China},
series = {ICCIP '23}
}

@inproceedings{10.1145/3589334.3645376,
author = {Yuan, Chenhan and Xie, Qianqian and Huang, Jimin and Ananiadou, Sophia},
title = {Back to the Future: Towards Explainable Temporal Reasoning with Large Language Models},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3645376},
doi = {10.1145/3589334.3645376},
abstract = {Temporal reasoning is a crucial natural language processing (NLP) task, providing a nuanced understanding of time-sensitive contexts within textual data. Although recent advancements in Large Language Models (LLMs) have demonstrated their potential in temporal reasoning, the predominant focus has been on tasks such as temporal expression detection, normalization, and temporal relation extraction. These tasks are primarily designed for the extraction of direct and past temporal cues from given contexts and to engage in simple reasoning processes. A significant gap remains when considering complex reasoning tasks such as event forecasting, which requires multi-step temporal reasoning on events and prediction on the future timestamp. Another notable limitation of existing methods is their incapability to illustrate their reasoning process for explaining their prediction, hindering explainability. In this paper, we introduce the first task of explainable temporal reasoning, to predict an event's occurrence at a future timestamp based on context which requires multiple reasoning over multiple events, and subsequently provide a clear explanation for their prediction. Our task offers a comprehensive evaluation of both the LLMs' complex temporal reasoning ability, the future event prediction ability, and explainability-a critical attribute for AI applications. To support this task, we present the first instruction-tuning dataset of explainable temporal reasoning (ExpTime) with 26k derived from the temporal knowledge graph datasets, using a novel knowledge-graph-instructed-generation strategy. Based on the dataset, we propose the first open-source LLM series TimeLlaMA based on the foundation LLM LlaMA2, with the ability of instruction following for explainable temporal reasoning. We compare the performance of our method and a variety of LLMs, where our method achieves the state-of-the-art performance of temporal prediction and explanation generation. We also explore the impact of instruction tuning and different training sizes of instruction-tuning data, highlighting LLM's capabilities and limitations in complex temporal prediction and explanation generation.},
booktitle = {Proceedings of the ACM Web Conference 2024},
pages = {1963–1974},
numpages = {12},
keywords = {event forecasting, explainable AI, large language models, temporal reasoning},
location = {Singapore, Singapore},
series = {WWW '24}
}

@article{10.14778/3648160.3648174,
author = {Zhu, Junhao and Mao, Yuren and Chen, Lu and Ge, Congcong and Wei, Ziheng and Gao, Yunjun},
title = {FusionQuery: On-demand Fusion Queries over Multi-source Heterogeneous Data},
year = {2024},
issue_date = {February 2024},
publisher = {VLDB Endowment},
volume = {17},
number = {6},
issn = {2150-8097},
url = {https://doi.org/10.14778/3648160.3648174},
doi = {10.14778/3648160.3648174},
abstract = {Centralised data management systems (e.g., data lakes) support queries over multi-source heterogeneous data. However, the query results from multiple sources commonly involve between-source conflicts, which makes query results unreliable and confusing and degrades the usability of centralised data management systems. Therefore, resolving the between-sourced conflicts is one of the most important problems for centralised data management systems. To solve it, many batch data fusion-based methods have been proposed, which require traversing all the data in the centralised data management systems and cause scalability and flexibility issues.To address these issues, this paper explores the problem of on-demand fusion queries, where the between-sourced conflicts are solved with only the query-related data; moreover, we propose an efficient on-demand fusion query framework, FusionQuery, which consists of a query stage and a fusion stage. In the query stage, we frame the heterogeneous data query problem as a knowledge graph matching problem and present a line graph-based method to accelerate it. In the fusion stage, we develop an Expectation Maximization-style algorithm to iteratively updates data veracity and source trustworthiness. Furthermore, we design an incremental estimation method of source trustworthiness to address the lack of sufficient observations. Extensive experiments on two real-world datasets demonstrate that FusionQuery outperforms state-of-the-art data fusion methods in terms of both effectiveness and efficiency.},
journal = {Proc. VLDB Endow.},
month = feb,
pages = {1337–1349},
numpages = {13}
}

@inproceedings{10.5555/3643142.3643333,
author = {Tu, Ming-Yu and Ehm, Hans and Ismail, Abdelgafar and Ulrich, Philipp},
title = {Reusable Ontology Generation and Matching from Simulation Models},
year = {2024},
isbn = {9798350369663},
publisher = {IEEE Press},
abstract = {As simulating semiconductor manufacturing grows complex, model reuse becomes appealing since it can reduce the time incurred in developing future models. Also, considering a large network of the semiconductor supply chain, knowledge sharing can enable the efficient development of simulation models in a collaborative organization. Such necessity of reusability and interoperability of simulation models motivates this paper. We will address these challenges through ontological modeling and linking of the simulation components. The first application is generating reusable ontologies from simulation models. Another discussed application is ontology matching for knowledge sharing between simulation components and a meta-model of the semiconductor supply chain. The proposed approach succeeds in automatically transforming simulation into reusable knowledge and identifying interconnection in a semiconductor manufacturing system.},
booktitle = {Proceedings of the Winter Simulation Conference},
pages = {2298–2309},
numpages = {12},
location = {San Antonio, Texas, USA},
series = {WSC '23}
}

@inproceedings{10.1145/3660395.3660474,
author = {Liang, Xiangdong and Ham, Hyun-Jin},
title = {Target sequences model based on the results of the corelation of demographic variables with other variables: application of the sequential patternmining algorithm},
year = {2024},
isbn = {9798400716362},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3660395.3660474},
doi = {10.1145/3660395.3660474},
abstract = {Sequential pattern mining (SPM) is an important technique of pattern mining, which has many applications in reality. Although many efficient sequential pattern mining algorithms have been proposed, there are few studies can focus on target sequences.. This study describes an AI task-specific model application solution method with the results of the influence of demographic variables on other variables for a certain group to construct an intelligent system with improved functions. After investigating the results of the influence of demographic variables on Chinese language learning anxiety and learning engagement, the results are improved from four aspects, namely, sequence pattern mining, knowledge graph, virtual digital human and intelligent emotion monitoring system.},
booktitle = {Proceedings of the 2023 3rd Guangdong-Hong Kong-Macao Greater Bay Area Artificial Intelligence and Big Data Forum},
pages = {456–460},
numpages = {5},
location = {Guangzhou, China},
series = {AIBDF '23}
}

@inproceedings{10.1145/3589335.3651914,
author = {Hanikov\'{a}, Kate\v{r}ina and Chud\'{a}n, David and Sv\'{a}tek, Vojt\v{e}ch and Vajde\v{c}ka, Peter and Troncy, Rapha\"{e}l and Vencovsk\'{y}, Filip and Syrov\'{a}tkov\'{a}, Jana},
title = {Towards Fact-check Summarization Leveraging on Argumentation Elements Tied to Entity Graphs},
year = {2024},
isbn = {9798400701726},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589335.3651914},
doi = {10.1145/3589335.3651914},
abstract = {Fact-check consumers can have different preferences regarding the amount of text being used for explaining the claim veracity verdict. Dynamically adapting the size of a fact-check report is thus an important functionality for systems designed to convey claim verification explainability. Recent works have experimented with applying transformers-based or LLM-based text summarization methods in a zero-shot or few-shot manner, making use of some existing texts available in the summary parts of fact-check reports (e.g., called "justification'' in PolitiFact). However, for complex fact-checks, the purely sub-symbolic summarizers tend to either omit some elements of the fact-checker's argumentation chains or include contextual statements that may not be essential at the given level of granularity. In this paper, we propose a new method for enhancing fact-check summarization with the aim of injecting elements of structured fact-checker argumentation. This argumentation is, in turn, not only captured at the discourse level but tied to an entity graph representing the fact-check, for which we employ the PURO diagrammatic language. We have empirically performed a manual analysis of fact-check reports from two fact-checker websites, yielding (1) textual snippets containing the argumentation essence of the fact-check report and (2) categorized argumentation elements tied to entity graphs. These snippets are then fed to a state-of-the-art hybrid summarizer which has previously produced accurate fact-check summaries, as an additional input. We observe mild improvements on various ROUGE metrics, even if the validity of the results is limited given the small size of the dataset. We also compare the human-provided argumentation element categories with those returned, for the given fact-check ground truth summary, using a pre-trained language model upon both basic and augmented prompting. This yields a moderate accuracy as the model often fails to comply with the explicit given instructions.},
booktitle = {Companion Proceedings of the ACM Web Conference 2024},
pages = {1473–1481},
numpages = {9},
keywords = {argumentation, entity graph, fact-checking, text summarization},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3677525.3678686,
author = {Bazouzi, Aymen and Le Capitaine, Ho\"{e}l and Miklos, Zoltan and Foursov, Micka\"{e}l},
title = {Precedability Prediction Between Open Educational Resources},
year = {2024},
isbn = {9798400710940},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3677525.3678686},
doi = {10.1145/3677525.3678686},
abstract = {The abundance of Educational Resources (ERs) has allowed people to have access to a vast amount of knowledge. However, it can be difficult, for both educators and learners, to navigate through these resources. One way to facilitate navigation is to identify useful relations between these resources. This can improve the teaching and learning experiences by allowing the users to go from one resource to another based on the identified relations, such as precedence. In this work, we introduce the notion of precedability between educational resources; whether a resource A can precede another resource B. Then, we propose a two-step method to identify precedability relations between educational resources. Our method structures the educational resources in an enriched Knowledge Graph (KG). Then, it uses a Graph Neural Network (GNN) model to predict precedability relations. Our method performed better than multiple baselines on different benchmarks.},
booktitle = {Proceedings of the 2024 International Conference on Information Technology for Social Good},
pages = {386–393},
numpages = {8},
keywords = {Educational Resources, Graph Machine Learning, Knowledge graphs},
location = {Bremen, Germany},
series = {GoodIT '24}
}

@article{10.1145/3660639,
author = {Sharma, Mandar and Gogineni, Ajay Kumar and Ramakrishnan, Naren},
title = {Neural Methods for Data-to-text Generation},
year = {2024},
issue_date = {October 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {5},
issn = {2157-6904},
url = {https://doi.org/10.1145/3660639},
doi = {10.1145/3660639},
abstract = {The neural boom that has sparked natural language processing (NLP) research throughout the last decade has similarly led to significant innovations in data-to-text (D2T) generation. This survey offers a consolidated view into the neural D2T paradigm with a structured examination of the approaches, benchmark datasets, and evaluation protocols. This survey draws boundaries separating D2T from the rest of the natural language generation (NLG) landscape, encompassing an up-to-date synthesis of the literature, and highlighting the stages of technological adoption from within and outside the greater NLG umbrella. With this holistic view, we highlight promising avenues for D2T research that focus not only on the design of linguistically capable systems but also on systems that exhibit fairness and accountability.},
journal = {ACM Trans. Intell. Syst. Technol.},
month = oct,
articleno = {89},
numpages = {46},
keywords = {Narration, data-to-text, data-to-text generation, natural language generation}
}

@inproceedings{10.1109/ASE56229.2023.00122,
author = {Shao, Shuai and Yu, Tingting},
title = {Information Retrieval-Based Fault Localization for Concurrent Programs},
year = {2024},
isbn = {9798350329964},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASE56229.2023.00122},
doi = {10.1109/ASE56229.2023.00122},
abstract = {Information retrieval-based fault localization (IRFL) techniques have been proposed as a solution to identify the files that are likely to contain faults that are root causes of failures reported by users. These techniques have been extensively studied to accurately rank source files, however, none of the existing approaches have focused on the specific case of concurrent programs. This is a critical issue since concurrency bugs are notoriously difficult to identify. To address this problem, this paper presents a novel approach called BLCoiR, which aims to reformulate bug report queries to more accurately localize source files related to concurrency bugs. The key idea of BLCoiR is based on a novel knowledge graph (KG), which represents the domain entities extracted from the concurrency bug reports and their semantic relations. The KG is then transformed into the IR query to perform fault localization. BLCoiR leverages natural language processing (NLP) and concept modeling techniques to construct the knowledge graph. Specifically, NLP techniques are used to extract relevant entities from the bug reports, such as the word entities related to concurrency constructs. These entities are then linked together based on their semantic relationships, forming the KG. We have conducted an empirical study on 692 concurrency bug reports from 44 real-world applications. The results show that BLCoiR outperforms existing IRFL techniques in terms of accuracy and efficiency in localizing concurrency bugs. BLCoiR demonstrates effectiveness of using a knowledge graph to model the domain entities and their relationships, providing a promising direction for future research in this area.},
booktitle = {Proceedings of the 38th IEEE/ACM International Conference on Automated Software Engineering},
pages = {1467–1479},
numpages = {13},
keywords = {concurrent program, fault localization, information retrieval},
location = {Echternach, Luxembourg},
series = {ASE '23}
}

@inproceedings{10.1145/3589335.3651970,
author = {Joshi, Saurav and Ilievski, Filip and Luceri, Luca},
title = {Contextualizing Internet Memes Across Social Media Platforms},
year = {2024},
isbn = {9798400701726},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589335.3651970},
doi = {10.1145/3589335.3651970},
abstract = {Internet memes have emerged as a novel format for communication and expressing ideas on the web. Their fluidity and creative nature are reflected in their widespread use, often across platforms and occasionally for unethical or harmful purposes. While computational work has already analyzed their high-level virality over time and developed specialized classifiers for hate speech detection, there have been no efforts to date that aim to holistically track, identify, and map internet memes posted on social media. To bridge this gap, we investigate whether internet memes across social media platforms can be contextualized by using a semantic repository of knowledge, namely, a knowledge graph. We collect thousands of potential internet meme posts from two social media platforms, namely Reddit and Discord, and develop an extract-transform-load procedure to create a data lake with candidate meme posts. By using vision transformer-based similarity, we match these candidates against the memes cataloged in IMKG --- a recently released knowledge graph of internet memes. We leverage this grounding to highlight the potential of our proposed framework to study the prevalence of memes on different platforms, map them to IMKG, and provide context about memes on social media.},
booktitle = {Companion Proceedings of the ACM Web Conference 2024},
pages = {1831–1840},
numpages = {10},
keywords = {internet memes, knowledge graphs, social media},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3643489.3661127,
author = {Rossetto, Luca and Kyriakou, Athina and Lange, Svenja and Ruosch, Florian and Wang, Ruijie and Wardatzky, Kathrin and Bernstein, Abraham},
title = {LifeGraph 4 - Lifelog Retrieval using Multimodal Knowledge Graphs and Vision-Language Models},
year = {2024},
isbn = {9798400705502},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643489.3661127},
doi = {10.1145/3643489.3661127},
abstract = {In the scope of the 7th Lifelog Search Challenge (LSC'24), we present the 4th iteration of LifeGraph, a multimodal knowledge-graph approach with data augmentations using Vision-Language Models (VLM). We extend the LifeGraph model presented in former LSC challenges by event-based clustering using temporal and spatial relations as well as information extracted from descriptions of Lifelog image captions produced by VLMs.},
booktitle = {Proceedings of the 7th Annual ACM Workshop on the Lifelog Search Challenge},
pages = {88–92},
numpages = {5},
keywords = {lifelogging, lifelog search challenge, multimodal knowledge graphs, graph-based retrieval, multi-modal retrieval, vision-language models},
location = {Phuket, Thailand},
series = {LSC '24}
}

@inproceedings{10.1145/3640457.3688146,
author = {Yang, Ting and Chen, Li},
title = {Unleashing the Retrieval Potential of Large Language Models in Conversational Recommender Systems},
year = {2024},
isbn = {9798400705052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3640457.3688146},
doi = {10.1145/3640457.3688146},
abstract = {Conversational recommender systems (CRSs) aim to capture user preferences and provide personalized recommendations through interactive natural language interaction. The recent advent of large language models (LLMs) has revolutionized human engagement in natural conversation, driven by their extensive world knowledge and remarkable natural language understanding and generation capabilities. However, introducing LLMs into CRSs presents new technical challenges. Directly prompting LLMs for recommendation generation requires understanding a large and evolving item corpus, as well as grounding the generated recommendations in the real item space. On the other hand, generating recommendations based on external recommendation engines or directly integrating their suggestions into responses may constrain the overall performance of LLMs, since these engines generally have inferior representation abilities compared to LLMs. To address these challenges, we propose an end-to-end large-scale CRS model, named as ReFICR, a novel LLM-enhanced conversational recommender that empowers a retrievable large language model to perform conversational recommendation by following retrieval and generation instructions through lightweight tuning. By decomposing the complex CRS task into multiple subtasks, we formulate these subtasks into two types of instruction formats: retrieval and generation. The hidden states of ReFICR are utilized for generating text embeddings for retrieval, and simultaneously ReFICR is fine-tuned to handle generation subtasks. We optimize the contrastive objective to enhance text embeddings for retrieval and jointly fine-tune the large language model objective for generation. Our experimental results on public datasets demonstrate that ReFICR significantly outperforms baselines in terms of recommendation accuracy and response quality. Our code is publicly available at the link: https://github.com/yt556677/ReFICR.},
booktitle = {Proceedings of the 18th ACM Conference on Recommender Systems},
pages = {43–52},
numpages = {10},
keywords = {Conversational Recommender Systems, Instruction Tuning, Retrievable Large Language Models},
location = {Bari, Italy},
series = {RecSys '24}
}

@inproceedings{10.1145/3626772.3657899,
author = {Sojitra, Daivik and Jain, Raghav and Saha, Sriparna and Jatowt, Adam and Gupta, Manish},
title = {Timeline Summarization in the Era of LLMs},
year = {2024},
isbn = {9798400704314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626772.3657899},
doi = {10.1145/3626772.3657899},
abstract = {Timeline summarization is the task of automatically generating concise overviews of documents that capture the key events and their progression on timelines. While this capability is useful for quickly comprehending event sequences without reading lengthy descriptions, timeline summarization remains a relatively underexplored area in recent years when compared to traditional document summarization task and their evolution. The advent of large language models (LLMs) has led some to presume summarization as a solved problem. However, timeline summarization poses unique challenges for LLMs. Our investigation is centered on evaluating the performance of LLMs, against state-of-the-art models in this field. We employed three different approaches: chunking, knowledge graph-based summarization, and TimeRanker. Each of these methods was systematically tested on three benchmark datasets for timeline summarization to assess their effectiveness in capturing and condensing key events and their evolution within timelines. Our findings reveal that while LLMs show promise, timeline summarization remains a complex task that is not yet fully resolved.},
booktitle = {Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {2657–2661},
numpages = {5},
keywords = {benchmarking, knowledge graphs, llms, timeline summarization},
location = {Washington DC, USA},
series = {SIGIR '24}
}

@inproceedings{10.1145/3660043.3660172,
author = {Zhu, Guibin and Zhao, Bo and Tang, Jianbo},
title = {Research on the Application of AI in Personalized Education},
year = {2024},
isbn = {9798400716157},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3660043.3660172},
doi = {10.1145/3660043.3660172},
abstract = {Smart education uses advanced information technology, combined with educational theories and teaching methods, to achieve automatic, intelligent, and efficient teaching process. Personalized education represents the core content and goal of smart education because traditional classroom or remote teaching can't accurately grasp every student's individual knowledge and understanding of the content being taught. The development of artificial intelligence technology has provided technical support for smart education, particularly for personalized education. Natural language processing models such as chatGPT and knowledge graph technology have made personalized education increasingly practicable. This article describes the technological framework of smart education, its potential applications, and emphasizes the use of AI technology in personalized education. The article covers topic areas, including learning situation analysis, implementing personalized instruction, personalized teaching management.},
booktitle = {Proceedings of the 2023 International Conference on Information Education and Artificial Intelligence},
pages = {723–727},
numpages = {5},
location = {Xiamen, China},
series = {ICIEAI '23}
}

@inproceedings{10.1145/3665939.3665969,
author = {Li, Yilin and Jobson, Deddy},
title = {LLMs as an Interactive Database Interface for Designing Large Queries},
year = {2024},
isbn = {9798400706936},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3665939.3665969},
doi = {10.1145/3665939.3665969},
abstract = {Text2SQL is typically considered a one-shot process where the user gives a natural language query and receives an SQL query in return. This approach is fraught with potential concerns, such as syntactical errors, logical mismatches, and schema hallucination, which often require time-consuming validations by end users. These challenges are exacerbated by the complexity of large queries typical in industry settings and the inherent ambiguity of natural language. To address these limitations, we propose a system that employs an iterative process for both query creation and validation, ensuring that the resulting data set meets the user's expectations. We tested this system against existing text-to-SQL LLM approaches using a standard industry use case, showcasing our system's ability to deliver coherent and accurate outcomes. Opportunities for future research to further refine this approach are also discussed1.},
booktitle = {Proceedings of the 2024 Workshop on Human-In-the-Loop Data Analytics},
pages = {1–7},
numpages = {7},
keywords = {Text2SQL, LLM, large language models, human-in-the-loop},
location = {Santiago, AA, Chile},
series = {HILDA  24}
}

@inproceedings{10.1145/3627050.3630732,
author = {Gui, Zhou and Freund, Michael and Harth, Andreas},
title = {A Natural Language Interface for IoT Systems Using the Web of Things Abstraction},
year = {2024},
isbn = {9798400708541},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627050.3630732},
doi = {10.1145/3627050.3630732},
abstract = {We present a demo of a Natural Language Interface (NLI) for controlling Internet of Things (IoT) devices using the Web of Things (WoT) specification as an intermediate abstraction layer. All interaction information of a device is stored in a Knowledge Graph using the thing description ontology. The central component of the NLI is a sequence-to-sequence neural network model for text to code translation. We build a data corpus based on the functionalities of a Philips Hue smart lamp and use the corpus to train the text to code model. Our demonstration illustrates how to control the power state, the light colour, and the brightness of a Philips Hue smart lamp using natural language commands. The implementation of an NLI system based on the WoT specification represents an approach towards the development of easy-to-use and interoperable IoT systems.},
booktitle = {Proceedings of the 13th International Conference on the Internet of Things},
pages = {186–188},
numpages = {3},
keywords = {Knowledge Graphs, Natural Language Understanding, Text to Code, Web of Things},
location = {Nagoya, Japan},
series = {IoT '23}
}

@inproceedings{10.1145/3627673.3679083,
author = {Cui, Xiquan and Dave, Vachik and Su, Yi and Al Jadda, Khalifeh and Kumar, Srijan and McAuley, Julian and Ye, Tao and Guo, Stephen and Huyen, Chip},
title = {International Workshop on Online and Adaptive Recommender Systems (OARS 2024)},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679083},
doi = {10.1145/3627673.3679083},
abstract = {Recommender system (RecSys) plays important roles in helping users navigate, discover, and consume massive and highly-dynamic information. Today, many RecSys solutions deployed in the real world rely on categorical user-profiles and/or pre-calculated recommendation actions that stay static during a user session. However, recent trends suggest that RecSys need to model user intent in real time and constantly adapt to meet user needs at the moment or change user behavior in situ. There are three primary drivers for this emerging need of online adaptation. First, in order to meet the increasing demand for a better personalized experience, the personalization dimensions and space will grow larger and larger. It would not be feasible to pre-compute recommended actions for all personalization scenarios beyond a certain scale. Second, in many settings the system does not have user prior history to leverage. Estimating user intent in real time is the only feasible way to personalize. As various consumer privacy laws tighten, it is foreseeable that many businesses will reduce their reliance on static user profiles. Therefore, it makes the modeling of user intent in real time an important research topic. Third, a user's intent often changes within a session and between sessions, and user behavior could shift significantly during dramatic events. Therefore, it is important to investigate more on online and adaptive recommender system (OARS) that can adapt in real time to meet user needs and be robust against distribution shifts. Every year, the organizers survey the most important topics for OARS and propose a new workshop program. In light of the recent advancement of LLMs and foundation models in RecSys, in this new edition, we decide to formally add the new topic of foundation and LLM models in OARS. We will invite experts and papers in the field to facilitate its further advancement. Our workshop offers a focused discussion of the new study and application of OARS, and will bring together an interdisciplinary community of researchers and practitioners from both industry and academia to discuss on new topics in the area, grow a community, and push the direction forward.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {5580–5583},
numpages = {4},
keywords = {artificial intelligence, foundation model, gen ai, llm, recommender system},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@inproceedings{10.1145/3639476.3639770,
author = {Maninger, Daniel and Narasimhan, Krishna and Mezini, Mira},
title = {Towards Trustworthy AI Software Development Assistance},
year = {2024},
isbn = {9798400705007},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639476.3639770},
doi = {10.1145/3639476.3639770},
abstract = {It is expected that in the near future, AI software development assistants will play an important role in the software industry. However, current software development assistants tend to be unreliable, often producing incorrect, unsafe, or low-quality code. We seek to resolve these issues by introducing a holistic architecture for constructing, training, and using trustworthy AI software development assistants. In the center of the architecture, there is a foundational LLM trained on datasets representative of real-world coding scenarios and complex software architectures, and fine-tuned on code quality criteria beyond correctness. The LLM will make use of graph-based code representations for advanced semantic comprehension. We envision a knowledge graph integrated into the system to provide up-to-date background knowledge and to enable the assistant to provide appropriate explanations. Finally, a modular framework for constrained decoding will ensure that certain guarantees (e.g., for correctness and security) hold for the generated code.},
booktitle = {Proceedings of the 2024 ACM/IEEE 44th International Conference on Software Engineering: New Ideas and Emerging Results},
pages = {112–116},
numpages = {5},
location = {Lisbon, Portugal},
series = {ICSE-NIER'24}
}

@inproceedings{10.1145/3627673.3679722,
author = {Shi, Yucheng and Tan, Qiaoyu and Wu, Xuansheng and Zhong, Shaochen and Zhou, Kaixiong and Liu, Ninghao},
title = {Retrieval-enhanced Knowledge Editing in Language Models for Multi-Hop Question Answering},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679722},
doi = {10.1145/3627673.3679722},
abstract = {Large Language Models (LLMs) have shown proficiency in question-answering tasks but often struggle to integrate real-time knowledge, leading to potentially outdated or inaccurate responses. This problem becomes even more challenging when dealing with multi-hop questions, since they require LLMs to update and integrate multiple knowledge pieces relevant to the questions. To tackle the problem, we propose the Retrieval-Augmented model Editing (RAE) framework for multi-hop question answering. RAE first retrieves edited facts and then refines the language model through in-context learning. Specifically, our retrieval approach, based on mutual information maximization, leverages the reasoning abilities of LLMs to identify chain facts that traditional similarity-based searches might miss. In addition, our framework includes a pruning strategy to eliminate redundant information from the retrieved facts, which enhances the editing accuracy and mitigates the hallucination problem. Our framework is supported by theoretical justification for its fact retrieval efficacy. Finally, comprehensive evaluation across various LLMs validates RAE's ability in providing accurate answers with updated knowledge. Our code is available at: https://github.com/sycny/RAE.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {2056–2066},
numpages = {11},
keywords = {model editing, question answering, retrieval-augmented generation},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@inproceedings{10.1145/3685650.3685667,
author = {Wanna, Selma and Solovyev, Nicholas and Barron, Ryan and Eren, Maksim E. and Bhattarai, Manish and Rasmussen, Kim \O{}. and Alexandrov, Boian S.},
title = {TopicTag: Automatic Annotation of NMF Topic Models Using Chain of Thought and Prompt Tuning with LLMs},
year = {2024},
isbn = {9798400711695},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3685650.3685667},
doi = {10.1145/3685650.3685667},
abstract = {Topic modeling is a technique for organizing and extracting themes from large collections of unstructured text. Non-negative matrix factorization (NMF) is a common unsupervised approach that decomposes a term frequency-inverse document frequency (TF-IDF) matrix to uncover latent topics and segment the dataset accordingly. While useful for highlighting patterns and clustering documents, NMF does not provide explicit topic labels, necessitating subject matter experts (SMEs) to assign labels manually. We present a methodology for automating topic labeling in documents clustered via NMF with automatic model determination (NMFk). By leveraging the output of NMFk and employing prompt engineering, we utilize large language models (LLMs) to generate accurate topic labels. Our case study on over 34,000 scientific abstracts on Knowledge Graphs demonstrates the effectiveness of our method in enhancing knowledge management and document organization.},
booktitle = {Proceedings of the ACM Symposium on Document Engineering 2024},
articleno = {8},
numpages = {4},
keywords = {chain of thought, llm, nmf, prompt tuning, topic labeling},
location = {San Jose, CA, USA},
series = {DocEng '24}
}

@inproceedings{10.1145/3664647.3680995,
author = {He, Liang and Wang, Hongke and Wu, Zhen and Zhang, Jianbing and Dai, Xinyu and Chen, Jiajun},
title = {Focus &amp; Gating: A Multimodal Approach for Unveiling Relations in Noisy Social Media},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3680995},
doi = {10.1145/3664647.3680995},
abstract = {Multimedia content's surge on the internet has made multimodal relation extraction vital for applications like intelligent search and knowledge graph construction. As a rich source of image-text data, social media plays a crucial role in populating knowledge bases. However, the noisy information present in social media poses a challenge in multimodal relation extraction. Current methods focus on extracting relevant information from images to improve model performance but often overlook the importance of global image information. In this paper, we propose a novel multimodal relation extraction method FocalMRE, which leverages image focal augmentation, focal attention, and gating mechanisms. FocalMRE enables the model to concentrate on the image's focal regions while effectively utilizing the global information in the image. Through gating mechanisms, FocalMRE optimizes the multimodal fusion strategy, allowing the model to select the most relevant augmented regions for overcoming noise interference in relation extraction. The experimental results on the public MNRE dataset reveal that FocalMRE exhibits robust and significant performance advantages in the multimodal relation extraction task, especially in scenarios with high noise, long-tail distributions, and limited resources. The code is available at https://github.com/NJUNLP/FocalMRE.},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {1379–1388},
numpages = {10},
keywords = {focal attention, focal augmentation, gating mechanism, multimodal relation extraction, noisy social media},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@inproceedings{10.1145/3589335.3651234,
author = {Jiang, Xinxi and Li, Xiang and Zhou, Qifeng and Wang, Qing},
title = {GRACE: Generating Cause and Effect of Disaster Sub-Events from Social Media Text},
year = {2024},
isbn = {9798400701726},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589335.3651234},
doi = {10.1145/3589335.3651234},
abstract = {In recent years, social media has emerged as a pivotal source of emergency response for natural disasters. Causal analysis of disaster sub-events is one of crucial concerns. However, the design and implementation of its application scenario present significant challenges, due to the intricate nature of events and information overload. In this work, we introduce GRACE, a system designed for generating the cause and effect of disaster sub-events from social media text. GRACE aims to provide a rapid, comprehensive, and real-time analysis of disaster intelligence. Different from conventional information digestion systems, GRACE employs event evolution reasoning by constructing a causal knowledge graph for disaster sub-events (referred to as DSECG) and fine-tuning GPT-2 on DSECG. This system offers users a comprehensive understanding of disaster events and supports human organizations in enhancing response efforts during disaster situations. Moreover, an online demo is accessible, allowing user interaction with GRACE and providing a visual representation of the cause and effect of disaster sub-events.},
booktitle = {Companion Proceedings of the ACM Web Conference 2024},
pages = {999–1002},
numpages = {4},
keywords = {cause and effect, disaster information system, social media text},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3627673.3679837,
author = {Huang, Shulin and Ma, Shirong and Li, Yangning and Li, Yinghui and Zheng, Hai-Tao},
title = {From Retrieval to Generation: Efficient and Effective Entity Set Expansion},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679837},
doi = {10.1145/3627673.3679837},
abstract = {Entity Set Expansion (ESE) is a critical task aiming at expanding entities of the target semantic class described by seed entities. Most existing ESE methods are retrieval-based frameworks that need to extract contextual features of entities and calculate the similarity between seed entities and candidate entities. To achieve the two purposes, they iteratively traverse the corpus and the entity vocabulary, resulting in poor efficiency and scalability. Experimental results indicate that the time consumed by the retrieval-based ESE methods increases linearly with entity vocabulary and corpus size. In this paper, we firstly propose Generative Entity Set Expansion (GenExpan) framework, which utilizes a generative pre-trained auto-regressive language model to accomplish ESE task. Specifically, a prefix tree is employed to guarantee the validity of entity generation, and automatically generated class names are adopted to guide the model to generate target entities. Moreover, we propose Knowledge Calibration and Generative Ranking to further bridge the gap between generic knowledge of the language model and the goal of ESE task. For efficiency, expansion time consumed by GenExpan is independent of entity vocabulary and corpus size, and GenExpan achieves an average 600% speedup compared to strong baselines. For expansion effectiveness, our framework outperforms previous state-of-the-art ESE methods.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {921–931},
numpages = {11},
keywords = {entity set expansion, generative framework, knowledge discovery},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@article{10.1145/3709155,
author = {Villena, Fabi\'{a}n and Quiroga, Tamara and Dunstan, Jocelyn},
title = {Clinical analogy resolution performance for foundation language models},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3709155},
doi = {10.1145/3709155},
abstract = {Using extensive data sources to create foundation language models has revolutionized the performance of deep learning-based architectures. This remarkable improvement has led to state-of-the-art results for various downstream NLP tasks, including clinical tasks. However, more research is needed to measure model performance intrinsically, especially in the clinical domain. We revisit the use of analogy questions as an effective method to measure the intrinsic performance of language models for the clinical domain in English. We tested multiple Transformers-based language models over analogy questions constructed from the Unified Medical Language System (UMLS), a massive knowledge graph of clinical concepts. Our results show that large language models are significantly more performant for analogy resolution than small language models. Similarly, domain-specific language models perform better than general domain language models. We also found a correlation between intrinsic and extrinsic performance, validated through PubMedQA extrinsic task. Creating clinical-specific and language-specific language models is essential for advancing biomedical and clinical NLP and will ensure a valid application in clinical practice. Finally, given that our proposed intrinsic test is based on a term graph available in multiple languages, the dataset can be built to measure the performance of models in languages other than English.},
note = {Just Accepted},
journal = {ACM Trans. Comput. Healthcare},
month = dec,
keywords = {Foundation Models, Clinical NLP, Intrinsic Tests}
}

@inproceedings{10.1145/3673791.3698435,
author = {Wang, Zihan and Ge, Xuri and Jose, Joemon M. and Yu, Haitao and Ma, Weizhi and Ren, Zhaochun and Xin, Xin},
title = {R3AG: First Workshop on Refined and Reliable Retrieval Augmented Generation},
year = {2024},
isbn = {9798400707247},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3673791.3698435},
doi = {10.1145/3673791.3698435},
abstract = {Retrieval-augmented generation (RAG) has gained wide attention as the key component to improve generative models with external knowledge augmentation from information retrieval. It has shown great prominence in enhancing the functionality and performance of large language model (LLM)-based applications. However, with the comprehensive application of RAG, more and more problems and limitations have been identified, thus urgently requiring further fundamental exploration to improve current RAG frameworks. This workshop aims to explore in depth how to conduct refined and reliable RAG for downstream AI tasks.To this end, we propose to organize the first R3AG workshop at SIGIR-AP 2024 to call for participants to re-examine and formulate the basic principles and practical implementation of refined and reliable RAG. The workshop serves as a platform for both academia and industry researchers to conduct discussions, share insights, and foster research to build the next generation of RAG systems. Participants will engage in discussions and presentations focusing on fundamental challenges, cutting-edge research, and potential pathways to improve RAG. At the end of the workshop, we aim to have a clearer understanding of how to improve the reliability and applicability of RAG with more robust information retrieval and language generation.},
booktitle = {Proceedings of the 2024 Annual International ACM SIGIR Conference on Research and Development in Information Retrieval in the Asia Pacific Region},
pages = {307–310},
numpages = {4},
keywords = {information retrieval, large lan- guage models, reliability, retrieval-augmented generation},
location = {Tokyo, Japan},
series = {SIGIR-AP 2024}
}

@inproceedings{10.1145/3627673.3679659,
author = {Huang, Yubo and Zeng, Guosun},
title = {RD-P: A Trustworthy Retrieval-Augmented Prompter with Knowledge Graphs for LLMs},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679659},
doi = {10.1145/3627673.3679659},
abstract = {Large Language Models (LLMs) face challenges due to hallucination issues. Current solutions use retrieval-augmented generation (RAG), integrating LLMs with external knowledge to enhance answer accuracy. However, the misuse of irrelevant external knowledge can be misleading. In this paper, we propose a novel method called Retrieve-and-Discriminate Prompter (RD-P), which leverages knowledge graphs (KGs) for trustworthy RAG by synchronizing knowledge retrieval and discrimination in a unified model. Specifically, we train a prompter based on a pre-trained language model with shared parameters. It has two key modules: the retriever and the discriminator. The retriever identifies relevant reasoning paths in the KG, while the discriminator evaluates their credibility through "logical coverage calculation" and in turn instructs the retrieval process. Prompts are then constructed to guide LLMs in reasoning and answering questions using both retrieved and implicit knowledge. Experiments on knowledge-intensive question answering (QA) tasks demonstrate that our method significantly improves answer coverage rate while reducing the retrieval scale, achieving superior performance in complex KGQA tasks compared with state-of-the-art RAG methods at a low cost.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {942–952},
numpages = {11},
keywords = {kgqa, large language models, prompter, retrieval-augmented generation},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@article{10.14778/3681954.3681987,
author = {Yan, Mengyi and Fan, Wenfei and Wang, Yaoshu and Xie, Min},
title = {Enriching Relations with Additional Attributes for ER},
year = {2024},
issue_date = {July 2024},
publisher = {VLDB Endowment},
volume = {17},
number = {11},
issn = {2150-8097},
url = {https://doi.org/10.14778/3681954.3681987},
doi = {10.14778/3681954.3681987},
abstract = {This paper studies a new problem of relation enrichment. Given a relation D of schema R and a knowledge graph G with overlapping information, it is to identify a small number of relevant features from G, and extend schema R with the additional attributes, to maximally improve the accuracy of resolving entities represented by the tuples of D. We formulate the enrichment problem and show its intractability. Nonetheless, we propose a method to extract features from G that are diverse from the existing attributes of R, minimize null values, and moreover, reduce false positives and false negatives of entity resolution (ER) models. The method links tuples and vertices that refer to the same entity, learns a robust policy to extract attributes via reinforcement learning, and jointly trains the policy and ER models. Moreover, we develop algorithms for (incrementally) enriching D. Using real-life data, we experimentally verify that relation enrichment improves the accuracy of ER above 15.4% (percentage points) by adding 5 attributes, up to 33%.},
journal = {Proc. VLDB Endow.},
month = jul,
pages = {3109–3123},
numpages = {15}
}

@inproceedings{10.1145/3589334.3645610,
author = {Bl\"{u}baum, Lukas and Heindorf, Stefan},
title = {Causal Question Answering with Reinforcement Learning},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3645610},
doi = {10.1145/3589334.3645610},
abstract = {Causal questions inquire about causal relationships between different events or phenomena. They are important for a variety of use cases, including virtual assistants and search engines. However, many current approaches to causal question answering cannot provide explanations or evidence for their answers. Hence, in this paper, we aim to answer causal questions with a causality graph, a large-scale dataset of causal relations between noun phrases along with the relations' provenance data. Inspired by recent, successful applications of reinforcement learning to knowledge graph tasks, such as link prediction and fact-checking, we explore the application of reinforcement learning on a causality graph for causal question answering. We introduce an Actor-Critic-based agent which learns to search through the graph to answer causal questions. We bootstrap the agent with a supervised learning procedure to deal with large action spaces and sparse rewards. Our evaluation shows that the agent successfully prunes the search space to answer binary causal questions by visiting less than 30 nodes per question compared to over 3,000 nodes by a naive breadth-first search. Our ablation study indicates that our supervised learning strategy provides a strong foundation upon which our reinforcement learning agent improves. The paths returned by our agent explain the mechanisms by which a cause produces an effect. Moreover, for each edge on a path, our causality graph provides its original source allowing for easy verification of paths.},
booktitle = {Proceedings of the ACM Web Conference 2024},
pages = {2204–2215},
numpages = {12},
keywords = {causality graphs, question answering, reinforcement learning},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3605098.3635949,
author = {Layegh, Amirhossein and Payberah, Amir H. and Soylu, Ahmet and Roman, Dumitru and Matskin, Mihhail},
title = {Wiki-based Prompts for Enhancing Relation Extraction using Language Models},
year = {2024},
isbn = {9798400702433},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3605098.3635949},
doi = {10.1145/3605098.3635949},
abstract = {Prompt-tuning and instruction-tuning of language models have exhibited significant results in few-shot Natural Language Processing (NLP) tasks, such as Relation Extraction (RE), which involves identifying relationships between entities within a sentence. However, the effectiveness of these methods relies heavily on the design of the prompts. A compelling question is whether incorporating external knowledge can enhance the language model's understanding of NLP tasks. In this paper, we introduce wiki-based prompt construction that leverages Wikidata as a source of information to craft more informative prompts for both prompt-tuning and instruction-tuning of language models in RE. Our experiments show that using wiki-based prompts enhances cutting-edge language models in RE, emphasizing their potential for improving RE tasks. Our code and datasets are available at GitHub 1.},
booktitle = {Proceedings of the 39th ACM/SIGAPP Symposium on Applied Computing},
pages = {731–740},
numpages = {10},
keywords = {relation extraction, language models, prompt construction, knowledge integration},
location = {Avila, Spain},
series = {SAC '24}
}

@article{10.1145/3665252.3665263,
author = {Fan, Ju and Tu, Jianhong and Li, Guoliang and Wang, Peng and Du, Xiaoyong and Jia, Xiaofeng and Gao, Song and Tang, Nan},
title = {Unicorn: A Unified Multi-Tasking Matching Model},
year = {2024},
issue_date = {March 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {1},
issn = {0163-5808},
url = {https://doi.org/10.1145/3665252.3665263},
doi = {10.1145/3665252.3665263},
abstract = {Data matching, which decides whether two data elements (e.g., string, tuple, column, or knowledge graph entity) are the "same" (a.k.a. a match), is a key concept in data integration. The widely used practice is to build task-specific or even dataset-specific solutions, which are hard to generalize and disable the opportunities of knowledge sharing that can be learned from different datasets and multiple tasks. In this paper, we propose Unicorn, a unified model for generally supporting common data matching tasks. Building such a unified model is challenging due to heterogeneous formats of input data elements and various matching semantics of multiple tasks. To address the challenges, Unicorn employs one generic Encoder that converts any pair of data elements (a, b) into a learned representation, and uses a Matcher, which is a binary classifier, to decide whether a matches b. To align matching semantics of multiple tasks, Unicorn adopts a mixture-of-experts model that enhances the learned representation into a better representation. We conduct extensive experiments using 20 datasets on 7 well-studied data matching tasks, and find that our unified model can achieve better performance on most tasks and on average, compared with the state-of-the-art specific models trained for ad-hoc tasks and datasets separately. Moreover, Unicorn can also well serve new matching tasks with zero-shot learning.},
journal = {SIGMOD Rec.},
month = may,
pages = {44–53},
numpages = {10}
}

@inproceedings{10.1145/3637528.3671576,
author = {Chen, Xuanzhong and Mao, Xiaohao and Guo, Qihan and Wang, Lun and Zhang, Shuyang and Chen, Ting},
title = {RareBench: Can LLMs Serve as Rare Diseases Specialists?},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671576},
doi = {10.1145/3637528.3671576},
abstract = {Generalist Large Language Models (LLMs), such as GPT-4, have shown considerable promise in various domains, including medical diagnosis. Rare diseases, affecting approximately 300 million people worldwide, often have unsatisfactory clinical diagnosis rates primarily due to a lack of experienced physicians and the complexity of differentiating among many rare diseases. In this context, recent news such as "ChatGPT correctly diagnosed a 4-year-old's rare disease after 17 doctors failed" underscore LLMs' potential, yet underexplored, role in clinically diagnosing rare diseases. To bridge this research gap, we introduce RareBench, a pioneering benchmark designed to systematically evaluate the capabilities of LLMs on 4 critical dimensions within the realm of rare diseases. Meanwhile, we have compiled the largest open-source dataset on rare disease patients, establishing a benchmark for future studies in this domain. To facilitate differential diagnosis of rare diseases, we develop a dynamic few-shot prompt methodology, leveraging a comprehensive rare disease knowledge graph synthesized from multiple knowledge bases, significantly enhancing LLMs' diagnostic performance. Moreover, we present an exhaustive comparative study of GPT-4's diagnostic capabilities against those of specialist physicians. Our experimental findings underscore the promising potential of integrating LLMs into the clinical diagnostic process for rare diseases. This paves the way for exciting possibilities in future advancements in this field.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {4850–4861},
numpages = {12},
keywords = {benchmark for llms, evaluation, rare disease diagnosis},
location = {Barcelona, Spain},
series = {KDD '24}
}

@inproceedings{10.1145/3641032.3641044,
author = {Mengjun, Du and Jin, Qian and Ang, Li and Xue, Feng and Yi, Yang},
title = {A Dual Information Flow Model For Entity Relation Extraction},
year = {2024},
isbn = {9798400709173},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641032.3641044},
doi = {10.1145/3641032.3641044},
abstract = {To leverage the vast amount of enterprise-related data on the Internet and construct an enterprise relation graph, entity relation extraction has received extensive attention. Currently, the research focus of joint entity relation extraction (JERE) models has shifted from the issue of overlapping to the problem of dependency between subtasks. Building upon previous work, this paper further explores the dependence between entity recognition and relation extraction tasks. Firstly, through experiments, this paper discovers the mutual dependency between entity recognition and relation extraction tasks. Then, this paper designs and implements the Dual Information Branch for JERE (DIB) model for joint entity relation extraction. The DIB model employs a dual-branch fusion structure on top of the encoding layer, learning the dependency between entity recognition and relation extraction tasks in both forward and backward propagation. Additionally, to extract enterprise relations and assist in constructing an enterprise relation knowledge graph, we manually annotate the Company dataset, which consists of 1000 prospectuses and 40,000 positive samples, with low overall noise. Finally, experimental results demonstrate that the DIB model achieves superior performance on both Company and NYT dataset.},
booktitle = {Proceedings of the 2023 8th International Conference on Information Systems Engineering},
pages = {95–100},
numpages = {6},
keywords = {Keywords natural language processing, dependence between subtasks, entity relation extraction},
location = {Bangkok, Thailand},
series = {ICISE '23}
}

@inproceedings{10.1145/3644815.3644945,
author = {Barnett, Scott and Kurniawan, Stefanus and Thudumu, Srikanth and Brannelly, Zach and Abdelrazek, Mohamed},
title = {Seven Failure Points When Engineering a Retrieval Augmented Generation System},
year = {2024},
isbn = {9798400705915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3644815.3644945},
doi = {10.1145/3644815.3644945},
abstract = {Software engineers are increasingly adding semantic search capabilities to applications using a strategy known as Retrieval Augmented Generation (RAG). A RAG system involves finding documents that semantically match a query and then passing the documents to a large language model (LLM) such as ChatGPT to extract the right answer using an LLM. RAG systems aim to: a) reduce the problem of hallucinated responses from LLMs, b) link sources/references to generated responses, and c) remove the need for annotating documents with meta-data. However, RAG systems suffer from limitations inherent to information retrieval systems and from reliance on LLMs. In this paper, we present an experience report on the failure points of RAG systems from three case studies from separate domains: research, education, and biomedical. We share the lessons learned and present 7 failure points to consider when designing a RAG system. The two key takeaways arising from our work are: 1) validation of a RAG system is only feasible during operation, and 2) the robustness of a RAG system evolves rather than designed in at the start. We conclude with a list of potential research directions on RAG systems for the software engineering community.},
booktitle = {Proceedings of the IEEE/ACM 3rd International Conference on AI Engineering - Software Engineering for AI},
pages = {194–199},
numpages = {6},
keywords = {retrieval augmented generation, RAG, SE4AI, case study},
location = {Lisbon, Portugal},
series = {CAIN '24}
}

@inproceedings{10.1145/3665065.3665081,
author = {Han, Yanbo and Zhan, Buchao and Zhang, Bin and Zhao, Chao and Yan, Shankai},
title = {BiCalBERT: An Efficient Transformer-based Model for Chinese Question Answering},
year = {2024},
isbn = {9798400717291},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3665065.3665081},
doi = {10.1145/3665065.3665081},
abstract = {The exponentially growing content on the Internet includes online publications, scientific news, and other expert websites. It brings a formidable challenge to extracting pertinent answers from such vast information. We proposed a deep neural network model based on BiLSTM(Bi-directional Long Short-Term Memory) and ALBERT(A Lite BERT for Self-Supervised Learning of Language Representations)&nbsp;for Chinese question-answering in the scientific context. Our model significantly enhances the generalization capabilities of the transformer-based model for question answering. The character extraction and word embedding modules are designed&nbsp;for tackling intricate science-related queries, swiftly assimilating knowledge from cutting-edge scientific literature, and contributing to constructing&nbsp;a comprehensive scientific knowledge graph. Our model is characterized by compactness, swift execution, and satisfactory accuracy. It has been meticulously fine-tuned, emphasizing multi-sentence coherence augmented by attention mechanisms, thereby ensuring robust scalability. Empirical evaluations on the LCQMC and XNLI datasets demonstrate that our approach surpasses the performance results of BERT and ALBERT, showing&nbsp;the potential for large-scale Chinese question-matching problems.},
booktitle = {Proceedings of the 2024 8th International Conference on Intelligent Systems, Metaheuristics &amp; Swarm Intelligence},
pages = {100–104},
numpages = {5},
keywords = {NLP, Question Answering, Transformer},
location = {Singapore, Singapore},
series = {ISMSI '24}
}

@inproceedings{10.1145/3674399.3674423,
author = {Xu, Ke and Yi, Hanxiao and Xu, Zichen and Wu, Dan},
title = {Data-driven Contribution-based Disciplinary Assessment System},
year = {2024},
isbn = {9798400710117},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3674399.3674423},
doi = {10.1145/3674399.3674423},
abstract = {A scientific disciplinary assessment system is crucial for nurturing high-quality disciplines within Computer Science. Computer Science Education (CSE) emphasizes the need for a scientific and comprehensive assessment method that guides the development of the discipline, with a particular focus on practical contributions. However, traditional assessment systems tend to prioritize the theoretical outcomes. Moreover, data expansion demands significant effort and time from educational professionals, making it challenging to conduct a thorough evaluation of the disciplines. To tackle these issues, we introduce a data-driven, contribution-based disciplinary assessment system. This system takes into account both theoretical and practical contributions to provide a holistic evaluation. Our proposed system employs a contribution-based assessment approach to establish a correct evaluative direction, steering discipline construction to align with societal needs. It also incorporates intelligent algorithms and a Large Language Model (LLM), leveraging their substantial computational power in the evaluation process. This integration alleviates the workload of educational professionals by automating the collection and analysis of information. The paper outlines a detailed implementation plan that integrates contribution evaluation theory with intelligent technologies, aiming to foster the ongoing advancement of CSE education.},
booktitle = {Proceedings of the ACM Turing Award Celebration Conference - China 2024},
pages = {42–47},
numpages = {6},
keywords = {Big Data-driven, Contribution-Based Evaluation Method, Disciplinary assessment},
location = {Changsha, China},
series = {ACM-TURC '24}
}

@inproceedings{10.1145/3626772.3657989,
author = {Cai, Qingpeng and Zhao, Xiangyu and Pan, Ling and Xin, Xin and Huang, Jin and Zhang, Weinan and Zhao, Li and Yin, Dawei and Yang, Grace Hui},
title = {AgentIR: 1st Workshop on Agent-based Information Retrieval},
year = {2024},
isbn = {9798400704314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626772.3657989},
doi = {10.1145/3626772.3657989},
abstract = {Information retrieval (IR) systems have become an essential component in modern society to help users find useful information, which consists of a series of processes including query expansion, item recall, item ranking and re-ranking, etc. Based on the ranked information list, users can provide their feedbacks. Such an interaction process between users and IR systems can be naturally formulated as a decision-making problem, which can be either one-step or sequential. In the last ten years, deep reinforcement learning (DRL) has become a promising direction for decision-making, since DRL utilizes the high model capacity of deep learning for complex decision-making tasks. On the one hand, there have been emerging research works focusing on leveraging DRL for IR tasks. However, the fundamental information theory under DRL settings, the challenge of RL methods for Industrial IR tasks, or the simulations of DRL-based IR systems, has not been deeply investigated. On the other hand, the emerging LLM provides new opportunities for optimizing and simulating IR systems. To this end, we propose the first Agent-based IR workshop at SIGIR 2024, as a continuation from one of the most successful IR workshops, DRL4IR. It provides a venue for both academia researchers and industry practitioners to present the recent advances of both DRL-based IR systems and LLM-based IR systems from the agent-based IR's perspective, to foster novel research, interesting findings, and new applications.},
booktitle = {Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {3025–3028},
numpages = {4},
keywords = {agent-based information retrieval, drl, llm},
location = {Washington DC, USA},
series = {SIGIR '24}
}

@inproceedings{10.1145/3589334.3645378,
author = {Yan, Yibo and Wen, Haomin and Zhong, Siru and Chen, Wei and Chen, Haodong and Wen, Qingsong and Zimmermann, Roger and Liang, Yuxuan},
title = {UrbanCLIP: Learning Text-enhanced Urban Region Profiling with Contrastive Language-Image Pretraining from the Web},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3645378},
doi = {10.1145/3589334.3645378},
abstract = {Urban region profiling from web-sourced data is of utmost importance for urban computing. We are witnessing a blossom of LLMs for various fields, especially in multi-modal data research such as vision-language learning, where text modality serves as a supplement for images. As textual modality has rarely been introduced into modality combinations in urban region profiling, we aim to answer two fundamental questions: i) Can text modality enhance urban region profiling? ii) and if so, in what ways and which aspects? To answer the questions, we leverage the power of Large Language Models (LLMs) and introduce the first-ever LLM-enhanced framework that integrates the knowledge of text modality into urban imagery, named LLM-enhanced Urban Region Profiling with Contrastive Language-Image Pretraining (UrbanCLIP ). Specifically, it first generates a detailed textual description for each satellite image by Image-to-Text LLMs. Then, the model is trained on image-text pairs, seamlessly unifying language supervision for urban visual representation learning, jointly with contrastive loss and language modeling loss. Results on urban indicator prediction in four major metropolises show its superior performance, with an average improvement of 6.1% on R2 compared to the state-of-the-art methods. Our code and dataset are available at https://github.com/StupidBuluchacha/UrbanCLIP.},
booktitle = {Proceedings of the ACM Web Conference 2024},
pages = {4006–4017},
numpages = {12},
keywords = {language-image pretraining, spatio-temporal data, urban computing},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3641142.3641165,
author = {Ananta, Ila and Khetarpaul, Sonia and Sharma, Dolly},
title = {Symptoms-Disease Detecting Conversation Agent using Knowledge Graphs},
year = {2024},
isbn = {9798400717307},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641142.3641165},
doi = {10.1145/3641142.3641165},
abstract = {Conversational agents have become extraordinarily popular over the last few years, with accelerated adoption due to COVID-19. Even though a lot of work has been done to devise a real-time agent very few of them focus on dynamic responses. The challenges for automatic medical diagnosis not only include issues for topic transition coherency and question understanding but also issues regarding the context of medical knowledge and symptoms of disease relations. In this paper, we propose a conversational agent that not only generates answers to specific medical questions but also makes more natural and human-like conversations and can adapt to the context and evolve over time. We propose an End-to-End knowledge-routed Relational Dialogue System that would incorporate a rich medical knowledge graph into the topic transition in dialogue management, and make it accommodative with NLU (Natural Language Understanding) and NLG (Natural Language Generation). A knowledge-routed graph for topic decision-making is used, which helps to identify relationships between symptoms and symptom-disease pairs. However, there are constraints on the extent of questions that knowledge graphs can address independently. To overcome these, we have used a fine-tuned GPT-3 model. While knowledge graphs organize data as interconnected entities, GPT-3 generates human-like text using learned patterns from large datasets. This approach enhances responses to intricate queries.},
booktitle = {Proceedings of the 2024 Australasian Computer Science Week},
pages = {98–107},
numpages = {10},
location = {Sydney, NSW, Australia},
series = {ACSW '24}
}

@inproceedings{10.1145/3703187.3703290,
author = {Ma, Xiangfei and Li, Lin},
title = {Geological Disaster Named Entity Recognition with Small Samples Based on Data Augmentation and Prompt Engineering},
year = {2024},
isbn = {9798400707254},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3703187.3703290},
doi = {10.1145/3703187.3703290},
abstract = {This paper uses a large language model to perform generative data enhancement on the original small sample data by performing random synonym replacement and random mask filling operations. In accordance with the reasoning logic of the large language model, three prompt templates are designed and the reasons are explored. Experiments show that when the parameters remain unchanged, the data enhanced by this method has been greatly improved under the three prompt templates, alleviating the difficulty of low resources of geological disaster data. And by comparing the performance of different instructions under different learning rates, the fine-tuning learning rate range suitable for the field of geological disasters is summarized. The limitation is that it is constrained by local computing resources, which reduces the parameter scale of LLM, and the recognition performance is low for extremely long or complex texts.},
booktitle = {Proceedings of the 2024 7th International Conference on Computer Information Science and Artificial Intelligence},
pages = {613–617},
numpages = {5},
keywords = {Data Augmentation, Geological Disasters, LLMs, Named Entity Recognition, Prompt Engineering},
location = {
},
series = {CISAI '24}
}

@inproceedings{10.1145/3626772.3657982,
author = {B\'{e}n\'{e}dict, Gabriel and Zhang, Ruqing and Metzler, Donald and Yates, Andrew and Jiang, Ziyan},
title = {Gen-IR @ SIGIR 2024: The Second Workshop on Generative Information Retrieval},
year = {2024},
isbn = {9798400704314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626772.3657982},
doi = {10.1145/3626772.3657982},
abstract = {Generative information retrieval (Gen-IR) is a fast-growing interdisciplinary research area that investigates how to leverage advances in generative Artificial Intelligence (AI) to improve information retrieval systems. Gen-IR has attracted interest from the information retrieval, natural language processing, and machine learning communities, among others. Since the dawn of Gen-IR last year, there has been an explosion of Gen-IR systems that have launched and are now widely used. Interest in this area across academia and industry is only expected to continue to grow as new research challenges and application opportunities arise. The goal of this proposed workshop, The Second Workshop on Generative Information Retrieval (Gen-IR @ SIGIR 2024) is to provide an interactive venue for exploring a broad range of foundational and applied Gen-IR research. The workshop will focus on tasks such as generative document retrieval, grounded answer generation, generative recommendation, and generative knowledge graphs, all through the lens of model training, model behavior, and broader issues. The workshop will be highly interactive, favoring panel discussions, poster sessions, and roundtable discussions over one-sided keynotes and paper talks.},
booktitle = {Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {3029–3032},
numpages = {4},
keywords = {generative models, information retrieval, large language models},
location = {Washington DC, USA},
series = {SIGIR '24}
}

@inproceedings{10.1145/3664647.3681598,
author = {Li, Ziyan and Yu, Jianfei and Yang, Jia and Wang, Wenya and Yang, Li and Xia, Rui},
title = {Generative Multimodal Data Augmentation for Low-Resource Multimodal Named Entity Recognition},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3681598},
doi = {10.1145/3664647.3681598},
abstract = {As an important task in multimodal information extraction, Multimodal Named Entity Recognition (MNER) has recently attracted considerable attention. One key challenge of MNER lies in the lack of sufficient fine-grained annotated data, especially in low-resource scenarios. Although data augmentation is a widely used technique to tackle the above issue, it is challenging to simultaneously generate synthetic text-image pairs and their corresponding high-quality entity annotations. In this work, we propose a novel Generative Multimodal Data Augmentation (GMDA) framework for MNER, which contains two stages: Multimodal Text Generation and Multimodal Image Generation. Specifically, we first transform each annotated sentence into a linearized labeled sequence, and then train a Label-aware Multimodal Large Language Model (LMLLM) to generate the labeled sequence based on a label-aware prompt and its associated image. We further employ a Stable Diffusion model to generate the synthetic images that are semantically related to these sentences. Experimental results on three benchmark datasets demonstrate the effectiveness of the proposed GMDA framework, which consistently boosts the performance of several competitive methods for two subtasks of MNER in both full-supervision and low-resource settings. The low-resource dataset and source code are released at https://github.com/NUSTM/GMDA.},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {7336–7345},
numpages = {10},
keywords = {data augmentation, generative framework, grounded multimodal named entity recognition, multimodal named entity recognition},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@inproceedings{10.1145/3663529.3663833,
author = {Zhang, Shenglin and Zhu, Jun and Hao, Bowen and Sun, Yongqian and Nie, Xiaohui and Zhu, Jingwen and Liu, Xilin and Li, Xiaoqian and Ma, Yuchi and Pei, Dan},
title = {Fault Diagnosis for Test Alarms in Microservices through Multi-source Data},
year = {2024},
isbn = {9798400706585},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663529.3663833},
doi = {10.1145/3663529.3663833},
abstract = {Nowadays, the testing of large-scale microservices could produce an enormous number of test alarms daily. Manually diagnosing these alarms is time-consuming and laborious for the testers. Automatic fault diagnosis with fault classification and localization can help testers efficiently handle the increasing volume of failed test cases. However, the current methods for diagnosing test alarms struggle to deal with the complex and frequently updated microservices. In this paper, we introduce SynthoDiag, a novel fault diagnosis framework for test alarms in microservices through multi-source logs (execution logs, trace logs, and test case information) organized with a knowledge graph. An Entity Fault Association and Position Value (EFA-PV) algorithm is proposed to localize the fault-indicative log entries. Additionally, an efficient block-based differentiation approach is used to filter out fault-irrelevant entries in the test cases, significantly improving the overall performance of fault diagnosis. At last, SynthoDiag is systematically evaluated with a large-scale real-world dataset from a top-tier global cloud service provider, Huawei Cloud, which provides services for more than three million users. The results show the Micro-F1 and Macro-F1 scores improvement of SynthoDiag over baseline methods in fault classification are 21% and 30%, respectively, and its top-5 accuracy of fault localization is 81.9%, significantly surpassing the previous methods.},
booktitle = {Companion Proceedings of the 32nd ACM International Conference on the Foundations of Software Engineering},
pages = {115–125},
numpages = {11},
keywords = {Execution Logs, Fault Diagnosis, Microservice, Test Case, Trace Logs},
location = {Porto de Galinhas, Brazil},
series = {FSE 2024}
}

@inproceedings{10.1145/3657604.3662030,
author = {Moore, Steven and Schmucker, Robin and Mitchell, Tom and Stamper, John},
title = {Automated Generation and Tagging of Knowledge Components from Multiple-Choice Questions},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3662030},
doi = {10.1145/3657604.3662030},
abstract = {Knowledge Components (KCs) linked to assessments enhance the measurement of student learning, enrich analytics, and facilitate adaptivity. However, generating and linking KCs to assessment items requires significant effort and domain-specific knowledge. To streamline this process for higher-education courses, we employed GPT-4 to generate KCs for multiple-choice questions (MCQs) in Chemistry and E-Learning. We analyzed discrepancies between the KCs generated by the Large Language Model (LLM) and those made by humans through evaluation from three domain experts in each subject area. This evaluation aimed to determine whether, in instances of non-matching KCs, evaluators showed a preference for the LLM-generated KCs over their human-created counterparts. We also developed an ontology induction algorithm to cluster questions that assess similar KCs based on their content. Our most effective LLM strategy accurately matched KCs for 56% of Chemistry and 35% of E-Learning MCQs, with even higher success when considering the top five KC suggestions. Human evaluators favored LLM-generated KCs, choosing them over human-assigned ones approximately two-thirds of the time, a preference that was statistically significant across both domains. Our clustering algorithm successfully grouped questions by their underlying KCs without needing explicit labels or contextual information. This research advances the automation of KC generation and classification for assessment items, alleviating the need for student data or predefined KC labels.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {122–133},
numpages = {12},
keywords = {concept labeling, knowledge component, knowledge labeling, learning engineering, multiple-choice question},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@inproceedings{10.1145/3638550.3641130,
author = {Xu, Huatao and Han, Liying and Yang, Qirui and Li, Mo and Srivastava, Mani},
title = {Penetrative AI: Making LLMs Comprehend the Physical World},
year = {2024},
isbn = {9798400704970},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3638550.3641130},
doi = {10.1145/3638550.3641130},
abstract = {Recent developments in Large Language Models (LLMs) have demonstrated their remarkable capabilities across a range of tasks. Questions, however, persist about the nature of LLMs and their potential to integrate common-sense human knowledge when performing tasks involving information about the real physical world. This paper delves into these questions by exploring how LLMs can be extended to interact with and reason about the physical world through IoT sensors and actuators, a concept that we term "Penetrative AI". The paper explores such an extension at two levels of LLMs' ability to penetrate into the physical world via the processing of sensory signals. Our preliminary findings indicate that LLMs, with ChatGPT being the representative example in our exploration, have considerable and unique proficiency in employing the embedded world knowledge for interpreting IoT sensor data and reasoning over them about tasks in the physical realm. Not only this opens up new applications for LLMs beyond traditional text-based tasks, but also enables new ways of incorporating human knowledge in cyber-physical systems.},
booktitle = {Proceedings of the 25th International Workshop on Mobile Computing Systems and Applications},
pages = {1–7},
numpages = {7},
keywords = {LLM, CPS, IoT, penetrative AI},
location = {San Diego, CA, USA},
series = {HotMobile '24}
}

@article{10.14778/3681954.3681973,
author = {Sun, Yushi and Xin, Hao and Sun, Kai and Xu, Yifan Ethan and Yang, Xiao and Dong, Xin Luna and Tang, Nan and Chen, Lei},
title = {Are Large Language Models a Good Replacement of Taxonomies?},
year = {2024},
issue_date = {July 2024},
publisher = {VLDB Endowment},
volume = {17},
number = {11},
issn = {2150-8097},
url = {https://doi.org/10.14778/3681954.3681973},
doi = {10.14778/3681954.3681973},
abstract = {Large language models (LLMs) demonstrate an impressive ability to internalize knowledge and answer natural language questions. Although previous studies validate that LLMs perform well on general knowledge while presenting poor performance on long-tail nuanced knowledge, the community is still doubtful about whether the traditional knowledge graphs should be replaced by LLMs. In this paper, we ask if the schema of knowledge graph (i.e., taxonomy) is made obsolete by LLMs. Intuitively, LLMs should perform well on common taxonomies and at taxonomy levels that are common to people. Unfortunately, there lacks a comprehensive benchmark that evaluates the LLMs over a wide range of taxonomies from common to specialized domains and at levels from root to leaf so that we can draw a confident conclusion. To narrow the research gap, we constructed a novel taxonomy hierarchical structure discovery benchmark named TaxoGlimpse to evaluate the performance of LLMs over taxonomies. TaxoGlimpse covers ten representative taxonomies from common to specialized domains with in-depth experiments of different levels of entities in this taxonomy from root to leaf. Our comprehensive experiments of eighteen LLMs under three prompting settings validate that LLMs perform miserably poorly in handling specialized taxonomies and leaf-level entities. Specifically, the QA accuracy of the best LLM drops by up to 30% as we go from common to specialized domains and from root to leaf levels of taxonomies.},
journal = {Proc. VLDB Endow.},
month = jul,
pages = {2919–2932},
numpages = {14}
}

@inproceedings{10.1145/3613904.3642450,
author = {Zulfikar, Wazeer Deen and Chan, Samantha and Maes, Pattie},
title = {Memoro: Using Large Language Models to Realize a Concise Interface for Real-Time Memory Augmentation},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642450},
doi = {10.1145/3613904.3642450},
abstract = {People have to remember an ever-expanding volume of information. Wearables that use information capture and retrieval for memory augmentation can help but can be disruptive and cumbersome in real-world tasks, such as in social settings. To address this, we developed Memoro, a wearable audio-based memory assistant with a concise user interface. Memoro uses a large language model (LLM) to infer the user’s memory needs in a conversational context, semantically search memories, and present minimal suggestions. The assistant has two interaction modes: Query Mode for voicing queries and Queryless Mode for on-demand predictive assistance, without explicit query. Our study of (N=20) participants engaged in a real-time conversation, demonstrated that using Memoro reduced device interaction time and increased recall confidence while preserving conversational quality. We report quantitative results and discuss the preferences and experiences of users. This work contributes towards utilizing LLMs to design wearable memory augmentation systems that are minimally disruptive.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {450},
numpages = {18},
keywords = {context-aware agent, large language models, memory assistant, minimal interfaces, voice interfaces},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@article{10.1145/3674501,
author = {Zhao, Xiaoyan and Deng, Yang and Yang, Min and Wang, Lingzhi and Zhang, Rui and Cheng, Hong and Lam, Wai and Shen, Ying and Xu, Ruifeng},
title = {A Comprehensive Survey on Relation Extraction: Recent Advances and New Frontiers},
year = {2024},
issue_date = {November 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {56},
number = {11},
issn = {0360-0300},
url = {https://doi.org/10.1145/3674501},
doi = {10.1145/3674501},
abstract = {Relation extraction (RE) involves identifying the relations between entities from underlying content. RE serves as the foundation for many natural language processing (NLP) and information retrieval applications, such as knowledge graph completion and question answering. In recent years, deep neural networks have dominated the field of RE and made noticeable progress. Subsequently, the large pre-trained language models (PLMs) have taken the state-of-the-art RE to a new level. This survey provides a comprehensive review of existing deep learning techniques for RE. First, we introduce RE resources, including datasets and evaluation metrics. Second, we propose a new taxonomy to categorize existing works from three perspectives, i.e., text representation, context encoding, and triplet prediction. Third, we discuss several important challenges faced by RE and summarize potential techniques to tackle these challenges. Finally, we outline some promising future directions and prospects in this field. This survey is expected to facilitate researchers’ collaborative efforts to address the challenges of real-world RE systems.},
journal = {ACM Comput. Surv.},
month = jul,
articleno = {293},
numpages = {39},
keywords = {Relation extraction, deep learning, pre-trained language models, low-resource relation extraction}
}

@inproceedings{10.1145/3589335.3651980,
author = {Damianou, Andreas and Fabbri, Francesco and Gigioli, Paul and De Nadai, Marco and Wang, Alice and Palumbo, Enrico and Lalmas, Mounia},
title = {Towards Graph Foundation Models for Personalization},
year = {2024},
isbn = {9798400701726},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589335.3651980},
doi = {10.1145/3589335.3651980},
abstract = {In the realm of personalization, integrating diverse information sources such as consumption signals and content-based representations is becoming increasingly critical to build state-of-the-art solutions. In this regard, two of the biggest trends in research around this subject are Graph Neural Networks (GNNs) and Foundation Models (FM). While GNNs emerged as a popular solution in industry for powering personalization at scale, FMs have only recently caught attention for their promising performance in personalization tasks like ranking and retrieval. In this paper, we present a graph-based foundation modeling approach tailored to personalization. Central to this approach is a Heterogeneous GNN (HGNN) designed to capture multi-hop content and consumption relationships across a range of recommendable item types. To ensure the generality required from a Foundation Model, we employ a Large Language Model (LLM) text-based featurization of nodes that accommodates all item types, and construct the graph using co-interaction signals, which inherently transcend content specificity. To facilitate practical generalization, we further couple the HGNN with an adaptation mechanism based on a two-tower (2T) architecture, which also operates agnostically to content type. This multi-stage approach ensures high scalability; while the HGNN produces general purpose embeddings, the 2T component models in a continuous space the sheer size of user-item interaction data. Our comprehensive approach has been rigorously tested and proven effective in delivering recommendations across a diverse array of products within a real-world, industrial audio streaming platform.},
booktitle = {Companion Proceedings of the ACM Web Conference 2024},
pages = {1798–1802},
numpages = {5},
keywords = {foundation models, graph neural networks, personalization, recommender systems},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3640457.3688133,
author = {Zhang, Xiaoyu and Xie, Ruobing and Lyu, Yougang and Xin, Xin and Ren, Pengjie and Liang, Mingfei and Zhang, Bo and Kang, Zhanhui and de Rijke, Maarten and Ren, Zhaochun},
title = {Towards Empathetic Conversational Recommender Systems},
year = {2024},
isbn = {9798400705052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3640457.3688133},
doi = {10.1145/3640457.3688133},
abstract = {Conversational recommender systems (CRSs) are able to elicit user preferences through multi-turn dialogues. They typically incorporate external knowledge and pre-trained language models to capture the dialogue context. Most CRS approaches, trained on benchmark datasets, assume that the standard items and responses in these benchmarks are optimal. However, they overlook that users may express negative emotions with the standard items and may not feel emotionally engaged by the standard responses. This issue leads to a tendency to replicate the logic of recommenders in the dataset instead of aligning with user needs. To remedy this misalignment, we introduce empathy within a CRS. With empathy we refer to a system’s ability to capture and express emotions. We propose an empathetic conversational recommender (ECR) framework. ECR contains two main modules: emotion-aware item recommendation and emotion-aligned response generation. Specifically, we employ user emotions to refine user preference modeling for accurate recommendations. To generate human-like emotional responses, ECR applies retrieval-augmented prompts to fine-tune a pre-trained language model aligning with emotions and mitigating hallucination. To address the challenge of insufficient supervision labels, we enlarge our empathetic data using emotion labels annotated by large language models and emotional reviews collected from external resources. We propose novel evaluation metrics to capture user satisfaction in real-world CRS scenarios. Our experiments on the ReDial dataset validate the efficacy of our framework in enhancing recommendation accuracy and improving user satisfaction.},
booktitle = {Proceedings of the 18th ACM Conference on Recommender Systems},
pages = {84–93},
numpages = {10},
keywords = {Conversational recommender system, Empathetic response generation, Prompt engineering, User preference modeling},
location = {Bari, Italy},
series = {RecSys '24}
}

@inproceedings{10.1145/3663741.3664785,
author = {Barbon Junior, Sylvio and Ceravolo, Paolo and Groppe, Sven and Jarrar, Mustafa and Maghool, Samira and S\`{e}des, Florence and Sahri, Soror and Van Keulen, Maurice},
title = {Are Large Language Models the New Interface for Data Pipelines?},
year = {2024},
isbn = {9798400706790},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663741.3664785},
doi = {10.1145/3663741.3664785},
abstract = {A Language Model is a term that encompasses various types of models designed to understand and generate human communication. Large Language Models (LLMs) have gained significant attention due to their ability to process text with human-like fluency and coherence, making them valuable for a wide range of data-related tasks fashioned as pipelines. The capabilities of LLMs in natural language understanding and generation, combined with their scalability, versatility, and state-of-the-art performance, enable innovative applications across various AI-related fields, including eXplainable Artificial Intelligence (XAI), Automated Machine Learning (AutoML), and Knowledge Graphs (KG). Furthermore, we believe these models can extract valuable insights and make data-driven decisions at scale, a practice commonly referred to as Big Data Analytics (BDA). In this position paper, we provide some discussions in the direction of unlocking synergies among these technologies, which can lead to more powerful and intelligent AI solutions, driving improvements in data pipelines across a wide range of applications and domains integrating humans, computers, and knowledge.},
booktitle = {Proceedings of the International Workshop on Big Data in Emergent Distributed Environments},
articleno = {6},
numpages = {6},
keywords = {Automated Machine Learning, Big Data Analytic, Human-Computer Interaction, Knowledge Graphs, Natural Language Understanding, eXplainable Artificial Intelligence},
location = {Santiago, AA, Chile},
series = {BiDEDE '24}
}

@inproceedings{10.1145/3632410.3632494,
author = {Shiri, Aidin and Roy, Kaushik and Sheth, Amit and Gaur, Manas},
title = {L3 Ensembles: Lifelong Learning Approach for Ensemble of Foundational Language Models✱},
year = {2024},
isbn = {9798400716348},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3632410.3632494},
doi = {10.1145/3632410.3632494},
abstract = {Fine-tuning pre-trained foundational language models (FLM) for specific tasks is often impractical, especially for resource-constrained devices. This necessitates the development of a Lifelong Learning (L3) framework that continuously adapts to a stream of Natural Language Processing (NLP) tasks efficiently. We propose an approach that focuses on extracting meaningful representations from unseen data, constructing a structured knowledge base, and improving task performance incrementally. We conducted experiments on various NLP tasks to validate its effectiveness, including benchmarks like GLUE and SuperGLUE. We measured good performance across the accuracy, training efficiency, and knowledge transfer metrics. Initial experimental results show that the proposed L3 ensemble method increases the model accuracy 4% ∼ 36% compared to the fine-tuned FLM. Furthermore, L3 model outperforms naive fine-tuning approaches while maintaining competitive or superior performance (up to 15.4% increase in accuracy) compared to the state-of-the-art language model (T5) for the given task, STS benchmark.},
booktitle = {Proceedings of the 7th Joint International Conference on Data Science &amp; Management of Data (11th ACM IKDD CODS and 29th COMAD)},
pages = {592–594},
numpages = {3},
location = {Bangalore, India},
series = {CODS-COMAD '24}
}

@inproceedings{10.1145/3637528.3672500,
author = {Dong, Xin Luna},
title = {Next-generation Intelligent Assistants for Wearable Devices},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3672500},
doi = {10.1145/3637528.3672500},
abstract = {An intelligent assistant shall be an agent that knows you and the world, can receive your requests or predict your needs, and provide you the right services at the right time with your permission. As smart devices such as Amazon Alexa, Google Home, Ray-ban Meta get popular, Intelligent Assistants are gradually playing an important role in people's lives. The Emergence of wearable devices brings more opportunities and calls for the next generation of Intelligent Assistants. In this talk, we discuss the many challenges and opportunities we face to grow intelligent assistants from voice-only to multi-modal, from context-agnostic to context-aware, from listening to the users' requests to predicting the user's needs, and from server-side to on-device. We describe our LLM-based solutions toward multi-modality, contextualization, personalization, and retrieval-augmentation, and discuss how they are enabled on devices. We expect these new challenges to open doors to new research areas and start a new chapter for providing personal assistance services},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {4735},
numpages = {1},
keywords = {multi-modal personal information management, smart assistant},
location = {Barcelona, Spain},
series = {KDD '24}
}

@proceedings{10.1145/3616855,
title = {WSDM '24: Proceedings of the 17th ACM International Conference on Web Search and Data Mining},
year = {2024},
isbn = {9798400703713},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our great pleasure to welcome you to the 17th ACM International Conference on Web Search and Data Mining - WSDM 2024. WSDM is one of the premier conferences in the fields of web search and data mining, with a dynamic and growing community from academia and industry. After two years of virtual conferences and in-person conferences in Singapore, the 2024 edition is an in-person conference with virtual elements. We hope you enjoy the conference at the "Centro Internacional de Congresos de Yucatan (CIC)" in Merida from March 4 to March 8, 2024.We are excited to kick off the program with a dynamic mix of Tutorials and Industry Day. Our seven tutorials will cover a broad range of search and data mining topics. Industry Day will provide valuable insights from leaders at major technology companies. The core technical program continues WSDM's tradition of a single-track format, featuring 109 thought-provoking papers from both academic and industry experts. We're honored to have inspiring keynote speakers each day: Nicolas Christin (CMU), Elizabeth Reid (Google), and Saiph Savage (Civic A.I. Lab). Additionally, 17 interactive demonstrations will showcase the latest prototypes and systems. The final day offers a stimulating Doctoral Consortium and six engaging workshops on topics including integrity in social networks, large language model for society, psychology-informed information access system, interactive and scalable information retrieval system and machine learning on graphs. WSDM 2024 proudly presents WSDM day on information retrieval and Web in the region. WSDM Cup Day highlights finalists' presentations addressing challenges in Conversational Multi-Doc QA. This diverse and stimulating program promises to be an enriching experience for all!.},
location = {Merida, Mexico}
}

@inproceedings{10.1145/3678717.3691318,
author = {Silva, Jo\~{a}o Daniel and Magalh\~{a}es, Jo\~{a}o and Tuia, Devis and Martins, Bruno},
title = {Multilingual Vision-Language Pre-training for the Remote Sensing Domain},
year = {2024},
isbn = {9798400711077},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3678717.3691318},
doi = {10.1145/3678717.3691318},
abstract = {Methods based on Contrastive Language-Image Pre-training (CLIP) are nowadays extensively used in support of vision-and-language tasks involving remote sensing data, such as cross-modal retrieval. The adaptation of CLIP to this specific domain has relied on model fine-tuning with the standard contrastive objective, using existing human-labeled image-caption datasets, or using synthetic data corresponding to image-caption pairs derived from other annotations over remote sensing images (e.g., object classes). The use of different pre-training mechanisms has received less attention, and only a few exceptions have considered multilingual inputs. This work proposes a novel vision-and-language model for the remote sensing domain, exploring the fine-tuning of a multilingual CLIP model and testing the use of a self-supervised method based on aligning local and global representations from individual input images, together with the standard CLIP objective. Model training relied on assembling pre-existing datasets of remote sensing images paired with English captions, followed by the use of automated machine translation into nine additional languages. We show that translated data is indeed helpful, e.g. improving performance also on English. Our resulting model, which we named Remote Sensing Multilingual CLIP (RS-M-CLIP), obtains state-of-the-art results in a variety of vision-and-language tasks, including cross-modal and multilingual image-text retrieval, or zero-shot image classification.},
booktitle = {Proceedings of the 32nd ACM International Conference on Advances in Geographic Information Systems},
pages = {220–232},
numpages = {13},
keywords = {Contrastive Language-Image Pre-training, Cross-Modal Retrieval, Remote Sensing, Self-Supervised Pre-training, Vision and Language},
location = {Atlanta, GA, USA},
series = {SIGSPATIAL '24}
}

@article{10.1145/3660826,
author = {Yan, Chuan and Meng, Mark Huasong and Xie, Fuman and Bai, Guangdong},
title = {Investigating Documented Privacy Changes in Android OS},
year = {2024},
issue_date = {July 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
number = {FSE},
url = {https://doi.org/10.1145/3660826},
doi = {10.1145/3660826},
abstract = {Android has empowered third-party apps to access data and services on mobile devices since its genesis.This involves a wide spectrum of user privacy-sensitive data, such as the device ID and location. In recent years, Android has taken proactive measures to adapt its access control policies for such data, in response to the increasingly strict privacy protection regulations around the world. When each new Android version is released, its privacy changes induced by the version evolution are transparently disclosed, and we refer to them as documented privacy changes (DPCs). Implementing DPCs in Android OS is a non-trivial task, due to not only the dispersed nature of those access control points within the OS, but also the challenges posed by backward compatibility. As a result, whether the actual access control enforcement in the OS implementations aligns with the disclosed DPCs becomes a critical concern.
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
 
In this work, we conduct the first systematic study on the consistency between the operational behaviors of the OS at runtime and the officially disclosed DPCs. We propose DopCheck, an automatic DPC-driven testing framework equipped with a large language model (LLM) pipeline. It features a serial of analysis to extract the ontology from the privacy change documents written in natural language, and then harnesses the few-shot capability of LLMs to construct test cases for the detection of DPC-compliance issues in OS implementations. We apply DopCheck with the latest versions (10 to 13) of Android Open Source Project (AOSP). Our evaluation involving 79 privacy-sensitive APIs demonstrates that DopCheck can effectively recognize DPCs from Android documentation and generate rigorous test cases. Our study reveals that the status quo of the DPC-compliance issues is concerning, evidenced by 19 bugs identified by DopCheck. Notably, 12 of them are discovered in Android 13 and 6 in Android 10 for the first time, posing more than 35% Android users to the risk of privacy leakage. Our findings should raise an alert to Android users and app developers on the DPC compliance issues when using or developing an app, and would also underscore the necessity for Google to comprehensively validate the actual implementation against its privacy documentation prior to the OS release.},
journal = {Proc. ACM Softw. Eng.},
month = jul,
articleno = {119},
numpages = {24},
keywords = {Android, documentation, privacy, testing}
}

@article{10.1145/3676956,
author = {Pei, Jiahuan and Yan, Guojun and De Rijke, Maarten and Ren, Pengjie},
title = {Mixture-of-Languages Routing for Multilingual Dialogues},
year = {2024},
issue_date = {November 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {42},
number = {6},
issn = {1046-8188},
url = {https://doi.org/10.1145/3676956},
doi = {10.1145/3676956},
abstract = {We consider multilingual dialogue systems and ask how the performance of a dialogue system can be improved by using information that is available in other languages than the language in which a conversation is being conducted. We adopt a collaborative chair-experts framework, where each expert agent can be either monolingual or cross-lingual, and a chair agent follows a mixture-of-experts procedure for globally optimizing multilingual task-oriented dialogue systems. We propose a mixture-of-languages routing framework that includes four functional components, i.e., input embeddings of multilingual dialogues, language model, pairwise alignment between the representation of every two languages, and mixture-of-languages. We quantify language characteristics of unity and diversity using a number of similarity metrics, i.e., genetic similarity and word and sentence similarity based on embeddings. Our main finding is that the performance of multilingual task-oriented dialogue systems can be greatly impacted by three key aspects, i.e., data sufficiency, language characteristics, and model design in a mixture-of-languages routing framework.},
journal = {ACM Trans. Inf. Syst.},
month = oct,
articleno = {165},
numpages = {33},
keywords = {multilingual systems, task-oriented dialogue systems, collaborative agents, mixture-of-experts}
}

@inproceedings{10.1145/3652583.3658040,
author = {Dai, Ruiting and Tan, Yuqiao and Mo, Lisi and Liang, Shuang and Huo, Guohao and Luo, Jiayi and Cheng, Yao},
title = {G-SAP: Graph-based Structure-Aware Prompt Learning over Heterogeneous Knowledge for Commonsense Reasoning},
year = {2024},
isbn = {9798400706196},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652583.3658040},
doi = {10.1145/3652583.3658040},
abstract = {Commonsense question answering has demonstrated considerable potential across various applications like assistants and social robots. Although fully fine-tuned Pre-trained Language Model(PLM) has achieved remarkable performance in commonsense reasoning, their tendency to excessively prioritize textual information hampers the precise transfer of structural knowledge and undermines interpretability. Some studies have explored combining Language Models (LM) with Knowledge Graphs (KGs) by coarsely fusing the two modalities to perform Graph Neural Network (GNN)-based reasoning that lacks a profound interaction between heterogeneous modalities. In this paper, we propose a novel underlineG raph-based underlineS tructure-underlineA ware underlineP rompt Learning Model for commonsense reasoning, named G-SAP, aiming to maintain a balance between heterogeneous knowledge and enhance the cross-modal interaction within the LM+GNNs model. In particular, an evidence graph is constructed by integrating multiple knowledge sources, i.e. ConceptNet, Wikipedia, and Cambridge Dictionary to boost the performance. Afterward, a structure-aware frozen PLM is employed to fully incorporate the structured and textual information from the evidence graph, where the generation of prompts is driven by graph entities and relations. Finally, a heterogeneous message-passing reasoning module is used to facilitate deep interaction of knowledge between the LM and graph-based networks. Empirical validation, conducted through extensive experiments on three benchmark datasets, demonstrates the notable performance of the proposed model. The results reveal a significant advancement over the existing models, especially, with 6.12% improvement over the SoTA LM+GNNs model ~citehuang2023mvp on the OpenbookQA dataset.},
booktitle = {Proceedings of the 2024 International Conference on Multimedia Retrieval},
pages = {1051–1060},
numpages = {10},
keywords = {commonsense question answering, graph-based networks, heterogeneous modalities, prompt learning},
location = {Phuket, Thailand},
series = {ICMR '24}
}

@inproceedings{10.1145/3637528.3672043,
author = {Luo, Yizhen and Yang, Kai and Hong, Massimo and Liu, Xing Yi and Nie, Zikun and Zhou, Hao and Nie, Zaiqing},
title = {Learning Multi-view Molecular Representations with Structured and Unstructured Knowledge},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3672043},
doi = {10.1145/3637528.3672043},
abstract = {Capturing molecular knowledge with representation learning approaches holds significant potential in vast scientific fields such as chemistry and life science. An effective and generalizable molecular representation is expected to capture the consensus and complementary molecular expertise from diverse views and perspectives. However, existing works fall short in learning multi-view molecular representations, due to challenges in explicitly incorporating view information and handling molecular knowledge from heterogeneous sources. To address these issues, we present MV-Mol, a molecular representation learning model that harvests multi-view molecular expertise from chemical structures, unstructured knowledge from biomedical texts, and structured knowledge from knowledge graphs. We utilize text prompts to model view information and design a fusion architecture to extract view-based molecular representations. We develop a two-stage pre-training procedure, exploiting heterogeneous data of varying quality and quantity. Through extensive experiments, we show that MV-Mol provides improved representations that substantially benefit molecular property prediction. Additionally, MV-Mol exhibits state-of-the-art performance in multi-modal comprehension of molecular structures and texts. Code and data are available at https://github.com/PharMolix/OpenBioMed.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {2082–2093},
numpages = {12},
keywords = {knowledge graphs, multi-view molecular representation learning, text mining},
location = {Barcelona, Spain},
series = {KDD '24}
}

@inproceedings{10.1145/3637528.3671460,
author = {Ren, Xubin and Tang, Jiabin and Yin, Dawei and Chawla, Nitesh and Huang, Chao},
title = {A Survey of Large Language Models for Graphs},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671460},
doi = {10.1145/3637528.3671460},
abstract = {Graphs are an essential data structure utilized to represent relationships in real-world scenarios. Prior research has established that Graph Neural Networks (GNNs) deliver impressive outcomes in graph-centric tasks, such as link prediction and node classification. Despite these advancements, challenges like data sparsity and limited generalization capabilities continue to persist. Recently, Large Language Models (LLMs) have gained attention in natural language processing. They excel in language comprehension and summarization. Integrating LLMs with graph learning techniques has attracted interest as a way to enhance performance in graph learning tasks. In this survey, we conduct an in-depth review of the latest state-of-the-art LLMs applied in graph learning and introduce a novel taxonomy to categorize existing methods based on their framework design. We detail four unique designs: i) GNNs as Prefix, ii) LLMs as Prefix, iii) LLMs-Graphs Integration, and iv) LLMs-Only, highlighting key methodologies within each category. We explore the strengths and limitations of each framework, and emphasize potential avenues for future research, including overcoming current integration challenges between LLMs and graph learning techniques, and venturing into new application areas. This survey aims to serve as a valuable resource for researchers and practitioners eager to leverage large language models in graph learning, and to inspire continued progress in this dynamic field. We consistently maintain the related open-source materials at https://github.com/HKUDS/Awesome-LLM4Graph-Papers.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {6616–6626},
numpages = {11},
keywords = {graph learning, large language models},
location = {Barcelona, Spain},
series = {KDD '24}
}

@inproceedings{10.1145/3688868.3689189,
author = {Zhou, Luping},
title = {Automated Medical Report Generation and Visual Question Answering},
year = {2024},
isbn = {9798400711954},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3688868.3689189},
doi = {10.1145/3688868.3689189},
abstract = {The rapid growth of medical imaging data has far outpaced the availability of trained radiologists, significantly increasing their workload. To alleviate this burden, reduce diagnostic errors, and streamline clinical workflows, the need for automated medical diagnostic report generation has become more urgent than ever. However, this task is particularly challenging, as it requires the ability to capture and describe clinically significant fine-grained visual differences in highly similar medical images. Additionally, critical disease-related keywords can easily be overshadowed by the prevalence of similar phrases describing common image content. Moreover, generating comprehensive reports that detail both normal and pathological findings within images adds to the complexity.In this presentation, I will showcase our latest research on automated medical diagnostic report generation and medical visual question answering, highlighting how we have tackled these challenges. Our work has transitioned from traditional encoder-decoder models to cutting-edge approaches utilizing large language models (LLMs). I will also discuss the current limitations of these methods and propose potential future directions.Specifically, I will present two methods we developed before the advent of pretrained LLMs, which enhance fine-grained recognition for medical report generation from different angles. The first is a self-boosting framework designed to learn highly correlated image and text features, enabling the model to narrate even finer visual changes in the generated reports. The second method is inspired by the 'multi-expert joint diagnosis' scenario and introduces multiple learnable 'expert' tokens into the transformer architecture, with each expert focusing on distinct image regions. These complementary perspectives are then aggregated to produce a final, more accurate report. In addition to report generation, I will also present our efforts in improving medical visual question answering (VQA).Following this, I will introduce our recent work on integrating LLMs for medical report generation. I will outline two frameworks we developed: the first employs a frozen LLM for report generation, training only a lightweight visual alignment module to achieve state-of-the-art performance. The second framework goes a step further by integrating a knowledge graph to unlock disease-related knowledge within the LLM, thereby enhancing the clinical relevance of the generated reports. Additionally, I will share our latest investigation into GPT-4V's multimodal capabilities in chest X-ray analysis and discuss the limitations of current evaluation metrics for radiology report generation. To address these limitations, I will introduce our recently developed MRScore framework, which guides LLMs in radiology report evaluation to ensure alignment with human expert analysis.},
booktitle = {Proceedings of the 1st International Workshop on Multimedia Computing for Health and Medicine},
pages = {3–4},
numpages = {2},
keywords = {large language models, medical report generation, medical visual question answering},
location = {Melbourne VIC, Australia},
series = {MCHM'24}
}

@inproceedings{10.1145/3664647.3681377,
author = {Mei, Xin and Mao, Rui and Cai, Xiaoyan and Yang, Libin and Cambria, Erik},
title = {Medical Report Generation via Multimodal Spatio-Temporal Fusion},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3681377},
doi = {10.1145/3664647.3681377},
abstract = {Medical report generation aims at automating the synthesis of accurate and comprehensive diagnostic reports from radiological images. The task can significantly enhance clinical decision-making and alleviate the workload on radiologists. Existing works normally generate reports from single chest radiographs, although historical examination data also serve as crucial references for radiologists in real-world clinical settings. To address this constraint, we introduce a novel framework that mimics the workflow of radiologists. This framework compares past and present patient images to monitor disease progression and incorporates prior diagnostic reports as references for generating current personalized reports. We tackle the textual diversity challenge in cross-modal tasks by promoting style-agnostic discrete report representation learning and token generation. Furthermore, we propose a novel spatio-temporal fusion method with multi-granularities to fuse textual and visual features by disentangling the differences between current and historical data. We also tackle token generation biases, which arise from long-tail frequency distributions, proposing a novel feature normalization technique. This technique ensures unbiased generation for tokens, whether they are frequent or infrequent, enabling the robustness of report generation for rare diseases. Experimental results on the two public datasets demonstrate that our proposed model outperforms state-of-the-art baselines.},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {4699–4708},
numpages = {10},
keywords = {cross-modal generation, medical report generation, multimodal fusion},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@inproceedings{10.1145/3691720.3691749,
author = {Yi, Chonghua and Li, Sihao and Ge, Bin},
title = {The Tremendous Influence of Large Language Models on Academia and Strategies for Coping with It},
year = {2024},
isbn = {9798400710230},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691720.3691749},
doi = {10.1145/3691720.3691749},
abstract = {Large language models have a profound influence on academic work, with both advantages and disadvantages. The beneficial effects are concentrated on promoting the formation of the fifth research paradigm, unprecedentedly enhancing researchers' efficiency in grasping academic frontiers, generating new knowledge through emergent effects, and facilitating the enhancement and expansion of researchers' innovative capabilities. The adverse effects are mainly embodied in the threat posed by large language model writing to the three fundamental principles of academia: objectivity, innovation, and openness, posing a serious threat to the long-term healthy development of academia. In response to the public product nature of academia and the characteristics of large language models as major international engineering projects, the countermeasures to address the significant influence of large language models require systematic construction and comprehensive implementation.},
booktitle = {Proceedings of the 2nd International Conference on Educational Knowledge and Informatization},
pages = {170–177},
numpages = {8},
location = {Shanghai, China},
series = {EKI '24}
}

@inproceedings{10.1145/3691620.3695037,
author = {Guo, An and Zhou, Yuan and Tian, Haoxiang and Fang, Chunrong and Sun, Yunjian and Sun, Weisong and Gao, Xinyu and Luu, Anh Tuan and Liu, Yang and Chen, Zhenyu},
title = {SoVAR: Build Generalizable Scenarios from Accident Reports for Autonomous Driving Testing},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695037},
doi = {10.1145/3691620.3695037},
abstract = {Autonomous driving systems (ADSs) have undergone remarkable development and are increasingly employed in safety-critical applications. However, recently reported data on fatal accidents involving ADSs suggests that the desired level of safety has not yet been fully achieved. Consequently, there is a growing need for more comprehensive and targeted testing approaches to ensure safe driving. Scenarios from real-world accident reports provide valuable resources for ADS testing, including critical scenarios and high-quality seeds. However, existing scenario reconstruction methods from accident reports often exhibit limited accuracy in information extraction. Moreover, due to the diversity and complexity of road environments, matching current accident information with the simulation map data for reconstruction poses significant challenges.In this paper, we design and implement SoVAR, a tool for automatically generating road-generalizable scenarios from accident reports. SoVAR utilizes well-designed prompts with linguistic patterns to guide the large language model (LLM) in extracting accident information from textual data. Subsequently, it formulates and solves accident-related constraints in conjunction with the extracted accident information to generate accident trajectories. Finally, SoVAR reconstructs accident scenarios on various map structures and converts them into test scenarios to evaluate its capability to detect defects in industrial ADSs. We experiment with SoVAR, using the accident reports from the National Highway Traffic Safety Administration's (NHTSA) database to generate test scenarios for the industrial-grade ADS Apollo. The experimental findings demonstrate that SoVAR can effectively generate generalized accident scenarios across different road structures. Furthermore, the results confirm that SoVAR identified 5 distinct safety violation types that contributed to the crash of Baidu Apollo.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {268–280},
numpages = {13},
keywords = {software testing, automatic test generation, constraint solving, autonomous driving system},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@article{10.1145/3696413,
author = {Li, Zihao and Yang, Chao and Chen, Yakun and Wang, Xianzhi and Chen, Hongxu and Xu, Guandong and Yao, Lina and Sheng, Michael},
title = {Graph and Sequential Neural Networks in Session-based Recommendation: A Survey},
year = {2024},
issue_date = {February 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {57},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/3696413},
doi = {10.1145/3696413},
abstract = {Recent years have witnessed the remarkable success of recommendation systems (RSs) in alleviating the information overload problem. As a new paradigm of RSs, session-based recommendation (SR) specializes in users’ short-term preferences and aims at providing a more dynamic and timely recommendation based on ongoing interactions. This survey presents a comprehensive overview of the recent works on SR. First, we clarify the key definitions within SR and compare the characteristics of SR against other recommendation tasks. Then, we summarize the existing methods in two categories: sequential neural network based methods and graph neural network (GNN) based methods. The relevant frameworks and technical details are further introduced. Finally, we discuss the challenges of SR and new research directions in this area.},
journal = {ACM Comput. Surv.},
month = nov,
articleno = {40},
numpages = {37},
keywords = {Recommendation survey, session-based recommendation, graph neural networks, sequential neural networks}
}

@article{10.1109/TASLP.2024.3419415,
author = {Song, Ran and Huang, Xiang and Peng, Hao and Gao, Shengxiang and Yu, Zhengtao and Yu, Philip},
title = {WDEA: The Structure and Semantic Fusion With Wasserstein Distance for Low-Resource Language Entity Alignment},
year = {2024},
issue_date = {2024},
publisher = {IEEE Press},
volume = {32},
issn = {2329-9290},
url = {https://doi.org/10.1109/TASLP.2024.3419415},
doi = {10.1109/TASLP.2024.3419415},
abstract = {Entity Alignment (EA) aims to identify pairs of entities from two distinct language knowledge graphs (KGs) that represent the same real-world objects. Current EA methods have exhibited impressive performance by leveraging both structural and semantic information. However, these approaches often falter when confronted with EA in low-resource languages. The primary challenge is that low-resource language KGs have sparse graph structures, resulting in difficulty in obtaining accurate entity representations. High-quality entity representation is the key to improving EA performance. Therefore, we propose augmenting entity representations with additional features derived from within the graph. In this paper, we introduce a novel approach: Structure and Semantic Fusion with WD for Low-Resource Language Entity Alignment (WDEA). Our method integrates structural and semantic information using the Wasserstein Distance. Specifically, we design a Wasserstein Graph Convolutional Network (WGCN), a GNN-based model that integrates multi-hop information using a message passing mechanism with WD. Additionally, our method adapts the semantic information from the pre-trained language model in the Wasserstein space to facilitate smooth integration. We also propose the Wasserstein Fusion Encoder (WFE), which effectively combines structural and semantic information in the Wasserstein space. To validate the efficacy of our proposed method, we construct low-resource language EA datasets, encompassing uncommon linguistic varieties with sparser structures compared to mainstream datasets. Experimental results show the superiority of our approach, demonstrating significant performance enhancements in low-resource language EA compared to prevailing baseline models across various information configurations.},
journal = {IEEE/ACM Trans. Audio, Speech and Lang. Proc.},
month = jun,
pages = {4511–4525},
numpages = {15}
}

@article{10.1145/3676280,
author = {O'Leary Jr, Daniel E.},
title = {USING LARGE LANGUAGE MODELS FOR ARMCHAIR AUDITORS},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3676280},
doi = {10.1145/3676280},
abstract = {Armchair auditors are citizens who use open data to investigate and monitor government activities, typically using analytics and other approaches. Armchair auditors provide a valuable role in holding governments and organizations accountable. This paper investigates the potential use of large language models (LLM) to support armchair auditor analyzes of different governmental entities. Unfortunately, the literature, prior to the development of LLM suggested several challenges for armchair auditors. However, the analysis in this paper suggests that LLM can provide substantial data and analytic process support for armchair auditors mitigating issues such as, providing guidelines for analyses, guiding users to appropriate communities, suggesting potential data availability opportunities, doing analysis and other issues. As part of an approach to unifying armchair auditor searches, this paper also suggests a prompt library designed to support, standardize and promote best practice analyzes among armchair auditors. In addition to these issues, this paper also analyzes emerging ethical issues associated with armchair auditors and their use of open data and LLMs. Finally, this paper extends the activity theory model to account for LLMs.},
note = {Just Accepted},
journal = {Digit. Gov.: Res. Pract.},
month = jul,
keywords = {Activity Theory, Large Language Models, Armchair Auditor, Open Data, ChatGPT, BARD}
}

@inproceedings{10.1145/3652628.3652731,
author = {Yu, Tingjie and Liao, Liefa and Yang, Yiguo and Xia, Weihuan and Zou, Zhenyuan},
title = {DBMAT: Research on Chinese Named Entity Recognition Using the Dilated Bidirectional Multi-layer Attentive Transformer Fusion Model},
year = {2024},
isbn = {9798400708831},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652628.3652731},
doi = {10.1145/3652628.3652731},
abstract = {In the realm of Chinese Named Entity Recognition tasks, conventional models have frequently fallen short in adequately addressing linguistic features and recognizing the essential role of context. To address this challenge, our research presents a unique Chinese Named Entity Recognition model, referred to as the LERT-DBMAT-CRF model. Initially, the LERT pre-trained language model incorporates language-informed pretraining strategies to enrich the semantic attributes in textual data. Subsequently, we apply the DBMAT module, unifying bidirectional Long Short-Term Memory networks with residual dilated convolutional networks, coordinated through a multi-head additive attention mechanism. This approach enhances feature extraction by employing the Exponential Linear Unit function, thus enhancing the model's capacity to capture temporal and spatial information relevant to semantic features. Lastly, a Conditional Random Field layer is introduced to exploit contextual information for label prediction. Experimental results demonstrate the exceptional model performance, achieving impressive F1 scores of 97.38% and 96.55% on the Resume dataset and the MSRA dataset, respectively, surpassing the performance of current mainstream models.},
booktitle = {Proceedings of the 4th International Conference on Artificial Intelligence and Computer Engineering},
pages = {616–621},
numpages = {6},
location = {Dalian, China},
series = {ICAICE '23}
}

@inproceedings{10.1145/3691720.3691807,
author = {Chen, Hongzhi and Gu, Shijia and Wang, Xiaoyan and Pang, Feng and Lin, Xiufeng},
title = {A human motivation driven based user-activity recommending service using AIGC and self-supervised agent cluster with debating scheme},
year = {2024},
isbn = {9798400710230},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691720.3691807},
doi = {10.1145/3691720.3691807},
abstract = {The manuscript introduces a self-supervised agent framework grounded in AIGC and a multi-debate mechanism. This framework leverages the multi-debate mechanism to facilitate the reflection and continuous iterative enhancement of agents, thereby enabling precise invocation of specialized models within the AIGC large-scale model. It enhances data insights through knowledge graph-augmented retrieval, ultimately replacing traditional keyboard-mouse interactions with natural language interfaces for executing critical user data prediction and insights, multi-model/application scheduling, integration with existing systems, and user decision support. Experiments conducted on a dataset comprising five major categories and over 10,000 SKUs from a medical consumables supplier, focusing on user interaction logic recommendation, model selection and prediction, as well as material demand forecasting and interpretation, have demonstrated the efficacy of our approach. The results confirm that the proposed multi-agent framework and multi-round debate mechanism achieve levels of human-machine interaction logic determination, predictive model selection, and business interpretability that are comparable to or on par with those of domain experts.},
booktitle = {Proceedings of the 2nd International Conference on Educational Knowledge and Informatization},
pages = {510–514},
numpages = {5},
location = {Shanghai, China},
series = {EKI '24}
}

@inproceedings{10.1145/3589334.3645424,
author = {Liu, Wenhan and Zhao, Ziliang and Zhu, Yutao and Dou, Zhicheng},
title = {Mining Exploratory Queries for Conversational Search},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3645424},
doi = {10.1145/3589334.3645424},
abstract = {Users' queries are usually vague, and their search intents tend to be ambiguous, thereby needing search clarification to clarify users' current intent by asking a clarifying question and providing several clickable sub-intent items as clarification options. However, in addition to drilling down the current query, users may also have exploratory needs that diverge from their current intent. For example, a user searching for the query "Cartier women watches'' may also potentially want to explore some parallel information by issuing queries such as "Rolex women watches'' or "Cartier women bracelets'', named exploratory queries in this paper. These exploratory needs are common during the search process yet cannot be satisfied by current search clarification approaches which typically stick to the sub-intents of the query. This paper focuses on mining exploratory queries as additional options to meet users' exploratory needs in conversational search systems. Specifically, we first design a rule-based model that generates exploratory queries based on the current query's top retrieved documents. Then, we propose using the data generated by the rule-based model to train a neural generation model through multi-task learning for further generalization. Finally, we borrow the in-context learning ability of the large language model to generate exploratory queries based on prompt engineering. We constructed an evaluation dataset based on human annotations and conduct an extensive set of experiments. The results show that our proposed methods generate higher-quality exploratory queries compared with several baselines.},
booktitle = {Proceedings of the ACM Web Conference 2024},
pages = {1386–1394},
numpages = {9},
keywords = {conversational search, exploratory search, search clarification},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3616855.3635744,
author = {I, Muneeswaran and Shankar, Advaith and V, Varun and Gopalakrishnan, Saisubramaniam and Vaddina, Vishal},
title = {Mitigating Factual Inconsistency and Hallucination in Large Language Models},
year = {2024},
isbn = {9798400703713},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3616855.3635744},
doi = {10.1145/3616855.3635744},
abstract = {Large Language Models (LLMs) have demonstrated remarkable capabilities in various language-related tasks enabling applications in various fields such as healthcare, education, financial services etc. However, they are prone to producing factually incorrect responses or ''hallucinations'' which can have detrimental consequences such as loss of credibility, diminished customer trust etc. In this presentation, we showcase a solution that addresses the challenge of minimizing hallucinations. Our solution provides accurate responses and generates detailed explanations, thereby enabling the users to know how the model arrived at the final response. Additionally, it verifies if the explanations are factually correct and offers insights into whether the generated explanations are directly derived from the provided context or if they are inferred from it. We also systematically assess the quality of generated responses using an LLM-based evaluation technique. We present empirical results on benchmark datasets to demonstrate the effectiveness of our approach. Our presentation also examines the impact of individual components in the solution, enhancing the factual correctness of the final response. This research is vital for industries utilizing LLMs, as it provides a means to enhance the reliability of responses and mitigate the risks associated with factual hallucinations. Researchers and practitioners seeking to enhance the reliability of LLM responses will find valuable insights in this presentation.},
booktitle = {Proceedings of the 17th ACM International Conference on Web Search and Data Mining},
pages = {1169–1170},
numpages = {2},
keywords = {hallucinations, information retrieval, large language models},
location = {Merida, Mexico},
series = {WSDM '24}
}

@article{10.1109/TCBB.2024.3451348,
author = {Li, Zhijing and Tian, Liwei and Jiang, Yiping and Huang, Yucheng},
title = {Relation Extraction in Biomedical Texts: A Cross-Sentence Approach},
year = {2024},
issue_date = {Nov.-Dec. 2024},
publisher = {IEEE Computer Society Press},
address = {Washington, DC, USA},
volume = {21},
number = {6},
issn = {1545-5963},
url = {https://doi.org/10.1109/TCBB.2024.3451348},
doi = {10.1109/TCBB.2024.3451348},
abstract = {Relation extraction, a crucial task in understanding the intricate relationships between entities in biomedical domains, has predominantly focused on binary relations within single sentences. However, in practical biomedical scenarios, relationships often extend across multiple sentences, leading to extraction errors with potential impacts on clinical decision-making and medical diagnosis. To overcome this limitation, we present a novel cross-sentence relation extraction framework that integrates and enhances coreference resolution and relation extraction models. Coreference resolution serves as the foundation, breaking sentence boundaries and linking entities across sentences. Our framework incorporates pre-trained deep language representations and leverages graph LSTMs to effectively model cross-sentence entity mentions. The use of a self-attentive Transformer architecture and external semantic information further enhances the modeling of intricate relationships. Comprehensive experiments conducted on two standard datasets, namely the BioNLP dataset and THYME dataset, demonstrate the state-of-the-art performance of our proposed approach.},
journal = {IEEE/ACM Trans. Comput. Biol. Bioinformatics},
month = sep,
pages = {2156–2166},
numpages = {11}
}

@inproceedings{10.1145/3626772.3657732,
author = {Sun, Zhongxiang and Si, Zihua and Zhang, Xiao and Zang, Xiaoxue and Song, Yang and Xu, Hongteng and Xu, Jun},
title = {To Search or to Recommend: Predicting Open-App Motivation with Neural Hawkes Process},
year = {2024},
isbn = {9798400704314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626772.3657732},
doi = {10.1145/3626772.3657732},
abstract = {Incorporating Search and Recommendation (S&amp;R) services within a singular application is prevalent in online platforms, leading to a new task termed open-app motivation prediction, which aims to predict whether users initiate the application with the specific intent of information searching, or to explore recommended content for entertainment. Studies have shown that predicting users' motivation to open an app can help to improve user engagement and enhance performance in various downstream tasks. However, accurately predicting open-app motivation is not trivial, as it is influenced by user-specific factors, search queries, clicked items, as well as their temporal occurrences. Furthermore, these activities occur sequentially and exhibit intricate temporal dependencies. Inspired by the success of the Neural Hawkes Process (NHP) in modeling temporal dependencies in sequences, this paper proposes a novel neural Hawkes process model to capture the temporal dependencies between historical user browsing and querying actions. The model, referred to as Neural Hawkes Process-based Open-App Motivation prediction model (NHP-OAM), employs a hierarchical transformer and a novel intensity function to encode multiple factors, and open-app motivation prediction layer to integrate time and user-specific information for predicting users' open-app motivations. To demonstrate the superiority of our NHP-OAM model and construct a benchmark for the Open-App Motivation Prediction task, we not only extend the public S&amp;R dataset ZhihuRec but also construct a new real-world Open-App Motivation Dataset (OAMD). Experiments on these two datasets validate NHP-OAM's superiority over baseline models. Further downstream application experiments demonstrate NHP-OAM's effectiveness in predicting users' Open-App Motivation, highlighting the immense application value of NHP-OAM.},
booktitle = {Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {1018–1028},
numpages = {11},
keywords = {behavior modeling, neural hawkes process, open-app motivation},
location = {Washington DC, USA},
series = {SIGIR '24}
}

@article{10.1145/3687035,
author = {Sun, Yuling and Chen, Jiaju and Yao, Bingsheng and Liu, Jiali and Wang, Dakuo and Ma, Xiaojuan and Lu, Yuxuan and Xu, Ying and He, Liang},
title = {Exploring Parent's Needs for Children-Centered AI to Support Preschoolers' Interactive Storytelling and Reading Activities},
year = {2024},
issue_date = {November 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {CSCW2},
url = {https://doi.org/10.1145/3687035},
doi = {10.1145/3687035},
abstract = {Interactive storytelling is vital for preschooler development. While children's interactive partners have traditionally been their parents and teachers, recent advances in artificial intelligence (AI) have sparked a surge of AI-based storytelling and reading technologies. As these technologies become increasingly ubiquitous in preschoolers' lives, questions arise regarding how they function in practical storytelling and reading scenarios and, how parents, the most critical stakeholders, experience and perceive these technologies. This paper investigates these questions through a qualitative study with 17 parents of children aged 3-6. Our findings suggest that even though AI-based storytelling and reading technologies provide more immersive and engaging interaction, they still cannot meet parents' expectations due to a series of interactive and algorithmic challenges. We elaborate on these challenges and discuss the possible implications of future AI-based interactive storytelling technologies for preschoolers.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = nov,
articleno = {496},
numpages = {25},
keywords = {ai, artificial intelligence, interactive, parents, preschoolers, storybook reading, storytelling}
}

@proceedings{10.1145/3690712,
title = {In2Writing '24: Proceedings of the Third Workshop on Intelligent and Interactive Writing Assistants},
year = {2024},
isbn = {9798400710315},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Honolulu, HI, USA}
}

@inproceedings{10.1145/3626772.3657985,
author = {Bendersky, Michael and Li, Cheng and Mei, Qiaozhu and Murdock, Vanessa and Tang, Jie and Wang, Hongning and Zamani, Hamed and Zhang, Mingyang and Zhang, Xingjian},
title = {The Second Workshop on Large Language Models for Individuals, Groups, and Society},
year = {2024},
isbn = {9798400704314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626772.3657985},
doi = {10.1145/3626772.3657985},
abstract = {This is the second workshop in the series which discusses the cutting-edge developments in research and applications of personalizing large language models (LLMs) and adapting them to the demands of diverse user populations and societal needs. The full-day workshop plan includes several keynotes and invited talks, a poster session and a panel discussion.},
booktitle = {Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {3062–3064},
numpages = {3},
keywords = {large language models, personalization},
location = {Washington DC, USA},
series = {SIGIR '24}
}

@article{10.1145/3696427,
author = {Rani, Nanda and Saha, Bikash and Maurya, Vikas and Shukla, Sandeep Kumar},
title = {TTPXHunter: Actionable Threat Intelligence Extraction as TTPs from Finished Cyber Threat Reports},
year = {2024},
issue_date = {December 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {4},
url = {https://doi.org/10.1145/3696427},
doi = {10.1145/3696427},
abstract = {Understanding the modus operandi of adversaries aids organizations to employ efficient defensive strategies and share intelligence in the community. This knowledge is often present in unstructured natural language text within threat analysis reports. A translation tool is needed to interpret the modus operandi explained in the sentences of the threat report and convert it into a structured format. This research introduces a methodology named TTPXHunter for automated extraction of threat intelligence in terms of Tactics, Techniques, and Procedures (TTPs) from finished cyber threat reports. It leverages cyber domain-specific state-of-the-art natural language model to augment sentences for minority class TTPs and refine pinpointing the TTPs in threat analysis reports significantly. We create two datasets: an augmented sentence-TTP dataset of  (39,296)  sentence samples and a  (149)  real-world cyber threat intelligence report-to-TTP dataset. Further, we evaluate TTPXHunter on the augmented sentence and report datasets. The TTPXHunter achieves the highest performance of  (92.42%)  f1-score on the augmented dataset, and it also outperforms existing state-of-the-art TTP extraction method by achieving an f1-score of  (97.09%)  when evaluated over the report dataset. TTPXHunter significantly improves cybersecurity threat intelligence by offering quick, actionable insights into attacker behaviors. This advancement automates threat intelligence analysis and provides a crucial tool for cybersecurity professionals to combat cyber threats.},
journal = {Digital Threats},
month = dec,
articleno = {37},
numpages = {19},
keywords = {Threat Intelligence, TTP Extraction, MITRE ATT&amp;CK, Natural Language Processing, Threat Intelligence Extraction, TTP Classification, Cyber Security and AI, Cyber Security Threats, NLP, Cybersecurity}
}

@inbook{10.1145/3674127.3702962,
title = {Authors’ Biography/Index},
year = {2024},
isbn = {9798400710506},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
edition = {1},
url = {https://doi.org/10.1145/3674127.3702962},
booktitle = {Information Retrieval: Advanced Topics and Techniques},
pages = {773–815},
numpages = {43}
}

@inproceedings{10.1109/JCDL57899.2023.00038,
author = {Sierra-M\'{u}nera, Alejandro and Westphal, Jan and Krestel, Ralf},
title = {Efficient Ultrafine Typing of Named Entities},
year = {2024},
isbn = {9798350399318},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/JCDL57899.2023.00038},
doi = {10.1109/JCDL57899.2023.00038},
abstract = {Ultrafine named entity typing (UFET) refers to the assignment of predefined labels to entity mentions in a given context. In contrast to traditional named entity typing, the number of potential labels is in the thousands and one mention can have more than one assigned type. Previous approaches either depend on large training datasets, or require inefficient encoding of all input-type combinations. Therefore, there is a need for investigating the efficiency during training and prediction of entity typing models in the ultrafine-grained setting, considering its distinctively bigger search space, compared to the coarse- and fine-grained tasks. To efficiently solve UFET, we propose Decent, a lightweight model that encodes, using a pretrained language model, the input sentences separately from the type labels. Additionally, we make use of negative oversampling to speed up the training while improving the generalization of unseen types. Using an openly available UFET dataset, we evaluated the classification and runtime performance of Decent and observed that training and prediction runtime is orders of magnitude faster than the current state-of-the-art approaches, while maintaining a competitive classification performance.},
booktitle = {Proceedings of the 2023 ACM/IEEE Joint Conference on Digital Libraries},
pages = {205–214},
numpages = {10},
keywords = {ultrafine enity typing, named entity recognition},
location = {Santa Fe, New Mexico, USA},
series = {JCDL '23}
}

@inproceedings{10.1145/3589334.3645406,
author = {Lin, Xin and Su, Tianhuang and Huang, Zhenya and Xue, Shangzi and Liu, Haifeng and Chen, Enhong},
title = {A Knowledge-Injected Curriculum Pretraining Framework for Question Answering},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3645406},
doi = {10.1145/3589334.3645406},
abstract = {Knowledge-based question answering (KBQA) is a key task in natural language processing research, and also an approach to access the web data and knowledge, which requires exploiting knowledge graphs (KGs) for reasoning. In the literature, one promising solution for KBQA is to incorporate the pretrained language model (LM) with KGs by generating KG-centered pretraining corpus, which has shown its superiority. However, these methods often depend on specific techniques and resources to work, which may not always be available and restrict its application. Moreover, existing methods focus more on improving language understanding with KGs, while neglect the more important human-like complex reasoning. To this end, in this paper, we propose a general K nowledge-I njected C urriculum P retraining framework (KICP) to achieve comprehensive KG learning and exploitation for KBQA tasks, which is composed of knowledge injection (KI), knowledge adaptation (KA) and curriculum reasoning (CR). Specifically, the KI module first injects knowledge into the LM by generating KG-centered pretraining corpus, and generalizes the process into three key steps that could work with different implementations for flexible application. Next, the KA module learns knowledge from the generated corpus with LM equipped with an adapter as well as keeps its original natural language understanding ability to reduce the negative impacts of the difference between the generated and natural corpus. Last, to enable the LM with complex reasoning, the CR module follows human reasoning patterns to construct three corpora with increasing difficulties of reasoning, and further trains the LM from easy to hard in a curriculum manner to promote model learning. We provide an implementation of the general framework, and evaluate the proposed KICP on four real-word datasets. The results demonstrate that our framework can achieve higher performances, and have good generalization ability to other QA tasks.},
booktitle = {Proceedings of the ACM Web Conference 2024},
pages = {1986–1997},
numpages = {12},
keywords = {curriculum learning, knowledge-injected pretraining, question answering},
location = {Singapore, Singapore},
series = {WWW '24}
}

@article{10.1109/TCBB.2024.3447037,
author = {Yu, Xindi and Zhou, Shusen and Zang, Mujun and Wang, Qingjun and Liu, Chanjuan and Liu, Tong},
title = {Parallel Convolutional Contrastive Learning Method for Enzyme Function Prediction},
year = {2024},
issue_date = {Nov.-Dec. 2024},
publisher = {IEEE Computer Society Press},
address = {Washington, DC, USA},
volume = {21},
number = {6},
issn = {1545-5963},
url = {https://doi.org/10.1109/TCBB.2024.3447037},
doi = {10.1109/TCBB.2024.3447037},
abstract = {The function labeling of enzymes has a wide range of application value in the medical field, industrial biology and other fields. Scientists define enzyme categories by enzyme commission (EC) numbers. At present, although there are some tools for enzyme function prediction, their effects have not reached the application level. To improve the precision of enzyme function prediction, we propose a parallel convolutional contrastive learning (PCCL) method to predict enzyme functions. First, we use the advanced protein language model ESM-2 to preprocess the protein sequences. Second, PCCL combines convolutional neural networks (CNNs) and contrastive learning to improve the prediction precision of multifunctional enzymes. Contrastive learning can make the model better deal with the problem of class imbalance. Finally, the deep learning framework is mainly composed of three parallel CNNs for fully extracting sample features. we compare PCCL with state-of-art enzyme function prediction methods based on three evaluation metrics. The performance of our model improves on both two test sets. Especially on the smaller test set, PCCL improves the AUC by 2.57%.},
journal = {IEEE/ACM Trans. Comput. Biol. Bioinformatics},
month = aug,
pages = {2604–2609},
numpages = {6}
}

@proceedings{10.1145/3643479,
title = {AIQAM '24: Proceedings of the 1st ACM Workshop on AI-Powered Q&amp;A Systems for Multimedia},
year = {2024},
isbn = {9798400705472},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Phuket, Thailand}
}

@article{10.1145/3631392,
author = {Yang, Jian and Hu, Xinyu and Xiao, Gang and Shen, Yulong},
title = {A Survey of Knowledge Enhanced Pre-trained Language Models},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {2375-4699},
url = {https://doi.org/10.1145/3631392},
doi = {10.1145/3631392},
abstract = {Pre-trained language models learn informative word representations on a large-scale text corpus through self-supervised learning, which has achieved promising performance in fields of natural language processing (NLP) after fine-tuning. These models, however, suffer from poor robustness and lack of interpretability. We refer to pre-trained language models with knowledge injection as knowledge-enhanced pre-trained language models (KEPLMs). These models demonstrate deep understanding and logical reasoning and introduce interpretability. In this survey, we provide a comprehensive overview of KEPLMs in NLP. We first discuss the advancements in pre-trained language models and knowledge representation learning. Then we systematically categorize existing KEPLMs from three different perspectives. Finally, we outline some potential directions of KEPLMs for future research.},
note = {Just Accepted},
journal = {ACM Trans. Asian Low-Resour. Lang. Inf. Process.},
month = mar,
keywords = {natural language processing, pre-trained language models, symbolic knowledge, knowledge enhanced pre-trained language models}
}

@inproceedings{10.1145/3613905.3650798,
author = {Reif, Emily and Qian, Crystal and Wexler, James and Kahng, Minsuk},
title = {Automatic Histograms: Leveraging Language Models for Text Dataset Exploration},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3650798},
doi = {10.1145/3613905.3650798},
abstract = {Making sense of unstructured text datasets is perennially difficult, yet increasingly relevant with Large Language Models. Data practitioners often rely on dataset summaries, especially distributions of various derived features. Some features, like toxicity or topics, are relevant to many datasets, but many interesting features are domain specific: instruments and genres for a music dataset, or diseases and symptoms for a medical dataset. Accordingly, data practitioners often run custom analyses for each dataset, which is cumbersome and difficult, or use unsupervised methods. We present AutoHistograms, a visualization tool leveraging LLMs. AutoHistograms automatically identifies relevant entity-based features, visualizes them, and allows the user to interactively query the dataset for new categories of entities. In a user study with (n=10) data practitioners, we observe that participants were able to quickly onboard to AutoHistograms, use the tool to identify actionable insights, and conceptualize a broad range of applicable use cases. Together, this tool and user study contribute to the growing field of LLM-assisted sensemaking tools.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {53},
numpages = {9},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}

@inproceedings{10.1145/3616855.3635726,
author = {Bendersky, Michael and Li, Cheng and Mei, Qiaozhu and Murdock, Vanessa and Tang, Jie and Wang, Hongning and Zamani, Hamed and Zhang, Mingyang},
title = {WSDM 2024 Workshop on Large Language Models for Individuals, Groups, and Society},
year = {2024},
isbn = {9798400703713},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3616855.3635726},
doi = {10.1145/3616855.3635726},
abstract = {This workshop discusses the cutting-edge developments in research and applications of personalizing large language models (LLMs) and adapting them to the demands of diverse user populations and societal needs. The full-day workshop includes several keynotes and invited talks, a poster session and a panel discussion.},
booktitle = {Proceedings of the 17th ACM International Conference on Web Search and Data Mining},
pages = {1206–1207},
numpages = {2},
keywords = {large language models, personalization, workshop},
location = {Merida, Mexico},
series = {WSDM '24}
}

@inproceedings{10.1145/3613905.3650949,
author = {Oelen, Allard and Auer, S\"{o}ren},
title = {Leveraging Large Language Models for Realizing Truly Intelligent User Interfaces},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3650949},
doi = {10.1145/3613905.3650949},
abstract = {The number of published scholarly articles is growing at a significant rate, making scholarly knowledge organization increasingly important. Various approaches have been proposed to organize scholarly information, including describing scholarly knowledge semantically leveraging knowledge graphs. Transforming unstructured knowledge, presented within articles, to structured and semantically represented knowledge generally requires human intelligence and labor since natural language processing methods alone typically do not render sufficient precision and recall for many applications. With the recent developments of Large Language Models (LLMs), it becomes increasingly possible to provide truly intelligent user interfaces guiding humans in the transformation process. We present an approach to integrate non-intrusive LLMs guidance into existing user interfaces. More specifically, we integrate LLM-supported user interface components into an existing scholarly knowledge infrastructure. Additionally, we provide our experiences with LLM integration, detailing best practices and obstacles. Finally, we evaluate the approach using a small-scale user evaluation with domain experts.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {222},
numpages = {8},
keywords = {Intelligent User Interface, LLM Interface, Scholarly Knowledge Graphs},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}

@article{10.1109/TASLP.2024.3419438,
author = {Li, Pijian and Huang, Qingbao and Li, Zhigang and Cai, Yi and Shuang, Feng and Li, Qing},
title = {Multi-Granularity Feature Fusion for Image-Guided Story Ending Generation},
year = {2024},
issue_date = {2024},
publisher = {IEEE Press},
volume = {32},
issn = {2329-9290},
url = {https://doi.org/10.1109/TASLP.2024.3419438},
doi = {10.1109/TASLP.2024.3419438},
abstract = {Image-guided Story Ending Generation aims at generating a reasonable and logical ending given a story context and an ending-related image. The existing models have achieved some success by fusing global image features with story context through an attention mechanism. However, they ignore the logical relationship between the story context and the image regions, and have not considered the high-level semantic features of the image such as visual sentiment. This may cause the generated ending inconsistent with the logic or sentiment of the given information. In this paper, we propose a &lt;bold&gt;M&lt;/bold&gt;ulti-&lt;bold&gt;G&lt;/bold&gt;ranularity feature &lt;bold&gt;F&lt;/bold&gt;usion (MGF) model to solve this problem. Concretely, we first employ an image sentiment extractor to grasp the sentiment features of the image as part of the global image features. We then design a scene subgraph selector to capture the image features of the key region by picking the scene subgraph most relevant to the context. Finally, we fuse the textual and visual features from object level, region level, and global level, respectively. Our model is thereby capable of effectively capturing the key region features and visual sentiment of the image, so as to generate a more logical and sentimental ending. Experimental results show that our MGF model outperforms the state-of-the-art models on most metrics.},
journal = {IEEE/ACM Trans. Audio, Speech and Lang. Proc.},
month = jun,
pages = {3437–3449},
numpages = {13}
}

@inproceedings{10.1145/3639631.3639665,
author = {Li, Peihong and Cai, Fei and Wang, Siyuan and Liu, Shixian and Liu, Dengfeng},
title = {A Review: Data and Semantic Augmentation for Relation Classification in Low Resource},
year = {2024},
isbn = {9798400709203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639631.3639665},
doi = {10.1145/3639631.3639665},
abstract = {Relation Classification (RC) is a significant study component in Natural Language Processing (NLP) that focuses on matching pairings of entities in natural utterances. Both traditional methods relying on rule matching and statistical features, as well as more contemporary methods utilizing deep learning and Pre-trained Language Model (PLM), excessively depends on vast quantities of data. In reality, numerous domains or subjects sometimes suffer from a scarcity of accessible data. Consequently, numerous academics have shifted their attention towards conducting research in low-resource domains, namely in areas such as semi-supervised learning and weakly supervised learning. However, both of these approaches bring a significant amount of noisy input into the model. Errors may arise in methods utilizing metric learning as a result of inappropriate metric selections. Prompt Learning (PL) has expanded its success in few-shot learning to also include RC tasks. Studies have been carried out to investigate the utilization of PL in enhancing the model’s capacity to comprehend and learn textual content. This includes augmenting the sample data with prompt templates to enhance the model’s ability to learn from a small amount of labeled data. This study presents a comprehensive overview of the latest research advancements in low-resource reading comprehension (RC). Additionally, it provides a summary of the few-shot RC technique based on pre-training and fine-tuning language models (PL). Lastly, the present challenges in research are examined, and the future trajectory of work on few-shot RC based on pre-training and language models are envisioned.},
booktitle = {Proceedings of the 2023 6th International Conference on Algorithms, Computing and Artificial Intelligence},
pages = {195–201},
numpages = {7},
keywords = {few-shot, prompt learning, relation classification},
location = {Sanya, China},
series = {ACAI '23}
}

@article{10.1145/3663482,
author = {Gilman, Ekaterina and Bugiotti, Francesca and Khalid, Ahmed and Mehmood, Hassan and Kostakos, Panos and Tuovinen, Lauri and Ylipulli, Johanna and Su, Xiang and Ferreira, Denzil},
title = {Addressing Data Challenges to Drive the Transformation of Smart Cities},
year = {2024},
issue_date = {October 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {5},
issn = {2157-6904},
url = {https://doi.org/10.1145/3663482},
doi = {10.1145/3663482},
abstract = {Cities serve as vital hubs of economic activity and knowledge generation and dissemination. As such, cities bear a significant responsibility to uphold environmental protection measures while promoting the welfare and living comfort of their residents. There are diverse views on the development of smart cities, from integrating Information and Communication Technologies into urban environments for better operational decisions to supporting sustainability, wealth, and comfort of people. However, for all these cases, data are the key ingredient and enabler for the vision and realization of smart cities. This article explores the challenges associated with smart city data. We start with gaining an understanding of the concept of a smart city, how to measure that the city is a smart one, and what architectures and platforms exist to develop one. Afterwards, we research the challenges associated with the data of the cities, including availability, heterogeneity, management, analysis, privacy, and security. Finally, we discuss ethical issues. This article aims to serve as a “one-stop shop” covering data-related issues of smart cities with references for diving deeper into particular topics of interest.},
journal = {ACM Trans. Intell. Syst. Technol.},
month = nov,
articleno = {88},
numpages = {65},
keywords = {Big data, smart city, urban computing, machine learning, data analysis}
}

@article{10.1145/3649449,
author = {Li, Junyi and Tang, Tianyi and Zhao, Wayne Xin and Nie, Jian-Yun and Wen, Ji-Rong},
title = {Pre-Trained Language Models for Text Generation: A Survey},
year = {2024},
issue_date = {September 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {56},
number = {9},
issn = {0360-0300},
url = {https://doi.org/10.1145/3649449},
doi = {10.1145/3649449},
abstract = {Text Generation aims to produce plausible and readable text in human language from input data. The resurgence of deep learning has greatly advanced this field, in particular, with the help of neural generation models based on pre-trained language models (PLMs). Text generation based on PLMs is viewed as a promising approach in both academia and industry. In this article, we provide a survey on the utilization of PLMs in text generation. We begin with introducing two key aspects of applying PLMs to text generation: (1) how to design an effective PLM to serve as the generation model; and (2) how to effectively optimize PLMs given the reference text and to ensure that the generated texts satisfy special text properties. Then, we show the major challenges that have arisen in these aspects, as well as possible solutions for them. We also include a summary of various useful resources and typical text generation applications based on PLMs. Finally, we highlight the future research directions which will further improve these PLMs for text generation. This comprehensive survey is intended to help researchers interested in text generation problems to learn the core concepts, the main techniques and the latest developments in this area based on PLMs.},
journal = {ACM Comput. Surv.},
month = apr,
articleno = {230},
numpages = {39},
keywords = {Pre-trained language models, natural language processing}
}

@inproceedings{10.1145/3626772.3657755,
author = {Dao, Huy and Deng, Yang and Le, Dung D. and Liao, Lizi},
title = {Broadening the View: Demonstration-augmented Prompt Learning for Conversational Recommendation},
year = {2024},
isbn = {9798400704314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626772.3657755},
doi = {10.1145/3626772.3657755},
abstract = {Conversational Recommender Systems (CRSs) leverage natural language dialogues to provide tailored recommendations. Traditional methods in this field primarily focus on extracting user preferences from isolated dialogues. It often yields responses with a limited perspective, confined to the scope of individual conversations. Recognizing the potential in collective dialogue examples, our research proposes an expanded approach for CRS models, utilizing selective analogues from dialogue histories and responses to enrich both generation and recommendation processes. This introduces significant research challenges, including: (1) How to secure high-quality collections of recommendation dialogue exemplars? (2) How to effectively leverage these exemplars to enhance CRS models?To tackle these challenges, we introduce a novel Demonstration-enhanced Conversational Recommender System (DCRS), which aims to strengthen its understanding on the given dialogue contexts by retrieving and learning from demonstrations. In particular, we first propose a knowledge-aware contrastive learning method that adeptly taps into the mentioned entities and the dialogue's contextual essence for pretraining the demonstration retriever. Subsequently, we further develop two adaptive demonstration-augmented prompt learning approaches, involving contextualized prompt learning and knowledge-enriched prompt learning, to bridge the gap between the retrieved demonstrations and the two end tasks of CRS, i.e., response generation and item recommendation, respectively. Rigorous evaluations on two established benchmark datasets underscore DCRS's superior performance over existing CRS methods in both item recommendation and response generation.},
booktitle = {Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {785–795},
numpages = {11},
keywords = {conversational recommendation, demonstration-based learning},
location = {Washington DC, USA},
series = {SIGIR '24}
}

@inproceedings{10.1145/3643489.3661114,
author = {Tran, Quang-Linh and Nguyen, Binh and Jones, Gareth J. F. and Gurrin, Cathal},
title = {MemoriEase 2.0: A Conversational Lifelog Retrieve System for LSC'24},
year = {2024},
isbn = {9798400705502},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643489.3661114},
doi = {10.1145/3643489.3661114},
abstract = {Lifelog retrieval plays an important role in memory support for lifeloggers. It helps the lifeloggers to browse, search and navigate their life moments from the lifelog data. However, the volume and variety of lifelog data are enormous and range in multiple modalities so they impose a big challenge to retrieve accurate lifelog moments. The Lifelog Search Challenges (LSCs) are a benchmark challenge for evaluating lifelog retrieval systems in different tasks. In this paper, we introduce the MemoriEase 2.0 lifelog retrieval system that participates in LSC'24. This system not only inherits core functions from the precedent system but also incorporates new components such as conversational search, visual similarity search and retrieval-augmented generation for question-answering tasks. The new functions are expected to help expert and novice users solve all topics in three tasks of LSC'24. We evaluate MemoriEase 2.0 in KIS topics in LSC'23 and the system achieves promising results with Recall@1 is 40% at the first hint and it solves 8 over 10 topics.},
booktitle = {Proceedings of the 7th Annual ACM Workshop on the Lifelog Search Challenge},
pages = {12–17},
numpages = {6},
keywords = {lifelog retrieval, conversational search, personal archive},
location = {Phuket, Thailand},
series = {LSC '24}
}

@article{10.1613/jair.1.15280,
author = {Liu, Bin and Yin, Guosheng},
title = {Graphmax for Text Generation},
year = {2024},
issue_date = {Jan 2024},
publisher = {AI Access Foundation},
address = {El Segundo, CA, USA},
volume = {78},
issn = {1076-9757},
url = {https://doi.org/10.1613/jair.1.15280},
doi = {10.1613/jair.1.15280},
abstract = {In text generation, a large language model (LM) makes a choice of each new word based only on the former selection of its context using the softmax function. Nevertheless, the link statistics information of concurrent words based on a scene-specific corpus is valuable in choosing the next word, which can help to ensure the topic of the generated text to be aligned with the current task. To fully explore the co-occurrence information, we propose a graphmax function for task-specific text generation. Using the graph-based regularization, graphmax enables the final word choice to be determined by both the global knowledge from the LM and the local knowledge from the scene-specific corpus. The traditional softmax function is regularized with a graph total variation (GTV) term, which incorporates the local knowledge into the LM and encourages the model to consider the statistical relationships between words in a scene-specific corpus. The proposed graphmax is versatile and can be readily plugged into any large pre-trained LM for text generation and machine translation. Through extensive experiments, we demonstrate that the new GTV-based regularization can improve performances in various natural language processing (NLP) tasks in comparison with existing methods. Moreover, through human experiments, we observe that participants can easily distinguish the text generated by graphmax or softmax.},
journal = {J. Artif. Int. Res.},
month = jan,
numpages = {26}
}

@proceedings{10.1145/3687311,
title = {IECT '24: Proceedings of the 2024 International Conference on Intelligent Education and Computer Technology},
year = {2024},
isbn = {9798400709920},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Guilin, China}
}

@inproceedings{10.1145/3672919.3672982,
author = {Zou, Feifei and Hu, Su and Yu, Wei and Yan, Zejun and Chan, Sijun},
title = {Research on Financial Fraud Text Classification Based on PET-BiLSTM},
year = {2024},
isbn = {9798400718212},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3672919.3672982},
doi = {10.1145/3672919.3672982},
abstract = {To address challenges associated with obscure features, unbalanced data, and diverse fraud types in Internet financial texts, this paper proposes the PET-BiLSTM financial fraud text classification model to enhance the semantic understanding and reasoning of financial fraud texts. Crawling news, comments and short messages about financial fraud from open source websites, desensitizing and cleaning the texts, labeling them automatically through LDA topic distribution model and financial fraud thesaurus, constructing prompt templates containing mask positions, forming cloze sentences for each sample, and transforming them into multi-classification tasks. The pre-trained BERT model is used to learn semantic information, combined with bidirectional LSTM (BiLSTM) to extract fraudulent text features, and supervised training is carried out. Experimental results show PET-BiLSTM achieving 89.11% and 84.54% F1 values in multi-classifying fraud types and three-classifying fraud degree identification tasks, surpassing deep learning baselines by 4.21% to 15.35% and 2.21% to 9.12%, respectively. PET-BiLSTM also outperforms ChatGPT in zero-shot prompt learning by 67.11% and 48.54%. The model demonstrates superior performance in understanding knowledge facts and fraud reasoning in the financial fraud text classification task, effectively addressing complex text fraud detection challenges within the financial field.},
booktitle = {Proceedings of the 2024 3rd International Conference on Cyber Security, Artificial Intelligence and Digital Economy},
pages = {341–345},
numpages = {5},
location = {Nanjing, China},
series = {CSAIDE '24}
}

@inproceedings{10.1145/3627673.3679915,
author = {Abdi, Samireh},
title = {Enhancing Event Detection with Inter-Event Dependencies in Large Ontologies},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679915},
doi = {10.1145/3627673.3679915},
abstract = {Event Detection (ED), a crucial component of comprehensive text analysis tools, is a well-established task within the fields of Natural Language Processing (NLP) and Information Extraction (IE). Current state-of-the-art models for ED primarily focus on identifying a limited set of predefined event types. Recently, the challenge of detecting a broad array of predefined event types has garnered increasing interest within the IE community. However, a significant gap in existing research on ED with extensive ontologies is the inadequate exploration of how interactions between event types affect ED model performance. One of the hindrances for this purpose is the lack of resources to encode event-event dependencies for large ontologies. This study introduces a novel approach that leverages existing inter-event dependency resources to provide this information for extensive ontologies. Specifically, a solution based on Optimal Transport is proposed to map event-event dependency from existing resources to a large ontology. We conduct extensive experiments on multiple benchmark datasets to assess the effectiveness of our approach. Our findings, supported by a thorough analysis, demonstrate that this innovative technique significantly enhances the performance of ED models, especially for ontologies with a large number of event types.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {3612–3616},
numpages = {5},
keywords = {event detection, large ontology, optimal transport},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@proceedings{10.1145/3649165,
title = {SIGCSE Virtual 2024: Proceedings of the 2024 on ACM Virtual Global Computing Education Conference V. 1},
year = {2024},
isbn = {9798400705984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {On behalf of SIGCSE Virtual 2024 Steering, Organization, and Program Committees, we would like to welcome you to this wonderful event. SIGCSE Virtual 2024, 1st ACM Virtual Global Computing Education Conference is now a reality after over a year of work by all the committee members. We like to send our special thanks to the SIGCSE Board and ACM for their continued support, encouragement and facilitation.One of the major goals of SIGCSE Virtual is to promote an inclusive and easily accessible conference to all interested in CS education research and practice. The hope is to allow those who are not able to easily travel to SIGCSE conferences to participate virtually from around the world. For this reason, the core of the conference follows all other SIGCSE conferences by providing papers, panels, posters/lightning talks, working groups, and doctoral consortium sessions dedicated to CS education research and practice.The conference has different themes based on the global aspects of CS education while considering regional circumstances. The sessions are offered considering time-zone constraints. The online program adjusts to time zones.Several different activities are provided besides the technical sessions by conference sponsors as well as for social engagements. All these activities are included in the program.},
location = {Virtual Event, NC, USA}
}

@proceedings{10.1145/3700297,
title = {ISAIE '24: Proceedings of the 2024 International Symposium on Artificial Intelligence for Education},
year = {2024},
isbn = {9798400707100},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@article{10.1145/3642979.3642997,
author = {Kille, Benjamin and Lommatzsch, Andreas and \"{O}zg\"{o}bek, \"{O}zlem and Liu, Peng and Zhang, Lemei and Eide, Simen},
title = {Report on the 11th International Workshop on News Recommendation and Analytics (INRA 2023) at ACM RecSys 2023},
year = {2024},
issue_date = {December 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {57},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/3642979.3642997},
doi = {10.1145/3642979.3642997},
abstract = {News remains a challenging domain for personalization. INRA'23 allowed experts and practitioners to get together and discuss recent trends and future directions. Peer review selected six contributions for presentation covering a wide array of topics including beyond accuracy evaluation, the use of large language models, misinformation, and emotions in news.Date: 18 September 2023.Website: https://research.idi.ntnu.no/NewsTech/INRA/.},
journal = {SIGIR Forum},
month = jan,
articleno = {15},
numpages = {4}
}

@inproceedings{10.1145/3687311.3687323,
author = {Hu, Bingying and Ni, Qin and Gao, Rong},
title = {Development Strategies and Practical Insights of Teachers' Artificial Intelligence Competence},
year = {2024},
isbn = {9798400709920},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3687311.3687323},
doi = {10.1145/3687311.3687323},
abstract = {Artificial Intelligence (AI) in education not only changes the education model but also transforms the role of teachers from traditional "knowledge transmitters" to "learning guides" and "skills trainers". This transformation underscores the importance of teachers in leveraging AI for educational enhancement and professional growth, highlighting the need for improved AI competencies. We adhere to human-centered principles and follow ethical and responsible AI ethical standards to ensure that technology truly serves education. Through a literature review from an international perspective, this study examines global trends in AI educational practices, comparing policies, curricula, and research across Asia, Europe, and Africa. This comparison facilitates a deep understanding of AI's application and challenges within various cultural and educational settings, offering insights into enhancing teacher's AI competencies. The paper concludes by suggesting a detailed strategy for bolstering teachers' AI skills, employing a stepwise approach to foster professional development and elevate educational quality in the AI era while providing guidance for teachers to use AI critically and transformatively.},
booktitle = {Proceedings of the 2024 International Conference on Intelligent Education and Computer Technology},
pages = {1–0},
location = {Guilin, China},
series = {IECT '24}
}

@proceedings{10.1145/3686397,
title = {ICISDM '24: Proceedings of the 2024 8th International Conference on Information System and Data Mining},
year = {2024},
isbn = {9798400717345},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3641237,
title = {SIGDOC '24: Proceedings of the 42nd ACM International Conference on Design of Communication},
year = {2024},
isbn = {9798400705199},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Fairfax, VA, USA}
}

@inproceedings{10.1145/3652583.3657599,
author = {Nguyen, Van-Loc and Nguyen, Bao-Tin and Nguyen, Thanh-Son and Dang-Nguyen, Duc-Tien and Tran, Minh-Triet},
title = {A Unified Network for Detecting Out-Of-Context Information Using Generative Synthetic Data},
year = {2024},
isbn = {9798400706196},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652583.3657599},
doi = {10.1145/3652583.3657599},
abstract = {In our modern world, the manipulation of digital content, especially the usage of out-of-context images known as Cheapfakes, has become a significant challenge for the endorsement of integrity and trustworthiness for information on the Internet. This highlights an urgent need for effective detection of the misuse of images and their accompanied captions. Motivated by this issue, our research presents an innovative approach to the solution of this problem. Participating in the ACM ICMR 2024 Grand Challenge on Detecting Cheapfakes, we leverage a unified end-to-end network, integrated with generative synthetic data for training. After complete evaluation, our proposed network demonstrated a remarkable accuracy of 95.60% on the public test dataset for Task 1, as well as efficiency in Task 2. This paper highlights the notable potential of employing an end-to-end network for Cheapfakes detection, which composes a significant contribution to the advancement of multimedia content integrity. Our source code is publicly available at https://github.com/thanhson28/cheapfakes_detection_icmr2024.git},
booktitle = {Proceedings of the 2024 International Conference on Multimedia Retrieval},
pages = {1300–1305},
numpages = {6},
keywords = {cheapfakes detection, miscontextualization, misinformation, out-of-context, visual entailment},
location = {Phuket, Thailand},
series = {ICMR '24}
}

@inproceedings{10.1145/3631085.3631302,
author = {De Lima, Edirlei Soares and Feij\'{o}, Bruno and Cassanova, Marco A. and Furtado, Antonio L.},
title = {ChatGeppetto - an AI-powered Storyteller},
year = {2024},
isbn = {9798400716270},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3631085.3631302},
doi = {10.1145/3631085.3631302},
abstract = {In this paper we introduce a novel highly interactive process to generate natural language narratives on the basis of our ongoing work on semiotic relations. To the two basic components of interactive systems, namely, a software tool and a user interface, we add a third component – AI agents, understood as an upgraded rendition of software agents. Our semiotic relations approach considers four ways of composing new narratives from existing narratives. Along what semioticians call the horizontal syntagmatic axis, one can form the new narrative by combining two or more previous narratives. Along the vertical paradigmatic axis, the new narrative may emerge as a similar version, which imitates the previous one, possibly in a different context. Along the depth meronymic axis, the hierarchic narrative levels, such as plot, event, and scene, are explored, allowing either expansion or summarization. Lastly, the antithetic consideration, rather than adding a dimension, aims at some form of reversal, through the adoption of opposite values. A fully operational prototype is described. Its name, ChatGeppetto, conflates the skilled Geppetto, who fashioned Pinocchio, an early case of artisanship-produced human level intelligence, with ChatGPT, which operates as the main AI agent component. To run the experiments, we concentrated on book narratives.},
booktitle = {Proceedings of the 22nd Brazilian Symposium on Games and Digital Entertainment},
pages = {28–37},
numpages = {10},
keywords = {Artificial Intelligence, Book Narratives, ChatGPT, Chatbots, Interactive Story Composition, Semiotic Relations, Storyboards},
location = {Rio Grande (RS), Brazil},
series = {SBGames '23}
}

@inproceedings{10.1145/3637528.3671503,
author = {Lakkaraju, Himabindu and Mei, Qiaozhu and Tan, Chenhao and Tang, Jie and Xie, Yutong},
title = {The First Workshop on AI Behavioral Science},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671503},
doi = {10.1145/3637528.3671503},
abstract = {This workshop initiates a new study field which may be named AI behavioral science. It discusses recent findings, methodologies, applications, and potential societal impacts that are related to analyzing, understanding, and directing the behaviors of AI models, especially those built upon large language models. This half-day workshop includes several keynote and invited talks, a poster session, and a panel discussion.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {6724–6725},
numpages = {2},
keywords = {ai behavioral science, large language models},
location = {Barcelona, Spain},
series = {KDD '24}
}

@article{10.1145/3698590,
author = {Wang, Song and Zhu, Yaochen and Liu, Haochen and Zheng, Zaiyi and Chen, Chen and Li, Jundong},
title = {Knowledge Editing for Large Language Models: A Survey},
year = {2024},
issue_date = {March 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {57},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/3698590},
doi = {10.1145/3698590},
abstract = {Large Language Models (LLMs) have recently transformed both the academic and industrial landscapes due to their remarkable capacity to understand, analyze, and generate texts based on their vast knowledge and reasoning ability. Nevertheless, one major drawback of LLMs is their substantial computational cost for pre-training due to their unprecedented amounts of parameters. The disadvantage is exacerbated when new knowledge frequently needs to be introduced into the pre-trained model. Therefore, it is imperative to develop effective and efficient techniques to update pre-trained LLMs. Traditional methods encode new knowledge in pre-trained LLMs through direct fine-tuning. However, naively re-training LLMs can be computationally intensive and risks degenerating valuable pre-trained knowledge irrelevant to the update in the model. Recently, Knowledge-based Model Editing (KME), also known as Knowledge Editing or Model Editing, has attracted increasing attention, which aims at precisely modifying the LLMs to incorporate specific knowledge, without negatively influencing other irrelevant knowledge. In this survey, we aim at providing a comprehensive and in-depth overview of recent advances in the field of KME. We first introduce a general formulation of KME to encompass different KME strategies. Afterward, we provide an innovative taxonomy of KME techniques based on how the new knowledge is introduced into pre-trained LLMs, and investigate existing KME strategies while analyzing key insights, advantages, and limitations of methods from each category. Moreover, representative metrics, datasets, and applications of KME are introduced accordingly. Finally, we provide an in-depth analysis regarding the practicality and remaining challenges of KME and suggest promising research directions for further advancement in this field.},
journal = {ACM Comput. Surv.},
month = nov,
articleno = {59},
numpages = {37},
keywords = {Model editing, knowledge update, fine-tuning, large language models}
}

@inproceedings{10.1145/3626772.3657767,
author = {Wang, Jie and Karatzoglou, Alexandros and Arapakis, Ioannis and Jose, Joemon M.},
title = {Reinforcement Learning-based Recommender Systems with Large Language Models for State Reward and Action Modeling},
year = {2024},
isbn = {9798400704314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626772.3657767},
doi = {10.1145/3626772.3657767},
abstract = {Reinforcement Learning (RL)-based recommender systems have demonstrated promising performance in session-based and sequential recommendation tasks. Existing offline RL-based sequential recommendation methods face the challenge of obtaining effective user feedback from the environment. Developing a model for the user state and shaping an appropriate reward for recommendation remains a challenge. In this paper, we leverage language understanding capabilities and adapt large language models (LLMs) as an environment (LE) to enhance RL-based recommenders. The LE is learned from a subset of user-item interaction data, thus reducing the need for large training data, and can synthesize user feedback for offline data by: (i) acting as a state model that produces high-quality states that enrich the user representation, and (ii) functioning as a reward model to accurately capture nuanced user preferences on actions. Moreover, the LE allows us to generate positive actions that augment the limited offline training data. We propose a LE Augmentation (LEA) method to further improve recommendation performance by optimising jointly the supervised component and the RL policy, using the augmented actions and historical user signals. We use LEA, the state, and reward models in conjunction with state-of-the-art RL recommenders and report experimental results on two publicly available datasets.},
booktitle = {Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {375–385},
numpages = {11},
keywords = {augmentation, large language models, reinforcement learning, sequential recommendation},
location = {Washington DC, USA},
series = {SIGIR '24}
}

@proceedings{10.1145/3661304,
title = {GRADES-NDA '24: Proceedings of the 7th Joint Workshop on Graph Data Management Experiences &amp; Systems (GRADES) and Network Data Analytics (NDA)},
year = {2024},
isbn = {9798400706530},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {We are delighted to present the papers from the 7th GRADES-NDA Joint Workshop on Graph Data Management Experiences &amp; Systems and Network Data Analytics which took place on 14th June 2024 co-located with ACM SIGMOD held in Santiago, Chile.},
location = {Santiago, AA, Chile}
}

@proceedings{10.1145/3648188,
title = {HT '24: Proceedings of the 35th ACM Conference on Hypertext and Social Media},
year = {2024},
isbn = {9798400705953},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Poznan, Poland}
}

@proceedings{10.1145/3637907,
title = {ICETM '23: Proceedings of the 2023 6th International Conference on Educational Technology Management},
year = {2023},
isbn = {9798400716676},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Guangzhou, China}
}

@proceedings{10.1145/3643562,
title = {CI '24: Proceedings of the ACM Collective Intelligence Conference},
year = {2024},
isbn = {9798400705540},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Boston, MA, USA}
}

@proceedings{10.1145/3641399,
title = {ISEC '24: Proceedings of the 17th Innovations in Software Engineering Conference},
year = {2024},
isbn = {9798400717673},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Bangalore, India}
}

@inproceedings{10.1109/SC41406.2024.00013,
author = {Dharuman, Gautham and Hippe, Kyle and Brace, Alexander and Foreman, Sam and Hatanp\"{a}\"{a}, V\"{a}in\"{o} and Sastry, Varuni K. and Zheng, Huihuo and Ward, Logan and Muralidharan, Servesh and Vasan, Archit and Kale, Bharat and Mann, Carla M. and Ma, Heng and Cheng, Yun-Hsuan and Zamora, Yuliana and Liu, Shengchao and Xiao, Chaowei and Emani, Murali and Gibbs, Tom and Tatineni, Mahidhar and Canchi, Deepak and Mitchell, Jerome and Yamada, Koichi and Garzaran, Maria and Papka, Michael E. and Foster, Ian and Stevens, Rick and Anandkumar, Anima and Vishwanath, Venkatram and Ramanathan, Arvind},
title = {MProt-DPO: Breaking the ExaFLOPS Barrier for Multimodal Protein Design Workflows with Direct Preference Optimization},
year = {2024},
isbn = {9798350352917},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/SC41406.2024.00013},
doi = {10.1109/SC41406.2024.00013},
abstract = {We present a scalable, end-to-end workflow for protein design. By augmenting protein sequences with natural language descriptions of their biochemical properties, we train generative models that can be preferentially aligned with protein fitness landscapes. Through complex experimental- and simulation-based observations, we integrate these measures as preferred parameters for generating new protein variants and demonstrate our workflow on five diverse supercomputers. We achieve &gt;1 ExaFLOPS sustained performance in mixed precision on each supercomputer and a maximum sustained performance of 4.11 ExaFLOPS and peak performance of 5.57 ExaFLOPS. We establish the scientific performance of our model on two tasks: (1) across a predetermined benchmark dataset of deep mutational scanning experiments to optimize the fitness-determining mutations in the yeast protein HIS7, and (2) in optimizing the design of the enzyme malate dehydrogenase to achieve lower activation barriers (and therefore increased catalytic rates) using simulation data. Our implementation thus sets high watermarks for multimodal protein design workflows.},
booktitle = {Proceedings of the International Conference for High Performance Computing, Networking, Storage, and Analysis},
articleno = {7},
numpages = {13},
keywords = {AI, HPC, Large language models, protein design},
location = {Atlanta, GA, USA},
series = {SC '24}
}

@inproceedings{10.1145/3644116.3644226,
author = {Zhou, Chunfang and Gong, Qingyue and Zhu, Jinyang and Luan, Huidan},
title = {Research and Application of Large Language Models in HealthcareCurrent Development of Large Language Models in the Healthcare FieldA Framework for Applying Large Language Models and the Opportunities and Challenges of Large Language Models in Healthcare: A Framework for Applying Large Language Models and the Opportunities and Challenges of Large Language Models in Healthcare},
year = {2024},
isbn = {9798400708138},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3644116.3644226},
doi = {10.1145/3644116.3644226},
abstract = {The burgeoning field of Large Language Models (LLM) within the realm of medical research has garnered significant attention. However, there exists a noticeable dearth of scholarly exploration concerning the practical utility of LLM in addressing substantive task-oriented issues within specific medical domains. In light of this lacuna, the present study endeavors to furnish a comprehensive examination and evaluation of the framework underpinning LLM applications and their corresponding research and implementation within the medical domain.Commencing with a concise explication of the foundational tenets of the LLM application framework, the paper proceeds to expound upon the evolutionary trajectory of LLM and their current research landscape within the medical sphere. Subsequently, it delves into the prospective avenues for LLM application within the medical field. Lastly, the study scrutinizes the multifaceted challenges confronting LLM in the medical domain and offers prescriptive insights aimed at mitigating these impediments.This scholarly endeavor not only serves as a foundational cornerstone for the development of a practical business system predicated on LLM by elucidating the architectural intricacies of their application but also furnishes a comprehensive overview of the research and deployment of LLM in the medical domain, thereby affording invaluable points of reference for future endeavors within this domain.},
booktitle = {Proceedings of the 2023 4th International Symposium on Artificial Intelligence for Medicine Science},
pages = {664–670},
numpages = {7},
location = {Chengdu, China},
series = {ISAIMS '23}
}

@proceedings{10.1145/3680530,
title = {SA '24: SIGGRAPH Asia 2024 Art Papers},
year = {2024},
isbn = {9798400711336},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3641032,
title = {ICISE '23: Proceedings of the 2023 8th International Conference on Information Systems Engineering},
year = {2023},
isbn = {9798400709173},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Bangkok, Thailand}
}

@proceedings{10.1145/3657054,
title = {dg.o '24: Proceedings of the 25th Annual International Conference on Digital Government Research},
year = {2024},
isbn = {9798400709883},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Taipei, Taiwan}
}

@inproceedings{10.1145/3652620.3688206,
author = {Rabbi, Fazle},
title = {A Model-Based Framework for Exploring Conflict Dynamics},
year = {2024},
isbn = {9798400706226},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652620.3688206},
doi = {10.1145/3652620.3688206},
abstract = {This paper introduces a novel framework for conflict analysis that leverages advanced visual modeling techniques. By employing comparative analysis, key variables influencing armed conflicts are identified and analyzed. The framework includes a meta-model representing domain concepts such as the goals and strategies of conflicting parties, escalating stages, and impacts of conflicts.Conflict escalation is a complex process characterized by interactions between opposing parties. This paper presents a structured model that outlines how conflicts evolve and intensify over time. We adapt a meta-modeling framework called the Diagram Predicate Framework (DPF) to represent conflict-related concepts and extend it to support abstract view generation. This framework facilitates the analysis of conflict trends and the study of dynamics across various levels of abstraction.A computational model based on category theory is proposed for trend analysis, enabling the extraction of patterns of conflict evolution and the comparison of strategies and goals at different escalation stages. Categorical operations such as pullback and limit construction are employed to compute conflict evolution and identify common structures among conflict instances, providing insights into conflict dynamics across diverse zones.},
booktitle = {Proceedings of the ACM/IEEE 27th International Conference on Model Driven Engineering Languages and Systems},
pages = {745–754},
numpages = {10},
keywords = {conflict analysis, computational journalism, category theory, metamodeling},
location = {Linz, Austria},
series = {MODELS Companion '24}
}

@article{10.1145/3703454,
author = {Sicari, Sabrina and Cevallos M., Jesus F. and Rizzardi, Alessandra and Coen-Porisini, Alberto},
title = {Open-Ethical AI: Advancements in Open-Source Human-Centric Neural Language Models},
year = {2024},
issue_date = {April 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {57},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/3703454},
doi = {10.1145/3703454},
abstract = {This survey summarises the most recent methods for building and assessing helpful, honest, and harmless neural language models, considering small, medium, and large-size models. Pointers to open-source resources that help to align pre-trained models are given, including methods that use parameter-efficient techniques, specialized prompting frameworks, adapter modules, case-specific knowledge injection, and adversarially robust training techniques. Special care is given to evidencing recent progress on value alignment, commonsense reasoning, factuality enhancement, and abstract reasoning of language models. Most reviewed works in this survey publicly shared their code and related data and were accepted in world-leading Machine Learning venues. This work aims at helping researchers and practitioners accelerate their entrance into the field of human-centric neural language models, which might be a cornerstone of the contemporary and near-future industrial and societal revolution.},
journal = {ACM Comput. Surv.},
month = dec,
articleno = {83},
numpages = {47},
keywords = {Neural language models, open-source, large-language models, human-centric AI}
}

@proceedings{10.1145/3678884,
title = {CSCW Companion '24: Companion Publication of the 2024 Conference on Computer-Supported Cooperative Work and Social Computing},
year = {2024},
isbn = {9798400711145},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to the 27th ACM Conference on Computer-Supported Cooperative Work and Social Computing (CSCW 2024). This year's conference is particularly special, as it marks the first time CSCW to be held in Latin America - a highly anticipated milestone for our Latin American community. We are excited to gather in San Jose, Costa Rica, and host a hybrid event that allows remote participation from community members worldwide.As in previous years, CSCW 2024 brings together a variety of disciplines, from system design to critical analysis, to propose, examine, and reimagine technologies that support groups and communities. As our discipline evolves, new topics continuously emerge and are embraced by our community. This year, we see an emphasis on issues centered around AI, including explainability, fairness, and AI-human collaboration. At the same time, our long-standing concerns remain well represented, including work on group dynamics and decision-making, social media, inclusive and culturally aware design, co-design with marginalized communities, and the creation of socially responsible tools. This year, we invited 387 PACM-HCI, TSC, and TOCHI papers to be presented alongside a diverse lineup of workshops, posters, demos, SIGs, panels, and the doctoral consortium. Below are the numbers of reviewed and accepted submissions for each track featured in this conference companion.},
location = {San Jose, Costa Rica}
}

@inproceedings{10.1145/3626772.3657717,
author = {Qin, Weicong and Cao, Zelin and Yu, Weijie and Si, Zihua and Chen, Sirui and Xu, Jun},
title = {Explicitly Integrating Judgment Prediction with Legal Document Retrieval: A Law-Guided Generative Approach},
year = {2024},
isbn = {9798400704314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626772.3657717},
doi = {10.1145/3626772.3657717},
abstract = {Legal document retrieval and judgment prediction are crucial tasks in intelligent legal systems. In practice, determining whether two documents share the same judgments is essential for establishing their relevance in legal retrieval. However, existing legal retrieval studies either ignore the vital role of judgment prediction or rely on implicit training objectives, expecting a proper alignment of legal documents in vector space based on their judgments. Neither approach provides explicit evidence of judgment consistency for relevance modeling, leading to inaccuracies and a lack of transparency in retrieval. To address this issue, we propose a law-guided method, namely GEAR, within the generative retrieval framework. GEAR explicitly integrates judgment prediction with legal document retrieval in a sequence-to-sequence manner. Specifically, given the intricate nature of legal documents, we first extract rationales from documents based on the definition of charges in law. We then employ these rationales as queries, ensuring efficiency and producing a shared, informative document representation for both tasks. Second, in accordance with the inherent hierarchy of law, we construct a law structure constraint tree and represent each candidate document as a hierarchical semantic ID based on this tree. This empowers GEAR to perform dual predictions for judgment and relevant documents in a single inference, i.e., traversing the tree from the root through intermediate judgment nodes, to document-specific leaf nodes. Third, we devise the revision loss that jointly minimizes the discrepancy between the IDs of predicted and labeled judgments, as well as retrieved documents, thus improving accuracy and consistency for both tasks. Extensive experiments on two Chinese legal case retrieval datasets show the superiority of GEAR over state-of-the-art methods while maintaining competitive judgment prediction performance. Moreover, we validate the effectiveness of GEAR on a French statutory article retrieval dataset, reaffirming its robustness across languages and domains.},
booktitle = {Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {2210–2220},
numpages = {11},
keywords = {generative retrieval, legal document retrieval, legal judgment prediction},
location = {Washington DC, USA},
series = {SIGIR '24}
}

@inproceedings{10.1145/3671127.3698792,
author = {Mulayim, Ozan Baris and Paul, Lazlo and Pritoni, Marco and Prakash, Anand Krishnan and Sudarshan, Malavikha and Fierro, Gabe},
title = {Large Language Models for the Creation and Use of Semantic Ontologies in Buildings: Requirements and Challenges},
year = {2024},
isbn = {9798400707063},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3671127.3698792},
doi = {10.1145/3671127.3698792},
abstract = {Semantic ontologies offer a formalized, machine-readable framework for representing knowledge, enabling the structured description of complex systems. In the building domain, the adoption of ontologies like the Brick schema has transformed how buildings and their systems are modeled by providing a standardized, interoperable language. However, the complexity and the steep learning curve involved in developing and querying semantic models present substantial challenges, often requiring a workforce with specialized expertise. This paper builds on our experience in investigating how Large Language Models (LLMs) can help address these challenges, focusing on their role in constructing and querying of semantic models, particularly using the Brick Schema. Our study outlines the requirements and metrics for evaluating the scalability and effectiveness of LLM-based tools, while also discussing the current challenges and limitations in developing such tools. Ultimately, this paper aims to orient research efforts as various groups experiment with diverse techniques, while enabling more effective comparison of emerging solutions and fostering collaboration across the field.},
booktitle = {Proceedings of the 11th ACM International Conference on Systems for Energy-Efficient Buildings, Cities, and Transportation},
pages = {312–317},
numpages = {6},
keywords = {Knowledge Graphs, Large Language Models, Semantic Ontology},
location = {Hangzhou, China},
series = {BuildSys '24}
}

@inproceedings{10.1145/3657604.3664683,
author = {Yan, Zhenting and Zhang, Rui},
title = {Enhancing Knowledge Tracing Efficacy with Expert-defined Graphs: A Case Study in Introductory Physics Classes},
year = {2024},
isbn = {9798400706332},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657604.3664683},
doi = {10.1145/3657604.3664683},
abstract = {Knowledge Tracing (KT) is essential in online education for tracking student progress and forecasting future performance. Despite the effectiveness of existing KT models, enhancing their educational interpretability and reliability remains crucial for both academic and practical applications. This study introduces an improved Graph-based Knowledge Tracing (GKT) model, enriched with domain expertise, instructional insights, and contextual features, to overcome current limitations. Our enhanced GKT model employs an expert-defined graph structure for more accurate domain knowledge representation. It integrates critical contextual features, like question difficulty and prompt usage, into the response matrix for a comprehensive context. Additionally, the model leverages second-order neighborhood features to more effectively capture complex interrelations between knowledge concepts. Validation using an Introductory Physics assignment dataset demonstrated that our updated GKT model surpasses its predecessor in both Area Under the Curve (AUC) and accuracy (ACC) metrics. These improvements are instrumental in refining knowledge graphs and developing personalized teaching strategies, thereby facilitating more effective and personalized educational experiences.},
booktitle = {Proceedings of the Eleventh ACM Conference on Learning @ Scale},
pages = {433–437},
numpages = {5},
keywords = {adaptive learning, educational interpretability, explicit graph structure, graph-based knowledge tracing, modified GNN},
location = {Atlanta, GA, USA},
series = {L@S '24}
}

@book{10.1145/3674127,
editor = {Alonso, Omar and Baeza-Yates, Ricardo},
title = {Information Retrieval: Advanced Topics and Techniques},
year = {2024},
isbn = {9798400710506},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
edition = {1},
volume = {60},
abstract = {In the last decade, deep learning and word embeddings have made significant impacts on information retrieval (IR) by adding techniques based in neural networks and language models. At the same time, certain search modalities such as neural IR and conversational search have become more popular. This book, written by international academic and industry experts, brings the field up to date with detailed discussions of these new approaches and techniques. The book is organized in three sections: Foundations, Adaptations and Concerns, and Verticals.Under Foundations, we address topics that form the basic structure of any modern IR system, including recommender systems. These new techniques are developed to augment indexing, retrieval, and ranking. Neural IR, recommender systems, evaluation, query-driven functionality, and knowledge graphs are covered in this section.IR systems need to adapt to specific user characteristics and preferences, and techniques that were considered too niche a few years ago are now a matter of system design consideration. The Adaptations and Concerns section covers the following topics: conversational search, cross-language retrieval, temporal extraction and retrieval, bias in retrieval systems, and privacy in search.While web search engines are the most popular information access point, there are cases where specific verticals provide a better experience in terms of content and relevance. The Verticals section describes eCommerce, professional search, personal collections, music retrieval, and biomedicine as examples.}
}

@proceedings{10.1145/3614407,
title = {CSLAW '24: Proceedings of the Symposium on Computer Science and Law},
year = {2024},
isbn = {9798400703331},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Boston, MA, USA}
}

@proceedings{10.1145/3663649,
title = {DataEd '24: Proceedings of the 3rd International Workshop on Data Systems Education: Bridging education practice with education research},
year = {2024},
isbn = {9798400706783},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Santiago, AA, Chile}
}

@article{10.1109/TASLP.2024.3434469,
author = {Wang, Yujie and Zhang, Hu and Liang, Jiye and Li, Ru},
title = {Heterogeneous-Graph Reasoning With Context Paraphrase for Commonsense Question Answering},
year = {2024},
issue_date = {2024},
publisher = {IEEE Press},
volume = {32},
issn = {2329-9290},
url = {https://doi.org/10.1109/TASLP.2024.3434469},
doi = {10.1109/TASLP.2024.3434469},
abstract = {Commonsense question answering (CQA) generally means that the machine uses its mastered commonsense to answer questions without relevant background material, which is a challenging task in natural language processing. Existing methods focus on retrieving relevant subgraphs from knowledge graphs based on key entities and designing complex graph neural networks to perform reasoning over the subgraphs. However, they have the following problems: i) the nested entities in key entities lead to the introduction of irrelevant knowledge; ii) the QA context is not well integrated with the subgraphs; and iii) insufficient context knowledge hinders subgraph nodes understanding. In this paper, we present a heterogeneous-graph reasoning with context paraphrase method (HCP), which introduces the paraphrase knowledge from the dictionary into key entity recognition and subgraphs construction, and effectively fuses QA context and subgraphs during the encoding phase of the pre-trained language model (PTLM). Specifically, HCP filters the nested entities through the dictionary's vocabulary and constructs the Heterogeneous Path-Paraphrase (HPP) graph by connecting the paraphrase descriptions&lt;xref ref-type="fn" rid="fn1"&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/xref&gt;&lt;fn id="fn1"&gt;&lt;label&gt;&lt;sup&gt;1&lt;/sup&gt;&lt;/label&gt;&lt;p&gt;The paraphrase descriptions are English explanations of words or phrases in WordNet and Wiktionary.&lt;/p&gt;&lt;/fn&gt; with the key entity nodes in the subgraphs. Then, by constructing the visible matrices in the PTLM encoding phase, we fuse the QA context representation into the HPP graph. Finally, to get the answer, we perform reasoning on the HPP graph by Mask Self-Attention. Experimental results on CommonsenseQA and OpenBookQA show that fusing QA context with HPP graph in the encoding stage and enhancing the HPP graph representation by using context paraphrase can improve the machine's commonsense reasoning ability.},
journal = {IEEE/ACM Trans. Audio, Speech and Lang. Proc.},
month = jul,
pages = {3759–3770},
numpages = {12}
}

@inproceedings{10.1145/3637528.3671469,
author = {Zhang, Yunyi and Zhong, Ming and Ouyang, Siru and Jiao, Yizhu and Zhou, Sizhe and Ding, Linyi and Han, Jiawei},
title = {Automated Mining of Structured Knowledge from Text in the Era of Large Language Models},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671469},
doi = {10.1145/3637528.3671469},
abstract = {Massive amount of unstructured text data are generated daily, ranging from news articles to scientific papers. How to mine structured knowledge from the text data remains a crucial research question. Recently, large language models (LLMs) have shed light on the text mining field with their superior text understanding and instruction-following ability. There are typically two ways of utilizing LLMs: fine-tune the LLMs with human-annotated training data, which is labor intensive and hard to scale; prompt the LLMs in a zero-shot or few-shot way, which cannot take advantage of the useful information in the massive text data. Therefore, it remains a challenge on automated mining of structured knowledge from massive text data in the era of large language models. In this tutorial, we cover the recent advancements in mining structured knowledge using language models with very weak supervision. We will introduce the following topics in this tutorial: (1) introduction to large language models, which serves as the foundation for recent text mining tasks, (2) ontology construction, which automatically enriches an ontology from a massive corpus, (3) weakly-supervised text classification in flat and hierarchical label space, (4) weakly-supervised information extraction, which extracts entity and relation structures.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {6644–6654},
numpages = {11},
keywords = {large language models, text mining, weak supervision},
location = {Barcelona, Spain},
series = {KDD '24}
}

@article{10.1145/3652598,
author = {Wang, Jian and Lin, Dongding and Li, Wenjie},
title = {Target-constrained Bidirectional Planning for Generation of Target-oriented Proactive Dialogue},
year = {2024},
issue_date = {September 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {42},
number = {5},
issn = {1046-8188},
url = {https://doi.org/10.1145/3652598},
doi = {10.1145/3652598},
abstract = {Target-oriented proactive dialogue systems aim at leading conversations from a dialogue context toward a pre-determined target, such as making recommendations on designated items or introducing new specific topics. To this end, it is critical for such dialogue systems to plan reasonable actions to drive the conversation proactively, and meanwhile, to plan appropriate topics to move the conversation forward to the target topic smoothly. In this work, we mainly focus on effective dialogue planning for target-oriented dialogue generation. Inspired by decision-making theories in cognitive science, we propose a novel target-constrained bidirectional planning (TRIP) approach, which plans an appropriate dialogue path by looking ahead and looking back. By formulating the planning as a generation task, our TRIP bidirectionally generates a dialogue path consisting of a sequence of &lt;action, topic&gt; pairs using two Transformer decoders. They are expected to supervise each other and converge on consistent actions and topics by minimizing the decision gap and contrastive generation of targets. Moreover, we propose a target-constrained decoding algorithm with a bidirectional agreement to better control the planning process. Subsequently, we adopt the planned dialogue paths to guide dialogue generation in a pipeline manner, where we explore two variants: prompt-based generation and plan-controlled generation. Extensive experiments are conducted on two challenging dialogue datasets, which are re-purposed for exploring target-oriented dialogue. Our automatic and human evaluations demonstrate that the proposed methods significantly outperform various baseline models.},
journal = {ACM Trans. Inf. Syst.},
month = apr,
articleno = {124},
numpages = {27},
keywords = {Target-oriented dialogue, dialogue generation, bidirectional planning}
}

@inproceedings{10.1145/3678717.3691312,
author = {Qi, Xiaoqian and Chai, Haoye and Yu, Li and Li, Yong and Wang, Zhaocheng},
title = {Regional Features Conditioned Diffusion Models for 5G Network Traffic Generation},
year = {2024},
isbn = {9798400711077},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3678717.3691312},
doi = {10.1145/3678717.3691312},
abstract = {The fifth-generation (5G) mobile network has significantly enhanced people's lives with faster internet speed and more reliable connections. However, there is still insufficient coverage of 5G networks worldwide, requiring telecom operators to deploy more base stations to meet the increasing demand for 5G's further commercialization. In this regard, a major challenge is understanding user network behaviors and traffic demands in target areas where 5G has not yet been deployed, which is crucial for developing a more efficient base station deployment strategy. Mobile traffic generation is a potential approach that enables operators to preemptively estimate user network demands in target areas, thereby specifying corresponding deployment strategies to enhance network performance. However, existing methods have limitations in capturing spatio-temporal features of 5G mobile traffic, particularly in areas with insufficient 5G coverage and limited historical 5G traffic data. To fill this gap, we introduce a regional feature conditioned diffusion framework for 5G network traffic generation. Our models explore the relationship between 5G traffic and existing 4G traffic, utilizing a customized cross attention mechanism and graph convolutional networks (GCN) to capture the correlation between network traffic and regional features. Based on this relationship, the framework can characterize mobile network traffic demands, thereby achieving high-fidelity 5G traffic generation in target regions with insufficient 5G coverage. Extensive experiments on real-world datasets have shown that the proposed scheme outperforms state-of-the-art baselines by more than 10%, demonstrating its high-fidelity generation capability, controllability, and generalizability. Moreover, we have deployed our scheme on China Mobile's Jiutian Platform as a network traffic simulator to improve 5G base station deployment strategies.},
booktitle = {Proceedings of the 32nd ACM International Conference on Advances in Geographic Information Systems},
pages = {396–409},
numpages = {14},
keywords = {5G network traffic generation, Cross attention, Diffusion models, GCN},
location = {Atlanta, GA, USA},
series = {SIGSPATIAL '24}
}

@proceedings{10.1145/3644815,
title = {CAIN '24: Proceedings of the IEEE/ACM 3rd International Conference on AI Engineering - Software Engineering for AI},
year = {2024},
isbn = {9798400705915},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {The goal of the CAIN Conference Series is to bring together researchers and practitioners in software engineering, data science, and artificial intelligence (AI) as part of a growing community that is targeting the challenges of Software Engineering for AI-enabled systems.},
location = {Lisbon, Portugal}
}

@proceedings{10.1145/3656156,
title = {DIS '24 Companion: Companion Publication of the 2024 ACM Designing Interactive Systems Conference},
year = {2024},
isbn = {9798400706325},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {IT University of Copenhagen, Denmark}
}

@proceedings{10.1145/3639856,
title = {AIMLSystems '23: Proceedings of the Third International Conference on AI-ML Systems},
year = {2023},
isbn = {9798400716492},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Bangalore, India}
}

@inproceedings{10.1145/3664647.3681542,
author = {Liao, Xinyao and Wei, Wei and Chen, Dangyang and Fu, Yuanyuan},
title = {UniQ: Unified Decoder with Task-specific Queries for Efficient Scene Graph Generation},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3681542},
doi = {10.1145/3664647.3681542},
abstract = {Scene Graph Generation(SGG) is a scene understanding task that aims at identifying object entities and reasoning their relationships within a given image. In contrast to prevailing two-stage methods based on a large object detector (e.g., Faster R-CNN), one-stage methods integrate a fixed-size set of learnable queries to jointly reason relational triplets &lt;subject, predicate, object&gt;. This paradigm demonstrates robust performance with significantly reduced parameters and computational overhead. However, the challenge in one-stage methods stems from the issue of weak entanglement, wherein entities involved in relationships require both coupled features shared within triplets and decoupled visual features. Previous methods either adopt a single decoder for coupled triplet feature modeling or multiple decoders for separate visual feature extraction but fail to consider both. In this paper, we introduce UniQ, a Unified decoder with task-specific Queries architecture, where task-specific queries generate decoupled visual features for subjects, objects, and predicates respectively, and unified decoder enables coupled feature modeling within relational triplets. Experimental results on the Visual Genome dataset demonstrate that UniQ has superior performance to both one-stage and two-stage methods.},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {8815–8824},
numpages = {10},
keywords = {one-stage model, scene graph generation, visual relationship detection},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@proceedings{10.1145/3631700,
title = {UMAP Adjunct '24: Adjunct Proceedings of the 32nd ACM Conference on User Modeling, Adaptation and Personalization},
year = {2024},
isbn = {9798400704666},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Cagliari, Italy}
}

@proceedings{10.1145/3649405,
title = {ITiCSE 2024: Proceedings of the 2024 on Innovation and Technology in Computer Science Education V. 2},
year = {2024},
isbn = {9798400706035},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to the 29th annual conference on Innovation and Technology in Computer Science Education (ITiCSE 2024), hosted by Universita degli Studi di Milano in Milan, Italy.ITiCSE 2024 will take place from Friday July 5 to Wednesday July 10. The conference program includes a keynote address, paper sessions, a panel, tips, techniques &amp; courseware demonstrations, posters, a doctoral consortium, and working group presentations. Working groups meet July 5-7 and will submit draft reports before the conference begins on July 8.The submissions to ITiCSE 2024 were reviewed by 446 researchers and practitioners from computing education and related fields, including 44 program committee members and 402 reviewers. Thanks to their outstanding effort and commitment, every submission received a metareview and most received at least three reviews, providing authors of all submissions with constructive feedback. Although no review process is flawless, we are confident that this effort led to a vibrant conference program, capturing multiple voices and perspectives in the field.},
location = {Milan, Italy}
}

@proceedings{10.1145/3675417,
title = {DEAI '24: Proceedings of the 2024 Guangdong-Hong Kong-Macao Greater Bay Area International Conference on Digital Economy and Artificial Intelligence},
year = {2024},
isbn = {9798400717147},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Hongkong, China}
}

@article{10.1145/3654795,
author = {Lai, Huiyuan and Nissim, Malvina},
title = {A Survey on Automatic Generation of Figurative Language: From Rule-based Systems to Large Language Models},
year = {2024},
issue_date = {October 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {56},
number = {10},
issn = {0360-0300},
url = {https://doi.org/10.1145/3654795},
doi = {10.1145/3654795},
abstract = {Figurative language generation (FLG) is the task of reformulating a given text to include a desired figure of speech, such as a hyperbole, a simile, and several others, while still being faithful to the original context. This is a fundamental, yet challenging task in Natural Language Processing (NLP), which has recently received increased attention due to the promising performance brought by pre-trained language models. Our survey provides a systematic overview of the development of FLG, mostly in English, starting with the description of some common figures of speech, their corresponding generation tasks, and datasets. We then focus on various modelling approaches and assessment strategies, leading us to discussing some challenges in this field, and suggesting some potential directions for future research. To the best of our knowledge, this is the first survey that summarizes the progress of FLG including the most recent development in NLP. We also organize corresponding resources, e.g., article lists and datasets, and make them accessible in an open repository. We hope this survey can help researchers in NLP and related fields to easily track the academic frontier, providing them with a landscape and a roadmap of this area.},
journal = {ACM Comput. Surv.},
month = may,
articleno = {244},
numpages = {34},
keywords = {Figurative language, language generation, systematic review}
}

@article{10.1145/3642979.3643007,
author = {Wang, Haixun and Na, Taesik},
title = {Rethinking E-Commerce Search},
year = {2024},
issue_date = {December 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {57},
number = {2},
issn = {0163-5840},
url = {https://doi.org/10.1145/3642979.3643007},
doi = {10.1145/3642979.3643007},
abstract = {E-commerce search and recommendation usually operate on structured data such as product catalogs and taxonomies. However, creating better search and recommendation systems often requires a large variety of unstructured data including customer reviews and articles on the web. Traditionally, the solution has always been converting unstructured data into structured data through information extraction, and conducting search over the structured data. However, this is a costly approach that often has low quality. In this paper, we envision a solution that does entirely the opposite. Instead of converting unstructured data (web pages, customer reviews, etc) to structured data, we instead convert structured data (product inventory, catalogs, taxonomies, etc) into textual data, which can be easily integrated into the text corpus that trains LLMs. Then, search and recommendation can be performed through a Q/A mechanism through an LLM instead of using traditional information retrieval methods over structured data.},
journal = {SIGIR Forum},
month = jan,
articleno = {24},
numpages = {19}
}

@article{10.1109/TASLP.2024.3358053,
author = {Chen, Xiang and Li, Lei and Zhu, Yuqi and Deng, Shumin and Tan, Chuanqi and Huang, Fei and Si, Luo and Zhang, Ningyu and Chen, Huajun},
title = {Sequence Labeling as Non-Autoregressive Dual-Query Set Generation},
year = {2024},
issue_date = {2024},
publisher = {IEEE Press},
volume = {32},
issn = {2329-9290},
url = {https://doi.org/10.1109/TASLP.2024.3358053},
doi = {10.1109/TASLP.2024.3358053},
abstract = {Sequence labeling is a crucial task in the NLP community that aims at identifying and assigning spans within the input sentence. It has wide applications in various fields such as information extraction, dialogue system, and sentiment analysis. However, previously proposed span-based or sequence-to-sequence models conduct locating and assigning in order, resulting in problems of error propagation and unnecessary training loss, respectively. This paper addresses the problem by reformulating the sequence labeling as a non-autoregressive set generation to realize locating and assigning in parallel. Herein, we propose a &lt;bold&gt;D&lt;/bold&gt;ual-&lt;bold&gt;Q&lt;/bold&gt;uery &lt;bold&gt;Set&lt;/bold&gt; &lt;bold&gt;Gen&lt;/bold&gt;eration (&lt;monospace&gt;&lt;bold&gt;DQSetGen&lt;/bold&gt;&lt;/monospace&gt;) model for unified sequence labeling tasks. Specifically, the dual-query set, including a prompted type query and a positional query with anchor span, is fed into the non-autoregressive decoder to probe the spans which correspond to the positional query and have similar patterns with the type query. By avoiding the autoregressive nature of previous approaches, our method significantly improves efficiency and reduces error propagation. Experimental results illustrate that our approach can obtain superior performance on 5 sub-tasks across 11 benchmark datasets. The non-autoregressive nature of our method allows for parallel computation, achieving faster inference speed than compared baselines. In conclusion, our proposed non-autoregressive dual-query set generation method offers a more efficient and accurate approach to sequence labeling tasks in NLP. Its advantages in terms of performance and efficiency make it a promising solution for various applications in data mining and other related fields.},
journal = {IEEE/ACM Trans. Audio, Speech and Lang. Proc.},
month = feb,
pages = {1546–1558},
numpages = {13}
}

@inproceedings{10.1145/3677052.3698671,
author = {Sarmah, Bhaskarjit and Mehta, Dhagash and Hall, Benika and Rao, Rohan and Patel, Sunil and Pasquali, Stefano},
title = {HybridRAG: Integrating Knowledge Graphs and Vector Retrieval Augmented Generation for Efficient Information Extraction},
year = {2024},
isbn = {9798400710810},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3677052.3698671},
doi = {10.1145/3677052.3698671},
abstract = {Extraction and interpretation of intricate information from unstructured text data arising in financial applications, such as earnings call transcripts, present substantial challenges to large language models (LLMs) even using the current best practices to use Retrieval Augmented Generation (RAG) (referred to as VectorRAG techniques which utilize vector databases for information retrieval) due to challenges such as domain specific terminology and complex formats of the documents. We introduce a novel approach based on a combination, called HybridRAG, of the Knowledge Graphs (KGs) based RAG techniques (called GraphRAG) and VectorRAG techniques to enhance question-answer (Q&amp;A) systems for information extraction from financial documents that is shown to be capable of generating accurate and contextually relevant answers. Using experiments on a set of financial earning call transcripts documents which come in the form of Q&amp;A format, and hence provide a natural set of pairs of ground-truth Q&amp;As, we show that HybridRAG which retrieves context from both vector database and KG outperforms both traditional VectorRAG and GraphRAG individually when evaluated at both the retrieval and generation stages in terms of retrieval accuracy and answer generation. The proposed technique has applications beyond the financial domain.},
booktitle = {Proceedings of the 5th ACM International Conference on AI in Finance},
pages = {608–616},
numpages = {9},
location = {Brooklyn, NY, USA},
series = {ICAIF '24}
}

@proceedings{10.1145/3689217,
title = {LAMPS '24: Proceedings of the 1st ACM Workshop on Large AI Systems and Models with Privacy and Safety Analysis},
year = {2024},
isbn = {9798400712098},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {This volume contains papers presented at the 1st ACM Workshop on Large AI Systems and Models with Privacy and Safety Analysis (LAMPS), which was held on October 14, 2024, in Salt Lake City, USA.This year we received 18 paper submissions from Australia, China, Italy, Luxembourg, Singapore, South Korea, USA, and Vietnam, and 11 high-quality papers were accepted. Each contributed paper was rigorously peer-reviewed by reviewers who were drawn from a pool of expert technical committee members in machine learning security and privacy. Each paper received two detailed review comments and one meta review comments that summarise the weaknesses/issues to be addressed in the camera-ready revision or future work.},
location = {Salt Lake City, UT, USA}
}

@proceedings{10.1145/3677892,
title = {DSAI '24: Proceedings of the 2024 International Conference on Digital Society and Artificial Intelligence},
year = {2024},
isbn = {9798400709838},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Qingdao, China}
}

@article{10.1145/3645099,
author = {He, Weidong and Li, Zhi and Wang, Hao and Xu, Tong and Wang, Zhefeng and Huai, Baoxing and Yuan, Nicholas Jing and Chen, Enhong},
title = {Multimodal Dialogue Systems via Capturing Context-aware Dependencies and Ordinal Information of Semantic Elements},
year = {2024},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {3},
issn = {2157-6904},
url = {https://doi.org/10.1145/3645099},
doi = {10.1145/3645099},
abstract = {The topic of multimodal conversation systems has recently garnered significant attention across various industries, including travel and retail, among others. While pioneering works in this field have shown promising performance, they often focus solely on context information at the utterance level, overlooking the context-aware dependencies of multimodal semantic elements like words and images. Furthermore, the ordinal information of images, which indicates the relevance between visual context and users’ demands, remains underutilized during the integration of visual content. Additionally, the exploration of how to effectively utilize corresponding attributes provided by users when searching for desired products is still largely unexplored. To address these challenges, we propose PMATE, a Position-aware Multimodal diAlogue system with semanTic Elements. Specifically, to obtain semantic representations at the element level, we first unfold the multimodal historical utterances and devise a position-aware multimodal element-level encoder. This component considers all images that may be relevant to the current turn and introduces a novel position-aware image selector to choose related images before fusing the information from the two modalities. Finally, we present a knowledge-aware two-stage decoder and an attribute-enhanced image searcher for the tasks of generating textual responses and selecting image responses, respectively. We extensively evaluate our model on two large-scale multimodal dialogue datasets, and the results of our experiments demonstrate that our approach outperforms several baseline methods.},
journal = {ACM Trans. Intell. Syst. Technol.},
month = apr,
articleno = {45},
numpages = {25},
keywords = {Multimodal dialogue system, natural language generation, conversational image search}
}

@inproceedings{10.1145/3626772.3661372,
author = {Jiang, Cong and Chen, Zhongde and Zhang, Bo and Ren, Yankun and Dong, Xin and Cheng, Lei and Yang, Xinxing and Li, Longfei and Zhou, Jun and Mo, Linjian},
title = {GATS: Generative Audience Targeting System for Online Advertising},
year = {2024},
isbn = {9798400704314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626772.3661372},
doi = {10.1145/3626772.3661372},
abstract = {This paper presents GATS (&lt;u&gt;G&lt;/u&gt;enerative &lt;u&gt;A&lt;/u&gt;udience &lt;u&gt;T&lt;/u&gt;argeting &lt;u&gt;S&lt;/u&gt; ystem for Online Advertising), a new framework using large language models (LLMs) to improve audience targeting in online advertising. GATS overcomes the shortcomings of rule-based, look-alike, and graph-based methods by facilitating flexible and interpretable audience criteria expression. The framework integrates intent recognition, knowledge mining, and Data Management Platform (DMP) mapping to translate advertiser demands into actionable user tags and correlate them within a DMP. A small, white-box model called LightGATS (base on QWen-14B), fine-tuned with a high-quality LLM corpus, ensures the framework's safety and efficiency, operating within a scalable hybrid online-offline architecture. GATS's effectiveness is validated through extensive experiments, marking a significant advancement in audience targeting technology.},
booktitle = {Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {2920–2924},
numpages = {5},
keywords = {audience targeting, large language models, multi-task fine-tuning, online advertising},
location = {Washington DC, USA},
series = {SIGIR '24}
}

@proceedings{10.1145/3643795,
title = {LLM4Code '24: Proceedings of the 1st International Workshop on Large Language Models for Code},
year = {2024},
isbn = {9798400705793},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to the first edition of the InternationalWorkshop on Large Language Models for Code (LLM4Code). Large Language Models (LLMs), which are large-scale models being trained on massive textual corpora, have achieved significant advances in various domains, including Software Engineering (SE). Recently, there has been a growing interest in applying LLMs to assist software development and maintenance, such as code generation and comprehension, test generation, and program repair. Although the application of LLMs on code-relevant tasks has shown very promising performance, there is a huge potential to explore this growing domain further. The motivation of the LLM4Code workshop is to provide a platform for academics and practitioners to discuss and share their ideas on applying and developing LLMs to solve code-relevant problems in SE activities.The LLM4Code workshop is concerned with the research on how to better apply LLMs to solve code-relevant tasks, how to design better LLMs for code-relevant tasks, and how to better benchmark LLMs on code-relevant tasks. The workshop aims to achieve multiple goals as follows. Firstly, the workshop aims to provide an opportunity for participants to discuss novel ideas and preliminary results on LLMs for solving code-relevant SE problems, to exchange the latest progress in this domain. Secondly, the workshop aims to encourage participants to discuss the open challenges and problems of LLM4code, to identify important future directions in this domain. Finally, the workshop aims to encourage participants to share infrastructures and benchmarks that are foundational and beneficial for future research in this domain.},
location = {Lisbon, Portugal}
}

@proceedings{10.1145/3613905,
title = {CHI EA '24: Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Honolulu, HI, USA}
}

@proceedings{10.1145/3678698,
title = {VINCI '24: Proceedings of the 17th International Symposium on Visual Information Communication and Interaction},
year = {2024},
isbn = {9798400709678},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3630106,
title = {FAccT '24: Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency},
year = {2024},
isbn = {9798400704505},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Rio de Janeiro, Brazil}
}

@inproceedings{10.1145/3652620.3688224,
author = {Khalilipour, Alireza and Challenger, Moharram},
title = {Towards Intelligent Model Management: An Exploratory Study and Road-mapping},
year = {2024},
isbn = {9798400706226},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652620.3688224},
doi = {10.1145/3652620.3688224},
abstract = {With data science entering various domains, new branches are emerging due to the extraction of latent knowledge from each domain's data. Model-based engineering and modeling are no exceptions. Now is the time to open a new chapter in this field by leveraging advanced artificial intelligence techniques. As the number and complexity of models increase, NP-complete problems arise that cannot be effectively addressed through deterministic management solutions. An effective way to address these challenges is by applying non-deterministic intelligent methodologies and data science-derived solutions. The increasing number of models and the formation of large model repositories necessitate intelligent model management, which aims to recognize hidden patterns and knowledge within these repositories using data science, machine learning techniques, and statistical and probabilistic methods for reuse. Despite the progress made in this area, both theoretically and practically, intelligent model management has not yet secured a prominent place in the body of knowledge of model-driven engineering. In this paper, we aim to clarify the exact position of intelligent model management by providing precise definitions, distinguishing it from conventional management, and identifying associated challenges. The above objective outlines the research approach in this area, making it easy for researchers to comprehend the procedures they employ for conducting their investigations.},
booktitle = {Proceedings of the ACM/IEEE 27th International Conference on Model Driven Engineering Languages and Systems},
pages = {1015–1024},
numpages = {10},
keywords = {intelligent model management, model repositories, machine learning, model-driven engineering, model reuse},
location = {Linz, Austria},
series = {MODELS Companion '24}
}

@proceedings{10.1145/3675812,
title = {ICDEL '24: Proceedings of the 2024 9th International Conference on Distance Education and Learning},
year = {2024},
isbn = {9798400716805},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Guangzhou, China}
}

@proceedings{10.1145/3632754,
title = {FIRE '23: Proceedings of the 15th Annual Meeting of the Forum for Information Retrieval Evaluation},
year = {2023},
isbn = {9798400716324},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Panjim, India}
}

@proceedings{10.1145/3680127,
title = {ICEGOV '24: Proceedings of the 17th International Conference on Theory and Practice of Electronic Governance},
year = {2024},
isbn = {9798400717802},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3689492,
title = {Onward! '24: Proceedings of the 2024 ACM SIGPLAN International Symposium on New Ideas, New Paradigms, and Reflections on Programming and Software},
year = {2024},
isbn = {9798400712159},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to the 2024 ACM SIGPLAN International Symposium on New Ideas, New Paradigms, and Reflections on Programming and Software (Onward! 2024), the premier multidisciplinary conference focused on everything to do with programming and software, including processes, methods, languages, communities and applications. Onward! is more radical, more visionary and more open than other conferences to ideas that are well-argued but not yet proven. We welcome different ways of thinking about, approaching, and reporting on programming language and software engineering research.},
location = {Pasadena, CA, USA}
}

@proceedings{10.1145/3671127,
title = {BuildSys '24: Proceedings of the 11th ACM International Conference on Systems for Energy-Efficient Buildings, Cities, and Transportation},
year = {2024},
isbn = {9798400707063},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Hangzhou, China}
}

@book{10.1145/3664191,
author = {Kumar, Amruth N. and Raj, Rajendra K. and Aly, Sherif G. and Anderson, Monica D. and Becker, Brett A. and Blumenthal, Richard L. and Eaton, Eric and Epstein, Susan L. and Goldweber, Michael and Jalote, Pankaj and Lea, Douglas and Oudshoorn, Michael and Pias, Marcelo and Reiser, Susan and Servin, Christian and Simha, Rahul and Winters, Titus and Xiang, Qiao},
title = {Computer Science Curricula 2023},
year = {2024},
isbn = {9798400710339},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA}
}

@proceedings{10.1145/3691720,
title = {EKI '24: Proceedings of the 2nd International Conference on Educational Knowledge and Informatization},
year = {2024},
isbn = {9798400710230},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Shanghai, China}
}

@proceedings{10.1145/3679058,
title = {HUMAN '24: Proceedings of the 7th Workshop on Human Factors in Hypertext},
year = {2024},
isbn = {9798400711206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Poznan, Poland}
}

@inproceedings{10.1145/3664475.3664559,
author = {Malicki-S\'{a}nchez, Keram and Morie, Jacquelyn Ford and Panos, Gregory},
title = {Beyond Life and Death: Exploring Digital Legacy with Spatial Media, Emerging Technologies, and Evolving Ethics},
year = {2024},
isbn = {9798400706837},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664475.3664559},
doi = {10.1145/3664475.3664559},
abstract = {This course covers how we use technology to capture and preserve ourselves and others, and the philosophical, legal and ethical considerations involved.},
booktitle = {ACM SIGGRAPH 2024 Courses},
articleno = {9},
numpages = {29},
location = {Denver, CO, USA},
series = {SIGGRAPH Courses '24}
}

@proceedings{10.1145/3697355,
title = {BDIOT '24: Proceedings of the 2024 8th International Conference on Big Data and Internet of Things},
year = {2024},
isbn = {9798400717529},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@inproceedings{10.1145/3613905.3650791,
author = {Ma, Donghyeok and Lee, Joon Hyub and Bae, Seok-Hyung},
title = {Understanding Visual, Integrated, and Flexible Workspace for Comprehensive Literature Reviews with SketchingRelatedWork},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3650791},
doi = {10.1145/3613905.3650791},
abstract = {Writing an academic paper requires significant time and effort to find, read, and organize many related papers, which are complex knowledge tasks. We present a novel interactive system that allows users to perform these tasks quickly and easily on the 2D canvas with pen and multitouch inputs, turning users’ sketches and handwriting into node-link diagrams of papers and citations that users can iteratively expand in situ toward constructing a coherent narrative when writing Related Work sections. Through a pilot study involving researchers experienced in publishing academic papers, we show that our system can serve as a visual, integrated, and flexible workspace for conducting comprehensive literature reviews.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {348},
numpages = {7},
keywords = {Related work, inking, node-link diagram},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}

@proceedings{10.1145/3688268,
title = {ICCCM '24: Proceedings of the 2024 12th International Conference on Computer and Communications Management},
year = {2024},
isbn = {9798400718038},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@inproceedings{10.1145/3639477.3639743,
author = {Fakih, Mohamad and Dharmaji, Rahul and Moghaddas, Yasamin and Quiros, Gustavo and Ogundare, Oluwatosin and Al Faruque, Mohammad Abdullah},
title = {LLM4PLC: Harnessing Large Language Models for Verifiable Programming of PLCs in Industrial Control Systems},
year = {2024},
isbn = {9798400705014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639477.3639743},
doi = {10.1145/3639477.3639743},
abstract = {Although Large Language Models (LLMs) have established predominance in automated code generation, they are not devoid of shortcomings. The pertinent issues primarily relate to the absence of execution guarantees for generated code, a lack of explainability, and suboptimal support for essential but niche programming languages. State-of-the-art LLMs such as GPT-4 and LLaMa2 fail to produce valid programs for Industrial Control Systems (ICS) operated by Programmable Logic Controllers (PLCs). We propose LLM4PLC, a user-guided iterative pipeline leveraging user feedback and external verification tools - including grammar checkers, compilers and SMV verifiers - to guide the LLM's generation. We further enhance the generation potential of LLM by employing Prompt Engineering and model fine-tuning through the creation and usage of LoRAs. We validate this system using a FischerTechnik Manufacturing TestBed (MFTB), illustrating how LLMs can evolve from generating structurally-flawed code to producing verifiably correct programs for industrial applications. We run a complete test suite on GPT-3.5, GPT-4, Code Llama-7B, a fine-tuned Code Llama-7B model, Code Llama-34B, and a fine-tuned Code Llama-34B model. The proposed pipeline improved the generation success rate from 47% to 72%, and the Survey-of-Experts code quality from 2.25/10 to 7.75/10.To promote open research, we share the complete experimental setup, the LLM Fine-Tuning Weights, and the video demonstrations of the different programs on our dedicated webpage1.},
booktitle = {Proceedings of the 46th International Conference on Software Engineering: Software Engineering in Practice},
pages = {192–203},
numpages = {12},
keywords = {industrial control, verifiable synthesis, large language models, prompt engineering},
location = {Lisbon, Portugal},
series = {ICSE-SEIP '24}
}

@inproceedings{10.1145/3632754.3632943,
author = {Santra, Payel and Ghosh, Madhusudan and Mukherjee, Shrimon and Ganguly, Debasis and Basuchowdhuri, Partha and Naskar, Sudip Kumar},
title = {Unleashing the Power of Large Language Models: A Hands-On Tutorial},
year = {2024},
isbn = {9798400716324},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3632754.3632943},
doi = {10.1145/3632754.3632943},
abstract = {LLMs have opened up possibilities for advancing the state-of-the-art in natural language processing (NLP). In this tutorial, we present the audience with an introduction to LLMs and the associated challenges. The tutorial is structured in the following manner. First, we provide a brief preface that outlines the fundamental principles of NLP, following which, we explore the area of distributional representation learning for NLP. Then, we delve into the essential component of transformer-based pretrained language models. We then follow this up with the concept of prompt learning or in-context learning (ICL) and discuss how it is emerging as a popular methodology replacing the conventional supervised learning workflow comprised of pretraining and fine-tuning. We outline the research challenges in ICL, which usually involves finding the correct set of examples and contexts for the purpose of guiding the LLM decoder towards effective predictions. Afterwards, a hands-on coding and demonstration session will be carried out to impart practical knowledge about LLMs and ICL to the tutorial participants.},
booktitle = {Proceedings of the 15th Annual Meeting of the Forum for Information Retrieval Evaluation},
pages = {149–152},
numpages = {4},
keywords = {In-context Learning, Large Language Models, Natural Language Inferencing, Sentiment Analysis, Text Summarization},
location = {Panjim, India},
series = {FIRE '23}
}

@proceedings{10.1145/3626772,
title = {SIGIR '24: Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
year = {2024},
isbn = {9798400704314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to the 47th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR 2024), taking place in Washington D.C., USA, from July 14 to 18, 2024.SIGIR serves as the foremost international forum for the presentation of groundbreaking research findings, the demonstration of innovative systems and techniques, and the exploration of forwardthinking research directions in the field of information retrieval.This year's SIGIR is an in-person conference. We believe that an in-person conference is beneficial for several reasons: it fosters direct engagement and networking opportunities, enhances the exchange of research ideas, contributes to a more dynamic and productive conference experience, and nurtures our research community by welcoming newcomers, providing them with the opportunity to become acquainted with SIGIR traditions. This decision has not been made lightly. We understand the challenges that can pose in the aftermath of a pandemic and amidst the uncertainties of the world around us. To accommodate those who cannot attend, we have implemented a series of measures such as proxy presenters, livestreaming, and recording sessions. These steps are taken to ensure that everyone has access to the valuable content that the conference offers.},
location = {Washington DC, USA}
}

@inproceedings{10.1145/3664647.3680760,
author = {Liu, Rui and Li, Mingjie and Zhao, Shen and Chen, Ling and Chang, Xiaojun and Yao, Lina},
title = {In-Context Learning for Zero-shot Medical Report Generation},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3680760},
doi = {10.1145/3664647.3680760},
abstract = {Medical report generation (MRG) has emerged as a pivotal research topic in the medical multi-modal field, given its potential to alleviate the heavy workloads of radiologists. Recently, advancements have been made with MRG systems that leverage large multimodal models (LMMs) to generate high-quality reports. To address the challenge of collecting large amounts of paired medical image-report data for training, this paper proposes a zero-shot report generation model based on in-context learning, we call it MCVGen. Departing from traditional in-context learning approaches that directly feed all demonstrations to a pre-trained large model, this work innovates by employing a multi-modal contextual vector (MCV) to represent the contextual information of demonstrations. Initially, we pre-train a medical large multi-modal model (Med-LMM) and secure the last hidden state of each demonstration through the forward pass in Med-LMM. Benefits from the auto-regressive mechanism, the last hidden state garners critical information to the targeted scenarios. Subsequently, we average the multiple MCVs and integrate them with the first hidden state on the new query, thereby shifting the latent states and guiding the model toward acquiring previously unlearned multi-modal contextual information. This approach has the advantage of regulating the number of prompts, thus reducing computational costs. We tested our model on the publicly available IU X-ray and MIMIC datasets, demonstrating its exceptional zero-shot capability on both cross-center and cross-disease evaluations. We hope it could be a viable solution for practical clinical applications.},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {8721–8730},
numpages = {10},
keywords = {large multi-modal model, medical report generation, multi-modal in-context learning, zero-shot},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@article{10.1145/3649451,
author = {Du, Kelvin and Xing, Frank and Mao, Rui and Cambria, Erik},
title = {Financial Sentiment Analysis: Techniques and Applications},
year = {2024},
issue_date = {September 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {56},
number = {9},
issn = {0360-0300},
url = {https://doi.org/10.1145/3649451},
doi = {10.1145/3649451},
abstract = {Financial Sentiment Analysis (FSA) is an important domain application of sentiment analysis that has gained increasing attention in the past decade. FSA research falls into two main streams. The first stream focuses on defining tasks and developing techniques for FSA, and its main objective is to improve the performances of various FSA tasks by advancing methods and using/curating human-annotated datasets. The second stream of research focuses on using financial sentiment, implicitly or explicitly, for downstream applications on financial markets, which has received more research efforts. The main objective is to discover appropriate market applications for existing techniques. More specifically, the application of FSA mainly includes hypothesis testing and predictive modeling in financial markets. This survey conducts a comprehensive review of FSA research in both the technique and application areas and proposes several frameworks to help understand the two areas’ interactive relationship. This article defines a clearer scope for FSA studies and conceptualizes the FSA-investor sentiment-market sentiment relationship. Major findings, challenges, and future research directions for both FSA techniques and applications have also been summarized and discussed.},
journal = {ACM Comput. Surv.},
month = apr,
articleno = {220},
numpages = {42},
keywords = {Financial sentiment analysis, financial forecasting, natural language processing, information system, machine learning, deep learning}
}

@inproceedings{10.1145/3680127.3680130,
author = {Maratsi, Maria Ioanna and Alexopoulos, Charalampos and Charalabidis, Yannis},
title = {On the Semantic Analysis of Open (Government) Data Portals’ Metadata Provision and Schema},
year = {2024},
isbn = {9798400717802},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3680127.3680130},
doi = {10.1145/3680127.3680130},
abstract = {The ever-increasing amount of data available through Open Data portals follows the momentum and proliferation of Open Data initiatives and, apart from the numerous benefits offered, poses a reality which brings forth several challenges. Metadata quality and management are key aspects in this regard; in their absence affecting the interoperability, findability, and consequently, open data consumption. The present study aims to analyse several semantic aspects of 3 major international data portals and their metadata schemas mapped to the main DCAT schema classes in order to assess the current status regarding metadata provision and aiming towards prospective standardisation and improved semantic interoperability of the datasets available. The analysis revealed several persisting challenges, including the lack of standardised information (e.g., controlled vocabularies) as accepted values of the identified mandatory metadata fields in use, or, in the case of existing standardisation schemas, a misalignment and lack of consensus among the different portals. The study also pinpoints future research lines centred around the elicitation of guidelines and practices to standardise not only descriptive but also domain-specific metadata provision across the portals, facilitating the process towards the identification of minimum sets of metadata descriptions applicable to various contexts, and reaching one step closer to the envisioned interoperable ODPs paradigm.},
booktitle = {Proceedings of the 17th International Conference on Theory and Practice of Electronic Governance},
pages = {147–157},
numpages = {11},
location = {
},
series = {ICEGOV '24}
}

@proceedings{10.1145/3629606,
title = {CHCHI '23: Proceedings of the Eleventh International Symposium of Chinese CHI},
year = {2023},
isbn = {9798400716454},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Denpasar, Bali, Indonesia}
}

@proceedings{10.1145/3689218,
title = {PRIS '24: Proceedings of the 2024 6th International Conference on Pattern Recognition and Intelligent Systems},
year = {2024},
isbn = {9798400718250},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Hong Kong, Hong Kong}
}

@proceedings{10.1145/3688671,
title = {SETN '24: Proceedings of the 13th Hellenic Conference on Artificial Intelligence},
year = {2024},
isbn = {9798400709821},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@article{10.1145/3674971,
author = {Ellouze, Mourad and Hadrich Belguith, Lamia},
title = {Artificial Intelligence application for the analysis of personality traits and disorders in social media: A Survey},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {2375-4699},
url = {https://doi.org/10.1145/3674971},
doi = {10.1145/3674971},
abstract = {Personality analysis has a positive influence on humanity as it aids in identifying personality traits and disorders. In addition, it facilitates the monitoring of cases and enriches doctors’ knowledge bases, particularly in decision-making processes. This study includes a comprehensive literature review on personality analysis approaches from social media, aiming to gain a thorough understanding of the current studies on personality therapy. Moreover, the objective of this study is to identify various limitations present in these studies and explore potential avenues for enhancement. More specifically, this research begins with an introduction that discusses the main concepts of traits and personality disorders, as well as the importance of psychological analysis. Following that, four cluster studies related to personality analysis on social media are presented: personality traits, personality disorders, detection of links between diseases, and monitoring patient status. Then, the majority of the currently available works for each cluster are exposed. Afterward, a comparative study of the different presented works is proposed. Finally, an outline of plans for further research in this area is provided, detailing potential paths for exploration.},
note = {Just Accepted},
journal = {ACM Trans. Asian Low-Resour. Lang. Inf. Process.},
month = jun,
keywords = {Social Media, Personality Traits, Personality Disorders, Artificial Intelligence, Text Mining, Natural Language Processing}
}

@proceedings{10.1145/3654777,
title = {UIST '24: Proceedings of the 37th Annual ACM Symposium on User Interface Software and Technology},
year = {2024},
isbn = {9798400706288},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Pittsburgh, PA, USA}
}

@article{10.1145/3651983,
author = {Rong, Huan and Chen, Zhongfeng and Lu, Zhenyu and Xu, Fan and Sheng, Victor S},
title = {Multization: Multi-Modal Summarization Enhanced by Multi-Contextually Relevant and Irrelevant Attention Alignment},
year = {2024},
issue_date = {May 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {5},
issn = {2375-4699},
url = {https://doi.org/10.1145/3651983},
doi = {10.1145/3651983},
abstract = {This article focuses on the task of Multi-Modal Summarization with Multi-Modal Output for China JD.COM e-commerce product description containing both source text and source images. In the context learning of multi-modal (text and image) input, there exists a semantic gap between text and image, especially in the cross-modal semantics of text and image. As a result, capturing shared cross-modal semantics earlier becomes crucial for multi-modal summarization. However, when generating the multi-modal summarization, based on the different contributions of input text and images, the relevance and irrelevance of multi-modal contexts to the target summary should be considered, so as to optimize the process of learning cross-modal context to guide the summary generation process and to emphasize the significant semantics within each modality. To address the aforementioned challenges, Multization has been proposed to enhance multi-modal semantic information by multi-contextually relevant and irrelevant attention alignment. Specifically, a Semantic Alignment Enhancement mechanism is employed to capture shared semantics between different modalities (text and image), so as to enhance the importance of crucial multi-modal information in the encoding stage. Additionally, the IR-Relevant Multi-Context Learning mechanism is utilized to observe the summary generation process from both relevant and irrelevant perspectives, so as to form a multi-modal context that incorporates both text and image semantic information. The experimental results in the China JD.COM e-commerce dataset demonstrate that the proposed Multization method effectively captures the shared semantics between the input source text and source images, and highlights essential semantics. It also successfully generates the multi-modal summary (including image and text) that comprehensively considers the semantics information of both text and image.},
journal = {ACM Trans. Asian Low-Resour. Lang. Inf. Process.},
month = may,
articleno = {69},
numpages = {29},
keywords = {Business intelligence, multi-modal summarization, semantic enhancement and attention, multi-modal cross learning}
}

@inproceedings{10.1145/3640310.3674085,
author = {Ben Chaaben, Meriem and Ben Sghaier, Oussama and Dhaouadi, Mouna and Elrasheed, Nafisa and Darif, Ikram and Jaoua, Imen and Oakes, Bentley and Syriani, Eugene and Hamdaqa, Mohammad},
title = {Toward Intelligent Generation of Tailored Graphical Concrete Syntax},
year = {2024},
isbn = {9798400705045},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3640310.3674085},
doi = {10.1145/3640310.3674085},
abstract = {In model-driven engineering, the concrete syntax of a domain-specific modeling language (DSML) is fundamental as it constitutes the primary point of interaction between the user and the DSML. Nevertheless, the conventional one-size-fits-all approach to concrete syntax often undermines the effectiveness of DSMLs, as it fails to accommodate the diverse constraints and specific requirements inherent to diverse users and usage contexts. Such shortcomings can lead to a significant decline in the performance, usability, and efficiency of DSMLs. This vision paper proposes a conceptual framework to generate concrete syntax intelligently. Our framework considers multiple concerns of users and aims to align the concrete syntax with the context of the DSML usage. Additionally, we detail a baseline process to employ our framework in practice, leveraging large language models to expedite the generation of tailored concrete syntax. We illustrate the potential of our vision with two concrete examples and discuss the shortcomings and research challenges of current intelligent generation techniques.},
booktitle = {Proceedings of the ACM/IEEE 27th International Conference on Model Driven Engineering Languages and Systems},
pages = {160–171},
numpages = {12},
keywords = {Artificial Intelligence, Concrete Syntax, Domain-specific Modeling Languages, Large Language Models},
location = {Linz, Austria},
series = {MODELS '24}
}

@inproceedings{10.1145/3689236.3696039,
author = {Wu, Jing and Guo, Zhenxin and Wang, Zhicheng and Zhang, Haotian and Kang, Xaolin and Ma, Xiaoguang},
title = {Design and Implementation of Embedded Qinghai Tourism Customer Service Question-and-Answer Robot Based on ChatGPT},
year = {2024},
isbn = {9798400718137},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689236.3696039},
doi = {10.1145/3689236.3696039},
abstract = {The application of big data technology has brought new impetus and possibilities to the development of tourism. The design of an embedded Q&amp;A robot system for Qinghai tourism customer service based on ChatGPT system aims to provide an intelligent customer service solution to help users obtain information about Qinghai tourism and answer questions. The system uses ChatGPT as the core dialogue model, combines the knowledge and data in the field of Qinghai tourism, and realizes the intelligent answer to user questions. This study application in the field of natural language processing, and analyzes the design requirements and implementation scheme of embedded travel question answering system in detail. The function module includes user login and registration, travel tickets, hotel information query, scenic spot ticket price query and other essential basic function modules of the tourism website. Whether the design is reasonable or not will also directly affect the user experience. The results show that ChatGPT embedded in Qinghai tourism Q&amp;A system can not only provide more intelligent and accurate answers, but also enhance the interactivity and practicability of the system, and provide users with more convenient and personalized tourism information services.},
booktitle = {Proceedings of the 2024 9th International Conference on Cyber Security and Information Engineering},
pages = {871–882},
numpages = {12},
keywords = {ChatGPT, Chatbot, Generative Artificial Intelligence, Qinghai Tourism},
location = {
},
series = {ICCSIE '24}
}

@inproceedings{10.1145/3589334.3645623,
author = {Bai, Yuyang and Feng, Shangbin and Balachandran, Vidhisha and Tan, Zhaoxuan and Lou, Shiqi and He, Tianxing and Tsvetkov, Yulia},
title = {KGQuiz: Evaluating the Generalization of Encoded Knowledge in Large Language Models},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3645623},
doi = {10.1145/3589334.3645623},
abstract = {Large language models (LLMs) demonstrate remarkable performance on knowledge-intensive tasks, suggesting that real-world knowledge is encoded in their model parameters. However, besides explorations on a few probing tasks in limited knowledge domains, it is not well understood how to evaluate LLMs' knowledge systematically and how well their knowledge abilities generalize, across a spectrum of knowledge domains and progressively complex task formats. To this end, we propose KGQuiz, a knowledge-intensive benchmark to comprehensively investigate the knowledge generalization abilities of LLMs. KGQuiz is a scalable framework constructed from triplet-based knowledge, which covers three knowledge domains and consists of five tasks with increasing complexity: true-or-false, multiple-choice QA, blank filling, factual editing, and open-ended knowledge generation. To gain a better understanding of LLMs' knowledge abilities and their generalization, we evaluate 10 open-source and black-box LLMs on the KGQuiz benchmark across the five knowledge-intensive tasks and knowledge domains. Extensive experiments demonstrate that LLMs achieve impressive performance in straightforward knowledge QA tasks, while settings and contexts requiring more complex reasoning or employing domain-specific facts still present significant challenges. We envision KGQuiz as a testbed to analyze such nuanced variations in performance across domains and task formats, and ultimately to understand, evaluate, and improve LLMs' knowledge abilities across a wide spectrum of knowledge domains and tasks.},
booktitle = {Proceedings of the ACM Web Conference 2024},
pages = {2226–2237},
numpages = {12},
keywords = {knowledge probing, large language models},
location = {Singapore, Singapore},
series = {WWW '24}
}

@proceedings{10.1145/3678717,
title = {SIGSPATIAL '24: Proceedings of the 32nd ACM International Conference on Advances in Geographic Information Systems},
year = {2024},
isbn = {9798400711077},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {These proceedings contain the papers from the 32nd ACM SIGSPATIAL International Conference on Advances in Geographic Information Systems (ACM SIGSPATIAL 2024), held as an in-person event in Atlanta, GA, USA on October 29- November 01, 2024. SIGSPATIAL academics, students, and industry practitioners could attend the technical talks in-person, meet in the hallway for further discussions, and boost their professional network over lunch.},
location = {Atlanta, GA, USA}
}

@proceedings{10.1145/3655497,
title = {ICIAI '24: Proceedings of the 2024 International Conference on Innovation in Artificial Intelligence},
year = {2024},
isbn = {9798400709302},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Tokyo, Japan}
}

@inproceedings{10.1145/3679058.3688633,
author = {Atzenbeck, Claus and Eidloth, Lisa},
title = {Harnessing Hypertext Paradigms to Augment VR Spaces},
year = {2024},
isbn = {9798400711206},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3679058.3688633},
doi = {10.1145/3679058.3688633},
abstract = {This paper explores the integration of hypertext structures within Virtual Reality (VR) environments, differentiating between two distinct design philosophies: VR as a native framework for 3D embodiment-enabled spaces similar to traditional 2D spatial hypertext, and utilizing hypertext to enhance VR experiences. Focusing on the latter approach, we propose an abstract knowledge layer that bridges typical VR systems and human thinking, thus facilitating the integration of human cognitive capabilities. Finally, we explore ethical implications of VR systems that arise in the presented context and propose hypertext as a paradigm to address some of these concerns.},
booktitle = {Proceedings of the 7th Workshop on Human Factors in Hypertext},
articleno = {5},
numpages = {10},
keywords = {Mother, VR, archeology, augmentation, cognitive maps, collaboration, digital twins, ethics, hypertext, note taking, spatial hypertext, virtual reality},
location = {Poznan, Poland},
series = {HUMAN '24}
}

@inproceedings{10.1145/3641234.3671068,
author = {Lee, Sin-Fei and Chi, Ming-Te},
title = {Illusory Eyescape - Exploring the Variations of Consciousness through Generative Art and Eye-Tracking Techniques},
year = {2024},
isbn = {9798400705168},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641234.3671068},
doi = {10.1145/3641234.3671068},
abstract = {Historically, art has been considered a form of expression uniquely reserved for humans. However, technological advances, particularly in computer graphics, have expanded the boundaries of artistic creation beyond human exclusivity. The emergence of Generative Art in recent years has not only transformed the artistic process but has also initiated extensive dialogues on the interactions between humans and machines. To delve deeper into this theme, we developed an interactive art installation titled "Illusory Eyescape." This installation integrates Generative Art and Eye-tracking Technologies to probe the fundamental nature of consciousness in humans and machines, questioning the role of art in this new epoch of human-machine synergy. This exploration broadens our comprehension of the potential amalgamations of art and technology and challenges our conventional perceptions of art.},
booktitle = {ACM SIGGRAPH 2024 Posters},
articleno = {13},
numpages = {2},
keywords = {Eye-tracking, Generative Art, Interactive Art},
location = {Denver, CO, USA},
series = {SIGGRAPH '24}
}

@inproceedings{10.1145/3613904.3642887,
author = {Chen, Liuqing and Jiang, Zhaojun and Xia, Duowei and Cai, Zebin and Sun, Lingyun and Childs, Peter and Zuo, Haoyu},
title = {BIDTrainer: An LLMs-driven Education Tool for Enhancing the Understanding and Reasoning in Bio-inspired Design},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642887},
doi = {10.1145/3613904.3642887},
abstract = {Bio-inspired design (BID) fosters innovations in engineering. Learning BID is crucial for developing multidisciplinary innovation skills of designers and engineers. Current BID education aims to enhance learners’ understanding and analogical reasoning skills. However, it often heavily relies on the teachers’ expertise. When learners pursue independent learning using some educational tools, they face challenges in understanding and reasoning practice within this multidisciplinary field. Additionally, evaluating their learning outcomes comprehensively becomes problematic. Addressing these challenges, we introduce a LLMs-driven BID education method based on a structured ontology and three strategies: enhancing understanding through LLMs-enpowered "learning by asking", assisting reasoning by providing hints and feedback, and assessing learning outcomes through benchmarking against existing BID cases. Implementing the method, we developed BIDTrainer, a BID education tool. User studies indicate that learners using BIDTrainer understood BID knowledge better, reason faster with higher interactivity than the baseline, and BIDTrainer assessed the learning outcomes consistent with experts.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {676},
numpages = {20},
keywords = {Analogy training, Bio-inspired design, Design education, Design evaluation},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3701571.3701588,
author = {Kronhardt, Kirill and Rolfes, Kevin and Gerken, Jens},
title = {Trickery: Exploring a Serious Game Approach to Raise Awareness of Deceptive Patterns},
year = {2024},
isbn = {9798400712838},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701571.3701588},
doi = {10.1145/3701571.3701588},
abstract = {Deceptive patterns are often used in interface design to manipulate users into taking actions they would not otherwise take, such as consenting to excessive data collection. We present Trickery, a narrative serious game that incorporates seven gamified deceptive patterns. We designed the game as a potential mechanism for raising awareness of, and increasing resistance to, deceptive patterns through direct consequences of player actions. We conducted an explorative gameplay study to examine player behavior when confronted with the game Trickery. In addition, we conducted an online survey to shed light on the perceived helpfulness of our gamified deceptive patterns. Our results reveal different player motivations and driving forces that players used to justify their behavior when confronted with deceptive patterns in the Trickery game. In addition, we identified several influencing factors that need to be considered when adapting deceptive patterns into gameplay. Overall, the approach appears to be a promising solution for increasing user understanding and awareness of deceptive patterns.},
booktitle = {Proceedings of the International Conference on Mobile and Ubiquitous Multimedia},
pages = {133–147},
numpages = {15},
keywords = {education, privacy, dark patterns, deceptive patterns, serious games, awareness},
location = {
},
series = {MUM '24}
}

@inproceedings{10.1145/3637528.3671454,
author = {Zheng, Lecheng and Jing, Baoyu and Li, Zihao and Tong, Hanghang and He, Jingrui},
title = {Heterogeneous Contrastive Learning for Foundation Models and Beyond},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671454},
doi = {10.1145/3637528.3671454},
abstract = {In the era of big data and Artificial Intelligence, an emerging paradigm is to utilize contrastive self-supervised learning to model large-scale heterogeneous data. Many existing foundation models benefit from the generalization capability of contrastive self-supervised learning by learning compact and high-quality representations without relying on any label information. Amidst the explosive advancements in foundation models across multiple domains, including natural language processing and computer vision, a thorough survey on heterogeneous contrastive learning for the foundation model is urgently needed. In response, this survey critically evaluates the current landscape of heterogeneous contrastive learning for foundation models, highlighting the open challenges and future trends of contrastive learning. In particular, we first present how the recent advanced contrastive learning-based methods deal with view heterogeneity and how contrastive learning is applied to train and fine-tune the multi-view foundation models. Then, we move to contrastive learning methods for task heterogeneity, including pretraining tasks and downstream tasks, and show how different tasks are combined with contrastive learning loss for different purposes. Finally, we conclude this survey by discussing the open challenges and shedding light on the future directions of contrastive learning.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {6666–6676},
numpages = {11},
keywords = {contrastive learning, foundation model, multi-task learning, heterogeneous learning, multi-view learning},
location = {Barcelona, Spain},
series = {KDD '24}
}

@proceedings{10.1145/3627508,
title = {CHIIR '24: Proceedings of the 2024 Conference on Human Information Interaction and Retrieval},
year = {2024},
isbn = {9798400704345},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Sheffield, United Kingdom}
}

@article{10.1109/TASLP.2024.3487409,
author = {Wei, Yuting and Hu, Linmei and Zhu, Yangfu and Zhao, Jiaqi and Wu, Bin},
title = {Knowledge-Guided Transformer for Joint Theme and Emotion Classification of Chinese Classical Poetry},
year = {2024},
issue_date = {2024},
publisher = {IEEE Press},
volume = {32},
issn = {2329-9290},
url = {https://doi.org/10.1109/TASLP.2024.3487409},
doi = {10.1109/TASLP.2024.3487409},
abstract = {The classifications of the theme and emotion are essential for understanding and organizing Chinese classical poetry. Existing works often overlook the rich semantic knowledge derived from poem annotations, which contain crucial insights into themes and emotions and are instrumental in semantic understanding. Additionally, the complex interdependence and diversity of themes and emotions within poems are frequently disregarded. Hence, this paper introduces a Poetry Knowledge-augmented Joint Model (Poka) specifically designed for the multi-label classification of themes and emotions in Chinese classical poetry. Specifically, we first employ an automated approach to construct two semantic knowledge graphs for theme and emotion. These graphs facilitate a deeper understanding of the poems by bridging the semantic gap between the obscure ancient words and their modern Chinese counterparts. Representations related to themes and emotions are then acquired through a knowledge-guided mask-transformer. Moreover, Poka leverages the inherent correlations between themes and emotions by adopting a joint classification strategy with shared training parameters. Extensive experiments demonstrate that our model achieves state-of-the-art performance on both theme and emotion classifications, especially on tail labels.},
journal = {IEEE/ACM Trans. Audio, Speech and Lang. Proc.},
month = oct,
pages = {4783–4794},
numpages = {12}
}

@inproceedings{10.1145/3677525.3678695,
author = {Altammami, Alaa and Dimitrova, Vania and Pournaras, Evangelos},
title = {What you see, What you get? Mapping Inconsistencies of Sustainability Judgements among Experts and Consumers},
year = {2024},
isbn = {9798400710940},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3677525.3678695},
doi = {10.1145/3677525.3678695},
abstract = {Addressing sustainability issues requires collective action, with individuals playing a crucial role. Despite a willingness to shop responsibly, people lack the knowledge needed to make informed decisions, this information gap underpins the intention-behaviour gap. Online shopping, now dominant, can offer rich sustainability information. However, consumers, especially those new to the sustainability domain, face challenges in comprehending this information due to its complexity and volume, including confusion over the meaning of ecolabels. Product descriptions are a key decision-making resource, yet there is no significant research analysing their sustainability content or their potential for seamless in-situ/situated learning. We propose a framework using a Taxonomy for Product Sustainability (TPS) to automatically extract and analyse sustainability profiles from product descriptions. By comparing these profiles with expert judgements, we identify how alignments can be seen as an opportunity to enhance consumer awareness and how misalignments can introduce cognitive biases that impede ethical shopping. Our analysis of food product descriptions reveals distinct patterns of agreement and disagreement, highlighting cognitive biases that affect consumer decisions. These biases, driven by misalignment and information overload, contribute to the intention-behaviour gap in sustainable shopping. By identifying specific areas of confusion, we suggest targeted interventions, such as informative prompts, to facilitate seamless learning and improve consumer knowledge, eventually promoting more informed and ethical choices.},
booktitle = {Proceedings of the 2024 International Conference on Information Technology for Social Good},
pages = {443–452},
numpages = {10},
keywords = {Consumer Decision Making, Ethical Consumption, Learning., Online Information, Sustainability Taxonomy},
location = {Bremen, Germany},
series = {GoodIT '24}
}

@inproceedings{10.1145/3648188.3675152,
author = {Li, Ge and Vachtsevanou, Danai and Lem\'{e}e, J\'{e}r\'{e}my and Mayer, Simon and Strecker, Jannis},
title = {Reader-aware Writing Assistance through Reader Profiles},
year = {2024},
isbn = {9798400705953},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3648188.3675152},
doi = {10.1145/3648188.3675152},
abstract = {Establishing rapport between authors and readers of scientific texts is essential for supporting readers in understanding texts as intended, facilitating socio-discursive practices within disciplinary communities, and helping in identifying interdisciplinary links among scientific writings. We propose a Reader-aware Congruence Assistant (RaCA), which supports writers to create texts that are adapted to target readers. Similar to user-centered design which is based on user profiles, RaCA features reader-centered writing through reader profiles that are dynamically computed from information discovered through academic search engines. Our assistant then leverages large language models to measure the congruence of a written text with a given reader profile, and provides feedback to the writer. We demonstrate our approach with an implemented prototype that illustrates how RaCA exploits information available on the Web to construct reader profiles, assesses writer-reader congruence and offers writers color-coded visual feedback accordingly. We argue that our approach to reader-oriented scientific writing paves the way towards the more personalized interaction of readers and writers with scientific content, and discuss how integration with Semantic Web technologies and Adaptive User Interface design can help materialize this vision within an ever-growing Web of scientific ideas, proof, and discourse.},
booktitle = {Proceedings of the 35th ACM Conference on Hypertext and Social Media},
pages = {344–350},
numpages = {7},
keywords = {Natural Language Processing, Personalized Text Adaptation, Reader Profile, Text Congruence},
location = {Poznan, Poland},
series = {HT '24}
}

@inproceedings{10.1145/3589334.3645678,
author = {Sun, Qi and Huang, Kun and Yang, Xiaocui and Tong, Rong and Zhang, Kun and Poria, Soujanya},
title = {Consistency Guided Knowledge Retrieval and Denoising in LLMs for Zero-shot Document-level Relation Triplet Extraction},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3645678},
doi = {10.1145/3589334.3645678},
abstract = {Document-level Relation Triplet Extraction (DocRTE) is a fundamental task in information systems that aims to simultaneously extract entities with semantic relations from a document. Existing methods heavily rely on a substantial amount of fully labeled data. However, collecting and annotating data for newly emerging relations is time-consuming and labor-intensive. Recent advanced Large Language Models (LLMs), such as ChatGPT and LLaMA, exhibit impressive long-text generation capabilities, inspiring us to explore an alternative approach for obtaining auto-labeled documents with new relations. In this paper, we propose a Zero-shot Document-level Relation Triplet Extraction (ZeroDocRTE) framework, which Generates labeled data by Retrieval and Denoising Knowledge from LLMs, called GenRDK. Specifically, we propose a chain-of-retrieval prompt to guide ChatGPT to generate labeled long-text data step by step. To improve the quality of synthetic data, we propose a denoising strategy based on the consistency of cross-document knowledge. Leveraging our denoised synthetic data, we proceed to fine-tune the LLaMA2-13B-Chat for extracting document-level relation triplets. We perform experiments for both zero-shot document-level relation and triplet extraction on two public datasets. The experimental results illustrate that our GenRDK framework outperforms strong baselines.},
booktitle = {Proceedings of the ACM Web Conference 2024},
pages = {4407–4416},
numpages = {10},
keywords = {document-level relation triplet extraction, knowledge denoising, large language models, synthetic data, zero-shot learning},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3652988.3696195,
author = {Origlia, Antonio and Di Maro, Maria},
title = {A Linguistically Motivated Approach to Hybrid Conversational AI with the FANTASIA Plugin},
year = {2024},
isbn = {9798400706257},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652988.3696195},
doi = {10.1145/3652988.3696195},
abstract = {This paper presents an installation showcasing the basic concepts of the FANTASIA tool and the Interaction Model built around it. The tool itself can be used in a variety of ways, through the modular set of components it provides to extend the capabilities of a powerful engine for Real Time Interactive 3D applications, the Unreal Engine. The Interaction Model represents how FANTASIA can be used to build linguistically motivated models for dialogue management, going beyond the use of statistical learning only. Specifically, an explicit separation between language modelling capabilities and decision making will be described for movie recommendations.},
booktitle = {Proceedings of the 24th ACM International Conference on Intelligent Virtual Agents},
articleno = {46},
numpages = {3},
keywords = {Conversational AI, Hybrid AI, Linguistics, Unreal Engine},
location = {GLASGOW, United Kingdom},
series = {IVA '24}
}

@proceedings{10.1145/3663548,
title = {ASSETS '24: Proceedings of the 26th International ACM SIGACCESS Conference on Computers and Accessibility},
year = {2024},
isbn = {9798400706776},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {St. John's, NL, Canada}
}

@inproceedings{10.1145/3637528.3671466,
author = {Deng, Songgaojun and de Rijke, Maarten and Ning, Yue},
title = {Advances in Human Event Modeling: From Graph Neural Networks to Language Models},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671466},
doi = {10.1145/3637528.3671466},
abstract = {Human events such as hospital visits, protests, and epidemic outbreaks directly affect individuals, communities, and societies. These events are often influenced by factors such as economics, politics, and public policies of our society. The abundance of online data sources such as social networks, official news articles, and personal blogs chronicle societal events, facilitating the development of AI models for social science, public health care, and decision making. Human event modeling generally comprises both the forecasting stage, which estimates future events based on historical data, and interpretation, which seeks to identify influential factors of such events to understand their causative attributes. Recent achievements, fueled by deep learning and the availability of public data, have significantly advanced the field of human event modeling.This survey offers a systematic overview of deep learning technologies for forecasting and interpreting human events, with a primary focus on political events. We first introduce the existing challenges and background in this domain. We then present the problem formulation of event forecasting and interpretation. We investigate recent achievements in graph neural networks, owing to the prevalence of relational data and the efficacy of graph learning models. We also discuss the latest studies that utilize large language models for event reasoning. Lastly, we provide summaries of data resources, open challenges, and future research directions in the study of human event modeling.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {6459–6469},
numpages = {11},
keywords = {event forecasting, graph neural networks, language models},
location = {Barcelona, Spain},
series = {KDD '24}
}

@inproceedings{10.1145/3675417.3675447,
author = {Lv, Han and Wang, Kun},
title = {A study of AIGC-enabled international marketing},
year = {2024},
isbn = {9798400717147},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3675417.3675447},
doi = {10.1145/3675417.3675447},
abstract = {The intelligent transformation and development of domestic small and medium-sized manufacturing enterprises is of great significance for transferring internal production capacity, enhancing the level of opening up to the outside world, and promoting the high-quality development of the foreign trade industry.The development of AIGC (Artificial Intelligence Generated Content) is not only a major technological breakthrough in the field of artificial intelligence, but also its highly efficient content production drives the generation of new intelligent export methods in the manufacturing industry. Through the mass generation of text, the use of pre-training models as well as the development and optimization of cue words, to the manufacturing and exporting enterprises to output content in line with SEO (Search Engine Optimization) rules, through the optimization of internal and external chains to improve search engine rankings, so as to enhance the overseas visibility of the enterprise's products, and to open up the sales of the products. Based on the mechanism analysis of economics and management perspective, AIGC can provide professional and in-depth website enhancement diagnostic solutions and key optimization for foreign trade enterprises on a regular basis through the revolution of content production, so as to enhance the export efficiency and competitiveness of foreign trade enterprises. Therefore, the application of AIGC technology in foreign trade enterprises should be promoted, and AIGC technology providers should be encouraged to strengthen the training of large models in different industries, so as to provide specialized technical support for export enterprises.},
booktitle = {Proceedings of the 2024 Guangdong-Hong Kong-Macao Greater Bay Area International Conference on Digital Economy and Artificial Intelligence},
pages = {179–191},
numpages = {13},
location = {Hongkong, China},
series = {DEAI '24}
}

@proceedings{10.1145/3643796,
title = {IDE '24: Proceedings of the 1st ACM/IEEE Workshop on Integrated Development Environments},
year = {2024},
isbn = {9798400705809},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Despite the research community's desire to improve the productivity of software developers, it is challenging for research to move beyond papers into the everyday practice of software development. Since IDEs are one of the most widely used tools in developers' toolkit, they remain a crucial venue for research to reach the practitioners. To close the gap between research and adoption in practice, we launched the first edition of the IDE Workshop.},
location = {Lisbon, Portugal}
}

@inproceedings{10.1145/3637528.3671742,
author = {Jiang, Wenyuan and Wu, Wenwei and Zhang, Le and Yuan, Zixuan and Xiang, Jian and Zhou, Jingbo and Xiong, Hui},
title = {Killing Two Birds with One Stone: Cross-modal Reinforced Prompting for Graph and Language Tasks},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671742},
doi = {10.1145/3637528.3671742},
abstract = {In recent years, Graph Neural Networks (GNNs) and Large Language Models (LLMs) have exhibited remarkable capability in addressing different graph learning and natural language tasks, respectively. Motivated by this, integrating LLMs with GNNs has been increasingly studied to acquire transferable knowledge across modalities, which leads to improved empirical performance in language and graph domains. However, existing studies mainly focused on a single-domain scenario by designing complicated integration techniques to manage multimodal data effectively. Therefore, a concise and generic learning framework for multi-domain tasks, i.e., graph and language domains, is highly desired yet remains under-exploited due to two major challenges. First, the language corpus of downstream tasks differs significantly from graph data, making it hard to bridge the knowledge gap between modalities. Second, not all knowledge demonstrates immediate benefits for downstream tasks, potentially introducing disruptive noise to context-sensitive models like LLMs. To tackle these challenges, we propose a novel plug-and-play framework for incorporating a lightweight cross-domain prompting method into both language and graph learning tasks. Specifically, we first convert the textual input into a domain-scalable prompt, which not only preserves the semantic and logical contents of the textual input, but also highlights related graph information as external knowledge for different domains. Then, we develop a reinforcement learning-based method to learn the optimal edge selection strategy for useful knowledge extraction, which profoundly sharpens the multi-domain model capabilities. In addition, we introduce a joint multi-view optimization module to regularize agent-level collaborative learning across two domains. Finally, extensive empirical justifications over 23 public and synthetic datasets demonstrate that our approach can be applied to diverse multi-domain tasks more accurately, robustly, and reasonably, and improve the performances of the state-of-the-art graph and language models in different learning paradigms.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {1301–1312},
numpages = {12},
keywords = {graph neural networks, large language models, prompt learning, reinforcement learning},
location = {Barcelona, Spain},
series = {KDD '24}
}

@proceedings{10.1145/3698387,
title = {SocialMeta '24: Proceedings of the Third International Workshop on Social and Metaverse Computing, Sensing and Networking},
year = {2024},
isbn = {9798400712999},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Hangzhou, China}
}

@proceedings{10.1145/3640457,
title = {RecSys '24: Proceedings of the 18th ACM Conference on Recommender Systems},
year = {2024},
isbn = {9798400705052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Bari, Italy}
}

@article{10.1145/3676279,
author = {Konstantinidis, Ioannis and Kapantai, Eleni and Michailidis, Alexios and Deligiannis, Athanasios and Berberidis, Christos and Magnisalis, Ioannis and Peristeras, Vassilios},
title = {From document-centric to data-centric public service provision},
year = {2024},
issue_date = {September 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {3},
url = {https://doi.org/10.1145/3676279},
doi = {10.1145/3676279},
abstract = {The profound digitization of public administration over recent decades has not eliminated information exchange via paper or electronic documents and certificates. We argue that a paradigm shift from document-centric to data-centric public service provision is needed and is feasible today with the exploitation of emerging technologies. We explore frameworks, architectures, benefits, and challenges in transforming document-centric administration processes into integrated, granular data exchange. A conceptual architecture for public service provision is proposed to extract preconditions from legislation, map the needed evidence to the service requirements, standardize evidence types, and integrate authoritative data sources. While promoting efficiency, privacy, and innovation, this shift faces technical and organizational challenges as the analysis of the “National Registry of Administrative Public Services” in Greece reveals. Further research on aligning policies, upholding trust, and coordinating institutional processes is warranted.},
journal = {Digit. Gov.: Res. Pract.},
month = sep,
articleno = {28},
numpages = {27},
keywords = {data, public service, digital transformation, AI, LLMs, Knowledge Graphs}
}

@inproceedings{10.1145/3675417.3675513,
author = {Li, Shiye and Yi, Li},
title = {A Few-Shot Entity Relation Extraction Method in the Legal Domain Based on Large Language Models},
year = {2024},
isbn = {9798400717147},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3675417.3675513},
doi = {10.1145/3675417.3675513},
abstract = {With the increasing transparency of judicial information, extracting implicit legal information from a massive corpus of legal documents becomes more academically valuable and practically significant. Large Language Models (LLMs) have demonstrated outstanding performance in many NLP tasks, particularly in generative tasks. However, satisfactory results are often elusive in vertical domains like legal entity relation extraction tasks. Due to the scarcity of well-annotated training data in the legal domain, and the expensive and time-consuming nature of labeling such data, research on few-shot learning becomes particularly crucial. Leveraging the advantage of large models pre-trained on extensive datasets, capable of acquiring vast prior knowledge of various tasks and adapting quickly to new tasks, this paper proposes a few-shot entity relation extraction method in the legal domain based on large language models. The proposed method is evaluated on two publicly available legal entity relation extraction datasets through relevant experiments. The research results indicate that the proposed approach reduces the cost of constructing training data and exhibits excellent performance in few-shot legal entity relation extraction tasks. The F1 score on two public datasets is improved by 2.8% and 3.1%, respectively, compared to traditional deep learning models, while maintaining better generalization capabilities.},
booktitle = {Proceedings of the 2024 Guangdong-Hong Kong-Macao Greater Bay Area International Conference on Digital Economy and Artificial Intelligence},
pages = {580–586},
numpages = {7},
location = {Hongkong, China},
series = {DEAI '24}
}

@proceedings{10.1145/3673791,
title = {SIGIR-AP 2024: Proceedings of the 2024 Annual International ACM SIGIR Conference on Research and Development in Information Retrieval in the Asia Pacific Region},
year = {2024},
isbn = {9798400707247},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our great pleasure to welcome you to the 2024 Annual International ACM SIGIR Conference on Research and Development in Information Retrieval in the Asia Pacific Region - the Second SIGIR-AP, hosted at Waseda University Nishiwaseda Campus, Tokyo, Japan, in December 2024. Following the great success of the very first SIGIR-AP held in Beijing in November 2023, we have worked very hard with our organising team over a year so that SIGIR-AP 2024 will live up to its high expectations.As noted in the SIGIR-AP Charter and Bylaws, SIGIR-AP cares about sustainability, and is fully hybrid so that participants may choose to enjoy the conference online to avoid taking earth-unfriendly longdistance flights. Moreover, we are experimenting with a few novel approaches to running a sustainable conference, thanks to the generous support from the Tokyo Convention and Visitors Bureau: we will provide sustainable seafood lunch boxes, as well as a conference bag and a mug that are made from recycled plastic! In addition, a substantial portion of the banquet dishes will be vegetarian, which is known to be better for the environment than meat dishes (See Greta Thunberg: The Climate Book, p.249, Penguin Press, 2023).The SIGIR-AP 2024 features two keynotes from Japan: one by Dr. Momoe Makino (Institute of Developing Economies Japan External Trade Organization), titled Information Experiment: What Does Empirical Microeconomics Tell Us? and the other by Professor Sadao Kurohashi (National Institute of Informatics) titled From Data Platforms to Knowledge Infrastructure. We thank Dr. Makino and Professor Kurohashi for boosting the brilliance of our conference program.},
location = {Tokyo, Japan}
}

@inproceedings{10.1145/3626772.3657904,
author = {Xie, Yuzhang and Lu, Jiaying and Ho, Joyce and Nahab, Fadi and Hu, Xiao and Yang, Carl},
title = {PromptLink: Leveraging Large Language Models for Cross-Source Biomedical Concept Linking},
year = {2024},
isbn = {9798400704314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626772.3657904},
doi = {10.1145/3626772.3657904},
abstract = {Linking (aligning) biomedical concepts across diverse data sources enables various integrative analyses, but it is challenging due to the discrepancies in concept naming conventions. Various strategies have been developed to overcome this challenge, such as those based on string-matching rules, manually crafted thesauri, and machine learning models. However, these methods are constrained by limited prior biomedical knowledge and can hardly generalize beyond the limited amounts of rules, thesauri, or training samples. Recently, large language models (LLMs) have exhibited impressive results in diverse biomedical NLP tasks due to their unprecedentedly rich prior knowledge and strong zero-shot prediction abilities. However, LLMs suffer from issues including high costs, limited context length, and unreliable predictions. In this research, we propose PromptLink, a novel biomedical concept linking framework that leverages LLMs. Empirical results on the concept linking task between two EHR datasets and an external biomedical KG demonstrate the effectiveness of PromptLink. Furthermore, PromptLink is a generic framework without reliance on additional prior knowledge, context, or training data, making it well-suited for concept linking across various types of data sources. The source code of this study is available at https://github.com/constantjxyz/PromptLink.},
booktitle = {Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {2589–2593},
numpages = {5},
keywords = {biomedical concept linking, few-shot prompting, large language models for resource-constrained field, retrieve &amp; re-rank},
location = {Washington DC, USA},
series = {SIGIR '24}
}

@proceedings{10.1145/3677052,
title = {ICAIF '24: Proceedings of the 5th ACM International Conference on AI in Finance},
year = {2024},
isbn = {9798400710810},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Brooklyn, NY, USA}
}

@inproceedings{10.1145/3589334.3645404,
author = {Baek, Jinheon and Chandrasekaran, Nirupama and Cucerzan, Silviu and Herring, Allen and Jauhar, Sujay Kumar},
title = {Knowledge-Augmented Large Language Models for Personalized Contextual Query Suggestion},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3645404},
doi = {10.1145/3589334.3645404},
abstract = {Large Language Models (LLMs) excel at tackling various natural language tasks. However, due to the significant costs involved in re-training or fine-tuning them, they remain largely static and difficult to personalize. Nevertheless, a variety of applications could benefit from generations that are tailored to users' preferences, goals, and knowledge. Among them is web search, where knowing what a user is trying to accomplish, what they care about, and what they know can lead to improved search experiences. In this work, we propose a novel and general approach that augments an LLM with relevant context from users' interaction histories with a search engine in order to personalize its outputs. Specifically, we construct an entity-centric knowledge store for each user based on their search and browsing activities on the web, which is then leveraged to provide contextually relevant LLM prompt augmentations. This knowledge store is light-weight, since it only produces user-specific aggregate projections of interests and knowledge onto public knowledge graphs, and leverages existing search log infrastructure, thereby mitigating the privacy, compliance, and scalability concerns associated with building deep user profiles for personalization. We validate our approach on the task of contextual query suggestion, which requires understanding not only the user's current search context but also what they historically know and care about. Through a number of experiments based on human evaluation, we show that our approach is significantly better than several other LLM-powered baselines, generating query suggestions that are contextually more relevant, personalized, and useful.},
booktitle = {Proceedings of the ACM Web Conference 2024},
pages = {3355–3366},
numpages = {12},
keywords = {contextual query suggestion, entity-centric knowledge, large language models, personalization},
location = {Singapore, Singapore},
series = {WWW '24}
}

@proceedings{10.1145/3688868,
title = {MCHM'24: Proceedings of the 1st International Workshop on Multimedia Computing for Health and Medicine},
year = {2024},
isbn = {9798400711954},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our great pleasure to welcome you to The 1st International Workshop on Multimedia Computing for Health and Medicine MCHM '24. This year we created the first international workshop on multimedia computing for health and medicine, a premier forum for presentation of research results on leading edge issues of multimedia-based health/medicine computing. The mission of the workshop is to share novel multimedia computing solutions that fulfill the needs of health and medicine problems. It gives researchers a unique opportunity to share their perspectives with others interested in multimedia computing for health and medicine.},
location = {Melbourne VIC, Australia}
}

@inproceedings{10.1145/3637528.3671793,
author = {Gyurek, Croix and Talukder, Niloy and Hasan, Mohammad Al},
title = {Binder: Hierarchical Concept Representation through Order Embedding of Binary Vectors},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671793},
doi = {10.1145/3637528.3671793},
abstract = {For natural language understanding and generation, embedding concepts using an order-based representation is an essential task. Unlike traditional point vector based representation, an order-based representation imposes geometric constraints on the representation vectors for explicitly capturing various semantic relationships that may exist between a pair of concepts. In existing literature, several approaches on order-based embedding have been proposed, mostly focusing on capturing hierarchical relationships; examples include vectors in Euclidean space, complex, Hyperbolic, order, and Box Embedding. Box embedding creates region-based rich representation of concepts, but along the process it sacrifices simplicity, requiring a custom-made optimization scheme for learning the representation. Hyperbolic embedding improves embedding quality by exploiting the ever-expanding property of Hyperbolic space, but it also suffers from the same fate as box embedding as gradient descent like optimization is not simple in the Hyperbolic space. In this work, we propose Binder, a novel approach for order-based representation. Binder uses binary vectors for embedding, so the embedding vectors are compact with an order of magnitude smaller footprint than other methods. Binder uses a simple and efficient optimization scheme for learning representation vectors with a linear time complexity. Our comprehensive experimental results show that Binder is very accurate, yielding competitive results on the representation task. But Binder stands out from its competitors on the transitive closure link prediction task as it can learn concept embeddings just from the direct edges, whereas all existing order-based approaches rely on the indirect edges. In particular, Binder achieves a whopping 70% higher F1-score than the second best method (98.6% vs 29%) in our largest dataset, WordNet Nouns (743,241 edges), when using only direct edges during training.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {980–991},
numpages = {12},
keywords = {binary vector embedding, concept graph, hierarchical embedding, order embedding},
location = {Barcelona, Spain},
series = {KDD '24}
}

@inproceedings{10.1145/3671151.3671324,
author = {Wang, Yaohui and Zhao, Yuxian and Hao, Qiang and Zhang, Jian and Sun, Xiaohu and Lyu, Xueqiang},
title = {Question-and-answer intention classification in the coal mine production field based on prompt learning},
year = {2024},
isbn = {9798400718106},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3671151.3671324},
doi = {10.1145/3671151.3671324},
abstract = {Intelligent Q&amp;A is an essential part of the intelligent construction of coal mines. However, in practical applications, there is a lack of Q&amp;A related data sets in the field of coal mine production, and it is difficult to obtain annotated data. The existing Q&amp;A system in the field of coal mine production has problems such as inability to solve polysemy issues and accurately understand user needs. To solve these problems, this paper introduces prompt learning into the field of coal mine production for the first time for Q&amp;A intent classification. By introducing multiple prompt templates to fine-tune the BERT pre-trained model, the accuracy of Q&amp;A intent classification is improved in the case of low data volume. Experimental results show that after introducing the prompt template, the accuracy, recall rate, and F1 value of the model are increased by 0.66, 1.21, and 1.29 percentage points, respectively. In addition, we have also conducted experiments in low-sample scenarios, proving that prompt learning methods can quickly adapt to new domain tasks in low-sample scenarios. The proposed method has good application value in Q&amp;A intent classification in the field of coal mine production.},
booktitle = {Proceedings of the 5th International Conference on Computer Information and Big Data Applications},
pages = {992–998},
numpages = {7},
location = {Wuhan, China},
series = {CIBDA '24}
}

@proceedings{10.1145/3675249,
title = {ICCMT '24: Proceedings of the 2024 International Conference on Computer and Multimedia Technology},
year = {2024},
isbn = {9798400718267},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Sanming, China}
}

@proceedings{10.1145/3677045,
title = {NordiCHI '24 Adjunct: Adjunct Proceedings of the 2024 Nordic Conference on Human-Computer Interaction},
year = {2024},
isbn = {9798400709654},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Uppsala, Sweden}
}

@article{10.1145/3681802,
author = {McDonald, Nora and Badillo-Urquiola, Karla and Razi, Afsaneh and Seberger, John S. and Agosto, Denise E. and Wisniewski, Pamela},
title = {AI Through Gen Z: Partnerships Toward New Research Agendas},
year = {2024},
issue_date = {September - October 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {31},
number = {5},
issn = {1072-5520},
url = {https://doi.org/10.1145/3681802},
doi = {10.1145/3681802},
journal = {Interactions},
month = aug,
pages = {28–31},
numpages = {4}
}

@proceedings{10.1145/3696409,
title = {MMAsia '24: Proceedings of the 6th ACM International Conference on Multimedia in Asia},
year = {2024},
isbn = {9798400712739},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3640794,
title = {CUI '24: Proceedings of the 6th ACM Conference on Conversational User Interfaces},
year = {2024},
isbn = {9798400705113},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Luxembourg, Luxembourg}
}

@inproceedings{10.1145/3640794.3665537,
author = {Seaborn, Katie and Gessinger, Iona and Yoshida, Suzuka and Cowan, Benjamin R. and Doyle, Philip R.},
title = {Cross-Cultural Validation of Partner Models for Voice User Interfaces},
year = {2024},
isbn = {9798400705113},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3640794.3665537},
doi = {10.1145/3640794.3665537},
abstract = {Recent research has begun to assess people’s perceptions of voice user interfaces (VUIs) as dialogue partners, termed partner models. Current self-report measures are only available in English, limiting research to English-speaking users. To improve the diversity of user samples and contexts that inform partner modelling research, we translated, localized, and evaluated the Partner Modelling Questionnaire (PMQ) for non-English speaking Western (German, n=185) and East Asian (Japanese, n=198) cohorts where VUI use is popular. Through confirmatory factor analysis (CFA), we find that the scale produces equivalent levels of “goodness-to-fit” for both our German and Japanese translations, confirming its cross-cultural validity. Still, the structure of the communicative flexibility factor did not replicate directly across Western and East Asian cohorts. We discuss how our translations can open up critical research on cultural similarities and differences in partner model use and design, whilst highlighting the challenges for ensuring accurate translation across cultural contexts.},
booktitle = {Proceedings of the 6th ACM Conference on Conversational User Interfaces},
articleno = {19},
numpages = {10},
keywords = {conversational user interfaces, cross-cultural research, human-computer interaction, human-machine dialogue, mental models, partner models, speech interfaces, voice user interfaces},
location = {Luxembourg, Luxembourg},
series = {CUI '24}
}

@inproceedings{10.1145/3665601.3669846,
author = {Feng, Yanlin and Rahman, Sajjadur and Feng, Aaron and Chen, Vincent and Kandogan, Eser},
title = {CMDBench: A Benchmark for Coarse-to-fine Multimodal Data Discovery in Compound AI Systems},
year = {2024},
isbn = {9798400706943},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3665601.3669846},
doi = {10.1145/3665601.3669846},
abstract = {Compound AI systems (CASs) that employ LLMs as agents to accomplish knowledge-intensive tasks via interactions with tools and data retrievers have garnered significant interest within database and AI communities. While these systems have the potential to supplement typical analysis workflows of data analysts in enterprise data platforms, unfortunately, CASs are subject to the same data discovery challenges that analysts have encountered over the years — silos of multimodal data sources, created across teams and departments within an organization, make it difficult to identify appropriate data sources for accomplishing the task at hand. Existing data discovery benchmarks do not model such multimodality and multiplicity of data sources. Moreover, benchmarks of CASs prioritize only evaluating end-to-end task performance. To catalyze research on evaluating the data discovery performance of multimodal data retrievers in CASs within a real-world setting, we propose CMDBench, a benchmark modeling the complexity of enterprise data platforms. We adapt existing datasets and benchmarks in open-domain — from question answering and complex reasoning tasks to natural language querying over structured data — to evaluate coarse- and fine-grained data discovery and task execution performance. Our experiments reveal the impact of data retriever design on downstream task performance — 46% drop in task accuracy on average — across various modalities, data sources, and task difficulty. The results indicate the need to develop optimization strategies to identify appropriate LLM agents and retrievers for efficient execution of CASs over enterprise data.},
booktitle = {Proceedings of the Conference on Governance, Understanding and Integration of Data for Effective and Responsible AI},
pages = {16–25},
numpages = {10},
keywords = {Benchmark, Compound AI Systems., Data Discovery, LLMs},
location = {Santiago, AA, Chile},
series = {GUIDE-AI '24}
}

@proceedings{10.1145/3674399,
title = {ACM-TURC '24: Proceedings of the ACM Turing Award Celebration Conference - China 2024},
year = {2024},
isbn = {9798400710117},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Changsha, China}
}

@inproceedings{10.1145/3664647.3680613,
author = {Deng, Ruoxi and Yu, Bin and Lu, Jinxuan and Zhou, Caixia and Chen, Zhao-Min and Hu, Jie},
title = {Advancing Semantic Edge Detection through Cross-Modal Knowledge Learning},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3680613},
doi = {10.1145/3664647.3680613},
abstract = {Semantic edge detection (SED) is pivotal for the precise demarcation of object boundaries, yet it faces ongoing challenges due to the prevalence of low-quality labels in current methods. In this paper, we present a novel solution to bolster SED through the encoding of both language and image data. Distinct from antecedent language-driven techniques, which predominantly utilize static elements such as dataset labels, our method taps into the dynamic language content that details the objects in each image and their interrelations. By encoding this varied input, we generate integrated features that utilize semantic insights to refine the high-level image features and the ultimate mask representations. This advancement improves the quality of these features and elevates SED performance. Experimental evaluation on benchmark datasets, including SBD and Cityscape, showcases the efficacy of our method, achieving leading ODS F-scores of 79.0 and 76.0, respectively. Our approach signifies a notable advancement in SED technology by seamlessly integrating multimodal textual information, embracing both static and dynamic aspects.},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {4524–4532},
numpages = {9},
keywords = {contour detection, deep convolutional neural networks, low-level vision, semantic edge detection},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@inproceedings{10.1145/3702038.3702094,
author = {Oliveira, Alberto Dumont Alves and Eler, Marcelo Medeiros},
title = {Exploring Accessibility of Mobile Applications Through User Feedback: Insights from App Reviews in a Systematic Literature Review},
year = {2024},
isbn = {9798400712241},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3702038.3702094},
doi = {10.1145/3702038.3702094},
abstract = {Mobile applications have become essential tools for daily activities, encompassing communication, productivity, and entertainment, serving a diverse user base that includes people with disabilities. Despite this broad usage, ensuring accessibility for users with varying needs remains a significant challenge. This paper presents a systematic literature review (SLR) examining the accessibility of mobile applications through user reviews. An initial search across major academic digital libraries identified 638 papers, which were narrowed down to 16 key studies published since 2013 based on specific inclusion and exclusion criteria. The articles analyzed featured a wide range of review counts, from 173 to over 179 million. Our analysis reveals various purposes, methodologies, and approaches that researchers have employed to explore digital accessibility. The SLR identifies four main strategies for collecting and analyzing accessibility reviews, with commonly referenced standards including BBC guidelines, Google Material Design, and WCAG. The results also identify persistent barriers for users with disabilities and synthesize 31 recommendations for future research directions in areas such as machine learning and the automatic extraction and classification of user reviews. These findings underscore the critical importance of integrating user feedback and perspectives into the design and development of mobile applications to ensure they are inclusive and accessible to all users.},
booktitle = {Proceedings of the XXIII Brazilian Symposium on Human Factors in Computing Systems},
articleno = {56},
numpages = {15},
keywords = {accessibility reviews, app reviews, user reviews, mobile, application, systematic literature review},
location = {
},
series = {IHC '24}
}

@proceedings{10.1145/3613904,
title = {CHI '24: Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Honolulu, HI, USA}
}

@inproceedings{10.1145/3687123.3698284,
author = {Tsiligkaridis, Athanasios and Kalinowski, Nicholas and Li, Zhongheng and Hou, Elizabeth},
title = {Encoding Agent Trajectories as Representations with Sequence Transformers},
year = {2024},
isbn = {9798400711763},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3687123.3698284},
doi = {10.1145/3687123.3698284},
abstract = {Spatiotemporal data faces many analogous challenges to natural language text including the ordering of locations (words) in a sequence, long range dependencies between locations, and locations having multiple meanings. In this work, we propose a novel model for representing high dimensional spatiotemporal trajectories as sequences of discrete locations and encoding them with a Transformer-based neural network architecture. Similar to language models, our Sequence Transformer for Agent Representation Encodings (STARE) model can learn representations and structure in trajectory data through both supervisory tasks (e.g., classification), and self-supervisory tasks (e.g., masked modelling). We present experimental results on various synthetic and real trajectory datasets and show that our proposed model can learn meaningful encodings that are useful for many downstream tasks including discriminating between labels and indicating similarity between locations. Using these encodings, we also learn relationships between agents and locations present in spatiotemporal data.},
booktitle = {Proceedings of the 7th ACM SIGSPATIAL International Workshop on AI for Geographic Knowledge Discovery},
pages = {38–49},
numpages = {12},
keywords = {Transformers, encoders, human mobility, spatiotemporal data, trajectory modeling},
location = {Atlanta, GA, USA},
series = {GeoAI '24}
}

@proceedings{10.1145/3675094,
title = {UbiComp '24: Companion of the 2024 on ACM International Joint Conference on Pervasive and Ubiquitous Computing},
year = {2024},
isbn = {9798400710582},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to UbiComp/ISWC 2024, the companion program of two premier conferences: The 2024 ACM International Joint Conference on Pervasive and Ubiquitous Computing (UbiComp 2024) and the 2024 International Symposium on Wearable Computers (ISWC 2024). UbiComp and ISWC are premier interdisciplinary venues for international researchers, designers, developers, practitioners and educators in the field to present and discuss novel and impactful research in interactive, mobile, wearable and ubiquitous computing. The companion program has traditionally been a very important part of the UbiComp/ISWC conference series.UbiComp/ISWC 2024 is held from October 5 to 9, 2024 in Melbourne, Australia. Originally, UbiComp/ISWC was scheduled to take place in Melbourne in 2021. However, due to the significant impact of COVID-19, our community decided to postpone conferences taking place in their traditional form until last year, when UbiComp took place as an in-person event in Mexico. Now, in 2024 we look to consolidate the strength and ties in our community by having another fully in-person event and hoping to welcome a new generation of researchers to meet and explore the wonderful people that make up our community.},
location = {Melbourne VIC, Australia}
}

@inproceedings{10.1145/3626772.3657705,
author = {Wang, Pancheng and Li, Shasha and Li, Dong and Long, Kehan and Tang, Jintao and Wang, Ting},
title = {Disentangling Instructive Information from Ranked Multiple Candidates for Multi-Document Scientific Summarization},
year = {2024},
isbn = {9798400704314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626772.3657705},
doi = {10.1145/3626772.3657705},
abstract = {Automatically condensing multiple topic-related scientific papers into a succinct and concise summary is referred to as Multi-Document Scientific Summarization (MDSS). Currently, while commonly used abstractive MDSS methods can generate flexible and coherent summaries, the difficulty in handling global information and the lack of guidance during decoding still make it challenging to generate better summaries. To alleviate these two shortcomings, this paper introduces summary candidates into MDSS, utilizing the global information of the document set and additional guidance from the summary candidates to guide the decoding process. Our insights are twofold: Firstly, summary candidates can provide instructive information from both positive and negative perspectives, and secondly, selecting higher-quality candidates from multiple options contributes to producing better summaries. Drawing on the insights, we propose a summary candidates fusion framework - Disentangling Instructive information from Ranked candidates (DIR) for MDSS. Specifically, DIR first uses a specialized pairwise comparison method towards multiple candidates to pick out those of higher quality. Then DIR disentangles the instructive information of summary candidates into positive and negative latent variables with Conditional Variational Autoencoder. These variables are further incorporated into the decoder to guide generation. We evaluate our approach with three different types of Transformer-based models and three different types of candidates, and consistently observe noticeable performance improvements according to automatic and human evaluation. More analyses further demonstrate the effectiveness of our model in handling global information and enhancing decoding controllability.},
booktitle = {Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {2028–2037},
numpages = {10},
keywords = {disentangled representation learning, multi-document scientific summarization, summary candidates, summary ranking},
location = {Washington DC, USA},
series = {SIGIR '24}
}

@article{10.1145/3695986,
author = {Zheng, Yu and Hao, Qianyue and Wang, Jingwei and Gao, Changzheng and Chen, Jinwei and Jin, Depeng and Li, Yong},
title = {A Survey of Machine Learning for Urban Decision Making: Applications in Planning, Transportation, and Healthcare},
year = {2024},
issue_date = {April 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {57},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/3695986},
doi = {10.1145/3695986},
abstract = {Developing smart cities is vital for ensuring sustainable development and improving human well-being. One critical aspect of building smart cities is designing intelligent methods to address various decision-making problems that arise in urban areas. As machine learning techniques continue to advance rapidly, a growing body of research has been focused on utilizing these methods to achieve intelligent urban decision-making. In this survey, we conduct a systematic literature review on the application of machine learning methods in urban decision-making, with a focus on planning, transportation, and healthcare. First, we provide a taxonomy based on typical applications of machine learning methods for urban decision-making. We then present background knowledge on these tasks and the machine learning techniques that have been adopted to solve them. Next, we examine the challenges and advantages of applying machine learning in urban decision-making, including issues related to urban complexity, urban heterogeneity, and computational cost. Afterward and primarily, we elaborate on the existing machine learning methods that aim at solving urban decision-making tasks in planning, transportation, and healthcare, highlighting their strengths and limitations. Finally, we discuss open problems and the future directions of applying machine learning to enable intelligent urban decision-making, such as developing foundation models and combining reinforcement learning algorithms with human feedback. We hope this survey can help researchers in related fields understand the recent progress made in existing works, and inspire novel applications of machine learning in smart cities.},
journal = {ACM Comput. Surv.},
month = dec,
articleno = {99},
numpages = {41},
keywords = {machine learning, urban planning, optimization, decision making}
}

@inproceedings{10.1145/3627673.3680025,
author = {Huang, Jia-Hong and Yang, Chao-Chun and Shen, Yixian and Pacces, Alessio M. and Kanoulas, Evangelos},
title = {Optimizing Numerical Estimation and Operational Efficiency in the Legal Domain through Large Language Models},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3680025},
doi = {10.1145/3627673.3680025},
abstract = {The legal landscape encompasses a wide array of lawsuit types, presenting lawyers with challenges in delivering timely and accurate information to clients, particularly concerning critical aspects like potential imprisonment duration or financial repercussions. Compounded by the scarcity of legal experts, there's an urgent need to enhance the efficiency of traditional legal workflows. Recent advances in deep learning, especially Large Language Models (LLMs), offer promising solutions to this challenge. Leveraging LLMs' mathematical reasoning capabilities, we propose a novel approach integrating LLM-based methodologies with specially designed prompts to address precision requirements in legal Artificial Intelligence (LegalAI) applications. The proposed work seeks to bridge the gap between traditional legal practices and modern technological advancements, paving the way for a more accessible, efficient, and equitable legal system. To validate this method, we introduce a curated dataset tailored to precision-oriented LegalAI tasks, serving as a benchmark for evaluating LLM-based approaches. Extensive experimentation confirms the efficacy of our methodology in generating accurate numerical estimates within the legal domain, emphasizing the role of LLMs in streamlining legal processes and meeting the evolving demands of LegalAI. Github: https://github.com/Jhhuangkay/Optimizing-Numerical-Estimation-and-Operational-Efficiency-in-the-Legal-Domain.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {4554–4562},
numpages = {9},
keywords = {large language models, precision-oriented legal artificial intelligence, tailored prompt design},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@inproceedings{10.1145/3664647.3681472,
author = {Sun, Luoyi and Xu, Xuenan and Wu, Mengyue and Xie, Weidi},
title = {Auto-ACD: A Large-scale Dataset for Audio-Language Representation Learning},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3681472},
doi = {10.1145/3664647.3681472},
abstract = {Recently, the AI community has made significant strides in developing powerful foundation models, driven by large-scale multimodal datasets. However, for audio representation learning, existing datasets suffer from limitations in the following aspects: insufficient volume, simplistic content, and arduous collection procedures. To establish an audio dataset with high-quality captions, we propose an innovative, automatic approach leveraging multimodal inputs, such as video frames, audio streams. Specifically, we construct a large-scale, high-quality, audio-language dataset, named as Auto-ACD, comprising over 1.5M audio-text pairs. We exploit a series of pre-trained models or APIs, to determine audio-visual synchronisation, generate image captions, object detection, or audio tags for specific videos. Subsequently, we employ LLM to paraphrase a congruent caption for each audio, guided by the extracted multi-modality clues. To demonstrate the effectiveness of the proposed dataset, we train widely used models on our dataset and show performance improvement on various downstream tasks, for example, audio-language retrieval, audio captioning, zero-shot classification. In addition, we establish a novel benchmark with environmental information and provide a benchmark for audio-text tasks.},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {5025–5034},
numpages = {10},
keywords = {audio captioning, audio-language dataset, audio-language representation learning},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@article{10.1145/3664615,
author = {Ji, Shaoxiong and Li, Xiaobo and Sun, Wei and Dong, Hang and Taalas, Ara and Zhang, Yijia and Wu, Honghan and Pitk\"{a}nen, Esa and Marttinen, Pekka},
title = {A Unified Review of Deep Learning for Automated Medical Coding},
year = {2024},
issue_date = {December 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {56},
number = {12},
issn = {0360-0300},
url = {https://doi.org/10.1145/3664615},
doi = {10.1145/3664615},
abstract = {Automated medical coding, an essential task for healthcare operation and delivery, makes unstructured data manageable by predicting medical codes from clinical documents. Recent advances in deep learning and natural language processing have been widely applied to this task. However, deep learning–based medical coding lacks a unified view of the design of neural network architectures. This review proposes a unified framework to provide a general understanding of the building blocks of medical coding models and summarizes recent advanced models under the proposed framework. Our unified framework decomposes medical coding into four main components, i.e., encoder modules for text feature extraction, mechanisms for building deep encoder architectures, decoder modules for transforming hidden representations into medical codes, and the usage of auxiliary information. Finally, we introduce the benchmarks and real-world usage and discuss key research challenges and future directions.},
journal = {ACM Comput. Surv.},
month = oct,
articleno = {306},
numpages = {41},
keywords = {Medical coding, deep learning, unified framework}
}

@inproceedings{10.1145/3637528.3671453,
author = {Zhang, Weijia and Han, Jindong and Xu, Zhao and Ni, Hang and Liu, Hao and Xiong, Hui},
title = {Urban Foundation Models: A Survey},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671453},
doi = {10.1145/3637528.3671453},
abstract = {Machine learning techniques are now integral to the advancement of intelligent urban services, playing a crucial role in elevating the efficiency, sustainability, and livability of urban environments. The recent emergence of foundation models such as ChatGPT marks a revolutionary shift in the fields of machine learning and artificial intelligence. Their unparalleled capabilities in contextual understanding, problem solving, and adaptability across a wide range of tasks suggest that integrating these models into urban domains could have a transformative impact on the development of smart cities. Despite growing interest in Urban Foundation Models (UFMs), this burgeoning field faces challenges such as a lack of clear definitions and systematic reviews. To this end, this paper first introduces the concept of UFMs and discusses the unique challenges involved in building them. We then propose a data-centric taxonomy that categorizes and clarifies current UFM-related works, based on urban data modalities and types. Furthermore, we explore the application landscape of UFMs, detailing their potential impact in various urban contexts. Relevant papers and open-source resources have been collated and are continuously updated at: https://github.com/usail-hkust/Awesome-Urban-Foundation-Models.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {6633–6643},
numpages = {11},
keywords = {geospatial artificial intelligence, spatio-temporal data mining, urban foundation models, urban general intelligence},
location = {Barcelona, Spain},
series = {KDD '24}
}

@article{10.1145/3673229,
author = {Taylor, Jordan and Deng, Wesley Hanwen and Holstein, Kenneth and Fox, Sarah and Zhu, Haiyi},
title = {Carefully Unmaking the “Marginalized User”: A Diffractive Analysis of a Gay Online Community},
year = {2024},
issue_date = {December 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {31},
number = {6},
issn = {1073-0516},
url = {https://doi.org/10.1145/3673229},
doi = {10.1145/3673229},
abstract = {HCI scholars are increasingly engaging in research about “marginalized groups,” such as LGBTQ+ people. While normative habitual readings of marginalized people in HCI often highlight real problems, this work has been criticized for flattening heterogeneous experiences and overemphasizing harms. Some have advocated for expanding how we approach research on marginalized people (e.g., assets-based design, the everyday, and joy). Sensitized by unmaking literature, we explore this tension between conditions, experiences, and representations of marginality in HCI scholarship. To do so, we perform a diffractive analysis of posts in a gay online community by bringing two readings of the same data together: a normative habitual reading of marginalization and an expanded reading. By examining the relationship between empirical material and its representations by HCI researchers, we explore how to carefully unmake HCI research, thus maintaining and repairing our research community. We discuss the political and designerly implications of different readings of marginalized people and offer considerations for attending to the processes and afterlives of HCI research.},
journal = {ACM Trans. Comput.-Hum. Interact.},
month = dec,
articleno = {81},
numpages = {30},
keywords = {Unmaking, Diffraction, Marginalized Groups, Marginalized Communities, Gay Men, LGBTQ, LGBTQ+ People}
}

@inproceedings{10.1145/3589335.3641306,
author = {Mao, Haitao and Zhao, Jianan and He, Xiaoxin and Chen, Zhikai and Huang, Qian and Zhu, Zhaocheng and Tang, Jian and Bronstein, Micheal and Bresson, Xavier and Hooi, Bryan and Zhang, Haiyang and Tang, Xianfeng and Chen, Luo and Tang, Jiliang},
title = {The 1st International Workshop on Graph Foundation Models (GFM)},
year = {2024},
isbn = {9798400701726},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589335.3641306},
doi = {10.1145/3589335.3641306},
abstract = {Foundation models such as GPT-4 for natural language processing (NLP), Flamingo for computer vision (CV), have set new benchmarks in AI by delivering state-of-the-art results across various tasks with minimal task-specific data. Despite their success, the application of these models to the graph domain is challenging due to the relational nature of graph-structured data. To address this gap, we propose the Graph Foundation Model (GFM) Workshop, the first workshop for GFMs, dedicated to exploring the adaptation and development of foundation models specifically designed for graph data. The GFM workshop focuses on two critical questions: (1) How can the underlying capabilities of existing foundation models be effectively applied to graph data? (2) What foundational principles should guide the creation of models tailored to the graph domain? Through a curated set of panel sections, keynote talks, and paper presentations, our workshop intends to catalyze innovative approaches and theoretical frameworks for Graph Foundation Models (GFMs). We target a broad audience, encompassing researchers, practitioners, and students, and aim to lay the groundwork for the next wave of breakthroughs in integrating graph data with foundation models.},
booktitle = {Companion Proceedings of the ACM Web Conference 2024},
pages = {1789–1792},
numpages = {4},
keywords = {data mining, foundation model, graph machine learning},
location = {Singapore, Singapore},
series = {WWW '24}
}

@proceedings{10.1145/3687123,
title = {GeoAI '24: Proceedings of the 7th ACM SIGSPATIAL International Workshop on AI for Geographic Knowledge Discovery},
year = {2024},
isbn = {9798400711763},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Advances in artificial intelligence, hardware accelerators, and data processing architectures continue to reach the geospatial information sciences, with a transformative impact on many societal challenges. Recent breakthroughs in deep learning have brought forward an automated capability to learn representational features from massive and complex data, including text, images, and videos. In tandem, rapid innovations in sensing technologies are supporting the collection of geospatial data in even higher resolution and throughput, supporting the observation, mapping, and analysis of different events/phenomena over the Earth's surface with unprecedented detail. Combined, these developments are offering the potential for breakthroughs in geographic knowledge discovery, impacting decision-making in areas such as humanitarian mapping, intelligent transport systems, urban expansion analysis, health data analysis and epidemiology, the study of climate change, handling natural disasters, the general monitoring of the Earth's surface, and achieving sustainability.},
location = {Atlanta, GA, USA}
}

@inproceedings{10.1145/3589335.3651242,
author = {Lian, Jianxun and Lei, Yuxuan and Huang, Xu and Yao, Jing and Xu, Wei and Xie, Xing},
title = {RecAI: Leveraging Large Language Models for Next-Generation Recommender Systems},
year = {2024},
isbn = {9798400701726},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589335.3651242},
doi = {10.1145/3589335.3651242},
abstract = {This paper introduces RecAI, a practical toolkit designed to augment or even revolutionize recommender systems with the advanced capabilities of Large Language Models (LLMs). RecAI provides a suite of tools, including Recommender AI Agent, Recommendation-oriented Language Models, Knowledge Plugin, RecExplainer, and Evaluator, to facilitate the integration of LLMs into recommender systems from multifaceted perspectives. The new generation of recommender systems, empowered by LLMs, are expected to be more versatile, explainable, conversational, and controllable, paving the way for more intelligent and user-centric recommendation experiences. We hope the open-source of RecAI can help accelerate evolution of new advanced recommender systems. The source code of RecAI is available at https://github.com/microsoft/RecAI.},
booktitle = {Companion Proceedings of the ACM Web Conference 2024},
pages = {1031–1034},
numpages = {4},
keywords = {large language models, recommender systems},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3614419.3644001,
author = {Pl\"{o}tzky, Florian and Kiehne, Niklas and Balke, Wolf-Tilo},
title = {Lost in Recursion: Mining Rich Event Semantics in Knowledge Graphs},
year = {2024},
isbn = {9798400703348},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3614419.3644001},
doi = {10.1145/3614419.3644001},
abstract = {Our world is shaped by events of various complexity. This includes both small-scale local events like local farmer markets and large complex events like political and military conflicts. The latter are typically not observed directly but through the lenses of intermediaries like newspapers or social media. In other words, we do not witness the unfolding of such events directly but are confronted with narratives surrounding them. Such narratives capture different aspects of a complex event and may also differ with respect to the narrator. Thus, they provide a rich semantics concerning real-world events. In this paper, we show how narratives concerning complex events can be constructed and utilized. We provide a formal representation of narratives based on recursive nodes to represent multiple levels of detail and discuss how narratives can be bound to event-centric knowledge graphs. Additionally, we provide an algorithm based on incremental prompting techniques that mines such narratives from texts to account for different perspectives on complex events. Finally, we show the effectiveness and future research directions in a proof of concept.},
booktitle = {Proceedings of the 16th ACM Web Science Conference},
pages = {354–364},
numpages = {11},
keywords = {Events, Narratives, Recursive Narrative Mining},
location = {Stuttgart, Germany},
series = {WEBSCI '24}
}

@inproceedings{10.1145/3637528.3671678,
author = {Hu, Qi and Li, Haoran and Bai, Jiaxin and Wang, Zihao and Song, Yangqiu},
title = {Privacy-Preserved Neural Graph Databases},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671678},
doi = {10.1145/3637528.3671678},
abstract = {In the era of large language models (LLMs), efficient and accurate data retrieval has become increasingly crucial for the use of domain-specific or private data in the retrieval augmented generation (RAG). Neural graph databases (NGDBs) have emerged as a powerful paradigm that combines the strengths of graph databases (GDBs) and neural networks to enable efficient storage, retrieval, and analysis of graph-structured data which can be adaptively trained with LLMs. The usage of neural embedding storage and Complex neural logical Query Answering (CQA) provides NGDBs with generalization ability. When the graph is incomplete, by extracting latent patterns and representations, neural graph databases can fill gaps in the graph structure, revealing hidden relationships and enabling accurate query answering. Nevertheless, this capability comes with inherent trade-offs, as it introduces additional privacy risks to the domain-specific or private databases. Malicious attackers can infer more sensitive information in the database using well-designed queries such as from the answer sets of where Turing Award winners born before 1950 and after 1940 lived, the living places of Turing Award winner Hinton are probably exposed, although the living places may have been deleted in the training stage due to the privacy concerns. In this work, we propose a privacy-preserved neural graph database (P-NGDB) framework to alleviate the risks of privacy leakage in NGDBs. We introduce adversarial training techniques in the training stage to enforce the NGDBs to generate indistinguishable answers when queried with private information, enhancing the difficulty of inferring sensitive information through combinations of multiple innocuous queries. Extensive experimental results on three datasets show that our framework can effectively protect private information in the graph database while delivering high-quality public answers responses to queries. The code is available at https://github.com/HKUST-KnowComp/PrivateNGDB.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {1108–1118},
numpages = {11},
keywords = {complex query answering (cqa), knowledge graphs (kgs), neural graph databases (ngdbs), privacy preserving},
location = {Barcelona, Spain},
series = {KDD '24}
}

@article{10.14778/3654621.3654639,
author = {He, Wenjia and Sabek, Ibrahim and Lou, Yuze and Cafarella, Michael},
title = {Optimizing Video Selection LIMIT Queries with Commonsense Knowledge},
year = {2024},
issue_date = {March 2024},
publisher = {VLDB Endowment},
volume = {17},
number = {7},
issn = {2150-8097},
url = {https://doi.org/10.14778/3654621.3654639},
doi = {10.14778/3654621.3654639},
abstract = {Video is becoming a major part of contemporary data collection. It is increasingly important to process video selection queries --- selecting videos that contain target objects. Advances in neural networks allow us to detect the objects in an image, and thereby offer query systems to examine the content of the video. Unfortunately, neural network-based approaches have long inference times. Processing this type of query through a standard scan would be time-consuming and would involve applying complex detectors to numerous irrelevant videos. It is tempting to try to improve query times by computing an index in advance. But unfortunately, many frames will never be beneficial for any query. Time spent processing them, whether at index time or at query time, is simply wasted computation.We propose a novel index mechanism to optimize video selection queries with commonsense knowledge. Commonsense knowledge consists of fundamental information about the world, such as the fact that a tennis racket is a tool designed for hitting a tennis ball. To save computation, an inexpensive but lossy index can be intentionally created, but this may result in missed target objects and suboptimal query time performance. Our mechanism addresses this issue by constructing probabilistic models from commonsense knowledge to patch the lossy index and then prioritizing predicate-related videos at query time. This method can achieve significant performance improvements comparable to those of a full index while keeping the construction costs of a lossy index. We describe our prototype system, Paine, plus experiments on two video corpora. We show our best optimization method can process up to 97.79% fewer videos compared to baselines. Even the model constructed without any video content can yield a 75.39% improvement over baselines.},
journal = {Proc. VLDB Endow.},
month = mar,
pages = {1751–1764},
numpages = {14}
}

@inproceedings{10.1145/3627673.3679917,
author = {Wang, Xiaotong and Liu, Xuanning and Zhong, Shuai and Chen, Xinming and Wu, Bin},
title = {Enhancing Temporal and Geographical Named Entity Recognition in Chinese Ancient Texts with External Time-series Knowledge Bases},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679917},
doi = {10.1145/3627673.3679917},
abstract = {In the field of ancient Chinese text, extracting and analysing temporal and geographic information are crucial for understanding the personal experiences of historical figures, the development of historical events, and the overall historical background. Currently, named entity recognition(NER) strategies such as BERT+CRF are used to extract temporal and geographic information from ancient Chinese text. However, ancient Chinese text covers a vast time span, and the temporal and geographic entities constantly evolve and change, making it difficult to extract these entities from text. This paper proposes a temporal and geographic extraction model for ancient Chinese text, enhanced by time-series external knowledge base. The extraction of proprietary nouns and general structures are divided into two independent networks. An external database is applied to enhance extraction of proprietary nouns and reduce noise for general structure inference. We constructed address trees and chronological tables containing commonly used places and time-related keywords from different periods and collected 12,000 texts spanning 3,000 years for extensive training. Overall, our research highlights the importance of external knowledge base for ancient Chinese NER, and provides new ideas for research in related fields.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {4107–4112},
numpages = {6},
keywords = {ancient Chinese texts, external knowledge enhancement, named entity recognition, time-series knowledge base},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@inproceedings{10.1145/3643834.3661498,
author = {Sivertsen, Christian and L\o{}vlie, Anders Sundnes},
title = {Exploring Aesthetic Qualities of Deep Generative Models through Technological (Art) Mediation},
year = {2024},
isbn = {9798400705830},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643834.3661498},
doi = {10.1145/3643834.3661498},
abstract = {Deep Generative Models (DGM) have had a great impact both on visual art and broader visual culture. In this research-through-design project we investigate the use of a DGM for helping museum visitors explore the aesthetics of Edvard Munch’s art. We designed and built an interactive drawing table that allows a user to explore a StyleGAN model trained on sketches by Edvard Munch. The paper makes two novel contributions: 1. It presents a system that allows users to interact with a DGM by drawing on paper (rather than the typical text prompts used by most current systems). 2. We demonstrate how this mode and quality of interaction establish a unique perspective on Munch’s drawings as a practice. Through qualitative evaluation, we discuss how this setup led users towards a specific hermeneutic drawing strategy that enables building competency with the model and by proxy the data it is trained on. We suggest that the resulting interaction may contribute to an "education of attention" helping museum visitors to become attentive to certain visual qualities in Munch’s drawing practice. Finally, we discuss how the concepts of technological mediation and relationality are useful for designing how the output of a DGM is understood by its users.},
booktitle = {Proceedings of the 2024 ACM Designing Interactive Systems Conference},
pages = {2738–2752},
numpages = {15},
keywords = {aesthetics, deep generative model, drawing, fine art, interaction design, machine learning, postphenomenology, stylegan},
location = {Copenhagen, Denmark},
series = {DIS '24}
}

@inproceedings{10.1145/3630106.3658917,
author = {Srinivasan, Ramya},
title = {To See or Not to See: Understanding the Tensions of Algorithmic Curation for Visual Arts},
year = {2024},
isbn = {9798400704505},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3630106.3658917},
doi = {10.1145/3630106.3658917},
abstract = {Algorithmic recommendation is one of the most popular applications of machine learning (ML) systems. While the implication of algorithmic recommendation has been studied in the context of high-stakes domains such as finance and healthcare, there has been very little focus in understanding its impacts with respect to the arts domain. Given that ML is increasingly finding place in the arts domain such as in generative arts and content analysis, in this paper, we examine the tensions of algorithmic curation in the context of visual arts. Through case studies, we describe how curatorial algorithms that are oblivious of broader socio-cultural contexts could potentially result in ethical concerns such as over-representation and misattribution, to name a few. Towards addressing some of these concerns, the paper offers design guidelines. Specifically, the paper outlines repair strategies that suggest ways 1) to engage with cultural stakeholders in building visual art curatorial algorithms, 2) to unlearn biases embedded in digital artworks and their meta-data, and 3) emphasize the need to establish regulatory norms specific to the use of ML in visual art curation. Taking cue from the process employed by artwork curators, the paper also describes how authenticity can be prioritized by re-calibrating visual art curatorial algorithms. The paper also suggest ways through which the potential of state-of-the-art ML curatorial algorithms can be re-imagined towards empowering the audience of artworks. We hope the insights presented in the paper spark interdisciplinary discussions and pave way for fostering reformation in algorithmic curation of visual arts.},
booktitle = {Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency},
pages = {444–455},
numpages = {12},
keywords = {algorithmic recommendation, case studies, curation, machine learning, visual arts},
location = {Rio de Janeiro, Brazil},
series = {FAccT '24}
}

@inproceedings{10.1145/3640457.3688191,
author = {Xie, Zhouhang and Wu, Junda and Jeon, Hyunsik and He, Zhankui and Steck, Harald and Jha, Rahul and Liang, Dawen and Kallus, Nathan and Mcauley, Julian},
title = {Neighborhood-Based Collaborative Filtering for Conversational Recommendation},
year = {2024},
isbn = {9798400705052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3640457.3688191},
doi = {10.1145/3640457.3688191},
abstract = {Conversational recommender systems (CRS) should understand users’ expressed interests, which are frequently semantically rich and knowledge-intensive. Prior works attempt to address this challenge by using external knowledge bases or parametric knowledge in large language models (LLMs). In this paper, we study a complementary solution, exploiting item knowledge in the training data. We hypothesize that many inference-time user requests can be answered by reusing popular crowd-written answers associated with similar training queries. Following this intuition, we define a class of neighborhood-based CRS that makes recommendations by identifying items commonly associated with similar training dialogue contexts. Experiments on Inspired, Redial, and Reddit-Movie benchmarks show our method outperforms state-of-the-art LLMs with 2 billion parameters, and offers on-par performance to 7 billion parameter models while using over 170 times less GPU memory. We also show neighborhood and model-based predictions can be combined to achieve further performance improvements1.},
booktitle = {Proceedings of the 18th ACM Conference on Recommender Systems},
pages = {1045–1050},
numpages = {6},
location = {Bari, Italy},
series = {RecSys '24}
}

@article{10.1145/3702315,
author = {Fan, Wenfei and Pang, Kehan and Lu, Ping and Tian, Chao},
title = {Making It Tractable to Detect and Correct Errors in Graphs},
year = {2024},
issue_date = {December 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {49},
number = {4},
issn = {0362-5915},
url = {https://doi.org/10.1145/3702315},
doi = {10.1145/3702315},
abstract = {This article develops Hercules, a system for entity resolution (ER), conflict resolution (CR), timeliness deduction (TD), and missing value/link imputation (MI) in graphs. It proposes GCR+s, a class of graph cleaning rules (GCR) that support not only predicates for ER and CR but also temporal orders to deduce timeliness and data extraction to impute missing data. As opposed to previous graph rules, GCR+s are defined with a dual graph pattern to accommodate irregular structures of schemaless graphs and adopt patterns of a star form to reduce the complexity. We show that while the implication and satisfiability problems are intractable for GCR+s, it is in polynomial time to detect and correct errors with GCR+s. Underlying Hercules, we train a ranking model to predict the temporal orders on attributes and embed it as a predicate of GCR+s. We provide an algorithm for discovering GCR+s by combining the generations of patterns and predicates. We also develop a method for conducting ER, CR, TD, and MI in the same process to improve the overall quality of graphs by leveraging their interactions and chasing with GCR+s; we show that the method has the Church–Rosser property under certain conditions. Using real-life and synthetic graphs, we empirically verify that Hercules is 53% more accurate than the state-of-the-art graph cleaning systems and performs comparably in efficiency and scalability.},
journal = {ACM Trans. Database Syst.},
month = dec,
articleno = {16},
numpages = {75},
keywords = {Entity resolution, conflict resolution, timeliness deduction, missing data imputation, graph cleaning rules}
}

@proceedings{10.1145/3639474,
title = {ICSE-SEET '24: Proceedings of the 46th International Conference on Software Engineering: Software Engineering Education and Training},
year = {2024},
isbn = {9798400704987},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Lisbon, Portugal}
}

@proceedings{10.1145/3677454,
title = {ARAEML '24: Proceedings of the 2024 International Conference on Advanced Robotics, Automation Engineering and Machine Learning},
year = {2024},
isbn = {9798400717116},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Hangzhou, China}
}

@article{10.1145/3664930,
author = {Fan, Lizhou and Li, Lingyao and Ma, Zihui and Lee, Sanggyu and Yu, Huizi and Hemphill, Libby},
title = {A Bibliometric Review of Large Language Models Research from 2017 to 2023},
year = {2024},
issue_date = {October 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {5},
issn = {2157-6904},
url = {https://doi.org/10.1145/3664930},
doi = {10.1145/3664930},
abstract = {Large language models (LLMs), such as OpenAI's Generative Pre-trained Transformer (GPT), are a class of language models that have demonstrated outstanding performance across a range of natural language processing (NLP) tasks. LLMs have become a highly sought-after research area because of their ability to generate human-like language and their potential to revolutionize science and technology. In this study, we conduct bibliometric and discourse analyses of scholarly literature on LLMs. Synthesizing over 5,000 publications, this article serves as a roadmap for researchers, practitioners, and policymakers to navigate the current landscape of LLMs research. We present the research trends from 2017 to early 2023, identifying patterns in research paradigms and collaborations. We start with analyzing the core algorithm developments and NLP tasks that are fundamental in LLMs research. We then investigate the applications of LLMs in various fields and domains, including medicine, engineering, social science, and humanities. Our review also reveals the dynamic, fast-paced evolution of LLMs research. Overall, this article offers valuable insights into the current state, impact, and potential of LLMs research and its applications.},
journal = {ACM Trans. Intell. Syst. Technol.},
month = oct,
articleno = {91},
numpages = {25},
keywords = {Bibliometric analysis, large language models, discourse analysis, scholarly collaboration networks, topic modeling}
}

@inproceedings{10.1145/3652620.3687806,
author = {Burgue\~{n}o, Lola and Keet, Maria and Kienzle, J\"{o}rg and Michael, Judith and Babur, \"{O}nder},
title = {A Human Behavior Exploration Approach Using LLMs for Cyber-Physical Systems},
year = {2024},
isbn = {9798400706226},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652620.3687806},
doi = {10.1145/3652620.3687806},
abstract = {In the early phases of Cyber-Physical Systems (CPS) development, scoping human behavior plays a significant role, especially when interactions extend beyond expected behavior. Here, it is especially challenging to develop cases that capture the full spectrum of human behavior. Up to now, identifying such behavior of humans remains a task for domain experts. We explore how one can use Large Languages Models (LLMs) in the design phase of systems to provide additional information about human-CPS interaction. Our approach proposes a preliminary ontology describing a hierarchy of types of behavior and relevant CPS components as input for prompt templates. It uses them to generate parts of human behavior descriptions, as well as a canned prompt with one variable about behavior. For demonstration, we take a smart building with a Home Energy System as the use case.An initial user evaluation shows that the behavior descriptions generated with standard and ontology-driven prompts complement each other and are useful when assisting humans. The discovered uncommon behaviors can be used to complete interaction scenarios that eventually result in a more robust CPS implementation.},
booktitle = {Proceedings of the ACM/IEEE 27th International Conference on Model Driven Engineering Languages and Systems},
pages = {578–586},
numpages = {9},
keywords = {human behavior, large language models, cyber-physical systems, user scenario, digital twin},
location = {Linz, Austria},
series = {MODELS Companion '24}
}

@article{10.1145/3656579,
author = {Liang, Wanying and Meo, Pasquale De and Tang, Yong and Zhu, Jia},
title = {A Survey of Multi-modal Knowledge Graphs: Technologies and Trends},
year = {2024},
issue_date = {November 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {56},
number = {11},
issn = {0360-0300},
url = {https://doi.org/10.1145/3656579},
doi = {10.1145/3656579},
abstract = {In recent years, Knowledge Graphs (KGs) have played a crucial role in the development of advanced knowledge-intensive applications, such as recommender systems and semantic search. However, the human sensory system is inherently multi-modal, as objects around us are often represented by a combination of multiple signals, such as visual and textual. Consequently, Multi-modal Knowledge Graphs (MMKGs), which combine structured knowledge representation with multiple modalities, represent a powerful extension of KGs. Although MMKGs can handle certain types of tasks (e.g., visual query answering) or queries that standard KGs cannot process, and they can effectively tackle some standard problems (e.g., entity alignment), we lack a widely accepted definition of MMKG. In this survey, we provide a rigorous definition of MMKGs along with a classification scheme based on how existing approaches address four fundamental challenges: representation, fusion, alignment, and translation, which are crucial to improving an MMKG. Our classification scheme is flexible and allows for easy incorporation of new approaches, as well as a comparison of two approaches in terms of how they address one of the fundamental challenges mentioned above. As the first comprehensive survey of MMKG, this article aims at inspiring and provide a reference for relevant researchers in the field of Artificial Intelligence.},
journal = {ACM Comput. Surv.},
month = jun,
articleno = {273},
numpages = {41},
keywords = {Multi-modal knowledge graphs, four fundamental challenges, pre-training in MMKGs}
}

@proceedings{10.1145/3641234,
title = {SIGGRAPH '24: ACM SIGGRAPH 2024 Posters},
year = {2024},
isbn = {9798400705168},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Denver, CO, USA}
}

@proceedings{10.1145/3614419,
title = {WEBSCI '24: Proceedings of the 16th ACM Web Science Conference},
year = {2024},
isbn = {9798400703348},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Stuttgart, Germany}
}

@inproceedings{10.1145/3676581.3676593,
author = {Zhao, Xiaoyan and He, Yao and Gao, Yankun and Luo, Xu and Ke, Wenjun},
title = {Techniques for Fine-Grained Analysis of Scientific and Technological Intelligence},
year = {2024},
isbn = {9798400716898},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3676581.3676593},
doi = {10.1145/3676581.3676593},
abstract = {In today's world, scientific and technological intelligence information presents challenges such as insufficient annotated samples in interdisciplinary and specialized fields, the continuous emergence of new technologies, and complex interwoven dependencies of technical points. These aspects pose significant obstacles for the fine-grained acquisition and analysis of scientific and technological intelligence. To address these issues, this paper focuses on three areas: domain-aware generation of scientific and technological intelligence samples, extraction of intelligence entity relationships based on continual learning, and mining of technological dependency chains using causal graphs. This research aims to provide foundational techniques and algorithms for the acquisition and analysis of fine-grained scientific and technological intelligence, thereby enhancing our nation's capability in technological trend assessment and development planning in the context of global competition.},
booktitle = {Proceedings of the 2024 2nd International Conference on Communications, Computing and Artificial Intelligence},
pages = {64–70},
numpages = {7},
keywords = {dependency chain mining, relationship extraction, sample generation},
location = {Jeju, Republic of Korea},
series = {CCCAI '24}
}

@inproceedings{10.1145/3627673.3679783,
author = {Anand, Avinash and Nair, Ashwin R and Prasad, Kritarth and Narayan, Vrinda and Lal, Naman and Mahata, Debanjan and Singla, Yaman K and Shah, Rajiv Ratn},
title = {Advances in Citation Text Generation: Leveraging Multi-Source Seq2Seq Models and Large Language Models},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679783},
doi = {10.1145/3627673.3679783},
abstract = {Citation Text Generation (CTG) in scientific documents often relies on standard summarization techniques, which may not fully capture the nuanced relationship between the citing and cited papers. To address this, we present a Multi-Source Citation Text Generation (M-CTG) architecture, leveraging a Seq2Seq transformer framework enhanced with keyphrase embeddings, graph embeddings, and text representations. This approach aims to produce more contextually relevant and accurate citation texts by integrating multiple sources of information. Our methodology is tested using the newly created CTG-S2ORC dataset, consisting of English-language computer science research papers. In a comparative analysis, we explore the performance of traditional Language Models (LMs) and demonstrate how Large Language Models (LLMs), particularly when integrated with various prompting techniques and Knowledge Graphs, offer superior capabilities in analyzing and generating citation texts. In addition to traditional evaluation metrics, we introduce a custom metric that emphasizes the overlap of key terms and semantic similarity, providing a more comprehensive assessment of our model's performance. Our code and data are available at https://github.com/midas-research/M-CTG/tree/main.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {56–64},
numpages = {9},
keywords = {S2ORC, citation text generation, graph embeddings, knowledge graphs, language models, large language models},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@proceedings{10.1145/3641142,
title = {ACSW '24: Proceedings of the 2024 Australasian Computer Science Week},
year = {2024},
isbn = {9798400717307},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Sydney, NSW, Australia}
}

@proceedings{10.1145/3639592,
title = {AICCC '23: Proceedings of the 2023 6th Artificial Intelligence and Cloud Computing Conference},
year = {2023},
isbn = {9798400716225},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Kyoto, Japan}
}

@proceedings{10.1145/3652583,
title = {ICMR '24: Proceedings of the 2024 International Conference on Multimedia Retrieval},
year = {2024},
isbn = {9798400706196},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {We are pleased to present the 2024 edition of the ACM International Conference on Multimedia Retrieval, ACM ICMR 2024, that took place from 10-14 June 2024, in Phuket, Thailand.Effectively and efficiently retrieving information from multimedia collections (e.g., text, image, video, audio, sensor data, 3D) based on user needs is one of the most exciting areas in multimedia research. The Annual ACM International Conference on Multimedia Retrieval (ICMR) offers a great opportunity for exchanging leading-edge multimedia retrieval ideas among researchers, practitioners, and other potential users of multimedia retrieval systems. ACM ICMR was created in 2011 in a merger of ACM CIVR (International Conference on Image and Video Retrieval) and ACM MIR (International Conference on Multimedia Information Retrieval). ACM ICMR serves to illuminate the state of the art in multimedia retrieval. ACM ICMR 2024 in Phuket follows the successful previous editions of ICMR in Trento, Italy 2011; Hong Kong, China 2012; Dallas, USA 2013; Glasgow, UK 2014; Shanghai, China 2015; New York, USA 2016; Bucharest, Romania 2017; Yokohama, Japan 2018; Ottawa, Canada 2019; Dublin, Ireland 2020 (online); Taipei, Taiwan 2021 (online); Newark, USA 2022 (hybrid); and Thessaloniki, Greece 2023 (hybrid).},
location = {Phuket, Thailand}
}

@inproceedings{10.1145/3613905.3651112,
author = {Zhao, Yijun and Pan, Jiangyu and Dong, Yan and Dong, Tianshu and Wang, Guanyun and Ying, Fangtian and Shen, Qihang and Cao, Jiacheng},
title = {Language Urban Odyssey: A Serious Game for Enhancing Second Language Acquisition through Large Language Models},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3651112},
doi = {10.1145/3613905.3651112},
abstract = {Traditional second language acquisition (SLA) often lacks deep immersion in authentic environments, presenting high learning and resource challenges. To overcome this, we introduced "Language Urban Odyssey" (LUO), a serious game designed to offer an affordable language practice environment. LUO combines Large Language Models (LLMs) with game-based learning, creating an immersive and interactive experience. Players interact with AI-driven characters in a fictional city, leveraging ChatGPT 3.5’s capabilities for simulating real language use and cultural diversity. The game aims to reduce language learning barriers, ignite interest, and provide practical scenarios. Test results show LUO significantly boosts interest and proficiency in language learning. Players praise its engaging narrative, interactive dialogues, and adaptive experience. However, while LUO is beneficial, it’s crucial to recognize gamified learning’s limits; genuine language fluency still requires real-life communication practice and validation.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {219},
numpages = {7},
keywords = {Educational Games, Human-AI Interaction, Large Language Models, Second Language Acquisition},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}

@proceedings{10.1145/3703187,
title = {CISAI '24: Proceedings of the 2024 7th International Conference on Computer Information Science and Artificial Intelligence},
year = {2024},
isbn = {9798400707254},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3652628,
title = {ICAICE '23: Proceedings of the 4th International Conference on Artificial Intelligence and Computer Engineering},
year = {2023},
isbn = {9798400708831},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Dalian, China}
}

@proceedings{10.1145/3643916,
title = {ICPC '24: Proceedings of the 32nd IEEE/ACM International Conference on Program Comprehension},
year = {2024},
isbn = {9798400705861},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {ICPC is the premier (CORE A) venue for research on program comprehension. Research on program comprehension encompasses both human activities for comprehending the software and technologies for supporting such comprehension.},
location = {Lisbon, Portugal}
}

@inproceedings{10.1145/3651671.3651778,
author = {Liu, Lijuan and Shi, Li},
title = {Application case study, security challenges and countermeasures of AIGC in the context of metaverse},
year = {2024},
isbn = {9798400709234},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3651671.3651778},
doi = {10.1145/3651671.3651778},
abstract = {With the rapid development of artificial intelligence technology, the era of AIGC is coming. This paper relies on the Metaverse theoretical system to conduct analysis and research from the perspective of AIGC core technology as well as AIGC application cases. Take ChatGPT and ERNIE Bot as products examples. Besides, security challenges are taken into consideration, it brings the risk of sensitive content, it leads to lower costs for criminal activities, it brings cross-border data security risk, and it will even reduce the public's thinking ability. To deal with the above security challenges, the security response methods are discussed from the perspective of decision-makers, program developers, and product users, in the hope that AIGC can better serve society.},
booktitle = {Proceedings of the 2024 16th International Conference on Machine Learning and Computing},
pages = {228–232},
numpages = {5},
keywords = {ChatGPT, Metaverse, intelligent applications, security challenges},
location = {Shenzhen, China},
series = {ICMLC '24}
}

@article{10.1145/3659942,
author = {Mashayekhi, Yoosof and Li, Nan and Kang, Bo and Lijffijt, Jefrey and De Bie, Tijl},
title = {A Challenge-based Survey of E-recruitment Recommendation Systems},
year = {2024},
issue_date = {October 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {56},
number = {10},
issn = {0360-0300},
url = {https://doi.org/10.1145/3659942},
doi = {10.1145/3659942},
abstract = {E-recruitment recommendation systems recommend jobs to job seekers and job seekers to recruiters. The recommendations are generated based on the suitability of job seekers for positions and on job seekers’ and recruiters’ preferences. Therefore, e-recruitment recommendation systems may greatly impact people’s careers. Moreover, by affecting the hiring processes of the companies, e-recruitment recommendation systems play an important role in shaping the competitive edge of companies. Hence, it seems prudent to consider what (unique) challenges there are for recommendation systems in e-recruitment. Existing surveys on this topic discuss past studies from the algorithmic perspective, e.g., by categorizing them into collaborative filtering, content-based, and hybrid methods. This survey, instead, takes a complementary, challenge-based approach. We believe this is more practical for developers facing a concrete e-recruitment design task with a specific set of challenges, and also for researchers that look for impactful research projects in this domain. In this survey, we first identify the main challenges in the e-recruitment recommendation research. Next, we discuss how those challenges have been studied in the literature. Finally, we provide future research directions that we consider most promising in the e-recruitment recommendation domain.},
journal = {ACM Comput. Surv.},
month = jun,
articleno = {252},
numpages = {33},
keywords = {Job recommendation, e-recruitment recommendation}
}

@inproceedings{10.1145/3637528.3671491,
author = {Alam, Mehwish and Buscaldi, Davide and Cochez, Michael and Gesese, Genet Asefa and Osborne, Francesco and Reforgiato Recupero, Diego},
title = {Workshop on Deep Learning and Large Language Models for Knowledge Graphs (DL4KG)},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671491},
doi = {10.1145/3637528.3671491},
abstract = {The use of Knowledge Graphs (KGs) which constitute large networks of real-world entities and their interrelationships, has grown rapidly. A substantial body of research has emerged, exploring the integration of deep learning (DL) and large language models (LLMs) with KGs. This workshop aims to bring together leading researchers in the field to discuss and foster collaborations on the intersection of KG and DL/LLMs.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {6704–6705},
numpages = {2},
keywords = {artificial intelligence, deep learning, knowledge graphs, large language models},
location = {Barcelona, Spain},
series = {KDD '24}
}

@article{10.1145/3653984,
author = {Zhuang, Haojie and Zhang, Wei and Chen, Weitong and Yang, Jian and Sheng, Quan Z.},
title = {Improving Faithfulness and Factuality with Contrastive Learning in Explainable Recommendation},
year = {2024},
issue_date = {February 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {1},
issn = {2157-6904},
url = {https://doi.org/10.1145/3653984},
doi = {10.1145/3653984},
abstract = {Recommender systems have become increasingly important in navigating the vast amount of information and options available in various domains. By tailoring and personalizing recommendations to user preferences and interests, these systems improve the user experience, efficiency, and satisfaction. With a growing demand for transparency and understanding of recommendation outputs, explainable recommender systems have gained growing attention in recent years. Additionally, as user reviews could be considered the rationales behind why the user likes (or dislikes) the products, generating informative and reliable reviews alongside recommendations has thus emerged as a research focus in explainable recommendation. However, the model-generated reviews might contain factually inconsistent contents (i.e., the hallucination issue), which would thus compromise the recommendation rationales. To address this issue, we propose a contrastive learning framework to improve the faithfulness and factuality in explainable recommendation in this article. We further develop different strategies of generating positive and negative examples for contrastive learning, such as back-translation or synonym substitution for positive examples, and editing positive examples or utilizing model-generated texts for negative examples. Our proposed method optimizes the model to distinguish faithful explanations (i.e., positive examples) and unfaithful ones with factual errors (i.e., negative examples), which thus drives the model to generate faithful reviews as explanations while avoiding inconsistent contents. Extensive experiments and analysis on three benchmark datasets show that our proposed model outperforms other review generation baselines in faithfulness and factuality. In addition, the proposed contrastive learning component could be easily incorporated into other explainable recommender systems in a plug-and-play manner.},
journal = {ACM Trans. Intell. Syst. Technol.},
month = dec,
articleno = {9},
numpages = {23},
keywords = {Recommender systems, explainable recommendation, review generation}
}

@article{10.1145/3700748,
author = {Mostafa, Mohamed and Almogren, Ahmad S and Al-Qurishi, Muhammad and Alrubaian, Majed},
title = {Modality Deep-learning Frameworks for Fake News Detection on Social Networks: A Systematic Literature Review},
year = {2024},
issue_date = {March 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {57},
number = {3},
issn = {0360-0300},
url = {https://doi.org/10.1145/3700748},
doi = {10.1145/3700748},
abstract = {Fake news on social networks is a challenging problem due to the rapid dissemination and volume of information, as well as the ease of creating and sharing content anonymously. Fake news stories are problematic not only for the credibility of online journalism, but also due to their detrimental real-world consequences. The primary research objective of this study is to identify recent state-of-the-art deep learning methods used to detect fake news in social networks. This article presents a systematic literature review of deep learning-based fake news detection models in social networks. The methodology followed a rigorous approach, including predefined criteria for study selection of deep learning modalities. This study focuses on the types of deep learning modalities: unimodal (refers to the use of a single model for analysis or modeling purposes) and multimodal models (refers to the integration of multiple models). The results of this review reveal the strengths and weaknesses of modalities approaches, as well as the limitations of low-resource languages datasets. Furthermore, it provides insights into future directions for deep learning models and different fact-checking techniques. At the end of this study, we discuss the problem of fake news detection in the era of large language models in terms of advantages, drawbacks, and challenges.},
journal = {ACM Comput. Surv.},
month = nov,
articleno = {77},
numpages = {50},
keywords = {Social computing, deep learning, modality architectures, unimodal, multimodal, fake news detection, text classification}
}

@inproceedings{10.1145/3613904.3642149,
author = {Liu, Michael Xieyang and Wu, Tongshuang and Chen, Tianying and Li, Franklin Mingzhe and Kittur, Aniket and Myers, Brad A},
title = {Selenite: Scaffolding Online Sensemaking with Comprehensive Overviews Elicited from Large Language Models},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642149},
doi = {10.1145/3613904.3642149},
abstract = {Sensemaking in unfamiliar domains can be challenging, demanding considerable user effort to compare different options with respect to various criteria. Prior research and our formative study found that people would benefit from reading an overview of an information space upfront, including the criteria others previously found useful. However, existing sensemaking tools struggle with the “cold-start” problem — it not only requires significant input from previous users to generate and share these overviews, but such overviews may also turn out to be biased and incomplete. In this work, we introduce a novel system, Selenite, which leverages Large Language Models (LLMs) as reasoning machines and knowledge retrievers to automatically produce a comprehensive overview of options and criteria to jumpstart users’ sensemaking processes. Subsequently, Selenite also adapts as people use it, helping users find, read, and navigate unfamiliar information in a systematic yet personalized manner. Through three studies, we found that Selenite produced accurate and high-quality overviews reliably, significantly accelerated users’ information processing, and effectively improved their overall comprehension and sensemaking experience.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {837},
numpages = {26},
keywords = {Human-AI Collaboration, Large Language Models, Natural Language Processing, Sensemaking},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3705677.3705701,
author = {Cai, Zhengna and Fan, Yujing and Xin, Jianfeng},
title = {Research on Medical Text Named Entity Recognition Model Based on Prompt Contrastive Learning},
year = {2025},
isbn = {9798400711848},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3705677.3705701},
doi = {10.1145/3705677.3705701},
abstract = {Medical Named Entity Recognition (NER) aims to automatically identify entities like diseases, drugs, and symptoms from medical texts, supporting medical knowledge graphs, clinical decision-making, and intelligent systems. Current research relies on deep learning models, particularly pre-trained language models like BERT, improving recognition accuracy. Challenges include data sparsity, ambiguous boundaries, and synonym diversity, affecting generalization on specific datasets. To address this, we enhance BERT with prompt learning and contrastive learning, using learnable entity class embeddings and similarity computations to improve classification and recognition on few-shot datasets. Our model achieves F1 scores of 90.19% on the CCKS 2019 dataset and 83.30% on the JNLPBA dataset.},
booktitle = {Proceedings of the 4th International Conference on Computer, Internet of Things and Control Engineering},
pages = {139–144},
numpages = {6},
keywords = {Contrast Learning, Named Entity Recognition, Prompt Learning},
location = {
},
series = {CITCE '24}
}

@article{10.1145/3664597,
author = {Wan, Yao and Bi, Zhangqian and He, Yang and Zhang, Jianguo and Zhang, Hongyu and Sui, Yulei and Xu, Guandong and Jin, Hai and Yu, Philip},
title = {Deep Learning for Code Intelligence: Survey, Benchmark and Toolkit},
year = {2024},
issue_date = {December 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {56},
number = {12},
issn = {0360-0300},
url = {https://doi.org/10.1145/3664597},
doi = {10.1145/3664597},
abstract = {Code intelligence leverages machine learning techniques to extract knowledge from extensive code corpora, with the aim of developing intelligent tools to improve the quality and productivity of computer programming. Currently, there is already a thriving research community focusing on code intelligence, with efforts ranging from software engineering, machine learning, data mining, natural language processing, and programming languages. In this paper, we conduct a comprehensive literature review on deep learning for code intelligence, from the aspects of code representation learning, deep learning techniques, and application tasks. We also benchmark several state-of-the-art neural models for code intelligence, and provide an open-source toolkit tailored for the rapid prototyping of deep-learning-based code intelligence models. In particular, we inspect the existing code intelligence models under the basis of code representation learning, and provide a comprehensive overview to enhance comprehension of the present state of code intelligence. Furthermore, we publicly release the source code and data resources to provide the community with a ready-to-use benchmark, which can facilitate the evaluation and comparison of existing and future code intelligence models (https://xcodemind.github.io). At last, we also point out several challenging and promising directions for future research.},
journal = {ACM Comput. Surv.},
month = oct,
articleno = {309},
numpages = {41},
keywords = {Code intelligence, code representation, deep learning, large language models, survey, benchmark, toolkit}
}

@inproceedings{10.1145/3687311.3687339,
author = {Yang, Xin and Zhao, Fengjuan},
title = {Integrating AI with Pedagogies: Drama, Multimodal and the Production-oriented Approach- a Study Based on the 6th SFLEP Intercultural Competence Contest},
year = {2024},
isbn = {9798400709920},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3687311.3687339},
doi = {10.1145/3687311.3687339},
abstract = {Cultural studies have garnered significant attention in China for many decades, and the cultivation of intercultural competence within the academic sphere has been meticulously developed, particularly within the university context. Although intercultural competence is inherently multidisciplinary, its cultivation is predominantly integrated into the pedagogy of foreign language instruction. The discourse surrounding intercultural communication is mainly led by educators and scholars in the field of foreign language studies. The SFLEP Intercultural Competence Contest comprises three pivotal tasks: the development of intercultural case studies, scenario analysis, and the narration of Chinese stories. The rapid development of AI has opened new avenues in the field of education, particularly in language learning. The integration of AI with traditional pedagogies like drama, multimodal learning, and the production-oriented approach has been observed to enrich the learning experience and improve intercultural competence. A thorough examination of the 6th iteration of the contest provides the foundation for this exploration. The study not only highlights the potential of AI integrated approaches but also underscores their significant relevance in enhancing scaffolding techniques in foreign language education.},
booktitle = {Proceedings of the 2024 International Conference on Intelligent Education and Computer Technology},
pages = {151–157},
numpages = {7},
location = {Guilin, China},
series = {IECT '24}
}

@proceedings{10.1145/3640310,
title = {MODELS '24: Proceedings of the ACM/IEEE 27th International Conference on Model Driven Engineering Languages and Systems},
year = {2024},
isbn = {9798400705045},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Linz, Austria}
}

@inproceedings{10.1145/3589335.3651480,
author = {Ahn, Dawon and Shiao, William and Khaled, Arindam and Bauer, Andrew and Poulis, Stefanos and Papalexakis, Evangelos E.},
title = {Compact Interpretable Tensor Graph Multi-Modal News Embeddings},
year = {2024},
isbn = {9798400701726},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589335.3651480},
doi = {10.1145/3589335.3651480},
abstract = {Online news articles encompass a variety of modalities such as text and images. How can we learn a representation that incorporates information from all those modalities in a compact and interpretable manner? In this paper, we propose CITEM (Compact Interpretable Tensor graph multi-modal news EMbedding), a tensor-based framework for compact and interpretable multi-modal news representations. CITEM generates a tensor graph consisting of a news similarity graph for each modality and employs a tensor decomposition to produce compact and interpretable embeddings, each dimension of which is a heterogeneous co-cluster of news articles and corresponding modalities. We extensively validate CITEM compared to baselines on two news classification tasks: misinformation news detection and news categorization. The experimental results show that CITEM performs within the same range of AUC as state-of-the-art baselines while producing 7x to 10.5x more compact embeddings. In addition, each embedding dimension of CITEM is interpretable, representing a latent co-cluster of articles.},
booktitle = {Companion Proceedings of the ACM Web Conference 2024},
pages = {847–850},
numpages = {4},
keywords = {interpretable multi-modal embeddings, tensor decomposition},
location = {Singapore, Singapore},
series = {WWW '24}
}

@article{10.1109/TCBB.2024.3412174,
author = {Dai, Yuanfei and Zhang, Bin and Wang, Shiping},
title = {Distantly Supervised Biomedical Relation Extraction via Negative Learning and Noisy Student Self-Training},
year = {2024},
issue_date = {Nov.-Dec. 2024},
publisher = {IEEE Computer Society Press},
address = {Washington, DC, USA},
volume = {21},
number = {6},
issn = {1545-5963},
url = {https://doi.org/10.1109/TCBB.2024.3412174},
doi = {10.1109/TCBB.2024.3412174},
abstract = {Biomedical relation extraction aims to identify underlying relationships among entities, such as gene associations and drug interactions, within biomedical texts. Despite advancements in relation extraction in general knowledge domains, the scarcity of labeled training data remains a significant challenge in the biomedical field. This paper provides a novel approach for biomedical relation extraction that leverages a noisy student self-training strategy combined with negative learning. This method addresses the challenge of data insufficiency by utilizing distantly supervised data to generate high-quality labeled samples. Negative learning, as opposed to traditional positive learning, offers a more robust mechanism to discern and relabel noisy samples, preventing model overfitting. The integration of these techniques ensures enhanced noise reduction and relabeling capabilities, leading to improved performance even with noisy datasets. Experimental results demonstrate the effectiveness of the proposed framework in mitigating the impact of noisy data and outperforming existing benchmarks.},
journal = {IEEE/ACM Trans. Comput. Biol. Bioinformatics},
month = jun,
pages = {1697–1708},
numpages = {12}
}

@inproceedings{10.1145/3639479.3639496,
author = {Shen, Yingli and Zhao, Xiaobing},
title = {Reinforcement Learning in Natural Language Processing: A Survey},
year = {2024},
isbn = {9798400709241},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639479.3639496},
doi = {10.1145/3639479.3639496},
abstract = {Reinforcement learning (RL) is a powerful technique for learning from data and feedback, but its effective application to natural language processing (NLP) tasks remains an open question. Consequently, this paper first introduces the general concepts of RL and the common approaches. Subsequently, we review the task construction settings and the application of RL for various NLP problems, such as machine translation, dialogue system, and text generation. Finally, we discuss some promising research directions and challenges of RL in NLP. We hope that our work can provide a comprehensive overview and inspire more research on this promising yet challenging topic.},
booktitle = {Proceedings of the 2023 6th International Conference on Machine Learning and Natural Language Processing},
pages = {84–90},
numpages = {7},
keywords = {Application, Natural Language Processing, Reinforcement Learning, Survey},
location = {Sanya, China},
series = {MLNLP '23}
}

@article{10.1145/3697838,
author = {Qu, Shilin and Wang, Weiqing and Zhou, Xin and Zhan, Haolan and Li, Zhuang and Qu, Lizhen and Luo, Linhao and Li, Yuan-Fang and Haffari, Gholamreza},
title = {Scalable Frame-based Construction of Sociocultural NormBases for Socially-Aware Dialogues},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1551-6857},
url = {https://doi.org/10.1145/3697838},
doi = {10.1145/3697838},
abstract = {Sociocultural norms serve as guiding principles for personal conduct in social interactions, emphasizing respect, cooperation, and appropriate behavior, which is able to benefit tasks including conversational information retrieval, contextual information retrieval and retrieval-enhanced machine learning. We propose a scalable approach for constructing a Sociocultural Norm (Scn) Base using Large Language Models (LLMs) for socially aware dialogues. We construct a comprehensive and publicly accessible Chinese Sociocultural NormBase (ChineseNormBase). Our approach utilizes socially-aware dialogues, enriched with contextual frames, as the primary data source to constrain the generating process and reduce the hallucinations. This enables extracting of high-quality and nuanced natural-language norm statements, leveraging the pragmatic implications of utterances with respect to the situation. As real dialogue annotated with gold frames are not readily available, we propose using synthetic data. Our empirical results show: (i) the quality of the Scns derived from synthetic data is comparable to that from real dialogues annotated with gold frames, and (ii) the quality of the Scns extracted from real data, annotated with either silver (predicted) or gold frames, surpasses that without the frame annotations. We further show the effectiveness of the extracted Scns in a RAG-based (Retrieval-Augmented Generation) model to reason about multiple downstream dialogue tasks.},
note = {Just Accepted},
journal = {ACM Trans. Multimedia Comput. Commun. Appl.},
month = oct,
keywords = {Social-culrutal Norm Base, Chinese Culture, Retrieval-Augmented Generation, Norm Construction}
}

@inproceedings{10.1145/3637528.3671873,
author = {Yan, Mengyi and Wang, Yaoshu and Pang, Kehan and Xie, Min and Li, Jianxin},
title = {Efficient Mixture of Experts based on Large Language Models for Low-Resource Data Preprocessing},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671873},
doi = {10.1145/3637528.3671873},
abstract = {Data preprocessing (DP) that transforms erroneous and raw data to a clean version is a cornerstone of the data mining pipeline. Due to the diverse requirements of downstream tasks, data scientists and domain experts have to handcraft domain-specific rules or train ML models with annotated examples, which is costly/time-consuming. In this paper, we present MELD (&lt;u&gt;M&lt;/u&gt;ixture of &lt;u&gt;E&lt;/u&gt;xperts on &lt;u&gt;L&lt;/u&gt;arge Language Models for &lt;u&gt;D&lt;/u&gt;ata Preprocessing), a universal solver for low-resource DP. MELD adopts a Mixture-of-Experts (MoE) architecture that enables the amalgamation and enhancement of domain-specific experts trained on limited annotated examples. To fine-tune MELD, we develop a suite of expert-tuning and MoE-tuning techniques, including a retrieval augmented generation (RAG) system, meta-path search for data augmentation, expert refinement and router network training based on information bottleneck. To further verify the effectiveness of MELD, we theoretically prove that MoE in MELD is superior than a single expert and the router network is able to dispatch data to the right experts. Finally, we conducted extensive experiments on 19 datasets over 10 DP tasks to show that MELD outperforms the state-of-the-art methods in both effectiveness and efficiency. More importantly, MELD is able to be fine-tuned in a low-resource environment, e.g. a local, single and low-priced 3090 GPU.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {3690–3701},
numpages = {12},
keywords = {LLMs, data preprocessing, low-resource, mixture of expert},
location = {Barcelona, Spain},
series = {KDD '24}
}

@proceedings{10.1145/3678610,
title = {ICSLT '24: Proceedings of the 2024 10th International Conference on e-Society, e-Learning and e-Technologies (ICSLT)},
year = {2024},
isbn = {9798400716799},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3679318,
title = {NordiCHI '24: Proceedings of the 13th Nordic Conference on Human-Computer Interaction},
year = {2024},
isbn = {9798400709661},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Uppsala, Sweden}
}

@inproceedings{10.1145/3627673.3679883,
author = {Yang, Xinjie and Gong, Xiaocheng and Tang, Binghao and Lei, Yang and Deng, Yayue and Ouyang, Huan and Zhao, Gang and Luo, Lei and Feng, Yunling and Duan, Bin and Li, Si and Xu, Yajing},
title = {CAG: A Consistency-Adaptive Text-Image Alignment Generation for Joint Multimodal Entity-Relation Extraction},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679883},
doi = {10.1145/3627673.3679883},
abstract = {Joint Multimodal Entity-Relation Extraction (JMERE) aims to extract entity-relationship triples in texts from given image-text pairs. As a joint multimodal information extraction task, it has attracted increasing research interest. Previous works of JMERE typically utilize graph networks to align textual entities and visual objects and achieve promising performance. However, these methods do not pay attention to the inconsistency between text and image and the straight alignment could limit the performance of JMERE models. In this paper, we propose a Consistency-adaptive text-image Alignment Generation (CAG) framework for various text-image consistency scenarios. Specifically, we propose a Consistency Factor (CF) to measure the consistency between images and texts. We also design consistency-adaptive contrastive learning based on CF, which can reduce the impact of inconsistent visual and textual information. Additionally, we adopt JMERE-specifical instruction tuning for better entity-relationship triplet generation. Experimental results on the JMERE dataset demonstrate that our proposed CAG is effective and achieves state-of-the-art performance.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {4183–4187},
numpages = {5},
keywords = {contrastive learning, instruction tuning, joint multimodal entity-relation extraction, multimodal alignment},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@proceedings{10.1145/3698587,
title = {BCB '24: Proceedings of the 15th ACM International Conference on Bioinformatics, Computational Biology and Health Informatics},
year = {2024},
isbn = {9798400713026},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Shenzhen, China}
}

@inproceedings{10.1145/3663976.3664023,
author = {Sun, Yaru and Yang, Ying and Fu, Wenhao},
title = {Exploring Synergies between Causal Models and LargeLanguage Models for Enhanced Understanding and Inference},
year = {2024},
isbn = {9798400716607},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663976.3664023},
doi = {10.1145/3663976.3664023},
abstract = {Large language models (LLMs) have sparked a new wave of excitement in the field of artificial intelligence, thanks to their robust generative capabilities. However, they fall short when it comes to comprehending factual knowledge and logical reasoning. In contrast, causal models demonstrate superior interpretability, resilience against disturbances, and decision-support capabilities. By integrating event generation mechanisms and external knowledge, causal models can enhance the reasoning and interpretability of LLMs. Nevertheless, the complex construction and iterative nature of causal models pose challenges that push the boundaries of current frameworks. Thus, leveraging the strengths of both LLMs and causal models can effectively address the limitations of LLMs in logical reasoning, complex inference, and causal deduction, as well as tackle the complexities and difficulties encountered in the establishment and analysis of causal models. These challenges include distinguishing between relevance and causality, handling reverse relationships, and managing interactions. This paper proposes a technical roadmap for a collaborative approach between LLMs and causal models, exploring four different methods of collaboration: causal relationship modeling, causal knowledge injection, causal perception, and causal relationship constraints. We review and summarize existing work while identifying future research directions in harnessing the synergy between LLMs and causal models.},
booktitle = {Proceedings of the 2024 2nd Asia Conference on Computer Vision, Image Processing and Pattern Recognition},
articleno = {38},
numpages = {8},
keywords = {Causal Knowledge Infusion, Causal Models, Causal Perception, Large Language Models},
location = {Xiamen, China},
series = {CVIPPR '24}
}

@inproceedings{10.5555/3635637.3663263,
author = {Rodriguez, Sebastian and Thangarajah, John},
title = {Explainable Agents (XAg) by Design},
year = {2024},
isbn = {9798400704864},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {The likes of ChatGPT has propelled the use of AI techniques beyond our community's expectations. Along with this, the fear of AI has also risen, in particular around the ability, or lack thereof, of the AI system to explain its behaviours. Explainability is a key element of building trust and an important issue for our community. In this paper we advocate for agents that are explainable-by-design, that is, explainability is built into the development of agents rather than an afterthought. We propose key features of an explainable agent (XAg) system and propose a general framework that enables explainability. We advocate the use of design patterns to develop XAgs and propose a general design pattern that can be used for any agent architecture. We instantiate our framework for goal-based agents and implement the framework for the SARL agent programming language coupled with a state-of-the-art event management system. We make a call to the developers of other agent programming languages (APLs) in our community to follow suit by instantiating the general framework we propose into their APL, perhaps even enhancing the framework we present. We also propose an open repository of design patterns and examples for agent systems. If nothing else, we hope this paper will inspire further work on XAg from the design perspective as it is critical that multi agent systems are explainable by design!},
booktitle = {Proceedings of the 23rd International Conference on Autonomous Agents and Multiagent Systems},
pages = {2712–2716},
numpages = {5},
keywords = {aose, emas, explainable ai},
location = {Auckland, New Zealand},
series = {AAMAS '24}
}

@article{10.1109/TASLP.2024.3394778,
author = {Hu, Maodi and Qian, Li and Chang, Zhijun and Zhang, Zhixiong},
title = {KDPG-Enhanced MRC Framework for Scientific Entity Recognition in Survey Papers},
year = {2024},
issue_date = {2024},
publisher = {IEEE Press},
volume = {32},
issn = {2329-9290},
url = {https://doi.org/10.1109/TASLP.2024.3394778},
doi = {10.1109/TASLP.2024.3394778},
abstract = {Scientific survey papers play a pivotal role in advancing knowledge and scientific progress by providing concise summaries and analyses of research trends and findings. To facilitate better knowledge organization and analysis, we have undertaken the challenge of defining the scientific entity recognition task for survey papers and carefully curated a dataset that closely emulates real-world scenarios. The scientific entity recognition task presents unique challenges, including multi-label, low-resource, and nested scenarios. To address these challenges, we propose a unified framework based on the machine reading comprehension (MRC) paradigm. This framework not only supports nested and multi-label settings but also enables the effective transfer of information from high-resource categories to low-resource ones, ensuring adaptability and robustness. To further enhance performance, we introduce the Knowledge-Driven Prototype Guidance (KDPG) module, seamlessly integrated into a two-phase learning strategy. The KDPG module leverages prior knowledge and acts as an initial prototype-based manifold constraint, effectively harnessing the power of few-shot learning capabilities. Through this integration, our approach complements the classification learning tasks for entity recognition, resulting in improved accuracy and efficiency. Our experimental results validate the effectiveness of the proposed KDPG-enhanced MRC framework, showcasing its leading performance on publicly available datasets and our collected scientific survey paper dataset.},
journal = {IEEE/ACM Trans. Audio, Speech and Lang. Proc.},
month = apr,
pages = {2532–2543},
numpages = {12}
}

@article{10.1145/3696379,
author = {Bui, Minh-Thanh and Boffa, Matteo and Valentim, Rodolfo Vieira and Navarro, Jose Manuel and Chen, Fuxing and Bao, Xiaosheng and Houidi, Zied Ben and Rossi, Dario},
title = {A Systematic Comparison of Large Language Models Performance for Intrusion Detection},
year = {2024},
issue_date = {December 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {CoNEXT4},
url = {https://doi.org/10.1145/3696379},
doi = {10.1145/3696379},
abstract = {We explore the capabilities of Large Language Models (LLMs) to assist or substitute devices (i.e., firewalls) and humans (i.e., security experts) respectively in the detection and analysis of security incidents. We leverage transformer-based technologies, from relatively small to foundational sizes, to address the problem of correctly identifying the attack severity (and accessorily identifying and explaining the attack type). We contrast a broad range of LLM techniques (prompting, retrieval augmented generation, and fine-tuning of several models) using state-of-the-art machine learning models as a baseline. Using proprietary data from commercial deployment, our study provides an unbiased picture of the strengths and weaknesses of LLM for intrusion detection.},
journal = {Proc. ACM Netw.},
month = nov,
articleno = {22},
numpages = {23},
keywords = {computing methodologies, firewalls, intrusion detection systems, machine learning, natural language processing, security and privacy}
}

@proceedings{10.1145/3651671,
title = {ICMLC '24: Proceedings of the 2024 16th International Conference on Machine Learning and Computing},
year = {2024},
isbn = {9798400709234},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Shenzhen, China}
}

@inproceedings{10.1145/3660043.3660126,
author = {Cui, Xiaofeng and Li, Liang},
title = {Conversational Recommender Systems based on Topic Prediction and Retrieval},
year = {2024},
isbn = {9798400716157},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3660043.3660126},
doi = {10.1145/3660043.3660126},
abstract = {The goal of conversation recommendation systems is to provide users with high-quality, personalized responses by analyzing conversation history, understanding user intent and context, and utilizing relevant knowledge and data. Existing conversation recommendation systems based on prompt learning, which generate response templates from fused knowledge representations generated by pre-trained semantic fusion modules, task-specific soft tokens and conversation contexts, utilize response templates generated from conversation sub-tasks as an important part of the prompts to enhance the recommendation subtask. However, the prompt information in existing methods is limited and may not fit well with the recommendation results when generating the final conversation. To this end, this article proposes a method, TPRCRS (Conversational Recommender Systems based on Topic Prediction and Retrieval), which predicts topics through the conversation context, the previous round of conversation topics, and the behavior of users and systems. Subsequently, through conversation topics, vocabulary, entities and semantic fusion and pre-training, using the fused topics to search in the datasets. When a result is found, it is treated as a conversation template and applied to the recommendation task; otherwise, the prompt is used to generate a conversation template. Finally, the optimal reply is generated through a hint learning method. Experiments show that TPRCRS achieves significantly improved results in two tasks.},
booktitle = {Proceedings of the 2023 International Conference on Information Education and Artificial Intelligence},
pages = {466–471},
numpages = {6},
location = {Xiamen, China},
series = {ICIEAI '23}
}

@proceedings{10.1145/3698300,
title = {ICBDT '24: Proceedings of the 2024 7th International Conference on Big Data Technologies},
year = {2024},
isbn = {9798400717512},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3678726,
title = {ICEMT '24: Proceedings of the 2024 8th International Conference on Education and Multimedia Technology},
year = {2024},
isbn = {9798400717611},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Tokyo, Japan}
}

@article{10.1145/3655103.3655110,
author = {Chen, Zhikai and Mao, Haitao and Li, Hang and Jin, Wei and Wen, Hongzhi and Wei, Xiaochi and Wang, Shuaiqiang and Yin, Dawei and Fan, Wenqi and Liu, Hui and Tang, Jiliang},
title = {Exploring the Potential of Large Language Models (LLMs)in Learning on Graphs},
year = {2024},
issue_date = {December 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {25},
number = {2},
issn = {1931-0145},
url = {https://doi.org/10.1145/3655103.3655110},
doi = {10.1145/3655103.3655110},
abstract = {Learning on Graphs has attracted immense attention due to its wide real-world applications. The most popular pipeline for learning on graphs with textual node attributes primarily relies on Graph Neural Networks (GNNs), and utilizes shallow text embedding as initial node representations, which has limitations in general knowledge and profound semantic understanding. In recent years, Large Language Models (LLMs) have been proven to possess extensive common knowledge and powerful semantic comprehension abilities that have revolutionized existing workflows to handle text data. In this paper, we aim to explore the potential of LLMs in graph machine learning, especially the node classification task, and investigate two possible pipelines: LLMs-as-Enhancers and LLMs-as-Predictors. The former leverages LLMs to enhance nodes' text attributes with their massive knowledge and then generate predictions through GNNs. The latter attempts to directly employ LLMs as standalone predictors. We conduct comprehensive and systematical studies on these two pipelines under various settings. From comprehensive empirical results, we make original observations and find new insights that open new possibilities and suggest promising directions to leverage LLMs for learning on graphs. Our codes and datasets are available at: https://github.com/CurryTang/Graph-LLM .},
journal = {SIGKDD Explor. Newsl.},
month = mar,
pages = {42–61},
numpages = {20}
}

@proceedings{10.1145/3698322,
title = {EuroPLoP '24: Proceedings of the 29th European Conference on Pattern Languages of Programs, People, and Practices},
year = {2024},
isbn = {9798400716836},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@inproceedings{10.1145/3664647.3681522,
author = {Chen, Jiali and Cai, Yi and Xu, Ruohang and Wang, Jiexin and Xie, Jiayuan and Li, Qing},
title = {Deconfounded Emotion Guidance Sticker Selection with Causal Inference},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3681522},
doi = {10.1145/3664647.3681522},
abstract = {With the increasing popularity of online social applications, stickers have become common in online chats. Teaching a model to select the appropriate sticker from a set of candidate stickers based on dialogue context is important for optimizing the user experience. Existing methods have proposed leveraging emotional information to facilitate the selection of appropriate stickers. However, considering the frequent co-occurrence among sticker images, words with emotional preference in the dialogue and emotion labels, these methods tend to over-rely on such dataset bias, inducing spurious correlations during training. As a result, these methods may select inappropriate stickers that do not match users' intended expression. In this paper, we introduce a causal graph to explicitly identify the spurious correlations in the sticker selection task. Building upon the analysis, we propose a Causal Knowledge-Enhanced Sticker Selection model to mitigate spurious correlations. Specifically, we design a knowledge-enhanced emotional utterance extractor to identify emotional information within dialogues. Then an interventional visual feature extractor is employed to obtain unbiased visual features, aligning them with the emotional utterances representation. Finally, a standard transformer encoder fuses the multimodal information for emotion recognition and sticker selection. Extensive experiments on the MOD dataset show that our CKS model significantly outperforms the baseline models.},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {3084–3093},
numpages = {10},
keywords = {causal inference, emotion recognition, sticker selection},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@proceedings{10.1145/3636555,
title = {LAK '24: Proceedings of the 14th Learning Analytics and Knowledge Conference},
year = {2024},
isbn = {9798400716188},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Kyoto, Japan}
}

@proceedings{10.1145/3674912,
title = {CompSysTech '24: Proceedings of the International Conference on Computer Systems and Technologies 2024},
year = {2024},
isbn = {9798400716843},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Ruse, Bulgaria}
}

@proceedings{10.1145/3639477,
title = {ICSE-SEIP '24: Proceedings of the 46th International Conference on Software Engineering: Software Engineering in Practice},
year = {2024},
isbn = {9798400705014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Lisbon, Portugal}
}

@article{10.1109/TASLP.2024.3374060,
author = {Wu, Yuxia and Dai, Tianhao and Zheng, Zhedong and Liao, Lizi},
title = {Active Discovering New Slots for Task-Oriented Conversation},
year = {2024},
issue_date = {2024},
publisher = {IEEE Press},
volume = {32},
issn = {2329-9290},
url = {https://doi.org/10.1109/TASLP.2024.3374060},
doi = {10.1109/TASLP.2024.3374060},
abstract = {Existing task-oriented conversational systems heavily rely on domain ontologies with pre-defined slots and candidate values. In practical settings, these prerequisites are hard to meet, due to the emerging new user requirements and ever-changing scenarios. To mitigate these issues for better interaction performance, there are efforts working towards detecting out-of-vocabulary values or discovering new slots under unsupervised or semi-supervised learning paradigms. However, overemphasizing on the conversation data patterns alone induces these methods to yield noisy and arbitrary slot results. To facilitate the pragmatic utility, real-world systems tend to provide a stringent amount of human labeling quota, which offers an authoritative way to obtain accurate and meaningful slot assignments. Nonetheless, it also brings forward the high requirement of utilizing such quota efficiently. Hence, we formulate a general new slot discovery task in an information extraction fashion and incorporate it into an active learning framework to realize human-in-the-loop learning. Specifically, we leverage existing language tools to extract value candidates where the corresponding labels are further leveraged as weak supervision signals. Based on these, we propose a bi-criteria selection scheme which incorporates two major strategies, namely, uncertainty-based and diversity-based sampling to efficiently identify terms of interest. We conduct extensive experiments on several public datasets and compare with a bunch of competitive baselines to demonstrate the effectiveness of our method.},
journal = {IEEE/ACM Trans. Audio, Speech and Lang. Proc.},
month = mar,
pages = {2062–2072},
numpages = {11}
}

@article{10.14778/3648160.3648162,
author = {Fan, Wenfei and Liu, Muyang and Liu, Shuhao and Tian, Chao},
title = {Capturing More Associations by Referencing External Graphs},
year = {2024},
issue_date = {February 2024},
publisher = {VLDB Endowment},
volume = {17},
number = {6},
issn = {2150-8097},
url = {https://doi.org/10.14778/3648160.3648162},
doi = {10.14778/3648160.3648162},
abstract = {This paper studies association rule discovery in a graph G1 by referencing an external graph G2 with overlapping information. The objective is to enrich G1 with relevant properties and links from G2. As a testbed, we consider Graph Association Rules (GARs). We propose a notion of graph joins to enrich G1 by aligning entities across G1 and G2. We also introduce a graph filtering method to support graph joins, by fetching only the data of G2 that pertains to the entities of G1, to reduce noise and the size of the fused data. Based on these we develop a parallel algorithm to discover GARs across G1 and G2. Moreover, we provide an incremental GAR discovery algorithm in response to updates to G1 and G2. We show that both algorithms guarantee to reduce parallel runtime when given more processors. Better yet, the incremental algorithm is bounded relative to the batch one. Using real-life and synthetic data, we empirically verify that the methods improve the accuracy of association analyses by 30.4% on average, and scale well with large graphs.},
journal = {Proc. VLDB Endow.},
month = feb,
pages = {1173–1186},
numpages = {14}
}

@article{10.1145/3641001,
author = {Jing, Felicia S. and Berger, Sara E. and Becerra Sandoval, Juana Catalina and Pepper, Kristin and Wheeler, April M. and Mayoral, Paula Redondo and Lokesh, Divya and Feng, Alice and Mijalkovic, Marija and Bao, Chaoyun and Dholakia, Sara and Goyal, Mohit},
title = {Designing for Agonism: 12 Workers' Perspectives on Contesting Technology Futures},
year = {2024},
issue_date = {April 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {CSCW1},
url = {https://doi.org/10.1145/3641001},
doi = {10.1145/3641001},
abstract = {In this paper, we gather 12 workers from a large technology company, as recent participants of a research initiative on the social impact of emerging technologies, to present a collaborative analysis of the opportunities and limitations of dissensus-based approaches to technology research and design. We introduce a series of speculative and deconstructive probes and present findings from their use in four collaborative design sessions. We then draw on the theoretical tradition of Agonism to identify moments of friction, refusal, and disagreement over the course of these sessions. We contend that this approach offers a politically important alternative to consensus-based collaborative design methods and can even surface new rhetorics of contestation within discourses on technology futures. We conclude with a discussion of the importance of worker-authored research and an initial set opportunities, challenges, and paradoxes as a resource for future efforts to "Design for Agonism."},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = apr,
articleno = {162},
numpages = {25},
keywords = {agonism, agonistic participatory design, collaborative design, deconstruction, dissensus, emerging technologies, speculative design}
}

@inproceedings{10.1109/ASE56229.2023.00070,
author = {Wang, Tao and Chen, Wei and Liu, Liwei and Wu, Guoquan and Wei, Jun and Huang, Tao},
title = {Detecting Smart Home Automation Application Interferences with Domain Knowledge},
year = {2024},
isbn = {9798350329964},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASE56229.2023.00070},
doi = {10.1109/ASE56229.2023.00070},
abstract = {Trigger-action programming (TAP) is a widely used development paradigm that simplifies the Internet of Things (IoT) automation. However, the exceptional interactions between automation applications may result in interferences, such as conflicts and infinite loops, which cause undesirable consequences and even security and safety risks. While several techniques have been proposed to address this problem, they are often restricted in handling explicit and simple conflicts without considering contextual influences. In addition, they suffer from performance issues when applying to large-scale applications.To address these challenges, we design an effective and practical tool KnowDetector with comprehensive domain knowledge to detect application interferences. To detect application interferences, KnowDetector constructs an automation graph with 1) events, conditions, and actions from automation applications, 2) vertices representing physical environment channels, and 3) edges derived from potential semantic relations between the vertices. In order to make the graph extensively capture the interactions between automation applications, we propose a knowledge model named KnowIoT that accurately characterizes IoT devices with command-level IoT services and the intricate relations between these services and the contextual environment. We abstract the interference detection into a graph pattern-matching problem and summarize ten application interference patterns of four types. Finally, KnowDetector can efficiently detect application interferences by searching for sub-graphs matching the patterns within the automation graph. We evaluated KnowDetector on three real-world datasets. The results demonstrated that it outperformed the other state-of-the-art tools with the highest precision, recall, and F-measure. In addition, KnowDetector is scalable to detect application interferences within a large number of applications with a minimal time overhead.},
booktitle = {Proceedings of the 38th IEEE/ACM International Conference on Automated Software Engineering},
pages = {1086–1097},
numpages = {12},
keywords = {smart home platform, TAP, automation application interference, internet of things},
location = {Echternach, Luxembourg},
series = {ASE '23}
}

@inproceedings{10.1145/3630106.3658981,
author = {Kraft, Angelie and Soulier, Elo\"{\i}se},
title = {Knowledge-Enhanced Language Models Are Not Bias-Proof: Situated Knowledge and Epistemic Injustice in AI},
year = {2024},
isbn = {9798400704505},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3630106.3658981},
doi = {10.1145/3630106.3658981},
abstract = {The factual inaccuracies ("hallucinations") of large language models have recently inspired more research on knowledge-enhanced language modeling approaches. These are often assumed to enhance the overall trustworthiness and objectivity of language models. Meanwhile, the issue of bias is usually only mentioned as a limitation of statistical representations. This dissociation of knowledge-enhancement and bias is in line with previous research on AI engineers’ assumptions about knowledge, which indicate that knowledge is commonly understood as objective and value-neutral by this community. We argue that claims and practices by actors of the field still reflect this underlying conception of knowledge. We contrast this assumption with literature from social and, in particular, feminist epistemology, which argues that the idea of a universal disembodied knower is blind to the reality of knowledge practices and seriously challenges claims of "objective" or "neutral" knowledge. Knowledge enhancement techniques commonly use Wikidata and Wikipedia as their sources for knowledge, due to their large scales, public accessibility, and assumed trustworthiness. In this work, they serve as a case study for the influence of the social setting and the identity of knowers on epistemic processes. Indeed, the communities behind Wikidata and Wikipedia are known to be male-dominated and many instances of hostile behavior have been reported in the past decade. In effect, the contents of these knowledge bases are highly biased. It is therefore doubtful that these knowledge bases would contribute to bias reduction. In fact, our empirical evaluations of RoBERTa, KEPLER, and CoLAKE, demonstrate that knowledge enhancement may not live up to the hopes of increased objectivity. In our study, the average probability for stereotypical associations was preserved on two out of three metrics and performance-related gender gaps on knowledge-driven task were also preserved. We build on these results and critical literature to argue that the label of "knowledge" and the commonly held beliefs about it can obscure the harm that is still done to marginalized groups. Knowledge enhancement is at risk of perpetuating epistemic injustice, and AI engineers’ understanding of knowledge as objective per se conceals this injustice. Finally, to get closer to trustworthy language models, we need to rethink knowledge in AI and aim for an agenda of diversification and scrutiny from outgroup members.},
booktitle = {Proceedings of the 2024 ACM Conference on Fairness, Accountability, and Transparency},
pages = {1433–1445},
numpages = {13},
keywords = {bias, epistemology, fairness, feminism, knowledge enhancement, knowledge graphs, language models, natural language processing, representation},
location = {Rio de Janeiro, Brazil},
series = {FAccT '24}
}

@article{10.1145/3652865,
author = {Sun, Zhu and Feng, Kaidong and Yang, Jie and Fang, Hui and Qu, Xinghua and Ong, Yew-Soon and Liu, Wenyuan},
title = {Revisiting Bundle Recommendation for Intent-aware Product Bundling},
year = {2024},
issue_date = {September 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {3},
url = {https://doi.org/10.1145/3652865},
doi = {10.1145/3652865},
abstract = {Product bundling represents a prevalent marketing strategy in both offline stores and e-commerce systems. Despite its widespread use, previous studies on bundle recommendation face two significant limitations. Firstly, they rely on noisy datasets, where bundles are defined by heuristics, e.g., products co-purchased in the same session. Secondly, they target specific tasks by holding unrealistic assumptions, e.g., the availability of bundles for recommendation directly. This paper proposes to take a step back and considers the process of bundle recommendation from a holistic user experience perspective. We first construct high-quality bundle datasets with rich metadata, particularly bundle intents, through a carefully designed crowd-sourcing task. We then define a series of tasks that together, support all key steps in a typical bundle recommendation process, from bundle detection, completion and ranking, to explanation and auto-naming, whereby 19 research questions are raised correspondingly to guide the analysis. Finally, we conduct extensive experiments and analyses with representative recommendation models and large language models (LLMs), demonstrating the challenges and opportunities, especially with the emergence of LLMs. To summarize, our study contributes by introducing novel data sources, paving the way for new research avenues, and offering insights to guide product bundling in real e-commerce platforms.},
journal = {ACM Trans. Recomm. Syst.},
month = jun,
articleno = {24},
numpages = {34},
keywords = {Product bundling, crowd-sourcing task, bundle datasets, bundle recommendation}
}

@inproceedings{10.1145/3627673.3679852,
author = {Zha, Zhiwei and Wang, Jiaan and Li, Zhixu and Zhu, Xiangru and Song, Wei and Xiao, Yanghua},
title = {M2ConceptBase: A Fine-Grained Aligned Concept-Centric Multimodal Knowledge Base},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679852},
doi = {10.1145/3627673.3679852},
abstract = {Multimodal knowledge bases (MMKBs) provide cross-modal aligned knowledge crucial for multimodal tasks. However, the images in existing MMKBs are generally collected for entities in encyclopedia knowledge graphs. Therefore, detailed groundings of visual semantics with linguistic concepts are lacking, which are essential for the visual concept cognition ability of multimodal models. Addressing this gap, we introduce M2 ConceptBase, the first concept-centric MMKB. M2 ConceptBase models concepts as nodes with associated images and detailed textual descriptions. We propose a context-aware multimodal symbol grounding approach to align concept-image and concept-description pairs using context information from image-text datasets. Comprising 951K images and 152K concepts, M2 ConceptBase links each concept to an average of 6.27 images and a single description, ensuring comprehensive visual and textual semantics. Human studies confirm more than 95% alignment accuracy, underscoring its quality. Additionally, our experiments demonstrate that M2 ConceptBase significantly enhances VQA model performance on the OK-VQA task. M2 ConceptBase also substantially improves the fine-grained concept understanding capabilities of multimodal large language models through retrieval augmentation in two concept-related tasks, highlighting its value.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {3113–3123},
numpages = {11},
keywords = {knowledge base, multimodal knowledge base, multimodal symbol grounding, visual question answering},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@inproceedings{10.1145/3613904.3642157,
author = {Meyer, Louie and Aaen, Johanne Engel and Tranberg, Anitamalina Regitse and Kun, Peter and Freiberger, Matthias and Risi, Sebastian and L\o{}vlie, Anders Sundnes},
title = {Algorithmic Ways of Seeing: Using Object Detection to Facilitate Art Exploration},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642157},
doi = {10.1145/3613904.3642157},
abstract = {This Research through Design paper explores how object detection may be applied to a large digital art museum collection to facilitate new ways of encountering and experiencing art. We present the design and evaluation of an interactive application called SMKExplore, which allows users to explore a museum’s digital collection of paintings by browsing through objects detected in the images, as a novel form of open-ended exploration. We provide three contributions. First, we show how an object detection pipeline can be integrated into a design process for visual exploration. Second, we present the design and development of an app that enables exploration of an art museum’s collection. Third, we offer reflections on future possibilities for museums and HCI researchers to incorporate object detection techniques into the digitalization of museums.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {29},
numpages = {18},
keywords = {Art, Computer Vision, Experience Design, Exploratory Search, Object Detection},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@article{10.1145/3679200,
author = {Liao, Weibin and Zhu, Yifan and Li, Yanyan and Zhang, Qi and Ou, Zhonghong and Li, Xuesong},
title = {RevGNN: Negative Sampling Enhanced Contrastive Graph Learning for Academic Reviewer Recommendation},
year = {2024},
issue_date = {January 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {43},
number = {1},
issn = {1046-8188},
url = {https://doi.org/10.1145/3679200},
doi = {10.1145/3679200},
abstract = {Acquiring reviewers for academic submissions is a challenging recommendation scenario. Recent graph learning-driven models have made remarkable progress in the field of recommendation, but their performance in the academic reviewer recommendation task may suffer from a significant false negative issue. This arises from the assumption that unobserved edges represent negative samples. In fact, the mechanism of anonymous review results in inadequate exposure of interactions between reviewers and submissions, leading to a higher number of unobserved interactions compared to those caused by reviewers declining to participate. Therefore, investigating how to better comprehend the negative labeling of unobserved interactions in academic reviewer recommendations is a significant challenge. This study aims to tackle the ambiguous nature of unobserved interactions in academic reviewer recommendations. Specifically, we propose an unsupervised Pseudo Neg-Label strategy to enhance graph contrastive learning (GCL) for recommending reviewers for academic submissions, which we call RevGNN. RevGNN utilizes a two-stage encoder structure that encodes both scientific knowledge and behavior using Pseudo Neg-Label to approximate review preference. Extensive experiments on three real-world datasets demonstrate that RevGNN outperforms all baselines across four metrics. Additionally, detailed further analyses confirm the effectiveness of each component in RevGNN.},
journal = {ACM Trans. Inf. Syst.},
month = nov,
articleno = {1},
numpages = {26},
keywords = {Academic reviewer recommendation, expert finding, GNN-based recommendation, negative sampling in GCL}
}

@inproceedings{10.1145/3660853.3660886,
author = {Tabaza, Abdulrahman and Quishawi, Omar and Yaghi, Abdelrahman and Qawasmeh, Omar},
title = {Binding Text, Images, Graphs, and Audio for Music Representation Learning},
year = {2024},
isbn = {9798400716928},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3660853.3660886},
doi = {10.1145/3660853.3660886},
abstract = {Abstract In the field of Information Retrieval and Natural Language Processing, text embeddings play a significant role in tasks such as classification, clustering, and topic modeling. However, extending these embeddings to abstract concepts such as music, which involves multiple modalities, presents a unique challenge. Our work addresses this challenge by integrating rich multi-modal data into a unified joint embedding space. This space includes: (1) textual, (2) visual, (3) acoustic, and (4) graph-based modality features. By doing so, we mirror cognitive processes associated with music interaction and overcome the disjoint nature of individual modalities. The resulting joint low-dimensional vector space facilitates retrieval, clustering, embedding space arithmetic, and cross-modal retrieval tasks. Importantly, our approach carries implications for music information retrieval and recommendation systems. Furthermore, we propose a novel multi-modal model that integrates various data types—text, images, graphs, and audio—for music representation learning. Our model aims to capture the complex relationships between different modalities, enhancing the overall understanding of music. By combining textual descriptions, visual imagery, graph-based structures, and audio signals, we create a comprehensive representation that can be leveraged for a wide range of music-related tasks. Notably, our model demonstrates promising results in music classification, and recommendation systems. Code Availability: The source code for the multi-modal music representation model described in this paper is available on GitHub. Access and further details can be found at the following repository link: //github.com/a-tabaza/binding_music/},
booktitle = {Proceedings of the Cognitive Models and Artificial Intelligence Conference},
pages = {139–146},
numpages = {8},
location = {undefinedstanbul, Turkiye},
series = {AICCONF '24}
}

@proceedings{10.1145/3665348,
title = {GAIIS '24: Proceedings of the 2024 International Conference on Generative Artificial Intelligence and Information Security},
year = {2024},
isbn = {9798400709562},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Kuala Lumpur, Malaysia}
}

@inproceedings{10.1145/3626772.3657877,
author = {Leventidis, Aristotelis and Christensen, Martin Pek\'{a}r and Lissandrini, Matteo and Di Rocco, Laura and Hose, Katja and Miller, Ren\'{e}e J.},
title = {A Large Scale Test Corpus for Semantic Table Search},
year = {2024},
isbn = {9798400704314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626772.3657877},
doi = {10.1145/3626772.3657877},
abstract = {Table search aims to answer a query with a ranked list of tables. Unfortunately, current test corpora have focused mostly on needle-in-the-haystack tasks, where only a few tables are expected to exactly match the query intent. Instead, table search tasks often arise in response to the need for retrieving new datasets or augmenting existing ones, e.g., for data augmentation within data science or machine learning pipelines. Existing table repositories and benchmarks are limited in their ability to test retrieval methods for table search tasks. Thus, to close this gap, we introduce a novel dataset for query-by-example Semantic Table Search. This novel dataset consists of two snapshots of the large-scale Wikipedia tables collection from 2013 and 2019 with two important additions: (1) a page and topic aware ground truth relevance judgment and (2) a large-scale DBpedia entity linking annotation. Moreover, we generate a novel set of entity-centric queries that allows testing existing methods under a novel search scenario: semantic exploratory search. The resulting resource consists of 9,296 novel queries, 610,553 query-table relevance annotations, and 238,038 entity-linked tables from the 2013 snapshot. Similarly, on the 2019 snapshot, the resource consists of 2,560 queries, 958,214 relevance annotations, and 457,714 total tables. This makes our resource the largest annotated table-search corpus to date (97 times more queries and 956 times more annotated tables than any existing benchmark). We perform a user study among domain experts and prove that these annotators agree with the automatically generated relevance annotations. As a result, we can re-evaluate some basic assumptions behind existing table search approaches identifying their shortcomings along with promising novel research directions.},
booktitle = {Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {1142–1151},
numpages = {10},
keywords = {benchmark, query-by-example, semantic search, table search},
location = {Washington DC, USA},
series = {SIGIR '24}
}

@proceedings{10.1145/3677779,
title = {CMNM '24: Proceedings of the International Conference on Modeling, Natural Language Processing and Machine Learning},
year = {2024},
isbn = {9798400709760},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Xi'an, China}
}

@inproceedings{10.1145/3626772.3657666,
author = {Prieur, Maxime and Du Mouza, C\'{e}dric and Gadek, Guillaume and Grilheres, Bruno},
title = {Shadowfax: Harnessing Textual Knowledge Base Population},
year = {2024},
isbn = {9798400704314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626772.3657666},
doi = {10.1145/3626772.3657666},
abstract = {Knowledge base population (KBP) from texts involves the extraction and organization of information from unstructured textual data to enhance or create a structured knowledge base. This process is crucial for various applications, such as natural language understanding, question-answering systems, and knowledge-driven decision-making. However the difficulty lies in the complexity of natural language, which is nuanced, ambiguous, and context-dependent. Extracting accurate and reliable information requires overcoming challenges such as entity disambiguation and relation extraction which are time-consuming tasks for users.Shadowfax is an interactive platform designed to support users by streamlining the process of knowledge base population (KPB) from text documents. Unlike other existing tools, it relies on a unified machine learning model to extract relevant information from unstructured text, enabling operational agents to gain a quick overview. The proposed system supports a variety of natural language processing (NLP) tasks using a single architecture, while presenting information in the most comprehensive way possible to the end user.},
booktitle = {Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {2796–2800},
numpages = {5},
keywords = {data mining, deep-learning, end-to-end, information extraction, knowledge base population, user in the loop},
location = {Washington DC, USA},
series = {SIGIR '24}
}

@article{10.1145/3688841,
author = {Latendresse, Jasmine and Abedu, Samuel and Abdellatif, Ahmad and Shihab, Emad},
title = {An Exploratory Study on Machine Learning Model Management},
year = {2024},
issue_date = {January 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {34},
number = {1},
issn = {1049-331X},
url = {https://doi.org/10.1145/3688841},
doi = {10.1145/3688841},
abstract = {Effective model management is crucial for ensuring performance and reliability in Machine Learning (ML) systems, given the dynamic nature of data and operational environments. However, standard practices are lacking, often resulting in ad hoc approaches. To address this, our research provides a clear definition of ML model management activities, processes, and techniques. Analyzing 227 ML repositories, we propose a taxonomy of 16 model management activities and identify 12 unique challenges. We find that 57.9% of the identified activities belong to the maintenance category, with activities like refactoring (20.5%) and documentation (18.3%) dominating. Our findings also reveal significant challenges in documentation maintenance (15.3%) and bug management (14.9%), emphasizing the need for robust versioning tools and practices in the ML pipeline. Additionally, we conducted a survey that underscores a shift toward automation, particularly in data, model, and documentation versioning, as key to managing ML models effectively. Our contributions include a detailed taxonomy of model management activities, a mapping of challenges to these activities, practitioner-informed solutions for challenge mitigation, and a publicly available dataset of model management activities and challenges. This work aims to equip ML developers with knowledge and best practices essential for the robust management of ML models.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = dec,
articleno = {16},
numpages = {31},
keywords = {Software engineering, machine learning, model management}
}

@proceedings{10.1145/3610978,
title = {HRI '24: Companion of the 2024 ACM/IEEE International Conference on Human-Robot Interaction},
year = {2024},
isbn = {9798400703232},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome one and all to the 19th Annual ACM/IEEE International Conference on Human-Robot Interaction (HRI)!We are so pleased to re-welcome the HRI community to Boulder, Colorado, where HRI 2021 would have been held, had the COVID pandemic not interfered. Following up on the successful in-person conference held last year in Sweden, this year's theme is "HRI in the Real World," and focuses on advances that aim to bring human-robot interaction out of the lab and into everyday life.One aspect of this that we are very excited about is the introduction of a robot challenge to the conference activities, where teams from around the world will showcase their research and development via actual, interactive robots in the "real world" of an academic conference. It is our hope that this feature will grow and develop over the coming years into a staple of the HRI conference.This year's HRI conference saw an impressive surge in global interest, with 352 full paper submissions from around the world, marking a significant 40% increase compared to the previous year. These papers were categorized under relevant thematic subcommittees and underwent a double-blind review process, a rebuttal phase, and selective shepherding by the HRI program committee. From this process, 87 outstanding papers (24.7%) were chosen for full presentation at the conference. Reflecting our joint sponsorship with IEEE and ACM, all accepted papers will be accessible in the ACM Digital Library and IEEE Xplore.},
location = {Boulder, CO, USA}
}

@inproceedings{10.1145/3633637.3633677,
author = {Wang, Peng and Liu, Jingju},
title = {A Cyber Threat Entity Recognition Method Based on Robust Feature Representation and Adversarial Training},
year = {2024},
isbn = {9798400707988},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3633637.3633677},
doi = {10.1145/3633637.3633677},
abstract = {With the development of Internet, cybersecurity attracts people's attention. In order to better protect cybersecurity, we can comprehensively analyze the security events based on cyber threat intelligence. We aim to identify correlations between security events to proactively address potential threats. However, there are still many challenges when people use cyber threat intelligence. Cyber threat intelligence mainly exists in unstructured form. It is necessary to extract the important elements from it. We design a cyber threat entity recognition method to help the analysis of cyber threat intelligence. The formation of accurate and robust feature representation is the key to realize the task of cyber threat entity recognition, but the feature representation of text is susceptible to noise interference. In order to form an accurate representation of the text, we design a robust feature representation method which extracts features based on multiple perspectives and adopts a mutual learning mechanism to promote feature interaction. It adopts iterative fusion to form the final feature representation. And we use an adversarial training framework that can learn attack strategies to alleviate the problem of noise interference. We conduct relevant experiments on the cyber threat intelligence dataset DNRTI. The experimental results show that our method can be used in cyber threat intelligence analysis.},
booktitle = {Proceedings of the 2023 12th International Conference on Computing and Pattern Recognition},
pages = {255–259},
numpages = {5},
keywords = {Adversarial training, Cyber threat intelligence, Feature representation, Threat entity recognition},
location = {Qingdao, China},
series = {ICCPR '23}
}

@inproceedings{10.1145/3626772.3657659,
author = {Lee, Yuan-Chi and Yen, An-Zi and Huang, Hen-Hsen and Chen, Hsin-Hsi},
title = {ConvLogRecaller: Real-Time Conversational Lifelog Recaller},
year = {2024},
isbn = {9798400704314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626772.3657659},
doi = {10.1145/3626772.3657659},
abstract = {The popularization of networks fosters the convenience of communication. People can easily share their life experiences and thoughts with relatives and friends via instant messaging software. As time passes, individuals may forget certain details of life events, leading to difficulties in effectively communicating with others. The propensity of individuals to forget or mix up life events highlights the importance of services aimed at retrieving information about past experiences. This paper presents a conversational information recall system, ConvLogRecaller, which proactively supports real-time memory recall assistance during online conversations. Given a conversation of the user with others, ConvLogRecaller suggests a message if the user forgets the details of the life experiences. The services provided by our system can avoid hesitations or memory lapses that might hinder the efficiency of a conversation.},
booktitle = {Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {2724–2728},
numpages = {5},
keywords = {conversational lifelogs retrieval, lifelogging, proactive information recall},
location = {Washington DC, USA},
series = {SIGIR '24}
}

@proceedings{10.1145/3663529,
title = {FSE 2024: Companion Proceedings of the 32nd ACM International Conference on the Foundations of Software Engineering},
year = {2024},
isbn = {9798400706585},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {We are pleased to welcome all delegates to FSE 2024, the ACM International Conference on the Foundations of Software Engineering (FSE) 2024. The conference now has a shorter name! FSE is an internationally renowned forum for researchers, practitioners, and educators to present and discuss the most recent innovations, trends, experiences, and challenges in the field of software engineering. FSE brings together experts from academia and industry to exchange the latest research results and trends as well as their practical application in all areas of software engineering.},
location = {Porto de Galinhas, Brazil}
}

@article{10.1145/3654984,
author = {Chen, Kaiwen and Koudas, Nick},
title = {Unstructured Data Fusion for Schema and Data Extraction},
year = {2024},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {3},
url = {https://doi.org/10.1145/3654984},
doi = {10.1145/3654984},
abstract = {Recently, there has been significant interest in extracting actionable insights from the abundance of unstructured textual data. In this paper, we introduce a novel problem, which we term Semistructured Schema and Data Extraction (SDE). This task aims to enhance and complete tables using information discovered from textual repositories, given partial table specifications in the form of queries. To effectively solve SDE, several challenges must be overcome, which involve transforming the partial table specifications into effective queries, retrieving relevant documents, discerning values for partially specified attributes, inferring additional attributes, and constructing an enriched output table while mitigating the influence of false positives from the retrieval.We propose an end-to-end pipeline for SDE, which consists of a retrieval component and an augmentation component, to address each of the challenges. In the retrieval component, we serialize the partial table specifications into a query and employ a dense passage retrieval algorithm to extract the top-k relevant results from the text repository. Subsequently, the augmentation component ingests the output documents from the retrieval phase and generates an enriched table. We formulate this table enrichment task as a unique sequence-to-sequence task, distinct from traditional approaches, as it operates on multiple documents during generation. Utilizing an interpolation mechanism on the encoder output, our model maintains a nearly constant context length while automatically prioritizing the importance of documents during the generation. Due to the novelty of SDE, we establish a validation methodology, adapting and expanding existing benchmarks with the use of powerful large language models. Our extensive experiments show that our method achieves high accuracy in enriching query tables through multi-document fusion, while also surpassing baseline methods in both accuracy and computational efficiency.},
journal = {Proc. ACM Manag. Data},
month = may,
articleno = {181},
numpages = {26},
keywords = {data fusion, information extraction, schema extraction}
}

@proceedings{10.1145/3681716,
title = {Mindtrek '24: Proceedings of the 27th International Academic Mindtrek Conference},
year = {2024},
isbn = {9798400718236},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Tampere, Finland}
}

@article{10.1145/3696117.3696122,
author = {Simensen, John Eidar and Esnoul, Coralie and Jee, Eunkyoung and Babar, Ali and Minh Le, Triet Huynh and Rashid, Awais},
title = {Report on the 5th International Workshop on Engineering and Cybersecurity of Critical Systems and 2nd International Workshop on Software Vulnerability Management (EnCyCriS/SVM - 2024)},
year = {2024},
issue_date = {October 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {49},
number = {4},
issn = {0163-5948},
url = {https://doi.org/10.1145/3696117.3696122},
doi = {10.1145/3696117.3696122},
abstract = {Increasing system interconnectivity, decentralization, and introduction of new, more intelligent technologies, result in critical infrastructures becoming exposed to increased risk of cyber, physical, and combine cyber-physical attacks. Cyber-attacks on critical systems can inflict severe consequences on to people, society, economy, and national security, and can have adverse effects on safety and reliability of critical infrastructures. The joint EnCyCriS-SVM workshop facilitates discourse and discussion among researchers, practitioner, and students who are working on challenges and solutions related to the industrial revolution. Focus is given on sharing industry experience and project results pertaining to cyber threats on critical systems; secure software engineering; and attack detection and response mechanisms.},
journal = {SIGSOFT Softw. Eng. Notes},
month = oct,
pages = {18–21},
numpages = {4},
keywords = {critical infrastructures., cybersecurity, safety, software engineering, systems engineering}
}

@inproceedings{10.1145/3677779.3677802,
author = {Yue, Liu and Liu, Shengquan and Zhao, Ming and Guo, Quanjiang},
title = {Research on Distant Supervision Relation Extraction based on Attention Graph Enhancement and Dynamic Loss},
year = {2024},
isbn = {9798400709760},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3677779.3677802},
doi = {10.1145/3677779.3677802},
abstract = {Distant supervision relation extraction utilizes alignment with existing knowledge bases to collect training data. In current research, entity types and relation types are often embedded separately in sentences or bags, ignoring the semantic connections between entity types and relation types. To address this issue, entity types, and relation types are concatenated to form an entity-relation graph. In this paper, the entity-relation graph is integrated into the relation extraction model using Attention Graph Enhancement (Attention Graph Enhancement, AGE) to identify relations. Furthermore, the imbalance in the number of training instances in distant supervision, with fewer training instances for long-tail relations, leads to insufficient extraction of long-tail relations. In this paper, a dynamic loss (Dynamic Loss, DL) is constructed based on the number of relation instances to design a weight-based dynamic loss function to optimize the proportion of head and long-tail relations instances during training. Each training round dynamically updates the training instance weights based on the loss, emphasizing long-tail relation training in the following training stage. The experimental results show that the proposed method improves the AUC values by 1.9% and 2.4% on the NYT-520K and NYT-570K datasets.},
booktitle = {Proceedings of the International Conference on Modeling, Natural Language Processing and Machine Learning},
pages = {139–146},
numpages = {8},
location = {Xi'an, China},
series = {CMNM '24}
}

@proceedings{10.1145/3625007,
title = {ASONAM '23: Proceedings of the 2023 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining},
year = {2023},
isbn = {9798400704093},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {The ASONAM conference series brings together researchers from around the world to share the latest advances in the attractive field of Social Networks Analysis and Mining.},
location = {Kusadasi, Turkiye}
}

@proceedings{10.1145/3627043,
title = {UMAP '24: Proceedings of the 32nd ACM Conference on User Modeling, Adaptation and Personalization},
year = {2024},
isbn = {9798400704338},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Cagliari, Italy}
}

@proceedings{10.1145/3605098,
title = {SAC '24: Proceedings of the 39th ACM/SIGAPP Symposium on Applied Computing},
year = {2024},
isbn = {9798400702433},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {On behalf of the Organizing Committee, I extend a warm welcome to you at the 39th Annual ACM Symposium on Applied Computing (SAC 2024), taking place in \'{A}vila, Spain, and hosted by the University of Salamanca. For more than three decades, this international forum has been dedicated to computer scientists, engineers, and practitioners, providing a platform for presenting their research findings and results in various areas of applied computing. The organizing committee sincerely appreciates your participation in this exciting international event, and we hope that the conference proves interesting and beneficial for all attendees.},
location = {Avila, Spain}
}

@proceedings{10.1145/3659677,
title = {NISS '24: Proceedings of the 7th International Conference on Networking, Intelligent Systems and Security},
year = {2024},
isbn = {9798400709296},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Meknes, AA, Morocco}
}

@proceedings{10.1145/3696500,
title = {ICBDDM '24: Proceedings of the 2024 International Conference on Big Data and Digital Management},
year = {2024},
isbn = {9798400710278},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Shanghai, China}
}

@inproceedings{10.1109/JCDL57899.2023.00012,
author = {Chekuri, Satvik and Chandrasekar, Prashant and Banerjee, Bipasha and Park, Sung Hee and Masrourisaadat, Nila and Ahuja, Aman and Ingram, William A. and Fox, Edward A.},
title = {Integrated Digital Library System for Long Documents and their Elements},
year = {2024},
isbn = {9798350399318},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/JCDL57899.2023.00012},
doi = {10.1109/JCDL57899.2023.00012},
abstract = {We describe a next-generation integrated Digital Library (DL) system that addresses the numerous goals associated with long documents such as Electronic Theses and Dissertations (ETDs). Our extensible workflow-centric design supports a variety of users/personas (e.g., researchers, curators, and experimenters) who can benefit from improved access to ETDs and the content buried therein. Our approach leverages natural language processing, deep learning, information retrieval, and software engineering methods. The services cover ingesting, storing, curating, analyzing, detecting, extracting, classifying, summarizing, topic modeling, browsing, searching, retrieving, recommending, visualizing/reporting, and interacting with ETDs and derivative text/image-based elements/objects. Workflows connect the services and their APIs, along with UI-based access. We believe our approach can guide others to combine tailored user support, research, and education by way of extensible DLs.},
booktitle = {Proceedings of the 2023 ACM/IEEE Joint Conference on Digital Libraries},
pages = {13–24},
numpages = {12},
keywords = {digital library, information system, information retrieval, deep learning, NLP},
location = {Santa Fe, New Mexico, USA},
series = {JCDL '23}
}

@inproceedings{10.1145/3652620.3687820,
author = {Moln\'{a}r, Vince and Graics, Bence and V\"{o}r\"{o}s, Andr\'{a}s and Tonetta, Stefano and Cristoforetti, Luca and Kimberly, Greg and Dyer, Pamela and Giammarco, Kristin and Koethe, Manfred and Hester, John and Smith, Jamie and Grimm, Christoph},
title = {Towards the Formal Verification of SysML v2 Models},
year = {2024},
isbn = {9798400706226},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652620.3687820},
doi = {10.1145/3652620.3687820},
abstract = {Systems Modeling Language (SysML) is the de facto standard in the industry for modeling complex systems. SysML v2 is the new version of the language with reworked fundamentals. In this paper, we explore how the new formal semantics of SysML v2 can enable formal verification and various forms of automated reasoning. Formal verification involves mathematically proving the correctness of a system's design with respect to certain specifications or properties. This rigorous approach ensures that models behave as intended under all possible conditions. Through a detailed examination, we demonstrate how five specific tools - Gamma, MP-Firebird, Imandra, SAVVS, and SysMD - can formally analyze SysML v2 models. We show how these tools support the different concepts in the language, as well as the set of features and technologies they provide to users of SysML v2, such as model checking, theorem proving, contract-based design, or automatic fault injections. We propose a workflow for applying formal methods on SysML v2 models, illustrated by example models and artifacts generated by the above tools.},
booktitle = {Proceedings of the ACM/IEEE 27th International Conference on Model Driven Engineering Languages and Systems},
pages = {1086–1095},
numpages = {10},
keywords = {SysML V2, systems modeling, formal methods, verification and validation, automated reasoning, tools},
location = {Linz, Austria},
series = {MODELS Companion '24}
}

@inproceedings{10.1145/3670105.3670124,
author = {Pang, Ronghui},
title = {Research on Text Classification Applications Based on NLP Technology},
year = {2024},
isbn = {9798400716751},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3670105.3670124},
doi = {10.1145/3670105.3670124},
abstract = {Text classification is a fundamental task in enterprise applications research based on natural language process- ing (NLP) technology. Faced with massive text data generated by enterprise users on the Internet, how to effectively classify and apply them is one of the challenges that enterprises face in management. This article takes user-generated content (UGC) on e-commerce platforms as the research background and uses the BERT model to classify the textual content generated by users. The model achieves an accuracy rate of up to 81%. The article demonstrates that compared with the W2V+SVM model, the BERT model can effectively address the problem of overly complex and disordered web text. This research provides a viable solution for enterprise managers to more effectively manage and utilize massive text data. Through text classification technology, enterprises can promptly understand consumer sentiment, product preferences, and feedback, thereby guiding decisions in marketing strategies, product development, and customer service.},
booktitle = {Proceedings of the 2024 5th International Conference on Computing, Networks and Internet of Things},
pages = {108–111},
numpages = {4},
keywords = {BERT, SVM, Text Classification, Word Embedding},
location = {Tokyo, Japan},
series = {CNIOT '24}
}

@proceedings{10.1145/3634814,
title = {ASSE '23: Proceedings of the 2023 4th Asia Service Sciences and Software Engineering Conference},
year = {2023},
isbn = {9798400708534},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Aizu-Wakamatsu City, Japan}
}

@inproceedings{10.1145/3670105.3670127,
author = {Li, Peng and Liu, Zhiqi and Pang, WeiJian and Cao, Jiang},
title = {Semantic Collaboration: A Collaborative Approach for Multi-Agent Systems Based on Semantic Communication},
year = {2024},
isbn = {9798400716751},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3670105.3670127},
doi = {10.1145/3670105.3670127},
abstract = {Abstract. In order to meet the practical needs of different intelligent agents collaborating to execute tasks, this paper has studied the multi-agent collaboration mode based on semantic communication and proposed a multi-agent collaboration method based on semantic communication. Firstly, the basic concept, basic framework, typical process and application of semantic communication are systematically described. On this basis, the basic concept and framework of multi-agent collaboration based are proposed, and the differences and relations between semantic communication and semantic collaboration are analyzed. Subsequently, the paper provides a detailed introduction to the typical process of semantic collaboration. Next, the key supporting technologies of semantic collaboration are analyzed. At last, taking the multi-agent cooperative search and rescue task as an example, the application mode of semantic collaboration is introduced.},
booktitle = {Proceedings of the 2024 5th International Conference on Computing, Networks and Internet of Things},
pages = {123–132},
numpages = {10},
keywords = {Multi-Agent Systems, Semantic Collaboration, Semantic Communication},
location = {Tokyo, Japan},
series = {CNIOT '24}
}

@article{10.1109/TASLP.2024.3350905,
author = {Jiang, Shu and Li, Zuchao and Zhao, Hai and Ding, Weiping},
title = {Entity-Relation Extraction as Full Shallow Semantic Dependency Parsing},
year = {2024},
issue_date = {2024},
publisher = {IEEE Press},
volume = {32},
issn = {2329-9290},
url = {https://doi.org/10.1109/TASLP.2024.3350905},
doi = {10.1109/TASLP.2024.3350905},
abstract = {Entity-relation extraction is the essential information extraction task and can be decomposed into Named Entity Recognition (NER) and Relation Extraction (RE) subtasks. This paper proposes a novel joint entity-relation extraction method that models the entity-relation extraction task as full shallow semantic dependency graph parsing. Specifically, it jointly and simultaneously converts the entities and relation mentions as the edges of the semantic dependency graph to be parsed and their types as the labels. This model also integrates the advantages of multiple feature tagging methods and enriches the token representation. Furthermore, second-order scoring is introduced to exploit the relationships between entities and relations, which improves the model performance. Our work is the first time to fully model entities and relations into a graph and uses higher-order modules to address their interaction problems. Compared with state-of-the-art scores on five benchmarks (ACE04, ACE05, CoNLL04, ADE, and SciERC), empirical results show that our proposed model makes significant improvements and demonstrates its effectiveness and practicability.},
journal = {IEEE/ACM Trans. Audio, Speech and Lang. Proc.},
month = jan,
pages = {1088–1099},
numpages = {12}
}

@proceedings{10.1145/3643991,
title = {MSR '24: Proceedings of the 21st International Conference on Mining Software Repositories},
year = {2024},
isbn = {9798400705878},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {MSR is a thriving research community that organizes a yearly conference with a solid reputation amongst software engineering researchers.},
location = {Lisbon, Portugal}
}

@proceedings{10.1145/3687272,
title = {HAI '24: Proceedings of the 12th International Conference on Human-Agent Interaction},
year = {2024},
isbn = {9798400711787},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Swansea, United Kingdom}
}

@article{10.1145/3678879,
author = {Xu, Jingyun and Yu, Junnan and Cai, Yi and Chua, Tat-Seng},
title = {Dual Contrastive Learning for Cross-Domain Named Entity Recognition},
year = {2024},
issue_date = {November 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {42},
number = {6},
issn = {1046-8188},
url = {https://doi.org/10.1145/3678879},
doi = {10.1145/3678879},
abstract = {Benefiting many information retrieval applications, named entity recognition (NER) has shown impressive progress. Recently, there has been a growing trend to decompose complex NER tasks into two subtasks (e.g., entity span detection (ESD) and entity type classification (ETC), to achieve better performance. Despite the remarkable success, from the perspective of representation, existing methods do not explicitly distinguish non-entities and entities, which may lead to ESD errors. Meanwhile, they do not explicitly distinguish entities with different entity types, which may lead to entity type misclassification. As such, the limited representation abilities may challenge some competitive NER methods, leading to unsatisfactory performance, especially in the low-resource setting (e.g., cross-domain NER). In light of these challenges, we propose to utilize contrastive learning to refine the original chaotic representations and learn the generalized representations for cross-domain NER. In particular, this article proposes a dual contrastive learning model (Dual-CL), which respectively utilizes a token-level contrastive learning module and a sentence-level contrastive learning module to enhance ESD, ETC for cross-domain NER. Empirical results on 10 domain pairs under two different settings show that Dual-CL achieves better performances than compared baselines in terms of several standard metrics. Moreover, we conduct detailed analyses to are presented to better understand each component’s effectiveness.},
journal = {ACM Trans. Inf. Syst.},
month = oct,
articleno = {163},
numpages = {33},
keywords = {Named Entity Recognition, Cross-domain, Contrastive Learning}
}

@proceedings{10.1145/3674558,
title = {ICCTA '24: Proceedings of the 2024 10th International Conference on Computer Technology Applications},
year = {2024},
isbn = {9798400716386},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Vienna, Austria}
}

@proceedings{10.1145/3695719,
title = {ICDLT '24: Proceedings of the 2024 8th International Conference on Deep Learning Technologies},
year = {2024},
isbn = {9798400716867},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@inproceedings{10.1145/3670085.3670104,
author = {Yao, zhan'ao and Yang, Hongxin and Chen, Tingwei},
title = {A pruning-based word-centered context fragment extraction method for relation extraction},
year = {2024},
isbn = {9798400717284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3670085.3670104},
doi = {10.1145/3670085.3670104},
abstract = {Neural relationship extraction is an important task in natural language processing, aimed at extracting relationships between target entity pairs from a given text. In recent years, with the development of deep neural networks, various types of neural networks to extract sentence entity-level, fragment-level, and sentence-level features for relationship extraction have become a mainstream research direction. Most existing studies use the BERT model to embed sentences and then use CNN to manipulate all words in the entire sentence to obtain fragment-level features. This article proposes a new word-centered context fragment-level method based on pruning the shortest dependency path between entity pairs. We demonstrate that using a pruning method based on the shortest dependency path between entity pairs can effectively improve the ability of model fragments and information extraction. We evaluated our method on a public benchmark: SemEval 2010 Task 8. The experimental results show that our method outperforms the advanced model using BERT as the embedding.},
booktitle = {Proceedings of the 2024 9th International Conference on Mathematics and Artificial Intelligence},
pages = {97–104},
numpages = {8},
keywords = {Neural relation extraction, Pruning method, Shortest dependency path, Word-centered context fragment},
location = {Beijing, China},
series = {ICMAI '24}
}

@proceedings{10.1145/3670474,
title = {MLCAD '24: Proceedings of the 2024 ACM/IEEE International Symposium on Machine Learning for CAD},
year = {2024},
isbn = {9798400706998},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Salt Lake City, UT, USA}
}

@inproceedings{10.1145/3613905.3644065,
author = {Xu, Chunchen and Ge, Xiao},
title = {AI as a Child of Mother Earth: Regrounding Human-AI Interaction in Ecological Thinking},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3644065},
doi = {10.1145/3613905.3644065},
abstract = {The anthropocentric cultural idea that humans are active agents exerting control over their environments has been largely normalized and inscribed in practices, policies, and products of contemporary industrialized societies. This view underlies a human-ecology relationship based on resource and knowledge extraction. To create a more sustainable and equitable future, it is essential to consider alternative cultural ideas rooted in ecological thinking. This perspective underscores the interconnectedness between humans and more-than-human worlds. We propose a path to reshape the human-ecology relationship by advocating for alternative human-AI interactions. In this paper, we undertake a critical comparison between anthropocentrism and ecological thinking, using storytelling to illustrate various human-AI interactions that embody ecological thinking. We also delineate a set of design principles aimed at guiding AI developments toward fostering a more caring human-ecology relationship.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {546},
numpages = {9},
keywords = {AI, Anthropocentrism, Culture, Design, Ecological thinking, Environmental justice, Human-ecology relationship, More-than-human, Storytelling, Sustainability},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}

@proceedings{10.1145/3672919,
title = {CSAIDE '24: Proceedings of the 2024 3rd International Conference on Cyber Security, Artificial Intelligence and Digital Economy},
year = {2024},
isbn = {9798400718212},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Nanjing, China}
}

@inproceedings{10.1145/3654777.3676462,
author = {Khanal, Nabin and Yu, Chun Meng and Chiu, Jui-Cheng and Chaudhary, Anav and Zhang, Ziyue and Katija, Kakani and Forbes, Angus G.},
title = {FathomGPT: A natural language interface for interactively exploring ocean science data},
year = {2024},
isbn = {9798400706288},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3654777.3676462},
doi = {10.1145/3654777.3676462},
abstract = {We introduce FathomGPT, an open source system for the interactive investigation of ocean science data via a natural language interface. FathomGPT was developed in close collaboration with marine scientists to enable researchers to explore and analyze the FathomNet image database. FathomGPT provides a custom information retrieval pipeline that leverages OpenAI’s large language models to enable: the creation of complex queries to retrieve images, taxonomic information, and scientific measurements; mapping common names and morphological features to scientific names; generating interactive charts on demand; and searching by image or specified patterns within an image. In designing FathomGPT, particular emphasis was placed on enhancing the user’s experience by facilitating free-form exploration and optimizing response times. We present an architectural overview and implementation details of FathomGPT, along with a series of ablation studies that demonstrate the effectiveness of our approach to name resolution, fine tuning, and prompt modification. We also present usage scenarios of interactive data exploration sessions and document feedback from ocean scientists and machine learning experts.},
booktitle = {Proceedings of the 37th Annual ACM Symposium on User Interface Software and Technology},
articleno = {95},
numpages = {15},
keywords = {Natural Language Interfaces, Ocean Science, Scientific Databases},
location = {Pittsburgh, PA, USA},
series = {UIST '24}
}

@proceedings{10.1145/3666094,
title = {PDC '24: Proceedings of the Participatory Design Conference 2024: Full Papers - Volume 1},
year = {2024},
isbn = {9798400708084},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {1},
location = {Sibu, Malaysia}
}

@inproceedings{10.1145/3639474.3640083,
author = {Parthasarathy, P. D. and Joshi, Swaroop},
title = {Teaching Digital Accessibility to Industry Professionals using the Community of Practice framework: An Experience Report},
year = {2024},
isbn = {9798400704987},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639474.3640083},
doi = {10.1145/3639474.3640083},
abstract = {Despite recent initiatives aimed at improving accessibility, the field of digital accessibility remains markedly behind contemporary advancements in the software industry, as many real-world software and web applications continue to fall short of accessibility requirements. A persisting skills deficit within the existing technology workforce has been an enduring impediment, hindering organizations from delivering truly accessible software products. This, in turn, elevates the risk of isolating and excluding a substantial portion of potential users. In this paper, we report lessons learned from a training program for teaching digital accessibility using the Communities of Practice (CoP) framework to industry professionals. We recruited 66 participants from a large multinational software company and assigned them to two groups: one participating in a CoP and the other using self-paced learning. We report experiences from designing the training program, conducting the actual training, and assessing the efficiency of the two approaches. Based on these findings, we provide recommendations for practitioners in Learning and Development teams and educators in designing accessibility courses for industry professionals.},
booktitle = {Proceedings of the 46th International Conference on Software Engineering: Software Engineering Education and Training},
pages = {191–200},
numpages = {10},
keywords = {accessibility, massive open online courses, community of practice, computing education, global computing education},
location = {Lisbon, Portugal},
series = {ICSE-SEET '24}
}

@inproceedings{10.1145/3640457.3688014,
author = {Schellingerhout, Roan},
title = {Explainable Multi-Stakeholder Job Recommender Systems},
year = {2024},
isbn = {9798400705052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3640457.3688014},
doi = {10.1145/3640457.3688014},
abstract = {Public opinion on recommender systems has become increasingly wary in recent years. In line with this trend, lawmakers have also started to become more critical of such systems, resulting in the introduction of new laws focusing on aspects such as privacy, fairness, and explainability for recommender systems and AI at large. These concepts are especially crucial in high-risk domains such as recruitment. In recruitment specifically, decisions carry substantial weight, as the outcomes can significantly impact individuals’ careers and companies’ success. Additionally, there is a need for a multi-stakeholder approach, as these systems are used by job seekers, recruiters, and companies simultaneously, each with its own requirements and expectations. In this paper, I summarize my current research on the topic of explainable, multi-stakeholder job recommender systems and set out a number of future research directions.},
booktitle = {Proceedings of the 18th ACM Conference on Recommender Systems},
pages = {1318–1322},
numpages = {5},
keywords = {Explainable AI, Graph Neural Networks, Job Recommender Systems, Knowledge Graphs, Multi-Stakeholder Recommendation},
location = {Bari, Italy},
series = {RecSys '24}
}

@proceedings{10.1145/3701625,
title = {SBQS '24: Proceedings of the XXIII Brazilian Symposium on Software Quality},
year = {2024},
isbn = {9798400717772},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@inproceedings{10.1145/3637528.3671973,
author = {Lin, Fake and Zhao, Ziwei and Zhu, Xi and Zhang, Da and Shen, Shitian and Li, Xueying and Xu, Tong and Zhang, Suojuan and Chen, Enhong},
title = {When Box Meets Graph Neural Network in Tag-aware Recommendation},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671973},
doi = {10.1145/3637528.3671973},
abstract = {Last year has witnessed the re-flourishment of tag-aware recommender systems supported by the LLM-enriched tags. Unfortunately, though large efforts have been made, current solutions may fail to describe the diversity and uncertainty inherent in user preferences with only tag-driven profiles. Recently, with the development of geometry-based techniques, e.g., box embeddings, the diversity of user preferences now could be fully modeled as the range within a box in high dimension space. However, defect still exists as these approaches are incapable of capturing high-order neighbor signals, i.e., semantic-rich multi-hop relations within the user-tag-item tripartite graph, which severely limits the effectiveness of user modeling. To deal with this challenge, in this paper, we propose a novel framework, called BoxGNN, to perform message aggregation via combinations of logical operations, thereby incorporating high-order signals. Specifically, we first embed users, items, and tags as hyper-boxes rather than simple points in the representation space, and define two logical operations, i.e., union and intersection, to facilitate the subsequent process. Next, we perform the message aggregation mechanism via the combination of logical operations, to obtain the corresponding high-order box representations. Finally, we adopt a volume-based learning objective with Gumbel smoothing techniques to refine the representation of boxes. Extensive experiments on two publicly available datasets and one LLM-enhanced e-commerce dataset have validated the superiority of BoxGNN compared with various state-of-the-art baselines. The code is released online: https://github.com/critical88/BoxGNN.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {1770–1780},
numpages = {11},
keywords = {box embedding, graph neural networks, recommendation system, tag-aware recommendation},
location = {Barcelona, Spain},
series = {KDD '24}
}

@proceedings{10.1145/3694811,
title = {GNNet '24: Proceedings of the 3rd GNNet Workshop on Graph Neural Networking Workshop},
year = {2024},
isbn = {9798400712548},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our great pleasure to welcome you to the Third International Workshop on Graph Neural Networking - GNNet 2024, co-located with ACM CoNEXT 2024.Graphs are emerging as an abstraction to represent complex data. Computer Networks are fundamentally graphs, and many of their relevant characteristics - such as topology and routing - are represented as graph-structured data. Machine learning, especially deep representation learning on graphs, is an emerging field with a wide array of applications. Within this field, Graph Neural Networks (GNNs) have been recently proposed to model and learn over graph-structured data. Due to their unique ability to generalize over graph data, GNNs are a central tool to apply AI/ML techniques to networking applications.The GNNet workshop continues its tradition of providing the first dedicated venue to present and discuss the latest advancements on the emerging topic of GNNs applied to computer networking problems. GNNet brings together leaders from academia and industry to showcase recent methodological advances of GNNs and their application to computer networks, covering a wide range of applications and practical challenges for training and deployment. The GNNet workshop serves as the meeting point for the growing community on this fascinating domain, which previously did not have a specific forum for sharing ideas and discussion.The third edition of the GNNet workshop is co-located with ACM CoNEXT 2024 and held in Los Angeles, CA, USA, in December 2024. The GNNet 2024 technical program consists of 9 quality papers. The TPC was composed of 21 well-recognized researchers and practitioners in the areas of GNN and AI/ML applied to computer networks.},
location = {Los Angeles, CA, USA}
}

@proceedings{10.1145/3671151,
title = {CIBDA '24: Proceedings of the 5th International Conference on Computer Information and Big Data Applications},
year = {2024},
isbn = {9798400718106},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Wuhan, China}
}

@proceedings{10.1145/3643662,
title = {EnCyCriS/SVM '24: Proceedings of the 2024 ACM/IEEE 4th International Workshop on Engineering and Cybersecurity of Critical Systems (EnCyCriS) and 2024 IEEE/ACM Second International Workshop on Software Vulnerability},
year = {2024},
isbn = {9798400705656},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Increasing system interconnectivity, decentralization, and introduction of new, more intelligent technologies, result in critical infrastructures becoming exposed to increased risk of cyber, physical, and combined cyber-physical attacks. Cyberattacks on critical systems can inflict severe consequences to people, society, economy, and national security, and can have adverse effects on safety and reliability of critical infrastructures. The joint EnCyCriS-SVM workshop facilitates discourse and discussions among researchers, practitioners, and students who are working on challenges and solutions related to the industrial revolution. Focus is given on sharing industry experience and project results pertaining to cyber threats on critical systems; secure software engineering; and attack detection and response mechanisms.},
location = {Lisbon, Portugal}
}

@inproceedings{10.1145/3652620.3686246,
author = {Siddeshwar, Vaishali and Alwidian, Sanaa and Makrehchi, Masoud},
title = {A Comparative Study of Large Language Models for Goal Model Extraction},
year = {2024},
isbn = {9798400706226},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652620.3686246},
doi = {10.1145/3652620.3686246},
abstract = {User stories, expressed in snippets of natural language text, are commonly used to elicit stakeholder's needs in agile software development. Requirement engineers model user stories to interpret the relations among goals and requirements. Manual transformation of goal models has challenges such as, difficulty of converting lower-abstraction user stories into higher-level goals, and extraction of goals embedded in user stories depends on the skill of requirements engineers. In this paper we introduce a technique that leverages Large Language Models (LLMs) to automatically generate goal models from user stories. The approach uses Iterative Prompt Engineering that guides LLM to extract intentional elements and generate its XML-compatible representation in Goal-oriented Requirements Language (GRL). The generated models can be visualized using jUCMNav tool. We evaluated our approach using three LLMs: GPT-4, Llama and Cohere. Our qualitative evaluation indicates that GPT-4 or Llama can be used to assist requirements engineers in modeling as they can produce GRL goal models that are understandable. Additionally, these LLMs are capable of exposing soft goals that are not apparent to stakeholders who are new to the domain.},
booktitle = {Proceedings of the ACM/IEEE 27th International Conference on Model Driven Engineering Languages and Systems},
pages = {253–263},
numpages = {11},
keywords = {goal-oriented requirement language (GRL), goal modeling, user story, agile development, requirements engineering, large language models (LLMS), GPT-4, llama, cohere},
location = {Linz, Austria},
series = {MODELS Companion '24}
}

@inproceedings{10.1145/3695080.3695096,
author = {Chi, Wenxin and Wei, Shijie},
title = {Construction of marketing risk perception framework based on large model agent},
year = {2024},
isbn = {9798400710223},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3695080.3695096},
doi = {10.1145/3695080.3695096},
abstract = {The new generation of artificial intelligence technology represented by the Chat-GPT large model is profoundly affecting all walks of life. The marketing risk perception framework based on large model agents brings new opportunities for marketing risk analysis of large enterprises. The author takes China Mobile's large-model intelligent marketing entity risk management and control as an example to discuss the application exploration of large-model intelligent entities in corporate marketing risks. This article first discusses the various opportunities and effects that large model intelligence brings to corporate marketing; secondly, it elaborates on its construction framework, then analyzes its user intentions and assesses risks, and finally elaborates on its operational logic. Through the above steps, the role of the marketing risk perception framework based on large model agents in the field of corporate marketing is systematically analyzed in terms of risk prediction, risk analysis, and risk prevention and control. This will systematically and comprehensively lay a practical foundation for large model agents in the field of marketing risk perception.},
booktitle = {Proceedings of the 2024 International Conference on Cloud Computing and Big Data},
pages = {93–99},
numpages = {7},
location = {Dali, China},
series = {ICCBD '24}
}

@inproceedings{10.1145/3661725.3661766,
author = {Nir, Oron and Vidra, Idan and Neeman, Avi and Kinarti, Barak and Shamir, Ariel},
title = {VCR: Video representation for Contextual Retrieval},
year = {2024},
isbn = {9798400716393},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3661725.3661766},
doi = {10.1145/3661725.3661766},
abstract = {Streamlining content discovery in media archives requires advanced data representations and effective visualization techniques for clear communication of video topics to users. The proposed system addresses the challenge of efficiently navigating large video collections by exploiting a fusion of visual, audio, and textual features to accurately index and categorize video content through a text-based method. Additionally, semantic embeddings are employed to provide contextually relevant information and recommendations to users, resulting in an intuitive and engaging exploratory experience over our topics ontology map using LLMs (GitHub).},
booktitle = {Proceedings of the International Conference on Computing, Machine Learning and Data Science},
articleno = {39},
numpages = {9},
keywords = {Archive Exploration, Media Search, Video Representation},
location = {Singapore, Singapore},
series = {CMLDS '24}
}

@inproceedings{10.1145/3678957.3688616,
author = {Raingeard de la Bletiere, Paul},
title = {A musical Robot for People with Dementia},
year = {2024},
isbn = {9798400704628},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3678957.3688616},
doi = {10.1145/3678957.3688616},
abstract = {This doctoral research aims to enhance the Quality of Life (QoL) of People with Dementia (PwD) by developing a personalized musical robot to provide support through music and reminiscence activities. Our research is dedicated to creating and facilitating meaningful activities, while reducing agitation and improving PwD’s mood. Key studies include the development of a music recommender system based on episodic memories, robotic assistance in daily activities through schedule-related music, and collaborative storytelling involving the PwD and their informal caregivers. These interventions are intended to support emotional regulation and communication. This PhD is part of the QoLEAD project, which integrates multidisciplinary research to bridge the gap between AI and warm care in dementia.},
booktitle = {Proceedings of the 26th International Conference on Multimodal Interaction},
pages = {602–606},
numpages = {5},
keywords = {Memories, Music, Music Recommendation, People with Dementia, PhD, Robot, Storytelling},
location = {San Jose, Costa Rica},
series = {ICMI '24}
}

@article{10.1145/3653070,
author = {Mai, Gengchen and Huang, Weiming and Sun, Jin and Song, Suhang and Mishra, Deepak and Liu, Ninghao and Gao, Song and Liu, Tianming and Cong, Gao and Hu, Yingjie and Cundy, Chris and Li, Ziyuan and Zhu, Rui and Lao, Ni},
title = {On the Opportunities and Challenges of Foundation Models for GeoAI (Vision Paper)},
year = {2024},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {10},
number = {2},
issn = {2374-0353},
url = {https://doi.org/10.1145/3653070},
doi = {10.1145/3653070},
abstract = {Large pre-trained models, also known as foundation models (FMs), are trained in a task-agnostic manner on large-scale data and can be adapted to a wide range of downstream tasks by fine-tuning, few-shot, or even zero-shot learning. Despite their successes in language and vision tasks, we have not yet seen an attempt to develop foundation models for geospatial artificial intelligence (GeoAI). In this work, we explore the promises and challenges of developing multimodal foundation models for GeoAI. We first investigate the potential of many existing FMs by testing their performances on seven tasks across multiple geospatial domains, including Geospatial Semantics, Health Geography, Urban Geography, and Remote Sensing. Our results indicate that on several geospatial tasks that only involve text modality, such as toponym recognition, location description recognition, and US state-level/county-level dementia time series forecasting, the task-agnostic large learning models (LLMs) can outperform task-specific fully supervised models in a zero-shot or few-shot learning setting. However, on other geospatial tasks, especially tasks that involve multiple data modalities (e.g., POI-based urban function classification, street view image–based urban noise intensity classification, and remote sensing image scene classification), existing FMs still underperform task-specific models. Based on these observations, we propose that one of the major challenges of developing an FM for GeoAI is to address the multimodal nature of geospatial tasks. After discussing the distinct challenges of each geospatial data modality, we suggest the possibility of a multimodal FM that can reason over various types of geospatial data through geospatial alignments. We conclude this article by discussing the unique risks and challenges to developing such a model for GeoAI.},
journal = {ACM Trans. Spatial Algorithms Syst.},
month = jul,
articleno = {11},
numpages = {46},
keywords = {Foundation models, geospatial artificial intelligence, multimodal learning}
}

@article{10.1145/3708504,
author = {Tsakalakis, Niko and Stalla-Bourdillon, Sophie and Huynh, Dong and Moreau, Luc},
title = {A Typology of Explanations for Explainability-by-Design},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3708504},
doi = {10.1145/3708504},
abstract = {As automated decision-making permeates almost all aspects of everyday life, capabilities to generate meaningful explanations for various stakeholders (i.e., decision-makers, addressees of decisions including individuals, auditors, and regulators) should be carefully deployed. This paper presents a typology of explanations intended to support the first pillar of an explainability-by-design strategy. Its production has been achieved by pursuing a responsible innovation approach and introducing a new persona within the research and innovation process, i.e., a legal engineer, whose role is to work at the interface of two teams, the compliance and the engineering teams and to oversee the process of requirement elicitation, which is often opinionated and narrowing. Once explanation requirements have been derived from applicable regulatory requirements, compliance rules or business policies, they have been mapped to the dimensions of the typology to produce fine-grained explanation requirements, forming computable building blocks that can then be translated into system requirements during the technical design phase. The typology has been co-created with industry partners operating in two sectors: finance and education. Two pilot studies have thus been conducted to test both the feasibility of the generation and computation of explanations on the basis of the typology and the usefulness of the outputs in the light of the state of the art. The typology comprises nine hierarchical dimensions. It can be leveraged to operate a stand-alone classifier of explanations that acts as detective controls within a broader partially-automated compliance strategy. A machine-readable format of the typology is provided in the form of a light ontology.},
note = {Just Accepted},
journal = {ACM J. Responsib. Comput.},
month = dec,
keywords = {artificial intelligence, explainability, typology, data protection, automated decisions}
}

@article{10.1145/3643505,
author = {King, Evan and Yu, Haoxiang and Lee, Sangsu and Julien, Christine},
title = {Sasha: Creative Goal-Oriented Reasoning in Smart Homes with Large Language Models},
year = {2024},
issue_date = {March 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {1},
url = {https://doi.org/10.1145/3643505},
doi = {10.1145/3643505},
abstract = {Smart home assistants function best when user commands are direct and well-specified---e.g., "turn on the kitchen light"---or when a hard-coded routine specifies the response. In more natural communication, however, human speech is unconstrained, often describing goals (e.g., "make it cozy in here" or "help me save energy") rather than indicating specific target devices and actions to take on those devices. Current systems fail to understand these under-specified commands since they cannot reason about devices and settings as they relate to human situations. We introduce large language models (LLMs) to this problem space, exploring their use for controlling devices and creating automation routines in response to under-specified user commands in smart homes. We empirically study the baseline quality and failure modes of LLM-created action plans with a survey of age-diverse users. We find that LLMs can reason creatively to achieve challenging goals, but they experience patterns of failure that diminish their usefulness. We address these gaps with Sasha, a smarter smart home assistant. Sasha responds to loosely-constrained commands like "make it cozy" or "help me sleep better" by executing plans to achieve user goals---e.g., setting a mood with available devices, or devising automation routines. We implement and evaluate Sasha in a hands-on user study, showing the capabilities and limitations of LLM-driven smart homes when faced with unconstrained user-generated scenarios.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = mar,
articleno = {12},
numpages = {38},
keywords = {ambient intelligence, large language models, pervasive computing, smart environments}
}

@inproceedings{10.1145/3638530.3664163,
author = {Custode, Leonardo Lucio and Caraffini, Fabio and Yaman, Anil and Iacca, Giovanni},
title = {An investigation on the use of Large Language Models for hyperparameter tuning in Evolutionary Algorithms},
year = {2024},
isbn = {9798400704956},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3638530.3664163},
doi = {10.1145/3638530.3664163},
abstract = {Hyperparameter optimization is a crucial problem in Evolutionary Computation. In fact, the values of the hyperparameters directly impact the trajectory taken by the optimization process, and their choice requires extensive reasoning by human operators. Although a variety of self-adaptive Evolutionary Algorithms have been proposed in the literature, no definitive solution has been found. In this work, we perform a preliminary investigation to automate the reasoning process that leads to the choice of hyperparameter values. We employ two open-source Large Language Models (LLMs), namely Llama2-70b and Mixtral, to analyze the optimization logs online and provide novel real-time hyperparameter recommendations. We study our approach in the context of step-size adaptation for (1 + 1)-ES. The results suggest that LLMs can be an effective method for optimizing hyperparameters in Evolution Strategies, encouraging further research in this direction.},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference Companion},
pages = {1838–1845},
numpages = {8},
keywords = {evolutionary algorithms, large language models, landscape analysis, parameter tuning},
location = {Melbourne, VIC, Australia},
series = {GECCO '24 Companion}
}

@article{10.1145/3698811,
author = {Yan, Mengyi and Wang, Yaoshu and Wang, Yue and Miao, Xiaoye and Li, Jianxin},
title = {GIDCL: A Graph-Enhanced Interpretable Data Cleaning Framework with Large Language Models},
year = {2024},
issue_date = {December 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {6},
url = {https://doi.org/10.1145/3698811},
doi = {10.1145/3698811},
abstract = {Data quality is critical across many applications. The utility of data is undermined by various errors, making rigorous data cleaning a necessity. Traditional data cleaning systems depend heavily on predefined rules and constraints, which necessitate significant domain knowledge and manual effort. Moreover, while configuration-free approaches and deep learning methods have been explored, they struggle with complex error patterns, lacking interpretability, requiring extensive feature engineering or labeled data. This paper introduces GIDCL (Graph-enhanced Interpretable Data Cleaning with Large language models), a pioneering framework that harnesses the capabilities of Large Language Models (LLMs) alongside Graph Neural Network (GNN) to address the challenges of traditional and machine learning-based data cleaning methods. By converting relational tables into graph structures, GIDCL utilizes GNN to effectively capture and leverage structural correlations among data, enhancing the model's ability to understand and rectify complex dependencies and errors. The framework's creator-critic workflow innovatively employs LLMs to automatically generate interpretable data cleaning rules and tailor feature engineering with minimal labeled data. This process includes the iterative refinement of error detection and correction models through few-shot learning, significantly reducing the need for extensive manual configuration. GIDCL not only improves the precision and efficiency of data cleaning but also enhances its interpretability, making it accessible and practical for non-expert users. Our extensive experiments demonstrate that GIDCL significantly outperforms existing methods, improving F1-scores by 10% on average while requiring only 20 labeled tuples.},
journal = {Proc. ACM Manag. Data},
month = dec,
articleno = {236},
numpages = {29},
keywords = {data quality, graph neural network, interpretable, large language models}
}

@inproceedings{10.1145/3657054.3657277,
author = {Bachinger, Sarah T. and Feddoul, Leila and Mauch, Marianne Jana and K\"{o}nig-Ries, Birgitta},
title = {Extracting Legal Norm Analysis Categories from German Law Texts with Large Language Models},
year = {2024},
isbn = {9798400709883},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657054.3657277},
doi = {10.1145/3657054.3657277},
abstract = {The digitization of public services in Germany is always based on a legal basis (e.g., laws). In the digitization process, first relevant entities in law documents (e.g., actors) are detected, then a list of possible process steps of their interactions is derived. The final process is constructed and transformed to a digital service for citizens and companies. Today, the discovery of custom entities in German law documents is still manual high effort work. In our study, we investigate the capabilities of Large Language Models (LLMs) to automate this task, choose five LLMs from 61 evaluated candidates, and perform prompt engineering to create five different prompt variants with differing parts. We examine the automatic annotation by two LLMs (LeoLM and BLOOM CLP German) in detail and find that the inclusion of more information in the prompts as well as an increased number of examples per prompt are beneficial. We report micro F1-scores for the optimal scenario of 0.91 for BLOOM CLP German, and 0.82 for LeoLM, with a higher balanced accuracy for LeoLM. The results indicate that LLMs have a good potential to perform named entity recognition, especially for supporting legal norm analysis in the context of the digitization of public administration.},
booktitle = {Proceedings of the 25th Annual International Conference on Digital Government Research},
pages = {481–493},
numpages = {13},
keywords = {Digital Transformation, Federal Information Management, Large Language Models, Named Entity Recognition, Public Administration},
location = {Taipei, Taiwan},
series = {dg.o '24}
}

@inproceedings{10.1145/3675249.3675319,
author = {Xu, Dapeng and Kang, Qi and Zhang, Wei},
title = {Risk Rating Method for Power Grid Production Operations Based on an Improved BERT Model},
year = {2024},
isbn = {9798400718267},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3675249.3675319},
doi = {10.1145/3675249.3675319},
abstract = {Enhancing the level of risk rating in power grid operations can effectively ensure the safety and stability of the power grid. Artificial intelligence-based risk rating methods can assist on-site workers in quickly and standardly judging operational risks. This paper proposes an improved model based on the bidirectional encoder representations from transformers(BERT) model. It replaces the gaussian error linear unit (GELU) activation function in the feedforward neural network (FFN) layer with the switched gated linear unit(SwiGLU) activation function to study its performance change pattern. Experiments were conducted on a collected dataset of power grid production operation risks. The results show that the model demonstrates excellent performance in risk rating.},
booktitle = {Proceedings of the 2024 International Conference on Computer and Multimedia Technology},
pages = {401–407},
numpages = {7},
location = {Sanming, China},
series = {ICCMT '24}
}

@inproceedings{10.1145/3626246.3653372,
author = {Bao, Xianchun and Bao, Zian and Binbin, Bie and Duan, QingSong and Fan, Wenfei and Lei, Hui and Li, Daji and Lin, Wei and Liu, Peng and Lv, Zhicong and Ouyang, Mingliang and Tang, Shuai and Wang, Yaoshu and Wei, Qiyuan and Xie, Min and Zhang, Jing and Zhang, Xin and Zhao, Runxiao and Zhou, Shuping},
title = {Rock: Cleaning Data by Embedding ML in Logic Rules},
year = {2024},
isbn = {9798400704222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626246.3653372},
doi = {10.1145/3626246.3653372},
abstract = {We introduce Rock, a system for cleaning relational data. Rock implements a framework that unifies machine learning (ML) and logic deduction by embedding ML classifiers in rules as predicates. In a unified process, it identifies tuples that refer to the same real-world entity, catches semantic inconsistencies among the entities, deduces the timeliness of the attribute values of the entities, and imputes missing values by possibly extracting data from knowledge graphs. That is, Rock conducts entity resolution, conflict resolution, incomplete information imputation and timeliness deduction in the same process, makes use of their interactions and improves the overall quality of the data. Moreover, Rock supports methods, batch and incremental, for discovering rules from real-life data, detecting errors with the learned rules, accumulating ground truth, and fixing the errors, such that the corrections are logical consequences of the rules and ground truth. We present the design and implementation of Rock. We evaluate the scalability and accuracy of Rock, and share lessons learned from a variety of real-life applications.},
booktitle = {Companion of the 2024 International Conference on Management of Data},
pages = {106–119},
numpages = {14},
keywords = {conflict resolution, data quality, entity resolution, error correction, error detection, missing value imputation, timeliness deduction},
location = {Santiago AA, Chile},
series = {SIGMOD/PODS '24}
}

@inproceedings{10.1145/3603273.3627834,
author = {Zhang, Xixiang and Meng, Qi and Tan, Qiwen and Dong, Yun and Chen, Yan and Tan, Zhixiang},
title = {GCN-based Entity Relation Extraction Method for Power Marketing Data},
year = {2024},
isbn = {9798400708268},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3603273.3627834},
doi = {10.1145/3603273.3627834},
abstract = {Power marketing text data contains more specialized terms in specific fields, and there are multiple nested text entities, therefore the relationship between entity recognition is more difficult. In this paper, a graph convolution-based entity relation extraction model PMRE for power marketing data is proposed. Firstly, using the span representation annotation method, the model extracts the bidirectional representation of text depth by using RoBERTa as the encoder layer, and uses the whole word masking strategy for pre-training. Then the feature representation is passed to the graph convolutional layer, and using multi-head attention mechanisms to capture the weights of relationships between words in the text across multiple dimensions, and the semantic dependency tree is constructed and then fed into the graph convolutional neural network, and the distance dependency problem solved by the spatial features between entities is obtained. Finally, the features are fed into the multilayer perceptron layer for entity relationship classification. In the process of model training, the cross-entropy loss function is used to obtain the maximum likelihood value of the predicted label and the target label. Using the power marketing data supplied by the Southern Power Grid as an example, the precision and F1 score of the relation extraction model in this paper reached 83.80% and 82.16%, respectively, compared with the benchmark model, recall, precision and F1 score of this model are significantly enhanced, indicating that the model proposed in this paper has a good solution effect on entity relation extraction of power marketing text data with complex entity nested and many professional terms.},
booktitle = {Proceedings of the 2023 International Conference on Advances in Artificial Intelligence and Applications},
pages = {120–127},
numpages = {8},
keywords = {GCN, RoBERTa, power marketing, relation extraction, whole word masking},
location = {Wuhan, China},
series = {AAIA '23}
}

@proceedings{10.1145/3670105,
title = {CNIOT '24: Proceedings of the 2024 5th International Conference on Computing, Networks and Internet of Things},
year = {2024},
isbn = {9798400716751},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Tokyo, Japan}
}

@inproceedings{10.1145/3658644.3690306,
author = {Wen, Rui and Li, Zheng and Backes, Michael and Zhang, Yang},
title = {Membership Inference Attacks Against In-Context Learning},
year = {2024},
isbn = {9798400706363},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3658644.3690306},
doi = {10.1145/3658644.3690306},
abstract = {Adapting Large Language Models (LLMs) to specific tasks introduces concerns about computational efficiency, prompting an exploration of efficient methods such as In-Context Learning (ICL). However, the vulnerability of ICL to privacy attacks under realistic assumptions remains largely unexplored. In this work, we present the first membership inference attack tailored for ICL, relying solely on generated texts without their associated probabilities. We propose four attack strategies tailored to various constrained scenarios and conduct extensive experiments on four popular large language models. Empirical results show that our attacks can accurately determine membership status in most cases, e.g., 95% accuracy advantage against LLaMA, indicating that the associated risks are much higher than those shown by existing probability-based attacks. Additionally, we propose a hybrid attack that synthesizes the strengths of the aforementioned strategies, achieving an accuracy advantage of over 95% in most cases. Furthermore, we investigate three potential defenses targeting data, instruction, and output. Results demonstrate combining defenses from orthogonal dimensions significantly reduces privacy leakage and offers enhanced privacy assurances.},
booktitle = {Proceedings of the 2024 on ACM SIGSAC Conference on Computer and Communications Security},
pages = {3481–3495},
numpages = {15},
keywords = {in-context learning, large language models, membership inference attacks},
location = {Salt Lake City, UT, USA},
series = {CCS '24}
}

@inproceedings{10.1145/3652620.3686251,
author = {Zavada, \'{A}rmin and Marussy, Krist\'{o}f and Moln\'{a}r, Vince},
title = {From Transpilers to Semantic Libraries: Formal Verification With Pluggable Semantics},
year = {2024},
isbn = {9798400706226},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652620.3686251},
doi = {10.1145/3652620.3686251},
abstract = {In the field of model-based systems engineering, there is an increasing demand for the application of formal methods. However, this requires expertise in formal methods, which cannot be expected from systems engineers. While several attempts have been made to bridge this gap, there are still open questions. (1) With the trend shifting towards ontological languages, systems are modeled as classes of 4D occurrences, rather than a 3D system evolving with time, which hinders the application of state-of-the-art model checking algorithms. (2) Ontological reasoning cannot handle the state space explosion problem, and can even make it harder for verifiers to operate efficiently. (3) When operationalizing ontological languages, we need to validate the conformance of the two semantics, even in the presence of optimizations. (4) On top of all, these challenges must be solved for every new engineering language, version, or variant. In this paper, we propose a new approach to address the aforementioned challenges. To validate its feasibility, we present a prototype tool and evaluate it on a SysML model.},
booktitle = {Proceedings of the ACM/IEEE 27th International Conference on Model Driven Engineering Languages and Systems},
pages = {311–317},
numpages = {7},
keywords = {model-based systems engineering, kernel modeling language, formal verification, declarative interpretation, metaprogramming, semantic libraries, operational libraries},
location = {Linz, Austria},
series = {MODELS Companion '24}
}

@proceedings{10.1145/3660043,
title = {ICIEAI '23: Proceedings of the 2023 International Conference on Information Education and Artificial Intelligence},
year = {2023},
isbn = {9798400716157},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Xiamen, China}
}

@inproceedings{10.1145/3689492.3690054,
author = {Marron, Mark},
title = {A Programming Language for Data and Configuration!},
year = {2024},
isbn = {9798400712159},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689492.3690054},
doi = {10.1145/3689492.3690054},
abstract = {A day in the life of a developer often involves more time working with schemas, configurations, and data description systems than writing code and logic in a classical programming language. As more systems move into distributed worlds, e.g. cloud and microservices, and developers make increasing use of libraries and frameworks, the need to interact with a range of data formats and configuration mechanisms is only increasing. This is a treacherous world, where a misspelled property name or missing field can render an entire service inoperable, a mistake that a number in an API represents 
 
 
 
seconds instead of milli-seconds can lead to a message being set for delivery in several months instead of in an hour, misconfigured schema can lead to public exposure of sensitive data, and corrupt or erroneous results from a misunderstood data format could result in massive financial and/or reputational damage.
 
 
 

 
 
 
To address these challenges this paper casts the problems of data and configuration descriptions, not as a problem of data representation, but as a type system problem, that can be addressed with well understood and highly effective programming language techniques! The novel challenge is that data representation and configuration are universal concerns in a system and, particularly in modern cloud or micro-service systems, these systems may involve many programming languages. In the past this has led to specification systems that use a least-common-denominator set of data types, often little more than strings and numbers, and then rely on conventions or (out-of-date) documentation to ensure that the data is interpreted correctly. This paper shows that, with careful design, it is possible to create a rich universal system that can be used to express data and configuration specifications in a way that is human readable/writable and that can be produced/consumed, much like JSON, by a wide range of programming languages and systems.},
booktitle = {Proceedings of the 2024 ACM SIGPLAN International Symposium on New Ideas, New Paradigms, and Reflections on Programming and Software},
pages = {147–161},
numpages = {15},
keywords = {Configuration, Data Specification, Programming Language},
location = {Pasadena, CA, USA},
series = {Onward! '24}
}

@proceedings{10.1145/3643657,
title = {SATrends '24: Proceedings of the 1st International Workshop on New Trends in Software Architecture},
year = {2024},
isbn = {9798400705601},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {In this workshop, we aim at establishing a forum to collect practitioners' experiences and/or researchers' observations related to trends, and enable practitioners and researchers to exchange opinions, learn from each other, and progress the state of the art in the adoption of new trends.},
location = {Lisbon, Portugal}
}

@article{10.1145/3674500,
author = {De Sousa Ribeiro, Fabio and Duarte, Kevin and Everett, Miles and Leontidis, Georgios and Shah, Mubarak},
title = {Object-centric Learning with Capsule Networks: A Survey},
year = {2024},
issue_date = {November 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {56},
number = {11},
issn = {0360-0300},
url = {https://doi.org/10.1145/3674500},
doi = {10.1145/3674500},
abstract = {Capsule networks emerged as a promising alternative to convolutional neural networks for learning object-centric representations. The idea is to explicitly model part-whole hierarchies by using groups of neurons called capsules to encode visual entities, then learn the relationships between these entities dynamically from data. However, a major hurdle for capsule network research has been the lack of a reliable point of reference for understanding their foundational ideas and motivations. This survey provides a comprehensive and critical overview of capsule networks, which aims to serve as a main point of reference going forward. To that end, we introduce the fundamental concepts and motivations behind capsule networks, such as equivariant inference. We then cover various technical advances in capsule routing algorithms as well as alternative geometric and generative formulations. We provide a detailed explanation of how capsule networks relate to the attention mechanism in Transformers and uncover non-trivial conceptual similarities between them in the context of object-centric representation learning. We also review the extensive applications of capsule networks in computer vision, video and motion, graph representation learning, natural language processing, medical imaging, and many others. To conclude, we provide an in-depth discussion highlighting promising directions for future work.},
journal = {ACM Comput. Surv.},
month = jul,
articleno = {291},
numpages = {291},
keywords = {Deep learning, capsule networks, deep neural networks, convolutional neural networks, transformers, routing-by-agreement, self-attention, representation learning, object-centric learning, generative models, computer vision}
}

@article{10.1145/3689629,
author = {Yang, Songhua and Zhang, Chenghao and He, Chenyuan and Xu, Hongfei and Zan, Hongying and Jia, Yuxiang},
title = {Knowledge-injected Prompt Learning for Chinese Biomedical Entity Normalization},
year = {2024},
issue_date = {October 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {10},
issn = {2375-4699},
url = {https://doi.org/10.1145/3689629},
doi = {10.1145/3689629},
abstract = {The Biomedical Entity Normalization (BEN) task aims to align raw, unstructured medical entities to standard entities, thus promoting data coherence and facilitating better downstream medical applications. Recently, prompt learning methods have shown promising results in the natural language processing field. However, existing research falls short in tackling the more complex Chinese BEN task, especially in the few-shot scenario with limited medical data, and the vast potential of the external medical knowledge base has not yet been fully exploited. To address these challenges, this article proposes a novel Knowledge-injected Prompt Learning (PL-Knowledge) method. Specifically, the approach consists of five stages: candidate entity matching, knowledge extraction, knowledge encoding, knowledge injection, and prediction output. By effectively encoding the knowledge items contained in medical entities and incorporating them into tailor-made knowledge-injected templates, the additional knowledge enhances the model’s ability to capture latent relationships between medical entities, thus achieving a better match with the standard entities. Comprehensive experiments are conducted on a benchmark dataset in both few-shot and full-scale settings. This method outperforms existing baselines, with an average accuracy improvement of 12.96 percentage points in few-shot and 0.94 percentage points in full-data cases, showcasing its excellence in the BEN task.},
journal = {ACM Trans. Asian Low-Resour. Lang. Inf. Process.},
month = oct,
articleno = {144},
numpages = {21},
keywords = {Biomedical entity normalization, prompt learning, knowledge enhancement, few-shot learning}
}

@inproceedings{10.1145/3660395.3660458,
author = {Zhao, Jiaqi and Lin, Rongheng and Wang, Baigen and Wang, Ou and Zhao, Qian and Liu, Huizhou},
title = {Pruned Contrastive Learning Verbalizer for Prompt-based Few-shot Text Classification},
year = {2024},
isbn = {9798400716362},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3660395.3660458},
doi = {10.1145/3660395.3660458},
abstract = {The utilization of pre-trained language models (PLMs) has led to remarkable advancements in the field of few-shot learning through prompt-based fine-tuning. This technique requires the use of templates to structure input text as a cloze question and the implementation of verbalizers to map the PLM's output to the answer space of a given task. However, the manual construction of verbalizers heavily relies on domain knowledge and experience, and the performance of automatic verbalizers searching based on limited samples is notably weaker compared to scenarios with sufficient data. To enhance the performance in low-data settings, we introduce a novel method called Pruned Contrastive Learning Verbalizers (PCV) for automatically generating verbalizers. Our approach comprises two phases: firstly, employing pruned searching to identify the most suitable label words, and secondly, utilizing contrastive learning to acquire class prototypes from the training data. Our experiments on text classification tasks show that PCV outperforms compared to manual and automatic verbalizers in resource-constrained environments. Finally, we applied PCV in a real-world scenario involving electrical safety inspections, further demonstrating its exceptional performance in classification tasks.},
booktitle = {Proceedings of the 2023 3rd Guangdong-Hong Kong-Macao Greater Bay Area Artificial Intelligence and Big Data Forum},
pages = {370–377},
numpages = {8},
location = {Guangzhou, China},
series = {AIBDF '23}
}

@inproceedings{10.1145/3669754.3669784,
author = {Jayawardena, Lasal and Yapa, Prasan},
title = {Improving Quality and Domain-Relevancy of Paraphrase Generation with Graph-Based Retrieval Augmented Generation},
year = {2024},
isbn = {9798400717055},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3669754.3669784},
doi = {10.1145/3669754.3669784},
abstract = {Paraphrase generation is a fundamental area of research in Natural Language Processing (NLP) and Natural Language Generation (NLG), due to its sequence-to-sequence (Seq2Seq) nature. Paraphrasing, spanning across various domains, poses challenges for simpler model architectures due to the extensive knowledge required to generate paraphrases. The added constraint of generating diverse paraphrases further complicates the task for models trained on existing datasets. We present a methodology that leverages Graph-Based Retrieval Augmented Generation (G-RAG), capable of utilizing both entity and phrasal knowledge to address this issue. We demonstrate through experiments that this approach enables both complex models like Large Language models (LLMs) and smaller Seq2Seq models to generate more diverse paraphrases without compromising semantic similarity. Furthermore, this approach’s capacity to integrate domain-specific knowledge makes it particularly effective across different domains, enhancing its applicability in varied contexts. The results are further corroborated by human evaluation and extensive quantitative analysis focusing on semantic similarity, lexical diversity, syntactic diversity, and grammatical correctness to gauge high-quality paraphrases.},
booktitle = {Proceedings of the 2024 10th International Conference on Computing and Artificial Intelligence},
pages = {196–208},
numpages = {13},
keywords = {Graph-based Knowledge, Large Language Models, Natural Language Processing, Paraphrase Generation, Sequence-to-Sequence Models},
location = {Bali Island, Indonesia},
series = {ICCAI '24}
}

@proceedings{10.1145/3695080,
title = {ICCBD '24: Proceedings of the 2024 International Conference on Cloud Computing and Big Data},
year = {2024},
isbn = {9798400710223},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Dali, China}
}

@inproceedings{10.1145/3589335.3651445,
author = {Kasela, Pranav and Braga, Marco and Pasi, Gabriella and Perego, Raffaele},
title = {SE-PQA: Personalized Community Question Answering},
year = {2024},
isbn = {9798400701726},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589335.3651445},
doi = {10.1145/3589335.3651445},
abstract = {Personalization in Information Retrieval is a topic studied for a long time. Nevertheless, there is still a lack of high-quality, real-world datasets to conduct large-scale experiments and evaluate models for personalized search. This paper contributes to filling this gap by introducing SE-PQA(StackExchange - Personalized Question Answering), a new curated resource to design and evaluate personalized models related to the task of community Question Answering (cQA). The contributed dataset includes more than 1 million queries and 2 million answers, annotated with a rich set of features modeling the social interactions among the users of a popular cQA platform. We describe the characteristics of SE-PQA and detail the features associated with questions and answers. We also provide reproducible baseline methods for the cQA task based on the resource, including deep learning models and personalization approaches. The results of the preliminary experiments conducted show the appropriateness of SE-PQA to train effective cQA models; they also show that personalization remarkably improves the effectiveness of all the methods tested. Furthermore, we show the benefits in terms of robustness and generalization of combining data from multiple communities for personalization purposes.},
booktitle = {Companion Proceedings of the ACM Web Conference 2024},
pages = {1095–1098},
numpages = {4},
keywords = {personalization, question answering, user model},
location = {Singapore, Singapore},
series = {WWW '24}
}

@proceedings{10.1145/3701571,
title = {MUM '24: Proceedings of the International Conference on Mobile and Ubiquitous Multimedia},
year = {2024},
isbn = {9798400712838},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3652037,
title = {PETRA '24: Proceedings of the 17th International Conference on PErvasive Technologies Related to Assistive Environments},
year = {2024},
isbn = {9798400717604},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Crete, Greece}
}

@inproceedings{10.1145/3652628.3652696,
author = {Li, Xianda and Azhati, Baheti},
title = {Research on the Application of an OPT Model Integrating Meta-Learning and Prompt Learning for Few-Shot Event Extraction},
year = {2024},
isbn = {9798400708831},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652628.3652696},
doi = {10.1145/3652628.3652696},
abstract = {Event extraction plays a pivotal role in natural language processing (NLP), especially in few-shot learning environments where research is increasingly growing. This paper proposes an OPT model that integrates Model-Agnostic Meta-Learning (MAML) and prompt learning to enhance the performance of few-shot event extraction. Our method was tested on the ACE2005 dataset and compared with existing models. The results demonstrate the effectiveness of our approach in improving few-shot event extraction.},
booktitle = {Proceedings of the 4th International Conference on Artificial Intelligence and Computer Engineering},
pages = {412–415},
numpages = {4},
location = {Dalian, China},
series = {ICAICE '23}
}

@article{10.1145/3659948,
author = {Hou, Wenlong and Zhao, Weidong and Liu, Xianhui and Guo, Wenyan},
title = {Knowledge-Enriched Prompt for Low-Resource Named Entity Recognition},
year = {2024},
issue_date = {May 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {5},
issn = {2375-4699},
url = {https://doi.org/10.1145/3659948},
doi = {10.1145/3659948},
abstract = {Named Entity Recognition (NER) in low-resource settings aims to identify and categorize entities in a sentence with limited labeled data. Although prompt-based methods have succeeded in low-resource perspectives, challenges persist in effectively harnessing information and optimizing computational efficiency. In this work, we present a novel prompt-based method to enhance low-resource NER without exhaustive template tuning. First, we construct knowledge-enriched prompts by integrating representative entities and background information to provide informative supervision tailored to each entity type. Then, we introduce an efficient reverse generative framework inspired by question answering (QA), which avoids redundant computations. Finally, we reduce costs by generating entities from their types while retaining model reasoning capacity. Experiment results demonstrate that our method outperforms other baselines on three datasets under few-shot settings.},
journal = {ACM Trans. Asian Low-Resour. Lang. Inf. Process.},
month = may,
articleno = {72},
numpages = {15},
keywords = {Low-resource NER, Knowledge Injection, Prompt Engineering}
}

@inproceedings{10.1145/3703187.3703233,
author = {Pan, Xinqi and Wang, Wei and Chen, Yefeng},
title = {Theme Classification of Chinese Classical Poetry Based on the GB-MSA-BGTCN Hybrid Model},
year = {2024},
isbn = {9798400707254},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3703187.3703233},
doi = {10.1145/3703187.3703233},
abstract = {The theme of Chinese classical poetry reveal its connotations and artistic conceptions, making them essential for understanding the poetry. Therefore, studying the theme classification of Chinese classical poetry is crucial. However, existing methods have struggled to effectively leverage key information and extract deep textual features. Traditional word embedding models have also failed to address polysemy, limiting their ability to convey the complex semantics of classical poetry. To overcome these challenges, we propose the GB-MSA-BGTCN model for theme classification. This model integrates GuwenBERT, a Multi-head Self-Attention (MSA) mechanism, Bidirectional Gated Recurrent Unit (BiGRU), and Temporal Convolutional Network (TCN). GuwenBERT, pre-trained on classical text corpora, is used for word embedding to effectively represent the semantic information of classical poetry. The MSA mechanism enhances classification accuracy by focusing on key textual information at multiple scales. The combined use of BiGRU and TCN captures long-term dependencies and contextual information, enabling deep feature extraction and improving performance. Due to the lack of public datasets on Chinese classical poetry themes, we constructed a new dataset for evaluation. Experimental results show that our model achieved precision, recall, and F1 scores of 84.10%, 81.65%, and 82.64%, respectively, surpassing other comparative models.},
booktitle = {Proceedings of the 2024 7th International Conference on Computer Information Science and Artificial Intelligence},
pages = {276–280},
numpages = {5},
keywords = {Bidirectional gated recurrent unit, Chinese classical poetry, GuwenBERT, Multi-head self-attention mechanism, Temporal convolutional network, Theme classification},
location = {
},
series = {CISAI '24}
}

@inproceedings{10.1145/3643657.3643910,
author = {Cabrera, Christian and Paleyes, Andrei and Lawrence, Neil David},
title = {Self-sustaining Software Systems (S4): Towards Improved Interpretability and Adaptation},
year = {2024},
isbn = {9798400705601},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643657.3643910},
doi = {10.1145/3643657.3643910},
abstract = {Software systems impact society at different levels as they pervasively solve real-world problems. Modern software systems are often so sophisticated that their complexity exceeds the limits of human comprehension. These systems must respond to changing goals, dynamic data, unexpected failures, and security threats, among other variable factors in real-world environments. Systems' complexity challenges their interpretability and requires autonomous responses to dynamic changes. Two main research areas explore autonomous systems' responses: evolutionary computing and autonomic computing. Evolutionary computing focuses on software improvement based on iterative modifications to the source code. Autonomic computing focuses on optimising systems' performance by changing their structure, behaviour, or environment variables. Approaches from both areas rely on feedback loops that accumulate knowledge from the system interactions to inform autonomous decision-making. However, this knowledge is often limited, constraining the systems' interpretability and adaptability. This paper proposes a new concept for interpretable and adaptable software systems: self-sustaining software systems (S4). S4 builds knowledge loops between all available knowledge sources that define modern software systems to improve their interpretability and adaptability. This paper introduces and discusses the S4 concept.},
booktitle = {Proceedings of the 1st International Workshop on New Trends in Software Architecture},
pages = {5–9},
numpages = {5},
keywords = {autonomous systems, software engineering, knowledge graphs, data-oriented architectures, large language models},
location = {Lisbon, Portugal},
series = {SATrends '24}
}

@proceedings{10.1145/3702250,
title = {ICVGIP '24: Proceedings of the Fifteenth Indian Conference on Computer Vision Graphics and Image Processing},
year = {2024},
isbn = {9798400710759},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@article{10.1145/3643675,
author = {Tao, Wei and Zhou, Yucheng and Wang, Yanlin and Zhang, Hongyu and Wang, Haofen and Zhang, Wenqiang},
title = {KADEL: Knowledge-Aware Denoising Learning for Commit Message Generation},
year = {2024},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {33},
number = {5},
issn = {1049-331X},
url = {https://doi.org/10.1145/3643675},
doi = {10.1145/3643675},
abstract = {Commit messages are natural language descriptions of code changes, which are important for software evolution such as code understanding and maintenance. However, previous methods are trained on the entire dataset without considering the fact that a portion of commit messages adhere to good practice (i.e., good-practice commits), while the rest do not. On the basis of our empirical study, we discover that training on good-practice commits significantly contributes to the commit message generation. Motivated by this finding, we propose a novel knowledge-aware denoising learning method called KADEL. Considering that good-practice commits constitute only a small proportion of the dataset, we align the remaining training samples with these good-practice commits. To achieve this, we propose a model that learns the commit knowledge by training on good-practice commits. This knowledge model enables supplementing more information for training samples that do not conform to good practice. However, since the supplementary information may contain noise or prediction errors, we propose a dynamic denoising training method. This method composes a distribution-aware confidence function and a dynamic distribution list, which enhances the effectiveness of the training process. Experimental results on the whole MCMD dataset demonstrate that our method overall achieves state-of-the-art performance compared with previous methods.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = jun,
articleno = {133},
numpages = {32},
keywords = {Commit message generation, knowledge introducing, denoising training}
}

@proceedings{10.1145/3643489,
title = {LSC '24: Proceedings of the 7th Annual ACM Workshop on the Lifelog Search Challenge},
year = {2024},
isbn = {9798400705502},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {The LSC workshops are participation workshops, where participants write and present an academic paper describing their prototype lifelog retrieval system, and then take part in a live interactive search competition. Consequently, the workshop is highly interactive and challenging for participants.},
location = {Phuket, Thailand}
}

@proceedings{10.1145/3632410,
title = {CODS-COMAD '24: Proceedings of the 7th Joint International Conference on Data Science &amp; Management of Data (11th ACM IKDD CODS and 29th COMAD)},
year = {2024},
isbn = {9798400716348},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Bangalore, India}
}

@inproceedings{10.1145/3675888.3676107,
author = {Kumar, Pratiksh and Gupta, Rishik and Kumar, Bagesh and Kumar, Aman},
title = {Bridging the Gap: Leveraging Textual and Visual Contexts for PreciseMedical Visual Question Answering},
year = {2024},
isbn = {9798400709722},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3675888.3676107},
doi = {10.1145/3675888.3676107},
abstract = {The advent of Visual Question Answering (VQA) technology has brought significant advancements in the medical field, offering transformative potential in clinical diagnostics and patient care. This research explores the application of VQA within the medical domain, highlighting its critical role in interpreting complex visual data, such as radiological images, pathology slides, and other diagnostic visuals. Traditional diagnostic processes often rely heavily on human expertise, which can be time-consuming and prone to variability. VQA systems, powered by sophisticated machine learning models, provide consistent and accurate interpretations, thus enhancing diagnostic accuracy and efficiency. Visual Question Answering (VQA) in the medical field necessitates extracting information from both textual and visual inputs to provide accurate answers, a critical requirement for supporting medical decision-making. This research introduces a novel approach to address VQA challenges in the medical domain using Bi-Directional Layout with Positional Encoding (BLIP) models. Our methodology seamlessly integrates text and image processing within a unified framework, enabling precise interactions between textual queries and medical imaging data. We commence with textual inputs, encoded by BLIP processors, and medical images, encoded by BLIP image processors. A custom VQA dataset, specifically designed for the medical field, includes textual questions and their corresponding medical image features. We employ a BLIP-based Question Answering architecture, fine-tuned on our medical VQA dataset, and optimized using the AdamW optimizer with a learning rate of 0.00005, ensuring efficient convergence. Additionally, we introduce attention mechanisms using Coarse and Fine Attention blocks for enhanced feature fusion and accurate answer prediction. Our results are highly encouraging, demonstrating competitive metrics in extensive VQA task experiments on both training and validation datasets. Qualitative analysis of sample predictions indicates the model’s capability to provide accurate answers for diverse visual and textual medical inputs. This work holds significant promise for improving automated medical image analysis and supporting clinical decision-making.},
booktitle = {Proceedings of the 2024 Sixteenth International Conference on Contemporary Computing},
pages = {519–526},
numpages = {8},
keywords = {Attention Model, BLIP, Medical Visual Question Answering, PathVQA},
location = {Noida, India},
series = {IC3-2024}
}

@article{10.1145/3705322,
author = {Zhang, Jianrong and Fan, Hehe and Yang, Yi},
title = {Protein Captioning: Bridging the Gap between Protein Sequences and Natural Languages},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1551-6857},
url = {https://doi.org/10.1145/3705322},
doi = {10.1145/3705322},
abstract = {We introduce the multimodal task of Protein Captioning, which is an easy-to-understand and flexible way for protein analysis. Compared to specific protein recognition or classification tasks, such as enzyme reaction classification and gene ontology term prediction, protein captioning provides comprehensive textural descriptions for proteins, thus playing a key role in bridging the gap between protein sequences and natural languages. To address the problem, we propose a simple yet effective method, Protein-to-Text Generative Pre-trained Transformer (P2T-GPT), to fuse multimodal embeddings and translate the chain of amino acid residues in a protein to a sequence of natural language words, i.e., text. For the evaluation of protein captioning, we collect the ProteinCap dataset that contains 94,454 protein-text pairs. Experiments on ProteinCap demonstrate the effectiveness of the proposed P2T-GPT on protein captioning. For example, our method obtains improvements of 8.74, 10.03, and 11.05 in the BERTScore compared to the baseline model on ProteinCap- (alpha,beta,gamma) , respectively. As minor contributions, first, P2T-GPT provides a way to connect protein science and Large Language Models (LLMs). By appending ChatGPT, our method can interact in a conversational way to answer questions given a protein. Second, we show that protein captioning can be treated as a pre-trained task that can benefit a range of downstream tasks, to a certain extent.},
note = {Just Accepted},
journal = {ACM Trans. Multimedia Comput. Commun. Appl.},
month = nov,
keywords = {Protein captioning, Natural language processing, Multimodal learning}
}

@inproceedings{10.1145/3640771.3640779,
author = {Liu, Zhou Yu and Yan, Xin and Luo, Long You},
title = {CLPLM-EE: Contrastive Learning Pre-training Model for Event Extraction In New Domain},
year = {2024},
isbn = {9798400708954},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3640771.3640779},
doi = {10.1145/3640771.3640779},
abstract = {The event extraction task recognizes events in natural language text and extracts the event triggers and arguments. The majority of existing methods that based on closed domains have poor generalization and are difficult to extend to new domains. As a result, event extraction models for new domains requires general event knowledge learned from large amounts of unsupervised data. Fortunately, existing studies have shown that a contrastive pre-training model for information extraction can better obtain prior knowledge from large unannotated data. However, such methods have insufficient perception of event structure, have not learnt enough about event representations, and thier contrastive learning methods used to construct negative samples lead to semantic conflicts. To adress the above problem, we propose CLPLM-EE, a contrastive pre-training MODEL for event extraction in new domians. CLPLM-EE contains has an encoder with event semantics and event structure awareness to learn the most common knowledge of the event. In addition, CLPLM-EE learns high-quality event representations by eliminating false negative samples and using a weighting mechanism to avoid the semantic conflicts generated in Contrastive learning pre-training.},
booktitle = {Proceedings of the 2023 2nd International Symposium on Computing and Artificial Intelligence},
pages = {28–34},
numpages = {7},
keywords = {Contrastive learning, Event extraction, Pre-trained model},
location = {Shanghai, China},
series = {ISCAI '23}
}

@inproceedings{10.1145/3632971.3632983,
author = {Zheng, Dequan and Zhang, Haoyu and Yu, Feng},
title = {Named entity recognition of Chinese electronic medical rec-ords based on adversarial training and feature fusion},
year = {2024},
isbn = {9798400707704},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3632971.3632983},
doi = {10.1145/3632971.3632983},
abstract = {Abstract. In the discipline of natural language processing, named entity recognition is the foundation for tasks such as information extraction, information retrieval, and knowledge graphs. This paper puts forward an entity recognition model based on adversarial training and feature fusion to address the issues of polysemy and not complete word recognition in Chinese electronic medical record named entity recognition. The above technique results in adversarial samples by infusing disturbance factors into the word embedding layer. These adversarial samples obtained are subsequently used for iterative training in order to optimize the model's parameters. Then, utilize the improved Transform encoder and Bi-GRU to extract global the field of semantics and direction information, add an attention mechanism to merge the extracted context features, and finally implement the entity labelling sequence using CRF. In addition, we use the RoBERTa-WWM pre-training model as the embedding layer of the model in order to offer character-level embedding, picking up more contextual semantic data as well as lexical information, as well as enhance entity recognition performance. Experimental results on the CCKS2017 and CCKS2019 evaluation datasets indicate that the proposed model outperforms the baseline model by 0.9% and 0.74 %, for example, in terms of F1. And comparative experiments demonstrate that the addition of adversarial training and feature fusion will improve the model's predictive ability and robustness.},
booktitle = {Proceedings of the 2023 International Joint Conference on Robotics and Artificial Intelligence},
pages = {175–179},
numpages = {5},
keywords = {Adversarial training, Attention mechanism, Electronic medical records, Named entity recognition, RoBERTa-WWM},
location = {Shanghai, China},
series = {JCRAI '23}
}

@proceedings{10.1145/3629527,
title = {ICPE '24 Companion: Companion of the 15th ACM/SPEC International Conference on Performance Engineering},
year = {2024},
isbn = {9798400704451},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our great pleasure to present the ICPE 2024 workshops program. ICPE workshops extend the main conference by providing a forum to foster discussion on hot and emerging topics from the broad field of performance engineering. They offer a highly dynamic venue to exchange ideas, establish new collaborations, and bootstrap debates on novel techniques, methodologies, and their associated early research results. Workshops feature various presentation formats, including research paper presentations, panel discussions, and keynote talks. Through these presentations and discussions with peer researchers, ICPE workshops help shape future research and identify promising research directions for performance engineering.},
location = {London, United Kingdom}
}

@inproceedings{10.1145/3678717.3691277,
author = {Paul, Arpan and Maheshwary, Saket and Sohoney, Saurabh},
title = {Accurate Customer Address Matching via Weak Supervision for Geocode Learning},
year = {2024},
isbn = {9798400711077},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3678717.3691277},
doi = {10.1145/3678717.3691277},
abstract = {Determining the precise location of customers is important for an efficient and reliable delivery experience, both for customers and delivery associates. Address text is a primary source of information provided by customers about their location. In this paper, we study the important and challenging task of matching free-form customer address text to determine if two addresses represent the same physical building. We introduce a novel address matching framework that leverages transformer-based encoder to prevent tedious and time-consuming efforts spent on manual feature engineering by the baseline model. Furthermore, our proposed framework employs weak supervision to leverage historic delivery information and generate high-quality labeled data. This reduces the requirement for massive amounts of labeled data, typically needed for transformer-based models. Our experiments on manually curated datasets demonstrate the effective and generic nature of our approach, as we achieve 15.57% improvement in recall at 95% precision, on average, compared to the current baseline model across four geographies. We also introduce delivery point (DP) geocode learning for cold-start addresses as a downstream application of customer address matching. In addition to offline experiments, we performed online A/B experiments for DP geocode learning with our proposed approach and observed delivery precision improved by 8.09% and delivery defects reduced by 11.78% on average across four geographies in comparison to the baseline model.},
booktitle = {Proceedings of the 32nd ACM International Conference on Advances in Geographic Information Systems},
pages = {454–464},
numpages = {11},
keywords = {Entity Matching, Geocoding, Language Models, Weak Supervision},
location = {Atlanta, GA, USA},
series = {SIGSPATIAL '24}
}

@inproceedings{10.1145/3639479.3639525,
author = {Jin, Fan and Chang, Qingling and Xu, Zhongwen},
title = {MuseumQA: A Fine-Grained Question Answering Dataset for Museums and Artifacts},
year = {2024},
isbn = {9798400709241},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639479.3639525},
doi = {10.1145/3639479.3639525},
abstract = {In this paper, we present a fine-grained museum artifact question-answering (QA) dataset, which serves as the cornerstone for developing museum question-answering systems. Creating these systems is essential for the advancement of museums and can enhance the visitor experience. Nevertheless, research reveals the current absence of domestically available datasets for museum artifacts in China. To ensure data authenticity and validity, we meticulously collected and screened 3,416 raw data entries from the official websites of provincial museums across China. Using these raw data, we annotated annotatable QA pair information to create the final QA dataset. Initially, a small batch of QA pairs was generated with the assistance of ChatGPT. Subsequently, the remaining QA pairs were annotated using an enhanced QA generation model, yielding 23,149 QA pairs. To mitigate overfitting due to dataset-model size disparities, a noise factor was incorporated into the enhanced generation model. Additionally, a Chinese grammar correction module was integrated to enhance the accuracy of the generated statements. Ultimately, the model achieved optimal performance, and the dataset demonstrated the highest semantic relevance.},
booktitle = {Proceedings of the 2023 6th International Conference on Machine Learning and Natural Language Processing},
pages = {221–226},
numpages = {6},
keywords = {museum artifact dataset, question-answering pair generation},
location = {Sanya, China},
series = {MLNLP '23}
}

@proceedings{10.1145/3639479,
title = {MLNLP '23: Proceedings of the 2023 6th International Conference on Machine Learning and Natural Language Processing},
year = {2023},
isbn = {9798400709241},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Sanya, China}
}

@inproceedings{10.1145/3634814.3634837,
author = {Bai, Minhao and Huang, Yongfeng and Yang, Jinshuai and Pang, Kaiyi and Li, Songbin},
title = {Exploration of the Effectiveness and Characteristics of ChatGPT in Steganalysis Tasks},
year = {2024},
isbn = {9798400708534},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3634814.3634837},
doi = {10.1145/3634814.3634837},
abstract = {Text steganography is a method of covert communication that aims to conceal the existence of secret information. Steganography has a long history of development and is widely used. However, its misuse poses a serious threat to information security, such as hiding malicious code to bypass security checks or hiding criminal evidence in network environments. In response to the potential threat of steganographic text, steganalysis techniques have received urgent demand from practical applications and extensive attention from researchers. Currently, steganalysis models for text are mainly based on statistical features of steganographic text to identify such text, and these models require a large amount of training data consisting of steganographic and normal text to achieve good classification performance. The emergence of the large-scale conversational model ChatGPT in November last year has attracted widespread attention. Considering the powerful understanding ability of ChatGPT for text, we expect that ChatGPT can achieve good performance in the task of steganalysis or obtain inspiration about steganographic text features from its results. To evaluate the effectiveness of ChatGPT, we conduct experiments on 2 datasets and 3 encoding methods. The experiments show that compared with normal steganalisis method, ChatGPT can achieve similar results with only 32 samples, even without any training or fine-tuning.},
booktitle = {Proceedings of the 2023 4th Asia Service Sciences and Software Engineering Conference},
pages = {163–170},
numpages = {8},
location = {Aizu-Wakamatsu City, Japan},
series = {ASSE '23}
}

@inproceedings{10.1145/3654777.3676390,
author = {Fan, Haoxiang and Chen, Guanzheng and Wang, Xingbo and Peng, Zhenhui},
title = {LessonPlanner: Assisting Novice Teachers to Prepare Pedagogy-Driven Lesson Plans with Large Language Models},
year = {2024},
isbn = {9798400706288},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3654777.3676390},
doi = {10.1145/3654777.3676390},
abstract = {Preparing a lesson plan, e.g., a detailed road map with strategies and materials for instructing a 90-minute class, is beneficial yet challenging for novice teachers. Large language models (LLMs) can ease this process by generating adaptive content for lesson plans, which would otherwise require teachers to create from scratch or search existing resources. In this work, we first conduct a formative study with six novice teachers to understand their needs for support of preparing lesson plans with LLMs. Then, we develop LessonPlanner that assists users to interactively construct lesson plans with adaptive LLM-generated content based on Gagne’s nine events. Our within-subjects study (N = 12) shows that compared to the baseline ChatGPT interface, LessonPlanner can significantly improve the quality of outcome lesson plans and ease users’ workload in the preparation process. Our expert interviews (N = 6) further demonstrate LessonPlanner ’s usefulness in suggesting effective teaching strategies and meaningful educational resources. We discuss concerns on and design considerations for supporting teaching activities with LLMs.},
booktitle = {Proceedings of the 37th Annual ACM Symposium on User Interface Software and Technology},
articleno = {146},
numpages = {20},
keywords = {Large language models, lesson plan preparation, pedagogy-driven system},
location = {Pittsburgh, PA, USA},
series = {UIST '24}
}

@article{10.1145/3578519,
author = {Frieder, Ophir and Mele, Ida and Muntean, Cristina Ioana and Nardini, Franco Maria and Perego, Raffaele and Tonellotto, Nicola},
title = {Caching Historical Embeddings in Conversational Search},
year = {2024},
issue_date = {November 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {4},
issn = {1559-1131},
url = {https://doi.org/10.1145/3578519},
doi = {10.1145/3578519},
abstract = {Rapid response, namely, low latency, is fundamental in search applications; it is particularly so in interactive search sessions, such as those encountered in conversational settings. An observation with a potential to reduce latency asserts that conversational queries exhibit a temporal locality in the lists of documents retrieved. Motivated by this observation, we propose and evaluate a client-side document embedding cache, improving the responsiveness of conversational search systems. By leveraging state-of-the-art dense retrieval models to abstract document and query semantics, we cache the embeddings of documents retrieved for a topic introduced in the conversation, as they are likely relevant to successive queries. Our document embedding cache implements an efficient metric index, answering nearest-neighbor similarity queries by estimating the approximate result sets returned. We demonstrate the efficiency achieved using our cache via reproducible experiments based on Text Retrieval Conference Conversational Assistant Track datasets, achieving a hit rate of up to 75% without degrading answer quality. Our achieved high cache hit rates significantly improve the responsiveness of conversational systems while likewise reducing the number of queries managed on the search back-end.},
journal = {ACM Trans. Web},
month = oct,
articleno = {42},
numpages = {19},
keywords = {Conversational search, similarity search, caching, dense retrieval}
}

@article{10.1145/3699759,
author = {Arakawa, Riku and Lehman, Jill Fain and Goel, Mayank},
title = {PrISM-Q&amp;A: Step-Aware Voice Assistant on a Smartwatch Enabled by Multimodal Procedure Tracking and Large Language Models},
year = {2024},
issue_date = {December 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {4},
url = {https://doi.org/10.1145/3699759},
doi = {10.1145/3699759},
abstract = {Voice assistants capable of answering user queries during various physical tasks have shown promise in guiding users through complex procedures. However, users often find it challenging to articulate their queries precisely, especially when unfamiliar with the specific terminologies required for machine-oriented tasks. We introduce PrISM-Q&amp;A, a novel question-answering (Q&amp;A) interaction termed step-aware Q&amp;A, which enhances the functionality of voice assistants on smartwatches by incorporating Human Activity Recognition (HAR) and providing the system with user context. It continuously monitors user behavior during procedural tasks via audio and motion sensors on the watch and estimates which step the user is performing. When a question is posed, this contextual information is supplied to Large Language Models (LLMs) as part of the context used to generate a response, even in the case of inherently vague questions like "What should I do next with this?" Our studies confirmed that users preferred the convenience of our approach compared to existing voice assistants. Our real-time assistant represents the first Q&amp;A system that provides contextually situated support during tasks without camera use, paving the way for the ubiquitous, intelligent assistant.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = nov,
articleno = {180},
numpages = {26},
keywords = {context-aware, large language models, procedure tracking, question answering, task assistance}
}

@inproceedings{10.1145/3626772.3657693,
author = {Tang, Yanran and Qiu, Ruihong and Yin, Hongzhi and Li, Xue and Huang, Zi},
title = {CaseLink: Inductive Graph Learning for Legal Case Retrieval},
year = {2024},
isbn = {9798400704314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626772.3657693},
doi = {10.1145/3626772.3657693},
abstract = {In case law, the precedents are the relevant cases that are used to support the decisions made by the judges and the opinions of lawyers towards a given case. This relevance is referred to as the case-to-case reference relation. To efficiently find relevant cases from a large case pool, retrieval tools are widely used by legal practitioners. Existing legal case retrieval models mainly work by comparing the text representations of individual cases. Although they obtain a decent retrieval accuracy, the intrinsic case connectivity relationships among cases have not been well exploited for case encoding, therefore limiting the further improvement of retrieval performance. In a case pool, there are three types of case connectivity relationships: the case reference relationship, the case semantic relationship, and the case legal charge relationship. Due to the inductive manner in the task of legal case retrieval, using case reference as input is not applicable for testing. Thus, in this paper, a CaseLink model based on inductive graph learning is proposed to utilise the intrinsic case connectivity for legal case retrieval, a novel Global Case Graph is incorporated to represent both the case semantic relationship and the case legal charge relationship. A novel contrastive objective with a regularisation on the degree of case nodes is proposed to leverage the information carried by the case reference relationship to optimise the model. Extensive experiments have been conducted on two benchmark datasets, which demonstrate the state-of-the-art performance of CaseLink. The code has been released on https://github.com/yanran-tang/CaseLink.},
booktitle = {Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {2199–2209},
numpages = {11},
keywords = {graph neural networks, information retrieval, legal case retrieval},
location = {Washington DC, USA},
series = {SIGIR '24}
}

@inproceedings{10.1145/3631700.3665188,
author = {Hendrawan, Rully Agus and Brusilovsky, Peter and Lekshmi Narayanan, Arun Balajiee and Barria-Pineda, Jordan},
title = {Explanations in Open User Models for Personalized Information Exploration},
year = {2024},
isbn = {9798400704666},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3631700.3665188},
doi = {10.1145/3631700.3665188},
abstract = {Open user models provide affordance for a transparent user control over recommendations based on shared symbolic representation within the system. Users must build their user profile by adding these symbols and tuning their importance to get meaningful recommendations. Since the link between these symbols and the reference explanation is often unavailable, it can be difficult for users to understand them. These symbols are often referred to as concepts, tags, areas, topics, labels, features, or keyphrases. This study showcases an information exploration system that helps students identify potential faculty members to collaborate with. The system works by matching user and faculty profiles that contain keywords or phrases representing topics/areas of interest. Students must develop their understanding of research topics while building their profiles, which can become challenging as they add more keywords. To support students in controlling the recommendation, we introduce post hoc explanations with three levels of detail: no explanations, individual explanation for topics, and explanation of the relationships between topics. This study explores how explanation is associated with the user context / tasks and the exploration process. Our observation suggests that expertise in the field is linked to exploring fewer novel topics and seeking fewer explanations but engaging more with explanations of relationships. In addition, we found that the engagement with faculty information is moderately correlated with the use of more advanced explanations.},
booktitle = {Adjunct Proceedings of the 32nd ACM Conference on User Modeling, Adaptation and Personalization},
pages = {256–263},
numpages = {8},
keywords = {Adaptive explanation, Concept graph, Information exploration, Intelligent interface, Open user model},
location = {Cagliari, Italy},
series = {UMAP Adjunct '24}
}

@article{10.1145/3649506,
author = {Yang, Jingfeng and Jin, Hongye and Tang, Ruixiang and Han, Xiaotian and Feng, Qizhang and Jiang, Haoming and Zhong, Shaochen and Yin, Bing and Hu, Xia},
title = {Harnessing the Power of LLMs in Practice: A Survey on ChatGPT and Beyond},
year = {2024},
issue_date = {July 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {6},
issn = {1556-4681},
url = {https://doi.org/10.1145/3649506},
doi = {10.1145/3649506},
abstract = {This article presents a comprehensive and practical guide for practitioners and end-users working with Large Language Models (LLMs) in their downstream Natural Language Processing (NLP) tasks. We provide discussions and insights into the usage of LLMs from the perspectives of models, data, and downstream tasks. First, we offer an introduction and brief summary of current language models. Then, we discuss the influence of pre-training data, training data, and test data. Most importantly, we provide a detailed discussion about the use and non-use cases of large language models for various natural language processing tasks, such as knowledge-intensive tasks, traditional natural language understanding tasks, generation tasks, emergent abilities, and considerations for specific tasks. We present various use cases and non-use cases to illustrate the practical applications and limitations of LLMs in real-world scenarios. We also try to understand the importance of data and the specific challenges associated with each NLP task. Furthermore, we explore the impact of spurious biases on LLMs and delve into other essential considerations, such as efficiency, cost, and latency, to ensure a comprehensive understanding of deploying LLMs in practice. This comprehensive guide aims to provide researchers and practitioners with valuable insights and best practices for working with LLMs, thereby enabling the successful implementation of these models in a wide range of NLP tasks. A curated list of practical guide resources of LLMs, regularly updated, can be found at . An LLMs evolutionary tree, editable yet regularly updated, can be found at  .},
journal = {ACM Trans. Knowl. Discov. Data},
month = apr,
articleno = {160},
numpages = {32},
keywords = {Large language models, neural language processing, practical guide, ChatGPT}
}

@proceedings{10.1145/3656650,
title = {AVI '24: Proceedings of the 2024 International Conference on Advanced Visual Interfaces},
year = {2024},
isbn = {9798400717642},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {AVI 2024 is the 17th edition of the International Conference on Advanced Visual Interfaces, held in Arenzano, Genoa (IT), in cooperation with ACM, ACM SIGCHI, ACM SIGMM, and ACM SIGWEB.Every two years since 1992, AVI has gathered a vast international community of experts with a wide range of backgrounds. Throughout three decades, AVI has gained and holds a prestigious position among International HCI conferences, boasting a dedicated nucleus of returning participants, but also providing a venue for young researchers to show their achievements and establish contacts with senior community members.AVI 2024 presents a broad and sound scientific program covering traditional AVI topics on information and data visualization, interaction with multimodal user interfaces, augmented and virtual reality, while also addressing emerging topics including the application of generative artificial intelligence in HCI design and evaluation.The program features the presentation of 21 long research papers and 28 short papers selected through a rigorous double-blind reviewing process and organized into sessions on 13 main topics. Furthermore, it includes the presentation of 48 poster papers, 9 demo papers, and 11 doctoral consortium papers, selected through a single-blind reviewing process. Finally, the rich and vibrant program includes 3 keynote talks, 3 tutorials, and 10 workshops addressing some of the most exciting issues in HCI.Submissions to AVI 2024 came from 34 different countries distributed in descending order in Europe, Asia, North America, South America, and Africa.},
location = {Arenzano, Genoa, Italy}
}

@inproceedings{10.1145/3616855.3635724,
author = {Dave, Vachik S. and Pang, Linsey and Cui, Xiquan and Luo, Chen and Zamani, Hamed and Wu, Lingfei and Karypis, George},
title = {The 3rd International Workshop on Interactive and Scalable Information Retrieval Methods for eCommerce (ISIR-eCom 2024)},
year = {2024},
isbn = {9798400703713},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3616855.3635724},
doi = {10.1145/3616855.3635724},
abstract = {Over the past few years, consumer behavior has shifted from traditional in-store shopping to online shopping. For example, eCommerce sales have grown from around 5% of total US sales in 2012 to around 15.4% in year 2023. This rapid growth of eCommerce has created new challenges and vital new requirements for intelligent information retrieval systems. Which lead to the primary motivations of this workshop:(1) Since the pandemic hit, eCommerce became an important part of people's routine and they started using online shop- ping for smallest grocery items to big electronics as well as cars. With such a large assortment of products and millions of users, achieving higher scalability without losing accuracy is a leading concern for information retrieval systems for eCommerce.(2) The diverse buyers make the relevance of the results highly subjective, because relevance varies for different buyers. The most suitable and intuitive solution to this problem is to make the system interactive and provide correct relevance for different users. Hence, interactive information retrieval systems are becoming necessity in eCommerce.(3) To handle sudden change in buyers' behavior, industries adopted existing sub-optimal information retrieval techniques for various eCommerce tasks. Parallelly, they also started exploring/researching for better solutions and in dire need of help from research community.This workshop will provide a forum to discuss and learn the latest trends for interactive and scalable information retrieval approaches for eCommerce. It will provide academic and industrial researchers a platform to present their latest works, share research ideas, present and discuss various challenges, and identify the areas where further research is needed. It will foster the development of a strong research community focused on solving eCommerce-related information retrieval problems that provide superior eCommerce experience to all users.},
booktitle = {Proceedings of the 17th ACM International Conference on Web Search and Data Mining},
pages = {1208–1209},
numpages = {2},
keywords = {ecommerce search, information retrieval, interactive systems, large language models (llms) in ecommerce, natural language processing (nlp) for ecommerce, ranking models, recommender systems},
location = {Merida, Mexico},
series = {WSDM '24}
}

@article{10.1145/3665244,
author = {Zhang, Jinyi and Su, Ke and Li, Haowei and Mao, Jiannan and Tian, Ye and Wen, Feng and Guo, Chong and Matsumoto, Tadahiro},
title = {Neural Machine Translation for Low-Resource Languages from a Chinese-centric Perspective: A Survey},
year = {2024},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {6},
issn = {2375-4699},
url = {https://doi.org/10.1145/3665244},
doi = {10.1145/3665244},
abstract = {Machine translation–the automatic transformation of one natural language (source language) into another (target language) through computational means–occupies a central role in computational linguistics and stands as a cornerstone of research within the field of Natural Language Processing (NLP). In recent years, the prominence of Neural Machine Translation (NMT) has grown exponentially, offering an advanced framework for machine translation research. It is noted for its superior translation performance, especially when tackling the challenges posed by low-resource language pairs that suffer from a limited corpus of data resources. This article offers an exhaustive exploration of the historical trajectory and advancements in NMT, accompanied by an analysis of the underlying foundational concepts. It subsequently provides a concise demarcation of the unique characteristics associated with low-resource languages and presents a succinct review of pertinent translation models and their applications, specifically within the context of languages with low-resources. Moreover, this article delves deeply into machine translation techniques, highlighting approaches tailored for Chinese-centric low-resource languages. Ultimately, it anticipates upcoming research directions in the realm of low-resource language translation.},
journal = {ACM Trans. Asian Low-Resour. Lang. Inf. Process.},
month = jun,
articleno = {80},
numpages = {60},
keywords = {Low-resource languages, neural machine translation, unsupervised learning, transfer learning, multilingual translation, large language models, Chinese-centric languages}
}

@inproceedings{10.1145/3651671.3651709,
author = {Shi, Yuning and Kimura, Masaomi},
title = {BERT-Based Models with Attention Mechanism and Lambda Layer for Biomedical Named Entity Recognition},
year = {2024},
isbn = {9798400709234},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3651671.3651709},
doi = {10.1145/3651671.3651709},
abstract = {Biomedical named entity recognition (NER) is a crucial subtask in the field of information extraction within natural language processing (NLP). Its primary objective is to identify and classify entities in biomedical text, playing a pivotal role in applications such as medical information retrieval and biomedical knowledge discovery. In this paper, we propose several enhanced versions of BERT-BiLSTM-CRF and BERT-IDCNN-CRF by incorporating an attention mechanism or lambda layer to improve entity recognition accuracy. Specifically, we utilize the attention mechanism to enable the model to learn interrelationships among all words in the input sequence. Additionally, we employ the lambda layer to enhance the model's capacity for capturing semantic relationships between words and considering word order. This integration results in superior accuracy in entity recognition. We evaluate our proposed methods using the i2b2 2010 dataset and six additional biomedical datasets from the Biomedical Language Understanding and Reasoning Benchmark (BLURB), including JNLPBA, BC2GM, BC5CDR, AnatEM, BioNLP-CG, and NCBI-disease. Experimental results demonstrate that our proposed methods achieve higher accuracy than the original methods, indicating superior capabilities in medical knowledge extraction for our models.},
booktitle = {Proceedings of the 2024 16th International Conference on Machine Learning and Computing},
pages = {536–544},
numpages = {9},
keywords = {Attention Mechanism, BERT-BiLSTM-CRF, BERT-IDCNN-CRF, Deep Learning, Lambda Layer, Named Entity Recognition},
location = {Shenzhen, China},
series = {ICMLC '24}
}

@article{10.1145/3655618,
author = {Zhang, Xinghua and Yu, Bowen and Cong, Xin and Su, Taoyu and Li, Quangang and Liu, Tingwen and Xu, Hongbo},
title = {Cross-Domain NER under a Divide-and-Transfer Paradigm},
year = {2024},
issue_date = {September 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {42},
number = {5},
issn = {1046-8188},
url = {https://doi.org/10.1145/3655618},
doi = {10.1145/3655618},
abstract = {Cross-domain Named Entity Recognition (NER) transfers knowledge learned from a rich-resource source domain to improve the learning in a low-resource target domain. Most existing works are designed based on the sequence labeling framework, defining entity detection and type prediction as a monolithic process. However, they typically ignore the discrepant transferability of these two sub-tasks: the former locating spans corresponding to entities is largely domain-robust, whereas the latter owns distinct entity types across domains. Combining them into an entangled learning problem may contribute to the complexity of domain transfer. In this work, we propose the novel divide-and-transfer paradigm in which different sub-tasks are learned using separate functional modules for respective cross-domain transfer. To demonstrate the effectiveness of divide-and-transfer, we concretely implement two NER frameworks by applying this paradigm with different cross-domain transfer strategies. Experimental results on 10 different domain pairs show the notable superiority of our proposed frameworks. Experimental analyses indicate that significant advantages of the divide-and-transfer paradigm over prior monolithic ones originate from its better performance on low-resource data and a much greater transferability. It gives us a new insight into cross-domain NER. Our code is available on GitHub.1},
journal = {ACM Trans. Inf. Syst.},
month = may,
articleno = {137},
numpages = {32},
keywords = {Named entity recognition, cross-domain transfer, information extraction, knowledge acquisition, task decomposition}
}

@proceedings{10.1145/3685650,
title = {DocEng '24: Proceedings of the ACM Symposium on Document Engineering 2024},
year = {2024},
isbn = {9798400711695},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {San Jose, CA, USA}
}

@inproceedings{10.1145/3664647.3681012,
author = {Zhao, Deji and Han, Donghong and Yuan, Ye and Ning, Bo and Li, Mengxiang and He, Zhongjiang and Song, Shuangyong},
title = {AutoGraph: Enabling Visual Context via Graph Alignment in Open Domain Multi-Modal Dialogue Generation},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3681012},
doi = {10.1145/3664647.3681012},
abstract = {Open-domain multi-modal dialogue system heavily relies on visual information to generate contextually relevant responses. The existing open-domain multi-modal dialog generation methods ignore the complementary relationship between multiple modalities, and are difficult to integrate with LLMs. To tackle these challenges, we introduce AutoGraph, an innovative method for constructing visual context graphs automatically. We aim to structure complex information and seamlessly integrate it with large language models (LLMs), aligning information from multiple modalities at both semantic and structural levels. Specifically, we fully connect the text graphs and scene graphs, and then trim unnecessary edges via LLMs to automatically construct a visual context graph. Next, we design several graph sampling grammar for the first time to convert graph structures into sequence which is suitable for LLMs. Finally, we propose a two-stage fine-tuning strategy to allow LLMs to understand graph sampling grammar and generate responses. We validate our proposed method on text-based LLMs, and visual-based LLMs, respectively. Experimental results show that our proposed method achieves state-of-the-art performance on multiple public datasets.},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {2079–2088},
numpages = {10},
keywords = {dialogue generation, dialogue graph, multi-modal alignment},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@article{10.1145/3615668,
author = {Hemberg, Erik and Turner, Matthew J. and Rutar, Nick and O’reilly, Una-May},
title = {Enhancements to Threat, Vulnerability, and Mitigation Knowledge for Cyber Analytics, Hunting, and Simulations},
year = {2024},
issue_date = {March 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {1},
url = {https://doi.org/10.1145/3615668},
doi = {10.1145/3615668},
abstract = {Cross-linked threat, vulnerability, and defensive mitigation knowledge is critical in defending against diverse and dynamic cyber threats. Cyber analysts consult it by deductively or inductively creating a chain of reasoning to identify a threat starting from indicators they observe or vice versa. Cyber hunters use it abductively to reason when hypothesizing specific threats. Threat modelers use it to explore threat postures. We aggregate five public sources of threat knowledge and three public sources of knowledge that describe cyber defensive mitigations, analytics, and engagements and which share some unidirectional links between them. We unify the sources into a graph, and in the graph, we make all unidirectional cross-source links bidirectional. This enhancement of the knowledge makes the questions that analysts and automated systems formulate easier to answer. We demonstrate this in the context of various cyber analytic and hunting tasks as well as modeling and simulations. Because the number of linked entries is very sparse, to further increase the analytic utility of the data, we use natural language processing and supervised machine learning to identify new links. These two contributions demonstrably increase the value of the knowledge sources for cyber security activities.},
journal = {Digital Threats},
month = mar,
articleno = {8},
numpages = {33},
keywords = {Cyber security, threat hunting, machine learning, natural language processing, information retrieval, reinforcement learning, coevolutionary algorithm}
}

@inproceedings{10.1145/3627673.3679746,
author = {Wang, Yu and Lipka, Nedim and Zhang, Ruiyi and Siu, Alexa and Zhao, Yuying and Ni, Bo and Wang, Xin and Rossi, Ryan and Derr, Tyler},
title = {Topology-aware Retrieval Augmentation for Text Generation},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679746},
doi = {10.1145/3627673.3679746},
abstract = {Retrieval-augmented Generation has been used to augment Language Models by retrieving texts from external databases. Since real-world texts are often connected in the graph (e.g., papers in citation networks), we use these relations to guide the retrieval process of RAG. Concretely, we investigate proximity and role-based relations, where the former considers topologically close nodes and the latter considers structurally similar nodes. We empirically verify their correlation to text relations, which motivates us to propose the framework of Topology-aware Retrieval-augmented Generation for text generation, which consists of a retrieval module to retrieve texts by their topological relations and an aggregation module to compose retrieved texts into prompts triggering LLMs for text generation. Extensive experiments verify the effectiveness of this framework, signifying the potential of equipping RAG with topological awareness.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {2442–2452},
numpages = {11},
keywords = {graph structural relations, retrieval-augmented generation},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@article{10.1145/3661996,
author = {Chen, Xiaocong and Wang, Siyu and McAuley, Julian and Jannach, Dietmar and Yao, Lina},
title = {On the Opportunities and Challenges of Offline Reinforcement Learning for Recommender Systems},
year = {2024},
issue_date = {November 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {42},
number = {6},
issn = {1046-8188},
url = {https://doi.org/10.1145/3661996},
doi = {10.1145/3661996},
abstract = {Reinforcement learning serves as a potent tool for modeling dynamic user interests within recommender systems, garnering increasing research attention of late. However, a significant drawback persists: its poor data efficiency, stemming from its interactive nature. The training of reinforcement learning-based recommender systems demands expensive online interactions to amass adequate trajectories, essential for agents to learn user preferences. This inefficiency renders reinforcement learning-based recommender systems a formidable undertaking, necessitating the exploration of potential solutions. Recent strides in offline reinforcement learning present a new perspective. Offline reinforcement learning empowers agents to glean insights from offline datasets and deploy learned policies in online settings. Given that recommender systems possess extensive offline datasets, the framework of offline reinforcement learning aligns seamlessly. Despite being a burgeoning field, works centered on recommender systems utilizing offline reinforcement learning remain limited. This survey aims to introduce and delve into offline reinforcement learning within recommender systems, offering an inclusive review of existing literature in this domain. Furthermore, we strive to underscore prevalent challenges, opportunities, and future pathways, poised to propel research in this evolving field.},
journal = {ACM Trans. Inf. Syst.},
month = aug,
articleno = {150},
numpages = {26},
keywords = {Offline reinforcement learning}
}

@proceedings{10.1145/3665939,
title = {HILDA  24: Proceedings of the 2024 Workshop on Human-In-the-Loop Data Analytics},
year = {2024},
isbn = {9798400706936},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Santiago, AA, Chile}
}

@inproceedings{10.1145/3652628.3652794,
author = {Zhu, Yanbing and Xu, Sitian and Liu, Boyang and Jia, Yuntao},
title = {Optimization of Smart Healthcare Services and Development Strategies Based on Large Language Models},
year = {2024},
isbn = {9798400708831},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652628.3652794},
doi = {10.1145/3652628.3652794},
abstract = {We aims to optimize online smart healthcare service projects and provide a reference for the development strategy of healthcare large language models. In terms of optimizing service projects, the paper utilizes the U&amp;A model to statistically analyze 27 commonly used digital products in the smart healthcare market. Employing the Kano model and empirical investigation, the service projects are categorized into basic, premium, and personalized types. Among these, basic service projects exhibit the highest positive impact on user satisfaction. Subsequently, building upon these research findings, the paper centers on basic service projects to explore the development strategy of large language models in smart healthcare. Concerning development strategy, the paper collects a total of 15,073 data points and establishes 13 testing dimensions. Tests are conducted on platforms such as chatGPT, chatDoctor, and the open-source chatGLM from Tsinghua iFLYTEK AI Research. Evaluation results indicate that general-purpose large models perform well in overall scores, but their performance in the healthcare domain is lower than that of fine-tuned medical large models. Therefore, the paper suggests that smart healthcare large models should start with the widely recognized "basic smart healthcare service projects." Leveraging the advantages of general-purpose large models, incorporating domain expertise for fine-tuned training is proposed to enhance model accuracy and meet the usage demands of medical scenarios.},
booktitle = {Proceedings of the 4th International Conference on Artificial Intelligence and Computer Engineering},
pages = {1004–1011},
numpages = {8},
location = {Dalian, China},
series = {ICAICE '23}
}

@inproceedings{10.1145/3660043.3660071,
author = {Jin, Guanghao and Zhao, Junhua and Wang, Yuqing and Wang, Jieying and Du, Hui and Song, Qingzeng},
title = {Multi-level Teaching Text Classification based on the Fusion of Deep Learning Models},
year = {2024},
isbn = {9798400716157},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3660043.3660071},
doi = {10.1145/3660043.3660071},
abstract = {Deep learning is widely used in text classification, which can be help the collection of teaching text samples from multiple datasets. On the other side, the variety of texts causes the difficulty of the classification. To solve this problem, we design a multi-level text classification system that fuses multiple models to increase the accuracy of the classification. In more details, we train the deep learning models on some public datasets. Then, we organize these to construct multi-level sets of models. On a text sample, we firstly detect if the dataset classification is needed. Then, we send this sample to the proper level of model set. Finally, we continuously optimize the system based on the collected samples. As the experimental results show, our method can achieve higher accuracy than the existing ones.},
booktitle = {Proceedings of the 2023 International Conference on Information Education and Artificial Intelligence},
pages = {155–159},
numpages = {5},
location = {Xiamen, China},
series = {ICIEAI '23}
}

@inproceedings{10.1145/3643991.3644931,
author = {Islam, Md Anaytul and Asaduzzman, Muhammad and Wang, Shaowei},
title = {On the Executability of R Markdown Files},
year = {2024},
isbn = {9798400705878},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643991.3644931},
doi = {10.1145/3643991.3644931},
abstract = {R Markdown files are examples of literate programming documents that combine R code with results and explanations. Such dynamic documents are designed to execute easily and reproduce study results. However, little is known about the executability of R Markdown files which can cause frustration among its users who intend to reuse the document. This paper presents a large-scale study on the executability of R Markdown files collected from GitHub. Results from our study show that a significant number of R Markdown files (64.95%) are not executable, even after our best efforts. To better understand the challenges, we categorize the exceptions encountered while executing the documents into different categories. Finally, we develop a classifier to determine which Markdown files are likely to be executable. Such a classifier can be utilized by search engines in their ranking which helps developers to find literate programming documents as learning resources.},
booktitle = {Proceedings of the 21st International Conference on Mining Software Repositories},
pages = {254–264},
numpages = {11},
keywords = {R Markdown, GitHub, executability, literate programming},
location = {Lisbon, Portugal},
series = {MSR '24}
}

@inproceedings{10.1145/3677779.3677824,
author = {Yao, Zhan‘ao and chen, Tingwei},
title = {A hop-based parallel graph attention network for relation extraction},
year = {2024},
isbn = {9798400709760},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3677779.3677824},
doi = {10.1145/3677779.3677824},
abstract = {Using graph neural networks to model dependency grammar information for relation extraction methods has become a very common approach. However, during the updating process of graph neural networks, they may be affected by the model architecture, which can lead to excessive attention to nearby nodes and affect the learning of distant words along the path. We suggest a graph neural network solution for relation extraction tasks by incorporating hop connections to tackle this issue. Meanwhile, in order to apply the dependency relationship of one hop to multiple hops, we designed a dependency relationship embedding based on the number of hops.The name is hop-based parallel graph attention network(Hp-GAT). This method not only compensates for the shortcomings of graph neural networks but also takes into account the information on the hop distance between words. We conducted experiments on the TACRED and SEMEVAL datasets, with findings indicating that our model outperformed the baseline dependency-driven graph neural network model.},
booktitle = {Proceedings of the International Conference on Modeling, Natural Language Processing and Machine Learning},
pages = {272–281},
numpages = {10},
location = {Xi'an, China},
series = {CMNM '24}
}

@inproceedings{10.1145/3631802.3631816,
author = {Malaise, Yoshi and Signer, Beat},
title = {Explorotron: An IDE Extension for Guided and Independent Code Exploration and Learning (Discussion Paper)},
year = {2024},
isbn = {9798400716539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3631802.3631816},
doi = {10.1145/3631802.3631816},
abstract = {We introduce the Explorotron Visual Studio Code extension for guided and independent code exploration and learning. Explorotron is a continuation of earlier work to explore how we can enable small organisations with limited resources to provide pedagogically sound learning experiences in programming. We situate Explorotron in the field of Computing Education Research&nbsp;(CER) and envision it to initiate a discussion around different topics, including how to balance the optimisation between the researcher-student-teacher trifecta that is inherent in CER, how to ethically and responsibly use large language models&nbsp;(LLMs) in the independent learning and exploration by students, and how to define better learning sessions over coding content that students obtained on their own. We further reflect on the question raised by Begel and Ko whether technology should “structure learning for learners” or whether learners should “be taught how to structure their own independent learning” outside of the classroom.},
booktitle = {Proceedings of the 23rd Koli Calling International Conference on Computing Education Research},
articleno = {24},
numpages = {8},
keywords = {PRIMM, Programming Education, Study Lenses},
location = {Koli, Finland},
series = {Koli Calling '23}
}

@proceedings{10.1145/3633637,
title = {ICCPR '23: Proceedings of the 2023 12th International Conference on Computing and Pattern Recognition},
year = {2023},
isbn = {9798400707988},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Qingdao, China}
}

@proceedings{10.1145/3638584,
title = {CSAI '23: Proceedings of the 2023 7th International Conference on Computer Science and Artificial Intelligence},
year = {2023},
isbn = {9798400708688},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Beijing, China}
}

@inproceedings{10.1145/3613904.3642855,
author = {Sivertsen, Christian and Salimbeni, Guido and L\o{}vlie, Anders Sundnes and Benford, Steven David and Zhu, Jichen},
title = {Machine Learning Processes As Sources of Ambiguity: Insights from AI Art},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642855},
doi = {10.1145/3613904.3642855},
abstract = {Ongoing efforts to turn Machine Learning (ML) into a design material have encountered limited success. This paper examines the burgeoning area of AI art to understand how artists incorporate ML in their creative work. Drawing upon related HCI theories, we investigate how artists create ambiguity by analyzing nine AI artworks that use computer vision and image synthesis. Our analysis shows that, in addition to the established types of ambiguity, artists worked closely with the ML process (dataset curation, model training, and application) and developed various techniques to evoke the ambiguity of processes. Our finding indicates that the current conceptualization of ML as a design material needs to reframe the ML process as design elements, instead of technical details. Finally, this paper offers reflections on commonly held assumptions in HCI about ML uncertainty, dependability, and explainability, and advocates to supplement the artifact-centered design perspective of ML with a process-centered one.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {165},
numpages = {14},
keywords = {ambiguity, art, artificial intelligence, computer vision, generative art, machine learning},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@inproceedings{10.1145/3638584.3638614,
author = {Wen, Luhan and Zhou, Dongmei and Luo, Hao and Cheng, Yongjian},
title = {A Novel Classification Model for Automatic Multi-Label ICD Coding via BERT-LSTM},
year = {2024},
isbn = {9798400708688},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3638584.3638614},
doi = {10.1145/3638584.3638614},
abstract = {Clinical notes are text documents created by physicians at each patient visit to record details of diagnosis and treatment, and are labeled using medical codes. However, manually marking up these codes is time-consuming and error-prone. To address this problem, we propose a new multi-label classification method inspired by the encoder-decoder structure that utilizes the BERT-LSTM network structure to automatically assign ICD codes to clinical texts. The model is able to accurately predict the appropriate medical codes based on the content and contextual information of the clinical text, improving efficiency while reducing errors. By combining these two powerful neural network models, we are able to better handle the task of coding clinical notes. In comparative experiments, the application results of the model are better than some basic neural network architectures, achieving 85.7% of AUC, 61.2% of precesion@5 and 56.5% of Micro-F1. This result demonstrates the robustness of our proposed method and the effectiveness automatic ICD coding classification.},
booktitle = {Proceedings of the 2023 7th International Conference on Computer Science and Artificial Intelligence},
pages = {1–7},
numpages = {7},
keywords = {BERT, Clinical note automatic coding, LSTM, Multi-label classification},
location = {Beijing, China},
series = {CSAI '23}
}

@proceedings{10.5555/3694718,
title = {JCDL '23: Proceedings of the 2023 ACM/IEEE Joint Conference on Digital Libraries},
year = {2024},
isbn = {9798350399318},
publisher = {IEEE Press},
location = {Santa Fe, New Mexico, USA}
}

@proceedings{10.1145/3671016,
title = {Internetware '24: Proceedings of the 15th Asia-Pacific Symposium on Internetware},
year = {2024},
isbn = {9798400707056},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Macau, China}
}

@inproceedings{10.1145/3689236.3696049,
author = {Shi, Jing and Yan, Jing and Zhang, Hong and Liu, Ting},
title = {Intelligent Editing and Publishing System Based on Deep Learning and Multi-Dimensional Cross-Encoding},
year = {2024},
isbn = {9798400718137},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689236.3696049},
doi = {10.1145/3689236.3696049},
abstract = {Abstract: With the rapid development of intelligent technologies in recent years, to enhance the level of intelligence in semantic modeling and automated processing of editing and publishing systems, this paper designs an intelligent editing and publishing system based on deep learning and multidimensional cross-encoding. The system's multidimensional cross-encoder performs semantic modeling of user-input keywords and achieves precise control over topics in the editing process through a weighted concatenation attention mechanism. To further optimize system performance, this study introduces a Generative Adversarial Network (GAN) to optimize the semantic representation of the generator. Experimental validation shows that the system performs excellently on evaluation metrics such as BLEU-3, BLEU-4, and Correlation, particularly with significant improvements in the consistency between keywords and text semantics. The research results indicate that the application of this system in intelligent editing and publishing processes offers significant technical advantages, effectively supporting topic planning and content proofreading in intelligent publishing workflows and providing technical support for the development of the intelligent publishing field.},
booktitle = {Proceedings of the 2024 9th International Conference on Cyber Security and Information Engineering},
pages = {923–930},
numpages = {8},
keywords = {Deep Learning, Generative Adversarial Network, Intelligence, Intelligent Editing and Publishing, Multi-Dimensional Cross-Encoding},
location = {
},
series = {ICCSIE '24}
}

@proceedings{10.1145/3649158,
title = {SACMAT 2024: Proceedings of the 29th ACM Symposium on Access Control Models and Technologies},
year = {2024},
isbn = {9798400704918},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our great pleasure to welcome you to the 29th ACM Symposium on Access Control Models and Technologies (SACMAT 2024). This year's symposium continues its tradition of being the premier venue for presenting research results and experience reports on cutting edge advances on access control, including models, systems, applications, and theory, while also embracing an expanded focus on the general area of computer and information security and privacy. The overarching goal of the symposium is to share novel access control and computer security solutions that fulfill the needs of emerging applications and environments, and also to identify new directions for future research and development. ACM SACMAT provides researchers and also practitioners with a unique opportunity to share their perspectives with others interested in the various aspects of access control and computer security.},
location = {San Antonio, TX, USA}
}

@proceedings{10.1145/3640543,
title = {IUI '24: Proceedings of the 29th International Conference on Intelligent User Interfaces},
year = {2024},
isbn = {9798400705083},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Greenville, SC, USA}
}

@proceedings{10.1145/3665463,
title = {CHI PLAY Companion '24: Companion Proceedings of the 2024 Annual Symposium on Computer-Human Interaction in Play},
year = {2024},
isbn = {9798400706929},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Tampere, Finland}
}

@inproceedings{10.1145/3589335.3653009,
author = {Poria, Soujanya},
title = {Understanding, Leveraging, and Improving Large Language Models},
year = {2024},
isbn = {9798400701726},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589335.3653009},
doi = {10.1145/3589335.3653009},
abstract = {The emergence of Large Language Models (LLMs) has marked a substantial advancement in Natural Language Processing (NLP), contributing significantly to enhanced task performance both within and outside specific domains. However, amidst these achievements, three key questions remain unanswered: 1) The mechanism through which LLMs accomplish their tasks and their limitations, 2) Effectively harnessing the power of LLMs across diverse domains, and 3) Strategies for enhancing the performance of LLMs. This talk aims to delve into our research group's endeavors to address these pivotal questions. Firstly, I will outline our approach, which involves utilizing ontology-guided prompt perturbations to unravel the primary limitations of LLMs in solving mathematical problems. Moving on to the second question, we will explore the utilization of synthetic data generated by LLMs to bolster challenging downstream tasks, particularly focusing on structured prediction where LLMs face persistent challenges. I will elaborate on our initiatives aimed at improving LLMs by incorporating highly effective retrieval strategies, specifically addressing the prevalent challenge of hallucinations that often plagues contemporary LLMs. Finally, I will present a technique on LLM realignment to restore safety lost during fine-tuning.},
booktitle = {Companion Proceedings of the ACM Web Conference 2024},
pages = {1805},
numpages = {1},
keywords = {keynote},
location = {Singapore, Singapore},
series = {WWW '24}
}

@proceedings{10.1145/3662739,
title = {MIDA '24: Proceedings of the 2024 International Conference on Machine Intelligence and Digital Applications},
year = {2024},
isbn = {9798400718144},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Ningbo, China}
}

@inproceedings{10.1145/3625007.3630110,
author = {Ventrice, Laura and Di Caro, Luigi},
title = {Enriching Wikipedia Texts through Geographic Information Extraction},
year = {2024},
isbn = {9798400704093},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3625007.3630110},
doi = {10.1145/3625007.3630110},
abstract = {Geographic Information Extraction (GIE) involves the extraction of geo-referenced information from a data collection through steps of geoparsing and geocoding. The former is a process that starts from a free textual description of locations with the goal of identifying an unambiguous location, such as specific geographic coordinates expressed as latitude-longitude. Differently, geocoding regards the easier task of translating an exact and well-formatted location such as postal addresses. This paper presents MAWI, i.e. a pipeline that starts from generic texts about cities that first extracts geographic information to automatically detect possible points of interest, then generates textual snippets from their contexts by means of Natural Language Processing (NLP) techniques. The adopted methodology involves several modules, ranging from publicly available geocoding systems to NLP libraries for Named Entity Recognition and text segmentation. The impact of the proposal includes multiple tasks and applications, e.g. i) the enrichment of public platforms of geographic data, ii) the detection of geographic scopes in textual documents, iii) a geo-centric exploration of locations in the tourism domain, and so forth. In this contribution, we present an experimentation of the system with 50 input Wikipedia pages referring different cities, first demonstrating its effectiveness with a running example, then evaluating its power to detect and structure a highly-significant amount of novel geo-referenced information with respect to what currently encoded in Wikipedia. Data and code are publicly available for future research at https://anonymous.4open.science/r/PointOfInterest-8D80/.},
booktitle = {Proceedings of the 2023 IEEE/ACM International Conference on Advances in Social Networks Analysis and Mining},
pages = {775–779},
numpages = {5},
keywords = {geographic information extraction, named entity recognition, geoparsing, wikipedia enrichment},
location = {Kusadasi, Turkiye},
series = {ASONAM '23}
}

@proceedings{10.1145/3652988,
title = {IVA '24: Proceedings of the 24th ACM International Conference on Intelligent Virtual Agents},
year = {2024},
isbn = {9798400706257},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {GLASGOW, United Kingdom}
}

@proceedings{10.1145/3658271,
title = {SBSI '24: Proceedings of the 20th Brazilian Symposium on Information Systems},
year = {2024},
isbn = {9798400709968},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Juiz de Fora, Brazil}
}

@inproceedings{10.1145/3652583.3658890,
author = {Mai, Tai Tan and Tran, Quang-Linh and Tran, Ly-Duyen and Ninh, Tu and Dang-Nguyen, Duc-Tien and Gurrin, Cathal},
title = {The First ACM Workshop on AI-Powered Question Answering Systems for Multimedia},
year = {2024},
isbn = {9798400706196},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652583.3658890},
doi = {10.1145/3652583.3658890},
abstract = {The advent of large language models (LLMs) has energised research in Question-Answering (QA) tasks, enabling responses across varied domains like economics and mathematics. Despite their capabilities, LLMs often lack explainability due to their complex parameter embeddings. Additionally, integrating multimedia data into QA systems introduces challenges in processing and interpreting diverse data types such as text, images, audio, and video. This necessitates sophisticated algorithms for accurate information retrieval across media while ensuring the reliability of the data and responses remains a significant challenge. The AIQAM workshop aims to bring together researchers and practitioners to address these challenges and enhance QA systems with multimedia data. The focus is on promoting innovations that improve the accuracy, explainability, and trustworthiness of QA systems, contributing to the development of the field.},
booktitle = {Proceedings of the 2024 International Conference on Multimedia Retrieval},
pages = {1328–1329},
numpages = {2},
keywords = {artificial intelligence, large language models, multimedia, question answering systems},
location = {Phuket, Thailand},
series = {ICMR '24}
}

@inproceedings{10.1145/3644032.3644456,
author = {Canizares, Pablo C. and \'{A}vila, Daniel and Perez-Soler, Sara and Guerra, Esther and De Lara, Juan},
title = {Coverage-based Strategies for the Automated Synthesis of Test Scenarios for Conversational Agents},
year = {2024},
isbn = {9798400705885},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3644032.3644456},
doi = {10.1145/3644032.3644456},
abstract = {Conversational agents - or chatbots - are increasingly used as the user interface to many software services. While open-domain chatbots like ChatGPT excel in their ability to chat about any topic, task-oriented conversational agents are designed to perform goal-oriented tasks (e.g., booking or shopping) guided by a dialogue-based user interaction, which is explicitly designed. Like any kind of software system, task-oriented conversational agents need to be properly tested to ensure their quality. For this purpose, some tools permit defining and executing conversation test cases. However, there are currently no established means to assess the coverage of the design of a task-oriented agent by a test suite, or mechanisms to automate quality test case generation ensuring the agent coverage.To attack this problem, we propose test coverage criteria for task-oriented conversational agents, and define coverage-based strategies to synthesise test scenarios, some oriented to test case reduction. We provide an implementation of the criteria and the strategies that is independent of the agent development platform. Finally, we report on their evaluation on open-source Dialogflow and Rasa agents, and a comparison against a state-of-the-art testing tool. The experiment shows benefits in terms of test generation correctness, increased coverage and reduced testing time.},
booktitle = {Proceedings of the 5th ACM/IEEE International Conference on Automation of Software Test (AST 2024)},
pages = {23–33},
numpages = {11},
keywords = {testing, test suite generation, task-oriented conversational agents},
location = {Lisbon, Portugal},
series = {AST '24}
}

@proceedings{10.1145/3686081,
title = {ICDSM '24: Proceedings of the International Conference on Decision Science &amp; Management},
year = {2024},
isbn = {9798400718151},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@article{10.1145/3649142,
author = {Chen, April and Rossi, Ryan A. and Park, Namyong and Trivedi, Puja and Wang, Yu and Yu, Tong and Kim, Sungchul and Dernoncourt, Franck and Ahmed, Nesreen K.},
title = {Fairness-Aware Graph Neural Networks: A Survey},
year = {2024},
issue_date = {July 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {6},
issn = {1556-4681},
url = {https://doi.org/10.1145/3649142},
doi = {10.1145/3649142},
abstract = {Graph Neural Networks (GNNs) have become increasingly important due to their representational power and state-of-the-art predictive performance on many fundamental learning tasks. Despite this success, GNNs suffer from fairness issues that arise as a result of the underlying graph data and the fundamental aggregation mechanism that lies at the heart of the large class of GNN models. In this article, we examine and categorize fairness techniques for improving the fairness of GNNs. We categorize these techniques by whether they focus on improving fairness in the pre-processing, in-processing (during training), or post-processing phases. We discuss how such techniques can be used together whenever appropriate and highlight the advantages and intuition as well. We also introduce an intuitive taxonomy for fairness evaluation metrics, including graph-level fairness, neighborhood-level fairness, embedding-level fairness, and prediction-level fairness metrics. In addition, graph datasets that are useful for benchmarking the fairness of GNN models are summarized succinctly. Finally, we highlight key open problems and challenges that remain to be addressed.},
journal = {ACM Trans. Knowl. Discov. Data},
month = apr,
articleno = {138},
numpages = {23},
keywords = {Fairness, Bias, Graph Neural Networks}
}

@inproceedings{10.1145/3664647.3680865,
author = {Zhang, Jiaxin and Wang, Yiqi and Yang, Xihong and Wang, Siwei and Feng, Yu and Shi, Yu and Ren, Ruichao and Zhu, En and Liu, Xinwang},
title = {Test-Time Training on Graphs with Large Language Models (LLMs)},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3680865},
doi = {10.1145/3664647.3680865},
abstract = {Graph Neural Networks have demonstrated great success in various fields of multimedia. However, the distribution shift between the training and test data challenges the effectiveness of GNNs. To mitigate this challenge, Test-Time Training (TTT) has been proposed as a promising approach. Traditional TTT methods require a demanding unsupervised training strategy to capture the information from test to benefit the main task. Inspired by the great annotation ability of Large Language Models (LLMs) on Text-Attributed Graphs (TAGs), we propose to enhance the test-time training on graphs with LLMs as annotators. In this paper, we design a novel Test-Time Training pipeline, LLMTTT, which conducts the test-time adaptation under the annotations by LLMs on a carefully-selected node set. Specifically, LLMTTT introduces a hybrid active node selection strategy that considers not only node diversity and representativeness, but also prediction signals from the pre-trained model. Given annotations from LLMs, a two-stage training strategy is designed to tailor the test-time model with the limited and noisy labels. A theoretical analysis ensures the validity of our method and extensive experiments demonstrate that the proposed LLMTTT can achieve a significant performance improvement compared to existing Out-of-Distribution (OOD) generalization methods.},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {2089–2098},
numpages = {10},
keywords = {graph neural networks, large language models, ood generalization, test time training},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@proceedings{10.1145/3597503,
title = {ICSE '24: Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Lisbon, Portugal}
}

@article{10.1145/3657285,
author = {Huang, Jiani and Chen, Haihua and Yu, Fengchang and Lu, Wei},
title = {From Detection to Application: Recent Advances in Understanding Scientific Tables and Figures},
year = {2024},
issue_date = {October 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {56},
number = {10},
issn = {0360-0300},
url = {https://doi.org/10.1145/3657285},
doi = {10.1145/3657285},
abstract = {Tables&nbsp;and figures are usually used to present information in a structured and visual way in scientific documents. Understanding the tables and figures in scientific documents is significant for a series of downstream tasks, such as academic search, scientific knowledge graphs, and so on. Existing studies mainly focus on detecting figures and tables from scientific documents, interpreting their semantics, and integrating them into downstream tasks. However, a systematic and comprehensive literature review on the mining and application of tables and figures in academic papers is still missing. In this article, we introduce the research framework and the whole pipeline for understanding tables and figures, including detection, structural analysis, interpretation, and application. We deliver a thorough analysis of benchmark datasets, recent techniques, and their pros and cons. Additionally, a quantitative analysis of the effectiveness of different models on popular benchmarks is presented. We further outline several important applications that exploit the semantics of scientific tables and figures. Finally, we highlight the challenges and some potential directions for future research. We believe this is the first comprehensive survey in understanding scientific tables and figures that covers the landscape from detection to application.},
journal = {ACM Comput. Surv.},
month = jun,
articleno = {261},
numpages = {39},
keywords = {Scientific documents, figure understanding, table understanding}
}

@article{10.1145/3637320,
author = {Hu, Jiaxiong and Guo, Jingya and Tang, Ningjing and Ma, Xiaojuan and Yao, Yuan and Yang, Changyuan and Xu, Yingqing},
title = {Designing the Conversational Agent: Asking Follow-up Questions for Information Elicitation},
year = {2024},
issue_date = {April 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {CSCW1},
url = {https://doi.org/10.1145/3637320},
doi = {10.1145/3637320},
abstract = {Conversational Agents (CAs) can facilitate information elicitation in various scenarios, such as semi-structured interviews. Current CAs can ask predetermined questions but lack skills for asking follow-up questions. Thus, we designed three approaches for CAs to automatically ask follow-up questions, i.e., follow-ups on concepts, follow-ups on related concepts, and general follow-ups. To investigate their effects, we conducted a user study (N=26) in which a CA interviewer asked follow-up questions generated by algorithms and crafted by human wizards. Our results showed that the CA's follow-up questions were readable and effective in information elicitation. The follow-ups on concepts and related concepts achieved a lower drop rate and better relevance, while the general follow-ups elicited more informative responses. Further qualitative analysis of the human-CA interview data revealed algorithm drawbacks and identified follow-up question techniques used by the human wizards. We provided design implications for improving information elicitation of future CAs based on the results.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = apr,
articleno = {43},
numpages = {30},
keywords = {conversational agent, conversational user interface, follow-up question, information elicitation, interview}
}

@inproceedings{10.1145/3589334.3645649,
author = {Gong, Jiaying and Eldardiry, Hoda},
title = {Multi-Label Zero-Shot Product Attribute-Value Extraction},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3645649},
doi = {10.1145/3589334.3645649},
abstract = {E-commerce platforms should provide detailed product descriptions (attribute values) for effective product search and recommendation. However, attribute value information is typically not available for new products. To predict unseen attribute values, large quantities of labeled training data are needed to train a traditional supervised learning model. Typically, it is difficult, time-consuming, and costly to manually label large quantities of new product profiles. In this paper, we propose a novel method to efficiently and effectively extract unseen attribute values from new products in the absence of labeled data (zero-shot setting). We propose HyperPAVE, a multi-label zero-shot attribute value extraction model that leverages inductive inference in heterogeneous hypergraphs. In particular, our proposed technique constructs heterogeneous hypergraphs to capture complex higher-order relations (i.e. user behavior information) to learn more accurate feature representations for graph nodes. Furthermore, our proposed HyperPAVE model uses an inductive link prediction mechanism to infer future connections between unseen nodes. This enables HyperPAVE to identify new attribute values without the need for labeled training data. We conduct extensive experiments with ablation studies on different categories of the MAVE dataset. The results demonstrate that our proposed HyperPAVE model significantly outperforms existing classification-based, generation-based large language models for attribute value extraction in the zero-shot setting.},
booktitle = {Proceedings of the ACM Web Conference 2024},
pages = {2259–2270},
numpages = {12},
keywords = {attribute value extraction, heterogeneous hypergraph, inductive link prediction, zero-shot learning},
location = {Singapore, Singapore},
series = {WWW '24}
}

@proceedings{10.1145/3675888,
title = {IC3-2024: Proceedings of the 2024 Sixteenth International Conference on Contemporary Computing},
year = {2024},
isbn = {9798400709722},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Noida, India}
}

@inproceedings{10.1145/3627673.3679793,
author = {Liu, Qi and He, Yongyi and Xu, Tong and Lian, Defu and Liu, Che and Zheng, Zhi and Chen, Enhong},
title = {UniMEL: A Unified Framework for Multimodal Entity Linking with Large Language Models},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679793},
doi = {10.1145/3627673.3679793},
abstract = {Multimodal Entity Linking (MEL) is a crucial task that aims at linking ambiguous mentions within multimodal contexts to the referent entities in a multimodal knowledge base, such as Wikipedia. Existing methods focus heavily on using complex mechanisms and extensive model tuning methods to model the multimodal interaction on specific datasets. However, these methods overcomplicate the MEL task and overlook the visual semantic information, which makes them costly and hard to scale. Moreover, these methods cannot solve the issues like textual ambiguity, redundancy, and noisy images, which severely degrade their performance. Fortunately, the advent of Large Language Models (LLMs) with robust capabilities in text understanding and reasoning, particularly Multimodal Large Language Models (MLLMs) that can process multimodal inputs, provides new insights into addressing this challenge. However, how to design a universally applicable LLMs-based MEL approach remains a pressing challenge. To this end, we propose UniMEL, a &lt;u&gt;uni&lt;/u&gt;fied framework which establishes a new paradigm to process &lt;u&gt;m&lt;/u&gt;ultimodal &lt;u&gt;e&lt;/u&gt;ntity &lt;u&gt;l&lt;/u&gt;inking tasks using LLMs. In this framework, we employ LLMs to augment the representation of mentions and entities individually by integrating textual and visual information and refining textual information. Subsequently, we employ the embedding-based method for retrieving and re-ranking candidate entities. Then, with only ~0.26% of the model parameters fine-tuned, LLMs can make the final selection from the candidate entities. Extensive experiments on three public benchmark datasets demonstrate that our solution achieves state-of-the-art performance, and ablation studies verify the effectiveness of all modules. Our code is available at https://github.com/Javkonline/UniMEL.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {1909–1919},
numpages = {11},
keywords = {large language models, multimodal entity linking, multimodal knowledge base},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@article{10.1145/3568164,
author = {Ahmed, Usman and Lin, Jerry Chun-Wei and Garcia Diaz, Vicente},
title = {Automatically Temporal Labeled Data Generation Using Positional Lexicon Expansion for Focus Time Estimation of News Articles},
year = {2024},
issue_date = {May 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {5},
issn = {2375-4699},
url = {https://doi.org/10.1145/3568164},
doi = {10.1145/3568164},
abstract = {Many facts change over time, which is a fundamental aspect of our physical environment. In the case of pandemic articles, the user is not interested in the creation date of the document but in the facts and the cause of the last pandemic. Fake news can be better combated by having a document with a temporal focus. Currently, neither the sequence of events nor the temporal focus is considered when obtaining news documents. Despite the limited number of temporal aspects in the available datasets, it is difficult to test and evaluate the temporal conclusions of the model. The goal of this work is to develop a temporal focus news article retrieval model based on co-training to advance research in semi-supervised learning. A mapping of the dataset is performed using (1) the evolving focus time of news articles and (2) the semi-supervised method based on coincidence contexts for learning low-dimensional continuous vectors for learning neural contrast embedding models generating focus time-based query in sequential news articles to facilitate temporal understanding by learning low-dimensional continuous vectors. A diverse dataset of news articles is used to evaluate the effectiveness of the proposed method. With semi-supervised learning and lexicon expansion, the result of the developed model can achieve 89%. The method performed better than previous baselines and traditional machine learning models with improvements of 12.65% and 4.7%, respectively.},
journal = {ACM Trans. Asian Low-Resour. Lang. Inf. Process.},
month = may,
articleno = {64},
numpages = {20},
keywords = {Information retrieval, temporal information retrieval, focus time, inverted pyramid, news retrieval}
}

@proceedings{10.1145/3639233,
title = {NLPIR '23: Proceedings of the 2023 7th International Conference on Natural Language Processing and Information Retrieval},
year = {2023},
isbn = {9798400709227},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Seoul, Republic of Korea}
}

@proceedings{10.1145/3643491,
title = {MAD '24: Proceedings of the 3rd ACM International Workshop on Multimedia AI against Disinformation},
year = {2024},
isbn = {9798400705526},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Phuket, Thailand}
}

@inproceedings{10.1145/3640457.3688071,
author = {Irrera, Ornella and Lissandrini, Matteo and Dell'Aglio, Daniele and Silvello, Gianmaria},
title = {Reproducibility and Analysis of Scientific Dataset Recommendation Methods},
year = {2024},
isbn = {9798400705052},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3640457.3688071},
doi = {10.1145/3640457.3688071},
abstract = {Datasets play a central role in scholarly communications. However, scholarly graphs are often incomplete, particularly due to the lack of connections between publications and datasets. Therefore, the importance of dataset recommendation—identifying relevant datasets for a scientific paper, an author, or a textual query—is increasing. Although various methods have been proposed for this task, their reproducibility remains unexplored, making it difficult to compare them with new approaches. We reviewed current recommendation methods for scientific datasets, focusing on the most recent and competitive approaches, including an SVM-based model, a bi-encoder retriever, a method leveraging co-authors and citation network embeddings, and a heterogeneous variational graph autoencoder. These approaches underwent a comprehensive analysis under consistent experimental conditions. Our reproducibility efforts show that three methods can be reproduced, while the graph variational autoencoder is challenging due to unavailable code and test datasets. Hence, we re-implemented this method and performed a component-based analysis to examine its strengths and limitations. Furthermore, our study indicated that three out of four considered methods produce subpar results when applied to real-world data instead of specialized datasets with ad-hoc features.},
booktitle = {Proceedings of the 18th ACM Conference on Recommender Systems},
pages = {570–579},
numpages = {10},
keywords = {Dataset Recommendations, Recommender Systems, Reproducibility},
location = {Bari, Italy},
series = {RecSys '24}
}

@inproceedings{10.1145/3626772.3657848,
author = {Zhai, ChengXiang},
title = {Large Language Models and Future of Information Retrieval: Opportunities and Challenges},
year = {2024},
isbn = {9798400704314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626772.3657848},
doi = {10.1145/3626772.3657848},
abstract = {Recent years have seen great success of large language models (LLMs) in performing many natural language processing tasks with impressive performance, including tasks that directly serve users such as question answering and text summarization. They open up unprecedented opportunities for transforming information retrieval (IR) research and applications. However, concerns such as halluciation undermine their trustworthiness, limiting their actual utility when deployed in real-world applications, especially high-stake applications where trust is vital. How can we both exploit the strengths of LLMs and mitigate any risk caused by their weaknesses when applying LLMs to IR? What are the best opportunities for us to apply LLMs to IR? What are the major challenges that we will need to address in the future to fully exploit such opportunities? Given the anticipated growth of LLMs, what will future information retrieval systems look like? Will LLMs eventually replace an IR system? In this perspective paper, we examine these questions and provide provisional answers to them. We argue that LLMs will not be able to replace search engines, and future LLMs would need to learn how to use a search engine so that they can interact with a search engine on behalf of users. We conclude with a set of promising future research directions in applying LLMs to IR.},
booktitle = {Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {481–490},
numpages = {10},
keywords = {conversational information access, information retrieval models, intelligent agent, large language models, search engines},
location = {Washington DC, USA},
series = {SIGIR '24}
}

@inproceedings{10.1145/3639479.3639527,
author = {Wang, Chen and Xiong, Xiong and Wang, Linjie and Zheng, Yifeng and Liu, Yunfei and Li, Shengyang},
title = {A Lexicon Enhanced Chinese Long Named Entity Recognition Using Word-Aware Attention},
year = {2024},
isbn = {9798400709241},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639479.3639527},
doi = {10.1145/3639479.3639527},
abstract = {In recent years, due to the rapid growth of space science and utilization research of China Manned Space Engineering, a considerable amount of technical documents and web data have been produced. Named entity recognition (NER) plays a vital role in extracting valuable information from these resources. However, the presence of numerous long named entities, which consist of complex, specialized terms and diverse phrase combinations, poses significant challenges for existing methods in identifying them correctly. To resolve this issue, we introduced two modules, SkipWord-Lattice and Word-Aware Attention, to improve the widely used lexical enhancement model in Chinese NER. SkipWord-Lattice reduces the overlap, redundancy, and confusion of word tokens, while Word-Aware Attention enhances the semantic interaction between character tokens and word tokens, improving the model’s comprehension of word tokens. Collectively, these modules significantly increase the model’s ability to identify long named entities. Moreover, using relevant corpus data publicly available in the field of space science and utilization of China Manned Space Engineering, we built a Chinese NER dataset, named SSUIE-NER, comprising rich entity types and a substantial number of long named entities. Experimental results indicate that, our method significantly improves the recognition of long named entities, outperforming other state-of-the-art (SOTA) approaches on SSUIE-NER and other three benchmarks in Chinese NER.},
booktitle = {Proceedings of the 2023 6th International Conference on Machine Learning and Natural Language Processing},
pages = {234–242},
numpages = {9},
keywords = {Chinese NER, Information extraction, Long named entity recognition},
location = {Sanya, China},
series = {MLNLP '23}
}

@proceedings{10.1145/3686169,
title = {HttF '24: Proceedings of the Halfway to the Future Symposium},
year = {2024},
isbn = {9798400710421},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Santa Cruz, CA, USA}
}

@proceedings{10.1145/3641825,
title = {VRST '24: Proceedings of the 30th ACM Symposium on Virtual Reality Software and Technology},
year = {2024},
isbn = {9798400705359},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Trier, Germany}
}

@article{10.1145/3652600,
author = {Chen, Junfan and Zhang, Richong and Jiang, Xiaohan and Hu, Chunming},
title = {SPContrastNet: A Self-Paced Contrastive Learning Model for Few-Shot Text Classification},
year = {2024},
issue_date = {September 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {42},
number = {5},
issn = {1046-8188},
url = {https://doi.org/10.1145/3652600},
doi = {10.1145/3652600},
abstract = {Meta-learning has recently promoted few-shot text classification, which identifies target classes based on information transferred from source classes through a series of small tasks or episodes. Existing works constructing their meta-learner on Prototypical Networks need improvement in learning discriminative text representations between similar classes that may lead to conflicts in label prediction. The overfitting problems caused by a few training instances need to be adequately addressed. In addition, efficient episode sampling procedures that could enhance few-shot training should be utilized. To address the problems mentioned above, we first present a contrastive learning framework that simultaneously learns discriminative text representations via supervised contrastive learning while mitigating the overfitting problem via unsupervised contrastive regularization, and then we build an efficient self-paced episode sampling approach on top of it to include more difficult episodes as training progresses. Empirical results on eight few-shot text classification datasets show that our model outperforms the current state-of-the-art models. The extensive experimental analysis demonstrates that our supervised contrastive representation learning and unsupervised contrastive regularization techniques improve the performance of few-shot text classification. The episode-sampling analysis reveals that our self-paced sampling strategy improves training efficiency.},
journal = {ACM Trans. Inf. Syst.},
month = apr,
articleno = {130},
numpages = {25},
keywords = {Text classification, few-shot learning, contrastive learning, self-paced learning}
}

@proceedings{10.1145/3639476,
title = {ICSE-NIER'24: Proceedings of the 2024 ACM/IEEE 44th International Conference on Software Engineering: New Ideas and Emerging Results},
year = {2024},
isbn = {9798400705007},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Lisbon, Portugal}
}

@inproceedings{10.1145/3637528.3671698,
author = {Wang, Chen and Fan, Ziwei and Yang, Liangwei and Yang, Mingdai and Liu, Xiaolong and Liu, Zhiwei and Yu, Philip},
title = {Pre-Training with Transferable Attention for Addressing Market Shifts in Cross-Market Sequential Recommendation},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671698},
doi = {10.1145/3637528.3671698},
abstract = {Cross-market recommendation (CMR) involves selling the same set of items across multiple nations or regions within a transfer learning framework. However, CMR's distinctive characteristics, including limited data sharing due to privacy policies, absence of user overlap, and a shared item set between markets present challenges for traditional recommendation methods. Moreover, CMR experiences market shifts, leading to differences in item popularity and user preferences among different markets. This study focuses on cross-market sequential recommendation (CMSR) and proposes the Cross-market Attention Transferring with Sequential Recommendation (CAT-SR) framework to address these challenges and market shifts. CAT-SR incorporates a pre-training strategy emphasizing item-item correlation, selective self-attention transferring for effective transfer learning, and query and key adapters for market-specific user preferences. Experimental results on real-world cross-market datasets demonstrate the superiority of CAT-SR, and ablation studies validate the benefits of its components across different geographical continents. CAT-SR offers a robust and adaptable solution for cross-market sequential recommendation. The code is available at https://github.com/ChenMetanoia/CATSR-KDD/.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {2970–2979},
numpages = {10},
keywords = {cross-market recommendation, pre-training, self-attention, sequential recommendation},
location = {Barcelona, Spain},
series = {KDD '24}
}

@proceedings{10.1145/3653081,
title = {IoTAAI '23: Proceedings of the 2023 5th International Conference on Internet of Things, Automation and Artificial Intelligence},
year = {2023},
isbn = {9798400716485},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Nanchang, China}
}

@proceedings{10.1145/3649921,
title = {FDG '24: Proceedings of the 19th International Conference on the Foundations of Digital Games},
year = {2024},
isbn = {9798400709555},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Worcester, MA, USA}
}

@proceedings{10.1145/3659211,
title = {BDEIM '23: Proceedings of the 2023 4th International Conference on Big Data Economy and Information Management},
year = {2023},
isbn = {9798400716669},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Zhengzhou, China}
}

@proceedings{10.1145/3650400,
title = {EITCE '23: Proceedings of the 2023 7th International Conference on Electronic Information Technology and Computer Engineering},
year = {2023},
isbn = {9798400708305},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Xiamen, China}
}

@inproceedings{10.1145/3635059.3635104,
author = {Karanikolas, Nikitas and Manga, Eirini and Samaridi, Nikoletta and Tousidou, Eleni and Vassilakopoulos, Michael},
title = {Large Language Models versus Natural Language Understanding and Generation},
year = {2024},
isbn = {9798400716263},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3635059.3635104},
doi = {10.1145/3635059.3635104},
abstract = {In recent years, the process humans adopt to learn a foreign language has moved from the strict "Grammar –Translation" method, which is based mainly on grammar and syntax rules, to more innovative processes, resulting to the more modern "Communicative approach". As its name states, this approach focuses on the coherent communication with native speakers and the cultivation of oral skills, without taking into consideration, at least at the first stages, the rules that govern the language. The same trend seems to have been applied to the way machinery can be "educated" to comprehend and reproduce the unfamiliar, human language. The "rule based" Natural Language Generation (NLG) and Natural Language Understanding (NLU) algorithms, on one hand, and the "text based" Large Language Models (LLMs), on the other, are two, analogous to the two human foreign language learning processes, subareas of Natural Language Processing (NLP). This paper presents these two alternative approaches, LLMs (a technology having surfaced as an influential catalyst of NLP, during last years) on the one hand and NLG/NLU on the other, highlighting their applications, their technologies, their capabilities, their differences, their strengths and weaknesses and the challenges they present, contributing to a deeper comprehension of the evolving landscape of Artificial Intelligence and human-computer communication.},
booktitle = {Proceedings of the 27th Pan-Hellenic Conference on Progress in Computing and Informatics},
pages = {278–290},
numpages = {13},
keywords = {Large Language Models, Natural Language Generation, Natural Language Processing, Natural Language Understanding},
location = {Lamia, Greece},
series = {PCI '23}
}

@inproceedings{10.1145/3664647.3681215,
author = {Han, Weixiang and Cai, Chengjun and Guo, Yu and Peng, Jialiang},
title = {ERL-MR: Harnessing the Power of Euler Feature Representations for Balanced Multi-modal Learning},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3681215},
doi = {10.1145/3664647.3681215},
abstract = {Multi-modal learning leverages data from diverse perceptual media to obtain enriched representations, thereby empowering machine learning models to complete more complex tasks. However, recent research results indicate that multi-modal learning still suffers from " modality imbalance '': Certain modalities' contributions are suppressed by dominant ones, consequently constraining the overall performance enhancement of multimodal learning. To tackle this issue, current approaches attempt to mitigate modality competition in various ways, but their effectiveness is still limited. To this end, we propose an Euler Representation Learning-based Modality Rebalance (ERL-MR) strategy, which reshapes the underlying competitive relationships between modalities into mutually reinforcing win-win situations while maintaining stable feature optimization directions. Specifically, ERL-MR employs Euler's formula to map original features to complex space, constructing cooperatively enhanced non-redundant features for each modality, which helps reverse the situation of modality competition. Moreover, to counteract the performance degradation resulting from optimization drift among modalities, we propose a Multi-Modal Constrained (MMC) loss based on cosine similarity of complex feature phase and cross-entropy loss of individual modalities, guiding the optimization direction of the fusion network. Extensive experiments conducted on four multi-modal multimedia datasets and two task-specific multi-modal multimedia datasets demonstrate the superiority of our ERL-MR strategy over state-of-the-art baselines, achieving modality rebalancing and further performance improvements.},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {4591–4600},
numpages = {10},
keywords = {euler formula, modality imbalance, multi-modal constrained loss, multi-modal learning},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@proceedings{10.1145/3639631,
title = {ACAI '23: Proceedings of the 2023 6th International Conference on Algorithms, Computing and Artificial Intelligence},
year = {2023},
isbn = {9798400709203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Sanya, China}
}

@inproceedings{10.1145/3691620.3694987,
author = {Gao, Xinyu and Xiong, Yun and Wang, Deze and Guan, Zhenhan and Shi, Zejian and Wang, Haofen and Li, Shanshan},
title = {Preference-Guided Refactored Tuning for Retrieval Augmented Code Generation},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3694987},
doi = {10.1145/3691620.3694987},
abstract = {Retrieval-augmented code generation utilizes Large Language Models as the generator and significantly expands their code generation capabilities by providing relevant code, documentation, and more via the retriever. The current approach suffers from two primary limitations: 1) information redundancy. The indiscriminate inclusion of redundant information can result in resource wastage and may misguide generators, affecting their effectiveness and efficiency. 2) preference gap. Due to different optimization objectives, the retriever strives to procure code with higher ground truth similarity, yet this effort does not substantially benefit the generator. The retriever and the generator may prefer different golden code, and this gap in preference results in a suboptimal design. Additionally, differences in parameterization knowledge acquired during pre-training result in varying preferences among different generators.To address these limitations, in this paper, we propose RRG (Retrieve, Refactor, Generate), a novel framework for effective and efficient code generation. This framework introduces a code refactorer module between the retriever and the generator to bridge them. The refactoring process transforms the raw retrieved code into a more concise, efficient, and model-friendly version. It eliminates redundant information and noise, reducing the input length. Consequently, the generator receives higher-quality context, enabling it to produce more accurate results with lower inference costs. We conducted comprehensive experiments on multiple datasets. In the experiments, we confirmed the existence of a preference gap between the retriever and the generator, and RRG effectively bridges this gap. Specifically, RRG achieved significant performance improvements, with increases of up to 28% on EM, 13% on BLEU, and 6.8% on CodeBLEU.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {65–77},
numpages = {13},
keywords = {retrieval-augmented code generation, preference-guided refactorer, deep reinforcement learning},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@proceedings{10.1145/3665601,
title = {GUIDE-AI '24: Proceedings of the Conference on Governance, Understanding and Integration of Data for Effective and Responsible AI},
year = {2024},
isbn = {9798400706943},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Santiago, AA, Chile}
}

@article{10.1145/3709007,
author = {Mishra, Sahil and Sudev, Ujjwal and Chakraborty, Tanmoy},
title = {FLAME: Self-Supervised Low-Resource Taxonomy Expansion Using Large Language Models},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {2157-6904},
url = {https://doi.org/10.1145/3709007},
doi = {10.1145/3709007},
abstract = {Taxonomies represent an arborescence hierarchical structure that establishes relationships among entities to convey knowledge within a specific domain. They find utility in various real-world applications, such as e-commerce search engines and recommendation systems. Consequently, there arises a necessity to enhance these taxonomies over time. However, manually curating taxonomies with neoteric data presents challenges due to limitations in available human resources and the exponential growth of data. Therefore, it becomes imperative to develop automatic taxonomy expansion methods. Traditional approaches encounter difficulties stemming from limited resources, primarily due to the small size of existing taxonomies. This scarcity of training data often leads to overfitting. In this paper, we propose FLAME (Fine-tuning LArge language Models for taxonomy Expansion), a novel approach for taxonomy expansion in low-resource environments (i.e., limited size of existing taxonomies, lack of robust representation capabilities of pre-trained language models, etc.) by harnessing the capabilities of large language models (LLMs) that are trained on extensive real-world knowledge. LLMs help compensate for the scarcity of domain-specific knowledge. Specifically, FLAME leverages prompting in few-shot settings to extract the inherent knowledge within the LLMs, ascertaining the hypernym entities within the taxonomy. Furthermore, it employs reinforcement learning to fine-tune LLMs, resulting in more accurate predictions. Experiments on four real-world benchmark datasets demonstrate the effectiveness of FLAME in real-world scenarios, achieving a remarkable improvement of 12.8% in accuracy and 5.6% in Wu &amp; Palmer metric over eleven baselines. Furthermore, we discuss the strengths and weaknesses of FLAME through an extensive case study, error analysis and ablation studies on the benchmarks.},
note = {Just Accepted},
journal = {ACM Trans. Intell. Syst. Technol.},
month = dec,
keywords = {Taxonomy Expansion, Large Language Models, Self-supervised Learning}
}

@proceedings{10.1145/3686215,
title = {ICMI Companion '24: Companion Proceedings of the 26th International Conference on Multimodal Interaction},
year = {2024},
isbn = {9798400704635},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {San Jose, Costa Rica}
}

@inproceedings{10.1145/3637528.3671603,
author = {Zheng, Da and Song, Xiang and Zhu, Qi and Zhang, Jian and Vasiloudis, Theodore and Ma, Runjie and Zhang, Houyu and Wang, Zichen and Adeshina, Soji and Nisa, Israt and Mottini, Alejandro and Cui, Qingjun and Rangwala, Huzefa and Zeng, Belinda and Faloutsos, Christos and Karypis, George},
title = {GraphStorm: All-in-one Graph Machine Learning Framework for Industry Applications},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671603},
doi = {10.1145/3637528.3671603},
abstract = {Graph machine learning (GML) is effective in many business applications. However, making GML easy to use and applicable to industry applications with massive datasets remain challenging. We developed GraphStorm, which provides an end-to-end solution for scalable graph construction, graph model training and inference. GraphStorm has the following desirable properties: (a) Easy to use: it can perform graph construction and model training and inference with just a single command; (b) Expert-friendly: GraphStorm contains many advanced GML modeling techniques to handle complex graph data and improve model performance; (c) Scalable: every component in GraphStorm can operate on graphs with billions of nodes and can scale model training and inference to different hardware without changing any code. GraphStorm has been used and deployed for over a &lt;u&gt;dozen&lt;/u&gt; &lt;u&gt;billion-scale&lt;/u&gt; industry applications after its release in May 2023. It is open-sourced in Github: https://github.com/awslabs/graphstorm.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {6356–6367},
numpages = {12},
keywords = {graph machine learning, industry scale},
location = {Barcelona, Spain},
series = {KDD '24}
}

@inproceedings{10.1145/3605098.3635888,
author = {Sourty, Rapha\"{e}l and Moreno, Jose G and Servant, Fran\c{c}ois-Paul and Tamine, Lynda},
title = {Knowledge Base Grounded Pre-trained Language Models via Distillation},
year = {2024},
isbn = {9798400702433},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3605098.3635888},
doi = {10.1145/3605098.3635888},
abstract = {Knowledge bases are key resources in a wide range of knowledge intensive applications. However, their incompleteness inherently limits their use and gives rise to the importance of their completion. To this end, an open-world view has recently been held in the literature by coupling the ability of knowledge bases to represent factual knowledge, with the abilities of pre-trained language models (PLMs) to capture high-level and contextual linguistic knowledge from large-scale text corpora. In this work, we propose a distillation framework for knowledge base completion where PLMs leverage soft labels in the form of entity and relations predictions provided by a knowledge base embedding model, while keeping their power of entity prediction over large-scale of texts. To better fit with the task of knowledge completion, we extend the traditional masked language modelling of PLMs toward predicting entities and related entities in context. Experiments using the fact classification and relation extraction tasks within the standard KILT evaluation benchmark shows the potential of our proposed approach.},
booktitle = {Proceedings of the 39th ACM/SIGAPP Symposium on Applied Computing},
pages = {1617–1625},
numpages = {9},
location = {Avila, Spain},
series = {SAC '24}
}

@article{10.1145/3687273.3687289,
author = {Campos, Ricardo and Jorge, Al\'{\i}pio M. and Jatowt, Adam and Bhatia, Sumit and Litvak, Marina and Cordeiro, Jo\~{a}o Paulo and Rocha, Concei\c{c}\~{a}o and Sousa, Hugo and Mansouri, Behrooz},
title = {Report on the 7th International Workshop on Narrative Extraction from Texts (Text2Story 2024) at ECIR 2024},
year = {2024},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {58},
number = {1},
issn = {0163-5840},
url = {https://doi.org/10.1145/3687273.3687289},
doi = {10.1145/3687273.3687289},
abstract = {The Seventh International Workshop on Narrative Extraction from Texts (Text2Story'24) was held on March 24th, 2024, in conjunction with the 46th European Conference on Information Retrieval (ECIR 2024) in Glasgow, Scotland. Over the day, more than 50 attendees engaged in discussions and presentations focused on recent advancements in narrative representation, extraction, and generation. The workshop featured two invited keynote addresses, fourteen research paper presentations, and a poster session. The workshop proceedings are available online.1Date: 24 March 2024.Website: https://text2story24.inesctec.pt/.},
journal = {SIGIR Forum},
month = aug,
pages = {1–11},
numpages = {11}
}

@proceedings{10.1145/3661167,
title = {EASE '24: Proceedings of the 28th International Conference on Evaluation and Assessment in Software Engineering},
year = {2024},
isbn = {9798400717017},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Salerno, Italy}
}

@proceedings{10.1145/3627050,
title = {IoT '23: Proceedings of the 13th International Conference on the Internet of Things},
year = {2023},
isbn = {9798400708541},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Nagoya, Japan}
}

@proceedings{10.1145/3673805,
title = {ECCE '24: Proceedings of the European Conference on Cognitive Ergonomics 2024},
year = {2024},
isbn = {9798400718243},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Paris, France}
}

@proceedings{10.1145/3626246,
title = {SIGMOD/PODS '24: Companion of the 2024 International Conference on Management of Data},
year = {2024},
isbn = {9798400704222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {On behalf of the SIGMOD 2024 organizing committee, it is our distinct honor, as General Chairs, to welcome you to the 2024 ACM International Conference on Management of Data - SIGMOD 2024. We are thrilled to be hosting this prestigious event for the very first time in Latin America, and specifically in Santiago de Chile, a recognized leader in data technology within the region. This marks a significant milestone for the SIGMOD community, and we are honored to have you join us for a fully in-person experience in this vibrant and innovative city.},
location = {Santiago AA, Chile}
}

@inproceedings{10.1145/3644116.3644314,
author = {Wang, Yue and Zhang, Xi},
title = {Research on Named Entity Recognition for Chinese Medical Case Reports},
year = {2024},
isbn = {9798400708138},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3644116.3644314},
doi = {10.1145/3644116.3644314},
abstract = {In the domain of medical informatics, accurately identifying entities within Electronic Health Records (EHR) presents a significant challenge, especially within specialized medical fields. This research delves deeply into this challenge, underscoring the unique linguistic complexities associated with Chinese medical texts. Unlike English where words are delineated by spaces, Chinese characters flow continuously without clear demarcations. This intrinsic characteristic necessitates a departure from traditional word-level Named Entity Recognition (NER) approaches. To address this, our study adopts a character-level method, ensuring more precise entity identification. Utilizing the comprehensive Yidu Cloud Structure 4K dataset, we juxtapose its original and corrected versions, shedding light on discrepancies and their implications. Central to our research is the introduction of the BERT BiLSTM CRF model. This innovative model, grounded in the data-intensive BERT framework, holds promise in enhancing entity recognition within EHRs. Our findings indicate an improved accuracy in named entity recognition for Chinese medical texts using this model. By harnessing the power of this model, we aspire to pave the way for a new era of intelligent and automated medical systems where data-driven insights can be seamlessly integrated into clinical decision-making processes.},
booktitle = {Proceedings of the 2023 4th International Symposium on Artificial Intelligence for Medicine Science},
pages = {1165–1169},
numpages = {5},
location = {Chengdu, China},
series = {ISAIMS '23}
}

@inproceedings{10.1145/3626246.3653378,
author = {Pavlenko, Anna and Cahoon, Joyce and Zhu, Yiwen and Kroth, Brian and Nelson, Michael and Carter, Andrew and Liao, David and Wright, Travis and Camacho-Rodr\'{\i}guez, Jes\'{u}s and Saur, Karla},
title = {Vertically Autoscaling Monolithic Applications with CaaSPER: Scalable Container-as-a-Service Performance Enhanced Resizing Algorithm for the Cloud},
year = {2024},
isbn = {9798400704222},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626246.3653378},
doi = {10.1145/3626246.3653378},
abstract = {Kubernetes has emerged as a prominent open-source platform for managing cloud applications, including stateful databases. These monolithic applications rely on vertical scaling, adjusting CPU cores based on load fluctuations. However, our analysis of Kubernetes-based Database-as-a-Service (DBaaS) offerings at Microsoft revealed that many customers consistently over-provision resources for peak workloads, neglecting cost-saving opportunities through resource scale-down. We found that there is a gap in the ability of existing vertical autoscaling tools to minimize resource slack and respond promptly to throttling, leading to increased costs and impacting crucial metrics such as throughput and availability.To address this challenge, we propose CaaSPER, a vertical autoscaling algorithm that blends reactive and proactive strategies. By dynamically adjusting CPU resources, CaaSPER minimizes resource slack, maintains optimal CPU utilization, and reduces throttling. Importantly, customers have the flexibility to prioritize either cost savings or high performance based on their preferences. Extensive testing demonstrates that CaaSPER effectively reduces throttling and keeps CPU utilization within target levels. CaaSPER is designed to be application-agnostic and platform-agnostic, with potential for extension to other applications requiring vertical autoscaling.},
booktitle = {Companion of the 2024 International Conference on Management of Data},
pages = {241–254},
numpages = {14},
keywords = {containers, kubernetes, resource optimization, vertical auto-scaling},
location = {Santiago AA, Chile},
series = {SIGMOD/PODS '24}
}

@article{10.1145/3637873,
author = {Razgallah, H\'{e}di and Vlachos, Michalis and Ajalloeian, Ahmad and Liu, Ninghao and Schneider, Johannes and Steinmann, Alexis},
title = {Using Neural and Graph Neural Recommender Systems to Overcome Choice Overload: Evidence From a Music Education Platform},
year = {2024},
issue_date = {July 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {42},
number = {4},
issn = {1046-8188},
url = {https://doi.org/10.1145/3637873},
doi = {10.1145/3637873},
abstract = {The application of recommendation technologies has been crucial in the promotion of physical and digital content across numerous global platforms such as Amazon, Apple, and Netflix. Our study aims to investigate the advantages of employing recommendation technologies on educational platforms, with a particular focus on an educational platform for learning and practicing music. Our research is based on data from Tomplay, a music platform that offers sheet music with professional audio recordings, enabling users to discover and practice music content at varying levels of difficulty. Through our analysis, we emphasize the distinct interaction patterns on educational platforms like Tomplay, which we compare with other commonly used recommendation datasets. We find that interactions are comparatively sparse on educational platforms, with users often focusing on specific content as they learn, rather than interacting with a broader range of material. Therefore, our primary goal is to address the issue of data sparsity. We achieve this through entity resolution principles and propose a neural network (NN)-based recommendation model. Further, we improve this model by utilizing graph neural networks (GNNs), which provide superior predictive accuracy compared to NNs. Notably, our study demonstrates that GNNs are highly effective even for users with little or no historical preferences (cold-start problem). Our cold-start experiments also provide valuable insights into an independent issue, namely, the number of historical interactions needed by a recommendation model to gain a comprehensive understanding of a user. Our findings demonstrate that a platform acquires a solid knowledge of a user’s general preferences and characteristics with 50 past interactions. Overall, our study makes significant contributions to information systems research on business analytics and prescriptive analytics. Moreover, our framework and evaluation results offer implications for various stakeholders, including online educational institutions, education policymakers, and learning platform users.},
journal = {ACM Trans. Inf. Syst.},
month = feb,
articleno = {92},
numpages = {26},
keywords = {Neural networks, digital education, embeddings, entity resolution}
}

@inproceedings{10.1145/3627673.3680111,
author = {Chen, Huaming and Zhuang, Jun and Yao, Yu and Jin, Wei and Wang, Haohan and Xie, Yong and Chi, Chi-Hung and Choo, Kim-Kwang Raymond},
title = {Trustworthy and Responsible AI for Information and Knowledge Management System},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3680111},
doi = {10.1145/3627673.3680111},
abstract = {The way research and business manage and utilize knowledge is undergoing a significant transformation, driven by Artificial Intelligence (AI). Deep learning and machine learning are emerging as powerful tools for optimizing knowledge management systems, leading to more informed and productive development. AI offers unique solutions for organizations struggling with information overload and inefficient knowledge transfer. These AI models can significantly improve data management and utilization. Imagine an AI-powered system that streamlines onboarding processes, provides precise answers to various queries, and even captures the valuable tacit knowledge (implicit skills and expertise) often residing within individuals. AI bridges the gap between explicit knowledge (easily documented information) and tacit knowledge, fostering a more comprehensive and accessible knowledge base. However, such AI systems solicit trustworthy and responsible approaches to mitigate potential misuse and malfunction. In this workshop, we aim to gather researchers and engineers from academia and industry to discuss the latest advances in trustworthy and responsible AI solutions for information and knowledge management systems.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {5574–5576},
numpages = {3},
keywords = {information retrieval, knowledge management, trustworthy AI},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@inproceedings{10.1145/3639631.3639644,
author = {Jiang, Yueqi and Sun, Xiao and Wang, Jiamin},
title = {EmoDamp: A Model for Speaker Emotion Inference in Dialogues with Bidirectional Emotion Damping Mechanism},
year = {2024},
isbn = {9798400709203},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3639631.3639644},
doi = {10.1145/3639631.3639644},
abstract = {Emotion analysis in conversation has been a popular research topic in the natural language processing field. While much of the existing research has focused on emotion recognition in conversation, the emotion inference task in conversation is more challenging due to its specific prerequisites. In this paper, we propose EmoDamp, a novel model for the conversational emotion inference task. By referring to psychological theories, a bidirectional emotion damping network(BED Net) is designed to model the emotion generation mechanism. Furthermore, external commonsense knowledge is also used to supplement the prediction results to make them more consistent with authentic logic. Finally, a conditional random field (CRF) is used to capture the potential constraints of the emotion transfer process in conversation and simulate emotion contagion. Experimental results on two benchmark datasets demonstrate that EmoDamp outperforms the baseline model, achieving improved results on each emotion category and showcasing its effectiveness.},
booktitle = {Proceedings of the 2023 6th International Conference on Algorithms, Computing and Artificial Intelligence},
pages = {74–81},
numpages = {8},
keywords = {Affective computing, Emotion Inference, Human–computer interaction},
location = {Sanya, China},
series = {ACAI '23}
}

@proceedings{10.1145/3685767,
title = {CTCNet '24: Proceedings of the 2024 Asia Pacific Conference on Computing Technologies, Communications and Networking},
year = {2024},
isbn = {9798400709609},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Chengdu, China}
}

@inproceedings{10.1145/3634737.3645000,
author = {Kumarasinghe, Udesh and Lekssays, Ahmed and Sencar, Husrev Taha and Boughorbel, Sabri and Elvitigala, Charitha and Nakov, Preslav},
title = {Semantic Ranking for Automated Adversarial Technique Annotation in Security Text},
year = {2024},
isbn = {9798400704826},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3634737.3645000},
doi = {10.1145/3634737.3645000},
abstract = {We introduce a novel approach for mapping attack behaviors described in threat analysis reports to entries in an adversarial techniques knowledge base. Our method leverages a multi-stage ranking architecture to efficiently rank the most related techniques based on their semantic relevance to the input text. Each ranker in our pipeline uses a distinct design for text representation. To enhance relevance modeling, we leverage pretrained language models, which we fine-tune for the technique annotation task. While generic large language models are not yet capable of fully addressing this challenge, we obtain very promising results. We achieve a recall rate improvement of +35% compared to the previous state-of-the-art results. We further create new public benchmark datasets for training and validating methods in this domain, which we release to the research community aiming to promote future research in this important direction.},
booktitle = {Proceedings of the 19th ACM Asia Conference on Computer and Communications Security},
pages = {49–62},
numpages = {14},
keywords = {threat intelligence, TTP annotation, text ranking, text attribution},
location = {Singapore, Singapore},
series = {ASIA CCS '24}
}

@inproceedings{10.1145/3638584.3638615,
author = {Wang, Na and Zhang, Rongqiang and Wu, Hengyang},
title = {Cultural Heritage Triple Information Extraction Based on Span Pointer Network},
year = {2024},
isbn = {9798400708688},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3638584.3638615},
doi = {10.1145/3638584.3638615},
abstract = {Knowledge in the field of cultural heritage has the characteristics of long data, large entity span, high semantic complexity and nesting among some entities, which increase the difficulty of knowledge extraction in the field of cultural heritage. In order to effectively solve the problem of knowledge extraction in the field of cultural heritage, and to solve the problem of error accumulation and entity redundancy in the pipeline method in the relationship extraction task, a relationship joint extraction model based on span pointer network is proposed to extract the triple information in the field of cultural heritage. In addition, in order to improve the extraction performance and generalization ability of the model, based on the model of span pointer network, ERNIE pre-training model which is more suitable for Chinese tasks is used as the coding layer and AdamW is used as the optimizer. The final experimental results show that this method has superior performance in solving the problem of knowledge extraction in the field of cultural heritage.},
booktitle = {Proceedings of the 2023 7th International Conference on Computer Science and Artificial Intelligence},
pages = {381–387},
numpages = {7},
keywords = {AdamW, Cultural Heritage, ERNIE, Relation Extraction, Span Pointer Network},
location = {Beijing, China},
series = {CSAI '23}
}

@inproceedings{10.1145/3644116.3644319,
author = {Han, Zongwang and Lin, Shaofu and Huang, Zhisheng and Guo, Chaohui},
title = {Named Entity Recognition for Long COVID Biomedical Literature by Using Bert-BiLSTM-IDCNN-ATT-CRF Approach},
year = {2024},
isbn = {9798400708138},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3644116.3644319},
doi = {10.1145/3644116.3644319},
abstract = {In recent years, with the exploration of pathological mechanisms and treatments of Long COVID, there has been a dramatic increase in related scientific publications. Effective extraction of key information from these texts is of great importance for public health and research progress. In the Long COVID context, Named Entity Recognition (NER) can be used to identify disease names as well as symptoms, which can help to analyze the sequelae caused by COVID-19 and its relationship with other diseases. Distinguished from molecular biomedical text mining, which focuses on the identification of entities such as genes, proteins, and chemistries and their relationships, Long COVID text mining faces problems such as the lack of publicly labeled datasets and the heavy workload of manual annotation. Moreover, due to the strong domain characteristics of Long COVID relevant named entities, models and methods that have achieved great performance in the generic domain will have significantly degraded named entity recognition performance on this domain. Based on the above problems, we constructed a Long COVID literature abstract NER dataset (LNER) and proposed a Long COVID biomedical literature NER model Bert-BiLSTM-IDCNN-ATT-CRF (BBIAC). First, the BERT-BiLSTM-CRF model is constructed on the LNER dataset. Then, the inflated convolutional neural network (IDCNN) is added between the BiLSTM and the CRF layers to obtain the local features in the text sequences. Finally, feature enhancement is performed by fusing the features of global and local information using the attention mechanism. The experimental results show that the method proposed in this paper for Long COVID literature can accurately extract the characteristic information of Long COVID symptoms and diseases, and has better performance compared to other baseline models.},
booktitle = {Proceedings of the 2023 4th International Symposium on Artificial Intelligence for Medicine Science},
pages = {1200–1205},
numpages = {6},
location = {Chengdu, China},
series = {ISAIMS '23}
}

@article{10.1145/3641278,
author = {Li, Jiuyi and Liu, Junpeng and Ma, Jianjun and Yang, Wei and Huang, Degen},
title = {Boundary-Aware Abstractive Summarization with Entity-Augmented Attention for Enhancing Faithfulness},
year = {2024},
issue_date = {April 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {4},
issn = {2375-4699},
url = {https://doi.org/10.1145/3641278},
doi = {10.1145/3641278},
abstract = {With the successful application of deep learning, document summarization systems can produce more readable results. However, abstractive summarization still suffers from unfaithful outputs and factual errors, especially in named entities. Current approaches tend to employ external knowledge to improve model performance while neglecting the boundary information and the semantics of the entities. In this article, we propose an entity-augmented method (EAM) to encourage the model to make full use of the entity boundary information and pay more attention to the critical entities. Experimental results on three Chinese and English summarization datasets show that our method outperforms several strong baselines and achieves state-of-the-art performance on the CLTS dataset. Our method can also improve the faithfulness of the summary and generalize well to different pre-trained language models. Moreover, we propose a method to evaluate the integrity of generated entities. Besides, we adapt the data augmentation method in the FactCC model according to the difference between Chinese and English in grammar and train a new evaluation model for factual consistency evaluation in Chinese summarization.},
journal = {ACM Trans. Asian Low-Resour. Lang. Inf. Process.},
month = apr,
articleno = {53},
numpages = {18},
keywords = {Abstractive text summarization, factual consistency, entity-augmented}
}

@proceedings{10.1145/3677525,
title = {GoodIT '24: Proceedings of the 2024 International Conference on Information Technology for Social Good},
year = {2024},
isbn = {9798400710940},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Bremen, Germany}
}

@inproceedings{10.1145/3632754.3633480,
author = {Paul, Soumen and Majumdar, Srijoni and Bandyopadhyay, Ayan and Dave, Bhargav and Chattopadhyay, Samiran and Das, Partha and Clough, Paul D and Majumder, Prasenjit},
title = {Efficiency of Large Language Models to scale up Ground Truth: Overview of the IRSE Track at Forum for Information Retrieval 2023},
year = {2024},
isbn = {9798400716324},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3632754.3633480},
doi = {10.1145/3632754.3633480},
abstract = {The Software Engineering Information Retrieval (IRSE) track aims to devise solutions for the automated evaluation of code comments within a machine learning framework, with labels generated by both humans and large language models. Within this track, there is a binary classification task: discerning comments as either useful or not useful. The dataset includes 9,048 pairs of code comments and surrounding code snippets drawn from open-source C-based projects on GitHub and an additional dataset generated by teams employing large language models. In total, 17 teams representing various universities and software companies have contributed 56 experiments. These experiments were assessed through quantitative metrics, primarily the F1-Score, and qualitative evaluations based on the features developed, the supervised learning models employed, and their respective hyperparameters. It is worth noting that labels generated by large language models introduce bias into the prediction model but lead to less over-fitted results.},
booktitle = {Proceedings of the 15th Annual Meeting of the Forum for Information Retrieval Evaluation},
pages = {16–18},
numpages = {3},
keywords = {Abstract syntax tree, Bert, GPT-2, Neural networks, Stanford POS Tagging},
location = {Panjim, India},
series = {FIRE '23}
}

@inproceedings{10.1145/3589335.3651945,
author = {Ayoub, Michael Antonios Kruse and Su, Zhan and Li, Qiuchi},
title = {A Case Study of Enhancing Sparse Retrieval using LLMs},
year = {2024},
isbn = {9798400701726},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589335.3651945},
doi = {10.1145/3589335.3651945},
abstract = {While dense retrieval methods have made significant advancements, sparse retrieval techniques continue to offer advantages in terms of interpretability and generalizability. However, query-document term mismatch in sparse retrieval persists, rendering it infeasible for many practical applications. Recent research has shown that Large Language Models (LLMs) hold relevant information that can enhance sparse retrieval through the application of prompt engineering. In this paper, we build upon this concept to explore various strategies employing LLMs for information retrieval purposes. Specifically, we utilize LLMs to enhance sparse retrieval by query rewriting and query expansion. In query rewriting, the original query is refined by creating several new queries. For query expansion, LLMs are employed to generate extra terms, thereby enriching the original query. We conduct experiments on a range of well-known information retrieval datasets, including MSMARCO-passage, TREC2019, TREC2020, Natural Questions, SCIFACT. The experiments show that LLMs can be beneficial for sparse methods since the added information provided by the LLMs can help diminish the discrepancy between the term frequencies of the important terms in a query and the relevant document. In certain domains, we demonstrate that the effectiveness of LLMs is constrained, indicating that they may not consistently perform optimally, which will be explored in future research.},
booktitle = {Companion Proceedings of the ACM Web Conference 2024},
pages = {1609–1615},
numpages = {7},
keywords = {information retrieval, large language models, query expansion, query writing},
location = {Singapore, Singapore},
series = {WWW '24}
}

@proceedings{10.1145/3664476,
title = {ARES '24: Proceedings of the 19th International Conference on Availability, Reliability and Security},
year = {2024},
isbn = {9798400717185},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Vienna, Austria}
}

@article{10.1145/3656168,
author = {Wang, Quan and Mao, Zhendong and Gao, Jie and Zhang, Yongdong},
title = {Document-level Relation Extraction with Progressive Self-distillation},
year = {2024},
issue_date = {November 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {42},
number = {6},
issn = {1046-8188},
url = {https://doi.org/10.1145/3656168},
doi = {10.1145/3656168},
abstract = {Document-level relation extraction (RE) aims to simultaneously predict relations (including no-relation cases denoted as NA) between all entity pairs in a document. It is typically formulated as a relation classification task with entities pre-detected in advance and solved by a hard-label training regime, which, however, neglects the divergence of the NA class and the correlations among other classes. This article introduces progressive self-distillation (PSD), a new training regime that employs online, self-knowledge distillation (KD) to produce and incorporate soft labels for document-level RE.The key idea of PSD is to gradually soften hard labels using past predictions from an RE model itself, which are adjusted adaptively as training proceeds. As such, PSD has to learn only one RE model within a single training pass, requiring no extra computation or annotation to pretrain another high-capacity teacher. PSD is conceptually simple, easy to implement, and generally applicable to various RE models to further improve their performance, without introducing additional parameters or significantly increasing training overheads into the models. It is also a general framework that can be flexibly extended to distilling various types of knowledge, rather than being restricted to soft labels themselves. Extensive experiments on four benchmarking datasets verify the effectiveness and generality of the proposed approach. The code is available at},
journal = {ACM Trans. Inf. Syst.},
month = jun,
articleno = {143},
numpages = {34},
keywords = {Document-level relation extraction, soft-label training regime, online knowledge distillation, self-knowledge distillation}
}

@inproceedings{10.1145/3701571.3701606,
author = {S. Jha, Sanjiv and Ghielmini, Nicol\`{o} and Garcia, Kimberly and Mayer, Simon},
title = {The Spectrum of Proactive Functioning in Digital Companions},
year = {2024},
isbn = {9798400712838},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3701571.3701606},
doi = {10.1145/3701571.3701606},
abstract = {The future of proactive Digital Companions (DCs)—smart agents capable of assisting and protecting their users—lies in their ability to collaborate effectively with users, learn their preferences, and adjust their behavior according to the user’s current state and their environment. To achieve this, DCs must carefully strike a balance between acting autonomously, while keeping users informed to minimize inconveniences, thereby enhancing user acceptance. In this article, we conduct a user survey to enrich the architecture of proactive personal DCs that explores the trade-off between full autonomous functioning and ensuring sufficient user control in various critical and non-critical scenarios. Our findings indicate that most of the participants lean towards having control over the actions of DCs, and will actively collaborate with those systems in everyday situations, in which decisions are not urgent. However, participants would not mind yielding their control to DCs in time-sensitive or urgent scenarios. Furthermore, in our survey, participants highlighted the importance of explaining such actions well. Given the results from our survey, we implemented a system prototype with the enriched architecture of an explainable and unobtrusive proactive DC for a smart home environment. The actions of this DC are not always fully autonomous and follow our survey findings.},
booktitle = {Proceedings of the International Conference on Mobile and Ubiquitous Multimedia},
pages = {331–337},
numpages = {7},
keywords = {Scene Understanding, Proactive, Video, Digital Assistants, Digital Companion},
location = {
},
series = {MUM '24}
}

@inproceedings{10.1145/3675094.3679000,
author = {Fiori, Michele and Civitarese, Gabriele and Bettini, Claudio},
title = {Using Large Language Models to Compare Explainable Models for Smart Home Human Activity Recognition},
year = {2024},
isbn = {9798400710582},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3675094.3679000},
doi = {10.1145/3675094.3679000},
abstract = {Recognizing daily activities with unobtrusive sensors in smart environments enables various healthcare applications. Monitoring how subjects perform activities at home and their changes over time can reveal early symptoms of health issues, such as cognitive decline. Most approaches in this field use deep learning models, which are often seen as black boxes mapping sensor data to activities. However, non-expert users like clinicians need to trust and understand these models' outputs. Thus, eXplainable AI (XAI) methods for Human Activity Recognition have emerged to provide intuitive natural language explanations from these models. Different XAI methods generate different explanations, and their effectiveness is typically evaluated through user surveys, that are often challenging in terms of costs and fairness. This paper proposes an automatic evaluation method using Large Language Models (LLMs) to identify, in a pool of candidates, the best XAI approach for non-expert users. Our preliminary results suggest that LLM evaluation aligns with user surveys.},
booktitle = {Companion of the 2024 on ACM International Joint Conference on Pervasive and Ubiquitous Computing},
pages = {881–884},
numpages = {4},
keywords = {evaluation, human activity recognition, llms, xai},
location = {Melbourne VIC, Australia},
series = {UbiComp '24}
}

@inproceedings{10.1145/3627673.3679544,
author = {Du, Kelvin and Mao, Rui and Xing, Frank and Cambria, Erik},
title = {Explainable Stock Price Movement Prediction using Contrastive Learning},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679544},
doi = {10.1145/3627673.3679544},
abstract = {Predicting stock price movements is a high-stakes task that demands explainability for human decision-makers. A key shortcoming in current methods is treating sub-predictions independently, without learning from accumulated experiences. We propose a novel triplet network for contrastive learning to enhance the explainability of stock movement prediction by considering instances of "integrated textual information and quantitative indicators". We refer to the target past-l-day tweet-price time series as the "anchor instance". Each anchor instance is paired with a "positive instance" characterized by highly correlated return trends yet significant differences across the entire feature space, and a "negative instance" that exhibits similar return trends along with high proximity in the feature space. The model is designed with the objective of (1) minimizing the cross entropy loss between input logits and target, (2) minimizing the distance between the anchor instances and positive instances, and (3) maximizing the distance between the anchor instances and negative instances. Our framework's effectiveness is demonstrated through extensive testing, showing superior performance on stock prediction benchmarks.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {529–537},
numpages = {9},
keywords = {AI, NLP, contrastive learning, explainability, stock price},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@article{10.1145/3652891,
author = {Ge, Yingqiang and Liu, Shuchang and Fu, Zuohui and Tan, Juntao and Li, Zelong and Xu, Shuyuan and Li, Yunqi and Xian, Yikun and Zhang, Yongfeng},
title = {A Survey on Trustworthy Recommender Systems},
year = {2024},
issue_date = {June 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {2},
url = {https://doi.org/10.1145/3652891},
doi = {10.1145/3652891},
abstract = {Recommender systems (RS), serving at the forefront of Human-centered AI, are widely deployed in almost every corner of the web and facilitate the human decision-making process. However, despite their enormous capabilities and potential, RS may also lead to undesired effects on users, items, producers, platforms, or even the society at large, such as compromised user trust due to non-transparency, unfair treatment of different consumers, or producers, privacy concerns due to extensive use of user’s private data for personalization, just to name a few. All of these create an urgent need for Trustworthy Recommender Systems (TRS) so as to mitigate or avoid such adverse impacts and risks. In this survey, we will introduce techniques related to trustworthy recommendation, including but not limited to explainable recommendation, fairness in recommendation, privacy-aware recommendation, robustness in recommendation, user-controllable recommendation, as well as the relationship between these different perspectives in terms of trustworthy recommendation. Through this survey, we hope to deliver readers with a comprehensive view of the research area and raise attention to the community about the importance, existing research achievements, and future research directions on trustworthy recommendation.},
journal = {ACM Trans. Recomm. Syst.},
month = nov,
articleno = {13},
numpages = {68},
keywords = {Recommender Systems, Trustworthiness, Explainability, Fairness, Privacy, Robustness, Controllability}
}

@inproceedings{10.1145/3643916.3644412,
author = {Pepe, Federica and Nardone, Vittoria and Mastropaolo, Antonio and Bavota, Gabriele and Canfora, Gerardo and Di Penta, Massimiliano},
title = {How do Hugging Face Models Document Datasets, Bias, and Licenses? An Empirical Study},
year = {2024},
isbn = {9798400705861},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643916.3644412},
doi = {10.1145/3643916.3644412},
abstract = {Pre-trained Machine Learning (ML) models help to create ML-intensive systems without having to spend conspicuous resources on training a new model from the ground up. However, the lack of transparency for such models could lead to undesired consequences in terms of bias, fairness, trustworthiness of the underlying data, and, potentially even legal implications. Taking as a case study the transformer models hosted by Hugging Face, a popular hub for pre-trained ML models, this paper empirically investigates the transparency of pre-trained transformer models. We look at the extent to which model descriptions (i) specify the datasets being used for their pre-training, (ii) discuss their possible training bias, (iii) declare their license, and whether projects using such models take these licenses into account. Results indicate that pre-trained models still have a limited exposure of their training datasets, possible biases, and adopted licenses. Also, we found several cases of possible licensing violations by client projects. Our findings motivate further research to improve the transparency of ML models, which may result in the definition, generation, and adoption of Artificial Intelligence Bills of Materials.},
booktitle = {Proceedings of the 32nd IEEE/ACM International Conference on Program Comprehension},
pages = {370–381},
numpages = {12},
keywords = {ML-intensive systems, pre-trained models, transparency, bias, and fairness, deep learning, empirical study},
location = {Lisbon, Portugal},
series = {ICPC '24}
}

@proceedings{10.1145/3690407,
title = {CAIBDA '24: Proceedings of the 2024 4th International Conference on Artificial Intelligence, Big Data and Algorithms},
year = {2024},
isbn = {9798400710247},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@inproceedings{10.1145/3649921.3650001,
author = {Zhou, Hongwei and Zhu, Jichen and Mateas, Michael and Wardrip-Fruin, Noah},
title = {The Eyes, the Hands and the Brain: What can Text-to-Image Models Offer for Game Design and Visual Creativity?},
year = {2024},
isbn = {9798400709555},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3649921.3650001},
doi = {10.1145/3649921.3650001},
abstract = {Text-to-image models such as DALL-E, Stable Diffusion, and Midjourney have seen a boom in development and adoption in both commercial and hobbyist spaces. This paper is a theoretical analysis aimed at informing the development of games that help improve critical literacy around text-to-image models. It asks: what assumptions and perspectives do text-to-image models have on visual creativity, and how do we bring that out through games? We propose a theory to differentiate between seeing an image through the expression of color, shapes and lines, and seeing an image through the recognition of concepts and ideas. These two ways of seeing are two different ways of orienting the player/user to their visual creativity. While traditional painting mechanics emphasize the former, text-to-image interfaces emphasize the latter. We deploy this perspective to study games with traditional painting interactions and games with text-to-image interactions. This paper hopes to contribute to design both broadly for games about visual creativity, and narrowly for gameplay with text-to-image models — specifically, how the latter fosters a different type of visual creativity than traditional painting interactions.},
booktitle = {Proceedings of the 19th International Conference on the Foundations of Digital Games},
articleno = {23},
numpages = {13},
keywords = {Game Design, Painting, Stable Diffusion, Text-to-Image, Visual Creativity},
location = {Worcester, MA, USA},
series = {FDG '24}
}

@article{10.1145/3686902,
author = {Do, Hyo Jin and Brachman, Michelle and Dugan, Casey and Johnson, James M. and Lauer, Julia and Rai, Priyanshu and Pan, Qian},
title = {Grounding with Structure: Exploring Design Variations of Grounded Human-AI Collaboration in a Natural Language Interface},
year = {2024},
issue_date = {November 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {CSCW2},
url = {https://doi.org/10.1145/3686902},
doi = {10.1145/3686902},
abstract = {Selecting an effective utterance among countless possibilities that match a user's intention poses a challenge when using natural language interfaces. To address the challenge, we leveraged the principle of least collaborative effort in communication grounding theory and designed three grounded conversational interactions: 1) a grounding interface allows users to start with a provisional input and then invite a conversational agent to complete their input, 2) a multiple grounding interface presents multiple inputs for the user to select from, and 3) a structured grounding interface guides users to write inputs in a structure best understood by the system. We compared our three grounding interfaces to an ungrounded control interface in a crowdsourced study (N=80) using a natural language system that generates small programs. We found that the grounding interfaces reduced cognitive load and improved task performance. The structured grounding interface further reduced speaker change costs and improved technology acceptance, without sacrificing the perception of control. We discuss the implications of designing grounded conversational interactions in natural language systems.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = nov,
articleno = {363},
numpages = {27},
keywords = {conversational grounding, conversational user interface, natural language interface}
}

@proceedings{10.1145/3630138,
title = {PCCNT '23: Proceedings of the 2023 International Conference on Power, Communication, Computing and Networking Technologies},
year = {2023},
isbn = {9781450399951},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Wuhan, China}
}

@proceedings{10.1145/3673277,
title = {CNSCT '24: Proceedings of the 2024 3rd International Conference on Cryptography, Network Security and Communication Technology},
year = {2024},
isbn = {9798400716959},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Harbin, China}
}

@proceedings{10.1145/3654522,
title = {ICIIT '24: Proceedings of the 2024 9th International Conference on Intelligent Information Technology},
year = {2024},
isbn = {9798400716713},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Ho Chi Minh City, Vietnam}
}

@inproceedings{10.1145/3657054.3657077,
author = {Maratsi, Maria Ioanna and Ahmed, Umair and Alexopoulos, Charalampos and Charalabidis, Yannis and Polini, Andrea},
title = {Towards Cross-Domain Linking of Data: A Semantic Mapping of Cultural Heritage Ontologies},
year = {2024},
isbn = {9798400709883},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3657054.3657077},
doi = {10.1145/3657054.3657077},
abstract = {The Linked Open Vocabularies (LOV) registry, designed with the Linked Data principles at core, provides an environment suitable for research which targets domain-specific, but also potentially reusable, information representation. The main purpose of this study is to follow the recommendations pertaining to the utilisation of LOV as a basis for experimentation in order to examine how information within the Cultural Heritage (CH) domain can be improved in terms of reusability and interoperability. The present lack of cross-domain knowledge transfer forms the motivation behind this study, with the aim of facilitating the transition from conventional, domain-specific knowledge representation to reusable and semantically interoperable information. The methodology of this study involves the manual semantic mapping of elements from 12 vocabularies in the LOV registry, reinforced by a small-scale experiment using contemporary large language models (LLMs), particularly GPT, for a preliminary assessment of the mapping process. The findings revealed several key aspects to consider regarding the alignment of semantically adjacent vocabulary elements in the CH domain and beyond, emphasising the potential unveiled by linking domain-focused schemata to standardised, established ones while preserving the conceptual hierarchies inherent to each individual knowledge domain. The contribution of this research pertains to the vision of linking data across different domains by initiating the alignment among representation schemata in CH, with the ultimate aim to expand beyond the boundaries of the in-word knowledge domain, while employing combinatory methodological approaches of technological means and human expertise to facilitate this process.},
booktitle = {Proceedings of the 25th Annual International Conference on Digital Government Research},
pages = {165–176},
numpages = {12},
location = {Taipei, Taiwan},
series = {dg.o '24}
}

@article{10.1145/3698236,
author = {Yin Hong, Kung and Han, Lifeng and Batista-Navarro, Riza and Nenadic, Goran},
title = {CantonMT: Investigating Back-Translation and Model-Switch Mechanisms for Cantonese-English Neural Machine Translation},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {2375-4699},
url = {https://doi.org/10.1145/3698236},
doi = {10.1145/3698236},
abstract = {This paper investigates the development and evaluation of machine translation models from Cantonese to English (and backward), where we propose a novel approach to tackle low-resource language translations. Despite recent improvements in Neural Machine Translation (NMT) models with Transformer-based architectures, Cantonese, a language with over 80 million native speakers, has below-par State-of-the-art commercial translation models due to a lack of resources. The main objectives of the study are to develop a model that can effectively translate Cantonese to English and evaluate it against state-of-the-art commercial models. To achieve this, a new parallel corpus has been created by combining different available corpora online with preprocessing and cleaning. In addition, a monolingual Cantonese dataset has been created through web scraping to aid the synthetic parallel corpus generation. Following the data collection process, several approaches, including fine-tuning models, back-translation, and model switch, have been used. The translation quality of models has been evaluated with multiple quality metrics, including lexicon-based metrics (SacreBLEU and hLEPOR) and embedding-space metrics (COMET and BERTscore). Based on the automatic metrics, the best model is selected and compared against the 2 best commercial translators using a new human evaluation framework HOPES. The best model proposed in this investigation (NLLB-mBART) with model switch mechanisms has reached comparable and even better automatic evaluation scores against State-of-the-art commercial models (Bing and Baidu Translators), with a SacreBLEU score of 16.8 on our test set. Furthermore, an open-source web application has been developed to allow users to translate between Cantonese and English, with the different trained models available for effective comparisons between models from this investigation and users. CantonMT is available at https://github.com/kenrickkung/CantoneseTranslation},
note = {Just Accepted},
journal = {ACM Trans. Asian Low-Resour. Lang. Inf. Process.},
month = oct,
keywords = {Neural Machine Translation, Cantonese-English Translation, Low Resource MT, Data Augmentation, Model Switch Mechanism}
}

@article{10.1109/TASLP.2024.3426287,
author = {Xiao, Yinlong and Ji, Zongcheng and Li, Jianqiang and Han, Mei},
title = {MVT: Chinese NER Using Multi-View Transformer},
year = {2024},
issue_date = {2024},
publisher = {IEEE Press},
volume = {32},
issn = {2329-9290},
url = {https://doi.org/10.1109/TASLP.2024.3426287},
doi = {10.1109/TASLP.2024.3426287},
abstract = {Integrating lexical knowledge in Chinese named entity recognition (NER) has been proven effective. Among the existing methods, Flat-LAttice Transformer (FLAT) has achieved great success in both performance and efficiency. FLAT performs lexical enhancement for each sentence by constructing a flat lattice (i.e., a sequence of tokens including the characters in a sentence and the matched words in a lexicon) and calculating self-attention with a fully-connected structure. However, the different interactions between tokens, which can bring different aspects of semantic information for Chinese NER, cannot be well captured by self-attention with a fully-connected structure. In this paper, we propose a novel Multi-View Transformer (MVT) to effectively capture the different interactions between tokens. We first define four views to capture four different token interaction structures. We then construct a view-aware visible matrix for each view according to the corresponding structure and introduce a view-aware dot-product attention for each view to limit the attention scope by incorporating the corresponding visible matrix. Finally, we design three different MVT variants to fuse the multi-view features at different levels of the Transformer architecture. Experimental results conducted on four public Chinese NER datasets show the effectiveness of the proposed method. Specifically, on the most challenging dataset Weibo, which is in an informal text style, MVT outperforms FLAT in F1 score by 2.56%, and when combined with BERT, MVT outperforms FLAT in F1 score by 3.03%.},
journal = {IEEE/ACM Trans. Audio, Speech and Lang. Proc.},
month = jul,
pages = {3656–3668},
numpages = {13}
}

@inproceedings{10.1145/3664647.3680924,
author = {Lin, Mingkai and Li, Wenzhong and Hong, Xiaobin and Lu, Sanglu},
title = {Scalable Multi-Source Pre-training for Graph Neural Networks},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3680924},
doi = {10.1145/3664647.3680924},
abstract = {Graph Neural Networks (GNNs) have proven effective in various scenarios. A key strategy involves pre-training existing graphs to extract knowledge that can be transferred to improve performance on downstream tasks, reducing the need for extensive labeled data. However, previous works commonly assumed that pre-training and fine-tuning occur in the same or closely related domains. A limitation is that for each individual graph without accessible pre-training data, a GNN must be trained from scratch, imposing high training overhead and hindering the ability of generalization. In this paper, we address the GNN multi-domain pre-training problem, which intends to pre-train a transferable GNN model from heterogeneous multi-source graph domains and then apply it in an unseen one with minor fine-tuning costs. To this end, we propose a scaLA ble Multi-source Pre-training (LAMP) method. For pre-training, LAMP presents a graph dual-distillation approach to distill massive knowledge from various graph domains to form synthetic homogeneous graphs. Simultaneously, high-level meta-knowledge from the synthetic graphs is extracted to train the GNN model, whose capability can be adjusted according to target graph contexts through a co-training modulation architecture. For fine-tuning, LAMP respectively aligns the target graph distribution, graph context, and graph task with the pretext so that the downstream task in the unseen domain can be reshaped to leverage the transferable knowledge efficiently. Extensive experiments on four different graph domain datasets show the superiority of LAMP.},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {1292–1301},
numpages = {10},
keywords = {gnns, multi-source pre-training, unseen domain fine-tuning},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@proceedings{10.1145/3658852,
title = {MOCO '24: Proceedings of the 9th International Conference on Movement and Computing},
year = {2024},
isbn = {9798400709944},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Utrecht, Netherlands}
}

@inproceedings{10.1145/3648188.3678216,
author = {Brooker, Sam},
title = {Computer, Enhance! Augmentation, Ideation, Hypertext},
year = {2024},
isbn = {9798400705953},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3648188.3678216},
doi = {10.1145/3648188.3678216},
abstract = {By ‘augmenting human intellect’ we mean increasing the capability of a man to approach a complex problem or situation, to gain comprehension to suit his particular needs, and to derive solutions to problems.” So wrote Douglas Engelbart in 1962, initiating a narrative of augmentation that runs through hypertext's history. To augment is to amplify something: our ideas, our activities, our thoughts. This paper explores hypertext's relationship with computers as intentional machines, its relationship with artificial and human intelligence, and what role it can play in negotiating between the two.},
booktitle = {Proceedings of the 35th ACM Conference on Hypertext and Social Media},
pages = {193–196},
numpages = {4},
location = {Poznan, Poland},
series = {HT '24}
}

@article{10.1145/3626234,
author = {Lu, Qinghua and Zhu, Liming and Xu, Xiwei and Whittle, Jon and Zowghi, Didar and Jacquet, Aurelie},
title = {Responsible AI Pattern Catalogue: A Collection of Best Practices for AI Governance and Engineering},
year = {2024},
issue_date = {July 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {56},
number = {7},
issn = {0360-0300},
url = {https://doi.org/10.1145/3626234},
doi = {10.1145/3626234},
abstract = {Responsible Artificial Intelligence (RAI) is widely considered as one of the greatest scientific challenges of our time and is key to increase the adoption of Artificial Intelligence (AI). Recently, a number of AI ethics principles frameworks have been published. However, without further guidance on best practices, practitioners are left with nothing much beyond truisms. In addition, significant efforts have been placed at algorithm level rather than system level, mainly focusing on a subset of mathematics-amenable ethical principles, such as fairness. Nevertheless, ethical issues can arise at any step of the development lifecycle, cutting across many AI and non-AI components of systems beyond AI algorithms and models. To operationalize RAI from a system perspective, in this article, we present an RAI Pattern Catalogue based on the results of a multivocal literature review. Rather than staying at the principle or algorithm level, we focus on patterns that AI system stakeholders can undertake in practice to ensure that the developed AI systems are responsible throughout the entire governance and engineering lifecycle. The RAI Pattern Catalogue classifies the patterns into three groups: multi-level governance patterns, trustworthy process patterns, and RAI-by-design product patterns. These patterns provide systematic and actionable guidance for stakeholders to implement RAI.},
journal = {ACM Comput. Surv.},
month = apr,
articleno = {173},
numpages = {35},
keywords = {Responsible AI, ethical AI, trustworthy AI, AI governance, AI engineering, MLOps, software engineering, software architecture, pattern, best practice}
}

@article{10.14778/3659437.3659448,
author = {Deng, Yuhao and Chai, Chengliang and Cao, Lei and Yuan, Qin and Chen, Siyuan and Yu, Yanrui and Sun, Zhaoze and Wang, Junyi and Li, Jiajun and Cao, Ziqi and Jin, Kaisen and Zhang, Chi and Jiang, Yuqing and Zhang, Yuanfang and Wang, Yuping and Yuan, Ye and Wang, Guoren and Tang, Nan},
title = {LakeBench: A Benchmark for Discovering Joinable and Unionable Tables in Data Lakes},
year = {2024},
issue_date = {April 2024},
publisher = {VLDB Endowment},
volume = {17},
number = {8},
issn = {2150-8097},
url = {https://doi.org/10.14778/3659437.3659448},
doi = {10.14778/3659437.3659448},
abstract = {Discovering tables from poorly maintained data lakes is a significant challenge in data management. Two key tasks are identifying joinable and unionable tables, crucial for data integration, analysis, and machine learning. However, there's a lack of a comprehensive benchmark for evaluating existing methods. To address this, we introduce LakeBench, a large-scale table discovery benchmark. It evaluates effectiveness, efficiency, and scalability of table join &amp; union search methods. With over 16 million real tables, LakeBench is 1,600X larger than existing datasets and 100X larger in storage size. It includes synthesized and real queries with ground truth, totaling more than 10 thousand queries - 10X more than used in any existing evaluation. We spent over 7,500 human hours labeling these queries and constructing diverse query categories for thorough evaluation. Our benchmark thoroughly evaluates state-of-the-art table discovery methods, providing insights into their performance and highlighting research opportunities.},
journal = {Proc. VLDB Endow.},
month = apr,
pages = {1925–1938},
numpages = {14}
}

@article{10.1145/3647639,
author = {Lien, Yen-Chieh and Zamani, Hamed and Croft, Bruce},
title = {Generalized Weak Supervision for Neural Information Retrieval},
year = {2024},
issue_date = {September 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {42},
number = {5},
issn = {1046-8188},
url = {https://doi.org/10.1145/3647639},
doi = {10.1145/3647639},
abstract = {Neural ranking models (NRMs) have demonstrated effective performance in several information retrieval (IR) tasks. However, training NRMs often requires large-scale training data, which is difficult and expensive to obtain. To address this issue, one can train NRMs via weak supervision, where a large dataset is automatically generated using an existing ranking model (called the weak labeler) for training NRMs. Weakly supervised NRMs can generalize from the observed data and significantly outperform the weak labeler. This paper generalizes this idea through an iterative re-labeling process, demonstrating that weakly supervised models can iteratively play the role of weak labeler and significantly improve ranking performance without using manually labeled data. The proposed Generalized Weak Supervision (GWS) solution is generic and orthogonal to the ranking model architecture. This paper offers four implementations of GWS: self-labeling, cross-labeling, joint cross- and self-labeling, and greedy multi-labeling. GWS also benefits from a query importance weighting mechanism based on query performance prediction methods to reduce noise in the generated training data. We further draw a theoretical connection between self-labeling and Expectation-Maximization. Our experiments on four retrieval benchmarks suggest that our implementations of GWS lead to substantial improvements compared to weak supervision if the weak labeler is sufficiently reliable.},
journal = {ACM Trans. Inf. Syst.},
month = apr,
articleno = {121},
numpages = {26},
keywords = {Weak supervision, distant supervision, neural ranking models, zero-shot learning, unsupervised learning}
}

@article{10.1145/3639563,
author = {Razniewski, Simon and Arnaout, Hiba and Ghosh, Shrestha and Suchanek, Fabian},
title = {Completeness, Recall, and Negation in Open-world Knowledge Bases: A Survey},
year = {2024},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {56},
number = {6},
issn = {0360-0300},
url = {https://doi.org/10.1145/3639563},
doi = {10.1145/3639563},
abstract = {General-purpose knowledge bases (KBs) are a cornerstone of knowledge-centric AI. Many of them are constructed pragmatically from web sources and are thus far from complete. This poses challenges for the consumption as well as the curation of their content. While several surveys target the problem of completing incomplete KBs, the first problem is arguably to know whether and where the KB is incomplete in the first place, and to which degree. In this survey, we discuss how knowledge about completeness, recall, and negation in KBs can be expressed, extracted, and inferred. We cover (i) the logical foundations of knowledge representation and querying under partial closed-world semantics; (ii) the estimation of this information via statistical patterns; (iii) the extraction of information about recall from KBs and text; (iv) the identification of interesting negative statements; and (v) relaxed notions of relative recall. This survey is targeted at two types of audiences: (1) practitioners who are interested in tracking KB quality, focusing extraction efforts, and building quality-aware downstream applications; and (2) data management, knowledge base, and semantic web researchers who wish to understand the state-of-the-art of knowledge bases beyond the open-world assumption. Consequently, our survey presents both fundamental methodologies and the results that they have produced, and gives practice-oriented recommendations on how to choose between different approaches for a problem at hand.},
journal = {ACM Comput. Surv.},
month = feb,
articleno = {150},
numpages = {42},
keywords = {Knowledge bases, data completeness}
}

@proceedings{10.1145/3626203,
title = {PEARC '24: Practice and Experience in Advanced Research Computing 2024: Human Powered Computing},
year = {2024},
isbn = {9798400704192},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Providence, RI, USA}
}

@proceedings{10.1145/3674225,
title = {PEAI '24: Proceedings of the 2024 International Conference on Power Electronics and Artificial Intelligence},
year = {2024},
isbn = {9798400716638},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Xiamen, China}
}

@proceedings{10.1145/3637494,
title = {CECCT '23: Proceedings of the 2023 International Conference on Electronics, Computers and Communication Technology},
year = {2023},
isbn = {9798400716300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Guilin, China}
}

@inproceedings{10.1145/3643916.3644413,
author = {Dhaouadi, Mouna and Oakes, Bentley James and Famelis, Michalis},
title = {Rationale Dataset and Analysis for the Commit Messages of the Linux Kernel Out-of-Memory Killer},
year = {2024},
isbn = {9798400705861},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3643916.3644413},
doi = {10.1145/3643916.3644413},
abstract = {Code commit messages can contain useful information on why a developer has made a change. However, the presence and structure of rationale in real-world code commit messages is not well studied. Here, we detail the creation of a labelled dataset to analyze the code commit messages of the Linux Kernel Out-Of-Memory Killer component. We study aspects of rationale information, such as presence, temporal evolution, and structure. We find that 98.9% of commits in our dataset contain sentences with rationale information, and that experienced developers report rationale in about 60% of the sentences in their commits. We report on the challenges we faced and provide examples for our labelling.},
booktitle = {Proceedings of the 32nd IEEE/ACM International Conference on Program Comprehension},
pages = {415–425},
numpages = {11},
keywords = {developer rationale, dataset, Linux kernel, commit messages},
location = {Lisbon, Portugal},
series = {ICPC '24}
}

@proceedings{10.1145/3640771,
title = {ISCAI '23: Proceedings of the 2023 2nd International Symposium on Computing and Artificial Intelligence},
year = {2023},
isbn = {9798400708954},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Shanghai, China}
}

@inproceedings{10.1145/3664647.3681389,
author = {Zhao, Shengwei and Xu, Linhai and Liu, Yuying and Du, Shaoyi},
title = {Multi-grained Correspondence Learning of Audio-language Models for Few-shot Audio Recognition},
year = {2024},
isbn = {9798400706868},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664647.3681389},
doi = {10.1145/3664647.3681389},
abstract = {Large-scale pre-trained audio-language models excel in general multi-modal representation, facilitating their adaptation to downstream audio recognition tasks in a data-efficient manner. However, existing few-shot audio recognition methods based on audio-language models primarily focus on learning coarse-grained correlations, which are not sufficient to capture the intricate matching patterns between the multi-level information of audio and the diverse characteristics of category concepts. To address this gap, we propose multi-grained correspondence learning for bootstrapping audio-language models to improve audio recognition with few training samples. This approach leverages generative models to enrich multi-modal representation learning, mining the multi-level information of audio alongside the diverse characteristics of category concepts. Multi-grained matching patterns are then established through multi-grained key-value cache and multi-grained cross-modal contrast, enhancing the alignment between audio and category concepts. Additionally, we incorporate optimal transport to tackle temporal misalignment and semantic intersection issues in fine-grained correspondence learning, enabling flexible fine-grained matching. Our method achieves state-of-the-art results on multiple benchmark datasets for few-shot audio recognition, with comprehensive ablation experiments validating its effectiveness.},
booktitle = {Proceedings of the 32nd ACM International Conference on Multimedia},
pages = {9244–9252},
numpages = {9},
keywords = {audio-language models, few-shot audio recognition, multi-grained correspondence learning, optimal transport},
location = {Melbourne VIC, Australia},
series = {MM '24}
}

@inproceedings{10.1145/3616855.3635822,
author = {Kaiser, Magdalena and Saha Roy, Rishiraj and Weikum, Gerhard},
title = {Robust Training for Conversational Question Answering Models with Reinforced Reformulation Generation},
year = {2024},
isbn = {9798400703713},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3616855.3635822},
doi = {10.1145/3616855.3635822},
abstract = {Models for conversational question answering (ConvQA) over knowledge graphs (KGs) are usually trained and tested on benchmarks of gold QA pairs. This implies that training is limited to surface forms seen in the respective datasets, and evaluation is on a small set of held-out questions. Through our proposed framework REIGN, we take several steps to remedy this restricted learning setup. First, we systematically generate reformulations of training questions to increase robustness of models to surface form variations. This is a particularly challenging problem, given the incomplete nature of such questions. Second, we guide ConvQA models towards higher performance by feeding it only those reformulations that help improve their answering quality, using deep reinforcement learning. Third, we demonstrate the viability of training major model components on one benchmark and applying them zero-shot to another. Finally, for a rigorous evaluation of robustness for trained models, we use and release large numbers of diverse reformulations generated by prompting ChatGPT for benchmark test sets (resulting in 20x increase in sizes). Our findings show that ConvQA models with robust training via reformulations significantly outperform those with standard training from gold QA pairs only.},
booktitle = {Proceedings of the 17th ACM International Conference on Web Search and Data Mining},
pages = {322–331},
numpages = {10},
keywords = {conversations, knowledge graphs, question answering},
location = {Merida, Mexico},
series = {WSDM '24}
}

@article{10.1145/3651313,
author = {Denisenko, Natalia and Zhang, Youzhi and Pulice, Chiara and Bhattasali, Shohini and Jajodia, Sushil and Resnik, Philip and Subrahmanian, V.S.},
title = {A Psycholinguistics-inspired Method to Counter IP Theft Using Fake Documents},
year = {2024},
issue_date = {June 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {2},
issn = {2158-656X},
url = {https://doi.org/10.1145/3651313},
doi = {10.1145/3651313},
abstract = {Intellectual property (IP) theft is a growing problem. We build on prior work to deter IP theft by generating n fake versions of a technical document so a thief has to expend time and effort in identifying the correct document. Our new SbFAKE framework proposes, for the first time, a novel combination of language processing, optimization, and the psycholinguistic concept of surprisal to generate a set of such fakes. We start by combining psycholinguistic-based surprisal scores and optimization to generate two bilevel surprisal optimization problems (an Explicit one and a simpler Implicit one) whose solutions correspond directly to the desired set of fakes. As bilevel problems are usually hard to solve, we then show that these two bilevel surprisal optimization problems can each be reduced to equivalent surprisal-based linear programs. We performed detailed parameter tuning experiments and identified the best parameters for each of these algorithms. We then tested these two variants of SbFAKE (with their best parameter settings) against the best performing prior work in the field. Our experiments show that SbFAKE is able to more effectively generate convincing fakes than past work. In addition, we show that replacing words in an original document with words having similar surprisal scores generates greater levels of deception.},
journal = {ACM Trans. Manage. Inf. Syst.},
month = jun,
articleno = {7},
numpages = {25},
keywords = {AI for security, fake document generation}
}

@article{10.1145/3689906,
author = {Shukla, Shiv Shankar Prasad and Singh, Maheshwari Prasad},
title = {Stacked Classification Approach using Optimized Hybrid Deep Learning Model for Early Prediction of Behaviour Changes on Social Media},
year = {2024},
issue_date = {November 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {11},
issn = {2375-4699},
url = {https://doi.org/10.1145/3689906},
doi = {10.1145/3689906},
abstract = {Detecting signs of suicidal thoughts on social media is paramount for preventing suicides, given the platforms' role as primary outlets for emotional expression. Traditional embedding techniques focus solely on semantic analysis and lack the sentiment analysis essential for capturing emotions. This limitation poses challenges in developing high-accuracy models. Additionally, previous studies often rely on a single dataset, further constraining their effectiveness. To overcome these challenges, this study proposes an innovative approach that integrates embedding techniques such as BERT, which offers semantic and syntactic analysis of the posts, with sentiment analysis provided by VADER scores extracted from the VADER sentiment analysis tool. The identified features are then input into the proposed optimised hybrid deep learning model, specifically the Bi-GRU and Attention incorporated with Stacked or Stacking Classifier (Decision Tree, Random Forest, Gradient Boost, as the base classifier and XGBoost as meta classifier), which undergoes optimisation using the grid search technique to enhance detection capabilities. In evaluations, the model achieved an impressive accuracy and F1-score of 98% on the Reddit dataset and 97% on the twitter (formally known as X) dataset. The research evaluates the efficacy of several machine learning models, encompassing Decision Trees, Random Forests, Gradient Boosting, and XGBoost. Moreover, it examines sophisticated models like LSTM with Attention, Bi-LSTM with Attention, and Bi-GRU with Attention, augmented with word embeddings such as BERT, MUSE, and fastText, alongside the fusion of sentiment VADER score. These results emphasise the promise of a holistic strategy that combines advanced feature embedding techniques with semantic features, showcasing a notably efficient detection of suicidal ideation on social media.},
journal = {ACM Trans. Asian Low-Resour. Lang. Inf. Process.},
month = nov,
articleno = {159},
numpages = {22},
keywords = {Bi-GRU, Attention, Stacked Classifier, XGBoost, Random Forest, Natural Language Processing, Suicidal Ideation}
}

@inproceedings{10.1145/3589335.3641300,
author = {Ding, Yujuan and Fan, Wenqi and Huang, Xiao and Li, Qing},
title = {Large Language Models for Graph Learning},
year = {2024},
isbn = {9798400701726},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589335.3641300},
doi = {10.1145/3589335.3641300},
abstract = {Graphs are widely applied to encode entities with various relations in web applications such as social media and recommender systems. Meanwhile, graph learning-based technologies, such as graph neural networks, are demanding to support the analysis, understanding, and usage of the data in graph structures. Recently, the boom of language foundation models, especially Large Language Models (LLMs), has advanced several main research areas in artificial intelligence, such as natural language processing, graph mining, and recommender systems. The synergy between LLMs and graph learning holds great potential to prompt the research in both areas. For example, LLMs can facilitate existing graph learning models by providing high-quality textual features for entities and edges, or enhancing the graph data with encoded knowledge and information. It may also innovate with novel problem formulations on graph-related tasks. Due to the research significance as well as the potential, the convergent area of LLMs and graph learning has attracted considerable research attention. Therefore, we propose to hold the workshop Large Language Models for Graph Learning at WWW'24, in order to provide a venue to gather researchers in academia and practitioners in the industry to present the recent progress on relevant topics and exchange their critical insights.},
booktitle = {Companion Proceedings of the ACM Web Conference 2024},
pages = {1643–1646},
numpages = {4},
keywords = {fine-tuning, graph learning, in-context learning, large language models, pre-training, prompting},
location = {Singapore, Singapore},
series = {WWW '24}
}

@proceedings{10.1145/3656766,
title = {ICBAR '23: Proceedings of the 2023 3rd International Conference on Big Data, Artificial Intelligence and Risk Management},
year = {2023},
isbn = {9798400716478},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Chengdu, China}
}

@article{10.1145/3686981,
author = {Zhu, Mengxiao and Wang, Xin and Wang, Xiantao and Chen, Zihang and Huang, Wei},
title = {Application of Prompt Learning Models in Identifying the Collaborative Problem Solving Skills in an Online Task},
year = {2024},
issue_date = {November 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {CSCW2},
url = {https://doi.org/10.1145/3686981},
doi = {10.1145/3686981},
abstract = {Collaborative problem solving (CPS) competence is considered one of the essential 21st-century skills. To facilitate the assessment and learning of CPS competence, researchers have proposed a series of frameworks to conceptualize CPS and explored ways to make sense of the complex processes involved in collaborative problem solving. However, encoding explicit behaviors into subskills within the frameworks of CPS skills is still a challenging task. Traditional studies have relied on manual coding to decipher behavioral data for CPS, but such coding methods can be very time-consuming and cannot support real-time analyses. Scholars have begun to explore approaches for constructing automatic coding models. Nevertheless, the existing models built using machine learning or deep learning techniques depend on a large amount of training data and have relatively low accuracy. To address these problems, this paper proposes a prompt-based learning pre-trained model. The model can achieve high performance even with limited training data. In this study, three experiments were conducted, and the results showed that our model not only produced the highest accuracy, macro F1 score, and kappa values on large training sets, but also performed the best on small training sets of the CPS behavioral data. The application of the proposed prompt-based learning pre-trained model contributes to the CPS skills coding task and can also be used for other CSCW coding tasks to replace manual coding.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = nov,
articleno = {442},
numpages = {23},
keywords = {automatic coding, collaborative problem solving, natural language processing, prompt-based learning}
}

@proceedings{10.1145/3661455,
title = {PDC '24: Proceedings of the Participatory Design Conference 2024: Exploratory Papers and Workshops - Volume 2},
year = {2024},
isbn = {9798400706547},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
location = {Sibu, Malaysia}
}

@proceedings{10.1145/3674029,
title = {ICMLT '24: Proceedings of the 2024 9th International Conference on Machine Learning Technologies},
year = {2024},
isbn = {9798400716379},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Oslo, Norway}
}

@inproceedings{10.1145/3627673.3679662,
author = {Balsebre, Pasquale and Huang, Weiming and Cong, Gao and Li, Yi},
title = {City Foundation Models for Learning General Purpose Representations from OpenStreetMap},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679662},
doi = {10.1145/3627673.3679662},
abstract = {Pre-trained Foundation Models (PFMs) have ushered in a paradigm-shift in AI, due to their ability to learn general-purpose representations that can be readily employed in downstream tasks. While PFMs have been successfully adopted in various fields such as NLP and Computer Vision, their capacity in handling geospatial data remains limited. This can be attributed to the intrinsic heterogeneity of such data, which encompasses different types, including points, segments and regions, as well as multiple information modalities. The proliferation of Volunteered Geographic Information initiatives, like OpenStreetMap, unveils a promising opportunity to bridge this gap. In this paper, we present CityFM, a self-supervised framework to train a foundation model within a selected geographical area. CityFM relies solely on open data from OSM, and produces multimodal representations, incorporating spatial, visual, and textual information. We analyse the entity representations generated by our foundation models from a qualitative perspective, and conduct experiments on road, building, and region-level downstream tasks. In all the experiments, CityFM achieves performance superior to, or on par with, application-specific algorithms.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {87–97},
numpages = {11},
keywords = {contrastive learning, foundation models, geospatial data},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@proceedings{10.1145/3643915,
title = {SEAMS '24: Proceedings of the 19th International Symposium on Software Engineering for Adaptive and Self-Managing Systems},
year = {2024},
isbn = {9798400705854},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Lisbon, AA, Portugal}
}

@inproceedings{10.1145/3652620.3688197,
author = {Silva Mercado, Jonathan},
title = {AI Assisted Domain Modeling Explainability and Traceability},
year = {2024},
isbn = {9798400706226},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652620.3688197},
doi = {10.1145/3652620.3688197},
abstract = {Domain Models are abstract representations of selected elements in a domain that is created in a collaborative process between domain and modeler experts. The participants share domain knowledge to conceptualize and reason about the elements that will create the domain models. Through this exchange, a comprehensive and accurate representation of the domain is achieved, ensuring that the model captures the relevant aspects and relationships in the domain. Research in Artificial Intelligence (AI) has explored various methods to assist in the creation of domain models from text using Natural Language Processing (NLP) and Machine Learning (ML). Recent advancements with Large Language Models (LLMs) have shown that it is possible to create domain models using prompting techniques; however, the generated domain models contain errors and remain constrained by the performance of the LLM used.Despite the impressive capabilities of LLMs to create domain models, it is evident that it does not address the needs of domain and modelers experts that participate in the creation of domain models. Every AI technique has its advantages and limitations that must be integrated with human feedback in a collaboration process. Therefore, we propose an approach that incorporates human-AI collaboration supported by AI assistants that follows a dialogue approach to understand the users needs and purpose to suggest relevant models. Our proposal combines symbolic and subsymbolic AI techniques with explainability and traceability of the decisions that assist to create domain models that are relevant for the users.},
booktitle = {Proceedings of the ACM/IEEE 27th International Conference on Model Driven Engineering Languages and Systems},
pages = {130–135},
numpages = {6},
keywords = {domain modeling, large language models, uncertainty, explainability, traceability},
location = {Linz, Austria},
series = {MODELS Companion '24}
}

@inproceedings{10.1145/3679431.3679514,
author = {Gao, Xiang and Zhou, Yuanchao},
title = {Exploring Computational Visual Interfaces for Artificial Intelligence Language Modeling User Experience among College Students: A Rooted Theoretical Approach},
year = {2024},
isbn = {9798400709951},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3679431.3679514},
doi = {10.1145/3679431.3679514},
abstract = {Artificial Intelligence (AI) is an emerging technology with the aim of developing intelligent applications that have broad applications in various fields such as healthcare, education, and design. AI design research is presently in an exploratory phase, yet its influence on computer vision interfaces for subjective user experience is becoming increasingly significant. Focused on Chinese university students, the research delves into AI user experience, emphasizing NLP, HCI, and SU. Data was collected via surveys and interviews, with deep learning techniques aiding data processing. A substantial volume of user data was gathered through user surveys and in-depth interviews, with deep learning techniques employed for data preprocessing and feature extraction. Results show a preference for personalized services and data mining in interface design, while technical features and operational fluency are priorities in programming. Enhancing HCI design can improve operational efficiency and meet individual needs, bolstered by clear visual interfaces and HCI technologies, thus enhancing overall user experience quality and effectiveness.},
booktitle = {Proceedings of the 2024 3rd International Symposium on Control Engineering and Robotics},
pages = {516–522},
numpages = {7},
location = {Changsha, China},
series = {ISCER '24}
}

@proceedings{10.1145/3655693,
title = {EICC '24: Proceedings of the 2024 European Interdisciplinary Cybersecurity Conference},
year = {2024},
isbn = {9798400716515},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Xanthi, Greece}
}

@proceedings{10.1145/3691016,
title = {IPICE '24: Proceedings of the 2024 International Conference on Image Processing, Intelligent Control and Computer Engineering},
year = {2024},
isbn = {9798400710285},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Qingdao, China}
}

@proceedings{10.1145/3672406,
title = {IMXw '24: Proceedings of the 2024 ACM International Conference on Interactive Media Experiences Workshops},
year = {2024},
isbn = {9798400717949},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Stockholm, Sweden}
}

@article{10.1109/TASLP.2024.3497586,
author = {Ma, Hao and Peng, Zhiyuan and Li, Xu and Shao, Mingjie and Wu, Xixin and Liu, Ju},
title = {CLAPSep: Leveraging Contrastive Pre-Trained Model for Multi-Modal Query-Conditioned Target Sound Extraction},
year = {2024},
issue_date = {2024},
publisher = {IEEE Press},
volume = {32},
issn = {2329-9290},
url = {https://doi.org/10.1109/TASLP.2024.3497586},
doi = {10.1109/TASLP.2024.3497586},
abstract = {Universal sound separation (USS) aims to extract arbitrary types of sounds from real-world recordings. This can be achieved by language-queried target sound extraction (TSE), which typically consists of two components: a query network that converts user queries into conditional embeddings, and a separation network that extracts the target sound accordingly. Existing methods commonly train models from scratch. As a consequence, substantial data and computational resources are required to make the randomly initialized model comprehend sound events and perform separation accordingly. In this paper, we propose to integrate pre-trained models into TSE models to address the above issue. To be specific, we tailor and adapt the powerful contrastive language-audio pre-trained model (CLAP) for USS, denoted as CLAPSep. CLAPSep also accepts flexible user inputs, taking both positive and negative user prompts of uni- and/or multi-modalities for target sound extraction. These key features of CLAPSep can not only enhance the extraction performance but also improve the versatility of its application. We provide extensive experiments on 5 diverse datasets to demonstrate the superior performance and zero- and few-shot generalizability of our proposed CLAPSep with fast training convergence, surpassing previous methods by a significant margin. Full codes and some audio examples are released for reproduction and evaluation.},
journal = {IEEE/ACM Trans. Audio, Speech and Lang. Proc.},
month = nov,
pages = {4945–4960},
numpages = {16}
}

@article{10.1145/3700890,
author = {Jannach, Dietmar and Zanker, Markus},
title = {A Survey on Intent-aware Recommender Systems},
year = {2024},
issue_date = {June 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
number = {2},
url = {https://doi.org/10.1145/3700890},
doi = {10.1145/3700890},
abstract = {Many modern online services feature personalized recommendations. A central challenge when providing such recommendations is that the reason why an individual user accesses the service may change from visit to visit or even during an ongoing usage session. To be effective, a recommender system should therefore aim to take the users’ probable intent of using the service at a certain point in time into account. In recent years, researchers have thus started to address this challenge by incorporating intent-awareness into recommender systems. Correspondingly, a number of technical approaches were put forward, including diversification techniques, intent prediction models, or latent intent modeling approaches. In this article, we survey and categorize existing approaches to building the next generation of Intent-Aware Recommender Systems (IARS). Based on an analysis of current evaluation practices, we outline open gaps and possible future directions in this area, which in particular include the consideration of additional interaction signals and contextual information to further improve the effectiveness of such systems.},
journal = {ACM Trans. Recomm. Syst.},
month = dec,
articleno = {23},
numpages = {32},
keywords = {Recommender systems, intent-awareness, survey}
}

@inproceedings{10.1145/3678717.3691305,
author = {Yankov, Dragomir and Karatzoglou, Antonios and Zhang, Chiqun and Evans, Mike and Dhifallah, Oussama and Sabau, Florin and Najafabadi, Maryam Mousaarab and Predovic, Goran},
title = {Routing As a Relevance System},
year = {2024},
isbn = {9798400711077},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3678717.3691305},
doi = {10.1145/3678717.3691305},
abstract = {Searching for directions is one of the most used features of map applications. This paper shares our vision on how Direction Services will change, with LLM-based chat assistants rapidly becoming an integral part of the underlying path search mechanism. We anticipate an influx of more complex, conversational route planning sessions, where users colloquially describe route-related preferences as if they were talking to their personal chauffeur. We envision future systems able to support asks like "avoid the East River tunnel", "take the bridge", or "find me a scenic route around the lake, oh and by the way, I'm driving the EV today". At present, popular map search engines fail in even simple, yet very natural preferences, such as 'take me from A to B via road C'. The reason is mainly twofold, inadequate query understanding and lack of mechanisms in routing to satisfy this type of preferences. The here proposed solution is a novel treatment of routing, one which casts it into an end-to-end 2-layer relevance framework. The framework is capable of performing query understanding for route queries with complex preferences and intents. It treats routes as richly annotated documents and the routing engine, in addition to performing optimization, acts (1) as a retriever of route documents that match the user intent and (2) as a ranker that ranks route candidates not just by a simple time-distance cost model, but by inferring the importance of many variables, some derived from explicitly stated preferences and others identified as relevant through data-driven methodology.},
booktitle = {Proceedings of the 32nd ACM International Conference on Advances in Geographic Information Systems},
pages = {613–616},
numpages = {4},
keywords = {Optimal Path, Query Understanding, Ranking, Retrieval, Routing},
location = {Atlanta, GA, USA},
series = {SIGSPATIAL '24}
}

@inproceedings{10.1145/3641343.3641422,
author = {Wang, Meilin},
title = {Design of Automatic Translation System for English for Special Purpose in Agriculture Based on Neural Machine Translation},
year = {2024},
isbn = {9798400716775},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641343.3641422},
doi = {10.1145/3641343.3641422},
abstract = {Agricultural terms have some unique characteristics, which make them need special treatment in machine translation. Agriculture is a highly specialized field, with a large number of specialized terms and concepts, which are not common in general texts. Neural Machine Translation (NMT) technology has made remarkable progress in recent years, and has been successful in various fields. The purpose of this thesis is to design and develop an automatic English translation system for special purposes in agricultural field based on NMT, so as to meet the translation needs of professional knowledge in agricultural field. Based on the embedded environment, the system software is designed. By using the sample training mechanism of deep learning algorithm and combining the characteristics of agricultural terminology translation, the system interaction and translation data are trained separately. By redesigning the interaction hardware, the hardware structure of the translation system is completely defined. The practical application test results with the comparison system show that the translation system designed by the deep learning algorithm has the characteristics of high efficiency, high translation accuracy and good stability in the interactive translation of agricultural terms.},
booktitle = {Proceedings of the 3rd International Conference on Electronic Information Technology and Smart Agriculture},
pages = {390–394},
numpages = {5},
keywords = {Agriculture, Automatic Translation System, Neural Machine Translation},
location = {Sanya, China},
series = {ICEITSA '23}
}

@inproceedings{10.1145/3658644.3690321,
author = {Zhan, Yuxia and Meng, Yan and Zhou, Lu and Xiong, Yichang and Zhang, Xiaokuan and Ma, Lichuan and Chen, Guoxing and Pei, Qingqi and Zhu, Haojin},
title = {VPVet: Vetting Privacy Policies of Virtual Reality Apps},
year = {2024},
isbn = {9798400706363},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3658644.3690321},
doi = {10.1145/3658644.3690321},
abstract = {Virtual reality (VR) apps can harvest a wider range of user data than web/mobile apps running on personal computers or smartphones. Existing law and privacy regulations emphasize that VR developers should inform users of what data are collected/used/shared (CUS) through privacy policies. However, privacy policies in the VR ecosystem are still in their early stages, and many developers fail to write appropriate privacy policies that comply with regulations and meet user expectations. In this paper, we propose VPVet to automatically vet privacy policy compliance issues for VR apps. VPVet first analyzes the availability and completeness of a VR privacy policy and then refines its analysis based on three key criteria: granularity, minimization, and consistency of CUS statements. Our study establishes the first and currently largest VR privacy policy dataset named VRPP, consisting of privacy policies of 11,923 different VR apps from 10 mainstream platforms. Our vetting results reveal severe privacy issues within the VR ecosystem, including the limited availability and poor quality of privacy policies, along with their coarse granularity, lack of adaptation to VR traits and the inconsistency between CUS statements in privacy policies and their actual behaviors. We open-source VPVet system along with our findings at repository https://github.com/kalamoo/PPAudit, aiming to raise awareness within the VR community and pave the way for further research in this field.},
booktitle = {Proceedings of the 2024 on ACM SIGSAC Conference on Computer and Communications Security},
pages = {1746–1760},
numpages = {15},
keywords = {privacy policy analysis, vetting, virtual reality applications},
location = {Salt Lake City, UT, USA},
series = {CCS '24}
}

@proceedings{10.1145/3603273,
title = {AAIA '23: Proceedings of the 2023 International Conference on Advances in Artificial Intelligence and Applications},
year = {2023},
isbn = {9798400708268},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Wuhan, China}
}

@proceedings{10.1145/3676581,
title = {CCCAI '24: Proceedings of the 2024 2nd International Conference on Communications, Computing and Artificial Intelligence},
year = {2024},
isbn = {9798400716898},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Jeju, Republic of Korea}
}

@proceedings{10.1145/3661725,
title = {CMLDS '24: Proceedings of the International Conference on Computing, Machine Learning and Data Science},
year = {2024},
isbn = {9798400716393},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Singapore, Singapore}
}

@proceedings{10.1145/3631908,
title = {ICACS '23: Proceedings of the 7th International Conference on Algorithms, Computing and Systems},
year = {2023},
isbn = {9798400709098},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Larissa, Greece}
}

@article{10.14778/3659437.3659461,
author = {Kayali, Moe and Lykov, Anton and Fountalis, Ilias and Vasiloglou, Nikolaos and Olteanu, Dan and Suciu, Dan},
title = {Chorus: Foundation Models for Unified Data Discovery and Exploration},
year = {2024},
issue_date = {April 2024},
publisher = {VLDB Endowment},
volume = {17},
number = {8},
issn = {2150-8097},
url = {https://doi.org/10.14778/3659437.3659461},
doi = {10.14778/3659437.3659461},
abstract = {We apply foundation models to data discovery and exploration tasks. Foundation models are large language models (LLMS) that show promising performance on a range of diverse tasks unrelated to their training. We show that these models are highly applicable to the data discovery and data exploration domain. When carefully used, they have superior capability on three representative tasks: table-class detection, column-type annotation and join-column prediction. On all three tasks, we show that a foundation-model-based approach outperforms the task-specific models and so the state of the art. Further, our approach often surpasses human-expert task performance. We investigate the fundamental characteristics of this approach including generalizability to several foundation models and the impact of non-determinism on the outputs. All in all, this suggests a future direction in which disparate data management tasks can be unified under foundation models.},
journal = {Proc. VLDB Endow.},
month = apr,
pages = {2104–2114},
numpages = {11}
}

@article{10.1145/3643885,
author = {Wan, Qizhi and Wan, Changxuan and Xiao, Keli and Xiong, Hui and Liu, Dexi and Liu, Xiping and Hu, Rong},
title = {Token-Event-Role Structure-Based Multi-Channel Document-Level Event Extraction},
year = {2024},
issue_date = {July 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {42},
number = {4},
issn = {1046-8188},
url = {https://doi.org/10.1145/3643885},
doi = {10.1145/3643885},
abstract = {Document-level event extraction is a long-standing challenging information retrieval problem involving a sequence of sub-tasks: entity extraction, event type judgment, and event type-specific multi-event extraction. However, addressing the problem as multiple learning tasks leads to increased model complexity. Also, existing methods insufficiently utilize the correlation of entities crossing different events, resulting in limited event extraction performance. This article introduces a novel framework for document-level event extraction, incorporating a new data structure called token-event-role and a multi-channel argument role prediction module. The proposed data structure enables our model to uncover the primary role of tokens in multiple events, facilitating a more comprehensive understanding of event relationships. By leveraging the multi-channel prediction module, we transform entity and multi-event extraction into a single task of predicting token–event pairs, thereby reducing the overall parameter size and enhancing model efficiency. The results demonstrate that our approach outperforms the state-of-the-art method by 9.5 percentage points in terms of the F1 score, highlighting its superior performance in event extraction. Furthermore, an ablation study confirms the significant value of the proposed data structure in improving event extraction tasks, further validating its importance in enhancing the overall performance of the framework.},
journal = {ACM Trans. Inf. Syst.},
month = mar,
articleno = {104},
numpages = {27},
keywords = {Document-level event extraction, token-event-role data structure, joint learning, multi-channel, neural network}
}

@proceedings{10.1145/3644116,
title = {ISAIMS '23: Proceedings of the 2023 4th International Symposium on Artificial Intelligence for Medicine Science},
year = {2023},
isbn = {9798400708138},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Chengdu, China}
}

@proceedings{10.1145/3674805,
title = {ESEM '24: Proceedings of the 18th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement},
year = {2024},
isbn = {9798400710476},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Barcelona, Spain}
}

@proceedings{10.1145/3689236,
title = {ICCSIE '24: Proceedings of the 2024 9th International Conference on Cyber Security and Information Engineering},
year = {2024},
isbn = {9798400718137},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@article{10.1109/TASLP.2024.3490373,
author = {Li, Ren and Xiao, Qiao and Yang, Jianxi and Zhang, Luyi and Chen, Yu},
title = {MRC-PASCL: A Few-Shot Machine Reading Comprehension Approach via Post-Training and Answer Span-Oriented Contrastive Learning},
year = {2024},
issue_date = {2024},
publisher = {IEEE Press},
volume = {32},
issn = {2329-9290},
url = {https://doi.org/10.1109/TASLP.2024.3490373},
doi = {10.1109/TASLP.2024.3490373},
abstract = {The rapid development of pre-trained language models (PLMs) has significantly enhanced the performance of machine reading comprehension (MRC). Nevertheless, the traditional fine-tuning approaches necessitate extensive labeled data. MRC remains a challenging task in the few-shot settings or low-resource scenarios. This study proposes a novel few-shot MRC approach via post-training and answer span-oriented contrastive learning, termed MRC-PASCL. Specifically, in the post-training module, a novel noun-entity-aware data selection and generation strategy is proposed according to characteristics of MRC task and data, focusing on masking nouns and named entities in the context. In terms of fine-tuning, the proposed answer span-oriented contrastive learning manner selects spans around the golden answers as negative examples, and performs multi-task learning together with the standard MRC answer prediction task. Experimental results show that MRC-PASCL outperforms the PLMs-based baseline models and the 7B and 13B large language models (LLMs) cross most MRQA 2019 datasets. Further analyses show that our approach achieves better inference efficiency with lower computational resource requirement. The analysis results also indicate that the proposed method can better adapt to the domain-specific scenarios.},
journal = {IEEE/ACM Trans. Audio, Speech and Lang. Proc.},
month = oct,
pages = {4838–4849},
numpages = {12}
}

@inproceedings{10.1145/3695080.3695170,
author = {Zhao, Yu and Ding, Zhaoyun and Wang, Fei and Zou, Longyin and Nian, Aixin},
title = {Integrating Entities in Text Summarization: A Review},
year = {2024},
isbn = {9798400710223},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3695080.3695170},
doi = {10.1145/3695080.3695170},
abstract = {Advancements in pretrained and large language models have significantly propelled the development of text summarization in recent years, making the generation of fluent and readable text possible. However, issues related to factuality, faithfulness, and controllability have limited the application of this technology in specific contexts such as news, medical, and reviews, hindering its adoption. To address these challenges, the scholarly attention has increasingly focused on more effective and feasible summarization methods, particularly emphasizing the enhancement effects of entities in text summarization. Although a growing number of studies have integrated entities as key elements within summarization systems, there is still a lack of comprehensive reviews on the methods for integrating entities into text summarization systems, analyzing the challenges faced and anticipating future research directions. Therefore, we have systematically organized and thoroughly examined recent studies in this area. We categorize various entity integration techniques according to the stages of the text summarization process, conduct an in-depth analysis and comprehensive evaluation of these techniques at each stage. Based on our findings, we identify the current effects and limitations of research on the integration of entity analysis with text summarization and discuss potential future research directions.},
booktitle = {Proceedings of the 2024 International Conference on Cloud Computing and Big Data},
pages = {521–528},
numpages = {8},
location = {Dali, China},
series = {ICCBD '24}
}

@proceedings{10.1145/3646547,
title = {IMC '24: Proceedings of the 2024 ACM on Internet Measurement Conference},
year = {2024},
isbn = {9798400705922},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to ACM IMC 2024 in Madrid!We are thrilled to host you in the vibrant city of Madrid, a historical and cultural hub, for this year's ACM Internet Measurement Conference. As we gather in the iconic Espacio Telef\'{o}nica to discuss the latest advances in network measurement, we continue to face evolving challenges and opportunities in this dynamic research field. IMC 2024 maintains a strong focus on reproducibility and data sharing, aiming to foster transparency and collaboration within our community.This year, we are privileged to have an exceptional program curated by our Program Chairs, Dave Levin (University of Maryland) and Cristel Pelsser (KU Louvain). Their hard work, along with contributions from all members of the organizing committee, ensures a high-quality program with 55 insightful paper presentations, 45 posters, and discussions, covering topics from Cellular and wireless networks to Security &amp; Privacy. The technical program is enriched by an opening keynote from Prof. Alan Mislove and several social and cultural activities, including a guided tour of the renowned art collection at the Thyssen-Bornemisza Museum. Together, these activities will not only advance our understanding of network performance, structure, and behavior but also foster new collaborations among community members.We are particularly proud of our efforts to promote diversity and inclusivity at IMC 2024, offering student travel grants, diversity grants, and expanding outreach to members of our global community, particularly in developing countries. These initiatives aim to ensure a more diverse, inclusive, and representative group of participants, enriching the conference with varied perspectives.},
location = {Madrid, Spain}
}

@article{10.1145/3688398,
author = {Gabbolini, Giovanni and Bridge, Derek},
title = {Surveying More Than Two Decades of Music Information Retrieval Research on Playlists},
year = {2024},
issue_date = {December 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {15},
number = {6},
issn = {2157-6904},
url = {https://doi.org/10.1145/3688398},
doi = {10.1145/3688398},
abstract = {In this article, we present an extensive survey of music information retrieval (MIR) research into music playlists. Our survey spans more than 20 years, and includes around 300 papers about playlists, with over 70 supporting sources. It is the first survey that is self-contained in the sense that it combines all the different MIR research into playlists. It embraces topics such as algorithms for automatic generation, for automatic continuation, for assisting with manual generation, for tagging and for captioning. It looks at manually constructed playlists, both those that are constructed for and by individuals and those constructed in collaboration with others. It covers ground-breaking research into enhancing playlists by cross-fading consecutive songs and by interleaving consecutive songs with speech, similar to what happens on a radio show. Most significantly, it is the first survey that can fully incorporate the paradigm shift that has taken place in the way people consume recorded music: the shift from physical media to music streaming. This has wrought profound changes in the size of music collections available to listeners and thus the algorithms that support the construction, curation and presentation of playlists and the methods adopted by users when they also construct, curate and listen to playlists.},
journal = {ACM Trans. Intell. Syst. Technol.},
month = nov,
articleno = {114},
numpages = {68},
keywords = {playlists, music, information retrieval, recommender systems}
}

@inproceedings{10.1145/3627673.3679599,
author = {Xi, Yunjia and Liu, Weiwen and Lin, Jianghao and Chen, Bo and Tang, Ruiming and Zhang, Weinan and Yu, Yong},
title = {MemoCRS: Memory-enhanced Sequential Conversational Recommender Systems with Large Language Models},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3679599},
doi = {10.1145/3627673.3679599},
abstract = {Conversational recommender systems (CRSs) aim to capture user preferences and provide personalized recommendations through multi-round natural language dialogues. However, most existing CRS models mainly focus on dialogue comprehension and preferences mining from the current dialogue session, overlooking user preferences in historical dialogue sessions. The preferences embedded in historical sessions and the current session exhibit continuity and sequentiality, and we refer to such CRSs as sequential CRSs. In this work, we leverage memory-enhanced LLMs to model the preference continuity, addressing two key issues: (1) redundancy and noise in historical dialogue sessions, and (2) the cold-start users problem. Thus, we propose a &lt;u&gt;Memo&lt;/u&gt;ry-enhanced &lt;u&gt;C&lt;/u&gt;onversational &lt;u&gt;R&lt;/u&gt;ecommender &lt;u&gt;S&lt;/u&gt;ystem Framework with Large Language Models (dubbed MemoCRS), consisting of user-specific memory and general memory. User-specific memory is tailored to each user's interests and uses an entity-based memory bank to refine preferences and retrieve relevant memory, thereby reducing the redundancy and noise of historical sessions. The general memory, encapsulating collaborative knowledge and reasoning guidelines, can provide shared knowledge for users, especially cold-start users. With the above memory, LLMs are empowered to deliver more precise and tailored recommendations for each user. Extensive experiments on Chinese and English datasets demonstrate MemoCRS's effectiveness.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {2585–2595},
numpages = {11},
keywords = {conversational recommendation, large language models, memory},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@proceedings{10.1145/3638884,
title = {ICCIP '23: Proceedings of the 2023 9th International Conference on Communication and Information Processing},
year = {2023},
isbn = {9798400708909},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Lingshui, China}
}

@proceedings{10.1145/3685088,
title = {ICSCIS '24: Proceedings of the 2024 International Conference on Smart City and Information System},
year = {2024},
isbn = {9798400710155},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Kuala Lumpur, Malaysia}
}

@inproceedings{10.1145/3663529.3663861,
author = {Goel, Drishti and Husain, Fiza and Singh, Aditya and Ghosh, Supriyo and Parayil, Anjaly and Bansal, Chetan and Zhang, Xuchao and Rajmohan, Saravan},
title = {X-Lifecycle Learning for Cloud Incident Management using LLMs},
year = {2024},
isbn = {9798400706585},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3663529.3663861},
doi = {10.1145/3663529.3663861},
abstract = {Incident management for large cloud services is a complex and tedious process that requires a significant amount of manual effort from on-call engineers (OCEs). OCEs typically leverage data from different stages of the software development lifecycle [SDLC] (e.g., codes, configuration, monitor data, service properties, service dependencies, trouble-shooting documents, etc.) to generate insights for detection, root cause analysis and mitigation of incidents. Recent advancements in large language models [LLMs] (e.g., ChatGPT, GPT-4, Gemini) have created opportunities to automatically generate contextual recommendations for the OCEs, assisting them in quickly identifying and mitigating critical issues. However, existing research typically takes a silo-ed view of solving a certain task in incident management by leveraging data from a single stage of the SDLC. In this paper, we demonstrate that augmenting additional contextual data from different stages of the SDLC improves the performance of two critically important and practically challenging tasks: (1) automatically generating root cause recommendations for dependency failure related incidents, and (2) identifying the ontology of service monitors used for automatically detecting incidents. By leveraging a dataset of 353 incidents and 260 monitors from Microsoft, we demonstrate that augmenting contextual information from different stages of the SDLC improves the performance over state-of-the-art methods.},
booktitle = {Companion Proceedings of the 32nd ACM International Conference on the Foundations of Software Engineering},
pages = {417–428},
numpages = {12},
keywords = {Cloud Services, Large language models, Monitor management, Reliability, Root-cause analysis},
location = {Porto de Galinhas, Brazil},
series = {FSE 2024}
}

@proceedings{10.1145/3638550,
title = {HotMobile '24: Proceedings of the 25th International Workshop on Mobile Computing Systems and Applications},
year = {2024},
isbn = {9798400704970},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {San Diego, CA, USA}
}

@article{10.1109/TASLP.2024.3378108,
author = {Xiang, Chunli and Zhang, Junchi and Zhou, Jun and Li, Fei and Teng, Chong and Ji, Donghong},
title = {Phrase-Aware Financial Sentiment Analysis Based on Constituent Syntax},
year = {2024},
issue_date = {2024},
publisher = {IEEE Press},
volume = {32},
issn = {2329-9290},
url = {https://doi.org/10.1109/TASLP.2024.3378108},
doi = {10.1109/TASLP.2024.3378108},
abstract = {Financial sentiment analysis is a fine-grained sentiment analysis task that needs to predict the sentiment value toward a given target entity. Recently, dependency-based graph neural networks have been introduced for target-based sentiment analysis. However, financial sentiment analysis with implicit sentiment expression is more challenging than target-based explicit sentiment analysis, requiring a deep understanding of the complex association between the sentiment clue in context and the target entity. In previous work related to financial sentiment analysis, most methods focused on learning the simple word-to-word relations between the contextual words and the target entity based on the dependency tree of the sentence, ignoring the exploitation of span-boundary information and phrase-level syntactic knowledge with regard to the target entity. In this paper, we perform financial implicit sentiment analysis by taking phrases as basic semantic units and proposing a graph attention network (&lt;inline-formula&gt;&lt;tex-math notation="LaTeX"&gt;$PhraseGAT$&lt;/tex-math&gt;&lt;/inline-formula&gt;) based on the constituent tree to leverage the phrase syntactic knowledge. To enhance the information flow between the nodes in the graph, we construct a heterogeneous graph based on the constituent tree and encode higher-order neighbor information. In addition, we introduce a multi-edge-type graph attention network (&lt;inline-formula&gt;&lt;tex-math notation="LaTeX"&gt;$MET$&lt;/tex-math&gt;&lt;/inline-formula&gt;-&lt;inline-formula&gt;&lt;tex-math notation="LaTeX"&gt;$GAT$&lt;/tex-math&gt;&lt;/inline-formula&gt;) to take full consideration of syntax and semantic interactions for the final prediction on the sentiment value of the target entity. Our proposed approach achieves 85.56% and 84.37% cosine similarity on public benchmark HEADLINE and MICROBLOG datasets, outperforms several strong baselines and achieves new state-of-the-art performance, verifying its effectiveness.},
journal = {IEEE/ACM Trans. Audio, Speech and Lang. Proc.},
month = mar,
pages = {1994–2005},
numpages = {12}
}

@article{10.1145/3661485,
author = {Huang, Yinqiu and Gao, Min and Shu, Kai and Lin, Chenghua and Wang, Jia and Zhou, Wei},
title = {EML: Emotion-Aware Meta Learning for Cross-Event False Information Detection},
year = {2024},
issue_date = {September 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {8},
issn = {1556-4681},
url = {https://doi.org/10.1145/3661485},
doi = {10.1145/3661485},
abstract = {Modern social media’s development has dramatically changed how people obtain information. However, the wide dissemination of various false information has severe detrimental effects. Accordingly, many deep learning-based methods have been proposed to detect false information and achieve promising results. However, these methods are unsuitable for new events due to the extremely limited labeled data and their discrepant data distribution to existing events. Domain adaptation methods have been proposed to mitigate these problems. However, their performance is suboptimal because they are not sensitive to new events due to they aim to align the domain information between existing events, and they hardly capture the fine-grained difference between real and fake claims by only using semantic information. Therefore, we propose a novel Emotion-aware Meta Learning (EML) approach for cross-event false information early detection, which deeply integrates emotions in meta learning to find event-sensitive initialization parameters that quickly adapt to new events. EML is non-trivial and faces three challenges: (1) How to effectively model semantic and emotional features to capture fine-grained differences? (2) How to reduce the impact of noise in meta learning based on semantic and emotional features? (3) How to detect the false information in a zero-shot detection scenario, i.e., no labeled data for new events? To tackle these challenges, firstly, we construct the emotion-aware meta tasks by selecting claims with similar and opposite emotions to the target claim other than usually used random sampling. Secondly, we propose a task weighting method and event-adaptation meta tasks to further improve the model’s robustness and generalization ability for detecting new events. Finally, we propose a weak label annotation method to extend EML to zero-shot detection according to the calculated labels’ confidence. Extensive experiments on real-world datasets show that the EML achieves superior performances on false information detection for new events.},
journal = {ACM Trans. Knowl. Discov. Data},
month = jul,
articleno = {185},
numpages = {25},
keywords = {False information detection, Meta learning, Emotional feature extraction}
}

@article{10.1145/3676959,
author = {Jiang, Yanjie and Liu, Hui and Cheung, Shing Chi and Zhang, Lu},
title = {Shortening Overlong Method Names with Abbreviations},
year = {2024},
issue_date = {November 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {33},
number = {8},
issn = {1049-331X},
url = {https://doi.org/10.1145/3676959},
doi = {10.1145/3676959},
abstract = {Methods should be named to summarize their responsibilities meaningfully. When a method has a non-trivial responsibility, it may require a naming using multiple words. However, overlong method names are susceptible to typos and reduced readability (e.g., displaying a statement partially in standard screen width or splitting it into multiple lines). Programming naming conventions commonly adopt a maximal length (in characters) for identifiers. In practice, developers may not necessarily find a meaningful name that follows such naming conventions when coding a non-trivial method. This article presents the first automated technique (called NameCompressor) to shorten overlong method names. Our inspiration is that many lengthy words/phrases in an overlong method name have known and unambiguous abbreviations. The use of these abbreviations for method names is common. To shorten an overlong method name, NameCompressor employs three compression techniques, i.e., context-aware compression, probability-based compression, and machine learning-based compression, to find appropriate abbreviations for the words/phrases in the method name. We evaluate NameCompressor on a dataset of 700 overlong method names. It correctly generates 613 short names identical to those specified by the developers of these methods.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = nov,
articleno = {205},
numpages = {24},
keywords = {Method name, abbreviation, identifier, code quality}
}

@article{10.1145/3687300,
author = {Al-Sada, Bader and Sadighian, Alireza and Oligeri, Gabriele},
title = {MITRE ATT&amp;CK: State of the Art and Way Forward},
year = {2024},
issue_date = {January 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {57},
number = {1},
issn = {0360-0300},
url = {https://doi.org/10.1145/3687300},
doi = {10.1145/3687300},
abstract = {MITRE ATT&amp;CK is a comprehensive framework of adversary tactics, techniques, and procedures based on real-world observations. It has been used as a foundation for threat modeling in different sectors, such as government, academia, and industry. To the best of our knowledge, no previous work has been devoted to the comprehensive collection, study, and investigation of the current state of the art leveraging the MITRE ATT&amp;CK framework. We select and inspect more than 50 major research contributions, while conducting a detailed analysis of their methodology and objectives in relation to the MITRE ATT&amp;CK framework. We provide a categorization of the identified papers according to different criteria such as use cases, application scenarios, adopted methodologies, and the use of additional data. Finally, we discuss open issues and future research directions involving not only the MITRE ATT&amp;CK framework but also the fields of threat analysis, threat modeling, and in general cyber-threat intelligence.},
journal = {ACM Comput. Surv.},
month = oct,
articleno = {12},
numpages = {37},
keywords = {MITRE ATT&amp;CK framework, cyber-threat intelligence, security risk analysis}
}

@article{10.1145/3708532,
author = {H\"{a}m\"{a}l\"{a}inen, Joonas and Das, Teerath and Mikkonen, Tommi},
title = {A Systematic Literature Review of Multi-Label Learning in Software Engineering},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3708532},
doi = {10.1145/3708532},
abstract = {In this paper, we provide the first systematic literature review of the intersection of two research areas, Multi-Label Learning (MLL) and Software Engineering (SE). We refer to this intersection as MLL4SE. In recent years, MLL problems have increased in many applications and research areas because real-world datasets often have a multi-label nature. For multi-label data, simplifying the assumption of traditional classification approaches that an instance can only be associated with one class only leads to worse accuracy. Thus, a better match of methods and assumptions about the data is required. We identified 50 primary studies in our systematic literature review in the MLL4SE domain. Based on this review, we identified six main SE application domains where MLL has been applied. These domains include Software Requirement Engineering, Issue Tracking and Management, Community and Knowledge Management, API Usage and Management, Code Quality and Maintenance, and Mobile Application Development. We summarized the methods used and the data nature of the MLL4SE applications. Moreover, we separately provide taxonomies of future work directions from machine learning and software engineering perspectives. In general, we highlight current trends, research gaps, and shortcomings.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = dec,
keywords = {Machine Learning, Multi-Label Learning, Software Engineering, Systematic Literature Review, Software Development Life Cycle (SDLC) Activities}
}

@article{10.1145/3631430,
author = {Rahman, Wasifur and Abdelkader, Abdelrahman and Lee, Sangwu and Yang, Phillip and Islam, Md Saiful and Adnan, Tariq and Hasan, Masum and Wagner, Ellen and Park, Sooyong and Dorsey, E. Ray and Schwartz, Catherine and Jaffe, Karen and Hoque, Ehsan},
title = {A User-Centered Framework to Empower People with Parkinson's Disease},
year = {2024},
issue_date = {December 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {7},
number = {4},
url = {https://doi.org/10.1145/3631430},
doi = {10.1145/3631430},
abstract = {We present a user-centric validation of a teleneurology platform, assessing its effectiveness in conveying screening information, facilitating user queries, and offering resources to enhance user empowerment. This validation process is implemented in the setting of Parkinson's disease (PD), in collaboration with a neurology department of a major medical center in the USA. Our intention is that with this platform, anyone globally with a webcam and microphone-equipped computer can carry out a series of speech, motor, and facial mimicry tasks. Our validation method demonstrates to users a mock PD risk assessment and provides access to relevant resources, including a chatbot driven by GPT, locations of local neurologists, and actionable and scientifically-backed PD prevention and management recommendations. We share findings from 91 participants (48 with PD, 43 without) aimed at evaluating the user experience and collecting feedback. Our framework was rated positively by 80.85% (standard deviation ± 8.92%) of the participants, and it achieved an above-average 70.42 (standard deviation ± 13.85) System-Usability-Scale (SUS) score. We also conducted a thematic analysis of open-ended feedback to further inform our future work. When given the option to ask any questions to the chatbot, participants typically asked for information about neurologists, screening results, and the community support group. We also provide a roadmap of how the knowledge generated in this paper can be generalized to screening frameworks for other diseases through designing appropriate recording environments, appropriate tasks, and tailored user-interfaces.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = jan,
articleno = {175},
numpages = {29},
keywords = {End-to-end framework, Framework Evaluation, Parkinson's Disease}
}

@proceedings{10.1145/3700906,
title = {IPMLP '24: Proceedings of the International Conference on Image Processing, Machine Learning and Pattern Recognition},
year = {2024},
isbn = {9798400707032},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@inproceedings{10.1145/3605098.3636026,
author = {Jamil, Hasan and Krawetz, Stephen and Gow, Alexander},
title = {Knowledge Synthesis using Large Language Models for a Computational Biology Workflow Ecosystem},
year = {2024},
isbn = {9798400702433},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3605098.3636026},
doi = {10.1145/3605098.3636026},
abstract = {An understanding of the molecular basis of musculoskeletal pain is necessary for the development of therapeutics, their management, and possible personalization. One-in-three Americans use OTC pain killers, and one tenth use prescription drugs to manage pain. The CDC also estimates that about 20% Americans suffer from chronic pain. As the experience of acute or chronic pain varies due to individual genetics and physiology, it is imperative that researchers continue to find novel therapeutics to treat or manage symptoms. In this paper, our goal is to develop a seed knowledgebase computational platform, called BioNursery, that will allow biologists to computationally hypothesize, define and test molecular mechanisms underlying pain. In our knowledge ecosystem, we accumulate curated information from users about the relationships among biological databases, analysis tools, and database contents to generate biological analyses modules, called π-graphs, or process graphs. We propose a mapping function from a natural language description of a hypothesized molecular model to a computational workflow for testing in BioNursery. We use a crowd computing feedback and curation system, called Explorer, to improve proposed computational models for molecular mechanism discovery, and growing the knowledge ecosystem. Since the pain knowledge ecosystem does not yet exist, we validate our approach over a similar application in fertility research.},
booktitle = {Proceedings of the 39th ACM/SIGAPP Symposium on Applied Computing},
pages = {523–530},
numpages = {8},
keywords = {knowledge ecosystem, crowdsourcing, query reformulation},
location = {Avila, Spain},
series = {SAC '24}
}

@inproceedings{10.1145/3613905.3651035,
author = {Kang, Hyeonsu B and Lin, David Chuan-En and Martelaro, Nikolas and Kittur, Aniket and Chen, Yan-Ying and Hong, Matthew K.},
title = {BioSpark: An End-to-End Generative System for Biological-Analogical Inspirations and Ideation},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3651035},
doi = {10.1145/3613905.3651035},
abstract = {Nature often inspires solutions for complex engineering problems, but it is challenging for designers to discover relevant analogies and synthesize from them. Here, we present an end-to-end system, BioSpark, that generates biological-analogical mechanisms and provides an interactive interface for comprehension and ideation. From a small seed set of expert-curated mechanisms, BioSpark’s pipeline iteratively expands them by constructing and traversing organism taxonomies, aiming to overcome both data sparsity in expert curation and limited conceptual diversity in purely automated analogy generation. The interface helps designers recognize and understand relevant analogs to design problems using four interaction features. We conduct an exploratory study with design students to showcase how BioSpark facilitated analogical transfer of ideas but was limited in conveying active ingredients, the core abstraction underpinning how mechanisms work. We discuss this limitation and other implications such as generative hallucination that could facilitate shifts in human exploration of new design spaces.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {61},
numpages = {13},
keywords = {Analogies, Design Creativity, Diversity-enhanced Generation, Ideation, Large Language Models, Nature},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}

@proceedings{10.1145/3672758,
title = {CAICE '24: Proceedings of the 3rd International Conference on Computer, Artificial Intelligence and Control Engineering},
year = {2024},
isbn = {9798400716942},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Xi' an, China}
}

@proceedings{10.1145/3658644,
title = {CCS '24: Proceedings of the 2024 on ACM SIGSAC Conference on Computer and Communications Security},
year = {2024},
isbn = {9798400706363},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is with great enthusiasm that we, on behalf of the Organizing Committee, invite you to join us for the 31st ACM SIGSAC Conference on Computer and Communications Security (CCS), a premier security and privacy conference where researchers, practitioners, and educators come together to present, learn, and debate research, innovation, and trends in the field of Computer and Communications Security and Privacy.This year, we are proud to introduce our conference theme to be "Inclusion, Mentorship, Community." These three pillars reflect our collective commitment to fostering a vibrant, supportive, and forwardthinking environment within the CCS community. Particularly, we host our inaugural Doctoral Symposium, which offers PhD students a unique platform to receive timely, constructive feedback on their dissertation research from leading experts in our community. Additionally, our first-ever Diversity, Equity, and Inclusion (DEI) Workshop is designed to cultivate a culture that embraces diversity and champions equity in our field. Moreover, understanding the importance of guidance and support, we have organized panels focusing on Student Mentoring, Faculty Mentoring, and Public Service. These panels are designed to facilitate mentorship connections, share valuable experiences, and encourage service that extends the impact of our work beyond academia. These new initiatives are also opportunities to strengthen the bonds within our CCS community.Regarding the main conference, this year's main conference is our largest ever, featuring 328 paper presentations that showcase the latest research and developments in our field. We are also honored to have two distinguished keynote speakers: Dr. Dan Boneh and Dr. Gene Tsudik, who will share their invaluable insights and perspectives on pressing topics in security and privacy. Additionally, 18 specialized workshops will take place on the pre-conference and post-conference days, providing platforms for focused discussions and collaborations on numerous specialized topics.},
location = {Salt Lake City, UT, USA}
}

@article{10.1145/3623381,
author = {Li, Miaoran and Peng, Baolin and Gao, Jianfeng and Zhang, Zhu},
title = {OPERA: Harmonizing Task-Oriented Dialogs and Information Seeking Experience},
year = {2024},
issue_date = {November 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {4},
issn = {1559-1131},
url = {https://doi.org/10.1145/3623381},
doi = {10.1145/3623381},
abstract = {Existing studies in conversational AI mostly treat task-oriented dialog (TOD) and question answering (QA) as separate tasks. Towards the goal of constructing a conversational agent that can complete user tasks and support information seeking, it is important to develop a system that can handle both TOD and QA with access to various external knowledge sources. In this work, we propose a new task, Open-Book TOD (OB-TOD), which combines TOD with QA and expands the external knowledge sources to include both explicit sources (e.g., the web) and implicit sources (e.g., pre-trained language models). We create a new dataset OB-MultiWOZ, where we enrich TOD sessions with QA-like information-seeking experience grounded on external knowledge. We propose a unified model OPERA (Open-book End-to-end Task-oriented Dialog) which can appropriately access explicit and implicit external knowledge to tackle the OB-TOD task. Experimental results show that OPERA outperforms closed-book baselines, highlighting the value of both types of knowledge.1},
journal = {ACM Trans. Web},
month = oct,
articleno = {45},
numpages = {27},
keywords = {Web search, task-oriented dialog systems, language models}
}

@proceedings{10.1145/3650212,
title = {ISSTA 2024: Proceedings of the 33rd ACM SIGSOFT International Symposium on Software Testing and Analysis},
year = {2024},
isbn = {9798400706127},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to the 33rd edition of the International Symposium on Software Testing and Analysis, ISSTA 2024, held on September 16--20, 2024 in Vienna, Austria. ISSTA 2024 is co-located with ECOOP and MPLR 2024. ISSTA brings together academics, industrial researchers, and practitioners from all over the world working on testing and analyzing software systems.},
location = {Vienna, Austria}
}

@proceedings{10.1145/3625468,
title = {MMSys '24: Proceedings of the 15th ACM Multimedia Systems Conference},
year = {2024},
isbn = {9798400704123},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Dear MMSys 2024 Participants,On behalf of the organizers, we are very pleased to welcome you to the 15th ACM Multimedia Systems Conference, taking place for the first time in Italy, in the city of Bari.MMSys is a premier conference dedicated to the exciting and multidisciplinary field of multimedia, with a specific focus on its systems and applications. The conference provides a platform for researchers from both academia and industry to share their latest findings in the multimedia systems research area. Many international researchers, practitioners, engineers, and students from academia, industry, standardization bodies, and government agencies join the MMSys conference each year.},
location = {Bari, Italy}
}

@article{10.1145/3630025,
author = {Bianchini, Devis and Bono, Carlo and Campi, Alessandro and Cappiello, Cinzia and Ceri, Stefano and De Luzi, Francesca and Mecella, Massimo and Pernici, Barbara and Plebani, Pierluigi},
title = {Challenges in AI-supported Process Analysis in the Italian Judicial System: what After Digitalization?},
year = {2024},
issue_date = {March 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {5},
number = {1},
url = {https://doi.org/10.1145/3630025},
doi = {10.1145/3630025},
abstract = {In this commentary article, we outline research challenges and possible directions for the potential applications of AI in the judicial domain by specifically considering process analysis in the Italian context. Applying AI to process analysis poses several challenges, including information extraction from legacy information systems and analysis of legal documents, process modeling with a particular emphasis on temporal analysis, real-time process monitoring, conformance and compliance checking, predictive techniques for accurate predictions, and analysis of judges’ workload. Solutions to these challenges include methods and tools for data identification and collection, innovative approaches to process modeling, reactive techniques for real-time monitoring, conformance checking with explainability, language models adapted to specific domains, and the identification of suitable indicators for the analysis of case handling efficiency and case classification.},
journal = {Digit. Gov.: Res. Pract.},
month = mar,
articleno = {10},
numpages = {10},
keywords = {Process analysis, process improvement, domain-specific text analysis, temporal analysis}
}

@article{10.1145/3665252.3665262,
author = {Doan, AnHai},
title = {Technical Perspective: Unicorn: A Unified Multi-Tasking Matching Model},
year = {2024},
issue_date = {March 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {1},
issn = {0163-5808},
url = {https://doi.org/10.1145/3665252.3665262},
doi = {10.1145/3665252.3665262},
abstract = {Data integration has been a long-standing challenge for data management. It has recently received significant attention due to at least three main reasons. First, many data science projects require integrating data from disparate sources before analysis can be carried out to extract insights. Second, many organizations want to build knowledge graphs, such as Customer 360s, Product 360s, and Supplier 360s, which capture all available information about the customers, products, and suppliers of an organization. Building such knowledge graphs often requires integrating data from multiple sources. Finally, there is also an increasing need to integrate a massive amount of data to create training data for AI models, such as large language models.},
journal = {SIGMOD Rec.},
month = may,
pages = {43},
numpages = {1}
}

@inproceedings{10.1145/3589334.3645512,
author = {Kang, SeongKu and Agarwal, Shivam and Jin, Bowen and Lee, Dongha and Yu, Hwanjo and Han, Jiawei},
title = {Improving Retrieval in Theme-specific Applications using a Corpus Topical Taxonomy},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3645512},
doi = {10.1145/3589334.3645512},
abstract = {Document retrieval has greatly benefited from the advancements of large-scale pre-trained language models (PLMs). However, their effectiveness is often limited in theme-specific applications for specialized areas or industries, due to unique terminologies, incomplete contexts of user queries, and specialized search intents. To capture the theme-specific information and improve retrieval, we propose to use a corpus topical taxonomy, which outlines the latent topic structure of the corpus while reflecting user-interested aspects. We introduce ToTER (Topical Taxonomy Enhanced Retrieval) framework, which identifies the central topics of queries and documents with the guidance of the taxonomy, and exploits their topical relatedness to supplement missing contexts. As a plug-and-play framework, ToTER can be flexibly employed to enhance various PLM-based retrievers. Through extensive quantitative, ablative, and exploratory experiments on two real-world datasets, we ascertain the benefits of using topical taxonomy for retrieval in theme-specific applications and demonstrate the effectiveness of ToTER.},
booktitle = {Proceedings of the ACM Web Conference 2024},
pages = {1497–1508},
numpages = {12},
keywords = {document retrieval, theme-specific application, topical taxonomy},
location = {Singapore, Singapore},
series = {WWW '24}
}

@proceedings{10.1145/3644523,
title = {ICCSMT '23: Proceedings of the 2023 4th International Conference on Computer Science and Management Technology},
year = {2023},
isbn = {9798400709517},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Xi'an, China}
}

@inproceedings{10.1145/3637528.3671992,
author = {Xiao, Congxi and Zhou, Jingbo and Xiao, Yixiong and Huang, Jizhou and Xiong, Hui},
title = {ReFound: Crafting a Foundation Model for Urban Region Understanding upon Language and Visual Foundations},
year = {2024},
isbn = {9798400704901},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3637528.3671992},
doi = {10.1145/3637528.3671992},
abstract = {Understanding urban regional characteristics is pivotal in driving critical insights for urban planning and management. We have witnessed the successful application of pre-trained Foundation Models (FMs) in generating universal representations for various downstream tasks. However, applying this principle to the geospatial domain remains challenging, primarily due to the difficulty of gathering extensive data for developing a dedicated urban foundation model. Though there have been some attempts to empower the existing FMs with urban data, most of them focus on single-modality FMs without considering the multi-modality nature of urban region understanding tasks. To address this gap, we introduce ReFound - a novel framework for &lt;u&gt;Re&lt;/u&gt;-training a &lt;u&gt;Found&lt;/u&gt;ation model for urban region understanding, harnessing the strengths of both language and visual FMs. In this framework, we first invent a Mixture-of-Geospatial-Expert (MoGE) Transformer, to effectively integrate the embedding of multi-source geospatial data. Building on this, ReFound is enhanced by jointly distilling knowledge from language, visual, and visual-language FMs respectively, thus augmenting its generalization capabilities. Meanwhile, we design a masked geospatial data modeling approach alongside a cross-modal spatial alignment mechanism, to enhance the spatial knowledge of ReFound derived from geospatial data. Extensive experiments conducted on six real-world datasets over three urban region understanding tasks demonstrate the superior performance of our framework.},
booktitle = {Proceedings of the 30th ACM SIGKDD Conference on Knowledge Discovery and Data Mining},
pages = {3527–3538},
numpages = {12},
keywords = {foundation model, multimodal data, urban region understanding},
location = {Barcelona, Spain},
series = {KDD '24}
}

@article{10.1145/3675781,
author = {Pham, Quoc-Hung and Le, Huu-Loi and Dang Nhat, Minh and Tran T., Khang and Tran-Tien, Manh and Dang, Viet-Hung and Vu, Huy-The and Nguyen, Minh-Tien and Phan, Xuan-Hieu},
title = {Towards Vietnamese Question and Answer Generation: An Empirical Study},
year = {2024},
issue_date = {September 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {9},
issn = {2375-4699},
url = {https://doi.org/10.1145/3675781},
doi = {10.1145/3675781},
abstract = {Question-answer generation (QAG) is a challenging task that generates both questions and answers from a given input paragraph context. The QAG task has recently achieved promising results thanks to the appearance of large pre-trained language models, yet, QAG models are mainly implemented in common languages, e.g., English. There still remains a gap in domain and language adaptation of these QAG models to low-resource languages such as Vietnamese. To address the gap, this article presents a large-scale and systematic study of QAG in Vietnamese. To do that, we first implement several QAG models by using the common fine-tuning techniques based on powerful pre-trained language models. We next introduce a set of instructions designed for the QAG task. These instructions are used to fine-tuned the pre-trained language and large language models. Extensive experimental results of both automatic and human evaluation on five benchmark machine reading comprehension datasets show two important points. First, the instruction-tuning method has the potential to enhance the performance of QAG models. Second, large language models trained in English need more data for fine-tuning to work well on the downstream QAG tasks of low-resource languages. We also provide a prototype system to demonstrate how our QAG models actually work. The code for fine-tuning QAG models and instructions are also made available.},
journal = {ACM Trans. Asian Low-Resour. Lang. Inf. Process.},
month = aug,
articleno = {132},
numpages = {28},
keywords = {Natural language processing, question and answer generation, large pre-trained language models, instruction fine-tuning, BARTPho, ViT5, LlaMa2}
}

@inproceedings{10.1145/3686215.3689201,
author = {Porfirio, Rui Pedro and Santos, Pedro Albuquerque and Madeira, Rui Neves},
title = {Enhancing Digital Agriculture with XAI: Case Studies on Tabular Data and Future Directions},
year = {2024},
isbn = {9798400704635},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3686215.3689201},
doi = {10.1145/3686215.3689201},
abstract = {Given the pivotal role of agriculture in ensuring food security, fostering economic stability, and addressing environmental sustainability, the sector has increasingly embraced smart farming solutions to respond to recent climate and societal challenges, such as rising water and food demands. These solutions provide actionable insights crucial for decision-making, enabling farm stakeholders to optimize resources, improve yields, and mitigate risks. However, the complexity of the predictive models often associated with this type of solutions results in a lack of transparency, hindering trust and adoption. To respond to such challenges, this paper explores the application of explainable AI (XAI) techniques to agriculture tabular data. Specifically, we focus on two case studies: wheat yield prediction and grapes produced for wine purposes yield prediction. Through these case studies, we propose initial contributions on how XAI techniques can be applied in the context of agriculture and how generated explanations can be adapted to the users’ level of expertise. Finally, as part of ongoing and future research directions, we introduce AgriUXE (Agricultural eXperience Enhanced through eXplainability), a novel user-centered digital platform designed to augment the explainability of multimodal data and machine learning model predictions for sustainable smart farming solutions. By providing transparent, data-driven decisions and generating user-adaptive explanations, AgriUXE aims to support the optimization of the user experience within these solutions.},
booktitle = {Companion Proceedings of the 26th International Conference on Multimodal Interaction},
pages = {211–217},
numpages = {7},
keywords = {Digital Agriculture, Explainable AI, Human-Computer Interaction, Machine Learning, Multimodal Systems},
location = {San Jose, Costa Rica},
series = {ICMI Companion '24}
}

@inproceedings{10.1145/3691620.3695019,
author = {Zhao, Jiuang and Yang, Zitian and Zhang, Li and Lian, Xiaoli and Yang, Donghao and Tan, Xin},
title = {DRMiner: Extracting Latent Design Rationale from Jira Issue Logs},
year = {2024},
isbn = {9798400712487},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3691620.3695019},
doi = {10.1145/3691620.3695019},
abstract = {Software architectures are usually meticulously designed to address multiple quality concerns and support long-term maintenance. However, there may be a lack of motivation for developers to document design rationales (i.e., the design alternatives and the underlying arguments for making or rejecting decisions) when they will not gain immediate benefit, resulting in a lack of standard capture of these rationales. With the turnover of developers, the architecture inevitably becomes eroded. This issue has motivated a number of studies to extract design knowledge from open-source communities in recent years. Unfortunately, none of the existing research has successfully extracted solutions alone with their corresponding arguments due to challenges such as the intricate semantics of online discussions and the lack of benchmarks for design rationale extraction.In this paper, we propose a novel approach, named DRMiner, to automatically mine latent design rationales from developers' live discussion in open-source community (i.e., issue logs in Jira). To better identify solutions and their relevant arguments, DRMiner skillfully decomposes the problem into multiple text classification tasks and tackles them using prompt tuning of large language models (LLMs) and specific heuristic features. To evaluate DRMiner, we acquire issue logs from Cassandra, Flink, and Solr repositories in Jira and form a dataset for design rationale mining. Experimental results show that DRMiner outperforms all baselines and achieves F1 improvements of 24%, 22%, and 20% for mining design rationales, solutions, and arguments, respectively, compared to the best baseline. Furthermore, we investigate the usefulness of the design rationales mined by DRMiner for automated program repair (APR) and find that advanced LLMs, when prompted with these extracted rationales, generate 10\texttimes{}-18\texttimes{} more full-match patches and achieve a 10%-13% gain in CodeBLEU scores.},
booktitle = {Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering},
pages = {468–480},
numpages = {13},
keywords = {design rationale, issue logs, design discussion, design recovery, program maintenance},
location = {Sacramento, CA, USA},
series = {ASE '24}
}

@inproceedings{10.1145/3673791.3698415,
author = {Soudani, Heydar and Kanoulas, Evangelos and Hasibi, Faegheh},
title = {Fine Tuning vs. Retrieval Augmented Generation for Less Popular Knowledge},
year = {2024},
isbn = {9798400707247},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3673791.3698415},
doi = {10.1145/3673791.3698415},
abstract = {Language Models (LMs) memorize a vast amount of factual knowledge, exhibiting strong performance across diverse tasks and domains. However, it has been observed that the performance diminishes when dealing with less-popular or low-frequency concepts and entities, for example in domain specific applications. The two prominent approaches to enhance the performance of LMs on low-frequent topics are: Retrieval Augmented Generation (RAG) and fine-tuning (FT) over synthetic data. This paper explores and evaluates the impact of RAG and FT on customizing LMs in handling low-frequency entities on question answering tasks. We conduct extensive experiments on twelve LMs of varying size and type and different FT methods, data augmentation, and retrieval models. Our findings indicate that while FT boosts the performance across entities of varying popularity, RAG surpasses FT by a large margin particularly for least popular factual knowledge. Additionally, the success of both RAG and FT approaches is amplified by improving retrieval and data augmentation techniques. Fine tuning, while beneficial for small LMs, requires extensive resources. To address this issue, we propose the new Stimulus RAG approach that surpasses the effectiveness of fine tuning based approaches, thereby eliminating the need for the costly data augmentation and fine tuning step for enriching LMs with less popular factual knowledge.},
booktitle = {Proceedings of the 2024 Annual International ACM SIGIR Conference on Research and Development in Information Retrieval in the Asia Pacific Region},
pages = {12–22},
numpages = {11},
keywords = {data augmentation, fine tuning, retrieval augmented generation},
location = {Tokyo, Japan},
series = {SIGIR-AP 2024}
}

@proceedings{10.1145/3705618,
title = {DECS '24: Proceedings of the 2024 International Conference on Digital Economy and Computer Science},
year = {2024},
isbn = {9798400711855},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@article{10.1145/3651169,
author = {Wu, Yaxiong and Macdonald, Craig and Ounis, Iadh},
title = {Personalised Multi-modal Interactive Recommendation with Hierarchical State Representations},
year = {2024},
issue_date = {September 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {3},
url = {https://doi.org/10.1145/3651169},
doi = {10.1145/3651169},
abstract = {Multi-modal interactive recommender systems (MMIRS) can effectively guide users towards their desired items through multi-turn interactions by leveraging the users’ real-time feedback (in the form of natural-language critiques) on previously recommended items (such as images of fashion products). In this scenario, the users’ preferences can be expressed by both the users’ past interests from their historical interactions and their current needs from the real-time interactions. However, it is typically challenging to make satisfactory personalised recommendations across multi-turn interactions due to the difficulty in balancing the users’ past interests and the current needs for generating the users’ state (i.e., current preferences) representations over time. However, hierarchical reinforcement learning has been successfully applied in various fields by decomposing a complex task into a hierarchy of more easily addressed subtasks. In this journal article, we propose a novel personalised multi-modal interactive recommendation model (PMMIR) using hierarchical reinforcement learning to more effectively incorporate the users’ preferences from both their past and real-time interactions. In particular, PMMIR decomposes the personalised interactive recommendation process into a sequence of two subtasks with hierarchical state representations: a first subtask where a history encoder learns the users’ past interests with the hidden states of history for providing personalised initial recommendations and a second subtask where a state tracker estimates the current needs with the real-time estimated states for updating the subsequent recommendations. The history encoder and the state tracker are jointly optimised with a single objective by maximising the users’ future satisfaction with the recommendations. Following previous work, we train and evaluate our PMMIR model using a user simulator that can generate natural-language critiques about the recommendations as a surrogate for real human users. Experiments conducted on two derived fashion datasets from two well-known public datasets demonstrate that our proposed PMMIR model yields significant improvements in comparison to the existing state-of-the-art baseline models. The datasets and code are publicly available at:},
journal = {ACM Trans. Recomm. Syst.},
month = jun,
articleno = {21},
numpages = {25},
keywords = {Interactive recommendation, multi-modal, personalisation, reinforcement learning}
}

@inproceedings{10.1145/3646547.3689015,
author = {Huang, Ziyuan and Tang, Jiaming and Karir, Manish and Liu, Mingyan and Sarabi, Armin},
title = {Analyzing Corporate Privacy Policies using AI Chatbots},
year = {2024},
isbn = {9798400705922},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3646547.3689015},
doi = {10.1145/3646547.3689015},
abstract = {In this paper, we present and evaluate an automated pipeline for the large-scale analysis of corporate privacy policies. Organizations usually develop their privacy policies in isolation to best balance their business needs, user rights, as well as regulatory requirements. A wide-ranging and structured analysis of corporate privacy policies is essential to facilitate a deeper understanding of how organizations have balanced competing requirements. Our approach consists of a web crawler that can navigate to and scrape content from web pages that contain privacy policies, and a set of AI chatbot task prompts to process and extract structured/labeled annotations from the raw data. The analysis includes the types of collected user data, the purposes for which data is collected and processed, data retention and protection practices, and user rights and choices. Our validation shows that our annotations are highly accurate and consistent. We use this architecture to gather data on the privacy policies of companies in the Russell 3000 index, resulting in hundreds of thousands of annotations across all categories. Analysis of the resulting data allows us to obtain unique insights into the state of the privacy policy ecosystem as a whole.},
booktitle = {Proceedings of the 2024 ACM on Internet Measurement Conference},
pages = {505–515},
numpages = {11},
keywords = {ai chatbots, large language models, privacy policies, text annotation, web crawling},
location = {Madrid, Spain},
series = {IMC '24}
}

@article{10.1145/3708521,
author = {Li, Rui and Liu, Huai and Poon, Pak-Lok and Towey, Dave and Sun, Chang-Ai and Zheng, Zheng and Zhou, Zhi Quan and Chen, Tsong Yueh},
title = {Metamorphic Relation Generation: State of the Art and Research Directions},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3708521},
doi = {10.1145/3708521},
abstract = {Metamorphic testing has become one mainstream technique to address the notorious oracle problem in software testing, thanks to its great successes in revealing real-life bugs in a wide variety of software systems. Metamorphic relations, the core component of metamorphic testing, have continuously attracted research interests from both academia and industry. In the last decade, a rapidly increasing number of studies have been conducted to systematically generate metamorphic relations from various sources and for different application domains. In this article, based on the systematic review on the state of the art for metamorphic relations’ generation, we summarize and highlight visions for further advancing the theory and techniques for identifying and constructing metamorphic relations, and discuss promising research directions in related areas.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = dec,
keywords = {Metamorphic testing, Metamorphic relation, Metamorphic relation generation}
}

@inproceedings{10.1145/3626772.3657882,
author = {Roy, Soumyadeep and Khatua, Aparup and Ghoochani, Fatemeh and Hadler, Uwe and Nejdl, Wolfgang and Ganguly, Niloy},
title = {Beyond Accuracy: Investigating Error Types in GPT-4 Responses to USMLE Questions},
year = {2024},
isbn = {9798400704314},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3626772.3657882},
doi = {10.1145/3626772.3657882},
abstract = {GPT-4 demonstrates high accuracy in medical QA tasks, leading with an accuracy of 86.70%, followed by Med-PaLM 2 at 86.50%. However, around 14% of errors remain. Additionally, current works use GPT-4 to only predict the correct option without providing any explanation and thus do not provide any insight into the thinking process and reasoning used by GPT-4 or other LLMs. Therefore, we introduce a new domain-specific error taxonomy derived from collaboration with medical students. Our GPT-4 USMLE Error (G4UE) dataset comprises 4153 GPT-4 correct responses and 919 incorrect responses to the United States Medical Licensing Examination (USMLE) respectively. These responses are quite long (258 words on average), containing detailed explanations from GPT-4 justifying the selected option. We then launch a large-scale annotation study using the Potato annotation platform and recruit 44 medical experts through Prolific, a well-known crowdsourcing platform. We annotated 300 out of these 919 incorrect data points at a granular level for different classes and created a multi-label span to identify the reasons behind the error. In our annotated dataset, a substantial portion of GPT-4's incorrect responses is categorized as a "Reasonable response by GPT-4," by annotators. This sheds light on the challenge of discerning explanations that may lead to incorrect options, even among trained medical professionals. We also provide medical concepts and medical semantic predications extracted using the SemRep tool for every data point. We believe that it will aid in evaluating the ability of LLMs to answer complex medical questions. We make the resources available at https://github.com/roysoumya/usmle-gpt4-error-taxonomy.},
booktitle = {Proceedings of the 47th International ACM SIGIR Conference on Research and Development in Information Retrieval},
pages = {1073–1082},
numpages = {10},
keywords = {gpt-4, medical qa, multi-label dataset, usmle error taxonomy},
location = {Washington DC, USA},
series = {SIGIR '24}
}

@proceedings{10.1145/3625223,
title = {RSP '23: Proceedings of the 34th International Workshop on Rapid System Prototyping},
year = {2023},
isbn = {9798400704109},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Hamburg, Germany}
}

@inproceedings{10.1145/3658644.3670377,
author = {Li, Shuai and Yang, Zhemin and Nan, Yuhong and Yu, Shutian and Zhu, Qirui and Yang, Min},
title = {Are We Getting Well-informed? An In-depth Study of Runtime Privacy Notice Practice in Mobile Apps},
year = {2024},
isbn = {9798400706363},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3658644.3670377},
doi = {10.1145/3658644.3670377},
abstract = {Under the General Data Protection Regulation (GDPR), mobile app developers are required to inform users of necessary information at the time when user data is collected (called users' "Right-to-be-Informed"). This is typically done by app developers via providing runtime privacy notices (RPNs for short). However, given the heterogeneous privacy data types and data access patterns in modern apps, it is not clear to what extent apps (app developers) effectively fulfill this compliance requirement in practice.In this paper, we perform the first systematic study of current RPN practices in mobile apps. Our research endeavors to comprehend (1) the ecosystem of RPN, (2) potential gaps between legal requirements and RPN practices, and (3) the underlying reasons for such gaps. To achieve this, we design an automated pipeline - RENO that can effectively identify, extract, and analyze RPN at a large scale. With the help of RENO, we investigated 4,656 mobile apps selected from 19 European Union countries. Our analysis reveals a number of interesting findings. For example, 77.10% of user data collection behaviors lack RPNs. Among those provided RPNs, 86.35% of them have no more than three required notice elements when GDPR requires seven. In addition, to further understand the reasons behind such gaps, we perform a notification campaign and ask for feedback from the app developers. Indeed, the collected responses highlighted several critical reasons. For instance, a substantial proportion of app developers regard RPN as an optional complement to their privacy policies as RPNs are not strictly enforced by app stores. Our study shows the pressing need for better transparency in user data collection delivered by RPN.},
booktitle = {Proceedings of the 2024 on ACM SIGSAC Conference on Computer and Communications Security},
pages = {1581–1595},
numpages = {15},
keywords = {GDPR compliance, mobile application, right to be informed, runtime privacy notice},
location = {Salt Lake City, UT, USA},
series = {CCS '24}
}

@proceedings{10.1145/3702879,
title = {IoTCCT '24: Proceedings of the 2024 2nd International Conference on Internet of Things and Cloud Computing Technology},
year = {2024},
isbn = {9798400710148},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3631802,
title = {Koli Calling '23: Proceedings of the 23rd Koli Calling International Conference on Computing Education Research},
year = {2023},
isbn = {9798400716539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Koli, Finland}
}

@proceedings{10.1145/3616901,
title = {FAIML '23: Proceedings of the 2023 International Conference on Frontiers of Artificial Intelligence and Machine Learning},
year = {2023},
isbn = {9798400707544},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Beijing, China}
}

@proceedings{10.1145/3663741,
title = {BiDEDE '24: Proceedings of the International Workshop on Big Data in Emergent Distributed Environments},
year = {2024},
isbn = {9798400706790},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Santiago, AA, Chile}
}

@proceedings{10.1145/3650215,
title = {ICMLCA '23: Proceedings of the 2023 4th International Conference on Machine Learning and Computer Application},
year = {2023},
isbn = {9798400709449},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Hangzhou, China}
}

@proceedings{10.1145/3643651,
title = {IWSPA '24: Proceedings of the 10th ACM International Workshop on Security and Privacy Analytics},
year = {2024},
isbn = {9798400705564},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our great pleasure to welcome you to the 2024 ACM International Workshop on Security and Privacy Analytics - IWSPA 2024. This year's workshop is the tenth in the series and co-hosted with the Fourteenth ACM Annual Conference on Data and Applications Security and Privacy (CODASPY 2024).IWSPA addresses important research topics associated with the application of data analytics tools and techniques (including statistical, machine/deep learning, data mining, and natural language processing) to challenges that arise with security and privacy preservation. IWSPA provides a forum for the interaction between researchers in these areas, identifying and pursuing new topics that arise in the intersection between the fields of Artificial Intelligence and Cybersecurity.},
location = {Porto, Portugal}
}

@proceedings{10.1145/3673971,
title = {ICMHI '24: Proceedings of the 2024 8th International Conference on Medical and Health Informatics},
year = {2024},
isbn = {9798400716874},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Yokohama, Japan}
}

@proceedings{10.1145/3674658,
title = {ICBBT '24: Proceedings of the 2024 16th International Conference on Bioinformatics and Biomedical Technology},
year = {2024},
isbn = {9798400717666},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@inproceedings{10.1145/3685650.3685660,
author = {Opitz, Dominik and Hamm, Andreas and El Baff, Roxanne and Korte, Jasper and Hecking, Tobias},
title = {Graph Detective: A User Interface for Intuitive Graph Exploration Through Visualized Queries},
year = {2024},
isbn = {9798400711695},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3685650.3685660},
doi = {10.1145/3685650.3685660},
abstract = {Graph databases are used across several domains due to the intuitive structure of graphs. They are well-suited for storing document collections together with their interlinkages through metadata and annotations. Yet, querying such graphs requires database experts' involvement for query formulation, reducing accessibility to nonexperts. To address this issue, we present Graph Detective, a web interface that provides an intuitive entry point for graph data exploration, where users can create queries visually with little effort, eliminating the need for expertise in query writing. After processing, the resulting query output (a graph) is then rendered in an interactive 3D visualization. This visualization allows the analysis of structural traits of the resulting graph data, exploiting the documents and metadata interlinkage. Our user evaluation revealed that even individuals inexperienced with graph databases or graph data, in general, could satisfactorily access the graph data through our interface. Furthermore, experienced participants commented that our interface was more efficient than writing explicit queries in graph database query language. Interested users can find the code openly accessible on GitHub1.},
booktitle = {Proceedings of the ACM Symposium on Document Engineering 2024},
articleno = {6},
numpages = {9},
keywords = {Graph Data, Graph Database, Graph Retrieval Interface, Query Generation, Visual Querying, Web Application},
location = {San Jose, CA, USA},
series = {DocEng '24}
}

@proceedings{10.1145/3660853,
title = {AICCONF '24: Proceedings of the Cognitive Models and Artificial Intelligence Conference},
year = {2024},
isbn = {9798400716928},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {undefinedstanbul, Turkiye}
}

@proceedings{10.1145/3680528,
title = {SA '24: SIGGRAPH Asia 2024 Conference Papers},
year = {2024},
isbn = {9798400711312},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@inproceedings{10.1145/3589334.3645631,
author = {Zhao, Rui and Zhao, Jun},
title = {Perennial Semantic Data Terms of Use for Decentralized Web},
year = {2024},
isbn = {9798400701719},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589334.3645631},
doi = {10.1145/3589334.3645631},
abstract = {In today's digital landscape, the Web has become increasingly centralized, raising concerns about user privacy violations. Decentralized Web architectures, such as Solid, offer a promising solution by empowering users with better control over their data in their personal 'Pods'. However, a significant challenge remains: users must navigate numerous applications to decide which application can be trusted with access to their data Pods. This often involves reading lengthy and complex Terms of Use agreements, a process that users often find daunting or simply ignore. This compromises user autonomy and impedes detection of data misuse. We propose a novel formal description of Data Terms of Use (DToU), along with a DToU reasoner. Users and applications specify their own parts of the DToU policy with local knowledge, covering permissions, requirements, prohibitions and obligations. Automated reasoning verifies compliance, and also derives policies for output data. This constitutes a "perennial'' DToU language, where the policy authoring only occurs once, and we can conduct ongoing automated checks across users, applications and activity cycles. Our solution is built on Turtle, Notation 3 and RDF Surfaces, for the language and the reasoning engine. It ensures seamless integration with other semantic tools for enhanced interoperability. We have successfully integrated this language into the Solid framework, and conducted performance benchmark. We believe this work demonstrates a practicality of a perennial DToU language and the potential of a paradigm shift to how users interact with data and applications in a decentralized Web, offering both improved privacy and usability.},
booktitle = {Proceedings of the ACM Web Conference 2024},
pages = {2238–2249},
numpages = {12},
keywords = {automated reasoning, data terms of use, decentralized web, formal modelling, notation 3, usage control},
location = {Singapore, Singapore},
series = {WWW '24}
}

@proceedings{10.1145/3665689,
title = {BIC '24: Proceedings of the 2024 4th International Conference on Bioinformatics and Intelligent Computing},
year = {2024},
isbn = {9798400716645},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Beijing, China}
}

@inproceedings{10.1145/3625549.3658830,
author = {Huang, Shaohan and Luan, Zhongzhi},
title = {Semantic-Aware Log Understanding and Analysis},
year = {2024},
isbn = {9798400704130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3625549.3658830},
doi = {10.1145/3625549.3658830},
abstract = {The exponential growth in system complexity and the corresponding surge in log data volume necessitate advanced log analysis techniques for efficient system management and anomaly detection. Traditional log understanding and analysis methods often fail to capture the rich semantic context inherent in log messages, leading to suboptimal monitoring and diagnostic capabilities. This paper aims to bridge the semantic gap by integrating cutting-edge semantic technologies into the log analysis pipeline. We leverage natural language processing, information retrieval, and large language models to enrich log data with semantic information, facilitating a deeper understanding of log messages. Our methodology enhances anomaly detection accuracy by utilizing hierarchical contextual information and pre-training technology, and refining log-based QA processes by log retrieval and log reader. Preliminary results demonstrate a significant improvement in identifying and diagnosing system anomalies, as well as in the automated answering log questions. This research not only presents a breakthrough in log data analysis but also sets the stage for future advancements in intelligent system monitoring and proactive fault resolution. Through this semantic-aware approach, we envision a new paradigm in log analysis that transcends traditional machine learning methods, offering a more robust and intuitive understanding of system behaviors and states.},
booktitle = {Proceedings of the 33rd International Symposium on High-Performance Parallel and Distributed Computing},
pages = {413–416},
numpages = {4},
keywords = {semantic-aware analysis, log understanding, natural language processing, anomaly detection, log parsing},
location = {Pisa, Italy},
series = {HPDC '24}
}

@article{10.1145/3675759,
author = {Mussa, Omar and Rana, Omer and Goossens, Benoit and Orozco Ter wengel, Pablo and Perera, Charith},
title = {ForestQB: Enhancing Linked Data Exploration through Graphical and Conversational UIs Integration},
year = {2024},
issue_date = {September 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {3},
url = {https://doi.org/10.1145/3675759},
doi = {10.1145/3675759},
abstract = {This article introduces the Forest Query Builder (ForestQB), an innovative toolkit designed to enhance the exploration and application of observational Linked Data (LD) within the field of wildlife research and conservation. Addressing the challenges faced by non-experts in navigating Resource Description Framework (RDF) triplestores and executing SPARQL queries, ForestQB employs a novel integrated approach. This approach combines a graphical user interface (GUI) with a conversational user interface (CUI), thereby greatly simplifying the process of query formulation and making observational LD accessible to users without expertise in RDF or SPARQL. Developed through insights derived from a comprehensive ethnographic study involving wildlife researchers, ForestQB is specifically designed to improve the accessibility of SPARQL endpoints and facilitate the exploration of observational LD in wildlife research contexts. To evaluate the effectiveness of our approach, we conducted a user experiment. The results of this evaluation affirm that ForestQB is not only efficient and user-friendly but also plays a crucial role in eliminating barriers for users, facilitating the effective use of observational LD in wildlife conservation and extending its benefits to wider domains. (GitHub Link: github.com/i3omar/ForestQB).},
journal = {ACM J. Comput. Sustain. Soc.},
month = sep,
articleno = {32},
numpages = {33},
keywords = {Linked data, SPARQL, RDF, query builder, visual queryin}
}

@inproceedings{10.1145/3689936.3694692,
author = {\r{A}str\"{o}m, Alexander},
title = {Revisiting Automotive Threat Analysis by Leveraging the Elements of the Threat Landscape},
year = {2024},
isbn = {9798400712326},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3689936.3694692},
doi = {10.1145/3689936.3694692},
abstract = {The automotive industry faces significant challenges due to rapid advancements in areas such as increased connectivity, automated driving, and electrification. These advancements, coupled with an evolving standard and regulatory landscape, place substantial demands on product development, particularly in the realm of cybersecurity. Features that enhance connectivity introduce various external interfaces, leading to numerous attack vectors and potential vulnerabilities in vehicle-connected devices at unprecedented levels. Additionally, the dynamic nature of the threat landscape complicates manufacturers' efforts to maintain adequate security and stay up-to-date. Two major pain points are the extensive resources required and the time-consuming nature of cybersecurity activities. In this paper, we propose a methodology to modularize cybersecurity activities and the corresponding work products related to the threat landscape. These modules are designed to be used as reusable elements in activities mandated by standards such as ISO/SAE 21434.},
booktitle = {Proceedings of the 2024 Cyber Security in CarS Workshop},
pages = {1–12},
numpages = {12},
keywords = {automotive, cybersecurity, threat landscape, threat modelling, threat profiling},
location = {Salt Lake City, UT, USA},
series = {CSCS '24}
}

@article{10.1109/TCBB.2024.3427381,
author = {Taha, Kamal},
title = {Employing Machine Learning Techniques to Detect Protein Function: A Survey, Experimental, and Empirical Evaluations},
year = {2024},
issue_date = {Nov.-Dec. 2024},
publisher = {IEEE Computer Society Press},
address = {Washington, DC, USA},
volume = {21},
number = {6},
issn = {1545-5963},
url = {https://doi.org/10.1109/TCBB.2024.3427381},
doi = {10.1109/TCBB.2024.3427381},
abstract = {This review article delves deeply into the various machine learning (ML) methods and algorithms employed in discerning protein functions. Each method discussed is assessed for its efficacy, limitations, potential improvements, and future prospects. We present an innovative hierarchical classification system that arranges algorithms into intricate categories and unique techniques. This taxonomy is based on a tri-level hierarchy, starting with the methodology category and narrowing down to specific techniques. Such a framework allows for a structured and comprehensive classification of algorithms, assisting researchers in understanding the interrelationships among diverse algorithms and techniques. The study incorporates both empirical and experimental evaluations to differentiate between the techniques. The empirical evaluation ranks the techniques based on four criteria. The experimental assessments rank: (1) individual techniques under the same methodology sub-category, (2) different sub-categories within the same category, and (3) the broad categories themselves. Integrating the innovative methodological classification, empirical findings, and experimental assessments, the article offers a well-rounded understanding of ML strategies in protein function identification. The paper also explores techniques for multi-task and multi-label detection of protein functions, in addition to focusing on single-task methods. Moreover, the paper sheds light on the future avenues of ML in protein function determination.},
journal = {IEEE/ACM Trans. Comput. Biol. Bioinformatics},
month = jul,
pages = {1965–1986},
numpages = {22}
}

@proceedings{10.1145/3660395,
title = {AIBDF '23: Proceedings of the 2023 3rd Guangdong-Hong Kong-Macao Greater Bay Area Artificial Intelligence and Big Data Forum},
year = {2023},
isbn = {9798400716362},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Guangzhou, China}
}

@proceedings{10.1145/3644713,
title = {ICFNDS '23: Proceedings of the 7th International Conference on Future Networks and Distributed Systems},
year = {2023},
isbn = {9798400709036},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Dubai, United Arab Emirates}
}

@proceedings{10.1145/3686424,
title = {EDCS '24: Proceedings of the 2024 Guangdong-Hong Kong-Macao Greater Bay Area International Conference on Education Digitalization and Computer Science},
year = {2024},
isbn = {9798400710360},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Shenzhen, China}
}

@article{10.1145/3690381,
author = {Zhang, Xiaoyu and Shi, Shaoyun and Li, Yishan and Ma, Weizhi and Sun, Peijie and Zhang, Min},
title = {Feature-Enhanced Neural Collaborative Reasoning for Explainable Recommendation},
year = {2024},
issue_date = {January 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {43},
number = {1},
issn = {1046-8188},
url = {https://doi.org/10.1145/3690381},
doi = {10.1145/3690381},
abstract = {Providing reasonable explanations for a specific suggestion given by the recommender can help users trust the system more. As logic rule-based inference is concise, transparent, and aligned with human cognition, it can be adopted to improve the interpretability of recommendation models. Previous work that interprets user preference with logic rules merely focuses on the construction of rules while neglecting the usage of feature embeddings. This limits the model in capturing implicit relationships between features. In this article, we aim to improve both the effectiveness and explainability of recommendation models by simultaneously representing logic rules and feature embeddings. We propose a novel model-intrinsic explainable recommendation method named Feature-Enhanced Neural Collaborative Reasoning (FENCR). The model automatically extracts representative logic rules from massive possibilities in a data-driven way. In addition, we utilize feature interaction-based neural modules to represent logic operators on embeddings. Experiments on two large public datasets show our model outperforms state-of-the-art neural logical recommendation models. Further case analyses demonstrate that FENCR can derive reasonable rules, indicating its high robustness and expandability.1},
journal = {ACM Trans. Inf. Syst.},
month = nov,
articleno = {7},
numpages = {33},
keywords = {collaborative reasoning, explainable recommendation, rule learning}
}

@article{10.1145/3649886,
author = {Zhang, Guangping and Li, Dongsheng and Gu, Hansu and Lu, Tun and Gu, Ning},
title = {Heterogeneous Graph Neural Network with Personalized and Adaptive Diversity for News Recommendation},
year = {2024},
issue_date = {August 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {3},
issn = {1559-1131},
url = {https://doi.org/10.1145/3649886},
doi = {10.1145/3649886},
abstract = {The emergence of online media has facilitated the dissemination of news, but has also introduced the problem of information overload. To address this issue, providing users with accurate and diverse news recommendations has become increasingly important. News possesses rich and heterogeneous content, and the factors that attract users to news reading are varied. Consequently, accurate news recommendation requires modeling of both the heterogeneous content of news and the heterogeneous user-news relationships. Furthermore, users’ news consumption is highly dynamic, which is reflected in the differences in topic concentration among different users and in the real-time changes in user interests. To this end, we propose a Heterogeneous Graph Neural Network with Personalized and Adaptive Diversity for News Recommendation (DivHGNN). DivHGNN first represents the heterogeneous content of news and the heterogeneous user-news relationships as an attributed heterogeneous graph. Then, through a heterogeneous node content adapter, it models the heterogeneous node attributes into aligned and fused node representations. With the proposed attributed heterogeneous graph neural network, DivHGNN integrates the heterogeneous relationships to enhance node representation for accurate news recommendations. We also discuss relation pruning, model deployment, and cold-start issues to further improve model efficiency. In terms of diversity, DivHGNN simultaneously models the variance of nodes through variational representation learning for providing personalized diversity. Additionally, a time-continuous exponentially decaying distribution cache is proposed to model the temporal dynamics of user real-time interests for providing adaptive diversity. Extensive experiments on real-world news datasets demonstrate the effectiveness of the proposed method.},
journal = {ACM Trans. Web},
month = may,
articleno = {34},
numpages = {33},
keywords = {News recommendation, graph neural network, heterogeneous information network, recommendation diversity}
}

@inproceedings{10.1145/3651671.3651759,
author = {Yang, Shuling and Chen, Hanzhu and Fang, Binbin},
title = {QuDial: A Quadruple-driven Dialogue System for Real Estate Consulting Services},
year = {2024},
isbn = {9798400709234},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3651671.3651759},
doi = {10.1145/3651671.3651759},
abstract = {Establishing connections with users is a critical task for brokers in real estate consulting dialogues and can be assisted by a task-oriented dialogue system. Existing task-oriented systems typically follow a pipeline structure with four subtasks, achieving great success in many domains. However, these systems confront expensive development costs in real estate domain, as they require multiple subtasks and multiple types of data labels. To tackle this problem, we introduce a novel semantic frame of quadruples {(action, subject, predicate, object)}, to build a simplified system with fewer subtasks and lower data costs than existing methods. Based on this, we propose QuDial, a simple yet effective quadruple-driven dialogue system that consists of two subtasks: Natural Language Understanding (NLU) and Dialogue Policy Learning (DPL). In NLU, we parse each dialogue into a quadruple sequence, which captures the evolution of dialogue contents. Then, in DPL, we encode the historical quadruple sequence to predict the next quadruple, which provides the main response content for brokers. Experiments on real estate business domain demonstrate that QuDial effectively improves the response predictions with its two simple subtasks.},
booktitle = {Proceedings of the 2024 16th International Conference on Machine Learning and Computing},
pages = {609–615},
numpages = {7},
location = {Shenzhen, China},
series = {ICMLC '24}
}

@inproceedings{10.1145/3627673.3680009,
author = {Agrawal, Sanjay and Merugu, Srujana and Sembium, Vivek},
title = {Boosting Entity Recognition by leveraging Cross-task Domain Models for Weak Supervision},
year = {2024},
isbn = {9798400704369},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627673.3680009},
doi = {10.1145/3627673.3680009},
abstract = {Entity Recognition (ER) is a common natural language processing task encountered in a number of real-world applications. For common domains and named entities such as places and organisations, there exists sufficient high quality annotated data and foundational models such as T5 and GPT-3.5 also provide highly accurate predictions. However, for niche domains such as e-commerce and medicine with specialized entity types, there is a paucity of labeled data since manual labeling of tokens is often time-consuming and expensive, which makes entity recognition challenging for such domains. Recent works such as NEEDLE [48] propose hybrid solutions to efficiently combine a small amount of strongly labeled (human-annotated) with a large amount of weakly labeled (distant supervision) data to yield superior performance relative to supervised training. The extensive noise in the weakly labeled data, however, remains a challenge. In this paper, we propose WeSDoM (Weak Supervision with Domain Models), which leverages pretrained encoder models from the same domain but different tasks to create domain ontologies that can enable the creation of less noisy weakly labeled data. Experiments on internal e-commerce and public biomedical NER datasets demonstrate that WeSDoM outperforms existing SOTA baselines by a significant margin. We achieve new SOTA F1 scores on two popular Biomedical NER datasets, BC5CDR-chem 94.27, BC5CDR-disease 91.23.},
booktitle = {Proceedings of the 33rd ACM International Conference on Information and Knowledge Management},
pages = {4324–4331},
numpages = {8},
keywords = {cross-task domain encoder, entity recognition, ontologies, weak supervision},
location = {Boise, ID, USA},
series = {CIKM '24}
}

@proceedings{10.1145/3640824,
title = {CCEAI '24: Proceedings of the 2024 8th International Conference on Control Engineering and Artificial Intelligence},
year = {2024},
isbn = {9798400707971},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Shanghai, China}
}

@inproceedings{10.1145/3665689.3665768,
author = {Deng, Qiwen and Han, Yuexia and Sun, Jianfei},
title = {A Joint Framework for Predicting Disease-Gene Interactions Based on Pre-trained Models and Graph Attention Networks},
year = {2024},
isbn = {9798400716645},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3665689.3665768},
doi = {10.1145/3665689.3665768},
abstract = {The study of disease-gene interactions is crucial in biomedical research. Identifying genes associated with diseases can provide critical insights into disease mechanisms, facilitate early diagnosis, and contribute to the development of targeted therapies. In this paper, we propose a novel framework for predicting disease-gene interactions called the PRGAT-DG, which utilizes pre-trained language models and graph attention networks to extract semantic and graph structure features respectively. Moreover, we introduce residual structure to alleviate the problem of excessive smoothing. Experimental results on a dataset released by Stanford University demonstrate the remarkable predictive accuracy of our framework, showcasing its superiority compared to other existing methods. This research holds significant implications for advancing our understanding of disease-gene interaction mechanisms and accelerating the development of relevant therapeutics.},
booktitle = {Proceedings of the 2024 4th International Conference on Bioinformatics and Intelligent Computing},
pages = {474–478},
numpages = {5},
location = {Beijing, China},
series = {BIC '24}
}

@proceedings{10.1145/3629296,
title = {ICETC '23: Proceedings of the 15th International Conference on Education Technology and Computers},
year = {2023},
isbn = {9798400709111},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Barcelona, Spain}
}

@article{10.1145/3678470,
author = {Swaileh A. Alzaidi, Muhammad and Alshammari, Alya and Almanea, Manar and Al-khawaja, Haneen A. and Al Sultan, Hanan and Alotaibi, Shoayee and Almukadi, Wafa},
title = {A Text-Inception-Based Natural Language Processing Model for Sentiment Analysis of Drug Experiences},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {2375-4699},
url = {https://doi.org/10.1145/3678470},
doi = {10.1145/3678470},
abstract = {The study of sentiment in Natural Language Processing (NLP) is among the most successful research areas because of the availability of millions of user opinions online since the turn of the century. The economic, political, and medical fields are just some of the many that have benefited from studies of sentiment research. While numerous studies have examined more mainstream topics like consumer electronics, movies, and restaurants, relatively few have examined health and medical concerns. Considerable insight into where to direct efforts to improve public health might be gained by a study of how people feel about healthcare as a whole and of individual drug experiences in particular. When it comes to medicine, automatic analysis of online user evaluations paves the way for sifting through massive amounts of user feedback to find information regarding medications' efficacy and side effects that might be used to enhance pharmacovigilance programs. Simple rules-based methods have given way to more complex machine learning approaches like deep learning, which is developing as a technology for many natural language processing jobs. The opensource datasets have been analyzed with models that use word embeddings and term frequency-inverse document frequency (TF-IDF). A feature-enhanced text-inception model for sentiment classification was presented to work in tandem with this approach. The model first employed a cutting-edge text-inception module to glean useful shallow features from the text. K-MaxPooling was subsequently employed to reduce the dimensionality of its shallow and deep includes as well as enhance the generalization of characteristics, and a deep feature extraction module was formed using the bidirectional gated recurrent unit (Bi-GRU) and the capsule neural network to comprehend the text's semantic data. By combining traditional methods with cutting-edge artificial intelligence techniques, this hybrid approach can revolutionize public health initiatives, decision-making, and pharmacovigilance in the healthcare industry. This model achieved an exceptional accuracy rate of 99%, underscoring its effectiveness in sentiment classification and demonstrating its potential to significantly contribute to advancing healthcare and medical research.},
note = {Just Accepted},
journal = {ACM Trans. Asian Low-Resour. Lang. Inf. Process.},
month = aug,
keywords = {Natural Language Processing (NLP), User Opinions, Healthcare, Medical Sentiment, Public Health, Deep learning}
}

@proceedings{10.1145/3635059,
title = {PCI '23: Proceedings of the 27th Pan-Hellenic Conference on Progress in Computing and Informatics},
year = {2023},
isbn = {9798400716263},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Lamia, Greece}
}

@inproceedings{10.1145/3638884.3638979,
author = {Wu, Yu and Miao, Lin and Li, Han},
title = {Attribute Value Extraction in Weapon Domain Based on Bi-LSTM and Attention},
year = {2024},
isbn = {9798400708909},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3638884.3638979},
doi = {10.1145/3638884.3638979},
abstract = {Aiming at the problem that the traditional extraction method caused by the diversification of weapon attributes has a large amount of work to construct the label of weapon attributes, in this paper, we propose a weapon attribute value extraction method based on bidirectional long-term and short-term memory network (Bi-LSTM) and attention mechanism. The method first uses the Bi-LSTM model to extract the features of the input text and attribute names. Then, the attention mechanism focuses on the relations between words and attributes in the sentence. Afterward, the global BIO tag marks the position of the attribute values in the sentence. In this way, the method can reduce the workload during the corpus preparation period to improve the generalization ability of the model so that it can extract different weapon attribute data. Compared with Bi-LSTM, Bi-LSTM_CRF, and OpenTag from the experimental results, the F1 values of the proposed model on the weapon domain attribute dataset are increased by about 6.9%, 5.7%, and 2.5%, respectively.},
booktitle = {Proceedings of the 2023 9th International Conference on Communication and Information Processing},
pages = {603–610},
numpages = {8},
keywords = {Attribute Value Extraction, Information Extraction, Knowledge Base, Natural Language Processing},
location = {Lingshui, China},
series = {ICCIP '23}
}

@article{10.1613/jair.1.15407,
author = {Castagna, Federico and K\"{o}kciyan, Nadin and Sassoon, Isabel and Parsons, Simon and Sklar, Elizabeth},
title = {Computational Argumentation-based Chatbots: A Survey},
year = {2024},
issue_date = {Sep 2024},
publisher = {AI Access Foundation},
address = {El Segundo, CA, USA},
volume = {80},
issn = {1076-9757},
url = {https://doi.org/10.1613/jair.1.15407},
doi = {10.1613/jair.1.15407},
abstract = {Chatbots are conversational software applications designed to interact dialectically with users for a plethora of different purposes. Surprisingly, these colloquial agents have only recently been coupled with computational models of arguments (i.e. computational argumentation), whose aim is to formalise, in a machine-readable format, the ordinary exchange of information that characterises human communications. Chatbots may employ argumentation with different degrees and in a variety of manners. The present survey sifts through the literature to review papers concerning this kind of argumentation-based bot, drawing conclusions about the benefits and drawbacks that this approach entails in comparison with standard chatbots, while also envisaging possible future development and integration with the Transformer-based architecture and state-of-the-art Large Language models.},
journal = {J. Artif. Int. Res.},
month = sep,
numpages = {40}
}

@proceedings{10.1145/3696230,
title = {ICDTE '24: Proceedings of the 2024 8th International Conference on Digital Technology in Education (ICDTE)},
year = {2024},
isbn = {9798400717574},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@inproceedings{10.1109/JCDL52503.2021.00021,
author = {Iana, Andreea and Paulheim, Heiko},
title = {GraphConfRec: A Graph Neural Network-Based Conference Recommender System},
year = {2024},
isbn = {9781665417709},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/JCDL52503.2021.00021},
doi = {10.1109/JCDL52503.2021.00021},
abstract = {In today's academic publishing model, especially in Computer Science, conferences commonly constitute the main platforms for releasing the latest peer-reviewed advancements in their respective fields. However, choosing a suitable academic venue for publishing one's research can represent a challenging task considering the plethora of available conferences, particularly for those at the start of their academic careers, or for those seeking to publish outside of their usual domain. In this paper, we propose GraphConfRec, a conference recommender system which combines SciGraph and graph neural networks, to infer suggestions based not only on title and abstract, but also on co-authorship and citation relationships. GraphConfRec achieves a recall@10 of up to 0.580 and a MAP of up to 0.336 with a graph attention network-based recommendation model. A user study with 25 subjects supports the positive results.},
booktitle = {Proceedings of the 2021 ACM/IEEE Joint Conference on Digital Libraries},
pages = {90–99},
numpages = {10},
keywords = {recommender system, graph neural network, SciGraph, scientific publications},
location = {Virtual Event},
series = {JCDL '21}
}

@article{10.1145/3637321,
author = {Peng, Zhenhui and Chen, Qiaoyi and Shen, Zhiyu and Ma, Xiaojuan and Oulasvirta, Antti},
title = {DesignQuizzer: A Community-Powered Conversational Agent for Learning Visual Design},
year = {2024},
issue_date = {April 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {8},
number = {CSCW1},
url = {https://doi.org/10.1145/3637321},
doi = {10.1145/3637321},
abstract = {Online design communities, where members exchange free-form views on others' designs, offer a space for beginners to learn visual design. However, the content of these communities is often unorganized for learners, containing many redundancies and irrelevant comments. In this paper, we propose a computational approach for leveraging online design communities to run a conversational agent that assists informal learning of visual elements (e.g., color and space). Our method extracts critiques, suggestions, and rationales on visual elements from comments. We present DesignQuizzer, which asks questions about visual design in UI examples and provides structured comment summaries. Two user studies demonstrate the engagement and usefulness of DesignQuizzer compared with the baseline (reading reddit.com/r/UI_design). We also showcase how effectively novices can apply what they learn with DesignQuizzer in a design critique task and a visual design task. We discuss how to use our approach with other communities and offer design considerations for community-powered learning support tools.},
journal = {Proc. ACM Hum.-Comput. Interact.},
month = apr,
articleno = {44},
numpages = {40},
keywords = {comment processing, informal learning, online communities, visual design}
}

@proceedings{10.1145/3623509,
title = {TEI '24: Proceedings of the Eighteenth International Conference on Tangible, Embedded, and Embodied Interaction},
year = {2024},
isbn = {9798400704024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Cork, Ireland}
}

@proceedings{10.1145/3669754,
title = {ICCAI '24: Proceedings of the 2024 10th International Conference on Computing and Artificial Intelligence},
year = {2024},
isbn = {9798400717055},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Bali Island, Indonesia}
}

@inproceedings{10.1145/3589335.3651898,
author = {Chen, Zefeng and Gan, Wensheng and Sun, Jiayi and Wu, Jiayang and Yu, Philip S.},
title = {Open Metaverse: Issues, Evolution, and Future},
year = {2024},
isbn = {9798400701726},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589335.3651898},
doi = {10.1145/3589335.3651898},
abstract = {With the content evolution on the web and the Internet, there is a need for cyberspace that can be used to work, live, and play in digital worlds regardless of geography. The Metaverse provides the possibility of the future Internet, representing a future trend for the web and the Internet. In the future, the Metaverse is a dataspace where the real and the virtual are combined instead of a virtual space. In this paper, we have a comprehensive survey of the compelling Metaverse, including issues of the Metaverse and Metaverse's evolution and future. We hope this survey can provide some helpful prospects and insightful directions for the Metaverse.},
booktitle = {Companion Proceedings of the ACM Web Conference 2024},
pages = {1351–1360},
numpages = {10},
keywords = {dataspace, digital world, evolution, internet, issues, metaverse},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1109/ASE56229.2023.00150,
author = {Li, Linyu and Xu, Sihan and Liu, Yang and Gao, Ya and Cai, Xiangrui and Wu, Jiarun and Song, Wenli and Liu, Zheli},
title = {LiSum: Open Source Software License Summarization with Multi-Task Learning},
year = {2024},
isbn = {9798350329964},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ASE56229.2023.00150},
doi = {10.1109/ASE56229.2023.00150},
abstract = {Open source software (OSS) licenses regulate the conditions under which users can reuse, modify, and distribute the software legally. However, there exist various OSS licenses in the community, written in a formal language, which are typically long and complicated to understand. In this paper, we conducted a 661-participants online survey to investigate the perspectives and practices of developers towards OSS licenses. The user study revealed an indeed need for an automated tool to facilitate license understanding. Motivated by the user study and the fast growth of licenses in the community, we propose the first study towards automated license summarization. Specifically, we released the first high quality text summarization dataset and designed two tasks, i.e., license text summarization (LTS), aiming at generating a relatively short summary for an arbitrary license, and license term classification (LTC), focusing on the attitude inference towards a predefined set of key license terms (e.g., Distribute). Aiming at the two tasks, we present LiSum, a multi-task learning method to help developers overcome the obstacles of understanding OSS licenses. Comprehensive experiments demonstrated that the proposed jointly training objective boosted the performance on both tasks, surpassing state-of-the-art baselines with gains of at least 5 points w.r.t. F1 scores of four summarization metrics and achieving 95.13% micro average F1 score for classification simultaneously. We released all the datasets, the replication package, and the questionnaires for the community.},
booktitle = {Proceedings of the 38th IEEE/ACM International Conference on Automated Software Engineering},
pages = {787–799},
numpages = {13},
keywords = {open source software licenses, multi-task learning, license comprehension},
location = {Echternach, Luxembourg},
series = {ASE '23}
}

@proceedings{10.1145/3641584,
title = {AIPR '23: Proceedings of the 2023 6th International Conference on Artificial Intelligence and Pattern Recognition},
year = {2023},
isbn = {9798400707674},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Xiamen, China}
}

@proceedings{10.1145/3638530,
title = {GECCO '24 Companion: Proceedings of the Genetic and Evolutionary Computation Conference Companion},
year = {2024},
isbn = {9798400704956},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Melbourne, VIC, Australia}
}

@inproceedings{10.1145/3589335.3651464,
author = {Huang, Run and Chattopadhyay, Souti},
title = {A Tale of Two Communities: Exploring Academic References on Stack Overflow},
year = {2024},
isbn = {9798400701726},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589335.3651464},
doi = {10.1145/3589335.3651464},
abstract = {Stack Overflow is widely recognized by software practitioners as the go-to resource for addressing technical issues and sharing practical solutions. While not typically seen as a scholarly forum, users on Stack Overflow commonly refer to academic sources in their discussions. Yet, little is known about these referenced academic works and how they intersect the needs and interests of the Stack Overflow community. To bridge this gap, we conducted an exploratory large-scale study on the landscape of academic references in Stack Overflow. Our findings reveal that Stack Overflow communities with different domains of interest engage with academic literature at varying frequencies and speeds. The contradicting patterns suggest that some disciplines may have diverged in their interests and development trajectories from the corresponding practitioner community. Finally, we discuss the potential of Stack Overflow in gauging the real-world relevance of academic research.},
booktitle = {Companion Proceedings of the ACM Web Conference 2024},
pages = {855–858},
numpages = {4},
keywords = {citation analysis, industry impact, stack overflow},
location = {Singapore, Singapore},
series = {WWW '24}
}

@article{10.1109/TCBB.2024.3426491,
author = {Kumar, Vikash and Deepak, Akshay and Ranjan, Ashish and Prakash, Aravind},
title = {&lt;italic&gt;Bi-SeqCNN:&lt;/italic&gt; A Novel Light-Weight Bi-Directional CNN Architecture for Protein Function Prediction},
year = {2024},
issue_date = {Nov.-Dec. 2024},
publisher = {IEEE Computer Society Press},
address = {Washington, DC, USA},
volume = {21},
number = {6},
issn = {1545-5963},
url = {https://doi.org/10.1109/TCBB.2024.3426491},
doi = {10.1109/TCBB.2024.3426491},
abstract = {Deep learning approaches, such as convolution neural networks (CNNs) and deep recurrent neural networks (RNNs), have been the backbone for predicting protein function, with promising state-of-the-art (SOTA) results. RNNs with an in-built ability (i) focus on past information, (ii) collect both &lt;italic&gt;short-and-long&lt;/italic&gt; range dependency information, and (iii) bi-directional processing offers a strong sequential processing mechanism. CNNs, however, are confined to focusing on &lt;italic&gt;short-term&lt;/italic&gt; information from both the past and the future, although they offer parallelism. Therefore, a novel &lt;italic&gt;bi-directional CNN&lt;/italic&gt; that strictly complies with the sequential processing mechanism of RNNs is introduced and is used for developing a protein function prediction framework, Bi-SeqCNN. This is a sub-sequence-based framework. Further, Bi-SeqCNN&lt;inline-formula&gt;&lt;tex-math notation="LaTeX"&gt;$^+$&lt;/tex-math&gt;&lt;alternatives&gt;&lt;mml:math&gt;&lt;mml:msup&gt;&lt;mml:mrow/&gt;&lt;mml:mo&gt;+&lt;/mml:mo&gt;&lt;/mml:msup&gt;&lt;/mml:math&gt;&lt;inline-graphic xlink:href="kumar-ieq1-3426491.gif"/&gt;&lt;/alternatives&gt;&lt;/inline-formula&gt; is an ensemble approach to better the prediction results. To our knowledge, this is the first time &lt;italic&gt;bi-directional CNNs&lt;/italic&gt; are employed for general temporal data analysis and not just for protein sequences. The proposed architecture produces improvements up to +5.5% over contemporary SOTA methods on three benchmark protein sequence datasets. Moreover, it is substantially lighter and attain these results with (0.50–0.70 times) fewer parameters than the SOTA methods.},
journal = {IEEE/ACM Trans. Comput. Biol. Bioinformatics},
month = jul,
pages = {1922–1933},
numpages = {12}
}

@proceedings{10.1145/3661904,
title = {ICETT '24: Proceedings of the 2024 10th International Conference on Education and Training Technologies},
year = {2024},
isbn = {9798400717895},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Macau, China}
}

@inproceedings{10.1145/3616901.3616924,
author = {Kong, Xiangyi},
title = {Balanced Data Augmentation for Dialogue State Tracking},
year = {2024},
isbn = {9798400707544},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3616901.3616924},
doi = {10.1145/3616901.3616924},
abstract = {Data augmentation methods for dialogue state tracking (DST) have made progress on producing more data based on internal or external datasets. However, they fall short in the balancing the generated dataset. We propose a balanced data augmentation method for DST to improve the quality of generated dataset. Our approach has two steps: (1) balance method in selecting slots and values: modify the possibility of selecting each slot and value when adding or replacing slots; (2) balance method for under-generation and over-generation: generate or delete cases based on their overall frequency of slots. We apply our method to MultiWOZ and the dataset generated by our method is more balance than the original and COCO augmented data. Then we evaluate a strong DST model trained on our generated training set. The performance of this DST model improves 5.93% (from 55.04% to 60.97%) joint goal accuracy than original model, and also surpasses the performance of the model trained on the data generated by COCO. This demonstrates the advantages and potential of our approach to be incorporated into data augmentation for DST.},
booktitle = {Proceedings of the 2023 International Conference on Frontiers of Artificial Intelligence and Machine Learning},
pages = {98–103},
numpages = {6},
location = {Beijing, China},
series = {FAIML '23}
}

@proceedings{10.1145/3638985,
title = {ICIT '23: Proceedings of the 2023 11th International Conference on Information Technology: IoT and Smart City},
year = {2023},
isbn = {9798400709043},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Kyoto, Japan}
}

@proceedings{10.1109/3686225,
title = {JCDL '21: Proceedings of the 2021 ACM/IEEE Joint Conference on Digital Libraries},
year = {2021},
isbn = {9781665417709},
publisher = {IEEE Press},
location = {Virtual Event}
}

@article{10.1145/3656341,
author = {Sun, Weisong and Fang, Chunrong and Ge, Yifei and Hu, Yuling and Chen, Yuchen and Zhang, Quanjun and Ge, Xiuting and Liu, Yang and Chen, Zhenyu},
title = {A Survey of Source Code Search: A 3-Dimensional Perspective},
year = {2024},
issue_date = {July 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {33},
number = {6},
issn = {1049-331X},
url = {https://doi.org/10.1145/3656341},
doi = {10.1145/3656341},
abstract = {(Source) code search is widely concerned by software engineering researchers because it can improve the productivity and quality of software development. Given a functionality requirement usually described in a natural language sentence, a code search system can retrieve code snippets that satisfy the requirement from a large-scale code corpus, e.g., GitHub. To realize effective and efficient code search, many techniques have been proposed successively. These techniques improve code search performance mainly by optimizing three core components, including query understanding component, code understanding component, and query-code matching component. In this article, we provide a 3-dimensional perspective survey for code search. Specifically, we categorize existing code search studies into query-end optimization techniques, code-end optimization techniques, and match-end optimization techniques according to the specific components they optimize. These optimization techniques are proposed to enhance the performance of specific components, and thus the overall performance of code search. Considering that each end can be optimized independently and contributes to the code search performance, we treat each end as a dimension. Therefore, this survey is 3-dimensional in nature, and it provides a comprehensive summary of each dimension in detail. To understand the research trends of the three dimensions in existing code search studies, we systematically review 68 relevant literatures. Different from existing code search surveys that only focus on the query end or code end or introduce various aspects shallowly (including codebase, evaluation metrics, modeling technique, etc.), our survey provides a more nuanced analysis and review of the evolution and development of the underlying techniques used in the three ends. Based on a systematic review and summary of existing work, we outline several open challenges and opportunities at the three ends that remain to be addressed in future work.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = jun,
articleno = {166},
numpages = {51},
keywords = {Source code search, deep learning, query-end optimization, code-end optimization, match-end optimization}
}

@article{10.1145/3604612,
author = {Dave, Nakul R. and Mehta, Mayuri A. and Kotecha, Ketan},
title = {A Systematic Review of Stemmers of Indian and Non-Indian Vernacular Languages},
year = {2024},
issue_date = {January 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {1},
issn = {2375-4699},
url = {https://doi.org/10.1145/3604612},
doi = {10.1145/3604612},
abstract = {The stemming process is crucial and significant in the pre-processing step of natural language processing. The stemmer oversees the stemming process. It facilitates the extraction of morphological variants of a root or base word from the provided word. Over the period, several stemmers for various vernacular languages have been proposed. However, very few research studies have comprehensively investigated these available stemmers. This article makes multifold contributions. First, we discuss the various stemmers of 15 Indian and 17 non-Indian languages describing their key points, benefits, and drawbacks. All the Indian languages for which stemmers have been built are covered in this study. For the non-Indian languages, stemmers of commonly spoken languages have been covered. Second, we present a language-wise comparative analysis of stemmers based on our identified parameters. Third, we discuss the wordnets and dictionaries available for different languages. Fourth, we provide details of the datasets available for various languages. Fifth, we also provide challenges in existing stemmers and future directions for future researchers. The study presented in this article reveals that significant research has been carried out for the stemmers of influential languages such as English, Arabic, and Urdu. On the other hand, languages with d resources, such as Farsi, Polish, Odia, Amharic, and others, have received the least attention for research. Moreover, rigorous analysis reveals that most of the stemmers suffer from over-stemming errors. With a complete catalogue of available stemmers, this study aims at assisting the researchers and professionals working in the areas such as information retrieval, semantic annotation, word meaning disambiguation, and ontology learning.},
journal = {ACM Trans. Asian Low-Resour. Lang. Inf. Process.},
month = jan,
articleno = {18},
numpages = {51},
keywords = {Natural Language Processing (NLP), stemming, rule-based stemmer, dictionary-based stemmer, hybrid stemmer, over-stemming error, under-stemming error}
}

@article{10.1145/3582261,
author = {Wei, Kaiwen and Jin, Li and Zhang, Zequn and Guo, Zhi and Li, Xiaoyu and Liu, Qing and Feng, Weimiao},
title = {More Than Syntaxes: Investigating Semantics to Zero-shot Cross-lingual Relation Extraction and Event Argument Role Labelling},
year = {2024},
issue_date = {May 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {23},
number = {5},
issn = {2375-4699},
url = {https://doi.org/10.1145/3582261},
doi = {10.1145/3582261},
abstract = {Syntactic dependency structures are commonly utilized as language-agnostic features to solve the word order difference issues in zero-shot cross-lingual relation and event extraction tasks. However, while sentences in multiple forms can be employed to express the same meaning, the syntactic structure may vary considerably in specific scenarios. To fix this problem, we find semantics are rarely considered, which could provide a more consistent semantic analysis of sentences and be served as another bridge between different languages. Therefore, in this article, we introduce Syntax and Semantic Driven Network (SSDN) to equip syntax and semantic knowledge across languages simultaneously. Specifically, predicate–argument structures from semantic role labelling are explicitly incorporated into word representations. Then, a semantic-aware relational graph convolutional network and a transformer-based encoder are utilized to model both semantic dependency and syntactic dependency structures, respectively. Finally, a fusion module is introduced to integrate output representations adaptively. We conduct experiments on the widely used Automatic Content Extraction 2005 English, Chinese, and Arabic datasets. The evaluation results demonstrate that the proposed method achieves the state-of-the-art performance. Further study also indicates SSDN could produce robust representations that facilitate the transfer operations across languages.},
journal = {ACM Trans. Asian Low-Resour. Lang. Inf. Process.},
month = may,
articleno = {61},
numpages = {21},
keywords = {Cross-lingual relation and event extraction, zero-resource transfer, semantic parsing, relational graph convolutional network}
}

@proceedings{10.1145/3686812,
title = {ICCMS '24: Proceedings of the 2024 16th International Conference on Computer Modeling and Simulation},
year = {2024},
isbn = {9798400717215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Dalian, China}
}

@proceedings{10.1145/3678890,
title = {RAID '24: Proceedings of the 27th International Symposium on Research in Attacks, Intrusions and Defenses},
year = {2024},
isbn = {9798400709593},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Padua, Italy}
}

@proceedings{10.1145/3666015,
title = {ICSSP '24: Proceedings of the 2024 International Conference on Software and Systems Processes},
year = {2024},
isbn = {9798400709913},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {M\, Germany}
}

@inproceedings{10.1145/3702038.3702113,
author = {Braga, Dieinison Jack Freire and Silva, Marisa Carmo da and Lima, Raul de Ara\'{u}jo and Barbosa, Gabriel Diniz Junqueira and Barbosa, Simone Diniz Junqueira},
title = {VisStoryMaker: supporting non-expert analysts in visually exploring datasets and communicating insights with visual annotations and data stories},
year = {2024},
isbn = {9798400712241},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3702038.3702113},
doi = {10.1145/3702038.3702113},
abstract = {Due to data production and availability growth, professionals in several disciplines have been facing an increasing need to explore and understand data, obtain insights, and communicate them effectively. Many visualization systems have been developed commercially and within the research community to support non-expert analysts. We can consider at least three challenges these tools aim to face: support the selection of appropriate visualizations and decide on the visual mappings, extract and communicate factual information from the visualizations, and use visualizations in data-rich narratives. In response to these challenges, we developed VisStoryMaker, a visualization tool that supports both exploration and communication about data. To aid users in exploring and understanding data, VisStoryMaker recommends visualizations through system-generated questions and data facts. To support communicating about data, the system recommends visual annotations of data facts and provides a story-building module, allowing analysts to use the generated charts and facts as a blueprint for a data story. We have conducted empirical studies to compare VisStoryMaker’s features with existing applications: chart recommendations with Voyager&nbsp;2, storytelling construction with Flourish, and data facts and chart annotations with Tableau. Our findings indicate that the system-generated questions and data facts supported non-expert analysts in exploratory analysis. They perceived visual data facts annotations as useful and supported them in raising hypotheses about the data, understanding data, and leading to insights, thus enhancing data analysis. Participants perceived the visual annotations and StoryMaker as helpful in organizing the system-generated pieces of information and incorporating them into comprehensive narratives and presentations.},
booktitle = {Proceedings of the XXIII Brazilian Symposium on Human Factors in Computing Systems},
articleno = {74},
numpages = {15},
keywords = {Visualization recommendations, Exploratory questions, Data facts, Visual annotations, Data story, Visual data exploration, Visual data communication},
location = {
},
series = {IHC '24}
}

@article{10.1109/TASLP.2024.3485547,
author = {Ma, Jun-Yu and Gu, Jia-Chen and Ling, Zhen-Hua and Liu, Quan and Liu, Cong and Hu, Guoping},
title = {Syntax-Augmented Hierarchical Interactive Encoder for Zero-Shot Cross-Lingual Information Extraction},
year = {2024},
issue_date = {2024},
publisher = {IEEE Press},
volume = {32},
issn = {2329-9290},
url = {https://doi.org/10.1109/TASLP.2024.3485547},
doi = {10.1109/TASLP.2024.3485547},
abstract = {Zero-shot cross-lingual information extraction (IE) aims at constructing an IE model for some low-resource target languages, given annotations exclusively in some rich-resource languages. Recent studies have shown language-universal features can bridge the gap between languages. However, prior work has neither explored the potential of establishing interactions between language-universal features and contextual representations nor incorporated features that can effectively model constituent span attributes and relationships between multiple spans. In this study, a &lt;bold&gt;s&lt;/bold&gt;yntax-augmented &lt;bold&gt;h&lt;/bold&gt;ierarchical &lt;bold&gt;in&lt;/bold&gt;teractive &lt;bold&gt;e&lt;/bold&gt;ncoder (SHINE) is proposed to transfer cross-lingual IE knowledge. The proposed encoder is capable of interactively capturing complementary information between features and contextual information, to derive language-agnostic representations for various cross-lingual IE tasks. Concretely, a multi-level interaction network is designed to hierarchically interact the complementary information to strengthen domain adaptability. Besides, in addition to the well-studied word-level syntax features of part-of-speech and dependency relation, a new span-level syntax feature of constituency structure is introduced to model the constituent span information which is crucial for IE. Experiments across seven languages on three IE tasks and four benchmarks verify the effectiveness and generalization ability of the proposed method.},
journal = {IEEE/ACM Trans. Audio, Speech and Lang. Proc.},
month = oct,
pages = {4795–4809},
numpages = {15}
}

@proceedings{10.1145/3691422,
title = {ICEME '24: Proceedings of the 2024 15th International Conference on E-business, Management and Economics},
year = {2024},
isbn = {9798400717260},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3631085,
title = {SBGames '23: Proceedings of the 22nd Brazilian Symposium on Games and Digital Entertainment},
year = {2023},
isbn = {9798400716270},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Rio Grande (RS), Brazil}
}

@proceedings{10.1145/3703847,
title = {SHWID '24: Proceedings of the 2024 International Conference on Smart Healthcare and Wearable Intelligent Devices},
year = {2024},
isbn = {9798400709746},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3698062,
title = {WSSE '24: Proceedings of the 2024 The 6th World Symposium on Software Engineering (WSSE)},
year = {2024},
isbn = {9798400717086},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3697467,
title = {IoTML '24: Proceedings of the 2024 4th  International Conference on Internet of Things and Machine Learning},
year = {2024},
isbn = {9798400710353},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@inproceedings{10.1145/3597503.3639185,
author = {Ferrara, Carmine and Casillo, Francesco and Gravino, Carmine and De Lucia, Andrea and Palomba, Fabio},
title = {ReFAIR: Toward a Context-Aware Recommender for Fairness Requirements Engineering},
year = {2024},
isbn = {9798400702174},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3597503.3639185},
doi = {10.1145/3597503.3639185},
abstract = {Machine learning (ML) is increasingly being used as a key component of most software systems, yet serious concerns have been raised about the fairness of ML predictions. Researchers have been proposing novel methods to support the development of fair machine learning solutions. Nonetheless, most of them can only be used in late development stages, e.g., during model training, while there is a lack of methods that may provide practitioners with early fairness analytics enabling the treatment of fairness throughout the development lifecycle. This paper proposes ReFair, a novel context-aware requirements engineering framework that allows to classify sensitive features from User Stories. By exploiting natural language processing and word embedding techniques, our framework first identifies both the use case domain and the machine learning task to be performed in the system being developed; afterward, it recommends which are the context-specific sensitive features to be considered during the implementation. We assess the capabilities of ReFair by experimenting it against a synthetic dataset---which we built as part of our research---composed of 12,401 User Stories related to 34 application domains. Our findings showcase the high accuracy of ReFair, other than highlighting its current limitations.},
booktitle = {Proceedings of the IEEE/ACM 46th International Conference on Software Engineering},
articleno = {213},
numpages = {12},
keywords = {software fairness, machine learning, requirements engineering},
location = {Lisbon, Portugal},
series = {ICSE '24}
}

@inproceedings{10.1109/JCDL52503.2021.00060,
author = {Gunaratne, Chathika and Walker, Vickie and Rooney, Andrew and Patton, Robert and Wolfe, Mary and Schmitt, Charles},
title = {Weak Supervision for Scientific Document Relevance Tagging Drahomira Herrmannova},
year = {2024},
isbn = {9781665417709},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/JCDL52503.2021.00060},
doi = {10.1109/JCDL52503.2021.00060},
abstract = {Developing training data for predicting the relevance of research articles to scientific concepts is a resource-intensive process, and existing datasets are only available for limited subject domains. In this work, we investigate the possibility of weakly supervised data generation for developing relevance models. We approach this by generating document, query, and label triples in an automated manner and by using this data to create a training set for a classification model. Published documents were sampled from an open access repository, and the concepts appearing in these documents were used as queries. We use the location of occurrence of each query concept within a document to determine the relevance label. We find that a classification model trained on this synthetic data can learn to tag documents according to their relevance to a query surprisingly well, providing an 11% f-score improvement over a model trained on ground truth data.},
booktitle = {Proceedings of the 2021 ACM/IEEE Joint Conference on Digital Libraries},
pages = {338–339},
numpages = {2},
location = {Virtual Event},
series = {JCDL '21}
}

@article{10.1145/3638243,
author = {Oakes, Bentley James and Famelis, Michalis and Sahraoui, Houari},
title = {Building Domain-Specific Machine Learning Workflows: A Conceptual Framework for the State of the Practice},
year = {2024},
issue_date = {May 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {33},
number = {4},
issn = {1049-331X},
url = {https://doi.org/10.1145/3638243},
doi = {10.1145/3638243},
abstract = {Domain experts are increasingly employing machine learning to solve their domain-specific problems. This article presents to software engineering researchers the six key challenges that a domain expert faces in addressing their problem with a computational workflow, and the underlying executable implementation. These challenges arise out of our conceptual framework which presents the “route” of transformations that a domain expert may choose to take while developing their solution.To ground our conceptual framework in the state of the practice, this article discusses a selection of available textual and graphical workflow systems and their support for the transformations described in our framework. Example studies from the literature in various domains are also examined to highlight the tools used by the domain experts as well as a classification of the domain specificity and machine learning usage of their problem, workflow, and implementation.The state of the practice informs our discussion of the six key challenges, where we identify which challenges and transformations are not sufficiently addressed by available tools. We also suggest possible research directions for software engineering researchers to increase the automation of these tools and disseminate best-practice techniques between software engineering and various scientific domains.},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = apr,
articleno = {91},
numpages = {50},
keywords = {Computational workflow, workflow composition, domain experts, machine learning, machine learning pipelines, software engineering framework}
}

@proceedings{10.1145/3654823,
title = {CACML '24: Proceedings of the 2024 3rd Asia Conference on Algorithms, Computing and Machine Learning},
year = {2024},
isbn = {9798400716416},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Shanghai, China}
}

@proceedings{10.1145/3702038,
title = {IHC '24: Proceedings of the XXIII Brazilian Symposium on Human Factors in Computing Systems},
year = {2024},
isbn = {9798400712241},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@article{10.1145/3698393,
author = {Javed, Yousra and Sajid, Ayesha},
title = {A Systematic Review of Privacy Policy Literature},
year = {2024},
issue_date = {February 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {57},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/3698393},
doi = {10.1145/3698393},
abstract = {An organization’s privacy policy states how it collects, stores, processes, and shares its users’ personal information. The growing number of data protection laws and regulations, as well as the numerous sectors where the organizations are collecting user information, has led to the investigation of privacy policies with regards to their accessibility, readability, completeness, comparison with organization’s actual data practices, use of machine learning/natural language processing for automated analysis, and comprehension/perception/concerns of end-users via summarization/visualization tools and user studies. However, there is limited work on systematically reviewing the existing research on this topic. We address this gap by conducting a systematic review of the existing privacy policy literature. To this end, we compiled and analyzed 202 papers (published till 31st December, 2023) that investigated privacy policies. Our work advances the field of privacy policies by summarizing the analysis techniques that have been used to study them, the data protection laws/regulations explored, and the sectors to which these policies pertain. We provide actionable insights for organizations to achieve better end-user privacy.},
journal = {ACM Comput. Surv.},
month = nov,
articleno = {45},
numpages = {43},
keywords = {Privacy policy, systematic literature review, survey, data protection, personal information}
}

@proceedings{10.1145/3685651,
title = {eSAAM '24: Proceedings of the 4th Eclipse Security, AI, Architecture and Modelling Conference on Data Space},
year = {2024},
isbn = {9798400709845},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Mainz, Germany}
}

@inproceedings{10.1145/3613905.3650810,
author = {Chakraborti, Mahasweta and Bonagiri, Sailendra Akash and Virg\"{u}ez-Ruiz, Santiago and Frey, Seth},
title = {NLP4Gov: A Comprehensive Library for Computational Policy Analysis},
year = {2024},
isbn = {9798400703317},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613905.3650810},
doi = {10.1145/3613905.3650810},
abstract = {Formal rules and policies are fundamental in formally specifying a social system: its operation, boundaries, processes, and even ontology. Recent scholarship has highlighted the role of formal policy in collective knowledge creation, game communities, the production of digital public goods, and national social media governance. Researchers have shown interest in how online communities convene tenable self-governance mechanisms to regulate member activities and distribute rights and privileges by designating responsibilities, roles, and hierarchies. We present NLP4Gov, an interactive kit to train and aid scholars and practitioners alike in computational policy analysis. The library explores and integrates methods and capabilities from computational linguistics and NLP to generate semantic and symbolic representations of community policies from text records. Versatile, documented, and accessible, NLP4Gov provides granular and comparative views into institutional structures and interactions, along with other information extraction capabilities for downstream analysis.},
booktitle = {Extended Abstracts of the CHI Conference on Human Factors in Computing Systems},
articleno = {248},
numpages = {8},
keywords = {Collective Action, OSS Governance, Online Communities, Open Source Software, Peer Production, Policy Analysis},
location = {Honolulu, HI, USA},
series = {CHI EA '24}
}

@proceedings{10.1145/3620666,
title = {ASPLOS '24: Proceedings of the 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 3},
year = {2024},
isbn = {9798400703867},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {3},
abstract = {Welcome to the third volume of ASPLOS'24: the 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems. This document is mostly dedicated to the 2024 fall cycle but also provides some statistics summarizing all three cycles.We introduced several notable changes to ASPLOS this year, most of which were discussed in our previous messages from program chairs in Volume 1 and 2, including: (1) significantly increasing the program committee size to over 220 members (more than twice the size of last year); (2) foregoing synchronous program committee (PC) meetings and instead making all decisions online; (3) overhauling the review assignment process; (4) developing an automated submission format violation identifier script that uncovers, e.g., disallowed vertical space manipulations that "squeeze" space; (5) introducing the new ASPLOS role of Program Vice Chairs to cope with the increased number of submissions and the added load caused by foregoing synchronous program committee; and (6) characterizing a systematic problem that ASPLOS is facing in reviewing quantum computing submissions, describing how we addressed it and highlighting how we believe that it should be handled in the future.Assuming readers have read our previous messages, here, we will only describe differences between the current cycle and the previous ones. These include: (1) Finally unifying submission and acceptance paper formatting instructions (forgoing the `jpaper' class) to rid authors of accepted papers from the need to reformat; (2) Describing the methodology we employed to select best papers, which we believe ensures quality and hope will persist; and (3) Reporting the ethical incidents we encountered and how we handled them. In the final, fourth volume, when the outcome of the ASPLOS'24 fall major revisions will become known, we plan to conduct a broader analysis of all the data we have gathered throughout the year.Following are some key statistics of the fall cycle: 340 submissions were finalized (43% more than last year's fall count and 17% less than our summer cycle) of which 111 are related to accelerators/FPGAs/GPUs, 105 to machine learning, 54 to security, 50 to datacenter/cloud and 50 to storage/memory; 183 (54%) submissions were promoted to the second review round; 39 (11.5%) papers were accepted (of which 19 were awarded artifact evaluation badges); 33 (9.7%) submissions were allowed to submit major revisions and are currently under review (these will be addressed in the fourth volume of ASPLOS'24 and will be presented in ASPLOS'25 if accepted); 1,368 reviews were uploaded; and 4,949 comments were generated during online discussions, of which 4,070 were dedicated to the submissions that made it to the second review round.This year, in the submission form, we asked authors to specify which of the three ASPLOS research areas are related to their submitted work. Analyzing this data revealed that 80%, 39%, and 29% of the submissions are categorized by their authors as related to architecture, operating systems, and programming languages, respectively, generating the highest difference we have observed across the cycles between architecture and the other two. About 46% of the fall submissions are "interdisciplinary," namely, were associated with two or more of the three areas.Overall, throughout all the ASPLOS'24 cycles, we received 922 submissions, constituting a 1.54x increase compared to last year. Our reviewers submitted a total of 3,634 reviews containing more than 2.6 million words, and we also generated 12,655 online comments consisting of nearly 1.2 million words. As planned, PC members submitted an average of 15.7 reviews and a median of 15, and external review committee (ERC) members submitted an average of 4.7 and a median of 5.We accepted 170 papers thus far, written by 1100 authors, leading to an 18.4% acceptance rate, with the aforementioned 33 major revisions still under review. Assuming that the revision acceptance rate will be similar to that of previous cycles, we estimate that ASPLOS'24 will accept nearly 200 (!) papers, namely, 21%–22% of the submissions.The ASPLOS'24 program consists of 193 papers: the 170 papers we accepted thus far and, in addition, 23 major revisions from the fall cycle of ASPLOS'23, which were re-reviewed and accepted. The full details are available in the PDF of the front matter.},
location = {La Jolla, CA, USA}
}

@proceedings{10.1145/3690931,
title = {AIAHPC '24: Proceedings of the 2024 4th International Conference on Artificial Intelligence, Automation and High Performance Computing},
year = {2024},
isbn = {9798400710049},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Zhuhai, China}
}

@article{10.1145/3702234,
author = {Fang, Chen and Wang, Yidong and Song, Yunze and Long, Qingqing and Lu, Wang and Chen, Linghui and Feng, Guihai and Zhou, Yuanchun and Li, Xin},
title = {How do Large Language Models understand Genes and Cells},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {2157-6904},
url = {https://doi.org/10.1145/3702234},
doi = {10.1145/3702234},
abstract = {Researching genes and their interactions is crucial for deciphering the fundamental laws of cellular activity, advancing disease treatment, drug discovery, and more. Large language Models (LLMs), with their profound text comprehension and generation capabilities, have made significant strides across various natural science fields. However, their application in cell biology remains limited and a systematic evaluation of their performance is lacking. To address this gap, in this paper, we select seven mainstream LLMs and evaluate their performance across nine gene-related problem scenarios. Our findings indicate that LLMs possess a certain level of understanding of genes and cells, but still lag behind domain-specific models in comprehending transcriptional expression profiles. Moreover, we have improved the current method of textual representation of cells, enhancing the LLMs’ ability to tackle cell annotation tasks. We encourage cell biology researchers to leverage LLMs for problem-solving while being mindful of the associated challenges. We release our code and data at .},
note = {Just Accepted},
journal = {ACM Trans. Intell. Syst. Technol.},
month = oct,
keywords = {large language models, cell biology, gene gene interaction, cell annotation}
}

@inproceedings{10.1145/3652620.3688223,
author = {Hallak, Yara and Blouin, Dominique and Pautet, Laurent and Saab, Layale and Laborie, Baptiste and Mittal, Rakshit},
title = {Model Management at Renault Virtual Simulation Team: State of Practice, Challenges and Research Directions},
year = {2024},
isbn = {9798400706226},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3652620.3688223},
doi = {10.1145/3652620.3688223},
abstract = {In the automotive industry, new systems are being developed to enhance vehicle safety and driver convenience. These systems are increasingly complex to build and maintain. To develop these systems Renault makes intensive use of simulation and must deal with thousands of models. This huge number of models must be well managed. To manage these models, Renault has developed the SysML-based Model Identity Card (MIC), used with a Model-Based Simulation (MBSi) approach. However, despite this first solution, managing simulation models remains a difficult task.In this paper, we describe the current simulation model management approaches used at Renault, and their shortcomings and challenges in the modelling and simulation of complex automotive systems. We use Advanced Driver Assistance System (ADAS) and its Automatic Emergency Breaking (AEB) sub-system as examples to illustrate the utilization of the MIC and demonstrate current practices. From these examples, we derive main challenges faced by the virtual simulation team and propose research directions to solve them, based on state of the art methodologies for simulation models' validation and verification management.},
booktitle = {Proceedings of the ACM/IEEE 27th International Conference on Model Driven Engineering Languages and Systems},
pages = {1005–1014},
numpages = {10},
keywords = {model management, model-based systems engineering, model identity card, model-based simulation, advanced driver assistance system},
location = {Linz, Austria},
series = {MODELS Companion '24}
}

@inproceedings{10.1145/3666015.3666016,
author = {Boudjemila, Chahrazed and Dagnat, Fabien and Mart\'{\i}nez, Salvador},
title = {Maintaining Security Consistency During System Development with Security-Oriented Model Federation},
year = {2024},
isbn = {9798400709913},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3666015.3666016},
doi = {10.1145/3666015.3666016},
abstract = {Multi-modeling is an approach within the MDE realm that promotes the development of complex systems by decomposing them in sets of heterogeneous models. These models are defined using different modeling languages and constructed using diverse tools. They represent different but often interdependent views. However, the models of a system are far from being static. They change to accommodate new requirements, functionality improvements, bug fixes, and other evolution events. These changes represent a challenge w.r.t. consistency. This is especially true in security-critical scenarios. Indeed, security information is often integrated within the systems models so that security requirements are met following what is called "security-by-design". In such scenarios, the security concern of the systems models must remain consistent across changes so that security properties continue to hold. In order to tackle this problem, we propose a methodology to enhance the (multi)model-based design phase of a system development process. It comprises the creation of a security federation in which security dependencies between the different models are reified and equipped with security rules expressing security consistency requirements. Then, whenever a model is changed, the security rules are evaluated to monitor the consistency of security across the system models. We evaluate the capabilities of this methodology by a prototype implementation and its application to different use cases.},
booktitle = {Proceedings of the 2024 International Conference on Software and Systems Processes},
pages = {66–76},
numpages = {11},
keywords = {Model-driven engineering, model evolution., model federation, security by design},
location = {M\, Germany},
series = {ICSSP '24}
}

@proceedings{10.1145/3643664,
title = {WSESE '24: Proceedings of the 1st IEEE/ACM International Workshop on Methodological Issues with Empirical Studies in Software Engineering},
year = {2024},
isbn = {9798400705670},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {WSESE 2024 was a one-day event held on April 16, 2024, in Lisbon, Portugal. The theme of the workshop was "Methodological Issues with Empirical Studies in Software Engineering". The primary goal was to gain a better understanding of the adoption of the empirical paradigm in SE. Specifically, our focus was on identifying, discussing and finding solutions for the issues in the empirical methods currently employed. The workshop provided an opportunity for researchers and practitioners to discuss current methodological challenges and explore ways to address them.},
location = {Lisbon, Portugal}
}

@proceedings{10.1145/3632971,
title = {JCRAI '23: Proceedings of the 2023 International Joint Conference on Robotics and Artificial Intelligence},
year = {2023},
isbn = {9798400707704},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Shanghai, China}
}

@proceedings{10.1145/3663976,
title = {CVIPPR '24: Proceedings of the 2024 2nd Asia Conference on Computer Vision, Image Processing and Pattern Recognition},
year = {2024},
isbn = {9798400716607},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Xiamen, China}
}

@proceedings{10.1145/3664934,
title = {ICIEI '24: Proceedings of the 2024 9th International Conference on Information and Education Innovations},
year = {2024},
isbn = {9798400716409},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Verbania, Italy}
}

@proceedings{10.1145/3610977,
title = {HRI '24: Proceedings of the 2024 ACM/IEEE International Conference on Human-Robot Interaction},
year = {2024},
isbn = {9798400703225},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome one and all to the 19th Annual ACM/IEEE International Conference on Human-Robot Interaction (HRI)!We are so pleased to re-welcome the HRI community to Boulder, Colorado, where HRI 2021 would have been held, had the COVID pandemic not interfered. Following up on the successful in-person conference held last year in Sweden, this year's theme is "HRI in the Real World," and focuses on advances that aim to bring human-robot interaction out of the lab and into everyday life.One aspect of this that we are very excited about is the introduction of a robot challenge to the conference activities, where teams from around the world will showcase their research and development via actual, interactive robots in the "real world" of an academic conference. It is our hope that this feature will grow and develop over the coming years into a staple of the HRI conference.This year's HRI conference saw an impressive surge in global interest, with 352 full paper submissions from around the world, marking a significant 40% increase compared to the previous year. These papers were categorized under relevant thematic subcommittees and underwent a double-blind review process, a rebuttal phase, and selective shepherding by the HRI program committee. From this process, 87 outstanding papers (24.7%) were chosen for full presentation at the conference. Reflecting our joint sponsorship with IEEE and ACM, all accepted papers will be accessible in the ACM Digital Library and IEEE Xplore.},
location = {Boulder, CO, USA}
}

@proceedings{10.1145/3676288,
title = {SSDBM '24: Proceedings of the 36th International Conference on Scientific and Statistical Database Management},
year = {2024},
isbn = {9798400710209},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Rennes, France}
}

@article{10.1145/3661484,
author = {Kr\"{u}ger, Jacob and Li, Yi and Lossev, Kirill and Zhu, Chenguang and Chechik, Marsha and Berger, Thorsten and Rubin, Julia},
title = {A Meta-Study of Software-Change Intentions},
year = {2024},
issue_date = {December 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {56},
number = {12},
issn = {0360-0300},
url = {https://doi.org/10.1145/3661484},
doi = {10.1145/3661484},
abstract = {Every software system undergoes changes, for example, to add new features, fix bugs, or refactor code. The importance of understanding software changes has been widely recognized, resulting in various techniques and studies, for instance, on change-impact analysis or classifying developers’ activities. Since changes are triggered by developers’ intentions—something they plan or want to change in the system—many researchers have studied intentions behind changes. While there appears to be a consensus among software-engineering researchers and practitioners that knowing the intentions behind software changes is important, it is not clear how developers can actually benefit from this knowledge. In fact, there is no consolidated, recent overview of the state of the art on software-change intentions (SCIs) and their relevance for software engineering. We present a meta-study of 122 publications, which we used to derive a categorization of SCIs and to discuss motivations, evidence, and techniques relating to SCIs. Unfortunately, we found that individual pieces of research are often disconnected from each other, because a common understanding is missing. Similarly, some publications showcase the potential of knowing SCIs, but more substantial research to understand the practical benefits of knowing SCIs is needed. Our contributions can help researchers and practitioners improve their understanding of SCIs and how SCIs can aid software engineering tasks.},
journal = {ACM Comput. Surv.},
month = oct,
articleno = {300},
numpages = {41},
keywords = {Intentions, software evolution, change management, version control}
}

@proceedings{10.1145/3670013,
title = {IC4E '24: Proceedings of the 2024 15th International Conference on E-Education, E-Business, E-Management and E-Learning},
year = {2024},
isbn = {9798400717062},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Fukuoka-shi, Japan}
}

@proceedings{10.5555/3635637,
title = {AAMAS '24: Proceedings of the 23rd International Conference on Autonomous Agents and Multiagent Systems},
year = {2024},
isbn = {9798400704864},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {Welcome to AAMAS-2024, the 23th edition of the International Conference on Autonomous Agents and Multiagent Systems!AAMAS is the largest and most influential conference in the area of agents and multiagent systems, bringing together researchers and practitioners in all areas of agent technology and providing an internationally renowned high-profile forum for publishing and finding out about the latest developments in the field. AAMAS is the flagship conference of the non-profit International Foundation for Autonomous Agents and Multiagent Systems (IFAAMAS).After two attempts to hold AAMAS in New Zealand for the first time, which were forced online by the COVID19 pandemic, we are happy that the 2024 edition finally comes to Auckland, New Zealand. Previous editions were held in Bologna (2002), Melbourne (2003), New York (2004), Utrecht (2005), Hakodate (2006), Honolulu (2007), Estoril (2008), Budapest (2009), Toronto (2010), Taipei (2011), Valencia (2012), Saint Paul (2013), Paris (2014), Istanbul (2015), Singapore (2016), Sao Paulo (2017), Stockholm (2018), Montreal (2019), Auckland/online (2020), London/online (2021), Auckland/online (2022), and London (2023).},
location = {Auckland, New Zealand}
}

@inproceedings{10.1145/3589335.3641302,
author = {Ragab, Mohamed and Savateeve, Yury and Wang, Wenjie and Moosaei, Reza and Tiropanis, Thanassis and Poulovassilis, Alexandra and Chapman, Adriane and Oliver, Helen and Roussos, George},
title = {The 1st Workshop on Decentralised Search and Recommendation},
year = {2024},
isbn = {9798400701726},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589335.3641302},
doi = {10.1145/3589335.3641302},
abstract = {The DESERE Workshop, our First Workshop on Decentralised Search and Recommendation, offers a platform for researchers to explore and share innovative ideas on decentralised web services, mainly focusing on three major topics: (i) societal impact of decentralised systems: their effects on privacy, policy, and regulation; (ii) decen- tralising applications: algorithmic and performance challenges that arise from decentralisation; and (iii) infrastructure to support de- centralised systems and services: peer-to-peer networks, routing, and performance evaluation tools.},
booktitle = {Companion Proceedings of the ACM Web Conference 2024},
pages = {1705–1708},
numpages = {4},
keywords = {decentralised web, distributed search, distributed systems, network algorithms, recommendation systems},
location = {Singapore, Singapore},
series = {WWW '24}
}

@inproceedings{10.1145/3665601.3669844,
author = {Huang, Zezhou},
title = {Disambiguate Entity Matching using Large Language Models through Relation Discovery},
year = {2024},
isbn = {9798400706943},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3665601.3669844},
doi = {10.1145/3665601.3669844},
abstract = {Entity matching is a critical problem in data integration, central to tasks like fuzzy joins for tuple enrichment. Traditional approaches have focused on overcoming fuzzy term representations through methods such as edit distance, Jaccard similarity, and more recently, embeddings and deep neural networks, including advancements from large language models (LLMs) like GPT. However, when integrating with external databases, the core challenge in entity matching extends beyond term fuzziness to the ambiguity in defining what constitutes a "match". This is because external databases contain tuples with varying levels of detail and granularity among entities, and an "exact match" in traditional entity matching rarely happens. As a result, understanding how entities are related and the potential nuances is critical, especially for high-stake tasks for responsible AI. In this work, we study a case problem of entity matching for ESG reporting. We propose a novel approach that shifts focus from purely identifying semantic similarities to understanding and defining the "relations" between entities for resolving ambiguities in matching, with a human-in-the-loop process to make the final decision. By pre-defining a set of relations relevant to the task at hand, our method allows analysts to navigate the spectrum of similarity more effectively, from exact matches to conceptually related entities, and responsibly perform downstream tasks.},
booktitle = {Proceedings of the Conference on Governance, Understanding and Integration of Data for Effective and Responsible AI},
pages = {36–39},
numpages = {4},
keywords = {Data Integration, Entity Matching, Large Language Models},
location = {Santiago, AA, Chile},
series = {GUIDE-AI '24}
}

@proceedings{10.1145/3603166,
title = {UCC '23: Proceedings of the IEEE/ACM 16th International Conference on Utility and Cloud Computing},
year = {2023},
isbn = {9798400702341},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {The IEEE/ACM International Conference on Utility and Cloud Computing (UCC) is a premier annual conference series aiming to provide a platform for researchers from both academia and industry to present new discoveries in the broad area of Cloud and Edge utility computing and applications.},
location = {Taormina (Messina), Italy}
}

@article{10.1145/3709351,
author = {Wang, Shenao and Li, Yuekang and Wang, Kailong and Liu, Yi and Li, Hui and Liu, Yang and Wang, Haoyu},
title = {MiniScope: Automated UI Exploration and Privacy Inconsistency Detection of MiniApps via Two-phase Iterative Hybrid Analysis},
year = {2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1049-331X},
url = {https://doi.org/10.1145/3709351},
doi = {10.1145/3709351},
abstract = {The advent of MiniApps, operating within larger SuperApps, has revolutionized user experiences by offering a wide range of services without the need for individual app downloads. However, this convenience has raised significant privacy concerns, as these MiniApps often require access to sensitive data, potentially leading to privacy violations. Despite existing privacy regulations and platform guidelines, there is a lack of effective mechanisms to safeguard user privacy fully. To address this critical gap, we introduce MiniScope, a novel two-phase hybrid analysis approach, specifically designed for the MiniApp environment. This approach overcomes the limitations of existing static analysis techniques by incorporating UI transition states analysis, cross-package callback control flow resolution, and automated iterative UI exploration. This allows for a comprehensive understanding of MiniApps’ privacy practices, addressing the unique challenges of sub-package loading and event-driven callbacks. Our empirical evaluation of over 120K MiniApps using MiniScope demonstrates its effectiveness in identifying privacy inconsistencies. The results reveal significant issues, with 5.7% of MiniApps over-collecting private data and 33.4% overclaiming data collection. We have responsibly disclosed our findings to 2,282 developers, receiving 44 acknowledgments. These findings emphasize the urgent need for more precise privacy monitoring systems and highlight the responsibility of SuperApp operators to enforce stricter privacy measures.},
note = {Just Accepted},
journal = {ACM Trans. Softw. Eng. Methodol.},
month = dec,
keywords = {MiniApps, Privacy Compliance, Hybrid Analysis}
}

@proceedings{10.1145/3705677,
title = {CITCE '24: Proceedings of the 4th International Conference on Computer, Internet of Things and Control Engineering},
year = {2024},
isbn = {9798400711848},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3661638,
title = {AISNS '23: Proceedings of the 2023 International Conference on Artificial Intelligence, Systems and Network Security},
year = {2023},
isbn = {9798400716966},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Mianyang, China}
}

@proceedings{10.1145/3625549,
title = {HPDC '24: Proceedings of the 33rd International Symposium on High-Performance Parallel and Distributed Computing},
year = {2024},
isbn = {9798400704130},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {HPDC is the premier annual conference for presenting the latest research on the design, implementation, evaluation, and use of parallel and distributed systems for high-end computing. HPDC provides research contributions in all aspects of parallel and distributed computing such as resilience, AI-based systems and applications, data compression, serverless computing, software systems, workflows, performance modeling, hardware accelerators, scientific computing, resource management, security aspects and many others. The scientific contribution of the conference lays its groundwork for the significant endeavor required to implement actual systems and applications, along with the priceless knowledge acquired through active measurement and experimentation in real-world use cases.},
location = {Pisa, Italy}
}

@proceedings{10.1145/3638380,
title = {OzCHI '23: Proceedings of the 35th Australian Computer-Human Interaction Conference},
year = {2023},
isbn = {9798400717079},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Wellington, New Zealand}
}

@proceedings{10.1145/3644479,
title = {EBIMCS '23: Proceedings of the 2023 6th International Conference on E-Business, Information Management and Computer Science},
year = {2023},
isbn = {9798400709333},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Hong Kong, Hong Kong}
}

@proceedings{10.1145/3640792,
title = {AutomotiveUI '24: Proceedings of the 16th International Conference on Automotive User Interfaces and Interactive Vehicular Applications},
year = {2024},
isbn = {9798400705106},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Stanford, CA, USA}
}

@proceedings{10.1145/3648536,
title = {TAHRI '24: Proceedings of the 2024 International Symposium on Technological Advances in Human-Robot Interaction},
year = {2024},
isbn = {9798400716614},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Boulder, CO, USA}
}

@proceedings{10.1145/3696952,
title = {ICIIP '24: Proceedings of the 2024 9th International Conference on Intelligent Information Processing},
year = {2024},
isbn = {9798400718076},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@inproceedings{10.1145/3589335.3641296,
author = {Todorov, Konstantin and Fafalios, Pavlos and Dietze, Stefan and Dimitrov, Dimitar},
title = {Beyond Facts: 4th International Workshop on Computational Methods for Online Discourse Analysis},
year = {2024},
isbn = {9798400701726},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3589335.3641296},
doi = {10.1145/3589335.3641296},
abstract = {Expressing opinions and interacting with others on the Web has led to the production of an abundance of online discourse data, such as claims and viewpoints on controversial topics, their sources and contexts (events, entities). This data constitutes a valuable source of insights for studies into misinformation spread, bias reinforcement, echo chambers or political agenda setting. Computational methods, mostly from the field of NLP, have emerged that tackle a wide range of tasks in this context, including argument and opinion mining, claim detection, checkworthiness detection, stance detection or fact verification. However, computational models require robust definitions of classes and concepts under investigation. Thus, these computational tasks require a strong interdisciplinary and epistemological foundation, specifically with respect to the underlying definitions of key concepts such as claims, arguments, stances, check-worthiness or veracity. This requires a highly interdisciplinary approach combining expertise from fields such as communication studies, computational linguistics and computer science. As opposed to facts, claims are inherently more complex. Their interpretation strongly depends on the context and a variety of intentional or unintended meanings, where terminology and conceptual understandings strongly diverge across communities. From a computational perspective, in order to address this complexity, the synergy of multiple approaches, coming both from symbolic (knowledge representation) and statistical AI seem to be promising to tackle such challenges. This workshop aims at strengthening the relations between these communities, providing a forum for shared works on the modeling, extraction and analysis of discourse on the Web. It will address the need for a shared understanding and structured knowledge about discourse data in order to enable machine-interpretation, discoverability and reuse, in support of scientific or journalistic studies into the analysis of societal debates on the Web. Beyond research into information and knowledge extraction, data consolidation and modeling for knowledge graphs building, the workshop targets communities focusing on the analysis of online discourse, relying on methods from machine learning, natural language processing, large language models and Web data mining.},
booktitle = {Companion Proceedings of the ACM Web Conference 2024},
pages = {1418–1421},
numpages = {4},
keywords = {computational fact-checking, computational journalism, intent detection, knowledge graphs, language models, mis- and dis-information, online discourse analysis, social web mining, stance and viewpoint discovery},
location = {Singapore, Singapore},
series = {WWW '24}
}

@article{10.1145/3696206,
author = {Cao, Chengtai and Zhou, Fan and Dai, Yurou and Wang, Jianping and Zhang, Kunpeng},
title = {A Survey of Mix-based Data Augmentation: Taxonomy, Methods, Applications, and Explainability},
year = {2024},
issue_date = {February 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {57},
number = {2},
issn = {0360-0300},
url = {https://doi.org/10.1145/3696206},
doi = {10.1145/3696206},
abstract = {Data augmentation (DA) is indispensable in modern machine learning and deep neural networks. The basic idea of DA is to construct new training data to improve the model’s generalization by adding slightly disturbed versions of existing data or synthesizing new data. This survey comprehensively reviews a crucial subset of DA techniques, namely Mix-based Data Augmentation (MixDA), which generates novel samples by combining multiple examples. In contrast to traditional DA approaches that operate on single samples or entire datasets, MixDA stands out due to its effectiveness, simplicity, computational efficiency, theoretical foundation, and broad applicability. We begin by introducing a novel taxonomy that categorizes MixDA into Mixup-based, Cutmix-based, and mixture approaches based on a hierarchical perspective of the data mixing operation. Subsequently, we provide an in-depth review of various MixDA techniques, focusing on their underlying motivations. Owing to its versatility, MixDA has penetrated a wide range of applications, which we also thoroughly investigate in this survey. Moreover, we delve into the underlying mechanisms of MixDA’s effectiveness by examining its impact on model generalization and calibration while providing insights into the model’s behavior by analyzing the inherent properties of MixDA. Finally, we recapitulate the critical findings and fundamental challenges of current MixDA studies while outlining the potential directions for future works. Different from previous related surveys that focus on DA approaches in specific domains (e.g., computer vision and natural language processing) or only review a limited subset of MixDA studies, we are the first to provide a systematical survey of MixDA, covering its taxonomy, methodology, application, and explainability. Furthermore, we provide promising directions for researchers interested in this exciting area.},
journal = {ACM Comput. Surv.},
month = oct,
articleno = {37},
numpages = {38},
keywords = {Data augmentation, regularization, generalization, machine learning, deep learning}
}

@proceedings{10.1145/3670085,
title = {ICMAI '24: Proceedings of the 2024 9th International Conference on Mathematics and Artificial Intelligence},
year = {2024},
isbn = {9798400717284},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Beijing, China}
}

@proceedings{10.1145/3665065,
title = {ISMSI '24: Proceedings of the 2024 8th International Conference on Intelligent Systems, Metaheuristics &amp; Swarm Intelligence},
year = {2024},
isbn = {9798400717291},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Singapore, Singapore}
}

@article{10.1145/3689430,
author = {Zeng, Ruihong and Fang, Jinyuan and Liu, Siwei and Meng, Zaiqiao and Liang, Shangsong},
title = {Enhancing Graph Neural Networks via Memorized Global Information},
year = {2024},
issue_date = {November 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {18},
number = {4},
issn = {1559-1131},
url = {https://doi.org/10.1145/3689430},
doi = {10.1145/3689430},
abstract = {Graph neural networks (GNNs) have gained significant attention for their impressive results on different graph-based tasks. The essential mechanism of GNNs is the message-passing framework, whereby node representations are aggregated from local neighborhoods. Recently, Transformer-based GNNs have been introduced to learn the long-range dependencies, enhancing performance. However, their quadratic computational complexity, due to the attention computation, has constrained their applicability on large-scale graphs. To address this issue, we propose MGIGNN (Memorized Global Information Graph Neural Network), an innovative approach that leverages memorized global information to enhance existing GNNs in both transductive and inductive scenarios. Specifically, MGIGNN captures long-range dependencies by identifying and incorporating global similar nodes, which are defined as nodes exhibiting similar features, structural patterns and label information within a graph. To alleviate the computational overhead associated with computing embeddings for all nodes, we introduce an external memory module to facilitate the retrieval of embeddings and optimize performance on large graphs. To enhance the memory-efficiency, MGIGNN selectively retrieves global similar nodes from a small set of candidate nodes. These candidate nodes are selected from the training nodes based on a sparse node selection distribution with a Dirichlet prior. This selecting approach not only reduces the memory size required but also ensures efficient utilization of computational resources. Through comprehensive experiments conducted on ten widely-used and real-world datasets, including seven homogeneous datasets and three heterogeneous datasets, we demonstrate that our&nbsp;MGIGNN can generally improve the performance of existing GNNs on node classification tasks under both inductive and transductive settings.},
journal = {ACM Trans. Web},
month = oct,
articleno = {50},
numpages = {34},
keywords = {Network embedding, graph neural network, memorized global information}
}

@proceedings{10.1145/3633624,
title = {BDSIC '23: Proceedings of the 2023 5th International Conference on Big-data Service and Intelligent Computation},
year = {2023},
isbn = {9798400708923},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Singapore, Singapore}
}

@proceedings{10.1145/3628034,
title = {EuroPLoP '23: Proceedings of the 28th European Conference on Pattern Languages of Programs},
year = {2023},
isbn = {9798400700408},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Irsee, Germany}
}

@proceedings{10.5555/3643142,
title = {WSC '23: Proceedings of the Winter Simulation Conference},
year = {2023},
isbn = {9798350369663},
publisher = {IEEE Press},
location = {San Antonio, Texas, USA}
}

@inproceedings{10.1145/3653946.3653961,
author = {Jiang, Yingdi and Yao, Jiarui and Li, Fangfei and Zhang, Yan},
title = {Research on Engineering Management Question-answering System in the Communication Industry Based on Large Language Models and Knowledge Graphs},
year = {2024},
isbn = {9798400716553},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3653946.3653961},
doi = {10.1145/3653946.3653961},
abstract = {In the engineering management of the communication industry, there are many issues, including low efficiency in information acquisition and limitations in the level of intelligence.Large language models, with their powerful text comprehension and generation capabilities, offer new perspectives for the development of this field.This study constructed a question-answering system using a combined approach of large language models and text knowledge bases. The system dynamically leverages abundant external knowledge and enhances the model's reasoning ability and interpretability through knowledge graphs. In response to five categories of issues in engineering management, experiments and in-depth analysis revealed that although large language models may lack granularity in addressing some complex problems, the question-answering system overall achieved intelligent assistance, improving the efficiency of collaborative engineering management.},
booktitle = {Proceedings of the 2024 7th International Conference on Machine Vision and Applications},
pages = {100–105},
numpages = {6},
keywords = {Engineering management, Keywords • Large language models, Knowledge graphs, Question-answering},
location = {Singapore, Singapore},
series = {ICMVA '24}
}

@proceedings{10.1145/3634737,
title = {ASIA CCS '24: Proceedings of the 19th ACM Asia Conference on Computer and Communications Security},
year = {2024},
isbn = {9798400704826},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our great pleasure to welcome you to ACM AsiaCCS 2024, the 19th ACM Asia Conference on Computer and Communications Security. AsiaCCS 2024 takes place in Singapore from 1 July to 5 July.},
location = {Singapore, Singapore}
}

@article{10.1145/3655032.3655035,
author = {Freedman, Richard G.},
title = {2025 EAAI Mentored Undergraduate Research Challenge: Playing Word Association Games},
year = {2024},
issue_date = {March 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {10},
number = {1},
url = {https://doi.org/10.1145/3655032.3655035},
doi = {10.1145/3655032.3655035},
abstract = {The topic for EAAI 2025's Mentored Undergraduate Research Challenge is PlayingWord Association Games. What does that mean? Where are the applications? How can you get started? We break down the topic, discuss applications, and explore project ideas in this column.},
journal = {AI Matters},
month = may,
pages = {16–25},
numpages = {10}
}

@proceedings{10.1145/3647444,
title = {ICIMMI '23: Proceedings of the 5th International Conference on Information Management &amp; Machine Intelligence},
year = {2023},
isbn = {9798400709418},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Jaipur, India}
}

@proceedings{10.1145/3626232,
title = {CODASPY '24: Proceedings of the Fourteenth ACM Conference on Data and Application Security and Privacy},
year = {2024},
isbn = {9798400704215},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our great pleasure to welcome you to the fourteenth edition of the ACM Conference on Data and Application Security and Privacy (CODASPY 2024), for the first time held outside United States of America. This conference series has been founded to foster novel and exciting research in the data and application security and privacy arena and to help generate new directions for further research and development. The initial concept was established by the two co-founders, Elisa Bertino and Ravi Sandhu, and sharpened by subsequent discussions with several fellow data security and privacy researchers. Their enthusiastic encouragement persuaded the co-founders to move ahead with the always daunting task of creating a high-quality conference. CODASPY has become a leading forum for presentation of research results and experience reports on hardware and software security. The conference gives researchers and practitioners a unique opportunity to share their perspectives with others interested in the various aspects of data and applications security and privacy.},
location = {Porto, Portugal}
}

@proceedings{10.1145/3620665,
title = {ASPLOS '24: Proceedings of the 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 2},
year = {2024},
isbn = {9798400703850},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
abstract = {Welcome to the second volume of ASPLOS'24: the 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems. This document is dedicated to the 2024 summer review cycle.We introduced several notable changes to ASPLOS this year, many of which were discussed in the previous message from program chairs in Volume 1. Here, to avoid repetition, we assume that readers have already read the latter message and will only describe differences between the current cycle and the previous one. These include: (1) developing and utilizing an automated format violation identifier script focused on uncovering disallowed vertical space manipulations that "squeeze" space; (2) incorporating authors-declared best-matching topics into our review assignment process; (3) introducing the new ASPLOS role of Program Vice Chairs to cope with the increased number of submissions and the added load caused by foregoing synchronous program committee (PC) meetings, which necessitated additional managerial involvement in online dissensions; and (4) characterizing a systematic problem that ASPLOS is facing in reviewing quantum computing submissions, describing how we addressed it, and highlighting how we believe that it should be handled in the future.Key statistics of the ASPLOS'24 summer cycle include: 409 submissions were finalized (about 1.5x more than last year's summer count and nearly 2.4x more than our spring cycle), with 107 related to accelerators/FPGAs/GPUs, 97 to machine learning, 88 to storage/memory, 80 to security, and 69 to datacenter/cloud; 179 (44%) submissions were promoted to the second review round; 54 (13.2%) papers were accepted (with 20 awarded one or more artifact evaluation badges); 33 (8.1%) submissions were allowed to submit major revisions, of which 27 were subsequently accepted during the fall cycle (with 13 awarded one or more artifact evaluation badges); 1,499 reviews were uploaded; and 5,557 comments were generated during online discussions.Analyzing the per-submission most-related broader areas of research, which we asked authors to associate with their work in the submission form, revealed that 71%, 47%, and 28% of the submissions are categorized by their authors as related to architecture, operating systems, and programming languages, respectively, with about 45% being "interdisciplinary" submissions (associated with more than one area). The full details are available in the PDF of the front matter.},
location = {La Jolla, CA, USA}
}

@proceedings{10.1145/3657242,
title = {Interacci\'{o}n '24: Proceedings of the XXIV International Conference on Human Computer Interaction},
year = {2024},
isbn = {9798400717871},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {A Coru\~{n}a, Spain}
}

@article{10.1145/3706057,
author = {Jayasundara, Sakuna Harinda and Gamagedara Arachchilage, Nalin Asanka and Russello, Giovanni},
title = {SoK: Access Control Policy Generation from High-level Natural Language Requirements},
year = {2024},
issue_date = {April 2025},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {57},
number = {4},
issn = {0360-0300},
url = {https://doi.org/10.1145/3706057},
doi = {10.1145/3706057},
abstract = {Administrator-centered access control failures can cause data breaches, putting organizations at risk of financial loss and reputation damage. Existing graphical policy configuration tools and automated policy generation frameworks attempt to help administrators configure and generate access control policies by avoiding such failures. However, graphical policy configuration tools are prone to human errors, making them unusable. On the other hand, automated policy generation frameworks are prone to erroneous predictions, making them unreliable. Therefore, to find ways to improve their usability and reliability, we conducted a Systematic Literature Review analyzing 49 publications. The thematic analysis of the publications revealed that graphical policy configuration tools are developed to write and visualize policies manually. Moreover, automated policy generation frameworks are developed using machine learning (ML) and natural language processing (NLP) techniques to automatically generate access control policies from high-level requirement specifications. Despite their utility in the access control domain, limitations of these tools, such as the lack of flexibility, and limitations of frameworks, such as the lack of domain adaptation, negatively affect their usability and reliability, respectively. Our study offers recommendations to address these limitations through real-world applications and recent advancements in the NLP domain, paving the way for future research.},
journal = {ACM Comput. Surv.},
month = dec,
articleno = {102},
numpages = {37},
keywords = {Access control, policy engineering, system administrator, user interfaces, frameworks, usability, reliability}
}

@proceedings{10.1145/3629104,
title = {DEBS '24: Proceedings of the 18th ACM International Conference on Distributed and Event-based Systems},
year = {2024},
isbn = {9798400704437},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {We welcome you to the 18th ACM International Conference on Distributed and Event-Based Systems (DEBS) 2024, hosted as an in-person event at the Institut National des Sciences Appliqu\'{e}es (INSA) Lyon.The history of DEBS spans over 20 years of scientific progress, beginning as a workshop and evolving into a conference 17 years ago. The conference's goals have evolved over time, but its primary objective - to provide a dedicated forum for the dissemination of high-quality, original, and impactful research on distributed systems and event-based computing - has remained unchanged. Alongside scientific contributions, the conference has always featured the discussion of practical insights and the reporting of experiences relevant to the industrial sector.},
location = {Villeurbanne, France}
}

@inproceedings{10.1145/3613904.3642542,
author = {Mildner, Thomas and Cooney, Orla and Meck, Anna-Maria and Bartl, Marion and Savino, Gian-Luca and Doyle, Philip R and Garaialde, Diego and Clark, Leigh and Sloan, John and Wenig, Nina and Malaka, Rainer and Niess, Jasmin},
title = {Listening to the Voices: Describing Ethical Caveats of Conversational User Interfaces According to Experts and Frequent Users},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642542},
doi = {10.1145/3613904.3642542},
abstract = {Advances in natural language processing and understanding have led to a rapid growth in the popularity of conversational user interfaces (CUIs). While CUIs introduce novel benefits, they also yield risks that may exploit people’s trust. Although research looking at unethical design deployed through graphical user interfaces (GUIs) established a thorough understanding of so-called dark patterns, there is a need to continue this discourse within the CUI community to understand potentially problematic interactions. Addressing this gap, we interviewed 27 participants from three cohorts: researchers, practitioners, and frequent users of CUIs. Applying thematic analysis, we construct five themes reflecting each cohort’s insights about ethical design challenges and introduce the CUI Expectation Cycle, bridging system capabilities and user expectations while considering each theme’s ethical caveats. This research aims to inform future development of CUIs to consider ethical constraints while adopting a human-centred approach.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {307},
numpages = {18},
keywords = {CUI, chatbots, conversational agents, conversational user interfaces, dark patterns, deceptive design patterns, ethical design, thematic analysis, voice agents},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@proceedings{10.1145/3644033,
title = {FormaliSE '24: Proceedings of the 2024 IEEE/ACM 12th International Conference on Formal Methods in Software Engineering (FormaliSE)},
year = {2024},
isbn = {9798400705892},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Historically, formal methods academic research and practical software development have had limited mutual interactions—except possibly in specialized domains such as safety-critical software. In recent times, the outlook has considerably improved: on the one hand, formal methods research has delivered more flexible techniques and tools that can support various aspects of the software development process—from user requirements elicitation, to design, implementation, verification and validation, as well as the creation of documentation. On the other hand, software engineering has developed a growing interest in rigorous techniques applied at scale.This evolution, and the desire to further improve it, motivated the creation of FormaliSE: a well-established annual conference whose main goal is to promote work at the intersection of the formal methods and software engineering communities, providing a venue to exchange ideas, experiences, techniques, and results. The collaboration between these two communities can be mutually beneficial by fostering the creation of formal methods that are practically useful and by helping develop higher-quality software.},
location = {Lisbon, Portugal}
}

@proceedings{10.1145/3638067,
title = {IHC '23: Proceedings of the XXII Brazilian Symposium on Human Factors in Computing Systems},
year = {2023},
isbn = {9798400717154},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Macei\'{o}, Brazil}
}

@inproceedings{10.1145/3664476.3664523,
author = {Ruman, \'{A}d\'{a}m and Dra\v{s}ar, Martin and Sadlek, Luk\'{a}\v{s} and Yang, Shanchieh Jay and Celeda, Pavel},
title = {Adversary Tactic Driven Scenario and Terrain Generation with Partial Infrastructure Specification},
year = {2024},
isbn = {9798400717185},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3664476.3664523},
doi = {10.1145/3664476.3664523},
abstract = {Diverse, accurate, and up-to-date training environments are essential for training cybersecurity experts and autonomous systems. However, preparation of their content is time-consuming and requires experts to provide detailed specifications. In this paper, we explore the challenges of automated generation of the content (composed of scenarios and terrains) for these environments. We propose new models to represent the cybersecurity domain and associated action spaces. These models are used to create sound and complex training content based on partial specifications provided by users. We compare the results with a real-world complex malware campaign to assess the realism of the synthesized content. To further evaluate the correctness and variability of the results, we utilize the kill-chain attack graph generation for the generated training content to asses the internal correspondence of its key components. Our results demonstrate that the proposed approach can create complex training content similar to advanced attack campaigns, which passes evaluation for soundness and practicality. Our proposed approach and its implementation significantly contribute to the state of the art, enabling novel approaches to cybersecurity training and autonomous system development.},
booktitle = {Proceedings of the 19th International Conference on Availability, Reliability and Security},
articleno = {33},
numpages = {11},
keywords = {adversary framework, attack scenario generation, cyber terrain generation, cybersecurity model},
location = {Vienna, Austria},
series = {ARES '24}
}

@proceedings{10.1145/3653644,
title = {FAIML '24: Proceedings of the 2024 3rd International Conference on Frontiers of Artificial Intelligence and Machine Learning},
year = {2024},
isbn = {9798400709777},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Yichang, China}
}

@article{10.1145/3673226,
author = {Uhrmacher, Adelinde M and Frazier, Peter and H\"{a}hnle, Reiner and Kl\"{u}gl, Franziska and Lorig, Fabian and Lud\"{a}scher, Bertram and Nenzi, Laura and Ruiz-Martin, Cristina and Rumpe, Bernhard and Szabo, Claudia and Wainer, Gabriel and Wilsdorf, Pia},
title = {Context, Composition, Automation, and Communication: The C2AC Roadmap for Modeling and Simulation},
year = {2024},
issue_date = {October 2024},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {34},
number = {4},
issn = {1049-3301},
url = {https://doi.org/10.1145/3673226},
doi = {10.1145/3673226},
abstract = {Simulation has become, in many application areas, a sine qua non. Most recently, COVID-19 has underlined the importance of simulation studies and limitations in current practices and methods. We identify four goals of methodological work for addressing these limitations. The first is to provide better support for capturing, representing, and evaluating the context of simulation studies, including research questions, assumptions, requirements, and activities contributing to a simulation study. In addition, the composition of simulation models and other simulation studies’ products must be supported beyond syntactical coherence, including aspects of semantics and purpose, enabling their effective reuse. A higher degree of automating simulation studies will contribute to more systematic, standardized simulation studies and their efficiency. Finally, it is essential to invest increased effort into effectively communicating results and the processes involved in simulation studies to enable their use in research and decision making. These goals are not pursued independently of each other, but they will benefit from and sometimes even rely on advances in other sub-fields. In this article, we explore the basis and interdependencies evident in current research and practice and delineate future research directions based on these considerations.},
journal = {ACM Trans. Model. Comput. Simul.},
month = aug,
articleno = {23},
numpages = {51},
keywords = {Modeling, simulation, state of the art, open challenges, reuse, composition, communication, reproducibility, automation, intelligent modeling and simulation lifecycle}
}

@inproceedings{10.1145/3613904.3642206,
author = {Gould, Sandy J. J.},
title = {Stochastic Machine Witnesses at Work: Today's Critiques of Taylorism are Inadequate for Workplace Surveillance Epistemologies of the Future},
year = {2024},
isbn = {9798400703300},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3613904.3642206},
doi = {10.1145/3613904.3642206},
abstract = {I argue that epistemologies of workplace surveillance are shifting in fundamental ways, and so critiques must shift accordingly. I begin the paper by relating Scientific Management to Human-Centred Computing’s ways of knowing through a study of ‘metaverse’ virtual reality workplaces. From this, I develop two observations. The first is that today’s workplace measurement science does not resemble the science that Taylor developed for Scientific Management. Contemporary workplace science is more passive, more intermediated and less controlled. The second observation is that new forms of workplace measurement challenge the norms of empirical science. Instead of having credentialed human witnesses observe phenomena and agree facts about them, we instead make outsourced, uncredentialed stochastic machine witnesses responsible for producing facts about work. With these observations in mind, I assert that critiques of workplace surveillance still framed by Taylorism will not be fit for interrogating workplace surveillance practices of the future.},
booktitle = {Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems},
articleno = {578},
numpages = {12},
keywords = {Metaverse, Neo-Taylorism, Scientific Management, Taylorism, Ubiquitous Computing, Work Measurement, Workplace Surveillance},
location = {Honolulu, HI, USA},
series = {CHI '24}
}

@proceedings{10.1145/3641343,
title = {ICEITSA '23: Proceedings of the 3rd International Conference on Electronic Information Technology and Smart Agriculture},
year = {2023},
isbn = {9798400716775},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Sanya, China}
}

@proceedings{10.1145/3689936,
title = {CSCS '24: Proceedings of the 2024 Cyber Security in CarS Workshop},
year = {2024},
isbn = {9798400712326},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our great pleasure to welcome you to the CSCS '24 - 1st Cyber Security in CarS Workshop. CSCS '24 aims to address current issues in the rapidly advancing field of automotive cybersecurity. The aim is to bring together academia and industry to address cybersecurity problems in the automotive domain. The CSCS '24 provides a forum for deliberating on the most recent advancements, exchanging current research contributions, and encouraging networking and collaboration to devise novel solutions. The CSCS workshop builds upon the foundation laid by the "ACM Computer Science in Cars Symposium" (CSCS symposium) and advances the field of automotive cybersecurity.},
location = {Salt Lake City, UT, USA}
}

@proceedings{10.1145/3677182,
title = {ASENS '24: Proceedings of the International Conference on Algorithms, Software Engineering, and Network Security},
year = {2024},
isbn = {9798400709784},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Nanchang, China}
}

@inproceedings{10.1145/3640543.3645208,
author = {Bendeck, Alexander and Bromley, Dennis and Setlur, Vidya},
title = {SlopeSeeker: A Search Tool for Exploring a Dataset of Quantifiable Trends},
year = {2024},
isbn = {9798400705083},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3640543.3645208},
doi = {10.1145/3640543.3645208},
abstract = {Natural language and search interfaces intuitively facilitate data exploration and provide visualization responses to diverse analytical queries based on the underlying datasets. However, these interfaces often fail to interpret more complex analytical intents, such as discerning subtleties and quantifiable differences between terms like “bump’’ and “spike’’ in the context of COVID cases, for example. We address this gap by extending the capabilities of a data exploration search interface for interpreting semantic concepts in time series trends. We first create a comprehensive dataset of semantic concepts by mapping quantifiable univariate data trends such as slope and angle to crowdsourced, semantically meaningful trend labels. The dataset contains quantifiable properties that capture the slope-scalar effect of semantic modifiers like “sharply” and “gradually,” as well as multi-line trends (e.g., “peak,” “valley”). We demonstrate the utility of this dataset in SlopeSeeker, a tool that supports natural language querying of quantifiable trends, such as “show me stocks that tanked in 2010.” The tool incorporates novel scoring and ranking techniques based on semantic relevance and visual prominence to present relevant trend chart responses containing these semantic trend concepts. In addition, SlopeSeeker provides a faceted search interface for users to navigate a semantic hierarchy of concepts from general trends (e.g., “increase’’) to more specific ones (e.g., “sharp increase’’). A preliminary user evaluation of the tool demonstrates that the search interface supports greater expressivity of queries containing concepts that describe data trends. We identify potential future directions for leveraging our publicly available quantitative semantics dataset in other data domains and for novel visual analytics interfaces.},
booktitle = {Proceedings of the 29th International Conference on Intelligent User Interfaces},
pages = {817–836},
numpages = {20},
keywords = {Semantics, quantifiable metadata, search, trends, visual analysis.},
location = {Greenville, SC, USA},
series = {IUI '24}
}

@proceedings{10.1145/3640912,
title = {CNML '23: Proceedings of the 2023 International Conference on Communication Network and Machine Learning},
year = {2023},
isbn = {9798400716683},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Zhengzhou, China}
}

@proceedings{10.1145/3697090,
title = {LADC '24: Proceedings of the 13th Latin-American Symposium on Dependable and Secure Computing},
year = {2024},
isbn = {9798400717406},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3659995,
title = {FlexScience'24: Proceedings of the 14th Workshop on AI and Scientific Computing at Scale using Flexible Computing Infrastructures},
year = {2024},
isbn = {9798400706424},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Pisa, Italy}
}

@proceedings{10.1145/3689094,
title = {SUMAC '24: Proceedings of the 6th workshop on the analySis, Understanding and proMotion of heritAge Contents},
year = {2024},
isbn = {9798400712050},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {It is our great pleasure to welcome you to SUMAC 2024, the 6th edition of the ACM workshop on analySis, Understanding and proMotion of heritAge Contents. The workshop focuses on analyzing, processing and valorizing all types of data related to cultural heritage, including tangible and intangible heritage. As stated by UNESCO, cultural heritage provides societies with a wealth of resources inherited from the past, created in the present for the benefit of future generations. The massive digitization of historical analogue resources and production of born-digital documents provide us with large volumes of varied multimedia heritage data (images, maps, text, video, 3D objects, multi-sensor data, etc.), which represent a rich heritage that can be exploited in a wide variety of fields, from research in social sciences and computational humanities to land use and territorial policies, including urban modeling, digital simulation, archaeology, tourism, education, culture preservation, creative media and entertainment. In terms of research in computer science, artificial intelligence and digital humanities, they address challenging problems related to the diversity, specificity or volume of the media, the veracity of the data, and different user needs with respect to engaging with this rich material and the extraction of value out of the data. These challenges are reflected in the corresponding sub-fields of machine learning, signal processing, multi-modal techniques and human-machine interaction, with special focus on:Analysis of historical data,Content understanding and pattern recognition,Linking and recommendation of multi-modal digital heritage,Human-machine interaction for big data analysis and visualization,Generative modeling of cultural heritage.},
location = {Melbourne VIC, Australia}
}

@proceedings{10.1145/3647817,
title = {ICBBS '23: Proceedings of the 2023 12th International Conference on Bioinformatics and Biomedical Science},
year = {2023},
isbn = {9798400716140},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Singapore, Singapore}
}

@proceedings{10.1145/3643833,
title = {WiSec '24: Proceedings of the 17th ACM Conference on Security and Privacy in Wireless and Mobile Networks},
year = {2024},
isbn = {9798400705823},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {Welcome to the 2024 ACM Conference on Security and Privacy in Wireless and Mobile Networks (ACM WiSec)!Now in its 17th year, WiSec continues to be the premier venue for research on all aspects of security and privacy in wireless and mobile networks, their systems, and their applications. We are hosted by the Korea Institute of Information Security &amp; Cryptology, located in the city center of Seoul, Korea - a city known for its dynamic mix of 600-year-old palaces and the contemporary urban landscape characterized by towering skyscrapers.We begin our exciting three-day main conference program on May 27th with single-track technical paper sessions, a poster and demo session, two excellent keynotes from telecommunication security expert Prof. Jean-Pierre Seifert (TU Berlin) and wireless security expert Mathy Vanhoef (KU Leuven), and a panel on wireless security and AI. Three invited talks named "Vision Talk" discuss the future of wireless and mobile security issues. The WiseML Workshop follows the main program on May 30th. We invite participants to attend the exciting paper presentations and keynotes, interact with the presenters during the Q&amp;A sessions after each talk, network during the coffee breaks and lunches each day, and socialize during the banquet dinner.},
location = {Seoul, Republic of Korea}
}

@proceedings{10.1145/3679409,
title = {ISCER '24: Proceedings of the 2024 3rd International Symposium on Control Engineering and Robotics},
year = {2024},
isbn = {9798400709951},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Changsha, China}
}

@proceedings{10.1145/3651781,
title = {ICSCA '24: Proceedings of the 2024 13th International Conference on Software and Computer Applications},
year = {2024},
isbn = {9798400708329},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Bali Island, Indonesia}
}

@proceedings{10.1145/3611315,
title = {NANOARCH '23: Proceedings of the 18th ACM International Symposium on Nanoscale Architectures},
year = {2023},
isbn = {9798400703256},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Dresden, Germany}
}

@proceedings{10.1145/3695652,
title = {IMMS '24: Proceedings of the 2024 7th International Conference on Information Management and Management Science},
year = {2024},
isbn = {9798400716997},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Beijing, China}
}

@proceedings{10.1145/3661814,
title = {LICS '24: Proceedings of the 39th Annual ACM/IEEE Symposium on Logic in Computer Science},
year = {2024},
isbn = {9798400706608},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {This volume contains the proceedings of the 39th Annual ACM/IEEE Symposium on Logic in Computer Science (LICS 2024).},
location = {Tallinn, Estonia}
}

@proceedings{10.1145/3655532,
title = {ICRSA '23: Proceedings of the 2023 6th International Conference on Robot Systems and Applications},
year = {2023},
isbn = {9798400708039},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Wuhan, China}
}

@proceedings{10.1145/3688459,
title = {EuroUSEC '24: Proceedings of the 2024 European Symposium on Usable Security},
year = {2024},
isbn = {9798400717963},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {
}
}

@proceedings{10.1145/3653946,
title = {ICMVA '24: Proceedings of the 2024 7th International Conference on Machine Vision and Applications},
year = {2024},
isbn = {9798400716553},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Singapore, Singapore}
}

@proceedings{10.1145/3640115,
title = {ICITEE '23: Proceedings of the 6th International Conference on Information Technologies and Electrical Engineering},
year = {2023},
isbn = {9798400708299},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
location = {Changde, Hunan, China}
}


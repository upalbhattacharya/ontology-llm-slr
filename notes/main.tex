\documentclass[a4paper,colorinlistoftodos]{article}
\input{preamble} % For common headers, utilities and styling
\input{hide} % For hiding TODOS, highlights, underlines and callouts

% Add other dependencies in preamble.tex (for cleaner visuals)

\author{Upal Bhattacharya}
\date{}
\title{Ontology LLM Systematic Literature Review}
\begin{document}

\maketitle

\begingroup
    \hypersetup{linkcolor=black}
    \tableofcontents
    \listoftodos
    \pagebreak
\endgroup

\linenumbers

\section{Variables to categorize along}
\label{sec:variables}

\begin{itemize}
\item OL Layer-Cake (Default Task categorization) \textit{add citation here}
\item NLP approach-based categorization of OL tasks.
  From \cite{du2024ShortReviewOntology}
\item Prompting vs. Fine-tuning methods
\item Low-resource approaches
\item Ontology learning tasks vs. ontology enrichment tasks and unifying the
  different task classifications
\end{itemize}

\section{Keyword Selection}
\label{sec:keyword-selection}

\subsection{Semantic Terms}
\label{subsec:semantic-terms}

\begin{itemize}
  \item \citet{babaei2023Llms4olLargeLanguage}: Ontologies, Ontology Learning
  \item \citet{babaei2025Llms4omMatchingOntologies}: Ontology Matching,
    Ontology Alignment
  \item \citet{li2025LargeLanguageModels}: Ontology Engineering, Ontology
    Development, \textit{ontolog*, ontology development,
    vocabulary}
\item \citet{mai2024DoLlmsReally}: ontology learning
\item \citet{bakker2024OntologyLearningText}: ontology learning
\item \citet{chen2023ContextualSemanticEmbeddings}: ontology embedding,
  subsumption prediction, ontology alignment, OWL
\end{itemize}

\subsection{LLM Terms}
\label{subsec:llm-terms}

\begin{itemize}
  \item \citet{babaei2023Llms4olLargeLanguage}: Large Language Models, LLMs
  \item \citet{babaei2025Llms4omMatchingOntologies}: Large Language Models
  \item \citet{li2025LargeLanguageModels}: Large Language Models,
    \textit{Language Model, LM, LLM*}
  \item \citet{mai2024DoLlmsReally}: LLMs
  \item \citet{bakker2024OntologyLearningText}: large language models
  \item \citet{chen2023ContextualSemanticEmbeddings}: Pre-trained language
    model, BERT
\end{itemize}

\bibliographystyle{splncs04nat}
\bibliography{bibliography}
\end{document}

